2019-04-13 16:58:34.352147 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size              300
trainer/QF1 Loss                  3.82339
trainer/QF2 Loss                  3.83577
trainer/Policy Loss               0.00743909
trainer/Q1 Predictions Mean      -0.00188859
trainer/Q1 Predictions Std        0.000307365
trainer/Q1 Predictions Max       -0.00129125
trainer/Q1 Predictions Min       -0.00230473
trainer/Q2 Predictions Mean       0.00115081
trainer/Q2 Predictions Std        0.000672095
trainer/Q2 Predictions Max        0.00199098
trainer/Q2 Predictions Min       -0.000191887
trainer/Q Targets Mean           -1.78311
trainer/Q Targets Std             0.806917
trainer/Q Targets Max            -0.385482
trainer/Q Targets Min            -2.82856
trainer/Bellman Errors 1 Mean     3.82339
trainer/Bellman Errors 1 Std      2.80643
trainer/Bellman Errors 1 Max      7.98771
trainer/Bellman Errors 1 Min      0.147523
trainer/Bellman Errors 2 Mean     3.83577
trainer/Bellman Errors 2 Std      2.81448
trainer/Bellman Errors 2 Max      8.01169
trainer/Bellman Errors 2 Min      0.148882
trainer/Policy Action Mean        0.00316276
trainer/Policy Action Std         0.00188833
trainer/Policy Action Max         0.00513356
trainer/Policy Action Min         0.000869562
exploration/num steps total     300
exploration/num paths total       3
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.96047
exploration/Rewards Std           0.548548
exploration/Rewards Max          -0.995645
exploration/Rewards Min          -2.91497
exploration/Returns Mean       -196.047
exploration/Returns Std          46.9908
exploration/Returns Max        -149.056
exploration/Returns Min        -243.038
exploration/Actions Mean          0.00917653
exploration/Actions Std           0.0954503
exploration/Actions Max           0.315903
exploration/Actions Min          -0.329624
exploration/Num Paths             2
exploration/Average Returns    -196.047
evaluation/num steps total      500
evaluation/num paths total        5
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.949621
evaluation/Rewards Std            0.475303
evaluation/Rewards Max           -0.192081
evaluation/Rewards Min           -1.8117
evaluation/Returns Mean         -94.9621
evaluation/Returns Std           46.1716
evaluation/Returns Max          -42.6815
evaluation/Returns Min         -169.357
evaluation/Actions Mean           0.00321972
evaluation/Actions Std            0.00176278
evaluation/Actions Max            0.00520924
evaluation/Actions Min            0.000822333
evaluation/Num Paths              5
evaluation/Average Returns      -94.9621
time/data storing (s)             0.00185946
time/evaluation sampling (s)      0.0953655
time/exploration sampling (s)     0.0520671
time/logging (s)                  0.00263295
time/saving (s)                   0.00250488
time/training (s)                 0.421557
time/epoch (s)                    0.575987
time/total (s)                    0.736695
Epoch                             0
-----------------------------  --------------
2019-04-13 16:58:34.913281 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size              500
trainer/QF1 Loss                  0.135491
trainer/QF2 Loss                  0.187926
trainer/Policy Loss               0.711073
trainer/Q1 Predictions Mean      -1.09026
trainer/Q1 Predictions Std        0.898767
trainer/Q1 Predictions Max       -0.297887
trainer/Q1 Predictions Min       -2.98632
trainer/Q2 Predictions Mean      -1.04612
trainer/Q2 Predictions Std        0.937322
trainer/Q2 Predictions Max       -0.17803
trainer/Q2 Predictions Min       -2.99225
trainer/Q Targets Mean           -1.30896
trainer/Q Targets Std             0.760076
trainer/Q Targets Max            -0.532862
trainer/Q Targets Min            -3.06205
trainer/Bellman Errors 1 Mean     0.135491
trainer/Bellman Errors 1 Std      0.199846
trainer/Bellman Errors 1 Max      0.569814
trainer/Bellman Errors 1 Min      4.92e-05
trainer/Bellman Errors 2 Mean     0.187926
trainer/Bellman Errors 2 Std      0.272362
trainer/Bellman Errors 2 Max      0.764579
trainer/Bellman Errors 2 Min      4.84404e-05
trainer/Policy Action Mean        0.00274222
trainer/Policy Action Std         0.991291
trainer/Policy Action Max         0.999679
trainer/Policy Action Min        -0.999103
exploration/num steps total     500
exploration/num paths total       5
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.752846
exploration/Rewards Std           0.183427
exploration/Rewards Max          -0.522941
exploration/Rewards Min          -0.938064
exploration/Returns Mean        -75.2846
exploration/Returns Std          18.1931
exploration/Returns Max         -57.0915
exploration/Returns Min         -93.4776
exploration/Actions Mean         -0.000157946
exploration/Actions Std           0.954917
exploration/Actions Max           1
exploration/Actions Min          -1
exploration/Num Paths             2
exploration/Average Returns     -75.2846
evaluation/num steps total     1000
evaluation/num paths total       10
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.35777
evaluation/Rewards Std            0.275295
evaluation/Rewards Max           -0.376869
evaluation/Rewards Min           -1.54162
evaluation/Returns Mean        -135.777
evaluation/Returns Std           27.2086
evaluation/Returns Max          -81.907
evaluation/Returns Min         -154.162
evaluation/Actions Mean           0.00846859
evaluation/Actions Std            0.966532
evaluation/Actions Max            0.998232
evaluation/Actions Min           -0.995935
evaluation/Num Paths              5
evaluation/Average Returns     -135.777
time/data storing (s)             0.00105835
time/evaluation sampling (s)      0.0840003
time/exploration sampling (s)     0.033499
time/logging (s)                  0.00235986
time/saving (s)                   0.00229478
time/training (s)                 0.432489
time/epoch (s)                    0.555701
time/total (s)                    1.29679
Epoch                             1
-----------------------------  --------------
2019-04-13 16:58:35.478449 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 2 finished
-----------------------------  --------------
replay_buffer/size              700
trainer/QF1 Loss                  0.0459229
trainer/QF2 Loss                  0.0287641
trainer/Policy Loss               1.1402
trainer/Q1 Predictions Mean      -1.52572
trainer/Q1 Predictions Std        0.7781
trainer/Q1 Predictions Max       -0.867818
trainer/Q1 Predictions Min       -3.51131
trainer/Q2 Predictions Mean      -1.52644
trainer/Q2 Predictions Std        0.783899
trainer/Q2 Predictions Max       -0.829391
trainer/Q2 Predictions Min       -3.51455
trainer/Q Targets Mean           -1.59098
trainer/Q Targets Std             0.79206
trainer/Q Targets Max            -0.793146
trainer/Q Targets Min            -3.55578
trainer/Bellman Errors 1 Mean     0.0459229
trainer/Bellman Errors 1 Std      0.117316
trainer/Bellman Errors 1 Max      0.420297
trainer/Bellman Errors 1 Min      2.41221e-09
trainer/Bellman Errors 2 Mean     0.0287641
trainer/Bellman Errors 2 Std      0.069605
trainer/Bellman Errors 2 Max      0.254867
trainer/Bellman Errors 2 Min      1.45829e-05
trainer/Policy Action Mean        0.000314411
trainer/Policy Action Std         0.705198
trainer/Policy Action Max         0.998676
trainer/Policy Action Min        -0.998711
exploration/num steps total     700
exploration/num paths total       7
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.06413
exploration/Rewards Std           0.432409
exploration/Rewards Max          -0.632367
exploration/Rewards Min          -1.5
exploration/Returns Mean       -106.413
exploration/Returns Std          43.1763
exploration/Returns Max         -63.2367
exploration/Returns Min        -149.589
exploration/Actions Mean         -0.00182567
exploration/Actions Std           0.485504
exploration/Actions Max           0.969029
exploration/Actions Min          -1
exploration/Num Paths             2
exploration/Average Returns    -106.413
evaluation/num steps total     1500
evaluation/num paths total       15
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.03052
evaluation/Rewards Std            0.403087
evaluation/Rewards Max           -0.531017
evaluation/Rewards Min           -1.50257
evaluation/Returns Mean        -103.052
evaluation/Returns Std           40.1915
evaluation/Returns Max          -59.5483
evaluation/Returns Min         -149.878
evaluation/Actions Mean           0.000442601
evaluation/Actions Std            0.499459
evaluation/Actions Max            0.98759
evaluation/Actions Min           -0.987802
evaluation/Num Paths              5
evaluation/Average Returns     -103.052
time/data storing (s)             0.00107809
time/evaluation sampling (s)      0.0832118
time/exploration sampling (s)     0.0350207
time/logging (s)                  0.00250251
time/saving (s)                   0.00252668
time/training (s)                 0.436565
time/epoch (s)                    0.560905
time/total (s)                    1.86149
Epoch                             2
-----------------------------  --------------
2019-04-13 16:58:36.038447 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 3 finished
-----------------------------  --------------
replay_buffer/size              900
trainer/QF1 Loss                  0.00668901
trainer/QF2 Loss                  0.00587825
trainer/Policy Loss               1.46547
trainer/Q1 Predictions Mean      -1.84406
trainer/Q1 Predictions Std        0.774314
trainer/Q1 Predictions Max       -1.03312
trainer/Q1 Predictions Min       -4.20409
trainer/Q2 Predictions Mean      -1.84281
trainer/Q2 Predictions Std        0.780248
trainer/Q2 Predictions Max       -1.00675
trainer/Q2 Predictions Min       -4.23011
trainer/Q Targets Mean           -1.83938
trainer/Q Targets Std             0.753715
trainer/Q Targets Max            -0.908228
trainer/Q Targets Min            -4.00138
trainer/Bellman Errors 1 Mean     0.00668901
trainer/Bellman Errors 1 Std      0.0116137
trainer/Bellman Errors 1 Max      0.0438657
trainer/Bellman Errors 1 Min      3.67742e-07
trainer/Bellman Errors 2 Mean     0.00587825
trainer/Bellman Errors 2 Std      0.0113455
trainer/Bellman Errors 2 Max      0.0523142
trainer/Bellman Errors 2 Min      8.95001e-07
trainer/Policy Action Mean        0.00393128
trainer/Policy Action Std         0.782092
trainer/Policy Action Max         0.999952
trainer/Policy Action Min        -0.999929
exploration/num steps total     900
exploration/num paths total       9
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.31081
exploration/Rewards Std           0.200229
exploration/Rewards Max          -0.455216
exploration/Rewards Min          -1.50478
exploration/Returns Mean       -131.081
exploration/Returns Std          19.3966
exploration/Returns Max        -111.684
exploration/Returns Min        -150.478
exploration/Actions Mean          0.00663287
exploration/Actions Std           0.528824
exploration/Actions Max           0.984607
exploration/Actions Min          -0.940129
exploration/Num Paths             2
exploration/Average Returns    -131.081
evaluation/num steps total     2000
evaluation/num paths total       20
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.05614
evaluation/Rewards Std            0.343518
evaluation/Rewards Max           -0.665656
evaluation/Rewards Min           -1.4819
evaluation/Returns Mean        -105.614
evaluation/Returns Std           34.3104
evaluation/Returns Max          -66.5656
evaluation/Returns Min         -147.812
evaluation/Actions Mean           0.00524231
evaluation/Actions Std            0.624981
evaluation/Actions Max            0.982662
evaluation/Actions Min           -0.979553
evaluation/Num Paths              5
evaluation/Average Returns     -105.614
time/data storing (s)             0.00116361
time/evaluation sampling (s)      0.0830046
time/exploration sampling (s)     0.0333366
time/logging (s)                  0.00244743
time/saving (s)                   0.00221813
time/training (s)                 0.433103
time/epoch (s)                    0.555274
time/total (s)                    2.42072
Epoch                             3
-----------------------------  --------------
2019-04-13 16:58:36.596846 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 4 finished
-----------------------------  --------------
replay_buffer/size             1100
trainer/QF1 Loss                  0.0228062
trainer/QF2 Loss                  0.0229052
trainer/Policy Loss               2.07797
trainer/Q1 Predictions Mean      -2.34529
trainer/Q1 Predictions Std        0.811987
trainer/Q1 Predictions Max       -1.22285
trainer/Q1 Predictions Min       -4.21754
trainer/Q2 Predictions Mean      -2.34343
trainer/Q2 Predictions Std        0.811547
trainer/Q2 Predictions Max       -1.2495
trainer/Q2 Predictions Min       -4.23322
trainer/Q Targets Mean           -2.31654
trainer/Q Targets Std             0.858321
trainer/Q Targets Max            -0.632367
trainer/Q Targets Min            -4.25575
trainer/Bellman Errors 1 Mean     0.0228062
trainer/Bellman Errors 1 Std      0.106357
trainer/Bellman Errors 1 Max      0.61391
trainer/Bellman Errors 1 Min      8.1991e-08
trainer/Bellman Errors 2 Mean     0.0229052
trainer/Bellman Errors 2 Std      0.107566
trainer/Bellman Errors 2 Max      0.620823
trainer/Bellman Errors 2 Min      2.02595e-08
trainer/Policy Action Mean       -0.0833174
trainer/Policy Action Std         0.49675
trainer/Policy Action Max         0.991092
trainer/Policy Action Min        -0.99993
exploration/num steps total    1100
exploration/num paths total      11
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.60976
exploration/Rewards Std           0.0781593
exploration/Rewards Max          -1.18165
exploration/Rewards Min          -1.68004
exploration/Returns Mean       -160.976
exploration/Returns Std           6.80067
exploration/Returns Max        -154.175
exploration/Returns Min        -167.776
exploration/Actions Mean         -0.110778
exploration/Actions Std           0.332317
exploration/Actions Max           1
exploration/Actions Min          -1
exploration/Num Paths             2
exploration/Average Returns    -160.976
evaluation/num steps total     2500
evaluation/num paths total       25
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.52824
evaluation/Rewards Std            0.0655383
evaluation/Rewards Max           -0.553267
evaluation/Rewards Min           -1.56529
evaluation/Returns Mean        -152.824
evaluation/Returns Std            3.009
evaluation/Returns Max         -149.195
evaluation/Returns Min         -156.472
evaluation/Actions Mean          -0.0936133
evaluation/Actions Std            0.241103
evaluation/Actions Max            0.969384
evaluation/Actions Min           -0.999279
evaluation/Num Paths              5
evaluation/Average Returns     -152.824
time/data storing (s)             0.00116123
time/evaluation sampling (s)      0.0835212
time/exploration sampling (s)     0.0337054
time/logging (s)                  0.0024481
time/saving (s)                   0.00228136
time/training (s)                 0.430738
time/epoch (s)                    0.553856
time/total (s)                    2.9784
Epoch                             4
-----------------------------  --------------
2019-04-13 16:58:37.157468 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 5 finished
-----------------------------  --------------
replay_buffer/size             1300
trainer/QF1 Loss                  0.0148533
trainer/QF2 Loss                  0.0152993
trainer/Policy Loss               2.77803
trainer/Q1 Predictions Mean      -3.0091
trainer/Q1 Predictions Std        0.966068
trainer/Q1 Predictions Max       -1.38139
trainer/Q1 Predictions Min       -4.89822
trainer/Q2 Predictions Mean      -3.04768
trainer/Q2 Predictions Std        0.984136
trainer/Q2 Predictions Max       -1.39593
trainer/Q2 Predictions Min       -4.91322
trainer/Q Targets Mean           -2.97905
trainer/Q Targets Std             0.986102
trainer/Q Targets Max            -1.1023
trainer/Q Targets Min            -4.88386
trainer/Bellman Errors 1 Mean     0.0148533
trainer/Bellman Errors 1 Std      0.0345514
trainer/Bellman Errors 1 Max      0.187967
trainer/Bellman Errors 1 Min      6.18312e-05
trainer/Bellman Errors 2 Mean     0.0152993
trainer/Bellman Errors 2 Std      0.0213957
trainer/Bellman Errors 2 Max      0.0862205
trainer/Bellman Errors 2 Min      0.000140702
trainer/Policy Action Mean       -0.0194923
trainer/Policy Action Std         0.406185
trainer/Policy Action Max         0.994118
trainer/Policy Action Min        -0.999977
exploration/num steps total    1300
exploration/num paths total      13
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.69488
exploration/Rewards Std           0.446033
exploration/Rewards Max          -0.349006
exploration/Rewards Min          -2.08709
exploration/Returns Mean       -169.488
exploration/Returns Std           1.16161
exploration/Returns Max        -168.327
exploration/Returns Min        -170.65
exploration/Actions Mean         -0.0256887
exploration/Actions Std           0.140576
exploration/Actions Max           0.452014
exploration/Actions Min          -0.500438
exploration/Num Paths             2
exploration/Average Returns    -169.488
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.83625
evaluation/Rewards Std            0.352404
evaluation/Rewards Max           -0.32412
evaluation/Rewards Min           -2.00102
evaluation/Returns Mean        -183.625
evaluation/Returns Std           18.33
evaluation/Returns Max         -147.547
evaluation/Returns Min         -198.116
evaluation/Actions Mean          -0.0177592
evaluation/Actions Std            0.0838582
evaluation/Actions Max            0.841551
evaluation/Actions Min           -0.983601
evaluation/Num Paths              5
evaluation/Average Returns     -183.625
time/data storing (s)             0.00111784
time/evaluation sampling (s)      0.0814287
time/exploration sampling (s)     0.0314527
time/logging (s)                  0.00245157
time/saving (s)                   0.00226387
time/training (s)                 0.4374
time/epoch (s)                    0.556114
time/total (s)                    3.5383
Epoch                             5
-----------------------------  --------------
2019-04-13 16:58:37.730759 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size             1500
trainer/QF1 Loss                  0.0116184
trainer/QF2 Loss                  0.0137998
trainer/Policy Loss               2.84453
trainer/Q1 Predictions Mean      -3.23611
trainer/Q1 Predictions Std        1.1668
trainer/Q1 Predictions Max       -1.52783
trainer/Q1 Predictions Min       -5.16224
trainer/Q2 Predictions Mean      -3.21955
trainer/Q2 Predictions Std        1.18963
trainer/Q2 Predictions Max       -1.44619
trainer/Q2 Predictions Min       -5.19965
trainer/Q Targets Mean           -3.19765
trainer/Q Targets Std             1.12802
trainer/Q Targets Max            -1.55515
trainer/Q Targets Min            -5.23205
trainer/Bellman Errors 1 Mean     0.0116184
trainer/Bellman Errors 1 Std      0.0199602
trainer/Bellman Errors 1 Max      0.0925966
trainer/Bellman Errors 1 Min      1.41456e-06
trainer/Bellman Errors 2 Mean     0.0137998
trainer/Bellman Errors 2 Std      0.0172753
trainer/Bellman Errors 2 Max      0.0774593
trainer/Bellman Errors 2 Min      4.2309e-05
trainer/Policy Action Mean        0.456302
trainer/Policy Action Std         0.521636
trainer/Policy Action Max         0.997879
trainer/Policy Action Min        -0.994815
exploration/num steps total    1500
exploration/num paths total      15
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.504037
exploration/Rewards Std           0.0403155
exploration/Rewards Max          -0.232554
exploration/Rewards Min          -0.895411
exploration/Returns Mean        -50.4037
exploration/Returns Std           0.0933465
exploration/Returns Max         -50.3103
exploration/Returns Min         -50.497
exploration/Actions Mean          0.153223
exploration/Actions Std           0.312773
exploration/Actions Max           1
exploration/Actions Min          -0.669993
exploration/Num Paths             2
exploration/Average Returns     -50.4037
evaluation/num steps total     3500
evaluation/num paths total       35
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.501018
evaluation/Rewards Std            0.0292275
evaluation/Rewards Max           -0.242944
evaluation/Rewards Min           -0.946227
evaluation/Returns Mean         -50.1018
evaluation/Returns Std            0.201846
evaluation/Returns Max          -49.8522
evaluation/Returns Min          -50.4611
evaluation/Actions Mean           0.18142
evaluation/Actions Std            0.254475
evaluation/Actions Max            0.987701
evaluation/Actions Min           -0.923898
evaluation/Num Paths              5
evaluation/Average Returns      -50.1018
time/data storing (s)             0.00113667
time/evaluation sampling (s)      0.0808673
time/exploration sampling (s)     0.032095
time/logging (s)                  0.00246937
time/saving (s)                   0.00228982
time/training (s)                 0.450216
time/epoch (s)                    0.569074
time/total (s)                    4.11087
Epoch                             6
-----------------------------  --------------
2019-04-13 16:58:38.301991 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size             1700
trainer/QF1 Loss                  0.0222624
trainer/QF2 Loss                  0.0235345
trainer/Policy Loss               2.74235
trainer/Q1 Predictions Mean      -3.32007
trainer/Q1 Predictions Std        1.26435
trainer/Q1 Predictions Max       -1.68669
trainer/Q1 Predictions Min       -5.53214
trainer/Q2 Predictions Mean      -3.31674
trainer/Q2 Predictions Std        1.26871
trainer/Q2 Predictions Max       -1.70152
trainer/Q2 Predictions Min       -5.56073
trainer/Q Targets Mean           -3.41685
trainer/Q Targets Std             1.30127
trainer/Q Targets Max            -1.74004
trainer/Q Targets Min            -5.93258
trainer/Bellman Errors 1 Mean     0.0222624
trainer/Bellman Errors 1 Std      0.0436873
trainer/Bellman Errors 1 Max      0.160355
trainer/Bellman Errors 1 Min      2.2038e-07
trainer/Bellman Errors 2 Mean     0.0235345
trainer/Bellman Errors 2 Std      0.0418079
trainer/Bellman Errors 2 Max      0.160979
trainer/Bellman Errors 2 Min      1.18329e-05
trainer/Policy Action Mean        0.32713
trainer/Policy Action Std         0.714831
trainer/Policy Action Max         0.999717
trainer/Policy Action Min        -0.993464
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.605265
exploration/Rewards Std           0.0820092
exploration/Rewards Max          -0.115647
exploration/Rewards Min          -1.14192
exploration/Returns Mean        -60.5265
exploration/Returns Std           5.2227
exploration/Returns Max         -55.3038
exploration/Returns Min         -65.7493
exploration/Actions Mean          0.327359
exploration/Actions Std           0.241007
exploration/Actions Max           1
exploration/Actions Min          -1
exploration/Num Paths             2
exploration/Average Returns     -60.5265
evaluation/num steps total     4000
evaluation/num paths total       40
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.570287
evaluation/Rewards Std            0.0599766
evaluation/Rewards Max           -0.0755531
evaluation/Rewards Min           -0.952847
evaluation/Returns Mean         -57.0287
evaluation/Returns Std            4.44187
evaluation/Returns Max          -53.0267
evaluation/Returns Min          -65.2696
evaluation/Actions Mean           0.225607
evaluation/Actions Std            0.202854
evaluation/Actions Max            0.997444
evaluation/Actions Min           -0.878147
evaluation/Num Paths              5
evaluation/Average Returns      -57.0287
time/data storing (s)             0.00111582
time/evaluation sampling (s)      0.0821183
time/exploration sampling (s)     0.0447442
time/logging (s)                  0.00245335
time/saving (s)                   0.00723187
time/training (s)                 0.428947
time/epoch (s)                    0.566611
time/total (s)                    4.68133
Epoch                             7
-----------------------------  --------------
2019-04-13 16:58:38.883095 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size             1900
trainer/QF1 Loss                  0.00496463
trainer/QF2 Loss                  0.00654797
trainer/Policy Loss               3.06738
trainer/Q1 Predictions Mean      -3.49614
trainer/Q1 Predictions Std        1.32721
trainer/Q1 Predictions Max       -1.91779
trainer/Q1 Predictions Min       -6.01358
trainer/Q2 Predictions Mean      -3.48627
trainer/Q2 Predictions Std        1.3298
trainer/Q2 Predictions Max       -1.90442
trainer/Q2 Predictions Min       -5.96776
trainer/Q Targets Mean           -3.5107
trainer/Q Targets Std             1.30437
trainer/Q Targets Max            -1.93976
trainer/Q Targets Min            -5.80728
trainer/Bellman Errors 1 Mean     0.00496463
trainer/Bellman Errors 1 Std      0.00960133
trainer/Bellman Errors 1 Max      0.042562
trainer/Bellman Errors 1 Min      6.53723e-06
trainer/Bellman Errors 2 Mean     0.00654797
trainer/Bellman Errors 2 Std      0.0104118
trainer/Bellman Errors 2 Max      0.0396421
trainer/Bellman Errors 2 Min      3.81665e-05
trainer/Policy Action Mean        0.491456
trainer/Policy Action Std         0.551338
trainer/Policy Action Max         0.999701
trainer/Policy Action Min        -0.971418
exploration/num steps total    1900
exploration/num paths total      19
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.620297
exploration/Rewards Std           0.0410522
exploration/Rewards Max          -0.41576
exploration/Rewards Min          -0.654877
exploration/Returns Mean        -62.0297
exploration/Returns Std           0.704078
exploration/Returns Max         -61.3256
exploration/Returns Min         -62.7338
exploration/Actions Mean          0.256137
exploration/Actions Std           0.24056
exploration/Actions Max           0.881739
exploration/Actions Min          -0.9332
exploration/Num Paths             2
exploration/Average Returns     -62.0297
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.604344
evaluation/Rewards Std            0.0647475
evaluation/Rewards Max           -0.0362353
evaluation/Rewards Min           -1.02756
evaluation/Returns Mean         -60.4344
evaluation/Returns Std            3.45659
evaluation/Returns Max          -53.7944
evaluation/Returns Min          -63.2081
evaluation/Actions Mean           0.227645
evaluation/Actions Std            0.213151
evaluation/Actions Max            0.998374
evaluation/Actions Min           -0.879731
evaluation/Num Paths              5
evaluation/Average Returns      -60.4344
time/data storing (s)             0.00108929
time/evaluation sampling (s)      0.0883782
time/exploration sampling (s)     0.0342552
time/logging (s)                  0.00246894
time/saving (s)                   0.00225189
time/training (s)                 0.448546
time/epoch (s)                    0.57699
time/total (s)                    5.26165
Epoch                             8
-----------------------------  --------------
2019-04-13 16:58:39.448862 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size             2100
trainer/QF1 Loss                  0.148756
trainer/QF2 Loss                  0.151401
trainer/Policy Loss               3.0727
trainer/Q1 Predictions Mean      -3.39115
trainer/Q1 Predictions Std        1.12126
trainer/Q1 Predictions Max       -2.04049
trainer/Q1 Predictions Min       -5.55753
trainer/Q2 Predictions Mean      -3.38242
trainer/Q2 Predictions Std        1.12567
trainer/Q2 Predictions Max       -1.9891
trainer/Q2 Predictions Min       -5.55815
trainer/Q Targets Mean           -3.30823
trainer/Q Targets Std             1.2008
trainer/Q Targets Max            -0.5714
trainer/Q Targets Min            -5.4264
trainer/Bellman Errors 1 Mean     0.148756
trainer/Bellman Errors 1 Std      0.682593
trainer/Bellman Errors 1 Max      3.93985
trainer/Bellman Errors 1 Min      5.4757e-05
trainer/Bellman Errors 2 Mean     0.151401
trainer/Bellman Errors 2 Std      0.696304
trainer/Bellman Errors 2 Max      4.02031
trainer/Bellman Errors 2 Min      1.17318e-06
trainer/Policy Action Mean        0.470313
trainer/Policy Action Std         0.459951
trainer/Policy Action Max         0.998801
trainer/Policy Action Min        -0.839127
exploration/num steps total    2100
exploration/num paths total      21
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.559061
exploration/Rewards Std           0.0894706
exploration/Rewards Max          -0.179994
exploration/Rewards Min          -0.665677
exploration/Returns Mean        -55.9061
exploration/Returns Std           0.300795
exploration/Returns Max         -55.6053
exploration/Returns Min         -56.2069
exploration/Actions Mean          0.142928
exploration/Actions Std           0.205133
exploration/Actions Max           0.641164
exploration/Actions Min          -0.744097
exploration/Num Paths             2
exploration/Average Returns     -55.9061
evaluation/num steps total     5000
evaluation/num paths total       50
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.526589
evaluation/Rewards Std            0.0564232
evaluation/Rewards Max           -0.0706617
evaluation/Rewards Min           -0.699629
evaluation/Returns Mean         -52.6589
evaluation/Returns Std            0.658532
evaluation/Returns Max          -51.7437
evaluation/Returns Min          -53.4632
evaluation/Actions Mean           0.00246222
evaluation/Actions Std            0.0992065
evaluation/Actions Max            0.992252
evaluation/Actions Min           -0.721959
evaluation/Num Paths              5
evaluation/Average Returns      -52.6589
time/data storing (s)             0.00116475
time/evaluation sampling (s)      0.0843759
time/exploration sampling (s)     0.0329944
time/logging (s)                  0.00246864
time/saving (s)                   0.00224476
time/training (s)                 0.437911
time/epoch (s)                    0.56116
time/total (s)                    5.82662
Epoch                             9
-----------------------------  --------------
2019-04-13 16:58:40.012311 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size             2300
trainer/QF1 Loss                  0.258769
trainer/QF2 Loss                  0.25434
trainer/Policy Loss               2.96321
trainer/Q1 Predictions Mean      -3.22176
trainer/Q1 Predictions Std        1.09707
trainer/Q1 Predictions Max       -2.24054
trainer/Q1 Predictions Min       -5.70586
trainer/Q2 Predictions Mean      -3.22601
trainer/Q2 Predictions Std        1.09103
trainer/Q2 Predictions Max       -2.24183
trainer/Q2 Predictions Min       -5.66808
trainer/Q Targets Mean           -3.25965
trainer/Q Targets Std             1.19703
trainer/Q Targets Max            -0.938064
trainer/Q Targets Min            -5.84856
trainer/Bellman Errors 1 Mean     0.258769
trainer/Bellman Errors 1 Std      1.28147
trainer/Bellman Errors 1 Max      7.39209
trainer/Bellman Errors 1 Min      2.63618e-06
trainer/Bellman Errors 2 Mean     0.25434
trainer/Bellman Errors 2 Std      1.27873
trainer/Bellman Errors 2 Max      7.37285
trainer/Bellman Errors 2 Min      0.000180278
trainer/Policy Action Mean        0.416305
trainer/Policy Action Std         0.466935
trainer/Policy Action Max         0.998184
trainer/Policy Action Min        -0.794088
exploration/num steps total    2300
exploration/num paths total      23
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.586107
exploration/Rewards Std           0.0827614
exploration/Rewards Max          -0.391985
exploration/Rewards Min          -1.36772
exploration/Returns Mean        -58.6107
exploration/Returns Std           4.03727
exploration/Returns Max         -54.5734
exploration/Returns Min         -62.6479
exploration/Actions Mean          0.287524
exploration/Actions Std           0.277303
exploration/Actions Max           1
exploration/Actions Min          -0.653685
exploration/Num Paths             2
exploration/Average Returns     -58.6107
evaluation/num steps total     5500
evaluation/num paths total       55
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.517785
evaluation/Rewards Std            0.0421413
evaluation/Rewards Max           -0.220354
evaluation/Rewards Min           -1.29722
evaluation/Returns Mean         -51.7785
evaluation/Returns Std            0.165193
evaluation/Returns Max          -51.5947
evaluation/Returns Min          -52.0882
evaluation/Actions Mean           0.11478
evaluation/Actions Std            0.217434
evaluation/Actions Max            0.998382
evaluation/Actions Min           -0.593978
evaluation/Num Paths              5
evaluation/Average Returns      -51.7785
time/data storing (s)             0.00111907
time/evaluation sampling (s)      0.0831559
time/exploration sampling (s)     0.0321132
time/logging (s)                  0.00248553
time/saving (s)                   0.00224601
time/training (s)                 0.437732
time/epoch (s)                    0.558852
time/total (s)                    6.38929
Epoch                            10
-----------------------------  --------------
2019-04-13 16:58:40.561315 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size             2500
trainer/QF1 Loss                  0.00681829
trainer/QF2 Loss                  0.00610344
trainer/Policy Loss               3.62296
trainer/Q1 Predictions Mean      -4.09275
trainer/Q1 Predictions Std        1.49615
trainer/Q1 Predictions Max       -2.3967
trainer/Q1 Predictions Min       -6.60942
trainer/Q2 Predictions Mean      -4.09423
trainer/Q2 Predictions Std        1.48759
trainer/Q2 Predictions Max       -2.43622
trainer/Q2 Predictions Min       -6.60205
trainer/Q Targets Mean           -4.10293
trainer/Q Targets Std             1.49209
trainer/Q Targets Max            -2.54532
trainer/Q Targets Min            -6.60977
trainer/Bellman Errors 1 Mean     0.00681829
trainer/Bellman Errors 1 Std      0.0189188
trainer/Bellman Errors 1 Max      0.103068
trainer/Bellman Errors 1 Min      1.19843e-07
trainer/Bellman Errors 2 Mean     0.00610344
trainer/Bellman Errors 2 Std      0.0179928
trainer/Bellman Errors 2 Max      0.102407
trainer/Bellman Errors 2 Min      9.00585e-06
trainer/Policy Action Mean        0.231923
trainer/Policy Action Std         0.456857
trainer/Policy Action Max         0.999269
trainer/Policy Action Min        -0.77146
exploration/num steps total    2500
exploration/num paths total      25
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.356996
exploration/Rewards Std           0.139
exploration/Rewards Max          -0.0229346
exploration/Rewards Min          -0.608756
exploration/Returns Mean        -35.6996
exploration/Returns Std           0.695868
exploration/Returns Max         -35.0037
exploration/Returns Min         -36.3954
exploration/Actions Mean          0.00178815
exploration/Actions Std           0.193296
exploration/Actions Max           0.97068
exploration/Actions Min          -0.776671
exploration/Num Paths             2
exploration/Average Returns     -35.6996
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.341691
evaluation/Rewards Std            0.0371992
evaluation/Rewards Max           -0.073294
evaluation/Rewards Min           -0.868923
evaluation/Returns Mean         -34.1691
evaluation/Returns Std            0.203357
evaluation/Returns Max          -33.9698
evaluation/Returns Min          -34.5334
evaluation/Actions Mean           0.00502022
evaluation/Actions Std            0.0781059
evaluation/Actions Max            0.966943
evaluation/Actions Min           -0.460686
evaluation/Num Paths              5
evaluation/Average Returns      -34.1691
time/data storing (s)             0.00120651
time/evaluation sampling (s)      0.0742707
time/exploration sampling (s)     0.0344399
time/logging (s)                  0.00231091
time/saving (s)                   0.00223581
time/training (s)                 0.429736
time/epoch (s)                    0.5442
time/total (s)                    6.93724
Epoch                            11
-----------------------------  --------------
2019-04-13 16:58:41.123081 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size             2700
trainer/QF1 Loss                  0.0110876
trainer/QF2 Loss                  0.0111839
trainer/Policy Loss               3.36992
trainer/Q1 Predictions Mean      -3.90092
trainer/Q1 Predictions Std        1.31394
trainer/Q1 Predictions Max       -2.52134
trainer/Q1 Predictions Min       -6.15236
trainer/Q2 Predictions Mean      -3.89849
trainer/Q2 Predictions Std        1.31539
trainer/Q2 Predictions Max       -2.52734
trainer/Q2 Predictions Min       -6.17547
trainer/Q Targets Mean           -3.91604
trainer/Q Targets Std             1.37015
trainer/Q Targets Max            -2.37385
trainer/Q Targets Min            -6.45078
trainer/Bellman Errors 1 Mean     0.0110876
trainer/Bellman Errors 1 Std      0.0181992
trainer/Bellman Errors 1 Max      0.0980265
trainer/Bellman Errors 1 Min      5.20703e-05
trainer/Bellman Errors 2 Mean     0.0111839
trainer/Bellman Errors 2 Std      0.0165154
trainer/Bellman Errors 2 Max      0.0801554
trainer/Bellman Errors 2 Min      5.91863e-06
trainer/Policy Action Mean        0.0655967
trainer/Policy Action Std         0.562272
trainer/Policy Action Max         0.997501
trainer/Policy Action Min        -0.870427
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.211711
exploration/Rewards Std           0.117047
exploration/Rewards Max          -0.015478
exploration/Rewards Min          -0.77691
exploration/Returns Mean        -21.1711
exploration/Returns Std           0.388773
exploration/Returns Max         -20.7823
exploration/Returns Min         -21.5599
exploration/Actions Mean          0.00579997
exploration/Actions Std           0.175945
exploration/Actions Max           0.803813
exploration/Actions Min          -0.551971
exploration/Num Paths             2
exploration/Average Returns     -21.1711
evaluation/num steps total     6500
evaluation/num paths total       65
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.182972
evaluation/Rewards Std            0.0600266
evaluation/Rewards Max           -0.0935003
evaluation/Rewards Min           -1.00244
evaluation/Returns Mean         -18.2972
evaluation/Returns Std            0.30892
evaluation/Returns Max          -17.8195
evaluation/Returns Min          -18.747
evaluation/Actions Mean           0.00758484
evaluation/Actions Std            0.0935474
evaluation/Actions Max            0.995312
evaluation/Actions Min           -0.587383
evaluation/Num Paths              5
evaluation/Average Returns      -18.2972
time/data storing (s)             0.0010997
time/evaluation sampling (s)      0.0768681
time/exploration sampling (s)     0.0325601
time/logging (s)                  0.00247863
time/saving (s)                   0.00225638
time/training (s)                 0.442382
time/epoch (s)                    0.557645
time/total (s)                    7.4986
Epoch                            12
-----------------------------  --------------
2019-04-13 16:58:41.690523 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size             2900
trainer/QF1 Loss                  0.111644
trainer/QF2 Loss                  0.108247
trainer/Policy Loss               3.20232
trainer/Q1 Predictions Mean      -3.63835
trainer/Q1 Predictions Std        1.14476
trainer/Q1 Predictions Max       -2.53803
trainer/Q1 Predictions Min       -6.66249
trainer/Q2 Predictions Mean      -3.63848
trainer/Q2 Predictions Std        1.14523
trainer/Q2 Predictions Max       -2.5861
trainer/Q2 Predictions Min       -6.6547
trainer/Q Targets Mean           -3.79058
trainer/Q Targets Std             1.2348
trainer/Q Targets Max            -2.48918
trainer/Q Targets Min            -6.94858
trainer/Bellman Errors 1 Mean     0.111644
trainer/Bellman Errors 1 Std      0.490427
trainer/Bellman Errors 1 Max      2.83903
trainer/Bellman Errors 1 Min      0.000921251
trainer/Bellman Errors 2 Mean     0.108247
trainer/Bellman Errors 2 Std      0.472548
trainer/Bellman Errors 2 Max      2.73642
trainer/Bellman Errors 2 Min      1.45943e-06
trainer/Policy Action Mean        0.0878443
trainer/Policy Action Std         0.481972
trainer/Policy Action Max         0.997871
trainer/Policy Action Min        -0.84375
exploration/num steps total    2900
exploration/num paths total      29
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.213916
exploration/Rewards Std           0.108221
exploration/Rewards Max          -0.0210067
exploration/Rewards Min          -0.651472
exploration/Returns Mean        -21.3916
exploration/Returns Std           0.67592
exploration/Returns Max         -20.7157
exploration/Returns Min         -22.0675
exploration/Actions Mean          0.0100756
exploration/Actions Std           0.175334
exploration/Actions Max           1
exploration/Actions Min          -0.531978
exploration/Num Paths             2
exploration/Average Returns     -21.3916
evaluation/num steps total     7000
evaluation/num paths total       70
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.165448
evaluation/Rewards Std            0.0447666
evaluation/Rewards Max           -0.103321
evaluation/Rewards Min           -0.91648
evaluation/Returns Mean         -16.5448
evaluation/Returns Std            0.38944
evaluation/Returns Max          -16.0632
evaluation/Returns Min          -17.0779
evaluation/Actions Mean           0.00401977
evaluation/Actions Std            0.0707025
evaluation/Actions Max            0.985153
evaluation/Actions Min           -0.706451
evaluation/Num Paths              5
evaluation/Average Returns      -16.5448
time/data storing (s)             0.00106818
time/evaluation sampling (s)      0.0752903
time/exploration sampling (s)     0.0328717
time/logging (s)                  0.00207154
time/saving (s)                   0.00235477
time/training (s)                 0.448604
time/epoch (s)                    0.56226
time/total (s)                    8.06463
Epoch                            13
-----------------------------  --------------
2019-04-13 16:58:42.266644 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size             3100
trainer/QF1 Loss                  0.0275525
trainer/QF2 Loss                  0.0244623
trainer/Policy Loss               3.6083
trainer/Q1 Predictions Mean      -4.23632
trainer/Q1 Predictions Std        1.36146
trainer/Q1 Predictions Max       -2.7123
trainer/Q1 Predictions Min       -7.03778
trainer/Q2 Predictions Mean      -4.24041
trainer/Q2 Predictions Std        1.35572
trainer/Q2 Predictions Max       -2.72355
trainer/Q2 Predictions Min       -7.00578
trainer/Q Targets Mean           -4.29638
trainer/Q Targets Std             1.38938
trainer/Q Targets Max            -2.76571
trainer/Q Targets Min            -7.25814
trainer/Bellman Errors 1 Mean     0.0275525
trainer/Bellman Errors 1 Std      0.0543235
trainer/Bellman Errors 1 Max      0.279732
trainer/Bellman Errors 1 Min      2.05205e-07
trainer/Bellman Errors 2 Mean     0.0244623
trainer/Bellman Errors 2 Std      0.048833
trainer/Bellman Errors 2 Max      0.263528
trainer/Bellman Errors 2 Min      1.89469e-05
trainer/Policy Action Mean        0.0941192
trainer/Policy Action Std         0.543172
trainer/Policy Action Max         0.997667
trainer/Policy Action Min        -0.834589
exploration/num steps total    3100
exploration/num paths total      31
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.231872
exploration/Rewards Std           0.11141
exploration/Rewards Max          -0.0160057
exploration/Rewards Min          -0.562196
exploration/Returns Mean        -23.1872
exploration/Returns Std           0.718055
exploration/Returns Max         -22.4692
exploration/Returns Min         -23.9053
exploration/Actions Mean          0.00059639
exploration/Actions Std           0.138285
exploration/Actions Max           0.652233
exploration/Actions Min          -0.406207
exploration/Num Paths             2
exploration/Average Returns     -23.1872
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.210563
evaluation/Rewards Std            0.0420181
evaluation/Rewards Max           -0.205502
evaluation/Rewards Min           -0.968128
evaluation/Returns Mean         -21.0563
evaluation/Returns Std            0.26327
evaluation/Returns Max          -20.7723
evaluation/Returns Min          -21.5447
evaluation/Actions Mean           0.00509073
evaluation/Actions Std            0.0658213
evaluation/Actions Max            0.988752
evaluation/Actions Min           -0.404639
evaluation/Num Paths              5
evaluation/Average Returns      -21.0563
time/data storing (s)             0.00107089
time/evaluation sampling (s)      0.075688
time/exploration sampling (s)     0.0345859
time/logging (s)                  0.00248583
time/saving (s)                   0.00232951
time/training (s)                 0.456201
time/epoch (s)                    0.572361
time/total (s)                    8.64058
Epoch                            14
-----------------------------  --------------
2019-04-13 16:58:42.823721 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size             3300
trainer/QF1 Loss                  0.0229517
trainer/QF2 Loss                  0.0269043
trainer/Policy Loss               3.69946
trainer/Q1 Predictions Mean      -4.2694
trainer/Q1 Predictions Std        1.29415
trainer/Q1 Predictions Max       -2.95669
trainer/Q1 Predictions Min       -7.54041
trainer/Q2 Predictions Mean      -4.26227
trainer/Q2 Predictions Std        1.29701
trainer/Q2 Predictions Max       -2.93073
trainer/Q2 Predictions Min       -7.53339
trainer/Q Targets Mean           -4.17722
trainer/Q Targets Std             1.3158
trainer/Q Targets Max            -2.72432
trainer/Q Targets Min            -7.59861
trainer/Bellman Errors 1 Mean     0.0229517
trainer/Bellman Errors 1 Std      0.0222556
trainer/Bellman Errors 1 Max      0.0817401
trainer/Bellman Errors 1 Min      1.48922e-05
trainer/Bellman Errors 2 Mean     0.0269043
trainer/Bellman Errors 2 Std      0.0320329
trainer/Bellman Errors 2 Max      0.140513
trainer/Bellman Errors 2 Min      3.94168e-05
trainer/Policy Action Mean        0.0950842
trainer/Policy Action Std         0.505751
trainer/Policy Action Max         0.99829
trainer/Policy Action Min        -0.806474
exploration/num steps total    3300
exploration/num paths total      33
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.172785
exploration/Rewards Std           0.0946938
exploration/Rewards Max          -0.0148493
exploration/Rewards Min          -0.640347
exploration/Returns Mean        -17.2785
exploration/Returns Std           1.43805
exploration/Returns Max         -15.8404
exploration/Returns Min         -18.7165
exploration/Actions Mean          0.00583578
exploration/Actions Std           0.141052
exploration/Actions Max           0.920638
exploration/Actions Min          -0.490394
exploration/Num Paths             2
exploration/Average Returns     -17.2785
evaluation/num steps total     8000
evaluation/num paths total       80
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.1346
evaluation/Rewards Std            0.0540947
evaluation/Rewards Max           -0.127717
evaluation/Rewards Min           -0.812575
evaluation/Returns Mean         -13.46
evaluation/Returns Std            0.360119
evaluation/Returns Max          -12.7852
evaluation/Returns Min          -13.7829
evaluation/Actions Mean           0.00386565
evaluation/Actions Std            0.0717323
evaluation/Actions Max            0.97941
evaluation/Actions Min           -0.638956
evaluation/Num Paths              5
evaluation/Average Returns      -13.46
time/data storing (s)             0.00111751
time/evaluation sampling (s)      0.0834494
time/exploration sampling (s)     0.0374735
time/logging (s)                  0.00246383
time/saving (s)                   0.00247765
time/training (s)                 0.42506
time/epoch (s)                    0.552042
time/total (s)                    9.19672
Epoch                            15
-----------------------------  --------------
2019-04-13 16:58:43.399515 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size             3500
trainer/QF1 Loss                  0.0503687
trainer/QF2 Loss                  0.0532806
trainer/Policy Loss               3.85
trainer/Q1 Predictions Mean      -4.56319
trainer/Q1 Predictions Std        1.66494
trainer/Q1 Predictions Max       -2.98917
trainer/Q1 Predictions Min       -8.53694
trainer/Q2 Predictions Mean      -4.56084
trainer/Q2 Predictions Std        1.66171
trainer/Q2 Predictions Max       -2.98322
trainer/Q2 Predictions Min       -8.55204
trainer/Q Targets Mean           -4.54867
trainer/Q Targets Std             1.66581
trainer/Q Targets Max            -2.84082
trainer/Q Targets Min            -7.90918
trainer/Bellman Errors 1 Mean     0.0503687
trainer/Bellman Errors 1 Std      0.14805
trainer/Bellman Errors 1 Max      0.825734
trainer/Bellman Errors 1 Min      1.65071e-05
trainer/Bellman Errors 2 Mean     0.0532805
trainer/Bellman Errors 2 Std      0.153934
trainer/Bellman Errors 2 Max      0.853411
trainer/Bellman Errors 2 Min      5.13263e-05
trainer/Policy Action Mean        0.100116
trainer/Policy Action Std         0.502412
trainer/Policy Action Max         0.999253
trainer/Policy Action Min        -0.762329
exploration/num steps total    3500
exploration/num paths total      35
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.196587
exploration/Rewards Std           0.118022
exploration/Rewards Max          -0.0206794
exploration/Rewards Min          -1.14627
exploration/Returns Mean        -19.6587
exploration/Returns Std           1.76151
exploration/Returns Max         -17.8972
exploration/Returns Min         -21.4202
exploration/Actions Mean          0.00985673
exploration/Actions Std           0.164123
exploration/Actions Max           0.980593
exploration/Actions Min          -0.594404
exploration/Num Paths             2
exploration/Average Returns     -19.6587
evaluation/num steps total     8500
evaluation/num paths total       85
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.151701
evaluation/Rewards Std            0.0389922
evaluation/Rewards Max           -0.069843
evaluation/Rewards Min           -0.904341
evaluation/Returns Mean         -15.1701
evaluation/Returns Std            0.391847
evaluation/Returns Max          -14.7038
evaluation/Returns Min          -15.8495
evaluation/Actions Mean           0.00243855
evaluation/Actions Std            0.0543413
evaluation/Actions Max            0.983904
evaluation/Actions Min           -0.581349
evaluation/Num Paths              5
evaluation/Average Returns      -15.1701
time/data storing (s)             0.00104398
time/evaluation sampling (s)      0.0838403
time/exploration sampling (s)     0.0332752
time/logging (s)                  0.00247349
time/saving (s)                   0.00227899
time/training (s)                 0.448183
time/epoch (s)                    0.571095
time/total (s)                    9.77166
Epoch                            16
-----------------------------  --------------
2019-04-13 16:58:43.972701 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size             3700
trainer/QF1 Loss                  0.0266074
trainer/QF2 Loss                  0.0299392
trainer/Policy Loss               3.78538
trainer/Q1 Predictions Mean      -4.52893
trainer/Q1 Predictions Std        1.45314
trainer/Q1 Predictions Max       -3.01635
trainer/Q1 Predictions Min       -7.46288
trainer/Q2 Predictions Mean      -4.52402
trainer/Q2 Predictions Std        1.43017
trainer/Q2 Predictions Max       -3.04809
trainer/Q2 Predictions Min       -7.3955
trainer/Q Targets Mean           -4.60412
trainer/Q Targets Std             1.51742
trainer/Q Targets Max            -2.96641
trainer/Q Targets Min            -7.89004
trainer/Bellman Errors 1 Mean     0.0266074
trainer/Bellman Errors 1 Std      0.0548002
trainer/Bellman Errors 1 Max      0.273607
trainer/Bellman Errors 1 Min      1.42497e-05
trainer/Bellman Errors 2 Mean     0.0299392
trainer/Bellman Errors 2 Std      0.0607287
trainer/Bellman Errors 2 Max      0.271641
trainer/Bellman Errors 2 Min      3.17669e-07
trainer/Policy Action Mean        0.127292
trainer/Policy Action Std         0.497274
trainer/Policy Action Max         0.998102
trainer/Policy Action Min        -0.899356
exploration/num steps total    3700
exploration/num paths total      37
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.2029
exploration/Rewards Std           0.0949086
exploration/Rewards Max          -0.0302383
exploration/Rewards Min          -0.601006
exploration/Returns Mean        -20.29
exploration/Returns Std           0.518017
exploration/Returns Max         -19.772
exploration/Returns Min         -20.808
exploration/Actions Mean          0.00490104
exploration/Actions Std           0.144697
exploration/Actions Max           0.592961
exploration/Actions Min          -0.375699
exploration/Num Paths             2
exploration/Average Returns     -20.29
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.173493
evaluation/Rewards Std            0.0321972
evaluation/Rewards Max           -0.169279
evaluation/Rewards Min           -0.644011
evaluation/Returns Mean         -17.3493
evaluation/Returns Std            0.0899152
evaluation/Returns Max          -17.2273
evaluation/Returns Min          -17.5
evaluation/Actions Mean           0.00529595
evaluation/Actions Std            0.0572973
evaluation/Actions Max            0.96456
evaluation/Actions Min           -0.347395
evaluation/Num Paths              5
evaluation/Average Returns      -17.3493
time/data storing (s)             0.00106353
time/evaluation sampling (s)      0.0745777
time/exploration sampling (s)     0.0313127
time/logging (s)                  0.00188824
time/saving (s)                   0.00186964
time/training (s)                 0.457188
time/epoch (s)                    0.5679
time/total (s)                   10.3433
Epoch                            17
-----------------------------  --------------
2019-04-13 16:58:44.553716 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size             3900
trainer/QF1 Loss                  0.0491782
trainer/QF2 Loss                  0.0499461
trainer/Policy Loss               3.52311
trainer/Q1 Predictions Mean      -4.03293
trainer/Q1 Predictions Std        1.20334
trainer/Q1 Predictions Max       -3.02577
trainer/Q1 Predictions Min       -7.3559
trainer/Q2 Predictions Mean      -4.03248
trainer/Q2 Predictions Std        1.19881
trainer/Q2 Predictions Max       -3.04438
trainer/Q2 Predictions Min       -7.25705
trainer/Q Targets Mean           -4.18574
trainer/Q Targets Std             1.2402
trainer/Q Targets Max            -3.01759
trainer/Q Targets Min            -7.05503
trainer/Bellman Errors 1 Mean     0.0491782
trainer/Bellman Errors 1 Std      0.0630297
trainer/Bellman Errors 1 Max      0.307265
trainer/Bellman Errors 1 Min      5.90356e-06
trainer/Bellman Errors 2 Mean     0.0499461
trainer/Bellman Errors 2 Std      0.0699623
trainer/Bellman Errors 2 Max      0.29089
trainer/Bellman Errors 2 Min      5.25945e-06
trainer/Policy Action Mean        0.0209626
trainer/Policy Action Std         0.432418
trainer/Policy Action Max         0.998949
trainer/Policy Action Min        -0.926513
exploration/num steps total    3900
exploration/num paths total      39
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.174608
exploration/Rewards Std           0.0876706
exploration/Rewards Max          -0.0207124
exploration/Rewards Min          -0.565759
exploration/Returns Mean        -17.4608
exploration/Returns Std           0.442001
exploration/Returns Max         -17.0188
exploration/Returns Min         -17.9028
exploration/Actions Mean          0.0069899
exploration/Actions Std           0.14147
exploration/Actions Max           0.997681
exploration/Actions Min          -0.528805
exploration/Num Paths             2
exploration/Average Returns     -17.4608
evaluation/num steps total     9500
evaluation/num paths total       95
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.148999
evaluation/Rewards Std            0.0714287
evaluation/Rewards Max           -0.139872
evaluation/Rewards Min           -1.10028
evaluation/Returns Mean         -14.8999
evaluation/Returns Std            0.419616
evaluation/Returns Max          -14.2038
evaluation/Returns Min          -15.3459
evaluation/Actions Mean           0.00767983
evaluation/Actions Std            0.0900613
evaluation/Actions Max            0.992176
evaluation/Actions Min           -0.693608
evaluation/Num Paths              5
evaluation/Average Returns      -14.8999
time/data storing (s)             0.00115744
time/evaluation sampling (s)      0.0754772
time/exploration sampling (s)     0.0334067
time/logging (s)                  0.00248279
time/saving (s)                   0.00228474
time/training (s)                 0.462743
time/epoch (s)                    0.577552
time/total (s)                   10.9243
Epoch                            18
-----------------------------  --------------
2019-04-13 16:58:45.117956 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 19 finished
-----------------------------  ---------------
replay_buffer/size              4100
trainer/QF1 Loss                   0.0279485
trainer/QF2 Loss                   0.0305568
trainer/Policy Loss                3.50782
trainer/Q1 Predictions Mean       -3.8322
trainer/Q1 Predictions Std         0.7329
trainer/Q1 Predictions Max        -3.25164
trainer/Q1 Predictions Min        -6.61306
trainer/Q2 Predictions Mean       -3.83522
trainer/Q2 Predictions Std         0.718735
trainer/Q2 Predictions Max        -3.29823
trainer/Q2 Predictions Min        -6.56061
trainer/Q Targets Mean            -3.84698
trainer/Q Targets Std              0.782295
trainer/Q Targets Max             -3.14865
trainer/Q Targets Min             -6.78967
trainer/Bellman Errors 1 Mean      0.0279485
trainer/Bellman Errors 1 Std       0.0671383
trainer/Bellman Errors 1 Max       0.373607
trainer/Bellman Errors 1 Min       2.57307e-06
trainer/Bellman Errors 2 Mean      0.0305568
trainer/Bellman Errors 2 Std       0.0804286
trainer/Bellman Errors 2 Max       0.462076
trainer/Bellman Errors 2 Min       0.000173707
trainer/Policy Action Mean         0.0218084
trainer/Policy Action Std          0.357997
trainer/Policy Action Max          0.988315
trainer/Policy Action Min         -0.760826
exploration/num steps total     4100
exploration/num paths total       41
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.183207
exploration/Rewards Std            0.095648
exploration/Rewards Max           -0.00279181
exploration/Rewards Min           -0.498515
exploration/Returns Mean         -18.3207
exploration/Returns Std            1.01547
exploration/Returns Max          -17.3052
exploration/Returns Min          -19.3362
exploration/Actions Mean           0.00540315
exploration/Actions Std            0.149732
exploration/Actions Max            0.983538
exploration/Actions Min           -0.411638
exploration/Num Paths              2
exploration/Average Returns      -18.3207
evaluation/num steps total     10000
evaluation/num paths total       100
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.146532
evaluation/Rewards Std             0.0540755
evaluation/Rewards Max            -0.125894
evaluation/Rewards Min            -1.04856
evaluation/Returns Mean          -14.6532
evaluation/Returns Std             0.446231
evaluation/Returns Max           -14.0857
evaluation/Returns Min           -15.3236
evaluation/Actions Mean            0.00493084
evaluation/Actions Std             0.0723981
evaluation/Actions Max             0.995267
evaluation/Actions Min            -0.502347
evaluation/Num Paths               5
evaluation/Average Returns       -14.6532
time/data storing (s)              0.00108393
time/evaluation sampling (s)       0.0759847
time/exploration sampling (s)      0.0328691
time/logging (s)                   0.00248521
time/saving (s)                    0.00229626
time/training (s)                  0.444849
time/epoch (s)                     0.559568
time/total (s)                    11.4876
Epoch                             19
-----------------------------  ---------------
2019-04-13 16:58:45.677478 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 20 finished
-----------------------------  ---------------
replay_buffer/size              4300
trainer/QF1 Loss                   0.0127646
trainer/QF2 Loss                   0.0154154
trainer/Policy Loss                3.78762
trainer/Q1 Predictions Mean       -4.31658
trainer/Q1 Predictions Std         1.25104
trainer/Q1 Predictions Max        -3.35145
trainer/Q1 Predictions Min        -7.56343
trainer/Q2 Predictions Mean       -4.30016
trainer/Q2 Predictions Std         1.24609
trainer/Q2 Predictions Max        -3.34152
trainer/Q2 Predictions Min        -7.52241
trainer/Q Targets Mean            -4.33201
trainer/Q Targets Std              1.27072
trainer/Q Targets Max             -3.27989
trainer/Q Targets Min             -7.76522
trainer/Bellman Errors 1 Mean      0.0127646
trainer/Bellman Errors 1 Std       0.0210467
trainer/Bellman Errors 1 Max       0.082109
trainer/Bellman Errors 1 Min       5.22839e-05
trainer/Bellman Errors 2 Mean      0.0154154
trainer/Bellman Errors 2 Std       0.0233425
trainer/Bellman Errors 2 Max       0.0844327
trainer/Bellman Errors 2 Min       6.70532e-06
trainer/Policy Action Mean         0.0549712
trainer/Policy Action Std          0.43632
trainer/Policy Action Max          0.998934
trainer/Policy Action Min         -0.943709
exploration/num steps total     4300
exploration/num paths total       43
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.147026
exploration/Rewards Std            0.0801206
exploration/Rewards Max           -0.00949881
exploration/Rewards Min           -0.436069
exploration/Returns Mean         -14.7026
exploration/Returns Std            0.169903
exploration/Returns Max          -14.5327
exploration/Returns Min          -14.8725
exploration/Actions Mean           0.00640646
exploration/Actions Std            0.145255
exploration/Actions Max            0.906267
exploration/Actions Min           -0.360883
exploration/Num Paths              2
exploration/Average Returns      -14.7026
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.069052
evaluation/Rewards Std             0.0263545
evaluation/Rewards Max            -0.0659072
evaluation/Rewards Min            -0.489581
evaluation/Returns Mean           -6.9052
evaluation/Returns Std             0.183612
evaluation/Returns Max            -6.64082
evaluation/Returns Min            -7.18569
evaluation/Actions Mean            0.0032977
evaluation/Actions Std             0.0637179
evaluation/Actions Max             0.934748
evaluation/Actions Min            -0.846964
evaluation/Num Paths               5
evaluation/Average Returns        -6.9052
time/data storing (s)              0.00114238
time/evaluation sampling (s)       0.0744432
time/exploration sampling (s)      0.0344136
time/logging (s)                   0.00247397
time/saving (s)                    0.00223782
time/training (s)                  0.440042
time/epoch (s)                     0.554753
time/total (s)                    12.0462
Epoch                             20
-----------------------------  ---------------
2019-04-13 16:58:46.252455 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 21 finished
-----------------------------  ---------------
replay_buffer/size              4500
trainer/QF1 Loss                   0.0285404
trainer/QF2 Loss                   0.0315998
trainer/Policy Loss                3.7521
trainer/Q1 Predictions Mean       -4.24304
trainer/Q1 Predictions Std         1.00052
trainer/Q1 Predictions Max        -3.42388
trainer/Q1 Predictions Min        -6.66917
trainer/Q2 Predictions Mean       -4.24093
trainer/Q2 Predictions Std         1.00094
trainer/Q2 Predictions Max        -3.46127
trainer/Q2 Predictions Min        -6.68565
trainer/Q Targets Mean            -4.34459
trainer/Q Targets Std              0.9805
trainer/Q Targets Max             -3.35612
trainer/Q Targets Min             -6.84116
trainer/Bellman Errors 1 Mean      0.0285404
trainer/Bellman Errors 1 Std       0.042038
trainer/Bellman Errors 1 Max       0.177048
trainer/Bellman Errors 1 Min       3.73871e-06
trainer/Bellman Errors 2 Mean      0.0315998
trainer/Bellman Errors 2 Std       0.0489572
trainer/Bellman Errors 2 Max       0.196043
trainer/Bellman Errors 2 Min       2.08022e-05
trainer/Policy Action Mean         0.042256
trainer/Policy Action Std          0.382514
trainer/Policy Action Max          0.99221
trainer/Policy Action Min         -0.46021
exploration/num steps total     4500
exploration/num paths total       45
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.178433
exploration/Rewards Std            0.0953526
exploration/Rewards Max           -0.0166808
exploration/Rewards Min           -0.57574
exploration/Returns Mean         -17.8433
exploration/Returns Std            0.248241
exploration/Returns Max          -17.595
exploration/Returns Min          -18.0915
exploration/Actions Mean           0.00356441
exploration/Actions Std            0.149633
exploration/Actions Max            0.486221
exploration/Actions Min           -0.431641
exploration/Num Paths              2
exploration/Average Returns      -17.8433
evaluation/num steps total     11000
evaluation/num paths total       110
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.122264
evaluation/Rewards Std             0.0401038
evaluation/Rewards Max            -0.0497979
evaluation/Rewards Min            -0.653356
evaluation/Returns Mean          -12.2264
evaluation/Returns Std             0.328312
evaluation/Returns Max           -11.6431
evaluation/Returns Min           -12.5767
evaluation/Actions Mean            0.00408819
evaluation/Actions Std             0.0705718
evaluation/Actions Max             0.983698
evaluation/Actions Min            -0.725594
evaluation/Num Paths               5
evaluation/Average Returns       -12.2264
time/data storing (s)              0.00113258
time/evaluation sampling (s)       0.074363
time/exploration sampling (s)      0.0337417
time/logging (s)                   0.00248028
time/saving (s)                    0.00227574
time/training (s)                  0.456227
time/epoch (s)                     0.57022
time/total (s)                    12.6202
Epoch                             21
-----------------------------  ---------------
2019-04-13 16:58:46.806258 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 22 finished
-----------------------------  ---------------
replay_buffer/size              4700
trainer/QF1 Loss                   0.0137432
trainer/QF2 Loss                   0.0174507
trainer/Policy Loss                3.77452
trainer/Q1 Predictions Mean       -4.05472
trainer/Q1 Predictions Std         0.561717
trainer/Q1 Predictions Max        -3.58466
trainer/Q1 Predictions Min        -6.58567
trainer/Q2 Predictions Mean       -4.04826
trainer/Q2 Predictions Std         0.561193
trainer/Q2 Predictions Max        -3.58158
trainer/Q2 Predictions Min        -6.60305
trainer/Q Targets Mean            -4.10092
trainer/Q Targets Std              0.57285
trainer/Q Targets Max             -3.51054
trainer/Q Targets Min             -6.62802
trainer/Bellman Errors 1 Mean      0.0137432
trainer/Bellman Errors 1 Std       0.0195071
trainer/Bellman Errors 1 Max       0.0907967
trainer/Bellman Errors 1 Min       3.64396e-05
trainer/Bellman Errors 2 Mean      0.0174507
trainer/Bellman Errors 2 Std       0.0244873
trainer/Bellman Errors 2 Max       0.114835
trainer/Bellman Errors 2 Min       2.97676e-05
trainer/Policy Action Mean        -0.021271
trainer/Policy Action Std          0.277831
trainer/Policy Action Max          0.988944
trainer/Policy Action Min         -0.371826
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.152377
exploration/Rewards Std            0.0800584
exploration/Rewards Max           -0.00973069
exploration/Rewards Min           -0.462461
exploration/Returns Mean         -15.2377
exploration/Returns Std            1.37781
exploration/Returns Max          -13.8599
exploration/Returns Min          -16.6155
exploration/Actions Mean           0.00649375
exploration/Actions Std            0.151661
exploration/Actions Max            0.795108
exploration/Actions Min           -0.323171
exploration/Num Paths              2
exploration/Average Returns      -15.2377
evaluation/num steps total     11500
evaluation/num paths total       115
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0748215
evaluation/Rewards Std             0.040911
evaluation/Rewards Max            -0.0708496
evaluation/Rewards Min            -0.817076
evaluation/Returns Mean           -7.48215
evaluation/Returns Std             0.404557
evaluation/Returns Max            -7.10139
evaluation/Returns Min            -8.19407
evaluation/Actions Mean            0.00331336
evaluation/Actions Std             0.0585401
evaluation/Actions Max             0.995623
evaluation/Actions Min            -0.606276
evaluation/Num Paths               5
evaluation/Average Returns        -7.48215
time/data storing (s)              0.00116783
time/evaluation sampling (s)       0.074837
time/exploration sampling (s)      0.0389231
time/logging (s)                   0.00249066
time/saving (s)                    0.00227398
time/training (s)                  0.42933
time/epoch (s)                     0.549022
time/total (s)                    13.1731
Epoch                             22
-----------------------------  ---------------
2019-04-13 16:58:47.376511 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 23 finished
-----------------------------  ---------------
replay_buffer/size              4900
trainer/QF1 Loss                   0.0280831
trainer/QF2 Loss                   0.0295173
trainer/Policy Loss                4.23914
trainer/Q1 Predictions Mean       -4.94899
trainer/Q1 Predictions Std         1.4686
trainer/Q1 Predictions Max        -3.63192
trainer/Q1 Predictions Min        -8.09528
trainer/Q2 Predictions Mean       -4.94807
trainer/Q2 Predictions Std         1.46091
trainer/Q2 Predictions Max        -3.6333
trainer/Q2 Predictions Min        -8.02295
trainer/Q Targets Mean            -4.95945
trainer/Q Targets Std              1.43246
trainer/Q Targets Max             -3.56827
trainer/Q Targets Min             -7.76775
trainer/Bellman Errors 1 Mean      0.0280831
trainer/Bellman Errors 1 Std       0.0324393
trainer/Bellman Errors 1 Max       0.118382
trainer/Bellman Errors 1 Min       7.67246e-05
trainer/Bellman Errors 2 Mean      0.0295173
trainer/Bellman Errors 2 Std       0.03314
trainer/Bellman Errors 2 Max       0.118056
trainer/Bellman Errors 2 Min       3.358e-06
trainer/Policy Action Mean         0.146362
trainer/Policy Action Std          0.518581
trainer/Policy Action Max          0.999539
trainer/Policy Action Min         -0.972416
exploration/num steps total     4900
exploration/num paths total       49
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.149066
exploration/Rewards Std            0.101063
exploration/Rewards Max           -0.00650547
exploration/Rewards Min           -0.978009
exploration/Returns Mean         -14.9066
exploration/Returns Std            1.03276
exploration/Returns Max          -13.8738
exploration/Returns Min          -15.9393
exploration/Actions Mean           0.00906269
exploration/Actions Std            0.158422
exploration/Actions Max            1
exploration/Actions Min           -0.590095
exploration/Num Paths              2
exploration/Average Returns      -14.9066
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0819512
evaluation/Rewards Std             0.052827
evaluation/Rewards Max            -0.0760703
evaluation/Rewards Min            -0.870469
evaluation/Returns Mean           -8.19512
evaluation/Returns Std             0.295276
evaluation/Returns Max            -7.85877
evaluation/Returns Min            -8.64408
evaluation/Actions Mean            0.00732736
evaluation/Actions Std             0.0773851
evaluation/Actions Max             0.994774
evaluation/Actions Min            -0.353617
evaluation/Num Paths               5
evaluation/Average Returns        -8.19512
time/data storing (s)              0.0010527
time/evaluation sampling (s)       0.0817968
time/exploration sampling (s)      0.0327163
time/logging (s)                   0.00251963
time/saving (s)                    0.00246211
time/training (s)                  0.444887
time/epoch (s)                     0.565434
time/total (s)                    13.7422
Epoch                             23
-----------------------------  ---------------
2019-04-13 16:58:47.947426 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 24 finished
-----------------------------  ---------------
replay_buffer/size              5100
trainer/QF1 Loss                   0.0332007
trainer/QF2 Loss                   0.0393354
trainer/Policy Loss                4.1174
trainer/Q1 Predictions Mean       -4.64861
trainer/Q1 Predictions Std         1.22897
trainer/Q1 Predictions Max        -3.72961
trainer/Q1 Predictions Min        -8.79259
trainer/Q2 Predictions Mean       -4.63241
trainer/Q2 Predictions Std         1.2266
trainer/Q2 Predictions Max        -3.74571
trainer/Q2 Predictions Min        -8.73447
trainer/Q Targets Mean            -4.64126
trainer/Q Targets Std              1.1921
trainer/Q Targets Max             -3.6411
trainer/Q Targets Min             -8.16688
trainer/Bellman Errors 1 Mean      0.0332007
trainer/Bellman Errors 1 Std       0.0743665
trainer/Bellman Errors 1 Max       0.391514
trainer/Bellman Errors 1 Min       8.85014e-05
trainer/Bellman Errors 2 Mean      0.0393354
trainer/Bellman Errors 2 Std       0.0880007
trainer/Bellman Errors 2 Max       0.410166
trainer/Bellman Errors 2 Min       1.98776e-05
trainer/Policy Action Mean         0.0890158
trainer/Policy Action Std          0.412828
trainer/Policy Action Max          0.999939
trainer/Policy Action Min         -0.949075
exploration/num steps total     5100
exploration/num paths total       51
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.169697
exploration/Rewards Std            0.0776236
exploration/Rewards Max           -0.0124136
exploration/Rewards Min           -0.405864
exploration/Returns Mean         -16.9697
exploration/Returns Std            0.64337
exploration/Returns Max          -16.3264
exploration/Returns Min          -17.6131
exploration/Actions Mean           0.000825624
exploration/Actions Std            0.142841
exploration/Actions Max            0.563346
exploration/Actions Min           -0.545296
exploration/Num Paths              2
exploration/Average Returns      -16.9697
evaluation/num steps total     12500
evaluation/num paths total       125
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.116692
evaluation/Rewards Std             0.0327651
evaluation/Rewards Max            -0.113143
evaluation/Rewards Min            -0.678894
evaluation/Returns Mean          -11.6692
evaluation/Returns Std             0.154369
evaluation/Returns Max           -11.5697
evaluation/Returns Min           -11.9762
evaluation/Actions Mean            0.00584028
evaluation/Actions Std             0.0658768
evaluation/Actions Max             0.944448
evaluation/Actions Min            -0.449657
evaluation/Num Paths               5
evaluation/Average Returns       -11.6692
time/data storing (s)              0.00106011
time/evaluation sampling (s)       0.0774748
time/exploration sampling (s)      0.0315781
time/logging (s)                   0.00248675
time/saving (s)                    0.00228591
time/training (s)                  0.452212
time/epoch (s)                     0.567098
time/total (s)                    14.3123
Epoch                             24
-----------------------------  ---------------
2019-04-13 16:58:48.504639 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 25 finished
-----------------------------  ---------------
replay_buffer/size              5300
trainer/QF1 Loss                   0.0208138
trainer/QF2 Loss                   0.0226271
trainer/Policy Loss                4.24386
trainer/Q1 Predictions Mean       -4.82388
trainer/Q1 Predictions Std         1.27029
trainer/Q1 Predictions Max        -3.81009
trainer/Q1 Predictions Min        -8.08057
trainer/Q2 Predictions Mean       -4.82735
trainer/Q2 Predictions Std         1.26221
trainer/Q2 Predictions Max        -3.82538
trainer/Q2 Predictions Min        -8.03755
trainer/Q Targets Mean            -4.87194
trainer/Q Targets Std              1.28869
trainer/Q Targets Max             -3.77024
trainer/Q Targets Min             -8.31196
trainer/Bellman Errors 1 Mean      0.0208138
trainer/Bellman Errors 1 Std       0.0240449
trainer/Bellman Errors 1 Max       0.0957641
trainer/Bellman Errors 1 Min       2.29699e-05
trainer/Bellman Errors 2 Mean      0.0226271
trainer/Bellman Errors 2 Std       0.0267078
trainer/Bellman Errors 2 Max       0.0975353
trainer/Bellman Errors 2 Min       7.30157e-07
trainer/Policy Action Mean         0.0968574
trainer/Policy Action Std          0.45923
trainer/Policy Action Max          0.999768
trainer/Policy Action Min         -0.928755
exploration/num steps total     5300
exploration/num paths total       53
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.164118
exploration/Rewards Std            0.103299
exploration/Rewards Max           -0.0211354
exploration/Rewards Min           -1.09231
exploration/Returns Mean         -16.4118
exploration/Returns Std            0.113862
exploration/Returns Max          -16.2979
exploration/Returns Min          -16.5256
exploration/Actions Mean           0.00685841
exploration/Actions Std            0.152939
exploration/Actions Max            1
exploration/Actions Min           -0.507619
exploration/Num Paths              2
exploration/Average Returns      -16.4118
evaluation/num steps total     13000
evaluation/num paths total       130
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.107548
evaluation/Rewards Std             0.0250574
evaluation/Rewards Max            -0.10483
evaluation/Rewards Min            -0.436573
evaluation/Returns Mean          -10.7548
evaluation/Returns Std             0.117457
evaluation/Returns Max           -10.5443
evaluation/Returns Min           -10.8694
evaluation/Actions Mean            0.0038905
evaluation/Actions Std             0.0591035
evaluation/Actions Max             0.784587
evaluation/Actions Min            -0.833716
evaluation/Num Paths               5
evaluation/Average Returns       -10.7548
time/data storing (s)              0.00108941
time/evaluation sampling (s)       0.0729616
time/exploration sampling (s)      0.0333951
time/logging (s)                   0.00248918
time/saving (s)                    0.00187013
time/training (s)                  0.440605
time/epoch (s)                     0.55241
time/total (s)                    14.8686
Epoch                             25
-----------------------------  ---------------
2019-04-13 16:58:49.071139 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 26 finished
-----------------------------  ---------------
replay_buffer/size              5500
trainer/QF1 Loss                   0.97805
trainer/QF2 Loss                   0.976643
trainer/Policy Loss                4.15281
trainer/Q1 Predictions Mean       -4.52251
trainer/Q1 Predictions Std         1.21766
trainer/Q1 Predictions Max        -3.92319
trainer/Q1 Predictions Min        -9.82366
trainer/Q2 Predictions Mean       -4.53049
trainer/Q2 Predictions Std         1.20814
trainer/Q2 Predictions Max        -3.94856
trainer/Q2 Predictions Min        -9.77111
trainer/Q Targets Mean            -4.30679
trainer/Q Targets Std              1.51406
trainer/Q Targets Max             -0.108801
trainer/Q Targets Min             -8.92141
trainer/Bellman Errors 1 Mean      0.97805
trainer/Bellman Errors 1 Std       3.62293
trainer/Bellman Errors 1 Max      15.171
trainer/Bellman Errors 1 Min       6.17525e-07
trainer/Bellman Errors 2 Mean      0.976643
trainer/Bellman Errors 2 Std       3.63056
trainer/Bellman Errors 2 Max      15.1188
trainer/Bellman Errors 2 Min       2.91086e-06
trainer/Policy Action Mean         0.0270783
trainer/Policy Action Std          0.348515
trainer/Policy Action Max          0.999961
trainer/Policy Action Min         -0.950818
exploration/num steps total     5500
exploration/num paths total       55
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.156793
exploration/Rewards Std            0.0872948
exploration/Rewards Max           -0.00811414
exploration/Rewards Min           -0.740116
exploration/Returns Mean         -15.6793
exploration/Returns Std            0.207512
exploration/Returns Max          -15.4718
exploration/Returns Min          -15.8868
exploration/Actions Mean           0.00635118
exploration/Actions Std            0.143088
exploration/Actions Max            0.681736
exploration/Actions Min           -0.401545
exploration/Num Paths              2
exploration/Average Returns      -15.6793
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0972894
evaluation/Rewards Std             0.0444403
evaluation/Rewards Max            -0.078085
evaluation/Rewards Min            -0.694076
evaluation/Returns Mean           -9.72894
evaluation/Returns Std             0.272375
evaluation/Returns Max            -9.24514
evaluation/Returns Min           -10.0411
evaluation/Actions Mean            0.00498266
evaluation/Actions Std             0.0824819
evaluation/Actions Max             0.995486
evaluation/Actions Min            -0.880466
evaluation/Num Paths               5
evaluation/Average Returns        -9.72894
time/data storing (s)              0.00104318
time/evaluation sampling (s)       0.074359
time/exploration sampling (s)      0.0327525
time/logging (s)                   0.00252096
time/saving (s)                    0.00223302
time/training (s)                  0.448789
time/epoch (s)                     0.561697
time/total (s)                    15.4341
Epoch                             26
-----------------------------  ---------------
2019-04-13 16:58:49.638497 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 27 finished
-----------------------------  ---------------
replay_buffer/size              5700
trainer/QF1 Loss                   0.0186843
trainer/QF2 Loss                   0.0204845
trainer/Policy Loss                4.38121
trainer/Q1 Predictions Mean       -4.73819
trainer/Q1 Predictions Std         1.02099
trainer/Q1 Predictions Max        -4.09077
trainer/Q1 Predictions Min        -9.33036
trainer/Q2 Predictions Mean       -4.73896
trainer/Q2 Predictions Std         1.01437
trainer/Q2 Predictions Max        -4.07095
trainer/Q2 Predictions Min        -9.2987
trainer/Q Targets Mean            -4.71559
trainer/Q Targets Std              1.05894
trainer/Q Targets Max             -3.94444
trainer/Q Targets Min             -9.66539
trainer/Bellman Errors 1 Mean      0.0186843
trainer/Bellman Errors 1 Std       0.0265937
trainer/Bellman Errors 1 Max       0.112243
trainer/Bellman Errors 1 Min       9.11925e-06
trainer/Bellman Errors 2 Mean      0.0204845
trainer/Bellman Errors 2 Std       0.0300703
trainer/Bellman Errors 2 Max       0.134461
trainer/Bellman Errors 2 Min       0.000161522
trainer/Policy Action Mean         0.0715904
trainer/Policy Action Std          0.391033
trainer/Policy Action Max          0.999976
trainer/Policy Action Min         -0.953365
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131445
exploration/Rewards Std            0.0932939
exploration/Rewards Max           -0.00998003
exploration/Rewards Min           -0.790693
exploration/Returns Mean         -13.1445
exploration/Returns Std            0.0982586
exploration/Returns Max          -13.0463
exploration/Returns Min          -13.2428
exploration/Actions Mean           0.00501801
exploration/Actions Std            0.152017
exploration/Actions Max            0.786549
exploration/Actions Min           -1
exploration/Num Paths              2
exploration/Average Returns      -13.1445
evaluation/num steps total     14000
evaluation/num paths total       140
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0229669
evaluation/Rewards Std             0.0286345
evaluation/Rewards Max            -0.0191933
evaluation/Rewards Min            -0.495885
evaluation/Returns Mean           -2.29669
evaluation/Returns Std             0.191668
evaluation/Returns Max            -2.02859
evaluation/Returns Min            -2.58566
evaluation/Actions Mean            0.00343907
evaluation/Actions Std             0.0672519
evaluation/Actions Max             0.953156
evaluation/Actions Min            -0.811597
evaluation/Num Paths               5
evaluation/Average Returns        -2.29669
time/data storing (s)              0.00111368
time/evaluation sampling (s)       0.0734067
time/exploration sampling (s)      0.0320117
time/logging (s)                   0.00246815
time/saving (s)                    0.00222909
time/training (s)                  0.451215
time/epoch (s)                     0.562444
time/total (s)                    16.0003
Epoch                             27
-----------------------------  ---------------
2019-04-13 16:58:50.215447 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 28 finished
-----------------------------  ---------------
replay_buffer/size              5900
trainer/QF1 Loss                   0.03757
trainer/QF2 Loss                   0.0388067
trainer/Policy Loss                4.39632
trainer/Q1 Predictions Mean       -4.78908
trainer/Q1 Predictions Std         1.32077
trainer/Q1 Predictions Max        -4.02448
trainer/Q1 Predictions Min        -9.43698
trainer/Q2 Predictions Mean       -4.78666
trainer/Q2 Predictions Std         1.32483
trainer/Q2 Predictions Max        -4.00396
trainer/Q2 Predictions Min        -9.46826
trainer/Q Targets Mean            -4.92168
trainer/Q Targets Std              1.36422
trainer/Q Targets Max             -3.94592
trainer/Q Targets Min             -9.86311
trainer/Bellman Errors 1 Mean      0.03757
trainer/Bellman Errors 1 Std       0.0487009
trainer/Bellman Errors 1 Max       0.181591
trainer/Bellman Errors 1 Min       0.000216874
trainer/Bellman Errors 2 Mean      0.0388067
trainer/Bellman Errors 2 Std       0.0489796
trainer/Bellman Errors 2 Max       0.189461
trainer/Bellman Errors 2 Min       1.46577e-06
trainer/Policy Action Mean         0.0629107
trainer/Policy Action Std          0.368532
trainer/Policy Action Max          0.999947
trainer/Policy Action Min         -0.973701
exploration/num steps total     5900
exploration/num paths total       59
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135381
exploration/Rewards Std            0.0727224
exploration/Rewards Max           -0.0120507
exploration/Rewards Min           -0.448646
exploration/Returns Mean         -13.5381
exploration/Returns Std            0.108608
exploration/Returns Max          -13.4295
exploration/Returns Min          -13.6467
exploration/Actions Mean           0.000922943
exploration/Actions Std            0.143777
exploration/Actions Max            0.328112
exploration/Actions Min           -0.877237
exploration/Num Paths              2
exploration/Average Returns      -13.5381
evaluation/num steps total     14500
evaluation/num paths total       145
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0394591
evaluation/Rewards Std             0.0602446
evaluation/Rewards Max            -0.0325504
evaluation/Rewards Min            -0.908208
evaluation/Returns Mean           -3.94591
evaluation/Returns Std             0.373248
evaluation/Returns Max            -3.44807
evaluation/Returns Min            -4.44068
evaluation/Actions Mean            0.00528473
evaluation/Actions Std             0.0881916
evaluation/Actions Max             0.998519
evaluation/Actions Min            -0.858204
evaluation/Num Paths               5
evaluation/Average Returns        -3.94591
time/data storing (s)              0.00150763
time/evaluation sampling (s)       0.0765319
time/exploration sampling (s)      0.0329949
time/logging (s)                   0.00187837
time/saving (s)                    0.00181783
time/training (s)                  0.456747
time/epoch (s)                     0.571478
time/total (s)                    16.5757
Epoch                             28
-----------------------------  ---------------
2019-04-13 16:58:50.788274 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 29 finished
-----------------------------  ---------------
replay_buffer/size              6100
trainer/QF1 Loss                   1.11327
trainer/QF2 Loss                   1.11145
trainer/Policy Loss                4.53915
trainer/Q1 Predictions Mean       -5.10163
trainer/Q1 Predictions Std         1.0654
trainer/Q1 Predictions Max        -4.1538
trainer/Q1 Predictions Min        -7.82952
trainer/Q2 Predictions Mean       -5.08781
trainer/Q2 Predictions Std         1.04452
trainer/Q2 Predictions Max        -4.12333
trainer/Q2 Predictions Min        -7.75643
trainer/Q Targets Mean            -4.89322
trainer/Q Targets Std              1.59136
trainer/Q Targets Max             -0.263094
trainer/Q Targets Min             -8.19576
trainer/Bellman Errors 1 Mean      1.11327
trainer/Bellman Errors 1 Std       4.26493
trainer/Bellman Errors 1 Max      19.1576
trainer/Bellman Errors 1 Min       5.85154e-06
trainer/Bellman Errors 2 Mean      1.11145
trainer/Bellman Errors 2 Std       4.24302
trainer/Bellman Errors 2 Max      19.1207
trainer/Bellman Errors 2 Min       5.274e-07
trainer/Policy Action Mean         0.121182
trainer/Policy Action Std          0.394642
trainer/Policy Action Max          0.998614
trainer/Policy Action Min         -0.36855
exploration/num steps total     6100
exploration/num paths total       61
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.136087
exploration/Rewards Std            0.0695366
exploration/Rewards Max           -0.00818382
exploration/Rewards Min           -0.388829
exploration/Returns Mean         -13.6087
exploration/Returns Std            0.10791
exploration/Returns Max          -13.5008
exploration/Returns Min          -13.7166
exploration/Actions Mean           0.00311825
exploration/Actions Std            0.147701
exploration/Actions Max            0.655177
exploration/Actions Min           -0.701634
exploration/Num Paths              2
exploration/Average Returns      -13.6087
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0437121
evaluation/Rewards Std             0.0421202
evaluation/Rewards Max            -0.0147876
evaluation/Rewards Min            -0.886022
evaluation/Returns Mean           -4.37121
evaluation/Returns Std             0.344018
evaluation/Returns Max            -4.04117
evaluation/Returns Min            -5.0333
evaluation/Actions Mean            0.00336412
evaluation/Actions Std             0.0667619
evaluation/Actions Max             0.998373
evaluation/Actions Min            -0.746479
evaluation/Num Paths               5
evaluation/Average Returns        -4.37121
time/data storing (s)              0.00104819
time/evaluation sampling (s)       0.081343
time/exploration sampling (s)      0.0317396
time/logging (s)                   0.0018694
time/saving (s)                    0.00180987
time/training (s)                  0.450163
time/epoch (s)                     0.567973
time/total (s)                    17.1473
Epoch                             29
-----------------------------  ---------------
2019-04-13 16:58:51.354542 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 30 finished
-----------------------------  ---------------
replay_buffer/size              6300
trainer/QF1 Loss                   0.025509
trainer/QF2 Loss                   0.0250468
trainer/Policy Loss                4.55044
trainer/Q1 Predictions Mean       -4.96566
trainer/Q1 Predictions Std         0.895306
trainer/Q1 Predictions Max        -4.29704
trainer/Q1 Predictions Min        -7.19402
trainer/Q2 Predictions Mean       -4.96692
trainer/Q2 Predictions Std         0.886569
trainer/Q2 Predictions Max        -4.29869
trainer/Q2 Predictions Min        -7.20843
trainer/Q Targets Mean            -4.94294
trainer/Q Targets Std              0.907145
trainer/Q Targets Max             -4.14649
trainer/Q Targets Min             -7.50125
trainer/Bellman Errors 1 Mean      0.025509
trainer/Bellman Errors 1 Std       0.0450563
trainer/Bellman Errors 1 Max       0.218374
trainer/Bellman Errors 1 Min       5.58314e-05
trainer/Bellman Errors 2 Mean      0.0250468
trainer/Bellman Errors 2 Std       0.0482393
trainer/Bellman Errors 2 Max       0.245731
trainer/Bellman Errors 2 Min       2.82045e-06
trainer/Policy Action Mean         0.0307481
trainer/Policy Action Std          0.353631
trainer/Policy Action Max          0.997689
trainer/Policy Action Min         -0.98894
exploration/num steps total     6300
exploration/num paths total       63
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.138279
exploration/Rewards Std            0.0671961
exploration/Rewards Max           -0.00940387
exploration/Rewards Min           -0.333751
exploration/Returns Mean         -13.8279
exploration/Returns Std            0.171398
exploration/Returns Max          -13.6565
exploration/Returns Min          -13.9993
exploration/Actions Mean           0.00147581
exploration/Actions Std            0.148542
exploration/Actions Max            0.678863
exploration/Actions Min           -0.827658
exploration/Num Paths              2
exploration/Average Returns      -13.8279
evaluation/num steps total     15500
evaluation/num paths total       155
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0578502
evaluation/Rewards Std             0.0248493
evaluation/Rewards Max            -0.0512361
evaluation/Rewards Min            -0.572991
evaluation/Returns Mean           -5.78502
evaluation/Returns Std             0.205762
evaluation/Returns Max            -5.59087
evaluation/Returns Min            -6.18122
evaluation/Actions Mean            0.00593115
evaluation/Actions Std             0.0649146
evaluation/Actions Max             0.979359
evaluation/Actions Min            -0.249808
evaluation/Num Paths               5
evaluation/Average Returns        -5.78502
time/data storing (s)              0.00109438
time/evaluation sampling (s)       0.0768078
time/exploration sampling (s)      0.040487
time/logging (s)                   0.00247515
time/saving (s)                    0.00225528
time/training (s)                  0.43926
time/epoch (s)                     0.562379
time/total (s)                    17.7135
Epoch                             30
-----------------------------  ---------------
2019-04-13 16:58:51.925195 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 31 finished
-----------------------------  ---------------
replay_buffer/size              6500
trainer/QF1 Loss                   0.0272349
trainer/QF2 Loss                   0.0274341
trainer/Policy Loss                4.54219
trainer/Q1 Predictions Mean       -4.93598
trainer/Q1 Predictions Std         0.743969
trainer/Q1 Predictions Max        -4.30963
trainer/Q1 Predictions Min        -6.8735
trainer/Q2 Predictions Mean       -4.93749
trainer/Q2 Predictions Std         0.751228
trainer/Q2 Predictions Max        -4.29861
trainer/Q2 Predictions Min        -6.91013
trainer/Q Targets Mean            -4.97707
trainer/Q Targets Std              0.768522
trainer/Q Targets Max             -4.21309
trainer/Q Targets Min             -7.3328
trainer/Bellman Errors 1 Mean      0.0272349
trainer/Bellman Errors 1 Std       0.0418236
trainer/Bellman Errors 1 Max       0.210953
trainer/Bellman Errors 1 Min       0.000396915
trainer/Bellman Errors 2 Mean      0.0274341
trainer/Bellman Errors 2 Std       0.0391387
trainer/Bellman Errors 2 Max       0.17865
trainer/Bellman Errors 2 Min       2.03007e-05
trainer/Policy Action Mean        -0.0131534
trainer/Policy Action Std          0.341787
trainer/Policy Action Max          0.995192
trainer/Policy Action Min         -0.973259
exploration/num steps total     6500
exploration/num paths total       65
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.154808
exploration/Rewards Std            0.102098
exploration/Rewards Max           -0.0140573
exploration/Rewards Min           -1.02018
exploration/Returns Mean         -15.4808
exploration/Returns Std            0.170669
exploration/Returns Max          -15.3101
exploration/Returns Min          -15.6514
exploration/Actions Mean           0.00786272
exploration/Actions Std            0.156094
exploration/Actions Max            1
exploration/Actions Min           -0.43612
exploration/Num Paths              2
exploration/Average Returns      -15.4808
evaluation/num steps total     16000
evaluation/num paths total       160
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0830455
evaluation/Rewards Std             0.0588943
evaluation/Rewards Max            -0.0765698
evaluation/Rewards Min            -0.893716
evaluation/Returns Mean           -8.30455
evaluation/Returns Std             0.271304
evaluation/Returns Max            -7.83809
evaluation/Returns Min            -8.64106
evaluation/Actions Mean            0.00885996
evaluation/Actions Std             0.0927931
evaluation/Actions Max             0.995058
evaluation/Actions Min            -0.555958
evaluation/Num Paths               5
evaluation/Average Returns        -8.30455
time/data storing (s)              0.00123273
time/evaluation sampling (s)       0.0820706
time/exploration sampling (s)      0.0323975
time/logging (s)                   0.00248904
time/saving (s)                    0.00226778
time/training (s)                  0.445315
time/epoch (s)                     0.565773
time/total (s)                    18.2831
Epoch                             31
-----------------------------  ---------------
2019-04-13 16:58:52.489227 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 32 finished
-----------------------------  ---------------
replay_buffer/size              6700
trainer/QF1 Loss                   0.67513
trainer/QF2 Loss                   0.671378
trainer/Policy Loss                4.59346
trainer/Q1 Predictions Mean       -4.9163
trainer/Q1 Predictions Std         0.681123
trainer/Q1 Predictions Max        -4.50367
trainer/Q1 Predictions Min        -7.23342
trainer/Q2 Predictions Mean       -4.91267
trainer/Q2 Predictions Std         0.67519
trainer/Q2 Predictions Max        -4.4856
trainer/Q2 Predictions Min        -7.21957
trainer/Q Targets Mean            -4.7506
trainer/Q Targets Std              1.02354
trainer/Q Targets Max             -0.624367
trainer/Q Targets Min             -7.24744
trainer/Bellman Errors 1 Mean      0.67513
trainer/Bellman Errors 1 Std       3.60465
trainer/Bellman Errors 1 Max      20.7438
trainer/Bellman Errors 1 Min       0.000241866
trainer/Bellman Errors 2 Mean      0.671378
trainer/Bellman Errors 2 Std       3.59665
trainer/Bellman Errors 2 Max      20.6958
trainer/Bellman Errors 2 Min       1.42587e-05
trainer/Policy Action Mean         0.0484217
trainer/Policy Action Std          0.308599
trainer/Policy Action Max          0.995631
trainer/Policy Action Min         -0.947296
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.136442
exploration/Rewards Std            0.0726524
exploration/Rewards Max           -0.0135429
exploration/Rewards Min           -0.467129
exploration/Returns Mean         -13.6442
exploration/Returns Std            1.46816
exploration/Returns Max          -12.176
exploration/Returns Min          -15.1123
exploration/Actions Mean           0.00298365
exploration/Actions Std            0.142521
exploration/Actions Max            0.688283
exploration/Actions Min           -0.556124
exploration/Num Paths              2
exploration/Average Returns      -13.6442
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0408209
evaluation/Rewards Std             0.0477291
evaluation/Rewards Max            -0.0312238
evaluation/Rewards Min            -0.739706
evaluation/Returns Mean           -4.08209
evaluation/Returns Std             0.248204
evaluation/Returns Max            -3.77533
evaluation/Returns Min            -4.42794
evaluation/Actions Mean            0.00612693
evaluation/Actions Std             0.0805007
evaluation/Actions Max             0.995594
evaluation/Actions Min            -0.896791
evaluation/Num Paths               5
evaluation/Average Returns        -4.08209
time/data storing (s)              0.00109204
time/evaluation sampling (s)       0.0723806
time/exploration sampling (s)      0.0317561
time/logging (s)                   0.00247323
time/saving (s)                    0.00229057
time/training (s)                  0.449051
time/epoch (s)                     0.559043
time/total (s)                    18.846
Epoch                             32
-----------------------------  ---------------
2019-04-13 16:58:53.057441 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 33 finished
-----------------------------  ---------------
replay_buffer/size              6900
trainer/QF1 Loss                   0.0239589
trainer/QF2 Loss                   0.0259223
trainer/Policy Loss                4.98053
trainer/Q1 Predictions Mean       -5.43065
trainer/Q1 Predictions Std         1.07889
trainer/Q1 Predictions Max        -4.55
trainer/Q1 Predictions Min        -7.9196
trainer/Q2 Predictions Mean       -5.44591
trainer/Q2 Predictions Std         1.08878
trainer/Q2 Predictions Max        -4.54159
trainer/Q2 Predictions Min        -7.93735
trainer/Q Targets Mean            -5.35464
trainer/Q Targets Std              1.08339
trainer/Q Targets Max             -4.38842
trainer/Q Targets Min             -7.96871
trainer/Bellman Errors 1 Mean      0.0239589
trainer/Bellman Errors 1 Std       0.0267291
trainer/Bellman Errors 1 Max       0.111818
trainer/Bellman Errors 1 Min       0.000157535
trainer/Bellman Errors 2 Mean      0.0259223
trainer/Bellman Errors 2 Std       0.0300583
trainer/Bellman Errors 2 Max       0.120336
trainer/Bellman Errors 2 Min       7.55721e-05
trainer/Policy Action Mean         0.144748
trainer/Policy Action Std          0.41005
trainer/Policy Action Max          0.998925
trainer/Policy Action Min         -0.407686
exploration/num steps total     6900
exploration/num paths total       69
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.151001
exploration/Rewards Std            0.109505
exploration/Rewards Max           -0.0150463
exploration/Rewards Min           -1.01965
exploration/Returns Mean         -15.1001
exploration/Returns Std            0.742258
exploration/Returns Max          -14.3578
exploration/Returns Min          -15.8423
exploration/Actions Mean           0.0079661
exploration/Actions Std            0.157295
exploration/Actions Max            1
exploration/Actions Min           -0.476701
exploration/Num Paths              2
exploration/Average Returns      -15.1001
evaluation/num steps total     17000
evaluation/num paths total       170
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0860645
evaluation/Rewards Std             0.0326919
evaluation/Rewards Max            -0.0719562
evaluation/Rewards Min            -0.711214
evaluation/Returns Mean           -8.60645
evaluation/Returns Std             0.254766
evaluation/Returns Max            -8.33339
evaluation/Returns Min            -9.04093
evaluation/Actions Mean            0.004336
evaluation/Actions Std             0.0722551
evaluation/Actions Max             0.987329
evaluation/Actions Min            -0.820756
evaluation/Num Paths               5
evaluation/Average Returns        -8.60645
time/data storing (s)              0.00106698
time/evaluation sampling (s)       0.0739811
time/exploration sampling (s)      0.0312949
time/logging (s)                   0.00248655
time/saving (s)                    0.00231248
time/training (s)                  0.452184
time/epoch (s)                     0.563326
time/total (s)                    19.4131
Epoch                             33
-----------------------------  ---------------
2019-04-13 16:58:53.621284 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 34 finished
-----------------------------  ---------------
replay_buffer/size              7100
trainer/QF1 Loss                   0.041345
trainer/QF2 Loss                   0.0440003
trainer/Policy Loss                4.74976
trainer/Q1 Predictions Mean       -5.01618
trainer/Q1 Predictions Std         0.67682
trainer/Q1 Predictions Max        -4.55227
trainer/Q1 Predictions Min        -7.26744
trainer/Q2 Predictions Mean       -5.01035
trainer/Q2 Predictions Std         0.667502
trainer/Q2 Predictions Max        -4.54679
trainer/Q2 Predictions Min        -7.26082
trainer/Q Targets Mean            -5.12587
trainer/Q Targets Std              0.661196
trainer/Q Targets Max             -4.47257
trainer/Q Targets Min             -7.33129
trainer/Bellman Errors 1 Mean      0.041345
trainer/Bellman Errors 1 Std       0.0710203
trainer/Bellman Errors 1 Max       0.272199
trainer/Bellman Errors 1 Min       3.22092e-05
trainer/Bellman Errors 2 Mean      0.0440003
trainer/Bellman Errors 2 Std       0.0750999
trainer/Bellman Errors 2 Max       0.277777
trainer/Bellman Errors 2 Min       1.2451e-09
trainer/Policy Action Mean         0.0817143
trainer/Policy Action Std          0.318682
trainer/Policy Action Max          0.99543
trainer/Policy Action Min         -0.402571
exploration/num steps total     7100
exploration/num paths total       71
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.147659
exploration/Rewards Std            0.104739
exploration/Rewards Max           -0.0039011
exploration/Rewards Min           -1.10645
exploration/Returns Mean         -14.7659
exploration/Returns Std            0.607886
exploration/Returns Max          -14.158
exploration/Returns Min          -15.3737
exploration/Actions Mean           0.00656797
exploration/Actions Std            0.167394
exploration/Actions Max            1
exploration/Actions Min           -0.582592
exploration/Num Paths              2
exploration/Average Returns      -14.7659
evaluation/num steps total     17500
evaluation/num paths total       175
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0763417
evaluation/Rewards Std             0.0200215
evaluation/Rewards Max            -0.0627145
evaluation/Rewards Min            -0.382913
evaluation/Returns Mean           -7.63417
evaluation/Returns Std             0.109572
evaluation/Returns Max            -7.45885
evaluation/Returns Min            -7.77967
evaluation/Actions Mean            0.00326979
evaluation/Actions Std             0.0652939
evaluation/Actions Max             0.984509
evaluation/Actions Min            -0.883512
evaluation/Num Paths               5
evaluation/Average Returns        -7.63417
time/data storing (s)              0.00125016
time/evaluation sampling (s)       0.0738476
time/exploration sampling (s)      0.0326305
time/logging (s)                   0.0024669
time/saving (s)                    0.0021906
time/training (s)                  0.446507
time/epoch (s)                     0.558893
time/total (s)                    19.9758
Epoch                             34
-----------------------------  ---------------
2019-04-13 16:58:54.179839 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 35 finished
-----------------------------  ---------------
replay_buffer/size              7300
trainer/QF1 Loss                   0.686007
trainer/QF2 Loss                   0.68506
trainer/Policy Loss                4.7906
trainer/Q1 Predictions Mean       -5.11251
trainer/Q1 Predictions Std         0.526465
trainer/Q1 Predictions Max        -4.6021
trainer/Q1 Predictions Min        -6.44672
trainer/Q2 Predictions Mean       -5.11224
trainer/Q2 Predictions Std         0.524011
trainer/Q2 Predictions Max        -4.62038
trainer/Q2 Predictions Min        -6.4802
trainer/Q Targets Mean            -5.06285
trainer/Q Targets Std              1.01277
trainer/Q Targets Max             -0.343988
trainer/Q Targets Min             -6.9108
trainer/Bellman Errors 1 Mean      0.686007
trainer/Bellman Errors 1 Std       3.55652
trainer/Bellman Errors 1 Max      20.4748
trainer/Bellman Errors 1 Min       8.00043e-05
trainer/Bellman Errors 2 Mean      0.68506
trainer/Bellman Errors 2 Std       3.53918
trainer/Bellman Errors 2 Max      20.3772
trainer/Bellman Errors 2 Min       0.000167923
trainer/Policy Action Mean        -0.0377528
trainer/Policy Action Std          0.312213
trainer/Policy Action Max          0.999413
trainer/Policy Action Min         -0.810563
exploration/num steps total     7300
exploration/num paths total       73
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.14317
exploration/Rewards Std            0.0729231
exploration/Rewards Max           -0.00427823
exploration/Rewards Min           -0.37062
exploration/Returns Mean         -14.317
exploration/Returns Std            0.570859
exploration/Returns Max          -13.7461
exploration/Returns Min          -14.8878
exploration/Actions Mean           0.00258428
exploration/Actions Std            0.155312
exploration/Actions Max            1
exploration/Actions Min           -1
exploration/Num Paths              2
exploration/Average Returns      -14.317
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0665545
evaluation/Rewards Std             0.0135332
evaluation/Rewards Max            -0.0530076
evaluation/Rewards Min            -0.279891
evaluation/Returns Mean           -6.65545
evaluation/Returns Std             0.0888101
evaluation/Returns Max            -6.54518
evaluation/Returns Min            -6.77137
evaluation/Actions Mean            0.00100996
evaluation/Actions Std             0.0617506
evaluation/Actions Max             0.901016
evaluation/Actions Min            -0.941411
evaluation/Num Paths               5
evaluation/Average Returns        -6.65545
time/data storing (s)              0.00113377
time/evaluation sampling (s)       0.0723122
time/exploration sampling (s)      0.0320625
time/logging (s)                   0.00248514
time/saving (s)                    0.00242996
time/training (s)                  0.443233
time/epoch (s)                     0.553656
time/total (s)                    20.5332
Epoch                             35
-----------------------------  ---------------
2019-04-13 16:58:54.750060 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 36 finished
-----------------------------  ---------------
replay_buffer/size              7500
trainer/QF1 Loss                   0.0372506
trainer/QF2 Loss                   0.0341624
trainer/Policy Loss                5.18808
trainer/Q1 Predictions Mean       -5.64082
trainer/Q1 Predictions Std         1.51384
trainer/Q1 Predictions Max        -4.76613
trainer/Q1 Predictions Min       -10.7139
trainer/Q2 Predictions Mean       -5.63461
trainer/Q2 Predictions Std         1.47282
trainer/Q2 Predictions Max        -4.76598
trainer/Q2 Predictions Min       -10.6146
trainer/Q Targets Mean            -5.69274
trainer/Q Targets Std              1.49175
trainer/Q Targets Max             -4.59692
trainer/Q Targets Min            -10.4597
trainer/Bellman Errors 1 Mean      0.0372506
trainer/Bellman Errors 1 Std       0.0712479
trainer/Bellman Errors 1 Max       0.349072
trainer/Bellman Errors 1 Min       1.83927e-05
trainer/Bellman Errors 2 Mean      0.0341624
trainer/Bellman Errors 2 Std       0.0682113
trainer/Bellman Errors 2 Max       0.355869
trainer/Bellman Errors 2 Min       1.0772e-05
trainer/Policy Action Mean         0.0454053
trainer/Policy Action Std          0.40551
trainer/Policy Action Max          0.999991
trainer/Policy Action Min         -0.98376
exploration/num steps total     7500
exploration/num paths total       75
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129677
exploration/Rewards Std            0.0773747
exploration/Rewards Max           -0.00856487
exploration/Rewards Min           -0.785244
exploration/Returns Mean         -12.9677
exploration/Returns Std            0.0462833
exploration/Returns Max          -12.9215
exploration/Returns Min          -13.014
exploration/Actions Mean           0.00697254
exploration/Actions Std            0.148116
exploration/Actions Max            0.835356
exploration/Actions Min           -0.359335
exploration/Num Paths              2
exploration/Average Returns      -12.9677
evaluation/num steps total     18500
evaluation/num paths total       185
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0380213
evaluation/Rewards Std             0.054942
evaluation/Rewards Max            -0.0121276
evaluation/Rewards Min            -0.860328
evaluation/Returns Mean           -3.80213
evaluation/Returns Std             0.331125
evaluation/Returns Max            -3.37539
evaluation/Returns Min            -4.29593
evaluation/Actions Mean            0.00556562
evaluation/Actions Std             0.0905329
evaluation/Actions Max             0.998311
evaluation/Actions Min            -0.905977
evaluation/Num Paths               5
evaluation/Average Returns        -3.80213
time/data storing (s)              0.00122775
time/evaluation sampling (s)       0.0783531
time/exploration sampling (s)      0.0318872
time/logging (s)                   0.0025442
time/saving (s)                    0.00227158
time/training (s)                  0.449058
time/epoch (s)                     0.565342
time/total (s)                    21.1024
Epoch                             36
-----------------------------  ---------------
2019-04-13 16:58:55.315069 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 37 finished
-----------------------------  ---------------
replay_buffer/size              7700
trainer/QF1 Loss                   0.0203744
trainer/QF2 Loss                   0.0243366
trainer/Policy Loss                5.13448
trainer/Q1 Predictions Mean       -5.57129
trainer/Q1 Predictions Std         1.26556
trainer/Q1 Predictions Max        -4.81705
trainer/Q1 Predictions Min       -10.5112
trainer/Q2 Predictions Mean       -5.58405
trainer/Q2 Predictions Std         1.26665
trainer/Q2 Predictions Max        -4.83471
trainer/Q2 Predictions Min       -10.5637
trainer/Q Targets Mean            -5.49029
trainer/Q Targets Std              1.20697
trainer/Q Targets Max             -4.63451
trainer/Q Targets Min            -10.1831
trainer/Bellman Errors 1 Mean      0.0203744
trainer/Bellman Errors 1 Std       0.0320197
trainer/Bellman Errors 1 Max       0.130833
trainer/Bellman Errors 1 Min       2.66733e-05
trainer/Bellman Errors 2 Mean      0.0243366
trainer/Bellman Errors 2 Std       0.0389925
trainer/Bellman Errors 2 Max       0.156202
trainer/Bellman Errors 2 Min       1.7699e-08
trainer/Policy Action Mean         0.0499626
trainer/Policy Action Std          0.384051
trainer/Policy Action Max          0.999991
trainer/Policy Action Min         -0.993465
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129071
exploration/Rewards Std            0.0664005
exploration/Rewards Max           -0.00686039
exploration/Rewards Min           -0.399497
exploration/Returns Mean         -12.9071
exploration/Returns Std            0.35444
exploration/Returns Max          -12.5527
exploration/Returns Min          -13.2615
exploration/Actions Mean           0.00215181
exploration/Actions Std            0.140875
exploration/Actions Max            0.583157
exploration/Actions Min           -0.805643
exploration/Num Paths              2
exploration/Average Returns      -12.9071
evaluation/num steps total     19000
evaluation/num paths total       190
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0482185
evaluation/Rewards Std             0.0437986
evaluation/Rewards Max            -0.0403852
evaluation/Rewards Min            -0.837432
evaluation/Returns Mean           -4.82185
evaluation/Returns Std             0.336758
evaluation/Returns Max            -4.4651
evaluation/Returns Min            -5.41154
evaluation/Actions Mean            0.00472158
evaluation/Actions Std             0.0754626
evaluation/Actions Max             0.998076
evaluation/Actions Min            -0.855903
evaluation/Num Paths               5
evaluation/Average Returns        -4.82185
time/data storing (s)              0.00107738
time/evaluation sampling (s)       0.0750519
time/exploration sampling (s)      0.032882
time/logging (s)                   0.00249241
time/saving (s)                    0.00227489
time/training (s)                  0.446313
time/epoch (s)                     0.560091
time/total (s)                    21.6662
Epoch                             37
-----------------------------  ---------------
2019-04-13 16:58:55.885412 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 38 finished
-----------------------------  ---------------
replay_buffer/size              7900
trainer/QF1 Loss                   0.0225451
trainer/QF2 Loss                   0.0236013
trainer/Policy Loss                5.12209
trainer/Q1 Predictions Mean       -5.37329
trainer/Q1 Predictions Std         0.816508
trainer/Q1 Predictions Max        -4.89473
trainer/Q1 Predictions Min        -8.47995
trainer/Q2 Predictions Mean       -5.37851
trainer/Q2 Predictions Std         0.83237
trainer/Q2 Predictions Max        -4.90314
trainer/Q2 Predictions Min        -8.58017
trainer/Q Targets Mean            -5.36906
trainer/Q Targets Std              0.865423
trainer/Q Targets Max             -4.71559
trainer/Q Targets Min             -8.55908
trainer/Bellman Errors 1 Mean      0.0225451
trainer/Bellman Errors 1 Std       0.0398035
trainer/Bellman Errors 1 Max       0.171629
trainer/Bellman Errors 1 Min       1.34594e-06
trainer/Bellman Errors 2 Mean      0.0236013
trainer/Bellman Errors 2 Std       0.0448001
trainer/Bellman Errors 2 Max       0.208234
trainer/Bellman Errors 2 Min       9.60205e-05
trainer/Policy Action Mean         0.0299488
trainer/Policy Action Std          0.294819
trainer/Policy Action Max          0.999655
trainer/Policy Action Min         -0.959393
exploration/num steps total     7900
exploration/num paths total       79
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.143721
exploration/Rewards Std            0.07921
exploration/Rewards Max           -0.00517871
exploration/Rewards Min           -0.790464
exploration/Returns Mean         -14.3721
exploration/Returns Std            0.648443
exploration/Returns Max          -13.7236
exploration/Returns Min          -15.0205
exploration/Actions Mean           0.00410912
exploration/Actions Std            0.146209
exploration/Actions Max            0.774861
exploration/Actions Min           -0.78984
exploration/Num Paths              2
exploration/Average Returns      -14.3721
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0762726
evaluation/Rewards Std             0.0490239
evaluation/Rewards Max            -0.0567029
evaluation/Rewards Min            -1.01246
evaluation/Returns Mean           -7.62726
evaluation/Returns Std             0.402518
evaluation/Returns Max            -7.24949
evaluation/Returns Min            -8.3459
evaluation/Actions Mean            0.00448082
evaluation/Actions Std             0.0845253
evaluation/Actions Max             0.999117
evaluation/Actions Min            -0.93832
evaluation/Num Paths               5
evaluation/Average Returns        -7.62726
time/data storing (s)              0.00111681
time/evaluation sampling (s)       0.0800193
time/exploration sampling (s)      0.0353711
time/logging (s)                   0.00246419
time/saving (s)                    0.00224609
time/training (s)                  0.4441
time/epoch (s)                     0.565317
time/total (s)                    22.2353
Epoch                             38
-----------------------------  ---------------
2019-04-13 16:58:56.461994 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 39 finished
-----------------------------  ---------------
replay_buffer/size              8100
trainer/QF1 Loss                   0.0217122
trainer/QF2 Loss                   0.0204982
trainer/Policy Loss                5.11234
trainer/Q1 Predictions Mean       -5.56859
trainer/Q1 Predictions Std         1.01321
trainer/Q1 Predictions Max        -4.94695
trainer/Q1 Predictions Min        -8.27349
trainer/Q2 Predictions Mean       -5.55952
trainer/Q2 Predictions Std         1.00611
trainer/Q2 Predictions Max        -4.93841
trainer/Q2 Predictions Min        -8.29549
trainer/Q Targets Mean            -5.59607
trainer/Q Targets Std              0.991656
trainer/Q Targets Max             -4.88336
trainer/Q Targets Min             -8.44594
trainer/Bellman Errors 1 Mean      0.0217122
trainer/Bellman Errors 1 Std       0.0314711
trainer/Bellman Errors 1 Max       0.158062
trainer/Bellman Errors 1 Min       7.28663e-06
trainer/Bellman Errors 2 Mean      0.0204982
trainer/Bellman Errors 2 Std       0.0294974
trainer/Bellman Errors 2 Max       0.120245
trainer/Bellman Errors 2 Min       8.03544e-05
trainer/Policy Action Mean         0.151774
trainer/Policy Action Std          0.324163
trainer/Policy Action Max          0.99874
trainer/Policy Action Min         -0.356541
exploration/num steps total     8100
exploration/num paths total       81
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.149147
exploration/Rewards Std            0.0777096
exploration/Rewards Max           -0.00361821
exploration/Rewards Min           -0.45369
exploration/Returns Mean         -14.9147
exploration/Returns Std            0.337375
exploration/Returns Max          -14.5773
exploration/Returns Min          -15.2521
exploration/Actions Mean           0.00294399
exploration/Actions Std            0.154943
exploration/Actions Max            0.821207
exploration/Actions Min           -0.788323
exploration/Num Paths              2
exploration/Average Returns      -14.9147
evaluation/num steps total     20000
evaluation/num paths total       200
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0941237
evaluation/Rewards Std             0.0626583
evaluation/Rewards Max            -0.0510188
evaluation/Rewards Min            -0.860088
evaluation/Returns Mean           -9.41237
evaluation/Returns Std             0.284942
evaluation/Returns Max            -8.87927
evaluation/Returns Min            -9.66169
evaluation/Actions Mean            0.0063068
evaluation/Actions Std             0.0912675
evaluation/Actions Max             0.999473
evaluation/Actions Min            -0.84309
evaluation/Num Paths               5
evaluation/Average Returns        -9.41237
time/data storing (s)              0.00108353
time/evaluation sampling (s)       0.0810396
time/exploration sampling (s)      0.0332526
time/logging (s)                   0.00250608
time/saving (s)                    0.0022611
time/training (s)                  0.451419
time/epoch (s)                     0.571562
time/total (s)                    22.8107
Epoch                             39
-----------------------------  ---------------
2019-04-13 16:58:57.033752 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 40 finished
-----------------------------  ---------------
replay_buffer/size              8300
trainer/QF1 Loss                   0.0404088
trainer/QF2 Loss                   0.0411201
trainer/Policy Loss                5.29521
trainer/Q1 Predictions Mean       -5.73325
trainer/Q1 Predictions Std         0.836458
trainer/Q1 Predictions Max        -5.01997
trainer/Q1 Predictions Min        -7.64855
trainer/Q2 Predictions Mean       -5.73439
trainer/Q2 Predictions Std         0.82178
trainer/Q2 Predictions Max        -5.05073
trainer/Q2 Predictions Min        -7.64632
trainer/Q Targets Mean            -5.80457
trainer/Q Targets Std              0.916099
trainer/Q Targets Max             -4.92305
trainer/Q Targets Min             -8.5071
trainer/Bellman Errors 1 Mean      0.0404088
trainer/Bellman Errors 1 Std       0.126652
trainer/Bellman Errors 1 Max       0.737114
trainer/Bellman Errors 1 Min       6.96335e-06
trainer/Bellman Errors 2 Mean      0.0411201
trainer/Bellman Errors 2 Std       0.127122
trainer/Bellman Errors 2 Max       0.740937
trainer/Bellman Errors 2 Min       0.000143693
trainer/Policy Action Mean         0.0975846
trainer/Policy Action Std          0.358896
trainer/Policy Action Max          0.998475
trainer/Policy Action Min         -0.378097
exploration/num steps total     8300
exploration/num paths total       83
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.143387
exploration/Rewards Std            0.0706368
exploration/Rewards Max           -0.0132192
exploration/Rewards Min           -0.32977
exploration/Returns Mean         -14.3387
exploration/Returns Std            0.360048
exploration/Returns Max          -13.9787
exploration/Returns Min          -14.6988
exploration/Actions Mean           0.00507834
exploration/Actions Std            0.144175
exploration/Actions Max            0.85132
exploration/Actions Min           -0.376711
exploration/Num Paths              2
exploration/Average Returns      -14.3387
evaluation/num steps total     20500
evaluation/num paths total       205
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0410531
evaluation/Rewards Std             0.00782473
evaluation/Rewards Max            -0.0218266
evaluation/Rewards Min            -0.164575
evaluation/Returns Mean           -4.10531
evaluation/Returns Std             0.0773311
evaluation/Returns Max            -4.03703
evaluation/Returns Min            -4.2054
evaluation/Actions Mean           -0.000151263
evaluation/Actions Std             0.0422655
evaluation/Actions Max             0.476041
evaluation/Actions Min            -0.946521
evaluation/Num Paths               5
evaluation/Average Returns        -4.10531
time/data storing (s)              0.00115232
time/evaluation sampling (s)       0.0774929
time/exploration sampling (s)      0.0323021
time/logging (s)                   0.00248297
time/saving (s)                    0.00209258
time/training (s)                  0.451149
time/epoch (s)                     0.566672
time/total (s)                    23.3812
Epoch                             40
-----------------------------  ---------------
2019-04-13 16:58:57.596537 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 41 finished
-----------------------------  ---------------
replay_buffer/size              8500
trainer/QF1 Loss                   0.0324335
trainer/QF2 Loss                   0.034731
trainer/Policy Loss                5.0746
trainer/Q1 Predictions Mean       -5.3459
trainer/Q1 Predictions Std         0.530965
trainer/Q1 Predictions Max        -4.97535
trainer/Q1 Predictions Min        -6.72617
trainer/Q2 Predictions Mean       -5.33822
trainer/Q2 Predictions Std         0.528865
trainer/Q2 Predictions Max        -4.99633
trainer/Q2 Predictions Min        -6.71763
trainer/Q Targets Mean            -5.44183
trainer/Q Targets Std              0.437092
trainer/Q Targets Max             -4.98938
trainer/Q Targets Min             -6.60144
trainer/Bellman Errors 1 Mean      0.0324335
trainer/Bellman Errors 1 Std       0.0456823
trainer/Bellman Errors 1 Max       0.195053
trainer/Bellman Errors 1 Min       0.00021353
trainer/Bellman Errors 2 Mean      0.034731
trainer/Bellman Errors 2 Std       0.051765
trainer/Bellman Errors 2 Max       0.225396
trainer/Bellman Errors 2 Min       2.81866e-05
trainer/Policy Action Mean        -0.0293626
trainer/Policy Action Std          0.239002
trainer/Policy Action Max          0.736283
trainer/Policy Action Min         -0.424629
exploration/num steps total     8500
exploration/num paths total       85
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.17088
exploration/Rewards Std            0.0901376
exploration/Rewards Max           -0.0100533
exploration/Rewards Min           -0.531096
exploration/Returns Mean         -17.088
exploration/Returns Std            0.973578
exploration/Returns Max          -16.1144
exploration/Returns Min          -18.0616
exploration/Actions Mean           0.00745415
exploration/Actions Std            0.166102
exploration/Actions Max            1
exploration/Actions Min           -0.741002
exploration/Num Paths              2
exploration/Average Returns      -17.088
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.124892
evaluation/Rewards Std             0.059115
evaluation/Rewards Max            -0.119088
evaluation/Rewards Min            -0.963473
evaluation/Returns Mean          -12.4892
evaluation/Returns Std             0.341873
evaluation/Returns Max           -11.9942
evaluation/Returns Min           -12.8897
evaluation/Actions Mean            0.00680505
evaluation/Actions Std             0.0915856
evaluation/Actions Max             0.99972
evaluation/Actions Min            -0.842534
evaluation/Num Paths               5
evaluation/Average Returns       -12.4892
time/data storing (s)              0.00118122
time/evaluation sampling (s)       0.0735286
time/exploration sampling (s)      0.0330919
time/logging (s)                   0.00244659
time/saving (s)                    0.00225903
time/training (s)                  0.445225
time/epoch (s)                     0.557732
time/total (s)                    23.9428
Epoch                             41
-----------------------------  ---------------
2019-04-13 16:58:58.165254 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size              8700
trainer/QF1 Loss                   0.0560023
trainer/QF2 Loss                   0.060734
trainer/Policy Loss                5.09174
trainer/Q1 Predictions Mean       -5.27439
trainer/Q1 Predictions Std         0.334651
trainer/Q1 Predictions Max        -4.99323
trainer/Q1 Predictions Min        -5.98643
trainer/Q2 Predictions Mean       -5.2661
trainer/Q2 Predictions Std         0.325155
trainer/Q2 Predictions Max        -4.98098
trainer/Q2 Predictions Min        -5.93963
trainer/Q Targets Mean            -5.48455
trainer/Q Targets Std              0.376216
trainer/Q Targets Max             -5.06401
trainer/Q Targets Min             -6.27436
trainer/Bellman Errors 1 Mean      0.0560023
trainer/Bellman Errors 1 Std       0.0519253
trainer/Bellman Errors 1 Max       0.212208
trainer/Bellman Errors 1 Min       0.00161456
trainer/Bellman Errors 2 Mean      0.060734
trainer/Bellman Errors 2 Std       0.0565572
trainer/Bellman Errors 2 Max       0.241627
trainer/Bellman Errors 2 Min       0.0001106
trainer/Policy Action Mean        -0.00656196
trainer/Policy Action Std          0.205279
trainer/Policy Action Max          0.433296
trainer/Policy Action Min         -0.783663
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.149427
exploration/Rewards Std            0.0873855
exploration/Rewards Max           -0.00379511
exploration/Rewards Min           -0.676904
exploration/Returns Mean         -14.9427
exploration/Returns Std            0.53091
exploration/Returns Max          -14.4118
exploration/Returns Min          -15.4736
exploration/Actions Mean           0.00863827
exploration/Actions Std            0.158506
exploration/Actions Max            0.970678
exploration/Actions Min           -0.445218
exploration/Num Paths              2
exploration/Average Returns      -14.9427
evaluation/num steps total     21500
evaluation/num paths total       215
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0763935
evaluation/Rewards Std             0.0386746
evaluation/Rewards Max            -0.0292565
evaluation/Rewards Min            -0.927225
evaluation/Returns Mean           -7.63935
evaluation/Returns Std             0.382549
evaluation/Returns Max            -7.38328
evaluation/Returns Min            -8.39521
evaluation/Actions Mean            0.00398049
evaluation/Actions Std             0.0659979
evaluation/Actions Max             0.999
evaluation/Actions Min            -0.922382
evaluation/Num Paths               5
evaluation/Average Returns        -7.63935
time/data storing (s)              0.00117547
time/evaluation sampling (s)       0.074629
time/exploration sampling (s)      0.0325785
time/logging (s)                   0.00245502
time/saving (s)                    0.00224353
time/training (s)                  0.450643
time/epoch (s)                     0.563724
time/total (s)                    24.5103
Epoch                             42
-----------------------------  --------------
2019-04-13 16:58:58.727617 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 43 finished
-----------------------------  ---------------
replay_buffer/size              8900
trainer/QF1 Loss                   0.838436
trainer/QF2 Loss                   0.839678
trainer/Policy Loss                5.36573
trainer/Q1 Predictions Mean       -5.74988
trainer/Q1 Predictions Std         0.915806
trainer/Q1 Predictions Max        -5.09981
trainer/Q1 Predictions Min        -8.37875
trainer/Q2 Predictions Mean       -5.7559
trainer/Q2 Predictions Std         0.921523
trainer/Q2 Predictions Max        -5.07747
trainer/Q2 Predictions Min        -8.40377
trainer/Q Targets Mean            -5.8104
trainer/Q Targets Std              1.38681
trainer/Q Targets Max             -0.12429
trainer/Q Targets Min             -8.55397
trainer/Bellman Errors 1 Mean      0.838436
trainer/Bellman Errors 1 Std       4.30338
trainer/Bellman Errors 1 Max      24.795
trainer/Bellman Errors 1 Min       0.000421627
trainer/Bellman Errors 2 Mean      0.839677
trainer/Bellman Errors 2 Std       4.32267
trainer/Bellman Errors 2 Max      24.9036
trainer/Bellman Errors 2 Min       0.000240252
trainer/Policy Action Mean         0.0956054
trainer/Policy Action Std          0.370394
trainer/Policy Action Max          0.998099
trainer/Policy Action Min         -0.974032
exploration/num steps total     8900
exploration/num paths total       89
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.154116
exploration/Rewards Std            0.0808585
exploration/Rewards Max           -0.00445944
exploration/Rewards Min           -0.687227
exploration/Returns Mean         -15.4116
exploration/Returns Std            0.0549306
exploration/Returns Max          -15.3566
exploration/Returns Min          -15.4665
exploration/Actions Mean           0.00924619
exploration/Actions Std            0.156385
exploration/Actions Max            1
exploration/Actions Min           -0.427915
exploration/Num Paths              2
exploration/Average Returns      -15.4116
evaluation/num steps total     22000
evaluation/num paths total       220
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0807763
evaluation/Rewards Std             0.0358767
evaluation/Rewards Max            -0.075222
evaluation/Rewards Min            -0.862603
evaluation/Returns Mean           -8.07763
evaluation/Returns Std             0.330225
evaluation/Returns Max            -7.85698
evaluation/Returns Min            -8.73257
evaluation/Actions Mean            0.00507355
evaluation/Actions Std             0.0613235
evaluation/Actions Max             0.997122
evaluation/Actions Min            -0.208967
evaluation/Num Paths               5
evaluation/Average Returns        -8.07763
time/data storing (s)              0.00193172
time/evaluation sampling (s)       0.0729903
time/exploration sampling (s)      0.031874
time/logging (s)                   0.00247637
time/saving (s)                    0.00245679
time/training (s)                  0.445585
time/epoch (s)                     0.557314
time/total (s)                    25.0714
Epoch                             43
-----------------------------  ---------------
2019-04-13 16:58:59.302888 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 44 finished
-----------------------------  ---------------
replay_buffer/size              9100
trainer/QF1 Loss                   0.0534182
trainer/QF2 Loss                   0.0550137
trainer/Policy Loss                5.54578
trainer/Q1 Predictions Mean       -6.00479
trainer/Q1 Predictions Std         0.949961
trainer/Q1 Predictions Max        -5.39353
trainer/Q1 Predictions Min        -8.73061
trainer/Q2 Predictions Mean       -6.00189
trainer/Q2 Predictions Std         0.957023
trainer/Q2 Predictions Max        -5.37358
trainer/Q2 Predictions Min        -8.76071
trainer/Q Targets Mean            -5.96149
trainer/Q Targets Std              0.918802
trainer/Q Targets Max             -5.11981
trainer/Q Targets Min             -8.53495
trainer/Bellman Errors 1 Mean      0.0534182
trainer/Bellman Errors 1 Std       0.0976751
trainer/Bellman Errors 1 Max       0.429768
trainer/Bellman Errors 1 Min       0.000621386
trainer/Bellman Errors 2 Mean      0.0550137
trainer/Bellman Errors 2 Std       0.100983
trainer/Bellman Errors 2 Max       0.450044
trainer/Bellman Errors 2 Min       1.30749e-06
trainer/Policy Action Mean         0.109617
trainer/Policy Action Std          0.380868
trainer/Policy Action Max          0.999667
trainer/Policy Action Min         -0.991733
exploration/num steps total     9100
exploration/num paths total       91
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.168146
exploration/Rewards Std            0.0832138
exploration/Rewards Max           -0.0125754
exploration/Rewards Min           -0.421133
exploration/Returns Mean         -16.8146
exploration/Returns Std            0.800574
exploration/Returns Max          -16.0141
exploration/Returns Min          -17.6152
exploration/Actions Mean           0.00585858
exploration/Actions Std            0.147675
exploration/Actions Max            0.734347
exploration/Actions Min           -0.357493
exploration/Num Paths              2
exploration/Average Returns      -16.8146
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.110936
evaluation/Rewards Std             0.0532686
evaluation/Rewards Max            -0.0317789
evaluation/Rewards Min            -0.853812
evaluation/Returns Mean          -11.0936
evaluation/Returns Std             0.280837
evaluation/Returns Max           -10.6188
evaluation/Returns Min           -11.3979
evaluation/Actions Mean            0.00652542
evaluation/Actions Std             0.088101
evaluation/Actions Max             0.999477
evaluation/Actions Min            -0.899927
evaluation/Num Paths               5
evaluation/Average Returns       -11.0936
time/data storing (s)              0.00104177
time/evaluation sampling (s)       0.0758215
time/exploration sampling (s)      0.0331589
time/logging (s)                   0.00246554
time/saving (s)                    0.00225077
time/training (s)                  0.455373
time/epoch (s)                     0.570111
time/total (s)                    25.6454
Epoch                             44
-----------------------------  ---------------
2019-04-13 16:58:59.863080 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 45 finished
-----------------------------  ---------------
replay_buffer/size              9300
trainer/QF1 Loss                   0.0311946
trainer/QF2 Loss                   0.035437
trainer/Policy Loss                5.41965
trainer/Q1 Predictions Mean       -5.71001
trainer/Q1 Predictions Std         0.677009
trainer/Q1 Predictions Max        -5.22087
trainer/Q1 Predictions Min        -7.72918
trainer/Q2 Predictions Mean       -5.69819
trainer/Q2 Predictions Std         0.679314
trainer/Q2 Predictions Max        -5.19522
trainer/Q2 Predictions Min        -7.73302
trainer/Q Targets Mean            -5.84024
trainer/Q Targets Std              0.695866
trainer/Q Targets Max             -5.21846
trainer/Q Targets Min             -7.94783
trainer/Bellman Errors 1 Mean      0.0311946
trainer/Bellman Errors 1 Std       0.0423215
trainer/Bellman Errors 1 Max       0.222672
trainer/Bellman Errors 1 Min       0.000292927
trainer/Bellman Errors 2 Mean      0.035437
trainer/Bellman Errors 2 Std       0.0512612
trainer/Bellman Errors 2 Max       0.269513
trainer/Bellman Errors 2 Min       0.000108583
trainer/Policy Action Mean         0.0579775
trainer/Policy Action Std          0.346231
trainer/Policy Action Max          0.99983
trainer/Policy Action Min         -0.74303
exploration/num steps total     9300
exploration/num paths total       93
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.133287
exploration/Rewards Std            0.0726132
exploration/Rewards Max           -0.00892997
exploration/Rewards Min           -0.322724
exploration/Returns Mean         -13.3287
exploration/Returns Std            0.055537
exploration/Returns Max          -13.2731
exploration/Returns Min          -13.3842
exploration/Actions Mean           0.0029206
exploration/Actions Std            0.140652
exploration/Actions Max            0.608877
exploration/Actions Min           -0.483604
exploration/Num Paths              2
exploration/Average Returns      -13.3287
evaluation/num steps total     23000
evaluation/num paths total       230
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0732516
evaluation/Rewards Std             0.0584005
evaluation/Rewards Max            -0.0331563
evaluation/Rewards Min            -1.0067
evaluation/Returns Mean           -7.32516
evaluation/Returns Std             0.348689
evaluation/Returns Max            -6.77709
evaluation/Returns Min            -7.81076
evaluation/Actions Mean            0.00656954
evaluation/Actions Std             0.087893
evaluation/Actions Max             0.999775
evaluation/Actions Min            -0.849573
evaluation/Num Paths               5
evaluation/Average Returns        -7.32516
time/data storing (s)              0.00118164
time/evaluation sampling (s)       0.0732562
time/exploration sampling (s)      0.0382044
time/logging (s)                   0.00244816
time/saving (s)                    0.00222049
time/training (s)                  0.437802
time/epoch (s)                     0.555113
time/total (s)                    26.2044
Epoch                             45
-----------------------------  ---------------
2019-04-13 16:59:00.430761 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 46 finished
-----------------------------  ---------------
replay_buffer/size              9500
trainer/QF1 Loss                   0.0160048
trainer/QF2 Loss                   0.0188623
trainer/Policy Loss                5.61357
trainer/Q1 Predictions Mean       -5.79913
trainer/Q1 Predictions Std         0.293832
trainer/Q1 Predictions Max        -5.57813
trainer/Q1 Predictions Min        -6.57886
trainer/Q2 Predictions Mean       -5.80379
trainer/Q2 Predictions Std         0.289255
trainer/Q2 Predictions Max        -5.57237
trainer/Q2 Predictions Min        -6.62619
trainer/Q Targets Mean            -5.786
trainer/Q Targets Std              0.316869
trainer/Q Targets Max             -5.42534
trainer/Q Targets Min             -6.57366
trainer/Bellman Errors 1 Mean      0.0160048
trainer/Bellman Errors 1 Std       0.0180619
trainer/Bellman Errors 1 Max       0.0628734
trainer/Bellman Errors 1 Min       2.44039e-07
trainer/Bellman Errors 2 Mean      0.0188623
trainer/Bellman Errors 2 Std       0.0224723
trainer/Bellman Errors 2 Max       0.0727026
trainer/Bellman Errors 2 Min       7.78186e-07
trainer/Policy Action Mean        -0.00892205
trainer/Policy Action Std          0.16147
trainer/Policy Action Max          0.349887
trainer/Policy Action Min         -0.360122
exploration/num steps total     9500
exploration/num paths total       95
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.139229
exploration/Rewards Std            0.083749
exploration/Rewards Max           -0.00967187
exploration/Rewards Min           -0.895178
exploration/Returns Mean         -13.9229
exploration/Returns Std            0.845183
exploration/Returns Max          -13.0777
exploration/Returns Min          -14.7681
exploration/Actions Mean           0.00845494
exploration/Actions Std            0.157418
exploration/Actions Max            1
exploration/Actions Min           -0.390469
exploration/Num Paths              2
exploration/Average Returns      -13.9229
evaluation/num steps total     23500
evaluation/num paths total       235
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0430433
evaluation/Rewards Std             0.0459212
evaluation/Rewards Max            -0.0215091
evaluation/Rewards Min            -1.02644
evaluation/Returns Mean           -4.30433
evaluation/Returns Std             0.375191
evaluation/Returns Max            -3.97194
evaluation/Returns Min            -5.03012
evaluation/Actions Mean            0.00686474
evaluation/Actions Std             0.077214
evaluation/Actions Max             0.999932
evaluation/Actions Min            -0.420899
evaluation/Num Paths               5
evaluation/Average Returns        -4.30433
time/data storing (s)              0.00105797
time/evaluation sampling (s)       0.0808329
time/exploration sampling (s)      0.0335168
time/logging (s)                   0.00187058
time/saving (s)                    0.00183575
time/training (s)                  0.443003
time/epoch (s)                     0.562117
time/total (s)                    26.7701
Epoch                             46
-----------------------------  ---------------
2019-04-13 16:59:00.999013 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 47 finished
-----------------------------  ---------------
replay_buffer/size              9700
trainer/QF1 Loss                   0.0276245
trainer/QF2 Loss                   0.0269297
trainer/Policy Loss                5.61022
trainer/Q1 Predictions Mean       -5.89156
trainer/Q1 Predictions Std         1.00681
trainer/Q1 Predictions Max        -5.48463
trainer/Q1 Predictions Min       -10.8805
trainer/Q2 Predictions Mean       -5.89466
trainer/Q2 Predictions Std         1.00316
trainer/Q2 Predictions Max        -5.47185
trainer/Q2 Predictions Min       -10.837
trainer/Q Targets Mean            -5.97779
trainer/Q Targets Std              0.929981
trainer/Q Targets Max             -5.49807
trainer/Q Targets Min            -10.5155
trainer/Bellman Errors 1 Mean      0.0276245
trainer/Bellman Errors 1 Std       0.037107
trainer/Bellman Errors 1 Max       0.133278
trainer/Bellman Errors 1 Min       3.76272e-06
trainer/Bellman Errors 2 Mean      0.0269297
trainer/Bellman Errors 2 Std       0.0338911
trainer/Bellman Errors 2 Max       0.114879
trainer/Bellman Errors 2 Min       1.9379e-05
trainer/Policy Action Mean         0.0140927
trainer/Policy Action Std          0.296158
trainer/Policy Action Max          0.999997
trainer/Policy Action Min         -0.985195
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.151701
exploration/Rewards Std            0.0702206
exploration/Rewards Max           -0.00966801
exploration/Rewards Min           -0.378106
exploration/Returns Mean         -15.1701
exploration/Returns Std            0.6445
exploration/Returns Max          -14.5256
exploration/Returns Min          -15.8146
exploration/Actions Mean           0.00293906
exploration/Actions Std            0.126444
exploration/Actions Max            0.474228
exploration/Actions Min           -0.379841
exploration/Num Paths              2
exploration/Average Returns      -15.1701
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.100128
evaluation/Rewards Std             0.0430287
evaluation/Rewards Max            -0.0626714
evaluation/Rewards Min            -0.853508
evaluation/Returns Mean          -10.0128
evaluation/Returns Std             0.368329
evaluation/Returns Max            -9.70298
evaluation/Returns Min           -10.5834
evaluation/Actions Mean            0.00391459
evaluation/Actions Std             0.0751848
evaluation/Actions Max             0.999773
evaluation/Actions Min            -0.927344
evaluation/Num Paths               5
evaluation/Average Returns       -10.0128
time/data storing (s)              0.00111977
time/evaluation sampling (s)       0.0768501
time/exploration sampling (s)      0.0327313
time/logging (s)                   0.00249603
time/saving (s)                    0.00232248
time/training (s)                  0.448272
time/epoch (s)                     0.563792
time/total (s)                    27.3381
Epoch                             47
-----------------------------  ---------------
2019-04-13 16:59:01.551750 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 48 finished
-----------------------------  ---------------
replay_buffer/size              9900
trainer/QF1 Loss                   3.36867
trainer/QF2 Loss                   3.3784
trainer/Policy Loss                5.79518
trainer/Q1 Predictions Mean       -6.13137
trainer/Q1 Predictions Std         0.721365
trainer/Q1 Predictions Max        -5.70411
trainer/Q1 Predictions Min        -8.74782
trainer/Q2 Predictions Mean       -6.12377
trainer/Q2 Predictions Std         0.734696
trainer/Q2 Predictions Max        -5.67776
trainer/Q2 Predictions Min        -8.75762
trainer/Q Targets Mean            -5.53172
trainer/Q Targets Std              1.80165
trainer/Q Targets Max             -0.0998128
trainer/Q Targets Min             -9.02793
trainer/Bellman Errors 1 Mean      3.36867
trainer/Bellman Errors 1 Std      10.4083
trainer/Bellman Errors 1 Max      38.1346
trainer/Bellman Errors 1 Min       9.57405e-06
trainer/Bellman Errors 2 Mean      3.3784
trainer/Bellman Errors 2 Std      10.4432
trainer/Bellman Errors 2 Max      38.9682
trainer/Bellman Errors 2 Min       8.48964e-05
trainer/Policy Action Mean         0.0399446
trainer/Policy Action Std          0.277199
trainer/Policy Action Max          0.992083
trainer/Policy Action Min         -0.396599
exploration/num steps total     9900
exploration/num paths total       99
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.150712
exploration/Rewards Std            0.0730176
exploration/Rewards Max           -0.00898664
exploration/Rewards Min           -0.492127
exploration/Returns Mean         -15.0712
exploration/Returns Std            0.127457
exploration/Returns Max          -14.9437
exploration/Returns Min          -15.1986
exploration/Actions Mean           0.00560013
exploration/Actions Std            0.148324
exploration/Actions Max            0.944462
exploration/Actions Min           -0.616606
exploration/Num Paths              2
exploration/Average Returns      -15.0712
evaluation/num steps total     24500
evaluation/num paths total       245
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0920223
evaluation/Rewards Std             0.0606593
evaluation/Rewards Max            -0.041717
evaluation/Rewards Min            -0.964921
evaluation/Returns Mean           -9.20223
evaluation/Returns Std             0.307346
evaluation/Returns Max            -8.80707
evaluation/Returns Min            -9.60847
evaluation/Actions Mean            0.00676543
evaluation/Actions Std             0.0876171
evaluation/Actions Max             0.99995
evaluation/Actions Min            -0.872065
evaluation/Num Paths               5
evaluation/Average Returns        -9.20223
time/data storing (s)              0.00116546
time/evaluation sampling (s)       0.0745044
time/exploration sampling (s)      0.0341628
time/logging (s)                   0.00244897
time/saving (s)                    0.00222486
time/training (s)                  0.433019
time/epoch (s)                     0.547525
time/total (s)                    27.8894
Epoch                             48
-----------------------------  ---------------
2019-04-13 16:59:02.108693 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 49 finished
-----------------------------  ---------------
replay_buffer/size             10100
trainer/QF1 Loss                   0.0160619
trainer/QF2 Loss                   0.0190059
trainer/Policy Loss                5.9182
trainer/Q1 Predictions Mean       -6.24374
trainer/Q1 Predictions Std         0.69414
trainer/Q1 Predictions Max        -5.69944
trainer/Q1 Predictions Min        -8.34374
trainer/Q2 Predictions Mean       -6.24727
trainer/Q2 Predictions Std         0.699214
trainer/Q2 Predictions Max        -5.6913
trainer/Q2 Predictions Min        -8.39561
trainer/Q Targets Mean            -6.25596
trainer/Q Targets Std              0.651643
trainer/Q Targets Max             -5.67163
trainer/Q Targets Min             -8.06364
trainer/Bellman Errors 1 Mean      0.0160619
trainer/Bellman Errors 1 Std       0.0199082
trainer/Bellman Errors 1 Max       0.0784533
trainer/Bellman Errors 1 Min       2.14333e-05
trainer/Bellman Errors 2 Mean      0.0190059
trainer/Bellman Errors 2 Std       0.0239265
trainer/Bellman Errors 2 Max       0.110201
trainer/Bellman Errors 2 Min       0.000203329
trainer/Policy Action Mean         0.0877423
trainer/Policy Action Std          0.324482
trainer/Policy Action Max          0.992401
trainer/Policy Action Min         -0.378536
exploration/num steps total    10100
exploration/num paths total      101
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.130652
exploration/Rewards Std            0.0703366
exploration/Rewards Max           -0.0125918
exploration/Rewards Min           -0.350633
exploration/Returns Mean         -13.0652
exploration/Returns Std            0.00818319
exploration/Returns Max          -13.057
exploration/Returns Min          -13.0734
exploration/Actions Mean           0.00701869
exploration/Actions Std            0.139742
exploration/Actions Max            0.878304
exploration/Actions Min           -0.357678
exploration/Num Paths              2
exploration/Average Returns      -13.0652
evaluation/num steps total     25000
evaluation/num paths total       250
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0517427
evaluation/Rewards Std             0.0585614
evaluation/Rewards Max            -0.0331736
evaluation/Rewards Min            -0.983908
evaluation/Returns Mean           -5.17427
evaluation/Returns Std             0.381534
evaluation/Returns Max            -4.74619
evaluation/Returns Min            -5.71996
evaluation/Actions Mean            0.00828957
evaluation/Actions Std             0.0831889
evaluation/Actions Max             0.999953
evaluation/Actions Min            -0.192245
evaluation/Num Paths               5
evaluation/Average Returns        -5.17427
time/data storing (s)              0.00111219
time/evaluation sampling (s)       0.0727723
time/exploration sampling (s)      0.0318075
time/logging (s)                   0.00247992
time/saving (s)                    0.0022148
time/training (s)                  0.442252
time/epoch (s)                     0.552639
time/total (s)                    28.4454
Epoch                             49
-----------------------------  ---------------
2019-04-13 16:59:02.675689 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 50 finished
-----------------------------  ---------------
replay_buffer/size             10300
trainer/QF1 Loss                   0.0207693
trainer/QF2 Loss                   0.0202002
trainer/Policy Loss                5.88021
trainer/Q1 Predictions Mean       -6.11857
trainer/Q1 Predictions Std         0.59191
trainer/Q1 Predictions Max        -5.7446
trainer/Q1 Predictions Min        -8.02199
trainer/Q2 Predictions Mean       -6.11653
trainer/Q2 Predictions Std         0.579177
trainer/Q2 Predictions Max        -5.75708
trainer/Q2 Predictions Min        -8.01227
trainer/Q Targets Mean            -6.14795
trainer/Q Targets Std              0.582296
trainer/Q Targets Max             -5.63631
trainer/Q Targets Min             -8.10904
trainer/Bellman Errors 1 Mean      0.0207693
trainer/Bellman Errors 1 Std       0.0482484
trainer/Bellman Errors 1 Max       0.27911
trainer/Bellman Errors 1 Min       2.39444e-05
trainer/Bellman Errors 2 Mean      0.0202002
trainer/Bellman Errors 2 Std       0.0491309
trainer/Bellman Errors 2 Max       0.282846
trainer/Bellman Errors 2 Min       1.63158e-05
trainer/Policy Action Mean         0.0833369
trainer/Policy Action Std          0.313833
trainer/Policy Action Max          0.99229
trainer/Policy Action Min         -0.355582
exploration/num steps total    10300
exploration/num paths total      103
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.137078
exploration/Rewards Std            0.0722944
exploration/Rewards Max           -0.0123768
exploration/Rewards Min           -0.371641
exploration/Returns Mean         -13.7078
exploration/Returns Std            0.642247
exploration/Returns Max          -13.0655
exploration/Returns Min          -14.35
exploration/Actions Mean           0.00344207
exploration/Actions Std            0.148072
exploration/Actions Max            0.988819
exploration/Actions Min           -0.536311
exploration/Num Paths              2
exploration/Average Returns      -13.7078
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0192011
evaluation/Rewards Std             0.0238956
evaluation/Rewards Max            -0.0154917
evaluation/Rewards Min            -0.506636
evaluation/Returns Mean           -1.92011
evaluation/Returns Std             0.186767
evaluation/Returns Max            -1.78894
evaluation/Returns Min            -2.28745
evaluation/Actions Mean            0.00285422
evaluation/Actions Std             0.0499912
evaluation/Actions Max             0.996569
evaluation/Actions Min            -0.446612
evaluation/Num Paths               5
evaluation/Average Returns        -1.92011
time/data storing (s)              0.00107847
time/evaluation sampling (s)       0.0750186
time/exploration sampling (s)      0.0331142
time/logging (s)                   0.00245174
time/saving (s)                    0.00225363
time/training (s)                  0.44796
time/epoch (s)                     0.561877
time/total (s)                    29.0111
Epoch                             50
-----------------------------  ---------------
2019-04-13 16:59:03.243900 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 51 finished
-----------------------------  ---------------
replay_buffer/size             10500
trainer/QF1 Loss                   0.018685
trainer/QF2 Loss                   0.0169991
trainer/Policy Loss                5.95869
trainer/Q1 Predictions Mean       -6.21368
trainer/Q1 Predictions Std         0.549608
trainer/Q1 Predictions Max        -5.83041
trainer/Q1 Predictions Min        -8.43135
trainer/Q2 Predictions Mean       -6.21892
trainer/Q2 Predictions Std         0.547967
trainer/Q2 Predictions Max        -5.82885
trainer/Q2 Predictions Min        -8.44148
trainer/Q Targets Mean            -6.24143
trainer/Q Targets Std              0.622462
trainer/Q Targets Max             -5.69408
trainer/Q Targets Min             -8.92414
trainer/Bellman Errors 1 Mean      0.018685
trainer/Bellman Errors 1 Std       0.0428154
trainer/Bellman Errors 1 Max       0.242845
trainer/Bellman Errors 1 Min       4.39309e-09
trainer/Bellman Errors 2 Mean      0.0169991
trainer/Bellman Errors 2 Std       0.0419724
trainer/Bellman Errors 2 Max       0.232959
trainer/Bellman Errors 2 Min       6.92121e-05
trainer/Policy Action Mean         0.0402943
trainer/Policy Action Std          0.24958
trainer/Policy Action Max          0.995144
trainer/Policy Action Min         -0.346079
exploration/num steps total    10500
exploration/num paths total      105
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131006
exploration/Rewards Std            0.0703909
exploration/Rewards Max           -0.0055041
exploration/Rewards Min           -0.357657
exploration/Returns Mean         -13.1006
exploration/Returns Std            0.660584
exploration/Returns Max          -12.4401
exploration/Returns Min          -13.7612
exploration/Actions Mean           0.00113142
exploration/Actions Std            0.143314
exploration/Actions Max            0.785321
exploration/Actions Min           -0.68226
exploration/Num Paths              2
exploration/Average Returns      -13.1006
evaluation/num steps total     26000
evaluation/num paths total       260
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0408606
evaluation/Rewards Std             0.0158395
evaluation/Rewards Max            -0.0134067
evaluation/Rewards Min            -0.33732
evaluation/Returns Mean           -4.08606
evaluation/Returns Std             0.0868688
evaluation/Returns Max            -3.99516
evaluation/Returns Min            -4.24584
evaluation/Actions Mean            0.00465394
evaluation/Actions Std             0.0608546
evaluation/Actions Max             0.99102
evaluation/Actions Min            -0.721788
evaluation/Num Paths               5
evaluation/Average Returns        -4.08606
time/data storing (s)              0.00114563
time/evaluation sampling (s)       0.074064
time/exploration sampling (s)      0.0346238
time/logging (s)                   0.00248247
time/saving (s)                    0.00243453
time/training (s)                  0.448369
time/epoch (s)                     0.563119
time/total (s)                    29.578
Epoch                             51
-----------------------------  ---------------
2019-04-13 16:59:03.805627 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 52 finished
-----------------------------  ---------------
replay_buffer/size             10700
trainer/QF1 Loss                   0.0561672
trainer/QF2 Loss                   0.0541633
trainer/Policy Loss                5.96975
trainer/Q1 Predictions Mean       -6.19522
trainer/Q1 Predictions Std         0.697727
trainer/Q1 Predictions Max        -5.72742
trainer/Q1 Predictions Min        -8.30385
trainer/Q2 Predictions Mean       -6.19966
trainer/Q2 Predictions Std         0.700728
trainer/Q2 Predictions Max        -5.72071
trainer/Q2 Predictions Min        -8.33625
trainer/Q Targets Mean            -6.39683
trainer/Q Targets Std              0.667315
trainer/Q Targets Max             -5.87568
trainer/Q Targets Min             -8.29108
trainer/Bellman Errors 1 Mean      0.0561672
trainer/Bellman Errors 1 Std       0.0609478
trainer/Bellman Errors 1 Max       0.245997
trainer/Bellman Errors 1 Min       0.000163065
trainer/Bellman Errors 2 Mean      0.0541633
trainer/Bellman Errors 2 Std       0.057545
trainer/Bellman Errors 2 Max       0.218688
trainer/Bellman Errors 2 Min       0.00203997
trainer/Policy Action Mean         0.0308613
trainer/Policy Action Std          0.321487
trainer/Policy Action Max          0.994842
trainer/Policy Action Min         -0.985985
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.159633
exploration/Rewards Std            0.0830407
exploration/Rewards Max           -0.00477472
exploration/Rewards Min           -0.439086
exploration/Returns Mean         -15.9633
exploration/Returns Std            0.480644
exploration/Returns Max          -15.4827
exploration/Returns Min          -16.444
exploration/Actions Mean           0.005835
exploration/Actions Std            0.139473
exploration/Actions Max            0.711798
exploration/Actions Min           -0.395858
exploration/Num Paths              2
exploration/Average Returns      -15.9633
evaluation/num steps total     26500
evaluation/num paths total       265
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.102786
evaluation/Rewards Std             0.0511646
evaluation/Rewards Max            -0.0636219
evaluation/Rewards Min            -0.842672
evaluation/Returns Mean          -10.2786
evaluation/Returns Std             0.234305
evaluation/Returns Max            -9.86341
evaluation/Returns Min           -10.5686
evaluation/Actions Mean            0.00609506
evaluation/Actions Std             0.0852055
evaluation/Actions Max             0.999082
evaluation/Actions Min            -0.894467
evaluation/Num Paths               5
evaluation/Average Returns       -10.2786
time/data storing (s)              0.00103863
time/evaluation sampling (s)       0.0750794
time/exploration sampling (s)      0.0317228
time/logging (s)                   0.00246475
time/saving (s)                    0.00226233
time/training (s)                  0.443921
time/epoch (s)                     0.556489
time/total (s)                    30.1383
Epoch                             52
-----------------------------  ---------------
2019-04-13 16:59:04.367715 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 53 finished
-----------------------------  ---------------
replay_buffer/size             10900
trainer/QF1 Loss                   0.0622255
trainer/QF2 Loss                   0.0598172
trainer/Policy Loss                6.03435
trainer/Q1 Predictions Mean       -6.23643
trainer/Q1 Predictions Std         0.560464
trainer/Q1 Predictions Max        -5.89844
trainer/Q1 Predictions Min        -8.48282
trainer/Q2 Predictions Mean       -6.23809
trainer/Q2 Predictions Std         0.559484
trainer/Q2 Predictions Max        -5.89934
trainer/Q2 Predictions Min        -8.50523
trainer/Q Targets Mean            -6.41937
trainer/Q Targets Std              0.598272
trainer/Q Targets Max             -5.84317
trainer/Q Targets Min             -8.90842
trainer/Bellman Errors 1 Mean      0.0622255
trainer/Bellman Errors 1 Std       0.0744116
trainer/Bellman Errors 1 Max       0.247246
trainer/Bellman Errors 1 Min       6.42071e-06
trainer/Bellman Errors 2 Mean      0.0598172
trainer/Bellman Errors 2 Std       0.070542
trainer/Bellman Errors 2 Max       0.254073
trainer/Bellman Errors 2 Min       5.27367e-06
trainer/Policy Action Mean         0.022198
trainer/Policy Action Std          0.242888
trainer/Policy Action Max          0.991195
trainer/Policy Action Min         -0.353114
exploration/num steps total    10900
exploration/num paths total      109
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135972
exploration/Rewards Std            0.0699392
exploration/Rewards Max           -0.00367297
exploration/Rewards Min           -0.350976
exploration/Returns Mean         -13.5972
exploration/Returns Std            0.283906
exploration/Returns Max          -13.3133
exploration/Returns Min          -13.8811
exploration/Actions Mean           0.00794204
exploration/Actions Std            0.14526
exploration/Actions Max            1
exploration/Actions Min           -0.379725
exploration/Num Paths              2
exploration/Average Returns      -13.5972
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0383698
evaluation/Rewards Std             0.0374234
evaluation/Rewards Max            -0.0327387
evaluation/Rewards Min            -0.849395
evaluation/Returns Mean           -3.83698
evaluation/Returns Std             0.315831
evaluation/Returns Max            -3.62699
evaluation/Returns Min            -4.4642
evaluation/Actions Mean            0.00374748
evaluation/Actions Std             0.0563448
evaluation/Actions Max             0.99975
evaluation/Actions Min            -0.573404
evaluation/Num Paths               5
evaluation/Average Returns        -3.83698
time/data storing (s)              0.00109095
time/evaluation sampling (s)       0.0743568
time/exploration sampling (s)      0.0329813
time/logging (s)                   0.00246052
time/saving (s)                    0.00223992
time/training (s)                  0.443797
time/epoch (s)                     0.556926
time/total (s)                    30.699
Epoch                             53
-----------------------------  ---------------
2019-04-13 16:59:04.942415 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 54 finished
-----------------------------  ---------------
replay_buffer/size             11100
trainer/QF1 Loss                   1.12886
trainer/QF2 Loss                   1.12228
trainer/Policy Loss                6.11055
trainer/Q1 Predictions Mean       -6.43243
trainer/Q1 Predictions Std         0.898286
trainer/Q1 Predictions Max        -6.03749
trainer/Q1 Predictions Min       -10.4457
trainer/Q2 Predictions Mean       -6.43232
trainer/Q2 Predictions Std         0.910609
trainer/Q2 Predictions Max        -6.01967
trainer/Q2 Predictions Min       -10.5294
trainer/Q Targets Mean            -6.26246
trainer/Q Targets Std              1.43557
trainer/Q Targets Max             -0.0770247
trainer/Q Targets Min            -10.4562
trainer/Bellman Errors 1 Mean      1.12886
trainer/Bellman Errors 1 Std       6.17816
trainer/Bellman Errors 1 Max      35.5271
trainer/Bellman Errors 1 Min       1.53558e-05
trainer/Bellman Errors 2 Mean      1.12228
trainer/Bellman Errors 2 Std       6.14126
trainer/Bellman Errors 2 Max      35.3151
trainer/Bellman Errors 2 Min       3.76966e-05
trainer/Policy Action Mean         0.0486819
trainer/Policy Action Std          0.288436
trainer/Policy Action Max          0.999975
trainer/Policy Action Min         -0.984612
exploration/num steps total    11100
exploration/num paths total      111
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134197
exploration/Rewards Std            0.0871158
exploration/Rewards Max           -0.0112322
exploration/Rewards Min           -0.769364
exploration/Returns Mean         -13.4197
exploration/Returns Std            0.646099
exploration/Returns Max          -12.7736
exploration/Returns Min          -14.0658
exploration/Actions Mean           0.00763827
exploration/Actions Std            0.156001
exploration/Actions Max            0.895739
exploration/Actions Min           -0.725086
exploration/Num Paths              2
exploration/Average Returns      -13.4197
evaluation/num steps total     27500
evaluation/num paths total       275
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0328612
evaluation/Rewards Std             0.0505201
evaluation/Rewards Max            -0.0100371
evaluation/Rewards Min            -0.830281
evaluation/Returns Mean           -3.28612
evaluation/Returns Std             0.349648
evaluation/Returns Max            -2.96666
evaluation/Returns Min            -3.73784
evaluation/Actions Mean            0.00391321
evaluation/Actions Std             0.0670669
evaluation/Actions Max             0.999898
evaluation/Actions Min            -0.565674
evaluation/Num Paths               5
evaluation/Average Returns        -3.28612
time/data storing (s)              0.00107088
time/evaluation sampling (s)       0.0800324
time/exploration sampling (s)      0.0333747
time/logging (s)                   0.00348022
time/saving (s)                    0.00588984
time/training (s)                  0.446632
time/epoch (s)                     0.57048
time/total (s)                    31.2734
Epoch                             54
-----------------------------  ---------------
2019-04-13 16:59:05.492698 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 55 finished
-----------------------------  ---------------
replay_buffer/size             11300
trainer/QF1 Loss                   0.0213189
trainer/QF2 Loss                   0.023723
trainer/Policy Loss                6.31496
trainer/Q1 Predictions Mean       -6.61258
trainer/Q1 Predictions Std         0.71879
trainer/Q1 Predictions Max        -6.15779
trainer/Q1 Predictions Min        -8.66897
trainer/Q2 Predictions Mean       -6.60733
trainer/Q2 Predictions Std         0.724409
trainer/Q2 Predictions Max        -6.14883
trainer/Q2 Predictions Min        -8.70599
trainer/Q Targets Mean            -6.59128
trainer/Q Targets Std              0.768717
trainer/Q Targets Max             -5.90003
trainer/Q Targets Min             -8.63653
trainer/Bellman Errors 1 Mean      0.0213189
trainer/Bellman Errors 1 Std       0.0287018
trainer/Bellman Errors 1 Max       0.133174
trainer/Bellman Errors 1 Min       0.000140047
trainer/Bellman Errors 2 Mean      0.023723
trainer/Bellman Errors 2 Std       0.0317583
trainer/Bellman Errors 2 Max       0.146732
trainer/Bellman Errors 2 Min       1.1706e-06
trainer/Policy Action Mean         0.123867
trainer/Policy Action Std          0.316154
trainer/Policy Action Max          0.995772
trainer/Policy Action Min         -0.341825
exploration/num steps total    11300
exploration/num paths total      113
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131368
exploration/Rewards Std            0.0649438
exploration/Rewards Max           -0.0112151
exploration/Rewards Min           -0.374287
exploration/Returns Mean         -13.1368
exploration/Returns Std            0.488575
exploration/Returns Max          -12.6482
exploration/Returns Min          -13.6253
exploration/Actions Mean           0.00163695
exploration/Actions Std            0.148153
exploration/Actions Max            0.980123
exploration/Actions Min           -0.819642
exploration/Num Paths              2
exploration/Average Returns      -13.1368
evaluation/num steps total     28000
evaluation/num paths total       280
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.046621
evaluation/Rewards Std             0.0687905
evaluation/Rewards Max            -0.00491284
evaluation/Rewards Min            -0.994066
evaluation/Returns Mean           -4.6621
evaluation/Returns Std             0.362015
evaluation/Returns Max            -4.126
evaluation/Returns Min            -5.03655
evaluation/Actions Mean            0.00592892
evaluation/Actions Std             0.0943134
evaluation/Actions Max             0.999977
evaluation/Actions Min            -0.919366
evaluation/Num Paths               5
evaluation/Average Returns        -4.6621
time/data storing (s)              0.00114721
time/evaluation sampling (s)       0.0748739
time/exploration sampling (s)      0.032731
time/logging (s)                   0.00246762
time/saving (s)                    0.00224615
time/training (s)                  0.430381
time/epoch (s)                     0.543846
time/total (s)                    31.8211
Epoch                             55
-----------------------------  ---------------
2019-04-13 16:59:06.058673 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 56 finished
-----------------------------  ---------------
replay_buffer/size             11500
trainer/QF1 Loss                   0.0257562
trainer/QF2 Loss                   0.0253722
trainer/Policy Loss                6.22894
trainer/Q1 Predictions Mean       -6.41983
trainer/Q1 Predictions Std         0.449386
trainer/Q1 Predictions Max        -6.14256
trainer/Q1 Predictions Min        -8.14691
trainer/Q2 Predictions Mean       -6.4093
trainer/Q2 Predictions Std         0.449271
trainer/Q2 Predictions Max        -6.10712
trainer/Q2 Predictions Min        -8.1279
trainer/Q Targets Mean            -6.47858
trainer/Q Targets Std              0.440802
trainer/Q Targets Max             -6.00054
trainer/Q Targets Min             -7.98276
trainer/Bellman Errors 1 Mean      0.0257562
trainer/Bellman Errors 1 Std       0.0409188
trainer/Bellman Errors 1 Max       0.211923
trainer/Bellman Errors 1 Min       3.90196e-09
trainer/Bellman Errors 2 Mean      0.0253722
trainer/Bellman Errors 2 Std       0.0427513
trainer/Bellman Errors 2 Max       0.226558
trainer/Bellman Errors 2 Min       0.000871067
trainer/Policy Action Mean         0.0682589
trainer/Policy Action Std          0.315204
trainer/Policy Action Max          0.993134
trainer/Policy Action Min         -0.932613
exploration/num steps total    11500
exploration/num paths total      115
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.166302
exploration/Rewards Std            0.087427
exploration/Rewards Max           -0.0130346
exploration/Rewards Min           -0.453876
exploration/Returns Mean         -16.6302
exploration/Returns Std            0.656255
exploration/Returns Max          -15.974
exploration/Returns Min          -17.2865
exploration/Actions Mean           5.82269e-05
exploration/Actions Std            0.142165
exploration/Actions Max            0.716553
exploration/Actions Min           -0.702994
exploration/Num Paths              2
exploration/Average Returns      -16.6302
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.128638
evaluation/Rewards Std             0.0225888
evaluation/Rewards Max            -0.049991
evaluation/Rewards Min            -0.599371
evaluation/Returns Mean          -12.8638
evaluation/Returns Std             0.210098
evaluation/Returns Max           -12.716
evaluation/Returns Min           -13.264
evaluation/Actions Mean            0.00434633
evaluation/Actions Std             0.0819984
evaluation/Actions Max             0.999256
evaluation/Actions Min            -0.869349
evaluation/Num Paths               5
evaluation/Average Returns       -12.8638
time/data storing (s)              0.00105425
time/evaluation sampling (s)       0.0752101
time/exploration sampling (s)      0.0335769
time/logging (s)                   0.00225335
time/saving (s)                    0.00236588
time/training (s)                  0.447018
time/epoch (s)                     0.561479
time/total (s)                    32.3859
Epoch                             56
-----------------------------  ---------------
2019-04-13 16:59:06.616436 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 57 finished
-----------------------------  ---------------
replay_buffer/size             11700
trainer/QF1 Loss                   0.0613305
trainer/QF2 Loss                   0.0662062
trainer/Policy Loss                6.22366
trainer/Q1 Predictions Mean       -6.37538
trainer/Q1 Predictions Std         0.429043
trainer/Q1 Predictions Max        -6.15978
trainer/Q1 Predictions Min        -8.41228
trainer/Q2 Predictions Mean       -6.37572
trainer/Q2 Predictions Std         0.428027
trainer/Q2 Predictions Max        -6.14078
trainer/Q2 Predictions Min        -8.42146
trainer/Q Targets Mean            -6.55227
trainer/Q Targets Std              0.497039
trainer/Q Targets Max             -6.18988
trainer/Q Targets Min             -8.7474
trainer/Bellman Errors 1 Mean      0.0613305
trainer/Bellman Errors 1 Std       0.115768
trainer/Bellman Errors 1 Max       0.642235
trainer/Bellman Errors 1 Min       0.000107483
trainer/Bellman Errors 2 Mean      0.0662062
trainer/Bellman Errors 2 Std       0.141152
trainer/Bellman Errors 2 Max       0.804061
trainer/Bellman Errors 2 Min       9.42068e-05
trainer/Policy Action Mean         0.0528005
trainer/Policy Action Std          0.229642
trainer/Policy Action Max          0.996703
trainer/Policy Action Min         -0.855581
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.158972
exploration/Rewards Std            0.0817465
exploration/Rewards Max           -0.00921344
exploration/Rewards Min           -0.356022
exploration/Returns Mean         -15.8972
exploration/Returns Std            0.00754407
exploration/Returns Max          -15.8897
exploration/Returns Min          -15.9047
exploration/Actions Mean           0.00635304
exploration/Actions Std            0.1418
exploration/Actions Max            0.864264
exploration/Actions Min           -0.401857
exploration/Num Paths              2
exploration/Average Returns      -15.8972
evaluation/num steps total     29000
evaluation/num paths total       290
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.109532
evaluation/Rewards Std             0.0367409
evaluation/Rewards Max            -0.0350431
evaluation/Rewards Min            -0.804957
evaluation/Returns Mean          -10.9532
evaluation/Returns Std             0.292944
evaluation/Returns Max           -10.695
evaluation/Returns Min           -11.4256
evaluation/Actions Mean            0.00546071
evaluation/Actions Std             0.0670699
evaluation/Actions Max             0.99993
evaluation/Actions Min            -0.373006
evaluation/Num Paths               5
evaluation/Average Returns       -10.9532
time/data storing (s)              0.00106718
time/evaluation sampling (s)       0.0731552
time/exploration sampling (s)      0.0312086
time/logging (s)                   0.00247899
time/saving (s)                    0.00228593
time/training (s)                  0.442564
time/epoch (s)                     0.55276
time/total (s)                    32.9424
Epoch                             57
-----------------------------  ---------------
2019-04-13 16:59:07.178906 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 58 finished
-----------------------------  ---------------
replay_buffer/size             11900
trainer/QF1 Loss                   0.0500004
trainer/QF2 Loss                   0.0479391
trainer/Policy Loss                6.32071
trainer/Q1 Predictions Mean       -6.492
trainer/Q1 Predictions Std         0.471011
trainer/Q1 Predictions Max        -6.13444
trainer/Q1 Predictions Min        -8.60324
trainer/Q2 Predictions Mean       -6.49616
trainer/Q2 Predictions Std         0.470384
trainer/Q2 Predictions Max        -6.10045
trainer/Q2 Predictions Min        -8.62542
trainer/Q Targets Mean            -6.66601
trainer/Q Targets Std              0.496834
trainer/Q Targets Max             -6.17126
trainer/Q Targets Min             -8.68282
trainer/Bellman Errors 1 Mean      0.0500003
trainer/Bellman Errors 1 Std       0.0486678
trainer/Bellman Errors 1 Max       0.17764
trainer/Bellman Errors 1 Min       0.000283617
trainer/Bellman Errors 2 Mean      0.0479391
trainer/Bellman Errors 2 Std       0.0518399
trainer/Bellman Errors 2 Max       0.227882
trainer/Bellman Errors 2 Min       0.00022159
trainer/Policy Action Mean        -0.0174296
trainer/Policy Action Std          0.209692
trainer/Policy Action Max          0.995744
trainer/Policy Action Min         -0.367742
exploration/num steps total    11900
exploration/num paths total      119
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135397
exploration/Rewards Std            0.0674647
exploration/Rewards Max           -0.0109221
exploration/Rewards Min           -0.346034
exploration/Returns Mean         -13.5397
exploration/Returns Std            0.812387
exploration/Returns Max          -12.7273
exploration/Returns Min          -14.352
exploration/Actions Mean           0.000634873
exploration/Actions Std            0.136511
exploration/Actions Max            0.369054
exploration/Actions Min           -0.481485
exploration/Num Paths              2
exploration/Average Returns      -13.5397
evaluation/num steps total     29500
evaluation/num paths total       295
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0660822
evaluation/Rewards Std             0.0333197
evaluation/Rewards Max            -0.0630546
evaluation/Rewards Min            -0.708227
evaluation/Returns Mean           -6.60822
evaluation/Returns Std             0.23341
evaluation/Returns Max            -6.39364
evaluation/Returns Min            -7.01416
evaluation/Actions Mean            0.00419137
evaluation/Actions Std             0.0759911
evaluation/Actions Max             0.999787
evaluation/Actions Min            -0.866591
evaluation/Num Paths               5
evaluation/Average Returns        -6.60822
time/data storing (s)              0.00106444
time/evaluation sampling (s)       0.074138
time/exploration sampling (s)      0.0316689
time/logging (s)                   0.00278054
time/saving (s)                    0.00206385
time/training (s)                  0.44584
time/epoch (s)                     0.557556
time/total (s)                    33.5038
Epoch                             58
-----------------------------  ---------------
2019-04-13 16:59:07.749848 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 59 finished
-----------------------------  ---------------
replay_buffer/size             12100
trainer/QF1 Loss                   1.34536
trainer/QF2 Loss                   1.32951
trainer/Policy Loss                6.49503
trainer/Q1 Predictions Mean       -6.69542
trainer/Q1 Predictions Std         0.609235
trainer/Q1 Predictions Max        -6.38957
trainer/Q1 Predictions Min        -9.18564
trainer/Q2 Predictions Mean       -6.7019
trainer/Q2 Predictions Std         0.610346
trainer/Q2 Predictions Max        -6.39946
trainer/Q2 Predictions Min        -9.27391
trainer/Q Targets Mean            -6.5418
trainer/Q Targets Std              1.22987
trainer/Q Targets Max             -0.624367
trainer/Q Targets Min             -9.14883
trainer/Bellman Errors 1 Mean      1.34536
trainer/Bellman Errors 1 Std       7.32391
trainer/Bellman Errors 1 Max      42.1219
trainer/Bellman Errors 1 Min       1.40471e-05
trainer/Bellman Errors 2 Mean      1.32951
trainer/Bellman Errors 2 Std       7.23772
trainer/Bellman Errors 2 Max      41.6262
trainer/Bellman Errors 2 Min       1.28171e-05
trainer/Policy Action Mean         0.0134972
trainer/Policy Action Std          0.245525
trainer/Policy Action Max          0.995078
trainer/Policy Action Min         -0.994238
exploration/num steps total    12100
exploration/num paths total      121
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132217
exploration/Rewards Std            0.0769778
exploration/Rewards Max           -0.00377251
exploration/Rewards Min           -0.500866
exploration/Returns Mean         -13.2217
exploration/Returns Std            0.467166
exploration/Returns Max          -12.7546
exploration/Returns Min          -13.6889
exploration/Actions Mean           0.00629758
exploration/Actions Std            0.147687
exploration/Actions Max            0.945254
exploration/Actions Min           -0.358604
exploration/Num Paths              2
exploration/Average Returns      -13.2217
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0490012
evaluation/Rewards Std             0.0225584
evaluation/Rewards Max            -0.0342869
evaluation/Rewards Min            -0.504649
evaluation/Returns Mean           -4.90012
evaluation/Returns Std             0.176367
evaluation/Returns Max            -4.73393
evaluation/Returns Min            -5.20271
evaluation/Actions Mean            0.00469702
evaluation/Actions Std             0.0665467
evaluation/Actions Max             0.998238
evaluation/Actions Min            -0.411327
evaluation/Num Paths               5
evaluation/Average Returns        -4.90012
time/data storing (s)              0.00107204
time/evaluation sampling (s)       0.0758057
time/exploration sampling (s)      0.0339107
time/logging (s)                   0.00188186
time/saving (s)                    0.00203889
time/training (s)                  0.449982
time/epoch (s)                     0.564691
time/total (s)                    34.0722
Epoch                             59
-----------------------------  ---------------
2019-04-13 16:59:08.314535 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 60 finished
-----------------------------  ---------------
replay_buffer/size             12300
trainer/QF1 Loss                   0.0259344
trainer/QF2 Loss                   0.0260822
trainer/Policy Loss                6.53316
trainer/Q1 Predictions Mean       -6.68149
trainer/Q1 Predictions Std         0.331293
trainer/Q1 Predictions Max        -6.44732
trainer/Q1 Predictions Min        -7.79904
trainer/Q2 Predictions Mean       -6.68393
trainer/Q2 Predictions Std         0.328409
trainer/Q2 Predictions Max        -6.42867
trainer/Q2 Predictions Min        -7.83378
trainer/Q Targets Mean            -6.77384
trainer/Q Targets Std              0.353316
trainer/Q Targets Max             -6.39824
trainer/Q Targets Min             -7.80356
trainer/Bellman Errors 1 Mean      0.0259344
trainer/Bellman Errors 1 Std       0.0421174
trainer/Bellman Errors 1 Max       0.213503
trainer/Bellman Errors 1 Min       2.04126e-05
trainer/Bellman Errors 2 Mean      0.0260822
trainer/Bellman Errors 2 Std       0.0416761
trainer/Bellman Errors 2 Max       0.176969
trainer/Bellman Errors 2 Min       5.35502e-06
trainer/Policy Action Mean         0.00890551
trainer/Policy Action Std          0.226984
trainer/Policy Action Max          0.879257
trainer/Policy Action Min         -0.891853
exploration/num steps total    12300
exploration/num paths total      123
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.142515
exploration/Rewards Std            0.0802528
exploration/Rewards Max           -0.0110667
exploration/Rewards Min           -0.567749
exploration/Returns Mean         -14.2515
exploration/Returns Std            0.0944488
exploration/Returns Max          -14.157
exploration/Returns Min          -14.3459
exploration/Actions Mean           0.0103244
exploration/Actions Std            0.164048
exploration/Actions Max            1
exploration/Actions Min           -0.489296
exploration/Num Paths              2
exploration/Average Returns      -14.2515
evaluation/num steps total     30500
evaluation/num paths total       305
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0489594
evaluation/Rewards Std             0.00279034
evaluation/Rewards Max            -0.012712
evaluation/Rewards Min            -0.0885402
evaluation/Returns Mean           -4.89594
evaluation/Returns Std             0.0231798
evaluation/Returns Max            -4.86208
evaluation/Returns Min            -4.93074
evaluation/Actions Mean            0.00225649
evaluation/Actions Std             0.0475985
evaluation/Actions Max             0.615302
evaluation/Actions Min            -0.92048
evaluation/Num Paths               5
evaluation/Average Returns        -4.89594
time/data storing (s)              0.00106334
time/evaluation sampling (s)       0.078515
time/exploration sampling (s)      0.0326209
time/logging (s)                   0.0024677
time/saving (s)                    0.0022457
time/training (s)                  0.443832
time/epoch (s)                     0.560744
time/total (s)                    34.6365
Epoch                             60
-----------------------------  ---------------
2019-04-13 16:59:08.881331 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 61 finished
-----------------------------  ---------------
replay_buffer/size             12500
trainer/QF1 Loss                   0.0370753
trainer/QF2 Loss                   0.0316665
trainer/Policy Loss                6.47828
trainer/Q1 Predictions Mean       -6.73777
trainer/Q1 Predictions Std         0.500754
trainer/Q1 Predictions Max        -6.36228
trainer/Q1 Predictions Min        -8.96698
trainer/Q2 Predictions Mean       -6.75302
trainer/Q2 Predictions Std         0.506888
trainer/Q2 Predictions Max        -6.37658
trainer/Q2 Predictions Min        -8.97304
trainer/Q Targets Mean            -6.85837
trainer/Q Targets Std              0.518905
trainer/Q Targets Max             -6.36242
trainer/Q Targets Min             -8.95097
trainer/Bellman Errors 1 Mean      0.0370753
trainer/Bellman Errors 1 Std       0.0608565
trainer/Bellman Errors 1 Max       0.281316
trainer/Bellman Errors 1 Min       4.91867e-05
trainer/Bellman Errors 2 Mean      0.0316665
trainer/Bellman Errors 2 Std       0.0510316
trainer/Bellman Errors 2 Max       0.196747
trainer/Bellman Errors 2 Min       4.32383e-07
trainer/Policy Action Mean        -0.00430623
trainer/Policy Action Std          0.224748
trainer/Policy Action Max          0.996424
trainer/Policy Action Min         -0.344109
exploration/num steps total    12500
exploration/num paths total      125
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.140342
exploration/Rewards Std            0.0964098
exploration/Rewards Max           -0.0180102
exploration/Rewards Min           -1.09894
exploration/Returns Mean         -14.0342
exploration/Returns Std            0.321546
exploration/Returns Max          -13.7127
exploration/Returns Min          -14.3557
exploration/Actions Mean           0.00664799
exploration/Actions Std            0.153853
exploration/Actions Max            1
exploration/Actions Min           -0.375264
exploration/Num Paths              2
exploration/Average Returns      -14.0342
evaluation/num steps total     31000
evaluation/num paths total       310
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0682003
evaluation/Rewards Std             0.0356985
evaluation/Rewards Max            -0.0577626
evaluation/Rewards Min            -0.753101
evaluation/Returns Mean           -6.82003
evaluation/Returns Std             0.23635
evaluation/Returns Max            -6.57625
evaluation/Returns Min            -7.23366
evaluation/Actions Mean            0.00304802
evaluation/Actions Std             0.0901307
evaluation/Actions Max             0.9999
evaluation/Actions Min            -0.916922
evaluation/Num Paths               5
evaluation/Average Returns        -6.82003
time/data storing (s)              0.00113084
time/evaluation sampling (s)       0.0740735
time/exploration sampling (s)      0.0338109
time/logging (s)                   0.00248797
time/saving (s)                    0.00238015
time/training (s)                  0.448203
time/epoch (s)                     0.562087
time/total (s)                    35.202
Epoch                             61
-----------------------------  ---------------
2019-04-13 16:59:09.467038 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 62 finished
-----------------------------  ---------------
replay_buffer/size             12700
trainer/QF1 Loss                   0.0526102
trainer/QF2 Loss                   0.0585705
trainer/Policy Loss                6.49692
trainer/Q1 Predictions Mean       -6.70662
trainer/Q1 Predictions Std         0.529421
trainer/Q1 Predictions Max        -6.44964
trainer/Q1 Predictions Min        -9.18815
trainer/Q2 Predictions Mean       -6.69825
trainer/Q2 Predictions Std         0.530592
trainer/Q2 Predictions Max        -6.40879
trainer/Q2 Predictions Min        -9.18984
trainer/Q Targets Mean            -6.87421
trainer/Q Targets Std              0.559281
trainer/Q Targets Max             -6.38999
trainer/Q Targets Min             -9.26815
trainer/Bellman Errors 1 Mean      0.0526102
trainer/Bellman Errors 1 Std       0.0768704
trainer/Bellman Errors 1 Max       0.281341
trainer/Bellman Errors 1 Min       5.62168e-05
trainer/Bellman Errors 2 Mean      0.0585705
trainer/Bellman Errors 2 Std       0.0836098
trainer/Bellman Errors 2 Max       0.270942
trainer/Bellman Errors 2 Min       3.00388e-05
trainer/Policy Action Mean         0.0357071
trainer/Policy Action Std          0.224144
trainer/Policy Action Max          0.995762
trainer/Policy Action Min         -0.335181
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.142921
exploration/Rewards Std            0.0865141
exploration/Rewards Max           -0.00889882
exploration/Rewards Min           -0.838801
exploration/Returns Mean         -14.2921
exploration/Returns Std            0.300232
exploration/Returns Max          -13.9919
exploration/Returns Min          -14.5924
exploration/Actions Mean           0.0122371
exploration/Actions Std            0.1635
exploration/Actions Max            0.963115
exploration/Actions Min           -0.425678
exploration/Num Paths              2
exploration/Average Returns      -14.2921
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0533882
evaluation/Rewards Std             0.0321694
evaluation/Rewards Max            -0.0453129
evaluation/Rewards Min            -0.559767
evaluation/Returns Mean           -5.33882
evaluation/Returns Std             0.171303
evaluation/Returns Max            -5.13766
evaluation/Returns Min            -5.57225
evaluation/Actions Mean            0.00297008
evaluation/Actions Std             0.0771783
evaluation/Actions Max             0.999516
evaluation/Actions Min            -0.911491
evaluation/Num Paths               5
evaluation/Average Returns        -5.33882
time/data storing (s)              0.00107143
time/evaluation sampling (s)       0.0822569
time/exploration sampling (s)      0.0340478
time/logging (s)                   0.00264204
time/saving (s)                    0.00332473
time/training (s)                  0.457102
time/epoch (s)                     0.580445
time/total (s)                    35.7862
Epoch                             62
-----------------------------  ---------------
2019-04-13 16:59:10.021808 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size             12900
trainer/QF1 Loss                   0.0429975
trainer/QF2 Loss                   0.0436041
trainer/Policy Loss                6.86875
trainer/Q1 Predictions Mean       -7.0774
trainer/Q1 Predictions Std         0.567164
trainer/Q1 Predictions Max        -6.56156
trainer/Q1 Predictions Min        -9.19135
trainer/Q2 Predictions Mean       -7.07327
trainer/Q2 Predictions Std         0.566585
trainer/Q2 Predictions Max        -6.60315
trainer/Q2 Predictions Min        -9.19104
trainer/Q Targets Mean            -7.05362
trainer/Q Targets Std              0.675348
trainer/Q Targets Max             -6.51078
trainer/Q Targets Min             -9.20038
trainer/Bellman Errors 1 Mean      0.0429975
trainer/Bellman Errors 1 Std       0.0818716
trainer/Bellman Errors 1 Max       0.457442
trainer/Bellman Errors 1 Min       1.00272e-10
trainer/Bellman Errors 2 Mean      0.0436041
trainer/Bellman Errors 2 Std       0.0813981
trainer/Bellman Errors 2 Max       0.447097
trainer/Bellman Errors 2 Min       5.80779e-06
trainer/Policy Action Mean         0.0664218
trainer/Policy Action Std          0.302246
trainer/Policy Action Max          0.996586
trainer/Policy Action Min         -0.376094
exploration/num steps total    12900
exploration/num paths total      129
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.118528
exploration/Rewards Std            0.0793717
exploration/Rewards Max           -0.00531557
exploration/Rewards Min           -0.657714
exploration/Returns Mean         -11.8528
exploration/Returns Std            0.142984
exploration/Returns Max          -11.7098
exploration/Returns Min          -11.9958
exploration/Actions Mean           0.00957145
exploration/Actions Std            0.144977
exploration/Actions Max            0.993629
exploration/Actions Min           -0.316092
exploration/Num Paths              2
exploration/Average Returns      -11.8528
evaluation/num steps total     32000
evaluation/num paths total       320
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0332861
evaluation/Rewards Std             0.0486894
evaluation/Rewards Max            -0.00931262
evaluation/Rewards Min            -0.933381
evaluation/Returns Mean           -3.32861
evaluation/Returns Std             0.357256
evaluation/Returns Max            -3.03234
evaluation/Returns Min            -3.93466
evaluation/Actions Mean            0.00329845
evaluation/Actions Std             0.0834928
evaluation/Actions Max             0.999973
evaluation/Actions Min            -0.930074
evaluation/Num Paths               5
evaluation/Average Returns        -3.32861
time/data storing (s)              0.00110564
time/evaluation sampling (s)       0.0749717
time/exploration sampling (s)      0.0329745
time/logging (s)                   0.0024867
time/saving (s)                    0.00223643
time/training (s)                  0.435483
time/epoch (s)                     0.549258
time/total (s)                    36.3394
Epoch                             63
-----------------------------  ---------------
2019-04-13 16:59:10.583742 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 64 finished
-----------------------------  ---------------
replay_buffer/size             13100
trainer/QF1 Loss                   0.0305046
trainer/QF2 Loss                   0.0385749
trainer/Policy Loss                6.8385
trainer/Q1 Predictions Mean       -7.0892
trainer/Q1 Predictions Std         0.582325
trainer/Q1 Predictions Max        -6.67912
trainer/Q1 Predictions Min        -8.87155
trainer/Q2 Predictions Mean       -7.07273
trainer/Q2 Predictions Std         0.567932
trainer/Q2 Predictions Max        -6.6679
trainer/Q2 Predictions Min        -8.86347
trainer/Q Targets Mean            -7.13569
trainer/Q Targets Std              0.649491
trainer/Q Targets Max             -6.62165
trainer/Q Targets Min             -9.16471
trainer/Bellman Errors 1 Mean      0.0305046
trainer/Bellman Errors 1 Std       0.0598328
trainer/Bellman Errors 1 Max       0.321626
trainer/Bellman Errors 1 Min       2.63248e-07
trainer/Bellman Errors 2 Mean      0.0385749
trainer/Bellman Errors 2 Std       0.104997
trainer/Bellman Errors 2 Max       0.595374
trainer/Bellman Errors 2 Min       2.41199e-06
trainer/Policy Action Mean         0.0909414
trainer/Policy Action Std          0.284047
trainer/Policy Action Max          0.996214
trainer/Policy Action Min         -0.32374
exploration/num steps total    13100
exploration/num paths total      131
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.138768
exploration/Rewards Std            0.106199
exploration/Rewards Max           -0.00602066
exploration/Rewards Min           -1.05683
exploration/Returns Mean         -13.8768
exploration/Returns Std            0.658674
exploration/Returns Max          -13.2181
exploration/Returns Min          -14.5355
exploration/Actions Mean           0.00753639
exploration/Actions Std            0.153643
exploration/Actions Max            1
exploration/Actions Min           -0.577096
exploration/Num Paths              2
exploration/Average Returns      -13.8768
evaluation/num steps total     32500
evaluation/num paths total       325
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0658199
evaluation/Rewards Std             0.0420858
evaluation/Rewards Max            -0.0556
evaluation/Rewards Min            -0.970281
evaluation/Returns Mean           -6.58199
evaluation/Returns Std             0.353429
evaluation/Returns Max            -6.38199
evaluation/Returns Min            -7.28683
evaluation/Actions Mean            0.00540902
evaluation/Actions Std             0.0744316
evaluation/Actions Max             0.999957
evaluation/Actions Min            -0.773046
evaluation/Num Paths               5
evaluation/Average Returns        -6.58199
time/data storing (s)              0.0011129
time/evaluation sampling (s)       0.078848
time/exploration sampling (s)      0.0323446
time/logging (s)                   0.00186385
time/saving (s)                    0.00175084
time/training (s)                  0.440399
time/epoch (s)                     0.556319
time/total (s)                    36.8992
Epoch                             64
-----------------------------  ---------------
2019-04-13 16:59:11.148927 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 65 finished
-----------------------------  ---------------
replay_buffer/size             13300
trainer/QF1 Loss                   0.017761
trainer/QF2 Loss                   0.0170926
trainer/Policy Loss                6.84417
trainer/Q1 Predictions Mean       -7.08334
trainer/Q1 Predictions Std         0.52606
trainer/Q1 Predictions Max        -6.75638
trainer/Q1 Predictions Min        -9.0256
trainer/Q2 Predictions Mean       -7.0765
trainer/Q2 Predictions Std         0.509322
trainer/Q2 Predictions Max        -6.75216
trainer/Q2 Predictions Min        -8.94133
trainer/Q Targets Mean            -7.03825
trainer/Q Targets Std              0.542868
trainer/Q Targets Max             -6.62783
trainer/Q Targets Min             -8.8691
trainer/Bellman Errors 1 Mean      0.017761
trainer/Bellman Errors 1 Std       0.0223682
trainer/Bellman Errors 1 Max       0.0971408
trainer/Bellman Errors 1 Min       1.84992e-07
trainer/Bellman Errors 2 Mean      0.0170926
trainer/Bellman Errors 2 Std       0.0218508
trainer/Bellman Errors 2 Max       0.100405
trainer/Bellman Errors 2 Min       2.67621e-05
trainer/Policy Action Mean         0.0063765
trainer/Policy Action Std          0.218162
trainer/Policy Action Max          0.995664
trainer/Policy Action Min         -0.362977
exploration/num steps total    13300
exploration/num paths total      133
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.156539
exploration/Rewards Std            0.0831769
exploration/Rewards Max           -0.00990306
exploration/Rewards Min           -0.455664
exploration/Returns Mean         -15.6539
exploration/Returns Std            1.43211
exploration/Returns Max          -14.2218
exploration/Returns Min          -17.086
exploration/Actions Mean           0.00593048
exploration/Actions Std            0.149874
exploration/Actions Max            0.784504
exploration/Actions Min           -0.377458
exploration/Num Paths              2
exploration/Average Returns      -15.6539
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0735382
evaluation/Rewards Std             0.0117157
evaluation/Rewards Max            -0.0380423
evaluation/Rewards Min            -0.27469
evaluation/Returns Mean           -7.35382
evaluation/Returns Std             0.111435
evaluation/Returns Max            -7.22533
evaluation/Returns Min            -7.51367
evaluation/Actions Mean            0.00503155
evaluation/Actions Std             0.0627168
evaluation/Actions Max             0.986004
evaluation/Actions Min            -0.441312
evaluation/Num Paths               5
evaluation/Average Returns        -7.35382
time/data storing (s)              0.00118295
time/evaluation sampling (s)       0.0740925
time/exploration sampling (s)      0.0317391
time/logging (s)                   0.00247558
time/saving (s)                    0.00252334
time/training (s)                  0.448508
time/epoch (s)                     0.560521
time/total (s)                    37.4636
Epoch                             65
-----------------------------  ---------------
2019-04-13 16:59:11.713220 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size             13500
trainer/QF1 Loss                   0.0460258
trainer/QF2 Loss                   0.0478235
trainer/Policy Loss                6.86712
trainer/Q1 Predictions Mean       -6.972
trainer/Q1 Predictions Std         0.535292
trainer/Q1 Predictions Max        -6.68086
trainer/Q1 Predictions Min        -9.30095
trainer/Q2 Predictions Mean       -6.97544
trainer/Q2 Predictions Std         0.528704
trainer/Q2 Predictions Max        -6.68256
trainer/Q2 Predictions Min        -9.28577
trainer/Q Targets Mean            -7.11534
trainer/Q Targets Std              0.596579
trainer/Q Targets Max             -6.7077
trainer/Q Targets Min             -9.42439
trainer/Bellman Errors 1 Mean      0.0460258
trainer/Bellman Errors 1 Std       0.0833542
trainer/Bellman Errors 1 Max       0.409915
trainer/Bellman Errors 1 Min       0.000309812
trainer/Bellman Errors 2 Mean      0.0478235
trainer/Bellman Errors 2 Std       0.0919474
trainer/Bellman Errors 2 Max       0.46094
trainer/Bellman Errors 2 Min       2.37581e-05
trainer/Policy Action Mean         0.022391
trainer/Policy Action Std          0.202783
trainer/Policy Action Max          0.992404
trainer/Policy Action Min         -0.324303
exploration/num steps total    13500
exploration/num paths total      135
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.145042
exploration/Rewards Std            0.0829182
exploration/Rewards Max           -0.00552273
exploration/Rewards Min           -0.661277
exploration/Returns Mean         -14.5042
exploration/Returns Std            0.471468
exploration/Returns Max          -14.0327
exploration/Returns Min          -14.9756
exploration/Actions Mean           0.00532147
exploration/Actions Std            0.151622
exploration/Actions Max            1
exploration/Actions Min           -0.545318
exploration/Num Paths              2
exploration/Average Returns      -14.5042
evaluation/num steps total     33500
evaluation/num paths total       335
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0688574
evaluation/Rewards Std             0.00853788
evaluation/Rewards Max            -0.0175441
evaluation/Rewards Min            -0.217792
evaluation/Returns Mean           -6.88574
evaluation/Returns Std             0.0904621
evaluation/Returns Max            -6.78371
evaluation/Returns Min            -7.055
evaluation/Actions Mean            0.00242535
evaluation/Actions Std             0.0555402
evaluation/Actions Max             0.968419
evaluation/Actions Min            -0.864286
evaluation/Num Paths               5
evaluation/Average Returns        -6.88574
time/data storing (s)              0.00105723
time/evaluation sampling (s)       0.0740305
time/exploration sampling (s)      0.0325148
time/logging (s)                   0.0024614
time/saving (s)                    0.00226567
time/training (s)                  0.446541
time/epoch (s)                     0.558871
time/total (s)                    38.0263
Epoch                             66
-----------------------------  ---------------
2019-04-13 16:59:12.284509 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size             13700
trainer/QF1 Loss                   0.0276225
trainer/QF2 Loss                   0.0293011
trainer/Policy Loss                6.86831
trainer/Q1 Predictions Mean       -7.14276
trainer/Q1 Predictions Std         0.565148
trainer/Q1 Predictions Max        -6.78577
trainer/Q1 Predictions Min        -9.14656
trainer/Q2 Predictions Mean       -7.1338
trainer/Q2 Predictions Std         0.558128
trainer/Q2 Predictions Max        -6.74119
trainer/Q2 Predictions Min        -9.12879
trainer/Q Targets Mean            -7.25966
trainer/Q Targets Std              0.567251
trainer/Q Targets Max             -6.75832
trainer/Q Targets Min             -9.17361
trainer/Bellman Errors 1 Mean      0.0276225
trainer/Bellman Errors 1 Std       0.0425289
trainer/Bellman Errors 1 Max       0.197379
trainer/Bellman Errors 1 Min       7.31788e-07
trainer/Bellman Errors 2 Mean      0.0293011
trainer/Bellman Errors 2 Std       0.0468994
trainer/Bellman Errors 2 Max       0.24645
trainer/Bellman Errors 2 Min       1.17784e-06
trainer/Policy Action Mean         0.036861
trainer/Policy Action Std          0.269132
trainer/Policy Action Max          0.99505
trainer/Policy Action Min         -0.776746
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.141181
exploration/Rewards Std            0.0826612
exploration/Rewards Max           -0.00988551
exploration/Rewards Min           -0.844076
exploration/Returns Mean         -14.1181
exploration/Returns Std            0.752633
exploration/Returns Max          -13.3655
exploration/Returns Min          -14.8708
exploration/Actions Mean           0.00551235
exploration/Actions Std            0.158583
exploration/Actions Max            1
exploration/Actions Min           -1
exploration/Num Paths              2
exploration/Average Returns      -14.1181
evaluation/num steps total     34000
evaluation/num paths total       340
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.051666
evaluation/Rewards Std             0.00545491
evaluation/Rewards Max            -0.0269665
evaluation/Rewards Min            -0.115026
evaluation/Returns Mean           -5.1666
evaluation/Returns Std             0.0110128
evaluation/Returns Max            -5.1448
evaluation/Returns Min            -5.1744
evaluation/Actions Mean            0.00705279
evaluation/Actions Std             0.0694036
evaluation/Actions Max             0.911591
evaluation/Actions Min            -0.00930279
evaluation/Num Paths               5
evaluation/Average Returns        -5.1666
time/data storing (s)              0.0010967
time/evaluation sampling (s)       0.0755781
time/exploration sampling (s)      0.0313223
time/logging (s)                   0.002495
time/saving (s)                    0.00227978
time/training (s)                  0.453175
time/epoch (s)                     0.565946
time/total (s)                    38.5961
Epoch                             67
-----------------------------  ---------------
2019-04-13 16:59:12.863149 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size             13900
trainer/QF1 Loss                   0.0325753
trainer/QF2 Loss                   0.0344343
trainer/Policy Loss                7.14294
trainer/Q1 Predictions Mean       -7.36439
trainer/Q1 Predictions Std         0.695563
trainer/Q1 Predictions Max        -7.00456
trainer/Q1 Predictions Min        -9.60141
trainer/Q2 Predictions Mean       -7.36396
trainer/Q2 Predictions Std         0.695305
trainer/Q2 Predictions Max        -6.9894
trainer/Q2 Predictions Min        -9.58335
trainer/Q Targets Mean            -7.31736
trainer/Q Targets Std              0.737823
trainer/Q Targets Max             -6.73781
trainer/Q Targets Min             -9.95657
trainer/Bellman Errors 1 Mean      0.0325753
trainer/Bellman Errors 1 Std       0.0431209
trainer/Bellman Errors 1 Max       0.148865
trainer/Bellman Errors 1 Min       1.09448e-05
trainer/Bellman Errors 2 Mean      0.0344343
trainer/Bellman Errors 2 Std       0.0474806
trainer/Bellman Errors 2 Max       0.159124
trainer/Bellman Errors 2 Min       5.9812e-05
trainer/Policy Action Mean         0.0294337
trainer/Policy Action Std          0.261235
trainer/Policy Action Max          0.9966
trainer/Policy Action Min         -0.590288
exploration/num steps total    13900
exploration/num paths total      139
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.130521
exploration/Rewards Std            0.0856112
exploration/Rewards Max           -0.0137566
exploration/Rewards Min           -0.879468
exploration/Returns Mean         -13.0521
exploration/Returns Std            0.31217
exploration/Returns Max          -12.7399
exploration/Returns Min          -13.3642
exploration/Actions Mean           0.0011393
exploration/Actions Std            0.15232
exploration/Actions Max            0.845428
exploration/Actions Min           -1
exploration/Num Paths              2
exploration/Average Returns      -13.0521
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0152744
evaluation/Rewards Std             0.0515971
evaluation/Rewards Max            -0.00774922
evaluation/Rewards Min            -0.892744
evaluation/Returns Mean           -1.52744
evaluation/Returns Std             0.388683
evaluation/Returns Max            -1.15433
evaluation/Returns Min            -2.12226
evaluation/Actions Mean            0.00801795
evaluation/Actions Std             0.0902398
evaluation/Actions Max             0.999965
evaluation/Actions Min            -0.891764
evaluation/Num Paths               5
evaluation/Average Returns        -1.52744
time/data storing (s)              0.00106899
time/evaluation sampling (s)       0.0896387
time/exploration sampling (s)      0.0332707
time/logging (s)                   0.00247168
time/saving (s)                    0.0116309
time/training (s)                  0.434738
time/epoch (s)                     0.572819
time/total (s)                    39.173
Epoch                             68
-----------------------------  ---------------
2019-04-13 16:59:13.431818 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size             14100
trainer/QF1 Loss                   0.0346398
trainer/QF2 Loss                   0.0360854
trainer/Policy Loss                7.04325
trainer/Q1 Predictions Mean       -7.22129
trainer/Q1 Predictions Std         0.560916
trainer/Q1 Predictions Max        -6.92458
trainer/Q1 Predictions Min        -9.53035
trainer/Q2 Predictions Mean       -7.22098
trainer/Q2 Predictions Std         0.551352
trainer/Q2 Predictions Max        -6.90075
trainer/Q2 Predictions Min        -9.5359
trainer/Q Targets Mean            -7.3251
trainer/Q Targets Std              0.624018
trainer/Q Targets Max             -6.87412
trainer/Q Targets Min             -9.66924
trainer/Bellman Errors 1 Mean      0.0346398
trainer/Bellman Errors 1 Std       0.0660771
trainer/Bellman Errors 1 Max       0.273065
trainer/Bellman Errors 1 Min       2.11514e-06
trainer/Bellman Errors 2 Mean      0.0360854
trainer/Bellman Errors 2 Std       0.0708589
trainer/Bellman Errors 2 Max       0.294977
trainer/Bellman Errors 2 Min       1.92575e-05
trainer/Policy Action Mean        -0.00396693
trainer/Policy Action Std          0.237027
trainer/Policy Action Max          0.995297
trainer/Policy Action Min         -0.358845
exploration/num steps total    14100
exploration/num paths total      141
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.124081
exploration/Rewards Std            0.065944
exploration/Rewards Max           -0.00775635
exploration/Rewards Min           -0.357956
exploration/Returns Mean         -12.4081
exploration/Returns Std            0.134909
exploration/Returns Max          -12.2732
exploration/Returns Min          -12.543
exploration/Actions Mean           0.00405231
exploration/Actions Std            0.147635
exploration/Actions Max            0.940805
exploration/Actions Min           -0.903556
exploration/Num Paths              2
exploration/Average Returns      -12.4081
evaluation/num steps total     35000
evaluation/num paths total       350
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0272467
evaluation/Rewards Std             0.0603315
evaluation/Rewards Max            -0.0215742
evaluation/Rewards Min            -0.966007
evaluation/Returns Mean           -2.72467
evaluation/Returns Std             0.274267
evaluation/Returns Max            -2.2754
evaluation/Returns Min            -3.12375
evaluation/Actions Mean            0.00648426
evaluation/Actions Std             0.0930867
evaluation/Actions Max             0.99999
evaluation/Actions Min            -0.843871
evaluation/Num Paths               5
evaluation/Average Returns        -2.72467
time/data storing (s)              0.00160715
time/evaluation sampling (s)       0.0750142
time/exploration sampling (s)      0.0363514
time/logging (s)                   0.00246862
time/saving (s)                    0.00225837
time/training (s)                  0.446827
time/epoch (s)                     0.564527
time/total (s)                    39.7405
Epoch                             69
-----------------------------  ---------------
2019-04-13 16:59:13.996971 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 70 finished
-----------------------------  ---------------
replay_buffer/size             14300
trainer/QF1 Loss                   1.53727
trainer/QF2 Loss                   1.53736
trainer/Policy Loss                7.12754
trainer/Q1 Predictions Mean       -7.28227
trainer/Q1 Predictions Std         0.546326
trainer/Q1 Predictions Max        -7.01321
trainer/Q1 Predictions Min        -9.95922
trainer/Q2 Predictions Mean       -7.28978
trainer/Q2 Predictions Std         0.555236
trainer/Q2 Predictions Max        -7.00365
trainer/Q2 Predictions Min       -10.0196
trainer/Q Targets Mean            -7.16238
trainer/Q Targets Std              1.40426
trainer/Q Targets Max             -0.12657
trainer/Q Targets Min            -10.228
trainer/Bellman Errors 1 Mean      1.53727
trainer/Bellman Errors 1 Std       8.38075
trainer/Bellman Errors 1 Max      48.1988
trainer/Bellman Errors 1 Min       2.56297e-05
trainer/Bellman Errors 2 Mean      1.53736
trainer/Bellman Errors 2 Std       8.39394
trainer/Bellman Errors 2 Max      48.2723
trainer/Bellman Errors 2 Min       1.22382e-08
trainer/Policy Action Mean         0.0343199
trainer/Policy Action Std          0.227141
trainer/Policy Action Max          0.998127
trainer/Policy Action Min         -0.392485
exploration/num steps total    14300
exploration/num paths total      143
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.133107
exploration/Rewards Std            0.0616884
exploration/Rewards Max           -0.00648373
exploration/Rewards Min           -0.335265
exploration/Returns Mean         -13.3107
exploration/Returns Std            0.106911
exploration/Returns Max          -13.2038
exploration/Returns Min          -13.4176
exploration/Actions Mean           0.00632899
exploration/Actions Std            0.144257
exploration/Actions Max            1
exploration/Actions Min           -0.300779
exploration/Num Paths              2
exploration/Average Returns      -13.3107
evaluation/num steps total     35500
evaluation/num paths total       355
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0122124
evaluation/Rewards Std             0.032592
evaluation/Rewards Max            -0.00401018
evaluation/Rewards Min            -0.600443
evaluation/Returns Mean           -1.22124
evaluation/Returns Std             0.221641
evaluation/Returns Max            -0.97672
evaluation/Returns Min            -1.56567
evaluation/Actions Mean            0.00557687
evaluation/Actions Std             0.0751895
evaluation/Actions Max             0.999731
evaluation/Actions Min            -0.913008
evaluation/Num Paths               5
evaluation/Average Returns        -1.22124
time/data storing (s)              0.00108158
time/evaluation sampling (s)       0.0819365
time/exploration sampling (s)      0.0332001
time/logging (s)                   0.00232591
time/saving (s)                    0.00204226
time/training (s)                  0.438756
time/epoch (s)                     0.559342
time/total (s)                    40.304
Epoch                             70
-----------------------------  ---------------
2019-04-13 16:59:14.557141 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size             14500
trainer/QF1 Loss                   0.0378707
trainer/QF2 Loss                   0.0400827
trainer/Policy Loss                7.10806
trainer/Q1 Predictions Mean       -7.33801
trainer/Q1 Predictions Std         0.689175
trainer/Q1 Predictions Max        -6.99899
trainer/Q1 Predictions Min        -9.95389
trainer/Q2 Predictions Mean       -7.33738
trainer/Q2 Predictions Std         0.702156
trainer/Q2 Predictions Max        -6.98424
trainer/Q2 Predictions Min       -10.0316
trainer/Q Targets Mean            -7.45583
trainer/Q Targets Std              0.60176
trainer/Q Targets Max             -6.97761
trainer/Q Targets Min             -9.65391
trainer/Bellman Errors 1 Mean      0.0378707
trainer/Bellman Errors 1 Std       0.0496267
trainer/Bellman Errors 1 Max       0.215556
trainer/Bellman Errors 1 Min       0.000339252
trainer/Bellman Errors 2 Mean      0.0400827
trainer/Bellman Errors 2 Std       0.0509318
trainer/Bellman Errors 2 Max       0.228961
trainer/Bellman Errors 2 Min       0.000280398
trainer/Policy Action Mean         0.0192148
trainer/Policy Action Std          0.222224
trainer/Policy Action Max          0.997126
trainer/Policy Action Min         -0.283531
exploration/num steps total    14500
exploration/num paths total      145
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129799
exploration/Rewards Std            0.081528
exploration/Rewards Max           -0.00456565
exploration/Rewards Min           -0.834484
exploration/Returns Mean         -12.9799
exploration/Returns Std            0.629416
exploration/Returns Max          -12.3505
exploration/Returns Min          -13.6093
exploration/Actions Mean           0.00770293
exploration/Actions Std            0.15218
exploration/Actions Max            1
exploration/Actions Min           -0.33616
exploration/Num Paths              2
exploration/Average Returns      -12.9799
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0180281
evaluation/Rewards Std             0.054874
evaluation/Rewards Max            -0.0100562
evaluation/Rewards Min            -1.00929
evaluation/Returns Mean           -1.80281
evaluation/Returns Std             0.351498
evaluation/Returns Max            -1.4031
evaluation/Returns Min            -2.37428
evaluation/Actions Mean            0.00468149
evaluation/Actions Std             0.0827349
evaluation/Actions Max             0.999987
evaluation/Actions Min            -0.893103
evaluation/Num Paths               5
evaluation/Average Returns        -1.80281
time/data storing (s)              0.00111357
time/evaluation sampling (s)       0.0758408
time/exploration sampling (s)      0.0323417
time/logging (s)                   0.00201629
time/saving (s)                    0.00227916
time/training (s)                  0.440577
time/epoch (s)                     0.554168
time/total (s)                    40.862
Epoch                             71
-----------------------------  ---------------
2019-04-13 16:59:15.116301 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size             14700
trainer/QF1 Loss                   1.63287
trainer/QF2 Loss                   1.62783
trainer/Policy Loss                7.3475
trainer/Q1 Predictions Mean       -7.52247
trainer/Q1 Predictions Std         0.605371
trainer/Q1 Predictions Max        -7.22559
trainer/Q1 Predictions Min        -9.60871
trainer/Q2 Predictions Mean       -7.52509
trainer/Q2 Predictions Std         0.593158
trainer/Q2 Predictions Max        -7.20014
trainer/Q2 Predictions Min        -9.56933
trainer/Q Targets Mean            -7.19924
trainer/Q Targets Std              1.43519
trainer/Q Targets Max             -0.125041
trainer/Q Targets Min             -9.71547
trainer/Bellman Errors 1 Mean      1.63287
trainer/Bellman Errors 1 Std       8.9665
trainer/Bellman Errors 1 Max      51.5561
trainer/Bellman Errors 1 Min       0.00030946
trainer/Bellman Errors 2 Mean      1.62783
trainer/Bellman Errors 2 Std       8.91981
trainer/Bellman Errors 2 Max      51.2911
trainer/Bellman Errors 2 Min       1.09448e-05
trainer/Policy Action Mean         0.039176
trainer/Policy Action Std          0.259381
trainer/Policy Action Max          0.992469
trainer/Policy Action Min         -0.269294
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129839
exploration/Rewards Std            0.0661514
exploration/Rewards Max           -0.0101622
exploration/Rewards Min           -0.409339
exploration/Returns Mean         -12.9839
exploration/Returns Std            0.0965756
exploration/Returns Max          -12.8873
exploration/Returns Min          -13.0805
exploration/Actions Mean           0.00354416
exploration/Actions Std            0.137908
exploration/Actions Max            0.730514
exploration/Actions Min           -0.408402
exploration/Num Paths              2
exploration/Average Returns      -12.9839
evaluation/num steps total     36500
evaluation/num paths total       365
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0243342
evaluation/Rewards Std             0.0118318
evaluation/Rewards Max            -0.0231655
evaluation/Rewards Min            -0.237388
evaluation/Returns Mean           -2.43342
evaluation/Returns Std             0.0795706
evaluation/Returns Max            -2.3586
evaluation/Returns Min            -2.5776
evaluation/Actions Mean            0.00189136
evaluation/Actions Std             0.0633789
evaluation/Actions Max             0.99075
evaluation/Actions Min            -0.931887
evaluation/Num Paths               5
evaluation/Average Returns        -2.43342
time/data storing (s)              0.00109374
time/evaluation sampling (s)       0.0738591
time/exploration sampling (s)      0.0311907
time/logging (s)                   0.00247853
time/saving (s)                    0.00254235
time/training (s)                  0.44302
time/epoch (s)                     0.554184
time/total (s)                    41.4205
Epoch                             72
-----------------------------  ---------------
2019-04-13 16:59:15.681728 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size             14900
trainer/QF1 Loss                   0.0215759
trainer/QF2 Loss                   0.024027
trainer/Policy Loss                7.46552
trainer/Q1 Predictions Mean       -7.81611
trainer/Q1 Predictions Std         1.17953
trainer/Q1 Predictions Max        -7.29538
trainer/Q1 Predictions Min       -12.1814
trainer/Q2 Predictions Mean       -7.81563
trainer/Q2 Predictions Std         1.18765
trainer/Q2 Predictions Max        -7.28321
trainer/Q2 Predictions Min       -12.1893
trainer/Q Targets Mean            -7.74841
trainer/Q Targets Std              1.12371
trainer/Q Targets Max             -7.09575
trainer/Q Targets Min            -11.7312
trainer/Bellman Errors 1 Mean      0.0215759
trainer/Bellman Errors 1 Std       0.051066
trainer/Bellman Errors 1 Max       0.295688
trainer/Bellman Errors 1 Min       9.38831e-05
trainer/Bellman Errors 2 Mean      0.024027
trainer/Bellman Errors 2 Std       0.0530673
trainer/Bellman Errors 2 Max       0.304335
trainer/Bellman Errors 2 Min       3.50117e-05
trainer/Policy Action Mean         0.0424586
trainer/Policy Action Std          0.31493
trainer/Policy Action Max          1
trainer/Policy Action Min         -0.953436
exploration/num steps total    14900
exploration/num paths total      149
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.137115
exploration/Rewards Std            0.0713945
exploration/Rewards Max           -0.0116626
exploration/Rewards Min           -0.349011
exploration/Returns Mean         -13.7115
exploration/Returns Std            0.238458
exploration/Returns Max          -13.4731
exploration/Returns Min          -13.95
exploration/Actions Mean           0.00722491
exploration/Actions Std            0.156501
exploration/Actions Max            1
exploration/Actions Min           -0.366008
exploration/Num Paths              2
exploration/Average Returns      -13.7115
evaluation/num steps total     37000
evaluation/num paths total       370
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0363666
evaluation/Rewards Std             0.0485697
evaluation/Rewards Max            -0.0312516
evaluation/Rewards Min            -0.841484
evaluation/Returns Mean           -3.63666
evaluation/Returns Std             0.30143
evaluation/Returns Max            -3.23569
evaluation/Returns Min            -4.1707
evaluation/Actions Mean            0.00629135
evaluation/Actions Std             0.0797886
evaluation/Actions Max             0.999963
evaluation/Actions Min            -0.372163
evaluation/Num Paths               5
evaluation/Average Returns        -3.63666
time/data storing (s)              0.00110671
time/evaluation sampling (s)       0.0745317
time/exploration sampling (s)      0.0333137
time/logging (s)                   0.00248371
time/saving (s)                    0.0022275
time/training (s)                  0.446031
time/epoch (s)                     0.559695
time/total (s)                    41.9843
Epoch                             73
-----------------------------  ---------------
2019-04-13 16:59:16.253892 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size             15100
trainer/QF1 Loss                   0.0298047
trainer/QF2 Loss                   0.0359509
trainer/Policy Loss                7.43088
trainer/Q1 Predictions Mean       -7.56281
trainer/Q1 Predictions Std         0.428906
trainer/Q1 Predictions Max        -7.2756
trainer/Q1 Predictions Min        -9.21011
trainer/Q2 Predictions Mean       -7.5486
trainer/Q2 Predictions Std         0.425534
trainer/Q2 Predictions Max        -7.24588
trainer/Q2 Predictions Min        -9.23843
trainer/Q Targets Mean            -7.63178
trainer/Q Targets Std              0.414342
trainer/Q Targets Max             -7.24297
trainer/Q Targets Min             -8.92088
trainer/Bellman Errors 1 Mean      0.0298047
trainer/Bellman Errors 1 Std       0.0409931
trainer/Bellman Errors 1 Max       0.18963
trainer/Bellman Errors 1 Min       9.5593e-06
trainer/Bellman Errors 2 Mean      0.0359509
trainer/Bellman Errors 2 Std       0.040426
trainer/Bellman Errors 2 Max       0.181673
trainer/Bellman Errors 2 Min       0.000263385
trainer/Policy Action Mean        -0.05341
trainer/Policy Action Std          0.264224
trainer/Policy Action Max          0.998894
trainer/Policy Action Min         -0.9338
exploration/num steps total    15100
exploration/num paths total      151
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.145322
exploration/Rewards Std            0.0797274
exploration/Rewards Max           -0.0163993
exploration/Rewards Min           -0.78071
exploration/Returns Mean         -14.5322
exploration/Returns Std            0.85749
exploration/Returns Max          -13.6747
exploration/Returns Min          -15.3897
exploration/Actions Mean           0.00726242
exploration/Actions Std            0.156283
exploration/Actions Max            1
exploration/Actions Min           -0.33775
exploration/Num Paths              2
exploration/Average Returns      -14.5322
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0610045
evaluation/Rewards Std             0.0425864
evaluation/Rewards Max            -0.0564298
evaluation/Rewards Min            -0.720226
evaluation/Returns Mean           -6.10045
evaluation/Returns Std             0.223251
evaluation/Returns Max            -5.82548
evaluation/Returns Min            -6.4027
evaluation/Actions Mean            0.00361289
evaluation/Actions Std             0.0890768
evaluation/Actions Max             0.999924
evaluation/Actions Min            -0.894634
evaluation/Num Paths               5
evaluation/Average Returns        -6.10045
time/data storing (s)              0.00110819
time/evaluation sampling (s)       0.0782201
time/exploration sampling (s)      0.032483
time/logging (s)                   0.00248324
time/saving (s)                    0.00225161
time/training (s)                  0.449874
time/epoch (s)                     0.56642
time/total (s)                    42.5548
Epoch                             74
-----------------------------  ---------------
2019-04-13 16:59:16.803228 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size             15300
trainer/QF1 Loss                   0.0483847
trainer/QF2 Loss                   0.0470079
trainer/Policy Loss                7.34964
trainer/Q1 Predictions Mean       -7.60169
trainer/Q1 Predictions Std         0.505711
trainer/Q1 Predictions Max        -7.26039
trainer/Q1 Predictions Min        -9.55226
trainer/Q2 Predictions Mean       -7.61021
trainer/Q2 Predictions Std         0.503665
trainer/Q2 Predictions Max        -7.26267
trainer/Q2 Predictions Min        -9.57546
trainer/Q Targets Mean            -7.71071
trainer/Q Targets Std              0.527904
trainer/Q Targets Max             -7.21496
trainer/Q Targets Min             -9.80252
trainer/Bellman Errors 1 Mean      0.0483847
trainer/Bellman Errors 1 Std       0.0844937
trainer/Bellman Errors 1 Max       0.340353
trainer/Bellman Errors 1 Min       4.38424e-05
trainer/Bellman Errors 2 Mean      0.0470079
trainer/Bellman Errors 2 Std       0.0813253
trainer/Bellman Errors 2 Max       0.320428
trainer/Bellman Errors 2 Min       1.41976e-05
trainer/Policy Action Mean        -0.0150134
trainer/Policy Action Std          0.205985
trainer/Policy Action Max          0.995723
trainer/Policy Action Min         -0.318717
exploration/num steps total    15300
exploration/num paths total      153
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.142583
exploration/Rewards Std            0.0799863
exploration/Rewards Max           -0.00969265
exploration/Rewards Min           -0.738348
exploration/Returns Mean         -14.2583
exploration/Returns Std            0.166902
exploration/Returns Max          -14.0914
exploration/Returns Min          -14.4252
exploration/Actions Mean           0.00355303
exploration/Actions Std            0.160846
exploration/Actions Max            1
exploration/Actions Min           -0.953912
exploration/Num Paths              2
exploration/Average Returns      -14.2583
evaluation/num steps total     38000
evaluation/num paths total       380
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0532146
evaluation/Rewards Std             0.0370532
evaluation/Rewards Max            -0.0366111
evaluation/Rewards Min            -0.861105
evaluation/Returns Mean           -5.32146
evaluation/Returns Std             0.295588
evaluation/Returns Max            -5.07244
evaluation/Returns Min            -5.90136
evaluation/Actions Mean            0.00416635
evaluation/Actions Std             0.0704319
evaluation/Actions Max             0.999968
evaluation/Actions Min            -0.88106
evaluation/Num Paths               5
evaluation/Average Returns        -5.32146
time/data storing (s)              0.0011214
time/evaluation sampling (s)       0.0731155
time/exploration sampling (s)      0.0339784
time/logging (s)                   0.00247972
time/saving (s)                    0.00223619
time/training (s)                  0.430693
time/epoch (s)                     0.543624
time/total (s)                    43.1025
Epoch                             75
-----------------------------  ---------------
2019-04-13 16:59:17.370146 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size             15500
trainer/QF1 Loss                   0.0312079
trainer/QF2 Loss                   0.0352733
trainer/Policy Loss                7.50092
trainer/Q1 Predictions Mean       -7.61149
trainer/Q1 Predictions Std         0.302713
trainer/Q1 Predictions Max        -7.39876
trainer/Q1 Predictions Min        -8.56106
trainer/Q2 Predictions Mean       -7.61008
trainer/Q2 Predictions Std         0.298338
trainer/Q2 Predictions Max        -7.38728
trainer/Q2 Predictions Min        -8.59211
trainer/Q Targets Mean            -7.64137
trainer/Q Targets Std              0.383508
trainer/Q Targets Max             -7.24832
trainer/Q Targets Min             -8.74139
trainer/Bellman Errors 1 Mean      0.0312079
trainer/Bellman Errors 1 Std       0.0603162
trainer/Bellman Errors 1 Max       0.340297
trainer/Bellman Errors 1 Min       3.65437e-06
trainer/Bellman Errors 2 Mean      0.0352733
trainer/Bellman Errors 2 Std       0.0725239
trainer/Bellman Errors 2 Max       0.407497
trainer/Bellman Errors 2 Min       3.82195e-05
trainer/Policy Action Mean         0.00155112
trainer/Policy Action Std          0.159497
trainer/Policy Action Max          0.412412
trainer/Policy Action Min         -0.638433
exploration/num steps total    15500
exploration/num paths total      155
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129555
exploration/Rewards Std            0.063524
exploration/Rewards Max           -0.00902364
exploration/Rewards Min           -0.297675
exploration/Returns Mean         -12.9555
exploration/Returns Std            0.399023
exploration/Returns Max          -12.5565
exploration/Returns Min          -13.3545
exploration/Actions Mean           0.00198662
exploration/Actions Std            0.132202
exploration/Actions Max            0.465151
exploration/Actions Min           -0.366914
exploration/Num Paths              2
exploration/Average Returns      -12.9555
evaluation/num steps total     38500
evaluation/num paths total       385
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0262425
evaluation/Rewards Std             0.0535113
evaluation/Rewards Max            -0.0114956
evaluation/Rewards Min            -0.936182
evaluation/Returns Mean           -2.62425
evaluation/Returns Std             0.419961
evaluation/Returns Max            -2.22527
evaluation/Returns Min            -3.16414
evaluation/Actions Mean            0.00440819
evaluation/Actions Std             0.0713152
evaluation/Actions Max             0.999994
evaluation/Actions Min            -0.755228
evaluation/Num Paths               5
evaluation/Average Returns        -2.62425
time/data storing (s)              0.00113552
time/evaluation sampling (s)       0.0754751
time/exploration sampling (s)      0.0330779
time/logging (s)                   0.00247148
time/saving (s)                    0.00221853
time/training (s)                  0.446855
time/epoch (s)                     0.561233
time/total (s)                    43.6678
Epoch                             76
-----------------------------  ---------------
2019-04-13 16:59:17.932771 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size             15700
trainer/QF1 Loss                   0.0269429
trainer/QF2 Loss                   0.0260733
trainer/Policy Loss                7.65671
trainer/Q1 Predictions Mean       -8.00906
trainer/Q1 Predictions Std         0.936523
trainer/Q1 Predictions Max        -7.3994
trainer/Q1 Predictions Min       -10.3778
trainer/Q2 Predictions Mean       -8.01894
trainer/Q2 Predictions Std         0.951389
trainer/Q2 Predictions Max        -7.39152
trainer/Q2 Predictions Min       -10.4773
trainer/Q Targets Mean            -8.0634
trainer/Q Targets Std              0.924189
trainer/Q Targets Max             -7.33169
trainer/Q Targets Min            -10.5703
trainer/Bellman Errors 1 Mean      0.0269429
trainer/Bellman Errors 1 Std       0.0436563
trainer/Bellman Errors 1 Max       0.197524
trainer/Bellman Errors 1 Min       1.97872e-08
trainer/Bellman Errors 2 Mean      0.0260733
trainer/Bellman Errors 2 Std       0.0381071
trainer/Bellman Errors 2 Max       0.152325
trainer/Bellman Errors 2 Min       7.49925e-06
trainer/Policy Action Mean         0.0839177
trainer/Policy Action Std          0.34667
trainer/Policy Action Max          0.997899
trainer/Policy Action Min         -0.991102
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.13011
exploration/Rewards Std            0.0642139
exploration/Rewards Max           -0.0179934
exploration/Rewards Min           -0.352386
exploration/Returns Mean         -13.011
exploration/Returns Std            0.474127
exploration/Returns Max          -12.5369
exploration/Returns Min          -13.4851
exploration/Actions Mean          -0.00122714
exploration/Actions Std            0.13446
exploration/Actions Max            0.337077
exploration/Actions Min           -0.869549
exploration/Num Paths              2
exploration/Average Returns      -13.011
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0318384
evaluation/Rewards Std             0.0178831
evaluation/Rewards Max            -0.0259495
evaluation/Rewards Min            -0.419415
evaluation/Returns Mean           -3.18384
evaluation/Returns Std             0.160431
evaluation/Returns Max            -3.06714
evaluation/Returns Min            -3.49899
evaluation/Actions Mean            0.00382185
evaluation/Actions Std             0.0564006
evaluation/Actions Max             0.999073
evaluation/Actions Min            -0.400488
evaluation/Num Paths               5
evaluation/Average Returns        -3.18384
time/data storing (s)              0.00107386
time/evaluation sampling (s)       0.0747471
time/exploration sampling (s)      0.0316891
time/logging (s)                   0.00188204
time/saving (s)                    0.00178123
time/training (s)                  0.445131
time/epoch (s)                     0.556305
time/total (s)                    44.2282
Epoch                             77
-----------------------------  ---------------
2019-04-13 16:59:18.500181 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size             15900
trainer/QF1 Loss                   3.55517
trainer/QF2 Loss                   3.57641
trainer/Policy Loss                7.54139
trainer/Q1 Predictions Mean       -7.75453
trainer/Q1 Predictions Std         0.449236
trainer/Q1 Predictions Max        -7.50767
trainer/Q1 Predictions Min       -10.11
trainer/Q2 Predictions Mean       -7.75433
trainer/Q2 Predictions Std         0.451256
trainer/Q2 Predictions Max        -7.53175
trainer/Q2 Predictions Min       -10.1166
trainer/Q Targets Mean            -7.26991
trainer/Q Targets Std              1.89398
trainer/Q Targets Max             -0.158573
trainer/Q Targets Min            -10.0551
trainer/Bellman Errors 1 Mean      3.55517
trainer/Bellman Errors 1 Std      13.6369
trainer/Bellman Errors 1 Max      57.3612
trainer/Bellman Errors 1 Min       3.97377e-07
trainer/Bellman Errors 2 Mean      3.57641
trainer/Bellman Errors 2 Std      13.7108
trainer/Bellman Errors 2 Max      57.5327
trainer/Bellman Errors 2 Min       5.78942e-06
trainer/Policy Action Mean         0.0507119
trainer/Policy Action Std          0.170524
trainer/Policy Action Max          0.997072
trainer/Policy Action Min         -0.299835
exploration/num steps total    15900
exploration/num paths total      159
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.150855
exploration/Rewards Std            0.0723373
exploration/Rewards Max           -0.0176463
exploration/Rewards Min           -0.395325
exploration/Returns Mean         -15.0855
exploration/Returns Std            0.635976
exploration/Returns Max          -14.4495
exploration/Returns Min          -15.7215
exploration/Actions Mean           0.00125071
exploration/Actions Std            0.1423
exploration/Actions Max            0.810192
exploration/Actions Min           -0.620981
exploration/Num Paths              2
exploration/Average Returns      -15.0855
evaluation/num steps total     39500
evaluation/num paths total       395
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0879039
evaluation/Rewards Std             0.0297452
evaluation/Rewards Max            -0.0607239
evaluation/Rewards Min            -0.736481
evaluation/Returns Mean           -8.79039
evaluation/Returns Std             0.274924
evaluation/Returns Max            -8.58559
evaluation/Returns Min            -9.32073
evaluation/Actions Mean            0.00267479
evaluation/Actions Std             0.0789785
evaluation/Actions Max             0.999964
evaluation/Actions Min            -0.918926
evaluation/Num Paths               5
evaluation/Average Returns        -8.79039
time/data storing (s)              0.00106989
time/evaluation sampling (s)       0.0806196
time/exploration sampling (s)      0.0356162
time/logging (s)                   0.00247132
time/saving (s)                    0.00227825
time/training (s)                  0.440604
time/epoch (s)                     0.562659
time/total (s)                    44.7947
Epoch                             78
-----------------------------  ---------------
2019-04-13 16:59:19.080985 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size             16100
trainer/QF1 Loss                   1.85364
trainer/QF2 Loss                   1.80587
trainer/Policy Loss                7.6921
trainer/Q1 Predictions Mean       -7.80247
trainer/Q1 Predictions Std         0.249273
trainer/Q1 Predictions Max        -7.59188
trainer/Q1 Predictions Min        -8.86243
trainer/Q2 Predictions Mean       -7.79742
trainer/Q2 Predictions Std         0.244923
trainer/Q2 Predictions Max        -7.64446
trainer/Q2 Predictions Min        -8.82443
trainer/Q Targets Mean            -7.54069
trainer/Q Targets Std              1.34487
trainer/Q Targets Max             -0.204515
trainer/Q Targets Min             -8.73253
trainer/Bellman Errors 1 Mean      1.85364
trainer/Bellman Errors 1 Std      10.2045
trainer/Bellman Errors 1 Max      58.6694
trainer/Bellman Errors 1 Min       1.41545e-07
trainer/Bellman Errors 2 Mean      1.80587
trainer/Bellman Errors 2 Std       9.95141
trainer/Bellman Errors 2 Max      57.2127
trainer/Bellman Errors 2 Min       9.96753e-06
trainer/Policy Action Mean        -0.00221547
trainer/Policy Action Std          0.129339
trainer/Policy Action Max          0.417733
trainer/Policy Action Min         -0.329221
exploration/num steps total    16100
exploration/num paths total      161
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131939
exploration/Rewards Std            0.0664888
exploration/Rewards Max           -0.0135397
exploration/Rewards Min           -0.301607
exploration/Returns Mean         -13.1939
exploration/Returns Std            1.10424
exploration/Returns Max          -12.0896
exploration/Returns Min          -14.2981
exploration/Actions Mean           0.00556552
exploration/Actions Std            0.142081
exploration/Actions Max            0.816094
exploration/Actions Min           -0.31448
exploration/Num Paths              2
exploration/Average Returns      -13.1939
evaluation/num steps total     40000
evaluation/num paths total       400
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0387929
evaluation/Rewards Std             0.0280344
evaluation/Rewards Max            -0.0366449
evaluation/Rewards Min            -0.631098
evaluation/Returns Mean           -3.87929
evaluation/Returns Std             0.22028
evaluation/Returns Max            -3.72415
evaluation/Returns Min            -4.29669
evaluation/Actions Mean            0.00521349
evaluation/Actions Std             0.0780402
evaluation/Actions Max             0.999886
evaluation/Actions Min            -0.878231
evaluation/Num Paths               5
evaluation/Average Returns        -3.87929
time/data storing (s)              0.001177
time/evaluation sampling (s)       0.0787044
time/exploration sampling (s)      0.0324683
time/logging (s)                   0.00249831
time/saving (s)                    0.00222998
time/training (s)                  0.455372
time/epoch (s)                     0.57245
time/total (s)                    45.3738
Epoch                             79
-----------------------------  ---------------
2019-04-13 16:59:19.658396 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size             16300
trainer/QF1 Loss                   0.145764
trainer/QF2 Loss                   0.147356
trainer/Policy Loss                7.35313
trainer/Q1 Predictions Mean       -7.45127
trainer/Q1 Predictions Std         0.233491
trainer/Q1 Predictions Max        -7.27156
trainer/Q1 Predictions Min        -8.40435
trainer/Q2 Predictions Mean       -7.45372
trainer/Q2 Predictions Std         0.234046
trainer/Q2 Predictions Max        -7.27169
trainer/Q2 Predictions Min        -8.42665
trainer/Q Targets Mean            -7.7992
trainer/Q Targets Std              0.285669
trainer/Q Targets Max             -7.43931
trainer/Q Targets Min             -8.64142
trainer/Bellman Errors 1 Mean      0.145764
trainer/Bellman Errors 1 Std       0.127621
trainer/Bellman Errors 1 Max       0.55483
trainer/Bellman Errors 1 Min       0.000919515
trainer/Bellman Errors 2 Mean      0.147356
trainer/Bellman Errors 2 Std       0.133527
trainer/Bellman Errors 2 Max       0.560533
trainer/Bellman Errors 2 Min       0.000115579
trainer/Policy Action Mean         0.016423
trainer/Policy Action Std          0.188971
trainer/Policy Action Max          0.97872
trainer/Policy Action Min         -0.344863
exploration/num steps total    16300
exploration/num paths total      163
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132155
exploration/Rewards Std            0.0708981
exploration/Rewards Max           -0.0116055
exploration/Rewards Min           -0.39036
exploration/Returns Mean         -13.2155
exploration/Returns Std            0.435082
exploration/Returns Max          -12.7804
exploration/Returns Min          -13.6506
exploration/Actions Mean           0.00125759
exploration/Actions Std            0.135532
exploration/Actions Max            0.500387
exploration/Actions Min           -0.777985
exploration/Num Paths              2
exploration/Average Returns      -13.2155
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0377989
evaluation/Rewards Std             0.0169901
evaluation/Rewards Max            -0.0142107
evaluation/Rewards Min            -0.381498
evaluation/Returns Mean           -3.77989
evaluation/Returns Std             0.163526
evaluation/Returns Max            -3.63782
evaluation/Returns Min            -4.0902
evaluation/Actions Mean            0.00288361
evaluation/Actions Std             0.0716033
evaluation/Actions Max             0.998628
evaluation/Actions Min            -0.835728
evaluation/Num Paths               5
evaluation/Average Returns        -3.77989
time/data storing (s)              0.00116711
time/evaluation sampling (s)       0.0772552
time/exploration sampling (s)      0.0344551
time/logging (s)                   0.00191476
time/saving (s)                    0.00223254
time/training (s)                  0.454233
time/epoch (s)                     0.571258
time/total (s)                    45.9489
Epoch                             80
-----------------------------  ---------------
2019-04-13 16:59:20.235072 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size             16500
trainer/QF1 Loss                   0.0221151
trainer/QF2 Loss                   0.025156
trainer/Policy Loss                7.69609
trainer/Q1 Predictions Mean       -7.94439
trainer/Q1 Predictions Std         0.565295
trainer/Q1 Predictions Max        -7.64219
trainer/Q1 Predictions Min       -10.2217
trainer/Q2 Predictions Mean       -7.94804
trainer/Q2 Predictions Std         0.576057
trainer/Q2 Predictions Max        -7.61725
trainer/Q2 Predictions Min       -10.3008
trainer/Q Targets Mean            -8.01322
trainer/Q Targets Std              0.600714
trainer/Q Targets Max             -7.56469
trainer/Q Targets Min            -10.3675
trainer/Bellman Errors 1 Mean      0.0221151
trainer/Bellman Errors 1 Std       0.0310834
trainer/Bellman Errors 1 Max       0.109825
trainer/Bellman Errors 1 Min       1.54296e-06
trainer/Bellman Errors 2 Mean      0.025156
trainer/Bellman Errors 2 Std       0.037592
trainer/Bellman Errors 2 Max       0.141985
trainer/Bellman Errors 2 Min       9.09495e-11
trainer/Policy Action Mean         0.00208084
trainer/Policy Action Std          0.225003
trainer/Policy Action Max          0.99651
trainer/Policy Action Min         -0.474803
exploration/num steps total    16500
exploration/num paths total      165
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.123454
exploration/Rewards Std            0.0737937
exploration/Rewards Max           -0.00325501
exploration/Rewards Min           -0.555243
exploration/Returns Mean         -12.3454
exploration/Returns Std            0.0368714
exploration/Returns Max          -12.3085
exploration/Returns Min          -12.3823
exploration/Actions Mean           0.00774342
exploration/Actions Std            0.144714
exploration/Actions Max            0.969421
exploration/Actions Min           -0.421506
exploration/Num Paths              2
exploration/Average Returns      -12.3454
evaluation/num steps total     41000
evaluation/num paths total       410
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0276804
evaluation/Rewards Std             0.0162447
evaluation/Rewards Max            -0.0261219
evaluation/Rewards Min            -0.275094
evaluation/Returns Mean           -2.76804
evaluation/Returns Std             0.095532
evaluation/Returns Max            -2.66204
evaluation/Returns Min            -2.89178
evaluation/Actions Mean            0.0060501
evaluation/Actions Std             0.0660039
evaluation/Actions Max             0.997127
evaluation/Actions Min            -0.012786
evaluation/Num Paths               5
evaluation/Average Returns        -2.76804
time/data storing (s)              0.0011235
time/evaluation sampling (s)       0.0768004
time/exploration sampling (s)      0.0333872
time/logging (s)                   0.00245983
time/saving (s)                    0.00230404
time/training (s)                  0.455725
time/epoch (s)                     0.571799
time/total (s)                    46.5245
Epoch                             81
-----------------------------  ---------------
2019-04-13 16:59:20.785234 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size             16700
trainer/QF1 Loss                   0.0252877
trainer/QF2 Loss                   0.0254308
trainer/Policy Loss                7.8173
trainer/Q1 Predictions Mean       -8.18496
trainer/Q1 Predictions Std         1.05784
trainer/Q1 Predictions Max        -7.66766
trainer/Q1 Predictions Min       -12.8047
trainer/Q2 Predictions Mean       -8.18556
trainer/Q2 Predictions Std         1.04755
trainer/Q2 Predictions Max        -7.68646
trainer/Q2 Predictions Min       -12.7766
trainer/Q Targets Mean            -8.18742
trainer/Q Targets Std              0.958762
trainer/Q Targets Max             -7.57595
trainer/Q Targets Min            -12.3467
trainer/Bellman Errors 1 Mean      0.0252877
trainer/Bellman Errors 1 Std       0.0453219
trainer/Bellman Errors 1 Max       0.209755
trainer/Bellman Errors 1 Min       0.000149968
trainer/Bellman Errors 2 Mean      0.0254308
trainer/Bellman Errors 2 Std       0.0417213
trainer/Bellman Errors 2 Max       0.184821
trainer/Bellman Errors 2 Min       0.000240385
trainer/Policy Action Mean         0.0211066
trainer/Policy Action Std          0.30573
trainer/Policy Action Max          1
trainer/Policy Action Min         -0.99489
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.127208
exploration/Rewards Std            0.0727198
exploration/Rewards Max           -0.0132856
exploration/Rewards Min           -0.396166
exploration/Returns Mean         -12.7208
exploration/Returns Std            0.244189
exploration/Returns Max          -12.4766
exploration/Returns Min          -12.965
exploration/Actions Mean           0.00445452
exploration/Actions Std            0.125486
exploration/Actions Max            0.581477
exploration/Actions Min           -0.355013
exploration/Num Paths              2
exploration/Average Returns      -12.7208
evaluation/num steps total     41500
evaluation/num paths total       415
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0287146
evaluation/Rewards Std             0.0247352
evaluation/Rewards Max            -0.013148
evaluation/Rewards Min            -0.519634
evaluation/Returns Mean           -2.87146
evaluation/Returns Std             0.159881
evaluation/Returns Max            -2.77571
evaluation/Returns Min            -3.19054
evaluation/Actions Mean            0.00294166
evaluation/Actions Std             0.0694741
evaluation/Actions Max             0.999791
evaluation/Actions Min            -0.859356
evaluation/Num Paths               5
evaluation/Average Returns        -2.87146
time/data storing (s)              0.00122243
time/evaluation sampling (s)       0.0738966
time/exploration sampling (s)      0.0333786
time/logging (s)                   0.00240154
time/saving (s)                    0.00180176
time/training (s)                  0.431842
time/epoch (s)                     0.544543
time/total (s)                    47.0728
Epoch                             82
-----------------------------  ---------------
2019-04-13 16:59:21.380260 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size             16900
trainer/QF1 Loss                   0.0270396
trainer/QF2 Loss                   0.0276536
trainer/Policy Loss                7.80142
trainer/Q1 Predictions Mean       -7.98042
trainer/Q1 Predictions Std         0.71125
trainer/Q1 Predictions Max        -7.68476
trainer/Q1 Predictions Min       -10.8267
trainer/Q2 Predictions Mean       -7.98594
trainer/Q2 Predictions Std         0.718041
trainer/Q2 Predictions Max        -7.70287
trainer/Q2 Predictions Min       -10.8928
trainer/Q Targets Mean            -8.06951
trainer/Q Targets Std              0.678421
trainer/Q Targets Max             -7.6013
trainer/Q Targets Min            -10.757
trainer/Bellman Errors 1 Mean      0.0270396
trainer/Bellman Errors 1 Std       0.0516551
trainer/Bellman Errors 1 Max       0.28936
trainer/Bellman Errors 1 Min       1.43345e-07
trainer/Bellman Errors 2 Mean      0.0276536
trainer/Bellman Errors 2 Std       0.0525128
trainer/Bellman Errors 2 Max       0.29484
trainer/Bellman Errors 2 Min       6.4434e-05
trainer/Policy Action Mean         0.0242801
trainer/Policy Action Std          0.229996
trainer/Policy Action Max          0.997691
trainer/Policy Action Min         -0.367083
exploration/num steps total    16900
exploration/num paths total      169
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.141755
exploration/Rewards Std            0.0834175
exploration/Rewards Max           -0.0139672
exploration/Rewards Min           -0.758411
exploration/Returns Mean         -14.1755
exploration/Returns Std            1.09377
exploration/Returns Max          -13.0817
exploration/Returns Min          -15.2693
exploration/Actions Mean           0.00384614
exploration/Actions Std            0.149468
exploration/Actions Max            0.954696
exploration/Actions Min           -0.390919
exploration/Num Paths              2
exploration/Average Returns      -14.1755
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0430808
evaluation/Rewards Std             0.0508914
evaluation/Rewards Max            -0.0377754
evaluation/Rewards Min            -0.858038
evaluation/Returns Mean           -4.30808
evaluation/Returns Std             0.319458
evaluation/Returns Max            -3.92521
evaluation/Returns Min            -4.76001
evaluation/Actions Mean            0.006052
evaluation/Actions Std             0.0786302
evaluation/Actions Max             0.999988
evaluation/Actions Min            -0.617412
evaluation/Num Paths               5
evaluation/Average Returns        -4.30808
time/data storing (s)              0.00107668
time/evaluation sampling (s)       0.0750973
time/exploration sampling (s)      0.0322814
time/logging (s)                   0.00246557
time/saving (s)                    0.00244172
time/training (s)                  0.476156
time/epoch (s)                     0.589519
time/total (s)                    47.6663
Epoch                             83
-----------------------------  ---------------
2019-04-13 16:59:21.947267 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 84 finished
-----------------------------  --------------
replay_buffer/size             17100
trainer/QF1 Loss                   0.066187
trainer/QF2 Loss                   0.0658274
trainer/Policy Loss                7.73839
trainer/Q1 Predictions Mean       -7.95403
trainer/Q1 Predictions Std         0.536846
trainer/Q1 Predictions Max        -7.65284
trainer/Q1 Predictions Min       -10.4581
trainer/Q2 Predictions Mean       -7.95207
trainer/Q2 Predictions Std         0.537893
trainer/Q2 Predictions Max        -7.64938
trainer/Q2 Predictions Min       -10.4443
trainer/Q Targets Mean            -8.16241
trainer/Q Targets Std              0.542
trainer/Q Targets Max             -7.73742
trainer/Q Targets Min            -10.5206
trainer/Bellman Errors 1 Mean      0.066187
trainer/Bellman Errors 1 Std       0.085196
trainer/Bellman Errors 1 Max       0.344978
trainer/Bellman Errors 1 Min       0.00143204
trainer/Bellman Errors 2 Mean      0.0658274
trainer/Bellman Errors 2 Std       0.0809234
trainer/Bellman Errors 2 Max       0.313668
trainer/Bellman Errors 2 Min       0.00263302
trainer/Policy Action Mean         0.0377291
trainer/Policy Action Std          0.198966
trainer/Policy Action Max          0.997027
trainer/Policy Action Min         -0.399316
exploration/num steps total    17100
exploration/num paths total      171
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.144207
exploration/Rewards Std            0.0749499
exploration/Rewards Max           -0.0136167
exploration/Rewards Min           -0.496542
exploration/Returns Mean         -14.4207
exploration/Returns Std            0.0897467
exploration/Returns Max          -14.331
exploration/Returns Min          -14.5105
exploration/Actions Mean           0.00511712
exploration/Actions Std            0.146276
exploration/Actions Max            0.925196
exploration/Actions Min           -0.379704
exploration/Num Paths              2
exploration/Average Returns      -14.4207
evaluation/num steps total     42500
evaluation/num paths total       425
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0791308
evaluation/Rewards Std             0.0529861
evaluation/Rewards Max            -0.0613585
evaluation/Rewards Min            -0.988579
evaluation/Returns Mean           -7.91308
evaluation/Returns Std             0.348007
evaluation/Returns Max            -7.42324
evaluation/Returns Min            -8.47092
evaluation/Actions Mean            0.00543241
evaluation/Actions Std             0.0813121
evaluation/Actions Max             0.999997
evaluation/Actions Min            -0.594241
evaluation/Num Paths               5
evaluation/Average Returns        -7.91308
time/data storing (s)              0.00108765
time/evaluation sampling (s)       0.0726902
time/exploration sampling (s)      0.0377398
time/logging (s)                   0.00244857
time/saving (s)                    0.00180325
time/training (s)                  0.445585
time/epoch (s)                     0.561354
time/total (s)                    48.2314
Epoch                             84
-----------------------------  --------------
2019-04-13 16:59:22.507238 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size             17300
trainer/QF1 Loss                   0.0328996
trainer/QF2 Loss                   0.0343382
trainer/Policy Loss                7.81921
trainer/Q1 Predictions Mean       -8.07969
trainer/Q1 Predictions Std         0.693552
trainer/Q1 Predictions Max        -7.71615
trainer/Q1 Predictions Min       -10.77
trainer/Q2 Predictions Mean       -8.07448
trainer/Q2 Predictions Std         0.692828
trainer/Q2 Predictions Max        -7.72306
trainer/Q2 Predictions Min       -10.7739
trainer/Q Targets Mean            -8.21866
trainer/Q Targets Std              0.701301
trainer/Q Targets Max             -7.73411
trainer/Q Targets Min            -11.0278
trainer/Bellman Errors 1 Mean      0.0328996
trainer/Bellman Errors 1 Std       0.039284
trainer/Bellman Errors 1 Max       0.132931
trainer/Bellman Errors 1 Min       3.16343e-06
trainer/Bellman Errors 2 Mean      0.0343382
trainer/Bellman Errors 2 Std       0.0394126
trainer/Bellman Errors 2 Max       0.135732
trainer/Bellman Errors 2 Min       0.00016326
trainer/Policy Action Mean         0.0747648
trainer/Policy Action Std          0.268487
trainer/Policy Action Max          0.997672
trainer/Policy Action Min         -0.348574
exploration/num steps total    17300
exploration/num paths total      173
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.136005
exploration/Rewards Std            0.071957
exploration/Rewards Max           -0.00599335
exploration/Rewards Min           -0.355354
exploration/Returns Mean         -13.6005
exploration/Returns Std            0.0264978
exploration/Returns Max          -13.574
exploration/Returns Min          -13.627
exploration/Actions Mean           0.0018488
exploration/Actions Std            0.144202
exploration/Actions Max            0.841525
exploration/Actions Min           -0.889422
exploration/Num Paths              2
exploration/Average Returns      -13.6005
evaluation/num steps total     43000
evaluation/num paths total       430
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0512544
evaluation/Rewards Std             0.00679915
evaluation/Rewards Max            -0.0396522
evaluation/Rewards Min            -0.181584
evaluation/Returns Mean           -5.12544
evaluation/Returns Std             0.0446248
evaluation/Returns Max            -5.08882
evaluation/Returns Min            -5.21102
evaluation/Actions Mean            0.0059436
evaluation/Actions Std             0.0630372
evaluation/Actions Max             0.980307
evaluation/Actions Min            -0.0809218
evaluation/Num Paths               5
evaluation/Average Returns        -5.12544
time/data storing (s)              0.00106472
time/evaluation sampling (s)       0.0831125
time/exploration sampling (s)      0.0333326
time/logging (s)                   0.00198642
time/saving (s)                    0.00196125
time/training (s)                  0.432484
time/epoch (s)                     0.553941
time/total (s)                    48.7892
Epoch                             85
-----------------------------  ---------------
2019-04-13 16:59:23.087721 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size             17500
trainer/QF1 Loss                   3.92701
trainer/QF2 Loss                   3.92848
trainer/Policy Loss                7.98431
trainer/Q1 Predictions Mean       -8.21984
trainer/Q1 Predictions Std         0.536158
trainer/Q1 Predictions Max        -7.9328
trainer/Q1 Predictions Min       -10.6563
trainer/Q2 Predictions Mean       -8.2215
trainer/Q2 Predictions Std         0.538937
trainer/Q2 Predictions Max        -7.92824
trainer/Q2 Predictions Min       -10.6648
trainer/Q Targets Mean            -7.74023
trainer/Q Targets Std              2.06972
trainer/Q Targets Max             -0.0584675
trainer/Q Targets Min            -10.8388
trainer/Bellman Errors 1 Mean      3.92701
trainer/Bellman Errors 1 Std      15.0938
trainer/Bellman Errors 1 Max      62.591
trainer/Bellman Errors 1 Min       3.36539e-05
trainer/Bellman Errors 2 Mean      3.92848
trainer/Bellman Errors 2 Std      15.0969
trainer/Bellman Errors 2 Max      62.7888
trainer/Bellman Errors 2 Min       1.53941e-06
trainer/Policy Action Mean         0.0197765
trainer/Policy Action Std          0.218252
trainer/Policy Action Max          0.997729
trainer/Policy Action Min         -0.359598
exploration/num steps total    17500
exploration/num paths total      175
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.144064
exploration/Rewards Std            0.0745606
exploration/Rewards Max           -0.0100443
exploration/Rewards Min           -0.407177
exploration/Returns Mean         -14.4064
exploration/Returns Std            0.0558472
exploration/Returns Max          -14.3506
exploration/Returns Min          -14.4623
exploration/Actions Mean           0.00246061
exploration/Actions Std            0.140936
exploration/Actions Max            0.763815
exploration/Actions Min           -0.76966
exploration/Num Paths              2
exploration/Average Returns      -14.4064
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0686996
evaluation/Rewards Std             0.0322634
evaluation/Rewards Max            -0.0609904
evaluation/Rewards Min            -0.718045
evaluation/Returns Mean           -6.86996
evaluation/Returns Std             0.261194
evaluation/Returns Max            -6.6358
evaluation/Returns Min            -7.33943
evaluation/Actions Mean            0.00403988
evaluation/Actions Std             0.0665422
evaluation/Actions Max             0.999982
evaluation/Actions Min            -0.770077
evaluation/Num Paths               5
evaluation/Average Returns        -6.86996
time/data storing (s)              0.00109294
time/evaluation sampling (s)       0.083687
time/exploration sampling (s)      0.0327044
time/logging (s)                   0.00246602
time/saving (s)                    0.00197047
time/training (s)                  0.453535
time/epoch (s)                     0.575456
time/total (s)                    49.3682
Epoch                             86
-----------------------------  ---------------
2019-04-13 16:59:23.655825 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size             17700
trainer/QF1 Loss                   2.0566
trainer/QF2 Loss                   2.04917
trainer/Policy Loss                8.24779
trainer/Q1 Predictions Mean       -8.5063
trainer/Q1 Predictions Std         0.718518
trainer/Q1 Predictions Max        -8.13934
trainer/Q1 Predictions Min       -11.0389
trainer/Q2 Predictions Mean       -8.50278
trainer/Q2 Predictions Std         0.718178
trainer/Q2 Predictions Max        -8.12773
trainer/Q2 Predictions Min       -11.0378
trainer/Q Targets Mean            -8.13087
trainer/Q Targets Std              1.63186
trainer/Q Targets Max             -0.108801
trainer/Q Targets Min            -11.341
trainer/Bellman Errors 1 Mean      2.0566
trainer/Bellman Errors 1 Std      11.2362
trainer/Bellman Errors 1 Max      64.6168
trainer/Bellman Errors 1 Min       6.66419e-05
trainer/Bellman Errors 2 Mean      2.04917
trainer/Bellman Errors 2 Std      11.1995
trainer/Bellman Errors 2 Max      64.4049
trainer/Bellman Errors 2 Min       3.50462e-06
trainer/Policy Action Mean         0.0690419
trainer/Policy Action Std          0.30344
trainer/Policy Action Max          0.997015
trainer/Policy Action Min         -0.361636
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.139476
exploration/Rewards Std            0.0745835
exploration/Rewards Max           -0.0120795
exploration/Rewards Min           -0.406011
exploration/Returns Mean         -13.9476
exploration/Returns Std            0.708928
exploration/Returns Max          -13.2387
exploration/Returns Min          -14.6565
exploration/Actions Mean           0.00836102
exploration/Actions Std            0.163242
exploration/Actions Max            1
exploration/Actions Min           -0.373644
exploration/Num Paths              2
exploration/Average Returns      -13.9476
evaluation/num steps total     44000
evaluation/num paths total       440
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0549029
evaluation/Rewards Std             0.0143002
evaluation/Rewards Max            -0.045621
evaluation/Rewards Min            -0.365214
evaluation/Returns Mean           -5.49029
evaluation/Returns Std             0.137641
evaluation/Returns Max            -5.39865
evaluation/Returns Min            -5.76364
evaluation/Actions Mean            0.00272701
evaluation/Actions Std             0.0545276
evaluation/Actions Max             0.998102
evaluation/Actions Min            -0.68286
evaluation/Num Paths               5
evaluation/Average Returns        -5.49029
time/data storing (s)              0.00108593
time/evaluation sampling (s)       0.0745236
time/exploration sampling (s)      0.031368
time/logging (s)                   0.0025152
time/saving (s)                    0.00222517
time/training (s)                  0.451248
time/epoch (s)                     0.562966
time/total (s)                    49.935
Epoch                             87
-----------------------------  ---------------
2019-04-13 16:59:24.229708 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 88 finished
-----------------------------  --------------
replay_buffer/size             17900
trainer/QF1 Loss                   0.115752
trainer/QF2 Loss                   0.11619
trainer/Policy Loss                7.8383
trainer/Q1 Predictions Mean       -8.02128
trainer/Q1 Predictions Std         0.357894
trainer/Q1 Predictions Max        -7.76652
trainer/Q1 Predictions Min        -9.38274
trainer/Q2 Predictions Mean       -8.02186
trainer/Q2 Predictions Std         0.348806
trainer/Q2 Predictions Max        -7.75495
trainer/Q2 Predictions Min        -9.3458
trainer/Q Targets Mean            -8.32476
trainer/Q Targets Std              0.386989
trainer/Q Targets Max             -7.89215
trainer/Q Targets Min             -9.72605
trainer/Bellman Errors 1 Mean      0.115752
trainer/Bellman Errors 1 Std       0.115015
trainer/Bellman Errors 1 Max       0.570194
trainer/Bellman Errors 1 Min       0.00286845
trainer/Bellman Errors 2 Mean      0.11619
trainer/Bellman Errors 2 Std       0.112928
trainer/Bellman Errors 2 Max       0.543639
trainer/Bellman Errors 2 Min       0.0017751
trainer/Policy Action Mean         0.0180939
trainer/Policy Action Std          0.189458
trainer/Policy Action Max          0.787473
trainer/Policy Action Min         -0.357045
exploration/num steps total    17900
exploration/num paths total      179
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.150091
exploration/Rewards Std            0.0787209
exploration/Rewards Max           -0.00544699
exploration/Rewards Min           -0.407554
exploration/Returns Mean         -15.0091
exploration/Returns Std            0.0834265
exploration/Returns Max          -14.9257
exploration/Returns Min          -15.0925
exploration/Actions Mean           0.00608453
exploration/Actions Std            0.152102
exploration/Actions Max            0.98213
exploration/Actions Min           -0.477699
exploration/Num Paths              2
exploration/Average Returns      -15.0091
evaluation/num steps total     44500
evaluation/num paths total       445
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0892732
evaluation/Rewards Std             0.0483321
evaluation/Rewards Max            -0.084103
evaluation/Rewards Min            -0.741877
evaluation/Returns Mean           -8.92732
evaluation/Returns Std             0.195785
evaluation/Returns Max            -8.56791
evaluation/Returns Min            -9.16745
evaluation/Actions Mean            0.00670959
evaluation/Actions Std             0.0873971
evaluation/Actions Max             0.999987
evaluation/Actions Min            -0.733391
evaluation/Num Paths               5
evaluation/Average Returns        -8.92732
time/data storing (s)              0.0011058
time/evaluation sampling (s)       0.0732492
time/exploration sampling (s)      0.033213
time/logging (s)                   0.00247114
time/saving (s)                    0.00237233
time/training (s)                  0.455661
time/epoch (s)                     0.568073
time/total (s)                    50.507
Epoch                             88
-----------------------------  --------------
2019-04-13 16:59:24.802157 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 89 finished
-----------------------------  ---------------
replay_buffer/size             18100
trainer/QF1 Loss                   0.0465169
trainer/QF2 Loss                   0.0439605
trainer/Policy Loss                8.1878
trainer/Q1 Predictions Mean       -8.33877
trainer/Q1 Predictions Std         0.458599
trainer/Q1 Predictions Max        -8.09746
trainer/Q1 Predictions Min       -10.5585
trainer/Q2 Predictions Mean       -8.35027
trainer/Q2 Predictions Std         0.458049
trainer/Q2 Predictions Max        -8.08054
trainer/Q2 Predictions Min       -10.5672
trainer/Q Targets Mean            -8.42708
trainer/Q Targets Std              0.5749
trainer/Q Targets Max             -8.01633
trainer/Q Targets Min            -11.0236
trainer/Bellman Errors 1 Mean      0.0465169
trainer/Bellman Errors 1 Std       0.132077
trainer/Bellman Errors 1 Max       0.737945
trainer/Bellman Errors 1 Min       2.2583e-05
trainer/Bellman Errors 2 Mean      0.0439605
trainer/Bellman Errors 2 Std       0.122465
trainer/Bellman Errors 2 Max       0.689709
trainer/Bellman Errors 2 Min       0.000289915
trainer/Policy Action Mean        -0.000764887
trainer/Policy Action Std          0.185582
trainer/Policy Action Max          0.998004
trainer/Policy Action Min         -0.349058
exploration/num steps total    18100
exploration/num paths total      181
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132013
exploration/Rewards Std            0.0726889
exploration/Rewards Max           -0.0115422
exploration/Rewards Min           -0.344067
exploration/Returns Mean         -13.2013
exploration/Returns Std            0.1898
exploration/Returns Max          -13.0115
exploration/Returns Min          -13.3911
exploration/Actions Mean           0.00250178
exploration/Actions Std            0.155594
exploration/Actions Max            1
exploration/Actions Min           -0.59914
exploration/Num Paths              2
exploration/Average Returns      -13.2013
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0365601
evaluation/Rewards Std             0.0242404
evaluation/Rewards Max            -0.0343124
evaluation/Rewards Min            -0.485043
evaluation/Returns Mean           -3.65601
evaluation/Returns Std             0.128347
evaluation/Returns Max            -3.54043
evaluation/Returns Min            -3.90009
evaluation/Actions Mean            0.00486631
evaluation/Actions Std             0.0865891
evaluation/Actions Max             0.999828
evaluation/Actions Min            -0.942338
evaluation/Num Paths               5
evaluation/Average Returns        -3.65601
time/data storing (s)              0.00107701
time/evaluation sampling (s)       0.0772045
time/exploration sampling (s)      0.0321751
time/logging (s)                   0.00252238
time/saving (s)                    0.00224831
time/training (s)                  0.451497
time/epoch (s)                     0.566725
time/total (s)                    51.0777
Epoch                             89
-----------------------------  ---------------
2019-04-13 16:59:25.371325 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size             18300
trainer/QF1 Loss                   3.9861
trainer/QF2 Loss                   4.01226
trainer/Policy Loss                7.9801
trainer/Q1 Predictions Mean       -8.32286
trainer/Q1 Predictions Std         0.709698
trainer/Q1 Predictions Max        -7.96621
trainer/Q1 Predictions Min       -10.8195
trainer/Q2 Predictions Mean       -8.31833
trainer/Q2 Predictions Std         0.715238
trainer/Q2 Predictions Max        -7.93833
trainer/Q2 Predictions Min       -10.9161
trainer/Q Targets Mean            -7.98757
trainer/Q Targets Std              2.15248
trainer/Q Targets Max             -0.137419
trainer/Q Targets Min            -11.2808
trainer/Bellman Errors 1 Mean      3.9861
trainer/Bellman Errors 1 Std      15.2275
trainer/Bellman Errors 1 Max      63.4077
trainer/Bellman Errors 1 Min       0.000469645
trainer/Bellman Errors 2 Mean      4.01226
trainer/Bellman Errors 2 Std      15.2981
trainer/Bellman Errors 2 Max      63.8044
trainer/Bellman Errors 2 Min       0.000344135
trainer/Policy Action Mean         0.0767766
trainer/Policy Action Std          0.277635
trainer/Policy Action Max          0.998244
trainer/Policy Action Min         -0.993022
exploration/num steps total    18300
exploration/num paths total      183
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.128926
exploration/Rewards Std            0.0760722
exploration/Rewards Max           -0.000905846
exploration/Rewards Min           -0.37205
exploration/Returns Mean         -12.8926
exploration/Returns Std            0.831838
exploration/Returns Max          -12.0607
exploration/Returns Min          -13.7244
exploration/Actions Mean           0.00339844
exploration/Actions Std            0.138566
exploration/Actions Max            0.835454
exploration/Actions Min           -0.320967
exploration/Num Paths              2
exploration/Average Returns      -12.8926
evaluation/num steps total     45500
evaluation/num paths total       455
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0660183
evaluation/Rewards Std             0.0186302
evaluation/Rewards Max            -0.0607704
evaluation/Rewards Min            -0.329133
evaluation/Returns Mean           -6.60183
evaluation/Returns Std             0.113597
evaluation/Returns Max            -6.44044
evaluation/Returns Min            -6.74208
evaluation/Actions Mean            0.00191234
evaluation/Actions Std             0.0769886
evaluation/Actions Max             0.999322
evaluation/Actions Min            -0.961445
evaluation/Num Paths               5
evaluation/Average Returns        -6.60183
time/data storing (s)              0.00115116
time/evaluation sampling (s)       0.0738626
time/exploration sampling (s)      0.0332581
time/logging (s)                   0.0018986
time/saving (s)                    0.00202164
time/training (s)                  0.450563
time/epoch (s)                     0.562755
time/total (s)                    51.6443
Epoch                             90
-----------------------------  ---------------
2019-04-13 16:59:25.934451 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size             18500
trainer/QF1 Loss                   4.07095
trainer/QF2 Loss                   4.08032
trainer/Policy Loss                8.09315
trainer/Q1 Predictions Mean       -8.32968
trainer/Q1 Predictions Std         0.472701
trainer/Q1 Predictions Max        -8.07979
trainer/Q1 Predictions Min       -10.7414
trainer/Q2 Predictions Mean       -8.32767
trainer/Q2 Predictions Std         0.470711
trainer/Q2 Predictions Max        -8.07177
trainer/Q2 Predictions Min       -10.7188
trainer/Q Targets Mean            -7.90231
trainer/Q Targets Std              2.04818
trainer/Q Targets Max             -0.189405
trainer/Q Targets Min            -10.903
trainer/Bellman Errors 1 Mean      4.07096
trainer/Bellman Errors 1 Std      15.6614
trainer/Bellman Errors 1 Max      64.7335
trainer/Bellman Errors 1 Min       3.78842e-05
trainer/Bellman Errors 2 Mean      4.08032
trainer/Bellman Errors 2 Std      15.6996
trainer/Bellman Errors 2 Max      65.1042
trainer/Bellman Errors 2 Min       4.03766e-06
trainer/Policy Action Mean        -0.0155903
trainer/Policy Action Std          0.160246
trainer/Policy Action Max          0.996436
trainer/Policy Action Min         -0.305609
exploration/num steps total    18500
exploration/num paths total      185
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129174
exploration/Rewards Std            0.092303
exploration/Rewards Max           -0.00863054
exploration/Rewards Min           -0.993576
exploration/Returns Mean         -12.9174
exploration/Returns Std            0.635256
exploration/Returns Max          -12.2822
exploration/Returns Min          -13.5527
exploration/Actions Mean           0.00183761
exploration/Actions Std            0.154986
exploration/Actions Max            1
exploration/Actions Min           -0.748077
exploration/Num Paths              2
exploration/Average Returns      -12.9174
evaluation/num steps total     46000
evaluation/num paths total       460
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0102561
evaluation/Rewards Std             0.0322299
evaluation/Rewards Max            -0.00446178
evaluation/Rewards Min            -0.586612
evaluation/Returns Mean           -1.02561
evaluation/Returns Std             0.247688
evaluation/Returns Max            -0.818602
evaluation/Returns Min            -1.41648
evaluation/Actions Mean            0.0035921
evaluation/Actions Std             0.0693287
evaluation/Actions Max             0.99985
evaluation/Actions Min            -0.84817
evaluation/Num Paths               5
evaluation/Average Returns        -1.02561
time/data storing (s)              0.00117667
time/evaluation sampling (s)       0.0770011
time/exploration sampling (s)      0.0315736
time/logging (s)                   0.00253971
time/saving (s)                    0.0024311
time/training (s)                  0.443656
time/epoch (s)                     0.558378
time/total (s)                    52.2065
Epoch                             91
-----------------------------  ---------------
2019-04-13 16:59:26.556679 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size             18700
trainer/QF1 Loss                   0.0261937
trainer/QF2 Loss                   0.029009
trainer/Policy Loss                8.22546
trainer/Q1 Predictions Mean       -8.33688
trainer/Q1 Predictions Std         0.186315
trainer/Q1 Predictions Max        -8.19519
trainer/Q1 Predictions Min        -9.1925
trainer/Q2 Predictions Mean       -8.33797
trainer/Q2 Predictions Std         0.179123
trainer/Q2 Predictions Max        -8.1834
trainer/Q2 Predictions Min        -9.14725
trainer/Q Targets Mean            -8.36425
trainer/Q Targets Std              0.301188
trainer/Q Targets Max             -8.10046
trainer/Q Targets Min             -9.73452
trainer/Bellman Errors 1 Mean      0.0261937
trainer/Bellman Errors 1 Std       0.0528444
trainer/Bellman Errors 1 Max       0.293779
trainer/Bellman Errors 1 Min       0.000293629
trainer/Bellman Errors 2 Mean      0.029009
trainer/Bellman Errors 2 Std       0.0614514
trainer/Bellman Errors 2 Max       0.344885
trainer/Bellman Errors 2 Min       2.14819e-07
trainer/Policy Action Mean        -0.0135883
trainer/Policy Action Std          0.128869
trainer/Policy Action Max          0.449435
trainer/Policy Action Min         -0.318182
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134454
exploration/Rewards Std            0.0848967
exploration/Rewards Max           -0.00557431
exploration/Rewards Min           -0.701953
exploration/Returns Mean         -13.4454
exploration/Returns Std            2.0906
exploration/Returns Max          -11.3548
exploration/Returns Min          -15.536
exploration/Actions Mean           0.00834155
exploration/Actions Std            0.144655
exploration/Actions Max            0.769215
exploration/Actions Min           -0.35144
exploration/Num Paths              2
exploration/Average Returns      -13.4454
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0397012
evaluation/Rewards Std             0.0429941
evaluation/Rewards Max            -0.0189823
evaluation/Rewards Min            -0.687387
evaluation/Returns Mean           -3.97012
evaluation/Returns Std             0.260974
evaluation/Returns Max            -3.65165
evaluation/Returns Min            -4.27093
evaluation/Actions Mean            0.00806543
evaluation/Actions Std             0.0826572
evaluation/Actions Max             0.999966
evaluation/Actions Min            -0.200498
evaluation/Num Paths               5
evaluation/Average Returns        -3.97012
time/data storing (s)              0.00120593
time/evaluation sampling (s)       0.0760979
time/exploration sampling (s)      0.0401194
time/logging (s)                   0.00245088
time/saving (s)                    0.00224422
time/training (s)                  0.494344
time/epoch (s)                     0.616463
time/total (s)                    52.8267
Epoch                             92
-----------------------------  ---------------
2019-04-13 16:59:27.132688 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size             18900
trainer/QF1 Loss                   2.0484
trainer/QF2 Loss                   2.04372
trainer/Policy Loss                8.38372
trainer/Q1 Predictions Mean       -8.6563
trainer/Q1 Predictions Std         1.12282
trainer/Q1 Predictions Max        -8.15768
trainer/Q1 Predictions Min       -14.3117
trainer/Q2 Predictions Mean       -8.65527
trainer/Q2 Predictions Std         1.12589
trainer/Q2 Predictions Max        -8.15242
trainer/Q2 Predictions Min       -14.3269
trainer/Q Targets Mean            -8.52272
trainer/Q Targets Std              1.84972
trainer/Q Targets Max             -0.305628
trainer/Q Targets Min            -14.3263
trainer/Bellman Errors 1 Mean      2.0484
trainer/Bellman Errors 1 Std      11.1803
trainer/Bellman Errors 1 Max      64.2968
trainer/Bellman Errors 1 Min       1.4007e-06
trainer/Bellman Errors 2 Mean      2.04372
trainer/Bellman Errors 2 Std      11.1582
trainer/Bellman Errors 2 Max      64.1691
trainer/Bellman Errors 2 Min       3.94976e-07
trainer/Policy Action Mean        -0.0260844
trainer/Policy Action Std          0.262811
trainer/Policy Action Max          1
trainer/Policy Action Min         -0.968112
exploration/num steps total    18900
exploration/num paths total      189
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134816
exploration/Rewards Std            0.0706926
exploration/Rewards Max           -0.00318181
exploration/Rewards Min           -0.459894
exploration/Returns Mean         -13.4816
exploration/Returns Std            0.0518723
exploration/Returns Max          -13.4297
exploration/Returns Min          -13.5334
exploration/Actions Mean           0.00339004
exploration/Actions Std            0.1468
exploration/Actions Max            0.926693
exploration/Actions Min           -0.413098
exploration/Num Paths              2
exploration/Average Returns      -13.4816
evaluation/num steps total     47000
evaluation/num paths total       470
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0561693
evaluation/Rewards Std             0.0516238
evaluation/Rewards Max            -0.0290858
evaluation/Rewards Min            -0.992052
evaluation/Returns Mean           -5.61693
evaluation/Returns Std             0.319836
evaluation/Returns Max            -5.22099
evaluation/Returns Min            -6.1585
evaluation/Actions Mean            0.00537747
evaluation/Actions Std             0.0880389
evaluation/Actions Max             0.999999
evaluation/Actions Min            -0.841202
evaluation/Num Paths               5
evaluation/Average Returns        -5.61693
time/data storing (s)              0.00114392
time/evaluation sampling (s)       0.0774624
time/exploration sampling (s)      0.0312913
time/logging (s)                   0.00246671
time/saving (s)                    0.00246276
time/training (s)                  0.456069
time/epoch (s)                     0.570896
time/total (s)                    53.4011
Epoch                             93
-----------------------------  ---------------
2019-04-13 16:59:27.692423 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size             19100
trainer/QF1 Loss                   2.09495
trainer/QF2 Loss                   2.0962
trainer/Policy Loss                8.18178
trainer/Q1 Predictions Mean       -8.37485
trainer/Q1 Predictions Std         0.425262
trainer/Q1 Predictions Max        -8.12218
trainer/Q1 Predictions Min       -10.358
trainer/Q2 Predictions Mean       -8.37437
trainer/Q2 Predictions Std         0.426133
trainer/Q2 Predictions Max        -8.10142
trainer/Q2 Predictions Min       -10.35
trainer/Q Targets Mean            -8.28482
trainer/Q Targets Std              1.53105
trainer/Q Targets Max             -0.0751176
trainer/Q Targets Min            -10.3875
trainer/Bellman Errors 1 Mean      2.09495
trainer/Bellman Errors 1 Std      11.3904
trainer/Bellman Errors 1 Max      65.5131
trainer/Bellman Errors 1 Min       4.33262e-05
trainer/Bellman Errors 2 Mean      2.0962
trainer/Bellman Errors 2 Std      11.4056
trainer/Bellman Errors 2 Max      65.5993
trainer/Bellman Errors 2 Min       3.37425e-05
trainer/Policy Action Mean         0.0183758
trainer/Policy Action Std          0.196133
trainer/Policy Action Max          0.827636
trainer/Policy Action Min         -0.992416
exploration/num steps total    19100
exploration/num paths total      191
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.138344
exploration/Rewards Std            0.0742581
exploration/Rewards Max           -0.00987723
exploration/Rewards Min           -0.42449
exploration/Returns Mean         -13.8344
exploration/Returns Std            0.539484
exploration/Returns Max          -13.295
exploration/Returns Min          -14.3739
exploration/Actions Mean           0.0053544
exploration/Actions Std            0.159917
exploration/Actions Max            1
exploration/Actions Min           -0.502259
exploration/Num Paths              2
exploration/Average Returns      -13.8344
evaluation/num steps total     47500
evaluation/num paths total       475
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.060848
evaluation/Rewards Std             0.0432174
evaluation/Rewards Max            -0.0402984
evaluation/Rewards Min            -0.624226
evaluation/Returns Mean           -6.0848
evaluation/Returns Std             0.236943
evaluation/Returns Max            -5.64743
evaluation/Returns Min            -6.29377
evaluation/Actions Mean            0.00731731
evaluation/Actions Std             0.0868113
evaluation/Actions Max             0.999948
evaluation/Actions Min            -0.887727
evaluation/Num Paths               5
evaluation/Average Returns        -6.0848
time/data storing (s)              0.00106188
time/evaluation sampling (s)       0.0754522
time/exploration sampling (s)      0.0326526
time/logging (s)                   0.00246323
time/saving (s)                    0.0022422
time/training (s)                  0.44014
time/epoch (s)                     0.554013
time/total (s)                    53.9589
Epoch                             94
-----------------------------  ---------------
2019-04-13 16:59:28.259887 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size             19300
trainer/QF1 Loss                   2.13768
trainer/QF2 Loss                   2.13991
trainer/Policy Loss                8.34577
trainer/Q1 Predictions Mean       -8.48212
trainer/Q1 Predictions Std         0.324733
trainer/Q1 Predictions Max        -8.2677
trainer/Q1 Predictions Min        -9.98736
trainer/Q2 Predictions Mean       -8.4828
trainer/Q2 Predictions Std         0.31489
trainer/Q2 Predictions Max        -8.2689
trainer/Q2 Predictions Min        -9.93399
trainer/Q Targets Mean            -8.26462
trainer/Q Targets Std              1.51998
trainer/Q Targets Max             -0.180937
trainer/Q Targets Min            -10.7137
trainer/Bellman Errors 1 Mean      2.13768
trainer/Bellman Errors 1 Std      11.716
trainer/Bellman Errors 1 Max      67.3678
trainer/Bellman Errors 1 Min       3.67445e-08
trainer/Bellman Errors 2 Mean      2.13991
trainer/Bellman Errors 2 Std      11.7105
trainer/Bellman Errors 2 Max      67.3384
trainer/Bellman Errors 2 Min       1.29197e-05
trainer/Policy Action Mean        -0.0206126
trainer/Policy Action Std          0.173449
trainer/Policy Action Max          0.932013
trainer/Policy Action Min         -0.55216
exploration/num steps total    19300
exploration/num paths total      193
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132079
exploration/Rewards Std            0.0663388
exploration/Rewards Max           -0.0202036
exploration/Rewards Min           -0.349282
exploration/Returns Mean         -13.2079
exploration/Returns Std            0.723256
exploration/Returns Max          -12.4846
exploration/Returns Min          -13.9312
exploration/Actions Mean           0.00031585
exploration/Actions Std            0.137047
exploration/Actions Max            0.371845
exploration/Actions Min           -0.565563
exploration/Num Paths              2
exploration/Average Returns      -13.2079
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0506097
evaluation/Rewards Std             0.0522074
evaluation/Rewards Max            -0.0374181
evaluation/Rewards Min            -0.875146
evaluation/Returns Mean           -5.06097
evaluation/Returns Std             0.349225
evaluation/Returns Max            -4.69774
evaluation/Returns Min            -5.50126
evaluation/Actions Mean            0.00355471
evaluation/Actions Std             0.0895926
evaluation/Actions Max             0.999996
evaluation/Actions Min            -0.899546
evaluation/Num Paths               5
evaluation/Average Returns        -5.06097
time/data storing (s)              0.00114455
time/evaluation sampling (s)       0.0768985
time/exploration sampling (s)      0.0322919
time/logging (s)                   0.00247655
time/saving (s)                    0.0022923
time/training (s)                  0.447255
time/epoch (s)                     0.562359
time/total (s)                    54.5245
Epoch                             95
-----------------------------  ---------------
2019-04-13 16:59:28.823980 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size             19500
trainer/QF1 Loss                   0.0140744
trainer/QF2 Loss                   0.0124481
trainer/Policy Loss                8.47845
trainer/Q1 Predictions Mean       -8.62458
trainer/Q1 Predictions Std         0.453829
trainer/Q1 Predictions Max        -8.38639
trainer/Q1 Predictions Min       -10.8686
trainer/Q2 Predictions Mean       -8.64712
trainer/Q2 Predictions Std         0.455668
trainer/Q2 Predictions Max        -8.42216
trainer/Q2 Predictions Min       -10.9094
trainer/Q Targets Mean            -8.62993
trainer/Q Targets Std              0.467783
trainer/Q Targets Max             -8.28858
trainer/Q Targets Min            -10.823
trainer/Bellman Errors 1 Mean      0.0140744
trainer/Bellman Errors 1 Std       0.0221906
trainer/Bellman Errors 1 Max       0.0960406
trainer/Bellman Errors 1 Min       4.67561e-07
trainer/Bellman Errors 2 Mean      0.0124481
trainer/Bellman Errors 2 Std       0.0170476
trainer/Bellman Errors 2 Max       0.0709397
trainer/Bellman Errors 2 Min       2.09722e-05
trainer/Policy Action Mean         0.000621977
trainer/Policy Action Std          0.184449
trainer/Policy Action Max          0.997793
trainer/Policy Action Min         -0.22955
exploration/num steps total    19500
exploration/num paths total      195
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.140261
exploration/Rewards Std            0.0687695
exploration/Rewards Max           -0.0239913
exploration/Rewards Min           -0.332406
exploration/Returns Mean         -14.0261
exploration/Returns Std            0.0623214
exploration/Returns Max          -13.9637
exploration/Returns Min          -14.0884
exploration/Actions Mean           0.0049377
exploration/Actions Std            0.15291
exploration/Actions Max            1
exploration/Actions Min           -0.444663
exploration/Num Paths              2
exploration/Average Returns      -14.0261
evaluation/num steps total     48500
evaluation/num paths total       485
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0410782
evaluation/Rewards Std             0.030308
evaluation/Rewards Max            -0.0208566
evaluation/Rewards Min            -0.678183
evaluation/Returns Mean           -4.10782
evaluation/Returns Std             0.250817
evaluation/Returns Max            -3.91265
evaluation/Returns Min            -4.58498
evaluation/Actions Mean            0.00574455
evaluation/Actions Std             0.0773216
evaluation/Actions Max             0.999908
evaluation/Actions Min            -0.915654
evaluation/Num Paths               5
evaluation/Average Returns        -4.10782
time/data storing (s)              0.00111846
time/evaluation sampling (s)       0.0734205
time/exploration sampling (s)      0.0338685
time/logging (s)                   0.00245884
time/saving (s)                    0.00226576
time/training (s)                  0.445189
time/epoch (s)                     0.558322
time/total (s)                    55.0867
Epoch                             96
-----------------------------  ---------------
2019-04-13 16:59:29.399434 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size             19700
trainer/QF1 Loss                   0.0484418
trainer/QF2 Loss                   0.0431185
trainer/Policy Loss                8.40586
trainer/Q1 Predictions Mean       -8.54791
trainer/Q1 Predictions Std         0.238856
trainer/Q1 Predictions Max        -8.33058
trainer/Q1 Predictions Min        -9.43525
trainer/Q2 Predictions Mean       -8.54991
trainer/Q2 Predictions Std         0.235097
trainer/Q2 Predictions Max        -8.35055
trainer/Q2 Predictions Min        -9.34086
trainer/Q Targets Mean            -8.65176
trainer/Q Targets Std              0.306679
trainer/Q Targets Max             -8.20836
trainer/Q Targets Min             -9.45035
trainer/Bellman Errors 1 Mean      0.0484418
trainer/Bellman Errors 1 Std       0.0824919
trainer/Bellman Errors 1 Max       0.415914
trainer/Bellman Errors 1 Min       2.97301e-06
trainer/Bellman Errors 2 Mean      0.0431185
trainer/Bellman Errors 2 Std       0.0771284
trainer/Bellman Errors 2 Max       0.393027
trainer/Bellman Errors 2 Min       7.7987e-07
trainer/Policy Action Mean         0.00250273
trainer/Policy Action Std          0.121299
trainer/Policy Action Max          0.349085
trainer/Policy Action Min         -0.266754
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.138424
exploration/Rewards Std            0.0695885
exploration/Rewards Max           -0.0213904
exploration/Rewards Min           -0.318783
exploration/Returns Mean         -13.8424
exploration/Returns Std            0.180492
exploration/Returns Max          -13.6619
exploration/Returns Min          -14.0229
exploration/Actions Mean           0.00564257
exploration/Actions Std            0.133609
exploration/Actions Max            1
exploration/Actions Min           -0.319061
exploration/Num Paths              2
exploration/Average Returns      -13.8424
evaluation/num steps total     49000
evaluation/num paths total       490
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0662641
evaluation/Rewards Std             0.0578527
evaluation/Rewards Max            -0.0613635
evaluation/Rewards Min            -1.00457
evaluation/Returns Mean           -6.62641
evaluation/Returns Std             0.365268
evaluation/Returns Max            -6.20394
evaluation/Returns Min            -7.14605
evaluation/Actions Mean            0.0066028
evaluation/Actions Std             0.0917774
evaluation/Actions Max             0.999999
evaluation/Actions Min            -0.872586
evaluation/Num Paths               5
evaluation/Average Returns        -6.62641
time/data storing (s)              0.00113241
time/evaluation sampling (s)       0.07518
time/exploration sampling (s)      0.0317477
time/logging (s)                   0.00247357
time/saving (s)                    0.00227154
time/training (s)                  0.456905
time/epoch (s)                     0.56971
time/total (s)                    55.6602
Epoch                             97
-----------------------------  ---------------
2019-04-13 16:59:29.959965 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size             19900
trainer/QF1 Loss                   0.0746906
trainer/QF2 Loss                   0.0707198
trainer/Policy Loss                8.33379
trainer/Q1 Predictions Mean       -8.4092
trainer/Q1 Predictions Std         0.154897
trainer/Q1 Predictions Max        -8.28505
trainer/Q1 Predictions Min        -9.1771
trainer/Q2 Predictions Mean       -8.41207
trainer/Q2 Predictions Std         0.156737
trainer/Q2 Predictions Max        -8.2858
trainer/Q2 Predictions Min        -9.2031
trainer/Q Targets Mean            -8.62622
trainer/Q Targets Std              0.210559
trainer/Q Targets Max             -8.33287
trainer/Q Targets Min             -9.3612
trainer/Bellman Errors 1 Mean      0.0746906
trainer/Bellman Errors 1 Std       0.0835619
trainer/Bellman Errors 1 Max       0.315412
trainer/Bellman Errors 1 Min       5.36442e-07
trainer/Bellman Errors 2 Mean      0.0707198
trainer/Bellman Errors 2 Std       0.0786521
trainer/Bellman Errors 2 Max       0.284186
trainer/Bellman Errors 2 Min       2.91774e-05
trainer/Policy Action Mean         0.0244587
trainer/Policy Action Std          0.102123
trainer/Policy Action Max          0.311254
trainer/Policy Action Min         -0.246994
exploration/num steps total    19900
exploration/num paths total      199
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.144201
exploration/Rewards Std            0.084521
exploration/Rewards Max           -0.0070425
exploration/Rewards Min           -0.438136
exploration/Returns Mean         -14.4201
exploration/Returns Std            0.197237
exploration/Returns Max          -14.2229
exploration/Returns Min          -14.6174
exploration/Actions Mean           0.00712911
exploration/Actions Std            0.165005
exploration/Actions Max            1
exploration/Actions Min           -0.340643
exploration/Num Paths              2
exploration/Average Returns      -14.4201
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0775882
evaluation/Rewards Std             0.0461515
evaluation/Rewards Max            -0.0734086
evaluation/Rewards Min            -0.847899
evaluation/Returns Mean           -7.75882
evaluation/Returns Std             0.306059
evaluation/Returns Max            -7.40016
evaluation/Returns Min            -8.1743
evaluation/Actions Mean            0.00842937
evaluation/Actions Std             0.089081
evaluation/Actions Max             0.999982
evaluation/Actions Min            -0.299552
evaluation/Num Paths               5
evaluation/Average Returns        -7.75882
time/data storing (s)              0.00112303
time/evaluation sampling (s)       0.0731979
time/exploration sampling (s)      0.0331061
time/logging (s)                   0.00204519
time/saving (s)                    0.0017724
time/training (s)                  0.443041
time/epoch (s)                     0.554286
time/total (s)                    56.2184
Epoch                             98
-----------------------------  ---------------
2019-04-13 16:59:30.521164 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size             20100
trainer/QF1 Loss                   0.0328939
trainer/QF2 Loss                   0.0297738
trainer/Policy Loss                8.60683
trainer/Q1 Predictions Mean       -8.74522
trainer/Q1 Predictions Std         0.413051
trainer/Q1 Predictions Max        -8.49398
trainer/Q1 Predictions Min       -10.8345
trainer/Q2 Predictions Mean       -8.73477
trainer/Q2 Predictions Std         0.401023
trainer/Q2 Predictions Max        -8.49943
trainer/Q2 Predictions Min       -10.7846
trainer/Q Targets Mean            -8.70701
trainer/Q Targets Std              0.364408
trainer/Q Targets Max             -8.34201
trainer/Q Targets Min            -10.3858
trainer/Bellman Errors 1 Mean      0.0328939
trainer/Bellman Errors 1 Std       0.0472023
trainer/Bellman Errors 1 Max       0.201295
trainer/Bellman Errors 1 Min       4.47428e-06
trainer/Bellman Errors 2 Mean      0.0297738
trainer/Bellman Errors 2 Std       0.0428409
trainer/Bellman Errors 2 Max       0.165511
trainer/Bellman Errors 2 Min       0.00049329
trainer/Policy Action Mean         0.0409877
trainer/Policy Action Std          0.20949
trainer/Policy Action Max          0.986071
trainer/Policy Action Min         -0.310958
exploration/num steps total    20100
exploration/num paths total      201
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.14242
exploration/Rewards Std            0.0770671
exploration/Rewards Max           -0.0120877
exploration/Rewards Min           -0.46821
exploration/Returns Mean         -14.242
exploration/Returns Std            0.124332
exploration/Returns Max          -14.1176
exploration/Returns Min          -14.3663
exploration/Actions Mean           0.00492246
exploration/Actions Std            0.151804
exploration/Actions Max            1
exploration/Actions Min           -0.488758
exploration/Num Paths              2
exploration/Average Returns      -14.242
evaluation/num steps total     50000
evaluation/num paths total       500
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0758376
evaluation/Rewards Std             0.00249991
evaluation/Rewards Max            -0.0377041
evaluation/Rewards Min            -0.099885
evaluation/Returns Mean           -7.58376
evaluation/Returns Std             0.0265561
evaluation/Returns Max            -7.54694
evaluation/Returns Min            -7.61725
evaluation/Actions Mean            0.00278219
evaluation/Actions Std             0.0699532
evaluation/Actions Max             0.916722
evaluation/Actions Min            -0.934948
evaluation/Num Paths               5
evaluation/Average Returns        -7.58376
time/data storing (s)              0.00113891
time/evaluation sampling (s)       0.0750616
time/exploration sampling (s)      0.0399035
time/logging (s)                   0.0024435
time/saving (s)                    0.00202764
time/training (s)                  0.435256
time/epoch (s)                     0.555831
time/total (s)                    56.7781
Epoch                             99
-----------------------------  ---------------
2019-04-13 16:59:31.101670 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size             20300
trainer/QF1 Loss                   0.0189918
trainer/QF2 Loss                   0.0188342
trainer/Policy Loss                8.61725
trainer/Q1 Predictions Mean       -8.79849
trainer/Q1 Predictions Std         0.472389
trainer/Q1 Predictions Max        -8.53322
trainer/Q1 Predictions Min       -10.9169
trainer/Q2 Predictions Mean       -8.81481
trainer/Q2 Predictions Std         0.479616
trainer/Q2 Predictions Max        -8.56309
trainer/Q2 Predictions Min       -10.936
trainer/Q Targets Mean            -8.82603
trainer/Q Targets Std              0.462805
trainer/Q Targets Max             -8.46955
trainer/Q Targets Min            -10.7944
trainer/Bellman Errors 1 Mean      0.0189918
trainer/Bellman Errors 1 Std       0.0352506
trainer/Bellman Errors 1 Max       0.182868
trainer/Bellman Errors 1 Min       8.55744e-05
trainer/Bellman Errors 2 Mean      0.0188342
trainer/Bellman Errors 2 Std       0.0398534
trainer/Bellman Errors 2 Max       0.200819
trainer/Bellman Errors 2 Min       0.000211709
trainer/Policy Action Mean        -0.0065882
trainer/Policy Action Std          0.208441
trainer/Policy Action Max          0.9979
trainer/Policy Action Min         -0.340653
exploration/num steps total    20300
exploration/num paths total      203
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.133562
exploration/Rewards Std            0.0617095
exploration/Rewards Max           -0.0126724
exploration/Rewards Min           -0.308185
exploration/Returns Mean         -13.3562
exploration/Returns Std            0.266901
exploration/Returns Max          -13.0893
exploration/Returns Min          -13.6231
exploration/Actions Mean           0.00314312
exploration/Actions Std            0.14023
exploration/Actions Max            0.69878
exploration/Actions Min           -0.352536
exploration/Num Paths              2
exploration/Average Returns      -13.3562
evaluation/num steps total     50500
evaluation/num paths total       505
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0477808
evaluation/Rewards Std             0.0436779
evaluation/Rewards Max            -0.0435279
evaluation/Rewards Min            -0.795856
evaluation/Returns Mean           -4.77808
evaluation/Returns Std             0.326879
evaluation/Returns Max            -4.49781
evaluation/Returns Min            -5.24613
evaluation/Actions Mean            0.00533555
evaluation/Actions Std             0.0784219
evaluation/Actions Max             0.999978
evaluation/Actions Min            -0.888466
evaluation/Num Paths               5
evaluation/Average Returns        -4.77808
time/data storing (s)              0.00117412
time/evaluation sampling (s)       0.0831158
time/exploration sampling (s)      0.0324379
time/logging (s)                   0.00248177
time/saving (s)                    0.00223491
time/training (s)                  0.453334
time/epoch (s)                     0.574779
time/total (s)                    57.3566
Epoch                            100
-----------------------------  ---------------
2019-04-13 16:59:31.686768 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size             20500
trainer/QF1 Loss                   0.0311775
trainer/QF2 Loss                   0.032767
trainer/Policy Loss                8.64702
trainer/Q1 Predictions Mean       -8.87388
trainer/Q1 Predictions Std         0.613796
trainer/Q1 Predictions Max        -8.54002
trainer/Q1 Predictions Min       -11.4197
trainer/Q2 Predictions Mean       -8.8713
trainer/Q2 Predictions Std         0.614627
trainer/Q2 Predictions Max        -8.5434
trainer/Q2 Predictions Min       -11.4325
trainer/Q Targets Mean            -8.93151
trainer/Q Targets Std              0.643015
trainer/Q Targets Max             -8.43459
trainer/Q Targets Min            -11.4843
trainer/Bellman Errors 1 Mean      0.0311775
trainer/Bellman Errors 1 Std       0.070009
trainer/Bellman Errors 1 Max       0.380177
trainer/Bellman Errors 1 Min       4.64956e-07
trainer/Bellman Errors 2 Mean      0.032767
trainer/Bellman Errors 2 Std       0.0714579
trainer/Bellman Errors 2 Max       0.360826
trainer/Bellman Errors 2 Min       1.30749e-06
trainer/Policy Action Mean         0.0281716
trainer/Policy Action Std          0.246078
trainer/Policy Action Max          0.99832
trainer/Policy Action Min         -0.477981
exploration/num steps total    20500
exploration/num paths total      205
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.127064
exploration/Rewards Std            0.0688599
exploration/Rewards Max           -0.00785292
exploration/Rewards Min           -0.367012
exploration/Returns Mean         -12.7064
exploration/Returns Std            0.594037
exploration/Returns Max          -12.1124
exploration/Returns Min          -13.3004
exploration/Actions Mean           0.00540086
exploration/Actions Std            0.142671
exploration/Actions Max            0.917517
exploration/Actions Min           -0.319732
exploration/Num Paths              2
exploration/Average Returns      -12.7064
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0262273
evaluation/Rewards Std             0.0352757
evaluation/Rewards Max            -0.0230342
evaluation/Rewards Min            -0.605225
evaluation/Returns Mean           -2.62273
evaluation/Returns Std             0.170663
evaluation/Returns Max            -2.35563
evaluation/Returns Min            -2.88821
evaluation/Actions Mean            0.00713693
evaluation/Actions Std             0.0820635
evaluation/Actions Max             0.999928
evaluation/Actions Min            -0.591569
evaluation/Num Paths               5
evaluation/Average Returns        -2.62273
time/data storing (s)              0.00116001
time/evaluation sampling (s)       0.0775407
time/exploration sampling (s)      0.0346333
time/logging (s)                   0.00246527
time/saving (s)                    0.0022609
time/training (s)                  0.461227
time/epoch (s)                     0.579287
time/total (s)                    57.9398
Epoch                            101
-----------------------------  ---------------
2019-04-13 16:59:32.541919 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size             20700
trainer/QF1 Loss                   2.27353
trainer/QF2 Loss                   2.27222
trainer/Policy Loss                8.52041
trainer/Q1 Predictions Mean       -8.74743
trainer/Q1 Predictions Std         0.297822
trainer/Q1 Predictions Max        -8.55339
trainer/Q1 Predictions Min        -9.66107
trainer/Q2 Predictions Mean       -8.73682
trainer/Q2 Predictions Std         0.288244
trainer/Q2 Predictions Max        -8.54532
trainer/Q2 Predictions Min        -9.61285
trainer/Q Targets Mean            -8.58334
trainer/Q Targets Std              1.55339
trainer/Q Targets Max             -0.136576
trainer/Q Targets Min             -9.76958
trainer/Bellman Errors 1 Mean      2.27353
trainer/Bellman Errors 1 Std      12.4652
trainer/Bellman Errors 1 Max      71.6763
trainer/Bellman Errors 1 Min       0.000252708
trainer/Bellman Errors 2 Mean      2.27222
trainer/Bellman Errors 2 Std      12.4499
trainer/Bellman Errors 2 Max      71.5896
trainer/Bellman Errors 2 Min       0.000242118
trainer/Policy Action Mean         0.0651746
trainer/Policy Action Std          0.225257
trainer/Policy Action Max          0.999618
trainer/Policy Action Min         -0.565704
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.153193
exploration/Rewards Std            0.101599
exploration/Rewards Max           -0.0129487
exploration/Rewards Min           -1.15437
exploration/Returns Mean         -15.3193
exploration/Returns Std            0.13385
exploration/Returns Max          -15.1855
exploration/Returns Min          -15.4532
exploration/Actions Mean           0.00583337
exploration/Actions Std            0.151383
exploration/Actions Max            1
exploration/Actions Min           -0.43214
exploration/Num Paths              2
exploration/Average Returns      -15.3193
evaluation/num steps total     51500
evaluation/num paths total       515
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0660907
evaluation/Rewards Std             0.0278452
evaluation/Rewards Max            -0.0264316
evaluation/Rewards Min            -0.522175
evaluation/Returns Mean           -6.60907
evaluation/Returns Std             0.18479
evaluation/Returns Max            -6.36933
evaluation/Returns Min            -6.84929
evaluation/Actions Mean            0.00297437
evaluation/Actions Std             0.0783164
evaluation/Actions Max             0.999899
evaluation/Actions Min            -0.912365
evaluation/Num Paths               5
evaluation/Average Returns        -6.60907
time/data storing (s)              0.00648104
time/evaluation sampling (s)       0.0909253
time/exploration sampling (s)      0.152838
time/logging (s)                   0.00248544
time/saving (s)                    0.0023486
time/training (s)                  0.593841
time/epoch (s)                     0.84892
time/total (s)                    58.7926
Epoch                            102
-----------------------------  ---------------
2019-04-13 16:59:33.063126 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size             20900
trainer/QF1 Loss                   0.0475791
trainer/QF2 Loss                   0.0439288
trainer/Policy Loss                8.72745
trainer/Q1 Predictions Mean       -8.92747
trainer/Q1 Predictions Std         0.59812
trainer/Q1 Predictions Max        -8.55069
trainer/Q1 Predictions Min       -11.0126
trainer/Q2 Predictions Mean       -8.94429
trainer/Q2 Predictions Std         0.588039
trainer/Q2 Predictions Max        -8.59908
trainer/Q2 Predictions Min       -11.0418
trainer/Q Targets Mean            -9.04445
trainer/Q Targets Std              0.591428
trainer/Q Targets Max             -8.51414
trainer/Q Targets Min            -10.9975
trainer/Bellman Errors 1 Mean      0.0475791
trainer/Bellman Errors 1 Std       0.0880265
trainer/Bellman Errors 1 Max       0.39756
trainer/Bellman Errors 1 Min       3.2851e-05
trainer/Bellman Errors 2 Mean      0.0439288
trainer/Bellman Errors 2 Std       0.0795181
trainer/Bellman Errors 2 Max       0.346899
trainer/Bellman Errors 2 Min       1.15928e-06
trainer/Policy Action Mean        -0.0251186
trainer/Policy Action Std          0.294336
trainer/Policy Action Max          0.997631
trainer/Policy Action Min         -0.977116
exploration/num steps total    20900
exploration/num paths total      209
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.137778
exploration/Rewards Std            0.0800118
exploration/Rewards Max           -0.00561752
exploration/Rewards Min           -0.593255
exploration/Returns Mean         -13.7778
exploration/Returns Std            0.479433
exploration/Returns Max          -13.2984
exploration/Returns Min          -14.2573
exploration/Actions Mean           0.00636121
exploration/Actions Std            0.153074
exploration/Actions Max            0.922815
exploration/Actions Min           -0.475855
exploration/Num Paths              2
exploration/Average Returns      -13.7778
evaluation/num steps total     52000
evaluation/num paths total       520
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0423266
evaluation/Rewards Std             0.0472303
evaluation/Rewards Max            -0.0352587
evaluation/Rewards Min            -0.784961
evaluation/Returns Mean           -4.23266
evaluation/Returns Std             0.283485
evaluation/Returns Max            -3.88851
evaluation/Returns Min            -4.60307
evaluation/Actions Mean            0.00742074
evaluation/Actions Std             0.0846611
evaluation/Actions Max             0.999988
evaluation/Actions Min            -0.713904
evaluation/Num Paths               5
evaluation/Average Returns        -4.23266
time/data storing (s)              0.00113921
time/evaluation sampling (s)       0.0804319
time/exploration sampling (s)      0.0337152
time/logging (s)                   0.00296573
time/saving (s)                    0.00236003
time/training (s)                  0.395255
time/epoch (s)                     0.515867
time/total (s)                    59.3124
Epoch                            103
-----------------------------  ---------------
2019-04-13 16:59:33.623492 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size             21100
trainer/QF1 Loss                   0.0228945
trainer/QF2 Loss                   0.0250555
trainer/Policy Loss                8.83913
trainer/Q1 Predictions Mean       -8.98882
trainer/Q1 Predictions Std         0.38267
trainer/Q1 Predictions Max        -8.73156
trainer/Q1 Predictions Min       -10.2096
trainer/Q2 Predictions Mean       -8.99773
trainer/Q2 Predictions Std         0.382391
trainer/Q2 Predictions Max        -8.75827
trainer/Q2 Predictions Min       -10.2655
trainer/Q Targets Mean            -9.02186
trainer/Q Targets Std              0.432748
trainer/Q Targets Max             -8.57593
trainer/Q Targets Min            -10.2383
trainer/Bellman Errors 1 Mean      0.0228945
trainer/Bellman Errors 1 Std       0.0420209
trainer/Bellman Errors 1 Max       0.195219
trainer/Bellman Errors 1 Min       0.000435207
trainer/Bellman Errors 2 Mean      0.0250555
trainer/Bellman Errors 2 Std       0.0432451
trainer/Bellman Errors 2 Max       0.179024
trainer/Bellman Errors 2 Min       5.44856e-07
trainer/Policy Action Mean        -0.0070415
trainer/Policy Action Std          0.205308
trainer/Policy Action Max          0.805449
trainer/Policy Action Min         -0.368169
exploration/num steps total    21100
exploration/num paths total      211
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.142757
exploration/Rewards Std            0.0777391
exploration/Rewards Max           -0.0217749
exploration/Rewards Min           -0.652611
exploration/Returns Mean         -14.2757
exploration/Returns Std            0.361157
exploration/Returns Max          -13.9146
exploration/Returns Min          -14.6369
exploration/Actions Mean           0.00418346
exploration/Actions Std            0.158765
exploration/Actions Max            1
exploration/Actions Min           -0.910891
exploration/Num Paths              2
exploration/Average Returns      -14.2757
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0591726
evaluation/Rewards Std             0.0369085
evaluation/Rewards Max            -0.0156473
evaluation/Rewards Min            -0.872733
evaluation/Returns Mean           -5.91726
evaluation/Returns Std             0.329037
evaluation/Returns Max            -5.67265
evaluation/Returns Min            -6.56833
evaluation/Actions Mean            0.00492425
evaluation/Actions Std             0.0700606
evaluation/Actions Max             0.999994
evaluation/Actions Min            -0.775391
evaluation/Num Paths               5
evaluation/Average Returns        -5.91726
time/data storing (s)              0.00104878
time/evaluation sampling (s)       0.0719251
time/exploration sampling (s)      0.0328897
time/logging (s)                   0.00242666
time/saving (s)                    0.00223103
time/training (s)                  0.442683
time/epoch (s)                     0.553204
time/total (s)                    59.8696
Epoch                            104
-----------------------------  ---------------
2019-04-13 16:59:34.133209 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 105 finished
-----------------------------  --------------
replay_buffer/size             21300
trainer/QF1 Loss                   0.0647093
trainer/QF2 Loss                   0.0684401
trainer/Policy Loss                8.61617
trainer/Q1 Predictions Mean       -8.75263
trainer/Q1 Predictions Std         0.46636
trainer/Q1 Predictions Max        -8.54155
trainer/Q1 Predictions Min       -11.0843
trainer/Q2 Predictions Mean       -8.74884
trainer/Q2 Predictions Std         0.463084
trainer/Q2 Predictions Max        -8.54031
trainer/Q2 Predictions Min       -11.0436
trainer/Q Targets Mean            -8.96801
trainer/Q Targets Std              0.473081
trainer/Q Targets Max             -8.59922
trainer/Q Targets Min            -11.3745
trainer/Bellman Errors 1 Mean      0.0647093
trainer/Bellman Errors 1 Std       0.0487312
trainer/Bellman Errors 1 Max       0.169929
trainer/Bellman Errors 1 Min       0.00155147
trainer/Bellman Errors 2 Mean      0.0684401
trainer/Bellman Errors 2 Std       0.0523094
trainer/Bellman Errors 2 Max       0.19718
trainer/Bellman Errors 2 Min       0.00059805
trainer/Policy Action Mean         0.0139792
trainer/Policy Action Std          0.171153
trainer/Policy Action Max          0.997681
trainer/Policy Action Min         -0.310254
exploration/num steps total    21300
exploration/num paths total      213
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.1621
exploration/Rewards Std            0.0956665
exploration/Rewards Max           -0.0159275
exploration/Rewards Min           -0.758934
exploration/Returns Mean         -16.21
exploration/Returns Std            0.179746
exploration/Returns Max          -16.0303
exploration/Returns Min          -16.3897
exploration/Actions Mean           0.00588473
exploration/Actions Std            0.156029
exploration/Actions Max            0.986354
exploration/Actions Min           -0.619198
exploration/Num Paths              2
exploration/Average Returns      -16.21
evaluation/num steps total     53000
evaluation/num paths total       530
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.116952
evaluation/Rewards Std             0.0407385
evaluation/Rewards Max            -0.100954
evaluation/Rewards Min            -1.02649
evaluation/Returns Mean          -11.6952
evaluation/Returns Std             0.378329
evaluation/Returns Max           -11.493
evaluation/Returns Min           -12.4517
evaluation/Actions Mean            0.00636915
evaluation/Actions Std             0.068771
evaluation/Actions Max             0.999999
evaluation/Actions Min            -0.175238
evaluation/Num Paths               5
evaluation/Average Returns       -11.6952
time/data storing (s)              0.00106073
time/evaluation sampling (s)       0.0742436
time/exploration sampling (s)      0.0325335
time/logging (s)                   0.00246887
time/saving (s)                    0.00213584
time/training (s)                  0.391532
time/epoch (s)                     0.503974
time/total (s)                    60.3773
Epoch                            105
-----------------------------  --------------
2019-04-13 16:59:34.632064 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size             21500
trainer/QF1 Loss                   2.62111
trainer/QF2 Loss                   2.62343
trainer/Policy Loss                8.8951
trainer/Q1 Predictions Mean       -9.14877
trainer/Q1 Predictions Std         0.956041
trainer/Q1 Predictions Max        -8.70339
trainer/Q1 Predictions Min       -13.349
trainer/Q2 Predictions Mean       -9.15452
trainer/Q2 Predictions Std         0.967686
trainer/Q2 Predictions Max        -8.71866
trainer/Q2 Predictions Min       -13.4175
trainer/Q Targets Mean            -8.92899
trainer/Q Targets Std              1.77479
trainer/Q Targets Max             -0.665677
trainer/Q Targets Min            -13.7386
trainer/Bellman Errors 1 Mean      2.62111
trainer/Bellman Errors 1 Std      14.4562
trainer/Bellman Errors 1 Max      83.1094
trainer/Bellman Errors 1 Min       1.17282e-05
trainer/Bellman Errors 2 Mean      2.62343
trainer/Bellman Errors 2 Std      14.4742
trainer/Bellman Errors 2 Max      83.2124
trainer/Bellman Errors 2 Min       0.000178567
trainer/Policy Action Mean         0.0106008
trainer/Policy Action Std          0.281113
trainer/Policy Action Max          1
trainer/Policy Action Min         -0.96814
exploration/num steps total    21500
exploration/num paths total      215
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.13354
exploration/Rewards Std            0.0731949
exploration/Rewards Max           -0.00333713
exploration/Rewards Min           -0.380976
exploration/Returns Mean         -13.354
exploration/Returns Std            0.112984
exploration/Returns Max          -13.241
exploration/Returns Min          -13.467
exploration/Actions Mean           0.00411904
exploration/Actions Std            0.135635
exploration/Actions Max            0.704755
exploration/Actions Min           -0.373892
exploration/Num Paths              2
exploration/Average Returns      -13.354
evaluation/num steps total     53500
evaluation/num paths total       535
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0496116
evaluation/Rewards Std             0.0540326
evaluation/Rewards Max            -0.0423539
evaluation/Rewards Min            -0.791596
evaluation/Returns Mean           -4.96116
evaluation/Returns Std             0.254286
evaluation/Returns Max            -4.54649
evaluation/Returns Min            -5.25072
evaluation/Actions Mean            0.00921977
evaluation/Actions Std             0.0816202
evaluation/Actions Max             0.999989
evaluation/Actions Min            -0.120771
evaluation/Num Paths               5
evaluation/Average Returns        -4.96116
time/data storing (s)              0.00121775
time/evaluation sampling (s)       0.0744211
time/exploration sampling (s)      0.0358496
time/logging (s)                   0.00245873
time/saving (s)                    0.0024592
time/training (s)                  0.376591
time/epoch (s)                     0.492997
time/total (s)                    60.8741
Epoch                            106
-----------------------------  ---------------
2019-04-13 16:59:35.146084 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size             21700
trainer/QF1 Loss                   0.0495024
trainer/QF2 Loss                   0.0471939
trainer/Policy Loss                8.8849
trainer/Q1 Predictions Mean       -9.12309
trainer/Q1 Predictions Std         0.809296
trainer/Q1 Predictions Max        -8.74682
trainer/Q1 Predictions Min       -12.1866
trainer/Q2 Predictions Mean       -9.12581
trainer/Q2 Predictions Std         0.801505
trainer/Q2 Predictions Max        -8.73933
trainer/Q2 Predictions Min       -12.1738
trainer/Q Targets Mean            -9.2423
trainer/Q Targets Std              0.776917
trainer/Q Targets Max             -8.73464
trainer/Q Targets Min            -12.2676
trainer/Bellman Errors 1 Mean      0.0495024
trainer/Bellman Errors 1 Std       0.0882526
trainer/Bellman Errors 1 Max       0.458316
trainer/Bellman Errors 1 Min       4.62229e-05
trainer/Bellman Errors 2 Mean      0.0471939
trainer/Bellman Errors 2 Std       0.0788302
trainer/Bellman Errors 2 Max       0.40938
trainer/Bellman Errors 2 Min       3.78607e-05
trainer/Policy Action Mean         0.0475451
trainer/Policy Action Std          0.270992
trainer/Policy Action Max          0.998805
trainer/Policy Action Min         -0.354362
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.133159
exploration/Rewards Std            0.0779035
exploration/Rewards Max           -0.0191283
exploration/Rewards Min           -0.659149
exploration/Returns Mean         -13.3159
exploration/Returns Std            0.0534065
exploration/Returns Max          -13.2624
exploration/Returns Min          -13.3693
exploration/Actions Mean           0.00891698
exploration/Actions Std            0.166547
exploration/Actions Max            1
exploration/Actions Min           -0.391591
exploration/Num Paths              2
exploration/Average Returns      -13.3159
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0323182
evaluation/Rewards Std             0.0280541
evaluation/Rewards Max            -0.0291676
evaluation/Rewards Min            -0.494615
evaluation/Returns Mean           -3.23182
evaluation/Returns Std             0.173744
evaluation/Returns Max            -2.99932
evaluation/Returns Min            -3.47245
evaluation/Actions Mean            0.00807164
evaluation/Actions Std             0.0827333
evaluation/Actions Max             0.999251
evaluation/Actions Min            -0.262099
evaluation/Num Paths               5
evaluation/Average Returns        -3.23182
time/data storing (s)              0.00112523
time/evaluation sampling (s)       0.0736248
time/exploration sampling (s)      0.0334879
time/logging (s)                   0.00255468
time/saving (s)                    0.00251794
time/training (s)                  0.394812
time/epoch (s)                     0.508123
time/total (s)                    61.386
Epoch                            107
-----------------------------  ---------------
2019-04-13 16:59:35.643925 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size             21900
trainer/QF1 Loss                   2.38837
trainer/QF2 Loss                   2.38922
trainer/Policy Loss                8.76756
trainer/Q1 Predictions Mean       -8.89855
trainer/Q1 Predictions Std         0.245291
trainer/Q1 Predictions Max        -8.70218
trainer/Q1 Predictions Min        -9.68051
trainer/Q2 Predictions Mean       -8.89866
trainer/Q2 Predictions Std         0.243405
trainer/Q2 Predictions Max        -8.69193
trainer/Q2 Predictions Min        -9.70375
trainer/Q Targets Mean            -8.79778
trainer/Q Targets Std              1.58722
trainer/Q Targets Max             -0.133799
trainer/Q Targets Min            -10.0541
trainer/Bellman Errors 1 Mean      2.38837
trainer/Bellman Errors 1 Std      12.9805
trainer/Bellman Errors 1 Max      74.6586
trainer/Bellman Errors 1 Min       6.56955e-05
trainer/Bellman Errors 2 Mean      2.38922
trainer/Bellman Errors 2 Std      12.9802
trainer/Bellman Errors 2 Max      74.6573
trainer/Bellman Errors 2 Min       3.89709e-06
trainer/Policy Action Mean        -0.00232654
trainer/Policy Action Std          0.134863
trainer/Policy Action Max          0.394675
trainer/Policy Action Min         -0.310321
exploration/num steps total    21900
exploration/num paths total      219
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132834
exploration/Rewards Std            0.0668959
exploration/Rewards Max           -0.0146565
exploration/Rewards Min           -0.407427
exploration/Returns Mean         -13.2834
exploration/Returns Std            0.693627
exploration/Returns Max          -12.5898
exploration/Returns Min          -13.977
exploration/Actions Mean           0.00222089
exploration/Actions Std            0.135374
exploration/Actions Max            0.644235
exploration/Actions Min           -0.338055
exploration/Num Paths              2
exploration/Average Returns      -13.2834
evaluation/num steps total     54500
evaluation/num paths total       545
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0492445
evaluation/Rewards Std             0.0697062
evaluation/Rewards Max            -0.0315456
evaluation/Rewards Min            -1.10482
evaluation/Returns Mean           -4.92445
evaluation/Returns Std             0.368445
evaluation/Returns Max            -4.35396
evaluation/Returns Min            -5.36839
evaluation/Actions Mean            0.00642592
evaluation/Actions Std             0.0905891
evaluation/Actions Max             0.999997
evaluation/Actions Min            -0.723641
evaluation/Num Paths               5
evaluation/Average Returns        -4.92445
time/data storing (s)              0.00119785
time/evaluation sampling (s)       0.0742769
time/exploration sampling (s)      0.0333409
time/logging (s)                   0.00246315
time/saving (s)                    0.00228499
time/training (s)                  0.379319
time/epoch (s)                     0.492883
time/total (s)                    61.8821
Epoch                            108
-----------------------------  ---------------
2019-04-13 16:59:36.154359 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size             22100
trainer/QF1 Loss                   0.0246775
trainer/QF2 Loss                   0.0277063
trainer/Policy Loss                9.13854
trainer/Q1 Predictions Mean       -9.3085
trainer/Q1 Predictions Std         0.611688
trainer/Q1 Predictions Max        -8.95201
trainer/Q1 Predictions Min       -11.4403
trainer/Q2 Predictions Mean       -9.31892
trainer/Q2 Predictions Std         0.624204
trainer/Q2 Predictions Max        -8.94968
trainer/Q2 Predictions Min       -11.5247
trainer/Q Targets Mean            -9.23769
trainer/Q Targets Std              0.597726
trainer/Q Targets Max             -8.75487
trainer/Q Targets Min            -11.2778
trainer/Bellman Errors 1 Mean      0.0246775
trainer/Bellman Errors 1 Std       0.0287758
trainer/Bellman Errors 1 Max       0.145387
trainer/Bellman Errors 1 Min       8.13097e-08
trainer/Bellman Errors 2 Mean      0.0277063
trainer/Bellman Errors 2 Std       0.0283808
trainer/Bellman Errors 2 Max       0.133959
trainer/Bellman Errors 2 Min       0.000108673
trainer/Policy Action Mean        -0.0295993
trainer/Policy Action Std          0.243366
trainer/Policy Action Max          0.99266
trainer/Policy Action Min         -0.992647
exploration/num steps total    22100
exploration/num paths total      221
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.144031
exploration/Rewards Std            0.0774681
exploration/Rewards Max           -0.0118264
exploration/Rewards Min           -0.384013
exploration/Returns Mean         -14.4031
exploration/Returns Std            0.0781408
exploration/Returns Max          -14.325
exploration/Returns Min          -14.4813
exploration/Actions Mean           0.000545182
exploration/Actions Std            0.148466
exploration/Actions Max            0.833157
exploration/Actions Min           -0.8417
exploration/Num Paths              2
exploration/Average Returns      -14.4031
evaluation/num steps total     55000
evaluation/num paths total       550
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0736101
evaluation/Rewards Std             0.0504724
evaluation/Rewards Max            -0.0621116
evaluation/Rewards Min            -1.01001
evaluation/Returns Mean           -7.36101
evaluation/Returns Std             0.345121
evaluation/Returns Max            -6.99033
evaluation/Returns Min            -7.9356
evaluation/Actions Mean            0.00484576
evaluation/Actions Std             0.0784509
evaluation/Actions Max             0.999994
evaluation/Actions Min            -0.819121
evaluation/Num Paths               5
evaluation/Average Returns        -7.36101
time/data storing (s)              0.00107254
time/evaluation sampling (s)       0.0733755
time/exploration sampling (s)      0.0322694
time/logging (s)                   0.00247411
time/saving (s)                    0.00230597
time/training (s)                  0.393062
time/epoch (s)                     0.50456
time/total (s)                    62.3905
Epoch                            109
-----------------------------  ---------------
2019-04-13 16:59:36.661566 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size             22300
trainer/QF1 Loss                   0.0262483
trainer/QF2 Loss                   0.0252051
trainer/Policy Loss                8.99323
trainer/Q1 Predictions Mean       -9.21482
trainer/Q1 Predictions Std         0.554519
trainer/Q1 Predictions Max        -8.88343
trainer/Q1 Predictions Min       -11.4062
trainer/Q2 Predictions Mean       -9.22254
trainer/Q2 Predictions Std         0.558356
trainer/Q2 Predictions Max        -8.89489
trainer/Q2 Predictions Min       -11.4305
trainer/Q Targets Mean            -9.29002
trainer/Q Targets Std              0.61728
trainer/Q Targets Max             -8.75762
trainer/Q Targets Min            -11.8926
trainer/Bellman Errors 1 Mean      0.0262483
trainer/Bellman Errors 1 Std       0.0433114
trainer/Bellman Errors 1 Max       0.236579
trainer/Bellman Errors 1 Min       5.32259e-07
trainer/Bellman Errors 2 Mean      0.0252051
trainer/Bellman Errors 2 Std       0.0394673
trainer/Bellman Errors 2 Max       0.213529
trainer/Bellman Errors 2 Min       4.89526e-06
trainer/Policy Action Mean         0.0540089
trainer/Policy Action Std          0.271368
trainer/Policy Action Max          0.997293
trainer/Policy Action Min         -0.55401
exploration/num steps total    22300
exploration/num paths total      223
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135559
exploration/Rewards Std            0.0785274
exploration/Rewards Max           -0.0142609
exploration/Rewards Min           -0.684039
exploration/Returns Mean         -13.5559
exploration/Returns Std            0.164907
exploration/Returns Max          -13.391
exploration/Returns Min          -13.7208
exploration/Actions Mean           0.00502069
exploration/Actions Std            0.155971
exploration/Actions Max            0.98289
exploration/Actions Min           -0.498928
exploration/Num Paths              2
exploration/Average Returns      -13.5559
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0580295
evaluation/Rewards Std             0.0388707
evaluation/Rewards Max            -0.0384961
evaluation/Rewards Min            -0.729036
evaluation/Returns Mean           -5.80295
evaluation/Returns Std             0.291105
evaluation/Returns Max            -5.50891
evaluation/Returns Min            -6.21428
evaluation/Actions Mean            0.00451258
evaluation/Actions Std             0.0767894
evaluation/Actions Max             0.999964
evaluation/Actions Min            -0.926839
evaluation/Num Paths               5
evaluation/Average Returns        -5.80295
time/data storing (s)              0.00106593
time/evaluation sampling (s)       0.0742305
time/exploration sampling (s)      0.0327176
time/logging (s)                   0.00255672
time/saving (s)                    0.00227083
time/training (s)                  0.388517
time/epoch (s)                     0.501359
time/total (s)                    62.8957
Epoch                            110
-----------------------------  ---------------
2019-04-13 16:59:37.168016 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size             22500
trainer/QF1 Loss                   2.46362
trainer/QF2 Loss                   2.47697
trainer/Policy Loss                8.86593
trainer/Q1 Predictions Mean       -9.12255
trainer/Q1 Predictions Std         0.731572
trainer/Q1 Predictions Max        -8.83255
trainer/Q1 Predictions Min       -12.425
trainer/Q2 Predictions Mean       -9.11075
trainer/Q2 Predictions Std         0.733349
trainer/Q2 Predictions Max        -8.81232
trainer/Q2 Predictions Min       -12.4564
trainer/Q Targets Mean            -8.99088
trainer/Q Targets Std              1.78163
trainer/Q Targets Max             -0.0720349
trainer/Q Targets Min            -13.0522
trainer/Bellman Errors 1 Mean      2.46362
trainer/Bellman Errors 1 Std      13.404
trainer/Bellman Errors 1 Max      77.0923
trainer/Bellman Errors 1 Min       1.08127e-05
trainer/Bellman Errors 2 Mean      2.47697
trainer/Bellman Errors 2 Std      13.4753
trainer/Bellman Errors 2 Max      77.5031
trainer/Bellman Errors 2 Min       0.000118946
trainer/Policy Action Mean         0.0381959
trainer/Policy Action Std          0.25967
trainer/Policy Action Max          0.999998
trainer/Policy Action Min         -0.989285
exploration/num steps total    22500
exploration/num paths total      225
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.160332
exploration/Rewards Std            0.0858794
exploration/Rewards Max           -0.0119079
exploration/Rewards Min           -0.722755
exploration/Returns Mean         -16.0332
exploration/Returns Std            0.520166
exploration/Returns Max          -15.513
exploration/Returns Min          -16.5534
exploration/Actions Mean           0.00836237
exploration/Actions Std            0.1494
exploration/Actions Max            1
exploration/Actions Min           -0.732083
exploration/Num Paths              2
exploration/Average Returns      -16.0332
evaluation/num steps total     56000
evaluation/num paths total       560
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.102463
evaluation/Rewards Std             0.01783
evaluation/Rewards Max            -0.0643623
evaluation/Rewards Min            -0.496456
evaluation/Returns Mean          -10.2463
evaluation/Returns Std             0.161583
evaluation/Returns Max           -10.1364
evaluation/Returns Min           -10.5656
evaluation/Actions Mean            0.0038555
evaluation/Actions Std             0.066819
evaluation/Actions Max             0.999724
evaluation/Actions Min            -0.936769
evaluation/Num Paths               5
evaluation/Average Returns       -10.2463
time/data storing (s)              0.00111917
time/evaluation sampling (s)       0.0741293
time/exploration sampling (s)      0.0325474
time/logging (s)                   0.00226985
time/saving (s)                    0.00179431
time/training (s)                  0.388388
time/epoch (s)                     0.500248
time/total (s)                    63.3998
Epoch                            111
-----------------------------  ---------------
2019-04-13 16:59:37.671904 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size             22700
trainer/QF1 Loss                   0.0206546
trainer/QF2 Loss                   0.0206635
trainer/Policy Loss                9.13092
trainer/Q1 Predictions Mean       -9.23108
trainer/Q1 Predictions Std         0.101563
trainer/Q1 Predictions Max        -9.09349
trainer/Q1 Predictions Min        -9.47336
trainer/Q2 Predictions Mean       -9.24271
trainer/Q2 Predictions Std         0.0971269
trainer/Q2 Predictions Max        -9.09662
trainer/Q2 Predictions Min        -9.51227
trainer/Q Targets Mean            -9.14628
trainer/Q Targets Std              0.161994
trainer/Q Targets Max             -8.80434
trainer/Q Targets Min             -9.52015
trainer/Bellman Errors 1 Mean      0.0206546
trainer/Bellman Errors 1 Std       0.0258904
trainer/Bellman Errors 1 Max       0.0908886
trainer/Bellman Errors 1 Min       9.35877e-05
trainer/Bellman Errors 2 Mean      0.0206635
trainer/Bellman Errors 2 Std       0.0259522
trainer/Bellman Errors 2 Max       0.0874515
trainer/Bellman Errors 2 Min       2.00564e-06
trainer/Policy Action Mean        -0.0343807
trainer/Policy Action Std          0.137162
trainer/Policy Action Max          0.657755
trainer/Policy Action Min         -0.338894
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.15808
exploration/Rewards Std            0.0917286
exploration/Rewards Max           -0.00582604
exploration/Rewards Min           -0.908017
exploration/Returns Mean         -15.808
exploration/Returns Std            0.0341506
exploration/Returns Max          -15.7739
exploration/Returns Min          -15.8422
exploration/Actions Mean           0.00625358
exploration/Actions Std            0.159421
exploration/Actions Max            1
exploration/Actions Min           -0.667869
exploration/Num Paths              2
exploration/Average Returns      -15.808
evaluation/num steps total     56500
evaluation/num paths total       565
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0772407
evaluation/Rewards Std             0.0221737
evaluation/Rewards Max            -0.0542899
evaluation/Rewards Min            -0.465775
evaluation/Returns Mean           -7.72407
evaluation/Returns Std             0.18642
evaluation/Returns Max            -7.49545
evaluation/Returns Min            -8.00596
evaluation/Actions Mean            0.00334283
evaluation/Actions Std             0.0561452
evaluation/Actions Max             0.998641
evaluation/Actions Min            -0.810549
evaluation/Num Paths               5
evaluation/Average Returns        -7.72407
time/data storing (s)              0.00106548
time/evaluation sampling (s)       0.0742468
time/exploration sampling (s)      0.0324045
time/logging (s)                   0.00229132
time/saving (s)                    0.00179399
time/training (s)                  0.386206
time/epoch (s)                     0.498008
time/total (s)                    63.9013
Epoch                            112
-----------------------------  ---------------
2019-04-13 16:59:38.167645 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size             22900
trainer/QF1 Loss                   0.0454256
trainer/QF2 Loss                   0.0420824
trainer/Policy Loss                9.01015
trainer/Q1 Predictions Mean       -9.12241
trainer/Q1 Predictions Std         0.517797
trainer/Q1 Predictions Max        -8.90904
trainer/Q1 Predictions Min       -11.9035
trainer/Q2 Predictions Mean       -9.13147
trainer/Q2 Predictions Std         0.517073
trainer/Q2 Predictions Max        -8.91049
trainer/Q2 Predictions Min       -11.9133
trainer/Q Targets Mean            -9.2714
trainer/Q Targets Std              0.598047
trainer/Q Targets Max             -8.89053
trainer/Q Targets Min            -12.41
trainer/Bellman Errors 1 Mean      0.0454256
trainer/Bellman Errors 1 Std       0.0700625
trainer/Bellman Errors 1 Max       0.307999
trainer/Bellman Errors 1 Min       2.43098e-05
trainer/Bellman Errors 2 Mean      0.0420824
trainer/Bellman Errors 2 Std       0.0658267
trainer/Bellman Errors 2 Max       0.281828
trainer/Bellman Errors 2 Min       0.000161365
trainer/Policy Action Mean         0.00633061
trainer/Policy Action Std          0.203385
trainer/Policy Action Max          0.994867
trainer/Policy Action Min         -0.307621
exploration/num steps total    22900
exploration/num paths total      229
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134845
exploration/Rewards Std            0.0679141
exploration/Rewards Max           -0.0123187
exploration/Rewards Min           -0.315019
exploration/Returns Mean         -13.4845
exploration/Returns Std            0.22796
exploration/Returns Max          -13.2565
exploration/Returns Min          -13.7124
exploration/Actions Mean           0.00163699
exploration/Actions Std            0.144529
exploration/Actions Max            0.994933
exploration/Actions Min           -0.745169
exploration/Num Paths              2
exploration/Average Returns      -13.4845
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0496104
evaluation/Rewards Std             0.0578353
evaluation/Rewards Max            -0.0448319
evaluation/Rewards Min            -0.985986
evaluation/Returns Mean           -4.96104
evaluation/Returns Std             0.399725
evaluation/Returns Max            -4.5136
evaluation/Returns Min            -5.49063
evaluation/Actions Mean            0.0055588
evaluation/Actions Std             0.0758218
evaluation/Actions Max             0.999998
evaluation/Actions Min            -0.503776
evaluation/Num Paths               5
evaluation/Average Returns        -4.96104
time/data storing (s)              0.00113967
time/evaluation sampling (s)       0.0741449
time/exploration sampling (s)      0.0325698
time/logging (s)                   0.002485
time/saving (s)                    0.00228075
time/training (s)                  0.37849
time/epoch (s)                     0.49111
time/total (s)                    64.3959
Epoch                            113
-----------------------------  ---------------
2019-04-13 16:59:38.674955 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 114 finished
-----------------------------  --------------
replay_buffer/size             23100
trainer/QF1 Loss                   0.0852603
trainer/QF2 Loss                   0.0829032
trainer/Policy Loss                8.98377
trainer/Q1 Predictions Mean       -9.11575
trainer/Q1 Predictions Std         0.603842
trainer/Q1 Predictions Max        -8.81715
trainer/Q1 Predictions Min       -12.2279
trainer/Q2 Predictions Mean       -9.11814
trainer/Q2 Predictions Std         0.600612
trainer/Q2 Predictions Max        -8.83293
trainer/Q2 Predictions Min       -12.1935
trainer/Q Targets Mean            -9.35202
trainer/Q Targets Std              0.524226
trainer/Q Targets Max             -8.99264
trainer/Q Targets Min            -11.8992
trainer/Bellman Errors 1 Mean      0.0852603
trainer/Bellman Errors 1 Std       0.0869555
trainer/Bellman Errors 1 Max       0.334069
trainer/Bellman Errors 1 Min       0.00211359
trainer/Bellman Errors 2 Mean      0.0829032
trainer/Bellman Errors 2 Std       0.0854479
trainer/Bellman Errors 2 Max       0.356505
trainer/Bellman Errors 2 Min       0.00134166
trainer/Policy Action Mean         0.0217546
trainer/Policy Action Std          0.208514
trainer/Policy Action Max          0.996955
trainer/Policy Action Min         -0.304014
exploration/num steps total    23100
exploration/num paths total      231
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.130499
exploration/Rewards Std            0.0885758
exploration/Rewards Max           -0.010629
exploration/Rewards Min           -0.912137
exploration/Returns Mean         -13.0499
exploration/Returns Std            0.429077
exploration/Returns Max          -12.6208
exploration/Returns Min          -13.479
exploration/Actions Mean           0.00195085
exploration/Actions Std            0.158737
exploration/Actions Max            1
exploration/Actions Min           -0.900233
exploration/Num Paths              2
exploration/Average Returns      -13.0499
evaluation/num steps total     57500
evaluation/num paths total       575
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0126054
evaluation/Rewards Std             0.0446417
evaluation/Rewards Max            -0.00400658
evaluation/Rewards Min            -0.762186
evaluation/Returns Mean           -1.26054
evaluation/Returns Std             0.281253
evaluation/Returns Max            -0.936942
evaluation/Returns Min            -1.68934
evaluation/Actions Mean            0.00718916
evaluation/Actions Std             0.0817869
evaluation/Actions Max             0.99997
evaluation/Actions Min            -0.926233
evaluation/Num Paths               5
evaluation/Average Returns        -1.26054
time/data storing (s)              0.00113425
time/evaluation sampling (s)       0.0740727
time/exploration sampling (s)      0.0321337
time/logging (s)                   0.00247603
time/saving (s)                    0.00244211
time/training (s)                  0.389054
time/epoch (s)                     0.501313
time/total (s)                    64.9011
Epoch                            114
-----------------------------  --------------
2019-04-13 16:59:39.181537 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 115 finished
-----------------------------  --------------
replay_buffer/size             23300
trainer/QF1 Loss                   0.0447891
trainer/QF2 Loss                   0.0438782
trainer/Policy Loss                9.09966
trainer/Q1 Predictions Mean       -9.27058
trainer/Q1 Predictions Std         0.336082
trainer/Q1 Predictions Max        -9.08276
trainer/Q1 Predictions Min       -10.5101
trainer/Q2 Predictions Mean       -9.27405
trainer/Q2 Predictions Std         0.332557
trainer/Q2 Predictions Max        -9.08319
trainer/Q2 Predictions Min       -10.5141
trainer/Q Targets Mean            -9.36265
trainer/Q Targets Std              0.417916
trainer/Q Targets Max             -9.01357
trainer/Q Targets Min            -10.8615
trainer/Bellman Errors 1 Mean      0.0447891
trainer/Bellman Errors 1 Std       0.0872431
trainer/Bellman Errors 1 Max       0.346524
trainer/Bellman Errors 1 Min       1.3481e-07
trainer/Bellman Errors 2 Mean      0.0438782
trainer/Bellman Errors 2 Std       0.0830911
trainer/Bellman Errors 2 Max       0.312073
trainer/Bellman Errors 2 Min       3.3422e-05
trainer/Policy Action Mean        -0.0136015
trainer/Policy Action Std          0.193709
trainer/Policy Action Max          0.975275
trainer/Policy Action Min         -0.430515
exploration/num steps total    23300
exploration/num paths total      233
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.12774
exploration/Rewards Std            0.0652161
exploration/Rewards Max           -0.0157124
exploration/Rewards Min           -0.335203
exploration/Returns Mean         -12.774
exploration/Returns Std            0.0638449
exploration/Returns Max          -12.7101
exploration/Returns Min          -12.8378
exploration/Actions Mean           0.00362238
exploration/Actions Std            0.140388
exploration/Actions Max            1
exploration/Actions Min           -0.38241
exploration/Num Paths              2
exploration/Average Returns      -12.774
evaluation/num steps total     58000
evaluation/num paths total       580
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0609231
evaluation/Rewards Std             0.0415014
evaluation/Rewards Max            -0.0571117
evaluation/Rewards Min            -0.88256
evaluation/Returns Mean           -6.09231
evaluation/Returns Std             0.30776
evaluation/Returns Max            -5.80734
evaluation/Returns Min            -6.67984
evaluation/Actions Mean            0.00711451
evaluation/Actions Std             0.0795823
evaluation/Actions Max             0.999985
evaluation/Actions Min            -0.818611
evaluation/Num Paths               5
evaluation/Average Returns        -6.09231
time/data storing (s)              0.00130087
time/evaluation sampling (s)       0.0726852
time/exploration sampling (s)      0.0320455
time/logging (s)                   0.0025358
time/saving (s)                    0.00223535
time/training (s)                  0.390556
time/epoch (s)                     0.501359
time/total (s)                    65.4055
Epoch                            115
-----------------------------  --------------
2019-04-13 16:59:39.683948 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size             23500
trainer/QF1 Loss                   0.0331223
trainer/QF2 Loss                   0.0314821
trainer/Policy Loss                9.235
trainer/Q1 Predictions Mean       -9.44962
trainer/Q1 Predictions Std         0.566995
trainer/Q1 Predictions Max        -9.09961
trainer/Q1 Predictions Min       -11.4476
trainer/Q2 Predictions Mean       -9.45929
trainer/Q2 Predictions Std         0.5713
trainer/Q2 Predictions Max        -9.07956
trainer/Q2 Predictions Min       -11.4861
trainer/Q Targets Mean            -9.56826
trainer/Q Targets Std              0.584517
trainer/Q Targets Max             -9.0619
trainer/Q Targets Min            -11.8152
trainer/Bellman Errors 1 Mean      0.0331223
trainer/Bellman Errors 1 Std       0.0412955
trainer/Bellman Errors 1 Max       0.17774
trainer/Bellman Errors 1 Min       3.07221e-05
trainer/Bellman Errors 2 Mean      0.0314821
trainer/Bellman Errors 2 Std       0.0387813
trainer/Bellman Errors 2 Max       0.178342
trainer/Bellman Errors 2 Min       2.19083e-05
trainer/Policy Action Mean         0.00114305
trainer/Policy Action Std          0.23813
trainer/Policy Action Max          0.994071
trainer/Policy Action Min         -0.9416
exploration/num steps total    23500
exploration/num paths total      235
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134212
exploration/Rewards Std            0.0680148
exploration/Rewards Max           -0.00607216
exploration/Rewards Min           -0.370051
exploration/Returns Mean         -13.4212
exploration/Returns Std            0.631196
exploration/Returns Max          -12.79
exploration/Returns Min          -14.0524
exploration/Actions Mean           0.00508734
exploration/Actions Std            0.136976
exploration/Actions Max            0.712508
exploration/Actions Min           -0.368592
exploration/Num Paths              2
exploration/Average Returns      -13.4212
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0378949
evaluation/Rewards Std             0.0419576
evaluation/Rewards Max            -0.0141469
evaluation/Rewards Min            -0.922223
evaluation/Returns Mean           -3.78949
evaluation/Returns Std             0.362397
evaluation/Returns Max            -3.52737
evaluation/Returns Min            -4.50403
evaluation/Actions Mean            0.004791
evaluation/Actions Std             0.0659854
evaluation/Actions Max             0.999991
evaluation/Actions Min            -0.903372
evaluation/Num Paths               5
evaluation/Average Returns        -3.78949
time/data storing (s)              0.00103896
time/evaluation sampling (s)       0.0787509
time/exploration sampling (s)      0.0330529
time/logging (s)                   0.00245438
time/saving (s)                    0.00224058
time/training (s)                  0.378951
time/epoch (s)                     0.496488
time/total (s)                    65.9057
Epoch                            116
-----------------------------  ---------------
2019-04-13 16:59:40.189714 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 117 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                   0.0287742
trainer/QF2 Loss                   0.029278
trainer/Policy Loss                9.1412
trainer/Q1 Predictions Mean       -9.26124
trainer/Q1 Predictions Std         0.142997
trainer/Q1 Predictions Max        -9.14202
trainer/Q1 Predictions Min        -9.99343
trainer/Q2 Predictions Mean       -9.25743
trainer/Q2 Predictions Std         0.145235
trainer/Q2 Predictions Max        -9.13253
trainer/Q2 Predictions Min       -10.0019
trainer/Q Targets Mean            -9.36935
trainer/Q Targets Std              0.183059
trainer/Q Targets Max             -9.10426
trainer/Q Targets Min             -9.96323
trainer/Bellman Errors 1 Mean      0.0287742
trainer/Bellman Errors 1 Std       0.0519054
trainer/Bellman Errors 1 Max       0.214002
trainer/Bellman Errors 1 Min       7.5398e-05
trainer/Bellman Errors 2 Mean      0.029278
trainer/Bellman Errors 2 Std       0.0530986
trainer/Bellman Errors 2 Max       0.224878
trainer/Bellman Errors 2 Min       8.3886e-06
trainer/Policy Action Mean        -0.0172264
trainer/Policy Action Std          0.0933143
trainer/Policy Action Max          0.224874
trainer/Policy Action Min         -0.321325
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129136
exploration/Rewards Std            0.067849
exploration/Rewards Max           -0.00757265
exploration/Rewards Min           -0.354931
exploration/Returns Mean         -12.9136
exploration/Returns Std            0.868714
exploration/Returns Max          -12.0448
exploration/Returns Min          -13.7823
exploration/Actions Mean           0.00141793
exploration/Actions Std            0.139356
exploration/Actions Max            0.507984
exploration/Actions Min           -1
exploration/Num Paths              2
exploration/Average Returns      -12.9136
evaluation/num steps total     59000
evaluation/num paths total       590
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0417629
evaluation/Rewards Std             0.0550647
evaluation/Rewards Max            -0.0364182
evaluation/Rewards Min            -0.8343
evaluation/Returns Mean           -4.17629
evaluation/Returns Std             0.38319
evaluation/Returns Max            -3.70022
evaluation/Returns Min            -4.611
evaluation/Actions Mean            0.00493755
evaluation/Actions Std             0.0816256
evaluation/Actions Max             0.999965
evaluation/Actions Min            -0.930794
evaluation/Num Paths               5
evaluation/Average Returns        -4.17629
time/data storing (s)              0.00108853
time/evaluation sampling (s)       0.0732696
time/exploration sampling (s)      0.0337416
time/logging (s)                   0.00247789
time/saving (s)                    0.00228925
time/training (s)                  0.386891
time/epoch (s)                     0.499758
time/total (s)                    66.4093
Epoch                            117
-----------------------------  --------------
2019-04-13 16:59:40.700314 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size             23900
trainer/QF1 Loss                   0.0436651
trainer/QF2 Loss                   0.0437027
trainer/Policy Loss                9.16901
trainer/Q1 Predictions Mean       -9.33623
trainer/Q1 Predictions Std         0.46331
trainer/Q1 Predictions Max        -9.07479
trainer/Q1 Predictions Min       -11.6152
trainer/Q2 Predictions Mean       -9.3299
trainer/Q2 Predictions Std         0.455933
trainer/Q2 Predictions Max        -9.06959
trainer/Q2 Predictions Min       -11.5536
trainer/Q Targets Mean            -9.4972
trainer/Q Targets Std              0.510971
trainer/Q Targets Max             -9.04069
trainer/Q Targets Min            -11.7264
trainer/Bellman Errors 1 Mean      0.0436651
trainer/Bellman Errors 1 Std       0.0531699
trainer/Bellman Errors 1 Max       0.22554
trainer/Bellman Errors 1 Min       3.74511e-05
trainer/Bellman Errors 2 Mean      0.0437027
trainer/Bellman Errors 2 Std       0.0489635
trainer/Bellman Errors 2 Max       0.18138
trainer/Bellman Errors 2 Min       1.80817e-06
trainer/Policy Action Mean         0.0391682
trainer/Policy Action Std          0.177166
trainer/Policy Action Max          0.99674
trainer/Policy Action Min         -0.339553
exploration/num steps total    23900
exploration/num paths total      239
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.140547
exploration/Rewards Std            0.105072
exploration/Rewards Max           -0.0116588
exploration/Rewards Min           -1.18774
exploration/Returns Mean         -14.0547
exploration/Returns Std            0.121988
exploration/Returns Max          -13.9327
exploration/Returns Min          -14.1767
exploration/Actions Mean           0.0058745
exploration/Actions Std            0.159265
exploration/Actions Max            1
exploration/Actions Min           -0.543059
exploration/Num Paths              2
exploration/Average Returns      -14.0547
evaluation/num steps total     59500
evaluation/num paths total       595
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0292775
evaluation/Rewards Std             0.0511647
evaluation/Rewards Max            -0.00781325
evaluation/Rewards Min            -0.917055
evaluation/Returns Mean           -2.92775
evaluation/Returns Std             0.42488
evaluation/Returns Max            -2.54172
evaluation/Returns Min            -3.57821
evaluation/Actions Mean            0.00654773
evaluation/Actions Std             0.071784
evaluation/Actions Max             0.999988
evaluation/Actions Min            -0.43096
evaluation/Num Paths               5
evaluation/Average Returns        -2.92775
time/data storing (s)              0.00108344
time/evaluation sampling (s)       0.0745248
time/exploration sampling (s)      0.0323816
time/logging (s)                   0.00248252
time/saving (s)                    0.00223835
time/training (s)                  0.391868
time/epoch (s)                     0.504579
time/total (s)                    66.9177
Epoch                            118
-----------------------------  ---------------
2019-04-13 16:59:41.385297 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size             24100
trainer/QF1 Loss                   0.0767959
trainer/QF2 Loss                   0.0787693
trainer/Policy Loss                9.1458
trainer/Q1 Predictions Mean       -9.21384
trainer/Q1 Predictions Std         0.198514
trainer/Q1 Predictions Max        -9.03849
trainer/Q1 Predictions Min       -10.0525
trainer/Q2 Predictions Mean       -9.20923
trainer/Q2 Predictions Std         0.196349
trainer/Q2 Predictions Max        -9.03144
trainer/Q2 Predictions Min       -10.0386
trainer/Q Targets Mean            -9.45103
trainer/Q Targets Std              0.237223
trainer/Q Targets Max             -9.1633
trainer/Q Targets Min            -10.2593
trainer/Bellman Errors 1 Mean      0.076796
trainer/Bellman Errors 1 Std       0.0752905
trainer/Bellman Errors 1 Max       0.27132
trainer/Bellman Errors 1 Min       0.000299245
trainer/Bellman Errors 2 Mean      0.0787693
trainer/Bellman Errors 2 Std       0.0750867
trainer/Bellman Errors 2 Max       0.270749
trainer/Bellman Errors 2 Min       0.0011706
trainer/Policy Action Mean        -0.0146593
trainer/Policy Action Std          0.129017
trainer/Policy Action Max          0.390573
trainer/Policy Action Min         -0.345525
exploration/num steps total    24100
exploration/num paths total      241
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.133532
exploration/Rewards Std            0.0712298
exploration/Rewards Max           -0.0109772
exploration/Rewards Min           -0.364685
exploration/Returns Mean         -13.3532
exploration/Returns Std            0.435202
exploration/Returns Max          -12.918
exploration/Returns Min          -13.7884
exploration/Actions Mean           0.00316708
exploration/Actions Std            0.155277
exploration/Actions Max            1
exploration/Actions Min           -0.854205
exploration/Num Paths              2
exploration/Average Returns      -13.3532
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0409274
evaluation/Rewards Std             0.0349654
evaluation/Rewards Max            -0.0300521
evaluation/Rewards Min            -0.584228
evaluation/Returns Mean           -4.09274
evaluation/Returns Std             0.275521
evaluation/Returns Max            -3.79832
evaluation/Returns Min            -4.42716
evaluation/Actions Mean            0.00328125
evaluation/Actions Std             0.0611128
evaluation/Actions Max             0.999616
evaluation/Actions Min            -0.813796
evaluation/Num Paths               5
evaluation/Average Returns        -4.09274
time/data storing (s)              0.0010515
time/evaluation sampling (s)       0.0734068
time/exploration sampling (s)      0.0349533
time/logging (s)                   0.00194082
time/saving (s)                    0.00181621
time/training (s)                  0.565204
time/epoch (s)                     0.678373
time/total (s)                    67.6
Epoch                            119
-----------------------------  ---------------
2019-04-13 16:59:42.205895 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size             24300
trainer/QF1 Loss                   0.0424882
trainer/QF2 Loss                   0.0435559
trainer/Policy Loss                9.28468
trainer/Q1 Predictions Mean       -9.35601
trainer/Q1 Predictions Std         0.178473
trainer/Q1 Predictions Max        -9.21082
trainer/Q1 Predictions Min       -10.2633
trainer/Q2 Predictions Mean       -9.34715
trainer/Q2 Predictions Std         0.187825
trainer/Q2 Predictions Max        -9.19701
trainer/Q2 Predictions Min       -10.2869
trainer/Q Targets Mean            -9.48374
trainer/Q Targets Std              0.273655
trainer/Q Targets Max             -9.15008
trainer/Q Targets Min            -10.6969
trainer/Bellman Errors 1 Mean      0.0424882
trainer/Bellman Errors 1 Std       0.0563854
trainer/Bellman Errors 1 Max       0.207312
trainer/Bellman Errors 1 Min       0.000166271
trainer/Bellman Errors 2 Mean      0.0435559
trainer/Bellman Errors 2 Std       0.0581901
trainer/Bellman Errors 2 Max       0.246122
trainer/Bellman Errors 2 Min       9.29614e-05
trainer/Policy Action Mean        -0.0202934
trainer/Policy Action Std          0.106213
trainer/Policy Action Max          0.360444
trainer/Policy Action Min         -0.337771
exploration/num steps total    24300
exploration/num paths total      243
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134411
exploration/Rewards Std            0.0973649
exploration/Rewards Max           -0.0117088
exploration/Rewards Min           -0.930159
exploration/Returns Mean         -13.4411
exploration/Returns Std            0.700736
exploration/Returns Max          -12.7403
exploration/Returns Min          -14.1418
exploration/Actions Mean           0.0106656
exploration/Actions Std            0.152872
exploration/Actions Max            1
exploration/Actions Min           -0.348824
exploration/Num Paths              2
exploration/Average Returns      -13.4411
evaluation/num steps total     60500
evaluation/num paths total       605
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.01625
evaluation/Rewards Std             0.0589436
evaluation/Rewards Max            -0.0103183
evaluation/Rewards Min            -0.7614
evaluation/Returns Mean           -1.625
evaluation/Returns Std             0.283255
evaluation/Returns Max            -1.07612
evaluation/Returns Min            -1.88327
evaluation/Actions Mean            0.00517737
evaluation/Actions Std             0.0822517
evaluation/Actions Max             0.999966
evaluation/Actions Min            -0.879553
evaluation/Num Paths               5
evaluation/Average Returns        -1.625
time/data storing (s)              0.00123041
time/evaluation sampling (s)       0.266308
time/exploration sampling (s)      0.0414713
time/logging (s)                   0.0029673
time/saving (s)                    0.00288866
time/training (s)                  0.500627
time/epoch (s)                     0.815493
time/total (s)                    68.4195
Epoch                            120
-----------------------------  ---------------
2019-04-13 16:59:42.996710 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size             24500
trainer/QF1 Loss                   2.67885
trainer/QF2 Loss                   2.69205
trainer/Policy Loss                9.2902
trainer/Q1 Predictions Mean       -9.6504
trainer/Q1 Predictions Std         0.567303
trainer/Q1 Predictions Max        -9.20773
trainer/Q1 Predictions Min       -11.5696
trainer/Q2 Predictions Mean       -9.64461
trainer/Q2 Predictions Std         0.558589
trainer/Q2 Predictions Max        -9.25027
trainer/Q2 Predictions Min       -11.5455
trainer/Q Targets Mean            -9.50869
trainer/Q Targets Std              1.7903
trainer/Q Targets Max             -0.157484
trainer/Q Targets Min            -11.9961
trainer/Bellman Errors 1 Mean      2.67885
trainer/Bellman Errors 1 Std      14.6338
trainer/Bellman Errors 1 Max      84.1554
trainer/Bellman Errors 1 Min       7.72644e-05
trainer/Bellman Errors 2 Mean      2.69205
trainer/Bellman Errors 2 Std      14.6825
trainer/Bellman Errors 2 Max      84.4398
trainer/Bellman Errors 2 Min       3.93484e-06
trainer/Policy Action Mean         0.0385826
trainer/Policy Action Std          0.252478
trainer/Policy Action Max          0.9956
trainer/Policy Action Min         -0.587966
exploration/num steps total    24500
exploration/num paths total      245
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.142472
exploration/Rewards Std            0.0732915
exploration/Rewards Max           -0.00675926
exploration/Rewards Min           -0.339938
exploration/Returns Mean         -14.2472
exploration/Returns Std            0.507592
exploration/Returns Max          -13.7396
exploration/Returns Min          -14.7547
exploration/Actions Mean           0.00227302
exploration/Actions Std            0.145906
exploration/Actions Max            0.617348
exploration/Actions Min           -0.456893
exploration/Num Paths              2
exploration/Average Returns      -14.2472
evaluation/num steps total     61000
evaluation/num paths total       610
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0511747
evaluation/Rewards Std             0.0414508
evaluation/Rewards Max            -0.0292101
evaluation/Rewards Min            -0.960182
evaluation/Returns Mean           -5.11747
evaluation/Returns Std             0.362655
evaluation/Returns Max            -4.87998
evaluation/Returns Min            -5.83205
evaluation/Actions Mean            0.00577442
evaluation/Actions Std             0.0698264
evaluation/Actions Max             0.999996
evaluation/Actions Min            -0.203833
evaluation/Num Paths               5
evaluation/Average Returns        -5.11747
time/data storing (s)              0.00123352
time/evaluation sampling (s)       0.341093
time/exploration sampling (s)      0.0436744
time/logging (s)                   0.00249904
time/saving (s)                    0.0114359
time/training (s)                  0.383174
time/epoch (s)                     0.783109
time/total (s)                    69.2068
Epoch                            121
-----------------------------  ---------------
2019-04-13 16:59:43.842352 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size             24700
trainer/QF1 Loss                   0.0364744
trainer/QF2 Loss                   0.0352386
trainer/Policy Loss                9.43882
trainer/Q1 Predictions Mean       -9.48933
trainer/Q1 Predictions Std         0.379373
trainer/Q1 Predictions Max        -9.30166
trainer/Q1 Predictions Min       -11.3142
trainer/Q2 Predictions Mean       -9.49851
trainer/Q2 Predictions Std         0.38253
trainer/Q2 Predictions Max        -9.31194
trainer/Q2 Predictions Min       -11.3534
trainer/Q Targets Mean            -9.61458
trainer/Q Targets Std              0.412339
trainer/Q Targets Max             -9.23876
trainer/Q Targets Min            -11.4175
trainer/Bellman Errors 1 Mean      0.0364744
trainer/Bellman Errors 1 Std       0.0789323
trainer/Bellman Errors 1 Max       0.447276
trainer/Bellman Errors 1 Min       2.1837e-05
trainer/Bellman Errors 2 Mean      0.0352386
trainer/Bellman Errors 2 Std       0.0777004
trainer/Bellman Errors 2 Max       0.43368
trainer/Bellman Errors 2 Min       0.000291248
trainer/Policy Action Mean        -0.0048529
trainer/Policy Action Std          0.162561
trainer/Policy Action Max          0.860375
trainer/Policy Action Min         -0.406853
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.140368
exploration/Rewards Std            0.0804359
exploration/Rewards Max           -0.00536655
exploration/Rewards Min           -0.68013
exploration/Returns Mean         -14.0368
exploration/Returns Std            0.696685
exploration/Returns Max          -13.3401
exploration/Returns Min          -14.7335
exploration/Actions Mean           0.00489765
exploration/Actions Std            0.137417
exploration/Actions Max            0.927142
exploration/Actions Min           -0.361263
exploration/Num Paths              2
exploration/Average Returns      -14.0368
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0527458
evaluation/Rewards Std             0.0650342
evaluation/Rewards Max            -0.0214786
evaluation/Rewards Min            -1.04332
evaluation/Returns Mean           -5.27458
evaluation/Returns Std             0.436641
evaluation/Returns Max            -4.75306
evaluation/Returns Min            -5.84908
evaluation/Actions Mean            0.00980495
evaluation/Actions Std             0.0905136
evaluation/Actions Max             0.999996
evaluation/Actions Min            -0.204779
evaluation/Num Paths               5
evaluation/Average Returns        -5.27458
time/data storing (s)              0.00148285
time/evaluation sampling (s)       0.075997
time/exploration sampling (s)      0.0391411
time/logging (s)                   0.00249667
time/saving (s)                    0.00225786
time/training (s)                  0.719199
time/epoch (s)                     0.840574
time/total (s)                    70.0508
Epoch                            122
-----------------------------  ---------------
2019-04-13 16:59:44.573141 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size             24900
trainer/QF1 Loss                   0.0448969
trainer/QF2 Loss                   0.0432308
trainer/Policy Loss                9.40065
trainer/Q1 Predictions Mean       -9.47988
trainer/Q1 Predictions Std         0.190661
trainer/Q1 Predictions Max        -9.32372
trainer/Q1 Predictions Min       -10.2938
trainer/Q2 Predictions Mean       -9.48778
trainer/Q2 Predictions Std         0.182364
trainer/Q2 Predictions Max        -9.35468
trainer/Q2 Predictions Min       -10.2816
trainer/Q Targets Mean            -9.59887
trainer/Q Targets Std              0.261532
trainer/Q Targets Max             -9.30483
trainer/Q Targets Min            -10.3573
trainer/Bellman Errors 1 Mean      0.0448969
trainer/Bellman Errors 1 Std       0.0709795
trainer/Bellman Errors 1 Max       0.339273
trainer/Bellman Errors 1 Min       4.89105e-06
trainer/Bellman Errors 2 Mean      0.0432308
trainer/Bellman Errors 2 Std       0.0670493
trainer/Bellman Errors 2 Max       0.317433
trainer/Bellman Errors 2 Min       5.21874e-05
trainer/Policy Action Mean        -0.014497
trainer/Policy Action Std          0.119061
trainer/Policy Action Max          0.385102
trainer/Policy Action Min         -0.298079
exploration/num steps total    24900
exploration/num paths total      249
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.13294
exploration/Rewards Std            0.0685163
exploration/Rewards Max           -0.0113373
exploration/Rewards Min           -0.352541
exploration/Returns Mean         -13.294
exploration/Returns Std            0.277411
exploration/Returns Max          -13.0166
exploration/Returns Min          -13.5714
exploration/Actions Mean           0.0040565
exploration/Actions Std            0.148466
exploration/Actions Max            1
exploration/Actions Min           -0.755221
exploration/Num Paths              2
exploration/Average Returns      -13.294
evaluation/num steps total     62000
evaluation/num paths total       620
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0458726
evaluation/Rewards Std             0.0608183
evaluation/Rewards Max            -0.0268856
evaluation/Rewards Min            -0.973438
evaluation/Returns Mean           -4.58726
evaluation/Returns Std             0.442698
evaluation/Returns Max            -4.12877
evaluation/Returns Min            -5.13641
evaluation/Actions Mean            0.00883171
evaluation/Actions Std             0.0839655
evaluation/Actions Max             0.999993
evaluation/Actions Min            -0.262447
evaluation/Num Paths               5
evaluation/Average Returns        -4.58726
time/data storing (s)              0.00148471
time/evaluation sampling (s)       0.0788227
time/exploration sampling (s)      0.0344816
time/logging (s)                   0.00249743
time/saving (s)                    0.00229413
time/training (s)                  0.604724
time/epoch (s)                     0.724305
time/total (s)                    70.7793
Epoch                            123
-----------------------------  ---------------
2019-04-13 16:59:45.282430 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size             25100
trainer/QF1 Loss                   2.75022
trainer/QF2 Loss                   2.73523
trainer/Policy Loss                9.22868
trainer/Q1 Predictions Mean       -9.45218
trainer/Q1 Predictions Std         0.489033
trainer/Q1 Predictions Max        -9.25791
trainer/Q1 Predictions Min       -12.1365
trainer/Q2 Predictions Mean       -9.4515
trainer/Q2 Predictions Std         0.497758
trainer/Q2 Predictions Max        -9.2643
trainer/Q2 Predictions Min       -12.1868
trainer/Q Targets Mean            -9.37632
trainer/Q Targets Std              1.74179
trainer/Q Targets Max             -0.0646464
trainer/Q Targets Min            -12.2569
trainer/Bellman Errors 1 Mean      2.75022
trainer/Bellman Errors 1 Std      14.9439
trainer/Bellman Errors 1 Max      85.9534
trainer/Bellman Errors 1 Min       0.000844948
trainer/Bellman Errors 2 Mean      2.73523
trainer/Bellman Errors 2 Std      14.865
trainer/Bellman Errors 2 Max      85.4994
trainer/Bellman Errors 2 Min       0.00176719
trainer/Policy Action Mean        -0.000942267
trainer/Policy Action Std          0.176899
trainer/Policy Action Max          0.997176
trainer/Policy Action Min         -0.191614
exploration/num steps total    25100
exploration/num paths total      251
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132842
exploration/Rewards Std            0.070616
exploration/Rewards Max           -0.00477726
exploration/Rewards Min           -0.365505
exploration/Returns Mean         -13.2842
exploration/Returns Std            0.165938
exploration/Returns Max          -13.1182
exploration/Returns Min          -13.4501
exploration/Actions Mean           0.0054562
exploration/Actions Std            0.152688
exploration/Actions Max            1
exploration/Actions Min           -0.993802
exploration/Num Paths              2
exploration/Average Returns      -13.2842
evaluation/num steps total     62500
evaluation/num paths total       625
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0642415
evaluation/Rewards Std             0.0516355
evaluation/Rewards Max            -0.0594567
evaluation/Rewards Min            -0.831473
evaluation/Returns Mean           -6.42415
evaluation/Returns Std             0.34957
evaluation/Returns Max            -5.98888
evaluation/Returns Min            -6.83778
evaluation/Actions Mean            0.00515275
evaluation/Actions Std             0.0790475
evaluation/Actions Max             0.999969
evaluation/Actions Min            -0.859045
evaluation/Num Paths               5
evaluation/Average Returns        -6.42415
time/data storing (s)              0.00107665
time/evaluation sampling (s)       0.0808943
time/exploration sampling (s)      0.03271
time/logging (s)                   0.00246383
time/saving (s)                    0.00257796
time/training (s)                  0.58306
time/epoch (s)                     0.702783
time/total (s)                    71.4862
Epoch                            124
-----------------------------  ---------------
2019-04-13 16:59:45.798361 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 125 finished
-----------------------------  --------------
replay_buffer/size             25300
trainer/QF1 Loss                   0.07465
trainer/QF2 Loss                   0.080382
trainer/Policy Loss                9.27231
trainer/Q1 Predictions Mean       -9.45415
trainer/Q1 Predictions Std         0.314277
trainer/Q1 Predictions Max        -9.21254
trainer/Q1 Predictions Min       -10.4448
trainer/Q2 Predictions Mean       -9.44439
trainer/Q2 Predictions Std         0.306857
trainer/Q2 Predictions Max        -9.20744
trainer/Q2 Predictions Min       -10.3997
trainer/Q Targets Mean            -9.69764
trainer/Q Targets Std              0.341745
trainer/Q Targets Max             -9.35655
trainer/Q Targets Min            -10.8732
trainer/Bellman Errors 1 Mean      0.07465
trainer/Bellman Errors 1 Std       0.0753282
trainer/Bellman Errors 1 Max       0.350335
trainer/Bellman Errors 1 Min       0.00616207
trainer/Bellman Errors 2 Mean      0.080382
trainer/Bellman Errors 2 Std       0.0809545
trainer/Bellman Errors 2 Max       0.370164
trainer/Bellman Errors 2 Min       0.00785303
trainer/Policy Action Mean         0.0138637
trainer/Policy Action Std          0.167527
trainer/Policy Action Max          0.480078
trainer/Policy Action Min         -0.384172
exploration/num steps total    25300
exploration/num paths total      253
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.158802
exploration/Rewards Std            0.0823444
exploration/Rewards Max           -0.0227165
exploration/Rewards Min           -0.46811
exploration/Returns Mean         -15.8802
exploration/Returns Std            0.0834875
exploration/Returns Max          -15.7968
exploration/Returns Min          -15.9637
exploration/Actions Mean           0.00177186
exploration/Actions Std            0.149115
exploration/Actions Max            0.857445
exploration/Actions Min           -0.661048
exploration/Num Paths              2
exploration/Average Returns      -15.8802
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.099075
evaluation/Rewards Std             0.040295
evaluation/Rewards Max            -0.0889873
evaluation/Rewards Min            -0.716455
evaluation/Returns Mean           -9.9075
evaluation/Returns Std             0.259065
evaluation/Returns Max            -9.58449
evaluation/Returns Min           -10.207
evaluation/Actions Mean            0.00566331
evaluation/Actions Std             0.0822084
evaluation/Actions Max             0.999887
evaluation/Actions Min            -0.882131
evaluation/Num Paths               5
evaluation/Average Returns        -9.9075
time/data storing (s)              0.00111975
time/evaluation sampling (s)       0.0727414
time/exploration sampling (s)      0.0331656
time/logging (s)                   0.00247822
time/saving (s)                    0.00227112
time/training (s)                  0.397797
time/epoch (s)                     0.509573
time/total (s)                    72
Epoch                            125
-----------------------------  --------------
2019-04-13 16:59:46.352728 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size             25500
trainer/QF1 Loss                   0.0257553
trainer/QF2 Loss                   0.0287032
trainer/Policy Loss                9.57509
trainer/Q1 Predictions Mean       -9.80047
trainer/Q1 Predictions Std         0.947404
trainer/Q1 Predictions Max        -9.35045
trainer/Q1 Predictions Min       -12.9717
trainer/Q2 Predictions Mean       -9.78807
trainer/Q2 Predictions Std         0.937519
trainer/Q2 Predictions Max        -9.34318
trainer/Q2 Predictions Min       -12.8998
trainer/Q Targets Mean            -9.88547
trainer/Q Targets Std              0.908849
trainer/Q Targets Max             -9.37652
trainer/Q Targets Min            -13.1257
trainer/Bellman Errors 1 Mean      0.0257553
trainer/Bellman Errors 1 Std       0.0464895
trainer/Bellman Errors 1 Max       0.248058
trainer/Bellman Errors 1 Min       7.105e-06
trainer/Bellman Errors 2 Mean      0.0287032
trainer/Bellman Errors 2 Std       0.0493152
trainer/Bellman Errors 2 Max       0.266682
trainer/Bellman Errors 2 Min       1.80817e-06
trainer/Policy Action Mean         0.0535691
trainer/Policy Action Std          0.298394
trainer/Policy Action Max          0.999323
trainer/Policy Action Min         -0.34556
exploration/num steps total    25500
exploration/num paths total      255
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.13869
exploration/Rewards Std            0.0829554
exploration/Rewards Max           -0.00439406
exploration/Rewards Min           -0.732348
exploration/Returns Mean         -13.869
exploration/Returns Std            0.0962478
exploration/Returns Max          -13.7728
exploration/Returns Min          -13.9653
exploration/Actions Mean           0.00644889
exploration/Actions Std            0.168043
exploration/Actions Max            1
exploration/Actions Min           -0.424638
exploration/Num Paths              2
exploration/Average Returns      -13.869
evaluation/num steps total     63500
evaluation/num paths total       635
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0324588
evaluation/Rewards Std             0.0294364
evaluation/Rewards Max            -0.0245681
evaluation/Rewards Min            -0.68111
evaluation/Returns Mean           -3.24588
evaluation/Returns Std             0.251294
evaluation/Returns Max            -3.09945
evaluation/Returns Min            -3.74656
evaluation/Actions Mean            0.00446435
evaluation/Actions Std             0.0689498
evaluation/Actions Max             0.999916
evaluation/Actions Min            -0.683565
evaluation/Num Paths               5
evaluation/Average Returns        -3.24588
time/data storing (s)              0.00110121
time/evaluation sampling (s)       0.0730487
time/exploration sampling (s)      0.0326569
time/logging (s)                   0.00538149
time/saving (s)                    0.00246444
time/training (s)                  0.436192
time/epoch (s)                     0.550845
time/total (s)                    72.555
Epoch                            126
-----------------------------  ---------------
2019-04-13 16:59:46.867581 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 127 finished
-----------------------------  --------------
replay_buffer/size             25700
trainer/QF1 Loss                   2.75692
trainer/QF2 Loss                   2.75355
trainer/Policy Loss                9.31686
trainer/Q1 Predictions Mean       -9.45122
trainer/Q1 Predictions Std         0.429948
trainer/Q1 Predictions Max        -9.22369
trainer/Q1 Predictions Min       -11.5413
trainer/Q2 Predictions Mean       -9.4441
trainer/Q2 Predictions Std         0.431169
trainer/Q2 Predictions Max        -9.1972
trainer/Q2 Predictions Min       -11.5126
trainer/Q Targets Mean            -9.44039
trainer/Q Targets Std              1.72699
trainer/Q Targets Max             -0.0751176
trainer/Q Targets Min            -11.5902
trainer/Bellman Errors 1 Mean      2.75692
trainer/Bellman Errors 1 Std      14.8051
trainer/Bellman Errors 1 Max      85.1867
trainer/Bellman Errors 1 Min       0.00238978
trainer/Bellman Errors 2 Mean      2.75355
trainer/Bellman Errors 2 Std      14.7553
trainer/Bellman Errors 2 Max      84.9062
trainer/Bellman Errors 2 Min       0.00601666
trainer/Policy Action Mean         0.03623
trainer/Policy Action Std          0.217588
trainer/Policy Action Max          0.999341
trainer/Policy Action Min         -0.350622
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.127478
exploration/Rewards Std            0.075674
exploration/Rewards Max           -0.0055145
exploration/Rewards Min           -0.584167
exploration/Returns Mean         -12.7478
exploration/Returns Std            0.113923
exploration/Returns Max          -12.6339
exploration/Returns Min          -12.8617
exploration/Actions Mean           0.0048252
exploration/Actions Std            0.147641
exploration/Actions Max            1
exploration/Actions Min           -0.438814
exploration/Num Paths              2
exploration/Average Returns      -12.7478
evaluation/num steps total     64000
evaluation/num paths total       640
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0236396
evaluation/Rewards Std             0.0187702
evaluation/Rewards Max            -0.019041
evaluation/Rewards Min            -0.411552
evaluation/Returns Mean           -2.36396
evaluation/Returns Std             0.138689
evaluation/Returns Max            -2.27019
evaluation/Returns Min            -2.63777
evaluation/Actions Mean            0.00415252
evaluation/Actions Std             0.0642745
evaluation/Actions Max             0.999069
evaluation/Actions Min            -0.587178
evaluation/Num Paths               5
evaluation/Average Returns        -2.36396
time/data storing (s)              0.00105899
time/evaluation sampling (s)       0.0878322
time/exploration sampling (s)      0.0338103
time/logging (s)                   0.00249597
time/saving (s)                    0.00227093
time/training (s)                  0.376658
time/epoch (s)                     0.504127
time/total (s)                    73.0642
Epoch                            127
-----------------------------  --------------
2019-04-13 16:59:47.381255 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size             25900
trainer/QF1 Loss                   0.0688744
trainer/QF2 Loss                   0.0671336
trainer/Policy Loss                9.43505
trainer/Q1 Predictions Mean       -9.50028
trainer/Q1 Predictions Std         0.108442
trainer/Q1 Predictions Max        -9.34465
trainer/Q1 Predictions Min        -9.80389
trainer/Q2 Predictions Mean       -9.50096
trainer/Q2 Predictions Std         0.0989724
trainer/Q2 Predictions Max        -9.3579
trainer/Q2 Predictions Min        -9.79544
trainer/Q Targets Mean            -9.69275
trainer/Q Targets Std              0.195373
trainer/Q Targets Max             -9.42074
trainer/Q Targets Min            -10.1799
trainer/Bellman Errors 1 Mean      0.0688744
trainer/Bellman Errors 1 Std       0.106118
trainer/Bellman Errors 1 Max       0.528359
trainer/Bellman Errors 1 Min       0.0005658
trainer/Bellman Errors 2 Mean      0.0671336
trainer/Bellman Errors 2 Std       0.104936
trainer/Bellman Errors 2 Max       0.516824
trainer/Bellman Errors 2 Min       0.000795195
trainer/Policy Action Mean        -0.000635114
trainer/Policy Action Std          0.127117
trainer/Policy Action Max          0.369398
trainer/Policy Action Min         -0.236162
exploration/num steps total    25900
exploration/num paths total      259
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131172
exploration/Rewards Std            0.0675318
exploration/Rewards Max           -0.00505246
exploration/Rewards Min           -0.368305
exploration/Returns Mean         -13.1172
exploration/Returns Std            0.755934
exploration/Returns Max          -12.3612
exploration/Returns Min          -13.8731
exploration/Actions Mean          -0.000974946
exploration/Actions Std            0.163623
exploration/Actions Max            0.938173
exploration/Actions Min           -0.945026
exploration/Num Paths              2
exploration/Average Returns      -13.1172
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0557724
evaluation/Rewards Std             0.0288654
evaluation/Rewards Max            -0.0483049
evaluation/Rewards Min            -0.648148
evaluation/Returns Mean           -5.57724
evaluation/Returns Std             0.218819
evaluation/Returns Max            -5.41925
evaluation/Returns Min            -5.98726
evaluation/Actions Mean            0.00345157
evaluation/Actions Std             0.0752058
evaluation/Actions Max             0.999928
evaluation/Actions Min            -0.84536
evaluation/Num Paths               5
evaluation/Average Returns        -5.57724
time/data storing (s)              0.00114478
time/evaluation sampling (s)       0.0748007
time/exploration sampling (s)      0.0341907
time/logging (s)                   0.00189685
time/saving (s)                    0.00242436
time/training (s)                  0.392588
time/epoch (s)                     0.507046
time/total (s)                    73.575
Epoch                            128
-----------------------------  ---------------
2019-04-13 16:59:47.891135 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size             26100
trainer/QF1 Loss                   5.67373
trainer/QF2 Loss                   5.6916
trainer/Policy Loss                9.5908
trainer/Q1 Predictions Mean       -9.82955
trainer/Q1 Predictions Std         0.79801
trainer/Q1 Predictions Max        -9.52154
trainer/Q1 Predictions Min       -12.9681
trainer/Q2 Predictions Mean       -9.82577
trainer/Q2 Predictions Std         0.790931
trainer/Q2 Predictions Max        -9.52471
trainer/Q2 Predictions Min       -12.9902
trainer/Q Targets Mean            -9.37261
trainer/Q Targets Std              2.53452
trainer/Q Targets Max             -0.0929272
trainer/Q Targets Min            -13.3322
trainer/Bellman Errors 1 Mean      5.67373
trainer/Bellman Errors 1 Std      21.8186
trainer/Bellman Errors 1 Max      90.5027
trainer/Bellman Errors 1 Min       4.30248e-06
trainer/Bellman Errors 2 Mean      5.6916
trainer/Bellman Errors 2 Std      21.8786
trainer/Bellman Errors 2 Max      90.8176
trainer/Bellman Errors 2 Min       0.000375348
trainer/Policy Action Mean         0.0503478
trainer/Policy Action Std          0.262118
trainer/Policy Action Max          0.999219
trainer/Policy Action Min         -0.198756
exploration/num steps total    26100
exploration/num paths total      261
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.1329
exploration/Rewards Std            0.0796818
exploration/Rewards Max           -0.00582795
exploration/Rewards Min           -0.844913
exploration/Returns Mean         -13.29
exploration/Returns Std            0.234229
exploration/Returns Max          -13.0558
exploration/Returns Min          -13.5242
exploration/Actions Mean           0.0103189
exploration/Actions Std            0.163837
exploration/Actions Max            1
exploration/Actions Min           -0.361826
exploration/Num Paths              2
exploration/Average Returns      -13.29
evaluation/num steps total     65000
evaluation/num paths total       650
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0379435
evaluation/Rewards Std             0.0433172
evaluation/Rewards Max            -0.0109409
evaluation/Rewards Min            -0.89784
evaluation/Returns Mean           -3.79435
evaluation/Returns Std             0.340668
evaluation/Returns Max            -3.49283
evaluation/Returns Min            -4.39212
evaluation/Actions Mean            0.0037671
evaluation/Actions Std             0.080353
evaluation/Actions Max             0.999997
evaluation/Actions Min            -0.908922
evaluation/Num Paths               5
evaluation/Average Returns        -3.79435
time/data storing (s)              0.00111721
time/evaluation sampling (s)       0.0746989
time/exploration sampling (s)      0.0338119
time/logging (s)                   0.00250332
time/saving (s)                    0.00237085
time/training (s)                  0.389845
time/epoch (s)                     0.504347
time/total (s)                    74.0834
Epoch                            129
-----------------------------  ---------------
2019-04-13 16:59:48.632437 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 130 finished
-----------------------------  --------------
replay_buffer/size             26300
trainer/QF1 Loss                   0.300694
trainer/QF2 Loss                   0.304269
trainer/Policy Loss                9.31789
trainer/Q1 Predictions Mean       -9.55361
trainer/Q1 Predictions Std         0.792931
trainer/Q1 Predictions Max        -9.18747
trainer/Q1 Predictions Min       -12.0481
trainer/Q2 Predictions Mean       -9.55093
trainer/Q2 Predictions Std         0.811598
trainer/Q2 Predictions Max        -9.18313
trainer/Q2 Predictions Min       -12.126
trainer/Q Targets Mean           -10.0784
trainer/Q Targets Std              0.807674
trainer/Q Targets Max             -9.52302
trainer/Q Targets Min            -12.7754
trainer/Bellman Errors 1 Mean      0.300694
trainer/Bellman Errors 1 Std       0.172755
trainer/Bellman Errors 1 Max       0.839993
trainer/Bellman Errors 1 Min       0.0448651
trainer/Bellman Errors 2 Mean      0.304269
trainer/Bellman Errors 2 Std       0.176557
trainer/Bellman Errors 2 Max       0.867926
trainer/Bellman Errors 2 Min       0.0503209
trainer/Policy Action Mean         0.0492654
trainer/Policy Action Std          0.266456
trainer/Policy Action Max          0.997495
trainer/Policy Action Min         -0.282454
exploration/num steps total    26300
exploration/num paths total      263
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.130004
exploration/Rewards Std            0.0871323
exploration/Rewards Max           -0.00133419
exploration/Rewards Min           -0.974742
exploration/Returns Mean         -13.0004
exploration/Returns Std            0.334738
exploration/Returns Max          -12.6657
exploration/Returns Min          -13.3351
exploration/Actions Mean           0.00859644
exploration/Actions Std            0.158688
exploration/Actions Max            1
exploration/Actions Min           -0.408197
exploration/Num Paths              2
exploration/Average Returns      -13.0004
evaluation/num steps total     65500
evaluation/num paths total       655
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0107184
evaluation/Rewards Std             0.0439172
evaluation/Rewards Max            -0.00365279
evaluation/Rewards Min            -0.895472
evaluation/Returns Mean           -1.07184
evaluation/Returns Std             0.312618
evaluation/Returns Max            -0.837172
evaluation/Returns Min            -1.65471
evaluation/Actions Mean            0.00698068
evaluation/Actions Std             0.0724851
evaluation/Actions Max             0.999994
evaluation/Actions Min            -0.227806
evaluation/Num Paths               5
evaluation/Average Returns        -1.07184
time/data storing (s)              0.00107941
time/evaluation sampling (s)       0.0731807
time/exploration sampling (s)      0.0335697
time/logging (s)                   0.00236799
time/saving (s)                    0.00196932
time/training (s)                  0.62253
time/epoch (s)                     0.734697
time/total (s)                    74.8222
Epoch                            130
-----------------------------  --------------
2019-04-13 16:59:49.139135 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size             26500
trainer/QF1 Loss                   0.0538303
trainer/QF2 Loss                   0.0541113
trainer/Policy Loss                9.58733
trainer/Q1 Predictions Mean       -9.67893
trainer/Q1 Predictions Std         0.198358
trainer/Q1 Predictions Max        -9.52016
trainer/Q1 Predictions Min       -10.6839
trainer/Q2 Predictions Mean       -9.68439
trainer/Q2 Predictions Std         0.206908
trainer/Q2 Predictions Max        -9.54167
trainer/Q2 Predictions Min       -10.7546
trainer/Q Targets Mean            -9.83743
trainer/Q Targets Std              0.217781
trainer/Q Targets Max             -9.57392
trainer/Q Targets Min            -10.5338
trainer/Bellman Errors 1 Mean      0.0538303
trainer/Bellman Errors 1 Std       0.0728412
trainer/Bellman Errors 1 Max       0.313528
trainer/Bellman Errors 1 Min       1.81969e-05
trainer/Bellman Errors 2 Mean      0.0541113
trainer/Bellman Errors 2 Std       0.0770959
trainer/Bellman Errors 2 Max       0.352238
trainer/Bellman Errors 2 Min       7.4289e-06
trainer/Policy Action Mean        -0.00841271
trainer/Policy Action Std          0.121581
trainer/Policy Action Max          0.285352
trainer/Policy Action Min         -0.315239
exploration/num steps total    26500
exploration/num paths total      265
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.140274
exploration/Rewards Std            0.0760409
exploration/Rewards Max           -0.0126955
exploration/Rewards Min           -0.74598
exploration/Returns Mean         -14.0274
exploration/Returns Std            0.436825
exploration/Returns Max          -13.5906
exploration/Returns Min          -14.4642
exploration/Actions Mean           0.00439173
exploration/Actions Std            0.154255
exploration/Actions Max            1
exploration/Actions Min           -0.393259
exploration/Num Paths              2
exploration/Average Returns      -14.0274
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0559931
evaluation/Rewards Std             0.0442301
evaluation/Rewards Max            -0.051979
evaluation/Rewards Min            -0.983697
evaluation/Returns Mean           -5.59931
evaluation/Returns Std             0.360489
evaluation/Returns Max            -5.36552
evaluation/Returns Min            -6.31523
evaluation/Actions Mean            0.00621097
evaluation/Actions Std             0.0871857
evaluation/Actions Max             0.999999
evaluation/Actions Min            -0.947353
evaluation/Num Paths               5
evaluation/Average Returns        -5.59931
time/data storing (s)              0.00109435
time/evaluation sampling (s)       0.0802635
time/exploration sampling (s)      0.0340928
time/logging (s)                   0.00256138
time/saving (s)                    0.0019085
time/training (s)                  0.380461
time/epoch (s)                     0.500382
time/total (s)                    75.3282
Epoch                            131
-----------------------------  ---------------
2019-04-13 16:59:50.172129 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size             26700
trainer/QF1 Loss                   2.89271
trainer/QF2 Loss                   2.91293
trainer/Policy Loss                9.79875
trainer/Q1 Predictions Mean       -9.93941
trainer/Q1 Predictions Std         0.393018
trainer/Q1 Predictions Max        -9.63611
trainer/Q1 Predictions Min       -10.9364
trainer/Q2 Predictions Mean       -9.93482
trainer/Q2 Predictions Std         0.386178
trainer/Q2 Predictions Max        -9.65735
trainer/Q2 Predictions Min       -10.9157
trainer/Q Targets Mean            -9.69925
trainer/Q Targets Std              1.75795
trainer/Q Targets Max             -0.19301
trainer/Q Targets Min            -11.0032
trainer/Bellman Errors 1 Mean      2.89271
trainer/Bellman Errors 1 Std      15.9522
trainer/Bellman Errors 1 Max      91.7108
trainer/Bellman Errors 1 Min       2.01678e-05
trainer/Bellman Errors 2 Mean      2.91293
trainer/Bellman Errors 2 Std      16.045
trainer/Bellman Errors 2 Max      92.2472
trainer/Bellman Errors 2 Min       1.50583e-05
trainer/Policy Action Mean         0.0119518
trainer/Policy Action Std          0.173617
trainer/Policy Action Max          0.501155
trainer/Policy Action Min         -0.338645
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.13185
exploration/Rewards Std            0.0796118
exploration/Rewards Max           -0.00529621
exploration/Rewards Min           -0.363619
exploration/Returns Mean         -13.185
exploration/Returns Std            0.546341
exploration/Returns Max          -12.6387
exploration/Returns Min          -13.7314
exploration/Actions Mean           0.000197958
exploration/Actions Std            0.15118
exploration/Actions Max            0.53043
exploration/Actions Min           -0.849467
exploration/Num Paths              2
exploration/Average Returns      -13.185
evaluation/num steps total     66500
evaluation/num paths total       665
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0607929
evaluation/Rewards Std             0.0484106
evaluation/Rewards Max            -0.0569007
evaluation/Rewards Min            -0.807785
evaluation/Returns Mean           -6.07929
evaluation/Returns Std             0.318054
evaluation/Returns Max            -5.74466
evaluation/Returns Min            -6.46932
evaluation/Actions Mean            0.00479746
evaluation/Actions Std             0.0927216
evaluation/Actions Max             0.99999
evaluation/Actions Min            -0.955226
evaluation/Num Paths               5
evaluation/Average Returns        -6.07929
time/data storing (s)              0.0011649
time/evaluation sampling (s)       0.0776824
time/exploration sampling (s)      0.0380954
time/logging (s)                   0.00889021
time/saving (s)                    0.0106779
time/training (s)                  0.893417
time/epoch (s)                     1.02993
time/total (s)                    76.3619
Epoch                            132
-----------------------------  ---------------
2019-04-13 16:59:50.959029 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size             26900
trainer/QF1 Loss                   2.90707
trainer/QF2 Loss                   2.88781
trainer/Policy Loss                9.63821
trainer/Q1 Predictions Mean       -9.81497
trainer/Q1 Predictions Std         0.317641
trainer/Q1 Predictions Max        -9.63014
trainer/Q1 Predictions Min       -10.9622
trainer/Q2 Predictions Mean       -9.80245
trainer/Q2 Predictions Std         0.326996
trainer/Q2 Predictions Max        -9.59992
trainer/Q2 Predictions Min       -11.0592
trainer/Q Targets Mean            -9.611
trainer/Q Targets Std              1.76217
trainer/Q Targets Max             -0.0797899
trainer/Q Targets Min            -11.5568
trainer/Bellman Errors 1 Mean      2.90707
trainer/Bellman Errors 1 Std      16.0101
trainer/Bellman Errors 1 Max      92.0468
trainer/Bellman Errors 1 Min       3.63798e-10
trainer/Bellman Errors 2 Mean      2.88781
trainer/Bellman Errors 2 Std      15.8981
trainer/Bellman Errors 2 Max      91.4045
trainer/Bellman Errors 2 Min       0.000433776
trainer/Policy Action Mean         0.00532612
trainer/Policy Action Std          0.18416
trainer/Policy Action Max          0.821149
trainer/Policy Action Min         -0.408046
exploration/num steps total    26900
exploration/num paths total      269
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132563
exploration/Rewards Std            0.0814973
exploration/Rewards Max           -0.00967982
exploration/Rewards Min           -0.720899
exploration/Returns Mean         -13.2563
exploration/Returns Std            0.904051
exploration/Returns Max          -12.3522
exploration/Returns Min          -14.1603
exploration/Actions Mean           0.00626499
exploration/Actions Std            0.155779
exploration/Actions Max            1
exploration/Actions Min           -0.348405
exploration/Num Paths              2
exploration/Average Returns      -13.2563
evaluation/num steps total     67000
evaluation/num paths total       670
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0436238
evaluation/Rewards Std             0.00394414
evaluation/Rewards Max            -0.0408778
evaluation/Rewards Min            -0.127842
evaluation/Returns Mean           -4.36238
evaluation/Returns Std             0.0285879
evaluation/Returns Max            -4.34552
evaluation/Returns Min            -4.41943
evaluation/Actions Mean            0.00608355
evaluation/Actions Std             0.0630748
evaluation/Actions Max             0.935122
evaluation/Actions Min            -0.000984139
evaluation/Num Paths               5
evaluation/Average Returns        -4.36238
time/data storing (s)              0.00301158
time/evaluation sampling (s)       0.222298
time/exploration sampling (s)      0.0960905
time/logging (s)                   0.00247759
time/saving (s)                    0.00229296
time/training (s)                  0.439682
time/epoch (s)                     0.765853
time/total (s)                    77.1391
Epoch                            133
-----------------------------  ---------------
2019-04-13 16:59:51.609991 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size             27100
trainer/QF1 Loss                   0.0458404
trainer/QF2 Loss                   0.0468698
trainer/Policy Loss                9.81104
trainer/Q1 Predictions Mean       -9.91924
trainer/Q1 Predictions Std         0.395442
trainer/Q1 Predictions Max        -9.62417
trainer/Q1 Predictions Min       -11.2972
trainer/Q2 Predictions Mean       -9.9336
trainer/Q2 Predictions Std         0.407312
trainer/Q2 Predictions Max        -9.65481
trainer/Q2 Predictions Min       -11.4126
trainer/Q Targets Mean           -10.0264
trainer/Q Targets Std              0.360987
trainer/Q Targets Max             -9.56389
trainer/Q Targets Min            -11.1324
trainer/Bellman Errors 1 Mean      0.0458404
trainer/Bellman Errors 1 Std       0.0619216
trainer/Bellman Errors 1 Max       0.225791
trainer/Bellman Errors 1 Min       1.63274e-05
trainer/Bellman Errors 2 Mean      0.0468699
trainer/Bellman Errors 2 Std       0.0600673
trainer/Bellman Errors 2 Max       0.220287
trainer/Bellman Errors 2 Min       0.000139461
trainer/Policy Action Mean        -0.00460914
trainer/Policy Action Std          0.195741
trainer/Policy Action Max          0.802461
trainer/Policy Action Min         -0.457432
exploration/num steps total    27100
exploration/num paths total      271
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134662
exploration/Rewards Std            0.0738555
exploration/Rewards Max           -0.00385043
exploration/Rewards Min           -0.403023
exploration/Returns Mean         -13.4662
exploration/Returns Std            0.777868
exploration/Returns Max          -12.6883
exploration/Returns Min          -14.2441
exploration/Actions Mean           0.00737726
exploration/Actions Std            0.161689
exploration/Actions Max            1
exploration/Actions Min           -0.446438
exploration/Num Paths              2
exploration/Average Returns      -13.4662
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0403399
evaluation/Rewards Std             0.0145412
evaluation/Rewards Max            -0.0309092
evaluation/Rewards Min            -0.339437
evaluation/Returns Mean           -4.03399
evaluation/Returns Std             0.120503
evaluation/Returns Max            -3.92657
evaluation/Returns Min            -4.25881
evaluation/Actions Mean            0.00435209
evaluation/Actions Std             0.0581339
evaluation/Actions Max             0.998483
evaluation/Actions Min            -0.40476
evaluation/Num Paths               5
evaluation/Average Returns        -4.03399
time/data storing (s)              0.00110951
time/evaluation sampling (s)       0.0889921
time/exploration sampling (s)      0.0345262
time/logging (s)                   0.00248238
time/saving (s)                    0.00233226
time/training (s)                  0.514961
time/epoch (s)                     0.644403
time/total (s)                    77.7877
Epoch                            134
-----------------------------  ---------------
2019-04-13 16:59:52.240602 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size             27300
trainer/QF1 Loss                   0.0366088
trainer/QF2 Loss                   0.0371863
trainer/Policy Loss                9.65671
trainer/Q1 Predictions Mean       -9.89163
trainer/Q1 Predictions Std         0.533949
trainer/Q1 Predictions Max        -9.63736
trainer/Q1 Predictions Min       -12.4188
trainer/Q2 Predictions Mean       -9.89926
trainer/Q2 Predictions Std         0.543036
trainer/Q2 Predictions Max        -9.61669
trainer/Q2 Predictions Min       -12.4898
trainer/Q Targets Mean           -10.0226
trainer/Q Targets Std              0.500046
trainer/Q Targets Max             -9.65477
trainer/Q Targets Min            -12.2352
trainer/Bellman Errors 1 Mean      0.0366088
trainer/Bellman Errors 1 Std       0.0469364
trainer/Bellman Errors 1 Max       0.17549
trainer/Bellman Errors 1 Min       0.000144712
trainer/Bellman Errors 2 Mean      0.0371863
trainer/Bellman Errors 2 Std       0.0489799
trainer/Bellman Errors 2 Max       0.197218
trainer/Bellman Errors 2 Min       5.7071e-06
trainer/Policy Action Mean         0.0047041
trainer/Policy Action Std          0.180426
trainer/Policy Action Max          0.997913
trainer/Policy Action Min         -0.398092
exploration/num steps total    27300
exploration/num paths total      273
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.141085
exploration/Rewards Std            0.0978093
exploration/Rewards Max           -0.0123076
exploration/Rewards Min           -0.862675
exploration/Returns Mean         -14.1085
exploration/Returns Std            0.0207595
exploration/Returns Max          -14.0878
exploration/Returns Min          -14.1293
exploration/Actions Mean           0.00922183
exploration/Actions Std            0.165003
exploration/Actions Max            1
exploration/Actions Min           -0.399673
exploration/Num Paths              2
exploration/Average Returns      -14.1085
evaluation/num steps total     68000
evaluation/num paths total       680
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0502183
evaluation/Rewards Std             0.0661816
evaluation/Rewards Max            -0.0183659
evaluation/Rewards Min            -0.956566
evaluation/Returns Mean           -5.02183
evaluation/Returns Std             0.404505
evaluation/Returns Max            -4.52341
evaluation/Returns Min            -5.39693
evaluation/Actions Mean            0.00716743
evaluation/Actions Std             0.0943927
evaluation/Actions Max             0.999996
evaluation/Actions Min            -0.853202
evaluation/Num Paths               5
evaluation/Average Returns        -5.02183
time/data storing (s)              0.00112278
time/evaluation sampling (s)       0.0858201
time/exploration sampling (s)      0.0345165
time/logging (s)                   0.00246028
time/saving (s)                    0.00243841
time/training (s)                  0.49778
time/epoch (s)                     0.624138
time/total (s)                    78.4158
Epoch                            135
-----------------------------  ---------------
2019-04-13 16:59:52.816349 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size             27500
trainer/QF1 Loss                   2.92785
trainer/QF2 Loss                   2.92868
trainer/Policy Loss                9.62092
trainer/Q1 Predictions Mean       -9.78377
trainer/Q1 Predictions Std         0.223286
trainer/Q1 Predictions Max        -9.6453
trainer/Q1 Predictions Min       -10.7447
trainer/Q2 Predictions Mean       -9.78372
trainer/Q2 Predictions Std         0.235868
trainer/Q2 Predictions Max        -9.6085
trainer/Q2 Predictions Min       -10.7565
trainer/Q Targets Mean            -9.65898
trainer/Q Targets Std              1.74579
trainer/Q Targets Max             -0.0733675
trainer/Q Targets Min            -11.1086
trainer/Bellman Errors 1 Mean      2.92785
trainer/Bellman Errors 1 Std      16.0155
trainer/Bellman Errors 1 Max      92.0974
trainer/Bellman Errors 1 Min       1.24443e-05
trainer/Bellman Errors 2 Mean      2.92868
trainer/Bellman Errors 2 Std      16.0115
trainer/Bellman Errors 2 Max      92.0764
trainer/Bellman Errors 2 Min       0.000122614
trainer/Policy Action Mean         0.0175644
trainer/Policy Action Std          0.164171
trainer/Policy Action Max          0.462885
trainer/Policy Action Min         -0.634603
exploration/num steps total    27500
exploration/num paths total      275
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.142212
exploration/Rewards Std            0.0891836
exploration/Rewards Max           -0.00952966
exploration/Rewards Min           -0.764696
exploration/Returns Mean         -14.2212
exploration/Returns Std            0.0551984
exploration/Returns Max          -14.166
exploration/Returns Min          -14.2764
exploration/Actions Mean           0.00979746
exploration/Actions Std            0.165064
exploration/Actions Max            0.921726
exploration/Actions Min           -0.455159
exploration/Num Paths              2
exploration/Average Returns      -14.2212
evaluation/num steps total     68500
evaluation/num paths total       685
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0269233
evaluation/Rewards Std             0.0420453
evaluation/Rewards Max            -0.0161438
evaluation/Rewards Min            -0.907153
evaluation/Returns Mean           -2.69233
evaluation/Returns Std             0.315217
evaluation/Returns Max            -2.45174
evaluation/Returns Min            -3.28917
evaluation/Actions Mean            0.00499919
evaluation/Actions Std             0.0749588
evaluation/Actions Max             0.999998
evaluation/Actions Min            -0.715085
evaluation/Num Paths               5
evaluation/Average Returns        -2.69233
time/data storing (s)              0.00107887
time/evaluation sampling (s)       0.0767465
time/exploration sampling (s)      0.0319901
time/logging (s)                   0.00193135
time/saving (s)                    0.00180217
time/training (s)                  0.455455
time/epoch (s)                     0.569004
time/total (s)                    78.9887
Epoch                            136
-----------------------------  ---------------
2019-04-13 16:59:53.382090 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size             27700
trainer/QF1 Loss                   0.0251984
trainer/QF2 Loss                   0.0285895
trainer/Policy Loss                9.83371
trainer/Q1 Predictions Mean       -9.92643
trainer/Q1 Predictions Std         0.463611
trainer/Q1 Predictions Max        -9.69537
trainer/Q1 Predictions Min       -12.3614
trainer/Q2 Predictions Mean       -9.92571
trainer/Q2 Predictions Std         0.467639
trainer/Q2 Predictions Max        -9.70252
trainer/Q2 Predictions Min       -12.3848
trainer/Q Targets Mean           -10.0373
trainer/Q Targets Std              0.453573
trainer/Q Targets Max             -9.68409
trainer/Q Targets Min            -12.3072
trainer/Bellman Errors 1 Mean      0.0251984
trainer/Bellman Errors 1 Std       0.0273578
trainer/Bellman Errors 1 Max       0.0868237
trainer/Bellman Errors 1 Min       1.75279e-07
trainer/Bellman Errors 2 Mean      0.0285895
trainer/Bellman Errors 2 Std       0.0304433
trainer/Bellman Errors 2 Max       0.0961629
trainer/Bellman Errors 2 Min       0.000102577
trainer/Policy Action Mean         0.0490536
trainer/Policy Action Std          0.245478
trainer/Policy Action Max          0.997211
trainer/Policy Action Min         -0.31403
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135861
exploration/Rewards Std            0.072243
exploration/Rewards Max           -0.010663
exploration/Rewards Min           -0.399484
exploration/Returns Mean         -13.5861
exploration/Returns Std            0.764582
exploration/Returns Max          -12.8216
exploration/Returns Min          -14.3507
exploration/Actions Mean           0.00325883
exploration/Actions Std            0.149694
exploration/Actions Max            0.823879
exploration/Actions Min           -1
exploration/Num Paths              2
exploration/Average Returns      -13.5861
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0451801
evaluation/Rewards Std             0.0130778
evaluation/Rewards Max            -0.0228349
evaluation/Rewards Min            -0.231784
evaluation/Returns Mean           -4.51801
evaluation/Returns Std             0.0740377
evaluation/Returns Max            -4.39426
evaluation/Returns Min            -4.62076
evaluation/Actions Mean            0.00185739
evaluation/Actions Std             0.0713986
evaluation/Actions Max             0.904795
evaluation/Actions Min            -0.935087
evaluation/Num Paths               5
evaluation/Average Returns        -4.51801
time/data storing (s)              0.0010559
time/evaluation sampling (s)       0.0735571
time/exploration sampling (s)      0.0337637
time/logging (s)                   0.00246038
time/saving (s)                    0.00226376
time/training (s)                  0.446913
time/epoch (s)                     0.560013
time/total (s)                    79.5526
Epoch                            137
-----------------------------  ---------------
2019-04-13 16:59:53.959894 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 138 finished
-----------------------------  --------------
replay_buffer/size             27900
trainer/QF1 Loss                   0.0925824
trainer/QF2 Loss                   0.0932154
trainer/Policy Loss                9.67591
trainer/Q1 Predictions Mean       -9.8742
trainer/Q1 Predictions Std         0.557691
trainer/Q1 Predictions Max        -9.59498
trainer/Q1 Predictions Min       -12.6264
trainer/Q2 Predictions Mean       -9.87816
trainer/Q2 Predictions Std         0.553377
trainer/Q2 Predictions Max        -9.62858
trainer/Q2 Predictions Min       -12.6543
trainer/Q Targets Mean           -10.1364
trainer/Q Targets Std              0.623857
trainer/Q Targets Max             -9.71819
trainer/Q Targets Min            -13.1605
trainer/Bellman Errors 1 Mean      0.0925824
trainer/Bellman Errors 1 Std       0.118394
trainer/Bellman Errors 1 Max       0.617122
trainer/Bellman Errors 1 Min       0.00442056
trainer/Bellman Errors 2 Mean      0.0932154
trainer/Bellman Errors 2 Std       0.119863
trainer/Bellman Errors 2 Max       0.614295
trainer/Bellman Errors 2 Min       0.00251951
trainer/Policy Action Mean         0.00789352
trainer/Policy Action Std          0.201118
trainer/Policy Action Max          0.998028
trainer/Policy Action Min         -0.374758
exploration/num steps total    27900
exploration/num paths total      279
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.146496
exploration/Rewards Std            0.074091
exploration/Rewards Max           -0.00543337
exploration/Rewards Min           -0.353725
exploration/Returns Mean         -14.6496
exploration/Returns Std            0.314593
exploration/Returns Max          -14.335
exploration/Returns Min          -14.9642
exploration/Actions Mean           0.00521965
exploration/Actions Std            0.145735
exploration/Actions Max            0.828406
exploration/Actions Min           -0.371423
exploration/Num Paths              2
exploration/Average Returns      -14.6496
evaluation/num steps total     69500
evaluation/num paths total       695
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0773852
evaluation/Rewards Std             0.0262769
evaluation/Rewards Max            -0.0586163
evaluation/Rewards Min            -0.50603
evaluation/Returns Mean           -7.73852
evaluation/Returns Std             0.215091
evaluation/Returns Max            -7.54474
evaluation/Returns Min            -8.01446
evaluation/Actions Mean            0.00346098
evaluation/Actions Std             0.0629367
evaluation/Actions Max             0.999584
evaluation/Actions Min            -0.895832
evaluation/Num Paths               5
evaluation/Average Returns        -7.73852
time/data storing (s)              0.0010936
time/evaluation sampling (s)       0.0754568
time/exploration sampling (s)      0.0316638
time/logging (s)                   0.00249275
time/saving (s)                    0.00226289
time/training (s)                  0.458614
time/epoch (s)                     0.571584
time/total (s)                    80.1279
Epoch                            138
-----------------------------  --------------
2019-04-13 16:59:54.523060 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size             28100
trainer/QF1 Loss                   0.0175995
trainer/QF2 Loss                   0.0179646
trainer/Policy Loss                9.98552
trainer/Q1 Predictions Mean      -10.0966
trainer/Q1 Predictions Std         0.3826
trainer/Q1 Predictions Max        -9.8527
trainer/Q1 Predictions Min       -11.2546
trainer/Q2 Predictions Mean      -10.0982
trainer/Q2 Predictions Std         0.369594
trainer/Q2 Predictions Max        -9.84642
trainer/Q2 Predictions Min       -11.2077
trainer/Q Targets Mean           -10.1289
trainer/Q Targets Std              0.42253
trainer/Q Targets Max             -9.74046
trainer/Q Targets Min            -11.5396
trainer/Bellman Errors 1 Mean      0.0175995
trainer/Bellman Errors 1 Std       0.0228405
trainer/Bellman Errors 1 Max       0.0967381
trainer/Bellman Errors 1 Min       1.81075e-05
trainer/Bellman Errors 2 Mean      0.0179646
trainer/Bellman Errors 2 Std       0.0255619
trainer/Bellman Errors 2 Max       0.110992
trainer/Bellman Errors 2 Min       3.82961e-06
trainer/Policy Action Mean        -0.0077695
trainer/Policy Action Std          0.183923
trainer/Policy Action Max          0.730811
trainer/Policy Action Min         -0.380309
exploration/num steps total    28100
exploration/num paths total      281
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134936
exploration/Rewards Std            0.0704404
exploration/Rewards Max           -0.0109315
exploration/Rewards Min           -0.348315
exploration/Returns Mean         -13.4936
exploration/Returns Std            0.831213
exploration/Returns Max          -12.6624
exploration/Returns Min          -14.3248
exploration/Actions Mean           0.00495731
exploration/Actions Std            0.141545
exploration/Actions Max            0.813924
exploration/Actions Min           -0.375268
exploration/Num Paths              2
exploration/Average Returns      -13.4936
evaluation/num steps total     70000
evaluation/num paths total       700
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0324647
evaluation/Rewards Std             0.0171597
evaluation/Rewards Max            -0.0303145
evaluation/Rewards Min            -0.260687
evaluation/Returns Mean           -3.24647
evaluation/Returns Std             0.0718914
evaluation/Returns Max            -3.12581
evaluation/Returns Min            -3.32276
evaluation/Actions Mean            0.00480161
evaluation/Actions Std             0.0648942
evaluation/Actions Max             0.988963
evaluation/Actions Min            -0.67227
evaluation/Num Paths               5
evaluation/Average Returns        -3.24647
time/data storing (s)              0.00106095
time/evaluation sampling (s)       0.0759477
time/exploration sampling (s)      0.034545
time/logging (s)                   0.00187194
time/saving (s)                    0.002221
time/training (s)                  0.440598
time/epoch (s)                     0.556244
time/total (s)                    80.6878
Epoch                            139
-----------------------------  ---------------
2019-04-13 16:59:55.098022 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size             28300
trainer/QF1 Loss                   0.0545007
trainer/QF2 Loss                   0.0528669
trainer/Policy Loss                9.76169
trainer/Q1 Predictions Mean       -9.92928
trainer/Q1 Predictions Std         0.360761
trainer/Q1 Predictions Max        -9.7378
trainer/Q1 Predictions Min       -11.6693
trainer/Q2 Predictions Mean       -9.93183
trainer/Q2 Predictions Std         0.368855
trainer/Q2 Predictions Max        -9.71638
trainer/Q2 Predictions Min       -11.7406
trainer/Q Targets Mean           -10.128
trainer/Q Targets Std              0.386826
trainer/Q Targets Max             -9.758
trainer/Q Targets Min            -11.9422
trainer/Bellman Errors 1 Mean      0.0545007
trainer/Bellman Errors 1 Std       0.0579813
trainer/Bellman Errors 1 Max       0.225069
trainer/Bellman Errors 1 Min       0.000407954
trainer/Bellman Errors 2 Mean      0.0528669
trainer/Bellman Errors 2 Std       0.0554424
trainer/Bellman Errors 2 Max       0.211411
trainer/Bellman Errors 2 Min       5.73956e-05
trainer/Policy Action Mean         0.0301922
trainer/Policy Action Std          0.196894
trainer/Policy Action Max          0.983268
trainer/Policy Action Min         -0.360338
exploration/num steps total    28300
exploration/num paths total      283
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.14286
exploration/Rewards Std            0.0812548
exploration/Rewards Max           -0.0125874
exploration/Rewards Min           -0.642603
exploration/Returns Mean         -14.286
exploration/Returns Std            0.44492
exploration/Returns Max          -13.841
exploration/Returns Min          -14.7309
exploration/Actions Mean           0.00757416
exploration/Actions Std            0.167727
exploration/Actions Max            1
exploration/Actions Min           -0.844784
exploration/Num Paths              2
exploration/Average Returns      -14.286
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0488535
evaluation/Rewards Std             0.0394558
evaluation/Rewards Max            -0.0356137
evaluation/Rewards Min            -0.890472
evaluation/Returns Mean           -4.88535
evaluation/Returns Std             0.30762
evaluation/Returns Max            -4.61385
evaluation/Returns Min            -5.48353
evaluation/Actions Mean            0.00295763
evaluation/Actions Std             0.0733106
evaluation/Actions Max             0.999992
evaluation/Actions Min            -0.928762
evaluation/Num Paths               5
evaluation/Average Returns        -4.88535
time/data storing (s)              0.0011204
time/evaluation sampling (s)       0.0757701
time/exploration sampling (s)      0.0325405
time/logging (s)                   0.00267213
time/saving (s)                    0.00226196
time/training (s)                  0.456534
time/epoch (s)                     0.570899
time/total (s)                    81.262
Epoch                            140
-----------------------------  ---------------
2019-04-13 16:59:55.676915 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size             28500
trainer/QF1 Loss                   0.0591009
trainer/QF2 Loss                   0.0666977
trainer/Policy Loss                9.82946
trainer/Q1 Predictions Mean       -9.88927
trainer/Q1 Predictions Std         0.189158
trainer/Q1 Predictions Max        -9.75031
trainer/Q1 Predictions Min       -10.5879
trainer/Q2 Predictions Mean       -9.87686
trainer/Q2 Predictions Std         0.186222
trainer/Q2 Predictions Max        -9.73404
trainer/Q2 Predictions Min       -10.5633
trainer/Q Targets Mean           -10.0843
trainer/Q Targets Std              0.256895
trainer/Q Targets Max             -9.80131
trainer/Q Targets Min            -10.9443
trainer/Bellman Errors 1 Mean      0.0591009
trainer/Bellman Errors 1 Std       0.0794293
trainer/Bellman Errors 1 Max       0.302299
trainer/Bellman Errors 1 Min       3.49159e-05
trainer/Bellman Errors 2 Mean      0.0666977
trainer/Bellman Errors 2 Std       0.0869137
trainer/Bellman Errors 2 Max       0.324993
trainer/Bellman Errors 2 Min       0.000451593
trainer/Policy Action Mean        -0.040187
trainer/Policy Action Std          0.11677
trainer/Policy Action Max          0.159127
trainer/Policy Action Min         -0.323674
exploration/num steps total    28500
exploration/num paths total      285
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131753
exploration/Rewards Std            0.0964923
exploration/Rewards Max           -0.0134167
exploration/Rewards Min           -1.04882
exploration/Returns Mean         -13.1753
exploration/Returns Std            0.224136
exploration/Returns Max          -12.9512
exploration/Returns Min          -13.3994
exploration/Actions Mean           0.00630136
exploration/Actions Std            0.16728
exploration/Actions Max            0.999434
exploration/Actions Min           -0.848009
exploration/Num Paths              2
exploration/Average Returns      -13.1753
evaluation/num steps total     71000
evaluation/num paths total       710
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0297776
evaluation/Rewards Std             0.051725
evaluation/Rewards Max            -0.0257288
evaluation/Rewards Min            -0.869149
evaluation/Returns Mean           -2.97776
evaluation/Returns Std             0.3486
evaluation/Returns Max            -2.68034
evaluation/Returns Min            -3.43808
evaluation/Actions Mean            0.00695068
evaluation/Actions Std             0.0783684
evaluation/Actions Max             0.999977
evaluation/Actions Min            -0.615193
evaluation/Num Paths               5
evaluation/Average Returns        -2.97776
time/data storing (s)              0.00113141
time/evaluation sampling (s)       0.0826406
time/exploration sampling (s)      0.035011
time/logging (s)                   0.0024912
time/saving (s)                    0.00282293
time/training (s)                  0.448236
time/epoch (s)                     0.572333
time/total (s)                    81.8381
Epoch                            141
-----------------------------  ---------------
2019-04-13 16:59:56.249919 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size             28700
trainer/QF1 Loss                   0.0686813
trainer/QF2 Loss                   0.0796008
trainer/Policy Loss                9.88235
trainer/Q1 Predictions Mean      -10.0186
trainer/Q1 Predictions Std         0.735719
trainer/Q1 Predictions Max        -9.76351
trainer/Q1 Predictions Min       -13.9331
trainer/Q2 Predictions Mean      -10.0019
trainer/Q2 Predictions Std         0.747562
trainer/Q2 Predictions Max        -9.73146
trainer/Q2 Predictions Min       -13.9627
trainer/Q Targets Mean           -10.2426
trainer/Q Targets Std              0.697438
trainer/Q Targets Max             -9.81411
trainer/Q Targets Min            -13.8999
trainer/Bellman Errors 1 Mean      0.0686813
trainer/Bellman Errors 1 Std       0.0681349
trainer/Bellman Errors 1 Max       0.220536
trainer/Bellman Errors 1 Min       0.000300996
trainer/Bellman Errors 2 Mean      0.0796008
trainer/Bellman Errors 2 Std       0.0774986
trainer/Bellman Errors 2 Max       0.254298
trainer/Bellman Errors 2 Min       0.00033776
trainer/Policy Action Mean        -0.0121984
trainer/Policy Action Std          0.213213
trainer/Policy Action Max          1
trainer/Policy Action Min         -0.994369
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132059
exploration/Rewards Std            0.0975219
exploration/Rewards Max           -0.00817612
exploration/Rewards Min           -0.861972
exploration/Returns Mean         -13.2059
exploration/Returns Std            0.0836947
exploration/Returns Max          -13.1222
exploration/Returns Min          -13.2896
exploration/Actions Mean           0.00971683
exploration/Actions Std            0.172454
exploration/Actions Max            1
exploration/Actions Min           -0.647395
exploration/Num Paths              2
exploration/Average Returns      -13.2059
evaluation/num steps total     71500
evaluation/num paths total       715
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0318662
evaluation/Rewards Std             0.0205121
evaluation/Rewards Max            -0.0215915
evaluation/Rewards Min            -0.36761
evaluation/Returns Mean           -3.18662
evaluation/Returns Std             0.114449
evaluation/Returns Max            -3.03149
evaluation/Returns Min            -3.38485
evaluation/Actions Mean            0.00246285
evaluation/Actions Std             0.0727176
evaluation/Actions Max             0.998821
evaluation/Actions Min            -0.886624
evaluation/Num Paths               5
evaluation/Average Returns        -3.18662
time/data storing (s)              0.00110431
time/evaluation sampling (s)       0.0743192
time/exploration sampling (s)      0.0337084
time/logging (s)                   0.00245803
time/saving (s)                    0.00226954
time/training (s)                  0.452163
time/epoch (s)                     0.566022
time/total (s)                    82.4086
Epoch                            142
-----------------------------  ---------------
2019-04-13 16:59:56.823053 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size             28900
trainer/QF1 Loss                   0.0433456
trainer/QF2 Loss                   0.045177
trainer/Policy Loss               10.0314
trainer/Q1 Predictions Mean      -10.1574
trainer/Q1 Predictions Std         0.500601
trainer/Q1 Predictions Max        -9.91613
trainer/Q1 Predictions Min       -12.6811
trainer/Q2 Predictions Mean      -10.1507
trainer/Q2 Predictions Std         0.490164
trainer/Q2 Predictions Max        -9.91981
trainer/Q2 Predictions Min       -12.621
trainer/Q Targets Mean           -10.3037
trainer/Q Targets Std              0.523395
trainer/Q Targets Max             -9.89755
trainer/Q Targets Min            -12.8945
trainer/Bellman Errors 1 Mean      0.0433456
trainer/Bellman Errors 1 Std       0.0625084
trainer/Bellman Errors 1 Max       0.257382
trainer/Bellman Errors 1 Min       0.000326395
trainer/Bellman Errors 2 Mean      0.045177
trainer/Bellman Errors 2 Std       0.0631226
trainer/Bellman Errors 2 Max       0.255966
trainer/Bellman Errors 2 Min       0.000632969
trainer/Policy Action Mean         0.0512338
trainer/Policy Action Std          0.259443
trainer/Policy Action Max          0.999802
trainer/Policy Action Min         -0.408697
exploration/num steps total    28900
exploration/num paths total      289
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.128289
exploration/Rewards Std            0.0683388
exploration/Rewards Max           -0.0146598
exploration/Rewards Min           -0.487329
exploration/Returns Mean         -12.8289
exploration/Returns Std            0.62891
exploration/Returns Max          -12.2
exploration/Returns Min          -13.4578
exploration/Actions Mean           0.0072396
exploration/Actions Std            0.161979
exploration/Actions Max            1
exploration/Actions Min           -0.34497
exploration/Num Paths              2
exploration/Average Returns      -12.8289
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.035186
evaluation/Rewards Std             0.0151819
evaluation/Rewards Max            -0.0284056
evaluation/Rewards Min            -0.365092
evaluation/Returns Mean           -3.5186
evaluation/Returns Std             0.133802
evaluation/Returns Max            -3.43355
evaluation/Returns Min            -3.78553
evaluation/Actions Mean            0.00468768
evaluation/Actions Std             0.0577564
evaluation/Actions Max             0.998102
evaluation/Actions Min            -0.100123
evaluation/Num Paths               5
evaluation/Average Returns        -3.5186
time/data storing (s)              0.00110017
time/evaluation sampling (s)       0.073826
time/exploration sampling (s)      0.0331488
time/logging (s)                   0.00246844
time/saving (s)                    0.00229244
time/training (s)                  0.453786
time/epoch (s)                     0.566622
time/total (s)                    82.9791
Epoch                            143
-----------------------------  ---------------
2019-04-13 16:59:57.396375 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size             29100
trainer/QF1 Loss                   0.0293957
trainer/QF2 Loss                   0.0331402
trainer/Policy Loss               10.1561
trainer/Q1 Predictions Mean      -10.4951
trainer/Q1 Predictions Std         0.8993
trainer/Q1 Predictions Max       -10.0117
trainer/Q1 Predictions Min       -13.1768
trainer/Q2 Predictions Mean      -10.4998
trainer/Q2 Predictions Std         0.896524
trainer/Q2 Predictions Max       -10.0203
trainer/Q2 Predictions Min       -13.0923
trainer/Q Targets Mean           -10.4896
trainer/Q Targets Std              0.906076
trainer/Q Targets Max             -9.83704
trainer/Q Targets Min            -13.4833
trainer/Bellman Errors 1 Mean      0.0293957
trainer/Bellman Errors 1 Std       0.063243
trainer/Bellman Errors 1 Max       0.338301
trainer/Bellman Errors 1 Min       2.64522e-05
trainer/Bellman Errors 2 Mean      0.0331402
trainer/Bellman Errors 2 Std       0.0741812
trainer/Bellman Errors 2 Max       0.397002
trainer/Bellman Errors 2 Min       1.61123e-06
trainer/Policy Action Mean         0.0459541
trainer/Policy Action Std          0.348017
trainer/Policy Action Max          0.997205
trainer/Policy Action Min         -0.995868
exploration/num steps total    29100
exploration/num paths total      291
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.127368
exploration/Rewards Std            0.0746547
exploration/Rewards Max           -0.0131834
exploration/Rewards Min           -0.592076
exploration/Returns Mean         -12.7368
exploration/Returns Std            0.582185
exploration/Returns Max          -12.1547
exploration/Returns Min          -13.319
exploration/Actions Mean           0.00665198
exploration/Actions Std            0.164527
exploration/Actions Max            0.942948
exploration/Actions Min           -0.454991
exploration/Num Paths              2
exploration/Average Returns      -12.7368
evaluation/num steps total     72500
evaluation/num paths total       725
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0383998
evaluation/Rewards Std             0.0559142
evaluation/Rewards Max            -0.0258946
evaluation/Rewards Min            -0.946329
evaluation/Returns Mean           -3.83998
evaluation/Returns Std             0.383796
evaluation/Returns Max            -3.37274
evaluation/Returns Min            -4.37278
evaluation/Actions Mean            0.00655412
evaluation/Actions Std             0.0857778
evaluation/Actions Max             0.999999
evaluation/Actions Min            -0.841439
evaluation/Num Paths               5
evaluation/Average Returns        -3.83998
time/data storing (s)              0.00111621
time/evaluation sampling (s)       0.0742024
time/exploration sampling (s)      0.0329106
time/logging (s)                   0.00251964
time/saving (s)                    0.00227478
time/training (s)                  0.454058
time/epoch (s)                     0.567082
time/total (s)                    83.55
Epoch                            144
-----------------------------  ---------------
2019-04-13 16:59:57.967311 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size             29300
trainer/QF1 Loss                   0.0342626
trainer/QF2 Loss                   0.0342851
trainer/Policy Loss                9.99334
trainer/Q1 Predictions Mean      -10.1435
trainer/Q1 Predictions Std         0.291694
trainer/Q1 Predictions Max        -9.9166
trainer/Q1 Predictions Min       -11.2188
trainer/Q2 Predictions Mean      -10.1554
trainer/Q2 Predictions Std         0.289729
trainer/Q2 Predictions Max        -9.94593
trainer/Q2 Predictions Min       -11.1888
trainer/Q Targets Mean           -10.2562
trainer/Q Targets Std              0.388596
trainer/Q Targets Max             -9.87745
trainer/Q Targets Min            -11.8133
trainer/Bellman Errors 1 Mean      0.0342626
trainer/Bellman Errors 1 Std       0.0638806
trainer/Bellman Errors 1 Max       0.353433
trainer/Bellman Errors 1 Min       1.26877e-05
trainer/Bellman Errors 2 Mean      0.0342851
trainer/Bellman Errors 2 Std       0.071248
trainer/Bellman Errors 2 Max       0.390073
trainer/Bellman Errors 2 Min       0.000248601
trainer/Policy Action Mean        -0.0523503
trainer/Policy Action Std          0.160568
trainer/Policy Action Max          0.687658
trainer/Policy Action Min         -0.387585
exploration/num steps total    29300
exploration/num paths total      293
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.145453
exploration/Rewards Std            0.0653426
exploration/Rewards Max           -0.00374376
exploration/Rewards Min           -0.323612
exploration/Returns Mean         -14.5453
exploration/Returns Std            0.457067
exploration/Returns Max          -14.0882
exploration/Returns Min          -15.0024
exploration/Actions Mean           0.00329106
exploration/Actions Std            0.148473
exploration/Actions Max            0.868701
exploration/Actions Min           -0.331146
exploration/Num Paths              2
exploration/Average Returns      -14.5453
evaluation/num steps total     73000
evaluation/num paths total       730
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0702875
evaluation/Rewards Std             0.0546859
evaluation/Rewards Max            -0.0652097
evaluation/Rewards Min            -0.933725
evaluation/Returns Mean           -7.02875
evaluation/Returns Std             0.309639
evaluation/Returns Max            -6.70343
evaluation/Returns Min            -7.45673
evaluation/Actions Mean            0.00769371
evaluation/Actions Std             0.084133
evaluation/Actions Max             0.999995
evaluation/Actions Min            -0.890886
evaluation/Num Paths               5
evaluation/Average Returns        -7.02875
time/data storing (s)              0.0011219
time/evaluation sampling (s)       0.0749359
time/exploration sampling (s)      0.0332629
time/logging (s)                   0.00191987
time/saving (s)                    0.00193418
time/training (s)                  0.450833
time/epoch (s)                     0.564008
time/total (s)                    84.1176
Epoch                            145
-----------------------------  ---------------
2019-04-13 16:59:58.525590 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size             29500
trainer/QF1 Loss                   3.12521
trainer/QF2 Loss                   3.11994
trainer/Policy Loss               10.1494
trainer/Q1 Predictions Mean      -10.4411
trainer/Q1 Predictions Std         1.02378
trainer/Q1 Predictions Max        -9.98887
trainer/Q1 Predictions Min       -15.4189
trainer/Q2 Predictions Mean      -10.4393
trainer/Q2 Predictions Std         1.00083
trainer/Q2 Predictions Max       -10.0097
trainer/Q2 Predictions Min       -15.3274
trainer/Q Targets Mean           -10.1483
trainer/Q Targets Std              2.077
trainer/Q Targets Max             -0.0900361
trainer/Q Targets Min            -15.4116
trainer/Bellman Errors 1 Mean      3.12521
trainer/Bellman Errors 1 Std      17.312
trainer/Bellman Errors 1 Max      99.5144
trainer/Bellman Errors 1 Min       5.24357e-05
trainer/Bellman Errors 2 Mean      3.11994
trainer/Bellman Errors 2 Std      17.2708
trainer/Bellman Errors 2 Max      99.2798
trainer/Bellman Errors 2 Min       3.23507e-06
trainer/Policy Action Mean         0.0142197
trainer/Policy Action Std          0.31518
trainer/Policy Action Max          1
trainer/Policy Action Min         -0.997171
exploration/num steps total    29500
exploration/num paths total      295
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.13154
exploration/Rewards Std            0.0692478
exploration/Rewards Max           -0.00981296
exploration/Rewards Min           -0.387597
exploration/Returns Mean         -13.154
exploration/Returns Std            0.162326
exploration/Returns Max          -12.9917
exploration/Returns Min          -13.3163
exploration/Actions Mean           0.00216176
exploration/Actions Std            0.144356
exploration/Actions Max            0.494496
exploration/Actions Min           -0.529953
exploration/Num Paths              2
exploration/Average Returns      -13.154
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0442864
evaluation/Rewards Std             0.0527508
evaluation/Rewards Max            -0.0336961
evaluation/Rewards Min            -0.839486
evaluation/Returns Mean           -4.42864
evaluation/Returns Std             0.310643
evaluation/Returns Max            -4.01147
evaluation/Returns Min            -4.79767
evaluation/Actions Mean            0.00863982
evaluation/Actions Std             0.0819257
evaluation/Actions Max             0.999991
evaluation/Actions Min            -0.251618
evaluation/Num Paths               5
evaluation/Average Returns        -4.42864
time/data storing (s)              0.00106559
time/evaluation sampling (s)       0.0756479
time/exploration sampling (s)      0.0317161
time/logging (s)                   0.00245457
time/saving (s)                    0.00208114
time/training (s)                  0.440919
time/epoch (s)                     0.553885
time/total (s)                    84.6748
Epoch                            146
-----------------------------  ---------------
2019-04-13 16:59:59.092154 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size             29700
trainer/QF1 Loss                   0.0536119
trainer/QF2 Loss                   0.0548292
trainer/Policy Loss               10.2744
trainer/Q1 Predictions Mean      -10.375
trainer/Q1 Predictions Std         0.0893039
trainer/Q1 Predictions Max       -10.2547
trainer/Q1 Predictions Min       -10.5614
trainer/Q2 Predictions Mean      -10.3776
trainer/Q2 Predictions Std         0.0913463
trainer/Q2 Predictions Max       -10.2559
trainer/Q2 Predictions Min       -10.6011
trainer/Q Targets Mean           -10.2147
trainer/Q Targets Std              0.198627
trainer/Q Targets Max             -9.87592
trainer/Q Targets Min            -10.7572
trainer/Bellman Errors 1 Mean      0.0536119
trainer/Bellman Errors 1 Std       0.0495214
trainer/Bellman Errors 1 Max       0.191067
trainer/Bellman Errors 1 Min       8.51162e-05
trainer/Bellman Errors 2 Mean      0.0548292
trainer/Bellman Errors 2 Std       0.0499284
trainer/Bellman Errors 2 Max       0.179641
trainer/Bellman Errors 2 Min       3.17022e-06
trainer/Policy Action Mean         0.0211578
trainer/Policy Action Std          0.0926958
trainer/Policy Action Max          0.242057
trainer/Policy Action Min         -0.212992
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131035
exploration/Rewards Std            0.0687943
exploration/Rewards Max           -0.0195497
exploration/Rewards Min           -0.318759
exploration/Returns Mean         -13.1035
exploration/Returns Std            0.131759
exploration/Returns Max          -12.9718
exploration/Returns Min          -13.2353
exploration/Actions Mean           0.00687077
exploration/Actions Std            0.139775
exploration/Actions Max            0.97212
exploration/Actions Min           -0.330675
exploration/Num Paths              2
exploration/Average Returns      -13.1035
evaluation/num steps total     74000
evaluation/num paths total       740
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0539449
evaluation/Rewards Std             0.0313938
evaluation/Rewards Max            -0.0216218
evaluation/Rewards Min            -0.734337
evaluation/Returns Mean           -5.39449
evaluation/Returns Std             0.253109
evaluation/Returns Max            -5.20755
evaluation/Returns Min            -5.89157
evaluation/Actions Mean            0.00108351
evaluation/Actions Std             0.0682486
evaluation/Actions Max             0.99999
evaluation/Actions Min            -0.924535
evaluation/Num Paths               5
evaluation/Average Returns        -5.39449
time/data storing (s)              0.0011078
time/evaluation sampling (s)       0.0753034
time/exploration sampling (s)      0.0330059
time/logging (s)                   0.00254798
time/saving (s)                    0.00222428
time/training (s)                  0.446083
time/epoch (s)                     0.560273
time/total (s)                    85.2389
Epoch                            147
-----------------------------  ---------------
2019-04-13 16:59:59.668382 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size             29900
trainer/QF1 Loss                   0.0432461
trainer/QF2 Loss                   0.0430691
trainer/Policy Loss               10.0653
trainer/Q1 Predictions Mean      -10.1746
trainer/Q1 Predictions Std         0.261598
trainer/Q1 Predictions Max        -9.96362
trainer/Q1 Predictions Min       -11.3183
trainer/Q2 Predictions Mean      -10.1803
trainer/Q2 Predictions Std         0.266678
trainer/Q2 Predictions Max        -9.9584
trainer/Q2 Predictions Min       -11.338
trainer/Q Targets Mean           -10.3131
trainer/Q Targets Std              0.252887
trainer/Q Targets Max            -10.0272
trainer/Q Targets Min            -11.1608
trainer/Bellman Errors 1 Mean      0.0432461
trainer/Bellman Errors 1 Std       0.062902
trainer/Bellman Errors 1 Max       0.256009
trainer/Bellman Errors 1 Min       1.51819e-06
trainer/Bellman Errors 2 Mean      0.0430691
trainer/Bellman Errors 2 Std       0.0619219
trainer/Bellman Errors 2 Max       0.260178
trainer/Bellman Errors 2 Min       3.16273e-05
trainer/Policy Action Mean         0.0285128
trainer/Policy Action Std          0.187158
trainer/Policy Action Max          0.990796
trainer/Policy Action Min         -0.330553
exploration/num steps total    29900
exploration/num paths total      299
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.13552
exploration/Rewards Std            0.0845119
exploration/Rewards Max           -0.00830104
exploration/Rewards Min           -0.812196
exploration/Returns Mean         -13.552
exploration/Returns Std            0.097103
exploration/Returns Max          -13.4549
exploration/Returns Min          -13.6491
exploration/Actions Mean           0.00668723
exploration/Actions Std            0.14811
exploration/Actions Max            1
exploration/Actions Min           -0.395723
exploration/Num Paths              2
exploration/Average Returns      -13.552
evaluation/num steps total     74500
evaluation/num paths total       745
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0403734
evaluation/Rewards Std             0.0458271
evaluation/Rewards Max            -0.0123556
evaluation/Rewards Min            -0.873874
evaluation/Returns Mean           -4.03734
evaluation/Returns Std             0.313937
evaluation/Returns Max            -3.73491
evaluation/Returns Min            -4.51795
evaluation/Actions Mean            0.00440024
evaluation/Actions Std             0.0737558
evaluation/Actions Max             0.99999
evaluation/Actions Min            -0.583322
evaluation/Num Paths               5
evaluation/Average Returns        -4.03734
time/data storing (s)              0.0012796
time/evaluation sampling (s)       0.0754979
time/exploration sampling (s)      0.0397134
time/logging (s)                   0.00190811
time/saving (s)                    0.00180388
time/training (s)                  0.448999
time/epoch (s)                     0.569202
time/total (s)                    85.8117
Epoch                            148
-----------------------------  ---------------
2019-04-13 17:00:00.331925 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size             30100
trainer/QF1 Loss                   0.0355274
trainer/QF2 Loss                   0.0389691
trainer/Policy Loss               10.2023
trainer/Q1 Predictions Mean      -10.3495
trainer/Q1 Predictions Std         0.534589
trainer/Q1 Predictions Max       -10.089
trainer/Q1 Predictions Min       -13.0619
trainer/Q2 Predictions Mean      -10.3517
trainer/Q2 Predictions Std         0.524681
trainer/Q2 Predictions Max       -10.083
trainer/Q2 Predictions Min       -13.0011
trainer/Q Targets Mean           -10.4389
trainer/Q Targets Std              0.641491
trainer/Q Targets Max            -10.0661
trainer/Q Targets Min            -13.66
trainer/Bellman Errors 1 Mean      0.0355274
trainer/Bellman Errors 1 Std       0.0767239
trainer/Bellman Errors 1 Max       0.357665
trainer/Bellman Errors 1 Min       2.15793e-05
trainer/Bellman Errors 2 Mean      0.038969
trainer/Bellman Errors 2 Std       0.0863437
trainer/Bellman Errors 2 Max       0.434152
trainer/Bellman Errors 2 Min       2.53265e-05
trainer/Policy Action Mean         0.0221999
trainer/Policy Action Std          0.257023
trainer/Policy Action Max          0.991379
trainer/Policy Action Min         -0.495938
exploration/num steps total    30100
exploration/num paths total      301
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.143982
exploration/Rewards Std            0.100492
exploration/Rewards Max           -0.00141295
exploration/Rewards Min           -1.01914
exploration/Returns Mean         -14.3982
exploration/Returns Std            0.0629245
exploration/Returns Max          -14.3353
exploration/Returns Min          -14.4611
exploration/Actions Mean           0.00676904
exploration/Actions Std            0.164167
exploration/Actions Max            1
exploration/Actions Min           -0.645313
exploration/Num Paths              2
exploration/Average Returns      -14.3982
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0368357
evaluation/Rewards Std             0.0276044
evaluation/Rewards Max            -0.00840411
evaluation/Rewards Min            -0.552267
evaluation/Returns Mean           -3.68357
evaluation/Returns Std             0.196444
evaluation/Returns Max            -3.51585
evaluation/Returns Min            -4.06041
evaluation/Actions Mean            0.00394134
evaluation/Actions Std             0.0680583
evaluation/Actions Max             0.999341
evaluation/Actions Min            -0.92981
evaluation/Num Paths               5
evaluation/Average Returns        -3.68357
time/data storing (s)              0.00114366
time/evaluation sampling (s)       0.0822004
time/exploration sampling (s)      0.0333476
time/logging (s)                   0.00250105
time/saving (s)                    0.00247995
time/training (s)                  0.536796
time/epoch (s)                     0.658469
time/total (s)                    86.4741
Epoch                            149
-----------------------------  ---------------
2019-04-13 17:00:00.915006 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size             30300
trainer/QF1 Loss                   0.0318632
trainer/QF2 Loss                   0.0294315
trainer/Policy Loss               10.2601
trainer/Q1 Predictions Mean      -10.3916
trainer/Q1 Predictions Std         0.260478
trainer/Q1 Predictions Max       -10.1356
trainer/Q1 Predictions Min       -11.2484
trainer/Q2 Predictions Mean      -10.392
trainer/Q2 Predictions Std         0.262567
trainer/Q2 Predictions Max       -10.1709
trainer/Q2 Predictions Min       -11.2093
trainer/Q Targets Mean           -10.4157
trainer/Q Targets Std              0.276036
trainer/Q Targets Max            -10.0827
trainer/Q Targets Min            -11.1949
trainer/Bellman Errors 1 Mean      0.0318632
trainer/Bellman Errors 1 Std       0.0419433
trainer/Bellman Errors 1 Max       0.188305
trainer/Bellman Errors 1 Min       8.56631e-06
trainer/Bellman Errors 2 Mean      0.0294315
trainer/Bellman Errors 2 Std       0.0390478
trainer/Bellman Errors 2 Max       0.166182
trainer/Bellman Errors 2 Min       0.000205374
trainer/Policy Action Mean         0.0183113
trainer/Policy Action Std          0.122704
trainer/Policy Action Max          0.38472
trainer/Policy Action Min         -0.328466
exploration/num steps total    30300
exploration/num paths total      303
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.143642
exploration/Rewards Std            0.0814238
exploration/Rewards Max           -0.0175747
exploration/Rewards Min           -0.79475
exploration/Returns Mean         -14.3642
exploration/Returns Std            0.632403
exploration/Returns Max          -13.7318
exploration/Returns Min          -14.9966
exploration/Actions Mean           0.00839133
exploration/Actions Std            0.14883
exploration/Actions Max            1
exploration/Actions Min           -0.377876
exploration/Num Paths              2
exploration/Average Returns      -14.3642
evaluation/num steps total     75500
evaluation/num paths total       755
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0763519
evaluation/Rewards Std             0.00909606
evaluation/Rewards Max            -0.0609671
evaluation/Rewards Min            -0.251502
evaluation/Returns Mean           -7.63519
evaluation/Returns Std             0.0625254
evaluation/Returns Max            -7.54181
evaluation/Returns Min            -7.73245
evaluation/Actions Mean            0.00261797
evaluation/Actions Std             0.0739843
evaluation/Actions Max             0.993126
evaluation/Actions Min            -0.900909
evaluation/Num Paths               5
evaluation/Average Returns        -7.63519
time/data storing (s)              0.00139002
time/evaluation sampling (s)       0.079998
time/exploration sampling (s)      0.0340373
time/logging (s)                   0.00211026
time/saving (s)                    0.00185603
time/training (s)                  0.456828
time/epoch (s)                     0.576219
time/total (s)                    87.0542
Epoch                            150
-----------------------------  ---------------
2019-04-13 17:00:01.496123 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size             30500
trainer/QF1 Loss                   0.0377254
trainer/QF2 Loss                   0.0383932
trainer/Policy Loss               10.2563
trainer/Q1 Predictions Mean      -10.4418
trainer/Q1 Predictions Std         0.506345
trainer/Q1 Predictions Max       -10.191
trainer/Q1 Predictions Min       -13.0739
trainer/Q2 Predictions Mean      -10.4595
trainer/Q2 Predictions Std         0.508313
trainer/Q2 Predictions Max       -10.1946
trainer/Q2 Predictions Min       -13.0956
trainer/Q Targets Mean           -10.4144
trainer/Q Targets Std              0.435565
trainer/Q Targets Max            -10.0842
trainer/Q Targets Min            -12.5356
trainer/Bellman Errors 1 Mean      0.0377254
trainer/Bellman Errors 1 Std       0.0634798
trainer/Bellman Errors 1 Max       0.28984
trainer/Bellman Errors 1 Min       4.88795e-05
trainer/Bellman Errors 2 Mean      0.0383932
trainer/Bellman Errors 2 Std       0.063711
trainer/Bellman Errors 2 Max       0.313575
trainer/Bellman Errors 2 Min       1.55884e-05
trainer/Policy Action Mean         0.0245138
trainer/Policy Action Std          0.18484
trainer/Policy Action Max          0.995428
trainer/Policy Action Min         -0.307095
exploration/num steps total    30500
exploration/num paths total      305
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.137077
exploration/Rewards Std            0.0780655
exploration/Rewards Max           -0.00526177
exploration/Rewards Min           -0.505229
exploration/Returns Mean         -13.7077
exploration/Returns Std            0.45555
exploration/Returns Max          -13.2521
exploration/Returns Min          -14.1632
exploration/Actions Mean           0.00285322
exploration/Actions Std            0.148899
exploration/Actions Max            0.912685
exploration/Actions Min           -0.431299
exploration/Num Paths              2
exploration/Average Returns      -13.7077
evaluation/num steps total     76000
evaluation/num paths total       760
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0319376
evaluation/Rewards Std             0.0296699
evaluation/Rewards Max            -0.0141221
evaluation/Rewards Min            -0.586985
evaluation/Returns Mean           -3.19376
evaluation/Returns Std             0.224953
evaluation/Returns Max            -2.94963
evaluation/Returns Min            -3.60135
evaluation/Actions Mean            0.00459242
evaluation/Actions Std             0.0747984
evaluation/Actions Max             0.998893
evaluation/Actions Min            -0.909698
evaluation/Num Paths               5
evaluation/Average Returns        -3.19376
time/data storing (s)              0.00136813
time/evaluation sampling (s)       0.0775299
time/exploration sampling (s)      0.0335873
time/logging (s)                   0.00230662
time/saving (s)                    0.00221437
time/training (s)                  0.457901
time/epoch (s)                     0.574907
time/total (s)                    87.6329
Epoch                            151
-----------------------------  ---------------
2019-04-13 17:00:02.063763 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size             30700
trainer/QF1 Loss                   0.0333267
trainer/QF2 Loss                   0.0296196
trainer/Policy Loss               10.193
trainer/Q1 Predictions Mean      -10.3897
trainer/Q1 Predictions Std         0.327899
trainer/Q1 Predictions Max       -10.1784
trainer/Q1 Predictions Min       -11.79
trainer/Q2 Predictions Mean      -10.3951
trainer/Q2 Predictions Std         0.360637
trainer/Q2 Predictions Max       -10.1672
trainer/Q2 Predictions Min       -11.8855
trainer/Q Targets Mean           -10.4505
trainer/Q Targets Std              0.416543
trainer/Q Targets Max            -10.1004
trainer/Q Targets Min            -12.2011
trainer/Bellman Errors 1 Mean      0.0333267
trainer/Bellman Errors 1 Std       0.0490913
trainer/Bellman Errors 1 Max       0.168987
trainer/Bellman Errors 1 Min       8.92116e-05
trainer/Bellman Errors 2 Mean      0.0296196
trainer/Bellman Errors 2 Std       0.0466219
trainer/Bellman Errors 2 Max       0.16241
trainer/Bellman Errors 2 Min       4.33638e-05
trainer/Policy Action Mean         0.00310698
trainer/Policy Action Std          0.193239
trainer/Policy Action Max          0.998028
trainer/Policy Action Min         -0.298178
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.154125
exploration/Rewards Std            0.0907507
exploration/Rewards Max           -0.00720986
exploration/Rewards Min           -0.664932
exploration/Returns Mean         -15.4125
exploration/Returns Std            0.707102
exploration/Returns Max          -14.7054
exploration/Returns Min          -16.1196
exploration/Actions Mean           0.00512459
exploration/Actions Std            0.1632
exploration/Actions Max            1
exploration/Actions Min           -0.932863
exploration/Num Paths              2
exploration/Average Returns      -15.4125
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.057676
evaluation/Rewards Std             0.0255486
evaluation/Rewards Max            -0.0297691
evaluation/Rewards Min            -0.565251
evaluation/Returns Mean           -5.7676
evaluation/Returns Std             0.242738
evaluation/Returns Max            -5.59547
evaluation/Returns Min            -6.23791
evaluation/Actions Mean            0.00318843
evaluation/Actions Std             0.0702157
evaluation/Actions Max             0.999363
evaluation/Actions Min            -0.868219
evaluation/Num Paths               5
evaluation/Average Returns        -5.7676
time/data storing (s)              0.00105843
time/evaluation sampling (s)       0.0731733
time/exploration sampling (s)      0.0319537
time/logging (s)                   0.00193722
time/saving (s)                    0.00178488
time/training (s)                  0.450946
time/epoch (s)                     0.560853
time/total (s)                    88.1976
Epoch                            152
-----------------------------  ---------------
2019-04-13 17:00:02.636997 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size             30900
trainer/QF1 Loss                   3.20792
trainer/QF2 Loss                   3.21144
trainer/Policy Loss               10.1274
trainer/Q1 Predictions Mean      -10.2745
trainer/Q1 Predictions Std         0.224783
trainer/Q1 Predictions Max       -10.0774
trainer/Q1 Predictions Min       -11.1222
trainer/Q2 Predictions Mean      -10.2707
trainer/Q2 Predictions Std         0.219448
trainer/Q2 Predictions Max       -10.0921
trainer/Q2 Predictions Min       -11.1027
trainer/Q Targets Mean           -10.1369
trainer/Q Targets Std              1.82932
trainer/Q Targets Max             -0.0504726
trainer/Q Targets Min            -11.1604
trainer/Bellman Errors 1 Mean      3.20792
trainer/Bellman Errors 1 Std      17.5309
trainer/Bellman Errors 1 Max     100.814
trainer/Bellman Errors 1 Min       9.49395e-05
trainer/Bellman Errors 2 Mean      3.21143
trainer/Bellman Errors 2 Std      17.5341
trainer/Bellman Errors 2 Max     100.835
trainer/Bellman Errors 2 Min       3.21227e-05
trainer/Policy Action Mean        -0.0656786
trainer/Policy Action Std          0.0941103
trainer/Policy Action Max          0.244766
trainer/Policy Action Min         -0.309997
exploration/num steps total    30900
exploration/num paths total      309
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.144165
exploration/Rewards Std            0.0813692
exploration/Rewards Max           -0.00722139
exploration/Rewards Min           -0.467441
exploration/Returns Mean         -14.4165
exploration/Returns Std            0.0821789
exploration/Returns Max          -14.3343
exploration/Returns Min          -14.4987
exploration/Actions Mean           0.00208879
exploration/Actions Std            0.146323
exploration/Actions Max            1
exploration/Actions Min           -0.77344
exploration/Num Paths              2
exploration/Average Returns      -14.4165
evaluation/num steps total     77000
evaluation/num paths total       770
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0813338
evaluation/Rewards Std             0.0210544
evaluation/Rewards Max            -0.0779592
evaluation/Rewards Min            -0.439228
evaluation/Returns Mean           -8.13338
evaluation/Returns Std             0.158696
evaluation/Returns Max            -7.9751
evaluation/Returns Min            -8.40726
evaluation/Actions Mean            0.00433529
evaluation/Actions Std             0.0496814
evaluation/Actions Max             0.996973
evaluation/Actions Min            -0.11904
evaluation/Num Paths               5
evaluation/Average Returns        -8.13338
time/data storing (s)              0.00106094
time/evaluation sampling (s)       0.0733834
time/exploration sampling (s)      0.0318333
time/logging (s)                   0.00249269
time/saving (s)                    0.00227368
time/training (s)                  0.456255
time/epoch (s)                     0.567299
time/total (s)                    88.7688
Epoch                            153
-----------------------------  ---------------
2019-04-13 17:00:03.223707 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 154 finished
-----------------------------  --------------
replay_buffer/size             31100
trainer/QF1 Loss                   3.2365
trainer/QF2 Loss                   3.22748
trainer/Policy Loss               10.0475
trainer/Q1 Predictions Mean      -10.1085
trainer/Q1 Predictions Std         0.140288
trainer/Q1 Predictions Max        -9.9998
trainer/Q1 Predictions Min       -10.8153
trainer/Q2 Predictions Mean      -10.109
trainer/Q2 Predictions Std         0.148332
trainer/Q2 Predictions Max        -9.98514
trainer/Q2 Predictions Min       -10.8614
trainer/Q Targets Mean           -10.0878
trainer/Q Targets Std              1.8133
trainer/Q Targets Max             -0.0442702
trainer/Q Targets Min            -11.0172
trainer/Bellman Errors 1 Mean      3.2365
trainer/Bellman Errors 1 Std      17.4122
trainer/Bellman Errors 1 Max     100.182
trainer/Bellman Errors 1 Min       0.00447284
trainer/Bellman Errors 2 Mean      3.22748
trainer/Bellman Errors 2 Std      17.3658
trainer/Bellman Errors 2 Max      99.9149
trainer/Bellman Errors 2 Min       0.00474565
trainer/Policy Action Mean         0.0188179
trainer/Policy Action Std          0.101778
trainer/Policy Action Max          0.251958
trainer/Policy Action Min         -0.319066
exploration/num steps total    31100
exploration/num paths total      311
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.153296
exploration/Rewards Std            0.0801411
exploration/Rewards Max           -0.0144789
exploration/Rewards Min           -0.382598
exploration/Returns Mean         -15.3296
exploration/Returns Std            0.833992
exploration/Returns Max          -14.4956
exploration/Returns Min          -16.1636
exploration/Actions Mean           0.00325943
exploration/Actions Std            0.162308
exploration/Actions Max            0.920195
exploration/Actions Min           -0.844813
exploration/Num Paths              2
exploration/Average Returns      -15.3296
evaluation/num steps total     77500
evaluation/num paths total       775
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0606879
evaluation/Rewards Std             0.0426159
evaluation/Rewards Max            -0.0374718
evaluation/Rewards Min            -0.992461
evaluation/Returns Mean           -6.06879
evaluation/Returns Std             0.374277
evaluation/Returns Max            -5.81467
evaluation/Returns Min            -6.8034
evaluation/Actions Mean            0.00461363
evaluation/Actions Std             0.0603242
evaluation/Actions Max             0.999994
evaluation/Actions Min            -0.352874
evaluation/Num Paths               5
evaluation/Average Returns        -6.06879
time/data storing (s)              0.00127962
time/evaluation sampling (s)       0.0808827
time/exploration sampling (s)      0.0343903
time/logging (s)                   0.00248531
time/saving (s)                    0.0033841
time/training (s)                  0.457804
time/epoch (s)                     0.580226
time/total (s)                    89.3528
Epoch                            154
-----------------------------  --------------
2019-04-13 17:00:03.783971 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size             31300
trainer/QF1 Loss                   3.34729
trainer/QF2 Loss                   3.33844
trainer/Policy Loss               10.2666
trainer/Q1 Predictions Mean      -10.4795
trainer/Q1 Predictions Std         0.196547
trainer/Q1 Predictions Max       -10.2908
trainer/Q1 Predictions Min       -11.2499
trainer/Q2 Predictions Mean      -10.4768
trainer/Q2 Predictions Std         0.203144
trainer/Q2 Predictions Max       -10.3379
trainer/Q2 Predictions Min       -11.2767
trainer/Q Targets Mean           -10.1753
trainer/Q Targets Std              1.83135
trainer/Q Targets Max             -0.0831794
trainer/Q Targets Min            -11.2588
trainer/Bellman Errors 1 Mean      3.34729
trainer/Bellman Errors 1 Std      18.4325
trainer/Bellman Errors 1 Max     105.975
trainer/Bellman Errors 1 Min       7.895e-05
trainer/Bellman Errors 2 Mean      3.33844
trainer/Bellman Errors 2 Std      18.4075
trainer/Bellman Errors 2 Max     105.827
trainer/Bellman Errors 2 Min       1.73209e-05
trainer/Policy Action Mean         0.00244503
trainer/Policy Action Std          0.108695
trainer/Policy Action Max          0.325788
trainer/Policy Action Min         -0.31603
exploration/num steps total    31300
exploration/num paths total      313
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.151047
exploration/Rewards Std            0.0779942
exploration/Rewards Max           -0.0162806
exploration/Rewards Min           -0.356104
exploration/Returns Mean         -15.1047
exploration/Returns Std            0.422423
exploration/Returns Max          -14.6823
exploration/Returns Min          -15.5272
exploration/Actions Mean           0.00491294
exploration/Actions Std            0.157936
exploration/Actions Max            0.978495
exploration/Actions Min           -0.618027
exploration/Num Paths              2
exploration/Average Returns      -15.1047
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.071381
evaluation/Rewards Std             0.0538408
evaluation/Rewards Max            -0.0549903
evaluation/Rewards Min            -0.97137
evaluation/Returns Mean           -7.1381
evaluation/Returns Std             0.420024
evaluation/Returns Max            -6.74538
evaluation/Returns Min            -7.70613
evaluation/Actions Mean            0.00399308
evaluation/Actions Std             0.0831564
evaluation/Actions Max             0.999976
evaluation/Actions Min            -0.92875
evaluation/Num Paths               5
evaluation/Average Returns        -7.1381
time/data storing (s)              0.00110673
time/evaluation sampling (s)       0.0761865
time/exploration sampling (s)      0.033119
time/logging (s)                   0.00191328
time/saving (s)                    0.00225955
time/training (s)                  0.438958
time/epoch (s)                     0.553543
time/total (s)                    89.9096
Epoch                            155
-----------------------------  ---------------
2019-04-13 17:00:04.362753 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size             31500
trainer/QF1 Loss                   3.36529
trainer/QF2 Loss                   3.35511
trainer/Policy Loss               10.363
trainer/Q1 Predictions Mean      -10.4856
trainer/Q1 Predictions Std         0.221288
trainer/Q1 Predictions Max       -10.2693
trainer/Q1 Predictions Min       -11.3356
trainer/Q2 Predictions Mean      -10.4912
trainer/Q2 Predictions Std         0.229553
trainer/Q2 Predictions Max       -10.2945
trainer/Q2 Predictions Min       -11.3932
trainer/Q Targets Mean           -10.1565
trainer/Q Targets Std              1.82768
trainer/Q Targets Max             -0.0994314
trainer/Q Targets Min            -11.4401
trainer/Bellman Errors 1 Mean      3.36529
trainer/Bellman Errors 1 Std      18.6072
trainer/Bellman Errors 1 Max     106.966
trainer/Bellman Errors 1 Min       1.45446e-05
trainer/Bellman Errors 2 Mean      3.35511
trainer/Bellman Errors 2 Std      18.5622
trainer/Bellman Errors 2 Max     106.705
trainer/Bellman Errors 2 Min       1.76238e-05
trainer/Policy Action Mean         0.0319832
trainer/Policy Action Std          0.127522
trainer/Policy Action Max          0.502439
trainer/Policy Action Min         -0.296514
exploration/num steps total    31500
exploration/num paths total      315
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.143219
exploration/Rewards Std            0.0746177
exploration/Rewards Max           -0.016197
exploration/Rewards Min           -0.385681
exploration/Returns Mean         -14.3219
exploration/Returns Std            0.0540684
exploration/Returns Max          -14.2678
exploration/Returns Min          -14.3759
exploration/Actions Mean           0.00809192
exploration/Actions Std            0.139484
exploration/Actions Max            1
exploration/Actions Min           -0.353237
exploration/Num Paths              2
exploration/Average Returns      -14.3219
evaluation/num steps total     78500
evaluation/num paths total       785
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0912835
evaluation/Rewards Std             0.0277857
evaluation/Rewards Max            -0.0508852
evaluation/Rewards Min            -0.631838
evaluation/Returns Mean           -9.12835
evaluation/Returns Std             0.212452
evaluation/Returns Max            -8.92064
evaluation/Returns Min            -9.48549
evaluation/Actions Mean            0.0059317
evaluation/Actions Std             0.0678953
evaluation/Actions Max             0.999723
evaluation/Actions Min            -0.345694
evaluation/Num Paths               5
evaluation/Average Returns        -9.12835
time/data storing (s)              0.00105641
time/evaluation sampling (s)       0.0732478
time/exploration sampling (s)      0.0334792
time/logging (s)                   0.00247667
time/saving (s)                    0.00225704
time/training (s)                  0.461449
time/epoch (s)                     0.573966
time/total (s)                    90.4872
Epoch                            156
-----------------------------  ---------------
2019-04-13 17:00:04.936839 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size             31700
trainer/QF1 Loss                   0.0563315
trainer/QF2 Loss                   0.057333
trainer/Policy Loss               10.1978
trainer/Q1 Predictions Mean      -10.3393
trainer/Q1 Predictions Std         0.149766
trainer/Q1 Predictions Max       -10.1983
trainer/Q1 Predictions Min       -11.0816
trainer/Q2 Predictions Mean      -10.3354
trainer/Q2 Predictions Std         0.151074
trainer/Q2 Predictions Max       -10.1946
trainer/Q2 Predictions Min       -11.0891
trainer/Q Targets Mean           -10.5067
trainer/Q Targets Std              0.204516
trainer/Q Targets Max            -10.204
trainer/Q Targets Min            -11.0742
trainer/Bellman Errors 1 Mean      0.0563315
trainer/Bellman Errors 1 Std       0.0722503
trainer/Bellman Errors 1 Max       0.304269
trainer/Bellman Errors 1 Min       5.44856e-05
trainer/Bellman Errors 2 Mean      0.057333
trainer/Bellman Errors 2 Std       0.072533
trainer/Bellman Errors 2 Max       0.309705
trainer/Bellman Errors 2 Min       2.98301e-05
trainer/Policy Action Mean         0.0275381
trainer/Policy Action Std          0.164328
trainer/Policy Action Max          0.904388
trainer/Policy Action Min         -0.437497
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.153585
exploration/Rewards Std            0.0850866
exploration/Rewards Max           -0.0112718
exploration/Rewards Min           -0.690769
exploration/Returns Mean         -15.3585
exploration/Returns Std            0.361211
exploration/Returns Max          -14.9973
exploration/Returns Min          -15.7197
exploration/Actions Mean           0.0124511
exploration/Actions Std            0.164371
exploration/Actions Max            1
exploration/Actions Min           -0.451076
exploration/Num Paths              2
exploration/Average Returns      -15.3585
evaluation/num steps total     79000
evaluation/num paths total       790
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.068503
evaluation/Rewards Std             0.0350701
evaluation/Rewards Max            -0.0465295
evaluation/Rewards Min            -0.815877
evaluation/Returns Mean           -6.8503
evaluation/Returns Std             0.301378
evaluation/Returns Max            -6.63283
evaluation/Returns Min            -7.43052
evaluation/Actions Mean            0.00356775
evaluation/Actions Std             0.0578052
evaluation/Actions Max             0.999957
evaluation/Actions Min            -0.673331
evaluation/Num Paths               5
evaluation/Average Returns        -6.8503
time/data storing (s)              0.00124769
time/evaluation sampling (s)       0.0758941
time/exploration sampling (s)      0.0319694
time/logging (s)                   0.00244321
time/saving (s)                    0.00224928
time/training (s)                  0.453689
time/epoch (s)                     0.567493
time/total (s)                    91.0585
Epoch                            157
-----------------------------  ---------------
2019-04-13 17:00:05.503934 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size             31900
trainer/QF1 Loss                   0.0784732
trainer/QF2 Loss                   0.0838798
trainer/Policy Loss               10.2111
trainer/Q1 Predictions Mean      -10.3427
trainer/Q1 Predictions Std         0.375202
trainer/Q1 Predictions Max       -10.1269
trainer/Q1 Predictions Min       -12.3753
trainer/Q2 Predictions Mean      -10.333
trainer/Q2 Predictions Std         0.372413
trainer/Q2 Predictions Max       -10.1351
trainer/Q2 Predictions Min       -12.3572
trainer/Q Targets Mean           -10.5838
trainer/Q Targets Std              0.37216
trainer/Q Targets Max            -10.2189
trainer/Q Targets Min            -12.4583
trainer/Bellman Errors 1 Mean      0.0784732
trainer/Bellman Errors 1 Std       0.0774922
trainer/Bellman Errors 1 Max       0.307391
trainer/Bellman Errors 1 Min       0.000245484
trainer/Bellman Errors 2 Mean      0.0838798
trainer/Bellman Errors 2 Std       0.0800233
trainer/Bellman Errors 2 Max       0.323276
trainer/Bellman Errors 2 Min       0.00067903
trainer/Policy Action Mean         0.0344137
trainer/Policy Action Std          0.213856
trainer/Policy Action Max          0.998848
trainer/Policy Action Min         -0.297342
exploration/num steps total    31900
exploration/num paths total      319
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.12886
exploration/Rewards Std            0.0787979
exploration/Rewards Max           -0.0125211
exploration/Rewards Min           -0.7257
exploration/Returns Mean         -12.886
exploration/Returns Std            1.09024
exploration/Returns Max          -11.7958
exploration/Returns Min          -13.9763
exploration/Actions Mean           0.00687619
exploration/Actions Std            0.162055
exploration/Actions Max            1
exploration/Actions Min           -0.377591
exploration/Num Paths              2
exploration/Average Returns      -12.886
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0304819
evaluation/Rewards Std             0.0343795
evaluation/Rewards Max            -0.00972318
evaluation/Rewards Min            -0.750708
evaluation/Returns Mean           -3.04819
evaluation/Returns Std             0.26876
evaluation/Returns Max            -2.81549
evaluation/Returns Min            -3.55242
evaluation/Actions Mean            0.00457416
evaluation/Actions Std             0.0674017
evaluation/Actions Max             0.999947
evaluation/Actions Min            -0.702445
evaluation/Num Paths               5
evaluation/Average Returns        -3.04819
time/data storing (s)              0.00103859
time/evaluation sampling (s)       0.0807019
time/exploration sampling (s)      0.0322426
time/logging (s)                   0.00248309
time/saving (s)                    0.00233949
time/training (s)                  0.44179
time/epoch (s)                     0.560596
time/total (s)                    91.6227
Epoch                            158
-----------------------------  ---------------
2019-04-13 17:00:06.069558 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size             32100
trainer/QF1 Loss                   0.0462755
trainer/QF2 Loss                   0.0483367
trainer/Policy Loss               10.4394
trainer/Q1 Predictions Mean      -10.6293
trainer/Q1 Predictions Std         0.666647
trainer/Q1 Predictions Max       -10.31
trainer/Q1 Predictions Min       -14.0011
trainer/Q2 Predictions Mean      -10.6352
trainer/Q2 Predictions Std         0.681201
trainer/Q2 Predictions Max       -10.3413
trainer/Q2 Predictions Min       -14.089
trainer/Q Targets Mean           -10.7427
trainer/Q Targets Std              0.596182
trainer/Q Targets Max            -10.2769
trainer/Q Targets Min            -13.5842
trainer/Bellman Errors 1 Mean      0.0462755
trainer/Bellman Errors 1 Std       0.0718914
trainer/Bellman Errors 1 Max       0.257875
trainer/Bellman Errors 1 Min       3.53683e-06
trainer/Bellman Errors 2 Mean      0.0483367
trainer/Bellman Errors 2 Std       0.0742596
trainer/Bellman Errors 2 Max       0.254771
trainer/Bellman Errors 2 Min       4.26758e-07
trainer/Policy Action Mean         0.0368003
trainer/Policy Action Std          0.249005
trainer/Policy Action Max          0.996992
trainer/Policy Action Min         -0.949588
exploration/num steps total    32100
exploration/num paths total      321
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.150315
exploration/Rewards Std            0.0956393
exploration/Rewards Max           -0.0209921
exploration/Rewards Min           -0.950736
exploration/Returns Mean         -15.0315
exploration/Returns Std            0.652187
exploration/Returns Max          -14.3793
exploration/Returns Min          -15.6837
exploration/Actions Mean           0.00572634
exploration/Actions Std            0.16614
exploration/Actions Max            1
exploration/Actions Min           -0.894612
exploration/Num Paths              2
exploration/Average Returns      -15.0315
evaluation/num steps total     80000
evaluation/num paths total       800
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0628378
evaluation/Rewards Std             0.0393024
evaluation/Rewards Max            -0.0513001
evaluation/Rewards Min            -0.797921
evaluation/Returns Mean           -6.28378
evaluation/Returns Std             0.278156
evaluation/Returns Max            -5.9412
evaluation/Returns Min            -6.75978
evaluation/Actions Mean            0.00856456
evaluation/Actions Std             0.0821439
evaluation/Actions Max             0.999943
evaluation/Actions Min            -0.100993
evaluation/Num Paths               5
evaluation/Average Returns        -6.28378
time/data storing (s)              0.00105885
time/evaluation sampling (s)       0.076805
time/exploration sampling (s)      0.031428
time/logging (s)                   0.00271783
time/saving (s)                    0.00248831
time/training (s)                  0.445464
time/epoch (s)                     0.559962
time/total (s)                    92.1865
Epoch                            159
-----------------------------  ---------------
2019-04-13 17:00:06.638039 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size             32300
trainer/QF1 Loss                   3.34223
trainer/QF2 Loss                   3.33284
trainer/Policy Loss               10.2583
trainer/Q1 Predictions Mean      -10.4009
trainer/Q1 Predictions Std         0.231622
trainer/Q1 Predictions Max       -10.2156
trainer/Q1 Predictions Min       -11.5444
trainer/Q2 Predictions Mean      -10.4087
trainer/Q2 Predictions Std         0.234602
trainer/Q2 Predictions Max       -10.2394
trainer/Q2 Predictions Min       -11.5805
trainer/Q Targets Mean           -10.3034
trainer/Q Targets Std              1.86708
trainer/Q Targets Max             -0.0391901
trainer/Q Targets Min            -11.8983
trainer/Bellman Errors 1 Mean      3.34223
trainer/Bellman Errors 1 Std      18.163
trainer/Bellman Errors 1 Max     104.468
trainer/Bellman Errors 1 Min       4.42348e-05
trainer/Bellman Errors 2 Mean      3.33284
trainer/Bellman Errors 2 Std      18.1337
trainer/Bellman Errors 2 Max     104.296
trainer/Bellman Errors 2 Min       0.000252617
trainer/Policy Action Mean         0.0350172
trainer/Policy Action Std          0.191878
trainer/Policy Action Max          0.903573
trainer/Policy Action Min         -0.325296
exploration/num steps total    32300
exploration/num paths total      323
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.127192
exploration/Rewards Std            0.0712788
exploration/Rewards Max           -0.00573699
exploration/Rewards Min           -0.339995
exploration/Returns Mean         -12.7192
exploration/Returns Std            0.687893
exploration/Returns Max          -12.0313
exploration/Returns Min          -13.4071
exploration/Actions Mean           0.00194357
exploration/Actions Std            0.144661
exploration/Actions Max            0.405752
exploration/Actions Min           -0.701116
exploration/Num Paths              2
exploration/Average Returns      -12.7192
evaluation/num steps total     80500
evaluation/num paths total       805
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0223786
evaluation/Rewards Std             0.0252156
evaluation/Rewards Max            -0.012661
evaluation/Rewards Min            -0.562807
evaluation/Returns Mean           -2.23786
evaluation/Returns Std             0.207047
evaluation/Returns Max            -2.09211
evaluation/Returns Min            -2.6466
evaluation/Actions Mean            0.00212264
evaluation/Actions Std             0.0752638
evaluation/Actions Max             0.999468
evaluation/Actions Min            -0.876771
evaluation/Num Paths               5
evaluation/Average Returns        -2.23786
time/data storing (s)              0.00221288
time/evaluation sampling (s)       0.0747211
time/exploration sampling (s)      0.034607
time/logging (s)                   0.00251106
time/saving (s)                    0.00223184
time/training (s)                  0.445554
time/epoch (s)                     0.561838
time/total (s)                    92.7521
Epoch                            160
-----------------------------  ---------------
2019-04-13 17:00:07.219159 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size             32500
trainer/QF1 Loss                   3.34684
trainer/QF2 Loss                   3.3551
trainer/Policy Loss               10.3329
trainer/Q1 Predictions Mean      -10.5818
trainer/Q1 Predictions Std         0.417454
trainer/Q1 Predictions Max       -10.3016
trainer/Q1 Predictions Min       -12.6037
trainer/Q2 Predictions Mean      -10.5714
trainer/Q2 Predictions Std         0.403632
trainer/Q2 Predictions Max       -10.3085
trainer/Q2 Predictions Min       -12.5245
trainer/Q Targets Mean           -10.4339
trainer/Q Targets Std              1.90241
trainer/Q Targets Max             -0.170792
trainer/Q Targets Min            -12.8609
trainer/Bellman Errors 1 Mean      3.34684
trainer/Bellman Errors 1 Std      18.3208
trainer/Bellman Errors 1 Max     105.352
trainer/Bellman Errors 1 Min       8.90856e-05
trainer/Bellman Errors 2 Mean      3.3551
trainer/Bellman Errors 2 Std      18.3417
trainer/Bellman Errors 2 Max     105.476
trainer/Bellman Errors 2 Min       0.000189642
trainer/Policy Action Mean         0.0460733
trainer/Policy Action Std          0.172349
trainer/Policy Action Max          0.996587
trainer/Policy Action Min         -0.277929
exploration/num steps total    32500
exploration/num paths total      325
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.13692
exploration/Rewards Std            0.0734291
exploration/Rewards Max           -0.012484
exploration/Rewards Min           -0.539698
exploration/Returns Mean         -13.692
exploration/Returns Std            0.226398
exploration/Returns Max          -13.4656
exploration/Returns Min          -13.9184
exploration/Actions Mean           0.0060859
exploration/Actions Std            0.155952
exploration/Actions Max            0.889204
exploration/Actions Min           -0.410918
exploration/Num Paths              2
exploration/Average Returns      -13.692
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0470002
evaluation/Rewards Std             0.0740311
evaluation/Rewards Max            -0.0271009
evaluation/Rewards Min            -0.970393
evaluation/Returns Mean           -4.70002
evaluation/Returns Std             0.336337
evaluation/Returns Max            -4.1366
evaluation/Returns Min            -4.9744
evaluation/Actions Mean            0.0079117
evaluation/Actions Std             0.0910546
evaluation/Actions Max             0.999994
evaluation/Actions Min            -0.488228
evaluation/Num Paths               5
evaluation/Average Returns        -4.70002
time/data storing (s)              0.00113489
time/evaluation sampling (s)       0.0778533
time/exploration sampling (s)      0.0377042
time/logging (s)                   0.00252688
time/saving (s)                    0.00226401
time/training (s)                  0.453005
time/epoch (s)                     0.574489
time/total (s)                    93.3304
Epoch                            161
-----------------------------  ---------------
2019-04-13 17:00:07.796623 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size             32700
trainer/QF1 Loss                   3.45189
trainer/QF2 Loss                   3.45951
trainer/Policy Loss               10.4626
trainer/Q1 Predictions Mean      -10.6979
trainer/Q1 Predictions Std         0.435387
trainer/Q1 Predictions Max       -10.47
trainer/Q1 Predictions Min       -12.9616
trainer/Q2 Predictions Mean      -10.6927
trainer/Q2 Predictions Std         0.413724
trainer/Q2 Predictions Max       -10.4718
trainer/Q2 Predictions Min       -12.833
trainer/Q Targets Mean           -10.4077
trainer/Q Targets Std              1.90353
trainer/Q Targets Max             -0.145997
trainer/Q Targets Min            -13.1644
trainer/Bellman Errors 1 Mean      3.45189
trainer/Bellman Errors 1 Std      19.0876
trainer/Bellman Errors 1 Max     109.727
trainer/Bellman Errors 1 Min       0.000126231
trainer/Bellman Errors 2 Mean      3.45951
trainer/Bellman Errors 2 Std      19.111
trainer/Bellman Errors 2 Max     109.865
trainer/Bellman Errors 2 Min       0.000168195
trainer/Policy Action Mean         0.0288445
trainer/Policy Action Std          0.183132
trainer/Policy Action Max          0.995835
trainer/Policy Action Min         -0.322719
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.130016
exploration/Rewards Std            0.0680878
exploration/Rewards Max           -0.00617096
exploration/Rewards Min           -0.342683
exploration/Returns Mean         -13.0016
exploration/Returns Std            0.459065
exploration/Returns Max          -12.5425
exploration/Returns Min          -13.4607
exploration/Actions Mean           0.00859364
exploration/Actions Std            0.143479
exploration/Actions Max            0.883251
exploration/Actions Min           -0.471417
exploration/Num Paths              2
exploration/Average Returns      -13.0016
evaluation/num steps total     81500
evaluation/num paths total       815
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0578099
evaluation/Rewards Std             0.0489126
evaluation/Rewards Max            -0.0229871
evaluation/Rewards Min            -0.870514
evaluation/Returns Mean           -5.78099
evaluation/Returns Std             0.317212
evaluation/Returns Max            -5.49357
evaluation/Returns Min            -6.21731
evaluation/Actions Mean            0.00925744
evaluation/Actions Std             0.085553
evaluation/Actions Max             0.999981
evaluation/Actions Min            -0.203541
evaluation/Num Paths               5
evaluation/Average Returns        -5.78099
time/data storing (s)              0.00121147
time/evaluation sampling (s)       0.077444
time/exploration sampling (s)      0.0341243
time/logging (s)                   0.00248644
time/saving (s)                    0.00226099
time/training (s)                  0.450454
time/epoch (s)                     0.567981
time/total (s)                    93.9051
Epoch                            162
-----------------------------  ---------------
2019-04-13 17:00:08.368461 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size             32900
trainer/QF1 Loss                   3.35966
trainer/QF2 Loss                   3.37189
trainer/Policy Loss               10.2944
trainer/Q1 Predictions Mean      -10.4699
trainer/Q1 Predictions Std         0.471846
trainer/Q1 Predictions Max       -10.259
trainer/Q1 Predictions Min       -13.0571
trainer/Q2 Predictions Mean      -10.4722
trainer/Q2 Predictions Std         0.488364
trainer/Q2 Predictions Max       -10.2548
trainer/Q2 Predictions Min       -13.1515
trainer/Q Targets Mean           -10.3954
trainer/Q Targets Std              1.92502
trainer/Q Targets Max             -0.0590946
trainer/Q Targets Min            -13.4516
trainer/Bellman Errors 1 Mean      3.35967
trainer/Bellman Errors 1 Std      18.23
trainer/Bellman Errors 1 Max     104.859
trainer/Bellman Errors 1 Min       0.000162287
trainer/Bellman Errors 2 Mean      3.37189
trainer/Bellman Errors 2 Std      18.3103
trainer/Bellman Errors 2 Max     105.318
trainer/Bellman Errors 2 Min       0.000763093
trainer/Policy Action Mean        -0.0314104
trainer/Policy Action Std          0.166029
trainer/Policy Action Max          0.99775
trainer/Policy Action Min         -0.327919
exploration/num steps total    32900
exploration/num paths total      329
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.150195
exploration/Rewards Std            0.0940505
exploration/Rewards Max           -0.0096398
exploration/Rewards Min           -0.894218
exploration/Returns Mean         -15.0195
exploration/Returns Std            0.163876
exploration/Returns Max          -14.8556
exploration/Returns Min          -15.1834
exploration/Actions Mean           0.00808964
exploration/Actions Std            0.168216
exploration/Actions Max            0.923217
exploration/Actions Min           -0.447369
exploration/Num Paths              2
exploration/Average Returns      -15.0195
evaluation/num steps total     82000
evaluation/num paths total       820
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0644452
evaluation/Rewards Std             0.0422292
evaluation/Rewards Max            -0.016672
evaluation/Rewards Min            -0.754932
evaluation/Returns Mean           -6.44452
evaluation/Returns Std             0.283607
evaluation/Returns Max            -6.15215
evaluation/Returns Min            -6.78974
evaluation/Actions Mean            0.00451896
evaluation/Actions Std             0.0839812
evaluation/Actions Max             0.99997
evaluation/Actions Min            -0.944045
evaluation/Num Paths               5
evaluation/Average Returns        -6.44452
time/data storing (s)              0.00112963
time/evaluation sampling (s)       0.0762792
time/exploration sampling (s)      0.033216
time/logging (s)                   0.00255522
time/saving (s)                    0.00227497
time/training (s)                  0.44989
time/epoch (s)                     0.565345
time/total (s)                    94.4742
Epoch                            163
-----------------------------  ---------------
2019-04-13 17:00:08.931174 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size             33100
trainer/QF1 Loss                   0.0168908
trainer/QF2 Loss                   0.0187284
trainer/Policy Loss               10.5262
trainer/Q1 Predictions Mean      -10.7151
trainer/Q1 Predictions Std         0.551798
trainer/Q1 Predictions Max       -10.406
trainer/Q1 Predictions Min       -13.4567
trainer/Q2 Predictions Mean      -10.7172
trainer/Q2 Predictions Std         0.569566
trainer/Q2 Predictions Max       -10.3881
trainer/Q2 Predictions Min       -13.5767
trainer/Q Targets Mean           -10.7761
trainer/Q Targets Std              0.574612
trainer/Q Targets Max            -10.3936
trainer/Q Targets Min            -13.562
trainer/Bellman Errors 1 Mean      0.0168908
trainer/Bellman Errors 1 Std       0.0349074
trainer/Bellman Errors 1 Max       0.143375
trainer/Bellman Errors 1 Min       1.60156e-06
trainer/Bellman Errors 2 Mean      0.0187284
trainer/Bellman Errors 2 Std       0.037462
trainer/Bellman Errors 2 Max       0.152167
trainer/Bellman Errors 2 Min       3.04914e-06
trainer/Policy Action Mean         0.00757898
trainer/Policy Action Std          0.190991
trainer/Policy Action Max          0.998369
trainer/Policy Action Min         -0.408552
exploration/num steps total    33100
exploration/num paths total      331
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.144122
exploration/Rewards Std            0.0721726
exploration/Rewards Max           -0.0163891
exploration/Rewards Min           -0.46223
exploration/Returns Mean         -14.4122
exploration/Returns Std            0.874052
exploration/Returns Max          -13.5381
exploration/Returns Min          -15.2862
exploration/Actions Mean          -0.000826891
exploration/Actions Std            0.140594
exploration/Actions Max            0.435206
exploration/Actions Min           -0.51995
exploration/Num Paths              2
exploration/Average Returns      -14.4122
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0637468
evaluation/Rewards Std             0.0273725
evaluation/Rewards Max            -0.0277095
evaluation/Rewards Min            -0.455818
evaluation/Returns Mean           -6.37468
evaluation/Returns Std             0.189572
evaluation/Returns Max            -6.1166
evaluation/Returns Min            -6.59335
evaluation/Actions Mean            0.00392655
evaluation/Actions Std             0.0727598
evaluation/Actions Max             0.999397
evaluation/Actions Min            -0.744007
evaluation/Num Paths               5
evaluation/Average Returns        -6.37468
time/data storing (s)              0.00113284
time/evaluation sampling (s)       0.0714454
time/exploration sampling (s)      0.0330645
time/logging (s)                   0.00247837
time/saving (s)                    0.00222402
time/training (s)                  0.445705
time/epoch (s)                     0.55605
time/total (s)                    95.0341
Epoch                            164
-----------------------------  ---------------
2019-04-13 17:00:09.495717 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size             33300
trainer/QF1 Loss                   0.0381101
trainer/QF2 Loss                   0.0376896
trainer/Policy Loss               10.5035
trainer/Q1 Predictions Mean      -10.7142
trainer/Q1 Predictions Std         0.588034
trainer/Q1 Predictions Max       -10.4868
trainer/Q1 Predictions Min       -13.9483
trainer/Q2 Predictions Mean      -10.7142
trainer/Q2 Predictions Std         0.587861
trainer/Q2 Predictions Max       -10.4981
trainer/Q2 Predictions Min       -13.9493
trainer/Q Targets Mean           -10.7637
trainer/Q Targets Std              0.712211
trainer/Q Targets Max            -10.3546
trainer/Q Targets Min            -14.5934
trainer/Bellman Errors 1 Mean      0.0381101
trainer/Bellman Errors 1 Std       0.0903242
trainer/Bellman Errors 1 Max       0.416254
trainer/Bellman Errors 1 Min       2.53457e-05
trainer/Bellman Errors 2 Mean      0.0376896
trainer/Bellman Errors 2 Std       0.0891339
trainer/Bellman Errors 2 Max       0.414901
trainer/Bellman Errors 2 Min       1.91363e-05
trainer/Policy Action Mean         0.0164912
trainer/Policy Action Std          0.201409
trainer/Policy Action Max          0.999104
trainer/Policy Action Min         -0.29065
exploration/num steps total    33300
exploration/num paths total      333
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.125321
exploration/Rewards Std            0.0686077
exploration/Rewards Max           -0.00672032
exploration/Rewards Min           -0.36091
exploration/Returns Mean         -12.5321
exploration/Returns Std            0.695131
exploration/Returns Max          -11.837
exploration/Returns Min          -13.2272
exploration/Actions Mean          -0.000379676
exploration/Actions Std            0.161391
exploration/Actions Max            0.934372
exploration/Actions Min           -0.964164
exploration/Num Paths              2
exploration/Average Returns      -12.5321
evaluation/num steps total     83000
evaluation/num paths total       830
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0332831
evaluation/Rewards Std             0.0347822
evaluation/Rewards Max            -0.0200653
evaluation/Rewards Min            -0.620453
evaluation/Returns Mean           -3.32831
evaluation/Returns Std             0.244173
evaluation/Returns Max            -3.07548
evaluation/Returns Min            -3.67628
evaluation/Actions Mean            0.00628843
evaluation/Actions Std             0.0821126
evaluation/Actions Max             0.99986
evaluation/Actions Min            -0.818519
evaluation/Num Paths               5
evaluation/Average Returns        -3.32831
time/data storing (s)              0.00114319
time/evaluation sampling (s)       0.076587
time/exploration sampling (s)      0.0327092
time/logging (s)                   0.00246127
time/saving (s)                    0.00230505
time/training (s)                  0.443471
time/epoch (s)                     0.558676
time/total (s)                    95.5959
Epoch                            165
-----------------------------  ---------------
2019-04-13 17:00:10.066702 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size             33500
trainer/QF1 Loss                   0.0217573
trainer/QF2 Loss                   0.0255681
trainer/Policy Loss               10.7515
trainer/Q1 Predictions Mean      -10.8422
trainer/Q1 Predictions Std         0.293678
trainer/Q1 Predictions Max       -10.6297
trainer/Q1 Predictions Min       -11.7503
trainer/Q2 Predictions Mean      -10.8577
trainer/Q2 Predictions Std         0.29737
trainer/Q2 Predictions Max       -10.6518
trainer/Q2 Predictions Min       -11.7913
trainer/Q Targets Mean           -10.7974
trainer/Q Targets Std              0.345646
trainer/Q Targets Max            -10.4099
trainer/Q Targets Min            -11.8954
trainer/Bellman Errors 1 Mean      0.0217573
trainer/Bellman Errors 1 Std       0.019278
trainer/Bellman Errors 1 Max       0.0767314
trainer/Bellman Errors 1 Min       1.01613e-06
trainer/Bellman Errors 2 Mean      0.0255681
trainer/Bellman Errors 2 Std       0.0217742
trainer/Bellman Errors 2 Max       0.0831447
trainer/Bellman Errors 2 Min       6.91311e-06
trainer/Policy Action Mean        -0.0157881
trainer/Policy Action Std          0.159035
trainer/Policy Action Max          0.45621
trainer/Policy Action Min         -0.333956
exploration/num steps total    33500
exploration/num paths total      335
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.121291
exploration/Rewards Std            0.0629483
exploration/Rewards Max           -0.00907466
exploration/Rewards Min           -0.371327
exploration/Returns Mean         -12.1291
exploration/Returns Std            0.422615
exploration/Returns Max          -11.7065
exploration/Returns Min          -12.5517
exploration/Actions Mean           0.00509096
exploration/Actions Std            0.134998
exploration/Actions Max            0.557707
exploration/Actions Min           -0.386659
exploration/Num Paths              2
exploration/Average Returns      -12.1291
evaluation/num steps total     83500
evaluation/num paths total       835
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0132312
evaluation/Rewards Std             0.0426874
evaluation/Rewards Max            -0.00227546
evaluation/Rewards Min            -0.794258
evaluation/Returns Mean           -1.32312
evaluation/Returns Std             0.34364
evaluation/Returns Max            -1.02763
evaluation/Returns Min            -1.86586
evaluation/Actions Mean            0.0063756
evaluation/Actions Std             0.0697622
evaluation/Actions Max             0.999966
evaluation/Actions Min            -0.506619
evaluation/Num Paths               5
evaluation/Average Returns        -1.32312
time/data storing (s)              0.00106909
time/evaluation sampling (s)       0.0753669
time/exploration sampling (s)      0.0335864
time/logging (s)                   0.0024498
time/saving (s)                    0.0023691
time/training (s)                  0.45033
time/epoch (s)                     0.565171
time/total (s)                    96.1641
Epoch                            166
-----------------------------  ---------------
2019-04-13 17:00:10.642215 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size             33700
trainer/QF1 Loss                   3.45906
trainer/QF2 Loss                   3.43113
trainer/Policy Loss               10.5534
trainer/Q1 Predictions Mean      -10.6151
trainer/Q1 Predictions Std         0.101314
trainer/Q1 Predictions Max       -10.4919
trainer/Q1 Predictions Min       -10.993
trainer/Q2 Predictions Mean      -10.6206
trainer/Q2 Predictions Std         0.107108
trainer/Q2 Predictions Max       -10.4995
trainer/Q2 Predictions Min       -11.0703
trainer/Q Targets Mean           -10.4072
trainer/Q Targets Std              1.85261
trainer/Q Targets Max             -0.122948
trainer/Q Targets Min            -11.2076
trainer/Bellman Errors 1 Mean      3.45906
trainer/Bellman Errors 1 Std      19.0593
trainer/Bellman Errors 1 Max     109.576
trainer/Bellman Errors 1 Min       2.00309e-05
trainer/Bellman Errors 2 Mean      3.43113
trainer/Bellman Errors 2 Std      18.9227
trainer/Bellman Errors 2 Max     108.788
trainer/Bellman Errors 2 Min       2.15881e-05
trainer/Policy Action Mean        -0.0120636
trainer/Policy Action Std          0.172389
trainer/Policy Action Max          0.920324
trainer/Policy Action Min         -0.279592
exploration/num steps total    33700
exploration/num paths total      337
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.137883
exploration/Rewards Std            0.0775603
exploration/Rewards Max           -0.00863572
exploration/Rewards Min           -0.523127
exploration/Returns Mean         -13.7883
exploration/Returns Std            0.289317
exploration/Returns Max          -13.4989
exploration/Returns Min          -14.0776
exploration/Actions Mean           0.00688975
exploration/Actions Std            0.155125
exploration/Actions Max            0.916925
exploration/Actions Min           -0.55723
exploration/Num Paths              2
exploration/Average Returns      -13.7883
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.057891
evaluation/Rewards Std             0.0525416
evaluation/Rewards Max            -0.0529649
evaluation/Rewards Min            -0.975358
evaluation/Returns Mean           -5.7891
evaluation/Returns Std             0.315438
evaluation/Returns Max            -5.37887
evaluation/Returns Min            -6.28115
evaluation/Actions Mean            0.00881186
evaluation/Actions Std             0.0813433
evaluation/Actions Max             0.999984
evaluation/Actions Min            -0.143669
evaluation/Num Paths               5
evaluation/Average Returns        -5.7891
time/data storing (s)              0.00112339
time/evaluation sampling (s)       0.0754915
time/exploration sampling (s)      0.0336762
time/logging (s)                   0.00248001
time/saving (s)                    0.00273165
time/training (s)                  0.453442
time/epoch (s)                     0.568944
time/total (s)                    96.7368
Epoch                            167
-----------------------------  ---------------
2019-04-13 17:00:11.656272 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size             33900
trainer/QF1 Loss                   0.068439
trainer/QF2 Loss                   0.0670229
trainer/Policy Loss               10.5606
trainer/Q1 Predictions Mean      -10.7449
trainer/Q1 Predictions Std         0.536164
trainer/Q1 Predictions Max       -10.4531
trainer/Q1 Predictions Min       -13.172
trainer/Q2 Predictions Mean      -10.7509
trainer/Q2 Predictions Std         0.529263
trainer/Q2 Predictions Max       -10.4445
trainer/Q2 Predictions Min       -13.1038
trainer/Q Targets Mean           -10.9222
trainer/Q Targets Std              0.51781
trainer/Q Targets Max            -10.4594
trainer/Q Targets Min            -13.1321
trainer/Bellman Errors 1 Mean      0.068439
trainer/Bellman Errors 1 Std       0.108517
trainer/Bellman Errors 1 Max       0.432008
trainer/Bellman Errors 1 Min       4.05231e-05
trainer/Bellman Errors 2 Mean      0.0670229
trainer/Bellman Errors 2 Std       0.105906
trainer/Bellman Errors 2 Max       0.428053
trainer/Bellman Errors 2 Min       0.000221817
trainer/Policy Action Mean         0.0328695
trainer/Policy Action Std          0.258174
trainer/Policy Action Max          0.999918
trainer/Policy Action Min         -0.684139
exploration/num steps total    33900
exploration/num paths total      339
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129832
exploration/Rewards Std            0.0661034
exploration/Rewards Max           -0.0161283
exploration/Rewards Min           -0.352663
exploration/Returns Mean         -12.9832
exploration/Returns Std            0.111183
exploration/Returns Max          -12.872
exploration/Returns Min          -13.0944
exploration/Actions Mean           0.00177732
exploration/Actions Std            0.147071
exploration/Actions Max            0.428077
exploration/Actions Min           -0.430812
exploration/Num Paths              2
exploration/Average Returns      -12.9832
evaluation/num steps total     84500
evaluation/num paths total       845
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0341569
evaluation/Rewards Std             0.0393746
evaluation/Rewards Max            -0.0259112
evaluation/Rewards Min            -0.812265
evaluation/Returns Mean           -3.41569
evaluation/Returns Std             0.312827
evaluation/Returns Max            -3.14192
evaluation/Returns Min            -3.98032
evaluation/Actions Mean            0.00328066
evaluation/Actions Std             0.0704631
evaluation/Actions Max             0.999938
evaluation/Actions Min            -0.754912
evaluation/Num Paths               5
evaluation/Average Returns        -3.41569
time/data storing (s)              0.00345849
time/evaluation sampling (s)       0.244726
time/exploration sampling (s)      0.0705275
time/logging (s)                   0.0025651
time/saving (s)                    0.00246898
time/training (s)                  0.683687
time/epoch (s)                     1.00743
time/total (s)                    97.7481
Epoch                            168
-----------------------------  ---------------
2019-04-13 17:00:12.591153 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size             34100
trainer/QF1 Loss                   0.0425799
trainer/QF2 Loss                   0.0429054
trainer/Policy Loss               10.5416
trainer/Q1 Predictions Mean      -10.6173
trainer/Q1 Predictions Std         0.0779485
trainer/Q1 Predictions Max       -10.5181
trainer/Q1 Predictions Min       -10.8046
trainer/Q2 Predictions Mean      -10.6169
trainer/Q2 Predictions Std         0.0716378
trainer/Q2 Predictions Max       -10.5207
trainer/Q2 Predictions Min       -10.7864
trainer/Q Targets Mean           -10.7704
trainer/Q Targets Std              0.173213
trainer/Q Targets Max            -10.4233
trainer/Q Targets Min            -11.1232
trainer/Bellman Errors 1 Mean      0.0425799
trainer/Bellman Errors 1 Std       0.0552237
trainer/Bellman Errors 1 Max       0.225339
trainer/Bellman Errors 1 Min       2.00834e-06
trainer/Bellman Errors 2 Mean      0.0429054
trainer/Bellman Errors 2 Std       0.0554553
trainer/Bellman Errors 2 Max       0.213789
trainer/Bellman Errors 2 Min       2.82271e-05
trainer/Policy Action Mean         0.00951846
trainer/Policy Action Std          0.0944703
trainer/Policy Action Max          0.266277
trainer/Policy Action Min         -0.181703
exploration/num steps total    34100
exploration/num paths total      341
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135313
exploration/Rewards Std            0.0688334
exploration/Rewards Max           -0.0112369
exploration/Rewards Min           -0.351295
exploration/Returns Mean         -13.5313
exploration/Returns Std            0.153676
exploration/Returns Max          -13.3776
exploration/Returns Min          -13.685
exploration/Actions Mean           0.00169231
exploration/Actions Std            0.143075
exploration/Actions Max            0.626428
exploration/Actions Min           -0.849277
exploration/Num Paths              2
exploration/Average Returns      -13.5313
evaluation/num steps total     85000
evaluation/num paths total       850
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0452342
evaluation/Rewards Std             0.0403159
evaluation/Rewards Max            -0.03338
evaluation/Rewards Min            -0.930262
evaluation/Returns Mean           -4.52342
evaluation/Returns Std             0.353296
evaluation/Returns Max            -4.28925
evaluation/Returns Min            -5.22567
evaluation/Actions Mean            0.00410805
evaluation/Actions Std             0.0713104
evaluation/Actions Max             0.999976
evaluation/Actions Min            -0.919018
evaluation/Num Paths               5
evaluation/Average Returns        -4.52342
time/data storing (s)              0.00107527
time/evaluation sampling (s)       0.271118
time/exploration sampling (s)      0.034445
time/logging (s)                   0.00247177
time/saving (s)                    0.0109182
time/training (s)                  0.607895
time/epoch (s)                     0.927923
time/total (s)                    98.6797
Epoch                            169
-----------------------------  ---------------
2019-04-13 17:00:13.119282 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size             34300
trainer/QF1 Loss                   3.52342
trainer/QF2 Loss                   3.53969
trainer/Policy Loss               10.599
trainer/Q1 Predictions Mean      -10.8217
trainer/Q1 Predictions Std         0.528482
trainer/Q1 Predictions Max       -10.597
trainer/Q1 Predictions Min       -13.7177
trainer/Q2 Predictions Mean      -10.8293
trainer/Q2 Predictions Std         0.524288
trainer/Q2 Predictions Max       -10.5998
trainer/Q2 Predictions Min       -13.6944
trainer/Q Targets Mean           -10.5697
trainer/Q Targets Std              1.96184
trainer/Q Targets Max             -0.184216
trainer/Q Targets Min            -14.1975
trainer/Bellman Errors 1 Mean      3.52342
trainer/Bellman Errors 1 Std      19.4559
trainer/Bellman Errors 1 Max     111.849
trainer/Bellman Errors 1 Min       6.53236e-08
trainer/Bellman Errors 2 Mean      3.53969
trainer/Bellman Errors 2 Std      19.5481
trainer/Bellman Errors 2 Max     112.379
trainer/Bellman Errors 2 Min       1.40471e-05
trainer/Policy Action Mean         0.0681468
trainer/Policy Action Std          0.209578
trainer/Policy Action Max          0.997232
trainer/Policy Action Min         -0.210624
exploration/num steps total    34300
exploration/num paths total      343
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.141248
exploration/Rewards Std            0.0894702
exploration/Rewards Max           -0.00136089
exploration/Rewards Min           -0.943357
exploration/Returns Mean         -14.1248
exploration/Returns Std            0.148746
exploration/Returns Max          -13.9761
exploration/Returns Min          -14.2735
exploration/Actions Mean           0.00679142
exploration/Actions Std            0.15961
exploration/Actions Max            0.933994
exploration/Actions Min           -0.811028
exploration/Num Paths              2
exploration/Average Returns      -14.1248
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0818944
evaluation/Rewards Std             0.044112
evaluation/Rewards Max            -0.0168882
evaluation/Rewards Min            -0.876626
evaluation/Returns Mean           -8.18944
evaluation/Returns Std             0.257487
evaluation/Returns Max            -7.90865
evaluation/Returns Min            -8.65582
evaluation/Actions Mean            0.00753588
evaluation/Actions Std             0.0805129
evaluation/Actions Max             0.999967
evaluation/Actions Min            -0.295003
evaluation/Num Paths               5
evaluation/Average Returns        -8.18944
time/data storing (s)              0.00111013
time/evaluation sampling (s)       0.0887254
time/exploration sampling (s)      0.0341757
time/logging (s)                   0.00207331
time/saving (s)                    0.0020605
time/training (s)                  0.394207
time/epoch (s)                     0.522352
time/total (s)                    99.2053
Epoch                            170
-----------------------------  ---------------
2019-04-13 17:00:13.660221 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 171 finished
-----------------------------  --------------
replay_buffer/size             34500
trainer/QF1 Loss                   0.119087
trainer/QF2 Loss                   0.113681
trainer/Policy Loss               10.5541
trainer/Q1 Predictions Mean      -10.6264
trainer/Q1 Predictions Std         0.458526
trainer/Q1 Predictions Max       -10.4213
trainer/Q1 Predictions Min       -13.1514
trainer/Q2 Predictions Mean      -10.6325
trainer/Q2 Predictions Std         0.466321
trainer/Q2 Predictions Max       -10.4208
trainer/Q2 Predictions Min       -13.2001
trainer/Q Targets Mean           -10.937
trainer/Q Targets Std              0.544384
trainer/Q Targets Max            -10.478
trainer/Q Targets Min            -13.8454
trainer/Bellman Errors 1 Mean      0.119087
trainer/Bellman Errors 1 Std       0.111626
trainer/Bellman Errors 1 Max       0.481635
trainer/Bellman Errors 1 Min       0.0014328
trainer/Bellman Errors 2 Mean      0.113681
trainer/Bellman Errors 2 Std       0.101872
trainer/Bellman Errors 2 Max       0.416289
trainer/Bellman Errors 2 Min       0.0013129
trainer/Policy Action Mean        -0.0189987
trainer/Policy Action Std          0.181124
trainer/Policy Action Max          0.99808
trainer/Policy Action Min         -0.246552
exploration/num steps total    34500
exploration/num paths total      345
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.143432
exploration/Rewards Std            0.078211
exploration/Rewards Max           -0.00627726
exploration/Rewards Min           -0.497574
exploration/Returns Mean         -14.3432
exploration/Returns Std            1.13685
exploration/Returns Max          -13.2064
exploration/Returns Min          -15.4801
exploration/Actions Mean           0.0051336
exploration/Actions Std            0.153204
exploration/Actions Max            0.991127
exploration/Actions Min           -0.800355
exploration/Num Paths              2
exploration/Average Returns      -14.3432
evaluation/num steps total     86000
evaluation/num paths total       860
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0593957
evaluation/Rewards Std             0.0377227
evaluation/Rewards Max            -0.0329634
evaluation/Rewards Min            -0.854401
evaluation/Returns Mean           -5.93957
evaluation/Returns Std             0.353772
evaluation/Returns Max            -5.64473
evaluation/Returns Min            -6.61214
evaluation/Actions Mean            0.00491769
evaluation/Actions Std             0.0723332
evaluation/Actions Max             0.999856
evaluation/Actions Min            -0.791434
evaluation/Num Paths               5
evaluation/Average Returns        -5.93957
time/data storing (s)              0.00111603
time/evaluation sampling (s)       0.0760012
time/exploration sampling (s)      0.0326151
time/logging (s)                   0.00249646
time/saving (s)                    0.00248086
time/training (s)                  0.419707
time/epoch (s)                     0.534417
time/total (s)                    99.7439
Epoch                            171
-----------------------------  --------------
2019-04-13 17:00:14.328748 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size             34700
trainer/QF1 Loss                   0.0303023
trainer/QF2 Loss                   0.02832
trainer/Policy Loss               10.7003
trainer/Q1 Predictions Mean      -10.8246
trainer/Q1 Predictions Std         0.27122
trainer/Q1 Predictions Max       -10.6448
trainer/Q1 Predictions Min       -11.8162
trainer/Q2 Predictions Mean      -10.8272
trainer/Q2 Predictions Std         0.291094
trainer/Q2 Predictions Max       -10.6479
trainer/Q2 Predictions Min       -11.8841
trainer/Q Targets Mean           -10.9164
trainer/Q Targets Std              0.274318
trainer/Q Targets Max            -10.5098
trainer/Q Targets Min            -11.6923
trainer/Bellman Errors 1 Mean      0.0303023
trainer/Bellman Errors 1 Std       0.0369922
trainer/Bellman Errors 1 Max       0.143545
trainer/Bellman Errors 1 Min       4.68083e-05
trainer/Bellman Errors 2 Mean      0.02832
trainer/Bellman Errors 2 Std       0.0356631
trainer/Bellman Errors 2 Max       0.143972
trainer/Bellman Errors 2 Min       8.13061e-05
trainer/Policy Action Mean        -0.0134535
trainer/Policy Action Std          0.288034
trainer/Policy Action Max          0.999978
trainer/Policy Action Min         -0.973943
exploration/num steps total    34700
exploration/num paths total      347
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.137433
exploration/Rewards Std            0.0717094
exploration/Rewards Max           -0.0166252
exploration/Rewards Min           -0.373468
exploration/Returns Mean         -13.7433
exploration/Returns Std            0.0657071
exploration/Returns Max          -13.6776
exploration/Returns Min          -13.809
exploration/Actions Mean          -0.000651644
exploration/Actions Std            0.134886
exploration/Actions Max            0.438184
exploration/Actions Min           -0.521571
exploration/Num Paths              2
exploration/Average Returns      -13.7433
evaluation/num steps total     86500
evaluation/num paths total       865
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0725495
evaluation/Rewards Std             0.0231447
evaluation/Rewards Max            -0.0555163
evaluation/Rewards Min            -0.573989
evaluation/Returns Mean           -7.25495
evaluation/Returns Std             0.212907
evaluation/Returns Max            -7.13979
evaluation/Returns Min            -7.68047
evaluation/Actions Mean            0.00351503
evaluation/Actions Std             0.0607129
evaluation/Actions Max             0.998955
evaluation/Actions Min            -0.73829
evaluation/Num Paths               5
evaluation/Average Returns        -7.25495
time/data storing (s)              0.00116616
time/evaluation sampling (s)       0.0799369
time/exploration sampling (s)      0.0401323
time/logging (s)                   0.00246492
time/saving (s)                    0.00226007
time/training (s)                  0.535395
time/epoch (s)                     0.661356
time/total (s)                   100.409
Epoch                            172
-----------------------------  ---------------
2019-04-13 17:00:14.844837 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size             34900
trainer/QF1 Loss                   0.0957203
trainer/QF2 Loss                   0.0944046
trainer/Policy Loss               10.5102
trainer/Q1 Predictions Mean      -10.6099
trainer/Q1 Predictions Std         0.0798401
trainer/Q1 Predictions Max       -10.4858
trainer/Q1 Predictions Min       -10.7825
trainer/Q2 Predictions Mean      -10.6113
trainer/Q2 Predictions Std         0.0756222
trainer/Q2 Predictions Max       -10.4978
trainer/Q2 Predictions Min       -10.7707
trainer/Q Targets Mean           -10.8726
trainer/Q Targets Std              0.191359
trainer/Q Targets Max            -10.5964
trainer/Q Targets Min            -11.3615
trainer/Bellman Errors 1 Mean      0.0957203
trainer/Bellman Errors 1 Std       0.100811
trainer/Bellman Errors 1 Max       0.35045
trainer/Bellman Errors 1 Min       0.000979008
trainer/Bellman Errors 2 Mean      0.0944047
trainer/Bellman Errors 2 Std       0.102612
trainer/Bellman Errors 2 Max       0.367692
trainer/Bellman Errors 2 Min       0.00198028
trainer/Policy Action Mean        -0.0188019
trainer/Policy Action Std          0.097688
trainer/Policy Action Max          0.248667
trainer/Policy Action Min         -0.258393
exploration/num steps total    34900
exploration/num paths total      349
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.122714
exploration/Rewards Std            0.0697197
exploration/Rewards Max           -0.0124951
exploration/Rewards Min           -0.355992
exploration/Returns Mean         -12.2714
exploration/Returns Std            0.519024
exploration/Returns Max          -11.7524
exploration/Returns Min          -12.7905
exploration/Actions Mean           0.00219892
exploration/Actions Std            0.132431
exploration/Actions Max            0.368119
exploration/Actions Min           -0.450436
exploration/Num Paths              2
exploration/Average Returns      -12.2714
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0373411
evaluation/Rewards Std             0.0386522
evaluation/Rewards Max            -0.0346096
evaluation/Rewards Min            -0.873349
evaluation/Returns Mean           -3.73411
evaluation/Returns Std             0.334264
evaluation/Returns Max            -3.52048
evaluation/Returns Min            -4.39729
evaluation/Actions Mean            0.00588265
evaluation/Actions Std             0.0674259
evaluation/Actions Max             0.999918
evaluation/Actions Min            -0.281339
evaluation/Num Paths               5
evaluation/Average Returns        -3.73411
time/data storing (s)              0.00111038
time/evaluation sampling (s)       0.0734014
time/exploration sampling (s)      0.0333364
time/logging (s)                   0.00247306
time/saving (s)                    0.00242662
time/training (s)                  0.39659
time/epoch (s)                     0.509338
time/total (s)                   100.923
Epoch                            173
-----------------------------  ---------------
2019-04-13 17:00:15.427915 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size             35100
trainer/QF1 Loss                   3.85975
trainer/QF2 Loss                   3.82311
trainer/Policy Loss               10.7369
trainer/Q1 Predictions Mean      -10.9287
trainer/Q1 Predictions Std         0.160992
trainer/Q1 Predictions Max       -10.7572
trainer/Q1 Predictions Min       -11.726
trainer/Q2 Predictions Mean      -10.9202
trainer/Q2 Predictions Std         0.150249
trainer/Q2 Predictions Max       -10.7694
trainer/Q2 Predictions Min       -11.6735
trainer/Q Targets Mean           -10.6001
trainer/Q Targets Std              1.7943
trainer/Q Targets Max             -0.643602
trainer/Q Targets Min            -11.1792
trainer/Bellman Errors 1 Mean      3.85975
trainer/Bellman Errors 1 Std      21.3657
trainer/Bellman Errors 1 Max     122.819
trainer/Bellman Errors 1 Min       0.000119863
trainer/Bellman Errors 2 Mean      3.82311
trainer/Bellman Errors 2 Std      21.1639
trainer/Bellman Errors 2 Max     121.659
trainer/Bellman Errors 2 Min       1.50657e-07
trainer/Policy Action Mean         0.00950407
trainer/Policy Action Std          0.129274
trainer/Policy Action Max          0.503766
trainer/Policy Action Min         -0.351587
exploration/num steps total    35100
exploration/num paths total      351
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.124972
exploration/Rewards Std            0.0834512
exploration/Rewards Max           -0.0109056
exploration/Rewards Min           -0.86591
exploration/Returns Mean         -12.4972
exploration/Returns Std            0.10165
exploration/Returns Max          -12.3956
exploration/Returns Min          -12.5989
exploration/Actions Mean           0.00604285
exploration/Actions Std            0.157724
exploration/Actions Max            0.921932
exploration/Actions Min           -0.60275
exploration/Num Paths              2
exploration/Average Returns      -12.4972
evaluation/num steps total     87500
evaluation/num paths total       875
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0158039
evaluation/Rewards Std             0.0200538
evaluation/Rewards Max            -0.00499
evaluation/Rewards Min            -0.415628
evaluation/Returns Mean           -1.58039
evaluation/Returns Std             0.15602
evaluation/Returns Max            -1.4223
evaluation/Returns Min            -1.87222
evaluation/Actions Mean            0.00394996
evaluation/Actions Std             0.0696935
evaluation/Actions Max             0.997367
evaluation/Actions Min            -0.556036
evaluation/Num Paths               5
evaluation/Average Returns        -1.58039
time/data storing (s)              0.00129667
time/evaluation sampling (s)       0.0774659
time/exploration sampling (s)      0.0339843
time/logging (s)                   0.00255693
time/saving (s)                    0.00224899
time/training (s)                  0.458911
time/epoch (s)                     0.576464
time/total (s)                   101.503
Epoch                            174
-----------------------------  ---------------
2019-04-13 17:00:15.951763 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size             35300
trainer/QF1 Loss                   0.0548314
trainer/QF2 Loss                   0.0593972
trainer/Policy Loss               10.6215
trainer/Q1 Predictions Mean      -10.9264
trainer/Q1 Predictions Std         0.574534
trainer/Q1 Predictions Max       -10.6153
trainer/Q1 Predictions Min       -13.3674
trainer/Q2 Predictions Mean      -10.9041
trainer/Q2 Predictions Std         0.560606
trainer/Q2 Predictions Max       -10.6239
trainer/Q2 Predictions Min       -13.2704
trainer/Q Targets Mean           -11.0821
trainer/Q Targets Std              0.574549
trainer/Q Targets Max            -10.6539
trainer/Q Targets Min            -13.6228
trainer/Bellman Errors 1 Mean      0.0548314
trainer/Bellman Errors 1 Std       0.0688771
trainer/Bellman Errors 1 Max       0.298636
trainer/Bellman Errors 1 Min       8.62783e-06
trainer/Bellman Errors 2 Mean      0.0593972
trainer/Bellman Errors 2 Std       0.0707004
trainer/Bellman Errors 2 Max       0.29611
trainer/Bellman Errors 2 Min       3.9462e-06
trainer/Policy Action Mean         0.0547594
trainer/Policy Action Std          0.215508
trainer/Policy Action Max          0.998044
trainer/Policy Action Min         -0.320484
exploration/num steps total    35300
exploration/num paths total      353
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.127579
exploration/Rewards Std            0.0685127
exploration/Rewards Max           -0.00300907
exploration/Rewards Min           -0.409317
exploration/Returns Mean         -12.7579
exploration/Returns Std            0.296644
exploration/Returns Max          -12.4613
exploration/Returns Min          -13.0545
exploration/Actions Mean           0.00618129
exploration/Actions Std            0.143738
exploration/Actions Max            1
exploration/Actions Min           -0.359349
exploration/Num Paths              2
exploration/Average Returns      -12.7579
evaluation/num steps total     88000
evaluation/num paths total       880
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0303193
evaluation/Rewards Std             0.04894
evaluation/Rewards Max            -0.0190265
evaluation/Rewards Min            -0.963343
evaluation/Returns Mean           -3.03193
evaluation/Returns Std             0.387164
evaluation/Returns Max            -2.65643
evaluation/Returns Min            -3.67871
evaluation/Actions Mean            0.00695106
evaluation/Actions Std             0.0772163
evaluation/Actions Max             0.99998
evaluation/Actions Min            -0.551305
evaluation/Num Paths               5
evaluation/Average Returns        -3.03193
time/data storing (s)              0.00111169
time/evaluation sampling (s)       0.0751081
time/exploration sampling (s)      0.0334873
time/logging (s)                   0.00249949
time/saving (s)                    0.00248748
time/training (s)                  0.402635
time/epoch (s)                     0.517329
time/total (s)                   102.024
Epoch                            175
-----------------------------  ---------------
2019-04-13 17:00:16.465794 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size             35500
trainer/QF1 Loss                   3.89707
trainer/QF2 Loss                   3.8951
trainer/Policy Loss               11.0825
trainer/Q1 Predictions Mean      -11.2281
trainer/Q1 Predictions Std         0.161598
trainer/Q1 Predictions Max       -11.0984
trainer/Q1 Predictions Min       -11.8269
trainer/Q2 Predictions Mean      -11.2336
trainer/Q2 Predictions Std         0.169364
trainer/Q2 Predictions Max       -11.1063
trainer/Q2 Predictions Min       -11.8728
trainer/Q Targets Mean           -10.6627
trainer/Q Targets Std              1.91223
trainer/Q Targets Max             -0.125041
trainer/Q Targets Min            -11.8923
trainer/Bellman Errors 1 Mean      3.89707
trainer/Bellman Errors 1 Std      21.2516
trainer/Bellman Errors 1 Max     122.22
trainer/Bellman Errors 1 Min       0.000113822
trainer/Bellman Errors 2 Mean      3.8951
trainer/Bellman Errors 2 Std      21.2351
trainer/Bellman Errors 2 Max     122.126
trainer/Bellman Errors 2 Min       5.67525e-06
trainer/Policy Action Mean        -0.0132729
trainer/Policy Action Std          0.125132
trainer/Policy Action Max          0.24795
trainer/Policy Action Min         -0.389061
exploration/num steps total    35500
exploration/num paths total      355
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135419
exploration/Rewards Std            0.0715502
exploration/Rewards Max           -0.00457546
exploration/Rewards Min           -0.390133
exploration/Returns Mean         -13.5419
exploration/Returns Std            0.653548
exploration/Returns Max          -12.8883
exploration/Returns Min          -14.1954
exploration/Actions Mean           0.00674151
exploration/Actions Std            0.152734
exploration/Actions Max            1
exploration/Actions Min           -0.369132
exploration/Num Paths              2
exploration/Average Returns      -13.5419
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0331153
evaluation/Rewards Std             0.0266411
evaluation/Rewards Max            -0.0254502
evaluation/Rewards Min            -0.608054
evaluation/Returns Mean           -3.31153
evaluation/Returns Std             0.233997
evaluation/Returns Max            -3.17526
evaluation/Returns Min            -3.7784
evaluation/Actions Mean            0.0059415
evaluation/Actions Std             0.060417
evaluation/Actions Max             0.999449
evaluation/Actions Min            -0.079284
evaluation/Num Paths               5
evaluation/Average Returns        -3.31153
time/data storing (s)              0.0011283
time/evaluation sampling (s)       0.0742919
time/exploration sampling (s)      0.0330328
time/logging (s)                   0.00248141
time/saving (s)                    0.00226616
time/training (s)                  0.393997
time/epoch (s)                     0.507197
time/total (s)                   102.535
Epoch                            176
-----------------------------  ---------------
2019-04-13 17:00:16.987207 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size             35700
trainer/QF1 Loss                   0.0563346
trainer/QF2 Loss                   0.0562858
trainer/Policy Loss               10.7878
trainer/Q1 Predictions Mean      -10.8988
trainer/Q1 Predictions Std         0.129514
trainer/Q1 Predictions Max       -10.7491
trainer/Q1 Predictions Min       -11.3402
trainer/Q2 Predictions Mean      -10.8899
trainer/Q2 Predictions Std         0.132183
trainer/Q2 Predictions Max       -10.7584
trainer/Q2 Predictions Min       -11.3852
trainer/Q Targets Mean           -11.0146
trainer/Q Targets Std              0.226194
trainer/Q Targets Max            -10.6776
trainer/Q Targets Min            -11.7237
trainer/Bellman Errors 1 Mean      0.0563346
trainer/Bellman Errors 1 Std       0.0857237
trainer/Bellman Errors 1 Max       0.378619
trainer/Bellman Errors 1 Min       1.30779e-05
trainer/Bellman Errors 2 Mean      0.0562858
trainer/Bellman Errors 2 Std       0.0847398
trainer/Bellman Errors 2 Max       0.387582
trainer/Bellman Errors 2 Min       1.37767e-05
trainer/Policy Action Mean         0.0194142
trainer/Policy Action Std          0.155791
trainer/Policy Action Max          0.890805
trainer/Policy Action Min         -0.355701
exploration/num steps total    35700
exploration/num paths total      357
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.140619
exploration/Rewards Std            0.0773474
exploration/Rewards Max           -0.0154675
exploration/Rewards Min           -0.687661
exploration/Returns Mean         -14.0619
exploration/Returns Std            0.383704
exploration/Returns Max          -13.6782
exploration/Returns Min          -14.4456
exploration/Actions Mean           0.00169748
exploration/Actions Std            0.164516
exploration/Actions Max            0.940353
exploration/Actions Min           -0.813554
exploration/Num Paths              2
exploration/Average Returns      -14.0619
evaluation/num steps total     89000
evaluation/num paths total       890
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0225297
evaluation/Rewards Std             0.0165529
evaluation/Rewards Max            -0.0214085
evaluation/Rewards Min            -0.382304
evaluation/Returns Mean           -2.25297
evaluation/Returns Std             0.154686
evaluation/Returns Max            -2.16445
evaluation/Returns Min            -2.56145
evaluation/Actions Mean            0.00164231
evaluation/Actions Std             0.0624024
evaluation/Actions Max             0.996131
evaluation/Actions Min            -0.915631
evaluation/Num Paths               5
evaluation/Average Returns        -2.25297
time/data storing (s)              0.00116124
time/evaluation sampling (s)       0.0772105
time/exploration sampling (s)      0.0334882
time/logging (s)                   0.00247105
time/saving (s)                    0.00224594
time/training (s)                  0.398028
time/epoch (s)                     0.514605
time/total (s)                   103.053
Epoch                            177
-----------------------------  ---------------
2019-04-13 17:00:17.502418 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size             35900
trainer/QF1 Loss                   0.0904475
trainer/QF2 Loss                   0.0963134
trainer/Policy Loss               10.7297
trainer/Q1 Predictions Mean      -11.0284
trainer/Q1 Predictions Std         0.601774
trainer/Q1 Predictions Max       -10.626
trainer/Q1 Predictions Min       -13.3127
trainer/Q2 Predictions Mean      -11.0215
trainer/Q2 Predictions Std         0.601663
trainer/Q2 Predictions Max       -10.6425
trainer/Q2 Predictions Min       -13.3198
trainer/Q Targets Mean           -11.2444
trainer/Q Targets Std              0.688503
trainer/Q Targets Max            -10.6722
trainer/Q Targets Min            -14.0555
trainer/Bellman Errors 1 Mean      0.0904475
trainer/Bellman Errors 1 Std       0.168918
trainer/Bellman Errors 1 Max       0.747052
trainer/Bellman Errors 1 Min       3.18041e-06
trainer/Bellman Errors 2 Mean      0.0963134
trainer/Bellman Errors 2 Std       0.180816
trainer/Bellman Errors 2 Max       0.845221
trainer/Bellman Errors 2 Min       4.09248e-05
trainer/Policy Action Mean         0.000492031
trainer/Policy Action Std          0.233024
trainer/Policy Action Max          0.99668
trainer/Policy Action Min         -0.374987
exploration/num steps total    35900
exploration/num paths total      359
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.130202
exploration/Rewards Std            0.0865623
exploration/Rewards Max           -0.00970566
exploration/Rewards Min           -0.926019
exploration/Returns Mean         -13.0202
exploration/Returns Std            0.025491
exploration/Returns Max          -12.9947
exploration/Returns Min          -13.0457
exploration/Actions Mean           0.002948
exploration/Actions Std            0.158285
exploration/Actions Max            0.881709
exploration/Actions Min           -0.749058
exploration/Num Paths              2
exploration/Average Returns      -13.0202
evaluation/num steps total     89500
evaluation/num paths total       895
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0362453
evaluation/Rewards Std             0.0343261
evaluation/Rewards Max            -0.0198744
evaluation/Rewards Min            -0.642612
evaluation/Returns Mean           -3.62453
evaluation/Returns Std             0.273024
evaluation/Returns Max            -3.32084
evaluation/Returns Min            -4.04194
evaluation/Actions Mean            0.00713036
evaluation/Actions Std             0.0679913
evaluation/Actions Max             0.999359
evaluation/Actions Min            -0.0488934
evaluation/Num Paths               5
evaluation/Average Returns        -3.62453
time/data storing (s)              0.00108788
time/evaluation sampling (s)       0.0755526
time/exploration sampling (s)      0.0327228
time/logging (s)                   0.00209764
time/saving (s)                    0.00178957
time/training (s)                  0.394702
time/epoch (s)                     0.507952
time/total (s)                   103.565
Epoch                            178
-----------------------------  ---------------
2019-04-13 17:00:18.014998 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size             36100
trainer/QF1 Loss                   3.62046
trainer/QF2 Loss                   3.63667
trainer/Policy Loss               10.8502
trainer/Q1 Predictions Mean      -10.9648
trainer/Q1 Predictions Std         0.238442
trainer/Q1 Predictions Max       -10.8074
trainer/Q1 Predictions Min       -12.1953
trainer/Q2 Predictions Mean      -10.9708
trainer/Q2 Predictions Std         0.223214
trainer/Q2 Predictions Max       -10.8229
trainer/Q2 Predictions Min       -12.1216
trainer/Q Targets Mean           -10.6734
trainer/Q Targets Std              1.91028
trainer/Q Targets Max             -0.154598
trainer/Q Targets Min            -12.3822
trainer/Bellman Errors 1 Mean      3.62046
trainer/Bellman Errors 1 Std      20.0542
trainer/Bellman Errors 1 Max     115.277
trainer/Bellman Errors 1 Min       1.4771e-07
trainer/Bellman Errors 2 Mean      3.63667
trainer/Bellman Errors 2 Std      20.1392
trainer/Bellman Errors 2 Max     115.767
trainer/Bellman Errors 2 Min       8.68957e-06
trainer/Policy Action Mean        -0.00744935
trainer/Policy Action Std          0.115133
trainer/Policy Action Max          0.494275
trainer/Policy Action Min         -0.187956
exploration/num steps total    36100
exploration/num paths total      361
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.133343
exploration/Rewards Std            0.0865275
exploration/Rewards Max           -0.0125702
exploration/Rewards Min           -0.851009
exploration/Returns Mean         -13.3343
exploration/Returns Std            0.712885
exploration/Returns Max          -12.6214
exploration/Returns Min          -14.0472
exploration/Actions Mean           0.00642072
exploration/Actions Std            0.144111
exploration/Actions Max            0.880503
exploration/Actions Min           -0.327902
exploration/Num Paths              2
exploration/Average Returns      -13.3343
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0372336
evaluation/Rewards Std             0.0385333
evaluation/Rewards Max            -0.025477
evaluation/Rewards Min            -0.818839
evaluation/Returns Mean           -3.72336
evaluation/Returns Std             0.301999
evaluation/Returns Max            -3.43833
evaluation/Returns Min            -4.29992
evaluation/Actions Mean            0.00574145
evaluation/Actions Std             0.072285
evaluation/Actions Max             0.999868
evaluation/Actions Min            -0.854781
evaluation/Num Paths               5
evaluation/Average Returns        -3.72336
time/data storing (s)              0.00109568
time/evaluation sampling (s)       0.0736591
time/exploration sampling (s)      0.0320895
time/logging (s)                   0.00188808
time/saving (s)                    0.00216339
time/training (s)                  0.394629
time/epoch (s)                     0.505525
time/total (s)                   104.075
Epoch                            179
-----------------------------  ---------------
2019-04-13 17:00:18.529592 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size             36300
trainer/QF1 Loss                   0.0290258
trainer/QF2 Loss                   0.0321815
trainer/Policy Loss               10.8481
trainer/Q1 Predictions Mean      -11.0252
trainer/Q1 Predictions Std         0.507513
trainer/Q1 Predictions Max       -10.7563
trainer/Q1 Predictions Min       -13.5633
trainer/Q2 Predictions Mean      -11.0265
trainer/Q2 Predictions Std         0.506201
trainer/Q2 Predictions Max       -10.7793
trainer/Q2 Predictions Min       -13.5608
trainer/Q Targets Mean           -11.1298
trainer/Q Targets Std              0.523125
trainer/Q Targets Max            -10.6794
trainer/Q Targets Min            -13.6379
trainer/Bellman Errors 1 Mean      0.0290258
trainer/Bellman Errors 1 Std       0.0555223
trainer/Bellman Errors 1 Max       0.307626
trainer/Bellman Errors 1 Min       4.57831e-05
trainer/Bellman Errors 2 Mean      0.0321815
trainer/Bellman Errors 2 Std       0.0610619
trainer/Bellman Errors 2 Max       0.338278
trainer/Bellman Errors 2 Min       4.7122e-05
trainer/Policy Action Mean        -0.0543392
trainer/Policy Action Std          0.18203
trainer/Policy Action Max          0.997258
trainer/Policy Action Min         -0.435658
exploration/num steps total    36300
exploration/num paths total      363
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.152308
exploration/Rewards Std            0.0750003
exploration/Rewards Max           -0.00188229
exploration/Rewards Min           -0.422671
exploration/Returns Mean         -15.2308
exploration/Returns Std            0.325548
exploration/Returns Max          -14.9053
exploration/Returns Min          -15.5564
exploration/Actions Mean           0.00372951
exploration/Actions Std            0.166739
exploration/Actions Max            1
exploration/Actions Min           -0.840381
exploration/Num Paths              2
exploration/Average Returns      -15.2308
evaluation/num steps total     90500
evaluation/num paths total       905
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0770421
evaluation/Rewards Std             0.0402625
evaluation/Rewards Max            -0.0744133
evaluation/Rewards Min            -0.952186
evaluation/Returns Mean           -7.70421
evaluation/Returns Std             0.336621
evaluation/Returns Max            -7.47522
evaluation/Returns Min            -8.36834
evaluation/Actions Mean            0.0050166
evaluation/Actions Std             0.0723404
evaluation/Actions Max             0.999947
evaluation/Actions Min            -0.688829
evaluation/Num Paths               5
evaluation/Average Returns        -7.70421
time/data storing (s)              0.00132919
time/evaluation sampling (s)       0.0766707
time/exploration sampling (s)      0.0329347
time/logging (s)                   0.00248646
time/saving (s)                    0.00235893
time/training (s)                  0.392967
time/epoch (s)                     0.508747
time/total (s)                   104.587
Epoch                            180
-----------------------------  ---------------
2019-04-13 17:00:19.043397 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size             36500
trainer/QF1 Loss                   0.110022
trainer/QF2 Loss                   0.108449
trainer/Policy Loss               10.646
trainer/Q1 Predictions Mean      -10.7254
trainer/Q1 Predictions Std         0.0740269
trainer/Q1 Predictions Max       -10.6064
trainer/Q1 Predictions Min       -10.911
trainer/Q2 Predictions Mean      -10.7275
trainer/Q2 Predictions Std         0.0671199
trainer/Q2 Predictions Max       -10.6217
trainer/Q2 Predictions Min       -10.8889
trainer/Q Targets Mean           -11.0189
trainer/Q Targets Std              0.157735
trainer/Q Targets Max            -10.7236
trainer/Q Targets Min            -11.3038
trainer/Bellman Errors 1 Mean      0.110022
trainer/Bellman Errors 1 Std       0.0992902
trainer/Bellman Errors 1 Max       0.348678
trainer/Bellman Errors 1 Min       0.000387604
trainer/Bellman Errors 2 Mean      0.108449
trainer/Bellman Errors 2 Std       0.0986182
trainer/Bellman Errors 2 Max       0.347876
trainer/Bellman Errors 2 Min       0.000515088
trainer/Policy Action Mean         0.0215522
trainer/Policy Action Std          0.107517
trainer/Policy Action Max          0.221105
trainer/Policy Action Min         -0.363523
exploration/num steps total    36500
exploration/num paths total      365
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.129944
exploration/Rewards Std            0.0648834
exploration/Rewards Max           -0.01198
exploration/Rewards Min           -0.38376
exploration/Returns Mean         -12.9944
exploration/Returns Std            0.314935
exploration/Returns Max          -12.6795
exploration/Returns Min          -13.3094
exploration/Actions Mean           0.00283405
exploration/Actions Std            0.154139
exploration/Actions Max            0.994913
exploration/Actions Min           -0.900871
exploration/Num Paths              2
exploration/Average Returns      -12.9944
evaluation/num steps total     91000
evaluation/num paths total       910
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0371947
evaluation/Rewards Std             0.0518174
evaluation/Rewards Max            -0.0323349
evaluation/Rewards Min            -0.85631
evaluation/Returns Mean           -3.71947
evaluation/Returns Std             0.264405
evaluation/Returns Max            -3.32193
evaluation/Returns Min            -4.08499
evaluation/Actions Mean            0.00891261
evaluation/Actions Std             0.0830561
evaluation/Actions Max             0.999943
evaluation/Actions Min            -0.146333
evaluation/Num Paths               5
evaluation/Average Returns        -3.71947
time/data storing (s)              0.0011212
time/evaluation sampling (s)       0.075695
time/exploration sampling (s)      0.033013
time/logging (s)                   0.00184216
time/saving (s)                    0.00176595
time/training (s)                  0.392795
time/epoch (s)                     0.506232
time/total (s)                   105.097
Epoch                            181
-----------------------------  ---------------
2019-04-13 17:00:19.560893 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size             36700
trainer/QF1 Loss                   0.151571
trainer/QF2 Loss                   0.149936
trainer/Policy Loss               10.6979
trainer/Q1 Predictions Mean      -10.7812
trainer/Q1 Predictions Std         0.234976
trainer/Q1 Predictions Max       -10.6057
trainer/Q1 Predictions Min       -11.6749
trainer/Q2 Predictions Mean      -10.7832
trainer/Q2 Predictions Std         0.232957
trainer/Q2 Predictions Max       -10.6376
trainer/Q2 Predictions Min       -11.6955
trainer/Q Targets Mean           -11.1366
trainer/Q Targets Std              0.300648
trainer/Q Targets Max            -10.7759
trainer/Q Targets Min            -12.1989
trainer/Bellman Errors 1 Mean      0.151571
trainer/Bellman Errors 1 Std       0.131785
trainer/Bellman Errors 1 Max       0.582454
trainer/Bellman Errors 1 Min       0.000381507
trainer/Bellman Errors 2 Mean      0.149936
trainer/Bellman Errors 2 Std       0.12869
trainer/Bellman Errors 2 Max       0.597881
trainer/Bellman Errors 2 Min       0.000303118
trainer/Policy Action Mean        -0.0129463
trainer/Policy Action Std          0.192189
trainer/Policy Action Max          0.976315
trainer/Policy Action Min         -0.372557
exploration/num steps total    36700
exploration/num paths total      367
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.131824
exploration/Rewards Std            0.0804864
exploration/Rewards Max           -0.00880829
exploration/Rewards Min           -0.798823
exploration/Returns Mean         -13.1824
exploration/Returns Std            0.399816
exploration/Returns Max          -12.7826
exploration/Returns Min          -13.5822
exploration/Actions Mean           0.00355819
exploration/Actions Std            0.16844
exploration/Actions Max            0.981283
exploration/Actions Min           -0.76844
exploration/Num Paths              2
exploration/Average Returns      -13.1824
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0368464
evaluation/Rewards Std             0.0151365
evaluation/Rewards Max            -0.034266
evaluation/Rewards Min            -0.277779
evaluation/Returns Mean           -3.68464
evaluation/Returns Std             0.116225
evaluation/Returns Max            -3.5853
evaluation/Returns Min            -3.83004
evaluation/Actions Mean            0.00190404
evaluation/Actions Std             0.0587837
evaluation/Actions Max             0.994555
evaluation/Actions Min            -0.792092
evaluation/Num Paths               5
evaluation/Average Returns        -3.68464
time/data storing (s)              0.00113415
time/evaluation sampling (s)       0.0758669
time/exploration sampling (s)      0.0339926
time/logging (s)                   0.00265105
time/saving (s)                    0.00226227
time/training (s)                  0.395641
time/epoch (s)                     0.511548
time/total (s)                   105.613
Epoch                            182
-----------------------------  ---------------
2019-04-13 17:00:20.073842 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size             36900
trainer/QF1 Loss                   0.04389
trainer/QF2 Loss                   0.0426521
trainer/Policy Loss               10.9831
trainer/Q1 Predictions Mean      -11.1212
trainer/Q1 Predictions Std         0.652288
trainer/Q1 Predictions Max       -10.8108
trainer/Q1 Predictions Min       -13.7343
trainer/Q2 Predictions Mean      -11.1163
trainer/Q2 Predictions Std         0.677888
trainer/Q2 Predictions Max       -10.8059
trainer/Q2 Predictions Min       -13.8999
trainer/Q Targets Mean           -11.2594
trainer/Q Targets Std              0.680556
trainer/Q Targets Max            -10.7562
trainer/Q Targets Min            -14.0139
trainer/Bellman Errors 1 Mean      0.04389
trainer/Bellman Errors 1 Std       0.0572366
trainer/Bellman Errors 1 Max       0.251139
trainer/Bellman Errors 1 Min       1.19975e-05
trainer/Bellman Errors 2 Mean      0.042652
trainer/Bellman Errors 2 Std       0.0587928
trainer/Bellman Errors 2 Max       0.249823
trainer/Bellman Errors 2 Min       1.60358e-05
trainer/Policy Action Mean         0.0025432
trainer/Policy Action Std          0.247132
trainer/Policy Action Max          0.997257
trainer/Policy Action Min         -0.463588
exploration/num steps total    36900
exploration/num paths total      369
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.137817
exploration/Rewards Std            0.106544
exploration/Rewards Max           -0.0155975
exploration/Rewards Min           -1.05737
exploration/Returns Mean         -13.7817
exploration/Returns Std            0.674837
exploration/Returns Max          -13.1068
exploration/Returns Min          -14.4565
exploration/Actions Mean           0.0102537
exploration/Actions Std            0.178103
exploration/Actions Max            1
exploration/Actions Min           -0.720368
exploration/Num Paths              2
exploration/Average Returns      -13.7817
evaluation/num steps total     92000
evaluation/num paths total       920
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0390824
evaluation/Rewards Std             0.0439682
evaluation/Rewards Max            -0.031842
evaluation/Rewards Min            -0.906242
evaluation/Returns Mean           -3.90824
evaluation/Returns Std             0.346427
evaluation/Returns Max            -3.61386
evaluation/Returns Min            -4.51069
evaluation/Actions Mean            0.00350424
evaluation/Actions Std             0.0750087
evaluation/Actions Max             0.999987
evaluation/Actions Min            -0.853939
evaluation/Num Paths               5
evaluation/Average Returns        -3.90824
time/data storing (s)              0.00122487
time/evaluation sampling (s)       0.0749277
time/exploration sampling (s)      0.0326838
time/logging (s)                   0.00227189
time/saving (s)                    0.00246456
time/training (s)                  0.392096
time/epoch (s)                     0.505669
time/total (s)                   106.122
Epoch                            183
-----------------------------  ---------------
2019-04-13 17:00:20.578052 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size             37100
trainer/QF1 Loss                   3.70323
trainer/QF2 Loss                   3.70562
trainer/Policy Loss               10.9243
trainer/Q1 Predictions Mean      -11.0582
trainer/Q1 Predictions Std         0.41927
trainer/Q1 Predictions Max       -10.8631
trainer/Q1 Predictions Min       -13.0433
trainer/Q2 Predictions Mean      -11.0535
trainer/Q2 Predictions Std         0.408954
trainer/Q2 Predictions Max       -10.8619
trainer/Q2 Predictions Min       -12.967
trainer/Q Targets Mean           -10.8125
trainer/Q Targets Std              1.96515
trainer/Q Targets Max             -0.111385
trainer/Q Targets Min            -12.9935
trainer/Bellman Errors 1 Mean      3.70323
trainer/Bellman Errors 1 Std      20.4704
trainer/Bellman Errors 1 Max     117.677
trainer/Bellman Errors 1 Min       1.92868e-05
trainer/Bellman Errors 2 Mean      3.70562
trainer/Bellman Errors 2 Std      20.4729
trainer/Bellman Errors 2 Max     117.693
trainer/Bellman Errors 2 Min       2.6462e-05
trainer/Policy Action Mean         0.0504245
trainer/Policy Action Std          0.189975
trainer/Policy Action Max          0.92975
trainer/Policy Action Min         -0.387625
exploration/num steps total    37100
exploration/num paths total      371
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.139422
exploration/Rewards Std            0.0726514
exploration/Rewards Max           -0.00707511
exploration/Rewards Min           -0.429905
exploration/Returns Mean         -13.9422
exploration/Returns Std            0.125625
exploration/Returns Max          -13.8166
exploration/Returns Min          -14.0678
exploration/Actions Mean           0.00210308
exploration/Actions Std            0.165844
exploration/Actions Max            1
exploration/Actions Min           -0.861892
exploration/Num Paths              2
exploration/Average Returns      -13.9422
evaluation/num steps total     92500
evaluation/num paths total       925
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0142384
evaluation/Rewards Std             0.0278486
evaluation/Rewards Max            -0.0117418
evaluation/Rewards Min            -0.504727
evaluation/Returns Mean           -1.42384
evaluation/Returns Std             0.200809
evaluation/Returns Max            -1.2466
evaluation/Returns Min            -1.75199
evaluation/Actions Mean            0.00361817
evaluation/Actions Std             0.0657516
evaluation/Actions Max             0.999465
evaluation/Actions Min            -0.945369
evaluation/Num Paths               5
evaluation/Average Returns        -1.42384
time/data storing (s)              0.00104488
time/evaluation sampling (s)       0.0743684
time/exploration sampling (s)      0.0331614
time/logging (s)                   0.0024663
time/saving (s)                    0.00225845
time/training (s)                  0.385401
time/epoch (s)                     0.4987
time/total (s)                   106.624
Epoch                            184
-----------------------------  ---------------
2019-04-13 17:00:21.094801 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size             37300
trainer/QF1 Loss                   0.0355543
trainer/QF2 Loss                   0.0354113
trainer/Policy Loss               11.101
trainer/Q1 Predictions Mean      -11.1733
trainer/Q1 Predictions Std         0.476888
trainer/Q1 Predictions Max       -10.9681
trainer/Q1 Predictions Min       -13.7016
trainer/Q2 Predictions Mean      -11.1779
trainer/Q2 Predictions Std         0.477296
trainer/Q2 Predictions Max       -10.9544
trainer/Q2 Predictions Min       -13.7125
trainer/Q Targets Mean           -11.2304
trainer/Q Targets Std              0.485892
trainer/Q Targets Max            -10.8896
trainer/Q Targets Min            -13.442
trainer/Bellman Errors 1 Mean      0.0355543
trainer/Bellman Errors 1 Std       0.0767259
trainer/Bellman Errors 1 Max       0.441163
trainer/Bellman Errors 1 Min       2.89923e-05
trainer/Bellman Errors 2 Mean      0.0354113
trainer/Bellman Errors 2 Std       0.0779102
trainer/Bellman Errors 2 Max       0.449128
trainer/Bellman Errors 2 Min       5.50837e-06
trainer/Policy Action Mean         0.0329874
trainer/Policy Action Std          0.171892
trainer/Policy Action Max          0.99754
trainer/Policy Action Min         -0.365589
exploration/num steps total    37300
exploration/num paths total      373
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.135933
exploration/Rewards Std            0.0924434
exploration/Rewards Max           -0.00805236
exploration/Rewards Min           -0.946008
exploration/Returns Mean         -13.5933
exploration/Returns Std            0.0906466
exploration/Returns Max          -13.5026
exploration/Returns Min          -13.6839
exploration/Actions Mean           0.00572065
exploration/Actions Std            0.159636
exploration/Actions Max            1
exploration/Actions Min           -0.688247
exploration/Num Paths              2
exploration/Average Returns      -13.5933
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0434348
evaluation/Rewards Std             0.0147325
evaluation/Rewards Max            -0.0385418
evaluation/Rewards Min            -0.296578
evaluation/Returns Mean           -4.34348
evaluation/Returns Std             0.0910484
evaluation/Returns Max            -4.23253
evaluation/Returns Min            -4.48364
evaluation/Actions Mean            0.00270465
evaluation/Actions Std             0.0780979
evaluation/Actions Max             0.979938
evaluation/Actions Min            -0.921034
evaluation/Num Paths               5
evaluation/Average Returns        -4.34348
time/data storing (s)              0.00114448
time/evaluation sampling (s)       0.0757309
time/exploration sampling (s)      0.0331748
time/logging (s)                   0.00249395
time/saving (s)                    0.00230348
time/training (s)                  0.394953
time/epoch (s)                     0.509801
time/total (s)                   107.138
Epoch                            185
-----------------------------  ---------------
2019-04-13 17:00:21.610034 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size             37500
trainer/QF1 Loss                   3.76974
trainer/QF2 Loss                   3.77019
trainer/Policy Loss               10.9189
trainer/Q1 Predictions Mean      -11.0689
trainer/Q1 Predictions Std         0.283048
trainer/Q1 Predictions Max       -10.8653
trainer/Q1 Predictions Min       -12.5203
trainer/Q2 Predictions Mean      -11.0776
trainer/Q2 Predictions Std         0.291797
trainer/Q2 Predictions Max       -10.8756
trainer/Q2 Predictions Min       -12.569
trainer/Q Targets Mean           -10.8184
trainer/Q Targets Std              1.94472
trainer/Q Targets Max             -0.131999
trainer/Q Targets Min            -12.5648
trainer/Bellman Errors 1 Mean      3.76974
trainer/Bellman Errors 1 Std      20.7601
trainer/Bellman Errors 1 Max     119.356
trainer/Bellman Errors 1 Min       3.81547e-05
trainer/Bellman Errors 2 Mean      3.77019
trainer/Bellman Errors 2 Std      20.7745
trainer/Bellman Errors 2 Max     119.437
trainer/Bellman Errors 2 Min       1.27761e-05
trainer/Policy Action Mean        -0.0252616
trainer/Policy Action Std          0.240482
trainer/Policy Action Max          0.99908
trainer/Policy Action Min         -0.88436
exploration/num steps total    37500
exploration/num paths total      375
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.152013
exploration/Rewards Std            0.075309
exploration/Rewards Max           -0.0077482
exploration/Rewards Min           -0.419531
exploration/Returns Mean         -15.2013
exploration/Returns Std            0.543682
exploration/Returns Max          -14.6576
exploration/Returns Min          -15.745
exploration/Actions Mean           0.00434837
exploration/Actions Std            0.16044
exploration/Actions Max            1
exploration/Actions Min           -0.495279
exploration/Num Paths              2
exploration/Average Returns      -15.2013
evaluation/num steps total     93500
evaluation/num paths total       935
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0834411
evaluation/Rewards Std             0.0550187
evaluation/Rewards Max            -0.0246402
evaluation/Rewards Min            -0.936441
evaluation/Returns Mean           -8.34411
evaluation/Returns Std             0.350514
evaluation/Returns Max            -7.88162
evaluation/Returns Min            -8.76202
evaluation/Actions Mean            0.00661771
evaluation/Actions Std             0.0819731
evaluation/Actions Max             0.999972
evaluation/Actions Min            -0.872157
evaluation/Num Paths               5
evaluation/Average Returns        -8.34411
time/data storing (s)              0.00106097
time/evaluation sampling (s)       0.0745938
time/exploration sampling (s)      0.0332825
time/logging (s)                   0.00245525
time/saving (s)                    0.00225042
time/training (s)                  0.395084
time/epoch (s)                     0.508727
time/total (s)                   107.65
Epoch                            186
-----------------------------  ---------------
2019-04-13 17:00:22.140859 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size             37700
trainer/QF1 Loss                   7.41945
trainer/QF2 Loss                   7.43452
trainer/Policy Loss               10.9586
trainer/Q1 Predictions Mean      -11.2245
trainer/Q1 Predictions Std         0.792817
trainer/Q1 Predictions Max       -10.89
trainer/Q1 Predictions Min       -15.2602
trainer/Q2 Predictions Mean      -11.22
trainer/Q2 Predictions Std         0.787172
trainer/Q2 Predictions Max       -10.8821
trainer/Q2 Predictions Min       -15.2596
trainer/Q Targets Mean           -10.6911
trainer/Q Targets Std              2.90473
trainer/Q Targets Max             -0.1367
trainer/Q Targets Min            -16.8195
trainer/Bellman Errors 1 Mean      7.41945
trainer/Bellman Errors 1 Std      28.3464
trainer/Bellman Errors 1 Max     117.276
trainer/Bellman Errors 1 Min       9.55341e-06
trainer/Bellman Errors 2 Mean      7.43453
trainer/Bellman Errors 2 Std      28.3914
trainer/Bellman Errors 2 Max     117.658
trainer/Bellman Errors 2 Min       2.88794e-05
trainer/Policy Action Mean        -0.0126017
trainer/Policy Action Std          0.238192
trainer/Policy Action Max          1
trainer/Policy Action Min         -0.996812
exploration/num steps total    37700
exploration/num paths total      377
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.130242
exploration/Rewards Std            0.0691507
exploration/Rewards Max           -0.00985648
exploration/Rewards Min           -0.333607
exploration/Returns Mean         -13.0242
exploration/Returns Std            0.0523852
exploration/Returns Max          -12.9718
exploration/Returns Min          -13.0766
exploration/Actions Mean           0.000185289
exploration/Actions Std            0.161313
exploration/Actions Max            0.889872
exploration/Actions Min           -0.904403
exploration/Num Paths              2
exploration/Average Returns      -13.0242
evaluation/num steps total     94000
evaluation/num paths total       940
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0152168
evaluation/Rewards Std             0.0395726
evaluation/Rewards Max            -0.0109749
evaluation/Rewards Min            -0.641594
evaluation/Returns Mean           -1.52168
evaluation/Returns Std             0.281673
evaluation/Returns Max            -1.25453
evaluation/Returns Min            -1.93669
evaluation/Actions Mean            0.00451923
evaluation/Actions Std             0.0773098
evaluation/Actions Max             0.999642
evaluation/Actions Min            -0.853938
evaluation/Num Paths               5
evaluation/Average Returns        -1.52168
time/data storing (s)              0.00112743
time/evaluation sampling (s)       0.0765985
time/exploration sampling (s)      0.0329734
time/logging (s)                   0.00248203
time/saving (s)                    0.00232008
time/training (s)                  0.40841
time/epoch (s)                     0.523911
time/total (s)                   108.178
Epoch                            187
-----------------------------  ---------------
2019-04-13 17:00:23.016566 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size             37900
trainer/QF1 Loss                   3.83219
trainer/QF2 Loss                   3.84163
trainer/Policy Loss               11.1279
trainer/Q1 Predictions Mean      -11.3481
trainer/Q1 Predictions Std         0.568601
trainer/Q1 Predictions Max       -11.0841
trainer/Q1 Predictions Min       -13.4698
trainer/Q2 Predictions Mean      -11.3408
trainer/Q2 Predictions Std         0.568449
trainer/Q2 Predictions Max       -11.0924
trainer/Q2 Predictions Min       -13.4747
trainer/Q Targets Mean           -11.0146
trainer/Q Targets Std              2.0792
trainer/Q Targets Max             -0.0470217
trainer/Q Targets Min            -13.9184
trainer/Bellman Errors 1 Mean      3.83219
trainer/Bellman Errors 1 Std      21.2001
trainer/Bellman Errors 1 Max     121.869
trainer/Bellman Errors 1 Min       3.9235e-06
trainer/Bellman Errors 2 Mean      3.84163
trainer/Bellman Errors 2 Std      21.2461
trainer/Bellman Errors 2 Max     122.134
trainer/Bellman Errors 2 Min       1.64432e-05
trainer/Policy Action Mean         0.0621948
trainer/Policy Action Std          0.202123
trainer/Policy Action Max          0.997068
trainer/Policy Action Min         -0.386003
exploration/num steps total    37900
exploration/num paths total      379
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.132871
exploration/Rewards Std            0.0594531
exploration/Rewards Max           -0.00972363
exploration/Rewards Min           -0.313046
exploration/Returns Mean         -13.2871
exploration/Returns Std            0.163988
exploration/Returns Max          -13.1231
exploration/Returns Min          -13.4511
exploration/Actions Mean           0.0058368
exploration/Actions Std            0.139645
exploration/Actions Max            0.870853
exploration/Actions Min           -0.297798
exploration/Num Paths              2
exploration/Average Returns      -13.2871
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.038783
evaluation/Rewards Std             0.00809575
evaluation/Rewards Max            -0.0165578
evaluation/Rewards Min            -0.200921
evaluation/Returns Mean           -3.8783
evaluation/Returns Std             0.0576477
evaluation/Returns Max            -3.81224
evaluation/Returns Min            -3.97133
evaluation/Actions Mean            0.00446418
evaluation/Actions Std             0.0598436
evaluation/Actions Max             0.869849
evaluation/Actions Min            -0.82383
evaluation/Num Paths               5
evaluation/Average Returns        -3.8783
time/data storing (s)              0.0011338
time/evaluation sampling (s)       0.077348
time/exploration sampling (s)      0.034703
time/logging (s)                   0.00677034
time/saving (s)                    0.00312444
time/training (s)                  0.749953
time/epoch (s)                     0.873033
time/total (s)                   109.056
Epoch                            188
-----------------------------  ---------------
2019-04-13 17:00:23.930296 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size             38100
trainer/QF1 Loss                   0.0307336
trainer/QF2 Loss                   0.0269964
trainer/Policy Loss               11.0604
trainer/Q1 Predictions Mean      -11.184
trainer/Q1 Predictions Std         0.170879
trainer/Q1 Predictions Max       -10.991
trainer/Q1 Predictions Min       -11.8857
trainer/Q2 Predictions Mean      -11.1818
trainer/Q2 Predictions Std         0.168098
trainer/Q2 Predictions Max       -10.9963
trainer/Q2 Predictions Min       -11.9096
trainer/Q Targets Mean           -11.2317
trainer/Q Targets Std              0.214634
trainer/Q Targets Max            -10.9035
trainer/Q Targets Min            -11.8654
trainer/Bellman Errors 1 Mean      0.0307336
trainer/Bellman Errors 1 Std       0.0486861
trainer/Bellman Errors 1 Max       0.190604
trainer/Bellman Errors 1 Min       0.000118302
trainer/Bellman Errors 2 Mean      0.0269964
trainer/Bellman Errors 2 Std       0.0395895
trainer/Bellman Errors 2 Max       0.171332
trainer/Bellman Errors 2 Min       1.14296e-05
trainer/Policy Action Mean        -0.00158704
trainer/Policy Action Std          0.149241
trainer/Policy Action Max          0.758708
trainer/Policy Action Min         -0.397235
exploration/num steps total    38100
exploration/num paths total      381
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.122865
exploration/Rewards Std            0.073501
exploration/Rewards Max           -0.00837496
exploration/Rewards Min           -0.660483
exploration/Returns Mean         -12.2865
exploration/Returns Std            0.582943
exploration/Returns Max          -11.7035
exploration/Returns Min          -12.8694
exploration/Actions Mean           0.00533111
exploration/Actions Std            0.146328
exploration/Actions Max            0.991007
exploration/Actions Min           -0.7838
exploration/Num Paths              2
exploration/Average Returns      -12.2865
evaluation/num steps total     95000
evaluation/num paths total       950
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0203198
evaluation/Rewards Std             0.00989654
evaluation/Rewards Max            -0.00911826
evaluation/Rewards Min            -0.153904
evaluation/Returns Mean           -2.03198
evaluation/Returns Std             0.0609314
evaluation/Returns Max            -1.94116
evaluation/Returns Min            -2.10133
evaluation/Actions Mean            0.00273148
evaluation/Actions Std             0.0480302
evaluation/Actions Max             0.835027
evaluation/Actions Min            -0.674751
evaluation/Num Paths               5
evaluation/Average Returns        -2.03198
time/data storing (s)              0.00162111
time/evaluation sampling (s)       0.222687
time/exploration sampling (s)      0.0913748
time/logging (s)                   0.00188919
time/saving (s)                    0.00181819
time/training (s)                  0.581312
time/epoch (s)                     0.900703
time/total (s)                   109.96
Epoch                            189
-----------------------------  ---------------
2019-04-13 17:00:24.527731 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size             38300
trainer/QF1 Loss                   0.0649016
trainer/QF2 Loss                   0.0643713
trainer/Policy Loss               11.0381
trainer/Q1 Predictions Mean      -11.2173
trainer/Q1 Predictions Std         0.532694
trainer/Q1 Predictions Max       -10.9315
trainer/Q1 Predictions Min       -13.3609
trainer/Q2 Predictions Mean      -11.2187
trainer/Q2 Predictions Std         0.532876
trainer/Q2 Predictions Max       -10.932
trainer/Q2 Predictions Min       -13.2762
trainer/Q Targets Mean           -11.3755
trainer/Q Targets Std              0.617812
trainer/Q Targets Max            -10.85
trainer/Q Targets Min            -13.7137
trainer/Bellman Errors 1 Mean      0.0649016
trainer/Bellman Errors 1 Std       0.0922959
trainer/Bellman Errors 1 Max       0.463037
trainer/Bellman Errors 1 Min       0.000192146
trainer/Bellman Errors 2 Mean      0.0643713
trainer/Bellman Errors 2 Std       0.0922654
trainer/Bellman Errors 2 Max       0.466838
trainer/Bellman Errors 2 Min       1.19975e-05
trainer/Policy Action Mean        -0.0401134
trainer/Policy Action Std          0.219215
trainer/Policy Action Max          0.99736
trainer/Policy Action Min         -0.993993
exploration/num steps total    38300
exploration/num paths total      383
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.133182
exploration/Rewards Std            0.0705043
exploration/Rewards Max           -0.0152059
exploration/Rewards Min           -0.336483
exploration/Returns Mean         -13.3182
exploration/Returns Std            0.240572
exploration/Returns Max          -13.0776
exploration/Returns Min          -13.5588
exploration/Actions Mean          -0.00189057
exploration/Actions Std            0.154581
exploration/Actions Max            1
exploration/Actions Min           -0.928767
exploration/Num Paths              2
exploration/Average Returns      -13.3182
evaluation/num steps total     95500
evaluation/num paths total       955
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0445912
evaluation/Rewards Std             0.0432976
evaluation/Rewards Max            -0.0408063
evaluation/Rewards Min            -0.848995
evaluation/Returns Mean           -4.45912
evaluation/Returns Std             0.27645
evaluation/Returns Max            -4.13231
evaluation/Returns Min            -4.90955
evaluation/Actions Mean            0.00697894
evaluation/Actions Std             0.0815013
evaluation/Actions Max             0.999887
evaluation/Actions Min            -0.88267
evaluation/Num Paths               5
evaluation/Average Returns        -4.45912
time/data storing (s)              0.00112864
time/evaluation sampling (s)       0.0777091
time/exploration sampling (s)      0.035496
time/logging (s)                   0.0021982
time/saving (s)                    0.00226209
time/training (s)                  0.473344
time/epoch (s)                     0.592138
time/total (s)                   110.555
Epoch                            190
-----------------------------  ---------------
2019-04-13 17:00:25.144571 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size             38500
trainer/QF1 Loss                   0.0560711
trainer/QF2 Loss                   0.0539782
trainer/Policy Loss               11.1222
trainer/Q1 Predictions Mean      -11.2943
trainer/Q1 Predictions Std         0.631626
trainer/Q1 Predictions Max       -10.9691
trainer/Q1 Predictions Min       -14.2361
trainer/Q2 Predictions Mean      -11.3176
trainer/Q2 Predictions Std         0.64544
trainer/Q2 Predictions Max       -11.0058
trainer/Q2 Predictions Min       -14.2644
trainer/Q Targets Mean           -11.4057
trainer/Q Targets Std              0.536769
trainer/Q Targets Max            -10.919
trainer/Q Targets Min            -13.8063
trainer/Bellman Errors 1 Mean      0.0560711
trainer/Bellman Errors 1 Std       0.0848176
trainer/Bellman Errors 1 Max       0.353327
trainer/Bellman Errors 1 Min       8.74024e-10
trainer/Bellman Errors 2 Mean      0.0539782
trainer/Bellman Errors 2 Std       0.0828302
trainer/Bellman Errors 2 Max       0.353413
trainer/Bellman Errors 2 Min       1.38269e-06
trainer/Policy Action Mean        -0.0155427
trainer/Policy Action Std          0.227965
trainer/Policy Action Max          0.997839
trainer/Policy Action Min         -0.460087
exploration/num steps total    38500
exploration/num paths total      385
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.16072
exploration/Rewards Std            0.0852267
exploration/Rewards Max           -0.0210113
exploration/Rewards Min           -0.555828
exploration/Returns Mean         -16.072
exploration/Returns Std            0.0961678
exploration/Returns Max          -15.9758
exploration/Returns Min          -16.1682
exploration/Actions Mean           0.00522966
exploration/Actions Std            0.15939
exploration/Actions Max            1
exploration/Actions Min           -0.470837
exploration/Num Paths              2
exploration/Average Returns      -16.072
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.100918
evaluation/Rewards Std             0.0572815
evaluation/Rewards Max            -0.0953466
evaluation/Rewards Min            -0.959279
evaluation/Returns Mean          -10.0918
evaluation/Returns Std             0.33233
evaluation/Returns Max            -9.69173
evaluation/Returns Min           -10.5006
evaluation/Actions Mean            0.00680526
evaluation/Actions Std             0.0878023
evaluation/Actions Max             0.999965
evaluation/Actions Min            -0.814624
evaluation/Num Paths               5
evaluation/Average Returns       -10.0918
time/data storing (s)              0.00110892
time/evaluation sampling (s)       0.0791664
time/exploration sampling (s)      0.0344306
time/logging (s)                   0.00248998
time/saving (s)                    0.00247375
time/training (s)                  0.490478
time/epoch (s)                     0.610148
time/total (s)                   111.169
Epoch                            191
-----------------------------  ---------------
2019-04-13 17:00:25.755757 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size             38700
trainer/QF1 Loss                   0.0559826
trainer/QF2 Loss                   0.0591192
trainer/Policy Loss               10.952
trainer/Q1 Predictions Mean      -11.1407
trainer/Q1 Predictions Std         0.526204
trainer/Q1 Predictions Max       -10.8526
trainer/Q1 Predictions Min       -13.7011
trainer/Q2 Predictions Mean      -11.1321
trainer/Q2 Predictions Std         0.531146
trainer/Q2 Predictions Max       -10.8425
trainer/Q2 Predictions Min       -13.7076
trainer/Q Targets Mean           -11.3139
trainer/Q Targets Std              0.531418
trainer/Q Targets Max            -10.9425
trainer/Q Targets Min            -14.0152
trainer/Bellman Errors 1 Mean      0.0559826
trainer/Bellman Errors 1 Std       0.0600482
trainer/Bellman Errors 1 Max       0.180248
trainer/Bellman Errors 1 Min       7.65413e-06
trainer/Bellman Errors 2 Mean      0.0591192
trainer/Bellman Errors 2 Std       0.0591215
trainer/Bellman Errors 2 Max       0.178737
trainer/Bellman Errors 2 Min       4.98443e-05
trainer/Policy Action Mean         0.102932
trainer/Policy Action Std          0.246446
trainer/Policy Action Max          0.999682
trainer/Policy Action Min         -0.380147
exploration/num steps total    38700
exploration/num paths total      387
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.150806
exploration/Rewards Std            0.076158
exploration/Rewards Max           -0.00907124
exploration/Rewards Min           -0.36978
exploration/Returns Mean         -15.0806
exploration/Returns Std            0.343142
exploration/Returns Max          -14.7374
exploration/Returns Min          -15.4237
exploration/Actions Mean           0.00284853
exploration/Actions Std            0.153789
exploration/Actions Max            1
exploration/Actions Min           -0.80257
exploration/Num Paths              2
exploration/Average Returns      -15.0806
evaluation/num steps total     96500
evaluation/num paths total       965
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0870045
evaluation/Rewards Std             0.0341585
evaluation/Rewards Max            -0.0729003
evaluation/Rewards Min            -0.753177
evaluation/Returns Mean           -8.70045
evaluation/Returns Std             0.235707
evaluation/Returns Max            -8.4721
evaluation/Returns Min            -9.12667
evaluation/Actions Mean            0.00592082
evaluation/Actions Std             0.0774269
evaluation/Actions Max             0.999644
evaluation/Actions Min            -0.83695
evaluation/Num Paths               5
evaluation/Average Returns        -8.70045
time/data storing (s)              0.00121267
time/evaluation sampling (s)       0.0854254
time/exploration sampling (s)      0.034392
time/logging (s)                   0.00246853
time/saving (s)                    0.00225819
time/training (s)                  0.478361
time/epoch (s)                     0.604118
time/total (s)                   111.777
Epoch                            192
-----------------------------  ---------------
2019-04-13 17:00:26.340899 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size             38900
trainer/QF1 Loss                   7.61063
trainer/QF2 Loss                   7.62456
trainer/Policy Loss               11.1104
trainer/Q1 Predictions Mean      -11.3237
trainer/Q1 Predictions Std         0.571693
trainer/Q1 Predictions Max       -11.0348
trainer/Q1 Predictions Min       -14.317
trainer/Q2 Predictions Mean      -11.335
trainer/Q2 Predictions Std         0.560946
trainer/Q2 Predictions Max       -11.0329
trainer/Q2 Predictions Min       -14.2728
trainer/Q Targets Mean           -10.7115
trainer/Q Targets Std              2.80603
trainer/Q Targets Max             -0.0386831
trainer/Q Targets Min            -14.2296
trainer/Bellman Errors 1 Mean      7.61063
trainer/Bellman Errors 1 Std      29.33
trainer/Bellman Errors 1 Max     122.159
trainer/Bellman Errors 1 Min       3.65577e-07
trainer/Bellman Errors 2 Mean      7.62456
trainer/Bellman Errors 2 Std      29.3961
trainer/Bellman Errors 2 Max     122.299
trainer/Bellman Errors 2 Min       3.16917e-05
trainer/Policy Action Mean         0.0260133
trainer/Policy Action Std          0.229452
trainer/Policy Action Max          0.99878
trainer/Policy Action Min         -0.405726
exploration/num steps total    38900
exploration/num paths total      389
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.140476
exploration/Rewards Std            0.0766072
exploration/Rewards Max           -0.0245124
exploration/Rewards Min           -0.682905
exploration/Returns Mean         -14.0476
exploration/Returns Std            0.00185848
exploration/Returns Max          -14.0457
exploration/Returns Min          -14.0494
exploration/Actions Mean           0.00991832
exploration/Actions Std            0.170482
exploration/Actions Max            1
exploration/Actions Min           -0.400107
exploration/Num Paths              2
exploration/Average Returns      -14.0476
evaluation/num steps total     97000
evaluation/num paths total       970
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0312851
evaluation/Rewards Std             0.0220005
evaluation/Rewards Max            -0.0294427
evaluation/Rewards Min            -0.454074
evaluation/Returns Mean           -3.12851
evaluation/Returns Std             0.184274
evaluation/Returns Max            -2.96044
evaluation/Returns Min            -3.45819
evaluation/Actions Mean            0.00280446
evaluation/Actions Std             0.0704275
evaluation/Actions Max             0.997553
evaluation/Actions Min            -0.947102
evaluation/Num Paths               5
evaluation/Average Returns        -3.12851
time/data storing (s)              0.00106218
time/evaluation sampling (s)       0.0820832
time/exploration sampling (s)      0.0324236
time/logging (s)                   0.00252907
time/saving (s)                    0.00182091
time/training (s)                  0.458273
time/epoch (s)                     0.578192
time/total (s)                   112.359
Epoch                            193
-----------------------------  ---------------
2019-04-13 17:00:26.913702 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size             39100
trainer/QF1 Loss                   0.0660198
trainer/QF2 Loss                   0.064199
trainer/Policy Loss               10.8969
trainer/Q1 Predictions Mean      -11.0596
trainer/Q1 Predictions Std         0.182068
trainer/Q1 Predictions Max       -10.909
trainer/Q1 Predictions Min       -11.9706
trainer/Q2 Predictions Mean      -11.0669
trainer/Q2 Predictions Std         0.182882
trainer/Q2 Predictions Max       -10.912
trainer/Q2 Predictions Min       -11.9994
trainer/Q Targets Mean           -11.2854
trainer/Q Targets Std              0.224902
trainer/Q Targets Max            -10.9584
trainer/Q Targets Min            -12.2723
trainer/Bellman Errors 1 Mean      0.0660198
trainer/Bellman Errors 1 Std       0.0588445
trainer/Bellman Errors 1 Max       0.240977
trainer/Bellman Errors 1 Min       3.95696e-05
trainer/Bellman Errors 2 Mean      0.064199
trainer/Bellman Errors 2 Std       0.0569804
trainer/Bellman Errors 2 Max       0.222193
trainer/Bellman Errors 2 Min       4.21912e-05
trainer/Policy Action Mean        -0.00915126
trainer/Policy Action Std          0.120409
trainer/Policy Action Max          0.452844
trainer/Policy Action Min         -0.412311
exploration/num steps total    39100
exploration/num paths total      391
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.146521
exploration/Rewards Std            0.0793975
exploration/Rewards Max           -0.0101373
exploration/Rewards Min           -0.770355
exploration/Returns Mean         -14.6521
exploration/Returns Std            0.906272
exploration/Returns Max          -13.7458
exploration/Returns Min          -15.5584
exploration/Actions Mean           0.00265403
exploration/Actions Std            0.160798
exploration/Actions Max            1
exploration/Actions Min           -0.932228
exploration/Num Paths              2
exploration/Average Returns      -14.6521
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0443504
evaluation/Rewards Std             0.0100677
evaluation/Rewards Max            -0.0304981
evaluation/Rewards Min            -0.184113
evaluation/Returns Mean           -4.43504
evaluation/Returns Std             0.0682243
evaluation/Returns Max            -4.32878
evaluation/Returns Min            -4.51157
evaluation/Actions Mean            0.00191275
evaluation/Actions Std             0.0571849
evaluation/Actions Max             0.734478
evaluation/Actions Min            -0.925884
evaluation/Num Paths               5
evaluation/Average Returns        -4.43504
time/data storing (s)              0.00107478
time/evaluation sampling (s)       0.0723783
time/exploration sampling (s)      0.0333039
time/logging (s)                   0.00248196
time/saving (s)                    0.00227557
time/training (s)                  0.454298
time/epoch (s)                     0.565812
time/total (s)                   112.929
Epoch                            194
-----------------------------  ---------------
2019-04-13 17:00:27.501068 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size             39300
trainer/QF1 Loss                   0.0333622
trainer/QF2 Loss                   0.0374581
trainer/Policy Loss               11.0062
trainer/Q1 Predictions Mean      -11.1539
trainer/Q1 Predictions Std         0.29095
trainer/Q1 Predictions Max       -10.9601
trainer/Q1 Predictions Min       -12.4274
trainer/Q2 Predictions Mean      -11.1424
trainer/Q2 Predictions Std         0.28632
trainer/Q2 Predictions Max       -10.9492
trainer/Q2 Predictions Min       -12.4203
trainer/Q Targets Mean           -11.2905
trainer/Q Targets Std              0.326813
trainer/Q Targets Max            -11.013
trainer/Q Targets Min            -12.7236
trainer/Bellman Errors 1 Mean      0.0333622
trainer/Bellman Errors 1 Std       0.0570671
trainer/Bellman Errors 1 Max       0.283906
trainer/Bellman Errors 1 Min       1.63197e-05
trainer/Bellman Errors 2 Mean      0.0374581
trainer/Bellman Errors 2 Std       0.0577435
trainer/Bellman Errors 2 Max       0.287854
trainer/Bellman Errors 2 Min       7.84931e-07
trainer/Policy Action Mean         0.0161846
trainer/Policy Action Std          0.220403
trainer/Policy Action Max          0.933037
trainer/Policy Action Min         -0.522119
exploration/num steps total    39300
exploration/num paths total      393
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.139894
exploration/Rewards Std            0.0716241
exploration/Rewards Max           -0.00845678
exploration/Rewards Min           -0.40618
exploration/Returns Mean         -13.9894
exploration/Returns Std            0.110974
exploration/Returns Max          -13.8784
exploration/Returns Min          -14.1004
exploration/Actions Mean           0.00701769
exploration/Actions Std            0.158735
exploration/Actions Max            0.91312
exploration/Actions Min           -0.369135
exploration/Num Paths              2
exploration/Average Returns      -13.9894
evaluation/num steps total     98000
evaluation/num paths total       980
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0581991
evaluation/Rewards Std             0.0242894
evaluation/Rewards Max            -0.0180948
evaluation/Rewards Min            -0.565651
evaluation/Returns Mean           -5.81991
evaluation/Returns Std             0.166697
evaluation/Returns Max            -5.68845
evaluation/Returns Min            -6.14913
evaluation/Actions Mean            0.00696371
evaluation/Actions Std             0.0733043
evaluation/Actions Max             0.999453
evaluation/Actions Min            -0.503147
evaluation/Num Paths               5
evaluation/Average Returns        -5.81991
time/data storing (s)              0.00115362
time/evaluation sampling (s)       0.0763305
time/exploration sampling (s)      0.0395157
time/logging (s)                   0.00249805
time/saving (s)                    0.002461
time/training (s)                  0.458331
time/epoch (s)                     0.58029
time/total (s)                   113.513
Epoch                            195
-----------------------------  ---------------
2019-04-13 17:00:28.076429 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size             39500
trainer/QF1 Loss                   0.162304
trainer/QF2 Loss                   0.165929
trainer/Policy Loss               10.8161
trainer/Q1 Predictions Mean      -10.9487
trainer/Q1 Predictions Std         0.306946
trainer/Q1 Predictions Max       -10.7342
trainer/Q1 Predictions Min       -12.5389
trainer/Q2 Predictions Mean      -10.9478
trainer/Q2 Predictions Std         0.321591
trainer/Q2 Predictions Max       -10.7372
trainer/Q2 Predictions Min       -12.6289
trainer/Q Targets Mean           -11.3236
trainer/Q Targets Std              0.27603
trainer/Q Targets Max            -11.0159
trainer/Q Targets Min            -12.5605
trainer/Bellman Errors 1 Mean      0.162304
trainer/Bellman Errors 1 Std       0.112315
trainer/Bellman Errors 1 Max       0.458901
trainer/Bellman Errors 1 Min       0.000465068
trainer/Bellman Errors 2 Mean      0.165929
trainer/Bellman Errors 2 Std       0.116527
trainer/Bellman Errors 2 Max       0.468826
trainer/Bellman Errors 2 Min       0.00467861
trainer/Policy Action Mean         0.0310735
trainer/Policy Action Std          0.17811
trainer/Policy Action Max          0.817171
trainer/Policy Action Min         -0.275879
exploration/num steps total    39500
exploration/num paths total      395
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.162847
exploration/Rewards Std            0.0887583
exploration/Rewards Max           -0.00554272
exploration/Rewards Min           -0.468364
exploration/Returns Mean         -16.2847
exploration/Returns Std            1.10655
exploration/Returns Max          -15.1781
exploration/Returns Min          -17.3912
exploration/Actions Mean           0.00488812
exploration/Actions Std            0.149599
exploration/Actions Max            0.60843
exploration/Actions Min           -0.350736
exploration/Num Paths              2
exploration/Average Returns      -16.2847
evaluation/num steps total     98500
evaluation/num paths total       985
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.104309
evaluation/Rewards Std             0.0478084
evaluation/Rewards Max            -0.0570515
evaluation/Rewards Min            -0.862968
evaluation/Returns Mean          -10.4309
evaluation/Returns Std             0.251783
evaluation/Returns Max           -10.1088
evaluation/Returns Min           -10.7925
evaluation/Actions Mean            0.0064004
evaluation/Actions Std             0.089337
evaluation/Actions Max             0.999989
evaluation/Actions Min            -0.978774
evaluation/Num Paths               5
evaluation/Average Returns       -10.4309
time/data storing (s)              0.00107655
time/evaluation sampling (s)       0.0731535
time/exploration sampling (s)      0.0318916
time/logging (s)                   0.00248327
time/saving (s)                    0.00226886
time/training (s)                  0.457461
time/epoch (s)                     0.568335
time/total (s)                   114.085
Epoch                            196
-----------------------------  ---------------
2019-04-13 17:00:28.657849 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size             39700
trainer/QF1 Loss                   0.0616863
trainer/QF2 Loss                   0.0690781
trainer/Policy Loss               11.1182
trainer/Q1 Predictions Mean      -11.3016
trainer/Q1 Predictions Std         0.549188
trainer/Q1 Predictions Max       -11.023
trainer/Q1 Predictions Min       -14.1608
trainer/Q2 Predictions Mean      -11.2954
trainer/Q2 Predictions Std         0.52157
trainer/Q2 Predictions Max       -11.0072
trainer/Q2 Predictions Min       -13.9717
trainer/Q Targets Mean           -11.4656
trainer/Q Targets Std              0.679478
trainer/Q Targets Max            -11.0332
trainer/Q Targets Min            -14.8702
trainer/Bellman Errors 1 Mean      0.0616863
trainer/Bellman Errors 1 Std       0.106363
trainer/Bellman Errors 1 Max       0.503331
trainer/Bellman Errors 1 Min       3.819e-07
trainer/Bellman Errors 2 Mean      0.0690781
trainer/Bellman Errors 2 Std       0.146928
trainer/Bellman Errors 2 Max       0.807293
trainer/Bellman Errors 2 Min       6.58347e-05
trainer/Policy Action Mean         0.00185442
trainer/Policy Action Std          0.239294
trainer/Policy Action Max          0.996519
trainer/Policy Action Min         -0.394638
exploration/num steps total    39700
exploration/num paths total      397
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.134937
exploration/Rewards Std            0.0772166
exploration/Rewards Max           -0.00707178
exploration/Rewards Min           -0.626526
exploration/Returns Mean         -13.4937
exploration/Returns Std            0.318714
exploration/Returns Max          -13.175
exploration/Returns Min          -13.8124
exploration/Actions Mean           0.00628199
exploration/Actions Std            0.147366
exploration/Actions Max            1
exploration/Actions Min           -0.524628
exploration/Num Paths              2
exploration/Average Returns      -13.4937
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0497452
evaluation/Rewards Std             0.0411018
evaluation/Rewards Max            -0.0322121
evaluation/Rewards Min            -0.849332
evaluation/Returns Mean           -4.97452
evaluation/Returns Std             0.288353
evaluation/Returns Max            -4.68702
evaluation/Returns Min            -5.47866
evaluation/Actions Mean            0.00604763
evaluation/Actions Std             0.0776707
evaluation/Actions Max             0.999924
evaluation/Actions Min            -0.912076
evaluation/Num Paths               5
evaluation/Average Returns        -4.97452
time/data storing (s)              0.00114748
time/evaluation sampling (s)       0.0755373
time/exploration sampling (s)      0.0329497
time/logging (s)                   0.0025536
time/saving (s)                    0.00226666
time/training (s)                  0.459975
time/epoch (s)                     0.57443
time/total (s)                   114.664
Epoch                            197
-----------------------------  ---------------
2019-04-13 17:00:29.241986 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size             39900
trainer/QF1 Loss                   3.82004
trainer/QF2 Loss                   3.81977
trainer/Policy Loss               11.1478
trainer/Q1 Predictions Mean      -11.2578
trainer/Q1 Predictions Std         0.181235
trainer/Q1 Predictions Max       -11.0934
trainer/Q1 Predictions Min       -12.1479
trainer/Q2 Predictions Mean      -11.2608
trainer/Q2 Predictions Std         0.192311
trainer/Q2 Predictions Max       -11.0955
trainer/Q2 Predictions Min       -12.2153
trainer/Q Targets Mean           -10.9373
trainer/Q Targets Std              1.95038
trainer/Q Targets Max             -0.129876
trainer/Q Targets Min            -12.0361
trainer/Bellman Errors 1 Mean      3.82004
trainer/Bellman Errors 1 Std      21.1647
trainer/Bellman Errors 1 Max     121.66
trainer/Bellman Errors 1 Min       4.10713e-07
trainer/Bellman Errors 2 Mean      3.81977
trainer/Bellman Errors 2 Std      21.162
trainer/Bellman Errors 2 Max     121.645
trainer/Bellman Errors 2 Min       0.000118032
trainer/Policy Action Mean         0.0596223
trainer/Policy Action Std          0.223133
trainer/Policy Action Max          0.990733
trainer/Policy Action Min         -0.421729
exploration/num steps total    39900
exploration/num paths total      399
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.147055
exploration/Rewards Std            0.0739081
exploration/Rewards Max           -0.0142531
exploration/Rewards Min           -0.407746
exploration/Returns Mean         -14.7055
exploration/Returns Std            0.44988
exploration/Returns Max          -14.2557
exploration/Returns Min          -15.1554
exploration/Actions Mean           0.002258
exploration/Actions Std            0.152241
exploration/Actions Max            0.886758
exploration/Actions Min           -0.394598
exploration/Num Paths              2
exploration/Average Returns      -14.7055
evaluation/num steps total     99500
evaluation/num paths total       995
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.0632463
evaluation/Rewards Std             0.0129406
evaluation/Rewards Max            -0.0245641
evaluation/Rewards Min            -0.29945
evaluation/Returns Mean           -6.32463
evaluation/Returns Std             0.101056
evaluation/Returns Max            -6.17572
evaluation/Returns Min            -6.49194
evaluation/Actions Mean            0.00246734
evaluation/Actions Std             0.0752194
evaluation/Actions Max             0.996528
evaluation/Actions Min            -0.900128
evaluation/Num Paths               5
evaluation/Average Returns        -6.32463
time/data storing (s)              0.00113048
time/evaluation sampling (s)       0.072711
time/exploration sampling (s)      0.0336597
time/logging (s)                   0.00239728
time/saving (s)                    0.00229881
time/training (s)                  0.464608
time/epoch (s)                     0.576805
time/total (s)                   115.244
Epoch                            198
-----------------------------  ---------------
2019-04-13 17:00:29.819485 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 199 finished
-----------------------------  ----------------
replay_buffer/size              40100
trainer/QF1 Loss                    7.91238
trainer/QF2 Loss                    7.91995
trainer/Policy Loss                11.2764
trainer/Q1 Predictions Mean       -11.4492
trainer/Q1 Predictions Std          0.196944
trainer/Q1 Predictions Max        -11.2711
trainer/Q1 Predictions Min        -12.1607
trainer/Q2 Predictions Mean       -11.4431
trainer/Q2 Predictions Std          0.186275
trainer/Q2 Predictions Max        -11.2822
trainer/Q2 Predictions Min        -12.1687
trainer/Q Targets Mean            -10.637
trainer/Q Targets Std               2.7324
trainer/Q Targets Max              -0.063307
trainer/Q Targets Min             -12.4792
trainer/Bellman Errors 1 Mean       7.91238
trainer/Bellman Errors 1 Std       30.4558
trainer/Bellman Errors 1 Max      126.119
trainer/Bellman Errors 1 Min        0.000221817
trainer/Bellman Errors 2 Mean       7.91995
trainer/Bellman Errors 2 Std       30.4852
trainer/Bellman Errors 2 Max      126.113
trainer/Bellman Errors 2 Min        0.000660911
trainer/Policy Action Mean          0.0461593
trainer/Policy Action Std           0.184609
trainer/Policy Action Max           0.890003
trainer/Policy Action Min          -0.410437
exploration/num steps total     40100
exploration/num paths total       401
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.155954
exploration/Rewards Std             0.0845679
exploration/Rewards Max            -0.0181681
exploration/Rewards Min            -0.705056
exploration/Returns Mean          -15.5954
exploration/Returns Std             0.0538159
exploration/Returns Max           -15.5416
exploration/Returns Min           -15.6492
exploration/Actions Mean            0.0132429
exploration/Actions Std             0.167785
exploration/Actions Max             1
exploration/Actions Min            -0.361624
exploration/Num Paths               2
exploration/Average Returns       -15.5954
evaluation/num steps total     100000
evaluation/num paths total       1000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0846098
evaluation/Rewards Std              0.0188806
evaluation/Rewards Max             -0.0660205
evaluation/Rewards Min             -0.415824
evaluation/Returns Mean            -8.46098
evaluation/Returns Std              0.112225
evaluation/Returns Max             -8.33866
evaluation/Returns Min             -8.6452
evaluation/Actions Mean             0.00334165
evaluation/Actions Std              0.0761734
evaluation/Actions Max              0.99931
evaluation/Actions Min             -0.803519
evaluation/Num Paths                5
evaluation/Average Returns         -8.46098
time/data storing (s)               0.00117546
time/evaluation sampling (s)        0.0857259
time/exploration sampling (s)       0.0353328
time/logging (s)                    0.00246695
time/saving (s)                     0.00228902
time/training (s)                   0.443195
time/epoch (s)                      0.570185
time/total (s)                    115.819
Epoch                             199
-----------------------------  ----------------
2019-04-13 17:00:30.410543 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 200 finished
-----------------------------  ----------------
replay_buffer/size              40300
trainer/QF1 Loss                    3.77921
trainer/QF2 Loss                    3.78549
trainer/Policy Loss                10.9898
trainer/Q1 Predictions Mean       -11.1212
trainer/Q1 Predictions Std          0.128323
trainer/Q1 Predictions Max        -10.9793
trainer/Q1 Predictions Min        -11.649
trainer/Q2 Predictions Mean       -11.125
trainer/Q2 Predictions Std          0.128859
trainer/Q2 Predictions Max        -10.9801
trainer/Q2 Predictions Min        -11.6113
trainer/Q Targets Mean            -10.98
trainer/Q Targets Std               1.94072
trainer/Q Targets Max              -0.215753
trainer/Q Targets Min             -11.7993
trainer/Bellman Errors 1 Mean       3.77921
trainer/Bellman Errors 1 Std       20.6764
trainer/Bellman Errors 1 Max      118.9
trainer/Bellman Errors 1 Min        0.000195491
trainer/Bellman Errors 2 Mean       3.78549
trainer/Bellman Errors 2 Std       20.6834
trainer/Bellman Errors 2 Max      118.945
trainer/Bellman Errors 2 Min        0.000239307
trainer/Policy Action Mean          0.0577373
trainer/Policy Action Std           0.238264
trainer/Policy Action Max           0.990853
trainer/Policy Action Min          -0.823862
exploration/num steps total     40300
exploration/num paths total       403
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143267
exploration/Rewards Std             0.0728982
exploration/Rewards Max            -0.013366
exploration/Rewards Min            -0.390064
exploration/Returns Mean          -14.3267
exploration/Returns Std             0.263548
exploration/Returns Max           -14.0632
exploration/Returns Min           -14.5903
exploration/Actions Mean            0.00397053
exploration/Actions Std             0.157915
exploration/Actions Max             1
exploration/Actions Min            -0.743089
exploration/Num Paths               2
exploration/Average Returns       -14.3267
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0805774
evaluation/Rewards Std              0.0498346
evaluation/Rewards Max             -0.0769536
evaluation/Rewards Min             -0.873205
evaluation/Returns Mean            -8.05774
evaluation/Returns Std              0.417242
evaluation/Returns Max             -7.711
evaluation/Returns Min             -8.57955
evaluation/Actions Mean             0.00312459
evaluation/Actions Std              0.076241
evaluation/Actions Max              0.999991
evaluation/Actions Min             -0.896179
evaluation/Num Paths                5
evaluation/Average Returns         -8.05774
time/data storing (s)               0.00121468
time/evaluation sampling (s)        0.0772637
time/exploration sampling (s)       0.0323726
time/logging (s)                    0.00229591
time/saving (s)                     0.00225868
time/training (s)                   0.465562
time/epoch (s)                      0.580968
time/total (s)                    116.406
Epoch                             200
-----------------------------  ----------------
2019-04-13 17:00:30.992245 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 201 finished
-----------------------------  ----------------
replay_buffer/size              40500
trainer/QF1 Loss                    3.90674
trainer/QF2 Loss                    3.89393
trainer/Policy Loss                11.2147
trainer/Q1 Predictions Mean       -11.352
trainer/Q1 Predictions Std          0.140857
trainer/Q1 Predictions Max        -11.1864
trainer/Q1 Predictions Min        -11.9997
trainer/Q2 Predictions Mean       -11.3561
trainer/Q2 Predictions Std          0.157677
trainer/Q2 Predictions Max        -11.1961
trainer/Q2 Predictions Min        -12.0988
trainer/Q Targets Mean            -11.028
trainer/Q Targets Std               1.95504
trainer/Q Targets Max              -0.195182
trainer/Q Targets Min             -11.9102
trainer/Bellman Errors 1 Mean       3.90674
trainer/Bellman Errors 1 Std       21.6516
trainer/Bellman Errors 1 Max      124.458
trainer/Bellman Errors 1 Min        5.82077e-07
trainer/Bellman Errors 2 Mean       3.89393
trainer/Bellman Errors 2 Std       21.5818
trainer/Bellman Errors 2 Max      124.056
trainer/Bellman Errors 2 Min        6.87805e-08
trainer/Policy Action Mean         -0.0111144
trainer/Policy Action Std           0.116977
trainer/Policy Action Max           0.253012
trainer/Policy Action Min          -0.423262
exploration/num steps total     40500
exploration/num paths total       405
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132678
exploration/Rewards Std             0.0707949
exploration/Rewards Max            -0.00685423
exploration/Rewards Min            -0.483971
exploration/Returns Mean          -13.2678
exploration/Returns Std             0.0598964
exploration/Returns Max           -13.2079
exploration/Returns Min           -13.3277
exploration/Actions Mean            0.00567368
exploration/Actions Std             0.156881
exploration/Actions Max             0.941665
exploration/Actions Min            -0.496834
exploration/Num Paths               2
exploration/Average Returns       -13.2678
evaluation/num steps total     101000
evaluation/num paths total       1010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0276855
evaluation/Rewards Std              0.0476368
evaluation/Rewards Max             -0.0194802
evaluation/Rewards Min             -0.825591
evaluation/Returns Mean            -2.76855
evaluation/Returns Std              0.325132
evaluation/Returns Max             -2.40711
evaluation/Returns Min             -3.19786
evaluation/Actions Mean             0.00575873
evaluation/Actions Std              0.0726711
evaluation/Actions Max              0.999969
evaluation/Actions Min             -0.829141
evaluation/Num Paths                5
evaluation/Average Returns         -2.76855
time/data storing (s)               0.00112203
time/evaluation sampling (s)        0.0754567
time/exploration sampling (s)       0.0338464
time/logging (s)                    0.00245708
time/saving (s)                     0.00246195
time/training (s)                   0.460493
time/epoch (s)                      0.575837
time/total (s)                    116.986
Epoch                             201
-----------------------------  ----------------
2019-04-13 17:00:31.554407 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 202 finished
-----------------------------  ----------------
replay_buffer/size              40700
trainer/QF1 Loss                    0.095804
trainer/QF2 Loss                    0.0994545
trainer/Policy Loss                11.0916
trainer/Q1 Predictions Mean       -11.2387
trainer/Q1 Predictions Std          0.458873
trainer/Q1 Predictions Max        -11.0146
trainer/Q1 Predictions Min        -13.74
trainer/Q2 Predictions Mean       -11.232
trainer/Q2 Predictions Std          0.452497
trainer/Q2 Predictions Max        -11.0265
trainer/Q2 Predictions Min        -13.7076
trainer/Q Targets Mean            -11.5057
trainer/Q Targets Std               0.528139
trainer/Q Targets Max             -11.1662
trainer/Q Targets Min             -14.3012
trainer/Bellman Errors 1 Mean       0.095804
trainer/Bellman Errors 1 Std        0.106354
trainer/Bellman Errors 1 Max        0.423898
trainer/Bellman Errors 1 Min        0.000178465
trainer/Bellman Errors 2 Mean       0.0994545
trainer/Bellman Errors 2 Std        0.110609
trainer/Bellman Errors 2 Max        0.437512
trainer/Bellman Errors 2 Min        0.000506338
trainer/Policy Action Mean         -0.0194388
trainer/Policy Action Std           0.174879
trainer/Policy Action Max           0.997077
trainer/Policy Action Min          -0.353117
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.123957
exploration/Rewards Std             0.0782682
exploration/Rewards Max            -0.00998575
exploration/Rewards Min            -0.697299
exploration/Returns Mean          -12.3957
exploration/Returns Std             0.199676
exploration/Returns Max           -12.196
exploration/Returns Min           -12.5954
exploration/Actions Mean            0.00850053
exploration/Actions Std             0.157078
exploration/Actions Max             1
exploration/Actions Min            -0.360303
exploration/Num Paths               2
exploration/Average Returns       -12.3957
evaluation/num steps total     101500
evaluation/num paths total       1015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0569416
evaluation/Rewards Std              0.0524006
evaluation/Rewards Max             -0.0207566
evaluation/Rewards Min             -0.730852
evaluation/Returns Mean            -5.69416
evaluation/Returns Std              0.281806
evaluation/Returns Max             -5.29057
evaluation/Returns Min             -5.92683
evaluation/Actions Mean             0.00767452
evaluation/Actions Std              0.0846308
evaluation/Actions Max              0.999956
evaluation/Actions Min             -0.763033
evaluation/Num Paths                5
evaluation/Average Returns         -5.69416
time/data storing (s)               0.00106314
time/evaluation sampling (s)        0.0762635
time/exploration sampling (s)       0.0323918
time/logging (s)                    0.00214248
time/saving (s)                     0.00240372
time/training (s)                   0.440522
time/epoch (s)                      0.554786
time/total (s)                    117.544
Epoch                             202
-----------------------------  ----------------
2019-04-13 17:00:32.121623 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 203 finished
-----------------------------  ----------------
replay_buffer/size              40900
trainer/QF1 Loss                    0.0303422
trainer/QF2 Loss                    0.0296764
trainer/Policy Loss                11.162
trainer/Q1 Predictions Mean       -11.3403
trainer/Q1 Predictions Std          0.107057
trainer/Q1 Predictions Max        -11.1697
trainer/Q1 Predictions Min        -11.564
trainer/Q2 Predictions Mean       -11.3315
trainer/Q2 Predictions Std          0.105412
trainer/Q2 Predictions Max        -11.1754
trainer/Q2 Predictions Min        -11.5886
trainer/Q Targets Mean            -11.3862
trainer/Q Targets Std               0.178796
trainer/Q Targets Max             -11.12
trainer/Q Targets Min             -12.0609
trainer/Bellman Errors 1 Mean       0.0303422
trainer/Bellman Errors 1 Std        0.0486121
trainer/Bellman Errors 1 Max        0.260523
trainer/Bellman Errors 1 Min        2.11237e-06
trainer/Bellman Errors 2 Mean       0.0296764
trainer/Bellman Errors 2 Std        0.0433933
trainer/Bellman Errors 2 Max        0.223046
trainer/Bellman Errors 2 Min        2.85523e-05
trainer/Policy Action Mean          0.0165143
trainer/Policy Action Std           0.173493
trainer/Policy Action Max           0.931128
trainer/Policy Action Min          -0.283194
exploration/num steps total     40900
exploration/num paths total       409
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.141421
exploration/Rewards Std             0.0680915
exploration/Rewards Max            -0.0129102
exploration/Rewards Min            -0.343574
exploration/Returns Mean          -14.1421
exploration/Returns Std             0.382244
exploration/Returns Max           -13.7599
exploration/Returns Min           -14.5243
exploration/Actions Mean            0.00414501
exploration/Actions Std             0.146481
exploration/Actions Max             0.838172
exploration/Actions Min            -0.435028
exploration/Num Paths               2
exploration/Average Returns       -14.1421
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0606239
evaluation/Rewards Std              0.0384732
evaluation/Rewards Max             -0.0583222
evaluation/Rewards Min             -0.907303
evaluation/Returns Mean            -6.06239
evaluation/Returns Std              0.317287
evaluation/Returns Max             -5.86753
evaluation/Returns Min             -6.69491
evaluation/Actions Mean             0.00309818
evaluation/Actions Std              0.075154
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.819445
evaluation/Num Paths                5
evaluation/Average Returns         -6.06239
time/data storing (s)               0.00119489
time/evaluation sampling (s)        0.0726925
time/exploration sampling (s)       0.0335569
time/logging (s)                    0.00247476
time/saving (s)                     0.00224877
time/training (s)                   0.448826
time/epoch (s)                      0.560994
time/total (s)                    118.109
Epoch                             203
-----------------------------  ----------------
2019-04-13 17:00:32.689914 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 204 finished
-----------------------------  ----------------
replay_buffer/size              41100
trainer/QF1 Loss                    0.0287889
trainer/QF2 Loss                    0.0276784
trainer/Policy Loss                11.2768
trainer/Q1 Predictions Mean       -11.4084
trainer/Q1 Predictions Std          0.71163
trainer/Q1 Predictions Max        -11.1208
trainer/Q1 Predictions Min        -15.2494
trainer/Q2 Predictions Mean       -11.4111
trainer/Q2 Predictions Std          0.720344
trainer/Q2 Predictions Max        -11.1214
trainer/Q2 Predictions Min        -15.2832
trainer/Q Targets Mean            -11.4992
trainer/Q Targets Std               0.728147
trainer/Q Targets Max             -11.1749
trainer/Q Targets Min             -15.3844
trainer/Bellman Errors 1 Mean       0.0287889
trainer/Bellman Errors 1 Std        0.0573827
trainer/Bellman Errors 1 Max        0.311558
trainer/Bellman Errors 1 Min        0.000160881
trainer/Bellman Errors 2 Mean       0.0276784
trainer/Bellman Errors 2 Std        0.0605174
trainer/Bellman Errors 2 Max        0.33102
trainer/Bellman Errors 2 Min        4.6717e-05
trainer/Policy Action Mean         -0.000708384
trainer/Policy Action Std           0.248332
trainer/Policy Action Max           0.999999
trainer/Policy Action Min          -0.997018
exploration/num steps total     41100
exploration/num paths total       411
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.120001
exploration/Rewards Std             0.0651022
exploration/Rewards Max            -0.00850675
exploration/Rewards Min            -0.287329
exploration/Returns Mean          -12.0001
exploration/Returns Std             0.427657
exploration/Returns Max           -11.5724
exploration/Returns Min           -12.4277
exploration/Actions Mean            0.00245314
exploration/Actions Std             0.135111
exploration/Actions Max             0.431967
exploration/Actions Min            -0.385517
exploration/Num Paths               2
exploration/Average Returns       -12.0001
evaluation/num steps total     102500
evaluation/num paths total       1025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0227632
evaluation/Rewards Std              0.0531935
evaluation/Rewards Max             -0.0153331
evaluation/Rewards Min             -0.933065
evaluation/Returns Mean            -2.27632
evaluation/Returns Std              0.321991
evaluation/Returns Max             -1.84788
evaluation/Returns Min             -2.74789
evaluation/Actions Mean             0.00646653
evaluation/Actions Std              0.0760425
evaluation/Actions Max              0.999989
evaluation/Actions Min             -0.411054
evaluation/Num Paths                5
evaluation/Average Returns         -2.27632
time/data storing (s)               0.00109133
time/evaluation sampling (s)        0.074065
time/exploration sampling (s)       0.0326628
time/logging (s)                    0.00208006
time/saving (s)                     0.00181725
time/training (s)                   0.449078
time/epoch (s)                      0.560794
time/total (s)                    118.674
Epoch                             204
-----------------------------  ----------------
2019-04-13 17:00:33.267707 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 205 finished
-----------------------------  ----------------
replay_buffer/size              41300
trainer/QF1 Loss                    0.0130662
trainer/QF2 Loss                    0.0135756
trainer/Policy Loss                11.2921
trainer/Q1 Predictions Mean       -11.4726
trainer/Q1 Predictions Std          0.161695
trainer/Q1 Predictions Max        -11.3085
trainer/Q1 Predictions Min        -12.2586
trainer/Q2 Predictions Mean       -11.4769
trainer/Q2 Predictions Std          0.15774
trainer/Q2 Predictions Max        -11.3274
trainer/Q2 Predictions Min        -12.2451
trainer/Q Targets Mean            -11.4192
trainer/Q Targets Std               0.190377
trainer/Q Targets Max             -11.1674
trainer/Q Targets Min             -12.1621
trainer/Bellman Errors 1 Mean       0.0130662
trainer/Bellman Errors 1 Std        0.0148097
trainer/Bellman Errors 1 Max        0.061746
trainer/Bellman Errors 1 Min        3.15523e-07
trainer/Bellman Errors 2 Mean       0.0135756
trainer/Bellman Errors 2 Std        0.0165707
trainer/Bellman Errors 2 Max        0.0729595
trainer/Bellman Errors 2 Min        3.00702e-07
trainer/Policy Action Mean         -0.0296585
trainer/Policy Action Std           0.121083
trainer/Policy Action Max           0.439477
trainer/Policy Action Min          -0.424473
exploration/num steps total     41300
exploration/num paths total       413
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.121927
exploration/Rewards Std             0.0645229
exploration/Rewards Max            -0.00728664
exploration/Rewards Min            -0.346998
exploration/Returns Mean          -12.1927
exploration/Returns Std             0.398233
exploration/Returns Max           -11.7945
exploration/Returns Min           -12.5909
exploration/Actions Mean            0.00308549
exploration/Actions Std             0.145795
exploration/Actions Max             0.703418
exploration/Actions Min            -0.82611
exploration/Num Paths               2
exploration/Average Returns       -12.1927
evaluation/num steps total     103000
evaluation/num paths total       1030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0338215
evaluation/Rewards Std              0.0466952
evaluation/Rewards Max             -0.0152428
evaluation/Rewards Min             -0.733874
evaluation/Returns Mean            -3.38215
evaluation/Returns Std              0.253619
evaluation/Returns Max             -2.99387
evaluation/Returns Min             -3.69177
evaluation/Actions Mean             0.00905034
evaluation/Actions Std              0.0820118
evaluation/Actions Max              0.999915
evaluation/Actions Min             -0.0519617
evaluation/Num Paths                5
evaluation/Average Returns         -3.38215
time/data storing (s)               0.00112098
time/evaluation sampling (s)        0.074711
time/exploration sampling (s)       0.0332103
time/logging (s)                    0.00248941
time/saving (s)                     0.00184693
time/training (s)                   0.458421
time/epoch (s)                      0.571799
time/total (s)                    119.249
Epoch                             205
-----------------------------  ----------------
2019-04-13 17:00:33.847390 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 206 finished
-----------------------------  ----------------
replay_buffer/size              41500
trainer/QF1 Loss                    3.85419
trainer/QF2 Loss                    3.8585
trainer/Policy Loss                11.0819
trainer/Q1 Predictions Mean       -11.1837
trainer/Q1 Predictions Std          0.179318
trainer/Q1 Predictions Max        -11.0475
trainer/Q1 Predictions Min        -11.8154
trainer/Q2 Predictions Mean       -11.1715
trainer/Q2 Predictions Std          0.173518
trainer/Q2 Predictions Max        -11.0302
trainer/Q2 Predictions Min        -11.7941
trainer/Q Targets Mean            -11.0761
trainer/Q Targets Std               1.98185
trainer/Q Targets Max              -0.103065
trainer/Q Targets Min             -12.0912
trainer/Bellman Errors 1 Mean       3.85419
trainer/Bellman Errors 1 Std       21.01
trainer/Bellman Errors 1 Max      120.832
trainer/Bellman Errors 1 Min        1.2586e-07
trainer/Bellman Errors 2 Mean       3.8585
trainer/Bellman Errors 2 Std       21.0045
trainer/Bellman Errors 2 Max      120.806
trainer/Bellman Errors 2 Min        0.000212181
trainer/Policy Action Mean         -0.0273775
trainer/Policy Action Std           0.217218
trainer/Policy Action Max           0.9997
trainer/Policy Action Min          -0.917846
exploration/num steps total     41500
exploration/num paths total       415
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137873
exploration/Rewards Std             0.0930985
exploration/Rewards Max            -0.0050856
exploration/Rewards Min            -0.935066
exploration/Returns Mean          -13.7873
exploration/Returns Std             0.455623
exploration/Returns Max           -13.3316
exploration/Returns Min           -14.2429
exploration/Actions Mean            0.00810219
exploration/Actions Std             0.173646
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.7873
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0349109
evaluation/Rewards Std              0.0347842
evaluation/Rewards Max             -0.0287563
evaluation/Rewards Min             -0.640607
evaluation/Returns Mean            -3.49109
evaluation/Returns Std              0.260668
evaluation/Returns Max             -3.21574
evaluation/Returns Min             -3.87443
evaluation/Actions Mean             0.00603299
evaluation/Actions Std              0.0726035
evaluation/Actions Max              0.99981
evaluation/Actions Min             -0.843448
evaluation/Num Paths                5
evaluation/Average Returns         -3.49109
time/data storing (s)               0.00111373
time/evaluation sampling (s)        0.0817796
time/exploration sampling (s)       0.0329558
time/logging (s)                    0.00340402
time/saving (s)                     0.00499427
time/training (s)                   0.449025
time/epoch (s)                      0.573272
time/total (s)                    119.826
Epoch                             206
-----------------------------  ----------------
2019-04-13 17:00:34.425394 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 207 finished
-----------------------------  ----------------
replay_buffer/size              41700
trainer/QF1 Loss                    0.0298384
trainer/QF2 Loss                    0.0311916
trainer/Policy Loss                11.3376
trainer/Q1 Predictions Mean       -11.4539
trainer/Q1 Predictions Std          0.125391
trainer/Q1 Predictions Max        -11.3216
trainer/Q1 Predictions Min        -11.9739
trainer/Q2 Predictions Mean       -11.4558
trainer/Q2 Predictions Std          0.125221
trainer/Q2 Predictions Max        -11.3138
trainer/Q2 Predictions Min        -11.9885
trainer/Q Targets Mean            -11.4661
trainer/Q Targets Std               0.20622
trainer/Q Targets Max             -11.2007
trainer/Q Targets Min             -12.0733
trainer/Bellman Errors 1 Mean       0.0298384
trainer/Bellman Errors 1 Std        0.054532
trainer/Bellman Errors 1 Max        0.285825
trainer/Bellman Errors 1 Min        2.27374e-09
trainer/Bellman Errors 2 Mean       0.0311916
trainer/Bellman Errors 2 Std        0.0556297
trainer/Bellman Errors 2 Max        0.286137
trainer/Bellman Errors 2 Min        9.40659e-06
trainer/Policy Action Mean          0.02682
trainer/Policy Action Std           0.189869
trainer/Policy Action Max           0.996116
trainer/Policy Action Min          -0.274613
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.121572
exploration/Rewards Std             0.0628677
exploration/Rewards Max            -0.00288347
exploration/Rewards Min            -0.326364
exploration/Returns Mean          -12.1572
exploration/Returns Std             0.303944
exploration/Returns Max           -11.8533
exploration/Returns Min           -12.4612
exploration/Actions Mean            0.00460846
exploration/Actions Std             0.159509
exploration/Actions Max             1
exploration/Actions Min            -0.81062
exploration/Num Paths               2
exploration/Average Returns       -12.1572
evaluation/num steps total     104000
evaluation/num paths total       1040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.00971574
evaluation/Rewards Std              0.0460168
evaluation/Rewards Max             -0.00582817
evaluation/Rewards Min             -0.951651
evaluation/Returns Mean            -0.971574
evaluation/Returns Std              0.369546
evaluation/Returns Max             -0.687705
evaluation/Returns Min             -1.64829
evaluation/Actions Mean             0.00537481
evaluation/Actions Std              0.0670034
evaluation/Actions Max              0.999988
evaluation/Actions Min             -0.407491
evaluation/Num Paths                5
evaluation/Average Returns         -0.971574
time/data storing (s)               0.00109562
time/evaluation sampling (s)        0.0739562
time/exploration sampling (s)       0.03348
time/logging (s)                    0.00246101
time/saving (s)                     0.00223941
time/training (s)                   0.45649
time/epoch (s)                      0.569723
time/total (s)                    120.4
Epoch                             207
-----------------------------  ----------------
2019-04-13 17:00:35.319167 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 208 finished
-----------------------------  ----------------
replay_buffer/size              41900
trainer/QF1 Loss                    0.0163765
trainer/QF2 Loss                    0.016071
trainer/Policy Loss                11.3454
trainer/Q1 Predictions Mean       -11.4419
trainer/Q1 Predictions Std          0.551613
trainer/Q1 Predictions Max        -11.247
trainer/Q1 Predictions Min        -14.4111
trainer/Q2 Predictions Mean       -11.4459
trainer/Q2 Predictions Std          0.55375
trainer/Q2 Predictions Max        -11.2441
trainer/Q2 Predictions Min        -14.428
trainer/Q Targets Mean            -11.4872
trainer/Q Targets Std               0.564729
trainer/Q Targets Max             -11.1309
trainer/Q Targets Min             -14.4917
trainer/Bellman Errors 1 Mean       0.0163765
trainer/Bellman Errors 1 Std        0.0280333
trainer/Bellman Errors 1 Max        0.125636
trainer/Bellman Errors 1 Min        5.63443e-06
trainer/Bellman Errors 2 Mean       0.016071
trainer/Bellman Errors 2 Std        0.0274332
trainer/Bellman Errors 2 Max        0.119733
trainer/Bellman Errors 2 Min        1.38718e-06
trainer/Policy Action Mean          0.0675968
trainer/Policy Action Std           0.254119
trainer/Policy Action Max           0.99948
trainer/Policy Action Min          -0.387969
exploration/num steps total     41900
exploration/num paths total       419
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.144499
exploration/Rewards Std             0.0763166
exploration/Rewards Max            -0.00312225
exploration/Rewards Min            -0.384391
exploration/Returns Mean          -14.4499
exploration/Returns Std             0.406506
exploration/Returns Max           -14.0433
exploration/Returns Min           -14.8564
exploration/Actions Mean            0.00614113
exploration/Actions Std             0.165476
exploration/Actions Max             0.874376
exploration/Actions Min            -0.510419
exploration/Num Paths               2
exploration/Average Returns       -14.4499
evaluation/num steps total     104500
evaluation/num paths total       1045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0582931
evaluation/Rewards Std              0.0403388
evaluation/Rewards Max             -0.0164819
evaluation/Rewards Min             -0.859639
evaluation/Returns Mean            -5.82931
evaluation/Returns Std              0.32991
evaluation/Returns Max             -5.51477
evaluation/Returns Min             -6.40162
evaluation/Actions Mean             0.00385999
evaluation/Actions Std              0.0807811
evaluation/Actions Max              0.999984
evaluation/Actions Min             -0.951419
evaluation/Num Paths                5
evaluation/Average Returns         -5.82931
time/data storing (s)               0.00111471
time/evaluation sampling (s)        0.075413
time/exploration sampling (s)       0.0324269
time/logging (s)                    0.00408215
time/saving (s)                     0.00275396
time/training (s)                   0.772361
time/epoch (s)                      0.888152
time/total (s)                    121.293
Epoch                             208
-----------------------------  ----------------
2019-04-13 17:00:36.201115 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 209 finished
-----------------------------  ----------------
replay_buffer/size              42100
trainer/QF1 Loss                    0.0344168
trainer/QF2 Loss                    0.0329276
trainer/Policy Loss                11.3173
trainer/Q1 Predictions Mean       -11.5304
trainer/Q1 Predictions Std          0.46442
trainer/Q1 Predictions Max        -11.287
trainer/Q1 Predictions Min        -13.2287
trainer/Q2 Predictions Mean       -11.5308
trainer/Q2 Predictions Std          0.47134
trainer/Q2 Predictions Max        -11.2793
trainer/Q2 Predictions Min        -13.3149
trainer/Q Targets Mean            -11.6104
trainer/Q Targets Std               0.48094
trainer/Q Targets Max             -11.174
trainer/Q Targets Min             -13.3722
trainer/Bellman Errors 1 Mean       0.0344168
trainer/Bellman Errors 1 Std        0.0516721
trainer/Bellman Errors 1 Max        0.226004
trainer/Bellman Errors 1 Min        6.72662e-07
trainer/Bellman Errors 2 Mean       0.0329276
trainer/Bellman Errors 2 Std        0.0511871
trainer/Bellman Errors 2 Max        0.208985
trainer/Bellman Errors 2 Min        3.52208e-05
trainer/Policy Action Mean          0.0265709
trainer/Policy Action Std           0.247676
trainer/Policy Action Max           0.968556
trainer/Policy Action Min          -0.971359
exploration/num steps total     42100
exploration/num paths total       421
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124934
exploration/Rewards Std             0.0658259
exploration/Rewards Max            -0.00882769
exploration/Rewards Min            -0.347934
exploration/Returns Mean          -12.4934
exploration/Returns Std             0.282821
exploration/Returns Max           -12.2106
exploration/Returns Min           -12.7762
exploration/Actions Mean           -0.000376129
exploration/Actions Std             0.146294
exploration/Actions Max             1
exploration/Actions Min            -0.787654
exploration/Num Paths               2
exploration/Average Returns       -12.4934
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0180285
evaluation/Rewards Std              0.0525737
evaluation/Rewards Max             -0.0134511
evaluation/Rewards Min             -0.960293
evaluation/Returns Mean            -1.80285
evaluation/Returns Std              0.37468
evaluation/Returns Max             -1.35754
evaluation/Returns Min             -2.42574
evaluation/Actions Mean             0.0047739
evaluation/Actions Std              0.0788267
evaluation/Actions Max              0.999978
evaluation/Actions Min             -0.783565
evaluation/Num Paths                5
evaluation/Average Returns         -1.80285
time/data storing (s)               0.00153677
time/evaluation sampling (s)        0.177395
time/exploration sampling (s)       0.0793142
time/logging (s)                    0.00283439
time/saving (s)                     0.00755489
time/training (s)                   0.600568
time/epoch (s)                      0.869203
time/total (s)                    122.167
Epoch                             209
-----------------------------  ----------------
2019-04-13 17:00:36.743887 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 210 finished
-----------------------------  ----------------
replay_buffer/size              42300
trainer/QF1 Loss                    0.0469478
trainer/QF2 Loss                    0.0465676
trainer/Policy Loss                11.3513
trainer/Q1 Predictions Mean       -11.4445
trainer/Q1 Predictions Std          0.478998
trainer/Q1 Predictions Max        -11.2774
trainer/Q1 Predictions Min        -14.0947
trainer/Q2 Predictions Mean       -11.4497
trainer/Q2 Predictions Std          0.484623
trainer/Q2 Predictions Max        -11.2955
trainer/Q2 Predictions Min        -14.1345
trainer/Q Targets Mean            -11.5711
trainer/Q Targets Std               0.444255
trainer/Q Targets Max             -11.2434
trainer/Q Targets Min             -13.8544
trainer/Bellman Errors 1 Mean       0.0469478
trainer/Bellman Errors 1 Std        0.070488
trainer/Bellman Errors 1 Max        0.316093
trainer/Bellman Errors 1 Min        1.08944e-05
trainer/Bellman Errors 2 Mean       0.0465676
trainer/Bellman Errors 2 Std        0.0711831
trainer/Bellman Errors 2 Max        0.338552
trainer/Bellman Errors 2 Min        2.95495e-07
trainer/Policy Action Mean          0.0413959
trainer/Policy Action Std           0.194571
trainer/Policy Action Max           0.989454
trainer/Policy Action Min          -0.170702
exploration/num steps total     42300
exploration/num paths total       423
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134214
exploration/Rewards Std             0.0751834
exploration/Rewards Max            -0.0103902
exploration/Rewards Min            -0.365493
exploration/Returns Mean          -13.4214
exploration/Returns Std             0.773866
exploration/Returns Max           -12.6476
exploration/Returns Min           -14.1953
exploration/Actions Mean            0.00289822
exploration/Actions Std             0.161831
exploration/Actions Max             1
exploration/Actions Min            -0.743543
exploration/Num Paths               2
exploration/Average Returns       -13.4214
evaluation/num steps total     105500
evaluation/num paths total       1055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0124705
evaluation/Rewards Std              0.0391135
evaluation/Rewards Max             -0.00572874
evaluation/Rewards Min             -0.732941
evaluation/Returns Mean            -1.24705
evaluation/Returns Std              0.30431
evaluation/Returns Max             -0.96631
evaluation/Returns Min             -1.72544
evaluation/Actions Mean             0.00549198
evaluation/Actions Std              0.0628527
evaluation/Actions Max              0.999932
evaluation/Actions Min             -0.0679246
evaluation/Num Paths                5
evaluation/Average Returns         -1.24705
time/data storing (s)               0.0017589
time/evaluation sampling (s)        0.0959646
time/exploration sampling (s)       0.0343123
time/logging (s)                    0.00262966
time/saving (s)                     0.00226771
time/training (s)                   0.39304
time/epoch (s)                      0.529973
time/total (s)                    122.705
Epoch                             210
-----------------------------  ----------------
2019-04-13 17:00:37.777896 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 211 finished
-----------------------------  ----------------
replay_buffer/size              42500
trainer/QF1 Loss                    0.0279029
trainer/QF2 Loss                    0.0303151
trainer/Policy Loss                11.5336
trainer/Q1 Predictions Mean       -11.6673
trainer/Q1 Predictions Std          0.403783
trainer/Q1 Predictions Max        -11.4634
trainer/Q1 Predictions Min        -13.7748
trainer/Q2 Predictions Mean       -11.6713
trainer/Q2 Predictions Std          0.40454
trainer/Q2 Predictions Max        -11.4561
trainer/Q2 Predictions Min        -13.7845
trainer/Q Targets Mean            -11.5547
trainer/Q Targets Std               0.468053
trainer/Q Targets Max             -11.2805
trainer/Q Targets Min             -13.9756
trainer/Bellman Errors 1 Mean       0.0279029
trainer/Bellman Errors 1 Std        0.0275848
trainer/Bellman Errors 1 Max        0.100087
trainer/Bellman Errors 1 Min        3.58361e-06
trainer/Bellman Errors 2 Mean       0.0303151
trainer/Bellman Errors 2 Std        0.0303071
trainer/Bellman Errors 2 Max        0.111925
trainer/Bellman Errors 2 Min        1.88855e-06
trainer/Policy Action Mean          0.0227191
trainer/Policy Action Std           0.192792
trainer/Policy Action Max           0.996647
trainer/Policy Action Min          -0.324524
exploration/num steps total     42500
exploration/num paths total       425
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132745
exploration/Rewards Std             0.0947376
exploration/Rewards Max            -0.00197488
exploration/Rewards Min            -1.07828
exploration/Returns Mean          -13.2745
exploration/Returns Std             0.359545
exploration/Returns Max           -12.915
exploration/Returns Min           -13.6341
exploration/Actions Mean            0.00595461
exploration/Actions Std             0.156113
exploration/Actions Max             0.94467
exploration/Actions Min            -0.458407
exploration/Num Paths               2
exploration/Average Returns       -13.2745
evaluation/num steps total     106000
evaluation/num paths total       1060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0305332
evaluation/Rewards Std              0.064666
evaluation/Rewards Max             -0.0116807
evaluation/Rewards Min             -0.935681
evaluation/Returns Mean            -3.05332
evaluation/Returns Std              0.201638
evaluation/Returns Max             -2.7405
evaluation/Returns Min             -3.34396
evaluation/Actions Mean             0.00948468
evaluation/Actions Std              0.0954172
evaluation/Actions Max              0.99998
evaluation/Actions Min             -0.690104
evaluation/Num Paths                5
evaluation/Average Returns         -3.05332
time/data storing (s)               0.00638973
time/evaluation sampling (s)        0.0802834
time/exploration sampling (s)       0.138647
time/logging (s)                    0.0024692
time/saving (s)                     0.00181981
time/training (s)                   0.797401
time/epoch (s)                      1.02701
time/total (s)                    123.736
Epoch                             211
-----------------------------  ----------------
2019-04-13 17:00:38.412443 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                    0.0702987
trainer/QF2 Loss                    0.0638264
trainer/Policy Loss                11.1639
trainer/Q1 Predictions Mean       -11.2893
trainer/Q1 Predictions Std          0.166079
trainer/Q1 Predictions Max        -11.163
trainer/Q1 Predictions Min        -12.148
trainer/Q2 Predictions Mean       -11.3064
trainer/Q2 Predictions Std          0.16593
trainer/Q2 Predictions Max        -11.1633
trainer/Q2 Predictions Min        -12.1616
trainer/Q Targets Mean            -11.5245
trainer/Q Targets Std               0.232237
trainer/Q Targets Max             -11.2532
trainer/Q Targets Min             -12.463
trainer/Bellman Errors 1 Mean       0.0702987
trainer/Bellman Errors 1 Std        0.0723433
trainer/Bellman Errors 1 Max        0.285803
trainer/Bellman Errors 1 Min        0.00457366
trainer/Bellman Errors 2 Mean       0.0638264
trainer/Bellman Errors 2 Std        0.0713159
trainer/Bellman Errors 2 Max        0.275583
trainer/Bellman Errors 2 Min        0.0012943
trainer/Policy Action Mean         -0.0129092
trainer/Policy Action Std           0.116221
trainer/Policy Action Max           0.426162
trainer/Policy Action Min          -0.286324
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133893
exploration/Rewards Std             0.0895053
exploration/Rewards Max            -0.0126507
exploration/Rewards Min            -0.885773
exploration/Returns Mean          -13.3893
exploration/Returns Std             0.219577
exploration/Returns Max           -13.1697
exploration/Returns Min           -13.6088
exploration/Actions Mean            0.0077013
exploration/Actions Std             0.166625
exploration/Actions Max             0.990004
exploration/Actions Min            -0.876712
exploration/Num Paths               2
exploration/Average Returns       -13.3893
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0279496
evaluation/Rewards Std              0.0663664
evaluation/Rewards Max             -0.015963
evaluation/Rewards Min             -0.991201
evaluation/Returns Mean            -2.79496
evaluation/Returns Std              0.33977
evaluation/Returns Max             -2.19506
evaluation/Returns Min             -3.1996
evaluation/Actions Mean             0.00679423
evaluation/Actions Std              0.0940729
evaluation/Actions Max              0.999983
evaluation/Actions Min             -0.96274
evaluation/Num Paths                5
evaluation/Average Returns         -2.79496
time/data storing (s)               0.00111391
time/evaluation sampling (s)        0.0827362
time/exploration sampling (s)       0.0384135
time/logging (s)                    0.00224306
time/saving (s)                     0.00179965
time/training (s)                   0.500631
time/epoch (s)                      0.626937
time/total (s)                    124.367
Epoch                             212
-----------------------------  ---------------
2019-04-13 17:00:39.027839 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 213 finished
-----------------------------  ----------------
replay_buffer/size              42900
trainer/QF1 Loss                    3.99191
trainer/QF2 Loss                    3.99557
trainer/Policy Loss                11.3659
trainer/Q1 Predictions Mean       -11.5328
trainer/Q1 Predictions Std          0.401817
trainer/Q1 Predictions Max        -11.2819
trainer/Q1 Predictions Min        -13.0958
trainer/Q2 Predictions Mean       -11.5409
trainer/Q2 Predictions Std          0.401462
trainer/Q2 Predictions Max        -11.3154
trainer/Q2 Predictions Min        -13.09
trainer/Q Targets Mean            -11.3402
trainer/Q Targets Std               2.09096
trainer/Q Targets Max              -0.0959165
trainer/Q Targets Min             -13.8527
trainer/Bellman Errors 1 Mean       3.99191
trainer/Bellman Errors 1 Std       21.8832
trainer/Bellman Errors 1 Max      125.831
trainer/Bellman Errors 1 Min        0.00018896
trainer/Bellman Errors 2 Mean       3.99557
trainer/Bellman Errors 2 Std       21.9187
trainer/Bellman Errors 2 Max      126.032
trainer/Bellman Errors 2 Min        3.30404e-06
trainer/Policy Action Mean          0.00282068
trainer/Policy Action Std           0.215664
trainer/Policy Action Max           0.99571
trainer/Policy Action Min          -0.360739
exploration/num steps total     42900
exploration/num paths total       429
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135145
exploration/Rewards Std             0.0680374
exploration/Rewards Max            -0.00781642
exploration/Rewards Min            -0.437062
exploration/Returns Mean          -13.5145
exploration/Returns Std             0.0846606
exploration/Returns Max           -13.4298
exploration/Returns Min           -13.5991
exploration/Actions Mean            0.00414072
exploration/Actions Std             0.146497
exploration/Actions Max             0.646619
exploration/Actions Min            -0.395921
exploration/Num Paths               2
exploration/Average Returns       -13.5145
evaluation/num steps total     107000
evaluation/num paths total       1070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0256254
evaluation/Rewards Std              0.0199976
evaluation/Rewards Max             -0.00219691
evaluation/Rewards Min             -0.385037
evaluation/Returns Mean            -2.56254
evaluation/Returns Std              0.110085
evaluation/Returns Max             -2.46533
evaluation/Returns Min             -2.77075
evaluation/Actions Mean             0.00488002
evaluation/Actions Std              0.0773133
evaluation/Actions Max              0.996659
evaluation/Actions Min             -0.903871
evaluation/Num Paths                5
evaluation/Average Returns         -2.56254
time/data storing (s)               0.00111109
time/evaluation sampling (s)        0.0784694
time/exploration sampling (s)       0.035017
time/logging (s)                    0.00247948
time/saving (s)                     0.00223972
time/training (s)                   0.488926
time/epoch (s)                      0.608243
time/total (s)                    124.979
Epoch                             213
-----------------------------  ----------------
2019-04-13 17:00:39.611966 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 214 finished
-----------------------------  ----------------
replay_buffer/size              43100
trainer/QF1 Loss                    7.92362
trainer/QF2 Loss                    7.92766
trainer/Policy Loss                11.3074
trainer/Q1 Predictions Mean       -11.5194
trainer/Q1 Predictions Std          0.395797
trainer/Q1 Predictions Max        -11.3008
trainer/Q1 Predictions Min        -13.5471
trainer/Q2 Predictions Mean       -11.5163
trainer/Q2 Predictions Std          0.380139
trainer/Q2 Predictions Max        -11.2817
trainer/Q2 Predictions Min        -13.4578
trainer/Q Targets Mean            -10.8751
trainer/Q Targets Std               2.79899
trainer/Q Targets Max              -0.0994314
trainer/Q Targets Min             -13.2879
trainer/Bellman Errors 1 Mean       7.92362
trainer/Bellman Errors 1 Std       30.5826
trainer/Bellman Errors 1 Max      126.655
trainer/Bellman Errors 1 Min        1.36355e-05
trainer/Bellman Errors 2 Mean       7.92766
trainer/Bellman Errors 2 Std       30.6005
trainer/Bellman Errors 2 Max      126.874
trainer/Bellman Errors 2 Min        7.1968e-06
trainer/Policy Action Mean          0.00891179
trainer/Policy Action Std           0.202269
trainer/Policy Action Max           0.986135
trainer/Policy Action Min          -0.982902
exploration/num steps total     43100
exploration/num paths total       431
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126561
exploration/Rewards Std             0.082439
exploration/Rewards Max            -0.00758667
exploration/Rewards Min            -0.782728
exploration/Returns Mean          -12.6561
exploration/Returns Std             0.150238
exploration/Returns Max           -12.5058
exploration/Returns Min           -12.8063
exploration/Actions Mean            0.00158068
exploration/Actions Std             0.152151
exploration/Actions Max             0.878003
exploration/Actions Min            -0.813583
exploration/Num Paths               2
exploration/Average Returns       -12.6561
evaluation/num steps total     107500
evaluation/num paths total       1075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.032223
evaluation/Rewards Std              0.0462569
evaluation/Rewards Max             -0.0150996
evaluation/Rewards Min             -0.892408
evaluation/Returns Mean            -3.2223
evaluation/Returns Std              0.340692
evaluation/Returns Max             -2.92639
evaluation/Returns Min             -3.79526
evaluation/Actions Mean             0.00682693
evaluation/Actions Std              0.0755213
evaluation/Actions Max              0.999974
evaluation/Actions Min             -0.146312
evaluation/Num Paths                5
evaluation/Average Returns         -3.2223
time/data storing (s)               0.00114108
time/evaluation sampling (s)        0.0785729
time/exploration sampling (s)       0.0339711
time/logging (s)                    0.00254013
time/saving (s)                     0.00225149
time/training (s)                   0.45826
time/epoch (s)                      0.576736
time/total (s)                    125.56
Epoch                             214
-----------------------------  ----------------
2019-04-13 17:00:40.178602 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 215 finished
-----------------------------  ----------------
replay_buffer/size              43300
trainer/QF1 Loss                    0.0442994
trainer/QF2 Loss                    0.0455016
trainer/Policy Loss                11.4175
trainer/Q1 Predictions Mean       -11.5324
trainer/Q1 Predictions Std          0.150054
trainer/Q1 Predictions Max        -11.3705
trainer/Q1 Predictions Min        -12.1763
trainer/Q2 Predictions Mean       -11.5297
trainer/Q2 Predictions Std          0.134849
trainer/Q2 Predictions Max        -11.3831
trainer/Q2 Predictions Min        -12.0781
trainer/Q Targets Mean            -11.631
trainer/Q Targets Std               0.248391
trainer/Q Targets Max             -11.2927
trainer/Q Targets Min             -12.4448
trainer/Bellman Errors 1 Mean       0.0442994
trainer/Bellman Errors 1 Std        0.0607267
trainer/Bellman Errors 1 Max        0.20958
trainer/Bellman Errors 1 Min        2.16058e-05
trainer/Bellman Errors 2 Mean       0.0455015
trainer/Bellman Errors 2 Std        0.0626455
trainer/Bellman Errors 2 Max        0.213094
trainer/Bellman Errors 2 Min        0.000215332
trainer/Policy Action Mean          0.00548345
trainer/Policy Action Std           0.105884
trainer/Policy Action Max           0.257008
trainer/Policy Action Min          -0.32764
exploration/num steps total     43300
exploration/num paths total       433
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.147726
exploration/Rewards Std             0.0736922
exploration/Rewards Max            -0.0178339
exploration/Rewards Min            -0.631545
exploration/Returns Mean          -14.7726
exploration/Returns Std             0.607897
exploration/Returns Max           -14.1647
exploration/Returns Min           -15.3805
exploration/Actions Mean            0.00749766
exploration/Actions Std             0.15895
exploration/Actions Max             1
exploration/Actions Min            -0.446333
exploration/Num Paths               2
exploration/Average Returns       -14.7726
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0286832
evaluation/Rewards Std              0.057467
evaluation/Rewards Max             -0.0236884
evaluation/Rewards Min             -1.1048
evaluation/Returns Mean            -2.86832
evaluation/Returns Std              0.469703
evaluation/Returns Max             -2.44355
evaluation/Returns Min             -3.65242
evaluation/Actions Mean             0.00483158
evaluation/Actions Std              0.0678317
evaluation/Actions Max              0.999984
evaluation/Actions Min             -0.345029
evaluation/Num Paths                5
evaluation/Average Returns         -2.86832
time/data storing (s)               0.00142449
time/evaluation sampling (s)        0.0790414
time/exploration sampling (s)       0.0350371
time/logging (s)                    0.00247158
time/saving (s)                     0.00234358
time/training (s)                   0.438879
time/epoch (s)                      0.559197
time/total (s)                    126.123
Epoch                             215
-----------------------------  ----------------
2019-04-13 17:00:40.753914 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 216 finished
-----------------------------  ----------------
replay_buffer/size              43500
trainer/QF1 Loss                    0.0134216
trainer/QF2 Loss                    0.0130761
trainer/Policy Loss                11.5007
trainer/Q1 Predictions Mean       -11.686
trainer/Q1 Predictions Std          0.392914
trainer/Q1 Predictions Max        -11.4668
trainer/Q1 Predictions Min        -13.5404
trainer/Q2 Predictions Mean       -11.6782
trainer/Q2 Predictions Std          0.364066
trainer/Q2 Predictions Max        -11.4657
trainer/Q2 Predictions Min        -13.3804
trainer/Q Targets Mean            -11.7282
trainer/Q Targets Std               0.377671
trainer/Q Targets Max             -11.4036
trainer/Q Targets Min             -13.3666
trainer/Bellman Errors 1 Mean       0.0134216
trainer/Bellman Errors 1 Std        0.0231394
trainer/Bellman Errors 1 Max        0.0983148
trainer/Bellman Errors 1 Min        4.01469e-06
trainer/Bellman Errors 2 Mean       0.0130761
trainer/Bellman Errors 2 Std        0.0234204
trainer/Bellman Errors 2 Max        0.101902
trainer/Bellman Errors 2 Min        4.01087e-10
trainer/Policy Action Mean          0.0246557
trainer/Policy Action Std           0.208639
trainer/Policy Action Max           0.99723
trainer/Policy Action Min          -0.944425
exploration/num steps total     43500
exploration/num paths total       435
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140125
exploration/Rewards Std             0.0764282
exploration/Rewards Max            -0.0179589
exploration/Rewards Min            -0.384732
exploration/Returns Mean          -14.0125
exploration/Returns Std             0.72336
exploration/Returns Max           -13.2892
exploration/Returns Min           -14.7359
exploration/Actions Mean            0.00185559
exploration/Actions Std             0.140785
exploration/Actions Max             0.525501
exploration/Actions Min            -0.328356
exploration/Num Paths               2
exploration/Average Returns       -14.0125
evaluation/num steps total     108500
evaluation/num paths total       1085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0572385
evaluation/Rewards Std              0.0498278
evaluation/Rewards Max             -0.0299703
evaluation/Rewards Min             -0.794355
evaluation/Returns Mean            -5.72385
evaluation/Returns Std              0.303342
evaluation/Returns Max             -5.33109
evaluation/Returns Min             -6.089
evaluation/Actions Mean             0.00628526
evaluation/Actions Std              0.0931216
evaluation/Actions Max              0.999964
evaluation/Actions Min             -0.966746
evaluation/Num Paths                5
evaluation/Average Returns         -5.72385
time/data storing (s)               0.00107902
time/evaluation sampling (s)        0.0757327
time/exploration sampling (s)       0.0329138
time/logging (s)                    0.0024761
time/saving (s)                     0.00226925
time/training (s)                   0.453996
time/epoch (s)                      0.568466
time/total (s)                    126.695
Epoch                             216
-----------------------------  ----------------
2019-04-13 17:00:41.330812 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 217 finished
-----------------------------  ----------------
replay_buffer/size              43700
trainer/QF1 Loss                    0.0416513
trainer/QF2 Loss                    0.0423218
trainer/Policy Loss                11.342
trainer/Q1 Predictions Mean       -11.4148
trainer/Q1 Predictions Std          0.100581
trainer/Q1 Predictions Max        -11.3127
trainer/Q1 Predictions Min        -11.7773
trainer/Q2 Predictions Mean       -11.4123
trainer/Q2 Predictions Std          0.100735
trainer/Q2 Predictions Max        -11.3064
trainer/Q2 Predictions Min        -11.7366
trainer/Q Targets Mean            -11.578
trainer/Q Targets Std               0.196212
trainer/Q Targets Max             -11.2833
trainer/Q Targets Min             -12.2662
trainer/Bellman Errors 1 Mean       0.0416513
trainer/Bellman Errors 1 Std        0.054816
trainer/Bellman Errors 1 Max        0.239096
trainer/Bellman Errors 1 Min        1.4212e-05
trainer/Bellman Errors 2 Mean       0.0423218
trainer/Bellman Errors 2 Std        0.0576423
trainer/Bellman Errors 2 Max        0.280516
trainer/Bellman Errors 2 Min        2.38325e-05
trainer/Policy Action Mean         -0.00216724
trainer/Policy Action Std           0.101853
trainer/Policy Action Max           0.34971
trainer/Policy Action Min          -0.331423
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137313
exploration/Rewards Std             0.0773319
exploration/Rewards Max            -0.00839824
exploration/Rewards Min            -0.706926
exploration/Returns Mean          -13.7313
exploration/Returns Std             0.500118
exploration/Returns Max           -13.2312
exploration/Returns Min           -14.2314
exploration/Actions Mean            0.00797457
exploration/Actions Std             0.159589
exploration/Actions Max             1
exploration/Actions Min            -0.40984
exploration/Num Paths               2
exploration/Average Returns       -13.7313
evaluation/num steps total     109000
evaluation/num paths total       1090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0459414
evaluation/Rewards Std              0.0380141
evaluation/Rewards Max             -0.0340034
evaluation/Rewards Min             -0.870561
evaluation/Returns Mean            -4.59414
evaluation/Returns Std              0.305767
evaluation/Returns Max             -4.382
evaluation/Returns Min             -5.19815
evaluation/Actions Mean             0.00480439
evaluation/Actions Std              0.0677154
evaluation/Actions Max              0.99994
evaluation/Actions Min             -0.812027
evaluation/Num Paths                5
evaluation/Average Returns         -4.59414
time/data storing (s)               0.00342873
time/evaluation sampling (s)        0.0751449
time/exploration sampling (s)       0.0343834
time/logging (s)                    0.0024874
time/saving (s)                     0.00245635
time/training (s)                   0.451681
time/epoch (s)                      0.569581
time/total (s)                    127.268
Epoch                             217
-----------------------------  ----------------
2019-04-13 17:00:41.910042 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 218 finished
-----------------------------  ----------------
replay_buffer/size              43900
trainer/QF1 Loss                    0.0323719
trainer/QF2 Loss                    0.0302428
trainer/Policy Loss                11.5278
trainer/Q1 Predictions Mean       -11.6299
trainer/Q1 Predictions Std          0.633317
trainer/Q1 Predictions Max        -11.3977
trainer/Q1 Predictions Min        -15.1291
trainer/Q2 Predictions Mean       -11.6393
trainer/Q2 Predictions Std          0.633147
trainer/Q2 Predictions Max        -11.3958
trainer/Q2 Predictions Min        -15.1368
trainer/Q Targets Mean            -11.6967
trainer/Q Targets Std               0.549446
trainer/Q Targets Max             -11.3245
trainer/Q Targets Min             -14.6011
trainer/Bellman Errors 1 Mean       0.0323719
trainer/Bellman Errors 1 Std        0.0618014
trainer/Bellman Errors 1 Max        0.278834
trainer/Bellman Errors 1 Min        5.32636e-06
trainer/Bellman Errors 2 Mean       0.0302428
trainer/Bellman Errors 2 Std        0.0596914
trainer/Bellman Errors 2 Max        0.286971
trainer/Bellman Errors 2 Min        3.03583e-06
trainer/Policy Action Mean          0.0189503
trainer/Policy Action Std           0.197156
trainer/Policy Action Max           0.99851
trainer/Policy Action Min          -0.15276
exploration/num steps total     43900
exploration/num paths total       439
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.141121
exploration/Rewards Std             0.0685601
exploration/Rewards Max            -0.00765669
exploration/Rewards Min            -0.326484
exploration/Returns Mean          -14.1121
exploration/Returns Std             0.174093
exploration/Returns Max           -13.938
exploration/Returns Min           -14.2862
exploration/Actions Mean            0.00527317
exploration/Actions Std             0.155354
exploration/Actions Max             1
exploration/Actions Min            -0.354392
exploration/Num Paths               2
exploration/Average Returns       -14.1121
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0614754
evaluation/Rewards Std              0.0270467
evaluation/Rewards Max             -0.00537079
evaluation/Rewards Min             -0.544039
evaluation/Returns Mean            -6.14754
evaluation/Returns Std              0.186692
evaluation/Returns Max             -5.85562
evaluation/Returns Min             -6.43889
evaluation/Actions Mean             0.00534931
evaluation/Actions Std              0.0724791
evaluation/Actions Max              0.996188
evaluation/Actions Min             -0.61185
evaluation/Num Paths                5
evaluation/Average Returns         -6.14754
time/data storing (s)               0.00105221
time/evaluation sampling (s)        0.0810555
time/exploration sampling (s)       0.0319182
time/logging (s)                    0.0022528
time/saving (s)                     0.0020365
time/training (s)                   0.453424
time/epoch (s)                      0.571739
time/total (s)                    127.844
Epoch                             218
-----------------------------  ----------------
2019-04-13 17:00:42.498420 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 219 finished
-----------------------------  ----------------
replay_buffer/size              44100
trainer/QF1 Loss                    0.0284092
trainer/QF2 Loss                    0.0234047
trainer/Policy Loss                11.6053
trainer/Q1 Predictions Mean       -11.8452
trainer/Q1 Predictions Std          0.499365
trainer/Q1 Predictions Max        -11.5358
trainer/Q1 Predictions Min        -14.1913
trainer/Q2 Predictions Mean       -11.8293
trainer/Q2 Predictions Std          0.512626
trainer/Q2 Predictions Max        -11.5383
trainer/Q2 Predictions Min        -14.3431
trainer/Q Targets Mean            -11.8081
trainer/Q Targets Std               0.551832
trainer/Q Targets Max             -11.311
trainer/Q Targets Min             -14.5463
trainer/Bellman Errors 1 Mean       0.0284092
trainer/Bellman Errors 1 Std        0.0341789
trainer/Bellman Errors 1 Max        0.130282
trainer/Bellman Errors 1 Min        2.09548e-07
trainer/Bellman Errors 2 Mean       0.0234047
trainer/Bellman Errors 2 Std        0.0242802
trainer/Bellman Errors 2 Max        0.0810326
trainer/Bellman Errors 2 Min        8.03288e-05
trainer/Policy Action Mean          0.00786974
trainer/Policy Action Std           0.243164
trainer/Policy Action Max           0.99812
trainer/Policy Action Min          -0.895022
exploration/num steps total     44100
exploration/num paths total       441
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142145
exploration/Rewards Std             0.0780146
exploration/Rewards Max            -0.0157686
exploration/Rewards Min            -0.386532
exploration/Returns Mean          -14.2145
exploration/Returns Std             0.223203
exploration/Returns Max           -13.9913
exploration/Returns Min           -14.4377
exploration/Actions Mean           -0.000151066
exploration/Actions Std             0.145159
exploration/Actions Max             0.575011
exploration/Actions Min            -0.73349
exploration/Num Paths               2
exploration/Average Returns       -14.2145
evaluation/num steps total     110000
evaluation/num paths total       1100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0689943
evaluation/Rewards Std              0.0479513
evaluation/Rewards Max             -0.0409651
evaluation/Rewards Min             -0.859896
evaluation/Returns Mean            -6.89943
evaluation/Returns Std              0.324286
evaluation/Returns Max             -6.59053
evaluation/Returns Min             -7.32497
evaluation/Actions Mean             0.00566455
evaluation/Actions Std              0.075273
evaluation/Actions Max              0.999764
evaluation/Actions Min             -0.363336
evaluation/Num Paths                5
evaluation/Average Returns         -6.89943
time/data storing (s)               0.00110866
time/evaluation sampling (s)        0.0734918
time/exploration sampling (s)       0.032551
time/logging (s)                    0.00246098
time/saving (s)                     0.0102517
time/training (s)                   0.461577
time/epoch (s)                      0.581441
time/total (s)                    128.429
Epoch                             219
-----------------------------  ----------------
2019-04-13 17:00:43.067828 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 220 finished
-----------------------------  ----------------
replay_buffer/size              44300
trainer/QF1 Loss                    4.09575
trainer/QF2 Loss                    4.03039
trainer/Policy Loss                11.4406
trainer/Q1 Predictions Mean       -11.5341
trainer/Q1 Predictions Std          0.158063
trainer/Q1 Predictions Max        -11.4312
trainer/Q1 Predictions Min        -12.3364
trainer/Q2 Predictions Mean       -11.5301
trainer/Q2 Predictions Std          0.166133
trainer/Q2 Predictions Max        -11.4237
trainer/Q2 Predictions Min        -12.3686
trainer/Q Targets Mean            -11.3028
trainer/Q Targets Std               2.00619
trainer/Q Targets Max              -0.195241
trainer/Q Targets Min             -12.4637
trainer/Bellman Errors 1 Mean       4.09575
trainer/Bellman Errors 1 Std       22.5876
trainer/Bellman Errors 1 Max      129.858
trainer/Bellman Errors 1 Min        1.76559e-05
trainer/Bellman Errors 2 Mean       4.03039
trainer/Bellman Errors 2 Std       22.2254
trainer/Bellman Errors 2 Max      127.776
trainer/Bellman Errors 2 Min        2.33877e-05
trainer/Policy Action Mean          0.00107072
trainer/Policy Action Std           0.116414
trainer/Policy Action Max           0.374246
trainer/Policy Action Min          -0.390387
exploration/num steps total     44300
exploration/num paths total       443
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.144608
exploration/Rewards Std             0.0893029
exploration/Rewards Max            -0.0173846
exploration/Rewards Min            -0.65847
exploration/Returns Mean          -14.4608
exploration/Returns Std             0.542546
exploration/Returns Max           -13.9183
exploration/Returns Min           -15.0034
exploration/Actions Mean            0.00917197
exploration/Actions Std             0.179365
exploration/Actions Max             1
exploration/Actions Min            -0.77007
exploration/Num Paths               2
exploration/Average Returns       -14.4608
evaluation/num steps total     110500
evaluation/num paths total       1105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.040925
evaluation/Rewards Std              0.034709
evaluation/Rewards Max             -0.0202243
evaluation/Rewards Min             -0.632725
evaluation/Returns Mean            -4.0925
evaluation/Returns Std              0.180574
evaluation/Returns Max             -3.8694
evaluation/Returns Min             -4.41789
evaluation/Actions Mean             0.00585753
evaluation/Actions Std              0.0821362
evaluation/Actions Max              0.999857
evaluation/Actions Min             -0.911651
evaluation/Num Paths                5
evaluation/Average Returns         -4.0925
time/data storing (s)               0.00105892
time/evaluation sampling (s)        0.0727464
time/exploration sampling (s)       0.0326723
time/logging (s)                    0.00246109
time/saving (s)                     0.00238352
time/training (s)                   0.451186
time/epoch (s)                      0.562508
time/total (s)                    128.996
Epoch                             220
-----------------------------  ----------------
2019-04-13 17:00:43.654623 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 221 finished
-----------------------------  ----------------
replay_buffer/size              44500
trainer/QF1 Loss                    4.09512
trainer/QF2 Loss                    4.10105
trainer/Policy Loss                11.458
trainer/Q1 Predictions Mean       -11.6092
trainer/Q1 Predictions Std          0.338214
trainer/Q1 Predictions Max        -11.4372
trainer/Q1 Predictions Min        -13.3435
trainer/Q2 Predictions Mean       -11.6097
trainer/Q2 Predictions Std          0.319436
trainer/Q2 Predictions Max        -11.4404
trainer/Q2 Predictions Min        -13.2037
trainer/Q Targets Mean            -11.3448
trainer/Q Targets Std               2.0753
trainer/Q Targets Max              -0.10713
trainer/Q Targets Min             -13.9901
trainer/Bellman Errors 1 Mean       4.09512
trainer/Bellman Errors 1 Std       22.5717
trainer/Bellman Errors 1 Max      129.768
trainer/Bellman Errors 1 Min        4.14757e-05
trainer/Bellman Errors 2 Mean       4.10105
trainer/Bellman Errors 2 Std       22.5883
trainer/Bellman Errors 2 Max      129.866
trainer/Bellman Errors 2 Min        1.54007e-05
trainer/Policy Action Mean          0.00608168
trainer/Policy Action Std           0.215704
trainer/Policy Action Max           0.981726
trainer/Policy Action Min          -0.532503
exploration/num steps total     44500
exploration/num paths total       445
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.146148
exploration/Rewards Std             0.0788982
exploration/Rewards Max            -0.0174639
exploration/Rewards Min            -0.588166
exploration/Returns Mean          -14.6148
exploration/Returns Std             0.615085
exploration/Returns Max           -13.9997
exploration/Returns Min           -15.2299
exploration/Actions Mean            0.0048173
exploration/Actions Std             0.162351
exploration/Actions Max             0.963294
exploration/Actions Min            -0.508124
exploration/Num Paths               2
exploration/Average Returns       -14.6148
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0771102
evaluation/Rewards Std              0.0535571
evaluation/Rewards Max             -0.0537429
evaluation/Rewards Min             -0.916048
evaluation/Returns Mean            -7.71102
evaluation/Returns Std              0.256682
evaluation/Returns Max             -7.28456
evaluation/Returns Min             -8.05488
evaluation/Actions Mean             0.00516872
evaluation/Actions Std              0.0896927
evaluation/Actions Max              0.999989
evaluation/Actions Min             -0.96012
evaluation/Num Paths                5
evaluation/Average Returns         -7.71102
time/data storing (s)               0.00105339
time/evaluation sampling (s)        0.0757163
time/exploration sampling (s)       0.033843
time/logging (s)                    0.00246858
time/saving (s)                     0.00234359
time/training (s)                   0.464092
time/epoch (s)                      0.579517
time/total (s)                    129.579
Epoch                             221
-----------------------------  ----------------
2019-04-13 17:00:44.240388 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 222 finished
-----------------------------  ----------------
replay_buffer/size              44700
trainer/QF1 Loss                    8.17844
trainer/QF2 Loss                    8.1883
trainer/Policy Loss                11.3217
trainer/Q1 Predictions Mean       -11.6656
trainer/Q1 Predictions Std          0.490875
trainer/Q1 Predictions Max        -11.3874
trainer/Q1 Predictions Min        -14.1424
trainer/Q2 Predictions Mean       -11.6626
trainer/Q2 Predictions Std          0.481945
trainer/Q2 Predictions Max        -11.3952
trainer/Q2 Predictions Min        -14.0564
trainer/Q Targets Mean            -11.0242
trainer/Q Targets Std               2.87573
trainer/Q Targets Max              -0.124141
trainer/Q Targets Min             -14.8454
trainer/Bellman Errors 1 Mean       8.17844
trainer/Bellman Errors 1 Std       31.5295
trainer/Bellman Errors 1 Max      130.294
trainer/Bellman Errors 1 Min        3.18961e-05
trainer/Bellman Errors 2 Mean       8.1883
trainer/Bellman Errors 2 Std       31.5424
trainer/Bellman Errors 2 Max      130.353
trainer/Bellman Errors 2 Min        7.36691e-09
trainer/Policy Action Mean         -0.0474008
trainer/Policy Action Std           0.19009
trainer/Policy Action Max           0.992681
trainer/Policy Action Min          -0.462751
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.172041
exploration/Rewards Std             0.102692
exploration/Rewards Max            -0.00747585
exploration/Rewards Min            -0.868538
exploration/Returns Mean          -17.2041
exploration/Returns Std             0.549922
exploration/Returns Max           -16.6542
exploration/Returns Min           -17.754
exploration/Actions Mean            0.00799829
exploration/Actions Std             0.177266
exploration/Actions Max             1
exploration/Actions Min            -0.88159
exploration/Num Paths               2
exploration/Average Returns       -17.2041
evaluation/num steps total     111500
evaluation/num paths total       1115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.10278
evaluation/Rewards Std              0.0486141
evaluation/Rewards Max             -0.0377665
evaluation/Rewards Min             -0.856203
evaluation/Returns Mean           -10.278
evaluation/Returns Std              0.259708
evaluation/Returns Max             -9.97534
evaluation/Returns Min            -10.6166
evaluation/Actions Mean             0.00618893
evaluation/Actions Std              0.0783226
evaluation/Actions Max              0.999978
evaluation/Actions Min             -0.582938
evaluation/Num Paths                5
evaluation/Average Returns        -10.278
time/data storing (s)               0.00122449
time/evaluation sampling (s)        0.0763705
time/exploration sampling (s)       0.0355557
time/logging (s)                    0.00251391
time/saving (s)                     0.00259785
time/training (s)                   0.459792
time/epoch (s)                      0.578055
time/total (s)                    130.161
Epoch                             222
-----------------------------  ----------------
2019-04-13 17:00:44.841564 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 223 finished
-----------------------------  ----------------
replay_buffer/size              44900
trainer/QF1 Loss                    4.00554
trainer/QF2 Loss                    4.00903
trainer/Policy Loss                11.3532
trainer/Q1 Predictions Mean       -11.4869
trainer/Q1 Predictions Std          0.0890059
trainer/Q1 Predictions Max        -11.3536
trainer/Q1 Predictions Min        -11.7497
trainer/Q2 Predictions Mean       -11.4856
trainer/Q2 Predictions Std          0.0849959
trainer/Q2 Predictions Max        -11.3631
trainer/Q2 Predictions Min        -11.7452
trainer/Q Targets Mean            -11.1997
trainer/Q Targets Std               1.97802
trainer/Q Targets Max              -0.222027
trainer/Q Targets Min             -11.9664
trainer/Bellman Errors 1 Mean       4.00553
trainer/Bellman Errors 1 Std       22.1939
trainer/Bellman Errors 1 Max      127.576
trainer/Bellman Errors 1 Min        7.24464e-05
trainer/Bellman Errors 2 Mean       4.00903
trainer/Bellman Errors 2 Std       22.214
trainer/Bellman Errors 2 Max      127.691
trainer/Bellman Errors 2 Min        8.13233e-05
trainer/Policy Action Mean         -0.0323076
trainer/Policy Action Std           0.105094
trainer/Policy Action Max           0.25582
trainer/Policy Action Min          -0.223747
exploration/num steps total     44900
exploration/num paths total       449
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132262
exploration/Rewards Std             0.067673
exploration/Rewards Max            -0.00822413
exploration/Rewards Min            -0.371268
exploration/Returns Mean          -13.2262
exploration/Returns Std             1.06686
exploration/Returns Max           -12.1593
exploration/Returns Min           -14.293
exploration/Actions Mean            0.00127277
exploration/Actions Std             0.17187
exploration/Actions Max             1
exploration/Actions Min            -0.919483
exploration/Num Paths               2
exploration/Average Returns       -13.2262
evaluation/num steps total     112000
evaluation/num paths total       1120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0449867
evaluation/Rewards Std              0.0289084
evaluation/Rewards Max             -0.0338827
evaluation/Rewards Min             -0.631541
evaluation/Returns Mean            -4.49867
evaluation/Returns Std              0.215002
evaluation/Returns Max             -4.31099
evaluation/Returns Min             -4.90103
evaluation/Actions Mean             0.00402637
evaluation/Actions Std              0.0763752
evaluation/Actions Max              0.999859
evaluation/Actions Min             -0.931906
evaluation/Num Paths                5
evaluation/Average Returns         -4.49867
time/data storing (s)               0.0012435
time/evaluation sampling (s)        0.0848353
time/exploration sampling (s)       0.0351574
time/logging (s)                    0.00327314
time/saving (s)                     0.00308541
time/training (s)                   0.466362
time/epoch (s)                      0.593956
time/total (s)                    130.759
Epoch                             223
-----------------------------  ----------------
2019-04-13 17:00:45.450209 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 224 finished
-----------------------------  ----------------
replay_buffer/size              45100
trainer/QF1 Loss                    0.0590121
trainer/QF2 Loss                    0.0592656
trainer/Policy Loss                11.3484
trainer/Q1 Predictions Mean       -11.421
trainer/Q1 Predictions Std          0.0797843
trainer/Q1 Predictions Max        -11.2891
trainer/Q1 Predictions Min        -11.6347
trainer/Q2 Predictions Mean       -11.4256
trainer/Q2 Predictions Std          0.0763608
trainer/Q2 Predictions Max        -11.2964
trainer/Q2 Predictions Min        -11.606
trainer/Q Targets Mean            -11.6062
trainer/Q Targets Std               0.192527
trainer/Q Targets Max             -11.3072
trainer/Q Targets Min             -12.2474
trainer/Bellman Errors 1 Mean       0.0590121
trainer/Bellman Errors 1 Std        0.0825868
trainer/Bellman Errors 1 Max        0.375332
trainer/Bellman Errors 1 Min        1.08852e-06
trainer/Bellman Errors 2 Mean       0.0592656
trainer/Bellman Errors 2 Std        0.0855652
trainer/Bellman Errors 2 Max        0.411365
trainer/Bellman Errors 2 Min        5.25324e-07
trainer/Policy Action Mean         -0.00200757
trainer/Policy Action Std           0.18326
trainer/Policy Action Max           0.955685
trainer/Policy Action Min          -0.777632
exploration/num steps total     45100
exploration/num paths total       451
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131274
exploration/Rewards Std             0.0734882
exploration/Rewards Max            -0.0115891
exploration/Rewards Min            -0.59215
exploration/Returns Mean          -13.1274
exploration/Returns Std             0.0226308
exploration/Returns Max           -13.1048
exploration/Returns Min           -13.15
exploration/Actions Mean            0.00543927
exploration/Actions Std             0.156904
exploration/Actions Max             1
exploration/Actions Min            -0.757849
exploration/Num Paths               2
exploration/Average Returns       -13.1274
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0272219
evaluation/Rewards Std              0.0586153
evaluation/Rewards Max             -0.0216021
evaluation/Rewards Min             -0.962483
evaluation/Returns Mean            -2.72219
evaluation/Returns Std              0.350564
evaluation/Returns Max             -2.2321
evaluation/Returns Min             -3.19424
evaluation/Actions Mean             0.00670457
evaluation/Actions Std              0.0814588
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.740996
evaluation/Num Paths                5
evaluation/Average Returns         -2.72219
time/data storing (s)               0.00111489
time/evaluation sampling (s)        0.0855187
time/exploration sampling (s)       0.0346765
time/logging (s)                    0.00247769
time/saving (s)                     0.00231456
time/training (s)                   0.473882
time/epoch (s)                      0.599985
time/total (s)                    131.364
Epoch                             224
-----------------------------  ----------------
2019-04-13 17:00:46.031797 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 225 finished
-----------------------------  ----------------
replay_buffer/size              45300
trainer/QF1 Loss                    0.0241657
trainer/QF2 Loss                    0.0252863
trainer/Policy Loss                11.5161
trainer/Q1 Predictions Mean       -11.6437
trainer/Q1 Predictions Std          0.100287
trainer/Q1 Predictions Max        -11.5368
trainer/Q1 Predictions Min        -11.9467
trainer/Q2 Predictions Mean       -11.6446
trainer/Q2 Predictions Std          0.0956747
trainer/Q2 Predictions Max        -11.5423
trainer/Q2 Predictions Min        -11.9319
trainer/Q Targets Mean            -11.6198
trainer/Q Targets Std               0.169417
trainer/Q Targets Max             -11.3098
trainer/Q Targets Min             -11.9789
trainer/Bellman Errors 1 Mean       0.0241657
trainer/Bellman Errors 1 Std        0.0267334
trainer/Bellman Errors 1 Max        0.0996656
trainer/Bellman Errors 1 Min        4.54867e-05
trainer/Bellman Errors 2 Mean       0.0252863
trainer/Bellman Errors 2 Std        0.0289273
trainer/Bellman Errors 2 Max        0.112829
trainer/Bellman Errors 2 Min        2.33324e-05
trainer/Policy Action Mean          0.0153826
trainer/Policy Action Std           0.136938
trainer/Policy Action Max           0.715317
trainer/Policy Action Min          -0.220534
exploration/num steps total     45300
exploration/num paths total       453
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143574
exploration/Rewards Std             0.0733492
exploration/Rewards Max            -0.0136878
exploration/Rewards Min            -0.455589
exploration/Returns Mean          -14.3574
exploration/Returns Std             0.0057622
exploration/Returns Max           -14.3516
exploration/Returns Min           -14.3632
exploration/Actions Mean            0.00686732
exploration/Actions Std             0.16858
exploration/Actions Max             0.952036
exploration/Actions Min            -0.868964
exploration/Num Paths               2
exploration/Average Returns       -14.3574
evaluation/num steps total     113000
evaluation/num paths total       1130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0536119
evaluation/Rewards Std              0.0362096
evaluation/Rewards Max             -0.0499851
evaluation/Rewards Min             -0.594243
evaluation/Returns Mean            -5.36119
evaluation/Returns Std              0.190138
evaluation/Returns Max             -5.15736
evaluation/Returns Min             -5.61343
evaluation/Actions Mean             0.00574488
evaluation/Actions Std              0.0844365
evaluation/Actions Max              0.999845
evaluation/Actions Min             -0.958104
evaluation/Num Paths                5
evaluation/Average Returns         -5.36119
time/data storing (s)               0.00112706
time/evaluation sampling (s)        0.0737555
time/exploration sampling (s)       0.0344319
time/logging (s)                    0.00257998
time/saving (s)                     0.00221379
time/training (s)                   0.459798
time/epoch (s)                      0.573906
time/total (s)                    131.942
Epoch                             225
-----------------------------  ----------------
2019-04-13 17:00:46.615972 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 226 finished
-----------------------------  ----------------
replay_buffer/size              45500
trainer/QF1 Loss                    4.07813
trainer/QF2 Loss                    4.07686
trainer/Policy Loss                11.3844
trainer/Q1 Predictions Mean       -11.4975
trainer/Q1 Predictions Std          0.145178
trainer/Q1 Predictions Max        -11.3588
trainer/Q1 Predictions Min        -12.22
trainer/Q2 Predictions Mean       -11.4976
trainer/Q2 Predictions Std          0.132509
trainer/Q2 Predictions Max        -11.3652
trainer/Q2 Predictions Min        -12.1535
trainer/Q Targets Mean            -11.3427
trainer/Q Targets Std               2.01076
trainer/Q Targets Max              -0.214872
trainer/Q Targets Min             -12.4318
trainer/Bellman Errors 1 Mean       4.07813
trainer/Bellman Errors 1 Std       22.2947
trainer/Bellman Errors 1 Max      128.209
trainer/Bellman Errors 1 Min        1.49327e-05
trainer/Bellman Errors 2 Mean       4.07686
trainer/Bellman Errors 2 Std       22.2978
trainer/Bellman Errors 2 Max      128.225
trainer/Bellman Errors 2 Min        0.000103332
trainer/Policy Action Mean         -0.000909359
trainer/Policy Action Std           0.10569
trainer/Policy Action Max           0.208139
trainer/Policy Action Min          -0.38065
exploration/num steps total     45500
exploration/num paths total       455
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130869
exploration/Rewards Std             0.0881212
exploration/Rewards Max            -0.012956
exploration/Rewards Min            -0.801567
exploration/Returns Mean          -13.0869
exploration/Returns Std             0.503155
exploration/Returns Max           -12.5838
exploration/Returns Min           -13.5901
exploration/Actions Mean            0.0124468
exploration/Actions Std             0.16098
exploration/Actions Max             0.953558
exploration/Actions Min            -0.441772
exploration/Num Paths               2
exploration/Average Returns       -13.0869
evaluation/num steps total     113500
evaluation/num paths total       1135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.034577
evaluation/Rewards Std              0.0206681
evaluation/Rewards Max             -0.0197465
evaluation/Rewards Min             -0.378941
evaluation/Returns Mean            -3.4577
evaluation/Returns Std              0.150483
evaluation/Returns Max             -3.28284
evaluation/Returns Min             -3.68653
evaluation/Actions Mean             0.00396497
evaluation/Actions Std              0.0672811
evaluation/Actions Max              0.991051
evaluation/Actions Min             -0.892127
evaluation/Num Paths                5
evaluation/Average Returns         -3.4577
time/data storing (s)               0.00111825
time/evaluation sampling (s)        0.0760473
time/exploration sampling (s)       0.0340556
time/logging (s)                    0.0024649
time/saving (s)                     0.00224936
time/training (s)                   0.460465
time/epoch (s)                      0.576401
time/total (s)                    132.522
Epoch                             226
-----------------------------  ----------------
2019-04-13 17:00:47.201947 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 227 finished
-----------------------------  ----------------
replay_buffer/size              45700
trainer/QF1 Loss                    0.01543
trainer/QF2 Loss                    0.0164092
trainer/Policy Loss                11.5586
trainer/Q1 Predictions Mean       -11.713
trainer/Q1 Predictions Std          0.210321
trainer/Q1 Predictions Max        -11.5448
trainer/Q1 Predictions Min        -12.6991
trainer/Q2 Predictions Mean       -11.7061
trainer/Q2 Predictions Std          0.207028
trainer/Q2 Predictions Max        -11.5439
trainer/Q2 Predictions Min        -12.6539
trainer/Q Targets Mean            -11.7117
trainer/Q Targets Std               0.234516
trainer/Q Targets Max             -11.4321
trainer/Q Targets Min             -12.7375
trainer/Bellman Errors 1 Mean       0.01543
trainer/Bellman Errors 1 Std        0.036352
trainer/Bellman Errors 1 Max        0.211911
trainer/Bellman Errors 1 Min        5.88936e-05
trainer/Bellman Errors 2 Mean       0.0164092
trainer/Bellman Errors 2 Std        0.0374954
trainer/Bellman Errors 2 Max        0.218997
trainer/Bellman Errors 2 Min        1.79133e-05
trainer/Policy Action Mean          0.0210984
trainer/Policy Action Std           0.14147
trainer/Policy Action Max           0.552584
trainer/Policy Action Min          -0.365928
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.146551
exploration/Rewards Std             0.0916827
exploration/Rewards Max            -0.00775232
exploration/Rewards Min            -0.940435
exploration/Returns Mean          -14.6551
exploration/Returns Std             0.850427
exploration/Returns Max           -13.8047
exploration/Returns Min           -15.5056
exploration/Actions Mean            0.00242853
exploration/Actions Std             0.156803
exploration/Actions Max             1
exploration/Actions Min            -0.894426
exploration/Num Paths               2
exploration/Average Returns       -14.6551
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.038306
evaluation/Rewards Std              0.0388505
evaluation/Rewards Max             -0.0137406
evaluation/Rewards Min             -0.857081
evaluation/Returns Mean            -3.8306
evaluation/Returns Std              0.365095
evaluation/Returns Max             -3.54904
evaluation/Returns Min             -4.55316
evaluation/Actions Mean             0.00447543
evaluation/Actions Std              0.0644727
evaluation/Actions Max              0.999889
evaluation/Actions Min             -0.755878
evaluation/Num Paths                5
evaluation/Average Returns         -3.8306
time/data storing (s)               0.00113166
time/evaluation sampling (s)        0.0754695
time/exploration sampling (s)       0.0336883
time/logging (s)                    0.00240697
time/saving (s)                     0.00201321
time/training (s)                   0.463652
time/epoch (s)                      0.578362
time/total (s)                    133.105
Epoch                             227
-----------------------------  ----------------
2019-04-13 17:00:47.871986 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 228 finished
-----------------------------  ----------------
replay_buffer/size              45900
trainer/QF1 Loss                    8.15472
trainer/QF2 Loss                    8.17452
trainer/Policy Loss                11.3871
trainer/Q1 Predictions Mean       -11.6693
trainer/Q1 Predictions Std          0.491594
trainer/Q1 Predictions Max        -11.3798
trainer/Q1 Predictions Min        -13.8677
trainer/Q2 Predictions Mean       -11.6615
trainer/Q2 Predictions Std          0.46877
trainer/Q2 Predictions Max        -11.3588
trainer/Q2 Predictions Min        -13.758
trainer/Q Targets Mean            -11.1885
trainer/Q Targets Std               2.93492
trainer/Q Targets Max              -0.0611288
trainer/Q Targets Min             -14.6325
trainer/Bellman Errors 1 Mean       8.15472
trainer/Bellman Errors 1 Std       31.1847
trainer/Bellman Errors 1 Max      129.116
trainer/Bellman Errors 1 Min        2.12175e-05
trainer/Bellman Errors 2 Mean       8.17452
trainer/Bellman Errors 2 Std       31.2294
trainer/Bellman Errors 2 Max      129.366
trainer/Bellman Errors 2 Min        0.000268065
trainer/Policy Action Mean          0.0218975
trainer/Policy Action Std           0.26494
trainer/Policy Action Max           0.999981
trainer/Policy Action Min          -0.668219
exploration/num steps total     45900
exploration/num paths total       459
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137115
exploration/Rewards Std             0.087023
exploration/Rewards Max            -0.015931
exploration/Rewards Min            -1.03536
exploration/Returns Mean          -13.7115
exploration/Returns Std             0.529828
exploration/Returns Max           -13.1816
exploration/Returns Min           -14.2413
exploration/Actions Mean            0.0107697
exploration/Actions Std             0.159729
exploration/Actions Max             0.949054
exploration/Actions Min            -0.363848
exploration/Num Paths               2
exploration/Average Returns       -13.7115
evaluation/num steps total     114500
evaluation/num paths total       1145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.00642101
evaluation/Rewards Std              0.0499569
evaluation/Rewards Max             -0.000732122
evaluation/Rewards Min             -0.698031
evaluation/Returns Mean            -0.642101
evaluation/Returns Std              0.260764
evaluation/Returns Max             -0.172579
evaluation/Returns Min             -0.939125
evaluation/Actions Mean             0.00613974
evaluation/Actions Std              0.0910524
evaluation/Actions Max              0.999581
evaluation/Actions Min             -0.833505
evaluation/Num Paths                5
evaluation/Average Returns         -0.642101
time/data storing (s)               0.00130046
time/evaluation sampling (s)        0.0823404
time/exploration sampling (s)       0.0379279
time/logging (s)                    0.00252254
time/saving (s)                     0.00230338
time/training (s)                   0.53596
time/epoch (s)                      0.662355
time/total (s)                    133.771
Epoch                             228
-----------------------------  ----------------
2019-04-13 17:00:48.543367 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 229 finished
-----------------------------  ----------------
replay_buffer/size              46100
trainer/QF1 Loss                    0.091866
trainer/QF2 Loss                    0.0898167
trainer/Policy Loss                11.3994
trainer/Q1 Predictions Mean       -11.5102
trainer/Q1 Predictions Std          0.398172
trainer/Q1 Predictions Max        -11.2374
trainer/Q1 Predictions Min        -13.4
trainer/Q2 Predictions Mean       -11.51
trainer/Q2 Predictions Std          0.403894
trainer/Q2 Predictions Max        -11.2412
trainer/Q2 Predictions Min        -13.5087
trainer/Q Targets Mean            -11.7595
trainer/Q Targets Std               0.394791
trainer/Q Targets Max             -11.3892
trainer/Q Targets Min             -13.5697
trainer/Bellman Errors 1 Mean       0.091866
trainer/Bellman Errors 1 Std        0.110268
trainer/Bellman Errors 1 Max        0.414806
trainer/Bellman Errors 1 Min        4.21045e-05
trainer/Bellman Errors 2 Mean       0.0898167
trainer/Bellman Errors 2 Std        0.104792
trainer/Bellman Errors 2 Max        0.37177
trainer/Bellman Errors 2 Min        0.000266443
trainer/Policy Action Mean          0.020421
trainer/Policy Action Std           0.196424
trainer/Policy Action Max           0.948701
trainer/Policy Action Min          -0.329432
exploration/num steps total     46100
exploration/num paths total       461
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.121945
exploration/Rewards Std             0.0656866
exploration/Rewards Max            -0.0139842
exploration/Rewards Min            -0.317449
exploration/Returns Mean          -12.1945
exploration/Returns Std             0.392573
exploration/Returns Max           -11.8019
exploration/Returns Min           -12.5871
exploration/Actions Mean            0.00466128
exploration/Actions Std             0.146832
exploration/Actions Max             1
exploration/Actions Min            -0.399363
exploration/Num Paths               2
exploration/Average Returns       -12.1945
evaluation/num steps total     115000
evaluation/num paths total       1150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0191422
evaluation/Rewards Std              0.0086867
evaluation/Rewards Max             -0.0152449
evaluation/Rewards Min             -0.162296
evaluation/Returns Mean            -1.91422
evaluation/Returns Std              0.0602752
evaluation/Returns Max             -1.84349
evaluation/Returns Min             -2.00706
evaluation/Actions Mean             0.00070491
evaluation/Actions Std              0.0643609
evaluation/Actions Max              0.993519
evaluation/Actions Min             -0.951392
evaluation/Num Paths                5
evaluation/Average Returns         -1.91422
time/data storing (s)               0.00115498
time/evaluation sampling (s)        0.0890097
time/exploration sampling (s)       0.0355937
time/logging (s)                    0.00256879
time/saving (s)                     0.00298715
time/training (s)                   0.532239
time/epoch (s)                      0.663553
time/total (s)                    134.439
Epoch                             229
-----------------------------  ----------------
2019-04-13 17:00:49.128317 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 230 finished
-----------------------------  ----------------
replay_buffer/size              46300
trainer/QF1 Loss                    0.0200826
trainer/QF2 Loss                    0.018356
trainer/Policy Loss                11.6897
trainer/Q1 Predictions Mean       -11.8577
trainer/Q1 Predictions Std          0.632616
trainer/Q1 Predictions Max        -11.5693
trainer/Q1 Predictions Min        -14.3683
trainer/Q2 Predictions Mean       -11.8672
trainer/Q2 Predictions Std          0.671339
trainer/Q2 Predictions Max        -11.5625
trainer/Q2 Predictions Min        -14.509
trainer/Q Targets Mean            -11.8995
trainer/Q Targets Std               0.684001
trainer/Q Targets Max             -11.5041
trainer/Q Targets Min             -14.5742
trainer/Bellman Errors 1 Mean       0.0200826
trainer/Bellman Errors 1 Std        0.0338864
trainer/Bellman Errors 1 Max        0.190821
trainer/Bellman Errors 1 Min        3.7218e-05
trainer/Bellman Errors 2 Mean       0.018356
trainer/Bellman Errors 2 Std        0.0320405
trainer/Bellman Errors 2 Max        0.17968
trainer/Bellman Errors 2 Min        5.03438e-07
trainer/Policy Action Mean          0.0215825
trainer/Policy Action Std           0.232613
trainer/Policy Action Max           0.999969
trainer/Policy Action Min          -0.863433
exploration/num steps total     46300
exploration/num paths total       463
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137459
exploration/Rewards Std             0.0681086
exploration/Rewards Max            -0.0163812
exploration/Rewards Min            -0.417184
exploration/Returns Mean          -13.7459
exploration/Returns Std             0.187585
exploration/Returns Max           -13.5583
exploration/Returns Min           -13.9334
exploration/Actions Mean            0.00596447
exploration/Actions Std             0.143811
exploration/Actions Max             1
exploration/Actions Min            -0.41956
exploration/Num Paths               2
exploration/Average Returns       -13.7459
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0611665
evaluation/Rewards Std              0.0493202
evaluation/Rewards Max             -0.0404107
evaluation/Rewards Min             -0.985782
evaluation/Returns Mean            -6.11665
evaluation/Returns Std              0.481418
evaluation/Returns Max             -5.71464
evaluation/Returns Min             -6.92052
evaluation/Actions Mean             0.00218534
evaluation/Actions Std              0.0809488
evaluation/Actions Max              0.999972
evaluation/Actions Min             -0.834241
evaluation/Num Paths                5
evaluation/Average Returns         -6.11665
time/data storing (s)               0.00137527
time/evaluation sampling (s)        0.080367
time/exploration sampling (s)       0.0334935
time/logging (s)                    0.00247862
time/saving (s)                     0.00198597
time/training (s)                   0.457456
time/epoch (s)                      0.577156
time/total (s)                    135.02
Epoch                             230
-----------------------------  ----------------
2019-04-13 17:00:49.699316 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 231 finished
-----------------------------  ----------------
replay_buffer/size              46500
trainer/QF1 Loss                    0.0295918
trainer/QF2 Loss                    0.0298137
trainer/Policy Loss                11.7132
trainer/Q1 Predictions Mean       -11.8854
trainer/Q1 Predictions Std          0.434122
trainer/Q1 Predictions Max        -11.6855
trainer/Q1 Predictions Min        -14.2657
trainer/Q2 Predictions Mean       -11.8855
trainer/Q2 Predictions Std          0.433548
trainer/Q2 Predictions Max        -11.6854
trainer/Q2 Predictions Min        -14.2629
trainer/Q Targets Mean            -11.8297
trainer/Q Targets Std               0.435603
trainer/Q Targets Max             -11.3927
trainer/Q Targets Min             -14.0582
trainer/Bellman Errors 1 Mean       0.0295918
trainer/Bellman Errors 1 Std        0.026732
trainer/Bellman Errors 1 Max        0.112242
trainer/Bellman Errors 1 Min        0.00029089
trainer/Bellman Errors 2 Mean       0.0298137
trainer/Bellman Errors 2 Std        0.0272129
trainer/Bellman Errors 2 Max        0.118203
trainer/Bellman Errors 2 Min        0.000125653
trainer/Policy Action Mean          0.0240137
trainer/Policy Action Std           0.15939
trainer/Policy Action Max           0.99179
trainer/Policy Action Min          -0.225463
exploration/num steps total     46500
exploration/num paths total       465
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.13057
exploration/Rewards Std             0.0770754
exploration/Rewards Max            -0.0110867
exploration/Rewards Min            -0.520804
exploration/Returns Mean          -13.057
exploration/Returns Std             0.426253
exploration/Returns Max           -12.6308
exploration/Returns Min           -13.4833
exploration/Actions Mean            0.00929824
exploration/Actions Std             0.150936
exploration/Actions Max             1
exploration/Actions Min            -0.373495
exploration/Num Paths               2
exploration/Average Returns       -13.057
evaluation/num steps total     116000
evaluation/num paths total       1160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0497486
evaluation/Rewards Std              0.027048
evaluation/Rewards Max             -0.00943119
evaluation/Rewards Min             -0.613792
evaluation/Returns Mean            -4.97486
evaluation/Returns Std              0.24156
evaluation/Returns Max             -4.77625
evaluation/Returns Min             -5.44697
evaluation/Actions Mean             0.00412598
evaluation/Actions Std              0.0748831
evaluation/Actions Max              0.999209
evaluation/Actions Min             -0.783862
evaluation/Num Paths                5
evaluation/Average Returns         -4.97486
time/data storing (s)               0.00113985
time/evaluation sampling (s)        0.0737444
time/exploration sampling (s)       0.0350965
time/logging (s)                    0.00248906
time/saving (s)                     0.00224853
time/training (s)                   0.448832
time/epoch (s)                      0.56355
time/total (s)                    135.588
Epoch                             231
-----------------------------  ----------------
2019-04-13 17:00:50.280500 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 232 finished
-----------------------------  ----------------
replay_buffer/size              46700
trainer/QF1 Loss                    0.0962166
trainer/QF2 Loss                    0.0936284
trainer/Policy Loss                11.4321
trainer/Q1 Predictions Mean       -11.6217
trainer/Q1 Predictions Std          0.313458
trainer/Q1 Predictions Max        -11.3806
trainer/Q1 Predictions Min        -13.0593
trainer/Q2 Predictions Mean       -11.6196
trainer/Q2 Predictions Std          0.325521
trainer/Q2 Predictions Max        -11.411
trainer/Q2 Predictions Min        -13.1678
trainer/Q Targets Mean            -11.8806
trainer/Q Targets Std               0.340804
trainer/Q Targets Max             -11.5182
trainer/Q Targets Min             -13.2147
trainer/Bellman Errors 1 Mean       0.0962166
trainer/Bellman Errors 1 Std        0.110332
trainer/Bellman Errors 1 Max        0.456314
trainer/Bellman Errors 1 Min        0.000430327
trainer/Bellman Errors 2 Mean       0.0936284
trainer/Bellman Errors 2 Std        0.102776
trainer/Bellman Errors 2 Max        0.424069
trainer/Bellman Errors 2 Min        0.00106876
trainer/Policy Action Mean          0.0312229
trainer/Policy Action Std           0.171029
trainer/Policy Action Max           0.575795
trainer/Policy Action Min          -0.353691
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.13132
exploration/Rewards Std             0.0710804
exploration/Rewards Max            -0.00487023
exploration/Rewards Min            -0.324775
exploration/Returns Mean          -13.132
exploration/Returns Std             0.290959
exploration/Returns Max           -12.8411
exploration/Returns Min           -13.423
exploration/Actions Mean            0.00212233
exploration/Actions Std             0.135091
exploration/Actions Max             0.576816
exploration/Actions Min            -0.790207
exploration/Num Paths               2
exploration/Average Returns       -13.132
evaluation/num steps total     116500
evaluation/num paths total       1165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0378689
evaluation/Rewards Std              0.00749103
evaluation/Rewards Max             -0.0268001
evaluation/Rewards Min             -0.151861
evaluation/Returns Mean            -3.78689
evaluation/Returns Std              0.0476773
evaluation/Returns Max             -3.70394
evaluation/Returns Min             -3.83975
evaluation/Actions Mean             0.00123965
evaluation/Actions Std              0.0483666
evaluation/Actions Max              0.76697
evaluation/Actions Min             -0.878984
evaluation/Num Paths                5
evaluation/Average Returns         -3.78689
time/data storing (s)               0.00104532
time/evaluation sampling (s)        0.0734924
time/exploration sampling (s)       0.0322999
time/logging (s)                    0.00257608
time/saving (s)                     0.00240665
time/training (s)                   0.46201
time/epoch (s)                      0.57383
time/total (s)                    136.165
Epoch                             232
-----------------------------  ----------------
2019-04-13 17:00:50.858768 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 233 finished
-----------------------------  ----------------
replay_buffer/size              46900
trainer/QF1 Loss                    0.109467
trainer/QF2 Loss                    0.104344
trainer/Policy Loss                11.4871
trainer/Q1 Predictions Mean       -11.6087
trainer/Q1 Predictions Std          0.493359
trainer/Q1 Predictions Max        -11.384
trainer/Q1 Predictions Min        -14.2177
trainer/Q2 Predictions Mean       -11.6169
trainer/Q2 Predictions Std          0.500224
trainer/Q2 Predictions Max        -11.4054
trainer/Q2 Predictions Min        -14.2787
trainer/Q Targets Mean            -11.8642
trainer/Q Targets Std               0.503369
trainer/Q Targets Max             -11.4725
trainer/Q Targets Min             -14.2146
trainer/Bellman Errors 1 Mean       0.109467
trainer/Bellman Errors 1 Std        0.18499
trainer/Bellman Errors 1 Max        0.984752
trainer/Bellman Errors 1 Min        9.72514e-06
trainer/Bellman Errors 2 Mean       0.104344
trainer/Bellman Errors 2 Std        0.173317
trainer/Bellman Errors 2 Max        0.916951
trainer/Bellman Errors 2 Min        0.000272927
trainer/Policy Action Mean          0.0367573
trainer/Policy Action Std           0.15817
trainer/Policy Action Max           0.996477
trainer/Policy Action Min          -0.312509
exploration/num steps total     46900
exploration/num paths total       469
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.144576
exploration/Rewards Std             0.0773253
exploration/Rewards Max            -0.0181443
exploration/Rewards Min            -0.423622
exploration/Returns Mean          -14.4576
exploration/Returns Std             1.16321
exploration/Returns Max           -13.2944
exploration/Returns Min           -15.6208
exploration/Actions Mean            0.000176246
exploration/Actions Std             0.137406
exploration/Actions Max             0.636022
exploration/Actions Min            -0.486715
exploration/Num Paths               2
exploration/Average Returns       -14.4576
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0687963
evaluation/Rewards Std              0.0507369
evaluation/Rewards Max             -0.0637348
evaluation/Rewards Min             -0.77416
evaluation/Returns Mean            -6.87963
evaluation/Returns Std              0.245256
evaluation/Returns Max             -6.45505
evaluation/Returns Min             -7.13494
evaluation/Actions Mean             0.00822248
evaluation/Actions Std              0.0856255
evaluation/Actions Max              0.999889
evaluation/Actions Min             -0.26802
evaluation/Num Paths                5
evaluation/Average Returns         -6.87963
time/data storing (s)               0.00107529
time/evaluation sampling (s)        0.0734927
time/exploration sampling (s)       0.0351444
time/logging (s)                    0.0024556
time/saving (s)                     0.00222571
time/training (s)                   0.456221
time/epoch (s)                      0.570615
time/total (s)                    136.74
Epoch                             233
-----------------------------  ----------------
2019-04-13 17:00:51.452378 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 234 finished
-----------------------------  ----------------
replay_buffer/size              47100
trainer/QF1 Loss                    8.346
trainer/QF2 Loss                    8.31145
trainer/Policy Loss                11.5687
trainer/Q1 Predictions Mean       -11.7595
trainer/Q1 Predictions Std          0.537981
trainer/Q1 Predictions Max        -11.5445
trainer/Q1 Predictions Min        -14.6864
trainer/Q2 Predictions Mean       -11.7574
trainer/Q2 Predictions Std          0.535617
trainer/Q2 Predictions Max        -11.5442
trainer/Q2 Predictions Min        -14.6832
trainer/Q Targets Mean            -11.1459
trainer/Q Targets Std               2.89625
trainer/Q Targets Max              -0.0909154
trainer/Q Targets Min             -14.8667
trainer/Bellman Errors 1 Mean       8.346
trainer/Bellman Errors 1 Std       32.2137
trainer/Bellman Errors 1 Max      133.405
trainer/Bellman Errors 1 Min        1.88951e-05
trainer/Bellman Errors 2 Mean       8.31145
trainer/Bellman Errors 2 Std       32.0825
trainer/Bellman Errors 2 Max      133.989
trainer/Bellman Errors 2 Min        6.25267e-06
trainer/Policy Action Mean          0.00563384
trainer/Policy Action Std           0.23043
trainer/Policy Action Max           0.997674
trainer/Policy Action Min          -0.800862
exploration/num steps total     47100
exploration/num paths total       471
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133056
exploration/Rewards Std             0.085335
exploration/Rewards Max            -0.0114104
exploration/Rewards Min            -0.698417
exploration/Returns Mean          -13.3056
exploration/Returns Std             1.32742
exploration/Returns Max           -11.9782
exploration/Returns Min           -14.6331
exploration/Actions Mean            0.00448742
exploration/Actions Std             0.166656
exploration/Actions Max             1
exploration/Actions Min            -0.999907
exploration/Num Paths               2
exploration/Average Returns       -13.3056
evaluation/num steps total     117500
evaluation/num paths total       1175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0405245
evaluation/Rewards Std              0.0286178
evaluation/Rewards Max             -0.0224936
evaluation/Rewards Min             -0.672782
evaluation/Returns Mean            -4.05245
evaluation/Returns Std              0.234173
evaluation/Returns Max             -3.90233
evaluation/Returns Min             -4.51729
evaluation/Actions Mean             0.00250315
evaluation/Actions Std              0.0557603
evaluation/Actions Max              0.999621
evaluation/Actions Min             -0.583166
evaluation/Num Paths                5
evaluation/Average Returns         -4.05245
time/data storing (s)               0.00113298
time/evaluation sampling (s)        0.0834393
time/exploration sampling (s)       0.0348501
time/logging (s)                    0.00256558
time/saving (s)                     0.00212385
time/training (s)                   0.462414
time/epoch (s)                      0.586526
time/total (s)                    137.33
Epoch                             234
-----------------------------  ----------------
2019-04-13 17:00:52.037201 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 235 finished
-----------------------------  ----------------
replay_buffer/size              47300
trainer/QF1 Loss                    0.0377531
trainer/QF2 Loss                    0.0399345
trainer/Policy Loss                11.6628
trainer/Q1 Predictions Mean       -11.7816
trainer/Q1 Predictions Std          0.398202
trainer/Q1 Predictions Max        -11.5996
trainer/Q1 Predictions Min        -13.8572
trainer/Q2 Predictions Mean       -11.7825
trainer/Q2 Predictions Std          0.388758
trainer/Q2 Predictions Max        -11.5878
trainer/Q2 Predictions Min        -13.793
trainer/Q Targets Mean            -11.87
trainer/Q Targets Std               0.517388
trainer/Q Targets Max             -11.5103
trainer/Q Targets Min             -14.5589
trainer/Bellman Errors 1 Mean       0.0377531
trainer/Bellman Errors 1 Std        0.0876544
trainer/Bellman Errors 1 Max        0.492387
trainer/Bellman Errors 1 Min        9.64883e-09
trainer/Bellman Errors 2 Mean       0.0399345
trainer/Bellman Errors 2 Std        0.10307
trainer/Bellman Errors 2 Max        0.586732
trainer/Bellman Errors 2 Min        1.68166e-07
trainer/Policy Action Mean          0.0245015
trainer/Policy Action Std           0.161989
trainer/Policy Action Max           0.996114
trainer/Policy Action Min          -0.386482
exploration/num steps total     47300
exploration/num paths total       473
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138937
exploration/Rewards Std             0.0739068
exploration/Rewards Max            -0.00927773
exploration/Rewards Min            -0.375912
exploration/Returns Mean          -13.8937
exploration/Returns Std             0.78559
exploration/Returns Max           -13.1081
exploration/Returns Min           -14.6793
exploration/Actions Mean            0.00743885
exploration/Actions Std             0.142669
exploration/Actions Max             0.895461
exploration/Actions Min            -0.387823
exploration/Num Paths               2
exploration/Average Returns       -13.8937
evaluation/num steps total     118000
evaluation/num paths total       1180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0687439
evaluation/Rewards Std              0.0377841
evaluation/Rewards Max             -0.0342898
evaluation/Rewards Min             -0.891923
evaluation/Returns Mean            -6.87439
evaluation/Returns Std              0.300419
evaluation/Returns Max             -6.66172
evaluation/Returns Min             -7.46947
evaluation/Actions Mean             0.00347512
evaluation/Actions Std              0.0782344
evaluation/Actions Max              0.999951
evaluation/Actions Min             -0.974041
evaluation/Num Paths                5
evaluation/Average Returns         -6.87439
time/data storing (s)               0.0011804
time/evaluation sampling (s)        0.0753462
time/exploration sampling (s)       0.0314268
time/logging (s)                    0.00247272
time/saving (s)                     0.00260726
time/training (s)                   0.465141
time/epoch (s)                      0.578175
time/total (s)                    137.911
Epoch                             235
-----------------------------  ----------------
2019-04-13 17:00:52.616933 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 236 finished
-----------------------------  ----------------
replay_buffer/size              47500
trainer/QF1 Loss                    0.0505558
trainer/QF2 Loss                    0.049339
trainer/Policy Loss                11.4537
trainer/Q1 Predictions Mean       -11.5816
trainer/Q1 Predictions Std          0.0727395
trainer/Q1 Predictions Max        -11.4688
trainer/Q1 Predictions Min        -11.7438
trainer/Q2 Predictions Mean       -11.5829
trainer/Q2 Predictions Std          0.083275
trainer/Q2 Predictions Max        -11.4714
trainer/Q2 Predictions Min        -11.7662
trainer/Q Targets Mean            -11.7755
trainer/Q Targets Std               0.128075
trainer/Q Targets Max             -11.4815
trainer/Q Targets Min             -12.03
trainer/Bellman Errors 1 Mean       0.0505558
trainer/Bellman Errors 1 Std        0.0440364
trainer/Bellman Errors 1 Max        0.139959
trainer/Bellman Errors 1 Min        1.61365e-06
trainer/Bellman Errors 2 Mean       0.049339
trainer/Bellman Errors 2 Std        0.0441053
trainer/Bellman Errors 2 Max        0.136846
trainer/Bellman Errors 2 Min        0.00010075
trainer/Policy Action Mean          0.0559103
trainer/Policy Action Std           0.102473
trainer/Policy Action Max           0.255543
trainer/Policy Action Min          -0.235441
exploration/num steps total     47500
exploration/num paths total       475
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.159554
exploration/Rewards Std             0.0989704
exploration/Rewards Max            -0.00588166
exploration/Rewards Min            -1.02681
exploration/Returns Mean          -15.9554
exploration/Returns Std             0.68826
exploration/Returns Max           -15.2671
exploration/Returns Min           -16.6436
exploration/Actions Mean            0.00826475
exploration/Actions Std             0.170894
exploration/Actions Max             0.994454
exploration/Actions Min            -0.630908
exploration/Num Paths               2
exploration/Average Returns       -15.9554
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0975136
evaluation/Rewards Std              0.0162073
evaluation/Rewards Max             -0.0642896
evaluation/Rewards Min             -0.430305
evaluation/Returns Mean            -9.75136
evaluation/Returns Std              0.125546
evaluation/Returns Max             -9.66235
evaluation/Returns Min             -9.9929
evaluation/Actions Mean             0.00294986
evaluation/Actions Std              0.0661379
evaluation/Actions Max              0.99424
evaluation/Actions Min             -0.928113
evaluation/Num Paths                5
evaluation/Average Returns         -9.75136
time/data storing (s)               0.00105356
time/evaluation sampling (s)        0.0754435
time/exploration sampling (s)       0.0341544
time/logging (s)                    0.00246033
time/saving (s)                     0.00223191
time/training (s)                   0.457055
time/epoch (s)                      0.572399
time/total (s)                    138.487
Epoch                             236
-----------------------------  ----------------
2019-04-13 17:00:53.197129 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 237 finished
-----------------------------  ---------------
replay_buffer/size              47700
trainer/QF1 Loss                    0.185744
trainer/QF2 Loss                    0.198834
trainer/Policy Loss                11.3749
trainer/Q1 Predictions Mean       -11.3849
trainer/Q1 Predictions Std          0.0809537
trainer/Q1 Predictions Max        -11.2566
trainer/Q1 Predictions Min        -11.5679
trainer/Q2 Predictions Mean       -11.3701
trainer/Q2 Predictions Std          0.0919232
trainer/Q2 Predictions Max        -11.241
trainer/Q2 Predictions Min        -11.577
trainer/Q Targets Mean            -11.782
trainer/Q Targets Std               0.170528
trainer/Q Targets Max             -11.5281
trainer/Q Targets Min             -12.0878
trainer/Bellman Errors 1 Mean       0.185744
trainer/Bellman Errors 1 Std        0.163371
trainer/Bellman Errors 1 Max        0.690944
trainer/Bellman Errors 1 Min        0.0272294
trainer/Bellman Errors 2 Mean       0.198834
trainer/Bellman Errors 2 Std        0.171407
trainer/Bellman Errors 2 Max        0.71718
trainer/Bellman Errors 2 Min        0.0175463
trainer/Policy Action Mean          0.00657622
trainer/Policy Action Std           0.111602
trainer/Policy Action Max           0.18482
trainer/Policy Action Min          -0.255569
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.155408
exploration/Rewards Std             0.0822118
exploration/Rewards Max            -0.0142889
exploration/Rewards Min            -0.493588
exploration/Returns Mean          -15.5408
exploration/Returns Std             0.601744
exploration/Returns Max           -14.939
exploration/Returns Min           -16.1425
exploration/Actions Mean            0.00672486
exploration/Actions Std             0.166953
exploration/Actions Max             1
exploration/Actions Min            -0.392476
exploration/Num Paths               2
exploration/Average Returns       -15.5408
evaluation/num steps total     119000
evaluation/num paths total       1190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0903951
evaluation/Rewards Std              0.0270649
evaluation/Rewards Max             -0.0478426
evaluation/Rewards Min             -0.462888
evaluation/Returns Mean            -9.03951
evaluation/Returns Std              0.173313
evaluation/Returns Max             -8.71843
evaluation/Returns Min             -9.2181
evaluation/Actions Mean             0.00694272
evaluation/Actions Std              0.0812629
evaluation/Actions Max              0.987721
evaluation/Actions Min             -0.544796
evaluation/Num Paths                5
evaluation/Average Returns         -9.03951
time/data storing (s)               0.00110028
time/evaluation sampling (s)        0.0761921
time/exploration sampling (s)       0.0336095
time/logging (s)                    0.00246535
time/saving (s)                     0.0022687
time/training (s)                   0.457103
time/epoch (s)                      0.572739
time/total (s)                    139.064
Epoch                             237
-----------------------------  ---------------
2019-04-13 17:00:53.781081 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 238 finished
-----------------------------  ----------------
replay_buffer/size              47900
trainer/QF1 Loss                    0.0269456
trainer/QF2 Loss                    0.0265503
trainer/Policy Loss                11.8362
trainer/Q1 Predictions Mean       -11.9191
trainer/Q1 Predictions Std          0.180411
trainer/Q1 Predictions Max        -11.8104
trainer/Q1 Predictions Min        -12.8606
trainer/Q2 Predictions Mean       -11.9146
trainer/Q2 Predictions Std          0.180736
trainer/Q2 Predictions Max        -11.8025
trainer/Q2 Predictions Min        -12.8499
trainer/Q Targets Mean            -11.836
trainer/Q Targets Std               0.249593
trainer/Q Targets Max             -11.4889
trainer/Q Targets Min             -12.8515
trainer/Bellman Errors 1 Mean       0.0269456
trainer/Bellman Errors 1 Std        0.0334048
trainer/Bellman Errors 1 Max        0.118237
trainer/Bellman Errors 1 Min        8.20992e-05
trainer/Bellman Errors 2 Mean       0.0265503
trainer/Bellman Errors 2 Std        0.0357778
trainer/Bellman Errors 2 Max        0.130375
trainer/Bellman Errors 2 Min        2.70004e-06
trainer/Policy Action Mean          0.0454605
trainer/Policy Action Std           0.131248
trainer/Policy Action Max           0.462034
trainer/Policy Action Min          -0.333608
exploration/num steps total     47900
exploration/num paths total       479
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126103
exploration/Rewards Std             0.0762274
exploration/Rewards Max            -0.00906355
exploration/Rewards Min            -0.625827
exploration/Returns Mean          -12.6103
exploration/Returns Std             0.106662
exploration/Returns Max           -12.5037
exploration/Returns Min           -12.717
exploration/Actions Mean            0.00770182
exploration/Actions Std             0.155406
exploration/Actions Max             1
exploration/Actions Min            -0.438734
exploration/Num Paths               2
exploration/Average Returns       -12.6103
evaluation/num steps total     119500
evaluation/num paths total       1195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0534382
evaluation/Rewards Std              0.0311876
evaluation/Rewards Max             -0.04206
evaluation/Rewards Min             -0.58534
evaluation/Returns Mean            -5.34382
evaluation/Returns Std              0.248589
evaluation/Returns Max             -5.1295
evaluation/Returns Min             -5.67644
evaluation/Actions Mean             0.00388314
evaluation/Actions Std              0.0688972
evaluation/Actions Max              0.998831
evaluation/Actions Min             -0.963672
evaluation/Num Paths                5
evaluation/Average Returns         -5.34382
time/data storing (s)               0.00110019
time/evaluation sampling (s)        0.0735832
time/exploration sampling (s)       0.0333998
time/logging (s)                    0.00191166
time/saving (s)                     0.00179304
time/training (s)                   0.464066
time/epoch (s)                      0.575854
time/total (s)                    139.644
Epoch                             238
-----------------------------  ----------------
2019-04-13 17:00:54.363976 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 239 finished
-----------------------------  ----------------
replay_buffer/size              48100
trainer/QF1 Loss                    0.0455457
trainer/QF2 Loss                    0.0454276
trainer/Policy Loss                11.6918
trainer/Q1 Predictions Mean       -11.8348
trainer/Q1 Predictions Std          0.244791
trainer/Q1 Predictions Max        -11.6891
trainer/Q1 Predictions Min        -12.9463
trainer/Q2 Predictions Mean       -11.8277
trainer/Q2 Predictions Std          0.240011
trainer/Q2 Predictions Max        -11.6856
trainer/Q2 Predictions Min        -12.932
trainer/Q Targets Mean            -11.8861
trainer/Q Targets Std               0.294822
trainer/Q Targets Max             -11.5348
trainer/Q Targets Min             -12.7931
trainer/Bellman Errors 1 Mean       0.0455457
trainer/Bellman Errors 1 Std        0.0885757
trainer/Bellman Errors 1 Max        0.402398
trainer/Bellman Errors 1 Min        3.42876e-07
trainer/Bellman Errors 2 Mean       0.0454276
trainer/Bellman Errors 2 Std        0.0839685
trainer/Bellman Errors 2 Max        0.366918
trainer/Bellman Errors 2 Min        1.09196e-05
trainer/Policy Action Mean         -0.0111788
trainer/Policy Action Std           0.138744
trainer/Policy Action Max           0.49691
trainer/Policy Action Min          -0.394583
exploration/num steps total     48100
exploration/num paths total       481
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.149589
exploration/Rewards Std             0.0740757
exploration/Rewards Max            -0.0176888
exploration/Rewards Min            -0.513308
exploration/Returns Mean          -14.9589
exploration/Returns Std             0.346154
exploration/Returns Max           -14.6127
exploration/Returns Min           -15.305
exploration/Actions Mean            0.00400096
exploration/Actions Std             0.157329
exploration/Actions Max             1
exploration/Actions Min            -0.565021
exploration/Num Paths               2
exploration/Average Returns       -14.9589
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0962803
evaluation/Rewards Std              0.0391034
evaluation/Rewards Max             -0.086623
evaluation/Rewards Min             -0.835641
evaluation/Returns Mean            -9.62803
evaluation/Returns Std              0.288064
evaluation/Returns Max             -9.32469
evaluation/Returns Min            -10.1086
evaluation/Actions Mean             0.00463728
evaluation/Actions Std              0.0793853
evaluation/Actions Max              0.999951
evaluation/Actions Min             -0.972632
evaluation/Num Paths                5
evaluation/Average Returns         -9.62803
time/data storing (s)               0.00111225
time/evaluation sampling (s)        0.0725108
time/exploration sampling (s)       0.0322996
time/logging (s)                    0.00247179
time/saving (s)                     0.002483
time/training (s)                   0.465288
time/epoch (s)                      0.576165
time/total (s)                    140.224
Epoch                             239
-----------------------------  ----------------
2019-04-13 17:00:54.950199 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 240 finished
-----------------------------  ----------------
replay_buffer/size              48300
trainer/QF1 Loss                    0.0782739
trainer/QF2 Loss                    0.0766542
trainer/Policy Loss                11.6884
trainer/Q1 Predictions Mean       -11.8471
trainer/Q1 Predictions Std          0.685162
trainer/Q1 Predictions Max        -11.5977
trainer/Q1 Predictions Min        -15.6403
trainer/Q2 Predictions Mean       -11.8462
trainer/Q2 Predictions Std          0.703782
trainer/Q2 Predictions Max        -11.595
trainer/Q2 Predictions Min        -15.7454
trainer/Q Targets Mean            -12.0569
trainer/Q Targets Std               0.699632
trainer/Q Targets Max             -11.6059
trainer/Q Targets Min             -15.7937
trainer/Bellman Errors 1 Mean       0.0782739
trainer/Bellman Errors 1 Std        0.0945942
trainer/Bellman Errors 1 Max        0.373058
trainer/Bellman Errors 1 Min        1.43705e-06
trainer/Bellman Errors 2 Mean       0.0766542
trainer/Bellman Errors 2 Std        0.093427
trainer/Bellman Errors 2 Max        0.358416
trainer/Bellman Errors 2 Min        3.62699e-05
trainer/Policy Action Mean          0.002612
trainer/Policy Action Std           0.205625
trainer/Policy Action Max           0.999999
trainer/Policy Action Min          -0.999069
exploration/num steps total     48300
exploration/num paths total       483
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129515
exploration/Rewards Std             0.070724
exploration/Rewards Max            -0.00531935
exploration/Rewards Min            -0.464077
exploration/Returns Mean          -12.9515
exploration/Returns Std             0.436345
exploration/Returns Max           -12.5152
exploration/Returns Min           -13.3878
exploration/Actions Mean            0.000123311
exploration/Actions Std             0.150336
exploration/Actions Max             1
exploration/Actions Min            -0.696946
exploration/Num Paths               2
exploration/Average Returns       -12.9515
evaluation/num steps total     120500
evaluation/num paths total       1205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0364728
evaluation/Rewards Std              0.0578974
evaluation/Rewards Max             -0.0204751
evaluation/Rewards Min             -0.935167
evaluation/Returns Mean            -3.64728
evaluation/Returns Std              0.330844
evaluation/Returns Max             -3.20794
evaluation/Returns Min             -4.033
evaluation/Actions Mean             0.00638767
evaluation/Actions Std              0.0882591
evaluation/Actions Max              0.999967
evaluation/Actions Min             -0.970456
evaluation/Num Paths                5
evaluation/Average Returns         -3.64728
time/data storing (s)               0.00106873
time/evaluation sampling (s)        0.0809651
time/exploration sampling (s)       0.032819
time/logging (s)                    0.00254517
time/saving (s)                     0.0046929
time/training (s)                   0.456753
time/epoch (s)                      0.578844
time/total (s)                    140.806
Epoch                             240
-----------------------------  ----------------
2019-04-13 17:00:55.534223 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 241 finished
-----------------------------  ----------------
replay_buffer/size              48500
trainer/QF1 Loss                    0.0282068
trainer/QF2 Loss                    0.0277967
trainer/Policy Loss                11.7217
trainer/Q1 Predictions Mean       -11.8152
trainer/Q1 Predictions Std          0.081667
trainer/Q1 Predictions Max        -11.6911
trainer/Q1 Predictions Min        -12.0285
trainer/Q2 Predictions Mean       -11.8181
trainer/Q2 Predictions Std          0.0837218
trainer/Q2 Predictions Max        -11.6888
trainer/Q2 Predictions Min        -12.024
trainer/Q Targets Mean            -11.8534
trainer/Q Targets Std               0.181931
trainer/Q Targets Max             -11.561
trainer/Q Targets Min             -12.2418
trainer/Bellman Errors 1 Mean       0.0282067
trainer/Bellman Errors 1 Std        0.0453527
trainer/Bellman Errors 1 Max        0.205208
trainer/Bellman Errors 1 Min        9.34235e-06
trainer/Bellman Errors 2 Mean       0.0277967
trainer/Bellman Errors 2 Std        0.0449591
trainer/Bellman Errors 2 Max        0.214924
trainer/Bellman Errors 2 Min        1.16109e-05
trainer/Policy Action Mean         -0.0499927
trainer/Policy Action Std           0.116951
trainer/Policy Action Max           0.392664
trainer/Policy Action Min          -0.327819
exploration/num steps total     48500
exploration/num paths total       485
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134397
exploration/Rewards Std             0.0725815
exploration/Rewards Max            -0.0145071
exploration/Rewards Min            -0.366053
exploration/Returns Mean          -13.4397
exploration/Returns Std             0.705875
exploration/Returns Max           -12.7338
exploration/Returns Min           -14.1455
exploration/Actions Mean           -0.00317943
exploration/Actions Std             0.162805
exploration/Actions Max             0.806276
exploration/Actions Min            -0.933646
exploration/Num Paths               2
exploration/Average Returns       -13.4397
evaluation/num steps total     121000
evaluation/num paths total       1210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0331272
evaluation/Rewards Std              0.03245
evaluation/Rewards Max             -0.00344668
evaluation/Rewards Min             -0.708491
evaluation/Returns Mean            -3.31272
evaluation/Returns Std              0.238881
evaluation/Returns Max             -3.12133
evaluation/Returns Min             -3.75794
evaluation/Actions Mean             0.0034699
evaluation/Actions Std              0.0677197
evaluation/Actions Max              0.999947
evaluation/Actions Min             -0.993613
evaluation/Num Paths                5
evaluation/Average Returns         -3.31272
time/data storing (s)               0.00109275
time/evaluation sampling (s)        0.0728044
time/exploration sampling (s)       0.0329812
time/logging (s)                    0.00246135
time/saving (s)                     0.00224386
time/training (s)                   0.464847
time/epoch (s)                      0.576431
time/total (s)                    141.386
Epoch                             241
-----------------------------  ----------------
2019-04-13 17:00:56.121782 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 242 finished
-----------------------------  ----------------
replay_buffer/size              48700
trainer/QF1 Loss                    0.0911795
trainer/QF2 Loss                    0.0917947
trainer/Policy Loss                11.5495
trainer/Q1 Predictions Mean       -11.6371
trainer/Q1 Predictions Std          0.142704
trainer/Q1 Predictions Max        -11.4881
trainer/Q1 Predictions Min        -12.3517
trainer/Q2 Predictions Mean       -11.6395
trainer/Q2 Predictions Std          0.132048
trainer/Q2 Predictions Max        -11.4937
trainer/Q2 Predictions Min        -12.2889
trainer/Q Targets Mean            -11.8885
trainer/Q Targets Std               0.2485
trainer/Q Targets Max             -11.6133
trainer/Q Targets Min             -12.7991
trainer/Bellman Errors 1 Mean       0.0911795
trainer/Bellman Errors 1 Std        0.100058
trainer/Bellman Errors 1 Max        0.383062
trainer/Bellman Errors 1 Min        0.000403038
trainer/Bellman Errors 2 Mean       0.0917947
trainer/Bellman Errors 2 Std        0.103172
trainer/Bellman Errors 2 Max        0.383186
trainer/Bellman Errors 2 Min        0.000290988
trainer/Policy Action Mean         -0.0165101
trainer/Policy Action Std           0.113264
trainer/Policy Action Max           0.241816
trainer/Policy Action Min          -0.354243
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142381
exploration/Rewards Std             0.0891161
exploration/Rewards Max            -0.0184316
exploration/Rewards Min            -0.795362
exploration/Returns Mean          -14.2381
exploration/Returns Std             1.07597
exploration/Returns Max           -13.1621
exploration/Returns Min           -15.3141
exploration/Actions Mean            0.00587325
exploration/Actions Std             0.167079
exploration/Actions Max             1
exploration/Actions Min            -0.884642
exploration/Num Paths               2
exploration/Average Returns       -14.2381
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.039864
evaluation/Rewards Std              0.0410581
evaluation/Rewards Max             -0.0352076
evaluation/Rewards Min             -0.929762
evaluation/Returns Mean            -3.9864
evaluation/Returns Std              0.32333
evaluation/Returns Max             -3.73528
evaluation/Returns Min             -4.61674
evaluation/Actions Mean             0.00482089
evaluation/Actions Std              0.0589247
evaluation/Actions Max              0.999938
evaluation/Actions Min             -0.210081
evaluation/Num Paths                5
evaluation/Average Returns         -3.9864
time/data storing (s)               0.00108555
time/evaluation sampling (s)        0.0784425
time/exploration sampling (s)       0.0321243
time/logging (s)                    0.00250829
time/saving (s)                     0.00227162
time/training (s)                   0.463542
time/epoch (s)                      0.579974
time/total (s)                    141.97
Epoch                             242
-----------------------------  ----------------
2019-04-13 17:00:56.706853 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 243 finished
-----------------------------  ----------------
replay_buffer/size              48900
trainer/QF1 Loss                    0.128601
trainer/QF2 Loss                    0.135387
trainer/Policy Loss                11.6436
trainer/Q1 Predictions Mean       -11.8182
trainer/Q1 Predictions Std          0.462745
trainer/Q1 Predictions Max        -11.5443
trainer/Q1 Predictions Min        -14.1291
trainer/Q2 Predictions Mean       -11.8095
trainer/Q2 Predictions Std          0.460474
trainer/Q2 Predictions Max        -11.5386
trainer/Q2 Predictions Min        -14.0721
trainer/Q Targets Mean            -12.1206
trainer/Q Targets Std               0.578664
trainer/Q Targets Max             -11.6556
trainer/Q Targets Min             -15.0021
trainer/Bellman Errors 1 Mean       0.128601
trainer/Bellman Errors 1 Std        0.160136
trainer/Bellman Errors 1 Max        0.762158
trainer/Bellman Errors 1 Min        3.28729e-05
trainer/Bellman Errors 2 Mean       0.135387
trainer/Bellman Errors 2 Std        0.172066
trainer/Bellman Errors 2 Max        0.864812
trainer/Bellman Errors 2 Min        3.63044e-05
trainer/Policy Action Mean          0.0284804
trainer/Policy Action Std           0.223346
trainer/Policy Action Max           0.999437
trainer/Policy Action Min          -0.392301
exploration/num steps total     48900
exploration/num paths total       489
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127405
exploration/Rewards Std             0.09142
exploration/Rewards Max            -0.00783083
exploration/Rewards Min            -0.866757
exploration/Returns Mean          -12.7405
exploration/Returns Std             0.0487891
exploration/Returns Max           -12.6917
exploration/Returns Min           -12.7893
exploration/Actions Mean            0.00911237
exploration/Actions Std             0.149437
exploration/Actions Max             1
exploration/Actions Min            -0.321456
exploration/Num Paths               2
exploration/Average Returns       -12.7405
evaluation/num steps total     122000
evaluation/num paths total       1220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0119578
evaluation/Rewards Std              0.0262322
evaluation/Rewards Max             -0.00926919
evaluation/Rewards Min             -0.485457
evaluation/Returns Mean            -1.19578
evaluation/Returns Std              0.169271
evaluation/Returns Max             -1.00078
evaluation/Returns Min             -1.47765
evaluation/Actions Mean             0.00575531
evaluation/Actions Std              0.062383
evaluation/Actions Max              0.994663
evaluation/Actions Min             -0.1784
evaluation/Num Paths                5
evaluation/Average Returns         -1.19578
time/data storing (s)               0.00105437
time/evaluation sampling (s)        0.0760381
time/exploration sampling (s)       0.03281
time/logging (s)                    0.0018718
time/saving (s)                     0.00180911
time/training (s)                   0.46322
time/epoch (s)                      0.576803
time/total (s)                    142.551
Epoch                             243
-----------------------------  ----------------
2019-04-13 17:00:57.303374 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 244 finished
-----------------------------  ----------------
replay_buffer/size              49100
trainer/QF1 Loss                    8.41244
trainer/QF2 Loss                    8.4182
trainer/Policy Loss                11.5937
trainer/Q1 Predictions Mean       -11.7741
trainer/Q1 Predictions Std          0.449347
trainer/Q1 Predictions Max        -11.6047
trainer/Q1 Predictions Min        -14.2461
trainer/Q2 Predictions Mean       -11.7771
trainer/Q2 Predictions Std          0.447111
trainer/Q2 Predictions Max        -11.5978
trainer/Q2 Predictions Min        -14.2308
trainer/Q Targets Mean            -11.2423
trainer/Q Targets Std               2.90921
trainer/Q Targets Max              -0.14161
trainer/Q Targets Min             -14.6861
trainer/Bellman Errors 1 Mean       8.41244
trainer/Bellman Errors 1 Std       32.3377
trainer/Bellman Errors 1 Max      134.114
trainer/Bellman Errors 1 Min        0.000121644
trainer/Bellman Errors 2 Mean       8.4182
trainer/Bellman Errors 2 Std       32.3642
trainer/Bellman Errors 2 Max      134.166
trainer/Bellman Errors 2 Min        0.00027214
trainer/Policy Action Mean          0.0162344
trainer/Policy Action Std           0.163967
trainer/Policy Action Max           0.995061
trainer/Policy Action Min          -0.239351
exploration/num steps total     49100
exploration/num paths total       491
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131621
exploration/Rewards Std             0.062801
exploration/Rewards Max            -0.022414
exploration/Rewards Min            -0.296379
exploration/Returns Mean          -13.1621
exploration/Returns Std             0.151578
exploration/Returns Max           -13.0106
exploration/Returns Min           -13.3137
exploration/Actions Mean            0.00552249
exploration/Actions Std             0.146009
exploration/Actions Max             0.731916
exploration/Actions Min            -0.332962
exploration/Num Paths               2
exploration/Average Returns       -13.1621
evaluation/num steps total     122500
evaluation/num paths total       1225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0380501
evaluation/Rewards Std              0.0336314
evaluation/Rewards Max             -0.0203079
evaluation/Rewards Min             -0.741955
evaluation/Returns Mean            -3.80501
evaluation/Returns Std              0.252772
evaluation/Returns Max             -3.5794
evaluation/Returns Min             -4.27947
evaluation/Actions Mean             0.0048719
evaluation/Actions Std              0.0645979
evaluation/Actions Max              0.999485
evaluation/Actions Min             -0.456409
evaluation/Num Paths                5
evaluation/Average Returns         -3.80501
time/data storing (s)               0.00112884
time/evaluation sampling (s)        0.0749215
time/exploration sampling (s)       0.033321
time/logging (s)                    0.00190017
time/saving (s)                     0.00178971
time/training (s)                   0.475859
time/epoch (s)                      0.58892
time/total (s)                    143.144
Epoch                             244
-----------------------------  ----------------
2019-04-13 17:00:57.899085 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 245 finished
-----------------------------  ----------------
replay_buffer/size              49300
trainer/QF1 Loss                    0.0302709
trainer/QF2 Loss                    0.0308475
trainer/Policy Loss                11.8247
trainer/Q1 Predictions Mean       -11.9922
trainer/Q1 Predictions Std          0.529665
trainer/Q1 Predictions Max        -11.7534
trainer/Q1 Predictions Min        -14.8492
trainer/Q2 Predictions Mean       -11.9906
trainer/Q2 Predictions Std          0.529674
trainer/Q2 Predictions Max        -11.7339
trainer/Q2 Predictions Min        -14.843
trainer/Q Targets Mean            -12.0655
trainer/Q Targets Std               0.508975
trainer/Q Targets Max             -11.58
trainer/Q Targets Min             -14.6928
trainer/Bellman Errors 1 Mean       0.0302709
trainer/Bellman Errors 1 Std        0.0499648
trainer/Bellman Errors 1 Max        0.214875
trainer/Bellman Errors 1 Min        1.02373e-05
trainer/Bellman Errors 2 Mean       0.0308475
trainer/Bellman Errors 2 Std        0.0506635
trainer/Bellman Errors 2 Max        0.219268
trainer/Bellman Errors 2 Min        2.21141e-05
trainer/Policy Action Mean          0.0302579
trainer/Policy Action Std           0.165273
trainer/Policy Action Max           0.995549
trainer/Policy Action Min          -0.374231
exploration/num steps total     49300
exploration/num paths total       493
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134036
exploration/Rewards Std             0.0672183
exploration/Rewards Max            -0.00196928
exploration/Rewards Min            -0.366774
exploration/Returns Mean          -13.4036
exploration/Returns Std             0.374559
exploration/Returns Max           -13.0291
exploration/Returns Min           -13.7782
exploration/Actions Mean            0.00176768
exploration/Actions Std             0.160736
exploration/Actions Max             0.950774
exploration/Actions Min            -0.823132
exploration/Num Paths               2
exploration/Average Returns       -13.4036
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0428633
evaluation/Rewards Std              0.0527296
evaluation/Rewards Max             -0.0354606
evaluation/Rewards Min             -0.868185
evaluation/Returns Mean            -4.28633
evaluation/Returns Std              0.383773
evaluation/Returns Max             -3.85742
evaluation/Returns Min             -4.78112
evaluation/Actions Mean             0.00404655
evaluation/Actions Std              0.0839946
evaluation/Actions Max              0.999973
evaluation/Actions Min             -0.978627
evaluation/Num Paths                5
evaluation/Average Returns         -4.28633
time/data storing (s)               0.00111955
time/evaluation sampling (s)        0.083414
time/exploration sampling (s)       0.0386806
time/logging (s)                    0.00213983
time/saving (s)                     0.00222384
time/training (s)                   0.461021
time/epoch (s)                      0.588599
time/total (s)                    143.736
Epoch                             245
-----------------------------  ----------------
2019-04-13 17:00:58.497453 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 246 finished
-----------------------------  ----------------
replay_buffer/size              49500
trainer/QF1 Loss                    0.0702587
trainer/QF2 Loss                    0.0668907
trainer/Policy Loss                11.6348
trainer/Q1 Predictions Mean       -11.7551
trainer/Q1 Predictions Std          0.163742
trainer/Q1 Predictions Max        -11.6393
trainer/Q1 Predictions Min        -12.5874
trainer/Q2 Predictions Mean       -11.7667
trainer/Q2 Predictions Std          0.164138
trainer/Q2 Predictions Max        -11.6058
trainer/Q2 Predictions Min        -12.5708
trainer/Q Targets Mean            -11.9733
trainer/Q Targets Std               0.210595
trainer/Q Targets Max             -11.7468
trainer/Q Targets Min             -12.7544
trainer/Bellman Errors 1 Mean       0.0702587
trainer/Bellman Errors 1 Std        0.0852028
trainer/Bellman Errors 1 Max        0.328175
trainer/Bellman Errors 1 Min        2.52689e-05
trainer/Bellman Errors 2 Mean       0.0668907
trainer/Bellman Errors 2 Std        0.0860998
trainer/Bellman Errors 2 Max        0.30675
trainer/Bellman Errors 2 Min        0.000209549
trainer/Policy Action Mean          0.0632777
trainer/Policy Action Std           0.103337
trainer/Policy Action Max           0.236429
trainer/Policy Action Min          -0.366044
exploration/num steps total     49500
exploration/num paths total       495
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140164
exploration/Rewards Std             0.0817348
exploration/Rewards Max            -0.0175461
exploration/Rewards Min            -0.799055
exploration/Returns Mean          -14.0164
exploration/Returns Std             0.49811
exploration/Returns Max           -13.5183
exploration/Returns Min           -14.5146
exploration/Actions Mean            0.00478037
exploration/Actions Std             0.146902
exploration/Actions Max             1
exploration/Actions Min            -0.411868
exploration/Num Paths               2
exploration/Average Returns       -14.0164
evaluation/num steps total     123500
evaluation/num paths total       1235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0834025
evaluation/Rewards Std              0.0234903
evaluation/Rewards Max             -0.0412313
evaluation/Rewards Min             -0.43897
evaluation/Returns Mean            -8.34025
evaluation/Returns Std              0.178064
evaluation/Returns Max             -8.1171
evaluation/Returns Min             -8.54575
evaluation/Actions Mean             0.00540573
evaluation/Actions Std              0.0769179
evaluation/Actions Max              0.996434
evaluation/Actions Min             -0.901817
evaluation/Num Paths                5
evaluation/Average Returns         -8.34025
time/data storing (s)               0.00124777
time/evaluation sampling (s)        0.0813998
time/exploration sampling (s)       0.0351559
time/logging (s)                    0.00256792
time/saving (s)                     0.0020707
time/training (s)                   0.468694
time/epoch (s)                      0.591136
time/total (s)                    144.331
Epoch                             246
-----------------------------  ----------------
2019-04-13 17:00:59.081358 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 247 finished
-----------------------------  ----------------
replay_buffer/size              49700
trainer/QF1 Loss                    8.91933
trainer/QF2 Loss                    8.89673
trainer/Policy Loss                11.9167
trainer/Q1 Predictions Mean       -12.2319
trainer/Q1 Predictions Std          1.06333
trainer/Q1 Predictions Max        -11.8276
trainer/Q1 Predictions Min        -17.4047
trainer/Q2 Predictions Mean       -12.2223
trainer/Q2 Predictions Std          1.04393
trainer/Q2 Predictions Max        -11.8198
trainer/Q2 Predictions Min        -17.2636
trainer/Q Targets Mean            -11.4802
trainer/Q Targets Std               3.06592
trainer/Q Targets Max              -0.108863
trainer/Q Targets Min             -17.2343
trainer/Bellman Errors 1 Mean       8.91933
trainer/Bellman Errors 1 Std       34.4987
trainer/Bellman Errors 1 Max      145.772
trainer/Bellman Errors 1 Min        0.000139078
trainer/Bellman Errors 2 Mean       8.89673
trainer/Bellman Errors 2 Std       34.4146
trainer/Bellman Errors 2 Max      145.268
trainer/Bellman Errors 2 Min        0.00031077
trainer/Policy Action Mean          0.0189027
trainer/Policy Action Std           0.280836
trainer/Policy Action Max           1
trainer/Policy Action Min          -0.999586
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132769
exploration/Rewards Std             0.0933046
exploration/Rewards Max            -0.002592
exploration/Rewards Min            -1.00644
exploration/Returns Mean          -13.2769
exploration/Returns Std             0.291378
exploration/Returns Max           -12.9855
exploration/Returns Min           -13.5683
exploration/Actions Mean            0.00377265
exploration/Actions Std             0.155306
exploration/Actions Max             0.940994
exploration/Actions Min            -0.964921
exploration/Num Paths               2
exploration/Average Returns       -13.2769
evaluation/num steps total     124000
evaluation/num paths total       1240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0366141
evaluation/Rewards Std              0.05403
evaluation/Rewards Max             -0.0311927
evaluation/Rewards Min             -0.827004
evaluation/Returns Mean            -3.66141
evaluation/Returns Std              0.241949
evaluation/Returns Max             -3.29706
evaluation/Returns Min             -3.96774
evaluation/Actions Mean             0.00596966
evaluation/Actions Std              0.0960127
evaluation/Actions Max              0.999915
evaluation/Actions Min             -0.976112
evaluation/Num Paths                5
evaluation/Average Returns         -3.66141
time/data storing (s)               0.00123069
time/evaluation sampling (s)        0.0749787
time/exploration sampling (s)       0.0339985
time/logging (s)                    0.00248423
time/saving (s)                     0.00221132
time/training (s)                   0.460963
time/epoch (s)                      0.575867
time/total (s)                    144.911
Epoch                             247
-----------------------------  ----------------
2019-04-13 17:00:59.680383 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 248 finished
-----------------------------  ----------------
replay_buffer/size              49900
trainer/QF1 Loss                    0.117124
trainer/QF2 Loss                    0.123312
trainer/Policy Loss                11.661
trainer/Q1 Predictions Mean       -11.7792
trainer/Q1 Predictions Std          0.204871
trainer/Q1 Predictions Max        -11.6186
trainer/Q1 Predictions Min        -12.491
trainer/Q2 Predictions Mean       -11.7724
trainer/Q2 Predictions Std          0.206375
trainer/Q2 Predictions Max        -11.593
trainer/Q2 Predictions Min        -12.4986
trainer/Q Targets Mean            -12.0609
trainer/Q Targets Std               0.250397
trainer/Q Targets Max             -11.6652
trainer/Q Targets Min             -12.7867
trainer/Bellman Errors 1 Mean       0.117124
trainer/Bellman Errors 1 Std        0.15979
trainer/Bellman Errors 1 Max        0.929172
trainer/Bellman Errors 1 Min        6.10501e-05
trainer/Bellman Errors 2 Mean       0.123312
trainer/Bellman Errors 2 Std        0.171737
trainer/Bellman Errors 2 Max        0.995721
trainer/Bellman Errors 2 Min        3.56919e-06
trainer/Policy Action Mean          0.0350476
trainer/Policy Action Std           0.159265
trainer/Policy Action Max           0.750272
trainer/Policy Action Min          -0.362021
exploration/num steps total     49900
exploration/num paths total       499
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143675
exploration/Rewards Std             0.0817081
exploration/Rewards Max            -0.0110826
exploration/Rewards Min            -0.771294
exploration/Returns Mean          -14.3675
exploration/Returns Std             0.0650728
exploration/Returns Max           -14.3025
exploration/Returns Min           -14.4326
exploration/Actions Mean            0.00853843
exploration/Actions Std             0.151018
exploration/Actions Max             0.989187
exploration/Actions Min            -0.398925
exploration/Num Paths               2
exploration/Average Returns       -14.3675
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0639708
evaluation/Rewards Std              0.0362072
evaluation/Rewards Max             -0.060599
evaluation/Rewards Min             -0.724583
evaluation/Returns Mean            -6.39708
evaluation/Returns Std              0.26573
evaluation/Returns Max             -6.16397
evaluation/Returns Min             -6.80264
evaluation/Actions Mean             0.00556627
evaluation/Actions Std              0.0787939
evaluation/Actions Max              0.999477
evaluation/Actions Min             -0.61979
evaluation/Num Paths                5
evaluation/Average Returns         -6.39708
time/data storing (s)               0.00110824
time/evaluation sampling (s)        0.0772511
time/exploration sampling (s)       0.0337931
time/logging (s)                    0.00247584
time/saving (s)                     0.00248944
time/training (s)                   0.47539
time/epoch (s)                      0.592508
time/total (s)                    145.507
Epoch                             248
-----------------------------  ----------------
2019-04-13 17:01:00.260978 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 249 finished
-----------------------------  ----------------
replay_buffer/size              50100
trainer/QF1 Loss                    0.0440039
trainer/QF2 Loss                    0.0403897
trainer/Policy Loss                11.843
trainer/Q1 Predictions Mean       -11.9712
trainer/Q1 Predictions Std          0.164352
trainer/Q1 Predictions Max        -11.8159
trainer/Q1 Predictions Min        -12.8225
trainer/Q2 Predictions Mean       -11.9815
trainer/Q2 Predictions Std          0.160826
trainer/Q2 Predictions Max        -11.8273
trainer/Q2 Predictions Min        -12.8017
trainer/Q Targets Mean            -12.048
trainer/Q Targets Std               0.204562
trainer/Q Targets Max             -11.7398
trainer/Q Targets Min             -12.62
trainer/Bellman Errors 1 Mean       0.0440039
trainer/Bellman Errors 1 Std        0.0696026
trainer/Bellman Errors 1 Max        0.315783
trainer/Bellman Errors 1 Min        1.79133e-05
trainer/Bellman Errors 2 Mean       0.0403897
trainer/Bellman Errors 2 Std        0.0618542
trainer/Bellman Errors 2 Max        0.28162
trainer/Bellman Errors 2 Min        4.30629e-05
trainer/Policy Action Mean          0.00893829
trainer/Policy Action Std           0.156632
trainer/Policy Action Max           0.999591
trainer/Policy Action Min          -0.201622
exploration/num steps total     50100
exploration/num paths total       501
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137475
exploration/Rewards Std             0.0735825
exploration/Rewards Max            -0.0132333
exploration/Rewards Min            -0.427322
exploration/Returns Mean          -13.7475
exploration/Returns Std             0.304705
exploration/Returns Max           -13.4428
exploration/Returns Min           -14.0522
exploration/Actions Mean            0.00451385
exploration/Actions Std             0.161326
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.7475
evaluation/num steps total     125000
evaluation/num paths total       1250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.040016
evaluation/Rewards Std              0.0290837
evaluation/Rewards Max             -0.00500201
evaluation/Rewards Min             -0.625553
evaluation/Returns Mean            -4.0016
evaluation/Returns Std              0.215836
evaluation/Returns Max             -3.85621
evaluation/Returns Min             -4.43063
evaluation/Actions Mean             0.00756227
evaluation/Actions Std              0.0714585
evaluation/Actions Max              0.999371
evaluation/Actions Min             -0.123138
evaluation/Num Paths                5
evaluation/Average Returns         -4.0016
time/data storing (s)               0.00107804
time/evaluation sampling (s)        0.0749779
time/exploration sampling (s)       0.0336815
time/logging (s)                    0.002468
time/saving (s)                     0.00226927
time/training (s)                   0.458314
time/epoch (s)                      0.572789
time/total (s)                    146.083
Epoch                             249
-----------------------------  ----------------
2019-04-13 17:01:01.021498 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 250 finished
-----------------------------  ----------------
replay_buffer/size              50300
trainer/QF1 Loss                    0.0515001
trainer/QF2 Loss                    0.0503439
trainer/Policy Loss                11.8144
trainer/Q1 Predictions Mean       -11.9074
trainer/Q1 Predictions Std          0.0707236
trainer/Q1 Predictions Max        -11.8308
trainer/Q1 Predictions Min        -12.0941
trainer/Q2 Predictions Mean       -11.9097
trainer/Q2 Predictions Std          0.0718422
trainer/Q2 Predictions Max        -11.8338
trainer/Q2 Predictions Min        -12.0926
trainer/Q Targets Mean            -12.0486
trainer/Q Targets Std               0.177979
trainer/Q Targets Max             -11.7135
trainer/Q Targets Min             -12.3869
trainer/Bellman Errors 1 Mean       0.0515001
trainer/Bellman Errors 1 Std        0.0642837
trainer/Bellman Errors 1 Max        0.208479
trainer/Bellman Errors 1 Min        0.000187599
trainer/Bellman Errors 2 Mean       0.0503439
trainer/Bellman Errors 2 Std        0.0620853
trainer/Bellman Errors 2 Max        0.191061
trainer/Bellman Errors 2 Min        0.000301957
trainer/Policy Action Mean         -0.0453988
trainer/Policy Action Std           0.0845545
trainer/Policy Action Max           0.198293
trainer/Policy Action Min          -0.242091
exploration/num steps total     50300
exploration/num paths total       503
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.149911
exploration/Rewards Std             0.101092
exploration/Rewards Max            -0.0150985
exploration/Rewards Min            -0.920567
exploration/Returns Mean          -14.9911
exploration/Returns Std             0.780395
exploration/Returns Max           -14.2107
exploration/Returns Min           -15.7715
exploration/Actions Mean            0.00366047
exploration/Actions Std             0.170144
exploration/Actions Max             0.990116
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.9911
evaluation/num steps total     125500
evaluation/num paths total       1255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0840305
evaluation/Rewards Std              0.016081
evaluation/Rewards Max             -0.0586619
evaluation/Rewards Min             -0.384815
evaluation/Returns Mean            -8.40305
evaluation/Returns Std              0.129634
evaluation/Returns Max             -8.29282
evaluation/Returns Min             -8.60809
evaluation/Actions Mean             0.00331007
evaluation/Actions Std              0.0637803
evaluation/Actions Max              0.997744
evaluation/Actions Min             -0.615665
evaluation/Num Paths                5
evaluation/Average Returns         -8.40305
time/data storing (s)               0.00122108
time/evaluation sampling (s)        0.0770578
time/exploration sampling (s)       0.0349608
time/logging (s)                    0.00250612
time/saving (s)                     0.00227536
time/training (s)                   0.635155
time/epoch (s)                      0.753177
time/total (s)                    146.84
Epoch                             250
-----------------------------  ----------------
2019-04-13 17:01:01.845216 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 251 finished
-----------------------------  ----------------
replay_buffer/size              50500
trainer/QF1 Loss                    4.39312
trainer/QF2 Loss                    4.36787
trainer/Policy Loss                11.8128
trainer/Q1 Predictions Mean       -11.9852
trainer/Q1 Predictions Std          0.146382
trainer/Q1 Predictions Max        -11.8539
trainer/Q1 Predictions Min        -12.6826
trainer/Q2 Predictions Mean       -11.9739
trainer/Q2 Predictions Std          0.134362
trainer/Q2 Predictions Max        -11.8364
trainer/Q2 Predictions Min        -12.6041
trainer/Q Targets Mean            -11.7363
trainer/Q Targets Std               2.0853
trainer/Q Targets Max              -0.179731
trainer/Q Targets Min             -12.6005
trainer/Bellman Errors 1 Mean       4.39312
trainer/Bellman Errors 1 Std       24.218
trainer/Bellman Errors 1 Max      139.233
trainer/Bellman Errors 1 Min        5.8677e-08
trainer/Bellman Errors 2 Mean       4.36787
trainer/Bellman Errors 2 Std       24.0669
trainer/Bellman Errors 2 Max      138.366
trainer/Bellman Errors 2 Min        1.30365e-05
trainer/Policy Action Mean          0.0160743
trainer/Policy Action Std           0.100999
trainer/Policy Action Max           0.181162
trainer/Policy Action Min          -0.365541
exploration/num steps total     50500
exploration/num paths total       505
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.148217
exploration/Rewards Std             0.0923191
exploration/Rewards Max            -0.00807239
exploration/Rewards Min            -0.929054
exploration/Returns Mean          -14.8217
exploration/Returns Std             0.927355
exploration/Returns Max           -13.8943
exploration/Returns Min           -15.7491
exploration/Actions Mean            0.00590801
exploration/Actions Std             0.173305
exploration/Actions Max             0.880237
exploration/Actions Min            -0.88581
exploration/Num Paths               2
exploration/Average Returns       -14.8217
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0509086
evaluation/Rewards Std              0.0117416
evaluation/Rewards Max             -0.0217888
evaluation/Rewards Min             -0.225041
evaluation/Returns Mean            -5.09086
evaluation/Returns Std              0.0738944
evaluation/Returns Max             -4.96175
evaluation/Returns Min             -5.18729
evaluation/Actions Mean             0.00526116
evaluation/Actions Std              0.0739406
evaluation/Actions Max              0.976514
evaluation/Actions Min             -0.644329
evaluation/Num Paths                5
evaluation/Average Returns         -5.09086
time/data storing (s)               0.00147961
time/evaluation sampling (s)        0.17057
time/exploration sampling (s)       0.0537582
time/logging (s)                    0.00248948
time/saving (s)                     0.00224881
time/training (s)                   0.586454
time/epoch (s)                      0.817
time/total (s)                    147.66
Epoch                             251
-----------------------------  ----------------
2019-04-13 17:01:02.380195 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 252 finished
-----------------------------  ----------------
replay_buffer/size              50700
trainer/QF1 Loss                    0.046584
trainer/QF2 Loss                    0.0429823
trainer/Policy Loss                11.8456
trainer/Q1 Predictions Mean       -12.0266
trainer/Q1 Predictions Std          0.486635
trainer/Q1 Predictions Max        -11.7895
trainer/Q1 Predictions Min        -14.3093
trainer/Q2 Predictions Mean       -12.0288
trainer/Q2 Predictions Std          0.490477
trainer/Q2 Predictions Max        -11.7872
trainer/Q2 Predictions Min        -14.3261
trainer/Q Targets Mean            -12.1869
trainer/Q Targets Std               0.520995
trainer/Q Targets Max             -11.75
trainer/Q Targets Min             -14.5684
trainer/Bellman Errors 1 Mean       0.046584
trainer/Bellman Errors 1 Std        0.0562748
trainer/Bellman Errors 1 Max        0.202529
trainer/Bellman Errors 1 Min        9.707e-05
trainer/Bellman Errors 2 Mean       0.0429823
trainer/Bellman Errors 2 Std        0.0524159
trainer/Bellman Errors 2 Max        0.199153
trainer/Bellman Errors 2 Min        1.17347e-05
trainer/Policy Action Mean          0.0537273
trainer/Policy Action Std           0.194261
trainer/Policy Action Max           0.995049
trainer/Policy Action Min          -0.396636
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132065
exploration/Rewards Std             0.0755075
exploration/Rewards Max            -0.0141244
exploration/Rewards Min            -0.411736
exploration/Returns Mean          -13.2065
exploration/Returns Std             0.0266998
exploration/Returns Max           -13.1798
exploration/Returns Min           -13.2332
exploration/Actions Mean            0.00594614
exploration/Actions Std             0.150154
exploration/Actions Max             0.836778
exploration/Actions Min            -0.395016
exploration/Num Paths               2
exploration/Average Returns       -13.2065
evaluation/num steps total     126500
evaluation/num paths total       1265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0584324
evaluation/Rewards Std              0.00811792
evaluation/Rewards Max             -0.0422568
evaluation/Rewards Min             -0.17495
evaluation/Returns Mean            -5.84324
evaluation/Returns Std              0.047642
evaluation/Returns Max             -5.76396
evaluation/Returns Min             -5.89373
evaluation/Actions Mean             0.00502119
evaluation/Actions Std              0.0700524
evaluation/Actions Max              0.944953
evaluation/Actions Min             -0.929704
evaluation/Num Paths                5
evaluation/Average Returns         -5.84324
time/data storing (s)               0.00117697
time/evaluation sampling (s)        0.0872304
time/exploration sampling (s)       0.0414771
time/logging (s)                    0.00245539
time/saving (s)                     0.0021587
time/training (s)                   0.392579
time/epoch (s)                      0.527078
time/total (s)                    148.191
Epoch                             252
-----------------------------  ----------------
2019-04-13 17:01:02.916929 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 253 finished
-----------------------------  ----------------
replay_buffer/size              50900
trainer/QF1 Loss                    0.023468
trainer/QF2 Loss                    0.0218889
trainer/Policy Loss                11.9914
trainer/Q1 Predictions Mean       -12.0927
trainer/Q1 Predictions Std          0.0598706
trainer/Q1 Predictions Max        -11.9756
trainer/Q1 Predictions Min        -12.2353
trainer/Q2 Predictions Mean       -12.084
trainer/Q2 Predictions Std          0.0556453
trainer/Q2 Predictions Max        -11.9877
trainer/Q2 Predictions Min        -12.2054
trainer/Q Targets Mean            -12.0569
trainer/Q Targets Std               0.146483
trainer/Q Targets Max             -11.8057
trainer/Q Targets Min             -12.4565
trainer/Bellman Errors 1 Mean       0.023468
trainer/Bellman Errors 1 Std        0.025602
trainer/Bellman Errors 1 Max        0.0852645
trainer/Bellman Errors 1 Min        0.00010937
trainer/Bellman Errors 2 Mean       0.0218889
trainer/Bellman Errors 2 Std        0.024048
trainer/Bellman Errors 2 Max        0.0903891
trainer/Bellman Errors 2 Min        0.000181998
trainer/Policy Action Mean          0.0697486
trainer/Policy Action Std           0.0992267
trainer/Policy Action Max           0.338264
trainer/Policy Action Min          -0.094447
exploration/num steps total     50900
exploration/num paths total       509
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.155913
exploration/Rewards Std             0.0877574
exploration/Rewards Max            -0.0219536
exploration/Rewards Min            -0.866758
exploration/Returns Mean          -15.5913
exploration/Returns Std             0.628163
exploration/Returns Max           -14.9632
exploration/Returns Min           -16.2195
exploration/Actions Mean            0.00421886
exploration/Actions Std             0.154185
exploration/Actions Max             1
exploration/Actions Min            -0.828822
exploration/Num Paths               2
exploration/Average Returns       -15.5913
evaluation/num steps total     127000
evaluation/num paths total       1270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0793159
evaluation/Rewards Std              0.0367003
evaluation/Rewards Max             -0.0682144
evaluation/Rewards Min             -0.889501
evaluation/Returns Mean            -7.93159
evaluation/Returns Std              0.323562
evaluation/Returns Max             -7.72322
evaluation/Returns Min             -8.57009
evaluation/Actions Mean             0.00423184
evaluation/Actions Std              0.0894001
evaluation/Actions Max              0.999611
evaluation/Actions Min             -0.909129
evaluation/Num Paths                5
evaluation/Average Returns         -7.93159
time/data storing (s)               0.00126454
time/evaluation sampling (s)        0.0738804
time/exploration sampling (s)       0.0423514
time/logging (s)                    0.00210616
time/saving (s)                     0.00186158
time/training (s)                   0.406965
time/epoch (s)                      0.528429
time/total (s)                    148.726
Epoch                             253
-----------------------------  ----------------
2019-04-13 17:01:03.466318 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 254 finished
-----------------------------  ----------------
replay_buffer/size              51100
trainer/QF1 Loss                    0.0406504
trainer/QF2 Loss                    0.0422931
trainer/Policy Loss                11.8598
trainer/Q1 Predictions Mean       -11.9605
trainer/Q1 Predictions Std          0.199562
trainer/Q1 Predictions Max        -11.8087
trainer/Q1 Predictions Min        -13.0013
trainer/Q2 Predictions Mean       -11.9552
trainer/Q2 Predictions Std          0.197364
trainer/Q2 Predictions Max        -11.8011
trainer/Q2 Predictions Min        -12.9861
trainer/Q Targets Mean            -12.0746
trainer/Q Targets Std               0.200427
trainer/Q Targets Max             -11.7756
trainer/Q Targets Min             -12.7519
trainer/Bellman Errors 1 Mean       0.0406504
trainer/Bellman Errors 1 Std        0.0698437
trainer/Bellman Errors 1 Max        0.290724
trainer/Bellman Errors 1 Min        2.66487e-05
trainer/Bellman Errors 2 Mean       0.0422931
trainer/Bellman Errors 2 Std        0.0705982
trainer/Bellman Errors 2 Max        0.295917
trainer/Bellman Errors 2 Min        4.4578e-05
trainer/Policy Action Mean          0.0255461
trainer/Policy Action Std           0.120361
trainer/Policy Action Max           0.326908
trainer/Policy Action Min          -0.382656
exploration/num steps total     51100
exploration/num paths total       511
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133545
exploration/Rewards Std             0.0715304
exploration/Rewards Max            -0.00421601
exploration/Rewards Min            -0.348192
exploration/Returns Mean          -13.3545
exploration/Returns Std             0.0258705
exploration/Returns Max           -13.3286
exploration/Returns Min           -13.3804
exploration/Actions Mean           -9.75584e-06
exploration/Actions Std             0.15625
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.3545
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0197091
evaluation/Rewards Std              0.0556465
evaluation/Rewards Max             -0.00817306
evaluation/Rewards Min             -0.844146
evaluation/Returns Mean            -1.97091
evaluation/Returns Std              0.274456
evaluation/Returns Max             -1.49676
evaluation/Returns Min             -2.33191
evaluation/Actions Mean             0.00545918
evaluation/Actions Std              0.0874205
evaluation/Actions Max              0.999977
evaluation/Actions Min             -0.985767
evaluation/Num Paths                5
evaluation/Average Returns         -1.97091
time/data storing (s)               0.00110574
time/evaluation sampling (s)        0.0949648
time/exploration sampling (s)       0.0358672
time/logging (s)                    0.00283586
time/saving (s)                     0.00247925
time/training (s)                   0.401568
time/epoch (s)                      0.538821
time/total (s)                    149.266
Epoch                             254
-----------------------------  ----------------
2019-04-13 17:01:04.155245 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 255 finished
-----------------------------  ----------------
replay_buffer/size              51300
trainer/QF1 Loss                    4.47904
trainer/QF2 Loss                    4.47632
trainer/Policy Loss                11.8877
trainer/Q1 Predictions Mean       -12.0616
trainer/Q1 Predictions Std          0.136975
trainer/Q1 Predictions Max        -11.9135
trainer/Q1 Predictions Min        -12.7008
trainer/Q2 Predictions Mean       -12.0498
trainer/Q2 Predictions Std          0.119788
trainer/Q2 Predictions Max        -11.8866
trainer/Q2 Predictions Min        -12.5184
trainer/Q Targets Mean            -11.7181
trainer/Q Targets Std               2.09274
trainer/Q Targets Max              -0.0889795
trainer/Q Targets Min             -12.2881
trainer/Bellman Errors 1 Mean       4.47904
trainer/Bellman Errors 1 Std       24.7191
trainer/Bellman Errors 1 Max      142.109
trainer/Bellman Errors 1 Min        0.000230508
trainer/Bellman Errors 2 Mean       4.47632
trainer/Bellman Errors 2 Std       24.7192
trainer/Bellman Errors 2 Max      142.107
trainer/Bellman Errors 2 Min        3.85563e-05
trainer/Policy Action Mean          0.0600752
trainer/Policy Action Std           0.172085
trainer/Policy Action Max           0.990282
trainer/Policy Action Min          -0.459878
exploration/num steps total     51300
exploration/num paths total       513
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.150296
exploration/Rewards Std             0.0840345
exploration/Rewards Max            -0.0223213
exploration/Rewards Min            -0.854574
exploration/Returns Mean          -15.0296
exploration/Returns Std             1.33681
exploration/Returns Max           -13.6928
exploration/Returns Min           -16.3664
exploration/Actions Mean            0.0059723
exploration/Actions Std             0.149146
exploration/Actions Max             1
exploration/Actions Min            -0.89181
exploration/Num Paths               2
exploration/Average Returns       -15.0296
evaluation/num steps total     128000
evaluation/num paths total       1280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0654401
evaluation/Rewards Std              0.00868042
evaluation/Rewards Max             -0.0490468
evaluation/Rewards Min             -0.210818
evaluation/Returns Mean            -6.54401
evaluation/Returns Std              0.0474335
evaluation/Returns Max             -6.47552
evaluation/Returns Min             -6.62017
evaluation/Actions Mean             0.00362157
evaluation/Actions Std              0.0605147
evaluation/Actions Max              0.973917
evaluation/Actions Min             -0.711389
evaluation/Num Paths                5
evaluation/Average Returns         -6.54401
time/data storing (s)               0.00121396
time/evaluation sampling (s)        0.0764295
time/exploration sampling (s)       0.0411002
time/logging (s)                    0.00665562
time/saving (s)                     0.00408347
time/training (s)                   0.552763
time/epoch (s)                      0.682246
time/total (s)                    149.953
Epoch                             255
-----------------------------  ----------------
2019-04-13 17:01:04.809695 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 256 finished
-----------------------------  ----------------
replay_buffer/size              51500
trainer/QF1 Loss                    0.0563398
trainer/QF2 Loss                    0.0565507
trainer/Policy Loss                11.8547
trainer/Q1 Predictions Mean       -11.9789
trainer/Q1 Predictions Std          0.386344
trainer/Q1 Predictions Max        -11.7766
trainer/Q1 Predictions Min        -13.7997
trainer/Q2 Predictions Mean       -11.9772
trainer/Q2 Predictions Std          0.388653
trainer/Q2 Predictions Max        -11.7617
trainer/Q2 Predictions Min        -13.8149
trainer/Q Targets Mean            -12.1812
trainer/Q Targets Std               0.384509
trainer/Q Targets Max             -11.8686
trainer/Q Targets Min             -13.9688
trainer/Bellman Errors 1 Mean       0.0563398
trainer/Bellman Errors 1 Std        0.0579868
trainer/Bellman Errors 1 Max        0.248731
trainer/Bellman Errors 1 Min        7.94423e-05
trainer/Bellman Errors 2 Mean       0.0565507
trainer/Bellman Errors 2 Std        0.0578552
trainer/Bellman Errors 2 Max        0.239346
trainer/Bellman Errors 2 Min        0.000262658
trainer/Policy Action Mean          0.0325018
trainer/Policy Action Std           0.233761
trainer/Policy Action Max           0.999965
trainer/Policy Action Min          -0.999146
exploration/num steps total     51500
exploration/num paths total       515
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132006
exploration/Rewards Std             0.0678247
exploration/Rewards Max            -0.0113091
exploration/Rewards Min            -0.322865
exploration/Returns Mean          -13.2006
exploration/Returns Std             0.371841
exploration/Returns Max           -12.8288
exploration/Returns Min           -13.5725
exploration/Actions Mean            0.00626202
exploration/Actions Std             0.149291
exploration/Actions Max             0.889387
exploration/Actions Min            -0.386248
exploration/Num Paths               2
exploration/Average Returns       -13.2006
evaluation/num steps total     128500
evaluation/num paths total       1285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0541176
evaluation/Rewards Std              0.0479785
evaluation/Rewards Max             -0.0140535
evaluation/Rewards Min             -0.963569
evaluation/Returns Mean            -5.41176
evaluation/Returns Std              0.314767
evaluation/Returns Max             -5.08419
evaluation/Returns Min             -5.92769
evaluation/Actions Mean             0.00637719
evaluation/Actions Std              0.0926108
evaluation/Actions Max              0.999941
evaluation/Actions Min             -0.978741
evaluation/Num Paths                5
evaluation/Average Returns         -5.41176
time/data storing (s)               0.00136635
time/evaluation sampling (s)        0.0801273
time/exploration sampling (s)       0.0348262
time/logging (s)                    0.00251338
time/saving (s)                     0.00224163
time/training (s)                   0.520362
time/epoch (s)                      0.641437
time/total (s)                    150.598
Epoch                             256
-----------------------------  ----------------
2019-04-13 17:01:05.469741 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 257 finished
-----------------------------  ----------------
replay_buffer/size              51700
trainer/QF1 Loss                    0.0676323
trainer/QF2 Loss                    0.0682724
trainer/Policy Loss                11.7727
trainer/Q1 Predictions Mean       -11.8901
trainer/Q1 Predictions Std          0.0677799
trainer/Q1 Predictions Max        -11.8073
trainer/Q1 Predictions Min        -12.057
trainer/Q2 Predictions Mean       -11.8941
trainer/Q2 Predictions Std          0.0568858
trainer/Q2 Predictions Max        -11.8025
trainer/Q2 Predictions Min        -12.0609
trainer/Q Targets Mean            -12.0957
trainer/Q Targets Std               0.177802
trainer/Q Targets Max             -11.8122
trainer/Q Targets Min             -12.5438
trainer/Bellman Errors 1 Mean       0.0676323
trainer/Bellman Errors 1 Std        0.0920561
trainer/Bellman Errors 1 Max        0.346587
trainer/Bellman Errors 1 Min        1.78771e-06
trainer/Bellman Errors 2 Mean       0.0682724
trainer/Bellman Errors 2 Std        0.0945468
trainer/Bellman Errors 2 Max        0.34585
trainer/Bellman Errors 2 Min        4.03412e-07
trainer/Policy Action Mean          0.000464931
trainer/Policy Action Std           0.103015
trainer/Policy Action Max           0.271752
trainer/Policy Action Min          -0.297384
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129997
exploration/Rewards Std             0.0709606
exploration/Rewards Max            -0.00210785
exploration/Rewards Min            -0.339886
exploration/Returns Mean          -12.9997
exploration/Returns Std             0.0917892
exploration/Returns Max           -12.9079
exploration/Returns Min           -13.0915
exploration/Actions Mean            0.00335627
exploration/Actions Std             0.13619
exploration/Actions Max             0.55513
exploration/Actions Min            -0.387095
exploration/Num Paths               2
exploration/Average Returns       -12.9997
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0501717
evaluation/Rewards Std              0.0534781
evaluation/Rewards Max             -0.0275771
evaluation/Rewards Min             -1.01421
evaluation/Returns Mean            -5.01717
evaluation/Returns Std              0.346867
evaluation/Returns Max             -4.62976
evaluation/Returns Min             -5.6146
evaluation/Actions Mean             0.00608455
evaluation/Actions Std              0.0898657
evaluation/Actions Max              0.999989
evaluation/Actions Min             -0.975009
evaluation/Num Paths                5
evaluation/Average Returns         -5.01717
time/data storing (s)               0.00137244
time/evaluation sampling (s)        0.0779897
time/exploration sampling (s)       0.0414703
time/logging (s)                    0.00275056
time/saving (s)                     0.00224891
time/training (s)                   0.526556
time/epoch (s)                      0.652388
time/total (s)                    151.254
Epoch                             257
-----------------------------  ----------------
2019-04-13 17:01:05.989377 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 258 finished
-----------------------------  ----------------
replay_buffer/size              51900
trainer/QF1 Loss                    0.0149477
trainer/QF2 Loss                    0.0162308
trainer/Policy Loss                12.069
trainer/Q1 Predictions Mean       -12.3302
trainer/Q1 Predictions Std          0.663052
trainer/Q1 Predictions Max        -11.9828
trainer/Q1 Predictions Min        -14.5417
trainer/Q2 Predictions Mean       -12.3471
trainer/Q2 Predictions Std          0.669311
trainer/Q2 Predictions Max        -12.0026
trainer/Q2 Predictions Min        -14.5704
trainer/Q Targets Mean            -12.2907
trainer/Q Targets Std               0.612257
trainer/Q Targets Max             -11.8645
trainer/Q Targets Min             -14.4965
trainer/Bellman Errors 1 Mean       0.0149477
trainer/Bellman Errors 1 Std        0.0223719
trainer/Bellman Errors 1 Max        0.106547
trainer/Bellman Errors 1 Min        0.000227535
trainer/Bellman Errors 2 Mean       0.0162308
trainer/Bellman Errors 2 Std        0.0277214
trainer/Bellman Errors 2 Max        0.135528
trainer/Bellman Errors 2 Min        4.4438e-07
trainer/Policy Action Mean          0.0344011
trainer/Policy Action Std           0.282615
trainer/Policy Action Max           0.996506
trainer/Policy Action Min          -0.998032
exploration/num steps total     51900
exploration/num paths total       519
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.139215
exploration/Rewards Std             0.108943
exploration/Rewards Max            -0.00371178
exploration/Rewards Min            -1.13458
exploration/Returns Mean          -13.9215
exploration/Returns Std             0.644067
exploration/Returns Max           -13.2775
exploration/Returns Min           -14.5656
exploration/Actions Mean            0.00917331
exploration/Actions Std             0.179725
exploration/Actions Max             1
exploration/Actions Min            -0.605863
exploration/Num Paths               2
exploration/Average Returns       -13.9215
evaluation/num steps total     129500
evaluation/num paths total       1295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0294808
evaluation/Rewards Std              0.0533188
evaluation/Rewards Max             -0.0245417
evaluation/Rewards Min             -0.988547
evaluation/Returns Mean            -2.94808
evaluation/Returns Std              0.359314
evaluation/Returns Max             -2.52754
evaluation/Returns Min             -3.53012
evaluation/Actions Mean             0.00548826
evaluation/Actions Std              0.0949581
evaluation/Actions Max              0.999982
evaluation/Actions Min             -0.975004
evaluation/Num Paths                5
evaluation/Average Returns         -2.94808
time/data storing (s)               0.00109497
time/evaluation sampling (s)        0.0763624
time/exploration sampling (s)       0.0325532
time/logging (s)                    0.00256279
time/saving (s)                     0.002266
time/training (s)                   0.393555
time/epoch (s)                      0.508394
time/total (s)                    151.768
Epoch                             258
-----------------------------  ----------------
2019-04-13 17:01:07.122863 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 259 finished
-----------------------------  ----------------
replay_buffer/size              52100
trainer/QF1 Loss                    0.0532229
trainer/QF2 Loss                    0.0522198
trainer/Policy Loss                12.0681
trainer/Q1 Predictions Mean       -12.1881
trainer/Q1 Predictions Std          0.671599
trainer/Q1 Predictions Max        -11.9182
trainer/Q1 Predictions Min        -14.9244
trainer/Q2 Predictions Mean       -12.1988
trainer/Q2 Predictions Std          0.680295
trainer/Q2 Predictions Max        -11.9186
trainer/Q2 Predictions Min        -15.0209
trainer/Q Targets Mean            -12.3157
trainer/Q Targets Std               0.652393
trainer/Q Targets Max             -11.8206
trainer/Q Targets Min             -15.0768
trainer/Bellman Errors 1 Mean       0.0532229
trainer/Bellman Errors 1 Std        0.0917322
trainer/Bellman Errors 1 Max        0.456777
trainer/Bellman Errors 1 Min        0.000320871
trainer/Bellman Errors 2 Mean       0.0522198
trainer/Bellman Errors 2 Std        0.0931095
trainer/Bellman Errors 2 Max        0.463781
trainer/Bellman Errors 2 Min        7.17177e-07
trainer/Policy Action Mean          0.0443721
trainer/Policy Action Std           0.196076
trainer/Policy Action Max           0.995826
trainer/Policy Action Min          -0.264039
exploration/num steps total     52100
exploration/num paths total       521
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130666
exploration/Rewards Std             0.0680509
exploration/Rewards Max            -0.00704156
exploration/Rewards Min            -0.387362
exploration/Returns Mean          -13.0666
exploration/Returns Std             0.409504
exploration/Returns Max           -12.6571
exploration/Returns Min           -13.4761
exploration/Actions Mean            0.00329642
exploration/Actions Std             0.155552
exploration/Actions Max             1
exploration/Actions Min            -0.521577
exploration/Num Paths               2
exploration/Average Returns       -13.0666
evaluation/num steps total     130000
evaluation/num paths total       1300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0315073
evaluation/Rewards Std              0.0473726
evaluation/Rewards Max             -0.024721
evaluation/Rewards Min             -0.902103
evaluation/Returns Mean            -3.15073
evaluation/Returns Std              0.337211
evaluation/Returns Max             -2.80603
evaluation/Returns Min             -3.69708
evaluation/Actions Mean             0.00248043
evaluation/Actions Std              0.0850959
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.971684
evaluation/Num Paths                5
evaluation/Average Returns         -3.15073
time/data storing (s)               0.00271148
time/evaluation sampling (s)        0.181522
time/exploration sampling (s)       0.0883822
time/logging (s)                    0.00635987
time/saving (s)                     0.00321481
time/training (s)                   0.846994
time/epoch (s)                      1.12918
time/total (s)                    152.902
Epoch                             259
-----------------------------  ----------------
2019-04-13 17:01:08.084077 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 260 finished
-----------------------------  ----------------
replay_buffer/size              52300
trainer/QF1 Loss                    0.0834307
trainer/QF2 Loss                    0.0906733
trainer/Policy Loss                12.0117
trainer/Q1 Predictions Mean       -12.1639
trainer/Q1 Predictions Std          0.91
trainer/Q1 Predictions Max        -11.8495
trainer/Q1 Predictions Min        -17.1574
trainer/Q2 Predictions Mean       -12.1576
trainer/Q2 Predictions Std          0.901005
trainer/Q2 Predictions Max        -11.8523
trainer/Q2 Predictions Min        -17.0936
trainer/Q Targets Mean            -12.3769
trainer/Q Targets Std               1.00241
trainer/Q Targets Max             -11.9474
trainer/Q Targets Min             -17.8881
trainer/Bellman Errors 1 Mean       0.0834306
trainer/Bellman Errors 1 Std        0.116682
trainer/Bellman Errors 1 Max        0.533966
trainer/Bellman Errors 1 Min        0.00023074
trainer/Bellman Errors 2 Mean       0.0906733
trainer/Bellman Errors 2 Std        0.129675
trainer/Bellman Errors 2 Max        0.631264
trainer/Bellman Errors 2 Min        6.82869e-05
trainer/Policy Action Mean          0.0174197
trainer/Policy Action Std           0.306004
trainer/Policy Action Max           1
trainer/Policy Action Min          -0.996341
exploration/num steps total     52300
exploration/num paths total       523
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129428
exploration/Rewards Std             0.0694831
exploration/Rewards Max            -0.0110263
exploration/Rewards Min            -0.34402
exploration/Returns Mean          -12.9428
exploration/Returns Std             0.280566
exploration/Returns Max           -12.6623
exploration/Returns Min           -13.2234
exploration/Actions Mean            0.000399561
exploration/Actions Std             0.144772
exploration/Actions Max             0.717024
exploration/Actions Min            -0.635931
exploration/Num Paths               2
exploration/Average Returns       -12.9428
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0607651
evaluation/Rewards Std              0.0438062
evaluation/Rewards Max             -0.0103899
evaluation/Rewards Min             -0.865102
evaluation/Returns Mean            -6.07651
evaluation/Returns Std              0.285639
evaluation/Returns Max             -5.75966
evaluation/Returns Min             -6.53339
evaluation/Actions Mean             0.00722937
evaluation/Actions Std              0.0828799
evaluation/Actions Max              0.999796
evaluation/Actions Min             -0.42827
evaluation/Num Paths                5
evaluation/Average Returns         -6.07651
time/data storing (s)               0.00496521
time/evaluation sampling (s)        0.228801
time/exploration sampling (s)       0.0857768
time/logging (s)                    0.00247543
time/saving (s)                     0.0025043
time/training (s)                   0.618729
time/epoch (s)                      0.943251
time/total (s)                    153.853
Epoch                             260
-----------------------------  ----------------
2019-04-13 17:01:08.708270 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 261 finished
-----------------------------  ----------------
replay_buffer/size              52500
trainer/QF1 Loss                    0.0726778
trainer/QF2 Loss                    0.0763032
trainer/Policy Loss                11.9683
trainer/Q1 Predictions Mean       -12.1442
trainer/Q1 Predictions Std          0.639998
trainer/Q1 Predictions Max        -11.8422
trainer/Q1 Predictions Min        -15.0437
trainer/Q2 Predictions Mean       -12.1446
trainer/Q2 Predictions Std          0.636333
trainer/Q2 Predictions Max        -11.8511
trainer/Q2 Predictions Min        -14.9466
trainer/Q Targets Mean            -12.3528
trainer/Q Targets Std               0.716002
trainer/Q Targets Max             -11.7584
trainer/Q Targets Min             -15.6498
trainer/Bellman Errors 1 Mean       0.0726778
trainer/Bellman Errors 1 Std        0.0989089
trainer/Bellman Errors 1 Max        0.367357
trainer/Bellman Errors 1 Min        0.000149734
trainer/Bellman Errors 2 Mean       0.0763032
trainer/Bellman Errors 2 Std        0.115559
trainer/Bellman Errors 2 Max        0.494412
trainer/Bellman Errors 2 Min        0.000280542
trainer/Policy Action Mean          0.038042
trainer/Policy Action Std           0.270058
trainer/Policy Action Max           0.999966
trainer/Policy Action Min          -0.988679
exploration/num steps total     52500
exploration/num paths total       525
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.13574
exploration/Rewards Std             0.0701538
exploration/Rewards Max            -0.0226734
exploration/Rewards Min            -0.49613
exploration/Returns Mean          -13.574
exploration/Returns Std             0.667476
exploration/Returns Max           -12.9066
exploration/Returns Min           -14.2415
exploration/Actions Mean            0.00524149
exploration/Actions Std             0.156001
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.574
evaluation/num steps total     131000
evaluation/num paths total       1310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0552056
evaluation/Rewards Std              0.0461282
evaluation/Rewards Max             -0.0182613
evaluation/Rewards Min             -0.824824
evaluation/Returns Mean            -5.52056
evaluation/Returns Std              0.320448
evaluation/Returns Max             -5.19257
evaluation/Returns Min             -5.93678
evaluation/Actions Mean             0.00408752
evaluation/Actions Std              0.0745199
evaluation/Actions Max              0.999905
evaluation/Actions Min             -0.899581
evaluation/Num Paths                5
evaluation/Average Returns         -5.52056
time/data storing (s)               0.00111689
time/evaluation sampling (s)        0.0776704
time/exploration sampling (s)       0.0340136
time/logging (s)                    0.00246156
time/saving (s)                     0.0021931
time/training (s)                   0.498815
time/epoch (s)                      0.616271
time/total (s)                    154.473
Epoch                             261
-----------------------------  ----------------
2019-04-13 17:01:09.328697 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 262 finished
-----------------------------  ----------------
replay_buffer/size              52700
trainer/QF1 Loss                    0.0572233
trainer/QF2 Loss                    0.0587504
trainer/Policy Loss                11.9845
trainer/Q1 Predictions Mean       -12.1795
trainer/Q1 Predictions Std          0.384481
trainer/Q1 Predictions Max        -11.9462
trainer/Q1 Predictions Min        -14.1422
trainer/Q2 Predictions Mean       -12.1603
trainer/Q2 Predictions Std          0.381534
trainer/Q2 Predictions Max        -11.9602
trainer/Q2 Predictions Min        -14.1257
trainer/Q Targets Mean            -12.2492
trainer/Q Targets Std               0.456596
trainer/Q Targets Max             -11.8275
trainer/Q Targets Min             -14.1492
trainer/Bellman Errors 1 Mean       0.0572233
trainer/Bellman Errors 1 Std        0.190843
trainer/Bellman Errors 1 Max        1.10611
trainer/Bellman Errors 1 Min        4.87995e-05
trainer/Bellman Errors 2 Mean       0.0587504
trainer/Bellman Errors 2 Std        0.189783
trainer/Bellman Errors 2 Max        1.09762
trainer/Bellman Errors 2 Min        1.05138e-07
trainer/Policy Action Mean          0.0484457
trainer/Policy Action Std           0.219473
trainer/Policy Action Max           0.937948
trainer/Policy Action Min          -0.390675
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.139737
exploration/Rewards Std             0.0829387
exploration/Rewards Max            -0.0143567
exploration/Rewards Min            -0.751994
exploration/Returns Mean          -13.9737
exploration/Returns Std             0.231585
exploration/Returns Max           -13.7421
exploration/Returns Min           -14.2053
exploration/Actions Mean            0.00324266
exploration/Actions Std             0.156034
exploration/Actions Max             1
exploration/Actions Min            -0.955144
exploration/Num Paths               2
exploration/Average Returns       -13.9737
evaluation/num steps total     131500
evaluation/num paths total       1315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0641225
evaluation/Rewards Std              0.011436
evaluation/Rewards Max             -0.0365699
evaluation/Rewards Min             -0.252904
evaluation/Returns Mean            -6.41225
evaluation/Returns Std              0.0613275
evaluation/Returns Max             -6.34086
evaluation/Returns Min             -6.51961
evaluation/Actions Mean             0.00280454
evaluation/Actions Std              0.0719289
evaluation/Actions Max              0.989533
evaluation/Actions Min             -0.931098
evaluation/Num Paths                5
evaluation/Average Returns         -6.41225
time/data storing (s)               0.00110677
time/evaluation sampling (s)        0.0770028
time/exploration sampling (s)       0.0336437
time/logging (s)                    0.00247026
time/saving (s)                     0.00226722
time/training (s)                   0.495983
time/epoch (s)                      0.612473
time/total (s)                    155.09
Epoch                             262
-----------------------------  ----------------
2019-04-13 17:01:09.920510 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 263 finished
-----------------------------  ---------------
replay_buffer/size              52900
trainer/QF1 Loss                    4.42137
trainer/QF2 Loss                    4.42419
trainer/Policy Loss                11.74
trainer/Q1 Predictions Mean       -11.9339
trainer/Q1 Predictions Std          0.475662
trainer/Q1 Predictions Max        -11.7125
trainer/Q1 Predictions Min        -14.418
trainer/Q2 Predictions Mean       -11.9282
trainer/Q2 Predictions Std          0.465511
trainer/Q2 Predictions Max        -11.7109
trainer/Q2 Predictions Min        -14.3591
trainer/Q Targets Mean            -11.9174
trainer/Q Targets Std               2.18839
trainer/Q Targets Max              -0.00921344
trainer/Q Targets Min             -14.5939
trainer/Bellman Errors 1 Mean       4.42136
trainer/Bellman Errors 1 Std       23.806
trainer/Bellman Errors 1 Max      136.967
trainer/Bellman Errors 1 Min        0.0167474
trainer/Bellman Errors 2 Mean       4.42419
trainer/Bellman Errors 2 Std       23.799
trainer/Bellman Errors 2 Max      136.93
trainer/Bellman Errors 2 Min        0.0179222
trainer/Policy Action Mean          0.00687253
trainer/Policy Action Std           0.207624
trainer/Policy Action Max           0.993563
trainer/Policy Action Min          -0.438761
exploration/num steps total     52900
exploration/num paths total       529
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.141851
exploration/Rewards Std             0.09052
exploration/Rewards Max            -0.00895992
exploration/Rewards Min            -0.9498
exploration/Returns Mean          -14.1851
exploration/Returns Std             0.391518
exploration/Returns Max           -13.7936
exploration/Returns Min           -14.5766
exploration/Actions Mean            0.00961621
exploration/Actions Std             0.159347
exploration/Actions Max             0.999438
exploration/Actions Min            -0.398586
exploration/Num Paths               2
exploration/Average Returns       -14.1851
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0446771
evaluation/Rewards Std              0.0240611
evaluation/Rewards Max             -0.0312132
evaluation/Rewards Min             -0.554816
evaluation/Returns Mean            -4.46771
evaluation/Returns Std              0.201369
evaluation/Returns Max             -4.3195
evaluation/Returns Min             -4.86118
evaluation/Actions Mean             0.00219168
evaluation/Actions Std              0.0686612
evaluation/Actions Max              0.999186
evaluation/Actions Min             -0.974926
evaluation/Num Paths                5
evaluation/Average Returns         -4.46771
time/data storing (s)               0.00125819
time/evaluation sampling (s)        0.07644
time/exploration sampling (s)       0.0396747
time/logging (s)                    0.0024941
time/saving (s)                     0.00245455
time/training (s)                   0.461631
time/epoch (s)                      0.583953
time/total (s)                    155.677
Epoch                             263
-----------------------------  ---------------
2019-04-13 17:01:10.666418 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 264 finished
-----------------------------  ----------------
replay_buffer/size              53100
trainer/QF1 Loss                    4.50057
trainer/QF2 Loss                    4.5011
trainer/Policy Loss                11.9976
trainer/Q1 Predictions Mean       -12.1456
trainer/Q1 Predictions Std          0.145228
trainer/Q1 Predictions Max        -11.9813
trainer/Q1 Predictions Min        -12.8587
trainer/Q2 Predictions Mean       -12.1443
trainer/Q2 Predictions Std          0.153181
trainer/Q2 Predictions Max        -12.0084
trainer/Q2 Predictions Min        -12.9045
trainer/Q Targets Mean            -11.8524
trainer/Q Targets Std               2.09255
trainer/Q Targets Max              -0.253597
trainer/Q Targets Min             -12.9339
trainer/Bellman Errors 1 Mean       4.50057
trainer/Bellman Errors 1 Std       24.8941
trainer/Bellman Errors 1 Max      143.105
trainer/Bellman Errors 1 Min        0.000155364
trainer/Bellman Errors 2 Mean       4.50109
trainer/Bellman Errors 2 Std       24.8984
trainer/Bellman Errors 2 Max      143.129
trainer/Bellman Errors 2 Min        0.000574361
trainer/Policy Action Mean          0.0506823
trainer/Policy Action Std           0.120476
trainer/Policy Action Max           0.341236
trainer/Policy Action Min          -0.424442
exploration/num steps total     53100
exploration/num paths total       531
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133527
exploration/Rewards Std             0.0712565
exploration/Rewards Max            -0.0114503
exploration/Rewards Min            -0.388747
exploration/Returns Mean          -13.3527
exploration/Returns Std             0.214657
exploration/Returns Max           -13.1381
exploration/Returns Min           -13.5674
exploration/Actions Mean            0.00114936
exploration/Actions Std             0.153253
exploration/Actions Max             0.718519
exploration/Actions Min            -0.966453
exploration/Num Paths               2
exploration/Average Returns       -13.3527
evaluation/num steps total     132500
evaluation/num paths total       1325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0554289
evaluation/Rewards Std              0.0302487
evaluation/Rewards Max             -0.0159429
evaluation/Rewards Min             -0.57296
evaluation/Returns Mean            -5.54289
evaluation/Returns Std              0.192708
evaluation/Returns Max             -5.32195
evaluation/Returns Min             -5.82964
evaluation/Actions Mean             0.00437672
evaluation/Actions Std              0.0832635
evaluation/Actions Max              0.999693
evaluation/Actions Min             -0.953423
evaluation/Num Paths                5
evaluation/Average Returns         -5.54289
time/data storing (s)               0.00112629
time/evaluation sampling (s)        0.0834092
time/exploration sampling (s)       0.0331702
time/logging (s)                    0.00254742
time/saving (s)                     0.0022501
time/training (s)                   0.615482
time/epoch (s)                      0.737985
time/total (s)                    156.419
Epoch                             264
-----------------------------  ----------------
2019-04-13 17:01:11.205479 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 265 finished
-----------------------------  ---------------
replay_buffer/size              53300
trainer/QF1 Loss                    0.078809
trainer/QF2 Loss                    0.0767625
trainer/Policy Loss                11.8923
trainer/Q1 Predictions Mean       -11.9841
trainer/Q1 Predictions Std          0.144052
trainer/Q1 Predictions Max        -11.8673
trainer/Q1 Predictions Min        -12.665
trainer/Q2 Predictions Mean       -11.9849
trainer/Q2 Predictions Std          0.155198
trainer/Q2 Predictions Max        -11.8544
trainer/Q2 Predictions Min        -12.6983
trainer/Q Targets Mean            -12.2371
trainer/Q Targets Std               0.218118
trainer/Q Targets Max             -11.9312
trainer/Q Targets Min             -13.0557
trainer/Bellman Errors 1 Mean       0.078809
trainer/Bellman Errors 1 Std        0.0678032
trainer/Bellman Errors 1 Max        0.271109
trainer/Bellman Errors 1 Min        0.00408309
trainer/Bellman Errors 2 Mean       0.0767625
trainer/Bellman Errors 2 Std        0.0603022
trainer/Bellman Errors 2 Max        0.23026
trainer/Bellman Errors 2 Min        0.00561739
trainer/Policy Action Mean          0.0312235
trainer/Policy Action Std           0.137282
trainer/Policy Action Max           0.474884
trainer/Policy Action Min          -0.463303
exploration/num steps total     53300
exploration/num paths total       533
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133325
exploration/Rewards Std             0.0712312
exploration/Rewards Max            -0.0157688
exploration/Rewards Min            -0.370263
exploration/Returns Mean          -13.3325
exploration/Returns Std             0.61491
exploration/Returns Max           -12.7176
exploration/Returns Min           -13.9474
exploration/Actions Mean            0.00265941
exploration/Actions Std             0.163882
exploration/Actions Max             1
exploration/Actions Min            -0.978942
exploration/Num Paths               2
exploration/Average Returns       -13.3325
evaluation/num steps total     133000
evaluation/num paths total       1330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0258821
evaluation/Rewards Std              0.013685
evaluation/Rewards Max             -0.0113778
evaluation/Rewards Min             -0.263006
evaluation/Returns Mean            -2.58821
evaluation/Returns Std              0.073778
evaluation/Returns Max             -2.51135
evaluation/Returns Min             -2.70805
evaluation/Actions Mean             0.00527524
evaluation/Actions Std              0.0592763
evaluation/Actions Max              0.972567
evaluation/Actions Min             -0.228565
evaluation/Num Paths                5
evaluation/Average Returns         -2.58821
time/data storing (s)               0.00114159
time/evaluation sampling (s)        0.0762658
time/exploration sampling (s)       0.0354041
time/logging (s)                    0.00246481
time/saving (s)                     0.00227584
time/training (s)                   0.413489
time/epoch (s)                      0.531041
time/total (s)                    156.954
Epoch                             265
-----------------------------  ---------------
2019-04-13 17:01:11.890022 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 266 finished
-----------------------------  ----------------
replay_buffer/size              53500
trainer/QF1 Loss                    0.0288066
trainer/QF2 Loss                    0.0270347
trainer/Policy Loss                12.1202
trainer/Q1 Predictions Mean       -12.2676
trainer/Q1 Predictions Std          0.583168
trainer/Q1 Predictions Max        -12.0077
trainer/Q1 Predictions Min        -15.2182
trainer/Q2 Predictions Mean       -12.2798
trainer/Q2 Predictions Std          0.599265
trainer/Q2 Predictions Max        -12.0124
trainer/Q2 Predictions Min        -15.2746
trainer/Q Targets Mean            -12.3548
trainer/Q Targets Std               0.579767
trainer/Q Targets Max             -11.961
trainer/Q Targets Min             -15.2343
trainer/Bellman Errors 1 Mean       0.0288066
trainer/Bellman Errors 1 Std        0.046034
trainer/Bellman Errors 1 Max        0.220818
trainer/Bellman Errors 1 Min        2.87156e-05
trainer/Bellman Errors 2 Mean       0.0270347
trainer/Bellman Errors 2 Std        0.0428788
trainer/Bellman Errors 2 Max        0.206959
trainer/Bellman Errors 2 Min        0.000137329
trainer/Policy Action Mean          0.0369585
trainer/Policy Action Std           0.193087
trainer/Policy Action Max           0.991017
trainer/Policy Action Min          -0.395896
exploration/num steps total     53500
exploration/num paths total       535
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130031
exploration/Rewards Std             0.0666509
exploration/Rewards Max            -0.00478466
exploration/Rewards Min            -0.379969
exploration/Returns Mean          -13.0031
exploration/Returns Std             0.142036
exploration/Returns Max           -12.8611
exploration/Returns Min           -13.1452
exploration/Actions Mean            0.00320328
exploration/Actions Std             0.158752
exploration/Actions Max             0.738867
exploration/Actions Min            -0.961735
exploration/Num Paths               2
exploration/Average Returns       -13.0031
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0340357
evaluation/Rewards Std              0.0429499
evaluation/Rewards Max             -0.010589
evaluation/Rewards Min             -0.622292
evaluation/Returns Mean            -3.40357
evaluation/Returns Std              0.216096
evaluation/Returns Max             -3.11998
evaluation/Returns Min             -3.61927
evaluation/Actions Mean             0.00318263
evaluation/Actions Std              0.0873948
evaluation/Actions Max              0.999581
evaluation/Actions Min             -0.958775
evaluation/Num Paths                5
evaluation/Average Returns         -3.40357
time/data storing (s)               0.00110484
time/evaluation sampling (s)        0.0757097
time/exploration sampling (s)       0.0334469
time/logging (s)                    0.00249134
time/saving (s)                     0.00226201
time/training (s)                   0.562002
time/epoch (s)                      0.677017
time/total (s)                    157.635
Epoch                             266
-----------------------------  ----------------
2019-04-13 17:01:12.691076 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 267 finished
-----------------------------  ----------------
replay_buffer/size              53700
trainer/QF1 Loss                    0.0209324
trainer/QF2 Loss                    0.0196719
trainer/Policy Loss                12.1551
trainer/Q1 Predictions Mean       -12.2403
trainer/Q1 Predictions Std          0.141244
trainer/Q1 Predictions Max        -12.0787
trainer/Q1 Predictions Min        -12.8583
trainer/Q2 Predictions Mean       -12.2422
trainer/Q2 Predictions Std          0.148377
trainer/Q2 Predictions Max        -12.0736
trainer/Q2 Predictions Min        -12.8872
trainer/Q Targets Mean            -12.2374
trainer/Q Targets Std               0.226682
trainer/Q Targets Max             -12.0114
trainer/Q Targets Min             -13.1411
trainer/Bellman Errors 1 Mean       0.0209324
trainer/Bellman Errors 1 Std        0.0201279
trainer/Bellman Errors 1 Max        0.0799935
trainer/Bellman Errors 1 Min        6.17825e-05
trainer/Bellman Errors 2 Mean       0.0196719
trainer/Bellman Errors 2 Std        0.0179056
trainer/Bellman Errors 2 Max        0.0644689
trainer/Bellman Errors 2 Min        0.000239691
trainer/Policy Action Mean          0.0235138
trainer/Policy Action Std           0.116572
trainer/Policy Action Max           0.310697
trainer/Policy Action Min          -0.415494
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136397
exploration/Rewards Std             0.0808768
exploration/Rewards Max            -0.01202
exploration/Rewards Min            -0.643904
exploration/Returns Mean          -13.6397
exploration/Returns Std             0.383785
exploration/Returns Max           -13.2559
exploration/Returns Min           -14.0235
exploration/Actions Mean            0.00607665
exploration/Actions Std             0.155725
exploration/Actions Max             1
exploration/Actions Min            -0.790239
exploration/Num Paths               2
exploration/Average Returns       -13.6397
evaluation/num steps total     134000
evaluation/num paths total       1340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0651758
evaluation/Rewards Std              0.0592176
evaluation/Rewards Max             -0.0351403
evaluation/Rewards Min             -0.966028
evaluation/Returns Mean            -6.51758
evaluation/Returns Std              0.340787
evaluation/Returns Max             -6.08561
evaluation/Returns Min             -6.96109
evaluation/Actions Mean             0.0080697
evaluation/Actions Std              0.0861337
evaluation/Actions Max              0.999965
evaluation/Actions Min             -0.31328
evaluation/Num Paths                5
evaluation/Average Returns         -6.51758
time/data storing (s)               0.00154335
time/evaluation sampling (s)        0.0837744
time/exploration sampling (s)       0.0460469
time/logging (s)                    0.00255627
time/saving (s)                     0.0115795
time/training (s)                   0.647684
time/epoch (s)                      0.793184
time/total (s)                    158.431
Epoch                             267
-----------------------------  ----------------
2019-04-13 17:01:13.241375 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 268 finished
-----------------------------  ----------------
replay_buffer/size              53900
trainer/QF1 Loss                    0.0203201
trainer/QF2 Loss                    0.0196459
trainer/Policy Loss                12.1507
trainer/Q1 Predictions Mean       -12.2478
trainer/Q1 Predictions Std          0.476669
trainer/Q1 Predictions Max        -12.0275
trainer/Q1 Predictions Min        -14.8137
trainer/Q2 Predictions Mean       -12.2492
trainer/Q2 Predictions Std          0.479086
trainer/Q2 Predictions Max        -12.0277
trainer/Q2 Predictions Min        -14.829
trainer/Q Targets Mean            -12.3039
trainer/Q Targets Std               0.466938
trainer/Q Targets Max             -11.9179
trainer/Q Targets Min             -14.7146
trainer/Bellman Errors 1 Mean       0.0203201
trainer/Bellman Errors 1 Std        0.0294054
trainer/Bellman Errors 1 Max        0.139126
trainer/Bellman Errors 1 Min        1.87024e-06
trainer/Bellman Errors 2 Mean       0.0196459
trainer/Bellman Errors 2 Std        0.0284573
trainer/Bellman Errors 2 Max        0.141743
trainer/Bellman Errors 2 Min        9.38831e-07
trainer/Policy Action Mean         -0.0205252
trainer/Policy Action Std           0.195784
trainer/Policy Action Max           0.99438
trainer/Policy Action Min          -0.787353
exploration/num steps total     53900
exploration/num paths total       539
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142653
exploration/Rewards Std             0.11419
exploration/Rewards Max            -0.0151575
exploration/Rewards Min            -1.16999
exploration/Returns Mean          -14.2653
exploration/Returns Std             0.125367
exploration/Returns Max           -14.14
exploration/Returns Min           -14.3907
exploration/Actions Mean            0.00804066
exploration/Actions Std             0.150654
exploration/Actions Max             0.972649
exploration/Actions Min            -0.552511
exploration/Num Paths               2
exploration/Average Returns       -14.2653
evaluation/num steps total     134500
evaluation/num paths total       1345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0709251
evaluation/Rewards Std              0.0499791
evaluation/Rewards Max             -0.0521761
evaluation/Rewards Min             -0.919551
evaluation/Returns Mean            -7.09251
evaluation/Returns Std              0.27938
evaluation/Returns Max             -6.63906
evaluation/Returns Min             -7.47956
evaluation/Actions Mean             0.00467778
evaluation/Actions Std              0.087689
evaluation/Actions Max              0.999838
evaluation/Actions Min             -0.788101
evaluation/Num Paths                5
evaluation/Average Returns         -7.09251
time/data storing (s)               0.00116021
time/evaluation sampling (s)        0.0785141
time/exploration sampling (s)       0.0353515
time/logging (s)                    0.00246217
time/saving (s)                     0.00245812
time/training (s)                   0.423556
time/epoch (s)                      0.543503
time/total (s)                    158.979
Epoch                             268
-----------------------------  ----------------
2019-04-13 17:01:13.795118 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 269 finished
-----------------------------  ----------------
replay_buffer/size              54100
trainer/QF1 Loss                    0.0512187
trainer/QF2 Loss                    0.047703
trainer/Policy Loss                12.0257
trainer/Q1 Predictions Mean       -12.1543
trainer/Q1 Predictions Std          0.347142
trainer/Q1 Predictions Max        -11.9492
trainer/Q1 Predictions Min        -13.9092
trainer/Q2 Predictions Mean       -12.1652
trainer/Q2 Predictions Std          0.366572
trainer/Q2 Predictions Max        -11.9362
trainer/Q2 Predictions Min        -13.9433
trainer/Q Targets Mean            -12.3313
trainer/Q Targets Std               0.426089
trainer/Q Targets Max             -11.9682
trainer/Q Targets Min             -14.3823
trainer/Bellman Errors 1 Mean       0.0512187
trainer/Bellman Errors 1 Std        0.0645896
trainer/Bellman Errors 1 Max        0.223839
trainer/Bellman Errors 1 Min        0.000610522
trainer/Bellman Errors 2 Mean       0.047703
trainer/Bellman Errors 2 Std        0.0640032
trainer/Bellman Errors 2 Max        0.241931
trainer/Bellman Errors 2 Min        0.000872897
trainer/Policy Action Mean          0.102263
trainer/Policy Action Std           0.22906
trainer/Policy Action Max           0.999936
trainer/Policy Action Min          -0.456523
exploration/num steps total     54100
exploration/num paths total       541
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.148533
exploration/Rewards Std             0.097121
exploration/Rewards Max            -0.0173644
exploration/Rewards Min            -0.999995
exploration/Returns Mean          -14.8533
exploration/Returns Std             0.567936
exploration/Returns Max           -14.2854
exploration/Returns Min           -15.4212
exploration/Actions Mean            0.00626225
exploration/Actions Std             0.163767
exploration/Actions Max             1
exploration/Actions Min            -0.779225
exploration/Num Paths               2
exploration/Average Returns       -14.8533
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0895184
evaluation/Rewards Std              0.0207785
evaluation/Rewards Max             -0.0767217
evaluation/Rewards Min             -0.442115
evaluation/Returns Mean            -8.95184
evaluation/Returns Std              0.146449
evaluation/Returns Max             -8.79252
evaluation/Returns Min             -9.16153
evaluation/Actions Mean             0.00338425
evaluation/Actions Std              0.0720998
evaluation/Actions Max              0.99925
evaluation/Actions Min             -0.869311
evaluation/Num Paths                5
evaluation/Average Returns         -8.95184
time/data storing (s)               0.00113009
time/evaluation sampling (s)        0.0767637
time/exploration sampling (s)       0.0346889
time/logging (s)                    0.00246871
time/saving (s)                     0.00225484
time/training (s)                   0.428152
time/epoch (s)                      0.545459
time/total (s)                    159.528
Epoch                             269
-----------------------------  ----------------
2019-04-13 17:01:14.530954 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 270 finished
-----------------------------  ----------------
replay_buffer/size              54300
trainer/QF1 Loss                    0.0634488
trainer/QF2 Loss                    0.0622414
trainer/Policy Loss                12.0986
trainer/Q1 Predictions Mean       -12.272
trainer/Q1 Predictions Std          0.726723
trainer/Q1 Predictions Max        -11.9505
trainer/Q1 Predictions Min        -15.5423
trainer/Q2 Predictions Mean       -12.2687
trainer/Q2 Predictions Std          0.723085
trainer/Q2 Predictions Max        -11.9444
trainer/Q2 Predictions Min        -15.4977
trainer/Q Targets Mean            -12.4494
trainer/Q Targets Std               0.663578
trainer/Q Targets Max             -12.0177
trainer/Q Targets Min             -15.4711
trainer/Bellman Errors 1 Mean       0.0634488
trainer/Bellman Errors 1 Std        0.0822892
trainer/Bellman Errors 1 Max        0.330038
trainer/Bellman Errors 1 Min        0.000342403
trainer/Bellman Errors 2 Mean       0.0622414
trainer/Bellman Errors 2 Std        0.0757426
trainer/Bellman Errors 2 Max        0.333683
trainer/Bellman Errors 2 Min        0.000500347
trainer/Policy Action Mean          0.075584
trainer/Policy Action Std           0.224774
trainer/Policy Action Max           0.997793
trainer/Policy Action Min          -0.373701
exploration/num steps total     54300
exploration/num paths total       543
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129394
exploration/Rewards Std             0.06437
exploration/Rewards Max            -0.008707
exploration/Rewards Min            -0.317862
exploration/Returns Mean          -12.9394
exploration/Returns Std             0.16798
exploration/Returns Max           -12.7714
exploration/Returns Min           -13.1074
exploration/Actions Mean            0.00841978
exploration/Actions Std             0.146869
exploration/Actions Max             0.997184
exploration/Actions Min            -0.328358
exploration/Num Paths               2
exploration/Average Returns       -12.9394
evaluation/num steps total     135500
evaluation/num paths total       1355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.055872
evaluation/Rewards Std              0.0344502
evaluation/Rewards Max             -0.024528
evaluation/Rewards Min             -0.627124
evaluation/Returns Mean            -5.5872
evaluation/Returns Std              0.28652
evaluation/Returns Max             -5.30918
evaluation/Returns Min             -5.99498
evaluation/Actions Mean             0.00284097
evaluation/Actions Std              0.0784853
evaluation/Actions Max              0.999546
evaluation/Actions Min             -0.946052
evaluation/Num Paths                5
evaluation/Average Returns         -5.5872
time/data storing (s)               0.001119
time/evaluation sampling (s)        0.0771817
time/exploration sampling (s)       0.0334394
time/logging (s)                    0.00685081
time/saving (s)                     0.00443384
time/training (s)                   0.609126
time/epoch (s)                      0.73215
time/total (s)                    160.265
Epoch                             270
-----------------------------  ----------------
2019-04-13 17:01:15.186595 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 271 finished
-----------------------------  ----------------
replay_buffer/size              54500
trainer/QF1 Loss                    4.58054
trainer/QF2 Loss                    4.58255
trainer/Policy Loss                12.0698
trainer/Q1 Predictions Mean       -12.2303
trainer/Q1 Predictions Std          0.142636
trainer/Q1 Predictions Max        -12.105
trainer/Q1 Predictions Min        -12.9067
trainer/Q2 Predictions Mean       -12.2328
trainer/Q2 Predictions Std          0.13429
trainer/Q2 Predictions Max        -12.0923
trainer/Q2 Predictions Min        -12.8208
trainer/Q Targets Mean            -11.9016
trainer/Q Targets Std               2.11515
trainer/Q Targets Max              -0.18105
trainer/Q Targets Min             -12.8972
trainer/Bellman Errors 1 Mean       4.58054
trainer/Bellman Errors 1 Std       25.358
trainer/Bellman Errors 1 Max      145.768
trainer/Bellman Errors 1 Min        6.00245e-06
trainer/Bellman Errors 2 Mean       4.58255
trainer/Bellman Errors 2 Std       25.3824
trainer/Bellman Errors 2 Max      145.906
trainer/Bellman Errors 2 Min        2.30798e-06
trainer/Policy Action Mean          0.0101152
trainer/Policy Action Std           0.118011
trainer/Policy Action Max           0.307483
trainer/Policy Action Min          -0.402721
exploration/num steps total     54500
exploration/num paths total       545
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129572
exploration/Rewards Std             0.0820135
exploration/Rewards Max            -0.00934754
exploration/Rewards Min            -0.80953
exploration/Returns Mean          -12.9572
exploration/Returns Std             0.232561
exploration/Returns Max           -12.7247
exploration/Returns Min           -13.1898
exploration/Actions Mean            0.00417681
exploration/Actions Std             0.158898
exploration/Actions Max             1
exploration/Actions Min            -0.682613
exploration/Num Paths               2
exploration/Average Returns       -12.9572
evaluation/num steps total     136000
evaluation/num paths total       1360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0375554
evaluation/Rewards Std              0.0159751
evaluation/Rewards Max             -0.0233896
evaluation/Rewards Min             -0.350984
evaluation/Returns Mean            -3.75554
evaluation/Returns Std              0.11358
evaluation/Returns Max             -3.63557
evaluation/Returns Min             -3.97047
evaluation/Actions Mean             0.00344888
evaluation/Actions Std              0.0732884
evaluation/Actions Max              0.998999
evaluation/Actions Min             -0.844831
evaluation/Num Paths                5
evaluation/Average Returns         -3.75554
time/data storing (s)               0.00143918
time/evaluation sampling (s)        0.15788
time/exploration sampling (s)       0.0550937
time/logging (s)                    0.00249083
time/saving (s)                     0.00227098
time/training (s)                   0.417147
time/epoch (s)                      0.636321
time/total (s)                    160.911
Epoch                             271
-----------------------------  ----------------
2019-04-13 17:01:15.727031 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 272 finished
-----------------------------  ----------------
replay_buffer/size              54700
trainer/QF1 Loss                    4.74383
trainer/QF2 Loss                    4.74903
trainer/Policy Loss                12.3143
trainer/Q1 Predictions Mean       -12.6374
trainer/Q1 Predictions Std          1.09327
trainer/Q1 Predictions Max        -12.125
trainer/Q1 Predictions Min        -18.2052
trainer/Q2 Predictions Mean       -12.6275
trainer/Q2 Predictions Std          1.08362
trainer/Q2 Predictions Max        -12.1291
trainer/Q2 Predictions Min        -18.2332
trainer/Q Targets Mean            -12.152
trainer/Q Targets Std               2.36856
trainer/Q Targets Max              -0.0647122
trainer/Q Targets Min             -17.1296
trainer/Bellman Errors 1 Mean       4.74383
trainer/Bellman Errors 1 Std       26.0092
trainer/Bellman Errors 1 Max      149.553
trainer/Bellman Errors 1 Min        1.88454e-05
trainer/Bellman Errors 2 Mean       4.74903
trainer/Bellman Errors 2 Std       26.0277
trainer/Bellman Errors 2 Max      149.66
trainer/Bellman Errors 2 Min        1.05509e-05
trainer/Policy Action Mean          0.0580404
trainer/Policy Action Std           0.292038
trainer/Policy Action Max           1
trainer/Policy Action Min          -0.99669
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.151155
exploration/Rewards Std             0.0786248
exploration/Rewards Max            -0.00822146
exploration/Rewards Min            -0.523847
exploration/Returns Mean          -15.1155
exploration/Returns Std             0.130297
exploration/Returns Max           -14.9852
exploration/Returns Min           -15.2458
exploration/Actions Mean            0.00125551
exploration/Actions Std             0.175535
exploration/Actions Max             1
exploration/Actions Min            -0.957966
exploration/Num Paths               2
exploration/Average Returns       -15.1155
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0523526
evaluation/Rewards Std              0.0372472
evaluation/Rewards Max             -0.0482388
evaluation/Rewards Min             -0.857011
evaluation/Returns Mean            -5.23526
evaluation/Returns Std              0.322103
evaluation/Returns Max             -5.04098
evaluation/Returns Min             -5.8768
evaluation/Actions Mean             0.0055992
evaluation/Actions Std              0.0663834
evaluation/Actions Max              0.999926
evaluation/Actions Min             -0.318297
evaluation/Num Paths                5
evaluation/Average Returns         -5.23526
time/data storing (s)               0.00110495
time/evaluation sampling (s)        0.0757424
time/exploration sampling (s)       0.0337762
time/logging (s)                    0.00247557
time/saving (s)                     0.00228832
time/training (s)                   0.416806
time/epoch (s)                      0.532193
time/total (s)                    161.448
Epoch                             272
-----------------------------  ----------------
2019-04-13 17:01:16.419512 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 273 finished
-----------------------------  ----------------
replay_buffer/size              54900
trainer/QF1 Loss                    4.57925
trainer/QF2 Loss                    4.59421
trainer/Policy Loss                12.1445
trainer/Q1 Predictions Mean       -12.2922
trainer/Q1 Predictions Std          0.313495
trainer/Q1 Predictions Max        -12.1215
trainer/Q1 Predictions Min        -13.8358
trainer/Q2 Predictions Mean       -12.2855
trainer/Q2 Predictions Std          0.299592
trainer/Q2 Predictions Max        -12.099
trainer/Q2 Predictions Min        -13.7608
trainer/Q Targets Mean            -11.9768
trainer/Q Targets Std               2.14887
trainer/Q Targets Max              -0.0959465
trainer/Q Targets Min             -13.4577
trainer/Bellman Errors 1 Mean       4.57925
trainer/Bellman Errors 1 Std       25.3193
trainer/Bellman Errors 1 Max      145.551
trainer/Bellman Errors 1 Min        6.82081e-07
trainer/Bellman Errors 2 Mean       4.59421
trainer/Bellman Errors 2 Std       25.4071
trainer/Bellman Errors 2 Max      146.055
trainer/Bellman Errors 2 Min        1.18405e-06
trainer/Policy Action Mean         -0.00459583
trainer/Policy Action Std           0.178724
trainer/Policy Action Max           0.999955
trainer/Policy Action Min          -0.405427
exploration/num steps total     54900
exploration/num paths total       549
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12481
exploration/Rewards Std             0.0808261
exploration/Rewards Max            -0.00488077
exploration/Rewards Min            -0.810879
exploration/Returns Mean          -12.481
exploration/Returns Std             0.762003
exploration/Returns Max           -11.719
exploration/Returns Min           -13.243
exploration/Actions Mean            0.00544127
exploration/Actions Std             0.141124
exploration/Actions Max             1
exploration/Actions Min            -0.405437
exploration/Num Paths               2
exploration/Average Returns       -12.481
evaluation/num steps total     137000
evaluation/num paths total       1370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0259019
evaluation/Rewards Std              0.0439673
evaluation/Rewards Max             -0.0216855
evaluation/Rewards Min             -0.626946
evaluation/Returns Mean            -2.59019
evaluation/Returns Std              0.271977
evaluation/Returns Max             -2.22346
evaluation/Returns Min             -2.86479
evaluation/Actions Mean             0.00559558
evaluation/Actions Std              0.0827585
evaluation/Actions Max              0.999786
evaluation/Actions Min             -0.957546
evaluation/Num Paths                5
evaluation/Average Returns         -2.59019
time/data storing (s)               0.00113465
time/evaluation sampling (s)        0.0769125
time/exploration sampling (s)       0.0338977
time/logging (s)                    0.00248255
time/saving (s)                     0.00250873
time/training (s)                   0.567154
time/epoch (s)                      0.68409
time/total (s)                    162.136
Epoch                             273
-----------------------------  ----------------
2019-04-13 17:01:17.155573 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 274 finished
-----------------------------  ----------------
replay_buffer/size              55100
trainer/QF1 Loss                    0.0815066
trainer/QF2 Loss                    0.0767147
trainer/Policy Loss                12.0198
trainer/Q1 Predictions Mean       -12.1272
trainer/Q1 Predictions Std          0.209287
trainer/Q1 Predictions Max        -11.9155
trainer/Q1 Predictions Min        -12.9125
trainer/Q2 Predictions Mean       -12.1376
trainer/Q2 Predictions Std          0.210166
trainer/Q2 Predictions Max        -11.9267
trainer/Q2 Predictions Min        -12.9201
trainer/Q Targets Mean            -12.3649
trainer/Q Targets Std               0.262935
trainer/Q Targets Max             -11.9631
trainer/Q Targets Min             -13.11
trainer/Bellman Errors 1 Mean       0.0815066
trainer/Bellman Errors 1 Std        0.0790743
trainer/Bellman Errors 1 Max        0.377501
trainer/Bellman Errors 1 Min        0.000214633
trainer/Bellman Errors 2 Mean       0.0767147
trainer/Bellman Errors 2 Std        0.0770574
trainer/Bellman Errors 2 Max        0.377266
trainer/Bellman Errors 2 Min        0.000688806
trainer/Policy Action Mean          0.0622742
trainer/Policy Action Std           0.193547
trainer/Policy Action Max           0.824586
trainer/Policy Action Min          -0.63259
exploration/num steps total     55100
exploration/num paths total       551
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.157991
exploration/Rewards Std             0.0811794
exploration/Rewards Max            -0.00590648
exploration/Rewards Min            -0.568303
exploration/Returns Mean          -15.7991
exploration/Returns Std             1.5394
exploration/Returns Max           -14.2597
exploration/Returns Min           -17.3385
exploration/Actions Mean            0.00731547
exploration/Actions Std             0.159545
exploration/Actions Max             1
exploration/Actions Min            -0.497923
exploration/Num Paths               2
exploration/Average Returns       -15.7991
evaluation/num steps total     137500
evaluation/num paths total       1375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0861901
evaluation/Rewards Std              0.0415862
evaluation/Rewards Max             -0.0448769
evaluation/Rewards Min             -0.829
evaluation/Returns Mean            -8.61901
evaluation/Returns Std              0.360813
evaluation/Returns Max             -8.19637
evaluation/Returns Min             -9.20553
evaluation/Actions Mean             0.00500247
evaluation/Actions Std              0.0770303
evaluation/Actions Max              0.999983
evaluation/Actions Min             -0.877335
evaluation/Num Paths                5
evaluation/Average Returns         -8.61901
time/data storing (s)               0.00112324
time/evaluation sampling (s)        0.0936964
time/exploration sampling (s)       0.0353894
time/logging (s)                    0.00189349
time/saving (s)                     0.00209605
time/training (s)                   0.593226
time/epoch (s)                      0.727424
time/total (s)                    162.867
Epoch                             274
-----------------------------  ----------------
2019-04-13 17:01:17.691869 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 275 finished
-----------------------------  ----------------
replay_buffer/size              55300
trainer/QF1 Loss                    0.0272549
trainer/QF2 Loss                    0.0276337
trainer/Policy Loss                12.3027
trainer/Q1 Predictions Mean       -12.3955
trainer/Q1 Predictions Std          0.173106
trainer/Q1 Predictions Max        -12.2639
trainer/Q1 Predictions Min        -13.2048
trainer/Q2 Predictions Mean       -12.3982
trainer/Q2 Predictions Std          0.171726
trainer/Q2 Predictions Max        -12.261
trainer/Q2 Predictions Min        -13.1194
trainer/Q Targets Mean            -12.3598
trainer/Q Targets Std               0.233331
trainer/Q Targets Max             -11.9938
trainer/Q Targets Min             -13.1572
trainer/Bellman Errors 1 Mean       0.0272549
trainer/Bellman Errors 1 Std        0.0294326
trainer/Bellman Errors 1 Max        0.0975752
trainer/Bellman Errors 1 Min        0.000156198
trainer/Bellman Errors 2 Mean       0.0276337
trainer/Bellman Errors 2 Std        0.0283175
trainer/Bellman Errors 2 Max        0.0849417
trainer/Bellman Errors 2 Min        1.04908e-06
trainer/Policy Action Mean          0.000663814
trainer/Policy Action Std           0.219847
trainer/Policy Action Max           0.989476
trainer/Policy Action Min          -0.953314
exploration/num steps total     55300
exploration/num paths total       553
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128555
exploration/Rewards Std             0.0752697
exploration/Rewards Max            -0.00607989
exploration/Rewards Min            -0.381576
exploration/Returns Mean          -12.8555
exploration/Returns Std             0.456236
exploration/Returns Max           -12.3992
exploration/Returns Min           -13.3117
exploration/Actions Mean            0.00113604
exploration/Actions Std             0.155396
exploration/Actions Max             0.752866
exploration/Actions Min            -0.906583
exploration/Num Paths               2
exploration/Average Returns       -12.8555
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0370235
evaluation/Rewards Std              0.0312012
evaluation/Rewards Max             -0.0296263
evaluation/Rewards Min             -0.560661
evaluation/Returns Mean            -3.70235
evaluation/Returns Std              0.267464
evaluation/Returns Max             -3.4653
evaluation/Returns Min             -4.08282
evaluation/Actions Mean             0.00365858
evaluation/Actions Std              0.0817098
evaluation/Actions Max              0.999258
evaluation/Actions Min             -0.961089
evaluation/Num Paths                5
evaluation/Average Returns         -3.70235
time/data storing (s)               0.00124109
time/evaluation sampling (s)        0.0752731
time/exploration sampling (s)       0.0345721
time/logging (s)                    0.00265556
time/saving (s)                     0.00239866
time/training (s)                   0.413627
time/epoch (s)                      0.529768
time/total (s)                    163.401
Epoch                             275
-----------------------------  ----------------
2019-04-13 17:01:18.245959 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 276 finished
-----------------------------  ----------------
replay_buffer/size              55500
trainer/QF1 Loss                    4.5926
trainer/QF2 Loss                    4.58828
trainer/Policy Loss                12.191
trainer/Q1 Predictions Mean       -12.3139
trainer/Q1 Predictions Std          0.0909131
trainer/Q1 Predictions Max        -12.1752
trainer/Q1 Predictions Min        -12.483
trainer/Q2 Predictions Mean       -12.3143
trainer/Q2 Predictions Std          0.103616
trainer/Q2 Predictions Max        -12.1495
trainer/Q2 Predictions Min        -12.5027
trainer/Q Targets Mean            -11.9879
trainer/Q Targets Std               2.10681
trainer/Q Targets Max              -0.293419
trainer/Q Targets Min             -12.7894
trainer/Bellman Errors 1 Mean       4.5926
trainer/Bellman Errors 1 Std       25.44
trainer/Bellman Errors 1 Max      146.237
trainer/Bellman Errors 1 Min        1.04128e-08
trainer/Bellman Errors 2 Mean       4.58828
trainer/Bellman Errors 2 Std       25.4186
trainer/Bellman Errors 2 Max      146.113
trainer/Bellman Errors 2 Min        4.95452e-06
trainer/Policy Action Mean          0.0373679
trainer/Policy Action Std           0.0920326
trainer/Policy Action Max           0.209246
trainer/Policy Action Min          -0.140608
exploration/num steps total     55500
exploration/num paths total       555
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134797
exploration/Rewards Std             0.0691413
exploration/Rewards Max            -0.00259903
exploration/Rewards Min            -0.414185
exploration/Returns Mean          -13.4797
exploration/Returns Std             0.344015
exploration/Returns Max           -13.1357
exploration/Returns Min           -13.8237
exploration/Actions Mean            0.00455145
exploration/Actions Std             0.163686
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.4797
evaluation/num steps total     138500
evaluation/num paths total       1385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.040331
evaluation/Rewards Std              0.0666863
evaluation/Rewards Max             -0.0286059
evaluation/Rewards Min             -1.01389
evaluation/Returns Mean            -4.0331
evaluation/Returns Std              0.470458
evaluation/Returns Max             -3.45181
evaluation/Returns Min             -4.55254
evaluation/Actions Mean             0.0063717
evaluation/Actions Std              0.0905315
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.867265
evaluation/Num Paths                5
evaluation/Average Returns         -4.0331
time/data storing (s)               0.00143337
time/evaluation sampling (s)        0.0830876
time/exploration sampling (s)       0.0342884
time/logging (s)                    0.00242383
time/saving (s)                     0.00213299
time/training (s)                   0.422293
time/epoch (s)                      0.545659
time/total (s)                    163.951
Epoch                             276
-----------------------------  ----------------
2019-04-13 17:01:19.016953 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 277 finished
-----------------------------  ----------------
replay_buffer/size              55700
trainer/QF1 Loss                    0.0386826
trainer/QF2 Loss                    0.0391125
trainer/Policy Loss                12.2305
trainer/Q1 Predictions Mean       -12.3292
trainer/Q1 Predictions Std          0.16989
trainer/Q1 Predictions Max        -12.1812
trainer/Q1 Predictions Min        -13.0184
trainer/Q2 Predictions Mean       -12.3248
trainer/Q2 Predictions Std          0.168751
trainer/Q2 Predictions Max        -12.172
trainer/Q2 Predictions Min        -13.0186
trainer/Q Targets Mean            -12.3871
trainer/Q Targets Std               0.227331
trainer/Q Targets Max             -12.0974
trainer/Q Targets Min             -13.0474
trainer/Bellman Errors 1 Mean       0.0386826
trainer/Bellman Errors 1 Std        0.0678617
trainer/Bellman Errors 1 Max        0.257656
trainer/Bellman Errors 1 Min        1.07689e-05
trainer/Bellman Errors 2 Mean       0.0391125
trainer/Bellman Errors 2 Std        0.0718642
trainer/Bellman Errors 2 Max        0.292
trainer/Bellman Errors 2 Min        1.72574e-05
trainer/Policy Action Mean         -0.0166944
trainer/Policy Action Std           0.109983
trainer/Policy Action Max           0.335061
trainer/Policy Action Min          -0.380882
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133417
exploration/Rewards Std             0.0697617
exploration/Rewards Max            -0.0101171
exploration/Rewards Min            -0.409661
exploration/Returns Mean          -13.3417
exploration/Returns Std             0.739895
exploration/Returns Max           -12.6018
exploration/Returns Min           -14.0816
exploration/Actions Mean            0.00441576
exploration/Actions Std             0.150699
exploration/Actions Max             1
exploration/Actions Min            -0.833207
exploration/Num Paths               2
exploration/Average Returns       -13.3417
evaluation/num steps total     139000
evaluation/num paths total       1390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0189985
evaluation/Rewards Std              0.0143738
evaluation/Rewards Max             -0.0177745
evaluation/Rewards Min             -0.314757
evaluation/Returns Mean            -1.89985
evaluation/Returns Std              0.112206
evaluation/Returns Max             -1.83022
evaluation/Returns Min             -2.12293
evaluation/Actions Mean             0.00184282
evaluation/Actions Std              0.0533717
evaluation/Actions Max              0.997361
evaluation/Actions Min             -0.922851
evaluation/Num Paths                5
evaluation/Average Returns         -1.89985
time/data storing (s)               0.00121516
time/evaluation sampling (s)        0.0800795
time/exploration sampling (s)       0.0356201
time/logging (s)                    0.00287617
time/saving (s)                     0.00205872
time/training (s)                   0.641213
time/epoch (s)                      0.763063
time/total (s)                    164.718
Epoch                             277
-----------------------------  ----------------
2019-04-13 17:01:19.610263 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 278 finished
-----------------------------  ----------------
replay_buffer/size              55900
trainer/QF1 Loss                    0.022558
trainer/QF2 Loss                    0.024701
trainer/Policy Loss                12.2722
trainer/Q1 Predictions Mean       -12.338
trainer/Q1 Predictions Std          0.0730554
trainer/Q1 Predictions Max        -12.2444
trainer/Q1 Predictions Min        -12.4952
trainer/Q2 Predictions Mean       -12.3297
trainer/Q2 Predictions Std          0.0747121
trainer/Q2 Predictions Max        -12.2213
trainer/Q2 Predictions Min        -12.4911
trainer/Q Targets Mean            -12.3615
trainer/Q Targets Std               0.157602
trainer/Q Targets Max             -12.1129
trainer/Q Targets Min             -12.8175
trainer/Bellman Errors 1 Mean       0.022558
trainer/Bellman Errors 1 Std        0.0471772
trainer/Bellman Errors 1 Max        0.265043
trainer/Bellman Errors 1 Min        9.36246e-05
trainer/Bellman Errors 2 Mean       0.024701
trainer/Bellman Errors 2 Std        0.0526127
trainer/Bellman Errors 2 Max        0.293748
trainer/Bellman Errors 2 Min        7.21216e-06
trainer/Policy Action Mean         -0.0150303
trainer/Policy Action Std           0.117534
trainer/Policy Action Max           0.496323
trainer/Policy Action Min          -0.222325
exploration/num steps total     55900
exploration/num paths total       559
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136652
exploration/Rewards Std             0.0743259
exploration/Rewards Max            -0.0138769
exploration/Rewards Min            -0.472839
exploration/Returns Mean          -13.6652
exploration/Returns Std             0.56811
exploration/Returns Max           -13.0971
exploration/Returns Min           -14.2333
exploration/Actions Mean            0.00867326
exploration/Actions Std             0.159443
exploration/Actions Max             1
exploration/Actions Min            -0.370062
exploration/Num Paths               2
exploration/Average Returns       -13.6652
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0364961
evaluation/Rewards Std              0.0529556
evaluation/Rewards Max             -0.0316762
evaluation/Rewards Min             -0.794197
evaluation/Returns Mean            -3.64961
evaluation/Returns Std              0.318688
evaluation/Returns Max             -3.22722
evaluation/Returns Min             -3.99845
evaluation/Actions Mean             0.0068142
evaluation/Actions Std              0.0828245
evaluation/Actions Max              0.999855
evaluation/Actions Min             -0.987691
evaluation/Num Paths                5
evaluation/Average Returns         -3.64961
time/data storing (s)               0.00128952
time/evaluation sampling (s)        0.0812348
time/exploration sampling (s)       0.0355098
time/logging (s)                    0.00249168
time/saving (s)                     0.00230292
time/training (s)                   0.462141
time/epoch (s)                      0.584969
time/total (s)                    165.307
Epoch                             278
-----------------------------  ----------------
2019-04-13 17:01:20.129578 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 279 finished
-----------------------------  ----------------
replay_buffer/size              56100
trainer/QF1 Loss                    0.0220758
trainer/QF2 Loss                    0.0248313
trainer/Policy Loss                12.2452
trainer/Q1 Predictions Mean       -12.4212
trainer/Q1 Predictions Std          0.161734
trainer/Q1 Predictions Max        -12.2564
trainer/Q1 Predictions Min        -12.9927
trainer/Q2 Predictions Mean       -12.4161
trainer/Q2 Predictions Std          0.154838
trainer/Q2 Predictions Max        -12.2649
trainer/Q2 Predictions Min        -13.0256
trainer/Q Targets Mean            -12.4248
trainer/Q Targets Std               0.233807
trainer/Q Targets Max             -12.123
trainer/Q Targets Min             -13.2183
trainer/Bellman Errors 1 Mean       0.0220758
trainer/Bellman Errors 1 Std        0.0410711
trainer/Bellman Errors 1 Max        0.216228
trainer/Bellman Errors 1 Min        1.60435e-07
trainer/Bellman Errors 2 Mean       0.0248313
trainer/Bellman Errors 2 Std        0.0486244
trainer/Bellman Errors 2 Max        0.223802
trainer/Bellman Errors 2 Min        1.18198e-08
trainer/Policy Action Mean          0.0265217
trainer/Policy Action Std           0.173845
trainer/Policy Action Max           0.868763
trainer/Policy Action Min          -0.421449
exploration/num steps total     56100
exploration/num paths total       561
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130362
exploration/Rewards Std             0.0822229
exploration/Rewards Max            -0.012662
exploration/Rewards Min            -0.805766
exploration/Returns Mean          -13.0362
exploration/Returns Std             0.703965
exploration/Returns Max           -12.3323
exploration/Returns Min           -13.7402
exploration/Actions Mean            0.00277164
exploration/Actions Std             0.14955
exploration/Actions Max             0.855969
exploration/Actions Min            -0.629932
exploration/Num Paths               2
exploration/Average Returns       -13.0362
evaluation/num steps total     140000
evaluation/num paths total       1400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0270074
evaluation/Rewards Std              0.0464085
evaluation/Rewards Max             -0.0158985
evaluation/Rewards Min             -0.818977
evaluation/Returns Mean            -2.70074
evaluation/Returns Std              0.359334
evaluation/Returns Max             -2.36463
evaluation/Returns Min             -3.21092
evaluation/Actions Mean             0.00701441
evaluation/Actions Std              0.0783629
evaluation/Actions Max              0.999904
evaluation/Actions Min             -0.471173
evaluation/Num Paths                5
evaluation/Average Returns         -2.70074
time/data storing (s)               0.00105496
time/evaluation sampling (s)        0.0775713
time/exploration sampling (s)       0.0337461
time/logging (s)                    0.00249075
time/saving (s)                     0.00199938
time/training (s)                   0.39399
time/epoch (s)                      0.510852
time/total (s)                    165.822
Epoch                             279
-----------------------------  ----------------
2019-04-13 17:01:20.660773 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 280 finished
-----------------------------  ----------------
replay_buffer/size              56300
trainer/QF1 Loss                    0.0573026
trainer/QF2 Loss                    0.0580798
trainer/Policy Loss                12.4386
trainer/Q1 Predictions Mean       -12.5566
trainer/Q1 Predictions Std          0.0971649
trainer/Q1 Predictions Max        -12.43
trainer/Q1 Predictions Min        -12.7748
trainer/Q2 Predictions Mean       -12.5548
trainer/Q2 Predictions Std          0.0918565
trainer/Q2 Predictions Max        -12.4323
trainer/Q2 Predictions Min        -12.7795
trainer/Q Targets Mean            -12.3974
trainer/Q Targets Std               0.180025
trainer/Q Targets Max             -12.0847
trainer/Q Targets Min             -12.8072
trainer/Bellman Errors 1 Mean       0.0573026
trainer/Bellman Errors 1 Std        0.0678848
trainer/Bellman Errors 1 Max        0.365364
trainer/Bellman Errors 1 Min        3.45225e-05
trainer/Bellman Errors 2 Mean       0.0580798
trainer/Bellman Errors 2 Std        0.0734685
trainer/Bellman Errors 2 Max        0.400103
trainer/Bellman Errors 2 Min        8.9789e-05
trainer/Policy Action Mean         -0.0172486
trainer/Policy Action Std           0.121606
trainer/Policy Action Max           0.4533
trainer/Policy Action Min          -0.390683
exploration/num steps total     56300
exploration/num paths total       563
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.120865
exploration/Rewards Std             0.0694793
exploration/Rewards Max            -0.00617189
exploration/Rewards Min            -0.393724
exploration/Returns Mean          -12.0865
exploration/Returns Std             0.799344
exploration/Returns Max           -11.2871
exploration/Returns Min           -12.8858
exploration/Actions Mean            0.00672659
exploration/Actions Std             0.139827
exploration/Actions Max             0.870263
exploration/Actions Min            -0.420924
exploration/Num Paths               2
exploration/Average Returns       -12.0865
evaluation/num steps total     140500
evaluation/num paths total       1405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0552262
evaluation/Rewards Std              0.0443985
evaluation/Rewards Max             -0.0374009
evaluation/Rewards Min             -0.767861
evaluation/Returns Mean            -5.52262
evaluation/Returns Std              0.302261
evaluation/Returns Max             -5.22841
evaluation/Returns Min             -5.92066
evaluation/Actions Mean             0.00620616
evaluation/Actions Std              0.0888942
evaluation/Actions Max              0.999858
evaluation/Actions Min             -0.977287
evaluation/Num Paths                5
evaluation/Average Returns         -5.52262
time/data storing (s)               0.00113327
time/evaluation sampling (s)        0.0770862
time/exploration sampling (s)       0.0343361
time/logging (s)                    0.00250187
time/saving (s)                     0.00227343
time/training (s)                   0.405507
time/epoch (s)                      0.522838
time/total (s)                    166.349
Epoch                             280
-----------------------------  ----------------
2019-04-13 17:01:21.355305 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 281 finished
-----------------------------  ----------------
replay_buffer/size              56500
trainer/QF1 Loss                    0.0416595
trainer/QF2 Loss                    0.0392681
trainer/Policy Loss                12.2941
trainer/Q1 Predictions Mean       -12.426
trainer/Q1 Predictions Std          0.153203
trainer/Q1 Predictions Max        -12.2906
trainer/Q1 Predictions Min        -13.1932
trainer/Q2 Predictions Mean       -12.4257
trainer/Q2 Predictions Std          0.160297
trainer/Q2 Predictions Max        -12.287
trainer/Q2 Predictions Min        -13.2074
trainer/Q Targets Mean            -12.4091
trainer/Q Targets Std               0.247719
trainer/Q Targets Max             -12.1191
trainer/Q Targets Min             -13.1372
trainer/Bellman Errors 1 Mean       0.0416595
trainer/Bellman Errors 1 Std        0.0954784
trainer/Bellman Errors 1 Max        0.543686
trainer/Bellman Errors 1 Min        2.72203e-08
trainer/Bellman Errors 2 Mean       0.0392681
trainer/Bellman Errors 2 Std        0.0918457
trainer/Bellman Errors 2 Max        0.520672
trainer/Bellman Errors 2 Min        3.4377e-05
trainer/Policy Action Mean          0.00956896
trainer/Policy Action Std           0.108857
trainer/Policy Action Max           0.272593
trainer/Policy Action Min          -0.451831
exploration/num steps total     56500
exploration/num paths total       565
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136066
exploration/Rewards Std             0.0806445
exploration/Rewards Max            -0.0021577
exploration/Rewards Min            -0.42005
exploration/Returns Mean          -13.6066
exploration/Returns Std             0.472246
exploration/Returns Max           -13.1344
exploration/Returns Min           -14.0789
exploration/Actions Mean            0.00745776
exploration/Actions Std             0.160472
exploration/Actions Max             0.918783
exploration/Actions Min            -0.36761
exploration/Num Paths               2
exploration/Average Returns       -13.6066
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0464231
evaluation/Rewards Std              0.068348
evaluation/Rewards Max             -0.0334008
evaluation/Rewards Min             -0.996564
evaluation/Returns Mean            -4.64231
evaluation/Returns Std              0.42114
evaluation/Returns Max             -4.08824
evaluation/Returns Min             -5.05941
evaluation/Actions Mean             0.00632898
evaluation/Actions Std              0.0853355
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.931758
evaluation/Num Paths                5
evaluation/Average Returns         -4.64231
time/data storing (s)               0.00117918
time/evaluation sampling (s)        0.0821553
time/exploration sampling (s)       0.0352259
time/logging (s)                    0.00250024
time/saving (s)                     0.00248168
time/training (s)                   0.562773
time/epoch (s)                      0.686315
time/total (s)                    167.039
Epoch                             281
-----------------------------  ----------------
2019-04-13 17:01:21.899003 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 282 finished
-----------------------------  ----------------
replay_buffer/size              56700
trainer/QF1 Loss                    0.0309701
trainer/QF2 Loss                    0.0293664
trainer/Policy Loss                12.4077
trainer/Q1 Predictions Mean       -12.524
trainer/Q1 Predictions Std          0.114402
trainer/Q1 Predictions Max        -12.3735
trainer/Q1 Predictions Min        -12.8655
trainer/Q2 Predictions Mean       -12.5168
trainer/Q2 Predictions Std          0.114913
trainer/Q2 Predictions Max        -12.3781
trainer/Q2 Predictions Min        -12.8877
trainer/Q Targets Mean            -12.4467
trainer/Q Targets Std               0.173375
trainer/Q Targets Max             -12.1603
trainer/Q Targets Min             -12.8695
trainer/Bellman Errors 1 Mean       0.0309701
trainer/Bellman Errors 1 Std        0.0415203
trainer/Bellman Errors 1 Max        0.173577
trainer/Bellman Errors 1 Min        2.13055e-07
trainer/Bellman Errors 2 Mean       0.0293664
trainer/Bellman Errors 2 Std        0.0437867
trainer/Bellman Errors 2 Max        0.188056
trainer/Bellman Errors 2 Min        7.09284e-05
trainer/Policy Action Mean         -0.0143442
trainer/Policy Action Std           0.108396
trainer/Policy Action Max           0.197202
trainer/Policy Action Min          -0.434235
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140583
exploration/Rewards Std             0.106863
exploration/Rewards Max            -0.0100461
exploration/Rewards Min            -1.00074
exploration/Returns Mean          -14.0583
exploration/Returns Std             0.712842
exploration/Returns Max           -13.3455
exploration/Returns Min           -14.7712
exploration/Actions Mean            0.0110828
exploration/Actions Std             0.166639
exploration/Actions Max             1
exploration/Actions Min            -0.614558
exploration/Num Paths               2
exploration/Average Returns       -14.0583
evaluation/num steps total     141500
evaluation/num paths total       1415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0327661
evaluation/Rewards Std              0.0433724
evaluation/Rewards Max             -0.0238383
evaluation/Rewards Min             -0.87911
evaluation/Returns Mean            -3.27661
evaluation/Returns Std              0.278588
evaluation/Returns Max             -3.02267
evaluation/Returns Min             -3.78534
evaluation/Actions Mean             0.00544076
evaluation/Actions Std              0.0894959
evaluation/Actions Max              0.999976
evaluation/Actions Min             -0.979292
evaluation/Num Paths                5
evaluation/Average Returns         -3.27661
time/data storing (s)               0.00112296
time/evaluation sampling (s)        0.073831
time/exploration sampling (s)       0.0336485
time/logging (s)                    0.00628286
time/saving (s)                     0.00288714
time/training (s)                   0.421802
time/epoch (s)                      0.539575
time/total (s)                    167.583
Epoch                             282
-----------------------------  ----------------
2019-04-13 17:01:23.133313 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 283 finished
-----------------------------  ----------------
replay_buffer/size              56900
trainer/QF1 Loss                    0.0358827
trainer/QF2 Loss                    0.036705
trainer/Policy Loss                12.282
trainer/Q1 Predictions Mean       -12.4084
trainer/Q1 Predictions Std          0.237235
trainer/Q1 Predictions Max        -12.2373
trainer/Q1 Predictions Min        -13.626
trainer/Q2 Predictions Mean       -12.4215
trainer/Q2 Predictions Std          0.241837
trainer/Q2 Predictions Max        -12.2476
trainer/Q2 Predictions Min        -13.638
trainer/Q Targets Mean            -12.4676
trainer/Q Targets Std               0.319787
trainer/Q Targets Max             -12.1143
trainer/Q Targets Min             -13.8509
trainer/Bellman Errors 1 Mean       0.0358827
trainer/Bellman Errors 1 Std        0.0781819
trainer/Bellman Errors 1 Max        0.446896
trainer/Bellman Errors 1 Min        9.7073e-06
trainer/Bellman Errors 2 Mean       0.036705
trainer/Bellman Errors 2 Std        0.0808686
trainer/Bellman Errors 2 Max        0.461432
trainer/Bellman Errors 2 Min        9.70136e-05
trainer/Policy Action Mean          0.0445252
trainer/Policy Action Std           0.146955
trainer/Policy Action Max           0.68052
trainer/Policy Action Min          -0.478621
exploration/num steps total     56900
exploration/num paths total       569
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136501
exploration/Rewards Std             0.0751312
exploration/Rewards Max            -0.00528727
exploration/Rewards Min            -0.410245
exploration/Returns Mean          -13.6501
exploration/Returns Std             0.422081
exploration/Returns Max           -13.228
exploration/Returns Min           -14.0722
exploration/Actions Mean            0.00348939
exploration/Actions Std             0.154888
exploration/Actions Max             0.90321
exploration/Actions Min            -0.862991
exploration/Num Paths               2
exploration/Average Returns       -13.6501
evaluation/num steps total     142000
evaluation/num paths total       1420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0654062
evaluation/Rewards Std              0.014264
evaluation/Rewards Max             -0.0311397
evaluation/Rewards Min             -0.355087
evaluation/Returns Mean            -6.54062
evaluation/Returns Std              0.0986755
evaluation/Returns Max             -6.44331
evaluation/Returns Min             -6.71595
evaluation/Actions Mean             0.00432819
evaluation/Actions Std              0.0725602
evaluation/Actions Max              0.999305
evaluation/Actions Min             -0.959113
evaluation/Num Paths                5
evaluation/Average Returns         -6.54062
time/data storing (s)               0.00201158
time/evaluation sampling (s)        0.23581
time/exploration sampling (s)       0.0831926
time/logging (s)                    0.00317974
time/saving (s)                     0.00251224
time/training (s)                   0.890501
time/epoch (s)                      1.21721
time/total (s)                    168.809
Epoch                             283
-----------------------------  ----------------
2019-04-13 17:01:24.281571 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 284 finished
-----------------------------  ----------------
replay_buffer/size              57100
trainer/QF1 Loss                    0.117625
trainer/QF2 Loss                    0.108974
trainer/Policy Loss                12.1024
trainer/Q1 Predictions Mean       -12.2712
trainer/Q1 Predictions Std          0.622426
trainer/Q1 Predictions Max        -12.0095
trainer/Q1 Predictions Min        -15.4491
trainer/Q2 Predictions Mean       -12.2839
trainer/Q2 Predictions Std          0.632312
trainer/Q2 Predictions Max        -12.0308
trainer/Q2 Predictions Min        -15.5221
trainer/Q Targets Mean            -12.5555
trainer/Q Targets Std               0.675322
trainer/Q Targets Max             -12.1504
trainer/Q Targets Min             -15.7788
trainer/Bellman Errors 1 Mean       0.117625
trainer/Bellman Errors 1 Std        0.135214
trainer/Bellman Errors 1 Max        0.502603
trainer/Bellman Errors 1 Min        0.00504887
trainer/Bellman Errors 2 Mean       0.108974
trainer/Bellman Errors 2 Std        0.125986
trainer/Bellman Errors 2 Max        0.44171
trainer/Bellman Errors 2 Min        0.00244426
trainer/Policy Action Mean          0.0426499
trainer/Policy Action Std           0.22277
trainer/Policy Action Max           0.999306
trainer/Policy Action Min          -0.511574
exploration/num steps total     57100
exploration/num paths total       571
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128233
exploration/Rewards Std             0.0760637
exploration/Rewards Max            -0.0104241
exploration/Rewards Min            -0.506945
exploration/Returns Mean          -12.8233
exploration/Returns Std             0.538295
exploration/Returns Max           -12.285
exploration/Returns Min           -13.3615
exploration/Actions Mean            0.00336009
exploration/Actions Std             0.16871
exploration/Actions Max             0.997487
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.8233
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0276897
evaluation/Rewards Std              0.0413724
evaluation/Rewards Max             -0.0138555
evaluation/Rewards Min             -0.895622
evaluation/Returns Mean            -2.76897
evaluation/Returns Std              0.334533
evaluation/Returns Max             -2.53112
evaluation/Returns Min             -3.39774
evaluation/Actions Mean             0.000943151
evaluation/Actions Std              0.0753269
evaluation/Actions Max              0.999995
evaluation/Actions Min             -0.966537
evaluation/Num Paths                5
evaluation/Average Returns         -2.76897
time/data storing (s)               0.00185266
time/evaluation sampling (s)        0.175227
time/exploration sampling (s)       0.108192
time/logging (s)                    0.0142136
time/saving (s)                     0.00563123
time/training (s)                   0.841076
time/epoch (s)                      1.14619
time/total (s)                    169.961
Epoch                             284
-----------------------------  ----------------
2019-04-13 17:01:25.434734 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 285 finished
-----------------------------  ----------------
replay_buffer/size              57300
trainer/QF1 Loss                    9.22806
trainer/QF2 Loss                    9.27311
trainer/Policy Loss                12.1912
trainer/Q1 Predictions Mean       -12.3842
trainer/Q1 Predictions Std          0.28104
trainer/Q1 Predictions Max        -12.1764
trainer/Q1 Predictions Min        -13.4232
trainer/Q2 Predictions Mean       -12.385
trainer/Q2 Predictions Std          0.271117
trainer/Q2 Predictions Max        -12.197
trainer/Q2 Predictions Min        -13.4174
trainer/Q Targets Mean            -11.7346
trainer/Q Targets Std               3.00533
trainer/Q Targets Max              -0.102563
trainer/Q Targets Min             -13.4054
trainer/Bellman Errors 1 Mean       9.22806
trainer/Bellman Errors 1 Std       35.5671
trainer/Bellman Errors 1 Max      147.063
trainer/Bellman Errors 1 Min        3.83789e-05
trainer/Bellman Errors 2 Mean       9.27311
trainer/Bellman Errors 2 Std       35.7372
trainer/Bellman Errors 2 Max      147.87
trainer/Bellman Errors 2 Min        1.13274e-06
trainer/Policy Action Mean         -0.00329079
trainer/Policy Action Std           0.208901
trainer/Policy Action Max           0.775953
trainer/Policy Action Min          -0.531132
exploration/num steps total     57300
exploration/num paths total       573
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133281
exploration/Rewards Std             0.0723027
exploration/Rewards Max            -0.00804728
exploration/Rewards Min            -0.485881
exploration/Returns Mean          -13.3281
exploration/Returns Std             0.118174
exploration/Returns Max           -13.2099
exploration/Returns Min           -13.4462
exploration/Actions Mean            0.00792398
exploration/Actions Std             0.155139
exploration/Actions Max             1
exploration/Actions Min            -0.409953
exploration/Num Paths               2
exploration/Average Returns       -13.3281
evaluation/num steps total     143000
evaluation/num paths total       1430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0594141
evaluation/Rewards Std              0.0217622
evaluation/Rewards Max             -0.0530894
evaluation/Rewards Min             -0.52285
evaluation/Returns Mean            -5.94141
evaluation/Returns Std              0.182764
evaluation/Returns Max             -5.79173
evaluation/Returns Min             -6.29936
evaluation/Actions Mean             0.00570278
evaluation/Actions Std              0.0684268
evaluation/Actions Max              0.998857
evaluation/Actions Min             -0.721403
evaluation/Num Paths                5
evaluation/Average Returns         -5.94141
time/data storing (s)               0.00329168
time/evaluation sampling (s)        0.212818
time/exploration sampling (s)       0.0811506
time/logging (s)                    0.00249848
time/saving (s)                     0.00230855
time/training (s)                   0.81905
time/epoch (s)                      1.12112
time/total (s)                    171.096
Epoch                             285
-----------------------------  ----------------
2019-04-13 17:01:26.077313 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 286 finished
-----------------------------  ----------------
replay_buffer/size              57500
trainer/QF1 Loss                    0.0617682
trainer/QF2 Loss                    0.0596978
trainer/Policy Loss                12.2132
trainer/Q1 Predictions Mean       -12.3139
trainer/Q1 Predictions Std          0.173473
trainer/Q1 Predictions Max        -12.1221
trainer/Q1 Predictions Min        -12.9332
trainer/Q2 Predictions Mean       -12.3138
trainer/Q2 Predictions Std          0.178812
trainer/Q2 Predictions Max        -12.1269
trainer/Q2 Predictions Min        -12.9297
trainer/Q Targets Mean            -12.4507
trainer/Q Targets Std               0.322444
trainer/Q Targets Max             -12.1284
trainer/Q Targets Min             -13.8445
trainer/Bellman Errors 1 Mean       0.0617682
trainer/Bellman Errors 1 Std        0.170912
trainer/Bellman Errors 1 Max        0.966349
trainer/Bellman Errors 1 Min        2.37488e-07
trainer/Bellman Errors 2 Mean       0.0596978
trainer/Bellman Errors 2 Std        0.16273
trainer/Bellman Errors 2 Max        0.920976
trainer/Bellman Errors 2 Min        1.15007e-05
trainer/Policy Action Mean          0.0110454
trainer/Policy Action Std           0.134082
trainer/Policy Action Max           0.273795
trainer/Policy Action Min          -0.450041
exploration/num steps total     57500
exploration/num paths total       575
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129782
exploration/Rewards Std             0.0713174
exploration/Rewards Max            -0.0166715
exploration/Rewards Min            -0.496981
exploration/Returns Mean          -12.9782
exploration/Returns Std             0.615151
exploration/Returns Max           -12.363
exploration/Returns Min           -13.5933
exploration/Actions Mean            0.0069055
exploration/Actions Std             0.16065
exploration/Actions Max             1
exploration/Actions Min            -0.772715
exploration/Num Paths               2
exploration/Average Returns       -12.9782
evaluation/num steps total     143500
evaluation/num paths total       1435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0511452
evaluation/Rewards Std              0.0554261
evaluation/Rewards Max             -0.0386802
evaluation/Rewards Min             -0.802865
evaluation/Returns Mean            -5.11452
evaluation/Returns Std              0.370114
evaluation/Returns Max             -4.62822
evaluation/Returns Min             -5.4625
evaluation/Actions Mean             0.010531
evaluation/Actions Std              0.0889269
evaluation/Actions Max              0.999971
evaluation/Actions Min             -0.0474106
evaluation/Num Paths                5
evaluation/Average Returns         -5.11452
time/data storing (s)               0.00128913
time/evaluation sampling (s)        0.0842366
time/exploration sampling (s)       0.039676
time/logging (s)                    0.00249893
time/saving (s)                     0.00247881
time/training (s)                   0.504257
time/epoch (s)                      0.634437
time/total (s)                    171.735
Epoch                             286
-----------------------------  ----------------
2019-04-13 17:01:26.713404 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 287 finished
-----------------------------  ----------------
replay_buffer/size              57700
trainer/QF1 Loss                    4.67038
trainer/QF2 Loss                    4.65267
trainer/Policy Loss                12.0618
trainer/Q1 Predictions Mean       -12.1931
trainer/Q1 Predictions Std          0.151973
trainer/Q1 Predictions Max        -12.0452
trainer/Q1 Predictions Min        -12.7292
trainer/Q2 Predictions Mean       -12.1942
trainer/Q2 Predictions Std          0.150693
trainer/Q2 Predictions Max        -12.0394
trainer/Q2 Predictions Min        -12.7238
trainer/Q Targets Mean            -12.1061
trainer/Q Targets Std               2.18096
trainer/Q Targets Max              -0.0558934
trainer/Q Targets Min             -13.4087
trainer/Bellman Errors 1 Mean       4.67038
trainer/Bellman Errors 1 Std       25.2314
trainer/Bellman Errors 1 Max      145.149
trainer/Bellman Errors 1 Min        0.000296841
trainer/Bellman Errors 2 Mean       4.65267
trainer/Bellman Errors 2 Std       25.1434
trainer/Bellman Errors 2 Max      144.642
trainer/Bellman Errors 2 Min        0.000878937
trainer/Policy Action Mean          0.0102463
trainer/Policy Action Std           0.127074
trainer/Policy Action Max           0.300456
trainer/Policy Action Min          -0.458094
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126914
exploration/Rewards Std             0.0698919
exploration/Rewards Max            -0.0150821
exploration/Rewards Min            -0.586946
exploration/Returns Mean          -12.6914
exploration/Returns Std             0.676673
exploration/Returns Max           -12.0148
exploration/Returns Min           -13.3681
exploration/Actions Mean            0.00436515
exploration/Actions Std             0.1467
exploration/Actions Max             1
exploration/Actions Min            -0.407868
exploration/Num Paths               2
exploration/Average Returns       -12.6914
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.041407
evaluation/Rewards Std              0.0572171
evaluation/Rewards Max             -0.0369187
evaluation/Rewards Min             -0.946392
evaluation/Returns Mean            -4.1407
evaluation/Returns Std              0.402949
evaluation/Returns Max             -3.72183
evaluation/Returns Min             -4.64778
evaluation/Actions Mean             0.00854462
evaluation/Actions Std              0.0844429
evaluation/Actions Max              0.999989
evaluation/Actions Min             -0.169171
evaluation/Num Paths                5
evaluation/Average Returns         -4.1407
time/data storing (s)               0.00118165
time/evaluation sampling (s)        0.0761468
time/exploration sampling (s)       0.03578
time/logging (s)                    0.00247719
time/saving (s)                     0.00238646
time/training (s)                   0.509781
time/epoch (s)                      0.627753
time/total (s)                    172.366
Epoch                             287
-----------------------------  ----------------
2019-04-13 17:01:27.355655 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 288 finished
-----------------------------  ----------------
replay_buffer/size              57900
trainer/QF1 Loss                    4.74085
trainer/QF2 Loss                    4.74442
trainer/Policy Loss                12.2404
trainer/Q1 Predictions Mean       -12.3799
trainer/Q1 Predictions Std          0.140083
trainer/Q1 Predictions Max        -12.2533
trainer/Q1 Predictions Min        -13.0869
trainer/Q2 Predictions Mean       -12.3826
trainer/Q2 Predictions Std          0.145766
trainer/Q2 Predictions Max        -12.2671
trainer/Q2 Predictions Min        -13.0983
trainer/Q Targets Mean            -12.0357
trainer/Q Targets Std               2.15887
trainer/Q Targets Max              -0.0593254
trainer/Q Targets Min             -13.0402
trainer/Bellman Errors 1 Mean       4.74085
trainer/Bellman Errors 1 Std       26.2921
trainer/Bellman Errors 1 Max      151.129
trainer/Bellman Errors 1 Min        5.51733e-06
trainer/Bellman Errors 2 Mean       4.74442
trainer/Bellman Errors 2 Std       26.3121
trainer/Bellman Errors 2 Max      151.244
trainer/Bellman Errors 2 Min        4.28005e-07
trainer/Policy Action Mean          0.0248208
trainer/Policy Action Std           0.116562
trainer/Policy Action Max           0.275549
trainer/Policy Action Min          -0.399368
exploration/num steps total     57900
exploration/num paths total       579
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135529
exploration/Rewards Std             0.0752161
exploration/Rewards Max            -0.0103884
exploration/Rewards Min            -0.419054
exploration/Returns Mean          -13.5529
exploration/Returns Std             1.71467
exploration/Returns Max           -11.8382
exploration/Returns Min           -15.2676
exploration/Actions Mean           -0.00262805
exploration/Actions Std             0.154261
exploration/Actions Max             0.776437
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.5529
evaluation/num steps total     144500
evaluation/num paths total       1445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0643333
evaluation/Rewards Std              0.0509832
evaluation/Rewards Max             -0.0455272
evaluation/Rewards Min             -0.79425
evaluation/Returns Mean            -6.43333
evaluation/Returns Std              0.296743
evaluation/Returns Max             -6.09246
evaluation/Returns Min             -6.75648
evaluation/Actions Mean             0.0065085
evaluation/Actions Std              0.0867388
evaluation/Actions Max              0.999931
evaluation/Actions Min             -0.863028
evaluation/Num Paths                5
evaluation/Average Returns         -6.43333
time/data storing (s)               0.00148708
time/evaluation sampling (s)        0.0801296
time/exploration sampling (s)       0.0342335
time/logging (s)                    0.00252781
time/saving (s)                     0.00226939
time/training (s)                   0.51328
time/epoch (s)                      0.633928
time/total (s)                    173.004
Epoch                             288
-----------------------------  ----------------
2019-04-13 17:01:27.952737 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 289 finished
-----------------------------  ----------------
replay_buffer/size              58100
trainer/QF1 Loss                    0.0233102
trainer/QF2 Loss                    0.0264513
trainer/Policy Loss                12.381
trainer/Q1 Predictions Mean       -12.5312
trainer/Q1 Predictions Std          0.331526
trainer/Q1 Predictions Max        -12.3233
trainer/Q1 Predictions Min        -13.9821
trainer/Q2 Predictions Mean       -12.5295
trainer/Q2 Predictions Std          0.315107
trainer/Q2 Predictions Max        -12.3178
trainer/Q2 Predictions Min        -13.8357
trainer/Q Targets Mean            -12.5605
trainer/Q Targets Std               0.380135
trainer/Q Targets Max             -12.1593
trainer/Q Targets Min             -14.1891
trainer/Bellman Errors 1 Mean       0.0233102
trainer/Bellman Errors 1 Std        0.0300691
trainer/Bellman Errors 1 Max        0.133453
trainer/Bellman Errors 1 Min        3.65692e-05
trainer/Bellman Errors 2 Mean       0.0264513
trainer/Bellman Errors 2 Std        0.0338941
trainer/Bellman Errors 2 Max        0.124925
trainer/Bellman Errors 2 Min        8.58392e-05
trainer/Policy Action Mean          0.025057
trainer/Policy Action Std           0.193694
trainer/Policy Action Max           0.651118
trainer/Policy Action Min          -0.981587
exploration/num steps total     58100
exploration/num paths total       581
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143009
exploration/Rewards Std             0.0821875
exploration/Rewards Max            -0.00600817
exploration/Rewards Min            -0.580626
exploration/Returns Mean          -14.3009
exploration/Returns Std             0.0853327
exploration/Returns Max           -14.2156
exploration/Returns Min           -14.3863
exploration/Actions Mean            0.00701925
exploration/Actions Std             0.157679
exploration/Actions Max             1
exploration/Actions Min            -0.409392
exploration/Num Paths               2
exploration/Average Returns       -14.3009
evaluation/num steps total     145000
evaluation/num paths total       1450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0690848
evaluation/Rewards Std              0.0548056
evaluation/Rewards Max             -0.0370268
evaluation/Rewards Min             -0.87409
evaluation/Returns Mean            -6.90848
evaluation/Returns Std              0.337973
evaluation/Returns Max             -6.51671
evaluation/Returns Min             -7.29887
evaluation/Actions Mean             0.00635738
evaluation/Actions Std              0.0870837
evaluation/Actions Max              0.999979
evaluation/Actions Min             -0.779672
evaluation/Num Paths                5
evaluation/Average Returns         -6.90848
time/data storing (s)               0.00112344
time/evaluation sampling (s)        0.0769207
time/exploration sampling (s)       0.0330707
time/logging (s)                    0.002486
time/saving (s)                     0.00226252
time/training (s)                   0.472921
time/epoch (s)                      0.588785
time/total (s)                    173.597
Epoch                             289
-----------------------------  ----------------
2019-04-13 17:01:28.533654 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 290 finished
-----------------------------  ----------------
replay_buffer/size              58300
trainer/QF1 Loss                    0.0393174
trainer/QF2 Loss                    0.0369777
trainer/Policy Loss                12.3513
trainer/Q1 Predictions Mean       -12.4833
trainer/Q1 Predictions Std          0.401168
trainer/Q1 Predictions Max        -12.2611
trainer/Q1 Predictions Min        -14.4728
trainer/Q2 Predictions Mean       -12.4864
trainer/Q2 Predictions Std          0.381989
trainer/Q2 Predictions Max        -12.2822
trainer/Q2 Predictions Min        -14.3776
trainer/Q Targets Mean            -12.5587
trainer/Q Targets Std               0.408751
trainer/Q Targets Max             -12.1504
trainer/Q Targets Min             -14.3742
trainer/Bellman Errors 1 Mean       0.0393174
trainer/Bellman Errors 1 Std        0.0746676
trainer/Bellman Errors 1 Max        0.321467
trainer/Bellman Errors 1 Min        1.71704e-05
trainer/Bellman Errors 2 Mean       0.0369777
trainer/Bellman Errors 2 Std        0.0702725
trainer/Bellman Errors 2 Max        0.310349
trainer/Bellman Errors 2 Min        1.14942e-05
trainer/Policy Action Mean          0.00128336
trainer/Policy Action Std           0.218495
trainer/Policy Action Max           0.952987
trainer/Policy Action Min          -0.997764
exploration/num steps total     58300
exploration/num paths total       583
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137328
exploration/Rewards Std             0.0685866
exploration/Rewards Max            -0.0105274
exploration/Rewards Min            -0.435543
exploration/Returns Mean          -13.7328
exploration/Returns Std             0.571347
exploration/Returns Max           -13.1615
exploration/Returns Min           -14.3042
exploration/Actions Mean            0.00424918
exploration/Actions Std             0.155448
exploration/Actions Max             0.965576
exploration/Actions Min            -0.885295
exploration/Num Paths               2
exploration/Average Returns       -13.7328
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0434389
evaluation/Rewards Std              0.0242435
evaluation/Rewards Max             -0.0386967
evaluation/Rewards Min             -0.551585
evaluation/Returns Mean            -4.34389
evaluation/Returns Std              0.212862
evaluation/Returns Max             -4.18489
evaluation/Returns Min             -4.74691
evaluation/Actions Mean             0.00369093
evaluation/Actions Std              0.0654182
evaluation/Actions Max              0.999514
evaluation/Actions Min             -0.875127
evaluation/Num Paths                5
evaluation/Average Returns         -4.34389
time/data storing (s)               0.00113031
time/evaluation sampling (s)        0.0732142
time/exploration sampling (s)       0.0330164
time/logging (s)                    0.00245692
time/saving (s)                     0.00226417
time/training (s)                   0.460567
time/epoch (s)                      0.572649
time/total (s)                    174.174
Epoch                             290
-----------------------------  ----------------
2019-04-13 17:01:29.142198 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 291 finished
-----------------------------  ----------------
replay_buffer/size              58500
trainer/QF1 Loss                    0.0238982
trainer/QF2 Loss                    0.0230736
trainer/Policy Loss                12.3647
trainer/Q1 Predictions Mean       -12.5067
trainer/Q1 Predictions Std          0.162624
trainer/Q1 Predictions Max        -12.3638
trainer/Q1 Predictions Min        -13.2451
trainer/Q2 Predictions Mean       -12.5052
trainer/Q2 Predictions Std          0.158296
trainer/Q2 Predictions Max        -12.3681
trainer/Q2 Predictions Min        -13.213
trainer/Q Targets Mean            -12.404
trainer/Q Targets Std               0.142939
trainer/Q Targets Max             -12.227
trainer/Q Targets Min             -12.9332
trainer/Bellman Errors 1 Mean       0.0238982
trainer/Bellman Errors 1 Std        0.0268765
trainer/Bellman Errors 1 Max        0.118115
trainer/Bellman Errors 1 Min        2.43663e-05
trainer/Bellman Errors 2 Mean       0.0230736
trainer/Bellman Errors 2 Std        0.0253152
trainer/Bellman Errors 2 Max        0.115358
trainer/Bellman Errors 2 Min        1.73765e-05
trainer/Policy Action Mean          0.0466527
trainer/Policy Action Std           0.173264
trainer/Policy Action Max           0.999728
trainer/Policy Action Min          -0.17895
exploration/num steps total     58500
exploration/num paths total       585
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142188
exploration/Rewards Std             0.0747742
exploration/Rewards Max            -0.0153856
exploration/Rewards Min            -0.587074
exploration/Returns Mean          -14.2188
exploration/Returns Std             0.558486
exploration/Returns Max           -13.6604
exploration/Returns Min           -14.7773
exploration/Actions Mean            0.00751196
exploration/Actions Std             0.144509
exploration/Actions Max             1
exploration/Actions Min            -0.309889
exploration/Num Paths               2
exploration/Average Returns       -14.2188
evaluation/num steps total     146000
evaluation/num paths total       1460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0618584
evaluation/Rewards Std              0.011052
evaluation/Rewards Max             -0.0456733
evaluation/Rewards Min             -0.282057
evaluation/Returns Mean            -6.18584
evaluation/Returns Std              0.0709124
evaluation/Returns Max             -6.13684
evaluation/Returns Min             -6.32243
evaluation/Actions Mean             0.00701173
evaluation/Actions Std              0.073941
evaluation/Actions Max              0.985019
evaluation/Actions Min             -0.37792
evaluation/Num Paths                5
evaluation/Average Returns         -6.18584
time/data storing (s)               0.00120133
time/evaluation sampling (s)        0.0730861
time/exploration sampling (s)       0.0413991
time/logging (s)                    0.00247139
time/saving (s)                     0.00257171
time/training (s)                   0.479635
time/epoch (s)                      0.600364
time/total (s)                    174.778
Epoch                             291
-----------------------------  ----------------
2019-04-13 17:01:29.722012 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 292 finished
-----------------------------  ----------------
replay_buffer/size              58700
trainer/QF1 Loss                    4.66265
trainer/QF2 Loss                    4.65481
trainer/Policy Loss                12.0551
trainer/Q1 Predictions Mean       -12.3087
trainer/Q1 Predictions Std          0.441353
trainer/Q1 Predictions Max        -12.0799
trainer/Q1 Predictions Min        -14.6471
trainer/Q2 Predictions Mean       -12.3104
trainer/Q2 Predictions Std          0.454146
trainer/Q2 Predictions Max        -12.0419
trainer/Q2 Predictions Min        -14.7041
trainer/Q Targets Mean            -12.186
trainer/Q Targets Std               2.21615
trainer/Q Targets Max              -0.102563
trainer/Q Targets Min             -14.7594
trainer/Bellman Errors 1 Mean       4.66265
trainer/Bellman Errors 1 Std       25.4156
trainer/Bellman Errors 1 Max      146.17
trainer/Bellman Errors 1 Min        4.64176e-05
trainer/Bellman Errors 2 Mean       4.65481
trainer/Bellman Errors 2 Std       25.3606
trainer/Bellman Errors 2 Max      145.855
trainer/Bellman Errors 2 Min        3.08597e-05
trainer/Policy Action Mean          0.0428089
trainer/Policy Action Std           0.166293
trainer/Policy Action Max           0.997466
trainer/Policy Action Min          -0.450904
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.162668
exploration/Rewards Std             0.08841
exploration/Rewards Max            -0.0263287
exploration/Rewards Min            -0.787934
exploration/Returns Mean          -16.2668
exploration/Returns Std             0.782079
exploration/Returns Max           -15.4848
exploration/Returns Min           -17.0489
exploration/Actions Mean            0.00311382
exploration/Actions Std             0.161475
exploration/Actions Max             1
exploration/Actions Min            -0.946756
exploration/Num Paths               2
exploration/Average Returns       -16.2668
evaluation/num steps total     146500
evaluation/num paths total       1465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.092376
evaluation/Rewards Std              0.0279237
evaluation/Rewards Max             -0.0762266
evaluation/Rewards Min             -0.709261
evaluation/Returns Mean            -9.2376
evaluation/Returns Std              0.252105
evaluation/Returns Max             -9.06801
evaluation/Returns Min             -9.73934
evaluation/Actions Mean             0.00655677
evaluation/Actions Std              0.0789683
evaluation/Actions Max              0.99981
evaluation/Actions Min             -0.955127
evaluation/Num Paths                5
evaluation/Average Returns         -9.2376
time/data storing (s)               0.00124972
time/evaluation sampling (s)        0.0751637
time/exploration sampling (s)       0.0415947
time/logging (s)                    0.00245299
time/saving (s)                     0.00204357
time/training (s)                   0.449046
time/epoch (s)                      0.57155
time/total (s)                    175.353
Epoch                             292
-----------------------------  ----------------
2019-04-13 17:01:30.293030 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 293 finished
-----------------------------  ----------------
replay_buffer/size              58900
trainer/QF1 Loss                    0.0265602
trainer/QF2 Loss                    0.0261311
trainer/Policy Loss                12.3016
trainer/Q1 Predictions Mean       -12.4243
trainer/Q1 Predictions Std          0.0802313
trainer/Q1 Predictions Max        -12.2927
trainer/Q1 Predictions Min        -12.6638
trainer/Q2 Predictions Mean       -12.4274
trainer/Q2 Predictions Std          0.0775636
trainer/Q2 Predictions Max        -12.297
trainer/Q2 Predictions Min        -12.6867
trainer/Q Targets Mean            -12.4947
trainer/Q Targets Std               0.14281
trainer/Q Targets Max             -12.254
trainer/Q Targets Min             -12.769
trainer/Bellman Errors 1 Mean       0.0265602
trainer/Bellman Errors 1 Std        0.0377468
trainer/Bellman Errors 1 Max        0.177418
trainer/Bellman Errors 1 Min        6.62222e-05
trainer/Bellman Errors 2 Mean       0.0261311
trainer/Bellman Errors 2 Std        0.0377571
trainer/Bellman Errors 2 Max        0.188143
trainer/Bellman Errors 2 Min        0.000165952
trainer/Policy Action Mean          0.0015206
trainer/Policy Action Std           0.105663
trainer/Policy Action Max           0.44405
trainer/Policy Action Min          -0.208265
exploration/num steps total     58900
exploration/num paths total       589
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124088
exploration/Rewards Std             0.0734872
exploration/Rewards Max            -0.00965058
exploration/Rewards Min            -0.517332
exploration/Returns Mean          -12.4088
exploration/Returns Std             0.137441
exploration/Returns Max           -12.2714
exploration/Returns Min           -12.5463
exploration/Actions Mean            0.00229511
exploration/Actions Std             0.160792
exploration/Actions Max             0.956052
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.4088
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0372733
evaluation/Rewards Std              0.0230421
evaluation/Rewards Max             -0.0119372
evaluation/Rewards Min             -0.525193
evaluation/Returns Mean            -3.72733
evaluation/Returns Std              0.193009
evaluation/Returns Max             -3.57653
evaluation/Returns Min             -4.1049
evaluation/Actions Mean             0.00293154
evaluation/Actions Std              0.065529
evaluation/Actions Max              0.998964
evaluation/Actions Min             -0.847532
evaluation/Num Paths                5
evaluation/Average Returns         -3.72733
time/data storing (s)               0.00116726
time/evaluation sampling (s)        0.0762219
time/exploration sampling (s)       0.0344026
time/logging (s)                    0.00187773
time/saving (s)                     0.00182142
time/training (s)                   0.446646
time/epoch (s)                      0.562137
time/total (s)                    175.919
Epoch                             293
-----------------------------  ----------------
2019-04-13 17:01:30.869761 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 294 finished
-----------------------------  ----------------
replay_buffer/size              59100
trainer/QF1 Loss                    0.0506623
trainer/QF2 Loss                    0.0472948
trainer/Policy Loss                12.4615
trainer/Q1 Predictions Mean       -12.6628
trainer/Q1 Predictions Std          0.484875
trainer/Q1 Predictions Max        -12.4276
trainer/Q1 Predictions Min        -15.2016
trainer/Q2 Predictions Mean       -12.6713
trainer/Q2 Predictions Std          0.494251
trainer/Q2 Predictions Max        -12.4356
trainer/Q2 Predictions Min        -15.2682
trainer/Q Targets Mean            -12.671
trainer/Q Targets Std               0.663875
trainer/Q Targets Max             -12.2714
trainer/Q Targets Min             -16.0096
trainer/Bellman Errors 1 Mean       0.0506623
trainer/Bellman Errors 1 Std        0.119884
trainer/Bellman Errors 1 Max        0.652874
trainer/Bellman Errors 1 Min        1.16499e-05
trainer/Bellman Errors 2 Mean       0.0472948
trainer/Bellman Errors 2 Std        0.104091
trainer/Bellman Errors 2 Max        0.549729
trainer/Bellman Errors 2 Min        8.22548e-05
trainer/Policy Action Mean          0.0530149
trainer/Policy Action Std           0.211559
trainer/Policy Action Max           0.991618
trainer/Policy Action Min          -0.458753
exploration/num steps total     59100
exploration/num paths total       591
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124061
exploration/Rewards Std             0.0735982
exploration/Rewards Max            -0.00532672
exploration/Rewards Min            -0.634916
exploration/Returns Mean          -12.4061
exploration/Returns Std             0.473111
exploration/Returns Max           -11.933
exploration/Returns Min           -12.8792
exploration/Actions Mean            0.00630015
exploration/Actions Std             0.135364
exploration/Actions Max             0.729488
exploration/Actions Min            -0.393604
exploration/Num Paths               2
exploration/Average Returns       -12.4061
evaluation/num steps total     147500
evaluation/num paths total       1475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0491008
evaluation/Rewards Std              0.0344451
evaluation/Rewards Max             -0.0102186
evaluation/Rewards Min             -0.78145
evaluation/Returns Mean            -4.91008
evaluation/Returns Std              0.255039
evaluation/Returns Max             -4.72518
evaluation/Returns Min             -5.40646
evaluation/Actions Mean             0.00640821
evaluation/Actions Std              0.0753198
evaluation/Actions Max              0.999931
evaluation/Actions Min             -0.551078
evaluation/Num Paths                5
evaluation/Average Returns         -4.91008
time/data storing (s)               0.00109297
time/evaluation sampling (s)        0.0735604
time/exploration sampling (s)       0.0327064
time/logging (s)                    0.00247833
time/saving (s)                     0.00224551
time/training (s)                   0.457424
time/epoch (s)                      0.569507
time/total (s)                    176.493
Epoch                             294
-----------------------------  ----------------
2019-04-13 17:01:31.454986 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 295 finished
-----------------------------  ---------------
replay_buffer/size              59300
trainer/QF1 Loss                    5.11783
trainer/QF2 Loss                    5.15842
trainer/Policy Loss                12.5612
trainer/Q1 Predictions Mean       -12.7513
trainer/Q1 Predictions Std          0.520784
trainer/Q1 Predictions Max        -12.5353
trainer/Q1 Predictions Min        -15.5567
trainer/Q2 Predictions Mean       -12.749
trainer/Q2 Predictions Std          0.512834
trainer/Q2 Predictions Max        -12.5254
trainer/Q2 Predictions Min        -15.4918
trainer/Q Targets Mean            -12.197
trainer/Q Targets Std               2.16786
trainer/Q Targets Max              -0.564059
trainer/Q Targets Min             -15.6874
trainer/Bellman Errors 1 Mean       5.11783
trainer/Bellman Errors 1 Std       28.2468
trainer/Bellman Errors 1 Max      162.389
trainer/Bellman Errors 1 Min        0.00179545
trainer/Bellman Errors 2 Mean       5.15842
trainer/Bellman Errors 2 Std       28.4658
trainer/Bellman Errors 2 Max      163.649
trainer/Bellman Errors 2 Min        0.00265258
trainer/Policy Action Mean          0.0307695
trainer/Policy Action Std           0.214343
trainer/Policy Action Max           0.997801
trainer/Policy Action Min          -0.460555
exploration/num steps total     59300
exploration/num paths total       593
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142733
exploration/Rewards Std             0.0821577
exploration/Rewards Max            -0.0128779
exploration/Rewards Min            -0.662101
exploration/Returns Mean          -14.2733
exploration/Returns Std             0.406513
exploration/Returns Max           -13.8668
exploration/Returns Min           -14.6798
exploration/Actions Mean            0.00164911
exploration/Actions Std             0.166074
exploration/Actions Max             0.904708
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.2733
evaluation/num steps total     148000
evaluation/num paths total       1480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0441243
evaluation/Rewards Std              0.018443
evaluation/Rewards Max             -0.00968244
evaluation/Rewards Min             -0.446794
evaluation/Returns Mean            -4.41243
evaluation/Returns Std              0.144847
evaluation/Returns Max             -4.28604
evaluation/Returns Min             -4.69619
evaluation/Actions Mean             0.00327153
evaluation/Actions Std              0.0549373
evaluation/Actions Max              0.998557
evaluation/Actions Min             -0.421249
evaluation/Num Paths                5
evaluation/Average Returns         -4.41243
time/data storing (s)               0.00125845
time/evaluation sampling (s)        0.0711778
time/exploration sampling (s)       0.0333059
time/logging (s)                    0.00245365
time/saving (s)                     0.00227518
time/training (s)                   0.466631
time/epoch (s)                      0.577102
time/total (s)                    177.073
Epoch                             295
-----------------------------  ---------------
2019-04-13 17:01:32.028392 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 296 finished
-----------------------------  ----------------
replay_buffer/size              59500
trainer/QF1 Loss                    0.033321
trainer/QF2 Loss                    0.0339081
trainer/Policy Loss                12.5295
trainer/Q1 Predictions Mean       -12.6461
trainer/Q1 Predictions Std          0.143662
trainer/Q1 Predictions Max        -12.5153
trainer/Q1 Predictions Min        -13.3522
trainer/Q2 Predictions Mean       -12.6512
trainer/Q2 Predictions Std          0.149201
trainer/Q2 Predictions Max        -12.5182
trainer/Q2 Predictions Min        -13.3917
trainer/Q Targets Mean            -12.5929
trainer/Q Targets Std               0.230591
trainer/Q Targets Max             -12.2552
trainer/Q Targets Min             -13.3242
trainer/Bellman Errors 1 Mean       0.033321
trainer/Bellman Errors 1 Std        0.0362167
trainer/Bellman Errors 1 Max        0.114189
trainer/Bellman Errors 1 Min        1.93454e-05
trainer/Bellman Errors 2 Mean       0.0339081
trainer/Bellman Errors 2 Std        0.035948
trainer/Bellman Errors 2 Max        0.11132
trainer/Bellman Errors 2 Min        3.67424e-05
trainer/Policy Action Mean          0.0256291
trainer/Policy Action Std           0.131564
trainer/Policy Action Max           0.286241
trainer/Policy Action Min          -0.469504
exploration/num steps total     59500
exploration/num paths total       595
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133866
exploration/Rewards Std             0.0968894
exploration/Rewards Max            -0.0116127
exploration/Rewards Min            -1.05757
exploration/Returns Mean          -13.3866
exploration/Returns Std             0.425805
exploration/Returns Max           -12.9608
exploration/Returns Min           -13.8124
exploration/Actions Mean            0.00568379
exploration/Actions Std             0.160751
exploration/Actions Max             0.97767
exploration/Actions Min            -0.669809
exploration/Num Paths               2
exploration/Average Returns       -13.3866
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0472875
evaluation/Rewards Std              0.0267514
evaluation/Rewards Max             -0.0269992
evaluation/Rewards Min             -0.539011
evaluation/Returns Mean            -4.72875
evaluation/Returns Std              0.155434
evaluation/Returns Max             -4.53427
evaluation/Returns Min             -5.0119
evaluation/Actions Mean             0.00255467
evaluation/Actions Std              0.083093
evaluation/Actions Max              0.999918
evaluation/Actions Min             -0.981372
evaluation/Num Paths                5
evaluation/Average Returns         -4.72875
time/data storing (s)               0.0012006
time/evaluation sampling (s)        0.074798
time/exploration sampling (s)       0.0327947
time/logging (s)                    0.00247792
time/saving (s)                     0.0023631
time/training (s)                   0.451358
time/epoch (s)                      0.564992
time/total (s)                    177.643
Epoch                             296
-----------------------------  ----------------
2019-04-13 17:01:32.608115 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 297 finished
-----------------------------  ----------------
replay_buffer/size              59700
trainer/QF1 Loss                    4.78314
trainer/QF2 Loss                    4.7893
trainer/Policy Loss                12.387
trainer/Q1 Predictions Mean       -12.5635
trainer/Q1 Predictions Std          0.17993
trainer/Q1 Predictions Max        -12.4033
trainer/Q1 Predictions Min        -13.2617
trainer/Q2 Predictions Mean       -12.5714
trainer/Q2 Predictions Std          0.181549
trainer/Q2 Predictions Max        -12.411
trainer/Q2 Predictions Min        -13.2822
trainer/Q Targets Mean            -12.175
trainer/Q Targets Std               2.18698
trainer/Q Targets Max              -0.051155
trainer/Q Targets Min             -13.1938
trainer/Bellman Errors 1 Mean       4.78314
trainer/Bellman Errors 1 Std       26.5444
trainer/Bellman Errors 1 Max      152.576
trainer/Bellman Errors 1 Min        0.000297499
trainer/Bellman Errors 2 Mean       4.78929
trainer/Bellman Errors 2 Std       26.5775
trainer/Bellman Errors 2 Max      152.767
trainer/Bellman Errors 2 Min        5.86304e-05
trainer/Policy Action Mean         -0.00557451
trainer/Policy Action Std           0.113045
trainer/Policy Action Max           0.287198
trainer/Policy Action Min          -0.415889
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.13014
exploration/Rewards Std             0.0667809
exploration/Rewards Max            -0.00560122
exploration/Rewards Min            -0.310209
exploration/Returns Mean          -13.014
exploration/Returns Std             0.165114
exploration/Returns Max           -12.8489
exploration/Returns Min           -13.1791
exploration/Actions Mean            0.00231769
exploration/Actions Std             0.143208
exploration/Actions Max             0.669671
exploration/Actions Min            -0.446245
exploration/Num Paths               2
exploration/Average Returns       -13.014
evaluation/num steps total     149000
evaluation/num paths total       1490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0333912
evaluation/Rewards Std              0.0298348
evaluation/Rewards Max             -0.0100119
evaluation/Rewards Min             -0.641695
evaluation/Returns Mean            -3.33912
evaluation/Returns Std              0.227241
evaluation/Returns Max             -3.14932
evaluation/Returns Min             -3.76714
evaluation/Actions Mean             0.00633581
evaluation/Actions Std              0.0720202
evaluation/Actions Max              0.999677
evaluation/Actions Min             -0.492391
evaluation/Num Paths                5
evaluation/Average Returns         -3.33912
time/data storing (s)               0.00110657
time/evaluation sampling (s)        0.0732946
time/exploration sampling (s)       0.0331464
time/logging (s)                    0.00247273
time/saving (s)                     0.00224346
time/training (s)                   0.459099
time/epoch (s)                      0.571363
time/total (s)                    178.218
Epoch                             297
-----------------------------  ----------------
2019-04-13 17:01:33.182086 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 298 finished
-----------------------------  ----------------
replay_buffer/size              59900
trainer/QF1 Loss                    0.0451558
trainer/QF2 Loss                    0.0471402
trainer/Policy Loss                12.3148
trainer/Q1 Predictions Mean       -12.4773
trainer/Q1 Predictions Std          0.464994
trainer/Q1 Predictions Max        -12.3032
trainer/Q1 Predictions Min        -15.0333
trainer/Q2 Predictions Mean       -12.4788
trainer/Q2 Predictions Std          0.450424
trainer/Q2 Predictions Max        -12.2821
trainer/Q2 Predictions Min        -14.9491
trainer/Q Targets Mean            -12.6216
trainer/Q Targets Std               0.540893
trainer/Q Targets Max             -12.2847
trainer/Q Targets Min             -15.5084
trainer/Bellman Errors 1 Mean       0.0451558
trainer/Bellman Errors 1 Std        0.0725259
trainer/Bellman Errors 1 Max        0.313195
trainer/Bellman Errors 1 Min        1.50178e-06
trainer/Bellman Errors 2 Mean       0.0471402
trainer/Bellman Errors 2 Std        0.0784181
trainer/Bellman Errors 2 Max        0.312835
trainer/Bellman Errors 2 Min        1.11031e-05
trainer/Policy Action Mean          0.0446825
trainer/Policy Action Std           0.178254
trainer/Policy Action Max           0.997337
trainer/Policy Action Min          -0.242567
exploration/num steps total     59900
exploration/num paths total       599
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127254
exploration/Rewards Std             0.0787193
exploration/Rewards Max            -0.00525026
exploration/Rewards Min            -0.778442
exploration/Returns Mean          -12.7254
exploration/Returns Std             0.479024
exploration/Returns Max           -12.2464
exploration/Returns Min           -13.2044
exploration/Actions Mean            0.00513672
exploration/Actions Std             0.156832
exploration/Actions Max             1
exploration/Actions Min            -0.91099
exploration/Num Paths               2
exploration/Average Returns       -12.7254
evaluation/num steps total     149500
evaluation/num paths total       1495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0447523
evaluation/Rewards Std              0.0238595
evaluation/Rewards Max             -0.0284473
evaluation/Rewards Min             -0.558256
evaluation/Returns Mean            -4.47523
evaluation/Returns Std              0.188005
evaluation/Returns Max             -4.3547
evaluation/Returns Min             -4.84594
evaluation/Actions Mean             0.00577852
evaluation/Actions Std              0.0687685
evaluation/Actions Max              0.999563
evaluation/Actions Min             -0.869413
evaluation/Num Paths                5
evaluation/Average Returns         -4.47523
time/data storing (s)               0.00105352
time/evaluation sampling (s)        0.074329
time/exploration sampling (s)       0.0333749
time/logging (s)                    0.00249103
time/saving (s)                     0.0022571
time/training (s)                   0.452169
time/epoch (s)                      0.565675
time/total (s)                    178.787
Epoch                             298
-----------------------------  ----------------
2019-04-13 17:01:33.776487 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 299 finished
-----------------------------  ----------------
replay_buffer/size              60100
trainer/QF1 Loss                    0.0335245
trainer/QF2 Loss                    0.0352934
trainer/Policy Loss                12.4936
trainer/Q1 Predictions Mean       -12.7274
trainer/Q1 Predictions Std          0.651183
trainer/Q1 Predictions Max        -12.438
trainer/Q1 Predictions Min        -15.3636
trainer/Q2 Predictions Mean       -12.724
trainer/Q2 Predictions Std          0.623188
trainer/Q2 Predictions Max        -12.4441
trainer/Q2 Predictions Min        -15.2527
trainer/Q Targets Mean            -12.8089
trainer/Q Targets Std               0.662693
trainer/Q Targets Max             -12.3048
trainer/Q Targets Min             -15.6365
trainer/Bellman Errors 1 Mean       0.0335245
trainer/Bellman Errors 1 Std        0.0465177
trainer/Bellman Errors 1 Max        0.188323
trainer/Bellman Errors 1 Min        2.07805e-07
trainer/Bellman Errors 2 Mean       0.0352934
trainer/Bellman Errors 2 Std        0.0505631
trainer/Bellman Errors 2 Max        0.20729
trainer/Bellman Errors 2 Min        8.07738e-05
trainer/Policy Action Mean          0.0593748
trainer/Policy Action Std           0.317629
trainer/Policy Action Max           0.998355
trainer/Policy Action Min          -0.993111
exploration/num steps total     60100
exploration/num paths total       601
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134964
exploration/Rewards Std             0.0754917
exploration/Rewards Max            -0.0125478
exploration/Rewards Min            -0.443219
exploration/Returns Mean          -13.4964
exploration/Returns Std             0.409554
exploration/Returns Max           -13.0869
exploration/Returns Min           -13.906
exploration/Actions Mean            0.00446599
exploration/Actions Std             0.162825
exploration/Actions Max             1
exploration/Actions Min            -0.866739
exploration/Num Paths               2
exploration/Average Returns       -13.4964
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0524911
evaluation/Rewards Std              0.0198095
evaluation/Rewards Max             -0.0314287
evaluation/Rewards Min             -0.474182
evaluation/Returns Mean            -5.24911
evaluation/Returns Std              0.157888
evaluation/Returns Max             -5.12202
evaluation/Returns Min             -5.55582
evaluation/Actions Mean             0.00472855
evaluation/Actions Std              0.0716813
evaluation/Actions Max              0.999366
evaluation/Actions Min             -0.891002
evaluation/Num Paths                5
evaluation/Average Returns         -5.24911
time/data storing (s)               0.00113457
time/evaluation sampling (s)        0.075166
time/exploration sampling (s)       0.0345447
time/logging (s)                    0.00248595
time/saving (s)                     0.00247318
time/training (s)                   0.470519
time/epoch (s)                      0.586323
time/total (s)                    179.378
Epoch                             299
-----------------------------  ----------------
2019-04-13 17:01:34.382406 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 300 finished
-----------------------------  ----------------
replay_buffer/size              60300
trainer/QF1 Loss                    0.0468595
trainer/QF2 Loss                    0.0473106
trainer/Policy Loss                12.3599
trainer/Q1 Predictions Mean       -12.5211
trainer/Q1 Predictions Std          0.304983
trainer/Q1 Predictions Max        -12.3527
trainer/Q1 Predictions Min        -14.0295
trainer/Q2 Predictions Mean       -12.5161
trainer/Q2 Predictions Std          0.271533
trainer/Q2 Predictions Max        -12.3715
trainer/Q2 Predictions Min        -13.8315
trainer/Q Targets Mean            -12.6323
trainer/Q Targets Std               0.321528
trainer/Q Targets Max             -12.306
trainer/Q Targets Min             -13.8993
trainer/Bellman Errors 1 Mean       0.0468595
trainer/Bellman Errors 1 Std        0.0822095
trainer/Bellman Errors 1 Max        0.27936
trainer/Bellman Errors 1 Min        3.38423e-05
trainer/Bellman Errors 2 Mean       0.0473106
trainer/Bellman Errors 2 Std        0.0830125
trainer/Bellman Errors 2 Max        0.265114
trainer/Bellman Errors 2 Min        9.61326e-05
trainer/Policy Action Mean          0.0392659
trainer/Policy Action Std           0.212262
trainer/Policy Action Max           0.991443
trainer/Policy Action Min          -0.965446
exploration/num steps total     60300
exploration/num paths total       603
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.157102
exploration/Rewards Std             0.0820615
exploration/Rewards Max            -0.00946193
exploration/Rewards Min            -0.448739
exploration/Returns Mean          -15.7102
exploration/Returns Std             0.0684028
exploration/Returns Max           -15.6418
exploration/Returns Min           -15.7786
exploration/Actions Mean            0.00515458
exploration/Actions Std             0.154454
exploration/Actions Max             1
exploration/Actions Min            -0.61899
exploration/Num Paths               2
exploration/Average Returns       -15.7102
evaluation/num steps total     150500
evaluation/num paths total       1505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0739844
evaluation/Rewards Std              0.0210462
evaluation/Rewards Max             -0.0669513
evaluation/Rewards Min             -0.431387
evaluation/Returns Mean            -7.39844
evaluation/Returns Std              0.152333
evaluation/Returns Max             -7.22071
evaluation/Returns Min             -7.60288
evaluation/Actions Mean             0.0075532
evaluation/Actions Std              0.0757642
evaluation/Actions Max              0.998437
evaluation/Actions Min             -0.0969455
evaluation/Num Paths                5
evaluation/Average Returns         -7.39844
time/data storing (s)               0.00112726
time/evaluation sampling (s)        0.0769911
time/exploration sampling (s)       0.0332214
time/logging (s)                    0.00209017
time/saving (s)                     0.00186686
time/training (s)                   0.48168
time/epoch (s)                      0.596977
time/total (s)                    179.979
Epoch                             300
-----------------------------  ----------------
2019-04-13 17:01:35.002778 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 301 finished
-----------------------------  ----------------
replay_buffer/size              60500
trainer/QF1 Loss                    0.0179724
trainer/QF2 Loss                    0.0165008
trainer/Policy Loss                12.4616
trainer/Q1 Predictions Mean       -12.6006
trainer/Q1 Predictions Std          0.466329
trainer/Q1 Predictions Max        -12.4046
trainer/Q1 Predictions Min        -15.1647
trainer/Q2 Predictions Mean       -12.602
trainer/Q2 Predictions Std          0.461495
trainer/Q2 Predictions Max        -12.3866
trainer/Q2 Predictions Min        -15.1194
trainer/Q Targets Mean            -12.6709
trainer/Q Targets Std               0.487556
trainer/Q Targets Max             -12.2735
trainer/Q Targets Min             -15.2611
trainer/Bellman Errors 1 Mean       0.0179724
trainer/Bellman Errors 1 Std        0.0196527
trainer/Bellman Errors 1 Max        0.0690083
trainer/Bellman Errors 1 Min        3.89709e-06
trainer/Bellman Errors 2 Mean       0.0165008
trainer/Bellman Errors 2 Std        0.0181889
trainer/Bellman Errors 2 Max        0.0719465
trainer/Bellman Errors 2 Min        6.01148e-07
trainer/Policy Action Mean          0.0523343
trainer/Policy Action Std           0.176314
trainer/Policy Action Max           0.998092
trainer/Policy Action Min          -0.203529
exploration/num steps total     60500
exploration/num paths total       605
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143701
exploration/Rewards Std             0.08904
exploration/Rewards Max            -0.00915098
exploration/Rewards Min            -0.645373
exploration/Returns Mean          -14.3701
exploration/Returns Std             0.572256
exploration/Returns Max           -13.7979
exploration/Returns Min           -14.9424
exploration/Actions Mean            0.00376465
exploration/Actions Std             0.161158
exploration/Actions Max             1
exploration/Actions Min            -0.966004
exploration/Num Paths               2
exploration/Average Returns       -14.3701
evaluation/num steps total     151000
evaluation/num paths total       1510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0749783
evaluation/Rewards Std              0.0557313
evaluation/Rewards Max             -0.0224535
evaluation/Rewards Min             -1.04818
evaluation/Returns Mean            -7.49783
evaluation/Returns Std              0.315887
evaluation/Returns Max             -7.1324
evaluation/Returns Min             -8.02673
evaluation/Actions Mean             0.00694755
evaluation/Actions Std              0.0882385
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.875345
evaluation/Num Paths                5
evaluation/Average Returns         -7.49783
time/data storing (s)               0.00113661
time/evaluation sampling (s)        0.0825008
time/exploration sampling (s)       0.0331476
time/logging (s)                    0.00256005
time/saving (s)                     0.00221425
time/training (s)                   0.491222
time/epoch (s)                      0.612781
time/total (s)                    180.595
Epoch                             301
-----------------------------  ----------------
2019-04-13 17:01:35.615021 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 302 finished
-----------------------------  ----------------
replay_buffer/size              60700
trainer/QF1 Loss                    0.0895056
trainer/QF2 Loss                    0.0919077
trainer/Policy Loss                12.3407
trainer/Q1 Predictions Mean       -12.4387
trainer/Q1 Predictions Std          0.235809
trainer/Q1 Predictions Max        -12.292
trainer/Q1 Predictions Min        -13.4096
trainer/Q2 Predictions Mean       -12.4321
trainer/Q2 Predictions Std          0.227726
trainer/Q2 Predictions Max        -12.2834
trainer/Q2 Predictions Min        -13.3383
trainer/Q Targets Mean            -12.7031
trainer/Q Targets Std               0.247438
trainer/Q Targets Max             -12.3882
trainer/Q Targets Min             -13.4709
trainer/Bellman Errors 1 Mean       0.0895055
trainer/Bellman Errors 1 Std        0.0847404
trainer/Bellman Errors 1 Max        0.335365
trainer/Bellman Errors 1 Min        4.19561e-05
trainer/Bellman Errors 2 Mean       0.0919077
trainer/Bellman Errors 2 Std        0.0833812
trainer/Bellman Errors 2 Max        0.344017
trainer/Bellman Errors 2 Min        0.00113145
trainer/Policy Action Mean          0.0135424
trainer/Policy Action Std           0.160378
trainer/Policy Action Max           0.520212
trainer/Policy Action Min          -0.524914
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.148109
exploration/Rewards Std             0.0805156
exploration/Rewards Max            -0.00833867
exploration/Rewards Min            -0.692943
exploration/Returns Mean          -14.8109
exploration/Returns Std             1.47531
exploration/Returns Max           -13.3356
exploration/Returns Min           -16.2862
exploration/Actions Mean            0.0093799
exploration/Actions Std             0.15894
exploration/Actions Max             1
exploration/Actions Min            -0.431329
exploration/Num Paths               2
exploration/Average Returns       -14.8109
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0850238
evaluation/Rewards Std              0.0460733
evaluation/Rewards Max             -0.0279854
evaluation/Rewards Min             -0.883389
evaluation/Returns Mean            -8.50238
evaluation/Returns Std              0.338264
evaluation/Returns Max             -8.20174
evaluation/Returns Min             -8.99043
evaluation/Actions Mean             0.00499173
evaluation/Actions Std              0.0645115
evaluation/Actions Max              0.999989
evaluation/Actions Min             -0.127253
evaluation/Num Paths                5
evaluation/Average Returns         -8.50238
time/data storing (s)               0.00120037
time/evaluation sampling (s)        0.0883669
time/exploration sampling (s)       0.0346784
time/logging (s)                    0.00256036
time/saving (s)                     0.00227593
time/training (s)                   0.474727
time/epoch (s)                      0.603809
time/total (s)                    181.203
Epoch                             302
-----------------------------  ----------------
2019-04-13 17:01:36.210323 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 303 finished
-----------------------------  ----------------
replay_buffer/size              60900
trainer/QF1 Loss                    0.0563988
trainer/QF2 Loss                    0.0555266
trainer/Policy Loss                12.4113
trainer/Q1 Predictions Mean       -12.5672
trainer/Q1 Predictions Std          0.568753
trainer/Q1 Predictions Max        -12.3178
trainer/Q1 Predictions Min        -14.8228
trainer/Q2 Predictions Mean       -12.5686
trainer/Q2 Predictions Std          0.570845
trainer/Q2 Predictions Max        -12.3242
trainer/Q2 Predictions Min        -14.8569
trainer/Q Targets Mean            -12.7321
trainer/Q Targets Std               0.561315
trainer/Q Targets Max             -12.2342
trainer/Q Targets Min             -14.9961
trainer/Bellman Errors 1 Mean       0.0563988
trainer/Bellman Errors 1 Std        0.102906
trainer/Bellman Errors 1 Max        0.461601
trainer/Bellman Errors 1 Min        0.000188776
trainer/Bellman Errors 2 Mean       0.0555266
trainer/Bellman Errors 2 Std        0.102928
trainer/Bellman Errors 2 Max        0.469735
trainer/Bellman Errors 2 Min        4.19191e-05
trainer/Policy Action Mean          0.0523325
trainer/Policy Action Std           0.1879
trainer/Policy Action Max           0.997517
trainer/Policy Action Min          -0.244396
exploration/num steps total     60900
exploration/num paths total       609
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136999
exploration/Rewards Std             0.0746386
exploration/Rewards Max            -0.00792677
exploration/Rewards Min            -0.475197
exploration/Returns Mean          -13.6999
exploration/Returns Std             0.175794
exploration/Returns Max           -13.5241
exploration/Returns Min           -13.8757
exploration/Actions Mean            0.00488881
exploration/Actions Std             0.157186
exploration/Actions Max             0.872819
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.6999
evaluation/num steps total     152000
evaluation/num paths total       1520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0678167
evaluation/Rewards Std              0.0228352
evaluation/Rewards Max             -0.0272738
evaluation/Rewards Min             -0.519891
evaluation/Returns Mean            -6.78167
evaluation/Returns Std              0.138463
evaluation/Returns Max             -6.6639
evaluation/Returns Min             -7.04678
evaluation/Actions Mean             0.00247576
evaluation/Actions Std              0.0762139
evaluation/Actions Max              0.999167
evaluation/Actions Min             -0.976297
evaluation/Num Paths                5
evaluation/Average Returns         -6.78167
time/data storing (s)               0.00114478
time/evaluation sampling (s)        0.0786387
time/exploration sampling (s)       0.0348174
time/logging (s)                    0.00253612
time/saving (s)                     0.00202301
time/training (s)                   0.467645
time/epoch (s)                      0.586805
time/total (s)                    181.794
Epoch                             303
-----------------------------  ----------------
2019-04-13 17:01:36.811186 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 304 finished
-----------------------------  ----------------
replay_buffer/size              61100
trainer/QF1 Loss                    0.0841059
trainer/QF2 Loss                    0.0911982
trainer/Policy Loss                12.4849
trainer/Q1 Predictions Mean       -12.4916
trainer/Q1 Predictions Std          0.277465
trainer/Q1 Predictions Max        -12.2923
trainer/Q1 Predictions Min        -13.4371
trainer/Q2 Predictions Mean       -12.4811
trainer/Q2 Predictions Std          0.278805
trainer/Q2 Predictions Max        -12.2971
trainer/Q2 Predictions Min        -13.4889
trainer/Q Targets Mean            -12.7215
trainer/Q Targets Std               0.307621
trainer/Q Targets Max             -12.2763
trainer/Q Targets Min             -13.4356
trainer/Bellman Errors 1 Mean       0.0841059
trainer/Bellman Errors 1 Std        0.108756
trainer/Bellman Errors 1 Max        0.523662
trainer/Bellman Errors 1 Min        0.000109011
trainer/Bellman Errors 2 Mean       0.0911982
trainer/Bellman Errors 2 Std        0.114794
trainer/Bellman Errors 2 Max        0.558027
trainer/Bellman Errors 2 Min        0.000327464
trainer/Policy Action Mean          0.0468796
trainer/Policy Action Std           0.223551
trainer/Policy Action Max           0.999995
trainer/Policy Action Min          -0.665496
exploration/num steps total     61100
exploration/num paths total       611
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126815
exploration/Rewards Std             0.0916346
exploration/Rewards Max            -0.0042103
exploration/Rewards Min            -1.01357
exploration/Returns Mean          -12.6815
exploration/Returns Std             0.00281697
exploration/Returns Max           -12.6787
exploration/Returns Min           -12.6844
exploration/Actions Mean            0.00943155
exploration/Actions Std             0.154373
exploration/Actions Max             1
exploration/Actions Min            -0.347945
exploration/Num Paths               2
exploration/Average Returns       -12.6815
evaluation/num steps total     152500
evaluation/num paths total       1525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0625121
evaluation/Rewards Std              0.0127267
evaluation/Rewards Max             -0.0449679
evaluation/Rewards Min             -0.288919
evaluation/Returns Mean            -6.25121
evaluation/Returns Std              0.0837719
evaluation/Returns Max             -6.155
evaluation/Returns Min             -6.38606
evaluation/Actions Mean             0.00211383
evaluation/Actions Std              0.0673616
evaluation/Actions Max              0.785769
evaluation/Actions Min             -0.958019
evaluation/Num Paths                5
evaluation/Average Returns         -6.25121
time/data storing (s)               0.00118985
time/evaluation sampling (s)        0.0778301
time/exploration sampling (s)       0.0373147
time/logging (s)                    0.00254585
time/saving (s)                     0.00220595
time/training (s)                   0.471284
time/epoch (s)                      0.59237
time/total (s)                    182.39
Epoch                             304
-----------------------------  ----------------
2019-04-13 17:01:37.385761 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 305 finished
-----------------------------  ----------------
replay_buffer/size              61300
trainer/QF1 Loss                    0.0281633
trainer/QF2 Loss                    0.029745
trainer/Policy Loss                12.4225
trainer/Q1 Predictions Mean       -12.5706
trainer/Q1 Predictions Std          0.0759348
trainer/Q1 Predictions Max        -12.4343
trainer/Q1 Predictions Min        -12.74
trainer/Q2 Predictions Mean       -12.5664
trainer/Q2 Predictions Std          0.0820564
trainer/Q2 Predictions Max        -12.4264
trainer/Q2 Predictions Min        -12.7553
trainer/Q Targets Mean            -12.6108
trainer/Q Targets Std               0.193359
trainer/Q Targets Max             -12.3023
trainer/Q Targets Min             -12.9999
trainer/Bellman Errors 1 Mean       0.0281633
trainer/Bellman Errors 1 Std        0.0370382
trainer/Bellman Errors 1 Max        0.184934
trainer/Bellman Errors 1 Min        1.76479e-05
trainer/Bellman Errors 2 Mean       0.029745
trainer/Bellman Errors 2 Std        0.0403437
trainer/Bellman Errors 2 Max        0.200119
trainer/Bellman Errors 2 Min        0.000100043
trainer/Policy Action Mean          0.0130244
trainer/Policy Action Std           0.101392
trainer/Policy Action Max           0.290194
trainer/Policy Action Min          -0.295539
exploration/num steps total     61300
exploration/num paths total       613
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127889
exploration/Rewards Std             0.0694683
exploration/Rewards Max            -0.00330258
exploration/Rewards Min            -0.422829
exploration/Returns Mean          -12.7889
exploration/Returns Std             0.18539
exploration/Returns Max           -12.6035
exploration/Returns Min           -12.9743
exploration/Actions Mean            0.0013253
exploration/Actions Std             0.154129
exploration/Actions Max             1
exploration/Actions Min            -0.993165
exploration/Num Paths               2
exploration/Average Returns       -12.7889
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0202281
evaluation/Rewards Std              0.0110632
evaluation/Rewards Max             -0.0139581
evaluation/Rewards Min             -0.237874
evaluation/Returns Mean            -2.02281
evaluation/Returns Std              0.0820718
evaluation/Returns Max             -1.94676
evaluation/Returns Min             -2.17241
evaluation/Actions Mean             0.00463805
evaluation/Actions Std              0.0642675
evaluation/Actions Max              0.956141
evaluation/Actions Min             -0.62209
evaluation/Num Paths                5
evaluation/Average Returns         -2.02281
time/data storing (s)               0.00111832
time/evaluation sampling (s)        0.0764375
time/exploration sampling (s)       0.0333215
time/logging (s)                    0.00252414
time/saving (s)                     0.00216838
time/training (s)                   0.450602
time/epoch (s)                      0.566171
time/total (s)                    182.96
Epoch                             305
-----------------------------  ----------------
2019-04-13 17:01:37.964665 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 306 finished
-----------------------------  ----------------
replay_buffer/size              61500
trainer/QF1 Loss                    0.0211513
trainer/QF2 Loss                    0.0206971
trainer/Policy Loss                12.6097
trainer/Q1 Predictions Mean       -12.7839
trainer/Q1 Predictions Std          0.497997
trainer/Q1 Predictions Max        -12.5848
trainer/Q1 Predictions Min        -15.5256
trainer/Q2 Predictions Mean       -12.7816
trainer/Q2 Predictions Std          0.475854
trainer/Q2 Predictions Max        -12.5897
trainer/Q2 Predictions Min        -15.3972
trainer/Q Targets Mean            -12.7692
trainer/Q Targets Std               0.505846
trainer/Q Targets Max             -12.4062
trainer/Q Targets Min             -15.4358
trainer/Bellman Errors 1 Mean       0.0211513
trainer/Bellman Errors 1 Std        0.0236528
trainer/Bellman Errors 1 Max        0.0909203
trainer/Bellman Errors 1 Min        3.6974e-05
trainer/Bellman Errors 2 Mean       0.0206971
trainer/Bellman Errors 2 Std        0.0220394
trainer/Bellman Errors 2 Max        0.0795943
trainer/Bellman Errors 2 Min        2.01917e-06
trainer/Policy Action Mean          0.0429167
trainer/Policy Action Std           0.182671
trainer/Policy Action Max           0.997998
trainer/Policy Action Min          -0.222972
exploration/num steps total     61500
exploration/num paths total       615
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131017
exploration/Rewards Std             0.0839479
exploration/Rewards Max            -0.00551185
exploration/Rewards Min            -0.841615
exploration/Returns Mean          -13.1017
exploration/Returns Std             0.370207
exploration/Returns Max           -12.7315
exploration/Returns Min           -13.4719
exploration/Actions Mean            0.00565288
exploration/Actions Std             0.160049
exploration/Actions Max             1
exploration/Actions Min            -0.943656
exploration/Num Paths               2
exploration/Average Returns       -13.1017
evaluation/num steps total     153500
evaluation/num paths total       1535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0402429
evaluation/Rewards Std              0.0112656
evaluation/Rewards Max             -0.0133724
evaluation/Rewards Min             -0.192035
evaluation/Returns Mean            -4.02429
evaluation/Returns Std              0.0667394
evaluation/Returns Max             -3.90227
evaluation/Returns Min             -4.09286
evaluation/Actions Mean             0.00114084
evaluation/Actions Std              0.0706766
evaluation/Actions Max              0.958195
evaluation/Actions Min             -0.99243
evaluation/Num Paths                5
evaluation/Average Returns         -4.02429
time/data storing (s)               0.00107203
time/evaluation sampling (s)        0.0742414
time/exploration sampling (s)       0.0323221
time/logging (s)                    0.0022522
time/saving (s)                     0.00244511
time/training (s)                   0.457891
time/epoch (s)                      0.570224
time/total (s)                    183.534
Epoch                             306
-----------------------------  ----------------
2019-04-13 17:01:38.570827 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 307 finished
-----------------------------  ----------------
replay_buffer/size              61700
trainer/QF1 Loss                    0.0374724
trainer/QF2 Loss                    0.035926
trainer/Policy Loss                12.4016
trainer/Q1 Predictions Mean       -12.5322
trainer/Q1 Predictions Std          0.194696
trainer/Q1 Predictions Max        -12.3675
trainer/Q1 Predictions Min        -13.3035
trainer/Q2 Predictions Mean       -12.5363
trainer/Q2 Predictions Std          0.188969
trainer/Q2 Predictions Max        -12.3583
trainer/Q2 Predictions Min        -13.2634
trainer/Q Targets Mean            -12.6426
trainer/Q Targets Std               0.228892
trainer/Q Targets Max             -12.2531
trainer/Q Targets Min             -13.241
trainer/Bellman Errors 1 Mean       0.0374724
trainer/Bellman Errors 1 Std        0.0550706
trainer/Bellman Errors 1 Max        0.264648
trainer/Bellman Errors 1 Min        3.27418e-05
trainer/Bellman Errors 2 Mean       0.035926
trainer/Bellman Errors 2 Std        0.0530037
trainer/Bellman Errors 2 Max        0.26156
trainer/Bellman Errors 2 Min        0.000116031
trainer/Policy Action Mean         -0.00889089
trainer/Policy Action Std           0.150571
trainer/Policy Action Max           0.32703
trainer/Policy Action Min          -0.48167
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126039
exploration/Rewards Std             0.0656216
exploration/Rewards Max            -0.0144417
exploration/Rewards Min            -0.38596
exploration/Returns Mean          -12.6039
exploration/Returns Std             0.286876
exploration/Returns Max           -12.317
exploration/Returns Min           -12.8907
exploration/Actions Mean            0.00607832
exploration/Actions Std             0.163065
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.6039
evaluation/num steps total     154000
evaluation/num paths total       1540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0184973
evaluation/Rewards Std              0.0473074
evaluation/Rewards Max             -0.00887352
evaluation/Rewards Min             -0.939993
evaluation/Returns Mean            -1.84973
evaluation/Returns Std              0.328372
evaluation/Returns Max             -1.5296
evaluation/Returns Min             -2.45766
evaluation/Actions Mean             0.0065462
evaluation/Actions Std              0.0763104
evaluation/Actions Max              0.999993
evaluation/Actions Min             -0.703457
evaluation/Num Paths                5
evaluation/Average Returns         -1.84973
time/data storing (s)               0.00131392
time/evaluation sampling (s)        0.0802531
time/exploration sampling (s)       0.0365785
time/logging (s)                    0.00248761
time/saving (s)                     0.00225557
time/training (s)                   0.475642
time/epoch (s)                      0.598531
time/total (s)                    184.137
Epoch                             307
-----------------------------  ----------------
2019-04-13 17:01:39.167742 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 308 finished
-----------------------------  ----------------
replay_buffer/size              61900
trainer/QF1 Loss                    0.0378664
trainer/QF2 Loss                    0.0345957
trainer/Policy Loss                12.3841
trainer/Q1 Predictions Mean       -12.5504
trainer/Q1 Predictions Std          0.455871
trainer/Q1 Predictions Max        -12.3552
trainer/Q1 Predictions Min        -15.0552
trainer/Q2 Predictions Mean       -12.5602
trainer/Q2 Predictions Std          0.442625
trainer/Q2 Predictions Max        -12.369
trainer/Q2 Predictions Min        -14.9893
trainer/Q Targets Mean            -12.6369
trainer/Q Targets Std               0.41429
trainer/Q Targets Max             -12.3155
trainer/Q Targets Min             -14.7315
trainer/Bellman Errors 1 Mean       0.0378664
trainer/Bellman Errors 1 Std        0.0587448
trainer/Bellman Errors 1 Max        0.212901
trainer/Bellman Errors 1 Min        1.4531e-06
trainer/Bellman Errors 2 Mean       0.0345957
trainer/Bellman Errors 2 Std        0.0548015
trainer/Bellman Errors 2 Max        0.214203
trainer/Bellman Errors 2 Min        3.38867e-05
trainer/Policy Action Mean          0.0483301
trainer/Policy Action Std           0.178798
trainer/Policy Action Max           0.997805
trainer/Policy Action Min          -0.199418
exploration/num steps total     61900
exploration/num paths total       619
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.125155
exploration/Rewards Std             0.0615023
exploration/Rewards Max            -0.0063838
exploration/Rewards Min            -0.382503
exploration/Returns Mean          -12.5155
exploration/Returns Std             0.523088
exploration/Returns Max           -11.9924
exploration/Returns Min           -13.0386
exploration/Actions Mean            0.0039755
exploration/Actions Std             0.15689
exploration/Actions Max             1
exploration/Actions Min            -0.932753
exploration/Num Paths               2
exploration/Average Returns       -12.5155
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0509751
evaluation/Rewards Std              0.0716201
evaluation/Rewards Max             -0.0358475
evaluation/Rewards Min             -0.948104
evaluation/Returns Mean            -5.09751
evaluation/Returns Std              0.192396
evaluation/Returns Max             -4.81034
evaluation/Returns Min             -5.30432
evaluation/Actions Mean             0.00998019
evaluation/Actions Std              0.094343
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.683213
evaluation/Num Paths                5
evaluation/Average Returns         -5.09751
time/data storing (s)               0.00111118
time/evaluation sampling (s)        0.0750888
time/exploration sampling (s)       0.0330204
time/logging (s)                    0.00244092
time/saving (s)                     0.00175029
time/training (s)                   0.475226
time/epoch (s)                      0.588638
time/total (s)                    184.728
Epoch                             308
-----------------------------  ----------------
2019-04-13 17:01:39.750287 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 309 finished
-----------------------------  ----------------
replay_buffer/size              62100
trainer/QF1 Loss                    4.85678
trainer/QF2 Loss                    4.84994
trainer/Policy Loss                12.4211
trainer/Q1 Predictions Mean       -12.6017
trainer/Q1 Predictions Std          0.406502
trainer/Q1 Predictions Max        -12.4152
trainer/Q1 Predictions Min        -14.8349
trainer/Q2 Predictions Mean       -12.6049
trainer/Q2 Predictions Std          0.436018
trainer/Q2 Predictions Max        -12.4289
trainer/Q2 Predictions Min        -15.0058
trainer/Q Targets Mean            -12.3381
trainer/Q Targets Std               2.2288
trainer/Q Targets Max              -0.121965
trainer/Q Targets Min             -14.7361
trainer/Bellman Errors 1 Mean       4.85678
trainer/Bellman Errors 1 Std       26.8407
trainer/Bellman Errors 1 Max      154.299
trainer/Bellman Errors 1 Min        1.75279e-07
trainer/Bellman Errors 2 Mean       4.84994
trainer/Bellman Errors 2 Std       26.7884
trainer/Bellman Errors 2 Max      154.001
trainer/Bellman Errors 2 Min        2.99608e-06
trainer/Policy Action Mean         -0.00635927
trainer/Policy Action Std           0.194691
trainer/Policy Action Max           0.947914
trainer/Policy Action Min          -0.244405
exploration/num steps total     62100
exploration/num paths total       621
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.146118
exploration/Rewards Std             0.0714202
exploration/Rewards Max            -0.0147929
exploration/Rewards Min            -0.368966
exploration/Returns Mean          -14.6118
exploration/Returns Std             0.100864
exploration/Returns Max           -14.5109
exploration/Returns Min           -14.7126
exploration/Actions Mean            0.00224048
exploration/Actions Std             0.151649
exploration/Actions Max             0.820215
exploration/Actions Min            -0.393515
exploration/Num Paths               2
exploration/Average Returns       -14.6118
evaluation/num steps total     155000
evaluation/num paths total       1550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0563128
evaluation/Rewards Std              0.0261137
evaluation/Rewards Max             -0.0368014
evaluation/Rewards Min             -0.577048
evaluation/Returns Mean            -5.63128
evaluation/Returns Std              0.210191
evaluation/Returns Max             -5.45044
evaluation/Returns Min             -6.03508
evaluation/Actions Mean             0.00283472
evaluation/Actions Std              0.0619385
evaluation/Actions Max              0.999337
evaluation/Actions Min             -0.981225
evaluation/Num Paths                5
evaluation/Average Returns         -5.63128
time/data storing (s)               0.001061
time/evaluation sampling (s)        0.0776181
time/exploration sampling (s)       0.0344548
time/logging (s)                    0.00250836
time/saving (s)                     0.00224331
time/training (s)                   0.457525
time/epoch (s)                      0.575411
time/total (s)                    185.307
Epoch                             309
-----------------------------  ----------------
2019-04-13 17:01:40.326898 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 310 finished
-----------------------------  ----------------
replay_buffer/size              62300
trainer/QF1 Loss                    0.0156759
trainer/QF2 Loss                    0.016067
trainer/Policy Loss                12.45
trainer/Q1 Predictions Mean       -12.6096
trainer/Q1 Predictions Std          0.0722907
trainer/Q1 Predictions Max        -12.4951
trainer/Q1 Predictions Min        -12.805
trainer/Q2 Predictions Mean       -12.6094
trainer/Q2 Predictions Std          0.0765477
trainer/Q2 Predictions Max        -12.498
trainer/Q2 Predictions Min        -12.8226
trainer/Q Targets Mean            -12.6097
trainer/Q Targets Std               0.144371
trainer/Q Targets Max             -12.3817
trainer/Q Targets Min             -13.0025
trainer/Bellman Errors 1 Mean       0.0156759
trainer/Bellman Errors 1 Std        0.0213928
trainer/Bellman Errors 1 Max        0.10045
trainer/Bellman Errors 1 Min        2.27283e-05
trainer/Bellman Errors 2 Mean       0.016067
trainer/Bellman Errors 2 Std        0.0224366
trainer/Bellman Errors 2 Max        0.103771
trainer/Bellman Errors 2 Min        3.56409e-05
trainer/Policy Action Mean         -0.0126804
trainer/Policy Action Std           0.124098
trainer/Policy Action Max           0.569554
trainer/Policy Action Min          -0.223264
exploration/num steps total     62300
exploration/num paths total       623
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133566
exploration/Rewards Std             0.0672121
exploration/Rewards Max            -0.00907656
exploration/Rewards Min            -0.318363
exploration/Returns Mean          -13.3566
exploration/Returns Std             0.162811
exploration/Returns Max           -13.1938
exploration/Returns Min           -13.5194
exploration/Actions Mean            0.00214426
exploration/Actions Std             0.153245
exploration/Actions Max             1
exploration/Actions Min            -0.79709
exploration/Num Paths               2
exploration/Average Returns       -13.3566
evaluation/num steps total     155500
evaluation/num paths total       1555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0326491
evaluation/Rewards Std              0.0141833
evaluation/Rewards Max             -0.0312761
evaluation/Rewards Min             -0.27357
evaluation/Returns Mean            -3.26491
evaluation/Returns Std              0.0686276
evaluation/Returns Max             -3.18208
evaluation/Returns Min             -3.38052
evaluation/Actions Mean             0.00226661
evaluation/Actions Std              0.0698401
evaluation/Actions Max              0.963148
evaluation/Actions Min             -0.987654
evaluation/Num Paths                5
evaluation/Average Returns         -3.26491
time/data storing (s)               0.00114188
time/evaluation sampling (s)        0.0756522
time/exploration sampling (s)       0.0345681
time/logging (s)                    0.00249577
time/saving (s)                     0.00224789
time/training (s)                   0.452013
time/epoch (s)                      0.568119
time/total (s)                    185.879
Epoch                             310
-----------------------------  ----------------
2019-04-13 17:01:40.900417 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 311 finished
-----------------------------  ----------------
replay_buffer/size              62500
trainer/QF1 Loss                    0.0416874
trainer/QF2 Loss                    0.0417392
trainer/Policy Loss                12.4018
trainer/Q1 Predictions Mean       -12.5047
trainer/Q1 Predictions Std          0.108049
trainer/Q1 Predictions Max        -12.3425
trainer/Q1 Predictions Min        -12.8493
trainer/Q2 Predictions Mean       -12.502
trainer/Q2 Predictions Std          0.116148
trainer/Q2 Predictions Max        -12.3518
trainer/Q2 Predictions Min        -12.8789
trainer/Q Targets Mean            -12.6644
trainer/Q Targets Std               0.159537
trainer/Q Targets Max             -12.3726
trainer/Q Targets Min             -13.2394
trainer/Bellman Errors 1 Mean       0.0416874
trainer/Bellman Errors 1 Std        0.0454043
trainer/Bellman Errors 1 Max        0.15519
trainer/Bellman Errors 1 Min        0.000716869
trainer/Bellman Errors 2 Mean       0.0417392
trainer/Bellman Errors 2 Std        0.0435611
trainer/Bellman Errors 2 Max        0.135368
trainer/Bellman Errors 2 Min        0.000143202
trainer/Policy Action Mean         -0.00412565
trainer/Policy Action Std           0.0947676
trainer/Policy Action Max           0.239452
trainer/Policy Action Min          -0.26095
exploration/num steps total     62500
exploration/num paths total       625
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12581
exploration/Rewards Std             0.0640816
exploration/Rewards Max            -0.00837874
exploration/Rewards Min            -0.308548
exploration/Returns Mean          -12.581
exploration/Returns Std             0.0614764
exploration/Returns Max           -12.5195
exploration/Returns Min           -12.6425
exploration/Actions Mean            0.00600784
exploration/Actions Std             0.146555
exploration/Actions Max             0.827932
exploration/Actions Min            -0.35463
exploration/Num Paths               2
exploration/Average Returns       -12.581
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0327691
evaluation/Rewards Std              0.023765
evaluation/Rewards Max             -0.0272132
evaluation/Rewards Min             -0.509106
evaluation/Returns Mean            -3.27691
evaluation/Returns Std              0.174049
evaluation/Returns Max             -3.09176
evaluation/Returns Min             -3.59829
evaluation/Actions Mean             0.00338326
evaluation/Actions Std              0.079574
evaluation/Actions Max              0.999238
evaluation/Actions Min             -0.992723
evaluation/Num Paths                5
evaluation/Average Returns         -3.27691
time/data storing (s)               0.00111585
time/evaluation sampling (s)        0.0730774
time/exploration sampling (s)       0.0332585
time/logging (s)                    0.00250316
time/saving (s)                     0.00226924
time/training (s)                   0.453403
time/epoch (s)                      0.565627
time/total (s)                    186.448
Epoch                             311
-----------------------------  ----------------
2019-04-13 17:01:41.485496 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 312 finished
-----------------------------  ----------------
replay_buffer/size              62700
trainer/QF1 Loss                    0.0714406
trainer/QF2 Loss                    0.0716997
trainer/Policy Loss                12.1872
trainer/Q1 Predictions Mean       -12.3282
trainer/Q1 Predictions Std          0.0943546
trainer/Q1 Predictions Max        -12.1838
trainer/Q1 Predictions Min        -12.5646
trainer/Q2 Predictions Mean       -12.3299
trainer/Q2 Predictions Std          0.0987164
trainer/Q2 Predictions Max        -12.1975
trainer/Q2 Predictions Min        -12.5773
trainer/Q Targets Mean            -12.5664
trainer/Q Targets Std               0.139827
trainer/Q Targets Max             -12.3067
trainer/Q Targets Min             -12.9098
trainer/Bellman Errors 1 Mean       0.0714405
trainer/Bellman Errors 1 Std        0.0651337
trainer/Bellman Errors 1 Max        0.301732
trainer/Bellman Errors 1 Min        0.00363343
trainer/Bellman Errors 2 Mean       0.0716998
trainer/Bellman Errors 2 Std        0.0652939
trainer/Bellman Errors 2 Max        0.304188
trainer/Bellman Errors 2 Min        0.00236625
trainer/Policy Action Mean         -0.00066139
trainer/Policy Action Std           0.151519
trainer/Policy Action Max           0.778963
trainer/Policy Action Min          -0.349295
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130894
exploration/Rewards Std             0.0676096
exploration/Rewards Max            -0.000208316
exploration/Rewards Min            -0.388764
exploration/Returns Mean          -13.0894
exploration/Returns Std             0.141624
exploration/Returns Max           -12.9478
exploration/Returns Min           -13.2311
exploration/Actions Mean            0.00335487
exploration/Actions Std             0.135175
exploration/Actions Max             0.709085
exploration/Actions Min            -0.348978
exploration/Num Paths               2
exploration/Average Returns       -13.0894
evaluation/num steps total     156500
evaluation/num paths total       1565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0394685
evaluation/Rewards Std              0.045474
evaluation/Rewards Max             -0.0354179
evaluation/Rewards Min             -0.841554
evaluation/Returns Mean            -3.94685
evaluation/Returns Std              0.31692
evaluation/Returns Max             -3.63734
evaluation/Returns Min             -4.45819
evaluation/Actions Mean             0.00576099
evaluation/Actions Std              0.0833425
evaluation/Actions Max              0.999977
evaluation/Actions Min             -0.89815
evaluation/Num Paths                5
evaluation/Average Returns         -3.94685
time/data storing (s)               0.00119997
time/evaluation sampling (s)        0.0721846
time/exploration sampling (s)       0.0335738
time/logging (s)                    0.00185153
time/saving (s)                     0.00177096
time/training (s)                   0.465378
time/epoch (s)                      0.575958
time/total (s)                    187.028
Epoch                             312
-----------------------------  ----------------
2019-04-13 17:01:42.074366 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 313 finished
-----------------------------  ----------------
replay_buffer/size              62900
trainer/QF1 Loss                    4.89193
trainer/QF2 Loss                    4.88617
trainer/Policy Loss                12.4805
trainer/Q1 Predictions Mean       -12.5924
trainer/Q1 Predictions Std          0.1364
trainer/Q1 Predictions Max        -12.428
trainer/Q1 Predictions Min        -13.2135
trainer/Q2 Predictions Mean       -12.584
trainer/Q2 Predictions Std          0.124247
trainer/Q2 Predictions Max        -12.4579
trainer/Q2 Predictions Min        -13.1549
trainer/Q Targets Mean            -12.208
trainer/Q Targets Std               2.19097
trainer/Q Targets Max              -0.0572174
trainer/Q Targets Min             -13.3681
trainer/Bellman Errors 1 Mean       4.89193
trainer/Bellman Errors 1 Std       27.1224
trainer/Bellman Errors 1 Max      155.903
trainer/Bellman Errors 1 Min        6.10054e-07
trainer/Bellman Errors 2 Mean       4.88617
trainer/Bellman Errors 2 Std       27.0921
trainer/Bellman Errors 2 Max      155.728
trainer/Bellman Errors 2 Min        1.55127e-06
trainer/Policy Action Mean         -0.0599339
trainer/Policy Action Std           0.102078
trainer/Policy Action Max           0.172606
trainer/Policy Action Min          -0.442656
exploration/num steps total     62900
exploration/num paths total       629
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136118
exploration/Rewards Std             0.0725362
exploration/Rewards Max            -0.00841471
exploration/Rewards Min            -0.458927
exploration/Returns Mean          -13.6118
exploration/Returns Std             0.423947
exploration/Returns Max           -13.1879
exploration/Returns Min           -14.0358
exploration/Actions Mean            0.00267241
exploration/Actions Std             0.15435
exploration/Actions Max             1
exploration/Actions Min            -0.724811
exploration/Num Paths               2
exploration/Average Returns       -13.6118
evaluation/num steps total     157000
evaluation/num paths total       1570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0464916
evaluation/Rewards Std              0.0559565
evaluation/Rewards Max             -0.0413487
evaluation/Rewards Min             -0.95682
evaluation/Returns Mean            -4.64916
evaluation/Returns Std              0.382282
evaluation/Returns Max             -4.13836
evaluation/Returns Min             -5.17466
evaluation/Actions Mean             0.00533574
evaluation/Actions Std              0.0778535
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.997861
evaluation/Num Paths                5
evaluation/Average Returns         -4.64916
time/data storing (s)               0.00124964
time/evaluation sampling (s)        0.0763987
time/exploration sampling (s)       0.0339034
time/logging (s)                    0.00244794
time/saving (s)                     0.00222128
time/training (s)                   0.466193
time/epoch (s)                      0.582414
time/total (s)                    187.614
Epoch                             313
-----------------------------  ----------------
2019-04-13 17:01:42.670914 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 314 finished
-----------------------------  ----------------
replay_buffer/size              63100
trainer/QF1 Loss                    0.0498374
trainer/QF2 Loss                    0.0488015
trainer/Policy Loss                12.3408
trainer/Q1 Predictions Mean       -12.4392
trainer/Q1 Predictions Std          0.0594346
trainer/Q1 Predictions Max        -12.3536
trainer/Q1 Predictions Min        -12.5785
trainer/Q2 Predictions Mean       -12.4429
trainer/Q2 Predictions Std          0.0570811
trainer/Q2 Predictions Max        -12.3603
trainer/Q2 Predictions Min        -12.5691
trainer/Q Targets Mean            -12.6057
trainer/Q Targets Std               0.157048
trainer/Q Targets Max             -12.3238
trainer/Q Targets Min             -12.9347
trainer/Bellman Errors 1 Mean       0.0498374
trainer/Bellman Errors 1 Std        0.058777
trainer/Bellman Errors 1 Max        0.229081
trainer/Bellman Errors 1 Min        0.000123142
trainer/Bellman Errors 2 Mean       0.0488015
trainer/Bellman Errors 2 Std        0.0593402
trainer/Bellman Errors 2 Max        0.222081
trainer/Bellman Errors 2 Min        1.6575e-05
trainer/Policy Action Mean         -0.0240466
trainer/Policy Action Std           0.102661
trainer/Policy Action Max           0.258379
trainer/Policy Action Min          -0.351297
exploration/num steps total     63100
exploration/num paths total       631
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137848
exploration/Rewards Std             0.0814214
exploration/Rewards Max            -0.0187101
exploration/Rewards Min            -0.803949
exploration/Returns Mean          -13.7848
exploration/Returns Std             0.181713
exploration/Returns Max           -13.6031
exploration/Returns Min           -13.9665
exploration/Actions Mean            0.00112579
exploration/Actions Std             0.158842
exploration/Actions Max             0.891104
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.7848
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0612832
evaluation/Rewards Std              0.0592975
evaluation/Rewards Max             -0.0557902
evaluation/Rewards Min             -0.890088
evaluation/Returns Mean            -6.12832
evaluation/Returns Std              0.330419
evaluation/Returns Max             -5.68058
evaluation/Returns Min             -6.48127
evaluation/Actions Mean             0.0079677
evaluation/Actions Std              0.0927004
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.921005
evaluation/Num Paths                5
evaluation/Average Returns         -6.12832
time/data storing (s)               0.00111689
time/evaluation sampling (s)        0.0737281
time/exploration sampling (s)       0.0338621
time/logging (s)                    0.00247602
time/saving (s)                     0.0110816
time/training (s)                   0.466537
time/epoch (s)                      0.588802
time/total (s)                    188.205
Epoch                             314
-----------------------------  ----------------
2019-04-13 17:01:43.252131 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 315 finished
-----------------------------  ----------------
replay_buffer/size              63300
trainer/QF1 Loss                    0.20583
trainer/QF2 Loss                    0.202419
trainer/Policy Loss                12.0627
trainer/Q1 Predictions Mean       -12.2193
trainer/Q1 Predictions Std          0.15082
trainer/Q1 Predictions Max        -12.0738
trainer/Q1 Predictions Min        -12.9777
trainer/Q2 Predictions Mean       -12.2226
trainer/Q2 Predictions Std          0.149213
trainer/Q2 Predictions Max        -12.1063
trainer/Q2 Predictions Min        -12.9841
trainer/Q Targets Mean            -12.6403
trainer/Q Targets Std               0.219703
trainer/Q Targets Max             -12.3609
trainer/Q Targets Min             -13.3989
trainer/Bellman Errors 1 Mean       0.20583
trainer/Bellman Errors 1 Std        0.175467
trainer/Bellman Errors 1 Max        0.69501
trainer/Bellman Errors 1 Min        0.0486093
trainer/Bellman Errors 2 Mean       0.202419
trainer/Bellman Errors 2 Std        0.172893
trainer/Bellman Errors 2 Max        0.707529
trainer/Bellman Errors 2 Min        0.0397417
trainer/Policy Action Mean          0.0138906
trainer/Policy Action Std           0.137081
trainer/Policy Action Max           0.539121
trainer/Policy Action Min          -0.534941
exploration/num steps total     63300
exploration/num paths total       633
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.141572
exploration/Rewards Std             0.0758243
exploration/Rewards Max            -0.0149794
exploration/Rewards Min            -0.401116
exploration/Returns Mean          -14.1572
exploration/Returns Std             0.0277
exploration/Returns Max           -14.1295
exploration/Returns Min           -14.1849
exploration/Actions Mean            0.00385715
exploration/Actions Std             0.13924
exploration/Actions Max             0.972237
exploration/Actions Min            -0.347172
exploration/Num Paths               2
exploration/Average Returns       -14.1572
evaluation/num steps total     158000
evaluation/num paths total       1580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0653668
evaluation/Rewards Std              0.0112745
evaluation/Rewards Max             -0.0640582
evaluation/Rewards Min             -0.264252
evaluation/Returns Mean            -6.53668
evaluation/Returns Std              0.0684557
evaluation/Returns Max             -6.44987
evaluation/Returns Min             -6.65031
evaluation/Actions Mean             0.00679159
evaluation/Actions Std              0.0663497
evaluation/Actions Max              0.983958
evaluation/Actions Min             -6.85453e-07
evaluation/Num Paths                5
evaluation/Average Returns         -6.53668
time/data storing (s)               0.00116309
time/evaluation sampling (s)        0.0743174
time/exploration sampling (s)       0.0332034
time/logging (s)                    0.00218192
time/saving (s)                     0.00221191
time/training (s)                   0.460674
time/epoch (s)                      0.573752
time/total (s)                    188.782
Epoch                             315
-----------------------------  ----------------
2019-04-13 17:01:43.829304 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 316 finished
-----------------------------  ----------------
replay_buffer/size              63500
trainer/QF1 Loss                    4.9122
trainer/QF2 Loss                    4.91689
trainer/Policy Loss                12.572
trainer/Q1 Predictions Mean       -12.8153
trainer/Q1 Predictions Std          0.519313
trainer/Q1 Predictions Max        -12.5369
trainer/Q1 Predictions Min        -15.1533
trainer/Q2 Predictions Mean       -12.8148
trainer/Q2 Predictions Std          0.548535
trainer/Q2 Predictions Max        -12.5301
trainer/Q2 Predictions Min        -15.1873
trainer/Q Targets Mean            -12.404
trainer/Q Targets Std               2.25664
trainer/Q Targets Max              -0.150727
trainer/Q Targets Min             -14.769
trainer/Bellman Errors 1 Mean       4.9122
trainer/Bellman Errors 1 Std       27.1978
trainer/Bellman Errors 1 Max      156.343
trainer/Bellman Errors 1 Min        1.36481e-06
trainer/Bellman Errors 2 Mean       4.91689
trainer/Bellman Errors 2 Std       27.188
trainer/Bellman Errors 2 Max      156.293
trainer/Bellman Errors 2 Min        1.19654e-06
trainer/Policy Action Mean          0.0729811
trainer/Policy Action Std           0.2293
trainer/Policy Action Max           0.9973
trainer/Policy Action Min          -0.427376
exploration/num steps total     63500
exploration/num paths total       635
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.156322
exploration/Rewards Std             0.0748149
exploration/Rewards Max            -0.0338324
exploration/Rewards Min            -0.390813
exploration/Returns Mean          -15.6322
exploration/Returns Std             0.178124
exploration/Returns Max           -15.454
exploration/Returns Min           -15.8103
exploration/Actions Mean           -0.000287546
exploration/Actions Std             0.146237
exploration/Actions Max             0.564174
exploration/Actions Min            -0.762818
exploration/Num Paths               2
exploration/Average Returns       -15.6322
evaluation/num steps total     158500
evaluation/num paths total       1585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0944032
evaluation/Rewards Std              0.0149904
evaluation/Rewards Max             -0.0425806
evaluation/Rewards Min             -0.411769
evaluation/Returns Mean            -9.44032
evaluation/Returns Std              0.135804
evaluation/Returns Max             -9.30617
evaluation/Returns Min             -9.68917
evaluation/Actions Mean             0.00277032
evaluation/Actions Std              0.0774803
evaluation/Actions Max              0.999631
evaluation/Actions Min             -0.989284
evaluation/Num Paths                5
evaluation/Average Returns         -9.44032
time/data storing (s)               0.00114107
time/evaluation sampling (s)        0.075635
time/exploration sampling (s)       0.0321622
time/logging (s)                    0.00259866
time/saving (s)                     0.00240838
time/training (s)                   0.456336
time/epoch (s)                      0.570281
time/total (s)                    189.357
Epoch                             316
-----------------------------  ----------------
2019-04-13 17:01:44.417274 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 317 finished
-----------------------------  ----------------
replay_buffer/size              63700
trainer/QF1 Loss                    0.0258544
trainer/QF2 Loss                    0.0260419
trainer/Policy Loss                12.4608
trainer/Q1 Predictions Mean       -12.5592
trainer/Q1 Predictions Std          0.139454
trainer/Q1 Predictions Max        -12.4306
trainer/Q1 Predictions Min        -13.1968
trainer/Q2 Predictions Mean       -12.5663
trainer/Q2 Predictions Std          0.145444
trainer/Q2 Predictions Max        -12.4335
trainer/Q2 Predictions Min        -13.2199
trainer/Q Targets Mean            -12.6361
trainer/Q Targets Std               0.183766
trainer/Q Targets Max             -12.3611
trainer/Q Targets Min             -13.1566
trainer/Bellman Errors 1 Mean       0.0258544
trainer/Bellman Errors 1 Std        0.0447215
trainer/Bellman Errors 1 Max        0.225849
trainer/Bellman Errors 1 Min        2.86645e-05
trainer/Bellman Errors 2 Mean       0.0260419
trainer/Bellman Errors 2 Std        0.0438091
trainer/Bellman Errors 2 Max        0.21331
trainer/Bellman Errors 2 Min        5.30438e-06
trainer/Policy Action Mean          0.0125455
trainer/Policy Action Std           0.151351
trainer/Policy Action Max           0.430714
trainer/Policy Action Min          -0.497116
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.184708
exploration/Rewards Std             0.0938881
exploration/Rewards Max            -0.0054476
exploration/Rewards Min            -0.607417
exploration/Returns Mean          -18.4708
exploration/Returns Std             0.416646
exploration/Returns Max           -18.0542
exploration/Returns Min           -18.8875
exploration/Actions Mean            0.00533216
exploration/Actions Std             0.16697
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -18.4708
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.119816
evaluation/Rewards Std              0.0156737
evaluation/Rewards Max             -0.0987678
evaluation/Rewards Min             -0.457944
evaluation/Returns Mean           -11.9816
evaluation/Returns Std              0.130926
evaluation/Returns Max            -11.8732
evaluation/Returns Min            -12.2308
evaluation/Actions Mean             0.00438805
evaluation/Actions Std              0.0555871
evaluation/Actions Max              0.997271
evaluation/Actions Min             -0.470554
evaluation/Num Paths                5
evaluation/Average Returns        -11.9816
time/data storing (s)               0.00110723
time/evaluation sampling (s)        0.072609
time/exploration sampling (s)       0.0343635
time/logging (s)                    0.00251296
time/saving (s)                     0.00224987
time/training (s)                   0.466246
time/epoch (s)                      0.579088
time/total (s)                    189.94
Epoch                             317
-----------------------------  ----------------
2019-04-13 17:01:45.004755 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 318 finished
-----------------------------  ---------------
replay_buffer/size              63900
trainer/QF1 Loss                    4.73048
trainer/QF2 Loss                    4.71624
trainer/Policy Loss                12.2815
trainer/Q1 Predictions Mean       -12.379
trainer/Q1 Predictions Std          0.18595
trainer/Q1 Predictions Max        -12.2368
trainer/Q1 Predictions Min        -13.2289
trainer/Q2 Predictions Mean       -12.371
trainer/Q2 Predictions Std          0.186324
trainer/Q2 Predictions Max        -12.2324
trainer/Q2 Predictions Min        -13.209
trainer/Q Targets Mean            -12.2747
trainer/Q Targets Std               2.19461
trainer/Q Targets Max              -0.125041
trainer/Q Targets Min             -13.3703
trainer/Bellman Errors 1 Mean       4.73048
trainer/Bellman Errors 1 Std       25.768
trainer/Bellman Errors 1 Max      148.2
trainer/Bellman Errors 1 Min        0.00272886
trainer/Bellman Errors 2 Mean       4.71624
trainer/Bellman Errors 2 Std       25.6678
trainer/Bellman Errors 2 Max      147.627
trainer/Bellman Errors 2 Min        0.00230074
trainer/Policy Action Mean         -0.0201785
trainer/Policy Action Std           0.137875
trainer/Policy Action Max           0.455031
trainer/Policy Action Min          -0.52016
exploration/num steps total     63900
exploration/num paths total       639
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.139802
exploration/Rewards Std             0.0908826
exploration/Rewards Max            -0.00589213
exploration/Rewards Min            -0.782316
exploration/Returns Mean          -13.9802
exploration/Returns Std             0.714219
exploration/Returns Max           -13.266
exploration/Returns Min           -14.6944
exploration/Actions Mean            0.00805978
exploration/Actions Std             0.169426
exploration/Actions Max             0.997851
exploration/Actions Min            -0.97948
exploration/Num Paths               2
exploration/Average Returns       -13.9802
evaluation/num steps total     159500
evaluation/num paths total       1595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0653709
evaluation/Rewards Std              0.0441733
evaluation/Rewards Max             -0.0579681
evaluation/Rewards Min             -0.748998
evaluation/Returns Mean            -6.53709
evaluation/Returns Std              0.272276
evaluation/Returns Max             -6.18686
evaluation/Returns Min             -6.87894
evaluation/Actions Mean             0.00586145
evaluation/Actions Std              0.0804504
evaluation/Actions Max              0.999897
evaluation/Actions Min             -0.972043
evaluation/Num Paths                5
evaluation/Average Returns         -6.53709
time/data storing (s)               0.001105
time/evaluation sampling (s)        0.074907
time/exploration sampling (s)       0.0343249
time/logging (s)                    0.00258873
time/saving (s)                     0.0024796
time/training (s)                   0.463488
time/epoch (s)                      0.578894
time/total (s)                    190.523
Epoch                             318
-----------------------------  ---------------
2019-04-13 17:01:45.608325 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 319 finished
-----------------------------  ----------------
replay_buffer/size              64100
trainer/QF1 Loss                    4.92319
trainer/QF2 Loss                    4.93466
trainer/Policy Loss                12.4002
trainer/Q1 Predictions Mean       -12.5646
trainer/Q1 Predictions Std          0.0970647
trainer/Q1 Predictions Max        -12.4357
trainer/Q1 Predictions Min        -12.8787
trainer/Q2 Predictions Mean       -12.5703
trainer/Q2 Predictions Std          0.0961923
trainer/Q2 Predictions Max        -12.4428
trainer/Q2 Predictions Min        -12.8654
trainer/Q Targets Mean            -12.233
trainer/Q Targets Std               2.15437
trainer/Q Targets Max              -0.297401
trainer/Q Targets Min             -13.3579
trainer/Bellman Errors 1 Mean       4.92319
trainer/Bellman Errors 1 Std       27.21
trainer/Bellman Errors 1 Max      156.422
trainer/Bellman Errors 1 Min        1.08057e-06
trainer/Bellman Errors 2 Mean       4.93466
trainer/Bellman Errors 2 Std       27.2686
trainer/Bellman Errors 2 Max      156.759
trainer/Bellman Errors 2 Min        5.44856e-07
trainer/Policy Action Mean         -0.0143647
trainer/Policy Action Std           0.120093
trainer/Policy Action Max           0.281781
trainer/Policy Action Min          -0.241755
exploration/num steps total     64100
exploration/num paths total       641
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133243
exploration/Rewards Std             0.105792
exploration/Rewards Max            -0.0109165
exploration/Rewards Min            -1.24829
exploration/Returns Mean          -13.3243
exploration/Returns Std             0.345542
exploration/Returns Max           -12.9787
exploration/Returns Min           -13.6698
exploration/Actions Mean            0.00550804
exploration/Actions Std             0.175325
exploration/Actions Max             1
exploration/Actions Min            -0.947584
exploration/Num Paths               2
exploration/Average Returns       -13.3243
evaluation/num steps total     160000
evaluation/num paths total       1600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.02561
evaluation/Rewards Std              0.0608869
evaluation/Rewards Max             -0.0168933
evaluation/Rewards Min             -0.996141
evaluation/Returns Mean            -2.561
evaluation/Returns Std              0.356635
evaluation/Returns Max             -2.05774
evaluation/Returns Min             -3.07127
evaluation/Actions Mean             0.00650133
evaluation/Actions Std              0.0935107
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.99944
evaluation/Num Paths                5
evaluation/Average Returns         -2.561
time/data storing (s)               0.00122004
time/evaluation sampling (s)        0.0771447
time/exploration sampling (s)       0.0332519
time/logging (s)                    0.00190691
time/saving (s)                     0.00224028
time/training (s)                   0.478102
time/epoch (s)                      0.593866
time/total (s)                    191.121
Epoch                             319
-----------------------------  ----------------
2019-04-13 17:01:46.191953 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 320 finished
-----------------------------  ---------------
replay_buffer/size              64300
trainer/QF1 Loss                    0.026583
trainer/QF2 Loss                    0.0308904
trainer/Policy Loss                12.4956
trainer/Q1 Predictions Mean       -12.5978
trainer/Q1 Predictions Std          0.168462
trainer/Q1 Predictions Max        -12.4555
trainer/Q1 Predictions Min        -13.3887
trainer/Q2 Predictions Mean       -12.6034
trainer/Q2 Predictions Std          0.170663
trainer/Q2 Predictions Max        -12.4889
trainer/Q2 Predictions Min        -13.4389
trainer/Q Targets Mean            -12.6462
trainer/Q Targets Std               0.23819
trainer/Q Targets Max             -12.3283
trainer/Q Targets Min             -13.3066
trainer/Bellman Errors 1 Mean       0.026583
trainer/Bellman Errors 1 Std        0.0340326
trainer/Bellman Errors 1 Max        0.130628
trainer/Bellman Errors 1 Min        0.00127836
trainer/Bellman Errors 2 Mean       0.0308904
trainer/Bellman Errors 2 Std        0.0380144
trainer/Bellman Errors 2 Max        0.154985
trainer/Bellman Errors 2 Min        0.00109574
trainer/Policy Action Mean          0.00368111
trainer/Policy Action Std           0.14443
trainer/Policy Action Max           0.511863
trainer/Policy Action Min          -0.507582
exploration/num steps total     64300
exploration/num paths total       643
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129446
exploration/Rewards Std             0.0662315
exploration/Rewards Max            -0.0075693
exploration/Rewards Min            -0.375137
exploration/Returns Mean          -12.9446
exploration/Returns Std             0.870878
exploration/Returns Max           -12.0738
exploration/Returns Min           -13.8155
exploration/Actions Mean            0.00536566
exploration/Actions Std             0.148362
exploration/Actions Max             0.760805
exploration/Actions Min            -0.386359
exploration/Num Paths               2
exploration/Average Returns       -12.9446
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0483611
evaluation/Rewards Std              0.039434
evaluation/Rewards Max             -0.0323814
evaluation/Rewards Min             -0.827857
evaluation/Returns Mean            -4.83611
evaluation/Returns Std              0.281399
evaluation/Returns Max             -4.58947
evaluation/Returns Min             -5.37428
evaluation/Actions Mean             0.0065857
evaluation/Actions Std              0.0840762
evaluation/Actions Max              0.999978
evaluation/Actions Min             -0.998028
evaluation/Num Paths                5
evaluation/Average Returns         -4.83611
time/data storing (s)               0.00104409
time/evaluation sampling (s)        0.0726271
time/exploration sampling (s)       0.0321322
time/logging (s)                    0.00246877
time/saving (s)                     0.00243461
time/training (s)                   0.465681
time/epoch (s)                      0.576388
time/total (s)                    191.702
Epoch                             320
-----------------------------  ---------------
2019-04-13 17:01:46.780505 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 321 finished
-----------------------------  ----------------
replay_buffer/size              64500
trainer/QF1 Loss                    9.48492
trainer/QF2 Loss                    9.48321
trainer/Policy Loss                12.324
trainer/Q1 Predictions Mean       -12.5293
trainer/Q1 Predictions Std          0.249713
trainer/Q1 Predictions Max        -12.3395
trainer/Q1 Predictions Min        -13.4145
trainer/Q2 Predictions Mean       -12.5364
trainer/Q2 Predictions Std          0.248127
trainer/Q2 Predictions Max        -12.3348
trainer/Q2 Predictions Min        -13.4107
trainer/Q Targets Mean            -11.937
trainer/Q Targets Std               3.03119
trainer/Q Targets Max              -0.214268
trainer/Q Targets Min             -13.3446
trainer/Bellman Errors 1 Mean       9.48492
trainer/Bellman Errors 1 Std       36.5153
trainer/Bellman Errors 1 Max      151.536
trainer/Bellman Errors 1 Min        0.000275232
trainer/Bellman Errors 2 Mean       9.48321
trainer/Bellman Errors 2 Std       36.5011
trainer/Bellman Errors 2 Max      151.911
trainer/Bellman Errors 2 Min        0.000632873
trainer/Policy Action Mean         -0.000989825
trainer/Policy Action Std           0.253488
trainer/Policy Action Max           0.88572
trainer/Policy Action Min          -0.993349
exploration/num steps total     64500
exploration/num paths total       645
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.14344
exploration/Rewards Std             0.106094
exploration/Rewards Max            -0.00692991
exploration/Rewards Min            -1.06099
exploration/Returns Mean          -14.344
exploration/Returns Std             0.0210157
exploration/Returns Max           -14.323
exploration/Returns Min           -14.365
exploration/Actions Mean            0.00528246
exploration/Actions Std             0.183131
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.344
evaluation/num steps total     161000
evaluation/num paths total       1610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0681656
evaluation/Rewards Std              0.0402135
evaluation/Rewards Max             -0.0343003
evaluation/Rewards Min             -0.777354
evaluation/Returns Mean            -6.81656
evaluation/Returns Std              0.251389
evaluation/Returns Max             -6.46893
evaluation/Returns Min             -7.23442
evaluation/Actions Mean             0.00580372
evaluation/Actions Std              0.0869561
evaluation/Actions Max              0.999967
evaluation/Actions Min             -0.979116
evaluation/Num Paths                5
evaluation/Average Returns         -6.81656
time/data storing (s)               0.00116481
time/evaluation sampling (s)        0.0756227
time/exploration sampling (s)       0.0319327
time/logging (s)                    0.00216489
time/saving (s)                     0.00181354
time/training (s)                   0.466659
time/epoch (s)                      0.579358
time/total (s)                    192.285
Epoch                             321
-----------------------------  ----------------
2019-04-13 17:01:47.364433 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 322 finished
-----------------------------  ----------------
replay_buffer/size              64700
trainer/QF1 Loss                    0.0251458
trainer/QF2 Loss                    0.026372
trainer/Policy Loss                12.5898
trainer/Q1 Predictions Mean       -12.7262
trainer/Q1 Predictions Std          0.296908
trainer/Q1 Predictions Max        -12.5748
trainer/Q1 Predictions Min        -14.3236
trainer/Q2 Predictions Mean       -12.725
trainer/Q2 Predictions Std          0.310108
trainer/Q2 Predictions Max        -12.558
trainer/Q2 Predictions Min        -14.3968
trainer/Q Targets Mean            -12.6611
trainer/Q Targets Std               0.339873
trainer/Q Targets Max             -12.3662
trainer/Q Targets Min             -14.2609
trainer/Bellman Errors 1 Mean       0.0251458
trainer/Bellman Errors 1 Std        0.02978
trainer/Bellman Errors 1 Max        0.153955
trainer/Bellman Errors 1 Min        6.71397e-06
trainer/Bellman Errors 2 Mean       0.026372
trainer/Bellman Errors 2 Std        0.0315298
trainer/Bellman Errors 2 Max        0.168964
trainer/Bellman Errors 2 Min        1.28102e-05
trainer/Policy Action Mean          0.018929
trainer/Policy Action Std           0.202876
trainer/Policy Action Max           0.998121
trainer/Policy Action Min          -0.99999
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131354
exploration/Rewards Std             0.0967658
exploration/Rewards Max            -0.00699283
exploration/Rewards Min            -0.958766
exploration/Returns Mean          -13.1354
exploration/Returns Std             0.749022
exploration/Returns Max           -12.3864
exploration/Returns Min           -13.8844
exploration/Actions Mean            0.0112004
exploration/Actions Std             0.171287
exploration/Actions Max             1
exploration/Actions Min            -0.367542
exploration/Num Paths               2
exploration/Average Returns       -13.1354
evaluation/num steps total     161500
evaluation/num paths total       1615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0487383
evaluation/Rewards Std              0.0522022
evaluation/Rewards Max             -0.0110043
evaluation/Rewards Min             -1.03215
evaluation/Returns Mean            -4.87383
evaluation/Returns Std              0.303662
evaluation/Returns Max             -4.57336
evaluation/Returns Min             -5.45518
evaluation/Actions Mean             0.00487562
evaluation/Actions Std              0.0898741
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.990325
evaluation/Num Paths                5
evaluation/Average Returns         -4.87383
time/data storing (s)               0.00113856
time/evaluation sampling (s)        0.0761238
time/exploration sampling (s)       0.0328863
time/logging (s)                    0.00193748
time/saving (s)                     0.00181965
time/training (s)                   0.461217
time/epoch (s)                      0.575123
time/total (s)                    192.864
Epoch                             322
-----------------------------  ----------------
2019-04-13 17:01:47.951196 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 323 finished
-----------------------------  ----------------
replay_buffer/size              64900
trainer/QF1 Loss                    0.0252513
trainer/QF2 Loss                    0.0255419
trainer/Policy Loss                12.5308
trainer/Q1 Predictions Mean       -12.6626
trainer/Q1 Predictions Std          0.126591
trainer/Q1 Predictions Max        -12.4976
trainer/Q1 Predictions Min        -13.0728
trainer/Q2 Predictions Mean       -12.6569
trainer/Q2 Predictions Std          0.111565
trainer/Q2 Predictions Max        -12.511
trainer/Q2 Predictions Min        -12.9913
trainer/Q Targets Mean            -12.7031
trainer/Q Targets Std               0.185837
trainer/Q Targets Max             -12.399
trainer/Q Targets Min             -13.1242
trainer/Bellman Errors 1 Mean       0.0252513
trainer/Bellman Errors 1 Std        0.0311034
trainer/Bellman Errors 1 Max        0.11176
trainer/Bellman Errors 1 Min        4.52555e-05
trainer/Bellman Errors 2 Mean       0.0255419
trainer/Bellman Errors 2 Std        0.0315119
trainer/Bellman Errors 2 Max        0.108071
trainer/Bellman Errors 2 Min        0.000411545
trainer/Policy Action Mean          0.0295541
trainer/Policy Action Std           0.187419
trainer/Policy Action Max           0.859299
trainer/Policy Action Min          -0.22068
exploration/num steps total     64900
exploration/num paths total       649
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129163
exploration/Rewards Std             0.0683465
exploration/Rewards Max            -0.0100696
exploration/Rewards Min            -0.3432
exploration/Returns Mean          -12.9163
exploration/Returns Std             0.0795596
exploration/Returns Max           -12.8367
exploration/Returns Min           -12.9958
exploration/Actions Mean            0.00380719
exploration/Actions Std             0.143494
exploration/Actions Max             0.545951
exploration/Actions Min            -0.448307
exploration/Num Paths               2
exploration/Average Returns       -12.9163
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0262465
evaluation/Rewards Std              0.0613067
evaluation/Rewards Max             -0.0099154
evaluation/Rewards Min             -0.974367
evaluation/Returns Mean            -2.62465
evaluation/Returns Std              0.373362
evaluation/Returns Max             -2.2629
evaluation/Returns Min             -3.10652
evaluation/Actions Mean             0.00783238
evaluation/Actions Std              0.0961103
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.996042
evaluation/Num Paths                5
evaluation/Average Returns         -2.62465
time/data storing (s)               0.00113318
time/evaluation sampling (s)        0.0739282
time/exploration sampling (s)       0.0337488
time/logging (s)                    0.00246596
time/saving (s)                     0.00226902
time/training (s)                   0.465599
time/epoch (s)                      0.579144
time/total (s)                    193.448
Epoch                             323
-----------------------------  ----------------
2019-04-13 17:01:48.540675 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 324 finished
-----------------------------  ----------------
replay_buffer/size              65100
trainer/QF1 Loss                    0.0440208
trainer/QF2 Loss                    0.0415333
trainer/Policy Loss                12.6113
trainer/Q1 Predictions Mean       -12.8029
trainer/Q1 Predictions Std          0.638273
trainer/Q1 Predictions Max        -12.5553
trainer/Q1 Predictions Min        -16.1538
trainer/Q2 Predictions Mean       -12.7774
trainer/Q2 Predictions Std          0.616035
trainer/Q2 Predictions Max        -12.5488
trainer/Q2 Predictions Min        -16.0244
trainer/Q Targets Mean            -12.7334
trainer/Q Targets Std               0.643025
trainer/Q Targets Max             -12.3914
trainer/Q Targets Min             -16.0867
trainer/Bellman Errors 1 Mean       0.0440208
trainer/Bellman Errors 1 Std        0.0636969
trainer/Bellman Errors 1 Max        0.268776
trainer/Bellman Errors 1 Min        0.000787094
trainer/Bellman Errors 2 Mean       0.0415333
trainer/Bellman Errors 2 Std        0.0607507
trainer/Bellman Errors 2 Max        0.269059
trainer/Bellman Errors 2 Min        2.81158e-07
trainer/Policy Action Mean          0.0358071
trainer/Policy Action Std           0.224801
trainer/Policy Action Max           0.999263
trainer/Policy Action Min          -0.574943
exploration/num steps total     65100
exploration/num paths total       651
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.147839
exploration/Rewards Std             0.0708882
exploration/Rewards Max            -0.0155432
exploration/Rewards Min            -0.373958
exploration/Returns Mean          -14.7839
exploration/Returns Std             0.157516
exploration/Returns Max           -14.6264
exploration/Returns Min           -14.9414
exploration/Actions Mean            0.00555208
exploration/Actions Std             0.157566
exploration/Actions Max             1
exploration/Actions Min            -0.439833
exploration/Num Paths               2
exploration/Average Returns       -14.7839
evaluation/num steps total     162500
evaluation/num paths total       1625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0707309
evaluation/Rewards Std              0.038069
evaluation/Rewards Max             -0.0255782
evaluation/Rewards Min             -0.916977
evaluation/Returns Mean            -7.07309
evaluation/Returns Std              0.331212
evaluation/Returns Max             -6.84595
evaluation/Returns Min             -7.7292
evaluation/Actions Mean             0.00319341
evaluation/Actions Std              0.0632059
evaluation/Actions Max              0.999984
evaluation/Actions Min             -0.44601
evaluation/Num Paths                5
evaluation/Average Returns         -7.07309
time/data storing (s)               0.00113498
time/evaluation sampling (s)        0.0748978
time/exploration sampling (s)       0.0321044
time/logging (s)                    0.00257375
time/saving (s)                     0.00227365
time/training (s)                   0.467758
time/epoch (s)                      0.580743
time/total (s)                    194.033
Epoch                             324
-----------------------------  ----------------
2019-04-13 17:01:49.125039 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 325 finished
-----------------------------  ----------------
replay_buffer/size              65300
trainer/QF1 Loss                    9.56032
trainer/QF2 Loss                    9.59232
trainer/Policy Loss                12.3437
trainer/Q1 Predictions Mean       -12.4657
trainer/Q1 Predictions Std          0.0996755
trainer/Q1 Predictions Max        -12.3528
trainer/Q1 Predictions Min        -12.7193
trainer/Q2 Predictions Mean       -12.4687
trainer/Q2 Predictions Std          0.10148
trainer/Q2 Predictions Max        -12.3619
trainer/Q2 Predictions Min        -12.7271
trainer/Q Targets Mean            -11.8604
trainer/Q Targets Std               3.05597
trainer/Q Targets Max              -0.0248457
trainer/Q Targets Min             -13.2698
trainer/Bellman Errors 1 Mean       9.56032
trainer/Bellman Errors 1 Std       36.8076
trainer/Bellman Errors 1 Max      152.483
trainer/Bellman Errors 1 Min        0.000422176
trainer/Bellman Errors 2 Mean       9.59232
trainer/Bellman Errors 2 Std       36.9307
trainer/Bellman Errors 2 Max      152.908
trainer/Bellman Errors 2 Min        4.64436e-05
trainer/Policy Action Mean         -0.0358631
trainer/Policy Action Std           0.114682
trainer/Policy Action Max           0.371552
trainer/Policy Action Min          -0.337073
exploration/num steps total     65300
exploration/num paths total       653
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124446
exploration/Rewards Std             0.0795143
exploration/Rewards Max            -0.00732713
exploration/Rewards Min            -0.708145
exploration/Returns Mean          -12.4446
exploration/Returns Std             0.281947
exploration/Returns Max           -12.1627
exploration/Returns Min           -12.7266
exploration/Actions Mean            0.00334328
exploration/Actions Std             0.167439
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.4446
evaluation/num steps total     163000
evaluation/num paths total       1630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0172292
evaluation/Rewards Std              0.0513727
evaluation/Rewards Max             -0.0121309
evaluation/Rewards Min             -0.790711
evaluation/Returns Mean            -1.72292
evaluation/Returns Std              0.304332
evaluation/Returns Max             -1.31602
evaluation/Returns Min             -2.10492
evaluation/Actions Mean             0.00648097
evaluation/Actions Std              0.083132
evaluation/Actions Max              0.999978
evaluation/Actions Min             -0.975886
evaluation/Num Paths                5
evaluation/Average Returns         -1.72292
time/data storing (s)               0.00106325
time/evaluation sampling (s)        0.0729919
time/exploration sampling (s)       0.0330228
time/logging (s)                    0.0024925
time/saving (s)                     0.00227046
time/training (s)                   0.463517
time/epoch (s)                      0.575358
time/total (s)                    194.612
Epoch                             325
-----------------------------  ----------------
2019-04-13 17:01:49.706673 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 326 finished
-----------------------------  ----------------
replay_buffer/size              65500
trainer/QF1 Loss                    0.0413321
trainer/QF2 Loss                    0.0439443
trainer/Policy Loss                12.6082
trainer/Q1 Predictions Mean       -12.6553
trainer/Q1 Predictions Std          0.188399
trainer/Q1 Predictions Max        -12.4573
trainer/Q1 Predictions Min        -13.6337
trainer/Q2 Predictions Mean       -12.6465
trainer/Q2 Predictions Std          0.188977
trainer/Q2 Predictions Max        -12.4145
trainer/Q2 Predictions Min        -13.6176
trainer/Q Targets Mean            -12.7228
trainer/Q Targets Std               0.242589
trainer/Q Targets Max             -12.4057
trainer/Q Targets Min             -13.7044
trainer/Bellman Errors 1 Mean       0.0413321
trainer/Bellman Errors 1 Std        0.09178
trainer/Bellman Errors 1 Max        0.521485
trainer/Bellman Errors 1 Min        1.99968e-05
trainer/Bellman Errors 2 Mean       0.0439443
trainer/Bellman Errors 2 Std        0.102864
trainer/Bellman Errors 2 Max        0.585053
trainer/Bellman Errors 2 Min        0.000133798
trainer/Policy Action Mean          0.00426793
trainer/Policy Action Std           0.150264
trainer/Policy Action Max           0.541229
trainer/Policy Action Min          -0.544146
exploration/num steps total     65500
exploration/num paths total       655
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138435
exploration/Rewards Std             0.0678122
exploration/Rewards Max            -0.0150564
exploration/Rewards Min            -0.325096
exploration/Returns Mean          -13.8435
exploration/Returns Std             0.497713
exploration/Returns Max           -13.3458
exploration/Returns Min           -14.3412
exploration/Actions Mean            0.00071475
exploration/Actions Std             0.152822
exploration/Actions Max             0.994641
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.8435
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0718675
evaluation/Rewards Std              0.0486334
evaluation/Rewards Max             -0.0548689
evaluation/Rewards Min             -0.885427
evaluation/Returns Mean            -7.18675
evaluation/Returns Std              0.268876
evaluation/Returns Max             -6.88555
evaluation/Returns Min             -7.60075
evaluation/Actions Mean             0.00600565
evaluation/Actions Std              0.0918644
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.965512
evaluation/Num Paths                5
evaluation/Average Returns         -7.18675
time/data storing (s)               0.00111777
time/evaluation sampling (s)        0.0753168
time/exploration sampling (s)       0.0343041
time/logging (s)                    0.00247417
time/saving (s)                     0.00222829
time/training (s)                   0.457338
time/epoch (s)                      0.572779
time/total (s)                    195.189
Epoch                             326
-----------------------------  ----------------
2019-04-13 17:01:50.289905 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 327 finished
-----------------------------  ----------------
replay_buffer/size              65700
trainer/QF1 Loss                    0.0360973
trainer/QF2 Loss                    0.03821
trainer/Policy Loss                12.4628
trainer/Q1 Predictions Mean       -12.5868
trainer/Q1 Predictions Std          0.10108
trainer/Q1 Predictions Max        -12.4403
trainer/Q1 Predictions Min        -12.8145
trainer/Q2 Predictions Mean       -12.5832
trainer/Q2 Predictions Std          0.0959108
trainer/Q2 Predictions Max        -12.4535
trainer/Q2 Predictions Min        -12.8127
trainer/Q Targets Mean            -12.6699
trainer/Q Targets Std               0.208189
trainer/Q Targets Max             -12.4044
trainer/Q Targets Min             -13.3155
trainer/Bellman Errors 1 Mean       0.0360973
trainer/Bellman Errors 1 Std        0.0608626
trainer/Bellman Errors 1 Max        0.282299
trainer/Bellman Errors 1 Min        0.000228832
trainer/Bellman Errors 2 Mean       0.03821
trainer/Bellman Errors 2 Std        0.0649718
trainer/Bellman Errors 2 Max        0.30129
trainer/Bellman Errors 2 Min        0.00042701
trainer/Policy Action Mean          0.0241197
trainer/Policy Action Std           0.115527
trainer/Policy Action Max           0.286771
trainer/Policy Action Min          -0.282362
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127104
exploration/Rewards Std             0.0651231
exploration/Rewards Max            -0.00868385
exploration/Rewards Min            -0.348876
exploration/Returns Mean          -12.7104
exploration/Returns Std             0.228376
exploration/Returns Max           -12.482
exploration/Returns Min           -12.9388
exploration/Actions Mean            0.00878513
exploration/Actions Std             0.16118
exploration/Actions Max             1
exploration/Actions Min            -0.362226
exploration/Num Paths               2
exploration/Average Returns       -12.7104
evaluation/num steps total     164000
evaluation/num paths total       1640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0456597
evaluation/Rewards Std              0.036115
evaluation/Rewards Max             -0.031329
evaluation/Rewards Min             -0.619236
evaluation/Returns Mean            -4.56597
evaluation/Returns Std              0.18039
evaluation/Returns Max             -4.36341
evaluation/Returns Min             -4.84471
evaluation/Actions Mean             0.00559899
evaluation/Actions Std              0.0901169
evaluation/Actions Max              0.999809
evaluation/Actions Min             -0.997624
evaluation/Num Paths                5
evaluation/Average Returns         -4.56597
time/data storing (s)               0.00118329
time/evaluation sampling (s)        0.0729403
time/exploration sampling (s)       0.0327638
time/logging (s)                    0.00248244
time/saving (s)                     0.00223762
time/training (s)                   0.462622
time/epoch (s)                      0.574229
time/total (s)                    195.767
Epoch                             327
-----------------------------  ----------------
2019-04-13 17:01:50.871425 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 328 finished
-----------------------------  ----------------
replay_buffer/size              65900
trainer/QF1 Loss                    4.91308
trainer/QF2 Loss                    4.90708
trainer/Policy Loss                12.492
trainer/Q1 Predictions Mean       -12.6349
trainer/Q1 Predictions Std          0.335093
trainer/Q1 Predictions Max        -12.4678
trainer/Q1 Predictions Min        -14.4655
trainer/Q2 Predictions Mean       -12.6445
trainer/Q2 Predictions Std          0.341125
trainer/Q2 Predictions Max        -12.4828
trainer/Q2 Predictions Min        -14.5194
trainer/Q Targets Mean            -12.3711
trainer/Q Targets Std               2.24415
trainer/Q Targets Max              -0.064343
trainer/Q Targets Min             -14.761
trainer/Bellman Errors 1 Mean       4.91308
trainer/Bellman Errors 1 Std       27.1514
trainer/Bellman Errors 1 Max      156.085
trainer/Bellman Errors 1 Min        3.63964e-05
trainer/Bellman Errors 2 Mean       4.90708
trainer/Bellman Errors 2 Std       27.1324
trainer/Bellman Errors 2 Max      155.974
trainer/Bellman Errors 2 Min        7.48195e-07
trainer/Policy Action Mean          0.0160647
trainer/Policy Action Std           0.237795
trainer/Policy Action Max           0.999925
trainer/Policy Action Min          -0.998724
exploration/num steps total     65900
exploration/num paths total       659
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.122427
exploration/Rewards Std             0.0662738
exploration/Rewards Max            -0.00313187
exploration/Rewards Min            -0.353102
exploration/Returns Mean          -12.2427
exploration/Returns Std             0.267049
exploration/Returns Max           -11.9757
exploration/Returns Min           -12.5098
exploration/Actions Mean            0.00129159
exploration/Actions Std             0.149206
exploration/Actions Max             0.979426
exploration/Actions Min            -0.958505
exploration/Num Paths               2
exploration/Average Returns       -12.2427
evaluation/num steps total     164500
evaluation/num paths total       1645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0107263
evaluation/Rewards Std              0.0537021
evaluation/Rewards Max             -0.00519497
evaluation/Rewards Min             -0.779611
evaluation/Returns Mean            -1.07263
evaluation/Returns Std              0.260188
evaluation/Returns Max             -0.691508
evaluation/Returns Min             -1.39815
evaluation/Actions Mean             0.00630857
evaluation/Actions Std              0.0922123
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.999296
evaluation/Num Paths                5
evaluation/Average Returns         -1.07263
time/data storing (s)               0.00112917
time/evaluation sampling (s)        0.0759561
time/exploration sampling (s)       0.034118
time/logging (s)                    0.00247658
time/saving (s)                     0.00249634
time/training (s)                   0.456683
time/epoch (s)                      0.572859
time/total (s)                    196.344
Epoch                             328
-----------------------------  ----------------
2019-04-13 17:01:51.448115 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 329 finished
-----------------------------  ----------------
replay_buffer/size              66100
trainer/QF1 Loss                    4.94448
trainer/QF2 Loss                    4.94223
trainer/Policy Loss                12.6453
trainer/Q1 Predictions Mean       -12.8492
trainer/Q1 Predictions Std          0.754737
trainer/Q1 Predictions Max        -12.5722
trainer/Q1 Predictions Min        -16.9634
trainer/Q2 Predictions Mean       -12.8469
trainer/Q2 Predictions Std          0.774579
trainer/Q2 Predictions Max        -12.5773
trainer/Q2 Predictions Min        -17.0734
trainer/Q Targets Mean            -12.4575
trainer/Q Targets Std               2.32559
trainer/Q Targets Max              -0.086035
trainer/Q Targets Min             -16.5035
trainer/Bellman Errors 1 Mean       4.94447
trainer/Bellman Errors 1 Std       27.3483
trainer/Bellman Errors 1 Max      157.213
trainer/Bellman Errors 1 Min        8.07668e-06
trainer/Bellman Errors 2 Mean       4.94223
trainer/Bellman Errors 2 Std       27.3093
trainer/Bellman Errors 2 Max      156.994
trainer/Bellman Errors 2 Min        4.17957e-05
trainer/Policy Action Mean         -0.0206506
trainer/Policy Action Std           0.214084
trainer/Policy Action Max           1
trainer/Policy Action Min          -0.999999
exploration/num steps total     66100
exploration/num paths total       661
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134481
exploration/Rewards Std             0.0819442
exploration/Rewards Max            -0.00856036
exploration/Rewards Min            -0.675746
exploration/Returns Mean          -13.4481
exploration/Returns Std             0.660156
exploration/Returns Max           -12.788
exploration/Returns Min           -14.1083
exploration/Actions Mean            0.0101485
exploration/Actions Std             0.159932
exploration/Actions Max             1
exploration/Actions Min            -0.373637
exploration/Num Paths               2
exploration/Average Returns       -13.4481
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0399108
evaluation/Rewards Std              0.0274839
evaluation/Rewards Max             -0.0363539
evaluation/Rewards Min             -0.415242
evaluation/Returns Mean            -3.99108
evaluation/Returns Std              0.0605
evaluation/Returns Max             -3.93475
evaluation/Returns Min             -4.10318
evaluation/Actions Mean             0.00130378
evaluation/Actions Std              0.0894711
evaluation/Actions Max              0.999311
evaluation/Actions Min             -0.998588
evaluation/Num Paths                5
evaluation/Average Returns         -3.99108
time/data storing (s)               0.00109818
time/evaluation sampling (s)        0.0736355
time/exploration sampling (s)       0.0326166
time/logging (s)                    0.00244647
time/saving (s)                     0.00226177
time/training (s)                   0.455714
time/epoch (s)                      0.567772
time/total (s)                    196.916
Epoch                             329
-----------------------------  ----------------
2019-04-13 17:01:52.018922 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 330 finished
-----------------------------  ----------------
replay_buffer/size              66300
trainer/QF1 Loss                    0.0895506
trainer/QF2 Loss                    0.083338
trainer/Policy Loss                12.2938
trainer/Q1 Predictions Mean       -12.4264
trainer/Q1 Predictions Std          0.0692281
trainer/Q1 Predictions Max        -12.3161
trainer/Q1 Predictions Min        -12.6232
trainer/Q2 Predictions Mean       -12.4392
trainer/Q2 Predictions Std          0.0707835
trainer/Q2 Predictions Max        -12.3104
trainer/Q2 Predictions Min        -12.633
trainer/Q Targets Mean            -12.6967
trainer/Q Targets Std               0.140498
trainer/Q Targets Max             -12.4272
trainer/Q Targets Min             -13.036
trainer/Bellman Errors 1 Mean       0.0895506
trainer/Bellman Errors 1 Std        0.0704471
trainer/Bellman Errors 1 Max        0.277027
trainer/Bellman Errors 1 Min        0.000383073
trainer/Bellman Errors 2 Mean       0.083338
trainer/Bellman Errors 2 Std        0.0668252
trainer/Bellman Errors 2 Max        0.26533
trainer/Bellman Errors 2 Min        2.01763e-07
trainer/Policy Action Mean         -0.00866108
trainer/Policy Action Std           0.116239
trainer/Policy Action Max           0.287332
trainer/Policy Action Min          -0.222313
exploration/num steps total     66300
exploration/num paths total       663
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143731
exploration/Rewards Std             0.0737329
exploration/Rewards Max            -0.0209211
exploration/Rewards Min            -0.371035
exploration/Returns Mean          -14.3731
exploration/Returns Std             0.14443
exploration/Returns Max           -14.2287
exploration/Returns Min           -14.5176
exploration/Actions Mean            0.00678103
exploration/Actions Std             0.162585
exploration/Actions Max             0.906142
exploration/Actions Min            -0.455214
exploration/Num Paths               2
exploration/Average Returns       -14.3731
evaluation/num steps total     165500
evaluation/num paths total       1655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0484805
evaluation/Rewards Std              0.0524626
evaluation/Rewards Max             -0.0221111
evaluation/Rewards Min             -0.981543
evaluation/Returns Mean            -4.84805
evaluation/Returns Std              0.329725
evaluation/Returns Max             -4.43673
evaluation/Returns Min             -5.41467
evaluation/Actions Mean             0.00626682
evaluation/Actions Std              0.0899526
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.993505
evaluation/Num Paths                5
evaluation/Average Returns         -4.84805
time/data storing (s)               0.00111223
time/evaluation sampling (s)        0.0729559
time/exploration sampling (s)       0.0327844
time/logging (s)                    0.00244475
time/saving (s)                     0.00222562
time/training (s)                   0.450227
time/epoch (s)                      0.56175
time/total (s)                    197.482
Epoch                             330
-----------------------------  ----------------
2019-04-13 17:01:52.590173 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 331 finished
-----------------------------  ----------------
replay_buffer/size              66500
trainer/QF1 Loss                    0.0268149
trainer/QF2 Loss                    0.0306044
trainer/Policy Loss                12.5895
trainer/Q1 Predictions Mean       -12.774
trainer/Q1 Predictions Std          0.746475
trainer/Q1 Predictions Max        -12.5373
trainer/Q1 Predictions Min        -16.9089
trainer/Q2 Predictions Mean       -12.7656
trainer/Q2 Predictions Std          0.693118
trainer/Q2 Predictions Max        -12.5136
trainer/Q2 Predictions Min        -16.6006
trainer/Q Targets Mean            -12.8634
trainer/Q Targets Std               0.752711
trainer/Q Targets Max             -12.5304
trainer/Q Targets Min             -16.9713
trainer/Bellman Errors 1 Mean       0.0268149
trainer/Bellman Errors 1 Std        0.0572778
trainer/Bellman Errors 1 Max        0.313876
trainer/Bellman Errors 1 Min        6.74854e-05
trainer/Bellman Errors 2 Mean       0.0306044
trainer/Bellman Errors 2 Std        0.0622927
trainer/Bellman Errors 2 Max        0.332803
trainer/Bellman Errors 2 Min        1.77843e-05
trainer/Policy Action Mean         -0.0122896
trainer/Policy Action Std           0.219432
trainer/Policy Action Max           1
trainer/Policy Action Min          -1
exploration/num steps total     66500
exploration/num paths total       665
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124158
exploration/Rewards Std             0.0691886
exploration/Rewards Max            -0.00627592
exploration/Rewards Min            -0.410564
exploration/Returns Mean          -12.4158
exploration/Returns Std             0.108161
exploration/Returns Max           -12.3076
exploration/Returns Min           -12.524
exploration/Actions Mean            0.00288865
exploration/Actions Std             0.172108
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.4158
evaluation/num steps total     166000
evaluation/num paths total       1660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0264152
evaluation/Rewards Std              0.0479221
evaluation/Rewards Max             -0.016901
evaluation/Rewards Min             -0.626028
evaluation/Returns Mean            -2.64152
evaluation/Returns Std              0.256778
evaluation/Returns Max             -2.18318
evaluation/Returns Min             -2.90959
evaluation/Actions Mean             0.00418134
evaluation/Actions Std              0.0817419
evaluation/Actions Max              0.999934
evaluation/Actions Min             -0.987315
evaluation/Num Paths                5
evaluation/Average Returns         -2.64152
time/data storing (s)               0.00111618
time/evaluation sampling (s)        0.0761586
time/exploration sampling (s)       0.0327872
time/logging (s)                    0.00247147
time/saving (s)                     0.00226448
time/training (s)                   0.447537
time/epoch (s)                      0.562335
time/total (s)                    198.049
Epoch                             331
-----------------------------  ----------------
2019-04-13 17:01:53.172415 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 332 finished
-----------------------------  ----------------
replay_buffer/size              66700
trainer/QF1 Loss                    0.0316344
trainer/QF2 Loss                    0.0325246
trainer/Policy Loss                12.5107
trainer/Q1 Predictions Mean       -12.6041
trainer/Q1 Predictions Std          0.116776
trainer/Q1 Predictions Max        -12.492
trainer/Q1 Predictions Min        -13.1968
trainer/Q2 Predictions Mean       -12.6074
trainer/Q2 Predictions Std          0.130676
trainer/Q2 Predictions Max        -12.5131
trainer/Q2 Predictions Min        -13.2861
trainer/Q Targets Mean            -12.6899
trainer/Q Targets Std               0.184753
trainer/Q Targets Max             -12.4153
trainer/Q Targets Min             -13.1652
trainer/Bellman Errors 1 Mean       0.0316344
trainer/Bellman Errors 1 Std        0.0596719
trainer/Bellman Errors 1 Max        0.29177
trainer/Bellman Errors 1 Min        5.13502e-05
trainer/Bellman Errors 2 Mean       0.0325246
trainer/Bellman Errors 2 Std        0.0574033
trainer/Bellman Errors 2 Max        0.274755
trainer/Bellman Errors 2 Min        7.84593e-05
trainer/Policy Action Mean          0.0495431
trainer/Policy Action Std           0.170724
trainer/Policy Action Max           0.999898
trainer/Policy Action Min          -0.206884
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124744
exploration/Rewards Std             0.0669821
exploration/Rewards Max            -0.00739899
exploration/Rewards Min            -0.337437
exploration/Returns Mean          -12.4744
exploration/Returns Std             0.840557
exploration/Returns Max           -11.6339
exploration/Returns Min           -13.315
exploration/Actions Mean            0.00399628
exploration/Actions Std             0.151695
exploration/Actions Max             0.946451
exploration/Actions Min            -0.447506
exploration/Num Paths               2
exploration/Average Returns       -12.4744
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0244603
evaluation/Rewards Std              0.0554852
evaluation/Rewards Max             -0.0186882
evaluation/Rewards Min             -0.911516
evaluation/Returns Mean            -2.44603
evaluation/Returns Std              0.262516
evaluation/Returns Max             -2.16123
evaluation/Returns Min             -2.89037
evaluation/Actions Mean             0.00562845
evaluation/Actions Std              0.0914039
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.995897
evaluation/Num Paths                5
evaluation/Average Returns         -2.44603
time/data storing (s)               0.00104663
time/evaluation sampling (s)        0.0760651
time/exploration sampling (s)       0.0330701
time/logging (s)                    0.00251151
time/saving (s)                     0.00224031
time/training (s)                   0.458372
time/epoch (s)                      0.573306
time/total (s)                    198.626
Epoch                             332
-----------------------------  ----------------
2019-04-13 17:01:53.757557 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 333 finished
-----------------------------  ----------------
replay_buffer/size              66900
trainer/QF1 Loss                    4.89348
trainer/QF2 Loss                    4.90012
trainer/Policy Loss                12.4423
trainer/Q1 Predictions Mean       -12.6138
trainer/Q1 Predictions Std          0.0641552
trainer/Q1 Predictions Max        -12.5187
trainer/Q1 Predictions Min        -12.7682
trainer/Q2 Predictions Mean       -12.6114
trainer/Q2 Predictions Std          0.0720231
trainer/Q2 Predictions Max        -12.4828
trainer/Q2 Predictions Min        -12.7955
trainer/Q Targets Mean            -12.3071
trainer/Q Targets Std               2.19106
trainer/Q Targets Max              -0.126411
trainer/Q Targets Min             -12.9243
trainer/Bellman Errors 1 Mean       4.89348
trainer/Bellman Errors 1 Std       27.1245
trainer/Bellman Errors 1 Max      155.916
trainer/Bellman Errors 1 Min        4.07992e-06
trainer/Bellman Errors 2 Mean       4.90012
trainer/Bellman Errors 2 Std       27.1475
trainer/Bellman Errors 2 Max      156.051
trainer/Bellman Errors 2 Min        2.63346e-05
trainer/Policy Action Mean          0.0439096
trainer/Policy Action Std           0.105279
trainer/Policy Action Max           0.292639
trainer/Policy Action Min          -0.195289
exploration/num steps total     66900
exploration/num paths total       669
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140467
exploration/Rewards Std             0.092853
exploration/Rewards Max            -0.0159744
exploration/Rewards Min            -0.937544
exploration/Returns Mean          -14.0467
exploration/Returns Std             0.921962
exploration/Returns Max           -13.1247
exploration/Returns Min           -14.9686
exploration/Actions Mean            0.00689804
exploration/Actions Std             0.155442
exploration/Actions Max             0.961812
exploration/Actions Min            -0.371953
exploration/Num Paths               2
exploration/Average Returns       -14.0467
evaluation/num steps total     167000
evaluation/num paths total       1670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0782867
evaluation/Rewards Std              0.0305224
evaluation/Rewards Max             -0.00734495
evaluation/Rewards Min             -0.590758
evaluation/Returns Mean            -7.82867
evaluation/Returns Std              0.192988
evaluation/Returns Max             -7.61294
evaluation/Returns Min             -8.10493
evaluation/Actions Mean             0.00509594
evaluation/Actions Std              0.0831385
evaluation/Actions Max              0.999946
evaluation/Actions Min             -0.954766
evaluation/Num Paths                5
evaluation/Average Returns         -7.82867
time/data storing (s)               0.00117958
time/evaluation sampling (s)        0.0763496
time/exploration sampling (s)       0.0336857
time/logging (s)                    0.00247817
time/saving (s)                     0.00222206
time/training (s)                   0.461064
time/epoch (s)                      0.576979
time/total (s)                    199.207
Epoch                             333
-----------------------------  ----------------
2019-04-13 17:01:54.335549 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 334 finished
-----------------------------  ----------------
replay_buffer/size              67100
trainer/QF1 Loss                    0.0303971
trainer/QF2 Loss                    0.0300429
trainer/Policy Loss                12.4989
trainer/Q1 Predictions Mean       -12.5668
trainer/Q1 Predictions Std          0.0626822
trainer/Q1 Predictions Max        -12.4219
trainer/Q1 Predictions Min        -12.6687
trainer/Q2 Predictions Mean       -12.5659
trainer/Q2 Predictions Std          0.0627116
trainer/Q2 Predictions Max        -12.4205
trainer/Q2 Predictions Min        -12.6704
trainer/Q Targets Mean            -12.6366
trainer/Q Targets Std               0.162765
trainer/Q Targets Max             -12.4021
trainer/Q Targets Min             -13.1229
trainer/Bellman Errors 1 Mean       0.0303971
trainer/Bellman Errors 1 Std        0.0550302
trainer/Bellman Errors 1 Max        0.247159
trainer/Bellman Errors 1 Min        7.92384e-05
trainer/Bellman Errors 2 Mean       0.0300429
trainer/Bellman Errors 2 Std        0.0552657
trainer/Bellman Errors 2 Max        0.244999
trainer/Bellman Errors 2 Min        2.75122e-05
trainer/Policy Action Mean          0.0347911
trainer/Policy Action Std           0.106966
trainer/Policy Action Max           0.316658
trainer/Policy Action Min          -0.238052
exploration/num steps total     67100
exploration/num paths total       671
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.152526
exploration/Rewards Std             0.0758399
exploration/Rewards Max            -0.0191779
exploration/Rewards Min            -0.52968
exploration/Returns Mean          -15.2526
exploration/Returns Std             0.844054
exploration/Returns Max           -14.4086
exploration/Returns Min           -16.0967
exploration/Actions Mean            0.00501418
exploration/Actions Std             0.165531
exploration/Actions Max             0.961397
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -15.2526
evaluation/num steps total     167500
evaluation/num paths total       1675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0808644
evaluation/Rewards Std              0.0418458
evaluation/Rewards Max             -0.0211423
evaluation/Rewards Min             -0.948196
evaluation/Returns Mean            -8.08644
evaluation/Returns Std              0.344158
evaluation/Returns Max             -7.79281
evaluation/Returns Min             -8.74737
evaluation/Actions Mean             0.00760211
evaluation/Actions Std              0.077792
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.2372
evaluation/Num Paths                5
evaluation/Average Returns         -8.08644
time/data storing (s)               0.0011229
time/evaluation sampling (s)        0.0752205
time/exploration sampling (s)       0.0332817
time/logging (s)                    0.00247526
time/saving (s)                     0.00231277
time/training (s)                   0.454518
time/epoch (s)                      0.568931
time/total (s)                    199.78
Epoch                             334
-----------------------------  ----------------
2019-04-13 17:01:54.917466 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 335 finished
-----------------------------  ----------------
replay_buffer/size              67300
trainer/QF1 Loss                    0.0656656
trainer/QF2 Loss                    0.0703147
trainer/Policy Loss                12.5173
trainer/Q1 Predictions Mean       -12.5747
trainer/Q1 Predictions Std          0.303972
trainer/Q1 Predictions Max        -12.3956
trainer/Q1 Predictions Min        -13.9123
trainer/Q2 Predictions Mean       -12.5618
trainer/Q2 Predictions Std          0.30188
trainer/Q2 Predictions Max        -12.3899
trainer/Q2 Predictions Min        -13.9197
trainer/Q Targets Mean            -12.7519
trainer/Q Targets Std               0.291015
trainer/Q Targets Max             -12.4051
trainer/Q Targets Min             -13.8426
trainer/Bellman Errors 1 Mean       0.0656656
trainer/Bellman Errors 1 Std        0.0886155
trainer/Bellman Errors 1 Max        0.419684
trainer/Bellman Errors 1 Min        9.06042e-05
trainer/Bellman Errors 2 Mean       0.0703148
trainer/Bellman Errors 2 Std        0.0923288
trainer/Bellman Errors 2 Max        0.437962
trainer/Bellman Errors 2 Min        1.08755e-05
trainer/Policy Action Mean          0.0632177
trainer/Policy Action Std           0.243542
trainer/Policy Action Max           0.872676
trainer/Policy Action Min          -0.392966
exploration/num steps total     67300
exploration/num paths total       673
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.145462
exploration/Rewards Std             0.0762533
exploration/Rewards Max            -0.0116454
exploration/Rewards Min            -0.464982
exploration/Returns Mean          -14.5462
exploration/Returns Std             0.439438
exploration/Returns Max           -14.1068
exploration/Returns Min           -14.9856
exploration/Actions Mean            0.00543552
exploration/Actions Std             0.164845
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.5462
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0662693
evaluation/Rewards Std              0.0400179
evaluation/Rewards Max             -0.0107602
evaluation/Rewards Min             -0.941202
evaluation/Returns Mean            -6.62693
evaluation/Returns Std              0.337473
evaluation/Returns Max             -6.38273
evaluation/Returns Min             -7.2816
evaluation/Actions Mean             0.00514782
evaluation/Actions Std              0.0857715
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.983983
evaluation/Num Paths                5
evaluation/Average Returns         -6.62693
time/data storing (s)               0.00111902
time/evaluation sampling (s)        0.0756935
time/exploration sampling (s)       0.0321986
time/logging (s)                    0.00248325
time/saving (s)                     0.00246066
time/training (s)                   0.458949
time/epoch (s)                      0.572904
time/total (s)                    200.357
Epoch                             335
-----------------------------  ----------------
2019-04-13 17:01:55.500412 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 336 finished
-----------------------------  ----------------
replay_buffer/size              67500
trainer/QF1 Loss                    0.0495659
trainer/QF2 Loss                    0.0526846
trainer/Policy Loss                12.5572
trainer/Q1 Predictions Mean       -12.6035
trainer/Q1 Predictions Std          0.0903451
trainer/Q1 Predictions Max        -12.4819
trainer/Q1 Predictions Min        -12.8281
trainer/Q2 Predictions Mean       -12.6088
trainer/Q2 Predictions Std          0.104286
trainer/Q2 Predictions Max        -12.4601
trainer/Q2 Predictions Min        -12.8981
trainer/Q Targets Mean            -12.691
trainer/Q Targets Std               0.175615
trainer/Q Targets Max             -12.4222
trainer/Q Targets Min             -13.3202
trainer/Bellman Errors 1 Mean       0.0495659
trainer/Bellman Errors 1 Std        0.113086
trainer/Bellman Errors 1 Max        0.633854
trainer/Bellman Errors 1 Min        2.0555e-05
trainer/Bellman Errors 2 Mean       0.0526846
trainer/Bellman Errors 2 Std        0.116099
trainer/Bellman Errors 2 Max        0.63979
trainer/Bellman Errors 2 Min        2.09301e-06
trainer/Policy Action Mean          0.0184407
trainer/Policy Action Std           0.155576
trainer/Policy Action Max           0.718103
trainer/Policy Action Min          -0.342408
exploration/num steps total     67500
exploration/num paths total       675
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.165215
exploration/Rewards Std             0.0825533
exploration/Rewards Max            -0.01999
exploration/Rewards Min            -0.463116
exploration/Returns Mean          -16.5215
exploration/Returns Std             1.05832
exploration/Returns Max           -15.4632
exploration/Returns Min           -17.5798
exploration/Actions Mean           -0.000703939
exploration/Actions Std             0.153135
exploration/Actions Max             0.721208
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -16.5215
evaluation/num steps total     168500
evaluation/num paths total       1685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.10412
evaluation/Rewards Std              0.0272743
evaluation/Rewards Max             -0.0240205
evaluation/Rewards Min             -0.703092
evaluation/Returns Mean           -10.412
evaluation/Returns Std              0.24727
evaluation/Returns Max            -10.2552
evaluation/Returns Min            -10.9036
evaluation/Actions Mean             0.00345744
evaluation/Actions Std              0.0615992
evaluation/Actions Max              0.99985
evaluation/Actions Min             -0.950975
evaluation/Num Paths                5
evaluation/Average Returns        -10.412
time/data storing (s)               0.00123031
time/evaluation sampling (s)        0.0724876
time/exploration sampling (s)       0.0334888
time/logging (s)                    0.00246954
time/saving (s)                     0.00222766
time/training (s)                   0.461965
time/epoch (s)                      0.573869
time/total (s)                    200.935
Epoch                             336
-----------------------------  ----------------
2019-04-13 17:01:56.101693 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 337 finished
-----------------------------  ----------------
replay_buffer/size              67700
trainer/QF1 Loss                    0.0563942
trainer/QF2 Loss                    0.0591612
trainer/Policy Loss                12.582
trainer/Q1 Predictions Mean       -12.6253
trainer/Q1 Predictions Std          0.409889
trainer/Q1 Predictions Max        -12.428
trainer/Q1 Predictions Min        -14.8805
trainer/Q2 Predictions Mean       -12.6156
trainer/Q2 Predictions Std          0.401352
trainer/Q2 Predictions Max        -12.4245
trainer/Q2 Predictions Min        -14.823
trainer/Q Targets Mean            -12.7869
trainer/Q Targets Std               0.350475
trainer/Q Targets Max             -12.5224
trainer/Q Targets Min             -14.5139
trainer/Bellman Errors 1 Mean       0.0563942
trainer/Bellman Errors 1 Std        0.0707095
trainer/Bellman Errors 1 Max        0.284306
trainer/Bellman Errors 1 Min        1.15108e-06
trainer/Bellman Errors 2 Mean       0.0591612
trainer/Bellman Errors 2 Std        0.0741094
trainer/Bellman Errors 2 Max        0.312369
trainer/Bellman Errors 2 Min        8.46612e-06
trainer/Policy Action Mean          0.0411611
trainer/Policy Action Std           0.152811
trainer/Policy Action Max           0.999028
trainer/Policy Action Min          -0.216774
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142663
exploration/Rewards Std             0.0713718
exploration/Rewards Max            -0.0096515
exploration/Rewards Min            -0.375001
exploration/Returns Mean          -14.2663
exploration/Returns Std             0.603628
exploration/Returns Max           -13.6627
exploration/Returns Min           -14.8699
exploration/Actions Mean            0.00550301
exploration/Actions Std             0.156374
exploration/Actions Max             1
exploration/Actions Min            -0.444124
exploration/Num Paths               2
exploration/Average Returns       -14.2663
evaluation/num steps total     169000
evaluation/num paths total       1690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0500311
evaluation/Rewards Std              0.0528261
evaluation/Rewards Max             -0.0329504
evaluation/Rewards Min             -0.968069
evaluation/Returns Mean            -5.00311
evaluation/Returns Std              0.407965
evaluation/Returns Max             -4.58115
evaluation/Returns Min             -5.61353
evaluation/Actions Mean             0.00436372
evaluation/Actions Std              0.075679
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.992392
evaluation/Num Paths                5
evaluation/Average Returns         -5.00311
time/data storing (s)               0.00111622
time/evaluation sampling (s)        0.0737685
time/exploration sampling (s)       0.0332207
time/logging (s)                    0.00247256
time/saving (s)                     0.00232015
time/training (s)                   0.479391
time/epoch (s)                      0.592289
time/total (s)                    201.531
Epoch                             337
-----------------------------  ----------------
2019-04-13 17:01:56.675693 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 338 finished
-----------------------------  ----------------
replay_buffer/size              67900
trainer/QF1 Loss                    4.85109
trainer/QF2 Loss                    4.85292
trainer/Policy Loss                12.3911
trainer/Q1 Predictions Mean       -12.557
trainer/Q1 Predictions Std          0.126105
trainer/Q1 Predictions Max        -12.4091
trainer/Q1 Predictions Min        -12.9972
trainer/Q2 Predictions Mean       -12.547
trainer/Q2 Predictions Std          0.124212
trainer/Q2 Predictions Max        -12.3976
trainer/Q2 Predictions Min        -12.9626
trainer/Q Targets Mean            -12.3215
trainer/Q Targets Std               2.19723
trainer/Q Targets Max              -0.118093
trainer/Q Targets Min             -13.0212
trainer/Bellman Errors 1 Mean       4.85109
trainer/Bellman Errors 1 Std       26.7318
trainer/Bellman Errors 1 Max      153.687
trainer/Bellman Errors 1 Min        4.58388e-06
trainer/Bellman Errors 2 Mean       4.85292
trainer/Bellman Errors 2 Std       26.7248
trainer/Bellman Errors 2 Max      153.65
trainer/Bellman Errors 2 Min        4.94009e-07
trainer/Policy Action Mean          0.00127696
trainer/Policy Action Std           0.109813
trainer/Policy Action Max           0.2433
trainer/Policy Action Min          -0.241494
exploration/num steps total     67900
exploration/num paths total       679
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130058
exploration/Rewards Std             0.0925028
exploration/Rewards Max            -0.0137333
exploration/Rewards Min            -1.01352
exploration/Returns Mean          -13.0058
exploration/Returns Std             0.503305
exploration/Returns Max           -12.5025
exploration/Returns Min           -13.5091
exploration/Actions Mean            0.00579571
exploration/Actions Std             0.164302
exploration/Actions Max             1
exploration/Actions Min            -0.639332
exploration/Num Paths               2
exploration/Average Returns       -13.0058
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.01998
evaluation/Rewards Std              0.0364792
evaluation/Rewards Max             -0.0134998
evaluation/Rewards Min             -0.691338
evaluation/Returns Mean            -1.998
evaluation/Returns Std              0.271101
evaluation/Returns Max             -1.71701
evaluation/Returns Min             -2.46515
evaluation/Actions Mean             0.00627638
evaluation/Actions Std              0.0664273
evaluation/Actions Max              0.999906
evaluation/Actions Min             -0.389222
evaluation/Num Paths                5
evaluation/Average Returns         -1.998
time/data storing (s)               0.00110518
time/evaluation sampling (s)        0.0738026
time/exploration sampling (s)       0.0329792
time/logging (s)                    0.00251911
time/saving (s)                     0.0022517
time/training (s)                   0.452251
time/epoch (s)                      0.564909
time/total (s)                    202.1
Epoch                             338
-----------------------------  ----------------
2019-04-13 17:01:57.260476 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 339 finished
-----------------------------  ---------------
replay_buffer/size              68100
trainer/QF1 Loss                    0.14257
trainer/QF2 Loss                    0.151988
trainer/Policy Loss                12.3605
trainer/Q1 Predictions Mean       -12.3868
trainer/Q1 Predictions Std          0.216025
trainer/Q1 Predictions Max        -12.2185
trainer/Q1 Predictions Min        -13.5246
trainer/Q2 Predictions Mean       -12.367
trainer/Q2 Predictions Std          0.208284
trainer/Q2 Predictions Max        -12.2268
trainer/Q2 Predictions Min        -13.4744
trainer/Q Targets Mean            -12.7153
trainer/Q Targets Std               0.209897
trainer/Q Targets Max             -12.4173
trainer/Q Targets Min             -13.4021
trainer/Bellman Errors 1 Mean       0.14257
trainer/Bellman Errors 1 Std        0.146241
trainer/Bellman Errors 1 Max        0.607715
trainer/Bellman Errors 1 Min        0.00349914
trainer/Bellman Errors 2 Mean       0.151988
trainer/Bellman Errors 2 Std        0.140242
trainer/Bellman Errors 2 Max        0.585777
trainer/Bellman Errors 2 Min        0.00521626
trainer/Policy Action Mean          0.0256292
trainer/Policy Action Std           0.180453
trainer/Policy Action Max           0.999993
trainer/Policy Action Min          -0.196462
exploration/num steps total     68100
exploration/num paths total       681
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140827
exploration/Rewards Std             0.0826795
exploration/Rewards Max            -0.0200886
exploration/Rewards Min            -0.775981
exploration/Returns Mean          -14.0827
exploration/Returns Std             0.18696
exploration/Returns Max           -13.8957
exploration/Returns Min           -14.2696
exploration/Actions Mean            0.0058199
exploration/Actions Std             0.15835
exploration/Actions Max             0.956327
exploration/Actions Min            -0.404725
exploration/Num Paths               2
exploration/Average Returns       -14.0827
evaluation/num steps total     170000
evaluation/num paths total       1700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0566603
evaluation/Rewards Std              0.0438755
evaluation/Rewards Max             -0.0335697
evaluation/Rewards Min             -0.956743
evaluation/Returns Mean            -5.66603
evaluation/Returns Std              0.340626
evaluation/Returns Max             -5.34804
evaluation/Returns Min             -6.29036
evaluation/Actions Mean             0.00592386
evaluation/Actions Std              0.081251
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.987152
evaluation/Num Paths                5
evaluation/Average Returns         -5.66603
time/data storing (s)               0.00123682
time/evaluation sampling (s)        0.074031
time/exploration sampling (s)       0.0343272
time/logging (s)                    0.00202998
time/saving (s)                     0.00227255
time/training (s)                   0.461348
time/epoch (s)                      0.575246
time/total (s)                    202.679
Epoch                             339
-----------------------------  ---------------
2019-04-13 17:01:57.884812 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 340 finished
-----------------------------  ----------------
replay_buffer/size              68300
trainer/QF1 Loss                    0.0202392
trainer/QF2 Loss                    0.0226355
trainer/Policy Loss                12.5334
trainer/Q1 Predictions Mean       -12.6966
trainer/Q1 Predictions Std          0.382538
trainer/Q1 Predictions Max        -12.5269
trainer/Q1 Predictions Min        -14.7773
trainer/Q2 Predictions Mean       -12.6907
trainer/Q2 Predictions Std          0.358088
trainer/Q2 Predictions Max        -12.5215
trainer/Q2 Predictions Min        -14.632
trainer/Q Targets Mean            -12.6991
trainer/Q Targets Std               0.41154
trainer/Q Targets Max             -12.3282
trainer/Q Targets Min             -14.7816
trainer/Bellman Errors 1 Mean       0.0202392
trainer/Bellman Errors 1 Std        0.0211996
trainer/Bellman Errors 1 Max        0.0809582
trainer/Bellman Errors 1 Min        1.59748e-05
trainer/Bellman Errors 2 Mean       0.0226355
trainer/Bellman Errors 2 Std        0.0219715
trainer/Bellman Errors 2 Max        0.0995512
trainer/Bellman Errors 2 Min        3.96176e-07
trainer/Policy Action Mean          0.0286304
trainer/Policy Action Std           0.187505
trainer/Policy Action Max           0.998748
trainer/Policy Action Min          -0.234843
exploration/num steps total     68300
exploration/num paths total       683
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135558
exploration/Rewards Std             0.0908755
exploration/Rewards Max            -0.0031012
exploration/Rewards Min            -0.993632
exploration/Returns Mean          -13.5558
exploration/Returns Std             0.915286
exploration/Returns Max           -12.6405
exploration/Returns Min           -14.4711
exploration/Actions Mean            0.0101969
exploration/Actions Std             0.16496
exploration/Actions Max             1
exploration/Actions Min            -0.390966
exploration/Num Paths               2
exploration/Average Returns       -13.5558
evaluation/num steps total     170500
evaluation/num paths total       1705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0357362
evaluation/Rewards Std              0.0486113
evaluation/Rewards Max             -0.0294909
evaluation/Rewards Min             -0.92907
evaluation/Returns Mean            -3.57362
evaluation/Returns Std              0.314636
evaluation/Returns Max             -3.23713
evaluation/Returns Min             -4.14586
evaluation/Actions Mean             0.00585681
evaluation/Actions Std              0.0897841
evaluation/Actions Max              0.999993
evaluation/Actions Min             -0.975975
evaluation/Num Paths                5
evaluation/Average Returns         -3.57362
time/data storing (s)               0.0011209
time/evaluation sampling (s)        0.07623
time/exploration sampling (s)       0.0329839
time/logging (s)                    0.00236267
time/saving (s)                     0.00179501
time/training (s)                   0.502498
time/epoch (s)                      0.616991
time/total (s)                    203.3
Epoch                             340
-----------------------------  ----------------
2019-04-13 17:01:58.473266 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 341 finished
-----------------------------  ----------------
replay_buffer/size              68500
trainer/QF1 Loss                    0.073983
trainer/QF2 Loss                    0.0702491
trainer/Policy Loss                12.3091
trainer/Q1 Predictions Mean       -12.399
trainer/Q1 Predictions Std          0.0588687
trainer/Q1 Predictions Max        -12.3058
trainer/Q1 Predictions Min        -12.5688
trainer/Q2 Predictions Mean       -12.4121
trainer/Q2 Predictions Std          0.0614361
trainer/Q2 Predictions Max        -12.3015
trainer/Q2 Predictions Min        -12.615
trainer/Q Targets Mean            -12.6165
trainer/Q Targets Std               0.156269
trainer/Q Targets Max             -12.3707
trainer/Q Targets Min             -13.0304
trainer/Bellman Errors 1 Mean       0.073983
trainer/Bellman Errors 1 Std        0.100662
trainer/Bellman Errors 1 Max        0.406115
trainer/Bellman Errors 1 Min        9.79741e-05
trainer/Bellman Errors 2 Mean       0.0702491
trainer/Bellman Errors 2 Std        0.0990745
trainer/Bellman Errors 2 Max        0.391974
trainer/Bellman Errors 2 Min        1.08255e-06
trainer/Policy Action Mean          0.036135
trainer/Policy Action Std           0.0867172
trainer/Policy Action Max           0.216046
trainer/Policy Action Min          -0.170952
exploration/num steps total     68500
exploration/num paths total       685
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.159659
exploration/Rewards Std             0.087223
exploration/Rewards Max            -0.00858934
exploration/Rewards Min            -0.550224
exploration/Returns Mean          -15.9659
exploration/Returns Std             0.432056
exploration/Returns Max           -15.5338
exploration/Returns Min           -16.3979
exploration/Actions Mean            0.00981794
exploration/Actions Std             0.168341
exploration/Actions Max             0.924977
exploration/Actions Min            -0.422376
exploration/Num Paths               2
exploration/Average Returns       -15.9659
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0793799
evaluation/Rewards Std              0.0474185
evaluation/Rewards Max             -0.0541482
evaluation/Rewards Min             -0.89879
evaluation/Returns Mean            -7.93799
evaluation/Returns Std              0.324583
evaluation/Returns Max             -7.54981
evaluation/Returns Min             -8.3876
evaluation/Actions Mean             0.00716013
evaluation/Actions Std              0.0843237
evaluation/Actions Max              0.999988
evaluation/Actions Min             -0.988
evaluation/Num Paths                5
evaluation/Average Returns         -7.93799
time/data storing (s)               0.00120889
time/evaluation sampling (s)        0.0754887
time/exploration sampling (s)       0.032494
time/logging (s)                    0.00247015
time/saving (s)                     0.00223064
time/training (s)                   0.466728
time/epoch (s)                      0.580621
time/total (s)                    203.885
Epoch                             341
-----------------------------  ----------------
2019-04-13 17:01:59.054774 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 342 finished
-----------------------------  ----------------
replay_buffer/size              68700
trainer/QF1 Loss                    4.78861
trainer/QF2 Loss                    4.80119
trainer/Policy Loss                12.4457
trainer/Q1 Predictions Mean       -12.5876
trainer/Q1 Predictions Std          0.239024
trainer/Q1 Predictions Max        -12.4054
trainer/Q1 Predictions Min        -13.467
trainer/Q2 Predictions Mean       -12.586
trainer/Q2 Predictions Std          0.230572
trainer/Q2 Predictions Max        -12.4121
trainer/Q2 Predictions Min        -13.4569
trainer/Q Targets Mean            -12.3417
trainer/Q Targets Std               2.19106
trainer/Q Targets Max              -0.205897
trainer/Q Targets Min             -13.4162
trainer/Bellman Errors 1 Mean       4.78861
trainer/Bellman Errors 1 Std       26.4339
trainer/Bellman Errors 1 Max      151.966
trainer/Bellman Errors 1 Min        1.04705e-05
trainer/Bellman Errors 2 Mean       4.80119
trainer/Bellman Errors 2 Std       26.4971
trainer/Bellman Errors 2 Max      152.33
trainer/Bellman Errors 2 Min        1.31746e-05
trainer/Policy Action Mean          0.0154491
trainer/Policy Action Std           0.231698
trainer/Policy Action Max           0.999005
trainer/Policy Action Min          -0.790584
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.150737
exploration/Rewards Std             0.0805382
exploration/Rewards Max            -0.00773245
exploration/Rewards Min            -0.444841
exploration/Returns Mean          -15.0737
exploration/Returns Std             1.19814
exploration/Returns Max           -13.8755
exploration/Returns Min           -16.2718
exploration/Actions Mean            0.00631296
exploration/Actions Std             0.164227
exploration/Actions Max             1
exploration/Actions Min            -0.861621
exploration/Num Paths               2
exploration/Average Returns       -15.0737
evaluation/num steps total     171500
evaluation/num paths total       1715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0812093
evaluation/Rewards Std              0.0540508
evaluation/Rewards Max             -0.0645518
evaluation/Rewards Min             -0.959368
evaluation/Returns Mean            -8.12093
evaluation/Returns Std              0.356002
evaluation/Returns Max             -7.76781
evaluation/Returns Min             -8.5895
evaluation/Actions Mean             0.00388888
evaluation/Actions Std              0.0823868
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.939364
evaluation/Num Paths                5
evaluation/Average Returns         -8.12093
time/data storing (s)               0.00106452
time/evaluation sampling (s)        0.0727297
time/exploration sampling (s)       0.0337333
time/logging (s)                    0.00189314
time/saving (s)                     0.00218344
time/training (s)                   0.460475
time/epoch (s)                      0.572079
time/total (s)                    204.461
Epoch                             342
-----------------------------  ----------------
2019-04-13 17:01:59.633052 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 343 finished
-----------------------------  ----------------
replay_buffer/size              68900
trainer/QF1 Loss                    4.79991
trainer/QF2 Loss                    4.82273
trainer/Policy Loss                12.225
trainer/Q1 Predictions Mean       -12.4554
trainer/Q1 Predictions Std          0.343739
trainer/Q1 Predictions Max        -12.2484
trainer/Q1 Predictions Min        -14.0169
trainer/Q2 Predictions Mean       -12.4536
trainer/Q2 Predictions Std          0.313636
trainer/Q2 Predictions Max        -12.2417
trainer/Q2 Predictions Min        -13.7759
trainer/Q Targets Mean            -12.3722
trainer/Q Targets Std               2.22619
trainer/Q Targets Max              -0.112259
trainer/Q Targets Min             -13.9877
trainer/Bellman Errors 1 Mean       4.79991
trainer/Bellman Errors 1 Std       26.0639
trainer/Bellman Errors 1 Max      149.917
trainer/Bellman Errors 1 Min        0.000847334
trainer/Bellman Errors 2 Mean       4.82273
trainer/Bellman Errors 2 Std       26.1875
trainer/Bellman Errors 2 Max      150.628
trainer/Bellman Errors 2 Min        0.000520165
trainer/Policy Action Mean         -0.0335137
trainer/Policy Action Std           0.277552
trainer/Policy Action Max           0.956579
trainer/Policy Action Min          -0.999319
exploration/num steps total     68900
exploration/num paths total       689
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136985
exploration/Rewards Std             0.0676304
exploration/Rewards Max            -0.00476476
exploration/Rewards Min            -0.399814
exploration/Returns Mean          -13.6985
exploration/Returns Std             0.0411047
exploration/Returns Max           -13.6574
exploration/Returns Min           -13.7396
exploration/Actions Mean            0.00674481
exploration/Actions Std             0.162221
exploration/Actions Max             0.964014
exploration/Actions Min            -0.664514
exploration/Num Paths               2
exploration/Average Returns       -13.6985
evaluation/num steps total     172000
evaluation/num paths total       1720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.052368
evaluation/Rewards Std              0.0444245
evaluation/Rewards Max             -0.0427288
evaluation/Rewards Min             -0.907892
evaluation/Returns Mean            -5.2368
evaluation/Returns Std              0.350516
evaluation/Returns Max             -4.94383
evaluation/Returns Min             -5.84365
evaluation/Actions Mean             0.00538854
evaluation/Actions Std              0.0767085
evaluation/Actions Max              0.999982
evaluation/Actions Min             -0.895246
evaluation/Num Paths                5
evaluation/Average Returns         -5.2368
time/data storing (s)               0.00132638
time/evaluation sampling (s)        0.0767681
time/exploration sampling (s)       0.0322919
time/logging (s)                    0.00241546
time/saving (s)                     0.00199953
time/training (s)                   0.455495
time/epoch (s)                      0.570296
time/total (s)                    205.035
Epoch                             343
-----------------------------  ----------------
2019-04-13 17:02:00.215141 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 344 finished
-----------------------------  ----------------
replay_buffer/size              69100
trainer/QF1 Loss                    0.0240331
trainer/QF2 Loss                    0.0248924
trainer/Policy Loss                12.5394
trainer/Q1 Predictions Mean       -12.6237
trainer/Q1 Predictions Std          0.0888126
trainer/Q1 Predictions Max        -12.4963
trainer/Q1 Predictions Min        -12.8231
trainer/Q2 Predictions Mean       -12.6179
trainer/Q2 Predictions Std          0.0941613
trainer/Q2 Predictions Max        -12.4899
trainer/Q2 Predictions Min        -12.813
trainer/Q Targets Mean            -12.7066
trainer/Q Targets Std               0.157004
trainer/Q Targets Max             -12.3404
trainer/Q Targets Min             -13.1215
trainer/Bellman Errors 1 Mean       0.0240331
trainer/Bellman Errors 1 Std        0.0328754
trainer/Bellman Errors 1 Max        0.113587
trainer/Bellman Errors 1 Min        2.01917e-08
trainer/Bellman Errors 2 Mean       0.0248924
trainer/Bellman Errors 2 Std        0.0347115
trainer/Bellman Errors 2 Max        0.119377
trainer/Bellman Errors 2 Min        6.82314e-06
trainer/Policy Action Mean          0.00203496
trainer/Policy Action Std           0.109478
trainer/Policy Action Max           0.357673
trainer/Policy Action Min          -0.311249
exploration/num steps total     69100
exploration/num paths total       691
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126393
exploration/Rewards Std             0.0677145
exploration/Rewards Max            -0.0050879
exploration/Rewards Min            -0.335202
exploration/Returns Mean          -12.6393
exploration/Returns Std             0.306292
exploration/Returns Max           -12.333
exploration/Returns Min           -12.9455
exploration/Actions Mean            0.00288647
exploration/Actions Std             0.141337
exploration/Actions Max             0.447729
exploration/Actions Min            -0.42816
exploration/Num Paths               2
exploration/Average Returns       -12.6393
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0161577
evaluation/Rewards Std              0.0130632
evaluation/Rewards Max             -0.00753399
evaluation/Rewards Min             -0.201156
evaluation/Returns Mean            -1.61577
evaluation/Returns Std              0.0548194
evaluation/Returns Max             -1.54615
evaluation/Returns Min             -1.68204
evaluation/Actions Mean             0.0041071
evaluation/Actions Std              0.0683971
evaluation/Actions Max              0.992767
evaluation/Actions Min             -0.997399
evaluation/Num Paths                5
evaluation/Average Returns         -1.61577
time/data storing (s)               0.00105292
time/evaluation sampling (s)        0.075588
time/exploration sampling (s)       0.0331123
time/logging (s)                    0.00207725
time/saving (s)                     0.00180927
time/training (s)                   0.458945
time/epoch (s)                      0.572585
time/total (s)                    205.612
Epoch                             344
-----------------------------  ----------------
2019-04-13 17:02:00.809582 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 345 finished
-----------------------------  ----------------
replay_buffer/size              69300
trainer/QF1 Loss                    0.0284296
trainer/QF2 Loss                    0.0280678
trainer/Policy Loss                12.5466
trainer/Q1 Predictions Mean       -12.652
trainer/Q1 Predictions Std          0.0774052
trainer/Q1 Predictions Max        -12.5429
trainer/Q1 Predictions Min        -12.9488
trainer/Q2 Predictions Mean       -12.6652
trainer/Q2 Predictions Std          0.0805311
trainer/Q2 Predictions Max        -12.5479
trainer/Q2 Predictions Min        -12.9773
trainer/Q Targets Mean            -12.6975
trainer/Q Targets Std               0.174773
trainer/Q Targets Max             -12.3764
trainer/Q Targets Min             -13.1152
trainer/Bellman Errors 1 Mean       0.0284296
trainer/Bellman Errors 1 Std        0.0334332
trainer/Bellman Errors 1 Max        0.116949
trainer/Bellman Errors 1 Min        5.02268e-08
trainer/Bellman Errors 2 Mean       0.0280678
trainer/Bellman Errors 2 Std        0.0316902
trainer/Bellman Errors 2 Max        0.110028
trainer/Bellman Errors 2 Min        1.70993e-05
trainer/Policy Action Mean          0.00824453
trainer/Policy Action Std           0.119458
trainer/Policy Action Max           0.272808
trainer/Policy Action Min          -0.277694
exploration/num steps total     69300
exploration/num paths total       693
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.1412
exploration/Rewards Std             0.0839841
exploration/Rewards Max            -0.000238502
exploration/Rewards Min            -0.694378
exploration/Returns Mean          -14.12
exploration/Returns Std             0.113825
exploration/Returns Max           -14.0062
exploration/Returns Min           -14.2339
exploration/Actions Mean            0.0048585
exploration/Actions Std             0.155053
exploration/Actions Max             0.870171
exploration/Actions Min            -0.453141
exploration/Num Paths               2
exploration/Average Returns       -14.12
evaluation/num steps total     173000
evaluation/num paths total       1730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0589233
evaluation/Rewards Std              0.0287026
evaluation/Rewards Max             -0.0147844
evaluation/Rewards Min             -0.579492
evaluation/Returns Mean            -5.89233
evaluation/Returns Std              0.196191
evaluation/Returns Max             -5.67119
evaluation/Returns Min             -6.19088
evaluation/Actions Mean             0.00448357
evaluation/Actions Std              0.0712689
evaluation/Actions Max              0.999295
evaluation/Actions Min             -0.956487
evaluation/Num Paths                5
evaluation/Average Returns         -5.89233
time/data storing (s)               0.0011149
time/evaluation sampling (s)        0.0725823
time/exploration sampling (s)       0.0333539
time/logging (s)                    0.00247798
time/saving (s)                     0.00222813
time/training (s)                   0.473919
time/epoch (s)                      0.585676
time/total (s)                    206.202
Epoch                             345
-----------------------------  ----------------
2019-04-13 17:02:01.399512 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 346 finished
-----------------------------  ----------------
replay_buffer/size              69500
trainer/QF1 Loss                    0.0580758
trainer/QF2 Loss                    0.0592567
trainer/Policy Loss                12.444
trainer/Q1 Predictions Mean       -12.6339
trainer/Q1 Predictions Std          0.417291
trainer/Q1 Predictions Max        -12.4243
trainer/Q1 Predictions Min        -14.9075
trainer/Q2 Predictions Mean       -12.6295
trainer/Q2 Predictions Std          0.426904
trainer/Q2 Predictions Max        -12.4283
trainer/Q2 Predictions Min        -14.9498
trainer/Q Targets Mean            -12.77
trainer/Q Targets Std               0.491709
trainer/Q Targets Max             -12.3411
trainer/Q Targets Min             -15.2712
trainer/Bellman Errors 1 Mean       0.0580758
trainer/Bellman Errors 1 Std        0.0969911
trainer/Bellman Errors 1 Max        0.491455
trainer/Bellman Errors 1 Min        0.000227852
trainer/Bellman Errors 2 Mean       0.0592567
trainer/Bellman Errors 2 Std        0.0970266
trainer/Bellman Errors 2 Max        0.481654
trainer/Bellman Errors 2 Min        6.96491e-05
trainer/Policy Action Mean         -0.0160434
trainer/Policy Action Std           0.186675
trainer/Policy Action Max           0.999339
trainer/Policy Action Min          -0.329499
exploration/num steps total     69500
exploration/num paths total       695
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143422
exploration/Rewards Std             0.0748091
exploration/Rewards Max            -0.0146932
exploration/Rewards Min            -0.366227
exploration/Returns Mean          -14.3422
exploration/Returns Std             0.108423
exploration/Returns Max           -14.2338
exploration/Returns Min           -14.4506
exploration/Actions Mean            0.00460813
exploration/Actions Std             0.144688
exploration/Actions Max             0.7806
exploration/Actions Min            -0.418244
exploration/Num Paths               2
exploration/Average Returns       -14.3422
evaluation/num steps total     173500
evaluation/num paths total       1735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0601948
evaluation/Rewards Std              0.0306265
evaluation/Rewards Max             -0.0437202
evaluation/Rewards Min             -0.594306
evaluation/Returns Mean            -6.01948
evaluation/Returns Std              0.206236
evaluation/Returns Max             -5.79235
evaluation/Returns Min             -6.36886
evaluation/Actions Mean             0.00488169
evaluation/Actions Std              0.0759882
evaluation/Actions Max              0.999541
evaluation/Actions Min             -0.771545
evaluation/Num Paths                5
evaluation/Average Returns         -6.01948
time/data storing (s)               0.00124032
time/evaluation sampling (s)        0.0736136
time/exploration sampling (s)       0.0341197
time/logging (s)                    0.00248582
time/saving (s)                     0.00226236
time/training (s)                   0.467031
time/epoch (s)                      0.580752
time/total (s)                    206.787
Epoch                             346
-----------------------------  ----------------
2019-04-13 17:02:01.980971 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 347 finished
-----------------------------  ---------------
replay_buffer/size              69700
trainer/QF1 Loss                    0.1647
trainer/QF2 Loss                    0.166587
trainer/Policy Loss                12.367
trainer/Q1 Predictions Mean       -12.3969
trainer/Q1 Predictions Std          0.0916775
trainer/Q1 Predictions Max        -12.2674
trainer/Q1 Predictions Min        -12.6987
trainer/Q2 Predictions Mean       -12.3934
trainer/Q2 Predictions Std          0.100385
trainer/Q2 Predictions Max        -12.2649
trainer/Q2 Predictions Min        -12.7184
trainer/Q Targets Mean            -12.7479
trainer/Q Targets Std               0.249816
trainer/Q Targets Max             -12.4146
trainer/Q Targets Min             -13.6033
trainer/Bellman Errors 1 Mean       0.1647
trainer/Bellman Errors 1 Std        0.177122
trainer/Bellman Errors 1 Max        0.818274
trainer/Bellman Errors 1 Min        0.00411092
trainer/Bellman Errors 2 Mean       0.166587
trainer/Bellman Errors 2 Std        0.175457
trainer/Bellman Errors 2 Max        0.783014
trainer/Bellman Errors 2 Min        0.00549583
trainer/Policy Action Mean          0.00894256
trainer/Policy Action Std           0.139692
trainer/Policy Action Max           0.668763
trainer/Policy Action Min          -0.250932
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129611
exploration/Rewards Std             0.10038
exploration/Rewards Max            -0.00835065
exploration/Rewards Min            -1.24558
exploration/Returns Mean          -12.9611
exploration/Returns Std             0.325693
exploration/Returns Max           -12.6354
exploration/Returns Min           -13.2868
exploration/Actions Mean            0.00866951
exploration/Actions Std             0.153966
exploration/Actions Max             0.91261
exploration/Actions Min            -0.352548
exploration/Num Paths               2
exploration/Average Returns       -12.9611
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0131198
evaluation/Rewards Std              0.0519778
evaluation/Rewards Max             -0.00496012
evaluation/Rewards Min             -0.939486
evaluation/Returns Mean            -1.31198
evaluation/Returns Std              0.308545
evaluation/Returns Max             -0.970236
evaluation/Returns Min             -1.83065
evaluation/Actions Mean             0.00531275
evaluation/Actions Std              0.0828007
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.872943
evaluation/Num Paths                5
evaluation/Average Returns         -1.31198
time/data storing (s)               0.00106061
time/evaluation sampling (s)        0.0742991
time/exploration sampling (s)       0.0326472
time/logging (s)                    0.0024669
time/saving (s)                     0.00189396
time/training (s)                   0.459874
time/epoch (s)                      0.572242
time/total (s)                    207.363
Epoch                             347
-----------------------------  ---------------
2019-04-13 17:02:02.563912 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 348 finished
-----------------------------  ----------------
replay_buffer/size              69900
trainer/QF1 Loss                    0.0266722
trainer/QF2 Loss                    0.0282768
trainer/Policy Loss                12.7218
trainer/Q1 Predictions Mean       -12.9382
trainer/Q1 Predictions Std          0.693988
trainer/Q1 Predictions Max        -12.5985
trainer/Q1 Predictions Min        -15.9545
trainer/Q2 Predictions Mean       -12.9349
trainer/Q2 Predictions Std          0.690788
trainer/Q2 Predictions Max        -12.592
trainer/Q2 Predictions Min        -15.9501
trainer/Q Targets Mean            -12.8602
trainer/Q Targets Std               0.738044
trainer/Q Targets Max             -12.3743
trainer/Q Targets Min             -15.8674
trainer/Bellman Errors 1 Mean       0.0266722
trainer/Bellman Errors 1 Std        0.0234251
trainer/Bellman Errors 1 Max        0.0889498
trainer/Bellman Errors 1 Min        3.70743e-06
trainer/Bellman Errors 2 Mean       0.0282768
trainer/Bellman Errors 2 Std        0.0234052
trainer/Bellman Errors 2 Max        0.0877383
trainer/Bellman Errors 2 Min        0.00025286
trainer/Policy Action Mean          0.0453787
trainer/Policy Action Std           0.249549
trainer/Policy Action Max           0.999719
trainer/Policy Action Min          -0.456204
exploration/num steps total     69900
exploration/num paths total       699
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127633
exploration/Rewards Std             0.0874472
exploration/Rewards Max            -0.00920364
exploration/Rewards Min            -0.954506
exploration/Returns Mean          -12.7633
exploration/Returns Std             0.109779
exploration/Returns Max           -12.6535
exploration/Returns Min           -12.8731
exploration/Actions Mean            0.00543432
exploration/Actions Std             0.165421
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.7633
evaluation/num steps total     174500
evaluation/num paths total       1745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0209851
evaluation/Rewards Std              0.040718
evaluation/Rewards Max             -0.00867975
evaluation/Rewards Min             -0.647003
evaluation/Returns Mean            -2.09851
evaluation/Returns Std              0.137369
evaluation/Returns Max             -1.99326
evaluation/Returns Min             -2.36051
evaluation/Actions Mean             0.0060052
evaluation/Actions Std              0.0973818
evaluation/Actions Max              0.999886
evaluation/Actions Min             -0.983609
evaluation/Num Paths                5
evaluation/Average Returns         -2.09851
time/data storing (s)               0.00106202
time/evaluation sampling (s)        0.0745435
time/exploration sampling (s)       0.0333615
time/logging (s)                    0.00252447
time/saving (s)                     0.00223911
time/training (s)                   0.460659
time/epoch (s)                      0.574389
time/total (s)                    207.941
Epoch                             348
-----------------------------  ----------------
2019-04-13 17:02:03.138102 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 349 finished
-----------------------------  ----------------
replay_buffer/size              70100
trainer/QF1 Loss                    4.86231
trainer/QF2 Loss                    4.86432
trainer/Policy Loss                12.4886
trainer/Q1 Predictions Mean       -12.7684
trainer/Q1 Predictions Std          0.632976
trainer/Q1 Predictions Max        -12.42
trainer/Q1 Predictions Min        -15.3621
trainer/Q2 Predictions Mean       -12.7554
trainer/Q2 Predictions Std          0.607004
trainer/Q2 Predictions Max        -12.4105
trainer/Q2 Predictions Min        -15.3465
trainer/Q Targets Mean            -12.5191
trainer/Q Targets Std               2.32344
trainer/Q Targets Max              -0.0530804
trainer/Q Targets Min             -15.6053
trainer/Bellman Errors 1 Mean       4.86231
trainer/Bellman Errors 1 Std       26.787
trainer/Bellman Errors 1 Max      154.006
trainer/Bellman Errors 1 Min        1.27012e-05
trainer/Bellman Errors 2 Mean       4.86432
trainer/Bellman Errors 2 Std       26.7739
trainer/Bellman Errors 2 Max      153.935
trainer/Bellman Errors 2 Min        2.77896e-06
trainer/Policy Action Mean          0.0789741
trainer/Policy Action Std           0.325576
trainer/Policy Action Max           0.999756
trainer/Policy Action Min          -0.999603
exploration/num steps total     70100
exploration/num paths total       701
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.15096
exploration/Rewards Std             0.0946367
exploration/Rewards Max            -0.0107163
exploration/Rewards Min            -0.995595
exploration/Returns Mean          -15.096
exploration/Returns Std             0.102531
exploration/Returns Max           -14.9935
exploration/Returns Min           -15.1986
exploration/Actions Mean            0.00401231
exploration/Actions Std             0.178922
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -15.096
evaluation/num steps total     175000
evaluation/num paths total       1750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0839518
evaluation/Rewards Std              0.0320456
evaluation/Rewards Max             -0.0494085
evaluation/Rewards Min             -0.689371
evaluation/Returns Mean            -8.39518
evaluation/Returns Std              0.173429
evaluation/Returns Max             -8.17474
evaluation/Returns Min             -8.70895
evaluation/Actions Mean             0.00520834
evaluation/Actions Std              0.0907286
evaluation/Actions Max              0.999911
evaluation/Actions Min             -0.946636
evaluation/Num Paths                5
evaluation/Average Returns         -8.39518
time/data storing (s)               0.0013773
time/evaluation sampling (s)        0.0741379
time/exploration sampling (s)       0.0321752
time/logging (s)                    0.00247618
time/saving (s)                     0.00225283
time/training (s)                   0.452734
time/epoch (s)                      0.565153
time/total (s)                    208.511
Epoch                             349
-----------------------------  ----------------
2019-04-13 17:02:03.721714 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 350 finished
-----------------------------  ----------------
replay_buffer/size              70300
trainer/QF1 Loss                    4.83441
trainer/QF2 Loss                    4.83228
trainer/Policy Loss                12.445
trainer/Q1 Predictions Mean       -12.5963
trainer/Q1 Predictions Std          0.538906
trainer/Q1 Predictions Max        -12.2424
trainer/Q1 Predictions Min        -14.8995
trainer/Q2 Predictions Mean       -12.5755
trainer/Q2 Predictions Std          0.528098
trainer/Q2 Predictions Max        -12.2116
trainer/Q2 Predictions Min        -14.914
trainer/Q Targets Mean            -12.4319
trainer/Q Targets Std               2.23338
trainer/Q Targets Max              -0.256174
trainer/Q Targets Min             -14.8775
trainer/Bellman Errors 1 Mean       4.83442
trainer/Bellman Errors 1 Std       26.4733
trainer/Bellman Errors 1 Max      152.231
trainer/Bellman Errors 1 Min        0.000485778
trainer/Bellman Errors 2 Mean       4.83228
trainer/Bellman Errors 2 Std       26.429
trainer/Bellman Errors 2 Max      151.982
trainer/Bellman Errors 2 Min        0.000497237
trainer/Policy Action Mean          0.0399958
trainer/Policy Action Std           0.24982
trainer/Policy Action Max           0.999989
trainer/Policy Action Min          -0.417875
exploration/num steps total     70300
exploration/num paths total       703
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137829
exploration/Rewards Std             0.0765928
exploration/Rewards Max            -0.00678248
exploration/Rewards Min            -0.343863
exploration/Returns Mean          -13.7829
exploration/Returns Std             0.39417
exploration/Returns Max           -13.3887
exploration/Returns Min           -14.1771
exploration/Actions Mean            0.00552856
exploration/Actions Std             0.158458
exploration/Actions Max             0.738656
exploration/Actions Min            -0.473528
exploration/Num Paths               2
exploration/Average Returns       -13.7829
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0457949
evaluation/Rewards Std              0.0543929
evaluation/Rewards Max             -0.0400099
evaluation/Rewards Min             -0.992042
evaluation/Returns Mean            -4.57949
evaluation/Returns Std              0.39561
evaluation/Returns Max             -4.20635
evaluation/Returns Min             -5.16045
evaluation/Actions Mean             0.00354955
evaluation/Actions Std              0.0784163
evaluation/Actions Max              0.999991
evaluation/Actions Min             -0.978738
evaluation/Num Paths                5
evaluation/Average Returns         -4.57949
time/data storing (s)               0.00127084
time/evaluation sampling (s)        0.0759707
time/exploration sampling (s)       0.0367366
time/logging (s)                    0.00248229
time/saving (s)                     0.00225038
time/training (s)                   0.455551
time/epoch (s)                      0.574262
time/total (s)                    209.089
Epoch                             350
-----------------------------  ----------------
2019-04-13 17:02:04.310571 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 351 finished
-----------------------------  ----------------
replay_buffer/size              70500
trainer/QF1 Loss                    0.0816562
trainer/QF2 Loss                    0.0729691
trainer/Policy Loss                12.4536
trainer/Q1 Predictions Mean       -12.6428
trainer/Q1 Predictions Std          0.559615
trainer/Q1 Predictions Max        -12.3827
trainer/Q1 Predictions Min        -15.6626
trainer/Q2 Predictions Mean       -12.6616
trainer/Q2 Predictions Std          0.580353
trainer/Q2 Predictions Max        -12.418
trainer/Q2 Predictions Min        -15.8014
trainer/Q Targets Mean            -12.8387
trainer/Q Targets Std               0.61285
trainer/Q Targets Max             -12.3554
trainer/Q Targets Min             -16.0167
trainer/Bellman Errors 1 Mean       0.0816562
trainer/Bellman Errors 1 Std        0.126797
trainer/Bellman Errors 1 Max        0.512046
trainer/Bellman Errors 1 Min        3.67656e-05
trainer/Bellman Errors 2 Mean       0.0729691
trainer/Bellman Errors 2 Std        0.121655
trainer/Bellman Errors 2 Max        0.483393
trainer/Bellman Errors 2 Min        4.76077e-05
trainer/Policy Action Mean          0.0160831
trainer/Policy Action Std           0.214513
trainer/Policy Action Max           0.998484
trainer/Policy Action Min          -0.415028
exploration/num steps total     70500
exploration/num paths total       705
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.13556
exploration/Rewards Std             0.0925605
exploration/Rewards Max            -0.0094458
exploration/Rewards Min            -0.942333
exploration/Returns Mean          -13.556
exploration/Returns Std             1.01761
exploration/Returns Max           -12.5384
exploration/Returns Min           -14.5736
exploration/Actions Mean            0.00709894
exploration/Actions Std             0.156447
exploration/Actions Max             1
exploration/Actions Min            -0.383004
exploration/Num Paths               2
exploration/Average Returns       -13.556
evaluation/num steps total     176000
evaluation/num paths total       1760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0561281
evaluation/Rewards Std              0.0601291
evaluation/Rewards Max             -0.0224486
evaluation/Rewards Min             -0.875508
evaluation/Returns Mean            -5.61281
evaluation/Returns Std              0.298831
evaluation/Returns Max             -5.20396
evaluation/Returns Min             -5.91805
evaluation/Actions Mean             0.0108272
evaluation/Actions Std              0.0918454
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.0377444
evaluation/Num Paths                5
evaluation/Average Returns         -5.61281
time/data storing (s)               0.00114345
time/evaluation sampling (s)        0.0746469
time/exploration sampling (s)       0.0338142
time/logging (s)                    0.00246613
time/saving (s)                     0.00248175
time/training (s)                   0.465017
time/epoch (s)                      0.57957
time/total (s)                    209.673
Epoch                             351
-----------------------------  ----------------
2019-04-13 17:02:04.891360 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 352 finished
-----------------------------  ----------------
replay_buffer/size              70700
trainer/QF1 Loss                    0.053171
trainer/QF2 Loss                    0.0506249
trainer/Policy Loss                12.7418
trainer/Q1 Predictions Mean       -12.7991
trainer/Q1 Predictions Std          0.271204
trainer/Q1 Predictions Max        -12.6664
trainer/Q1 Predictions Min        -14.2752
trainer/Q2 Predictions Mean       -12.786
trainer/Q2 Predictions Std          0.271708
trainer/Q2 Predictions Max        -12.6343
trainer/Q2 Predictions Min        -14.2631
trainer/Q Targets Mean            -12.7015
trainer/Q Targets Std               0.241955
trainer/Q Targets Max             -12.376
trainer/Q Targets Min             -13.5497
trainer/Bellman Errors 1 Mean       0.053171
trainer/Bellman Errors 1 Std        0.0917465
trainer/Bellman Errors 1 Max        0.526332
trainer/Bellman Errors 1 Min        3.84261e-09
trainer/Bellman Errors 2 Mean       0.0506249
trainer/Bellman Errors 2 Std        0.0892108
trainer/Bellman Errors 2 Max        0.508854
trainer/Bellman Errors 2 Min        7.58791e-05
trainer/Policy Action Mean          0.0478755
trainer/Policy Action Std           0.160061
trainer/Policy Action Max           0.949042
trainer/Policy Action Min          -0.423829
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.14908
exploration/Rewards Std             0.078928
exploration/Rewards Max            -0.0144523
exploration/Rewards Min            -0.687668
exploration/Returns Mean          -14.908
exploration/Returns Std             0.668661
exploration/Returns Max           -14.2393
exploration/Returns Min           -15.5767
exploration/Actions Mean            0.00435455
exploration/Actions Std             0.171244
exploration/Actions Max             1
exploration/Actions Min            -0.923847
exploration/Num Paths               2
exploration/Average Returns       -14.908
evaluation/num steps total     176500
evaluation/num paths total       1765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0690156
evaluation/Rewards Std              0.0584659
evaluation/Rewards Max             -0.0448974
evaluation/Rewards Min             -0.976751
evaluation/Returns Mean            -6.90156
evaluation/Returns Std              0.383117
evaluation/Returns Max             -6.42986
evaluation/Returns Min             -7.36845
evaluation/Actions Mean             0.00473102
evaluation/Actions Std              0.0886665
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.971482
evaluation/Num Paths                5
evaluation/Average Returns         -6.90156
time/data storing (s)               0.00105756
time/evaluation sampling (s)        0.0744674
time/exploration sampling (s)       0.0338628
time/logging (s)                    0.00244675
time/saving (s)                     0.00228054
time/training (s)                   0.457116
time/epoch (s)                      0.571231
time/total (s)                    210.248
Epoch                             352
-----------------------------  ----------------
2019-04-13 17:02:05.485076 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 353 finished
-----------------------------  ----------------
replay_buffer/size              70900
trainer/QF1 Loss                    4.99308
trainer/QF2 Loss                    4.98053
trainer/Policy Loss                12.5753
trainer/Q1 Predictions Mean       -12.7241
trainer/Q1 Predictions Std          0.112228
trainer/Q1 Predictions Max        -12.6146
trainer/Q1 Predictions Min        -13.2393
trainer/Q2 Predictions Mean       -12.7147
trainer/Q2 Predictions Std          0.108588
trainer/Q2 Predictions Max        -12.5993
trainer/Q2 Predictions Min        -13.2045
trainer/Q Targets Mean            -12.3038
trainer/Q Targets Std               2.21688
trainer/Q Targets Max              -0.00921344
trainer/Q Targets Min             -13.294
trainer/Bellman Errors 1 Mean       4.99308
trainer/Bellman Errors 1 Std       27.6764
trainer/Bellman Errors 1 Max      159.088
trainer/Bellman Errors 1 Min        3.52608e-06
trainer/Bellman Errors 2 Mean       4.98053
trainer/Bellman Errors 2 Std       27.6096
trainer/Bellman Errors 2 Max      158.704
trainer/Bellman Errors 2 Min        4.53325e-07
trainer/Policy Action Mean          0.0211186
trainer/Policy Action Std           0.12286
trainer/Policy Action Max           0.377934
trainer/Policy Action Min          -0.466591
exploration/num steps total     70900
exploration/num paths total       709
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130029
exploration/Rewards Std             0.0688921
exploration/Rewards Max            -0.00609377
exploration/Rewards Min            -0.380627
exploration/Returns Mean          -13.0029
exploration/Returns Std             0.306733
exploration/Returns Max           -12.6961
exploration/Returns Min           -13.3096
exploration/Actions Mean            0.000721353
exploration/Actions Std             0.160296
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.0029
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0555205
evaluation/Rewards Std              0.0162837
evaluation/Rewards Max             -0.021397
evaluation/Rewards Min             -0.281292
evaluation/Returns Mean            -5.55205
evaluation/Returns Std              0.085597
evaluation/Returns Max             -5.38835
evaluation/Returns Min             -5.63168
evaluation/Actions Mean             0.00467163
evaluation/Actions Std              0.0788969
evaluation/Actions Max              0.991326
evaluation/Actions Min             -0.996692
evaluation/Num Paths                5
evaluation/Average Returns         -5.55205
time/data storing (s)               0.00111728
time/evaluation sampling (s)        0.0753279
time/exploration sampling (s)       0.0340888
time/logging (s)                    0.00248439
time/saving (s)                     0.00223549
time/training (s)                   0.469305
time/epoch (s)                      0.584559
time/total (s)                    210.837
Epoch                             353
-----------------------------  ----------------
2019-04-13 17:02:06.068530 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 354 finished
-----------------------------  ----------------
replay_buffer/size              71100
trainer/QF1 Loss                    0.0247021
trainer/QF2 Loss                    0.0250662
trainer/Policy Loss                12.5389
trainer/Q1 Predictions Mean       -12.6516
trainer/Q1 Predictions Std          0.0733475
trainer/Q1 Predictions Max        -12.5418
trainer/Q1 Predictions Min        -12.8451
trainer/Q2 Predictions Mean       -12.648
trainer/Q2 Predictions Std          0.066752
trainer/Q2 Predictions Max        -12.5567
trainer/Q2 Predictions Min        -12.8375
trainer/Q Targets Mean            -12.7148
trainer/Q Targets Std               0.176654
trainer/Q Targets Max             -12.505
trainer/Q Targets Min             -13.2182
trainer/Bellman Errors 1 Mean       0.0247021
trainer/Bellman Errors 1 Std        0.0536265
trainer/Bellman Errors 1 Max        0.290578
trainer/Bellman Errors 1 Min        0.000105143
trainer/Bellman Errors 2 Mean       0.0250662
trainer/Bellman Errors 2 Std        0.0559839
trainer/Bellman Errors 2 Max        0.30836
trainer/Bellman Errors 2 Min        0.000119988
trainer/Policy Action Mean          0.0221503
trainer/Policy Action Std           0.111877
trainer/Policy Action Max           0.248689
trainer/Policy Action Min          -0.185201
exploration/num steps total     71100
exploration/num paths total       711
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131394
exploration/Rewards Std             0.0812932
exploration/Rewards Max            -0.00357888
exploration/Rewards Min            -0.662184
exploration/Returns Mean          -13.1394
exploration/Returns Std             0.667071
exploration/Returns Max           -12.4723
exploration/Returns Min           -13.8065
exploration/Actions Mean            0.00766826
exploration/Actions Std             0.173331
exploration/Actions Max             1
exploration/Actions Min            -0.76684
exploration/Num Paths               2
exploration/Average Returns       -13.1394
evaluation/num steps total     177500
evaluation/num paths total       1775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0442493
evaluation/Rewards Std              0.0285776
evaluation/Rewards Max             -0.0276705
evaluation/Rewards Min             -0.570837
evaluation/Returns Mean            -4.42493
evaluation/Returns Std              0.194459
evaluation/Returns Max             -4.21817
evaluation/Returns Min             -4.74069
evaluation/Actions Mean             0.00485175
evaluation/Actions Std              0.0655235
evaluation/Actions Max              0.99962
evaluation/Actions Min             -0.424284
evaluation/Num Paths                5
evaluation/Average Returns         -4.42493
time/data storing (s)               0.00113489
time/evaluation sampling (s)        0.0748273
time/exploration sampling (s)       0.0326667
time/logging (s)                    0.00249723
time/saving (s)                     0.0023343
time/training (s)                   0.461563
time/epoch (s)                      0.575023
time/total (s)                    211.415
Epoch                             354
-----------------------------  ----------------
2019-04-13 17:02:06.651220 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 355 finished
-----------------------------  ---------------
replay_buffer/size              71300
trainer/QF1 Loss                    0.057533
trainer/QF2 Loss                    0.0540494
trainer/Policy Loss                12.3828
trainer/Q1 Predictions Mean       -12.4725
trainer/Q1 Predictions Std          0.226417
trainer/Q1 Predictions Max        -12.3278
trainer/Q1 Predictions Min        -13.6795
trainer/Q2 Predictions Mean       -12.4819
trainer/Q2 Predictions Std          0.215572
trainer/Q2 Predictions Max        -12.3047
trainer/Q2 Predictions Min        -13.6185
trainer/Q Targets Mean            -12.6853
trainer/Q Targets Std               0.226218
trainer/Q Targets Max             -12.4258
trainer/Q Targets Min             -13.7723
trainer/Bellman Errors 1 Mean       0.057533
trainer/Bellman Errors 1 Std        0.0565271
trainer/Bellman Errors 1 Max        0.2267
trainer/Bellman Errors 1 Min        0.00117125
trainer/Bellman Errors 2 Mean       0.0540494
trainer/Bellman Errors 2 Std        0.0544847
trainer/Bellman Errors 2 Max        0.207442
trainer/Bellman Errors 2 Min        0.00029448
trainer/Policy Action Mean          0.0314166
trainer/Policy Action Std           0.181944
trainer/Policy Action Max           0.929303
trainer/Policy Action Min          -0.384725
exploration/num steps total     71300
exploration/num paths total       713
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.145798
exploration/Rewards Std             0.0680743
exploration/Rewards Max            -0.0166199
exploration/Rewards Min            -0.409373
exploration/Returns Mean          -14.5798
exploration/Returns Std             0.382784
exploration/Returns Max           -14.197
exploration/Returns Min           -14.9626
exploration/Actions Mean            0.0046624
exploration/Actions Std             0.173106
exploration/Actions Max             1
exploration/Actions Min            -0.507512
exploration/Num Paths               2
exploration/Average Returns       -14.5798
evaluation/num steps total     178000
evaluation/num paths total       1780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.00991175
evaluation/Rewards Std              0.0434098
evaluation/Rewards Max             -0.00197701
evaluation/Rewards Min             -0.945836
evaluation/Returns Mean            -0.991175
evaluation/Returns Std              0.363265
evaluation/Returns Max             -0.755004
evaluation/Returns Min             -1.69771
evaluation/Actions Mean             0.00420487
evaluation/Actions Std              0.0732832
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.989582
evaluation/Num Paths                5
evaluation/Average Returns         -0.991175
time/data storing (s)               0.00107091
time/evaluation sampling (s)        0.0721084
time/exploration sampling (s)       0.033513
time/logging (s)                    0.00257283
time/saving (s)                     0.00225996
time/training (s)                   0.462926
time/epoch (s)                      0.574451
time/total (s)                    211.994
Epoch                             355
-----------------------------  ---------------
2019-04-13 17:02:07.238437 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 356 finished
-----------------------------  ---------------
replay_buffer/size              71500
trainer/QF1 Loss                    4.79949
trainer/QF2 Loss                    4.81379
trainer/Policy Loss                12.3039
trainer/Q1 Predictions Mean       -12.4732
trainer/Q1 Predictions Std          0.39444
trainer/Q1 Predictions Max        -12.2581
trainer/Q1 Predictions Min        -14.6359
trainer/Q2 Predictions Mean       -12.4736
trainer/Q2 Predictions Std          0.373915
trainer/Q2 Predictions Max        -12.2847
trainer/Q2 Predictions Min        -14.5203
trainer/Q Targets Mean            -12.3818
trainer/Q Targets Std               2.25037
trainer/Q Targets Max              -0.109119
trainer/Q Targets Min             -15.1804
trainer/Bellman Errors 1 Mean       4.79949
trainer/Bellman Errors 1 Std       26.1118
trainer/Bellman Errors 1 Max      150.183
trainer/Bellman Errors 1 Min        0.00817625
trainer/Bellman Errors 2 Mean       4.81379
trainer/Bellman Errors 2 Std       26.1779
trainer/Bellman Errors 2 Max      150.565
trainer/Bellman Errors 2 Min        0.00768157
trainer/Policy Action Mean          0.0522147
trainer/Policy Action Std           0.209015
trainer/Policy Action Max           0.999628
trainer/Policy Action Min          -0.265116
exploration/num steps total     71500
exploration/num paths total       715
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135894
exploration/Rewards Std             0.0853956
exploration/Rewards Max            -0.00522424
exploration/Rewards Min            -0.649874
exploration/Returns Mean          -13.5894
exploration/Returns Std             0.200486
exploration/Returns Max           -13.389
exploration/Returns Min           -13.7899
exploration/Actions Mean            0.0106581
exploration/Actions Std             0.163821
exploration/Actions Max             1
exploration/Actions Min            -0.409382
exploration/Num Paths               2
exploration/Average Returns       -13.5894
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0461421
evaluation/Rewards Std              0.0318521
evaluation/Rewards Max             -0.0118954
evaluation/Rewards Min             -0.678394
evaluation/Returns Mean            -4.61421
evaluation/Returns Std              0.24596
evaluation/Returns Max             -4.37935
evaluation/Returns Min             -5.02106
evaluation/Actions Mean             0.00479384
evaluation/Actions Std              0.0813909
evaluation/Actions Max              0.999956
evaluation/Actions Min             -0.876976
evaluation/Num Paths                5
evaluation/Average Returns         -4.61421
time/data storing (s)               0.00112026
time/evaluation sampling (s)        0.0749674
time/exploration sampling (s)       0.0338848
time/logging (s)                    0.00248246
time/saving (s)                     0.00227336
time/training (s)                   0.463046
time/epoch (s)                      0.577774
time/total (s)                    212.576
Epoch                             356
-----------------------------  ---------------
2019-04-13 17:02:07.819649 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 357 finished
-----------------------------  ----------------
replay_buffer/size              71700
trainer/QF1 Loss                    0.020089
trainer/QF2 Loss                    0.0210356
trainer/Policy Loss                12.5437
trainer/Q1 Predictions Mean       -12.6473
trainer/Q1 Predictions Std          0.13793
trainer/Q1 Predictions Max        -12.5033
trainer/Q1 Predictions Min        -13.3065
trainer/Q2 Predictions Mean       -12.6443
trainer/Q2 Predictions Std          0.156409
trainer/Q2 Predictions Max        -12.5096
trainer/Q2 Predictions Min        -13.4244
trainer/Q Targets Mean            -12.6987
trainer/Q Targets Std               0.140832
trainer/Q Targets Max             -12.483
trainer/Q Targets Min             -13.2209
trainer/Bellman Errors 1 Mean       0.020089
trainer/Bellman Errors 1 Std        0.0366217
trainer/Bellman Errors 1 Max        0.161272
trainer/Bellman Errors 1 Min        8.70082e-06
trainer/Bellman Errors 2 Mean       0.0210356
trainer/Bellman Errors 2 Std        0.0361674
trainer/Bellman Errors 2 Max        0.158143
trainer/Bellman Errors 2 Min        1.29266e-07
trainer/Policy Action Mean          0.0030186
trainer/Policy Action Std           0.12585
trainer/Policy Action Max           0.729755
trainer/Policy Action Min          -0.253663
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12958
exploration/Rewards Std             0.0741391
exploration/Rewards Max            -0.0146344
exploration/Rewards Min            -0.649318
exploration/Returns Mean          -12.958
exploration/Returns Std             0.0667258
exploration/Returns Max           -12.8913
exploration/Returns Min           -13.0248
exploration/Actions Mean            0.00490724
exploration/Actions Std             0.164819
exploration/Actions Max             1
exploration/Actions Min            -0.974272
exploration/Num Paths               2
exploration/Average Returns       -12.958
evaluation/num steps total     179000
evaluation/num paths total       1790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0222598
evaluation/Rewards Std              0.0552413
evaluation/Rewards Max             -0.00710427
evaluation/Rewards Min             -0.921085
evaluation/Returns Mean            -2.22598
evaluation/Returns Std              0.372506
evaluation/Returns Max             -1.82293
evaluation/Returns Min             -2.72328
evaluation/Actions Mean             0.00682911
evaluation/Actions Std              0.0889978
evaluation/Actions Max              0.999992
evaluation/Actions Min             -0.992645
evaluation/Num Paths                5
evaluation/Average Returns         -2.22598
time/data storing (s)               0.00126266
time/evaluation sampling (s)        0.0732039
time/exploration sampling (s)       0.038685
time/logging (s)                    0.00192029
time/saving (s)                     0.00180716
time/training (s)                   0.454525
time/epoch (s)                      0.571404
time/total (s)                    213.152
Epoch                             357
-----------------------------  ----------------
2019-04-13 17:02:08.403028 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 358 finished
-----------------------------  ----------------
replay_buffer/size              71900
trainer/QF1 Loss                    5.83775
trainer/QF2 Loss                    5.80582
trainer/Policy Loss                12.5327
trainer/Q1 Predictions Mean       -12.7295
trainer/Q1 Predictions Std          0.54097
trainer/Q1 Predictions Max        -12.4935
trainer/Q1 Predictions Min        -15.6804
trainer/Q2 Predictions Mean       -12.7299
trainer/Q2 Predictions Std          0.536282
trainer/Q2 Predictions Max        -12.5011
trainer/Q2 Predictions Min        -15.645
trainer/Q Targets Mean            -12.39
trainer/Q Targets Std               1.86449
trainer/Q Targets Max              -2.05137
trainer/Q Targets Min             -13.417
trainer/Bellman Errors 1 Mean       5.83775
trainer/Bellman Errors 1 Std       32.3134
trainer/Bellman Errors 1 Max      185.751
trainer/Bellman Errors 1 Min        2.842e-07
trainer/Bellman Errors 2 Mean       5.80582
trainer/Bellman Errors 2 Std       32.146
trainer/Bellman Errors 2 Max      184.787
trainer/Bellman Errors 2 Min        0.000438117
trainer/Policy Action Mean          0.0221234
trainer/Policy Action Std           0.217415
trainer/Policy Action Max           0.999806
trainer/Policy Action Min          -0.413904
exploration/num steps total     71900
exploration/num paths total       719
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133871
exploration/Rewards Std             0.0655474
exploration/Rewards Max            -0.00729919
exploration/Rewards Min            -0.315198
exploration/Returns Mean          -13.3871
exploration/Returns Std             0.894256
exploration/Returns Max           -12.4929
exploration/Returns Min           -14.2814
exploration/Actions Mean            0.0031854
exploration/Actions Std             0.171368
exploration/Actions Max             0.740364
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.3871
evaluation/num steps total     179500
evaluation/num paths total       1795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0447202
evaluation/Rewards Std              0.0440676
evaluation/Rewards Max             -0.040894
evaluation/Rewards Min             -0.742262
evaluation/Returns Mean            -4.47202
evaluation/Returns Std              0.296577
evaluation/Returns Max             -4.21209
evaluation/Returns Min             -4.83951
evaluation/Actions Mean             0.00582853
evaluation/Actions Std              0.0775709
evaluation/Actions Max              0.999935
evaluation/Actions Min             -0.524615
evaluation/Num Paths                5
evaluation/Average Returns         -4.47202
time/data storing (s)               0.00105819
time/evaluation sampling (s)        0.0736484
time/exploration sampling (s)       0.0330717
time/logging (s)                    0.00247529
time/saving (s)                     0.00228091
time/training (s)                   0.462043
time/epoch (s)                      0.574577
time/total (s)                    213.731
Epoch                             358
-----------------------------  ----------------
2019-04-13 17:02:08.986500 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 359 finished
-----------------------------  ----------------
replay_buffer/size              72100
trainer/QF1 Loss                    0.0174804
trainer/QF2 Loss                    0.0180916
trainer/Policy Loss                12.5697
trainer/Q1 Predictions Mean       -12.6987
trainer/Q1 Predictions Std          0.405017
trainer/Q1 Predictions Max        -12.5547
trainer/Q1 Predictions Min        -14.9321
trainer/Q2 Predictions Mean       -12.706
trainer/Q2 Predictions Std          0.429366
trainer/Q2 Predictions Max        -12.5627
trainer/Q2 Predictions Min        -15.0777
trainer/Q Targets Mean            -12.7525
trainer/Q Targets Std               0.419006
trainer/Q Targets Max             -12.4627
trainer/Q Targets Min             -14.9761
trainer/Bellman Errors 1 Mean       0.0174804
trainer/Bellman Errors 1 Std        0.0234177
trainer/Bellman Errors 1 Max        0.0839369
trainer/Bellman Errors 1 Min        7.43254e-07
trainer/Bellman Errors 2 Mean       0.0180916
trainer/Bellman Errors 2 Std        0.0237419
trainer/Bellman Errors 2 Max        0.0894819
trainer/Bellman Errors 2 Min        6.00712e-06
trainer/Policy Action Mean          0.0060794
trainer/Policy Action Std           0.154224
trainer/Policy Action Max           0.999825
trainer/Policy Action Min          -0.238809
exploration/num steps total     72100
exploration/num paths total       721
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128126
exploration/Rewards Std             0.0723433
exploration/Rewards Max            -0.00302558
exploration/Rewards Min            -0.524455
exploration/Returns Mean          -12.8126
exploration/Returns Std             0.728367
exploration/Returns Max           -12.0843
exploration/Returns Min           -13.541
exploration/Actions Mean            0.00534032
exploration/Actions Std             0.160497
exploration/Actions Max             0.870057
exploration/Actions Min            -0.518146
exploration/Num Paths               2
exploration/Average Returns       -12.8126
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0353105
evaluation/Rewards Std              0.0428506
evaluation/Rewards Max             -0.0229817
evaluation/Rewards Min             -0.953768
evaluation/Returns Mean            -3.53105
evaluation/Returns Std              0.356319
evaluation/Returns Max             -3.25494
evaluation/Returns Min             -4.22673
evaluation/Actions Mean             0.00435177
evaluation/Actions Std              0.0712596
evaluation/Actions Max              0.999995
evaluation/Actions Min             -0.907958
evaluation/Num Paths                5
evaluation/Average Returns         -3.53105
time/data storing (s)               0.00109097
time/evaluation sampling (s)        0.0760164
time/exploration sampling (s)       0.032819
time/logging (s)                    0.00246524
time/saving (s)                     0.00225924
time/training (s)                   0.45952
time/epoch (s)                      0.574171
time/total (s)                    214.309
Epoch                             359
-----------------------------  ----------------
2019-04-13 17:02:09.568094 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 360 finished
-----------------------------  ----------------
replay_buffer/size              72300
trainer/QF1 Loss                    4.97929
trainer/QF2 Loss                    4.96292
trainer/Policy Loss                12.6417
trainer/Q1 Predictions Mean       -12.7587
trainer/Q1 Predictions Std          0.0614691
trainer/Q1 Predictions Max        -12.687
trainer/Q1 Predictions Min        -12.9223
trainer/Q2 Predictions Mean       -12.755
trainer/Q2 Predictions Std          0.0598891
trainer/Q2 Predictions Max        -12.6753
trainer/Q2 Predictions Min        -12.9492
trainer/Q Targets Mean            -12.3489
trainer/Q Targets Std               2.19418
trainer/Q Targets Max              -0.163388
trainer/Q Targets Min             -13.2294
trainer/Bellman Errors 1 Mean       4.97929
trainer/Bellman Errors 1 Std       27.5526
trainer/Bellman Errors 1 Max      158.385
trainer/Bellman Errors 1 Min        4.09492e-07
trainer/Bellman Errors 2 Mean       4.96292
trainer/Bellman Errors 2 Std       27.4703
trainer/Bellman Errors 2 Max      157.911
trainer/Bellman Errors 2 Min        0.000333393
trainer/Policy Action Mean         -0.00177854
trainer/Policy Action Std           0.128944
trainer/Policy Action Max           0.670149
trainer/Policy Action Min          -0.248744
exploration/num steps total     72300
exploration/num paths total       723
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.11897
exploration/Rewards Std             0.0673165
exploration/Rewards Max            -0.00782288
exploration/Rewards Min            -0.383692
exploration/Returns Mean          -11.897
exploration/Returns Std             0.074983
exploration/Returns Max           -11.822
exploration/Returns Min           -11.972
exploration/Actions Mean            0.00462317
exploration/Actions Std             0.157497
exploration/Actions Max             0.984274
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -11.897
evaluation/num steps total     180500
evaluation/num paths total       1805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0304831
evaluation/Rewards Std              0.0408599
evaluation/Rewards Max             -0.0258278
evaluation/Rewards Min             -0.767737
evaluation/Returns Mean            -3.04831
evaluation/Returns Std              0.294751
evaluation/Returns Max             -2.72954
evaluation/Returns Min             -3.53922
evaluation/Actions Mean             0.00473325
evaluation/Actions Std              0.0861802
evaluation/Actions Max              0.999912
evaluation/Actions Min             -0.994674
evaluation/Num Paths                5
evaluation/Average Returns         -3.04831
time/data storing (s)               0.00114252
time/evaluation sampling (s)        0.0739839
time/exploration sampling (s)       0.032998
time/logging (s)                    0.0024602
time/saving (s)                     0.00231589
time/training (s)                   0.459418
time/epoch (s)                      0.572318
time/total (s)                    214.885
Epoch                             360
-----------------------------  ----------------
2019-04-13 17:02:10.193383 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 361 finished
-----------------------------  ----------------
replay_buffer/size              72500
trainer/QF1 Loss                    0.0208437
trainer/QF2 Loss                    0.0182696
trainer/Policy Loss                12.7055
trainer/Q1 Predictions Mean       -12.7582
trainer/Q1 Predictions Std          0.0575582
trainer/Q1 Predictions Max        -12.6818
trainer/Q1 Predictions Min        -12.8859
trainer/Q2 Predictions Mean       -12.7492
trainer/Q2 Predictions Std          0.0696617
trainer/Q2 Predictions Max        -12.6666
trainer/Q2 Predictions Min        -12.8808
trainer/Q Targets Mean            -12.6872
trainer/Q Targets Std               0.146594
trainer/Q Targets Max             -12.4624
trainer/Q Targets Min             -13.0558
trainer/Bellman Errors 1 Mean       0.0208437
trainer/Bellman Errors 1 Std        0.0186667
trainer/Bellman Errors 1 Max        0.0620811
trainer/Bellman Errors 1 Min        6.93821e-06
trainer/Bellman Errors 2 Mean       0.0182696
trainer/Bellman Errors 2 Std        0.0168185
trainer/Bellman Errors 2 Max        0.0595911
trainer/Bellman Errors 2 Min        1.8056e-06
trainer/Policy Action Mean          0.00155072
trainer/Policy Action Std           0.070644
trainer/Policy Action Max           0.248011
trainer/Policy Action Min          -0.139977
exploration/num steps total     72500
exploration/num paths total       725
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131543
exploration/Rewards Std             0.0692226
exploration/Rewards Max            -0.0116065
exploration/Rewards Min            -0.361439
exploration/Returns Mean          -13.1543
exploration/Returns Std             1.26489
exploration/Returns Max           -11.8894
exploration/Returns Min           -14.4192
exploration/Actions Mean            0.00374815
exploration/Actions Std             0.146104
exploration/Actions Max             0.829648
exploration/Actions Min            -0.478277
exploration/Num Paths               2
exploration/Average Returns       -13.1543
evaluation/num steps total     181000
evaluation/num paths total       1810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0310717
evaluation/Rewards Std              0.028829
evaluation/Rewards Max             -0.021607
evaluation/Rewards Min             -0.498
evaluation/Returns Mean            -3.10717
evaluation/Returns Std              0.223754
evaluation/Returns Max             -2.87684
evaluation/Returns Min             -3.39753
evaluation/Actions Mean             0.00349766
evaluation/Actions Std              0.0591334
evaluation/Actions Max              0.998767
evaluation/Actions Min             -0.573862
evaluation/Num Paths                5
evaluation/Average Returns         -3.10717
time/data storing (s)               0.00112919
time/evaluation sampling (s)        0.0771358
time/exploration sampling (s)       0.034897
time/logging (s)                    0.00254934
time/saving (s)                     0.00222248
time/training (s)                   0.498453
time/epoch (s)                      0.616387
time/total (s)                    215.506
Epoch                             361
-----------------------------  ----------------
2019-04-13 17:02:10.744967 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 362 finished
-----------------------------  ----------------
replay_buffer/size              72700
trainer/QF1 Loss                    0.0727973
trainer/QF2 Loss                    0.0718749
trainer/Policy Loss                12.4603
trainer/Q1 Predictions Mean       -12.6494
trainer/Q1 Predictions Std          0.604354
trainer/Q1 Predictions Max        -12.4008
trainer/Q1 Predictions Min        -15.9524
trainer/Q2 Predictions Mean       -12.6529
trainer/Q2 Predictions Std          0.597374
trainer/Q2 Predictions Max        -12.4234
trainer/Q2 Predictions Min        -15.9006
trainer/Q Targets Mean            -12.8384
trainer/Q Targets Std               0.596112
trainer/Q Targets Max             -12.3683
trainer/Q Targets Min             -15.9853
trainer/Bellman Errors 1 Mean       0.0727973
trainer/Bellman Errors 1 Std        0.130075
trainer/Bellman Errors 1 Max        0.748162
trainer/Bellman Errors 1 Min        0.000586723
trainer/Bellman Errors 2 Mean       0.0718749
trainer/Bellman Errors 2 Std        0.128551
trainer/Bellman Errors 2 Max        0.743372
trainer/Bellman Errors 2 Min        2.0685e-05
trainer/Policy Action Mean          0.0433983
trainer/Policy Action Std           0.202387
trainer/Policy Action Max           0.999693
trainer/Policy Action Min          -0.241827
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.152231
exploration/Rewards Std             0.0800528
exploration/Rewards Max            -0.0199006
exploration/Rewards Min            -0.41501
exploration/Returns Mean          -15.2231
exploration/Returns Std             0.904002
exploration/Returns Max           -14.3191
exploration/Returns Min           -16.1271
exploration/Actions Mean            0.00460242
exploration/Actions Std             0.161698
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -15.2231
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0819385
evaluation/Rewards Std              0.0461464
evaluation/Rewards Max             -0.0235664
evaluation/Rewards Min             -0.8268
evaluation/Returns Mean            -8.19385
evaluation/Returns Std              0.343123
evaluation/Returns Max             -7.82247
evaluation/Returns Min             -8.63246
evaluation/Actions Mean             0.00664233
evaluation/Actions Std              0.0829836
evaluation/Actions Max              0.999987
evaluation/Actions Min             -0.986944
evaluation/Num Paths                5
evaluation/Average Returns         -8.19385
time/data storing (s)               0.00124688
time/evaluation sampling (s)        0.0882692
time/exploration sampling (s)       0.0387271
time/logging (s)                    0.00248759
time/saving (s)                     0.00226019
time/training (s)                   0.409067
time/epoch (s)                      0.542058
time/total (s)                    216.052
Epoch                             362
-----------------------------  ----------------
2019-04-13 17:02:11.304965 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 363 finished
-----------------------------  ----------------
replay_buffer/size              72900
trainer/QF1 Loss                    0.0435633
trainer/QF2 Loss                    0.0430841
trainer/Policy Loss                12.7028
trainer/Q1 Predictions Mean       -12.836
trainer/Q1 Predictions Std          0.434077
trainer/Q1 Predictions Max        -12.661
trainer/Q1 Predictions Min        -15.2089
trainer/Q2 Predictions Mean       -12.8451
trainer/Q2 Predictions Std          0.433519
trainer/Q2 Predictions Max        -12.6773
trainer/Q2 Predictions Min        -15.2069
trainer/Q Targets Mean            -12.8005
trainer/Q Targets Std               0.57428
trainer/Q Targets Max             -12.3992
trainer/Q Targets Min             -15.7405
trainer/Bellman Errors 1 Mean       0.0435632
trainer/Bellman Errors 1 Std        0.0596432
trainer/Bellman Errors 1 Max        0.28264
trainer/Bellman Errors 1 Min        0.000379795
trainer/Bellman Errors 2 Mean       0.0430841
trainer/Bellman Errors 2 Std        0.0578907
trainer/Bellman Errors 2 Max        0.284753
trainer/Bellman Errors 2 Min        0.000851002
trainer/Policy Action Mean          0.0172436
trainer/Policy Action Std           0.216004
trainer/Policy Action Max           0.999466
trainer/Policy Action Min          -0.496455
exploration/num steps total     72900
exploration/num paths total       729
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127114
exploration/Rewards Std             0.0665571
exploration/Rewards Max            -0.00906189
exploration/Rewards Min            -0.396542
exploration/Returns Mean          -12.7114
exploration/Returns Std             0.485402
exploration/Returns Max           -12.226
exploration/Returns Min           -13.1968
exploration/Actions Mean           -0.00132568
exploration/Actions Std             0.15513
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.7114
evaluation/num steps total     182000
evaluation/num paths total       1820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0250718
evaluation/Rewards Std              0.0261054
evaluation/Rewards Max             -0.0151778
evaluation/Rewards Min             -0.577968
evaluation/Returns Mean            -2.50718
evaluation/Returns Std              0.216305
evaluation/Returns Max             -2.35998
evaluation/Returns Min             -2.92279
evaluation/Actions Mean             0.00552701
evaluation/Actions Std              0.0740612
evaluation/Actions Max              0.999501
evaluation/Actions Min             -0.879786
evaluation/Num Paths                5
evaluation/Average Returns         -2.50718
time/data storing (s)               0.00130234
time/evaluation sampling (s)        0.085868
time/exploration sampling (s)       0.0348626
time/logging (s)                    0.00246389
time/saving (s)                     0.00247349
time/training (s)                   0.422524
time/epoch (s)                      0.549494
time/total (s)                    216.605
Epoch                             363
-----------------------------  ----------------
2019-04-13 17:02:11.836531 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 364 finished
-----------------------------  ---------------
replay_buffer/size              73100
trainer/QF1 Loss                    0.216702
trainer/QF2 Loss                    0.228883
trainer/Policy Loss                12.3702
trainer/Q1 Predictions Mean       -12.4379
trainer/Q1 Predictions Std          0.607576
trainer/Q1 Predictions Max        -12.1946
trainer/Q1 Predictions Min        -14.8066
trainer/Q2 Predictions Mean       -12.4247
trainer/Q2 Predictions Std          0.606213
trainer/Q2 Predictions Max        -12.1881
trainer/Q2 Predictions Min        -14.775
trainer/Q Targets Mean            -12.8618
trainer/Q Targets Std               0.695173
trainer/Q Targets Max             -12.4235
trainer/Q Targets Min             -15.7251
trainer/Bellman Errors 1 Mean       0.216702
trainer/Bellman Errors 1 Std        0.209212
trainer/Bellman Errors 1 Max        0.91911
trainer/Bellman Errors 1 Min        0.0226311
trainer/Bellman Errors 2 Mean       0.228883
trainer/Bellman Errors 2 Std        0.217669
trainer/Bellman Errors 2 Max        0.926048
trainer/Bellman Errors 2 Min        0.0256659
trainer/Policy Action Mean          0.0730902
trainer/Policy Action Std           0.224352
trainer/Policy Action Max           0.999651
trainer/Policy Action Min          -0.344795
exploration/num steps total     73100
exploration/num paths total       731
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131836
exploration/Rewards Std             0.0728135
exploration/Rewards Max            -0.00656233
exploration/Rewards Min            -0.373514
exploration/Returns Mean          -13.1836
exploration/Returns Std             0.262045
exploration/Returns Max           -12.9215
exploration/Returns Min           -13.4456
exploration/Actions Mean            0.00299324
exploration/Actions Std             0.154293
exploration/Actions Max             1
exploration/Actions Min            -0.882282
exploration/Num Paths               2
exploration/Average Returns       -13.1836
evaluation/num steps total     182500
evaluation/num paths total       1825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0603476
evaluation/Rewards Std              0.0233955
evaluation/Rewards Max             -0.0373906
evaluation/Rewards Min             -0.442309
evaluation/Returns Mean            -6.03476
evaluation/Returns Std              0.117919
evaluation/Returns Max             -5.89838
evaluation/Returns Min             -6.21596
evaluation/Actions Mean             0.00828768
evaluation/Actions Std              0.081119
evaluation/Actions Max              0.99823
evaluation/Actions Min             -0.103333
evaluation/Num Paths                5
evaluation/Average Returns         -6.03476
time/data storing (s)               0.00104732
time/evaluation sampling (s)        0.0740181
time/exploration sampling (s)       0.03208
time/logging (s)                    0.00244593
time/saving (s)                     0.00225672
time/training (s)                   0.410318
time/epoch (s)                      0.522167
time/total (s)                    217.132
Epoch                             364
-----------------------------  ---------------
2019-04-13 17:02:12.378535 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 365 finished
-----------------------------  ----------------
replay_buffer/size              73300
trainer/QF1 Loss                    0.0486138
trainer/QF2 Loss                    0.0497858
trainer/Policy Loss                12.4122
trainer/Q1 Predictions Mean       -12.5852
trainer/Q1 Predictions Std          0.12465
trainer/Q1 Predictions Max        -12.4531
trainer/Q1 Predictions Min        -13.1297
trainer/Q2 Predictions Mean       -12.5843
trainer/Q2 Predictions Std          0.126529
trainer/Q2 Predictions Max        -12.4706
trainer/Q2 Predictions Min        -13.1579
trainer/Q Targets Mean            -12.7335
trainer/Q Targets Std               0.208468
trainer/Q Targets Max             -12.3749
trainer/Q Targets Min             -13.1812
trainer/Bellman Errors 1 Mean       0.0486138
trainer/Bellman Errors 1 Std        0.0640995
trainer/Bellman Errors 1 Max        0.313835
trainer/Bellman Errors 1 Min        1.92282e-05
trainer/Bellman Errors 2 Mean       0.0497858
trainer/Bellman Errors 2 Std        0.0661713
trainer/Bellman Errors 2 Max        0.315144
trainer/Bellman Errors 2 Min        0.000158494
trainer/Policy Action Mean          0.0286085
trainer/Policy Action Std           0.163203
trainer/Policy Action Max           0.695227
trainer/Policy Action Min          -0.395978
exploration/num steps total     73300
exploration/num paths total       733
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134943
exploration/Rewards Std             0.0696606
exploration/Rewards Max            -0.00686328
exploration/Rewards Min            -0.356316
exploration/Returns Mean          -13.4943
exploration/Returns Std             0.33417
exploration/Returns Max           -13.1601
exploration/Returns Min           -13.8284
exploration/Actions Mean            0.00221728
exploration/Actions Std             0.144897
exploration/Actions Max             0.771992
exploration/Actions Min            -0.40907
exploration/Num Paths               2
exploration/Average Returns       -13.4943
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0572784
evaluation/Rewards Std              0.0624947
evaluation/Rewards Max             -0.0109654
evaluation/Rewards Min             -0.962621
evaluation/Returns Mean            -5.72784
evaluation/Returns Std              0.314983
evaluation/Returns Max             -5.38066
evaluation/Returns Min             -6.09763
evaluation/Actions Mean             0.00826368
evaluation/Actions Std              0.0923738
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.81299
evaluation/Num Paths                5
evaluation/Average Returns         -5.72784
time/data storing (s)               0.00112021
time/evaluation sampling (s)        0.0719549
time/exploration sampling (s)       0.0331804
time/logging (s)                    0.00247124
time/saving (s)                     0.00621184
time/training (s)                   0.417736
time/epoch (s)                      0.532674
time/total (s)                    217.669
Epoch                             365
-----------------------------  ----------------
2019-04-13 17:02:12.905031 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 366 finished
-----------------------------  ----------------
replay_buffer/size              73500
trainer/QF1 Loss                    0.0189544
trainer/QF2 Loss                    0.0201121
trainer/Policy Loss                12.5155
trainer/Q1 Predictions Mean       -12.6287
trainer/Q1 Predictions Std          0.108957
trainer/Q1 Predictions Max        -12.479
trainer/Q1 Predictions Min        -12.9078
trainer/Q2 Predictions Mean       -12.622
trainer/Q2 Predictions Std          0.0960339
trainer/Q2 Predictions Max        -12.4836
trainer/Q2 Predictions Min        -12.8576
trainer/Q Targets Mean            -12.7043
trainer/Q Targets Std               0.156784
trainer/Q Targets Max             -12.3806
trainer/Q Targets Min             -13.0353
trainer/Bellman Errors 1 Mean       0.0189544
trainer/Bellman Errors 1 Std        0.0205464
trainer/Bellman Errors 1 Max        0.0870588
trainer/Bellman Errors 1 Min        4.66779e-05
trainer/Bellman Errors 2 Mean       0.0201121
trainer/Bellman Errors 2 Std        0.0227655
trainer/Bellman Errors 2 Max        0.0816348
trainer/Bellman Errors 2 Min        4.8196e-06
trainer/Policy Action Mean          0.0200199
trainer/Policy Action Std           0.0944609
trainer/Policy Action Max           0.242987
trainer/Policy Action Min          -0.208246
exploration/num steps total     73500
exploration/num paths total       735
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137757
exploration/Rewards Std             0.0884304
exploration/Rewards Max            -0.00791186
exploration/Rewards Min            -0.814974
exploration/Returns Mean          -13.7757
exploration/Returns Std             0.0231227
exploration/Returns Max           -13.7526
exploration/Returns Min           -13.7988
exploration/Actions Mean            0.0100179
exploration/Actions Std             0.153326
exploration/Actions Max             1
exploration/Actions Min            -0.506021
exploration/Num Paths               2
exploration/Average Returns       -13.7757
evaluation/num steps total     183500
evaluation/num paths total       1835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0392928
evaluation/Rewards Std              0.0424374
evaluation/Rewards Max             -0.0227525
evaluation/Rewards Min             -0.882994
evaluation/Returns Mean            -3.92928
evaluation/Returns Std              0.331456
evaluation/Returns Max             -3.67165
evaluation/Returns Min             -4.51025
evaluation/Actions Mean             0.00837717
evaluation/Actions Std              0.081973
evaluation/Actions Max              0.999992
evaluation/Actions Min             -0.296504
evaluation/Num Paths                5
evaluation/Average Returns         -3.92928
time/data storing (s)               0.00111015
time/evaluation sampling (s)        0.0723656
time/exploration sampling (s)       0.0331787
time/logging (s)                    0.00252104
time/saving (s)                     0.00223179
time/training (s)                   0.406292
time/epoch (s)                      0.517699
time/total (s)                    218.19
Epoch                             366
-----------------------------  ----------------
2019-04-13 17:02:13.418378 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 367 finished
-----------------------------  ----------------
replay_buffer/size              73700
trainer/QF1 Loss                    0.0727831
trainer/QF2 Loss                    0.0691501
trainer/Policy Loss                12.4087
trainer/Q1 Predictions Mean       -12.5036
trainer/Q1 Predictions Std          0.193838
trainer/Q1 Predictions Max        -12.3846
trainer/Q1 Predictions Min        -13.2607
trainer/Q2 Predictions Mean       -12.514
trainer/Q2 Predictions Std          0.191277
trainer/Q2 Predictions Max        -12.3877
trainer/Q2 Predictions Min        -13.2604
trainer/Q Targets Mean            -12.7354
trainer/Q Targets Std               0.222647
trainer/Q Targets Max             -12.4199
trainer/Q Targets Min             -13.4506
trainer/Bellman Errors 1 Mean       0.0727831
trainer/Bellman Errors 1 Std        0.0746544
trainer/Bellman Errors 1 Max        0.339175
trainer/Bellman Errors 1 Min        4.73974e-05
trainer/Bellman Errors 2 Mean       0.0691501
trainer/Bellman Errors 2 Std        0.0761021
trainer/Bellman Errors 2 Max        0.357605
trainer/Bellman Errors 2 Min        0.000112929
trainer/Policy Action Mean         -0.00262669
trainer/Policy Action Std           0.142679
trainer/Policy Action Max           0.433282
trainer/Policy Action Min          -0.443656
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12157
exploration/Rewards Std             0.0644118
exploration/Rewards Max            -0.00404861
exploration/Rewards Min            -0.358821
exploration/Returns Mean          -12.157
exploration/Returns Std             0.250557
exploration/Returns Max           -11.9064
exploration/Returns Min           -12.4076
exploration/Actions Mean            0.00608312
exploration/Actions Std             0.145085
exploration/Actions Max             0.934774
exploration/Actions Min            -0.448348
exploration/Num Paths               2
exploration/Average Returns       -12.157
evaluation/num steps total     184000
evaluation/num paths total       1840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0278497
evaluation/Rewards Std              0.0273247
evaluation/Rewards Max             -0.0192262
evaluation/Rewards Min             -0.625771
evaluation/Returns Mean            -2.78497
evaluation/Returns Std              0.241573
evaluation/Returns Max             -2.64614
evaluation/Returns Min             -3.26657
evaluation/Actions Mean             0.00561772
evaluation/Actions Std              0.0603033
evaluation/Actions Max              0.999766
evaluation/Actions Min             -0.135934
evaluation/Num Paths                5
evaluation/Average Returns         -2.78497
time/data storing (s)               0.00107792
time/evaluation sampling (s)        0.0734164
time/exploration sampling (s)       0.0333128
time/logging (s)                    0.0025007
time/saving (s)                     0.002268
time/training (s)                   0.391389
time/epoch (s)                      0.503965
time/total (s)                    218.697
Epoch                             367
-----------------------------  ----------------
2019-04-13 17:02:13.947026 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 368 finished
-----------------------------  ----------------
replay_buffer/size              73900
trainer/QF1 Loss                    0.0464215
trainer/QF2 Loss                    0.0563734
trainer/Policy Loss                12.5313
trainer/Q1 Predictions Mean       -12.6719
trainer/Q1 Predictions Std          0.491364
trainer/Q1 Predictions Max        -12.432
trainer/Q1 Predictions Min        -15.0237
trainer/Q2 Predictions Mean       -12.6561
trainer/Q2 Predictions Std          0.474184
trainer/Q2 Predictions Max        -12.4174
trainer/Q2 Predictions Min        -15.0021
trainer/Q Targets Mean            -12.8419
trainer/Q Targets Std               0.546218
trainer/Q Targets Max             -12.4056
trainer/Q Targets Min             -15.2927
trainer/Bellman Errors 1 Mean       0.0464215
trainer/Bellman Errors 1 Std        0.0494642
trainer/Bellman Errors 1 Max        0.158213
trainer/Bellman Errors 1 Min        2.21411e-05
trainer/Bellman Errors 2 Mean       0.0563734
trainer/Bellman Errors 2 Std        0.0740417
trainer/Bellman Errors 2 Max        0.365385
trainer/Bellman Errors 2 Min        0.000151889
trainer/Policy Action Mean          0.0323154
trainer/Policy Action Std           0.220138
trainer/Policy Action Max           0.999672
trainer/Policy Action Min          -0.447856
exploration/num steps total     73900
exploration/num paths total       739
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137528
exploration/Rewards Std             0.0978297
exploration/Rewards Max            -0.00734807
exploration/Rewards Min            -1.08627
exploration/Returns Mean          -13.7528
exploration/Returns Std             0.864804
exploration/Returns Max           -12.8879
exploration/Returns Min           -14.6176
exploration/Actions Mean            0.00382031
exploration/Actions Std             0.150472
exploration/Actions Max             0.911854
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.7528
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0591774
evaluation/Rewards Std              0.0505652
evaluation/Rewards Max             -0.0325134
evaluation/Rewards Min             -0.944024
evaluation/Returns Mean            -5.91774
evaluation/Returns Std              0.394149
evaluation/Returns Max             -5.58121
evaluation/Returns Min             -6.48792
evaluation/Actions Mean             0.0058345
evaluation/Actions Std              0.0842515
evaluation/Actions Max              0.999995
evaluation/Actions Min             -0.997311
evaluation/Num Paths                5
evaluation/Average Returns         -5.91774
time/data storing (s)               0.00107444
time/evaluation sampling (s)        0.0744037
time/exploration sampling (s)       0.032679
time/logging (s)                    0.00246425
time/saving (s)                     0.00222681
time/training (s)                   0.407645
time/epoch (s)                      0.520494
time/total (s)                    219.222
Epoch                             368
-----------------------------  ----------------
2019-04-13 17:02:14.489214 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 369 finished
-----------------------------  ----------------
replay_buffer/size              74100
trainer/QF1 Loss                    0.0489935
trainer/QF2 Loss                    0.0432135
trainer/Policy Loss                12.4196
trainer/Q1 Predictions Mean       -12.5256
trainer/Q1 Predictions Std          0.148778
trainer/Q1 Predictions Max        -12.4125
trainer/Q1 Predictions Min        -13.2399
trainer/Q2 Predictions Mean       -12.5329
trainer/Q2 Predictions Std          0.159629
trainer/Q2 Predictions Max        -12.3862
trainer/Q2 Predictions Min        -13.2513
trainer/Q Targets Mean            -12.6854
trainer/Q Targets Std               0.212771
trainer/Q Targets Max             -12.3637
trainer/Q Targets Min             -13.4004
trainer/Bellman Errors 1 Mean       0.0489935
trainer/Bellman Errors 1 Std        0.0622221
trainer/Bellman Errors 1 Max        0.202048
trainer/Bellman Errors 1 Min        0.000465644
trainer/Bellman Errors 2 Mean       0.0432135
trainer/Bellman Errors 2 Std        0.0536448
trainer/Bellman Errors 2 Max        0.203777
trainer/Bellman Errors 2 Min        4.5076e-07
trainer/Policy Action Mean          0.00449262
trainer/Policy Action Std           0.121733
trainer/Policy Action Max           0.363216
trainer/Policy Action Min          -0.423231
exploration/num steps total     74100
exploration/num paths total       741
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12524
exploration/Rewards Std             0.0691666
exploration/Rewards Max            -0.00965002
exploration/Rewards Min            -0.350507
exploration/Returns Mean          -12.524
exploration/Returns Std             0.147656
exploration/Returns Max           -12.3764
exploration/Returns Min           -12.6717
exploration/Actions Mean            0.00489256
exploration/Actions Std             0.145425
exploration/Actions Max             0.791937
exploration/Actions Min            -0.398366
exploration/Num Paths               2
exploration/Average Returns       -12.524
evaluation/num steps total     185000
evaluation/num paths total       1850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0312698
evaluation/Rewards Std              0.0495549
evaluation/Rewards Max             -0.0228265
evaluation/Rewards Min             -0.934205
evaluation/Returns Mean            -3.12698
evaluation/Returns Std              0.362371
evaluation/Returns Max             -2.77587
evaluation/Returns Min             -3.69309
evaluation/Actions Mean             0.00433477
evaluation/Actions Std              0.0843206
evaluation/Actions Max              0.999988
evaluation/Actions Min             -0.94272
evaluation/Num Paths                5
evaluation/Average Returns         -3.12698
time/data storing (s)               0.00116701
time/evaluation sampling (s)        0.0745553
time/exploration sampling (s)       0.0317185
time/logging (s)                    0.0025463
time/saving (s)                     0.0022484
time/training (s)                   0.420537
time/epoch (s)                      0.532773
time/total (s)                    219.759
Epoch                             369
-----------------------------  ----------------
2019-04-13 17:02:15.012700 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 370 finished
-----------------------------  ----------------
replay_buffer/size              74300
trainer/QF1 Loss                    0.0892945
trainer/QF2 Loss                    0.0923542
trainer/Policy Loss                12.4371
trainer/Q1 Predictions Mean       -12.5646
trainer/Q1 Predictions Std          0.470721
trainer/Q1 Predictions Max        -12.34
trainer/Q1 Predictions Min        -14.9756
trainer/Q2 Predictions Mean       -12.5544
trainer/Q2 Predictions Std          0.475961
trainer/Q2 Predictions Max        -12.2977
trainer/Q2 Predictions Min        -15.0047
trainer/Q Targets Mean            -12.7918
trainer/Q Targets Std               0.472685
trainer/Q Targets Max             -12.3995
trainer/Q Targets Min             -15.07
trainer/Bellman Errors 1 Mean       0.0892945
trainer/Bellman Errors 1 Std        0.123088
trainer/Bellman Errors 1 Max        0.433603
trainer/Bellman Errors 1 Min        0.000251164
trainer/Bellman Errors 2 Mean       0.0923542
trainer/Bellman Errors 2 Std        0.123086
trainer/Bellman Errors 2 Max        0.460234
trainer/Bellman Errors 2 Min        4.51529e-05
trainer/Policy Action Mean          0.0296429
trainer/Policy Action Std           0.226385
trainer/Policy Action Max           0.999131
trainer/Policy Action Min          -0.20622
exploration/num steps total     74300
exploration/num paths total       743
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133795
exploration/Rewards Std             0.077174
exploration/Rewards Max            -0.0188974
exploration/Rewards Min            -0.528804
exploration/Returns Mean          -13.3795
exploration/Returns Std             0.174738
exploration/Returns Max           -13.2048
exploration/Returns Min           -13.5542
exploration/Actions Mean            0.00428216
exploration/Actions Std             0.144762
exploration/Actions Max             0.999101
exploration/Actions Min            -0.403895
exploration/Num Paths               2
exploration/Average Returns       -13.3795
evaluation/num steps total     185500
evaluation/num paths total       1855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0379122
evaluation/Rewards Std              0.0227047
evaluation/Rewards Max             -0.0357816
evaluation/Rewards Min             -0.420338
evaluation/Returns Mean            -3.79122
evaluation/Returns Std              0.157923
evaluation/Returns Max             -3.62137
evaluation/Returns Min             -4.01929
evaluation/Actions Mean             0.00556666
evaluation/Actions Std              0.0733474
evaluation/Actions Max              0.998238
evaluation/Actions Min             -0.536546
evaluation/Num Paths                5
evaluation/Average Returns         -3.79122
time/data storing (s)               0.00122172
time/evaluation sampling (s)        0.0742689
time/exploration sampling (s)       0.0371344
time/logging (s)                    0.00248188
time/saving (s)                     0.00226417
time/training (s)                   0.397346
time/epoch (s)                      0.514717
time/total (s)                    220.278
Epoch                             370
-----------------------------  ----------------
2019-04-13 17:02:15.544632 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 371 finished
-----------------------------  ----------------
replay_buffer/size              74500
trainer/QF1 Loss                    9.75792
trainer/QF2 Loss                    9.75594
trainer/Policy Loss                12.4697
trainer/Q1 Predictions Mean       -12.7595
trainer/Q1 Predictions Std          0.588011
trainer/Q1 Predictions Max        -12.4689
trainer/Q1 Predictions Min        -15.071
trainer/Q2 Predictions Mean       -12.7638
trainer/Q2 Predictions Std          0.616603
trainer/Q2 Predictions Max        -12.4659
trainer/Q2 Predictions Min        -15.2664
trainer/Q Targets Mean            -12.1473
trainer/Q Targets Std               3.16779
trainer/Q Targets Max              -0.0593254
trainer/Q Targets Min             -15.4407
trainer/Bellman Errors 1 Mean       9.75792
trainer/Bellman Errors 1 Std       37.5309
trainer/Bellman Errors 1 Max      155.335
trainer/Bellman Errors 1 Min        3.20686e-05
trainer/Bellman Errors 2 Mean       9.75594
trainer/Bellman Errors 2 Std       37.524
trainer/Bellman Errors 2 Max      155.649
trainer/Bellman Errors 2 Min        2.21335e-08
trainer/Policy Action Mean          0.0283102
trainer/Policy Action Std           0.227768
trainer/Policy Action Max           0.999714
trainer/Policy Action Min          -0.431871
exploration/num steps total     74500
exploration/num paths total       745
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136393
exploration/Rewards Std             0.104299
exploration/Rewards Max            -0.00658498
exploration/Rewards Min            -1.04175
exploration/Returns Mean          -13.6393
exploration/Returns Std             0.748878
exploration/Returns Max           -12.8905
exploration/Returns Min           -14.3882
exploration/Actions Mean            0.00754879
exploration/Actions Std             0.161989
exploration/Actions Max             1
exploration/Actions Min            -0.353241
exploration/Num Paths               2
exploration/Average Returns       -13.6393
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0227554
evaluation/Rewards Std              0.0423155
evaluation/Rewards Max             -0.0135871
evaluation/Rewards Min             -0.881714
evaluation/Returns Mean            -2.27554
evaluation/Returns Std              0.325361
evaluation/Returns Max             -1.98379
evaluation/Returns Min             -2.87712
evaluation/Actions Mean             0.00344337
evaluation/Actions Std              0.0784961
evaluation/Actions Max              0.999985
evaluation/Actions Min             -0.97643
evaluation/Num Paths                5
evaluation/Average Returns         -2.27554
time/data storing (s)               0.00114607
time/evaluation sampling (s)        0.0738329
time/exploration sampling (s)       0.0340823
time/logging (s)                    0.00250925
time/saving (s)                     0.00226682
time/training (s)                   0.408585
time/epoch (s)                      0.522423
time/total (s)                    220.804
Epoch                             371
-----------------------------  ----------------
2019-04-13 17:02:16.085679 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 372 finished
-----------------------------  ---------------
replay_buffer/size              74700
trainer/QF1 Loss                    0.132926
trainer/QF2 Loss                    0.123955
trainer/Policy Loss                12.3249
trainer/Q1 Predictions Mean       -12.3955
trainer/Q1 Predictions Std          0.110652
trainer/Q1 Predictions Max        -12.2818
trainer/Q1 Predictions Min        -12.7515
trainer/Q2 Predictions Mean       -12.4097
trainer/Q2 Predictions Std          0.112954
trainer/Q2 Predictions Max        -12.3031
trainer/Q2 Predictions Min        -12.7705
trainer/Q Targets Mean            -12.7083
trainer/Q Targets Std               0.16419
trainer/Q Targets Max             -12.4011
trainer/Q Targets Min             -13.0671
trainer/Bellman Errors 1 Mean       0.132926
trainer/Bellman Errors 1 Std        0.127726
trainer/Bellman Errors 1 Max        0.440073
trainer/Bellman Errors 1 Min        0.00079724
trainer/Bellman Errors 2 Mean       0.123955
trainer/Bellman Errors 2 Std        0.121691
trainer/Bellman Errors 2 Max        0.406422
trainer/Bellman Errors 2 Min        0.00148437
trainer/Policy Action Mean          0.0043174
trainer/Policy Action Std           0.108347
trainer/Policy Action Max           0.320363
trainer/Policy Action Min          -0.286185
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137917
exploration/Rewards Std             0.0881077
exploration/Rewards Max            -0.00973974
exploration/Rewards Min            -0.766736
exploration/Returns Mean          -13.7917
exploration/Returns Std             0.372892
exploration/Returns Max           -13.4188
exploration/Returns Min           -14.1646
exploration/Actions Mean            0.00894055
exploration/Actions Std             0.15392
exploration/Actions Max             1
exploration/Actions Min            -0.909675
exploration/Num Paths               2
exploration/Average Returns       -13.7917
evaluation/num steps total     186500
evaluation/num paths total       1865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0701913
evaluation/Rewards Std              0.0378711
evaluation/Rewards Max             -0.0608445
evaluation/Rewards Min             -0.893011
evaluation/Returns Mean            -7.01913
evaluation/Returns Std              0.31083
evaluation/Returns Max             -6.77983
evaluation/Returns Min             -7.62692
evaluation/Actions Mean             0.00278937
evaluation/Actions Std              0.0880363
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.974391
evaluation/Num Paths                5
evaluation/Average Returns         -7.01913
time/data storing (s)               0.00120972
time/evaluation sampling (s)        0.0749545
time/exploration sampling (s)       0.0375519
time/logging (s)                    0.00247207
time/saving (s)                     0.00226821
time/training (s)                   0.413655
time/epoch (s)                      0.532111
time/total (s)                    221.34
Epoch                             372
-----------------------------  ---------------
2019-04-13 17:02:16.612913 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 373 finished
-----------------------------  ----------------
replay_buffer/size              74900
trainer/QF1 Loss                    0.054845
trainer/QF2 Loss                    0.0555169
trainer/Policy Loss                12.6075
trainer/Q1 Predictions Mean       -12.8259
trainer/Q1 Predictions Std          0.428844
trainer/Q1 Predictions Max        -12.5358
trainer/Q1 Predictions Min        -15.0995
trainer/Q2 Predictions Mean       -12.8298
trainer/Q2 Predictions Std          0.434473
trainer/Q2 Predictions Max        -12.5802
trainer/Q2 Predictions Min        -15.1505
trainer/Q Targets Mean            -12.7808
trainer/Q Targets Std               0.524918
trainer/Q Targets Max             -12.4066
trainer/Q Targets Min             -15.2988
trainer/Bellman Errors 1 Mean       0.054845
trainer/Bellman Errors 1 Std        0.10041
trainer/Bellman Errors 1 Max        0.541792
trainer/Bellman Errors 1 Min        3.65e-05
trainer/Bellman Errors 2 Mean       0.0555169
trainer/Bellman Errors 2 Std        0.10828
trainer/Bellman Errors 2 Max        0.599289
trainer/Bellman Errors 2 Min        0.000115456
trainer/Policy Action Mean          0.0226376
trainer/Policy Action Std           0.169115
trainer/Policy Action Max           0.999583
trainer/Policy Action Min          -0.429505
exploration/num steps total     74900
exploration/num paths total       749
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128944
exploration/Rewards Std             0.0745289
exploration/Rewards Max            -0.0030855
exploration/Rewards Min            -0.577065
exploration/Returns Mean          -12.8944
exploration/Returns Std             0.138271
exploration/Returns Max           -12.7561
exploration/Returns Min           -13.0326
exploration/Actions Mean            0.00711572
exploration/Actions Std             0.152517
exploration/Actions Max             1
exploration/Actions Min            -0.491565
exploration/Num Paths               2
exploration/Average Returns       -12.8944
evaluation/num steps total     187000
evaluation/num paths total       1870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0312382
evaluation/Rewards Std              0.0459816
evaluation/Rewards Max             -0.0245619
evaluation/Rewards Min             -0.970326
evaluation/Returns Mean            -3.12382
evaluation/Returns Std              0.374621
evaluation/Returns Max             -2.799
evaluation/Returns Min             -3.81988
evaluation/Actions Mean             0.00623145
evaluation/Actions Std              0.0787238
evaluation/Actions Max              0.999991
evaluation/Actions Min             -0.980858
evaluation/Num Paths                5
evaluation/Average Returns         -3.12382
time/data storing (s)               0.0012081
time/evaluation sampling (s)        0.0741999
time/exploration sampling (s)       0.0337158
time/logging (s)                    0.00255458
time/saving (s)                     0.00228837
time/training (s)                   0.403701
time/epoch (s)                      0.517668
time/total (s)                    221.862
Epoch                             373
-----------------------------  ----------------
2019-04-13 17:02:17.138968 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 374 finished
-----------------------------  ----------------
replay_buffer/size              75100
trainer/QF1 Loss                    0.0827242
trainer/QF2 Loss                    0.081095
trainer/Policy Loss                12.4393
trainer/Q1 Predictions Mean       -12.5576
trainer/Q1 Predictions Std          0.315244
trainer/Q1 Predictions Max        -12.3856
trainer/Q1 Predictions Min        -14.2205
trainer/Q2 Predictions Mean       -12.5548
trainer/Q2 Predictions Std          0.319293
trainer/Q2 Predictions Max        -12.369
trainer/Q2 Predictions Min        -14.2428
trainer/Q Targets Mean            -12.7821
trainer/Q Targets Std               0.417252
trainer/Q Targets Max             -12.4281
trainer/Q Targets Min             -14.8249
trainer/Bellman Errors 1 Mean       0.0827242
trainer/Bellman Errors 1 Std        0.115905
trainer/Bellman Errors 1 Max        0.50048
trainer/Bellman Errors 1 Min        2.72129e-05
trainer/Bellman Errors 2 Mean       0.0810949
trainer/Bellman Errors 2 Std        0.108153
trainer/Bellman Errors 2 Max        0.444636
trainer/Bellman Errors 2 Min        0.000142905
trainer/Policy Action Mean          0.0152968
trainer/Policy Action Std           0.175696
trainer/Policy Action Max           0.984529
trainer/Policy Action Min          -0.38889
exploration/num steps total     75100
exploration/num paths total       751
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128463
exploration/Rewards Std             0.0642152
exploration/Rewards Max            -0.0103337
exploration/Rewards Min            -0.289701
exploration/Returns Mean          -12.8463
exploration/Returns Std             0.265493
exploration/Returns Max           -12.5808
exploration/Returns Min           -13.1118
exploration/Actions Mean            0.00445182
exploration/Actions Std             0.139383
exploration/Actions Max             0.875837
exploration/Actions Min            -0.342508
exploration/Num Paths               2
exploration/Average Returns       -12.8463
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0350726
evaluation/Rewards Std              0.0538626
evaluation/Rewards Max             -0.00547719
evaluation/Rewards Min             -0.846931
evaluation/Returns Mean            -3.50726
evaluation/Returns Std              0.339823
evaluation/Returns Max             -3.09505
evaluation/Returns Min             -3.92098
evaluation/Actions Mean             0.00578657
evaluation/Actions Std              0.0823153
evaluation/Actions Max              0.999973
evaluation/Actions Min             -0.923535
evaluation/Num Paths                5
evaluation/Average Returns         -3.50726
time/data storing (s)               0.00107253
time/evaluation sampling (s)        0.0737456
time/exploration sampling (s)       0.0334077
time/logging (s)                    0.00247002
time/saving (s)                     0.00179089
time/training (s)                   0.403923
time/epoch (s)                      0.51641
time/total (s)                    222.382
Epoch                             374
-----------------------------  ----------------
2019-04-13 17:02:17.660126 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 375 finished
-----------------------------  ----------------
replay_buffer/size              75300
trainer/QF1 Loss                    4.86567
trainer/QF2 Loss                    4.87936
trainer/Policy Loss                12.3674
trainer/Q1 Predictions Mean       -12.5163
trainer/Q1 Predictions Std          0.11192
trainer/Q1 Predictions Max        -12.3828
trainer/Q1 Predictions Min        -12.9235
trainer/Q2 Predictions Mean       -12.518
trainer/Q2 Predictions Std          0.101252
trainer/Q2 Predictions Max        -12.3965
trainer/Q2 Predictions Min        -12.9046
trainer/Q Targets Mean            -12.3168
trainer/Q Targets Std               2.18212
trainer/Q Targets Max              -0.210537
trainer/Q Targets Min             -13.1986
trainer/Bellman Errors 1 Mean       4.86567
trainer/Bellman Errors 1 Std       26.7235
trainer/Bellman Errors 1 Max      153.655
trainer/Bellman Errors 1 Min        0.000704665
trainer/Bellman Errors 2 Mean       4.87936
trainer/Bellman Errors 2 Std       26.7976
trainer/Bellman Errors 2 Max      154.081
trainer/Bellman Errors 2 Min        0.000387942
trainer/Policy Action Mean         -0.00331366
trainer/Policy Action Std           0.123143
trainer/Policy Action Max           0.268989
trainer/Policy Action Min          -0.427114
exploration/num steps total     75300
exploration/num paths total       753
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129164
exploration/Rewards Std             0.073222
exploration/Rewards Max            -0.0125463
exploration/Rewards Min            -0.550048
exploration/Returns Mean          -12.9164
exploration/Returns Std             0.455207
exploration/Returns Max           -12.4612
exploration/Returns Min           -13.3717
exploration/Actions Mean            0.00568246
exploration/Actions Std             0.164398
exploration/Actions Max             0.996968
exploration/Actions Min            -0.572481
exploration/Num Paths               2
exploration/Average Returns       -12.9164
evaluation/num steps total     188000
evaluation/num paths total       1880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0150306
evaluation/Rewards Std              0.0484917
evaluation/Rewards Max             -0.00772583
evaluation/Rewards Min             -0.966397
evaluation/Returns Mean            -1.50306
evaluation/Returns Std              0.385313
evaluation/Returns Max             -1.16316
evaluation/Returns Min             -2.16926
evaluation/Actions Mean             0.00494251
evaluation/Actions Std              0.0845871
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.997017
evaluation/Num Paths                5
evaluation/Average Returns         -1.50306
time/data storing (s)               0.00118812
time/evaluation sampling (s)        0.0724927
time/exploration sampling (s)       0.0321766
time/logging (s)                    0.00248452
time/saving (s)                     0.00226298
time/training (s)                   0.40106
time/epoch (s)                      0.511665
time/total (s)                    222.899
Epoch                             375
-----------------------------  ----------------
2019-04-13 17:02:18.189548 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 376 finished
-----------------------------  ----------------
replay_buffer/size              75500
trainer/QF1 Loss                    4.93508
trainer/QF2 Loss                    4.93309
trainer/Policy Loss                12.4934
trainer/Q1 Predictions Mean       -12.6151
trainer/Q1 Predictions Std          0.0736557
trainer/Q1 Predictions Max        -12.5025
trainer/Q1 Predictions Min        -12.7656
trainer/Q2 Predictions Mean       -12.5967
trainer/Q2 Predictions Std          0.0753367
trainer/Q2 Predictions Max        -12.4873
trainer/Q2 Predictions Min        -12.759
trainer/Q Targets Mean            -12.3534
trainer/Q Targets Std               2.18104
trainer/Q Targets Max              -0.257189
trainer/Q Targets Min             -13.0791
trainer/Bellman Errors 1 Mean       4.93508
trainer/Bellman Errors 1 Std       27.215
trainer/Bellman Errors 1 Max      156.462
trainer/Bellman Errors 1 Min        0.000341416
trainer/Bellman Errors 2 Mean       4.93309
trainer/Bellman Errors 2 Std       27.177
trainer/Bellman Errors 2 Max      156.248
trainer/Bellman Errors 2 Min        0.000142541
trainer/Policy Action Mean          0.0520487
trainer/Policy Action Std           0.149844
trainer/Policy Action Max           0.866714
trainer/Policy Action Min          -0.217293
exploration/num steps total     75500
exploration/num paths total       755
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128258
exploration/Rewards Std             0.0673034
exploration/Rewards Max            -0.00320064
exploration/Rewards Min            -0.317627
exploration/Returns Mean          -12.8258
exploration/Returns Std             0.0843765
exploration/Returns Max           -12.7415
exploration/Returns Min           -12.9102
exploration/Actions Mean            0.00186457
exploration/Actions Std             0.150733
exploration/Actions Max             0.92111
exploration/Actions Min            -0.626647
exploration/Num Paths               2
exploration/Average Returns       -12.8258
evaluation/num steps total     188500
evaluation/num paths total       1885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0551763
evaluation/Rewards Std              0.0548251
evaluation/Rewards Max             -0.0443907
evaluation/Rewards Min             -0.988181
evaluation/Returns Mean            -5.51763
evaluation/Returns Std              0.368238
evaluation/Returns Max             -5.12927
evaluation/Returns Min             -6.03956
evaluation/Actions Mean             0.00348567
evaluation/Actions Std              0.0770311
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.891704
evaluation/Num Paths                5
evaluation/Average Returns         -5.51763
time/data storing (s)               0.00116267
time/evaluation sampling (s)        0.0725512
time/exploration sampling (s)       0.0353291
time/logging (s)                    0.00245665
time/saving (s)                     0.00244207
time/training (s)                   0.405722
time/epoch (s)                      0.519664
time/total (s)                    223.423
Epoch                             376
-----------------------------  ----------------
2019-04-13 17:02:18.716257 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 377 finished
-----------------------------  ----------------
replay_buffer/size              75700
trainer/QF1 Loss                    0.0525092
trainer/QF2 Loss                    0.0558358
trainer/Policy Loss                12.7156
trainer/Q1 Predictions Mean       -12.8242
trainer/Q1 Predictions Std          0.166949
trainer/Q1 Predictions Max        -12.6508
trainer/Q1 Predictions Min        -13.5308
trainer/Q2 Predictions Mean       -12.8058
trainer/Q2 Predictions Std          0.173805
trainer/Q2 Predictions Max        -12.6631
trainer/Q2 Predictions Min        -13.5493
trainer/Q Targets Mean            -12.8374
trainer/Q Targets Std               0.219031
trainer/Q Targets Max             -12.4852
trainer/Q Targets Min             -13.362
trainer/Bellman Errors 1 Mean       0.0525092
trainer/Bellman Errors 1 Std        0.0838736
trainer/Bellman Errors 1 Max        0.415427
trainer/Bellman Errors 1 Min        2.11385e-05
trainer/Bellman Errors 2 Mean       0.0558358
trainer/Bellman Errors 2 Std        0.0863634
trainer/Bellman Errors 2 Max        0.399647
trainer/Bellman Errors 2 Min        4.13016e-06
trainer/Policy Action Mean         -0.0273255
trainer/Policy Action Std           0.168358
trainer/Policy Action Max           0.826222
trainer/Policy Action Min          -0.484152
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137291
exploration/Rewards Std             0.0726385
exploration/Rewards Max            -0.00509058
exploration/Rewards Min            -0.552848
exploration/Returns Mean          -13.7291
exploration/Returns Std             1.01305
exploration/Returns Max           -12.716
exploration/Returns Min           -14.7421
exploration/Actions Mean            0.00427913
exploration/Actions Std             0.157965
exploration/Actions Max             1
exploration/Actions Min            -0.346101
exploration/Num Paths               2
exploration/Average Returns       -13.7291
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0411258
evaluation/Rewards Std              0.045075
evaluation/Rewards Max             -0.0343385
evaluation/Rewards Min             -0.919515
evaluation/Returns Mean            -4.11258
evaluation/Returns Std              0.311829
evaluation/Returns Max             -3.79406
evaluation/Returns Min             -4.66229
evaluation/Actions Mean             0.00522987
evaluation/Actions Std              0.0837237
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.9925
evaluation/Num Paths                5
evaluation/Average Returns         -4.11258
time/data storing (s)               0.00108666
time/evaluation sampling (s)        0.0723343
time/exploration sampling (s)       0.0328983
time/logging (s)                    0.00247548
time/saving (s)                     0.00232998
time/training (s)                   0.406
time/epoch (s)                      0.517124
time/total (s)                    223.944
Epoch                             377
-----------------------------  ----------------
2019-04-13 17:02:19.246427 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 378 finished
-----------------------------  ----------------
replay_buffer/size              75900
trainer/QF1 Loss                    4.92855
trainer/QF2 Loss                    4.92151
trainer/Policy Loss                12.4616
trainer/Q1 Predictions Mean       -12.6692
trainer/Q1 Predictions Std          0.743074
trainer/Q1 Predictions Max        -12.3919
trainer/Q1 Predictions Min        -16.4699
trainer/Q2 Predictions Mean       -12.6732
trainer/Q2 Predictions Std          0.75433
trainer/Q2 Predictions Max        -12.4149
trainer/Q2 Predictions Min        -16.5606
trainer/Q Targets Mean            -12.5324
trainer/Q Targets Std               2.38933
trainer/Q Targets Max              -0.0768954
trainer/Q Targets Min             -16.9511
trainer/Bellman Errors 1 Mean       4.92855
trainer/Bellman Errors 1 Std       26.8193
trainer/Bellman Errors 1 Max      154.249
trainer/Bellman Errors 1 Min        6.82554e-05
trainer/Bellman Errors 2 Mean       4.92151
trainer/Bellman Errors 2 Std       26.7998
trainer/Bellman Errors 2 Max      154.134
trainer/Bellman Errors 2 Min        7.43089e-05
trainer/Policy Action Mean          0.0285083
trainer/Policy Action Std           0.267193
trainer/Policy Action Max           1
trainer/Policy Action Min          -0.999948
exploration/num steps total     75900
exploration/num paths total       759
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134561
exploration/Rewards Std             0.081228
exploration/Rewards Max            -0.0130452
exploration/Rewards Min            -0.814478
exploration/Returns Mean          -13.4561
exploration/Returns Std             0.537178
exploration/Returns Max           -12.9189
exploration/Returns Min           -13.9932
exploration/Actions Mean            0.00647829
exploration/Actions Std             0.151426
exploration/Actions Max             1
exploration/Actions Min            -0.431508
exploration/Num Paths               2
exploration/Average Returns       -13.4561
evaluation/num steps total     189500
evaluation/num paths total       1895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0414371
evaluation/Rewards Std              0.011871
evaluation/Rewards Max             -0.0280278
evaluation/Rewards Min             -0.225851
evaluation/Returns Mean            -4.14371
evaluation/Returns Std              0.0659697
evaluation/Returns Max             -4.06366
evaluation/Returns Min             -4.22266
evaluation/Actions Mean             0.0018254
evaluation/Actions Std              0.0701295
evaluation/Actions Max              0.998084
evaluation/Actions Min             -0.994528
evaluation/Num Paths                5
evaluation/Average Returns         -4.14371
time/data storing (s)               0.00111889
time/evaluation sampling (s)        0.0728471
time/exploration sampling (s)       0.0330675
time/logging (s)                    0.00252854
time/saving (s)                     0.00229014
time/training (s)                   0.408797
time/epoch (s)                      0.520649
time/total (s)                    224.469
Epoch                             378
-----------------------------  ----------------
2019-04-13 17:02:19.771726 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 379 finished
-----------------------------  ----------------
replay_buffer/size              76100
trainer/QF1 Loss                    0.0508422
trainer/QF2 Loss                    0.0539995
trainer/Policy Loss                12.5876
trainer/Q1 Predictions Mean       -12.6669
trainer/Q1 Predictions Std          0.108088
trainer/Q1 Predictions Max        -12.5452
trainer/Q1 Predictions Min        -13.1363
trainer/Q2 Predictions Mean       -12.6629
trainer/Q2 Predictions Std          0.103858
trainer/Q2 Predictions Max        -12.5604
trainer/Q2 Predictions Min        -13.1131
trainer/Q Targets Mean            -12.7977
trainer/Q Targets Std               0.206038
trainer/Q Targets Max             -12.4591
trainer/Q Targets Min             -13.2954
trainer/Bellman Errors 1 Mean       0.0508422
trainer/Bellman Errors 1 Std        0.0811167
trainer/Bellman Errors 1 Max        0.406017
trainer/Bellman Errors 1 Min        5.58456e-05
trainer/Bellman Errors 2 Mean       0.0539995
trainer/Bellman Errors 2 Std        0.0807738
trainer/Bellman Errors 2 Max        0.386837
trainer/Bellman Errors 2 Min        0.00017023
trainer/Policy Action Mean         -0.0141685
trainer/Policy Action Std           0.117241
trainer/Policy Action Max           0.244916
trainer/Policy Action Min          -0.483695
exploration/num steps total     76100
exploration/num paths total       761
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133624
exploration/Rewards Std             0.0867194
exploration/Rewards Max            -0.0248692
exploration/Rewards Min            -0.992849
exploration/Returns Mean          -13.3624
exploration/Returns Std             0.355043
exploration/Returns Max           -13.0073
exploration/Returns Min           -13.7174
exploration/Actions Mean            0.00290383
exploration/Actions Std             0.162435
exploration/Actions Max             1
exploration/Actions Min            -0.833217
exploration/Num Paths               2
exploration/Average Returns       -13.3624
evaluation/num steps total     190000
evaluation/num paths total       1900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0106852
evaluation/Rewards Std              0.018696
evaluation/Rewards Max             -0.00683471
evaluation/Rewards Min             -0.390438
evaluation/Returns Mean            -1.06852
evaluation/Returns Std              0.139471
evaluation/Returns Max             -0.962169
evaluation/Returns Min             -1.32711
evaluation/Actions Mean             0.00587599
evaluation/Actions Std              0.0741132
evaluation/Actions Max              0.999123
evaluation/Actions Min             -0.593115
evaluation/Num Paths                5
evaluation/Average Returns         -1.06852
time/data storing (s)               0.00106728
time/evaluation sampling (s)        0.0718514
time/exploration sampling (s)       0.0321486
time/logging (s)                    0.0023737
time/saving (s)                     0.00178714
time/training (s)                   0.406546
time/epoch (s)                      0.515774
time/total (s)                    224.989
Epoch                             379
-----------------------------  ----------------
2019-04-13 17:02:20.301118 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 380 finished
-----------------------------  ----------------
replay_buffer/size              76300
trainer/QF1 Loss                    0.0367349
trainer/QF2 Loss                    0.0344273
trainer/Policy Loss                12.5542
trainer/Q1 Predictions Mean       -12.6608
trainer/Q1 Predictions Std          0.0623338
trainer/Q1 Predictions Max        -12.5446
trainer/Q1 Predictions Min        -12.8123
trainer/Q2 Predictions Mean       -12.6751
trainer/Q2 Predictions Std          0.0554799
trainer/Q2 Predictions Max        -12.5948
trainer/Q2 Predictions Min        -12.8308
trainer/Q Targets Mean            -12.7777
trainer/Q Targets Std               0.143445
trainer/Q Targets Max             -12.5138
trainer/Q Targets Min             -13.1276
trainer/Bellman Errors 1 Mean       0.0367349
trainer/Bellman Errors 1 Std        0.0589626
trainer/Bellman Errors 1 Max        0.263028
trainer/Bellman Errors 1 Min        8.17711e-05
trainer/Bellman Errors 2 Mean       0.0344273
trainer/Bellman Errors 2 Std        0.0555598
trainer/Bellman Errors 2 Max        0.228788
trainer/Bellman Errors 2 Min        1.63505e-07
trainer/Policy Action Mean         -0.0134743
trainer/Policy Action Std           0.119044
trainer/Policy Action Max           0.295428
trainer/Policy Action Min          -0.350333
exploration/num steps total     76300
exploration/num paths total       763
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132062
exploration/Rewards Std             0.070679
exploration/Rewards Max            -0.0096258
exploration/Rewards Min            -0.394737
exploration/Returns Mean          -13.2062
exploration/Returns Std             1.64751
exploration/Returns Max           -11.5587
exploration/Returns Min           -14.8537
exploration/Actions Mean            0.00230613
exploration/Actions Std             0.148201
exploration/Actions Max             0.900673
exploration/Actions Min            -0.404838
exploration/Num Paths               2
exploration/Average Returns       -13.2062
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0444781
evaluation/Rewards Std              0.0560875
evaluation/Rewards Max             -0.0375013
evaluation/Rewards Min             -0.940618
evaluation/Returns Mean            -4.44781
evaluation/Returns Std              0.236369
evaluation/Returns Max             -4.11197
evaluation/Returns Min             -4.84017
evaluation/Actions Mean             0.00692368
evaluation/Actions Std              0.0946752
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.980614
evaluation/Num Paths                5
evaluation/Average Returns         -4.44781
time/data storing (s)               0.00106676
time/evaluation sampling (s)        0.0725347
time/exploration sampling (s)       0.0339372
time/logging (s)                    0.00244335
time/saving (s)                     0.00225719
time/training (s)                   0.407657
time/epoch (s)                      0.519896
time/total (s)                    225.513
Epoch                             380
-----------------------------  ----------------
2019-04-13 17:02:20.943016 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 381 finished
-----------------------------  ----------------
replay_buffer/size              76500
trainer/QF1 Loss                    0.0310779
trainer/QF2 Loss                    0.0265342
trainer/Policy Loss                12.5612
trainer/Q1 Predictions Mean       -12.6933
trainer/Q1 Predictions Std          0.094207
trainer/Q1 Predictions Max        -12.5484
trainer/Q1 Predictions Min        -12.9762
trainer/Q2 Predictions Mean       -12.7051
trainer/Q2 Predictions Std          0.101937
trainer/Q2 Predictions Max        -12.5613
trainer/Q2 Predictions Min        -13.0766
trainer/Q Targets Mean            -12.7648
trainer/Q Targets Std               0.205368
trainer/Q Targets Max             -12.4919
trainer/Q Targets Min             -13.4222
trainer/Bellman Errors 1 Mean       0.0310779
trainer/Bellman Errors 1 Std        0.0468495
trainer/Bellman Errors 1 Max        0.198915
trainer/Bellman Errors 1 Min        3.78495e-06
trainer/Bellman Errors 2 Mean       0.0265342
trainer/Bellman Errors 2 Std        0.0369109
trainer/Bellman Errors 2 Max        0.154067
trainer/Bellman Errors 2 Min        0.000146323
trainer/Policy Action Mean          0.0331269
trainer/Policy Action Std           0.20175
trainer/Policy Action Max           0.999886
trainer/Policy Action Min          -0.883192
exploration/num steps total     76500
exploration/num paths total       765
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.13506
exploration/Rewards Std             0.0730818
exploration/Rewards Max            -0.0105366
exploration/Rewards Min            -0.379696
exploration/Returns Mean          -13.506
exploration/Returns Std             0.148542
exploration/Returns Max           -13.3575
exploration/Returns Min           -13.6546
exploration/Actions Mean            0.00557132
exploration/Actions Std             0.142464
exploration/Actions Max             0.905317
exploration/Actions Min            -0.415513
exploration/Num Paths               2
exploration/Average Returns       -13.506
evaluation/num steps total     191000
evaluation/num paths total       1910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0567991
evaluation/Rewards Std              0.0252098
evaluation/Rewards Max             -0.0442883
evaluation/Rewards Min             -0.51205
evaluation/Returns Mean            -5.67991
evaluation/Returns Std              0.172988
evaluation/Returns Max             -5.49337
evaluation/Returns Min             -5.94561
evaluation/Actions Mean             0.00472668
evaluation/Actions Std              0.0726937
evaluation/Actions Max              0.999767
evaluation/Actions Min             -0.837003
evaluation/Num Paths                5
evaluation/Average Returns         -5.67991
time/data storing (s)               0.00118244
time/evaluation sampling (s)        0.076807
time/exploration sampling (s)       0.0377725
time/logging (s)                    0.00381377
time/saving (s)                     0.00350125
time/training (s)                   0.511366
time/epoch (s)                      0.634443
time/total (s)                    226.153
Epoch                             381
-----------------------------  ----------------
2019-04-13 17:02:22.051619 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 382 finished
-----------------------------  ----------------
replay_buffer/size              76700
trainer/QF1 Loss                    0.0147141
trainer/QF2 Loss                    0.0146889
trainer/Policy Loss                12.7043
trainer/Q1 Predictions Mean       -12.8281
trainer/Q1 Predictions Std          0.179638
trainer/Q1 Predictions Max        -12.6825
trainer/Q1 Predictions Min        -13.5048
trainer/Q2 Predictions Mean       -12.8326
trainer/Q2 Predictions Std          0.179005
trainer/Q2 Predictions Max        -12.6975
trainer/Q2 Predictions Min        -13.4881
trainer/Q Targets Mean            -12.8203
trainer/Q Targets Std               0.195687
trainer/Q Targets Max             -12.5649
trainer/Q Targets Min             -13.3458
trainer/Bellman Errors 1 Mean       0.0147141
trainer/Bellman Errors 1 Std        0.0158754
trainer/Bellman Errors 1 Max        0.0610998
trainer/Bellman Errors 1 Min        9.38831e-07
trainer/Bellman Errors 2 Mean       0.0146889
trainer/Bellman Errors 2 Std        0.0171331
trainer/Bellman Errors 2 Max        0.062328
trainer/Bellman Errors 2 Min        3.58804e-05
trainer/Policy Action Mean         -0.0373105
trainer/Policy Action Std           0.163934
trainer/Policy Action Max           0.417156
trainer/Policy Action Min          -0.589782
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12687
exploration/Rewards Std             0.0713302
exploration/Rewards Max            -0.00991248
exploration/Rewards Min            -0.3882
exploration/Returns Mean          -12.687
exploration/Returns Std             0.968562
exploration/Returns Max           -11.7184
exploration/Returns Min           -13.6556
exploration/Actions Mean            0.000758244
exploration/Actions Std             0.15438
exploration/Actions Max             0.599202
exploration/Actions Min            -0.795191
exploration/Num Paths               2
exploration/Average Returns       -12.687
evaluation/num steps total     191500
evaluation/num paths total       1915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0281943
evaluation/Rewards Std              0.0404152
evaluation/Rewards Max             -0.0164293
evaluation/Rewards Min             -0.806175
evaluation/Returns Mean            -2.81943
evaluation/Returns Std              0.298041
evaluation/Returns Max             -2.53273
evaluation/Returns Min             -3.32868
evaluation/Actions Mean             0.00578767
evaluation/Actions Std              0.0803548
evaluation/Actions Max              0.99999
evaluation/Actions Min             -0.958412
evaluation/Num Paths                5
evaluation/Average Returns         -2.81943
time/data storing (s)               0.00613793
time/evaluation sampling (s)        0.166726
time/exploration sampling (s)       0.0873928
time/logging (s)                    0.00881376
time/saving (s)                     0.00656165
time/training (s)                   0.822944
time/epoch (s)                      1.09858
time/total (s)                    227.256
Epoch                             382
-----------------------------  ----------------
2019-04-13 17:02:22.781733 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 383 finished
-----------------------------  ----------------
replay_buffer/size              76900
trainer/QF1 Loss                    9.99122
trainer/QF2 Loss                    9.98505
trainer/Policy Loss                12.6938
trainer/Q1 Predictions Mean       -12.8206
trainer/Q1 Predictions Std          0.179641
trainer/Q1 Predictions Max        -12.6211
trainer/Q1 Predictions Min        -13.6976
trainer/Q2 Predictions Mean       -12.8158
trainer/Q2 Predictions Std          0.172421
trainer/Q2 Predictions Max        -12.6048
trainer/Q2 Predictions Min        -13.6404
trainer/Q Targets Mean            -12.0357
trainer/Q Targets Std               3.08927
trainer/Q Targets Max              -0.0248457
trainer/Q Targets Min             -13.4264
trainer/Bellman Errors 1 Mean       9.99122
trainer/Bellman Errors 1 Std       38.6175
trainer/Bellman Errors 1 Max      161.084
trainer/Bellman Errors 1 Min        1.30641e-05
trainer/Bellman Errors 2 Mean       9.98506
trainer/Bellman Errors 2 Std       38.5951
trainer/Bellman Errors 2 Max      161.229
trainer/Bellman Errors 2 Min        2.02459e-06
trainer/Policy Action Mean          0.0465663
trainer/Policy Action Std           0.168322
trainer/Policy Action Max           0.999997
trainer/Policy Action Min          -0.255304
exploration/num steps total     76900
exploration/num paths total       769
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.149689
exploration/Rewards Std             0.0809882
exploration/Rewards Max            -0.0102898
exploration/Rewards Min            -0.623123
exploration/Returns Mean          -14.9689
exploration/Returns Std             0.615455
exploration/Returns Max           -14.3534
exploration/Returns Min           -15.5843
exploration/Actions Mean            0.00593048
exploration/Actions Std             0.174748
exploration/Actions Max             1
exploration/Actions Min            -0.47455
exploration/Num Paths               2
exploration/Average Returns       -14.9689
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0623014
evaluation/Rewards Std              0.0233146
evaluation/Rewards Max             -0.0271617
evaluation/Rewards Min             -0.556915
evaluation/Returns Mean            -6.23014
evaluation/Returns Std              0.195463
evaluation/Returns Max             -6.06059
evaluation/Returns Min             -6.60267
evaluation/Actions Mean             0.00427297
evaluation/Actions Std              0.0723195
evaluation/Actions Max              0.999968
evaluation/Actions Min             -0.733464
evaluation/Num Paths                5
evaluation/Average Returns         -6.23014
time/data storing (s)               0.00159718
time/evaluation sampling (s)        0.174764
time/exploration sampling (s)       0.111743
time/logging (s)                    0.00247622
time/saving (s)                     0.00228733
time/training (s)                   0.413979
time/epoch (s)                      0.706847
time/total (s)                    227.972
Epoch                             383
-----------------------------  ----------------
2019-04-13 17:02:23.435718 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 384 finished
-----------------------------  ---------------
replay_buffer/size              77100
trainer/QF1 Loss                    9.60869
trainer/QF2 Loss                    9.6456
trainer/Policy Loss                12.2984
trainer/Q1 Predictions Mean       -12.4665
trainer/Q1 Predictions Std          0.0730428
trainer/Q1 Predictions Max        -12.3551
trainer/Q1 Predictions Min        -12.6912
trainer/Q2 Predictions Mean       -12.4675
trainer/Q2 Predictions Std          0.0637561
trainer/Q2 Predictions Max        -12.3601
trainer/Q2 Predictions Min        -12.6628
trainer/Q Targets Mean            -12.0453
trainer/Q Targets Std               3.08806
trainer/Q Targets Max              -0.0929247
trainer/Q Targets Min             -13.1075
trainer/Bellman Errors 1 Mean       9.60869
trainer/Bellman Errors 1 Std       36.619
trainer/Bellman Errors 1 Max      151.661
trainer/Bellman Errors 1 Min        0.0299232
trainer/Bellman Errors 2 Mean       9.6456
trainer/Bellman Errors 2 Std       36.7601
trainer/Bellman Errors 2 Max      152.055
trainer/Bellman Errors 2 Min        0.0227742
trainer/Policy Action Mean          0.00878361
trainer/Policy Action Std           0.100697
trainer/Policy Action Max           0.215699
trainer/Policy Action Min          -0.279319
exploration/num steps total     77100
exploration/num paths total       771
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126031
exploration/Rewards Std             0.0728986
exploration/Rewards Max            -0.0197384
exploration/Rewards Min            -0.532145
exploration/Returns Mean          -12.6031
exploration/Returns Std             0.047313
exploration/Returns Max           -12.5558
exploration/Returns Min           -12.6504
exploration/Actions Mean            0.00501639
exploration/Actions Std             0.167363
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.6031
evaluation/num steps total     192500
evaluation/num paths total       1925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0247303
evaluation/Rewards Std              0.0399463
evaluation/Rewards Max             -0.00316969
evaluation/Rewards Min             -0.890387
evaluation/Returns Mean            -2.47303
evaluation/Returns Std              0.320101
evaluation/Returns Max             -2.2526
evaluation/Returns Min             -3.09853
evaluation/Actions Mean             0.00225048
evaluation/Actions Std              0.0730393
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.954436
evaluation/Num Paths                5
evaluation/Average Returns         -2.47303
time/data storing (s)               0.00111994
time/evaluation sampling (s)        0.0961074
time/exploration sampling (s)       0.0355504
time/logging (s)                    0.0024869
time/saving (s)                     0.00218719
time/training (s)                   0.506771
time/epoch (s)                      0.644223
time/total (s)                    228.621
Epoch                             384
-----------------------------  ---------------
2019-04-13 17:02:24.073423 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 385 finished
-----------------------------  ----------------
replay_buffer/size              77300
trainer/QF1 Loss                    4.9259
trainer/QF2 Loss                    4.91761
trainer/Policy Loss                12.522
trainer/Q1 Predictions Mean       -12.6155
trainer/Q1 Predictions Std          0.076151
trainer/Q1 Predictions Max        -12.5031
trainer/Q1 Predictions Min        -12.7437
trainer/Q2 Predictions Mean       -12.5953
trainer/Q2 Predictions Std          0.0677806
trainer/Q2 Predictions Max        -12.4993
trainer/Q2 Predictions Min        -12.7401
trainer/Q Targets Mean            -12.4246
trainer/Q Targets Std               2.21278
trainer/Q Targets Max              -0.163338
trainer/Q Targets Min             -13.358
trainer/Bellman Errors 1 Mean       4.9259
trainer/Bellman Errors 1 Std       26.9951
trainer/Bellman Errors 1 Max      155.227
trainer/Bellman Errors 1 Min        0.000222244
trainer/Bellman Errors 2 Mean       4.91761
trainer/Bellman Errors 2 Std       26.9046
trainer/Bellman Errors 2 Max      154.714
trainer/Bellman Errors 2 Min        2.96533e-05
trainer/Policy Action Mean          0.00500267
trainer/Policy Action Std           0.104791
trainer/Policy Action Max           0.276116
trainer/Policy Action Min          -0.24779
exploration/num steps total     77300
exploration/num paths total       773
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126854
exploration/Rewards Std             0.0707022
exploration/Rewards Max            -0.0109555
exploration/Rewards Min            -0.415676
exploration/Returns Mean          -12.6854
exploration/Returns Std             0.247567
exploration/Returns Max           -12.4378
exploration/Returns Min           -12.9329
exploration/Actions Mean            0.00796927
exploration/Actions Std             0.163879
exploration/Actions Max             1
exploration/Actions Min            -0.366789
exploration/Num Paths               2
exploration/Average Returns       -12.6854
evaluation/num steps total     193000
evaluation/num paths total       1930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0212943
evaluation/Rewards Std              0.047495
evaluation/Rewards Max             -0.0110576
evaluation/Rewards Min             -0.698279
evaluation/Returns Mean            -2.12943
evaluation/Returns Std              0.296702
evaluation/Returns Max             -1.75187
evaluation/Returns Min             -2.44259
evaluation/Actions Mean             0.0048823
evaluation/Actions Std              0.0792599
evaluation/Actions Max              0.999992
evaluation/Actions Min             -0.950066
evaluation/Num Paths                5
evaluation/Average Returns         -2.12943
time/data storing (s)               0.0011152
time/evaluation sampling (s)        0.0793244
time/exploration sampling (s)       0.0351434
time/logging (s)                    0.00255133
time/saving (s)                     0.00224818
time/training (s)                   0.507831
time/epoch (s)                      0.628214
time/total (s)                    229.253
Epoch                             385
-----------------------------  ----------------
2019-04-13 17:02:24.651369 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 386 finished
-----------------------------  ---------------
replay_buffer/size              77500
trainer/QF1 Loss                    0.161332
trainer/QF2 Loss                    0.15918
trainer/Policy Loss                12.4461
trainer/Q1 Predictions Mean       -12.4764
trainer/Q1 Predictions Std          0.162254
trainer/Q1 Predictions Max        -12.3457
trainer/Q1 Predictions Min        -13.2011
trainer/Q2 Predictions Mean       -12.4795
trainer/Q2 Predictions Std          0.148772
trainer/Q2 Predictions Max        -12.3612
trainer/Q2 Predictions Min        -13.1388
trainer/Q Targets Mean            -12.8478
trainer/Q Targets Std               0.2064
trainer/Q Targets Max             -12.5214
trainer/Q Targets Min             -13.5497
trainer/Bellman Errors 1 Mean       0.161332
trainer/Bellman Errors 1 Std        0.119796
trainer/Bellman Errors 1 Max        0.416783
trainer/Bellman Errors 1 Min        0.007283
trainer/Bellman Errors 2 Mean       0.15918
trainer/Bellman Errors 2 Std        0.121883
trainer/Bellman Errors 2 Max        0.453859
trainer/Bellman Errors 2 Min        0.0169902
trainer/Policy Action Mean         -0.00822854
trainer/Policy Action Std           0.13445
trainer/Policy Action Max           0.416997
trainer/Policy Action Min          -0.532803
exploration/num steps total     77500
exploration/num paths total       775
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124446
exploration/Rewards Std             0.0652062
exploration/Rewards Max            -0.0054021
exploration/Rewards Min            -0.375114
exploration/Returns Mean          -12.4446
exploration/Returns Std             0.513951
exploration/Returns Max           -11.9307
exploration/Returns Min           -12.9586
exploration/Actions Mean            0.0061806
exploration/Actions Std             0.161848
exploration/Actions Max             1
exploration/Actions Min            -0.731448
exploration/Num Paths               2
exploration/Average Returns       -12.4446
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0256684
evaluation/Rewards Std              0.039885
evaluation/Rewards Max             -0.00929972
evaluation/Rewards Min             -0.910127
evaluation/Returns Mean            -2.56684
evaluation/Returns Std              0.381262
evaluation/Returns Max             -2.35569
evaluation/Returns Min             -3.3283
evaluation/Actions Mean             0.00294386
evaluation/Actions Std              0.0608953
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.708787
evaluation/Num Paths                5
evaluation/Average Returns         -2.56684
time/data storing (s)               0.00105402
time/evaluation sampling (s)        0.0749312
time/exploration sampling (s)       0.0323796
time/logging (s)                    0.00246633
time/saving (s)                     0.00230266
time/training (s)                   0.454941
time/epoch (s)                      0.568075
time/total (s)                    229.826
Epoch                             386
-----------------------------  ---------------
2019-04-13 17:02:25.239362 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 387 finished
-----------------------------  ----------------
replay_buffer/size              77700
trainer/QF1 Loss                    5.01066
trainer/QF2 Loss                    5.01518
trainer/Policy Loss                12.7551
trainer/Q1 Predictions Mean       -12.9965
trainer/Q1 Predictions Std          0.956917
trainer/Q1 Predictions Max        -12.6479
trainer/Q1 Predictions Min        -17.6169
trainer/Q2 Predictions Mean       -12.9928
trainer/Q2 Predictions Std          0.942623
trainer/Q2 Predictions Max        -12.6554
trainer/Q2 Predictions Min        -17.5537
trainer/Q Targets Mean            -12.6489
trainer/Q Targets Std               2.498
trainer/Q Targets Max              -0.022768
trainer/Q Targets Min             -18.1702
trainer/Bellman Errors 1 Mean       5.01066
trainer/Bellman Errors 1 Std       27.757
trainer/Bellman Errors 1 Max      159.555
trainer/Bellman Errors 1 Min        4.41841e-07
trainer/Bellman Errors 2 Mean       5.01518
trainer/Bellman Errors 2 Std       27.7615
trainer/Bellman Errors 2 Max      159.584
trainer/Bellman Errors 2 Min        1.79026e-06
trainer/Policy Action Mean          0.0433691
trainer/Policy Action Std           0.292722
trainer/Policy Action Max           1
trainer/Policy Action Min          -0.999996
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136925
exploration/Rewards Std             0.0908
exploration/Rewards Max            -0.00629652
exploration/Rewards Min            -0.950254
exploration/Returns Mean          -13.6925
exploration/Returns Std             0.348221
exploration/Returns Max           -13.3442
exploration/Returns Min           -14.0407
exploration/Actions Mean            0.00510616
exploration/Actions Std             0.172283
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.6925
evaluation/num steps total     194000
evaluation/num paths total       1940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0414643
evaluation/Rewards Std              0.022101
evaluation/Rewards Max             -0.0203042
evaluation/Rewards Min             -0.520191
evaluation/Returns Mean            -4.14643
evaluation/Returns Std              0.188137
evaluation/Returns Max             -4.00255
evaluation/Returns Min             -4.51125
evaluation/Actions Mean             0.00511747
evaluation/Actions Std              0.0701386
evaluation/Actions Max              0.999813
evaluation/Actions Min             -0.48728
evaluation/Num Paths                5
evaluation/Average Returns         -4.14643
time/data storing (s)               0.00105336
time/evaluation sampling (s)        0.0705758
time/exploration sampling (s)       0.032212
time/logging (s)                    0.00256811
time/saving (s)                     0.00225224
time/training (s)                   0.469771
time/epoch (s)                      0.578433
time/total (s)                    230.408
Epoch                             387
-----------------------------  ----------------
2019-04-13 17:02:25.816022 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 388 finished
-----------------------------  ----------------
replay_buffer/size              77900
trainer/QF1 Loss                    0.0242199
trainer/QF2 Loss                    0.0266506
trainer/Policy Loss                12.7442
trainer/Q1 Predictions Mean       -12.9024
trainer/Q1 Predictions Std          0.462803
trainer/Q1 Predictions Max        -12.6894
trainer/Q1 Predictions Min        -15.4289
trainer/Q2 Predictions Mean       -12.91
trainer/Q2 Predictions Std          0.484386
trainer/Q2 Predictions Max        -12.6905
trainer/Q2 Predictions Min        -15.5557
trainer/Q Targets Mean            -12.8669
trainer/Q Targets Std               0.4661
trainer/Q Targets Max             -12.4627
trainer/Q Targets Min             -15.2611
trainer/Bellman Errors 1 Mean       0.0242199
trainer/Bellman Errors 1 Std        0.0218916
trainer/Bellman Errors 1 Max        0.0689813
trainer/Bellman Errors 1 Min        0.000225955
trainer/Bellman Errors 2 Mean       0.0266506
trainer/Bellman Errors 2 Std        0.0236497
trainer/Bellman Errors 2 Max        0.086772
trainer/Bellman Errors 2 Min        0.00033955
trainer/Policy Action Mean          0.0252501
trainer/Policy Action Std           0.158374
trainer/Policy Action Max           0.99964
trainer/Policy Action Min          -0.240482
exploration/num steps total     77900
exploration/num paths total       779
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124493
exploration/Rewards Std             0.0661489
exploration/Rewards Max            -0.00631794
exploration/Rewards Min            -0.358087
exploration/Returns Mean          -12.4493
exploration/Returns Std             0.555092
exploration/Returns Max           -11.8942
exploration/Returns Min           -13.0044
exploration/Actions Mean            0.00771719
exploration/Actions Std             0.155613
exploration/Actions Max             0.777866
exploration/Actions Min            -0.369736
exploration/Num Paths               2
exploration/Average Returns       -12.4493
evaluation/num steps total     194500
evaluation/num paths total       1945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0155022
evaluation/Rewards Std              0.0225536
evaluation/Rewards Max             -0.0116173
evaluation/Rewards Min             -0.306333
evaluation/Returns Mean            -1.55022
evaluation/Returns Std              0.123067
evaluation/Returns Max             -1.37506
evaluation/Returns Min             -1.661
evaluation/Actions Mean             0.00359713
evaluation/Actions Std              0.0822948
evaluation/Actions Max              0.999384
evaluation/Actions Min             -0.998871
evaluation/Num Paths                5
evaluation/Average Returns         -1.55022
time/data storing (s)               0.00106757
time/evaluation sampling (s)        0.0728414
time/exploration sampling (s)       0.0325409
time/logging (s)                    0.0026427
time/saving (s)                     0.0022884
time/training (s)                   0.455686
time/epoch (s)                      0.567067
time/total (s)                    230.979
Epoch                             388
-----------------------------  ----------------
2019-04-13 17:02:26.397443 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 389 finished
-----------------------------  ----------------
replay_buffer/size              78100
trainer/QF1 Loss                    0.0555962
trainer/QF2 Loss                    0.0518873
trainer/Policy Loss                12.5563
trainer/Q1 Predictions Mean       -12.6023
trainer/Q1 Predictions Std          0.119809
trainer/Q1 Predictions Max        -12.4912
trainer/Q1 Predictions Min        -13.1064
trainer/Q2 Predictions Mean       -12.6091
trainer/Q2 Predictions Std          0.108049
trainer/Q2 Predictions Max        -12.4539
trainer/Q2 Predictions Min        -13.0276
trainer/Q Targets Mean            -12.7986
trainer/Q Targets Std               0.153259
trainer/Q Targets Max             -12.5576
trainer/Q Targets Min             -13.1451
trainer/Bellman Errors 1 Mean       0.0555962
trainer/Bellman Errors 1 Std        0.0542889
trainer/Bellman Errors 1 Max        0.210918
trainer/Bellman Errors 1 Min        1.82359e-06
trainer/Bellman Errors 2 Mean       0.0518873
trainer/Bellman Errors 2 Std        0.0499021
trainer/Bellman Errors 2 Max        0.190097
trainer/Bellman Errors 2 Min        1.26198e-05
trainer/Policy Action Mean         -0.015768
trainer/Policy Action Std           0.16091
trainer/Policy Action Max           0.998
trainer/Policy Action Min          -0.260513
exploration/num steps total     78100
exploration/num paths total       781
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.141578
exploration/Rewards Std             0.0989762
exploration/Rewards Max            -0.0125547
exploration/Rewards Min            -1.0202
exploration/Returns Mean          -14.1578
exploration/Returns Std             0.248572
exploration/Returns Max           -13.9092
exploration/Returns Min           -14.4063
exploration/Actions Mean            0.00910319
exploration/Actions Std             0.164332
exploration/Actions Max             1
exploration/Actions Min            -0.579301
exploration/Num Paths               2
exploration/Average Returns       -14.1578
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0531914
evaluation/Rewards Std              0.0344628
evaluation/Rewards Max             -0.0298122
evaluation/Rewards Min             -0.650675
evaluation/Returns Mean            -5.31914
evaluation/Returns Std              0.258181
evaluation/Returns Max             -5.03461
evaluation/Returns Min             -5.69924
evaluation/Actions Mean             0.0045736
evaluation/Actions Std              0.0740381
evaluation/Actions Max              0.999984
evaluation/Actions Min             -0.98699
evaluation/Num Paths                5
evaluation/Average Returns         -5.31914
time/data storing (s)               0.00116299
time/evaluation sampling (s)        0.0733128
time/exploration sampling (s)       0.0340504
time/logging (s)                    0.00189614
time/saving (s)                     0.00221918
time/training (s)                   0.458671
time/epoch (s)                      0.571312
time/total (s)                    231.555
Epoch                             389
-----------------------------  ----------------
2019-04-13 17:02:26.981812 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 390 finished
-----------------------------  ----------------
replay_buffer/size              78300
trainer/QF1 Loss                    0.0680394
trainer/QF2 Loss                    0.0661272
trainer/Policy Loss                12.4151
trainer/Q1 Predictions Mean       -12.6113
trainer/Q1 Predictions Std          0.190146
trainer/Q1 Predictions Max        -12.4818
trainer/Q1 Predictions Min        -13.583
trainer/Q2 Predictions Mean       -12.6133
trainer/Q2 Predictions Std          0.183447
trainer/Q2 Predictions Max        -12.4897
trainer/Q2 Predictions Min        -13.5513
trainer/Q Targets Mean            -12.8142
trainer/Q Targets Std               0.223132
trainer/Q Targets Max             -12.5712
trainer/Q Targets Min             -13.6892
trainer/Bellman Errors 1 Mean       0.0680394
trainer/Bellman Errors 1 Std        0.101852
trainer/Bellman Errors 1 Max        0.463746
trainer/Bellman Errors 1 Min        0.00032289
trainer/Bellman Errors 2 Mean       0.0661272
trainer/Bellman Errors 2 Std        0.0984372
trainer/Bellman Errors 2 Max        0.45672
trainer/Bellman Errors 2 Min        0.00121706
trainer/Policy Action Mean          0.0426038
trainer/Policy Action Std           0.122775
trainer/Policy Action Max           0.510171
trainer/Policy Action Min          -0.497374
exploration/num steps total     78300
exploration/num paths total       783
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.145675
exploration/Rewards Std             0.0784255
exploration/Rewards Max            -0.0121112
exploration/Rewards Min            -0.502827
exploration/Returns Mean          -14.5675
exploration/Returns Std             0.637818
exploration/Returns Max           -13.9297
exploration/Returns Min           -15.2053
exploration/Actions Mean            0.000944676
exploration/Actions Std             0.164143
exploration/Actions Max             0.963739
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.5675
evaluation/num steps total     195500
evaluation/num paths total       1955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0900275
evaluation/Rewards Std              0.0471508
evaluation/Rewards Max             -0.0740871
evaluation/Rewards Min             -0.981526
evaluation/Returns Mean            -9.00275
evaluation/Returns Std              0.346354
evaluation/Returns Max             -8.63621
evaluation/Returns Min             -9.59779
evaluation/Actions Mean             0.0103678
evaluation/Actions Std              0.0920705
evaluation/Actions Max              1
evaluation/Actions Min             -0.0341634
evaluation/Num Paths                5
evaluation/Average Returns         -9.00275
time/data storing (s)               0.00112491
time/evaluation sampling (s)        0.0720833
time/exploration sampling (s)       0.0320786
time/logging (s)                    0.00205123
time/saving (s)                     0.00225493
time/training (s)                   0.466342
time/epoch (s)                      0.575935
time/total (s)                    232.134
Epoch                             390
-----------------------------  ----------------
2019-04-13 17:02:27.587839 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 391 finished
-----------------------------  ----------------
replay_buffer/size              78500
trainer/QF1 Loss                    0.16539
trainer/QF2 Loss                    0.15749
trainer/Policy Loss                12.422
trainer/Q1 Predictions Mean       -12.524
trainer/Q1 Predictions Std          0.166937
trainer/Q1 Predictions Max        -12.3529
trainer/Q1 Predictions Min        -13.174
trainer/Q2 Predictions Mean       -12.5343
trainer/Q2 Predictions Std          0.16154
trainer/Q2 Predictions Max        -12.3753
trainer/Q2 Predictions Min        -13.1488
trainer/Q Targets Mean            -12.9097
trainer/Q Targets Std               0.209268
trainer/Q Targets Max             -12.514
trainer/Q Targets Min             -13.5105
trainer/Bellman Errors 1 Mean       0.16539
trainer/Bellman Errors 1 Std        0.108923
trainer/Bellman Errors 1 Max        0.456001
trainer/Bellman Errors 1 Min        0.0214842
trainer/Bellman Errors 2 Mean       0.15749
trainer/Bellman Errors 2 Std        0.10495
trainer/Bellman Errors 2 Max        0.446279
trainer/Bellman Errors 2 Min        0.0166156
trainer/Policy Action Mean          0.00554408
trainer/Policy Action Std           0.15914
trainer/Policy Action Max           0.356355
trainer/Policy Action Min          -0.481121
exploration/num steps total     78500
exploration/num paths total       785
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138991
exploration/Rewards Std             0.071673
exploration/Rewards Max            -0.00959113
exploration/Rewards Min            -0.485634
exploration/Returns Mean          -13.8991
exploration/Returns Std             0.226093
exploration/Returns Max           -13.673
exploration/Returns Min           -14.1252
exploration/Actions Mean           -0.000407435
exploration/Actions Std             0.150894
exploration/Actions Max             0.807617
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.8991
evaluation/num steps total     196000
evaluation/num paths total       1960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0553063
evaluation/Rewards Std              0.0442186
evaluation/Rewards Max             -0.0285222
evaluation/Rewards Min             -0.866103
evaluation/Returns Mean            -5.53063
evaluation/Returns Std              0.304843
evaluation/Returns Max             -5.20165
evaluation/Returns Min             -6.03515
evaluation/Actions Mean             0.00580172
evaluation/Actions Std              0.0839421
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.752349
evaluation/Num Paths                5
evaluation/Average Returns         -5.53063
time/data storing (s)               0.00115246
time/evaluation sampling (s)        0.0867067
time/exploration sampling (s)       0.0372521
time/logging (s)                    0.00248224
time/saving (s)                     0.00226502
time/training (s)                   0.467863
time/epoch (s)                      0.597722
time/total (s)                    232.736
Epoch                             391
-----------------------------  ----------------
2019-04-13 17:02:28.165152 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 392 finished
-----------------------------  ----------------
replay_buffer/size              78700
trainer/QF1 Loss                    0.125114
trainer/QF2 Loss                    0.130389
trainer/Policy Loss                12.4931
trainer/Q1 Predictions Mean       -12.5527
trainer/Q1 Predictions Std          0.166687
trainer/Q1 Predictions Max        -12.4073
trainer/Q1 Predictions Min        -13.3892
trainer/Q2 Predictions Mean       -12.5468
trainer/Q2 Predictions Std          0.164126
trainer/Q2 Predictions Max        -12.411
trainer/Q2 Predictions Min        -13.3697
trainer/Q Targets Mean            -12.8748
trainer/Q Targets Std               0.205229
trainer/Q Targets Max             -12.5115
trainer/Q Targets Min             -13.609
trainer/Bellman Errors 1 Mean       0.125114
trainer/Bellman Errors 1 Std        0.105879
trainer/Bellman Errors 1 Max        0.419754
trainer/Bellman Errors 1 Min        2.56829e-05
trainer/Bellman Errors 2 Mean       0.130389
trainer/Bellman Errors 2 Std        0.112132
trainer/Bellman Errors 2 Max        0.454676
trainer/Bellman Errors 2 Min        6.30524e-06
trainer/Policy Action Mean         -0.0180575
trainer/Policy Action Std           0.194435
trainer/Policy Action Max           0.999998
trainer/Policy Action Min          -0.787997
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127054
exploration/Rewards Std             0.0696665
exploration/Rewards Max            -0.0131484
exploration/Rewards Min            -0.563457
exploration/Returns Mean          -12.7054
exploration/Returns Std             0.142937
exploration/Returns Max           -12.5625
exploration/Returns Min           -12.8483
exploration/Actions Mean            0.0059715
exploration/Actions Std             0.156428
exploration/Actions Max             1
exploration/Actions Min            -0.576091
exploration/Num Paths               2
exploration/Average Returns       -12.7054
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0306647
evaluation/Rewards Std              0.0483301
evaluation/Rewards Max             -0.0103308
evaluation/Rewards Min             -0.987222
evaluation/Returns Mean            -3.06647
evaluation/Returns Std              0.391986
evaluation/Returns Max             -2.72169
evaluation/Returns Min             -3.74872
evaluation/Actions Mean             0.00360385
evaluation/Actions Std              0.0714846
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.714112
evaluation/Num Paths                5
evaluation/Average Returns         -3.06647
time/data storing (s)               0.00113109
time/evaluation sampling (s)        0.0755911
time/exploration sampling (s)       0.03288
time/logging (s)                    0.00247468
time/saving (s)                     0.00240503
time/training (s)                   0.452974
time/epoch (s)                      0.567456
time/total (s)                    233.308
Epoch                             392
-----------------------------  ----------------
2019-04-13 17:02:28.754314 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 393 finished
-----------------------------  ---------------
replay_buffer/size              78900
trainer/QF1 Loss                    0.0686964
trainer/QF2 Loss                    0.0702544
trainer/Policy Loss                12.5923
trainer/Q1 Predictions Mean       -12.7401
trainer/Q1 Predictions Std          0.479015
trainer/Q1 Predictions Max        -12.4858
trainer/Q1 Predictions Min        -15.1185
trainer/Q2 Predictions Mean       -12.735
trainer/Q2 Predictions Std          0.457507
trainer/Q2 Predictions Max        -12.4718
trainer/Q2 Predictions Min        -14.9711
trainer/Q Targets Mean            -12.9507
trainer/Q Targets Std               0.48307
trainer/Q Targets Max             -12.5454
trainer/Q Targets Min             -15.154
trainer/Bellman Errors 1 Mean       0.0686964
trainer/Bellman Errors 1 Std        0.0971848
trainer/Bellman Errors 1 Max        0.521342
trainer/Bellman Errors 1 Min        0.00126191
trainer/Bellman Errors 2 Mean       0.0702544
trainer/Bellman Errors 2 Std        0.0986029
trainer/Bellman Errors 2 Max        0.538591
trainer/Bellman Errors 2 Min        0.00379817
trainer/Policy Action Mean          0.0286284
trainer/Policy Action Std           0.273548
trainer/Policy Action Max           0.999787
trainer/Policy Action Min          -0.527544
exploration/num steps total     78900
exploration/num paths total       789
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12849
exploration/Rewards Std             0.0830866
exploration/Rewards Max            -0.0170705
exploration/Rewards Min            -0.818302
exploration/Returns Mean          -12.849
exploration/Returns Std             0.334541
exploration/Returns Max           -12.5144
exploration/Returns Min           -13.1835
exploration/Actions Mean            0.0086935
exploration/Actions Std             0.157602
exploration/Actions Max             0.892462
exploration/Actions Min            -0.402137
exploration/Num Paths               2
exploration/Average Returns       -12.849
evaluation/num steps total     197000
evaluation/num paths total       1970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0380285
evaluation/Rewards Std              0.0457669
evaluation/Rewards Max             -0.0245986
evaluation/Rewards Min             -0.913985
evaluation/Returns Mean            -3.80285
evaluation/Returns Std              0.304129
evaluation/Returns Max             -3.4952
evaluation/Returns Min             -4.32537
evaluation/Actions Mean             0.00415516
evaluation/Actions Std              0.0790127
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.925948
evaluation/Num Paths                5
evaluation/Average Returns         -3.80285
time/data storing (s)               0.00106929
time/evaluation sampling (s)        0.0766338
time/exploration sampling (s)       0.0324864
time/logging (s)                    0.00249197
time/saving (s)                     0.00221995
time/training (s)                   0.46462
time/epoch (s)                      0.579521
time/total (s)                    233.892
Epoch                             393
-----------------------------  ---------------
2019-04-13 17:02:29.371818 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 394 finished
-----------------------------  ----------------
replay_buffer/size              79100
trainer/QF1 Loss                    0.0419468
trainer/QF2 Loss                    0.0408373
trainer/Policy Loss                12.5823
trainer/Q1 Predictions Mean       -12.7529
trainer/Q1 Predictions Std          0.115087
trainer/Q1 Predictions Max        -12.6338
trainer/Q1 Predictions Min        -13.2401
trainer/Q2 Predictions Mean       -12.7581
trainer/Q2 Predictions Std          0.114883
trainer/Q2 Predictions Max        -12.6425
trainer/Q2 Predictions Min        -13.2498
trainer/Q Targets Mean            -12.884
trainer/Q Targets Std               0.204134
trainer/Q Targets Max             -12.5305
trainer/Q Targets Min             -13.4002
trainer/Bellman Errors 1 Mean       0.0419468
trainer/Bellman Errors 1 Std        0.048501
trainer/Bellman Errors 1 Max        0.178949
trainer/Bellman Errors 1 Min        6.98562e-05
trainer/Bellman Errors 2 Mean       0.0408373
trainer/Bellman Errors 2 Std        0.0472224
trainer/Bellman Errors 2 Max        0.176189
trainer/Bellman Errors 2 Min        0.000146508
trainer/Policy Action Mean          0.0440367
trainer/Policy Action Std           0.130745
trainer/Policy Action Max           0.468838
trainer/Policy Action Min          -0.393316
exploration/num steps total     79100
exploration/num paths total       791
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.151854
exploration/Rewards Std             0.0844331
exploration/Rewards Max            -0.0231992
exploration/Rewards Min            -0.73907
exploration/Returns Mean          -15.1854
exploration/Returns Std             0.568096
exploration/Returns Max           -14.6173
exploration/Returns Min           -15.7535
exploration/Actions Mean            0.00865578
exploration/Actions Std             0.175343
exploration/Actions Max             1
exploration/Actions Min            -0.690647
exploration/Num Paths               2
exploration/Average Returns       -15.1854
evaluation/num steps total     197500
evaluation/num paths total       1975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0681695
evaluation/Rewards Std              0.0466797
evaluation/Rewards Max             -0.0601359
evaluation/Rewards Min             -0.81567
evaluation/Returns Mean            -6.81695
evaluation/Returns Std              0.349199
evaluation/Returns Max             -6.51054
evaluation/Returns Min             -7.25259
evaluation/Actions Mean             0.00902088
evaluation/Actions Std              0.0841212
evaluation/Actions Max              0.999994
evaluation/Actions Min             -0.0232647
evaluation/Num Paths                5
evaluation/Average Returns         -6.81695
time/data storing (s)               0.00121796
time/evaluation sampling (s)        0.0717626
time/exploration sampling (s)       0.0373007
time/logging (s)                    0.00193793
time/saving (s)                     0.00180294
time/training (s)                   0.493115
time/epoch (s)                      0.607137
time/total (s)                    234.503
Epoch                             394
-----------------------------  ----------------
2019-04-13 17:02:29.952008 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 395 finished
-----------------------------  ---------------
replay_buffer/size              79300
trainer/QF1 Loss                    0.118109
trainer/QF2 Loss                    0.119878
trainer/Policy Loss                12.5086
trainer/Q1 Predictions Mean       -12.6054
trainer/Q1 Predictions Std          0.376279
trainer/Q1 Predictions Max        -12.3941
trainer/Q1 Predictions Min        -14.5793
trainer/Q2 Predictions Mean       -12.5994
trainer/Q2 Predictions Std          0.392248
trainer/Q2 Predictions Max        -12.4025
trainer/Q2 Predictions Min        -14.6506
trainer/Q Targets Mean            -12.9104
trainer/Q Targets Std               0.425135
trainer/Q Targets Max             -12.5684
trainer/Q Targets Min             -15.0132
trainer/Bellman Errors 1 Mean       0.118109
trainer/Bellman Errors 1 Std        0.118144
trainer/Bellman Errors 1 Max        0.453308
trainer/Bellman Errors 1 Min        0.00089467
trainer/Bellman Errors 2 Mean       0.119878
trainer/Bellman Errors 2 Std        0.116382
trainer/Bellman Errors 2 Max        0.47284
trainer/Bellman Errors 2 Min        0.00610486
trainer/Policy Action Mean          0.0209381
trainer/Policy Action Std           0.198709
trainer/Policy Action Max           0.999638
trainer/Policy Action Min          -0.470141
exploration/num steps total     79300
exploration/num paths total       793
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126056
exploration/Rewards Std             0.060534
exploration/Rewards Max            -0.00526927
exploration/Rewards Min            -0.317158
exploration/Returns Mean          -12.6056
exploration/Returns Std             0.101613
exploration/Returns Max           -12.504
exploration/Returns Min           -12.7072
exploration/Actions Mean            0.00332196
exploration/Actions Std             0.160161
exploration/Actions Max             1
exploration/Actions Min            -0.782496
exploration/Num Paths               2
exploration/Average Returns       -12.6056
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.00635715
evaluation/Rewards Std              0.0317918
evaluation/Rewards Max             -0.0020548
evaluation/Rewards Min             -0.544232
evaluation/Returns Mean            -0.635715
evaluation/Returns Std              0.209645
evaluation/Returns Max             -0.406422
evaluation/Returns Min             -0.939806
evaluation/Actions Mean             0.00793639
evaluation/Actions Std              0.0794145
evaluation/Actions Max              0.999952
evaluation/Actions Min             -0.0171805
evaluation/Num Paths                5
evaluation/Average Returns         -0.635715
time/data storing (s)               0.00113404
time/evaluation sampling (s)        0.071815
time/exploration sampling (s)       0.0333825
time/logging (s)                    0.00245927
time/saving (s)                     0.0022855
time/training (s)                   0.4599
time/epoch (s)                      0.570976
time/total (s)                    235.078
Epoch                             395
-----------------------------  ---------------
2019-04-13 17:02:30.537292 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 396 finished
-----------------------------  ----------------
replay_buffer/size              79500
trainer/QF1 Loss                    0.0327428
trainer/QF2 Loss                    0.0295299
trainer/Policy Loss                12.6761
trainer/Q1 Predictions Mean       -12.8565
trainer/Q1 Predictions Std          0.493699
trainer/Q1 Predictions Max        -12.6029
trainer/Q1 Predictions Min        -15.5288
trainer/Q2 Predictions Mean       -12.8669
trainer/Q2 Predictions Std          0.51154
trainer/Q2 Predictions Max        -12.6205
trainer/Q2 Predictions Min        -15.6409
trainer/Q Targets Mean            -12.9355
trainer/Q Targets Std               0.58393
trainer/Q Targets Max             -12.5346
trainer/Q Targets Min             -16.0465
trainer/Bellman Errors 1 Mean       0.0327428
trainer/Bellman Errors 1 Std        0.0638913
trainer/Bellman Errors 1 Max        0.268003
trainer/Bellman Errors 1 Min        0.000104986
trainer/Bellman Errors 2 Mean       0.0295299
trainer/Bellman Errors 2 Std        0.0558571
trainer/Bellman Errors 2 Max        0.253267
trainer/Bellman Errors 2 Min        0.000136058
trainer/Policy Action Mean          0.0237953
trainer/Policy Action Std           0.202347
trainer/Policy Action Max           0.999912
trainer/Policy Action Min          -0.190995
exploration/num steps total     79500
exploration/num paths total       795
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129149
exploration/Rewards Std             0.0657073
exploration/Rewards Max            -0.00695664
exploration/Rewards Min            -0.329489
exploration/Returns Mean          -12.9149
exploration/Returns Std             0.357824
exploration/Returns Max           -12.5571
exploration/Returns Min           -13.2727
exploration/Actions Mean            0.00298391
exploration/Actions Std             0.158627
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.9149
evaluation/num steps total     198500
evaluation/num paths total       1985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0347866
evaluation/Rewards Std              0.0352975
evaluation/Rewards Max             -0.0279563
evaluation/Rewards Min             -0.743852
evaluation/Returns Mean            -3.47866
evaluation/Returns Std              0.271254
evaluation/Returns Max             -3.24605
evaluation/Returns Min             -3.98947
evaluation/Actions Mean             0.00272653
evaluation/Actions Std              0.0746084
evaluation/Actions Max              0.999987
evaluation/Actions Min             -0.997769
evaluation/Num Paths                5
evaluation/Average Returns         -3.47866
time/data storing (s)               0.00137281
time/evaluation sampling (s)        0.0722642
time/exploration sampling (s)       0.0328602
time/logging (s)                    0.00246512
time/saving (s)                     0.00226823
time/training (s)                   0.464845
time/epoch (s)                      0.576076
time/total (s)                    235.658
Epoch                             396
-----------------------------  ----------------
2019-04-13 17:02:31.117444 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 397 finished
-----------------------------  ----------------
replay_buffer/size              79700
trainer/QF1 Loss                    0.0159619
trainer/QF2 Loss                    0.0157217
trainer/Policy Loss                12.7552
trainer/Q1 Predictions Mean       -12.8475
trainer/Q1 Predictions Std          0.0730924
trainer/Q1 Predictions Max        -12.7196
trainer/Q1 Predictions Min        -13.0248
trainer/Q2 Predictions Mean       -12.8361
trainer/Q2 Predictions Std          0.0697409
trainer/Q2 Predictions Max        -12.7122
trainer/Q2 Predictions Min        -12.9921
trainer/Q Targets Mean            -12.8588
trainer/Q Targets Std               0.134442
trainer/Q Targets Max             -12.6641
trainer/Q Targets Min             -13.1999
trainer/Bellman Errors 1 Mean       0.0159619
trainer/Bellman Errors 1 Std        0.0222668
trainer/Bellman Errors 1 Max        0.0807782
trainer/Bellman Errors 1 Min        6.97924e-05
trainer/Bellman Errors 2 Mean       0.0157217
trainer/Bellman Errors 2 Std        0.0227925
trainer/Bellman Errors 2 Max        0.087279
trainer/Bellman Errors 2 Min        6.64863e-07
trainer/Policy Action Mean          0.048131
trainer/Policy Action Std           0.104325
trainer/Policy Action Max           0.271888
trainer/Policy Action Min          -0.189736
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.145113
exploration/Rewards Std             0.0738802
exploration/Rewards Max            -0.0105827
exploration/Rewards Min            -0.534619
exploration/Returns Mean          -14.5113
exploration/Returns Std             0.0730944
exploration/Returns Max           -14.4382
exploration/Returns Min           -14.5844
exploration/Actions Mean            0.00622427
exploration/Actions Std             0.165107
exploration/Actions Max             0.999608
exploration/Actions Min            -0.601345
exploration/Num Paths               2
exploration/Average Returns       -14.5113
evaluation/num steps total     199000
evaluation/num paths total       1990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0737937
evaluation/Rewards Std              0.0580179
evaluation/Rewards Max             -0.0151778
evaluation/Rewards Min             -0.968323
evaluation/Returns Mean            -7.37937
evaluation/Returns Std              0.309215
evaluation/Returns Max             -6.92743
evaluation/Returns Min             -7.77312
evaluation/Actions Mean             0.00648172
evaluation/Actions Std              0.0861023
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.9148
evaluation/Num Paths                5
evaluation/Average Returns         -7.37937
time/data storing (s)               0.00109841
time/evaluation sampling (s)        0.0737459
time/exploration sampling (s)       0.0327055
time/logging (s)                    0.00248015
time/saving (s)                     0.00226483
time/training (s)                   0.458559
time/epoch (s)                      0.570854
time/total (s)                    236.233
Epoch                             397
-----------------------------  ----------------
2019-04-13 17:02:31.709931 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 398 finished
-----------------------------  ----------------
replay_buffer/size              79900
trainer/QF1 Loss                    0.154254
trainer/QF2 Loss                    0.153213
trainer/Policy Loss                12.5019
trainer/Q1 Predictions Mean       -12.5975
trainer/Q1 Predictions Std          0.102048
trainer/Q1 Predictions Max        -12.4958
trainer/Q1 Predictions Min        -13.042
trainer/Q2 Predictions Mean       -12.5997
trainer/Q2 Predictions Std          0.100748
trainer/Q2 Predictions Max        -12.4792
trainer/Q2 Predictions Min        -13.0187
trainer/Q Targets Mean            -12.9534
trainer/Q Targets Std               0.217353
trainer/Q Targets Max             -12.6375
trainer/Q Targets Min             -13.6965
trainer/Bellman Errors 1 Mean       0.154254
trainer/Bellman Errors 1 Std        0.123073
trainer/Bellman Errors 1 Max        0.428303
trainer/Bellman Errors 1 Min        0.0158749
trainer/Bellman Errors 2 Mean       0.153213
trainer/Bellman Errors 2 Std        0.12412
trainer/Bellman Errors 2 Max        0.459447
trainer/Bellman Errors 2 Min        0.0140458
trainer/Policy Action Mean          0.01058
trainer/Policy Action Std           0.101856
trainer/Policy Action Max           0.221087
trainer/Policy Action Min          -0.22562
exploration/num steps total     79900
exploration/num paths total       799
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132128
exploration/Rewards Std             0.0769479
exploration/Rewards Max            -0.000243668
exploration/Rewards Min            -0.727322
exploration/Returns Mean          -13.2128
exploration/Returns Std             0.781363
exploration/Returns Max           -12.4315
exploration/Returns Min           -13.9942
exploration/Actions Mean            0.00423648
exploration/Actions Std             0.160148
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.2128
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.016297
evaluation/Rewards Std              0.00902868
evaluation/Rewards Max             -0.00617849
evaluation/Rewards Min             -0.183353
evaluation/Returns Mean            -1.6297
evaluation/Returns Std              0.0643001
evaluation/Returns Max             -1.54514
evaluation/Returns Min             -1.73929
evaluation/Actions Mean             0.00103768
evaluation/Actions Std              0.0462012
evaluation/Actions Max              0.739971
evaluation/Actions Min             -0.641848
evaluation/Num Paths                5
evaluation/Average Returns         -1.6297
time/data storing (s)               0.00112692
time/evaluation sampling (s)        0.0739741
time/exploration sampling (s)       0.0326676
time/logging (s)                    0.00247188
time/saving (s)                     0.0022263
time/training (s)                   0.470183
time/epoch (s)                      0.58265
time/total (s)                    236.82
Epoch                             398
-----------------------------  ----------------
2019-04-13 17:02:32.309697 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 399 finished
-----------------------------  ----------------
replay_buffer/size              80100
trainer/QF1 Loss                    0.0438674
trainer/QF2 Loss                    0.0426725
trainer/Policy Loss                12.766
trainer/Q1 Predictions Mean       -12.9261
trainer/Q1 Predictions Std          0.501724
trainer/Q1 Predictions Max        -12.6906
trainer/Q1 Predictions Min        -14.9345
trainer/Q2 Predictions Mean       -12.9107
trainer/Q2 Predictions Std          0.480413
trainer/Q2 Predictions Max        -12.6676
trainer/Q2 Predictions Min        -14.9362
trainer/Q Targets Mean            -13.02
trainer/Q Targets Std               0.497414
trainer/Q Targets Max             -12.5988
trainer/Q Targets Min             -15.2367
trainer/Bellman Errors 1 Mean       0.0438674
trainer/Bellman Errors 1 Std        0.065152
trainer/Bellman Errors 1 Max        0.279008
trainer/Bellman Errors 1 Min        3.98821e-05
trainer/Bellman Errors 2 Mean       0.0426725
trainer/Bellman Errors 2 Std        0.0648559
trainer/Bellman Errors 2 Max        0.274893
trainer/Bellman Errors 2 Min        7.79726e-06
trainer/Policy Action Mean          0.0597474
trainer/Policy Action Std           0.266204
trainer/Policy Action Max           0.999755
trainer/Policy Action Min          -0.99985
exploration/num steps total     80100
exploration/num paths total       801
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.15882
exploration/Rewards Std             0.0755554
exploration/Rewards Max            -0.0136737
exploration/Rewards Min            -0.393311
exploration/Returns Mean          -15.882
exploration/Returns Std             0.688443
exploration/Returns Max           -15.1936
exploration/Returns Min           -16.5705
exploration/Actions Mean            0.00913256
exploration/Actions Std             0.142352
exploration/Actions Max             0.938941
exploration/Actions Min            -0.325713
exploration/Num Paths               2
exploration/Average Returns       -15.882
evaluation/num steps total     200000
evaluation/num paths total       2000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.102787
evaluation/Rewards Std              0.05467
evaluation/Rewards Max             -0.010123
evaluation/Rewards Min             -0.908033
evaluation/Returns Mean           -10.2787
evaluation/Returns Std              0.297202
evaluation/Returns Max             -9.83502
evaluation/Returns Min            -10.6183
evaluation/Actions Mean             0.00924896
evaluation/Actions Std              0.0934199
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.992225
evaluation/Num Paths                5
evaluation/Average Returns        -10.2787
time/data storing (s)               0.00106156
time/evaluation sampling (s)        0.0760042
time/exploration sampling (s)       0.0328913
time/logging (s)                    0.0021874
time/saving (s)                     0.00198968
time/training (s)                   0.475626
time/epoch (s)                      0.58976
time/total (s)                    237.413
Epoch                             399
-----------------------------  ----------------
2019-04-13 17:02:32.896555 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 400 finished
-----------------------------  ---------------
replay_buffer/size              80300
trainer/QF1 Loss                    0.152061
trainer/QF2 Loss                    0.149011
trainer/Policy Loss                12.5798
trainer/Q1 Predictions Mean       -12.6899
trainer/Q1 Predictions Std          0.473063
trainer/Q1 Predictions Max        -12.4575
trainer/Q1 Predictions Min        -15.1681
trainer/Q2 Predictions Mean       -12.6987
trainer/Q2 Predictions Std          0.477046
trainer/Q2 Predictions Max        -12.4692
trainer/Q2 Predictions Min        -15.2121
trainer/Q Targets Mean            -13.045
trainer/Q Targets Std               0.493616
trainer/Q Targets Max             -12.626
trainer/Q Targets Min             -15.3495
trainer/Bellman Errors 1 Mean       0.152061
trainer/Bellman Errors 1 Std        0.140808
trainer/Bellman Errors 1 Max        0.589323
trainer/Bellman Errors 1 Min        0.0142582
trainer/Bellman Errors 2 Mean       0.149011
trainer/Bellman Errors 2 Std        0.148085
trainer/Bellman Errors 2 Max        0.596898
trainer/Bellman Errors 2 Min        0.0118378
trainer/Policy Action Mean          0.0434404
trainer/Policy Action Std           0.172634
trainer/Policy Action Max           0.999798
trainer/Policy Action Min          -0.434393
exploration/num steps total     80300
exploration/num paths total       803
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.151382
exploration/Rewards Std             0.0770437
exploration/Rewards Max            -0.00789482
exploration/Rewards Min            -0.4206
exploration/Returns Mean          -15.1382
exploration/Returns Std             0.609831
exploration/Returns Max           -14.5283
exploration/Returns Min           -15.748
exploration/Actions Mean            0.00577954
exploration/Actions Std             0.1524
exploration/Actions Max             0.739629
exploration/Actions Min            -0.45768
exploration/Num Paths               2
exploration/Average Returns       -15.1382
evaluation/num steps total     200500
evaluation/num paths total       2005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0897239
evaluation/Rewards Std              0.0326093
evaluation/Rewards Max             -0.0785265
evaluation/Rewards Min             -0.658258
evaluation/Returns Mean            -8.97239
evaluation/Returns Std              0.218103
evaluation/Returns Max             -8.70759
evaluation/Returns Min             -9.30025
evaluation/Actions Mean             0.00651363
evaluation/Actions Std              0.0827543
evaluation/Actions Max              0.999906
evaluation/Actions Min             -0.996401
evaluation/Num Paths                5
evaluation/Average Returns         -8.97239
time/data storing (s)               0.00106892
time/evaluation sampling (s)        0.0746236
time/exploration sampling (s)       0.0323351
time/logging (s)                    0.00247155
time/saving (s)                     0.00222166
time/training (s)                   0.464754
time/epoch (s)                      0.577475
time/total (s)                    237.995
Epoch                             400
-----------------------------  ---------------
2019-04-13 17:02:33.478086 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 401 finished
-----------------------------  ----------------
replay_buffer/size              80500
trainer/QF1 Loss                    0.118587
trainer/QF2 Loss                    0.11632
trainer/Policy Loss                12.5682
trainer/Q1 Predictions Mean       -12.724
trainer/Q1 Predictions Std          0.460277
trainer/Q1 Predictions Max        -12.5311
trainer/Q1 Predictions Min        -15.2459
trainer/Q2 Predictions Mean       -12.7299
trainer/Q2 Predictions Std          0.463744
trainer/Q2 Predictions Max        -12.5316
trainer/Q2 Predictions Min        -15.2699
trainer/Q Targets Mean            -13.0095
trainer/Q Targets Std               0.561846
trainer/Q Targets Max             -12.616
trainer/Q Targets Min             -15.9744
trainer/Bellman Errors 1 Mean       0.118587
trainer/Bellman Errors 1 Std        0.159505
trainer/Bellman Errors 1 Max        0.625241
trainer/Bellman Errors 1 Min        9.36615e-05
trainer/Bellman Errors 2 Mean       0.11632
trainer/Bellman Errors 2 Std        0.159529
trainer/Bellman Errors 2 Max        0.642334
trainer/Bellman Errors 2 Min        0.000225812
trainer/Policy Action Mean          0.0185359
trainer/Policy Action Std           0.168405
trainer/Policy Action Max           0.999787
trainer/Policy Action Min          -0.271332
exploration/num steps total     80500
exploration/num paths total       805
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131079
exploration/Rewards Std             0.0642227
exploration/Rewards Max            -0.00317982
exploration/Rewards Min            -0.346692
exploration/Returns Mean          -13.1079
exploration/Returns Std             0.154652
exploration/Returns Max           -12.9533
exploration/Returns Min           -13.2626
exploration/Actions Mean            0.00769443
exploration/Actions Std             0.149162
exploration/Actions Max             1
exploration/Actions Min            -0.420002
exploration/Num Paths               2
exploration/Average Returns       -13.1079
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0108477
evaluation/Rewards Std              0.0311426
evaluation/Rewards Max             -0.00852019
evaluation/Rewards Min             -0.669048
evaluation/Returns Mean            -1.08477
evaluation/Returns Std              0.247362
evaluation/Returns Max             -0.912576
evaluation/Returns Min             -1.57213
evaluation/Actions Mean             0.00609912
evaluation/Actions Std              0.0699806
evaluation/Actions Max              0.999906
evaluation/Actions Min             -0.321997
evaluation/Num Paths                5
evaluation/Average Returns         -1.08477
time/data storing (s)               0.00108935
time/evaluation sampling (s)        0.0741253
time/exploration sampling (s)       0.0333414
time/logging (s)                    0.002117
time/saving (s)                     0.00223045
time/training (s)                   0.458488
time/epoch (s)                      0.571392
time/total (s)                    238.57
Epoch                             401
-----------------------------  ----------------
2019-04-13 17:02:34.069841 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 402 finished
-----------------------------  ----------------
replay_buffer/size              80700
trainer/QF1 Loss                    0.0701867
trainer/QF2 Loss                    0.068698
trainer/Policy Loss                12.6537
trainer/Q1 Predictions Mean       -12.7276
trainer/Q1 Predictions Std          0.0840722
trainer/Q1 Predictions Max        -12.6219
trainer/Q1 Predictions Min        -12.9223
trainer/Q2 Predictions Mean       -12.731
trainer/Q2 Predictions Std          0.080278
trainer/Q2 Predictions Max        -12.621
trainer/Q2 Predictions Min        -12.9168
trainer/Q Targets Mean            -12.9311
trainer/Q Targets Std               0.180972
trainer/Q Targets Max             -12.6289
trainer/Q Targets Min             -13.2987
trainer/Bellman Errors 1 Mean       0.0701867
trainer/Bellman Errors 1 Std        0.0938639
trainer/Bellman Errors 1 Max        0.368932
trainer/Bellman Errors 1 Min        1.32717e-07
trainer/Bellman Errors 2 Mean       0.068698
trainer/Bellman Errors 2 Std        0.0936444
trainer/Bellman Errors 2 Max        0.362793
trainer/Bellman Errors 2 Min        1.54381e-07
trainer/Policy Action Mean          0.0047149
trainer/Policy Action Std           0.0841988
trainer/Policy Action Max           0.226555
trainer/Policy Action Min          -0.2066
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138766
exploration/Rewards Std             0.0675652
exploration/Rewards Max            -0.00866124
exploration/Rewards Min            -0.355348
exploration/Returns Mean          -13.8766
exploration/Returns Std             0.126536
exploration/Returns Max           -13.75
exploration/Returns Min           -14.0031
exploration/Actions Mean            0.003772
exploration/Actions Std             0.162457
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.8766
evaluation/num steps total     201500
evaluation/num paths total       2015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0808577
evaluation/Rewards Std              0.0415664
evaluation/Rewards Max             -0.0481019
evaluation/Rewards Min             -0.762605
evaluation/Returns Mean            -8.08577
evaluation/Returns Std              0.305056
evaluation/Returns Max             -7.79213
evaluation/Returns Min             -8.48932
evaluation/Actions Mean             0.00624308
evaluation/Actions Std              0.0831786
evaluation/Actions Max              0.999944
evaluation/Actions Min             -0.988219
evaluation/Num Paths                5
evaluation/Average Returns         -8.08577
time/data storing (s)               0.00104941
time/evaluation sampling (s)        0.0747204
time/exploration sampling (s)       0.0332633
time/logging (s)                    0.00244765
time/saving (s)                     0.00230037
time/training (s)                   0.468378
time/epoch (s)                      0.582159
time/total (s)                    239.157
Epoch                             402
-----------------------------  ----------------
2019-04-13 17:02:34.648987 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 403 finished
-----------------------------  ----------------
replay_buffer/size              80900
trainer/QF1 Loss                    0.0213665
trainer/QF2 Loss                    0.020966
trainer/Policy Loss                12.811
trainer/Q1 Predictions Mean       -12.8538
trainer/Q1 Predictions Std          0.0635862
trainer/Q1 Predictions Max        -12.7546
trainer/Q1 Predictions Min        -13.0237
trainer/Q2 Predictions Mean       -12.8518
trainer/Q2 Predictions Std          0.0647789
trainer/Q2 Predictions Max        -12.7446
trainer/Q2 Predictions Min        -13.0218
trainer/Q Targets Mean            -12.8446
trainer/Q Targets Std               0.159431
trainer/Q Targets Max             -12.5751
trainer/Q Targets Min             -13.1822
trainer/Bellman Errors 1 Mean       0.0213665
trainer/Bellman Errors 1 Std        0.0332553
trainer/Bellman Errors 1 Max        0.134045
trainer/Bellman Errors 1 Min        8.02256e-08
trainer/Bellman Errors 2 Mean       0.020966
trainer/Bellman Errors 2 Std        0.0331872
trainer/Bellman Errors 2 Max        0.141995
trainer/Bellman Errors 2 Min        5.19512e-08
trainer/Policy Action Mean         -0.0209171
trainer/Policy Action Std           0.0804122
trainer/Policy Action Max           0.152757
trainer/Policy Action Min          -0.183138
exploration/num steps total     80900
exploration/num paths total       809
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133572
exploration/Rewards Std             0.0865039
exploration/Rewards Max            -0.013791
exploration/Rewards Min            -0.875734
exploration/Returns Mean          -13.3572
exploration/Returns Std             0.535705
exploration/Returns Max           -12.8215
exploration/Returns Min           -13.8929
exploration/Actions Mean            0.00244839
exploration/Actions Std             0.155295
exploration/Actions Max             0.982819
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.3572
evaluation/num steps total     202000
evaluation/num paths total       2020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0493968
evaluation/Rewards Std              0.0394327
evaluation/Rewards Max             -0.0456818
evaluation/Rewards Min             -0.695039
evaluation/Returns Mean            -4.93968
evaluation/Returns Std              0.276054
evaluation/Returns Max             -4.64369
evaluation/Returns Min             -5.30891
evaluation/Actions Mean             0.00450319
evaluation/Actions Std              0.0809577
evaluation/Actions Max              0.999884
evaluation/Actions Min             -0.989724
evaluation/Num Paths                5
evaluation/Average Returns         -4.93968
time/data storing (s)               0.00112119
time/evaluation sampling (s)        0.0735544
time/exploration sampling (s)       0.0346175
time/logging (s)                    0.00197566
time/saving (s)                     0.00177525
time/training (s)                   0.45576
time/epoch (s)                      0.568804
time/total (s)                    239.73
Epoch                             403
-----------------------------  ----------------
2019-04-13 17:02:35.238449 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 404 finished
-----------------------------  ----------------
replay_buffer/size              81100
trainer/QF1 Loss                    0.0159627
trainer/QF2 Loss                    0.0160994
trainer/Policy Loss                12.8375
trainer/Q1 Predictions Mean       -12.9096
trainer/Q1 Predictions Std          0.068202
trainer/Q1 Predictions Max        -12.8249
trainer/Q1 Predictions Min        -13.0618
trainer/Q2 Predictions Mean       -12.9073
trainer/Q2 Predictions Std          0.0704094
trainer/Q2 Predictions Max        -12.8031
trainer/Q2 Predictions Min        -13.0808
trainer/Q Targets Mean            -12.853
trainer/Q Targets Std               0.116346
trainer/Q Targets Max             -12.6778
trainer/Q Targets Min             -13.1264
trainer/Bellman Errors 1 Mean       0.0159627
trainer/Bellman Errors 1 Std        0.0159385
trainer/Bellman Errors 1 Max        0.0733521
trainer/Bellman Errors 1 Min        2.43426e-06
trainer/Bellman Errors 2 Mean       0.0160994
trainer/Bellman Errors 2 Std        0.0171525
trainer/Bellman Errors 2 Max        0.0795318
trainer/Bellman Errors 2 Min        1.34483e-06
trainer/Policy Action Mean          0.00226021
trainer/Policy Action Std           0.129447
trainer/Policy Action Max           0.711756
trainer/Policy Action Min          -0.177009
exploration/num steps total     81100
exploration/num paths total       811
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126551
exploration/Rewards Std             0.0659861
exploration/Rewards Max            -0.00724881
exploration/Rewards Min            -0.341657
exploration/Returns Mean          -12.6551
exploration/Returns Std             0.184088
exploration/Returns Max           -12.471
exploration/Returns Min           -12.8392
exploration/Actions Mean            0.00167155
exploration/Actions Std             0.166022
exploration/Actions Max             0.952707
exploration/Actions Min            -0.980535
exploration/Num Paths               2
exploration/Average Returns       -12.6551
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.00630426
evaluation/Rewards Std              0.0530615
evaluation/Rewards Max             -0.00087077
evaluation/Rewards Min             -0.936989
evaluation/Returns Mean            -0.630426
evaluation/Returns Std              0.321893
evaluation/Returns Max             -0.179814
evaluation/Returns Min             -1.17236
evaluation/Actions Mean             0.00460706
evaluation/Actions Std              0.0852684
evaluation/Actions Max              0.999995
evaluation/Actions Min             -0.999737
evaluation/Num Paths                5
evaluation/Average Returns         -0.630426
time/data storing (s)               0.00104024
time/evaluation sampling (s)        0.0748802
time/exploration sampling (s)       0.0377929
time/logging (s)                    0.00186337
time/saving (s)                     0.0020845
time/training (s)                   0.46184
time/epoch (s)                      0.579501
time/total (s)                    240.313
Epoch                             404
-----------------------------  ----------------
2019-04-13 17:02:35.828614 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 405 finished
-----------------------------  ----------------
replay_buffer/size              81300
trainer/QF1 Loss                    0.0242408
trainer/QF2 Loss                    0.0253128
trainer/Policy Loss                12.695
trainer/Q1 Predictions Mean       -12.8187
trainer/Q1 Predictions Std          0.119747
trainer/Q1 Predictions Max        -12.6803
trainer/Q1 Predictions Min        -13.2102
trainer/Q2 Predictions Mean       -12.8216
trainer/Q2 Predictions Std          0.12453
trainer/Q2 Predictions Max        -12.6865
trainer/Q2 Predictions Min        -13.2066
trainer/Q Targets Mean            -12.8952
trainer/Q Targets Std               0.178753
trainer/Q Targets Max             -12.5749
trainer/Q Targets Min             -13.4249
trainer/Bellman Errors 1 Mean       0.0242408
trainer/Bellman Errors 1 Std        0.0334185
trainer/Bellman Errors 1 Max        0.12373
trainer/Bellman Errors 1 Min        6.83657e-05
trainer/Bellman Errors 2 Mean       0.0253128
trainer/Bellman Errors 2 Std        0.0345308
trainer/Bellman Errors 2 Max        0.129383
trainer/Bellman Errors 2 Min        3.56198e-06
trainer/Policy Action Mean         -0.0243501
trainer/Policy Action Std           0.0978932
trainer/Policy Action Max           0.208981
trainer/Policy Action Min          -0.201873
exploration/num steps total     81300
exploration/num paths total       813
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133183
exploration/Rewards Std             0.0824478
exploration/Rewards Max            -0.0115066
exploration/Rewards Min            -0.766172
exploration/Returns Mean          -13.3183
exploration/Returns Std             0.910149
exploration/Returns Max           -12.4081
exploration/Returns Min           -14.2284
exploration/Actions Mean            0.00608482
exploration/Actions Std             0.152028
exploration/Actions Max             0.96527
exploration/Actions Min            -0.4326
exploration/Num Paths               2
exploration/Average Returns       -13.3183
evaluation/num steps total     203000
evaluation/num paths total       2030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.039182
evaluation/Rewards Std              0.0577593
evaluation/Rewards Max             -0.032333
evaluation/Rewards Min             -0.962605
evaluation/Returns Mean            -3.9182
evaluation/Returns Std              0.394637
evaluation/Returns Max             -3.49805
evaluation/Returns Min             -4.42758
evaluation/Actions Mean             0.00781779
evaluation/Actions Std              0.0911151
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.911283
evaluation/Num Paths                5
evaluation/Average Returns         -3.9182
time/data storing (s)               0.00114241
time/evaluation sampling (s)        0.0732273
time/exploration sampling (s)       0.0337875
time/logging (s)                    0.00247439
time/saving (s)                     0.00222456
time/training (s)                   0.468893
time/epoch (s)                      0.581749
time/total (s)                    240.899
Epoch                             405
-----------------------------  ----------------
2019-04-13 17:02:36.426748 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 406 finished
-----------------------------  ----------------
replay_buffer/size              81500
trainer/QF1 Loss                    5.00571
trainer/QF2 Loss                    5.01852
trainer/Policy Loss                12.5503
trainer/Q1 Predictions Mean       -12.7411
trainer/Q1 Predictions Std          0.130733
trainer/Q1 Predictions Max        -12.5441
trainer/Q1 Predictions Min        -13.0747
trainer/Q2 Predictions Mean       -12.7425
trainer/Q2 Predictions Std          0.128123
trainer/Q2 Predictions Max        -12.5637
trainer/Q2 Predictions Min        -13.0317
trainer/Q Targets Mean            -12.5069
trainer/Q Targets Std               2.23451
trainer/Q Targets Max              -0.101205
trainer/Q Targets Min             -13.3574
trainer/Bellman Errors 1 Mean       5.00571
trainer/Bellman Errors 1 Std       27.5159
trainer/Bellman Errors 1 Max      158.207
trainer/Bellman Errors 1 Min        2.44511e-05
trainer/Bellman Errors 2 Mean       5.01852
trainer/Bellman Errors 2 Std       27.5876
trainer/Bellman Errors 2 Max      158.619
trainer/Bellman Errors 2 Min        3.06915e-06
trainer/Policy Action Mean          0.0307291
trainer/Policy Action Std           0.175461
trainer/Policy Action Max           0.820398
trainer/Policy Action Min          -0.270031
exploration/num steps total     81500
exploration/num paths total       815
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143888
exploration/Rewards Std             0.0987137
exploration/Rewards Max            -0.00538431
exploration/Rewards Min            -0.810997
exploration/Returns Mean          -14.3888
exploration/Returns Std             0.731556
exploration/Returns Max           -13.6572
exploration/Returns Min           -15.1204
exploration/Actions Mean            0.012937
exploration/Actions Std             0.169039
exploration/Actions Max             1
exploration/Actions Min            -0.365485
exploration/Num Paths               2
exploration/Average Returns       -14.3888
evaluation/num steps total     203500
evaluation/num paths total       2035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.06333
evaluation/Rewards Std              0.0430234
evaluation/Rewards Max             -0.0403082
evaluation/Rewards Min             -0.786027
evaluation/Returns Mean            -6.333
evaluation/Returns Std              0.302919
evaluation/Returns Max             -6.00075
evaluation/Returns Min             -6.74941
evaluation/Actions Mean             0.00497029
evaluation/Actions Std              0.0816997
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.991478
evaluation/Num Paths                5
evaluation/Average Returns         -6.333
time/data storing (s)               0.00115585
time/evaluation sampling (s)        0.075235
time/exploration sampling (s)       0.0327648
time/logging (s)                    0.00250499
time/saving (s)                     0.00231845
time/training (s)                   0.474258
time/epoch (s)                      0.588237
time/total (s)                    241.492
Epoch                             406
-----------------------------  ----------------
2019-04-13 17:02:37.037778 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 407 finished
-----------------------------  ----------------
replay_buffer/size              81700
trainer/QF1 Loss                    4.96866
trainer/QF2 Loss                    4.96898
trainer/Policy Loss                12.6563
trainer/Q1 Predictions Mean       -12.7657
trainer/Q1 Predictions Std          0.168616
trainer/Q1 Predictions Max        -12.6178
trainer/Q1 Predictions Min        -13.5373
trainer/Q2 Predictions Mean       -12.7564
trainer/Q2 Predictions Std          0.157726
trainer/Q2 Predictions Max        -12.6219
trainer/Q2 Predictions Min        -13.4846
trainer/Q Targets Mean            -12.4964
trainer/Q Targets Std               2.22517
trainer/Q Targets Max              -0.155358
trainer/Q Targets Min             -13.5084
trainer/Bellman Errors 1 Mean       4.96866
trainer/Bellman Errors 1 Std       27.4541
trainer/Bellman Errors 1 Max      157.826
trainer/Bellman Errors 1 Min        3.59807e-06
trainer/Bellman Errors 2 Mean       4.96898
trainer/Bellman Errors 2 Std       27.4383
trainer/Bellman Errors 2 Max      157.738
trainer/Bellman Errors 2 Min        1.54531e-05
trainer/Policy Action Mean          0.00471937
trainer/Policy Action Std           0.128877
trainer/Policy Action Max           0.313651
trainer/Policy Action Min          -0.461895
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130241
exploration/Rewards Std             0.0723063
exploration/Rewards Max            -0.0108519
exploration/Rewards Min            -0.44276
exploration/Returns Mean          -13.0241
exploration/Returns Std             0.314917
exploration/Returns Max           -12.7092
exploration/Returns Min           -13.339
exploration/Actions Mean            0.00539205
exploration/Actions Std             0.143758
exploration/Actions Max             0.900429
exploration/Actions Min            -0.421455
exploration/Num Paths               2
exploration/Average Returns       -13.0241
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0500452
evaluation/Rewards Std              0.0381236
evaluation/Rewards Max             -0.0248711
evaluation/Rewards Min             -0.858021
evaluation/Returns Mean            -5.00452
evaluation/Returns Std              0.303677
evaluation/Returns Max             -4.73622
evaluation/Returns Min             -5.58169
evaluation/Actions Mean             0.00538579
evaluation/Actions Std              0.0755227
evaluation/Actions Max              0.999987
evaluation/Actions Min             -0.785509
evaluation/Num Paths                5
evaluation/Average Returns         -5.00452
time/data storing (s)               0.00119391
time/evaluation sampling (s)        0.0797452
time/exploration sampling (s)       0.0356536
time/logging (s)                    0.00250455
time/saving (s)                     0.00223129
time/training (s)                   0.479793
time/epoch (s)                      0.601122
time/total (s)                    242.097
Epoch                             407
-----------------------------  ----------------
2019-04-13 17:02:37.633642 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 408 finished
-----------------------------  ----------------
replay_buffer/size              81900
trainer/QF1 Loss                    0.130596
trainer/QF2 Loss                    0.134901
trainer/Policy Loss                12.6499
trainer/Q1 Predictions Mean       -12.7244
trainer/Q1 Predictions Std          0.324152
trainer/Q1 Predictions Max        -12.52
trainer/Q1 Predictions Min        -14.3337
trainer/Q2 Predictions Mean       -12.717
trainer/Q2 Predictions Std          0.329653
trainer/Q2 Predictions Max        -12.538
trainer/Q2 Predictions Min        -14.3552
trainer/Q Targets Mean            -13.0191
trainer/Q Targets Std               0.385408
trainer/Q Targets Max             -12.6674
trainer/Q Targets Min             -14.612
trainer/Bellman Errors 1 Mean       0.130596
trainer/Bellman Errors 1 Std        0.18057
trainer/Bellman Errors 1 Max        0.805285
trainer/Bellman Errors 1 Min        0.00105509
trainer/Bellman Errors 2 Mean       0.134901
trainer/Bellman Errors 2 Std        0.186108
trainer/Bellman Errors 2 Max        0.836707
trainer/Bellman Errors 2 Min        0.000752801
trainer/Policy Action Mean          0.00202814
trainer/Policy Action Std           0.193371
trainer/Policy Action Max           0.982101
trainer/Policy Action Min          -0.550172
exploration/num steps total     81900
exploration/num paths total       819
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.139574
exploration/Rewards Std             0.0717095
exploration/Rewards Max            -0.00716448
exploration/Rewards Min            -0.378707
exploration/Returns Mean          -13.9574
exploration/Returns Std             0.877585
exploration/Returns Max           -13.0798
exploration/Returns Min           -14.835
exploration/Actions Mean            0.00278758
exploration/Actions Std             0.167928
exploration/Actions Max             1
exploration/Actions Min            -0.872548
exploration/Num Paths               2
exploration/Average Returns       -13.9574
evaluation/num steps total     204500
evaluation/num paths total       2045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0374629
evaluation/Rewards Std              0.0182428
evaluation/Rewards Max             -0.0194633
evaluation/Rewards Min             -0.384032
evaluation/Returns Mean            -3.74629
evaluation/Returns Std              0.109361
evaluation/Returns Max             -3.66951
evaluation/Returns Min             -3.96127
evaluation/Actions Mean             0.00429555
evaluation/Actions Std              0.078667
evaluation/Actions Max              0.999119
evaluation/Actions Min             -0.995948
evaluation/Num Paths                5
evaluation/Average Returns         -3.74629
time/data storing (s)               0.00105868
time/evaluation sampling (s)        0.07444
time/exploration sampling (s)       0.0328472
time/logging (s)                    0.00238266
time/saving (s)                     0.00218489
time/training (s)                   0.472892
time/epoch (s)                      0.585806
time/total (s)                    242.687
Epoch                             408
-----------------------------  ----------------
2019-04-13 17:02:38.227003 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 409 finished
-----------------------------  ----------------
replay_buffer/size              82100
trainer/QF1 Loss                    0.0769314
trainer/QF2 Loss                    0.0763254
trainer/Policy Loss                12.6978
trainer/Q1 Predictions Mean       -12.816
trainer/Q1 Predictions Std          0.49698
trainer/Q1 Predictions Max        -12.5999
trainer/Q1 Predictions Min        -15.5207
trainer/Q2 Predictions Mean       -12.8133
trainer/Q2 Predictions Std          0.495686
trainer/Q2 Predictions Max        -12.6097
trainer/Q2 Predictions Min        -15.5136
trainer/Q Targets Mean            -13.034
trainer/Q Targets Std               0.50757
trainer/Q Targets Max             -12.694
trainer/Q Targets Min             -15.7149
trainer/Bellman Errors 1 Mean       0.0769314
trainer/Bellman Errors 1 Std        0.0957274
trainer/Bellman Errors 1 Max        0.44482
trainer/Bellman Errors 1 Min        0.000289915
trainer/Bellman Errors 2 Mean       0.0763254
trainer/Bellman Errors 2 Std        0.0914394
trainer/Bellman Errors 2 Max        0.412848
trainer/Bellman Errors 2 Min        0.00041932
trainer/Policy Action Mean          0.0232238
trainer/Policy Action Std           0.235084
trainer/Policy Action Max           0.999718
trainer/Policy Action Min          -0.991825
exploration/num steps total     82100
exploration/num paths total       821
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129936
exploration/Rewards Std             0.0734044
exploration/Rewards Max            -0.01096
exploration/Rewards Min            -0.697375
exploration/Returns Mean          -12.9936
exploration/Returns Std             0.12161
exploration/Returns Max           -12.872
exploration/Returns Min           -13.1152
exploration/Actions Mean            0.00308908
exploration/Actions Std             0.152326
exploration/Actions Max             0.925429
exploration/Actions Min            -0.533667
exploration/Num Paths               2
exploration/Average Returns       -12.9936
evaluation/num steps total     205000
evaluation/num paths total       2050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0411574
evaluation/Rewards Std              0.0224361
evaluation/Rewards Max             -0.0341804
evaluation/Rewards Min             -0.349231
evaluation/Returns Mean            -4.11574
evaluation/Returns Std              0.120592
evaluation/Returns Max             -3.93268
evaluation/Returns Min             -4.23568
evaluation/Actions Mean             0.0054139
evaluation/Actions Std              0.0741582
evaluation/Actions Max              0.997157
evaluation/Actions Min             -0.866269
evaluation/Num Paths                5
evaluation/Average Returns         -4.11574
time/data storing (s)               0.00113535
time/evaluation sampling (s)        0.0749226
time/exploration sampling (s)       0.0328541
time/logging (s)                    0.00247586
time/saving (s)                     0.00178191
time/training (s)                   0.470402
time/epoch (s)                      0.583572
time/total (s)                    243.275
Epoch                             409
-----------------------------  ----------------
2019-04-13 17:02:38.845332 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 410 finished
-----------------------------  ----------------
replay_buffer/size              82300
trainer/QF1 Loss                    0.0326477
trainer/QF2 Loss                    0.0315636
trainer/Policy Loss                12.9502
trainer/Q1 Predictions Mean       -13.1071
trainer/Q1 Predictions Std          0.432673
trainer/Q1 Predictions Max        -12.9158
trainer/Q1 Predictions Min        -15.4817
trainer/Q2 Predictions Mean       -13.1041
trainer/Q2 Predictions Std          0.437133
trainer/Q2 Predictions Max        -12.9193
trainer/Q2 Predictions Min        -15.5097
trainer/Q Targets Mean            -13.0017
trainer/Q Targets Std               0.468665
trainer/Q Targets Max             -12.6169
trainer/Q Targets Min             -15.4365
trainer/Bellman Errors 1 Mean       0.0326477
trainer/Bellman Errors 1 Std        0.0304705
trainer/Bellman Errors 1 Max        0.0916643
trainer/Bellman Errors 1 Min        1.82213e-05
trainer/Bellman Errors 2 Mean       0.0315636
trainer/Bellman Errors 2 Std        0.0293469
trainer/Bellman Errors 2 Max        0.106818
trainer/Bellman Errors 2 Min        1.84091e-05
trainer/Policy Action Mean         -0.0181588
trainer/Policy Action Std           0.160455
trainer/Policy Action Max           0.999563
trainer/Policy Action Min          -0.275363
exploration/num steps total     82300
exploration/num paths total       823
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.141264
exploration/Rewards Std             0.0807906
exploration/Rewards Max            -0.00575983
exploration/Rewards Min            -0.781482
exploration/Returns Mean          -14.1264
exploration/Returns Std             0.877787
exploration/Returns Max           -13.2486
exploration/Returns Min           -15.0042
exploration/Actions Mean            0.00566933
exploration/Actions Std             0.159312
exploration/Actions Max             1
exploration/Actions Min            -0.757001
exploration/Num Paths               2
exploration/Average Returns       -14.1264
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0635148
evaluation/Rewards Std              0.0154305
evaluation/Rewards Max             -0.0603303
evaluation/Rewards Min             -0.293667
evaluation/Returns Mean            -6.35148
evaluation/Returns Std              0.0826228
evaluation/Returns Max             -6.26966
evaluation/Returns Min             -6.46547
evaluation/Actions Mean             0.00465922
evaluation/Actions Std              0.0651668
evaluation/Actions Max              0.990319
evaluation/Actions Min             -0.773705
evaluation/Num Paths                5
evaluation/Average Returns         -6.35148
time/data storing (s)               0.00114004
time/evaluation sampling (s)        0.0752761
time/exploration sampling (s)       0.0335326
time/logging (s)                    0.00249405
time/saving (s)                     0.00223169
time/training (s)                   0.493584
time/epoch (s)                      0.608259
time/total (s)                    243.887
Epoch                             410
-----------------------------  ----------------
2019-04-13 17:02:39.660955 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 411 finished
-----------------------------  ----------------
replay_buffer/size              82500
trainer/QF1 Loss                    0.0406782
trainer/QF2 Loss                    0.0400459
trainer/Policy Loss                12.7564
trainer/Q1 Predictions Mean       -12.8436
trainer/Q1 Predictions Std          0.158499
trainer/Q1 Predictions Max        -12.7092
trainer/Q1 Predictions Min        -13.6236
trainer/Q2 Predictions Mean       -12.845
trainer/Q2 Predictions Std          0.156181
trainer/Q2 Predictions Max        -12.71
trainer/Q2 Predictions Min        -13.6047
trainer/Q Targets Mean            -12.9656
trainer/Q Targets Std               0.188059
trainer/Q Targets Max             -12.7002
trainer/Q Targets Min             -13.6003
trainer/Bellman Errors 1 Mean       0.0406782
trainer/Bellman Errors 1 Std        0.0807403
trainer/Bellman Errors 1 Max        0.416992
trainer/Bellman Errors 1 Min        1.6575e-05
trainer/Bellman Errors 2 Mean       0.0400459
trainer/Bellman Errors 2 Std        0.0808886
trainer/Bellman Errors 2 Max        0.416506
trainer/Bellman Errors 2 Min        7.20411e-07
trainer/Policy Action Mean          0.0299748
trainer/Policy Action Std           0.182181
trainer/Policy Action Max           0.999949
trainer/Policy Action Min          -0.269254
exploration/num steps total     82500
exploration/num paths total       825
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132109
exploration/Rewards Std             0.0727721
exploration/Rewards Max            -0.00670421
exploration/Rewards Min            -0.366636
exploration/Returns Mean          -13.2109
exploration/Returns Std             0.0795553
exploration/Returns Max           -13.1313
exploration/Returns Min           -13.2904
exploration/Actions Mean            0.00826738
exploration/Actions Std             0.170252
exploration/Actions Max             1
exploration/Actions Min            -0.467802
exploration/Num Paths               2
exploration/Average Returns       -13.2109
evaluation/num steps total     206000
evaluation/num paths total       2060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0241319
evaluation/Rewards Std              0.0333997
evaluation/Rewards Max             -0.0166789
evaluation/Rewards Min             -0.586102
evaluation/Returns Mean            -2.41319
evaluation/Returns Std              0.222291
evaluation/Returns Max             -2.20747
evaluation/Returns Min             -2.7371
evaluation/Actions Mean             0.00438639
evaluation/Actions Std              0.0748193
evaluation/Actions Max              0.999756
evaluation/Actions Min             -0.958811
evaluation/Num Paths                5
evaluation/Average Returns         -2.41319
time/data storing (s)               0.0012075
time/evaluation sampling (s)        0.104654
time/exploration sampling (s)       0.0457769
time/logging (s)                    0.00303563
time/saving (s)                     0.00298615
time/training (s)                   0.64832
time/epoch (s)                      0.80598
time/total (s)                    244.697
Epoch                             411
-----------------------------  ----------------
2019-04-13 17:02:40.356065 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 412 finished
-----------------------------  ----------------
replay_buffer/size              82700
trainer/QF1 Loss                    4.95544
trainer/QF2 Loss                    4.95307
trainer/Policy Loss                12.6254
trainer/Q1 Predictions Mean       -12.7645
trainer/Q1 Predictions Std          0.201842
trainer/Q1 Predictions Max        -12.6139
trainer/Q1 Predictions Min        -13.8207
trainer/Q2 Predictions Mean       -12.762
trainer/Q2 Predictions Std          0.193553
trainer/Q2 Predictions Max        -12.6256
trainer/Q2 Predictions Min        -13.7658
trainer/Q Targets Mean            -12.5416
trainer/Q Targets Std               2.23262
trainer/Q Targets Max              -0.158491
trainer/Q Targets Min             -13.7986
trainer/Bellman Errors 1 Mean       4.95544
trainer/Bellman Errors 1 Std       27.3231
trainer/Bellman Errors 1 Max      157.083
trainer/Bellman Errors 1 Min        0.000143271
trainer/Bellman Errors 2 Mean       4.95307
trainer/Bellman Errors 2 Std       27.3065
trainer/Bellman Errors 2 Max      156.989
trainer/Bellman Errors 2 Min        1.54831e-05
trainer/Policy Action Mean         -0.00202419
trainer/Policy Action Std           0.142478
trainer/Policy Action Max           0.507571
trainer/Policy Action Min          -0.523391
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.142202
exploration/Rewards Std             0.0962194
exploration/Rewards Max            -0.00878842
exploration/Rewards Min            -0.99214
exploration/Returns Mean          -14.2202
exploration/Returns Std             0.0418759
exploration/Returns Max           -14.1783
exploration/Returns Min           -14.262
exploration/Actions Mean            0.00969324
exploration/Actions Std             0.174243
exploration/Actions Max             1
exploration/Actions Min            -0.433752
exploration/Num Paths               2
exploration/Average Returns       -14.2202
evaluation/num steps total     206500
evaluation/num paths total       2065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0686749
evaluation/Rewards Std              0.058087
evaluation/Rewards Max             -0.0107955
evaluation/Rewards Min             -0.82548
evaluation/Returns Mean            -6.86749
evaluation/Returns Std              0.360166
evaluation/Returns Max             -6.33395
evaluation/Returns Min             -7.17232
evaluation/Actions Mean             0.00697595
evaluation/Actions Std              0.0925701
evaluation/Actions Max              0.999991
evaluation/Actions Min             -0.983268
evaluation/Num Paths                5
evaluation/Average Returns         -6.86749
time/data storing (s)               0.00133491
time/evaluation sampling (s)        0.104545
time/exploration sampling (s)       0.0561936
time/logging (s)                    0.0024324
time/saving (s)                     0.0022969
time/training (s)                   0.51645
time/epoch (s)                      0.683253
time/total (s)                    245.385
Epoch                             412
-----------------------------  ----------------
2019-04-13 17:02:41.118666 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 413 finished
-----------------------------  ----------------
replay_buffer/size              82900
trainer/QF1 Loss                    5.24627
trainer/QF2 Loss                    5.24442
trainer/Policy Loss                12.8589
trainer/Q1 Predictions Mean       -13.1186
trainer/Q1 Predictions Std          0.470423
trainer/Q1 Predictions Max        -12.872
trainer/Q1 Predictions Min        -15.6841
trainer/Q2 Predictions Mean       -13.1194
trainer/Q2 Predictions Std          0.476471
trainer/Q2 Predictions Max        -12.8821
trainer/Q2 Predictions Min        -15.7179
trainer/Q Targets Mean            -12.7051
trainer/Q Targets Std               2.32078
trainer/Q Targets Max              -0.122996
trainer/Q Targets Min             -15.8146
trainer/Bellman Errors 1 Mean       5.24627
trainer/Bellman Errors 1 Std       29.004
trainer/Bellman Errors 1 Max      166.734
trainer/Bellman Errors 1 Min        0.000118842
trainer/Bellman Errors 2 Mean       5.24442
trainer/Bellman Errors 2 Std       28.9929
trainer/Bellman Errors 2 Max      166.67
trainer/Bellman Errors 2 Min        2.04428e-05
trainer/Policy Action Mean          0.0494493
trainer/Policy Action Std           0.208757
trainer/Policy Action Max           0.99988
trainer/Policy Action Min          -0.960434
exploration/num steps total     82900
exploration/num paths total       829
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138256
exploration/Rewards Std             0.0768226
exploration/Rewards Max            -0.00722078
exploration/Rewards Min            -0.493213
exploration/Returns Mean          -13.8256
exploration/Returns Std             0.436457
exploration/Returns Max           -13.3891
exploration/Returns Min           -14.262
exploration/Actions Mean            0.00287576
exploration/Actions Std             0.154416
exploration/Actions Max             1
exploration/Actions Min            -0.984929
exploration/Num Paths               2
exploration/Average Returns       -13.8256
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0862546
evaluation/Rewards Std              0.0306515
evaluation/Rewards Max             -0.0503264
evaluation/Rewards Min             -0.766006
evaluation/Returns Mean            -8.62546
evaluation/Returns Std              0.261134
evaluation/Returns Max             -8.44932
evaluation/Returns Min             -9.14256
evaluation/Actions Mean             0.00595345
evaluation/Actions Std              0.0749653
evaluation/Actions Max              0.999972
evaluation/Actions Min             -0.745779
evaluation/Num Paths                5
evaluation/Average Returns         -8.62546
time/data storing (s)               0.00167558
time/evaluation sampling (s)        0.0836324
time/exploration sampling (s)       0.0429737
time/logging (s)                    0.00453282
time/saving (s)                     0.00394912
time/training (s)                   0.617274
time/epoch (s)                      0.754037
time/total (s)                    246.145
Epoch                             413
-----------------------------  ----------------
2019-04-13 17:02:42.098295 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 414 finished
-----------------------------  ----------------
replay_buffer/size              83100
trainer/QF1 Loss                    0.0295238
trainer/QF2 Loss                    0.02948
trainer/Policy Loss                12.7739
trainer/Q1 Predictions Mean       -12.9431
trainer/Q1 Predictions Std          0.18615
trainer/Q1 Predictions Max        -12.764
trainer/Q1 Predictions Min        -13.8032
trainer/Q2 Predictions Mean       -12.9481
trainer/Q2 Predictions Std          0.184381
trainer/Q2 Predictions Max        -12.7804
trainer/Q2 Predictions Min        -13.8096
trainer/Q Targets Mean            -13.0213
trainer/Q Targets Std               0.222712
trainer/Q Targets Max             -12.6846
trainer/Q Targets Min             -13.6357
trainer/Bellman Errors 1 Mean       0.0295238
trainer/Bellman Errors 1 Std        0.0448879
trainer/Bellman Errors 1 Max        0.171905
trainer/Bellman Errors 1 Min        6.37729e-06
trainer/Bellman Errors 2 Mean       0.02948
trainer/Bellman Errors 2 Std        0.0441162
trainer/Bellman Errors 2 Max        0.162004
trainer/Bellman Errors 2 Min        1.0055e-05
trainer/Policy Action Mean          0.00151925
trainer/Policy Action Std           0.127983
trainer/Policy Action Max           0.469582
trainer/Policy Action Min          -0.469711
exploration/num steps total     83100
exploration/num paths total       831
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143322
exploration/Rewards Std             0.0818539
exploration/Rewards Max            -0.00927773
exploration/Rewards Min            -0.638246
exploration/Returns Mean          -14.3322
exploration/Returns Std             0.408983
exploration/Returns Max           -13.9233
exploration/Returns Min           -14.7412
exploration/Actions Mean            0.005545
exploration/Actions Std             0.173318
exploration/Actions Max             1
exploration/Actions Min            -0.987153
exploration/Num Paths               2
exploration/Average Returns       -14.3322
evaluation/num steps total     207500
evaluation/num paths total       2075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0696493
evaluation/Rewards Std              0.0216298
evaluation/Rewards Max             -0.0531426
evaluation/Rewards Min             -0.536147
evaluation/Returns Mean            -6.96493
evaluation/Returns Std              0.183623
evaluation/Returns Max             -6.82469
evaluation/Returns Min             -7.32666
evaluation/Actions Mean             0.0045516
evaluation/Actions Std              0.0633765
evaluation/Actions Max              0.999786
evaluation/Actions Min             -0.80127
evaluation/Num Paths                5
evaluation/Average Returns         -6.96493
time/data storing (s)               0.00127818
time/evaluation sampling (s)        0.129023
time/exploration sampling (s)       0.0388371
time/logging (s)                    0.00248103
time/saving (s)                     0.00227853
time/training (s)                   0.788068
time/epoch (s)                      0.961966
time/total (s)                    247.113
Epoch                             414
-----------------------------  ----------------
2019-04-13 17:02:42.930887 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 415 finished
-----------------------------  ----------------
replay_buffer/size              83300
trainer/QF1 Loss                    0.0328544
trainer/QF2 Loss                    0.0313198
trainer/Policy Loss                12.8869
trainer/Q1 Predictions Mean       -13.0846
trainer/Q1 Predictions Std          0.619381
trainer/Q1 Predictions Max        -12.7627
trainer/Q1 Predictions Min        -15.4743
trainer/Q2 Predictions Mean       -13.0816
trainer/Q2 Predictions Std          0.622335
trainer/Q2 Predictions Max        -12.7661
trainer/Q2 Predictions Min        -15.5673
trainer/Q Targets Mean            -13.1487
trainer/Q Targets Std               0.590805
trainer/Q Targets Max             -12.7409
trainer/Q Targets Min             -15.6118
trainer/Bellman Errors 1 Mean       0.0328544
trainer/Bellman Errors 1 Std        0.044476
trainer/Bellman Errors 1 Max        0.217193
trainer/Bellman Errors 1 Min        1.0925e-06
trainer/Bellman Errors 2 Mean       0.0313198
trainer/Bellman Errors 2 Std        0.0497462
trainer/Bellman Errors 2 Max        0.258207
trainer/Bellman Errors 2 Min        0.000699813
trainer/Policy Action Mean          0.0896629
trainer/Policy Action Std           0.292988
trainer/Policy Action Max           0.999967
trainer/Policy Action Min          -0.606739
exploration/num steps total     83300
exploration/num paths total       833
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.180026
exploration/Rewards Std             0.113041
exploration/Rewards Max            -0.0204894
exploration/Rewards Min            -0.98916
exploration/Returns Mean          -18.0026
exploration/Returns Std             0.408698
exploration/Returns Max           -17.5939
exploration/Returns Min           -18.4113
exploration/Actions Mean            0.00888739
exploration/Actions Std             0.187476
exploration/Actions Max             1
exploration/Actions Min            -0.95482
exploration/Num Paths               2
exploration/Average Returns       -18.0026
evaluation/num steps total     208000
evaluation/num paths total       2080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.115822
evaluation/Rewards Std              0.0452304
evaluation/Rewards Max             -0.0681652
evaluation/Rewards Min             -0.899562
evaluation/Returns Mean           -11.5822
evaluation/Returns Std              0.289394
evaluation/Returns Max            -11.2158
evaluation/Returns Min            -12.0157
evaluation/Actions Mean             0.00729031
evaluation/Actions Std              0.0813002
evaluation/Actions Max              0.999986
evaluation/Actions Min             -0.533656
evaluation/Num Paths                5
evaluation/Average Returns        -11.5822
time/data storing (s)               0.00157623
time/evaluation sampling (s)        0.224088
time/exploration sampling (s)       0.124259
time/logging (s)                    0.00249937
time/saving (s)                     0.0037314
time/training (s)                   0.466167
time/epoch (s)                      0.82232
time/total (s)                    247.939
Epoch                             415
-----------------------------  ----------------
2019-04-13 17:02:43.590231 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 416 finished
-----------------------------  ----------------
replay_buffer/size              83500
trainer/QF1 Loss                    0.0431979
trainer/QF2 Loss                    0.0461597
trainer/Policy Loss                12.8086
trainer/Q1 Predictions Mean       -12.9019
trainer/Q1 Predictions Std          0.183266
trainer/Q1 Predictions Max        -12.7691
trainer/Q1 Predictions Min        -13.8189
trainer/Q2 Predictions Mean       -12.8905
trainer/Q2 Predictions Std          0.181391
trainer/Q2 Predictions Max        -12.7493
trainer/Q2 Predictions Min        -13.7866
trainer/Q Targets Mean            -12.957
trainer/Q Targets Std               0.225207
trainer/Q Targets Max             -12.6981
trainer/Q Targets Min             -13.5255
trainer/Bellman Errors 1 Mean       0.0431979
trainer/Bellman Errors 1 Std        0.0880132
trainer/Bellman Errors 1 Max        0.454305
trainer/Bellman Errors 1 Min        1.86225e-05
trainer/Bellman Errors 2 Mean       0.0461597
trainer/Bellman Errors 2 Std        0.0945554
trainer/Bellman Errors 2 Max        0.478029
trainer/Bellman Errors 2 Min        3.04058e-05
trainer/Policy Action Mean          0.0110409
trainer/Policy Action Std           0.143498
trainer/Policy Action Max           0.594067
trainer/Policy Action Min          -0.544055
exploration/num steps total     83500
exploration/num paths total       835
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128718
exploration/Rewards Std             0.0789586
exploration/Rewards Max            -0.00072876
exploration/Rewards Min            -0.367364
exploration/Returns Mean          -12.8718
exploration/Returns Std             0.040259
exploration/Returns Max           -12.8315
exploration/Returns Min           -12.912
exploration/Actions Mean            0.0013969
exploration/Actions Std             0.146839
exploration/Actions Max             0.51399
exploration/Actions Min            -0.402499
exploration/Num Paths               2
exploration/Average Returns       -12.8718
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.037796
evaluation/Rewards Std              0.0526049
evaluation/Rewards Max             -0.0327836
evaluation/Rewards Min             -0.878626
evaluation/Returns Mean            -3.7796
evaluation/Returns Std              0.292056
evaluation/Returns Max             -3.39812
evaluation/Returns Min             -4.17077
evaluation/Actions Mean             0.006269
evaluation/Actions Std              0.0941668
evaluation/Actions Max              0.999987
evaluation/Actions Min             -0.982811
evaluation/Num Paths                5
evaluation/Average Returns         -3.7796
time/data storing (s)               0.00157003
time/evaluation sampling (s)        0.0845239
time/exploration sampling (s)       0.0374798
time/logging (s)                    0.00249415
time/saving (s)                     0.00239707
time/training (s)                   0.520997
time/epoch (s)                      0.649462
time/total (s)                    248.593
Epoch                             416
-----------------------------  ----------------
2019-04-13 17:02:44.439194 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 417 finished
-----------------------------  ----------------
replay_buffer/size              83700
trainer/QF1 Loss                   10.3207
trainer/QF2 Loss                   10.3052
trainer/Policy Loss                12.7186
trainer/Q1 Predictions Mean       -12.9778
trainer/Q1 Predictions Std          0.365927
trainer/Q1 Predictions Max        -12.7734
trainer/Q1 Predictions Min        -14.9255
trainer/Q2 Predictions Mean       -12.9761
trainer/Q2 Predictions Std          0.369292
trainer/Q2 Predictions Max        -12.755
trainer/Q2 Predictions Min        -14.9463
trainer/Q Targets Mean            -12.2803
trainer/Q Targets Std               3.19263
trainer/Q Targets Max              -0.03845
trainer/Q Targets Min             -15.491
trainer/Bellman Errors 1 Mean      10.3207
trainer/Bellman Errors 1 Std       39.8073
trainer/Bellman Errors 1 Max      164.992
trainer/Bellman Errors 1 Min        3.38076e-06
trainer/Bellman Errors 2 Mean      10.3052
trainer/Bellman Errors 2 Std       39.7407
trainer/Bellman Errors 2 Max      164.646
trainer/Bellman Errors 2 Min        0.000129162
trainer/Policy Action Mean          0.102602
trainer/Policy Action Std           0.232797
trainer/Policy Action Max           0.999898
trainer/Policy Action Min          -0.281708
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.146077
exploration/Rewards Std             0.073583
exploration/Rewards Max            -0.00824799
exploration/Rewards Min            -0.436585
exploration/Returns Mean          -14.6077
exploration/Returns Std             0.314963
exploration/Returns Max           -14.2927
exploration/Returns Min           -14.9227
exploration/Actions Mean            0.00396298
exploration/Actions Std             0.168038
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.6077
evaluation/num steps total     209000
evaluation/num paths total       2090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.065212
evaluation/Rewards Std              0.0175591
evaluation/Rewards Max             -0.0457799
evaluation/Rewards Min             -0.305272
evaluation/Returns Mean            -6.5212
evaluation/Returns Std              0.0670554
evaluation/Returns Max             -6.39707
evaluation/Returns Min             -6.58663
evaluation/Actions Mean             0.00142235
evaluation/Actions Std              0.0777456
evaluation/Actions Max              0.996864
evaluation/Actions Min             -0.998429
evaluation/Num Paths                5
evaluation/Average Returns         -6.5212
time/data storing (s)               0.00200518
time/evaluation sampling (s)        0.17706
time/exploration sampling (s)       0.102871
time/logging (s)                    0.00251447
time/saving (s)                     0.00241829
time/training (s)                   0.55091
time/epoch (s)                      0.837779
time/total (s)                    249.435
Epoch                             417
-----------------------------  ----------------
2019-04-13 17:02:45.064152 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 418 finished
-----------------------------  ----------------
replay_buffer/size              83900
trainer/QF1 Loss                    0.0359247
trainer/QF2 Loss                    0.0361535
trainer/Policy Loss                12.9123
trainer/Q1 Predictions Mean       -13.0629
trainer/Q1 Predictions Std          0.142446
trainer/Q1 Predictions Max        -12.892
trainer/Q1 Predictions Min        -13.6316
trainer/Q2 Predictions Mean       -13.0647
trainer/Q2 Predictions Std          0.144899
trainer/Q2 Predictions Max        -12.8944
trainer/Q2 Predictions Min        -13.6418
trainer/Q Targets Mean            -13.0717
trainer/Q Targets Std               0.27219
trainer/Q Targets Max             -12.685
trainer/Q Targets Min             -13.9686
trainer/Bellman Errors 1 Mean       0.0359247
trainer/Bellman Errors 1 Std        0.0365096
trainer/Bellman Errors 1 Max        0.15258
trainer/Bellman Errors 1 Min        0.000329711
trainer/Bellman Errors 2 Mean       0.0361535
trainer/Bellman Errors 2 Std        0.0363713
trainer/Bellman Errors 2 Max        0.155251
trainer/Bellman Errors 2 Min        3.79547e-07
trainer/Policy Action Mean         -0.0161135
trainer/Policy Action Std           0.174403
trainer/Policy Action Max           0.99996
trainer/Policy Action Min          -0.614695
exploration/num steps total     83900
exploration/num paths total       839
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.123463
exploration/Rewards Std             0.0728598
exploration/Rewards Max            -0.0126963
exploration/Rewards Min            -0.395339
exploration/Returns Mean          -12.3463
exploration/Returns Std             0.602803
exploration/Returns Max           -11.7435
exploration/Returns Min           -12.9491
exploration/Actions Mean            0.0096505
exploration/Actions Std             0.171357
exploration/Actions Max             1
exploration/Actions Min            -0.485845
exploration/Num Paths               2
exploration/Average Returns       -12.3463
evaluation/num steps total     209500
evaluation/num paths total       2095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0395569
evaluation/Rewards Std              0.052205
evaluation/Rewards Max             -0.0343392
evaluation/Rewards Min             -0.94189
evaluation/Returns Mean            -3.95569
evaluation/Returns Std              0.375095
evaluation/Returns Max             -3.64549
evaluation/Returns Min             -4.49814
evaluation/Actions Mean             0.00821633
evaluation/Actions Std              0.0809068
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.104752
evaluation/Num Paths                5
evaluation/Average Returns         -3.95569
time/data storing (s)               0.00116007
time/evaluation sampling (s)        0.0808939
time/exploration sampling (s)       0.0357316
time/logging (s)                    0.00243218
time/saving (s)                     0.0018174
time/training (s)                   0.492255
time/epoch (s)                      0.61429
time/total (s)                    250.054
Epoch                             418
-----------------------------  ----------------
2019-04-13 17:02:45.705035 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 419 finished
-----------------------------  ----------------
replay_buffer/size              84100
trainer/QF1 Loss                    4.98006
trainer/QF2 Loss                    4.97061
trainer/Policy Loss                12.5368
trainer/Q1 Predictions Mean       -12.6584
trainer/Q1 Predictions Std          0.0883497
trainer/Q1 Predictions Max        -12.5331
trainer/Q1 Predictions Min        -12.8778
trainer/Q2 Predictions Mean       -12.6666
trainer/Q2 Predictions Std          0.0842765
trainer/Q2 Predictions Max        -12.5424
trainer/Q2 Predictions Min        -12.853
trainer/Q Targets Mean            -12.5859
trainer/Q Targets Std               2.23418
trainer/Q Targets Max              -0.177796
trainer/Q Targets Min             -13.2381
trainer/Bellman Errors 1 Mean       4.98006
trainer/Bellman Errors 1 Std       27.0153
trainer/Bellman Errors 1 Max      155.394
trainer/Bellman Errors 1 Min        0.00799344
trainer/Bellman Errors 2 Mean       4.97061
trainer/Bellman Errors 2 Std       26.9943
trainer/Bellman Errors 2 Max      155.268
trainer/Bellman Errors 2 Min        0.00545983
trainer/Policy Action Mean         -0.00186973
trainer/Policy Action Std           0.123503
trainer/Policy Action Max           0.262213
trainer/Policy Action Min          -0.307529
exploration/num steps total     84100
exploration/num paths total       841
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133279
exploration/Rewards Std             0.0699442
exploration/Rewards Max            -0.00997815
exploration/Rewards Min            -0.351879
exploration/Returns Mean          -13.3279
exploration/Returns Std             0.315824
exploration/Returns Max           -13.0121
exploration/Returns Min           -13.6437
exploration/Actions Mean           -0.000700188
exploration/Actions Std             0.170345
exploration/Actions Max             0.613302
exploration/Actions Min            -0.940707
exploration/Num Paths               2
exploration/Average Returns       -13.3279
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0335564
evaluation/Rewards Std              0.0274095
evaluation/Rewards Max             -0.0262285
evaluation/Rewards Min             -0.55438
evaluation/Returns Mean            -3.35564
evaluation/Returns Std              0.185535
evaluation/Returns Max             -3.15103
evaluation/Returns Min             -3.67735
evaluation/Actions Mean             0.00707661
evaluation/Actions Std              0.0757697
evaluation/Actions Max              0.999733
evaluation/Actions Min             -0.15307
evaluation/Num Paths                5
evaluation/Average Returns         -3.35564
time/data storing (s)               0.00116737
time/evaluation sampling (s)        0.0956467
time/exploration sampling (s)       0.0359307
time/logging (s)                    0.00248142
time/saving (s)                     0.00223744
time/training (s)                   0.493059
time/epoch (s)                      0.630523
time/total (s)                    250.689
Epoch                             419
-----------------------------  ----------------
2019-04-13 17:02:46.425171 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 420 finished
-----------------------------  ----------------
replay_buffer/size              84300
trainer/QF1 Loss                    9.95993
trainer/QF2 Loss                    9.93201
trainer/Policy Loss                12.5828
trainer/Q1 Predictions Mean       -12.6684
trainer/Q1 Predictions Std          0.0604632
trainer/Q1 Predictions Max        -12.568
trainer/Q1 Predictions Min        -12.84
trainer/Q2 Predictions Mean       -12.6618
trainer/Q2 Predictions Std          0.0661695
trainer/Q2 Predictions Max        -12.5544
trainer/Q2 Predictions Min        -12.8564
trainer/Q Targets Mean            -12.1423
trainer/Q Targets Std               3.11989
trainer/Q Targets Max              -0.060222
trainer/Q Targets Min             -13.5215
trainer/Bellman Errors 1 Mean       9.95993
trainer/Bellman Errors 1 Std       38.1922
trainer/Bellman Errors 1 Max      159.47
trainer/Bellman Errors 1 Min        0.000592188
trainer/Bellman Errors 2 Mean       9.93201
trainer/Bellman Errors 2 Std       38.0734
trainer/Bellman Errors 2 Max      158.448
trainer/Bellman Errors 2 Min        0.000534575
trainer/Policy Action Mean          0.0301854
trainer/Policy Action Std           0.131254
trainer/Policy Action Max           0.373689
trainer/Policy Action Min          -0.483703
exploration/num steps total     84300
exploration/num paths total       843
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.139238
exploration/Rewards Std             0.0711433
exploration/Rewards Max            -0.0117346
exploration/Rewards Min            -0.391288
exploration/Returns Mean          -13.9238
exploration/Returns Std             0.719791
exploration/Returns Max           -13.204
exploration/Returns Min           -14.6436
exploration/Actions Mean            0.00157043
exploration/Actions Std             0.1576
exploration/Actions Max             1
exploration/Actions Min            -0.587812
exploration/Num Paths               2
exploration/Average Returns       -13.9238
evaluation/num steps total     210500
evaluation/num paths total       2105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0617926
evaluation/Rewards Std              0.0202219
evaluation/Rewards Max             -0.0119959
evaluation/Rewards Min             -0.49463
evaluation/Returns Mean            -6.17926
evaluation/Returns Std              0.16527
evaluation/Returns Max             -6.02348
evaluation/Returns Min             -6.49536
evaluation/Actions Mean             0.00664247
evaluation/Actions Std              0.0780355
evaluation/Actions Max              0.999864
evaluation/Actions Min             -0.363516
evaluation/Num Paths                5
evaluation/Average Returns         -6.17926
time/data storing (s)               0.00123475
time/evaluation sampling (s)        0.0825711
time/exploration sampling (s)       0.0362775
time/logging (s)                    0.00215391
time/saving (s)                     0.00185182
time/training (s)                   0.585651
time/epoch (s)                      0.70974
time/total (s)                    251.402
Epoch                             420
-----------------------------  ----------------
2019-04-13 17:02:47.071228 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 421 finished
-----------------------------  ----------------
replay_buffer/size              84500
trainer/QF1 Loss                    0.0307014
trainer/QF2 Loss                    0.0300256
trainer/Policy Loss                12.7739
trainer/Q1 Predictions Mean       -12.9869
trainer/Q1 Predictions Std          0.14715
trainer/Q1 Predictions Max        -12.7966
trainer/Q1 Predictions Min        -13.3562
trainer/Q2 Predictions Mean       -12.9882
trainer/Q2 Predictions Std          0.136009
trainer/Q2 Predictions Max        -12.811
trainer/Q2 Predictions Min        -13.3094
trainer/Q Targets Mean            -13.0159
trainer/Q Targets Std               0.176222
trainer/Q Targets Max             -12.6319
trainer/Q Targets Min             -13.3946
trainer/Bellman Errors 1 Mean       0.0307014
trainer/Bellman Errors 1 Std        0.0456968
trainer/Bellman Errors 1 Max        0.196685
trainer/Bellman Errors 1 Min        4.07992e-06
trainer/Bellman Errors 2 Mean       0.0300256
trainer/Bellman Errors 2 Std        0.0442619
trainer/Bellman Errors 2 Max        0.182474
trainer/Bellman Errors 2 Min        1.56317e-06
trainer/Policy Action Mean         -0.0222166
trainer/Policy Action Std           0.158315
trainer/Policy Action Max           0.408337
trainer/Policy Action Min          -0.402756
exploration/num steps total     84500
exploration/num paths total       845
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.145144
exploration/Rewards Std             0.0909146
exploration/Rewards Max            -0.00686946
exploration/Rewards Min            -0.90393
exploration/Returns Mean          -14.5144
exploration/Returns Std             0.702367
exploration/Returns Max           -13.812
exploration/Returns Min           -15.2168
exploration/Actions Mean            0.00683902
exploration/Actions Std             0.16525
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.5144
evaluation/num steps total     211000
evaluation/num paths total       2110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.075845
evaluation/Rewards Std              0.0403396
evaluation/Rewards Max             -0.0600509
evaluation/Rewards Min             -0.896003
evaluation/Returns Mean            -7.5845
evaluation/Returns Std              0.302123
evaluation/Returns Max             -7.31261
evaluation/Returns Min             -8.14359
evaluation/Actions Mean             0.00374259
evaluation/Actions Std              0.0823557
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.992745
evaluation/Num Paths                5
evaluation/Average Returns         -7.5845
time/data storing (s)               0.00116588
time/evaluation sampling (s)        0.0872693
time/exploration sampling (s)       0.036814
time/logging (s)                    0.00238428
time/saving (s)                     0.00222086
time/training (s)                   0.506741
time/epoch (s)                      0.636595
time/total (s)                    252.043
Epoch                             421
-----------------------------  ----------------
2019-04-13 17:02:47.710518 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 422 finished
-----------------------------  ----------------
replay_buffer/size              84700
trainer/QF1 Loss                    0.0218988
trainer/QF2 Loss                    0.0214029
trainer/Policy Loss                12.8505
trainer/Q1 Predictions Mean       -13.067
trainer/Q1 Predictions Std          0.364891
trainer/Q1 Predictions Max        -12.8125
trainer/Q1 Predictions Min        -14.5514
trainer/Q2 Predictions Mean       -13.0637
trainer/Q2 Predictions Std          0.359218
trainer/Q2 Predictions Max        -12.8206
trainer/Q2 Predictions Min        -14.5651
trainer/Q Targets Mean            -13.0429
trainer/Q Targets Std               0.319908
trainer/Q Targets Max             -12.7118
trainer/Q Targets Min             -14.3067
trainer/Bellman Errors 1 Mean       0.0218988
trainer/Bellman Errors 1 Std        0.0261719
trainer/Bellman Errors 1 Max        0.112419
trainer/Bellman Errors 1 Min        0.00039201
trainer/Bellman Errors 2 Mean       0.0214029
trainer/Bellman Errors 2 Std        0.0233452
trainer/Bellman Errors 2 Max        0.0980835
trainer/Bellman Errors 2 Min        0.000445333
trainer/Policy Action Mean          0.000340857
trainer/Policy Action Std           0.226567
trainer/Policy Action Max           0.999998
trainer/Policy Action Min          -0.999993
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.148908
exploration/Rewards Std             0.0766101
exploration/Rewards Max            -0.0120363
exploration/Rewards Min            -0.584381
exploration/Returns Mean          -14.8908
exploration/Returns Std             0.304194
exploration/Returns Max           -14.5866
exploration/Returns Min           -15.195
exploration/Actions Mean            0.000371637
exploration/Actions Std             0.17267
exploration/Actions Max             0.769689
exploration/Actions Min            -0.917637
exploration/Num Paths               2
exploration/Average Returns       -14.8908
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0631653
evaluation/Rewards Std              0.0331442
evaluation/Rewards Max             -0.00976638
evaluation/Rewards Min             -0.670663
evaluation/Returns Mean            -6.31653
evaluation/Returns Std              0.236215
evaluation/Returns Max             -6.07748
evaluation/Returns Min             -6.724
evaluation/Actions Mean             0.00289944
evaluation/Actions Std              0.0693756
evaluation/Actions Max              0.999969
evaluation/Actions Min             -0.913683
evaluation/Num Paths                5
evaluation/Average Returns         -6.31653
time/data storing (s)               0.00112973
time/evaluation sampling (s)        0.0773076
time/exploration sampling (s)       0.0354206
time/logging (s)                    0.00247859
time/saving (s)                     0.00249075
time/training (s)                   0.510515
time/epoch (s)                      0.629343
time/total (s)                    252.677
Epoch                             422
-----------------------------  ----------------
2019-04-13 17:02:48.311949 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 423 finished
-----------------------------  ----------------
replay_buffer/size              84900
trainer/QF1 Loss                    0.0539057
trainer/QF2 Loss                    0.0456646
trainer/Policy Loss                12.7149
trainer/Q1 Predictions Mean       -12.845
trainer/Q1 Predictions Std          0.087422
trainer/Q1 Predictions Max        -12.7141
trainer/Q1 Predictions Min        -13.0497
trainer/Q2 Predictions Mean       -12.8721
trainer/Q2 Predictions Std          0.092825
trainer/Q2 Predictions Max        -12.7613
trainer/Q2 Predictions Min        -13.1214
trainer/Q Targets Mean            -13.0188
trainer/Q Targets Std               0.148933
trainer/Q Targets Max             -12.7644
trainer/Q Targets Min             -13.2808
trainer/Bellman Errors 1 Mean       0.0539057
trainer/Bellman Errors 1 Std        0.0689347
trainer/Bellman Errors 1 Max        0.28435
trainer/Bellman Errors 1 Min        0.000194692
trainer/Bellman Errors 2 Mean       0.0456646
trainer/Bellman Errors 2 Std        0.0618927
trainer/Bellman Errors 2 Max        0.256752
trainer/Bellman Errors 2 Min        5.24742e-06
trainer/Policy Action Mean          0.0159138
trainer/Policy Action Std           0.131331
trainer/Policy Action Max           0.433802
trainer/Policy Action Min          -0.305143
exploration/num steps total     84900
exploration/num paths total       849
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140719
exploration/Rewards Std             0.0728374
exploration/Rewards Max            -0.0171896
exploration/Rewards Min            -0.349024
exploration/Returns Mean          -14.0719
exploration/Returns Std             0.313737
exploration/Returns Max           -13.7581
exploration/Returns Min           -14.3856
exploration/Actions Mean            0.00354141
exploration/Actions Std             0.158982
exploration/Actions Max             1
exploration/Actions Min            -0.962854
exploration/Num Paths               2
exploration/Average Returns       -14.0719
evaluation/num steps total     212000
evaluation/num paths total       2120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0707156
evaluation/Rewards Std              0.00941563
evaluation/Rewards Max             -0.0450667
evaluation/Rewards Min             -0.247093
evaluation/Returns Mean            -7.07156
evaluation/Returns Std              0.0576702
evaluation/Returns Max             -7.00563
evaluation/Returns Min             -7.16764
evaluation/Actions Mean             0.00374463
evaluation/Actions Std              0.0744231
evaluation/Actions Max              0.99919
evaluation/Actions Min             -0.998639
evaluation/Num Paths                5
evaluation/Average Returns         -7.07156
time/data storing (s)               0.00110383
time/evaluation sampling (s)        0.0886175
time/exploration sampling (s)       0.0349512
time/logging (s)                    0.00246363
time/saving (s)                     0.00230528
time/training (s)                   0.462354
time/epoch (s)                      0.591795
time/total (s)                    253.272
Epoch                             423
-----------------------------  ----------------
2019-04-13 17:02:48.959750 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 424 finished
-----------------------------  ----------------
replay_buffer/size              85100
trainer/QF1 Loss                    5.11548
trainer/QF2 Loss                    5.1064
trainer/Policy Loss                12.7202
trainer/Q1 Predictions Mean       -12.8633
trainer/Q1 Predictions Std          0.152062
trainer/Q1 Predictions Max        -12.7356
trainer/Q1 Predictions Min        -13.5704
trainer/Q2 Predictions Mean       -12.8737
trainer/Q2 Predictions Std          0.14238
trainer/Q2 Predictions Max        -12.7666
trainer/Q2 Predictions Min        -13.5282
trainer/Q Targets Mean            -12.5419
trainer/Q Targets Std               2.25029
trainer/Q Targets Max              -0.0569517
trainer/Q Targets Min             -13.512
trainer/Bellman Errors 1 Mean       5.11548
trainer/Bellman Errors 1 Std       28.3328
trainer/Bellman Errors 1 Max      162.866
trainer/Bellman Errors 1 Min        6.11246e-05
trainer/Bellman Errors 2 Mean       5.1064
trainer/Bellman Errors 2 Std       28.2988
trainer/Bellman Errors 2 Max      162.667
trainer/Bellman Errors 2 Min        7.77345e-05
trainer/Policy Action Mean         -0.00409077
trainer/Policy Action Std           0.13046
trainer/Policy Action Max           0.525131
trainer/Policy Action Min          -0.453817
exploration/num steps total     85100
exploration/num paths total       851
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126282
exploration/Rewards Std             0.0654654
exploration/Rewards Max            -0.0143263
exploration/Rewards Min            -0.366563
exploration/Returns Mean          -12.6282
exploration/Returns Std             0.135394
exploration/Returns Max           -12.4928
exploration/Returns Min           -12.7636
exploration/Actions Mean            0.00721804
exploration/Actions Std             0.157962
exploration/Actions Max             1
exploration/Actions Min            -0.353244
exploration/Num Paths               2
exploration/Average Returns       -12.6282
evaluation/num steps total     212500
evaluation/num paths total       2125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0222192
evaluation/Rewards Std              0.0505585
evaluation/Rewards Max             -0.0105143
evaluation/Rewards Min             -0.945762
evaluation/Returns Mean            -2.22192
evaluation/Returns Std              0.347471
evaluation/Returns Max             -1.84661
evaluation/Returns Min             -2.781
evaluation/Actions Mean             0.00543595
evaluation/Actions Std              0.0879116
evaluation/Actions Max              1
evaluation/Actions Min             -0.994118
evaluation/Num Paths                5
evaluation/Average Returns         -2.22192
time/data storing (s)               0.00106334
time/evaluation sampling (s)        0.0707531
time/exploration sampling (s)       0.0332519
time/logging (s)                    0.00256828
time/saving (s)                     0.00227507
time/training (s)                   0.527879
time/epoch (s)                      0.637791
time/total (s)                    253.914
Epoch                             424
-----------------------------  ----------------
2019-04-13 17:02:49.580712 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 425 finished
-----------------------------  ----------------
replay_buffer/size              85300
trainer/QF1 Loss                    0.145335
trainer/QF2 Loss                    0.147324
trainer/Policy Loss                12.6037
trainer/Q1 Predictions Mean       -12.7166
trainer/Q1 Predictions Std          0.090681
trainer/Q1 Predictions Max        -12.5844
trainer/Q1 Predictions Min        -12.9669
trainer/Q2 Predictions Mean       -12.7154
trainer/Q2 Predictions Std          0.0885953
trainer/Q2 Predictions Max        -12.587
trainer/Q2 Predictions Min        -12.9412
trainer/Q Targets Mean            -13.0378
trainer/Q Targets Std               0.220941
trainer/Q Targets Max             -12.7245
trainer/Q Targets Min             -13.7365
trainer/Bellman Errors 1 Mean       0.145335
trainer/Bellman Errors 1 Std        0.178505
trainer/Bellman Errors 1 Max        0.784215
trainer/Bellman Errors 1 Min        0.00122359
trainer/Bellman Errors 2 Mean       0.147324
trainer/Bellman Errors 2 Std        0.178013
trainer/Bellman Errors 2 Max        0.766278
trainer/Bellman Errors 2 Min        0.000650314
trainer/Policy Action Mean          0.014835
trainer/Policy Action Std           0.0933784
trainer/Policy Action Max           0.169676
trainer/Policy Action Min          -0.246833
exploration/num steps total     85300
exploration/num paths total       853
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129215
exploration/Rewards Std             0.0659762
exploration/Rewards Max            -0.00994591
exploration/Rewards Min            -0.315158
exploration/Returns Mean          -12.9215
exploration/Returns Std             0.364015
exploration/Returns Max           -12.5574
exploration/Returns Min           -13.2855
exploration/Actions Mean            0.00524603
exploration/Actions Std             0.150943
exploration/Actions Max             0.953483
exploration/Actions Min            -0.397693
exploration/Num Paths               2
exploration/Average Returns       -12.9215
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0638351
evaluation/Rewards Std              0.0438337
evaluation/Rewards Max             -0.0467442
evaluation/Rewards Min             -1.00127
evaluation/Returns Mean            -6.38351
evaluation/Returns Std              0.345748
evaluation/Returns Max             -6.12292
evaluation/Returns Min             -7.03951
evaluation/Actions Mean             0.00659856
evaluation/Actions Std              0.0848702
evaluation/Actions Max              1
evaluation/Actions Min             -0.850027
evaluation/Num Paths                5
evaluation/Average Returns         -6.38351
time/data storing (s)               0.00119839
time/evaluation sampling (s)        0.0935476
time/exploration sampling (s)       0.0349886
time/logging (s)                    0.00243663
time/saving (s)                     0.0018059
time/training (s)                   0.476999
time/epoch (s)                      0.610976
time/total (s)                    254.529
Epoch                             425
-----------------------------  ----------------
2019-04-13 17:02:50.181586 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 426 finished
-----------------------------  ----------------
replay_buffer/size              85500
trainer/QF1 Loss                    0.084366
trainer/QF2 Loss                    0.0941956
trainer/Policy Loss                13.0507
trainer/Q1 Predictions Mean       -13.2853
trainer/Q1 Predictions Std          0.494129
trainer/Q1 Predictions Max        -13.0081
trainer/Q1 Predictions Min        -15.4241
trainer/Q2 Predictions Mean       -13.3003
trainer/Q2 Predictions Std          0.519397
trainer/Q2 Predictions Max        -13.029
trainer/Q2 Predictions Min        -15.5434
trainer/Q Targets Mean            -13.0494
trainer/Q Targets Std               0.47887
trainer/Q Targets Max             -12.7357
trainer/Q Targets Min             -15.3321
trainer/Bellman Errors 1 Mean       0.084366
trainer/Bellman Errors 1 Std        0.084294
trainer/Bellman Errors 1 Max        0.336368
trainer/Bellman Errors 1 Min        3.86986e-05
trainer/Bellman Errors 2 Mean       0.0941956
trainer/Bellman Errors 2 Std        0.0997267
trainer/Bellman Errors 2 Max        0.449597
trainer/Bellman Errors 2 Min        0.000846224
trainer/Policy Action Mean          0.106084
trainer/Policy Action Std           0.271116
trainer/Policy Action Max           0.997289
trainer/Policy Action Min          -0.40991
exploration/num steps total     85500
exploration/num paths total       855
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.148725
exploration/Rewards Std             0.0742883
exploration/Rewards Max            -0.0101818
exploration/Rewards Min            -0.423481
exploration/Returns Mean          -14.8725
exploration/Returns Std             0.403996
exploration/Returns Max           -14.4685
exploration/Returns Min           -15.2765
exploration/Actions Mean            0.000281029
exploration/Actions Std             0.147841
exploration/Actions Max             0.648546
exploration/Actions Min            -0.980164
exploration/Num Paths               2
exploration/Average Returns       -14.8725
evaluation/num steps total     213500
evaluation/num paths total       2135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0944798
evaluation/Rewards Std              0.0272935
evaluation/Rewards Max             -0.0452769
evaluation/Rewards Min             -0.522383
evaluation/Returns Mean            -9.44798
evaluation/Returns Std              0.186115
evaluation/Returns Max             -9.26033
evaluation/Returns Min             -9.67436
evaluation/Actions Mean             0.00421198
evaluation/Actions Std              0.077271
evaluation/Actions Max              0.999916
evaluation/Actions Min             -0.994197
evaluation/Num Paths                5
evaluation/Average Returns         -9.44798
time/data storing (s)               0.00171623
time/evaluation sampling (s)        0.0764362
time/exploration sampling (s)       0.0354903
time/logging (s)                    0.00248245
time/saving (s)                     0.00228934
time/training (s)                   0.472572
time/epoch (s)                      0.590986
time/total (s)                    255.124
Epoch                             426
-----------------------------  ----------------
2019-04-13 17:02:50.763771 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 427 finished
-----------------------------  ----------------
replay_buffer/size              85700
trainer/QF1 Loss                    0.0783531
trainer/QF2 Loss                    0.0737802
trainer/Policy Loss                12.7293
trainer/Q1 Predictions Mean       -12.8706
trainer/Q1 Predictions Std          0.227755
trainer/Q1 Predictions Max        -12.7022
trainer/Q1 Predictions Min        -13.8559
trainer/Q2 Predictions Mean       -12.8784
trainer/Q2 Predictions Std          0.233111
trainer/Q2 Predictions Max        -12.7236
trainer/Q2 Predictions Min        -13.9076
trainer/Q Targets Mean            -13.0735
trainer/Q Targets Std               0.299431
trainer/Q Targets Max             -12.6828
trainer/Q Targets Min             -14.1885
trainer/Bellman Errors 1 Mean       0.0783531
trainer/Bellman Errors 1 Std        0.117054
trainer/Bellman Errors 1 Max        0.523029
trainer/Bellman Errors 1 Min        0.000114413
trainer/Bellman Errors 2 Mean       0.0737802
trainer/Bellman Errors 2 Std        0.113555
trainer/Bellman Errors 2 Max        0.495781
trainer/Bellman Errors 2 Min        0.000145425
trainer/Policy Action Mean          0.0356745
trainer/Policy Action Std           0.168549
trainer/Policy Action Max           0.999997
trainer/Policy Action Min          -0.393641
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.152022
exploration/Rewards Std             0.10126
exploration/Rewards Max            -0.00625356
exploration/Rewards Min            -0.951789
exploration/Returns Mean          -15.2022
exploration/Returns Std             0.295782
exploration/Returns Max           -14.9064
exploration/Returns Min           -15.498
exploration/Actions Mean            0.00773043
exploration/Actions Std             0.163615
exploration/Actions Max             1
exploration/Actions Min            -0.764148
exploration/Num Paths               2
exploration/Average Returns       -15.2022
evaluation/num steps total     214000
evaluation/num paths total       2140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0921978
evaluation/Rewards Std              0.0125032
evaluation/Rewards Max             -0.0606241
evaluation/Rewards Min             -0.359222
evaluation/Returns Mean            -9.21978
evaluation/Returns Std              0.0907603
evaluation/Returns Max             -9.14644
evaluation/Returns Min             -9.39192
evaluation/Actions Mean             0.00492027
evaluation/Actions Std              0.0760901
evaluation/Actions Max              0.99945
evaluation/Actions Min             -0.64467
evaluation/Num Paths                5
evaluation/Average Returns         -9.21978
time/data storing (s)               0.00113174
time/evaluation sampling (s)        0.0738127
time/exploration sampling (s)       0.0332364
time/logging (s)                    0.00249887
time/saving (s)                     0.00230606
time/training (s)                   0.459092
time/epoch (s)                      0.572078
time/total (s)                    255.7
Epoch                             427
-----------------------------  ----------------
2019-04-13 17:02:51.368637 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 428 finished
-----------------------------  ----------------
replay_buffer/size              85900
trainer/QF1 Loss                    5.14311
trainer/QF2 Loss                    5.1424
trainer/Policy Loss                12.837
trainer/Q1 Predictions Mean       -12.9535
trainer/Q1 Predictions Std          0.0588694
trainer/Q1 Predictions Max        -12.8609
trainer/Q1 Predictions Min        -13.0825
trainer/Q2 Predictions Mean       -12.9527
trainer/Q2 Predictions Std          0.0610533
trainer/Q2 Predictions Max        -12.85
trainer/Q2 Predictions Min        -13.0734
trainer/Q Targets Mean            -12.5288
trainer/Q Targets Std               2.23361
trainer/Q Targets Max              -0.109119
trainer/Q Targets Min             -13.1811
trainer/Bellman Errors 1 Mean       5.14311
trainer/Bellman Errors 1 Std       28.568
trainer/Bellman Errors 1 Max      164.203
trainer/Bellman Errors 1 Min        4.12794e-05
trainer/Bellman Errors 2 Mean       5.1424
trainer/Bellman Errors 2 Std       28.565
trainer/Bellman Errors 2 Max      164.185
trainer/Bellman Errors 2 Min        2.11034e-05
trainer/Policy Action Mean          0.04385
trainer/Policy Action Std           0.117765
trainer/Policy Action Max           0.293746
trainer/Policy Action Min          -0.442016
exploration/num steps total     85900
exploration/num paths total       859
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.14103
exploration/Rewards Std             0.0904028
exploration/Rewards Max            -0.0040453
exploration/Rewards Min            -0.775669
exploration/Returns Mean          -14.103
exploration/Returns Std             0.210541
exploration/Returns Max           -13.8924
exploration/Returns Min           -14.3135
exploration/Actions Mean            0.00649531
exploration/Actions Std             0.163178
exploration/Actions Max             1
exploration/Actions Min            -0.426332
exploration/Num Paths               2
exploration/Average Returns       -14.103
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0750773
evaluation/Rewards Std              0.0373515
evaluation/Rewards Max             -0.0553838
evaluation/Rewards Min             -0.881123
evaluation/Returns Mean            -7.50773
evaluation/Returns Std              0.314276
evaluation/Returns Max             -7.27566
evaluation/Returns Min             -8.11968
evaluation/Actions Mean             0.00448463
evaluation/Actions Std              0.0795755
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.996841
evaluation/Num Paths                5
evaluation/Average Returns         -7.50773
time/data storing (s)               0.00116361
time/evaluation sampling (s)        0.0757438
time/exploration sampling (s)       0.0344486
time/logging (s)                    0.00251411
time/saving (s)                     0.00222943
time/training (s)                   0.47904
time/epoch (s)                      0.59514
time/total (s)                    256.3
Epoch                             428
-----------------------------  ----------------
2019-04-13 17:02:51.972550 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 429 finished
-----------------------------  ----------------
replay_buffer/size              86100
trainer/QF1 Loss                    0.0714647
trainer/QF2 Loss                    0.0736504
trainer/Policy Loss                12.7287
trainer/Q1 Predictions Mean       -12.8793
trainer/Q1 Predictions Std          0.0793528
trainer/Q1 Predictions Max        -12.7319
trainer/Q1 Predictions Min        -13.0024
trainer/Q2 Predictions Mean       -12.8738
trainer/Q2 Predictions Std          0.0884276
trainer/Q2 Predictions Max        -12.7021
trainer/Q2 Predictions Min        -13.0878
trainer/Q Targets Mean            -13.0635
trainer/Q Targets Std               0.197444
trainer/Q Targets Max             -12.7517
trainer/Q Targets Min             -13.6548
trainer/Bellman Errors 1 Mean       0.0714647
trainer/Bellman Errors 1 Std        0.125001
trainer/Bellman Errors 1 Max        0.53885
trainer/Bellman Errors 1 Min        4.1488e-05
trainer/Bellman Errors 2 Mean       0.0736503
trainer/Bellman Errors 2 Std        0.132653
trainer/Bellman Errors 2 Max        0.594588
trainer/Bellman Errors 2 Min        6.83311e-06
trainer/Policy Action Mean          0.0228202
trainer/Policy Action Std           0.161632
trainer/Policy Action Max           0.749112
trainer/Policy Action Min          -0.291082
exploration/num steps total     86100
exploration/num paths total       861
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.149232
exploration/Rewards Std             0.093199
exploration/Rewards Max            -0.0156491
exploration/Rewards Min            -0.84555
exploration/Returns Mean          -14.9232
exploration/Returns Std             0.40506
exploration/Returns Max           -14.5181
exploration/Returns Min           -15.3282
exploration/Actions Mean            0.0128279
exploration/Actions Std             0.167701
exploration/Actions Max             0.988039
exploration/Actions Min            -0.40613
exploration/Num Paths               2
exploration/Average Returns       -14.9232
evaluation/num steps total     215000
evaluation/num paths total       2150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0884232
evaluation/Rewards Std              0.0234044
evaluation/Rewards Max             -0.0454384
evaluation/Rewards Min             -0.566733
evaluation/Returns Mean            -8.84232
evaluation/Returns Std              0.140966
evaluation/Returns Max             -8.71637
evaluation/Returns Min             -9.11159
evaluation/Actions Mean             0.00184636
evaluation/Actions Std              0.0693496
evaluation/Actions Max              0.999941
evaluation/Actions Min             -0.824204
evaluation/Num Paths                5
evaluation/Average Returns         -8.84232
time/data storing (s)               0.0010677
time/evaluation sampling (s)        0.0797139
time/exploration sampling (s)       0.0333936
time/logging (s)                    0.00249111
time/saving (s)                     0.00257213
time/training (s)                   0.474269
time/epoch (s)                      0.593507
time/total (s)                    256.897
Epoch                             429
-----------------------------  ----------------
2019-04-13 17:02:52.753652 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 430 finished
-----------------------------  ----------------
replay_buffer/size              86300
trainer/QF1 Loss                    0.0273542
trainer/QF2 Loss                    0.0296548
trainer/Policy Loss                12.8513
trainer/Q1 Predictions Mean       -12.9894
trainer/Q1 Predictions Std          0.361835
trainer/Q1 Predictions Max        -12.8151
trainer/Q1 Predictions Min        -14.9614
trainer/Q2 Predictions Mean       -12.983
trainer/Q2 Predictions Std          0.371843
trainer/Q2 Predictions Max        -12.801
trainer/Q2 Predictions Min        -15.0122
trainer/Q Targets Mean            -13.0559
trainer/Q Targets Std               0.340707
trainer/Q Targets Max             -12.7266
trainer/Q Targets Min             -14.6944
trainer/Bellman Errors 1 Mean       0.0273542
trainer/Bellman Errors 1 Std        0.046785
trainer/Bellman Errors 1 Max        0.246226
trainer/Bellman Errors 1 Min        1.52141e-07
trainer/Bellman Errors 2 Mean       0.0296548
trainer/Bellman Errors 2 Std        0.0484503
trainer/Bellman Errors 2 Max        0.247737
trainer/Bellman Errors 2 Min        0.000183106
trainer/Policy Action Mean         -0.0295831
trainer/Policy Action Std           0.181418
trainer/Policy Action Max           0.808289
trainer/Policy Action Min          -0.99999
exploration/num steps total     86300
exploration/num paths total       863
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130098
exploration/Rewards Std             0.0829838
exploration/Rewards Max            -0.00336413
exploration/Rewards Min            -0.729824
exploration/Returns Mean          -13.0098
exploration/Returns Std             0.318534
exploration/Returns Max           -12.6913
exploration/Returns Min           -13.3283
exploration/Actions Mean            0.0056451
exploration/Actions Std             0.159569
exploration/Actions Max             1
exploration/Actions Min            -0.741388
exploration/Num Paths               2
exploration/Average Returns       -13.0098
evaluation/num steps total     215500
evaluation/num paths total       2155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0389415
evaluation/Rewards Std              0.0568665
evaluation/Rewards Max             -0.0203368
evaluation/Rewards Min             -0.878032
evaluation/Returns Mean            -3.89415
evaluation/Returns Std              0.339522
evaluation/Returns Max             -3.47036
evaluation/Returns Min             -4.25875
evaluation/Actions Mean             0.00681194
evaluation/Actions Std              0.0841856
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.863775
evaluation/Num Paths                5
evaluation/Average Returns         -3.89415
time/data storing (s)               0.00116817
time/evaluation sampling (s)        0.0781299
time/exploration sampling (s)       0.0358111
time/logging (s)                    0.00266992
time/saving (s)                     0.00191309
time/training (s)                   0.651335
time/epoch (s)                      0.771027
time/total (s)                    257.672
Epoch                             430
-----------------------------  ----------------
2019-04-13 17:02:53.422533 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 431 finished
-----------------------------  ----------------
replay_buffer/size              86500
trainer/QF1 Loss                    5.05479
trainer/QF2 Loss                    5.04406
trainer/Policy Loss                12.5884
trainer/Q1 Predictions Mean       -12.8444
trainer/Q1 Predictions Std          0.393959
trainer/Q1 Predictions Max        -12.6112
trainer/Q1 Predictions Min        -14.9966
trainer/Q2 Predictions Mean       -12.8445
trainer/Q2 Predictions Std          0.357793
trainer/Q2 Predictions Max        -12.6232
trainer/Q2 Predictions Min        -14.7941
trainer/Q Targets Mean            -12.6863
trainer/Q Targets Std               2.28494
trainer/Q Targets Max              -0.15756
trainer/Q Targets Min             -15.1009
trainer/Bellman Errors 1 Mean       5.0548
trainer/Bellman Errors 1 Std       27.6665
trainer/Bellman Errors 1 Max      159.094
trainer/Bellman Errors 1 Min        0.000329469
trainer/Bellman Errors 2 Mean       5.04406
trainer/Bellman Errors 2 Std       27.6219
trainer/Bellman Errors 2 Max      158.835
trainer/Bellman Errors 2 Min        0.00046919
trainer/Policy Action Mean          0.000473773
trainer/Policy Action Std           0.194841
trainer/Policy Action Max           0.993048
trainer/Policy Action Min          -0.999956
exploration/num steps total     86500
exploration/num paths total       865
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.132968
exploration/Rewards Std             0.0653334
exploration/Rewards Max            -0.00285489
exploration/Rewards Min            -0.346689
exploration/Returns Mean          -13.2968
exploration/Returns Std             0.631809
exploration/Returns Max           -12.665
exploration/Returns Min           -13.9286
exploration/Actions Mean            0.00573895
exploration/Actions Std             0.155338
exploration/Actions Max             0.959956
exploration/Actions Min            -0.405754
exploration/Num Paths               2
exploration/Average Returns       -13.2968
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0244858
evaluation/Rewards Std              0.0506907
evaluation/Rewards Max             -0.018718
evaluation/Rewards Min             -0.937323
evaluation/Returns Mean            -2.44858
evaluation/Returns Std              0.305995
evaluation/Returns Max             -2.11057
evaluation/Returns Min             -2.94773
evaluation/Actions Mean             0.00864844
evaluation/Actions Std              0.0878087
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.249914
evaluation/Num Paths                5
evaluation/Average Returns         -2.44858
time/data storing (s)               0.0012001
time/evaluation sampling (s)        0.123948
time/exploration sampling (s)       0.0419676
time/logging (s)                    0.0024867
time/saving (s)                     0.00229853
time/training (s)                   0.486326
time/epoch (s)                      0.658227
time/total (s)                    258.335
Epoch                             431
-----------------------------  ----------------
2019-04-13 17:02:54.052520 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 432 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                    0.279418
trainer/QF2 Loss                    0.271962
trainer/Policy Loss                12.499
trainer/Q1 Predictions Mean       -12.5947
trainer/Q1 Predictions Std          0.135553
trainer/Q1 Predictions Max        -12.4661
trainer/Q1 Predictions Min        -13.2623
trainer/Q2 Predictions Mean       -12.6011
trainer/Q2 Predictions Std          0.13398
trainer/Q2 Predictions Max        -12.4733
trainer/Q2 Predictions Min        -13.2461
trainer/Q Targets Mean            -13.088
trainer/Q Targets Std               0.235547
trainer/Q Targets Max             -12.7097
trainer/Q Targets Min             -13.7728
trainer/Bellman Errors 1 Mean       0.279418
trainer/Bellman Errors 1 Std        0.245826
trainer/Bellman Errors 1 Max        1.33353
trainer/Bellman Errors 1 Min        0.0496536
trainer/Bellman Errors 2 Mean       0.271962
trainer/Bellman Errors 2 Std        0.234431
trainer/Bellman Errors 2 Max        1.23814
trainer/Bellman Errors 2 Min        0.0558834
trainer/Policy Action Mean         -0.0104042
trainer/Policy Action Std           0.113134
trainer/Policy Action Max           0.410518
trainer/Policy Action Min          -0.465481
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137002
exploration/Rewards Std             0.0870296
exploration/Rewards Max            -0.00847393
exploration/Rewards Min            -0.876034
exploration/Returns Mean          -13.7002
exploration/Returns Std             0.302187
exploration/Returns Max           -13.398
exploration/Returns Min           -14.0024
exploration/Actions Mean            0.0102408
exploration/Actions Std             0.164439
exploration/Actions Max             1
exploration/Actions Min            -0.351122
exploration/Num Paths               2
exploration/Average Returns       -13.7002
evaluation/num steps total     216500
evaluation/num paths total       2165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0319785
evaluation/Rewards Std              0.053238
evaluation/Rewards Max             -0.0270159
evaluation/Rewards Min             -0.709153
evaluation/Returns Mean            -3.19785
evaluation/Returns Std              0.242525
evaluation/Returns Max             -2.7452
evaluation/Returns Min             -3.40483
evaluation/Actions Mean             0.00758569
evaluation/Actions Std              0.0831199
evaluation/Actions Max              0.999982
evaluation/Actions Min             -0.607719
evaluation/Num Paths                5
evaluation/Average Returns         -3.19785
time/data storing (s)               0.00113253
time/evaluation sampling (s)        0.0890652
time/exploration sampling (s)       0.0360305
time/logging (s)                    0.00259519
time/saving (s)                     0.00228318
time/training (s)                   0.489126
time/epoch (s)                      0.620233
time/total (s)                    258.959
Epoch                             432
-----------------------------  ---------------
2019-04-13 17:02:54.637677 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 433 finished
-----------------------------  ----------------
replay_buffer/size              86900
trainer/QF1 Loss                    0.0414373
trainer/QF2 Loss                    0.0436937
trainer/Policy Loss                12.8384
trainer/Q1 Predictions Mean       -12.9457
trainer/Q1 Predictions Std          0.272243
trainer/Q1 Predictions Max        -12.7739
trainer/Q1 Predictions Min        -14.3684
trainer/Q2 Predictions Mean       -12.9372
trainer/Q2 Predictions Std          0.275449
trainer/Q2 Predictions Max        -12.7587
trainer/Q2 Predictions Min        -14.3732
trainer/Q Targets Mean            -13.0453
trainer/Q Targets Std               0.324211
trainer/Q Targets Max             -12.7078
trainer/Q Targets Min             -14.4335
trainer/Bellman Errors 1 Mean       0.0414373
trainer/Bellman Errors 1 Std        0.0728475
trainer/Bellman Errors 1 Max        0.282897
trainer/Bellman Errors 1 Min        1.87875e-05
trainer/Bellman Errors 2 Mean       0.0436937
trainer/Bellman Errors 2 Std        0.0760485
trainer/Bellman Errors 2 Max        0.304182
trainer/Bellman Errors 2 Min        0.000118468
trainer/Policy Action Mean          0.0158224
trainer/Policy Action Std           0.162407
trainer/Policy Action Max           0.973942
trainer/Policy Action Min          -0.323488
exploration/num steps total     86900
exploration/num paths total       869
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135655
exploration/Rewards Std             0.0723655
exploration/Rewards Max            -0.0107971
exploration/Rewards Min            -0.389328
exploration/Returns Mean          -13.5655
exploration/Returns Std             0.0371896
exploration/Returns Max           -13.5283
exploration/Returns Min           -13.6027
exploration/Actions Mean            0.00413556
exploration/Actions Std             0.154209
exploration/Actions Max             0.814114
exploration/Actions Min            -0.643374
exploration/Num Paths               2
exploration/Average Returns       -13.5655
evaluation/num steps total     217000
evaluation/num paths total       2170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0455092
evaluation/Rewards Std              0.0255608
evaluation/Rewards Max             -0.00661016
evaluation/Rewards Min             -0.559711
evaluation/Returns Mean            -4.55092
evaluation/Returns Std              0.197122
evaluation/Returns Max             -4.39108
evaluation/Returns Min             -4.90787
evaluation/Actions Mean             0.00567935
evaluation/Actions Std              0.0666963
evaluation/Actions Max              0.999917
evaluation/Actions Min             -0.646127
evaluation/Num Paths                5
evaluation/Average Returns         -4.55092
time/data storing (s)               0.0011762
time/evaluation sampling (s)        0.0939779
time/exploration sampling (s)       0.0380142
time/logging (s)                    0.00260816
time/saving (s)                     0.0022573
time/training (s)                   0.435511
time/epoch (s)                      0.573545
time/total (s)                    259.537
Epoch                             433
-----------------------------  ----------------
2019-04-13 17:02:55.280892 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 434 finished
-----------------------------  ----------------
replay_buffer/size              87100
trainer/QF1 Loss                    5.063
trainer/QF2 Loss                    5.05906
trainer/Policy Loss                12.6563
trainer/Q1 Predictions Mean       -12.856
trainer/Q1 Predictions Std          0.0985107
trainer/Q1 Predictions Max        -12.7121
trainer/Q1 Predictions Min        -13.1063
trainer/Q2 Predictions Mean       -12.8692
trainer/Q2 Predictions Std          0.0990865
trainer/Q2 Predictions Max        -12.7286
trainer/Q2 Predictions Min        -13.1267
trainer/Q Targets Mean            -12.5469
trainer/Q Targets Std               2.23928
trainer/Q Targets Max              -0.0998128
trainer/Q Targets Min             -13.2354
trainer/Bellman Errors 1 Mean       5.063
trainer/Bellman Errors 1 Std       28.0763
trainer/Bellman Errors 1 Max      161.385
trainer/Bellman Errors 1 Min        2.29288e-05
trainer/Bellman Errors 2 Mean       5.05906
trainer/Bellman Errors 2 Std       28.0669
trainer/Bellman Errors 2 Max      161.329
trainer/Bellman Errors 2 Min        4.24334e-08
trainer/Policy Action Mean         -0.0127989
trainer/Policy Action Std           0.0867999
trainer/Policy Action Max           0.156076
trainer/Policy Action Min          -0.245952
exploration/num steps total     87100
exploration/num paths total       871
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.119869
exploration/Rewards Std             0.0634589
exploration/Rewards Max            -0.00302595
exploration/Rewards Min            -0.342423
exploration/Returns Mean          -11.9869
exploration/Returns Std             0.0590501
exploration/Returns Max           -11.9278
exploration/Returns Min           -12.0459
exploration/Actions Mean            0.00183859
exploration/Actions Std             0.145627
exploration/Actions Max             0.997975
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -11.9869
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0148624
evaluation/Rewards Std              0.0454346
evaluation/Rewards Max             -0.00385627
evaluation/Rewards Min             -0.856989
evaluation/Returns Mean            -1.48624
evaluation/Returns Std              0.342088
evaluation/Returns Max             -1.18654
evaluation/Returns Min             -2.03695
evaluation/Actions Mean             0.00399986
evaluation/Actions Std              0.080471
evaluation/Actions Max              0.999987
evaluation/Actions Min             -0.998677
evaluation/Num Paths                5
evaluation/Average Returns         -1.48624
time/data storing (s)               0.00123161
time/evaluation sampling (s)        0.0815603
time/exploration sampling (s)       0.040313
time/logging (s)                    0.0024845
time/saving (s)                     0.00231199
time/training (s)                   0.504674
time/epoch (s)                      0.632575
time/total (s)                    260.174
Epoch                             434
-----------------------------  ----------------
2019-04-13 17:02:55.933573 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 435 finished
-----------------------------  ----------------
replay_buffer/size              87300
trainer/QF1 Loss                    5.16023
trainer/QF2 Loss                    5.15656
trainer/Policy Loss                12.7609
trainer/Q1 Predictions Mean       -12.9353
trainer/Q1 Predictions Std          0.268457
trainer/Q1 Predictions Max        -12.7539
trainer/Q1 Predictions Min        -14.353
trainer/Q2 Predictions Mean       -12.9343
trainer/Q2 Predictions Std          0.253175
trainer/Q2 Predictions Max        -12.7502
trainer/Q2 Predictions Min        -14.257
trainer/Q Targets Mean            -12.6408
trainer/Q Targets Std               2.27105
trainer/Q Targets Max              -0.0648623
trainer/Q Targets Min             -14.1452
trainer/Bellman Errors 1 Mean       5.16023
trainer/Bellman Errors 1 Std       28.5763
trainer/Bellman Errors 1 Max      164.266
trainer/Bellman Errors 1 Min        0.0001037
trainer/Bellman Errors 2 Mean       5.15656
trainer/Bellman Errors 2 Std       28.567
trainer/Bellman Errors 2 Max      164.211
trainer/Bellman Errors 2 Min        6.21879e-05
trainer/Policy Action Mean          0.0326692
trainer/Policy Action Std           0.144526
trainer/Policy Action Max           0.629512
trainer/Policy Action Min          -0.188101
exploration/num steps total     87300
exploration/num paths total       873
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134416
exploration/Rewards Std             0.0702865
exploration/Rewards Max            -0.00793199
exploration/Rewards Min            -0.343779
exploration/Returns Mean          -13.4416
exploration/Returns Std             0.27694
exploration/Returns Max           -13.1647
exploration/Returns Min           -13.7185
exploration/Actions Mean            0.00372154
exploration/Actions Std             0.147223
exploration/Actions Max             0.934128
exploration/Actions Min            -0.446258
exploration/Num Paths               2
exploration/Average Returns       -13.4416
evaluation/num steps total     218000
evaluation/num paths total       2180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0439189
evaluation/Rewards Std              0.0339021
evaluation/Rewards Max             -0.0113906
evaluation/Rewards Min             -0.687776
evaluation/Returns Mean            -4.39189
evaluation/Returns Std              0.235694
evaluation/Returns Max             -4.10426
evaluation/Returns Min             -4.79818
evaluation/Actions Mean             0.00656268
evaluation/Actions Std              0.0792256
evaluation/Actions Max              0.999954
evaluation/Actions Min             -0.67257
evaluation/Num Paths                5
evaluation/Average Returns         -4.39189
time/data storing (s)               0.00114635
time/evaluation sampling (s)        0.0870935
time/exploration sampling (s)       0.0365133
time/logging (s)                    0.00281011
time/saving (s)                     0.00275013
time/training (s)                   0.511357
time/epoch (s)                      0.64167
time/total (s)                    260.821
Epoch                             435
-----------------------------  ----------------
2019-04-13 17:02:56.523361 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 436 finished
-----------------------------  ----------------
replay_buffer/size              87500
trainer/QF1 Loss                    0.0547338
trainer/QF2 Loss                    0.0535908
trainer/Policy Loss                12.8767
trainer/Q1 Predictions Mean       -13.113
trainer/Q1 Predictions Std          0.928282
trainer/Q1 Predictions Max        -12.7972
trainer/Q1 Predictions Min        -18.2356
trainer/Q2 Predictions Mean       -13.1033
trainer/Q2 Predictions Std          0.915649
trainer/Q2 Predictions Max        -12.781
trainer/Q2 Predictions Min        -18.1556
trainer/Q Targets Mean            -13.2406
trainer/Q Targets Std               0.830792
trainer/Q Targets Max             -12.7491
trainer/Q Targets Min             -17.7269
trainer/Bellman Errors 1 Mean       0.0547338
trainer/Bellman Errors 1 Std        0.0882711
trainer/Bellman Errors 1 Max        0.436733
trainer/Bellman Errors 1 Min        5.13444e-06
trainer/Bellman Errors 2 Mean       0.0535908
trainer/Bellman Errors 2 Std        0.0824439
trainer/Bellman Errors 2 Max        0.431144
trainer/Bellman Errors 2 Min        0.00059126
trainer/Policy Action Mean         -0.00774061
trainer/Policy Action Std           0.217443
trainer/Policy Action Max           1
trainer/Policy Action Min          -0.999984
exploration/num steps total     87500
exploration/num paths total       875
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.139377
exploration/Rewards Std             0.08952
exploration/Rewards Max            -0.0176769
exploration/Rewards Min            -0.87867
exploration/Returns Mean          -13.9377
exploration/Returns Std             0.749525
exploration/Returns Max           -13.1882
exploration/Returns Min           -14.6872
exploration/Actions Mean            0.008359
exploration/Actions Std             0.157583
exploration/Actions Max             1
exploration/Actions Min            -0.514132
exploration/Num Paths               2
exploration/Average Returns       -13.9377
evaluation/num steps total     218500
evaluation/num paths total       2185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0546172
evaluation/Rewards Std              0.00207259
evaluation/Rewards Max             -0.0448013
evaluation/Rewards Min             -0.0940255
evaluation/Returns Mean            -5.46172
evaluation/Returns Std              0.0142629
evaluation/Returns Max             -5.44435
evaluation/Returns Min             -5.48628
evaluation/Actions Mean             0.00178805
evaluation/Actions Std              0.0741644
evaluation/Actions Max              0.986602
evaluation/Actions Min             -0.998605
evaluation/Num Paths                5
evaluation/Average Returns         -5.46172
time/data storing (s)               0.00122035
time/evaluation sampling (s)        0.087772
time/exploration sampling (s)       0.0436485
time/logging (s)                    0.00262858
time/saving (s)                     0.00259262
time/training (s)                   0.440281
time/epoch (s)                      0.578143
time/total (s)                    261.404
Epoch                             436
-----------------------------  ----------------
2019-04-13 17:02:57.141225 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 437 finished
-----------------------------  ----------------
replay_buffer/size              87700
trainer/QF1 Loss                    0.1022
trainer/QF2 Loss                    0.109025
trainer/Policy Loss                12.7058
trainer/Q1 Predictions Mean       -12.8567
trainer/Q1 Predictions Std          0.280666
trainer/Q1 Predictions Max        -12.678
trainer/Q1 Predictions Min        -14.3423
trainer/Q2 Predictions Mean       -12.8384
trainer/Q2 Predictions Std          0.262832
trainer/Q2 Predictions Max        -12.6427
trainer/Q2 Predictions Min        -14.1983
trainer/Q Targets Mean            -13.0958
trainer/Q Targets Std               0.254156
trainer/Q Targets Max             -12.7902
trainer/Q Targets Min             -14.1153
trainer/Bellman Errors 1 Mean       0.1022
trainer/Bellman Errors 1 Std        0.159305
trainer/Bellman Errors 1 Max        0.844757
trainer/Bellman Errors 1 Min        0.000186217
trainer/Bellman Errors 2 Mean       0.109025
trainer/Bellman Errors 2 Std        0.167984
trainer/Bellman Errors 2 Max        0.878988
trainer/Bellman Errors 2 Min        0.000452364
trainer/Policy Action Mean          0.0211061
trainer/Policy Action Std           0.159086
trainer/Policy Action Max           0.929037
trainer/Policy Action Min          -0.382803
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128949
exploration/Rewards Std             0.0702838
exploration/Rewards Max            -0.00631148
exploration/Rewards Min            -0.32583
exploration/Returns Mean          -12.8949
exploration/Returns Std             0.702439
exploration/Returns Max           -12.1925
exploration/Returns Min           -13.5973
exploration/Actions Mean            0.00603493
exploration/Actions Std             0.163214
exploration/Actions Max             0.924266
exploration/Actions Min            -0.781633
exploration/Num Paths               2
exploration/Average Returns       -12.8949
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0479638
evaluation/Rewards Std              0.0289594
evaluation/Rewards Max             -0.0305301
evaluation/Rewards Min             -0.666113
evaluation/Returns Mean            -4.79638
evaluation/Returns Std              0.221157
evaluation/Returns Max             -4.6302
evaluation/Returns Min             -5.22616
evaluation/Actions Mean             0.0056636
evaluation/Actions Std              0.075204
evaluation/Actions Max              0.999962
evaluation/Actions Min             -0.792558
evaluation/Num Paths                5
evaluation/Average Returns         -4.79638
time/data storing (s)               0.00123656
time/evaluation sampling (s)        0.0865115
time/exploration sampling (s)       0.039081
time/logging (s)                    0.00256764
time/saving (s)                     0.00238807
time/training (s)                   0.475718
time/epoch (s)                      0.607503
time/total (s)                    262.015
Epoch                             437
-----------------------------  ----------------
2019-04-13 17:02:57.835265 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 438 finished
-----------------------------  ----------------
replay_buffer/size              87900
trainer/QF1 Loss                    0.0289167
trainer/QF2 Loss                    0.0281376
trainer/Policy Loss                12.9886
trainer/Q1 Predictions Mean       -13.0779
trainer/Q1 Predictions Std          0.0942778
trainer/Q1 Predictions Max        -12.9449
trainer/Q1 Predictions Min        -13.2936
trainer/Q2 Predictions Mean       -13.0743
trainer/Q2 Predictions Std          0.0916374
trainer/Q2 Predictions Max        -12.949
trainer/Q2 Predictions Min        -13.3207
trainer/Q Targets Mean            -12.9914
trainer/Q Targets Std               0.137694
trainer/Q Targets Max             -12.7561
trainer/Q Targets Min             -13.3695
trainer/Bellman Errors 1 Mean       0.0289167
trainer/Bellman Errors 1 Std        0.0350939
trainer/Bellman Errors 1 Max        0.155195
trainer/Bellman Errors 1 Min        3.33881e-06
trainer/Bellman Errors 2 Mean       0.0281376
trainer/Bellman Errors 2 Std        0.0380972
trainer/Bellman Errors 2 Max        0.180984
trainer/Bellman Errors 2 Min        1.6166e-05
trainer/Policy Action Mean          0.020094
trainer/Policy Action Std           0.164663
trainer/Policy Action Max           0.954689
trainer/Policy Action Min          -0.183173
exploration/num steps total     87900
exploration/num paths total       879
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135958
exploration/Rewards Std             0.0727473
exploration/Rewards Max            -0.0152592
exploration/Rewards Min            -0.465289
exploration/Returns Mean          -13.5958
exploration/Returns Std             0.504448
exploration/Returns Max           -13.0913
exploration/Returns Min           -14.1002
exploration/Actions Mean            0.0101632
exploration/Actions Std             0.161419
exploration/Actions Max             0.902085
exploration/Actions Min            -0.387852
exploration/Num Paths               2
exploration/Average Returns       -13.5958
evaluation/num steps total     219500
evaluation/num paths total       2195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0558126
evaluation/Rewards Std              0.0465294
evaluation/Rewards Max             -0.0446693
evaluation/Rewards Min             -0.962105
evaluation/Returns Mean            -5.58126
evaluation/Returns Std              0.328359
evaluation/Returns Max             -5.3022
evaluation/Returns Min             -6.16429
evaluation/Actions Mean             0.00808217
evaluation/Actions Std              0.0841127
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.183998
evaluation/Num Paths                5
evaluation/Average Returns         -5.58126
time/data storing (s)               0.00134684
time/evaluation sampling (s)        0.0943363
time/exploration sampling (s)       0.0474009
time/logging (s)                    0.00249384
time/saving (s)                     0.00257198
time/training (s)                   0.53522
time/epoch (s)                      0.68337
time/total (s)                    262.703
Epoch                             438
-----------------------------  ----------------
2019-04-13 17:02:58.466178 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 439 finished
-----------------------------  ----------------
replay_buffer/size              88100
trainer/QF1 Loss                    0.126572
trainer/QF2 Loss                    0.125113
trainer/Policy Loss                12.7747
trainer/Q1 Predictions Mean       -12.9274
trainer/Q1 Predictions Std          0.469637
trainer/Q1 Predictions Max        -12.6954
trainer/Q1 Predictions Min        -15.4439
trainer/Q2 Predictions Mean       -12.9304
trainer/Q2 Predictions Std          0.483025
trainer/Q2 Predictions Max        -12.6776
trainer/Q2 Predictions Min        -15.5188
trainer/Q Targets Mean            -13.2073
trainer/Q Targets Std               0.585645
trainer/Q Targets Max             -12.847
trainer/Q Targets Min             -16.2527
trainer/Bellman Errors 1 Mean       0.126572
trainer/Bellman Errors 1 Std        0.175014
trainer/Bellman Errors 1 Max        0.654077
trainer/Bellman Errors 1 Min        3.06482e-05
trainer/Bellman Errors 2 Mean       0.125113
trainer/Bellman Errors 2 Std        0.169315
trainer/Bellman Errors 2 Max        0.577102
trainer/Bellman Errors 2 Min        2.44605e-05
trainer/Policy Action Mean         -0.0180191
trainer/Policy Action Std           0.179699
trainer/Policy Action Max           0.999744
trainer/Policy Action Min          -0.480857
exploration/num steps total     88100
exploration/num paths total       881
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.122949
exploration/Rewards Std             0.0649758
exploration/Rewards Max            -0.0060497
exploration/Rewards Min            -0.322881
exploration/Returns Mean          -12.2949
exploration/Returns Std             0.33923
exploration/Returns Max           -11.9557
exploration/Returns Min           -12.6341
exploration/Actions Mean            0.00227521
exploration/Actions Std             0.140837
exploration/Actions Max             0.681574
exploration/Actions Min            -0.368369
exploration/Num Paths               2
exploration/Average Returns       -12.2949
evaluation/num steps total     220000
evaluation/num paths total       2200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0500548
evaluation/Rewards Std              0.0414704
evaluation/Rewards Max             -0.0321409
evaluation/Rewards Min             -0.780847
evaluation/Returns Mean            -5.00548
evaluation/Returns Std              0.272131
evaluation/Returns Max             -4.65018
evaluation/Returns Min             -5.43295
evaluation/Actions Mean             0.00706594
evaluation/Actions Std              0.0844718
evaluation/Actions Max              0.999983
evaluation/Actions Min             -0.575402
evaluation/Num Paths                5
evaluation/Average Returns         -5.00548
time/data storing (s)               0.00125704
time/evaluation sampling (s)        0.0944918
time/exploration sampling (s)       0.0373961
time/logging (s)                    0.00256416
time/saving (s)                     0.00250903
time/training (s)                   0.481473
time/epoch (s)                      0.619691
time/total (s)                    263.328
Epoch                             439
-----------------------------  ----------------
2019-04-13 17:02:59.189686 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 440 finished
-----------------------------  ----------------
replay_buffer/size              88300
trainer/QF1 Loss                    0.017274
trainer/QF2 Loss                    0.0200623
trainer/Policy Loss                12.8724
trainer/Q1 Predictions Mean       -13.0533
trainer/Q1 Predictions Std          0.57736
trainer/Q1 Predictions Max        -12.8182
trainer/Q1 Predictions Min        -16.0994
trainer/Q2 Predictions Mean       -13.0464
trainer/Q2 Predictions Std          0.581789
trainer/Q2 Predictions Max        -12.798
trainer/Q2 Predictions Min        -16.135
trainer/Q Targets Mean            -13.0969
trainer/Q Targets Std               0.540808
trainer/Q Targets Max             -12.722
trainer/Q Targets Min             -15.8936
trainer/Bellman Errors 1 Mean       0.017274
trainer/Bellman Errors 1 Std        0.0207621
trainer/Bellman Errors 1 Max        0.105728
trainer/Bellman Errors 1 Min        0.000339023
trainer/Bellman Errors 2 Mean       0.0200623
trainer/Bellman Errors 2 Std        0.0270439
trainer/Bellman Errors 2 Max        0.127927
trainer/Bellman Errors 2 Min        1.74462e-06
trainer/Policy Action Mean          0.0198438
trainer/Policy Action Std           0.196598
trainer/Policy Action Max           0.999804
trainer/Policy Action Min          -0.551895
exploration/num steps total     88300
exploration/num paths total       883
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127938
exploration/Rewards Std             0.0693921
exploration/Rewards Max            -0.00283799
exploration/Rewards Min            -0.307748
exploration/Returns Mean          -12.7938
exploration/Returns Std             0.0498852
exploration/Returns Max           -12.744
exploration/Returns Min           -12.8437
exploration/Actions Mean            0.00348825
exploration/Actions Std             0.157631
exploration/Actions Max             0.934501
exploration/Actions Min            -0.383469
exploration/Num Paths               2
exploration/Average Returns       -12.7938
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0424257
evaluation/Rewards Std              0.0279552
evaluation/Rewards Max             -0.0318777
evaluation/Rewards Min             -0.65076
evaluation/Returns Mean            -4.24257
evaluation/Returns Std              0.23214
evaluation/Returns Max             -4.0887
evaluation/Returns Min             -4.69717
evaluation/Actions Mean             0.0053185
evaluation/Actions Std              0.0769276
evaluation/Actions Max              0.999908
evaluation/Actions Min             -0.999417
evaluation/Num Paths                5
evaluation/Average Returns         -4.24257
time/data storing (s)               0.00166799
time/evaluation sampling (s)        0.102844
time/exploration sampling (s)       0.0378385
time/logging (s)                    0.0029824
time/saving (s)                     0.00247937
time/training (s)                   0.564923
time/epoch (s)                      0.712735
time/total (s)                    264.044
Epoch                             440
-----------------------------  ----------------
2019-04-13 17:02:59.891978 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 441 finished
-----------------------------  ----------------
replay_buffer/size              88500
trainer/QF1 Loss                    0.0489905
trainer/QF2 Loss                    0.0512487
trainer/Policy Loss                13.0113
trainer/Q1 Predictions Mean       -13.1448
trainer/Q1 Predictions Std          0.141674
trainer/Q1 Predictions Max        -13.0345
trainer/Q1 Predictions Min        -13.8555
trainer/Q2 Predictions Mean       -13.1497
trainer/Q2 Predictions Std          0.132661
trainer/Q2 Predictions Max        -13.045
trainer/Q2 Predictions Min        -13.8165
trainer/Q Targets Mean            -13.0974
trainer/Q Targets Std               0.311718
trainer/Q Targets Max             -12.7929
trainer/Q Targets Min             -14.592
trainer/Bellman Errors 1 Mean       0.0489905
trainer/Bellman Errors 1 Std        0.0947876
trainer/Bellman Errors 1 Max        0.542303
trainer/Bellman Errors 1 Min        0.000428627
trainer/Bellman Errors 2 Mean       0.0512487
trainer/Bellman Errors 2 Std        0.104401
trainer/Bellman Errors 2 Max        0.601352
trainer/Bellman Errors 2 Min        1.75723e-06
trainer/Policy Action Mean         -0.0134542
trainer/Policy Action Std           0.129295
trainer/Policy Action Max           0.312164
trainer/Policy Action Min          -0.442636
exploration/num steps total     88500
exploration/num paths total       885
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.156941
exploration/Rewards Std             0.087649
exploration/Rewards Max            -0.0148401
exploration/Rewards Min            -0.781047
exploration/Returns Mean          -15.6941
exploration/Returns Std             0.134517
exploration/Returns Max           -15.5596
exploration/Returns Min           -15.8286
exploration/Actions Mean            0.00426164
exploration/Actions Std             0.189071
exploration/Actions Max             1
exploration/Actions Min            -0.874549
exploration/Num Paths               2
exploration/Average Returns       -15.6941
evaluation/num steps total     221000
evaluation/num paths total       2210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0560753
evaluation/Rewards Std              0.0451047
evaluation/Rewards Max             -0.030729
evaluation/Rewards Min             -0.812338
evaluation/Returns Mean            -5.60753
evaluation/Returns Std              0.279922
evaluation/Returns Max             -5.2743
evaluation/Returns Min             -6.01778
evaluation/Actions Mean             0.00419031
evaluation/Actions Std              0.0838584
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.986312
evaluation/Num Paths                5
evaluation/Average Returns         -5.60753
time/data storing (s)               0.00148442
time/evaluation sampling (s)        0.096265
time/exploration sampling (s)       0.0487981
time/logging (s)                    0.00497875
time/saving (s)                     0.00293953
time/training (s)                   0.538629
time/epoch (s)                      0.693094
time/total (s)                    264.742
Epoch                             441
-----------------------------  ----------------
2019-04-13 17:03:00.624521 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 442 finished
-----------------------------  ----------------
replay_buffer/size              88700
trainer/QF1 Loss                    0.0609199
trainer/QF2 Loss                    0.0553949
trainer/Policy Loss                13.0927
trainer/Q1 Predictions Mean       -13.2673
trainer/Q1 Predictions Std          0.222535
trainer/Q1 Predictions Max        -13.095
trainer/Q1 Predictions Min        -14.3365
trainer/Q2 Predictions Mean       -13.2529
trainer/Q2 Predictions Std          0.206843
trainer/Q2 Predictions Max        -13.0994
trainer/Q2 Predictions Min        -14.2035
trainer/Q Targets Mean            -13.0637
trainer/Q Targets Std               0.220643
trainer/Q Targets Max             -12.786
trainer/Q Targets Min             -13.9892
trainer/Bellman Errors 1 Mean       0.0609199
trainer/Bellman Errors 1 Std        0.0541864
trainer/Bellman Errors 1 Max        0.221253
trainer/Bellman Errors 1 Min        3.66962e-05
trainer/Bellman Errors 2 Mean       0.0553949
trainer/Bellman Errors 2 Std        0.0514342
trainer/Bellman Errors 2 Max        0.189654
trainer/Bellman Errors 2 Min        0.000536915
trainer/Policy Action Mean          0.0182042
trainer/Policy Action Std           0.203465
trainer/Policy Action Max           0.999993
trainer/Policy Action Min          -0.478506
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140807
exploration/Rewards Std             0.0928282
exploration/Rewards Max            -0.0152148
exploration/Rewards Min            -0.928895
exploration/Returns Mean          -14.0807
exploration/Returns Std             0.675985
exploration/Returns Max           -13.4047
exploration/Returns Min           -14.7567
exploration/Actions Mean            0.00519064
exploration/Actions Std             0.165211
exploration/Actions Max             1
exploration/Actions Min            -0.859136
exploration/Num Paths               2
exploration/Average Returns       -14.0807
evaluation/num steps total     221500
evaluation/num paths total       2215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0596389
evaluation/Rewards Std              0.0404439
evaluation/Rewards Max             -0.0123648
evaluation/Rewards Min             -0.908526
evaluation/Returns Mean            -5.96389
evaluation/Returns Std              0.293308
evaluation/Returns Max             -5.68474
evaluation/Returns Min             -6.52588
evaluation/Actions Mean             0.00701166
evaluation/Actions Std              0.0768477
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.467614
evaluation/Num Paths                5
evaluation/Average Returns         -5.96389
time/data storing (s)               0.00113855
time/evaluation sampling (s)        0.0839895
time/exploration sampling (s)       0.0382134
time/logging (s)                    0.00321177
time/saving (s)                     0.00238152
time/training (s)                   0.590047
time/epoch (s)                      0.718982
time/total (s)                    265.465
Epoch                             442
-----------------------------  ----------------
2019-04-13 17:03:01.311156 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 443 finished
-----------------------------  ----------------
replay_buffer/size              88900
trainer/QF1 Loss                    0.0327362
trainer/QF2 Loss                    0.0317451
trainer/Policy Loss                12.7317
trainer/Q1 Predictions Mean       -12.8506
trainer/Q1 Predictions Std          0.073807
trainer/Q1 Predictions Max        -12.7374
trainer/Q1 Predictions Min        -13.0109
trainer/Q2 Predictions Mean       -12.8496
trainer/Q2 Predictions Std          0.0774449
trainer/Q2 Predictions Max        -12.7307
trainer/Q2 Predictions Min        -13.0075
trainer/Q Targets Mean            -12.9742
trainer/Q Targets Std               0.161524
trainer/Q Targets Max             -12.7038
trainer/Q Targets Min             -13.4316
trainer/Bellman Errors 1 Mean       0.0327362
trainer/Bellman Errors 1 Std        0.0457235
trainer/Bellman Errors 1 Max        0.214496
trainer/Bellman Errors 1 Min        1.83391e-08
trainer/Bellman Errors 2 Mean       0.0317451
trainer/Bellman Errors 2 Std        0.0421397
trainer/Bellman Errors 2 Max        0.18346
trainer/Bellman Errors 2 Min        5.3742e-05
trainer/Policy Action Mean          0.0209229
trainer/Policy Action Std           0.0898804
trainer/Policy Action Max           0.35371
trainer/Policy Action Min          -0.149005
exploration/num steps total     88900
exploration/num paths total       889
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124899
exploration/Rewards Std             0.0690645
exploration/Rewards Max            -0.00173281
exploration/Rewards Min            -0.330093
exploration/Returns Mean          -12.4899
exploration/Returns Std             0.433498
exploration/Returns Max           -12.0564
exploration/Returns Min           -12.9234
exploration/Actions Mean            0.00571269
exploration/Actions Std             0.143064
exploration/Actions Max             0.856502
exploration/Actions Min            -0.374327
exploration/Num Paths               2
exploration/Average Returns       -12.4899
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0415757
evaluation/Rewards Std              0.0369858
evaluation/Rewards Max             -0.00997923
evaluation/Rewards Min             -0.594996
evaluation/Returns Mean            -4.15757
evaluation/Returns Std              0.13116
evaluation/Returns Max             -4.00617
evaluation/Returns Min             -4.37467
evaluation/Actions Mean             0.00430074
evaluation/Actions Std              0.0869237
evaluation/Actions Max              0.999928
evaluation/Actions Min             -0.993757
evaluation/Num Paths                5
evaluation/Average Returns         -4.15757
time/data storing (s)               0.00126868
time/evaluation sampling (s)        0.0964886
time/exploration sampling (s)       0.0409143
time/logging (s)                    0.00314783
time/saving (s)                     0.00238168
time/training (s)                   0.530475
time/epoch (s)                      0.674676
time/total (s)                    266.144
Epoch                             443
-----------------------------  ----------------
2019-04-13 17:03:02.226040 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 444 finished
-----------------------------  ----------------
replay_buffer/size              89100
trainer/QF1 Loss                    5.22519
trainer/QF2 Loss                    5.21006
trainer/Policy Loss                12.858
trainer/Q1 Predictions Mean       -13.0522
trainer/Q1 Predictions Std          0.251181
trainer/Q1 Predictions Max        -12.8707
trainer/Q1 Predictions Min        -14.3161
trainer/Q2 Predictions Mean       -13.0454
trainer/Q2 Predictions Std          0.249106
trainer/Q2 Predictions Max        -12.8599
trainer/Q2 Predictions Min        -14.3005
trainer/Q Targets Mean            -12.699
trainer/Q Targets Std               2.2801
trainer/Q Targets Max              -0.0970354
trainer/Q Targets Min             -14.0803
trainer/Bellman Errors 1 Mean       5.22519
trainer/Bellman Errors 1 Std       28.8939
trainer/Bellman Errors 1 Max      166.1
trainer/Bellman Errors 1 Min        0.000195358
trainer/Bellman Errors 2 Mean       5.21006
trainer/Bellman Errors 2 Std       28.8042
trainer/Bellman Errors 2 Max      165.585
trainer/Bellman Errors 2 Min        3.27418e-11
trainer/Policy Action Mean          0.0549539
trainer/Policy Action Std           0.154568
trainer/Policy Action Max           0.802741
trainer/Policy Action Min          -0.19031
exploration/num steps total     89100
exploration/num paths total       891
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.137387
exploration/Rewards Std             0.0750917
exploration/Rewards Max            -0.00714469
exploration/Rewards Min            -0.387788
exploration/Returns Mean          -13.7387
exploration/Returns Std             0.31215
exploration/Returns Max           -13.4265
exploration/Returns Min           -14.0508
exploration/Actions Mean            0.00341385
exploration/Actions Std             0.150812
exploration/Actions Max             0.838602
exploration/Actions Min            -0.401361
exploration/Num Paths               2
exploration/Average Returns       -13.7387
evaluation/num steps total     222500
evaluation/num paths total       2225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0774246
evaluation/Rewards Std              0.0277414
evaluation/Rewards Max             -0.0388363
evaluation/Rewards Min             -0.622005
evaluation/Returns Mean            -7.74246
evaluation/Returns Std              0.224341
evaluation/Returns Max             -7.55279
evaluation/Returns Min             -8.10779
evaluation/Actions Mean             0.00404356
evaluation/Actions Std              0.0635697
evaluation/Actions Max              0.999969
evaluation/Actions Min             -0.887365
evaluation/Num Paths                5
evaluation/Average Returns         -7.74246
time/data storing (s)               0.00118082
time/evaluation sampling (s)        0.12315
time/exploration sampling (s)       0.0397463
time/logging (s)                    0.00246471
time/saving (s)                     0.00220762
time/training (s)                   0.733406
time/epoch (s)                      0.902155
time/total (s)                    267.049
Epoch                             444
-----------------------------  ----------------
2019-04-13 17:03:02.972727 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 445 finished
-----------------------------  ----------------
replay_buffer/size              89300
trainer/QF1 Loss                    5.16517
trainer/QF2 Loss                    5.15374
trainer/Policy Loss                12.897
trainer/Q1 Predictions Mean       -13.0597
trainer/Q1 Predictions Std          0.193599
trainer/Q1 Predictions Max        -12.9175
trainer/Q1 Predictions Min        -13.9252
trainer/Q2 Predictions Mean       -13.048
trainer/Q2 Predictions Std          0.198808
trainer/Q2 Predictions Max        -12.8921
trainer/Q2 Predictions Min        -13.9592
trainer/Q Targets Mean            -12.656
trainer/Q Targets Std               2.23015
trainer/Q Targets Max              -0.31469
trainer/Q Targets Min             -13.8617
trainer/Bellman Errors 1 Mean       5.16517
trainer/Bellman Errors 1 Std       28.5948
trainer/Bellman Errors 1 Max      164.374
trainer/Bellman Errors 1 Min        3.56919e-06
trainer/Bellman Errors 2 Mean       5.15374
trainer/Bellman Errors 2 Std       28.5246
trainer/Bellman Errors 2 Max      163.972
trainer/Bellman Errors 2 Min        7.56633e-05
trainer/Policy Action Mean          0.017927
trainer/Policy Action Std           0.150971
trainer/Policy Action Max           0.54103
trainer/Policy Action Min          -0.54077
exploration/num steps total     89300
exploration/num paths total       893
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131663
exploration/Rewards Std             0.0702018
exploration/Rewards Max            -0.00177567
exploration/Rewards Min            -0.355924
exploration/Returns Mean          -13.1663
exploration/Returns Std             0.193521
exploration/Returns Max           -12.9728
exploration/Returns Min           -13.3598
exploration/Actions Mean            0.00362748
exploration/Actions Std             0.144592
exploration/Actions Max             0.803495
exploration/Actions Min            -0.347785
exploration/Num Paths               2
exploration/Average Returns       -13.1663
evaluation/num steps total     223000
evaluation/num paths total       2230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0581491
evaluation/Rewards Std              0.0316963
evaluation/Rewards Max             -0.0520874
evaluation/Rewards Min             -0.650891
evaluation/Returns Mean            -5.81491
evaluation/Returns Std              0.235589
evaluation/Returns Max             -5.59945
evaluation/Returns Min             -6.19494
evaluation/Actions Mean             0.00440262
evaluation/Actions Std              0.0648781
evaluation/Actions Max              0.999988
evaluation/Actions Min             -0.360257
evaluation/Num Paths                5
evaluation/Average Returns         -5.81491
time/data storing (s)               0.00223857
time/evaluation sampling (s)        0.183445
time/exploration sampling (s)       0.0914749
time/logging (s)                    0.00246661
time/saving (s)                     0.00246158
time/training (s)                   0.452916
time/epoch (s)                      0.735003
time/total (s)                    267.79
Epoch                             445
-----------------------------  ----------------
2019-04-13 17:03:03.562357 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 446 finished
-----------------------------  ----------------
replay_buffer/size              89500
trainer/QF1 Loss                    5.04452
trainer/QF2 Loss                    5.03389
trainer/Policy Loss                12.7462
trainer/Q1 Predictions Mean       -12.8442
trainer/Q1 Predictions Std          0.40555
trainer/Q1 Predictions Max        -12.6499
trainer/Q1 Predictions Min        -14.881
trainer/Q2 Predictions Mean       -12.8438
trainer/Q2 Predictions Std          0.380767
trainer/Q2 Predictions Max        -12.66
trainer/Q2 Predictions Min        -14.7115
trainer/Q Targets Mean            -12.7277
trainer/Q Targets Std               2.29728
trainer/Q Targets Max              -0.150727
trainer/Q Targets Min             -15.1616
trainer/Bellman Errors 1 Mean       5.04452
trainer/Bellman Errors 1 Std       27.4608
trainer/Bellman Errors 1 Max      157.939
trainer/Bellman Errors 1 Min        2.42816e-05
trainer/Bellman Errors 2 Mean       5.03389
trainer/Bellman Errors 2 Std       27.3927
trainer/Bellman Errors 2 Max      157.549
trainer/Bellman Errors 2 Min        2.18994e-05
trainer/Policy Action Mean         -0.0154604
trainer/Policy Action Std           0.254214
trainer/Policy Action Max           0.999988
trainer/Policy Action Min          -1
exploration/num steps total     89500
exploration/num paths total       895
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134581
exploration/Rewards Std             0.07587
exploration/Rewards Max            -0.0165607
exploration/Rewards Min            -0.72579
exploration/Returns Mean          -13.4581
exploration/Returns Std             0.749901
exploration/Returns Max           -12.7082
exploration/Returns Min           -14.208
exploration/Actions Mean            0.00634045
exploration/Actions Std             0.169408
exploration/Actions Max             1
exploration/Actions Min            -0.843937
exploration/Num Paths               2
exploration/Average Returns       -13.4581
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0251455
evaluation/Rewards Std              0.0423167
evaluation/Rewards Max             -0.00353173
evaluation/Rewards Min             -0.909684
evaluation/Returns Mean            -2.51455
evaluation/Returns Std              0.30407
evaluation/Returns Max             -2.22944
evaluation/Returns Min             -3.0933
evaluation/Actions Mean             0.0048299
evaluation/Actions Std              0.0714864
evaluation/Actions Max              1
evaluation/Actions Min             -0.801388
evaluation/Num Paths                5
evaluation/Average Returns         -2.51455
time/data storing (s)               0.00134755
time/evaluation sampling (s)        0.0787893
time/exploration sampling (s)       0.0359972
time/logging (s)                    0.00245151
time/saving (s)                     0.00228018
time/training (s)                   0.458479
time/epoch (s)                      0.579344
time/total (s)                    268.373
Epoch                             446
-----------------------------  ----------------
2019-04-13 17:03:04.149046 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 447 finished
-----------------------------  ---------------
replay_buffer/size              89700
trainer/QF1 Loss                    0.111354
trainer/QF2 Loss                    0.112113
trainer/Policy Loss                12.6503
trainer/Q1 Predictions Mean       -12.6962
trainer/Q1 Predictions Std          0.0536284
trainer/Q1 Predictions Max        -12.6288
trainer/Q1 Predictions Min        -12.8346
trainer/Q2 Predictions Mean       -12.6936
trainer/Q2 Predictions Std          0.0548197
trainer/Q2 Predictions Max        -12.6086
trainer/Q2 Predictions Min        -12.8151
trainer/Q Targets Mean            -13.0003
trainer/Q Targets Std               0.139931
trainer/Q Targets Max             -12.7531
trainer/Q Targets Min             -13.322
trainer/Bellman Errors 1 Mean       0.111354
trainer/Bellman Errors 1 Std        0.0976783
trainer/Bellman Errors 1 Max        0.39934
trainer/Bellman Errors 1 Min        0.0141797
trainer/Bellman Errors 2 Mean       0.112113
trainer/Bellman Errors 2 Std        0.0964472
trainer/Bellman Errors 2 Max        0.408021
trainer/Bellman Errors 2 Min        0.0153962
trainer/Policy Action Mean          0.0104082
trainer/Policy Action Std           0.10448
trainer/Policy Action Max           0.254632
trainer/Policy Action Min          -0.21247
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138387
exploration/Rewards Std             0.074901
exploration/Rewards Max            -0.00280088
exploration/Rewards Min            -0.654744
exploration/Returns Mean          -13.8387
exploration/Returns Std             0.447269
exploration/Returns Max           -13.3914
exploration/Returns Min           -14.286
exploration/Actions Mean            0.0100525
exploration/Actions Std             0.165222
exploration/Actions Max             0.998246
exploration/Actions Min            -0.396435
exploration/Num Paths               2
exploration/Average Returns       -13.8387
evaluation/num steps total     224000
evaluation/num paths total       2240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0554239
evaluation/Rewards Std              0.0197454
evaluation/Rewards Max             -0.0366531
evaluation/Rewards Min             -0.376861
evaluation/Returns Mean            -5.54239
evaluation/Returns Std              0.116597
evaluation/Returns Max             -5.37763
evaluation/Returns Min             -5.71361
evaluation/Actions Mean             0.00314036
evaluation/Actions Std              0.0770243
evaluation/Actions Max              0.999689
evaluation/Actions Min             -0.999768
evaluation/Num Paths                5
evaluation/Average Returns         -5.54239
time/data storing (s)               0.00106011
time/evaluation sampling (s)        0.0773731
time/exploration sampling (s)       0.0322069
time/logging (s)                    0.00249198
time/saving (s)                     0.00223428
time/training (s)                   0.46099
time/epoch (s)                      0.576357
time/total (s)                    268.953
Epoch                             447
-----------------------------  ---------------
2019-04-13 17:03:04.731477 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 448 finished
-----------------------------  ----------------
replay_buffer/size              89900
trainer/QF1 Loss                    5.23506
trainer/QF2 Loss                    5.22612
trainer/Policy Loss                12.7715
trainer/Q1 Predictions Mean       -12.9495
trainer/Q1 Predictions Std          0.0938091
trainer/Q1 Predictions Max        -12.8273
trainer/Q1 Predictions Min        -13.2561
trainer/Q2 Predictions Mean       -12.9494
trainer/Q2 Predictions Std          0.0975301
trainer/Q2 Predictions Max        -12.827
trainer/Q2 Predictions Min        -13.2906
trainer/Q Targets Mean            -12.6228
trainer/Q Targets Std               2.23931
trainer/Q Targets Max              -0.209474
trainer/Q Targets Min             -13.8094
trainer/Bellman Errors 1 Mean       5.23506
trainer/Bellman Errors 1 Std       28.9282
trainer/Bellman Errors 1 Max      166.3
trainer/Bellman Errors 1 Min        0.000159312
trainer/Bellman Errors 2 Mean       5.22612
trainer/Bellman Errors 2 Std       28.8864
trainer/Bellman Errors 2 Max      166.058
trainer/Bellman Errors 2 Min        0.000165977
trainer/Policy Action Mean          0.0711645
trainer/Policy Action Std           0.149112
trainer/Policy Action Max           0.863068
trainer/Policy Action Min          -0.154572
exploration/num steps total     89900
exploration/num paths total       899
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.125617
exploration/Rewards Std             0.0661877
exploration/Rewards Max            -0.0109195
exploration/Rewards Min            -0.328277
exploration/Returns Mean          -12.5617
exploration/Returns Std             0.00201526
exploration/Returns Max           -12.5597
exploration/Returns Min           -12.5637
exploration/Actions Mean            0.00540267
exploration/Actions Std             0.151682
exploration/Actions Max             0.944013
exploration/Actions Min            -0.356467
exploration/Num Paths               2
exploration/Average Returns       -12.5617
evaluation/num steps total     224500
evaluation/num paths total       2245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0462016
evaluation/Rewards Std              0.0207757
evaluation/Rewards Max             -0.0344688
evaluation/Rewards Min             -0.363492
evaluation/Returns Mean            -4.62016
evaluation/Returns Std              0.143411
evaluation/Returns Max             -4.46618
evaluation/Returns Min             -4.80638
evaluation/Actions Mean             0.00583365
evaluation/Actions Std              0.0795866
evaluation/Actions Max              0.999174
evaluation/Actions Min             -0.986944
evaluation/Num Paths                5
evaluation/Average Returns         -4.62016
time/data storing (s)               0.00112094
time/evaluation sampling (s)        0.0727928
time/exploration sampling (s)       0.0365078
time/logging (s)                    0.00250256
time/saving (s)                     0.00226095
time/training (s)                   0.457135
time/epoch (s)                      0.57232
time/total (s)                    269.529
Epoch                             448
-----------------------------  ----------------
2019-04-13 17:03:05.309881 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 449 finished
-----------------------------  ----------------
replay_buffer/size              90100
trainer/QF1 Loss                    0.0476486
trainer/QF2 Loss                    0.0469211
trainer/Policy Loss                12.7792
trainer/Q1 Predictions Mean       -12.9997
trainer/Q1 Predictions Std          0.516572
trainer/Q1 Predictions Max        -12.7768
trainer/Q1 Predictions Min        -15.8189
trainer/Q2 Predictions Mean       -13.0043
trainer/Q2 Predictions Std          0.518123
trainer/Q2 Predictions Max        -12.767
trainer/Q2 Predictions Min        -15.8187
trainer/Q Targets Mean            -13.1443
trainer/Q Targets Std               0.48017
trainer/Q Targets Max             -12.6952
trainer/Q Targets Min             -15.5894
trainer/Bellman Errors 1 Mean       0.0476486
trainer/Bellman Errors 1 Std        0.0603294
trainer/Bellman Errors 1 Max        0.213033
trainer/Bellman Errors 1 Min        0.000410307
trainer/Bellman Errors 2 Mean       0.0469211
trainer/Bellman Errors 2 Std        0.0590323
trainer/Bellman Errors 2 Max        0.22264
trainer/Bellman Errors 2 Min        1.92542e-06
trainer/Policy Action Mean          0.0326
trainer/Policy Action Std           0.214171
trainer/Policy Action Max           0.999533
trainer/Policy Action Min          -0.871983
exploration/num steps total     90100
exploration/num paths total       901
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136707
exploration/Rewards Std             0.0699721
exploration/Rewards Max            -0.00694928
exploration/Rewards Min            -0.366914
exploration/Returns Mean          -13.6707
exploration/Returns Std             0.464166
exploration/Returns Max           -13.2066
exploration/Returns Min           -14.1349
exploration/Actions Mean            0.0071959
exploration/Actions Std             0.163406
exploration/Actions Max             1
exploration/Actions Min            -0.381871
exploration/Num Paths               2
exploration/Average Returns       -13.6707
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0574824
evaluation/Rewards Std              0.0632641
evaluation/Rewards Max             -0.0423502
evaluation/Rewards Min             -0.949228
evaluation/Returns Mean            -5.74824
evaluation/Returns Std              0.180125
evaluation/Returns Max             -5.4829
evaluation/Returns Min             -6.03706
evaluation/Actions Mean             0.0105913
evaluation/Actions Std              0.0929449
evaluation/Actions Max              1
evaluation/Actions Min             -0.0270142
evaluation/Num Paths                5
evaluation/Average Returns         -5.74824
time/data storing (s)               0.00108127
time/evaluation sampling (s)        0.0741555
time/exploration sampling (s)       0.032577
time/logging (s)                    0.00246451
time/saving (s)                     0.00221667
time/training (s)                   0.455804
time/epoch (s)                      0.568299
time/total (s)                    270.102
Epoch                             449
-----------------------------  ----------------
2019-04-13 17:03:05.895210 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 450 finished
-----------------------------  ----------------
replay_buffer/size              90300
trainer/QF1 Loss                    0.0300836
trainer/QF2 Loss                    0.0262326
trainer/Policy Loss                12.7241
trainer/Q1 Predictions Mean       -12.9178
trainer/Q1 Predictions Std          0.138567
trainer/Q1 Predictions Max        -12.7728
trainer/Q1 Predictions Min        -13.5243
trainer/Q2 Predictions Mean       -12.9352
trainer/Q2 Predictions Std          0.141663
trainer/Q2 Predictions Max        -12.7911
trainer/Q2 Predictions Min        -13.5412
trainer/Q Targets Mean            -13.0188
trainer/Q Targets Std               0.223706
trainer/Q Targets Max             -12.7367
trainer/Q Targets Min             -13.9272
trainer/Bellman Errors 1 Mean       0.0300836
trainer/Bellman Errors 1 Std        0.0511475
trainer/Bellman Errors 1 Max        0.207352
trainer/Bellman Errors 1 Min        0.000102249
trainer/Bellman Errors 2 Mean       0.0262326
trainer/Bellman Errors 2 Std        0.0451281
trainer/Bellman Errors 2 Max        0.176336
trainer/Bellman Errors 2 Min        6.17375e-05
trainer/Policy Action Mean          0.0304693
trainer/Policy Action Std           0.114198
trainer/Policy Action Max           0.239841
trainer/Policy Action Min          -0.479101
exploration/num steps total     90300
exploration/num paths total       903
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126993
exploration/Rewards Std             0.0671274
exploration/Rewards Max            -0.00704904
exploration/Rewards Min            -0.351537
exploration/Returns Mean          -12.6993
exploration/Returns Std             0.408383
exploration/Returns Max           -12.291
exploration/Returns Min           -13.1077
exploration/Actions Mean            0.000928533
exploration/Actions Std             0.138164
exploration/Actions Max             0.410822
exploration/Actions Min            -0.368555
exploration/Num Paths               2
exploration/Average Returns       -12.6993
evaluation/num steps total     225500
evaluation/num paths total       2255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0430549
evaluation/Rewards Std              0.0429204
evaluation/Rewards Max             -0.0371036
evaluation/Rewards Min             -0.936588
evaluation/Returns Mean            -4.30549
evaluation/Returns Std              0.331305
evaluation/Returns Max             -4.03372
evaluation/Returns Min             -4.92577
evaluation/Actions Mean             0.00428687
evaluation/Actions Std              0.0799658
evaluation/Actions Max              1
evaluation/Actions Min             -0.997721
evaluation/Num Paths                5
evaluation/Average Returns         -4.30549
time/data storing (s)               0.00108358
time/evaluation sampling (s)        0.0740542
time/exploration sampling (s)       0.0342099
time/logging (s)                    0.00186727
time/saving (s)                     0.00177187
time/training (s)                   0.461401
time/epoch (s)                      0.574388
time/total (s)                    270.681
Epoch                             450
-----------------------------  ----------------
2019-04-13 17:03:06.479399 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 451 finished
-----------------------------  ----------------
replay_buffer/size              90500
trainer/QF1 Loss                    0.0345685
trainer/QF2 Loss                    0.0363468
trainer/Policy Loss                12.8548
trainer/Q1 Predictions Mean       -12.9368
trainer/Q1 Predictions Std          0.0841772
trainer/Q1 Predictions Max        -12.8052
trainer/Q1 Predictions Min        -13.1521
trainer/Q2 Predictions Mean       -12.9291
trainer/Q2 Predictions Std          0.0857336
trainer/Q2 Predictions Max        -12.776
trainer/Q2 Predictions Min        -13.1359
trainer/Q Targets Mean            -13.0551
trainer/Q Targets Std               0.162342
trainer/Q Targets Max             -12.7818
trainer/Q Targets Min             -13.4185
trainer/Bellman Errors 1 Mean       0.0345685
trainer/Bellman Errors 1 Std        0.0509992
trainer/Bellman Errors 1 Max        0.268944
trainer/Bellman Errors 1 Min        1.00007e-05
trainer/Bellman Errors 2 Mean       0.0363468
trainer/Bellman Errors 2 Std        0.05216
trainer/Bellman Errors 2 Max        0.277494
trainer/Bellman Errors 2 Min        0.000286677
trainer/Policy Action Mean          0.011935
trainer/Policy Action Std           0.116823
trainer/Policy Action Max           0.297998
trainer/Policy Action Min          -0.316885
exploration/num steps total     90500
exploration/num paths total       905
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133996
exploration/Rewards Std             0.0736985
exploration/Rewards Max            -0.0129903
exploration/Rewards Min            -0.351048
exploration/Returns Mean          -13.3996
exploration/Returns Std             0.333324
exploration/Returns Max           -13.0662
exploration/Returns Min           -13.7329
exploration/Actions Mean            4.61952e-05
exploration/Actions Std             0.147452
exploration/Actions Max             0.420121
exploration/Actions Min            -0.42413
exploration/Num Paths               2
exploration/Average Returns       -13.3996
evaluation/num steps total     226000
evaluation/num paths total       2260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.055
evaluation/Rewards Std              0.0290912
evaluation/Rewards Max             -0.0414219
evaluation/Rewards Min             -0.70458
evaluation/Returns Mean            -5.5
evaluation/Returns Std              0.266529
evaluation/Returns Max             -5.35584
evaluation/Returns Min             -6.03293
evaluation/Actions Mean             0.00473888
evaluation/Actions Std              0.0708524
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.996408
evaluation/Num Paths                5
evaluation/Average Returns         -5.5
time/data storing (s)               0.00122124
time/evaluation sampling (s)        0.0751636
time/exploration sampling (s)       0.038543
time/logging (s)                    0.00252153
time/saving (s)                     0.00227212
time/training (s)                   0.45459
time/epoch (s)                      0.574311
time/total (s)                    271.259
Epoch                             451
-----------------------------  ----------------
2019-04-13 17:03:07.057879 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 452 finished
-----------------------------  ----------------
replay_buffer/size              90700
trainer/QF1 Loss                    0.0626171
trainer/QF2 Loss                    0.0628649
trainer/Policy Loss                12.8859
trainer/Q1 Predictions Mean       -13.2192
trainer/Q1 Predictions Std          0.830878
trainer/Q1 Predictions Max        -12.8126
trainer/Q1 Predictions Min        -16.268
trainer/Q2 Predictions Mean       -13.2293
trainer/Q2 Predictions Std          0.832684
trainer/Q2 Predictions Max        -12.8318
trainer/Q2 Predictions Min        -16.2549
trainer/Q Targets Mean            -13.2771
trainer/Q Targets Std               0.742653
trainer/Q Targets Max             -12.7348
trainer/Q Targets Min             -16.1844
trainer/Bellman Errors 1 Mean       0.0626171
trainer/Bellman Errors 1 Std        0.104161
trainer/Bellman Errors 1 Max        0.464709
trainer/Bellman Errors 1 Min        2.90128e-05
trainer/Bellman Errors 2 Mean       0.0628649
trainer/Bellman Errors 2 Std        0.101784
trainer/Bellman Errors 2 Max        0.447149
trainer/Bellman Errors 2 Min        3.52322e-05
trainer/Policy Action Mean          0.0906063
trainer/Policy Action Std           0.287877
trainer/Policy Action Max           0.999301
trainer/Policy Action Min          -0.367539
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140703
exploration/Rewards Std             0.0864575
exploration/Rewards Max            -0.00443027
exploration/Rewards Min            -0.861774
exploration/Returns Mean          -14.0703
exploration/Returns Std             0.165283
exploration/Returns Max           -13.905
exploration/Returns Min           -14.2356
exploration/Actions Mean            0.00835049
exploration/Actions Std             0.151221
exploration/Actions Max             1
exploration/Actions Min            -0.328613
exploration/Num Paths               2
exploration/Average Returns       -14.0703
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0682389
evaluation/Rewards Std              0.0513299
evaluation/Rewards Max             -0.0235618
evaluation/Rewards Min             -0.965651
evaluation/Returns Mean            -6.82389
evaluation/Returns Std              0.38433
evaluation/Returns Max             -6.48939
evaluation/Returns Min             -7.36996
evaluation/Actions Mean             0.00913546
evaluation/Actions Std              0.0836719
evaluation/Actions Max              1
evaluation/Actions Min             -0.0156748
evaluation/Num Paths                5
evaluation/Average Returns         -6.82389
time/data storing (s)               0.00104142
time/evaluation sampling (s)        0.0728498
time/exploration sampling (s)       0.032467
time/logging (s)                    0.00185049
time/saving (s)                     0.001756
time/training (s)                   0.457295
time/epoch (s)                      0.56726
time/total (s)                    271.83
Epoch                             452
-----------------------------  ----------------
2019-04-13 17:03:07.736583 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 453 finished
-----------------------------  ----------------
replay_buffer/size              90900
trainer/QF1 Loss                    0.0575491
trainer/QF2 Loss                    0.0605164
trainer/Policy Loss                12.7395
trainer/Q1 Predictions Mean       -12.9071
trainer/Q1 Predictions Std          0.148039
trainer/Q1 Predictions Max        -12.7521
trainer/Q1 Predictions Min        -13.5594
trainer/Q2 Predictions Mean       -12.9007
trainer/Q2 Predictions Std          0.153819
trainer/Q2 Predictions Max        -12.7269
trainer/Q2 Predictions Min        -13.571
trainer/Q Targets Mean            -13.0743
trainer/Q Targets Std               0.216294
trainer/Q Targets Max             -12.7479
trainer/Q Targets Min             -13.7684
trainer/Bellman Errors 1 Mean       0.0575491
trainer/Bellman Errors 1 Std        0.0823444
trainer/Bellman Errors 1 Max        0.359608
trainer/Bellman Errors 1 Min        2.42158e-05
trainer/Bellman Errors 2 Mean       0.0605164
trainer/Bellman Errors 2 Std        0.0860999
trainer/Bellman Errors 2 Max        0.384839
trainer/Bellman Errors 2 Min        0.000117143
trainer/Policy Action Mean          0.0612089
trainer/Policy Action Std           0.116972
trainer/Policy Action Max           0.390479
trainer/Policy Action Min          -0.430265
exploration/num steps total     90900
exploration/num paths total       909
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.147629
exploration/Rewards Std             0.0944603
exploration/Rewards Max            -0.0130058
exploration/Rewards Min            -0.900392
exploration/Returns Mean          -14.7629
exploration/Returns Std             0.580043
exploration/Returns Max           -14.1829
exploration/Returns Min           -15.343
exploration/Actions Mean            0.0102145
exploration/Actions Std             0.166694
exploration/Actions Max             1
exploration/Actions Min            -0.366943
exploration/Num Paths               2
exploration/Average Returns       -14.7629
evaluation/num steps total     227000
evaluation/num paths total       2270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0723367
evaluation/Rewards Std              0.0254792
evaluation/Rewards Max             -0.0257945
evaluation/Rewards Min             -0.616804
evaluation/Returns Mean            -7.23367
evaluation/Returns Std              0.192551
evaluation/Returns Max             -7.06791
evaluation/Returns Min             -7.59455
evaluation/Actions Mean             0.00561234
evaluation/Actions Std              0.0745311
evaluation/Actions Max              0.999984
evaluation/Actions Min             -0.979363
evaluation/Num Paths                5
evaluation/Average Returns         -7.23367
time/data storing (s)               0.00111276
time/evaluation sampling (s)        0.0834675
time/exploration sampling (s)       0.0344067
time/logging (s)                    0.0025002
time/saving (s)                     0.00198385
time/training (s)                   0.545484
time/epoch (s)                      0.668955
time/total (s)                    272.504
Epoch                             453
-----------------------------  ----------------
2019-04-13 17:03:08.352470 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 454 finished
-----------------------------  ----------------
replay_buffer/size              91100
trainer/QF1 Loss                    0.0219777
trainer/QF2 Loss                    0.0223386
trainer/Policy Loss                12.9013
trainer/Q1 Predictions Mean       -13.0342
trainer/Q1 Predictions Std          0.146886
trainer/Q1 Predictions Max        -12.8621
trainer/Q1 Predictions Min        -13.5488
trainer/Q2 Predictions Mean       -13.0386
trainer/Q2 Predictions Std          0.142988
trainer/Q2 Predictions Max        -12.8635
trainer/Q2 Predictions Min        -13.5595
trainer/Q Targets Mean            -13.0678
trainer/Q Targets Std               0.192549
trainer/Q Targets Max             -12.756
trainer/Q Targets Min             -13.5744
trainer/Bellman Errors 1 Mean       0.0219777
trainer/Bellman Errors 1 Std        0.0253618
trainer/Bellman Errors 1 Max        0.0888719
trainer/Bellman Errors 1 Min        0.000161316
trainer/Bellman Errors 2 Mean       0.0223386
trainer/Bellman Errors 2 Std        0.0261199
trainer/Bellman Errors 2 Max        0.0980262
trainer/Bellman Errors 2 Min        3.66731e-07
trainer/Policy Action Mean          0.0302859
trainer/Policy Action Std           0.12181
trainer/Policy Action Max           0.255827
trainer/Policy Action Min          -0.393715
exploration/num steps total     91100
exploration/num paths total       911
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.146725
exploration/Rewards Std             0.076915
exploration/Rewards Max            -0.00556528
exploration/Rewards Min            -0.400782
exploration/Returns Mean          -14.6725
exploration/Returns Std             0.471338
exploration/Returns Max           -14.2011
exploration/Returns Min           -15.1438
exploration/Actions Mean           -0.000389819
exploration/Actions Std             0.150786
exploration/Actions Max             0.637856
exploration/Actions Min            -0.761596
exploration/Num Paths               2
exploration/Average Returns       -14.6725
evaluation/num steps total     227500
evaluation/num paths total       2275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0837293
evaluation/Rewards Std              0.066468
evaluation/Rewards Max             -0.00505972
evaluation/Rewards Min             -0.99686
evaluation/Returns Mean            -8.37293
evaluation/Returns Std              0.336149
evaluation/Returns Max             -7.85439
evaluation/Returns Min             -8.73125
evaluation/Actions Mean             0.0103996
evaluation/Actions Std              0.0962999
evaluation/Actions Max              1
evaluation/Actions Min             -0.482532
evaluation/Num Paths                5
evaluation/Average Returns         -8.37293
time/data storing (s)               0.00104441
time/evaluation sampling (s)        0.0754491
time/exploration sampling (s)       0.0331016
time/logging (s)                    0.0024573
time/saving (s)                     0.00224863
time/training (s)                   0.491074
time/epoch (s)                      0.605375
time/total (s)                    273.113
Epoch                             454
-----------------------------  ----------------
2019-04-13 17:03:08.929016 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 455 finished
-----------------------------  ----------------
replay_buffer/size              91300
trainer/QF1 Loss                    5.15856
trainer/QF2 Loss                    5.16551
trainer/Policy Loss                12.8723
trainer/Q1 Predictions Mean       -13.076
trainer/Q1 Predictions Std          0.269731
trainer/Q1 Predictions Max        -12.8562
trainer/Q1 Predictions Min        -13.9861
trainer/Q2 Predictions Mean       -13.0639
trainer/Q2 Predictions Std          0.265864
trainer/Q2 Predictions Max        -12.8466
trainer/Q2 Predictions Min        -13.9187
trainer/Q Targets Mean            -12.7615
trainer/Q Targets Std               2.29405
trainer/Q Targets Max              -0.0977442
trainer/Q Targets Min             -13.9106
trainer/Bellman Errors 1 Mean       5.15856
trainer/Bellman Errors 1 Std       28.533
trainer/Bellman Errors 1 Max      164.023
trainer/Bellman Errors 1 Min        2.1738e-06
trainer/Bellman Errors 2 Mean       5.16551
trainer/Bellman Errors 2 Std       28.5476
trainer/Bellman Errors 2 Max      164.112
trainer/Bellman Errors 2 Min        4.4527e-05
trainer/Policy Action Mean         -0.00153317
trainer/Policy Action Std           0.193681
trainer/Policy Action Max           0.706949
trainer/Policy Action Min          -0.512348
exploration/num steps total     91300
exploration/num paths total       913
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12955
exploration/Rewards Std             0.066445
exploration/Rewards Max            -0.0113914
exploration/Rewards Min            -0.354409
exploration/Returns Mean          -12.955
exploration/Returns Std             0.0888857
exploration/Returns Max           -12.8661
exploration/Returns Min           -13.0438
exploration/Actions Mean           -0.000195801
exploration/Actions Std             0.160199
exploration/Actions Max             0.783473
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.955
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0208427
evaluation/Rewards Std              0.0464964
evaluation/Rewards Max             -0.015356
evaluation/Rewards Min             -0.8013
evaluation/Returns Mean            -2.08427
evaluation/Returns Std              0.302898
evaluation/Returns Max             -1.77738
evaluation/Returns Min             -2.52031
evaluation/Actions Mean             0.00850042
evaluation/Actions Std              0.0791923
evaluation/Actions Max              0.999996
evaluation/Actions Min             -0.0544739
evaluation/Num Paths                5
evaluation/Average Returns         -2.08427
time/data storing (s)               0.00116835
time/evaluation sampling (s)        0.0727714
time/exploration sampling (s)       0.0335293
time/logging (s)                    0.00251661
time/saving (s)                     0.00222097
time/training (s)                   0.4539
time/epoch (s)                      0.566106
time/total (s)                    273.683
Epoch                             455
-----------------------------  ----------------
2019-04-13 17:03:09.523011 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 456 finished
-----------------------------  ----------------
replay_buffer/size              91500
trainer/QF1 Loss                    0.0713645
trainer/QF2 Loss                    0.0658714
trainer/Policy Loss                12.722
trainer/Q1 Predictions Mean       -12.8891
trainer/Q1 Predictions Std          0.0968685
trainer/Q1 Predictions Max        -12.7578
trainer/Q1 Predictions Min        -13.2291
trainer/Q2 Predictions Mean       -12.9032
trainer/Q2 Predictions Std          0.0942009
trainer/Q2 Predictions Max        -12.7683
trainer/Q2 Predictions Min        -13.2358
trainer/Q Targets Mean            -13.0935
trainer/Q Targets Std               0.181243
trainer/Q Targets Max             -12.8275
trainer/Q Targets Min             -13.5486
trainer/Bellman Errors 1 Mean       0.0713646
trainer/Bellman Errors 1 Std        0.0869919
trainer/Bellman Errors 1 Max        0.340532
trainer/Bellman Errors 1 Min        0.000136704
trainer/Bellman Errors 2 Mean       0.0658714
trainer/Bellman Errors 2 Std        0.0821692
trainer/Bellman Errors 2 Max        0.337175
trainer/Bellman Errors 2 Min        3.29495e-05
trainer/Policy Action Mean         -0.0238792
trainer/Policy Action Std           0.0968423
trainer/Policy Action Max           0.198509
trainer/Policy Action Min          -0.250576
exploration/num steps total     91500
exploration/num paths total       915
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.129301
exploration/Rewards Std             0.0930969
exploration/Rewards Max            -0.00559676
exploration/Rewards Min            -1.00345
exploration/Returns Mean          -12.9301
exploration/Returns Std             0.780195
exploration/Returns Max           -12.1499
exploration/Returns Min           -13.7103
exploration/Actions Mean            0.00232373
exploration/Actions Std             0.161424
exploration/Actions Max             1
exploration/Actions Min            -0.86914
exploration/Num Paths               2
exploration/Average Returns       -12.9301
evaluation/num steps total     228500
evaluation/num paths total       2285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0265733
evaluation/Rewards Std              0.0254717
evaluation/Rewards Max             -0.0151841
evaluation/Rewards Min             -0.457972
evaluation/Returns Mean            -2.65733
evaluation/Returns Std              0.182578
evaluation/Returns Max             -2.50155
evaluation/Returns Min             -2.90722
evaluation/Actions Mean             0.00557279
evaluation/Actions Std              0.0718453
evaluation/Actions Max              0.999438
evaluation/Actions Min             -0.857189
evaluation/Num Paths                5
evaluation/Average Returns         -2.65733
time/data storing (s)               0.00105465
time/evaluation sampling (s)        0.0746328
time/exploration sampling (s)       0.0327338
time/logging (s)                    0.00246832
time/saving (s)                     0.00234992
time/training (s)                   0.470775
time/epoch (s)                      0.584015
time/total (s)                    274.271
Epoch                             456
-----------------------------  ----------------
2019-04-13 17:03:10.120230 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 457 finished
-----------------------------  ----------------
replay_buffer/size              91700
trainer/QF1 Loss                    0.0386684
trainer/QF2 Loss                    0.0382371
trainer/Policy Loss                12.9317
trainer/Q1 Predictions Mean       -13.0908
trainer/Q1 Predictions Std          0.162657
trainer/Q1 Predictions Max        -12.907
trainer/Q1 Predictions Min        -13.7836
trainer/Q2 Predictions Mean       -13.098
trainer/Q2 Predictions Std          0.162173
trainer/Q2 Predictions Max        -12.929
trainer/Q2 Predictions Min        -13.7755
trainer/Q Targets Mean            -13.1337
trainer/Q Targets Std               0.271367
trainer/Q Targets Max             -12.7561
trainer/Q Targets Min             -14.2491
trainer/Bellman Errors 1 Mean       0.0386684
trainer/Bellman Errors 1 Std        0.0538337
trainer/Bellman Errors 1 Max        0.216637
trainer/Bellman Errors 1 Min        6.29574e-05
trainer/Bellman Errors 2 Mean       0.0382371
trainer/Bellman Errors 2 Std        0.0520513
trainer/Bellman Errors 2 Max        0.22427
trainer/Bellman Errors 2 Min        0.000238688
trainer/Policy Action Mean         -0.00935767
trainer/Policy Action Std           0.131955
trainer/Policy Action Max           0.386663
trainer/Policy Action Min          -0.521073
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.120604
exploration/Rewards Std             0.0658004
exploration/Rewards Max            -0.0034158
exploration/Rewards Min            -0.534619
exploration/Returns Mean          -12.0604
exploration/Returns Std             0.551187
exploration/Returns Max           -11.5092
exploration/Returns Min           -12.6116
exploration/Actions Mean            0.0101038
exploration/Actions Std             0.15643
exploration/Actions Max             1
exploration/Actions Min            -0.362479
exploration/Num Paths               2
exploration/Average Returns       -12.0604
evaluation/num steps total     229000
evaluation/num paths total       2290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.012183
evaluation/Rewards Std              0.0380855
evaluation/Rewards Max             -0.00895955
evaluation/Rewards Min             -0.665734
evaluation/Returns Mean            -1.2183
evaluation/Returns Std              0.266009
evaluation/Returns Max             -0.906892
evaluation/Returns Min             -1.60996
evaluation/Actions Mean             0.0078032
evaluation/Actions Std              0.076856
evaluation/Actions Max              0.999992
evaluation/Actions Min             -0.0781013
evaluation/Num Paths                5
evaluation/Average Returns         -1.2183
time/data storing (s)               0.00104882
time/evaluation sampling (s)        0.0745309
time/exploration sampling (s)       0.033985
time/logging (s)                    0.00249147
time/saving (s)                     0.00221739
time/training (s)                   0.472514
time/epoch (s)                      0.586787
time/total (s)                    274.861
Epoch                             457
-----------------------------  ----------------
2019-04-13 17:03:10.701008 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 458 finished
-----------------------------  ----------------
replay_buffer/size              91900
trainer/QF1 Loss                    0.0964733
trainer/QF2 Loss                    0.0887607
trainer/Policy Loss                12.6846
trainer/Q1 Predictions Mean       -12.7987
trainer/Q1 Predictions Std          0.0853842
trainer/Q1 Predictions Max        -12.6616
trainer/Q1 Predictions Min        -13.0185
trainer/Q2 Predictions Mean       -12.8095
trainer/Q2 Predictions Std          0.0771638
trainer/Q2 Predictions Max        -12.6715
trainer/Q2 Predictions Min        -13.0038
trainer/Q Targets Mean            -13.0688
trainer/Q Targets Std               0.165271
trainer/Q Targets Max             -12.7629
trainer/Q Targets Min             -13.402
trainer/Bellman Errors 1 Mean       0.0964733
trainer/Bellman Errors 1 Std        0.0927962
trainer/Bellman Errors 1 Max        0.339988
trainer/Bellman Errors 1 Min        3.37536e-05
trainer/Bellman Errors 2 Mean       0.0887607
trainer/Bellman Errors 2 Std        0.0858484
trainer/Bellman Errors 2 Max        0.311067
trainer/Bellman Errors 2 Min        0.00187255
trainer/Policy Action Mean         -0.0110683
trainer/Policy Action Std           0.148095
trainer/Policy Action Max           0.766893
trainer/Policy Action Min          -0.222736
exploration/num steps total     91900
exploration/num paths total       919
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138073
exploration/Rewards Std             0.0892581
exploration/Rewards Max            -0.00319215
exploration/Rewards Min            -0.832708
exploration/Returns Mean          -13.8073
exploration/Returns Std             0.148924
exploration/Returns Max           -13.6584
exploration/Returns Min           -13.9563
exploration/Actions Mean            0.00760706
exploration/Actions Std             0.16241
exploration/Actions Max             0.911198
exploration/Actions Min            -0.440466
exploration/Num Paths               2
exploration/Average Returns       -13.8073
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0511633
evaluation/Rewards Std              0.0137385
evaluation/Rewards Max             -0.0484797
evaluation/Rewards Min             -0.322009
evaluation/Returns Mean            -5.11633
evaluation/Returns Std              0.0805485
evaluation/Returns Max             -5.0638
evaluation/Returns Min             -5.27482
evaluation/Actions Mean             0.0072278
evaluation/Actions Std              0.0764487
evaluation/Actions Max              0.998031
evaluation/Actions Min             -0.0556173
evaluation/Num Paths                5
evaluation/Average Returns         -5.11633
time/data storing (s)               0.00104976
time/evaluation sampling (s)        0.0718522
time/exploration sampling (s)       0.0337773
time/logging (s)                    0.00214543
time/saving (s)                     0.00201112
time/training (s)                   0.459656
time/epoch (s)                      0.570492
time/total (s)                    275.436
Epoch                             458
-----------------------------  ----------------
2019-04-13 17:03:11.283529 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 459 finished
-----------------------------  ----------------
replay_buffer/size              92100
trainer/QF1 Loss                    0.0389452
trainer/QF2 Loss                    0.0369917
trainer/Policy Loss                12.8405
trainer/Q1 Predictions Mean       -12.9891
trainer/Q1 Predictions Std          0.108115
trainer/Q1 Predictions Max        -12.8559
trainer/Q1 Predictions Min        -13.3508
trainer/Q2 Predictions Mean       -13.0063
trainer/Q2 Predictions Std          0.10414
trainer/Q2 Predictions Max        -12.8724
trainer/Q2 Predictions Min        -13.3613
trainer/Q Targets Mean            -13.0496
trainer/Q Targets Std               0.216869
trainer/Q Targets Max             -12.735
trainer/Q Targets Min             -13.6031
trainer/Bellman Errors 1 Mean       0.0389452
trainer/Bellman Errors 1 Std        0.0745828
trainer/Bellman Errors 1 Max        0.349337
trainer/Bellman Errors 1 Min        1.91279e-05
trainer/Bellman Errors 2 Mean       0.0369918
trainer/Bellman Errors 2 Std        0.0687443
trainer/Bellman Errors 2 Max        0.322676
trainer/Bellman Errors 2 Min        2.2574e-05
trainer/Policy Action Mean          0.0121373
trainer/Policy Action Std           0.154097
trainer/Policy Action Max           0.990789
trainer/Policy Action Min          -0.315826
exploration/num steps total     92100
exploration/num paths total       921
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.149874
exploration/Rewards Std             0.108189
exploration/Rewards Max            -0.00979731
exploration/Rewards Min            -1.16145
exploration/Returns Mean          -14.9874
exploration/Returns Std             0.973433
exploration/Returns Max           -14.014
exploration/Returns Min           -15.9609
exploration/Actions Mean            0.00622136
exploration/Actions Std             0.176286
exploration/Actions Max             0.906671
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.9874
evaluation/num steps total     230000
evaluation/num paths total       2300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0464903
evaluation/Rewards Std              0.00890385
evaluation/Rewards Max             -0.0071637
evaluation/Rewards Min             -0.238284
evaluation/Returns Mean            -4.64903
evaluation/Returns Std              0.0818607
evaluation/Returns Max             -4.57099
evaluation/Returns Min             -4.80658
evaluation/Actions Mean             0.0049762
evaluation/Actions Std              0.0742452
evaluation/Actions Max              0.952094
evaluation/Actions Min             -0.998801
evaluation/Num Paths                5
evaluation/Average Returns         -4.64903
time/data storing (s)               0.00121529
time/evaluation sampling (s)        0.0755722
time/exploration sampling (s)       0.0328849
time/logging (s)                    0.00248128
time/saving (s)                     0.00227008
time/training (s)                   0.458545
time/epoch (s)                      0.572968
time/total (s)                    276.012
Epoch                             459
-----------------------------  ----------------
2019-04-13 17:03:11.870608 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 460 finished
-----------------------------  ----------------
replay_buffer/size              92300
trainer/QF1 Loss                    0.129175
trainer/QF2 Loss                    0.121374
trainer/Policy Loss                12.6575
trainer/Q1 Predictions Mean       -12.766
trainer/Q1 Predictions Std          0.191411
trainer/Q1 Predictions Max        -12.5929
trainer/Q1 Predictions Min        -13.6423
trainer/Q2 Predictions Mean       -12.7774
trainer/Q2 Predictions Std          0.1806
trainer/Q2 Predictions Max        -12.6111
trainer/Q2 Predictions Min        -13.5879
trainer/Q Targets Mean            -13.0826
trainer/Q Targets Std               0.227648
trainer/Q Targets Max             -12.7593
trainer/Q Targets Min             -13.796
trainer/Bellman Errors 1 Mean       0.129175
trainer/Bellman Errors 1 Std        0.136025
trainer/Bellman Errors 1 Max        0.572046
trainer/Bellman Errors 1 Min        0.00495807
trainer/Bellman Errors 2 Mean       0.121374
trainer/Bellman Errors 2 Std        0.13565
trainer/Bellman Errors 2 Max        0.590795
trainer/Bellman Errors 2 Min        0.000256818
trainer/Policy Action Mean          0.0206634
trainer/Policy Action Std           0.17977
trainer/Policy Action Max           0.999978
trainer/Policy Action Min          -0.471049
exploration/num steps total     92300
exploration/num paths total       923
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126088
exploration/Rewards Std             0.0685966
exploration/Rewards Max            -0.00476629
exploration/Rewards Min            -0.375894
exploration/Returns Mean          -12.6088
exploration/Returns Std             0.0980197
exploration/Returns Max           -12.5108
exploration/Returns Min           -12.7068
exploration/Actions Mean            0.0043141
exploration/Actions Std             0.151149
exploration/Actions Max             0.887683
exploration/Actions Min            -0.893024
exploration/Num Paths               2
exploration/Average Returns       -12.6088
evaluation/num steps total     230500
evaluation/num paths total       2305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0319512
evaluation/Rewards Std              0.028519
evaluation/Rewards Max             -0.0093019
evaluation/Rewards Min             -0.525879
evaluation/Returns Mean            -3.19512
evaluation/Returns Std              0.226388
evaluation/Returns Max             -3.00055
evaluation/Returns Min             -3.51493
evaluation/Actions Mean             0.00473406
evaluation/Actions Std              0.0660841
evaluation/Actions Max              0.999854
evaluation/Actions Min             -0.896573
evaluation/Num Paths                5
evaluation/Average Returns         -3.19512
time/data storing (s)               0.0011373
time/evaluation sampling (s)        0.0737178
time/exploration sampling (s)       0.0320344
time/logging (s)                    0.0024673
time/saving (s)                     0.00246343
time/training (s)                   0.464847
time/epoch (s)                      0.576667
time/total (s)                    276.592
Epoch                             460
-----------------------------  ----------------
2019-04-13 17:03:12.493916 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 461 finished
-----------------------------  ----------------
replay_buffer/size              92500
trainer/QF1 Loss                    5.06812
trainer/QF2 Loss                    5.07572
trainer/Policy Loss                12.6273
trainer/Q1 Predictions Mean       -12.7298
trainer/Q1 Predictions Std          0.0968363
trainer/Q1 Predictions Max        -12.5713
trainer/Q1 Predictions Min        -12.977
trainer/Q2 Predictions Mean       -12.7218
trainer/Q2 Predictions Std          0.0935877
trainer/Q2 Predictions Max        -12.5893
trainer/Q2 Predictions Min        -12.9742
trainer/Q Targets Mean            -12.6142
trainer/Q Targets Std               2.2233
trainer/Q Targets Max              -0.266568
trainer/Q Targets Min             -13.3709
trainer/Bellman Errors 1 Mean       5.06812
trainer/Bellman Errors 1 Std       27.6242
trainer/Bellman Errors 1 Max      158.873
trainer/Bellman Errors 1 Min        0.000139281
trainer/Bellman Errors 2 Mean       5.07572
trainer/Bellman Errors 2 Std       27.6402
trainer/Bellman Errors 2 Max      158.969
trainer/Bellman Errors 2 Min        0.000295692
trainer/Policy Action Mean          0.0348326
trainer/Policy Action Std           0.0898914
trainer/Policy Action Max           0.245356
trainer/Policy Action Min          -0.162292
exploration/num steps total     92500
exploration/num paths total       925
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.144539
exploration/Rewards Std             0.0724521
exploration/Rewards Max            -0.00300058
exploration/Rewards Min            -0.410817
exploration/Returns Mean          -14.4539
exploration/Returns Std             0.502589
exploration/Returns Max           -13.9513
exploration/Returns Min           -14.9565
exploration/Actions Mean            0.00308488
exploration/Actions Std             0.155775
exploration/Actions Max             0.987152
exploration/Actions Min            -0.829481
exploration/Num Paths               2
exploration/Average Returns       -14.4539
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0747278
evaluation/Rewards Std              0.0244747
evaluation/Rewards Max             -0.0398752
evaluation/Rewards Min             -0.613499
evaluation/Returns Mean            -7.47278
evaluation/Returns Std              0.1935
evaluation/Returns Max             -7.33605
evaluation/Returns Min             -7.85549
evaluation/Actions Mean             0.00573526
evaluation/Actions Std              0.0759131
evaluation/Actions Max              0.999964
evaluation/Actions Min             -0.999487
evaluation/Num Paths                5
evaluation/Average Returns         -7.47278
time/data storing (s)               0.00111809
time/evaluation sampling (s)        0.0738856
time/exploration sampling (s)       0.0337892
time/logging (s)                    0.0024856
time/saving (s)                     0.010883
time/training (s)                   0.491051
time/epoch (s)                      0.613212
time/total (s)                    277.209
Epoch                             461
-----------------------------  ----------------
2019-04-13 17:03:13.088893 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 462 finished
-----------------------------  ----------------
replay_buffer/size              92700
trainer/QF1 Loss                    0.0631823
trainer/QF2 Loss                    0.0541064
trainer/Policy Loss                12.7816
trainer/Q1 Predictions Mean       -12.9436
trainer/Q1 Predictions Std          0.474523
trainer/Q1 Predictions Max        -12.7492
trainer/Q1 Predictions Min        -15.5629
trainer/Q2 Predictions Mean       -12.9614
trainer/Q2 Predictions Std          0.491232
trainer/Q2 Predictions Max        -12.7621
trainer/Q2 Predictions Min        -15.6728
trainer/Q Targets Mean            -13.1274
trainer/Q Targets Std               0.577723
trainer/Q Targets Max             -12.742
trainer/Q Targets Min             -16.2167
trainer/Bellman Errors 1 Mean       0.0631823
trainer/Bellman Errors 1 Std        0.0929708
trainer/Bellman Errors 1 Max        0.427427
trainer/Bellman Errors 1 Min        3.00806e-05
trainer/Bellman Errors 2 Mean       0.0541064
trainer/Bellman Errors 2 Std        0.0750573
trainer/Bellman Errors 2 Max        0.295764
trainer/Bellman Errors 2 Min        3.59605e-05
trainer/Policy Action Mean          0.0133875
trainer/Policy Action Std           0.164539
trainer/Policy Action Max           0.99977
trainer/Policy Action Min          -0.321944
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138306
exploration/Rewards Std             0.0789355
exploration/Rewards Max            -0.00640327
exploration/Rewards Min            -0.55218
exploration/Returns Mean          -13.8306
exploration/Returns Std             0.0259185
exploration/Returns Max           -13.8047
exploration/Returns Min           -13.8565
exploration/Actions Mean            0.00512261
exploration/Actions Std             0.168001
exploration/Actions Max             0.962937
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.8306
evaluation/num steps total     231500
evaluation/num paths total       2315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0482574
evaluation/Rewards Std              0.0541263
evaluation/Rewards Max             -0.0428829
evaluation/Rewards Min             -0.860626
evaluation/Returns Mean            -4.82574
evaluation/Returns Std              0.309845
evaluation/Returns Max             -4.43693
evaluation/Returns Min             -5.18646
evaluation/Actions Mean             0.00478988
evaluation/Actions Std              0.082195
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.993291
evaluation/Num Paths                5
evaluation/Average Returns         -4.82574
time/data storing (s)               0.00113927
time/evaluation sampling (s)        0.0753763
time/exploration sampling (s)       0.0335629
time/logging (s)                    0.00220486
time/saving (s)                     0.00179881
time/training (s)                   0.472569
time/epoch (s)                      0.586651
time/total (s)                    277.8
Epoch                             462
-----------------------------  ----------------
2019-04-13 17:03:13.665795 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 463 finished
-----------------------------  ----------------
replay_buffer/size              92900
trainer/QF1 Loss                    5.11
trainer/QF2 Loss                    5.0943
trainer/Policy Loss                12.7777
trainer/Q1 Predictions Mean       -12.8404
trainer/Q1 Predictions Std          0.0717327
trainer/Q1 Predictions Max        -12.7462
trainer/Q1 Predictions Min        -13.0158
trainer/Q2 Predictions Mean       -12.831
trainer/Q2 Predictions Std          0.0693275
trainer/Q2 Predictions Max        -12.6958
trainer/Q2 Predictions Min        -13.0137
trainer/Q Targets Mean            -12.6367
trainer/Q Targets Std               2.25782
trainer/Q Targets Max              -0.118093
trainer/Q Targets Min             -13.671
trainer/Bellman Errors 1 Mean       5.11
trainer/Bellman Errors 1 Std       28.0594
trainer/Bellman Errors 1 Max      161.338
trainer/Bellman Errors 1 Min        0.000117577
trainer/Bellman Errors 2 Mean       5.0943
trainer/Bellman Errors 2 Std       27.9428
trainer/Bellman Errors 2 Max      160.672
trainer/Bellman Errors 2 Min        0.000176762
trainer/Policy Action Mean         -0.0305154
trainer/Policy Action Std           0.17431
trainer/Policy Action Max           0.630752
trainer/Policy Action Min          -0.944499
exploration/num steps total     92900
exploration/num paths total       929
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131939
exploration/Rewards Std             0.0714598
exploration/Rewards Max            -0.019626
exploration/Rewards Min            -0.471788
exploration/Returns Mean          -13.1939
exploration/Returns Std             0.998819
exploration/Returns Max           -12.1951
exploration/Returns Min           -14.1927
exploration/Actions Mean            0.00336006
exploration/Actions Std             0.165775
exploration/Actions Max             1
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -13.1939
evaluation/num steps total     232000
evaluation/num paths total       2320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0182104
evaluation/Rewards Std              0.0436568
evaluation/Rewards Max             -0.0109675
evaluation/Rewards Min             -0.940248
evaluation/Returns Mean            -1.82104
evaluation/Returns Std              0.346124
evaluation/Returns Max             -1.52614
evaluation/Returns Min             -2.49704
evaluation/Actions Mean             0.00513109
evaluation/Actions Std              0.0828365
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.998886
evaluation/Num Paths                5
evaluation/Average Returns         -1.82104
time/data storing (s)               0.00111399
time/evaluation sampling (s)        0.0744786
time/exploration sampling (s)       0.0326603
time/logging (s)                    0.00204057
time/saving (s)                     0.00225786
time/training (s)                   0.454178
time/epoch (s)                      0.566729
time/total (s)                    278.37
Epoch                             463
-----------------------------  ----------------
2019-04-13 17:03:14.254771 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 464 finished
-----------------------------  ----------------
replay_buffer/size              93100
trainer/QF1 Loss                    0.020687
trainer/QF2 Loss                    0.0189729
trainer/Policy Loss                12.9519
trainer/Q1 Predictions Mean       -13.0572
trainer/Q1 Predictions Std          0.141634
trainer/Q1 Predictions Max        -12.9029
trainer/Q1 Predictions Min        -13.6129
trainer/Q2 Predictions Mean       -13.0435
trainer/Q2 Predictions Std          0.141275
trainer/Q2 Predictions Max        -12.9003
trainer/Q2 Predictions Min        -13.6352
trainer/Q Targets Mean            -13.0506
trainer/Q Targets Std               0.192857
trainer/Q Targets Max             -12.8174
trainer/Q Targets Min             -13.7722
trainer/Bellman Errors 1 Mean       0.0206869
trainer/Bellman Errors 1 Std        0.0259937
trainer/Bellman Errors 1 Max        0.109435
trainer/Bellman Errors 1 Min        0.000238599
trainer/Bellman Errors 2 Mean       0.0189729
trainer/Bellman Errors 2 Std        0.0229604
trainer/Bellman Errors 2 Max        0.0889941
trainer/Bellman Errors 2 Min        3.04914e-06
trainer/Policy Action Mean         -0.00179991
trainer/Policy Action Std           0.212158
trainer/Policy Action Max           0.724901
trainer/Policy Action Min          -0.999424
exploration/num steps total     93100
exploration/num paths total       931
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.125172
exploration/Rewards Std             0.0687936
exploration/Rewards Max            -0.0127039
exploration/Rewards Min            -0.315295
exploration/Returns Mean          -12.5172
exploration/Returns Std             0.387108
exploration/Returns Max           -12.1301
exploration/Returns Min           -12.9043
exploration/Actions Mean            0.00484623
exploration/Actions Std             0.149265
exploration/Actions Max             1
exploration/Actions Min            -0.368108
exploration/Num Paths               2
exploration/Average Returns       -12.5172
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0282245
evaluation/Rewards Std              0.0208797
evaluation/Rewards Max             -0.0235028
evaluation/Rewards Min             -0.428995
evaluation/Returns Mean            -2.82245
evaluation/Returns Std              0.158403
evaluation/Returns Max             -2.68829
evaluation/Returns Min             -3.08054
evaluation/Actions Mean             0.00384655
evaluation/Actions Std              0.0649639
evaluation/Actions Max              0.999797
evaluation/Actions Min             -0.945092
evaluation/Num Paths                5
evaluation/Average Returns         -2.82245
time/data storing (s)               0.00111555
time/evaluation sampling (s)        0.07444
time/exploration sampling (s)       0.0331192
time/logging (s)                    0.00246658
time/saving (s)                     0.00241899
time/training (s)                   0.465338
time/epoch (s)                      0.578898
time/total (s)                    278.953
Epoch                             464
-----------------------------  ----------------
2019-04-13 17:03:14.842942 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 465 finished
-----------------------------  ----------------
replay_buffer/size              93300
trainer/QF1 Loss                    0.0288264
trainer/QF2 Loss                    0.0284713
trainer/Policy Loss                12.9944
trainer/Q1 Predictions Mean       -13.1093
trainer/Q1 Predictions Std          0.08235
trainer/Q1 Predictions Max        -13.0009
trainer/Q1 Predictions Min        -13.3592
trainer/Q2 Predictions Mean       -13.1061
trainer/Q2 Predictions Std          0.0822004
trainer/Q2 Predictions Max        -12.9976
trainer/Q2 Predictions Min        -13.357
trainer/Q Targets Mean            -13.0377
trainer/Q Targets Std               0.140789
trainer/Q Targets Max             -12.7955
trainer/Q Targets Min             -13.3529
trainer/Bellman Errors 1 Mean       0.0288264
trainer/Bellman Errors 1 Std        0.022334
trainer/Bellman Errors 1 Max        0.0804916
trainer/Bellman Errors 1 Min        0.000311342
trainer/Bellman Errors 2 Mean       0.0284713
trainer/Bellman Errors 2 Std        0.0227784
trainer/Bellman Errors 2 Max        0.0911038
trainer/Bellman Errors 2 Min        0.000253224
trainer/Policy Action Mean         -0.00189038
trainer/Policy Action Std           0.110853
trainer/Policy Action Max           0.27901
trainer/Policy Action Min          -0.261435
exploration/num steps total     93300
exploration/num paths total       933
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131807
exploration/Rewards Std             0.0735268
exploration/Rewards Max            -0.00677505
exploration/Rewards Min            -0.611588
exploration/Returns Mean          -13.1807
exploration/Returns Std             0.738448
exploration/Returns Max           -12.4423
exploration/Returns Min           -13.9192
exploration/Actions Mean            0.00376997
exploration/Actions Std             0.167291
exploration/Actions Max             1
exploration/Actions Min            -0.777202
exploration/Num Paths               2
exploration/Average Returns       -13.1807
evaluation/num steps total     233000
evaluation/num paths total       2330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0241267
evaluation/Rewards Std              0.0406018
evaluation/Rewards Max             -0.0197906
evaluation/Rewards Min             -0.717788
evaluation/Returns Mean            -2.41267
evaluation/Returns Std              0.241762
evaluation/Returns Max             -2.09024
evaluation/Returns Min             -2.78092
evaluation/Actions Mean             0.00625036
evaluation/Actions Std              0.0844523
evaluation/Actions Max              0.999995
evaluation/Actions Min             -0.985764
evaluation/Num Paths                5
evaluation/Average Returns         -2.41267
time/data storing (s)               0.00130352
time/evaluation sampling (s)        0.0721259
time/exploration sampling (s)       0.0334628
time/logging (s)                    0.0024618
time/saving (s)                     0.0022553
time/training (s)                   0.466084
time/epoch (s)                      0.577693
time/total (s)                    279.534
Epoch                             465
-----------------------------  ----------------
2019-04-13 17:03:15.426572 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 466 finished
-----------------------------  ----------------
replay_buffer/size              93500
trainer/QF1 Loss                    0.0423791
trainer/QF2 Loss                    0.0443256
trainer/Policy Loss                12.8916
trainer/Q1 Predictions Mean       -12.9915
trainer/Q1 Predictions Std          0.224527
trainer/Q1 Predictions Max        -12.7847
trainer/Q1 Predictions Min        -13.7188
trainer/Q2 Predictions Mean       -12.9772
trainer/Q2 Predictions Std          0.209152
trainer/Q2 Predictions Max        -12.7756
trainer/Q2 Predictions Min        -13.6438
trainer/Q Targets Mean            -13.1063
trainer/Q Targets Std               0.219969
trainer/Q Targets Max             -12.8262
trainer/Q Targets Min             -13.7743
trainer/Bellman Errors 1 Mean       0.0423791
trainer/Bellman Errors 1 Std        0.0579698
trainer/Bellman Errors 1 Max        0.207183
trainer/Bellman Errors 1 Min        7.94173e-06
trainer/Bellman Errors 2 Mean       0.0443256
trainer/Bellman Errors 2 Std        0.0614834
trainer/Bellman Errors 2 Max        0.215526
trainer/Bellman Errors 2 Min        4.46622e-06
trainer/Policy Action Mean          0.0103917
trainer/Policy Action Std           0.321412
trainer/Policy Action Max           0.999985
trainer/Policy Action Min          -0.998808
exploration/num steps total     93500
exploration/num paths total       935
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135762
exploration/Rewards Std             0.0771828
exploration/Rewards Max            -0.0165112
exploration/Rewards Min            -0.634471
exploration/Returns Mean          -13.5762
exploration/Returns Std             0.629096
exploration/Returns Max           -12.9471
exploration/Returns Min           -14.2053
exploration/Actions Mean            0.0058815
exploration/Actions Std             0.152091
exploration/Actions Max             1
exploration/Actions Min            -0.385902
exploration/Num Paths               2
exploration/Average Returns       -13.5762
evaluation/num steps total     233500
evaluation/num paths total       2335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0347282
evaluation/Rewards Std              0.0151548
evaluation/Rewards Max             -0.0169632
evaluation/Rewards Min             -0.33351
evaluation/Returns Mean            -3.47282
evaluation/Returns Std              0.0939694
evaluation/Returns Max             -3.38159
evaluation/Returns Min             -3.65099
evaluation/Actions Mean             0.00462714
evaluation/Actions Std              0.0750515
evaluation/Actions Max              0.998648
evaluation/Actions Min             -0.988147
evaluation/Num Paths                5
evaluation/Average Returns         -3.47282
time/data storing (s)               0.00118712
time/evaluation sampling (s)        0.0749958
time/exploration sampling (s)       0.0326642
time/logging (s)                    0.00189469
time/saving (s)                     0.00182321
time/training (s)                   0.460422
time/epoch (s)                      0.572987
time/total (s)                    280.112
Epoch                             466
-----------------------------  ----------------
2019-04-13 17:03:16.019460 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 467 finished
-----------------------------  ----------------
replay_buffer/size              93700
trainer/QF1 Loss                    5.13706
trainer/QF2 Loss                    5.12888
trainer/Policy Loss                12.7763
trainer/Q1 Predictions Mean       -13.0457
trainer/Q1 Predictions Std          0.486958
trainer/Q1 Predictions Max        -12.7987
trainer/Q1 Predictions Min        -15.5699
trainer/Q2 Predictions Mean       -13.0388
trainer/Q2 Predictions Std          0.489136
trainer/Q2 Predictions Max        -12.8032
trainer/Q2 Predictions Min        -15.5808
trainer/Q Targets Mean            -12.7843
trainer/Q Targets Std               2.33599
trainer/Q Targets Max              -0.063208
trainer/Q Targets Min             -15.6558
trainer/Bellman Errors 1 Mean       5.13707
trainer/Bellman Errors 1 Std       28.3695
trainer/Bellman Errors 1 Max      163.091
trainer/Bellman Errors 1 Min        6.88238e-05
trainer/Bellman Errors 2 Mean       5.12888
trainer/Bellman Errors 2 Std       28.3198
trainer/Bellman Errors 2 Max      162.806
trainer/Bellman Errors 2 Min        1.25049e-05
trainer/Policy Action Mean          0.0275553
trainer/Policy Action Std           0.224742
trainer/Policy Action Max           0.999593
trainer/Policy Action Min          -0.527921
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131617
exploration/Rewards Std             0.0879501
exploration/Rewards Max            -0.0162931
exploration/Rewards Min            -0.795519
exploration/Returns Mean          -13.1617
exploration/Returns Std             0.175162
exploration/Returns Max           -12.9866
exploration/Returns Min           -13.3369
exploration/Actions Mean            0.0118548
exploration/Actions Std             0.164328
exploration/Actions Max             1
exploration/Actions Min            -0.425056
exploration/Num Paths               2
exploration/Average Returns       -13.1617
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0113324
evaluation/Rewards Std              0.0564613
evaluation/Rewards Max             -0.00641532
evaluation/Rewards Min             -0.890816
evaluation/Returns Mean            -1.13324
evaluation/Returns Std              0.362136
evaluation/Returns Max             -0.68143
evaluation/Returns Min             -1.58296
evaluation/Actions Mean             0.00516209
evaluation/Actions Std              0.0855589
evaluation/Actions Max              1
evaluation/Actions Min             -0.999369
evaluation/Num Paths                5
evaluation/Average Returns         -1.13324
time/data storing (s)               0.00133259
time/evaluation sampling (s)        0.0727482
time/exploration sampling (s)       0.0338757
time/logging (s)                    0.00249283
time/saving (s)                     0.00220841
time/training (s)                   0.470085
time/epoch (s)                      0.582742
time/total (s)                    280.699
Epoch                             467
-----------------------------  ----------------
2019-04-13 17:03:16.607896 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 468 finished
-----------------------------  ----------------
replay_buffer/size              93900
trainer/QF1 Loss                    0.0323908
trainer/QF2 Loss                    0.0314557
trainer/Policy Loss                12.9085
trainer/Q1 Predictions Mean       -13.0457
trainer/Q1 Predictions Std          0.172929
trainer/Q1 Predictions Max        -12.8794
trainer/Q1 Predictions Min        -13.7549
trainer/Q2 Predictions Mean       -13.0431
trainer/Q2 Predictions Std          0.16237
trainer/Q2 Predictions Max        -12.8901
trainer/Q2 Predictions Min        -13.685
trainer/Q Targets Mean            -13.0672
trainer/Q Targets Std               0.197453
trainer/Q Targets Max             -12.7441
trainer/Q Targets Min             -13.4852
trainer/Bellman Errors 1 Mean       0.0323908
trainer/Bellman Errors 1 Std        0.0428808
trainer/Bellman Errors 1 Max        0.196843
trainer/Bellman Errors 1 Min        0.000240933
trainer/Bellman Errors 2 Mean       0.0314557
trainer/Bellman Errors 2 Std        0.0450662
trainer/Bellman Errors 2 Max        0.22323
trainer/Bellman Errors 2 Min        0.000106457
trainer/Policy Action Mean          0.0138258
trainer/Policy Action Std           0.184641
trainer/Policy Action Max           0.732992
trainer/Policy Action Min          -0.508586
exploration/num steps total     93900
exploration/num paths total       939
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130784
exploration/Rewards Std             0.0691874
exploration/Rewards Max            -0.0143883
exploration/Rewards Min            -0.493479
exploration/Returns Mean          -13.0784
exploration/Returns Std             0.281737
exploration/Returns Max           -12.7967
exploration/Returns Min           -13.3602
exploration/Actions Mean            0.00400315
exploration/Actions Std             0.153065
exploration/Actions Max             0.922778
exploration/Actions Min            -0.394663
exploration/Num Paths               2
exploration/Average Returns       -13.0784
evaluation/num steps total     234500
evaluation/num paths total       2345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0527305
evaluation/Rewards Std              0.0158392
evaluation/Rewards Max             -0.0362835
evaluation/Rewards Min             -0.288372
evaluation/Returns Mean            -5.27305
evaluation/Returns Std              0.106319
evaluation/Returns Max             -5.14426
evaluation/Returns Min             -5.3987
evaluation/Actions Mean             0.00222224
evaluation/Actions Std              0.0708132
evaluation/Actions Max              0.997377
evaluation/Actions Min             -0.99329
evaluation/Num Paths                5
evaluation/Average Returns         -5.27305
time/data storing (s)               0.00113436
time/evaluation sampling (s)        0.0747746
time/exploration sampling (s)       0.033652
time/logging (s)                    0.00248408
time/saving (s)                     0.00223978
time/training (s)                   0.463526
time/epoch (s)                      0.57781
time/total (s)                    281.28
Epoch                             468
-----------------------------  ----------------
2019-04-13 17:03:17.186250 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 469 finished
-----------------------------  ----------------
replay_buffer/size              94100
trainer/QF1 Loss                    5.10006
trainer/QF2 Loss                    5.09794
trainer/Policy Loss                12.618
trainer/Q1 Predictions Mean       -12.8194
trainer/Q1 Predictions Std          0.126862
trainer/Q1 Predictions Max        -12.6759
trainer/Q1 Predictions Min        -13.2359
trainer/Q2 Predictions Mean       -12.8228
trainer/Q2 Predictions Std          0.132315
trainer/Q2 Predictions Max        -12.6702
trainer/Q2 Predictions Min        -13.2437
trainer/Q Targets Mean            -12.7509
trainer/Q Targets Std               2.27945
trainer/Q Targets Max              -0.111385
trainer/Q Targets Min             -13.5595
trainer/Bellman Errors 1 Mean       5.10006
trainer/Bellman Errors 1 Std       27.5937
trainer/Bellman Errors 1 Max      158.734
trainer/Bellman Errors 1 Min        0.0011269
trainer/Bellman Errors 2 Mean       5.09794
trainer/Bellman Errors 2 Std       27.5799
trainer/Bellman Errors 2 Max      158.654
trainer/Bellman Errors 2 Min        0.000185671
trainer/Policy Action Mean          0.0173958
trainer/Policy Action Std           0.13634
trainer/Policy Action Max           0.63016
trainer/Policy Action Min          -0.233502
exploration/num steps total     94100
exploration/num paths total       941
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127531
exploration/Rewards Std             0.0695688
exploration/Rewards Max            -0.00371149
exploration/Rewards Min            -0.34559
exploration/Returns Mean          -12.7531
exploration/Returns Std             0.328747
exploration/Returns Max           -12.4244
exploration/Returns Min           -13.0819
exploration/Actions Mean            0.000911733
exploration/Actions Std             0.156322
exploration/Actions Max             0.894083
exploration/Actions Min            -0.940091
exploration/Num Paths               2
exploration/Average Returns       -12.7531
evaluation/num steps total     235000
evaluation/num paths total       2350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0224481
evaluation/Rewards Std              0.0364936
evaluation/Rewards Max             -0.00124316
evaluation/Rewards Min             -0.634908
evaluation/Returns Mean            -2.24481
evaluation/Returns Std              0.275108
evaluation/Returns Max             -1.97606
evaluation/Returns Min             -2.62915
evaluation/Actions Mean             0.00440929
evaluation/Actions Std              0.073024
evaluation/Actions Max              0.999977
evaluation/Actions Min             -0.909634
evaluation/Num Paths                5
evaluation/Average Returns         -2.24481
time/data storing (s)               0.0011099
time/evaluation sampling (s)        0.073012
time/exploration sampling (s)       0.0319387
time/logging (s)                    0.00247051
time/saving (s)                     0.00224194
time/training (s)                   0.457074
time/epoch (s)                      0.567847
time/total (s)                    281.852
Epoch                             469
-----------------------------  ----------------
2019-04-13 17:03:17.778634 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 470 finished
-----------------------------  ----------------
replay_buffer/size              94300
trainer/QF1 Loss                    0.0726719
trainer/QF2 Loss                    0.0715045
trainer/Policy Loss                12.7983
trainer/Q1 Predictions Mean       -12.943
trainer/Q1 Predictions Std          0.37534
trainer/Q1 Predictions Max        -12.7614
trainer/Q1 Predictions Min        -14.9822
trainer/Q2 Predictions Mean       -12.9443
trainer/Q2 Predictions Std          0.369275
trainer/Q2 Predictions Max        -12.7682
trainer/Q2 Predictions Min        -14.952
trainer/Q Targets Mean            -13.1498
trainer/Q Targets Std               0.388698
trainer/Q Targets Max             -12.7467
trainer/Q Targets Min             -15.053
trainer/Bellman Errors 1 Mean       0.0726719
trainer/Bellman Errors 1 Std        0.0941435
trainer/Bellman Errors 1 Max        0.399459
trainer/Bellman Errors 1 Min        0.000313567
trainer/Bellman Errors 2 Mean       0.0715045
trainer/Bellman Errors 2 Std        0.0909005
trainer/Bellman Errors 2 Max        0.366116
trainer/Bellman Errors 2 Min        7.67455e-05
trainer/Policy Action Mean         -0.021757
trainer/Policy Action Std           0.203534
trainer/Policy Action Max           0.989116
trainer/Policy Action Min          -0.259216
exploration/num steps total     94300
exploration/num paths total       943
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.135992
exploration/Rewards Std             0.0734251
exploration/Rewards Max            -0.00756734
exploration/Rewards Min            -0.608167
exploration/Returns Mean          -13.5992
exploration/Returns Std             0.340117
exploration/Returns Max           -13.259
exploration/Returns Min           -13.9393
exploration/Actions Mean            0.00281614
exploration/Actions Std             0.148703
exploration/Actions Max             1
exploration/Actions Min            -0.592794
exploration/Num Paths               2
exploration/Average Returns       -13.5992
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0509355
evaluation/Rewards Std              0.0483919
evaluation/Rewards Max             -0.0336283
evaluation/Rewards Min             -0.950931
evaluation/Returns Mean            -5.09355
evaluation/Returns Std              0.384241
evaluation/Returns Max             -4.72614
evaluation/Returns Min             -5.70724
evaluation/Actions Mean             0.00407191
evaluation/Actions Std              0.0819337
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.992253
evaluation/Num Paths                5
evaluation/Average Returns         -5.09355
time/data storing (s)               0.00132359
time/evaluation sampling (s)        0.0764349
time/exploration sampling (s)       0.0324081
time/logging (s)                    0.00248683
time/saving (s)                     0.00245469
time/training (s)                   0.466572
time/epoch (s)                      0.581681
time/total (s)                    282.438
Epoch                             470
-----------------------------  ----------------
2019-04-13 17:03:18.362727 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 471 finished
-----------------------------  ----------------
replay_buffer/size              94500
trainer/QF1 Loss                    5.3789
trainer/QF2 Loss                    5.32571
trainer/Policy Loss                13.1384
trainer/Q1 Predictions Mean       -13.2484
trainer/Q1 Predictions Std          0.241928
trainer/Q1 Predictions Max        -13.0434
trainer/Q1 Predictions Min        -14.1648
trainer/Q2 Predictions Mean       -13.2233
trainer/Q2 Predictions Std          0.238812
trainer/Q2 Predictions Max        -13.0546
trainer/Q2 Predictions Min        -14.1349
trainer/Q Targets Mean            -12.7268
trainer/Q Targets Std               2.27287
trainer/Q Targets Max              -0.151223
trainer/Q Targets Min             -13.8552
trainer/Bellman Errors 1 Mean       5.3789
trainer/Bellman Errors 1 Std       29.7109
trainer/Bellman Errors 1 Max      170.802
trainer/Bellman Errors 1 Min        4.22656e-05
trainer/Bellman Errors 2 Mean       5.32571
trainer/Bellman Errors 2 Std       29.4416
trainer/Bellman Errors 2 Max      169.25
trainer/Bellman Errors 2 Min        9.12789e-06
trainer/Policy Action Mean         -0.00927946
trainer/Policy Action Std           0.172454
trainer/Policy Action Max           0.587563
trainer/Policy Action Min          -0.527007
exploration/num steps total     94500
exploration/num paths total       945
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.145203
exploration/Rewards Std             0.102141
exploration/Rewards Max            -0.0124588
exploration/Rewards Min            -1.06542
exploration/Returns Mean          -14.5203
exploration/Returns Std             0.613953
exploration/Returns Max           -13.9063
exploration/Returns Min           -15.1342
exploration/Actions Mean            0.00907798
exploration/Actions Std             0.178858
exploration/Actions Max             1
exploration/Actions Min            -0.843264
exploration/Num Paths               2
exploration/Average Returns       -14.5203
evaluation/num steps total     236000
evaluation/num paths total       2360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0364461
evaluation/Rewards Std              0.0425414
evaluation/Rewards Max             -0.0326594
evaluation/Rewards Min             -0.685599
evaluation/Returns Mean            -3.64461
evaluation/Returns Std              0.250508
evaluation/Returns Max             -3.36137
evaluation/Returns Min             -3.95992
evaluation/Actions Mean             0.00741101
evaluation/Actions Std              0.0849019
evaluation/Actions Max              0.999981
evaluation/Actions Min             -0.871115
evaluation/Num Paths                5
evaluation/Average Returns         -3.64461
time/data storing (s)               0.00110426
time/evaluation sampling (s)        0.0762052
time/exploration sampling (s)       0.0328172
time/logging (s)                    0.00246678
time/saving (s)                     0.00226211
time/training (s)                   0.458731
time/epoch (s)                      0.573587
time/total (s)                    283.015
Epoch                             471
-----------------------------  ----------------
2019-04-13 17:03:18.959017 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 472 finished
-----------------------------  ----------------
replay_buffer/size              94700
trainer/QF1 Loss                    5.31188
trainer/QF2 Loss                    5.31983
trainer/Policy Loss                12.9839
trainer/Q1 Predictions Mean       -13.1394
trainer/Q1 Predictions Std          0.154168
trainer/Q1 Predictions Max        -12.9974
trainer/Q1 Predictions Min        -13.8144
trainer/Q2 Predictions Mean       -13.1456
trainer/Q2 Predictions Std          0.158804
trainer/Q2 Predictions Max        -13.0034
trainer/Q2 Predictions Min        -13.8809
trainer/Q Targets Mean            -12.7024
trainer/Q Targets Std               2.28747
trainer/Q Targets Max              -0.0213904
trainer/Q Targets Min             -13.753
trainer/Bellman Errors 1 Mean       5.31188
trainer/Bellman Errors 1 Std       29.3798
trainer/Bellman Errors 1 Max      168.891
trainer/Bellman Errors 1 Min        1.30296e-05
trainer/Bellman Errors 2 Mean       5.31983
trainer/Bellman Errors 2 Std       29.4217
trainer/Bellman Errors 2 Max      169.133
trainer/Bellman Errors 2 Min        1.18526e-05
trainer/Policy Action Mean         -0.0164515
trainer/Policy Action Std           0.144069
trainer/Policy Action Max           0.602005
trainer/Policy Action Min          -0.539901
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124919
exploration/Rewards Std             0.060666
exploration/Rewards Max            -0.0041573
exploration/Rewards Min            -0.309988
exploration/Returns Mean          -12.4919
exploration/Returns Std             0.530419
exploration/Returns Max           -11.9615
exploration/Returns Min           -13.0223
exploration/Actions Mean            0.00599312
exploration/Actions Std             0.146652
exploration/Actions Max             0.761868
exploration/Actions Min            -0.406948
exploration/Num Paths               2
exploration/Average Returns       -12.4919
evaluation/num steps total     236500
evaluation/num paths total       2365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0503006
evaluation/Rewards Std              0.0491117
evaluation/Rewards Max             -0.029026
evaluation/Rewards Min             -0.832082
evaluation/Returns Mean            -5.03006
evaluation/Returns Std              0.354759
evaluation/Returns Max             -4.65858
evaluation/Returns Min             -5.47856
evaluation/Actions Mean             0.00423347
evaluation/Actions Std              0.0837557
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.99619
evaluation/Num Paths                5
evaluation/Average Returns         -5.03006
time/data storing (s)               0.00114441
time/evaluation sampling (s)        0.0746269
time/exploration sampling (s)       0.0346473
time/logging (s)                    0.00249171
time/saving (s)                     0.00229206
time/training (s)                   0.470474
time/epoch (s)                      0.585676
time/total (s)                    283.605
Epoch                             472
-----------------------------  ----------------
2019-04-13 17:03:19.558474 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 473 finished
-----------------------------  ----------------
replay_buffer/size              94900
trainer/QF1 Loss                    5.25957
trainer/QF2 Loss                    5.23934
trainer/Policy Loss                12.9322
trainer/Q1 Predictions Mean       -13.0831
trainer/Q1 Predictions Std          0.529466
trainer/Q1 Predictions Max        -12.8654
trainer/Q1 Predictions Min        -15.9671
trainer/Q2 Predictions Mean       -13.076
trainer/Q2 Predictions Std          0.525531
trainer/Q2 Predictions Max        -12.865
trainer/Q2 Predictions Min        -15.9278
trainer/Q Targets Mean            -12.745
trainer/Q Targets Std               2.31041
trainer/Q Targets Max              -0.260761
trainer/Q Targets Min             -16.108
trainer/Bellman Errors 1 Mean       5.25957
trainer/Bellman Errors 1 Std       29.1208
trainer/Bellman Errors 1 Max      167.397
trainer/Bellman Errors 1 Min        4.52042e-05
trainer/Bellman Errors 2 Mean       5.23934
trainer/Bellman Errors 2 Std       29.0027
trainer/Bellman Errors 2 Max      166.719
trainer/Bellman Errors 2 Min        1.47344e-05
trainer/Policy Action Mean          0.0205924
trainer/Policy Action Std           0.198063
trainer/Policy Action Max           0.999548
trainer/Policy Action Min          -0.205855
exploration/num steps total     94900
exploration/num paths total       949
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128235
exploration/Rewards Std             0.0671708
exploration/Rewards Max            -0.00817856
exploration/Rewards Min            -0.392987
exploration/Returns Mean          -12.8235
exploration/Returns Std             0.0273256
exploration/Returns Max           -12.7961
exploration/Returns Min           -12.8508
exploration/Actions Mean            0.00538029
exploration/Actions Std             0.158693
exploration/Actions Max             0.976232
exploration/Actions Min            -0.974126
exploration/Num Paths               2
exploration/Average Returns       -12.8235
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0166267
evaluation/Rewards Std              0.0468255
evaluation/Rewards Max             -0.0127611
evaluation/Rewards Min             -0.879049
evaluation/Returns Mean            -1.66267
evaluation/Returns Std              0.374769
evaluation/Returns Max             -1.35648
evaluation/Returns Min             -2.2542
evaluation/Actions Mean             0.00705772
evaluation/Actions Std              0.0752552
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.381355
evaluation/Num Paths                5
evaluation/Average Returns         -1.66267
time/data storing (s)               0.0010846
time/evaluation sampling (s)        0.0757562
time/exploration sampling (s)       0.032241
time/logging (s)                    0.00246635
time/saving (s)                     0.00227394
time/training (s)                   0.474961
time/epoch (s)                      0.588783
time/total (s)                    284.198
Epoch                             473
-----------------------------  ----------------
2019-04-13 17:03:20.155753 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 474 finished
-----------------------------  ----------------
replay_buffer/size              95100
trainer/QF1 Loss                    5.23196
trainer/QF2 Loss                    5.23419
trainer/Policy Loss                13.0226
trainer/Q1 Predictions Mean       -13.1697
trainer/Q1 Predictions Std          0.365909
trainer/Q1 Predictions Max        -12.9326
trainer/Q1 Predictions Min        -14.8402
trainer/Q2 Predictions Mean       -13.1531
trainer/Q2 Predictions Std          0.372939
trainer/Q2 Predictions Max        -12.9077
trainer/Q2 Predictions Min        -14.8507
trainer/Q Targets Mean            -12.7707
trainer/Q Targets Std               2.29503
trainer/Q Targets Max              -0.195948
trainer/Q Targets Min             -14.8386
trainer/Bellman Errors 1 Mean       5.23196
trainer/Bellman Errors 1 Std       29.0033
trainer/Bellman Errors 1 Max      166.715
trainer/Bellman Errors 1 Min        2.3663e-06
trainer/Bellman Errors 2 Mean       5.23419
trainer/Bellman Errors 2 Std       29.0172
trainer/Bellman Errors 2 Max      166.795
trainer/Bellman Errors 2 Min        9.18612e-07
trainer/Policy Action Mean         -0.0231155
trainer/Policy Action Std           0.226373
trainer/Policy Action Max           1
trainer/Policy Action Min          -0.618108
exploration/num steps total     95100
exploration/num paths total       951
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.138379
exploration/Rewards Std             0.089766
exploration/Rewards Max            -0.0145026
exploration/Rewards Min            -0.917006
exploration/Returns Mean          -13.8379
exploration/Returns Std             0.510565
exploration/Returns Max           -13.3274
exploration/Returns Min           -14.3485
exploration/Actions Mean            0.00425006
exploration/Actions Std             0.162054
exploration/Actions Max             0.95131
exploration/Actions Min            -0.819741
exploration/Num Paths               2
exploration/Average Returns       -13.8379
evaluation/num steps total     237500
evaluation/num paths total       2375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0623132
evaluation/Rewards Std              0.0495933
evaluation/Rewards Max             -0.0553243
evaluation/Rewards Min             -0.857644
evaluation/Returns Mean            -6.23132
evaluation/Returns Std              0.321865
evaluation/Returns Max             -5.86466
evaluation/Returns Min             -6.64857
evaluation/Actions Mean             0.00683214
evaluation/Actions Std              0.0757457
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.395361
evaluation/Num Paths                5
evaluation/Average Returns         -6.23132
time/data storing (s)               0.00116476
time/evaluation sampling (s)        0.0734947
time/exploration sampling (s)       0.0326667
time/logging (s)                    0.0025425
time/saving (s)                     0.00231559
time/training (s)                   0.47528
time/epoch (s)                      0.587464
time/total (s)                    284.789
Epoch                             474
-----------------------------  ----------------
2019-04-13 17:03:20.742111 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 475 finished
-----------------------------  ----------------
replay_buffer/size              95300
trainer/QF1 Loss                    0.0446724
trainer/QF2 Loss                    0.0484052
trainer/Policy Loss                12.9784
trainer/Q1 Predictions Mean       -13.1099
trainer/Q1 Predictions Std          0.431079
trainer/Q1 Predictions Max        -12.9269
trainer/Q1 Predictions Min        -15.4578
trainer/Q2 Predictions Mean       -13.0982
trainer/Q2 Predictions Std          0.417164
trainer/Q2 Predictions Max        -12.9064
trainer/Q2 Predictions Min        -15.3616
trainer/Q Targets Mean            -13.2241
trainer/Q Targets Std               0.476695
trainer/Q Targets Max             -12.758
trainer/Q Targets Min             -15.6432
trainer/Bellman Errors 1 Mean       0.0446724
trainer/Bellman Errors 1 Std        0.0635605
trainer/Bellman Errors 1 Max        0.210485
trainer/Bellman Errors 1 Min        2.38419e-05
trainer/Bellman Errors 2 Mean       0.0484052
trainer/Bellman Errors 2 Std        0.0665427
trainer/Bellman Errors 2 Max        0.230542
trainer/Bellman Errors 2 Min        7.30466e-06
trainer/Policy Action Mean          0.0198217
trainer/Policy Action Std           0.159784
trainer/Policy Action Max           0.999837
trainer/Policy Action Min          -0.245507
exploration/num steps total     95300
exploration/num paths total       953
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130626
exploration/Rewards Std             0.0955809
exploration/Rewards Max            -0.00748637
exploration/Rewards Min            -1.02938
exploration/Returns Mean          -13.0626
exploration/Returns Std             0.322803
exploration/Returns Max           -12.7398
exploration/Returns Min           -13.3854
exploration/Actions Mean            0.0121833
exploration/Actions Std             0.174328
exploration/Actions Max             1
exploration/Actions Min            -0.436803
exploration/Num Paths               2
exploration/Average Returns       -13.0626
evaluation/num steps total     238000
evaluation/num paths total       2380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.00837322
evaluation/Rewards Std              0.0399229
evaluation/Rewards Max             -0.00358482
evaluation/Rewards Min             -0.830108
evaluation/Returns Mean            -0.837322
evaluation/Returns Std              0.294027
evaluation/Returns Max             -0.58132
evaluation/Returns Min             -1.38031
evaluation/Actions Mean             0.00266173
evaluation/Actions Std              0.0830385
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.999345
evaluation/Num Paths                5
evaluation/Average Returns         -0.837322
time/data storing (s)               0.00113132
time/evaluation sampling (s)        0.0724528
time/exploration sampling (s)       0.0327543
time/logging (s)                    0.00259171
time/saving (s)                     0.00228612
time/training (s)                   0.464784
time/epoch (s)                      0.576001
time/total (s)                    285.368
Epoch                             475
-----------------------------  ----------------
2019-04-13 17:03:21.328234 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 476 finished
-----------------------------  ---------------
replay_buffer/size              95500
trainer/QF1 Loss                    0.10232
trainer/QF2 Loss                    0.099456
trainer/Policy Loss                12.7591
trainer/Q1 Predictions Mean       -12.8718
trainer/Q1 Predictions Std          0.0696812
trainer/Q1 Predictions Max        -12.7442
trainer/Q1 Predictions Min        -13.0401
trainer/Q2 Predictions Mean       -12.8755
trainer/Q2 Predictions Std          0.06903
trainer/Q2 Predictions Max        -12.7501
trainer/Q2 Predictions Min        -13.0394
trainer/Q Targets Mean            -13.1542
trainer/Q Targets Std               0.16051
trainer/Q Targets Max             -12.8879
trainer/Q Targets Min             -13.5308
trainer/Bellman Errors 1 Mean       0.10232
trainer/Bellman Errors 1 Std        0.104593
trainer/Bellman Errors 1 Max        0.481869
trainer/Bellman Errors 1 Min        0.00188545
trainer/Bellman Errors 2 Mean       0.099456
trainer/Bellman Errors 2 Std        0.0996568
trainer/Bellman Errors 2 Max        0.442028
trainer/Bellman Errors 2 Min        0.00172503
trainer/Policy Action Mean         -0.023969
trainer/Policy Action Std           0.103446
trainer/Policy Action Max           0.264148
trainer/Policy Action Min          -0.221229
exploration/num steps total     95500
exploration/num paths total       955
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.131429
exploration/Rewards Std             0.0783203
exploration/Rewards Max            -0.00552015
exploration/Rewards Min            -0.553173
exploration/Returns Mean          -13.1429
exploration/Returns Std             0.676614
exploration/Returns Max           -12.4663
exploration/Returns Min           -13.8195
exploration/Actions Mean            0.00898176
exploration/Actions Std             0.152222
exploration/Actions Max             1
exploration/Actions Min            -0.393105
exploration/Num Paths               2
exploration/Average Returns       -13.1429
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0466184
evaluation/Rewards Std              0.0490253
evaluation/Rewards Max             -0.0283716
evaluation/Rewards Min             -0.917445
evaluation/Returns Mean            -4.66184
evaluation/Returns Std              0.328149
evaluation/Returns Max             -4.27854
evaluation/Returns Min             -5.15069
evaluation/Actions Mean             0.00449345
evaluation/Actions Std              0.0958284
evaluation/Actions Max              1
evaluation/Actions Min             -0.999613
evaluation/Num Paths                5
evaluation/Average Returns         -4.66184
time/data storing (s)               0.00176838
time/evaluation sampling (s)        0.0735102
time/exploration sampling (s)       0.0325055
time/logging (s)                    0.00252547
time/saving (s)                     0.00222347
time/training (s)                   0.463542
time/epoch (s)                      0.576075
time/total (s)                    285.949
Epoch                             476
-----------------------------  ---------------
2019-04-13 17:03:21.905000 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 477 finished
-----------------------------  ----------------
replay_buffer/size              95700
trainer/QF1 Loss                    0.0791103
trainer/QF2 Loss                    0.0843677
trainer/Policy Loss                12.8385
trainer/Q1 Predictions Mean       -13.0427
trainer/Q1 Predictions Std          0.47476
trainer/Q1 Predictions Max        -12.8294
trainer/Q1 Predictions Min        -15.6305
trainer/Q2 Predictions Mean       -13.0383
trainer/Q2 Predictions Std          0.466853
trainer/Q2 Predictions Max        -12.8313
trainer/Q2 Predictions Min        -15.5734
trainer/Q Targets Mean            -13.2482
trainer/Q Targets Std               0.600858
trainer/Q Targets Max             -12.8564
trainer/Q Targets Min             -16.5125
trainer/Bellman Errors 1 Mean       0.0791103
trainer/Bellman Errors 1 Std        0.14171
trainer/Bellman Errors 1 Max        0.777996
trainer/Bellman Errors 1 Min        6.04257e-05
trainer/Bellman Errors 2 Mean       0.0843677
trainer/Bellman Errors 2 Std        0.157619
trainer/Bellman Errors 2 Max        0.881891
trainer/Bellman Errors 2 Min        0.000127692
trainer/Policy Action Mean          0.0450763
trainer/Policy Action Std           0.253457
trainer/Policy Action Max           0.999919
trainer/Policy Action Min          -0.21256
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.139218
exploration/Rewards Std             0.0783635
exploration/Rewards Max            -0.0261119
exploration/Rewards Min            -0.649872
exploration/Returns Mean          -13.9218
exploration/Returns Std             0.335136
exploration/Returns Max           -13.5866
exploration/Returns Min           -14.2569
exploration/Actions Mean            0.00916441
exploration/Actions Std             0.167953
exploration/Actions Max             1
exploration/Actions Min            -0.384879
exploration/Num Paths               2
exploration/Average Returns       -13.9218
evaluation/num steps total     239000
evaluation/num paths total       2390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0282372
evaluation/Rewards Std              0.0623582
evaluation/Rewards Max             -0.0224383
evaluation/Rewards Min             -0.765341
evaluation/Returns Mean            -2.82372
evaluation/Returns Std              0.285976
evaluation/Returns Max             -2.26174
evaluation/Returns Min             -3.01017
evaluation/Actions Mean             0.00709758
evaluation/Actions Std              0.083619
evaluation/Actions Max              0.999997
evaluation/Actions Min             -0.512435
evaluation/Num Paths                5
evaluation/Average Returns         -2.82372
time/data storing (s)               0.00106846
time/evaluation sampling (s)        0.074008
time/exploration sampling (s)       0.0322674
time/logging (s)                    0.002458
time/saving (s)                     0.0024746
time/training (s)                   0.453765
time/epoch (s)                      0.566042
time/total (s)                    286.519
Epoch                             477
-----------------------------  ----------------
2019-04-13 17:03:22.500262 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 478 finished
-----------------------------  ----------------
replay_buffer/size              95900
trainer/QF1 Loss                    0.0404429
trainer/QF2 Loss                    0.0375068
trainer/Policy Loss                13.1441
trainer/Q1 Predictions Mean       -13.3699
trainer/Q1 Predictions Std          0.456966
trainer/Q1 Predictions Max        -13.1089
trainer/Q1 Predictions Min        -15.7522
trainer/Q2 Predictions Mean       -13.3592
trainer/Q2 Predictions Std          0.449404
trainer/Q2 Predictions Max        -13.1032
trainer/Q2 Predictions Min        -15.6999
trainer/Q Targets Mean            -13.2155
trainer/Q Targets Std               0.445397
trainer/Q Targets Max             -12.8719
trainer/Q Targets Min             -15.5059
trainer/Bellman Errors 1 Mean       0.0404429
trainer/Bellman Errors 1 Std        0.0383575
trainer/Bellman Errors 1 Max        0.129987
trainer/Bellman Errors 1 Min        0.000343286
trainer/Bellman Errors 2 Mean       0.0375068
trainer/Bellman Errors 2 Std        0.0361959
trainer/Bellman Errors 2 Max        0.120634
trainer/Bellman Errors 2 Min        6.43038e-06
trainer/Policy Action Mean         -0.00553475
trainer/Policy Action Std           0.183835
trainer/Policy Action Max           0.999606
trainer/Policy Action Min          -0.544013
exploration/num steps total     95900
exploration/num paths total       959
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.143276
exploration/Rewards Std             0.0687565
exploration/Rewards Max            -0.00771483
exploration/Rewards Min            -0.341913
exploration/Returns Mean          -14.3276
exploration/Returns Std             0.846112
exploration/Returns Max           -13.4815
exploration/Returns Min           -15.1737
exploration/Actions Mean            0.00103051
exploration/Actions Std             0.16709
exploration/Actions Max             0.962403
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -14.3276
evaluation/num steps total     239500
evaluation/num paths total       2395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0389408
evaluation/Rewards Std              0.0473744
evaluation/Rewards Max             -0.0355845
evaluation/Rewards Min             -0.989533
evaluation/Returns Mean            -3.89408
evaluation/Returns Std              0.376659
evaluation/Returns Max             -3.56512
evaluation/Returns Min             -4.56581
evaluation/Actions Mean             0.00144576
evaluation/Actions Std              0.076051
evaluation/Actions Max              1
evaluation/Actions Min             -0.99943
evaluation/Num Paths                5
evaluation/Average Returns         -3.89408
time/data storing (s)               0.00111994
time/evaluation sampling (s)        0.0736172
time/exploration sampling (s)       0.0342862
time/logging (s)                    0.00245775
time/saving (s)                     0.00176513
time/training (s)                   0.471388
time/epoch (s)                      0.584634
time/total (s)                    287.107
Epoch                             478
-----------------------------  ----------------
2019-04-13 17:03:23.095826 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 479 finished
-----------------------------  ---------------
replay_buffer/size              96100
trainer/QF1 Loss                    0.190486
trainer/QF2 Loss                    0.183175
trainer/Policy Loss                12.6854
trainer/Q1 Predictions Mean       -12.7896
trainer/Q1 Predictions Std          0.213686
trainer/Q1 Predictions Max        -12.5856
trainer/Q1 Predictions Min        -13.6106
trainer/Q2 Predictions Mean       -12.7951
trainer/Q2 Predictions Std          0.208213
trainer/Q2 Predictions Max        -12.6016
trainer/Q2 Predictions Min        -13.5819
trainer/Q Targets Mean            -13.1858
trainer/Q Targets Std               0.193704
trainer/Q Targets Max             -12.8508
trainer/Q Targets Min             -13.6536
trainer/Bellman Errors 1 Mean       0.190486
trainer/Bellman Errors 1 Std        0.150631
trainer/Bellman Errors 1 Max        0.623455
trainer/Bellman Errors 1 Min        0.00184869
trainer/Bellman Errors 2 Mean       0.183175
trainer/Bellman Errors 2 Std        0.145693
trainer/Bellman Errors 2 Max        0.616497
trainer/Bellman Errors 2 Min        0.00513721
trainer/Policy Action Mean          0.013244
trainer/Policy Action Std           0.170258
trainer/Policy Action Max           0.519748
trainer/Policy Action Min          -0.507261
exploration/num steps total     96100
exploration/num paths total       961
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.152091
exploration/Rewards Std             0.0991879
exploration/Rewards Max            -0.00250248
exploration/Rewards Min            -0.90025
exploration/Returns Mean          -15.2091
exploration/Returns Std             0.118329
exploration/Returns Max           -15.0908
exploration/Returns Min           -15.3275
exploration/Actions Mean            0.012716
exploration/Actions Std             0.169511
exploration/Actions Max             1
exploration/Actions Min            -0.43566
exploration/Num Paths               2
exploration/Average Returns       -15.2091
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0712337
evaluation/Rewards Std              0.0207545
evaluation/Rewards Max             -0.0436312
evaluation/Rewards Min             -0.419536
evaluation/Returns Mean            -7.12337
evaluation/Returns Std              0.161103
evaluation/Returns Max             -6.96159
evaluation/Returns Min             -7.34371
evaluation/Actions Mean             0.00610559
evaluation/Actions Std              0.0762899
evaluation/Actions Max              0.999702
evaluation/Actions Min             -0.744806
evaluation/Num Paths                5
evaluation/Average Returns         -7.12337
time/data storing (s)               0.00105693
time/evaluation sampling (s)        0.0751382
time/exploration sampling (s)       0.033006
time/logging (s)                    0.0024517
time/saving (s)                     0.00227043
time/training (s)                   0.471363
time/epoch (s)                      0.585286
time/total (s)                    287.696
Epoch                             479
-----------------------------  ---------------
2019-04-13 17:03:23.689866 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 480 finished
-----------------------------  ----------------
replay_buffer/size              96300
trainer/QF1 Loss                    0.0525637
trainer/QF2 Loss                    0.0534124
trainer/Policy Loss                12.8808
trainer/Q1 Predictions Mean       -12.9724
trainer/Q1 Predictions Std          0.0751186
trainer/Q1 Predictions Max        -12.8487
trainer/Q1 Predictions Min        -13.1528
trainer/Q2 Predictions Mean       -12.9714
trainer/Q2 Predictions Std          0.0789961
trainer/Q2 Predictions Max        -12.8629
trainer/Q2 Predictions Min        -13.1685
trainer/Q Targets Mean            -13.128
trainer/Q Targets Std               0.179148
trainer/Q Targets Max             -12.9059
trainer/Q Targets Min             -13.6539
trainer/Bellman Errors 1 Mean       0.0525637
trainer/Bellman Errors 1 Std        0.093952
trainer/Bellman Errors 1 Max        0.485709
trainer/Bellman Errors 1 Min        0.000166321
trainer/Bellman Errors 2 Mean       0.0534124
trainer/Bellman Errors 2 Std        0.0922591
trainer/Bellman Errors 2 Max        0.469624
trainer/Bellman Errors 2 Min        2.86237e-05
trainer/Policy Action Mean         -0.00234979
trainer/Policy Action Std           0.101795
trainer/Policy Action Max           0.206876
trainer/Policy Action Min          -0.254158
exploration/num steps total     96300
exploration/num paths total       963
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.130535
exploration/Rewards Std             0.0709204
exploration/Rewards Max            -0.0109804
exploration/Rewards Min            -0.665519
exploration/Returns Mean          -13.0535
exploration/Returns Std             0.557406
exploration/Returns Max           -12.4961
exploration/Returns Min           -13.6109
exploration/Actions Mean            0.00518695
exploration/Actions Std             0.148609
exploration/Actions Max             0.984121
exploration/Actions Min            -0.94265
exploration/Num Paths               2
exploration/Average Returns       -13.0535
evaluation/num steps total     240500
evaluation/num paths total       2405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0494285
evaluation/Rewards Std              0.0532608
evaluation/Rewards Max             -0.0242877
evaluation/Rewards Min             -1.01677
evaluation/Returns Mean            -4.94285
evaluation/Returns Std              0.378334
evaluation/Returns Max             -4.53094
evaluation/Returns Min             -5.53494
evaluation/Actions Mean             0.00710075
evaluation/Actions Std              0.0746325
evaluation/Actions Max              1
evaluation/Actions Min             -0.60015
evaluation/Num Paths                5
evaluation/Average Returns         -4.94285
time/data storing (s)               0.00113328
time/evaluation sampling (s)        0.0746616
time/exploration sampling (s)       0.0324467
time/logging (s)                    0.00247053
time/saving (s)                     0.00223124
time/training (s)                   0.470937
time/epoch (s)                      0.58388
time/total (s)                    288.284
Epoch                             480
-----------------------------  ----------------
2019-04-13 17:03:24.287737 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 481 finished
-----------------------------  ----------------
replay_buffer/size              96500
trainer/QF1 Loss                    0.100652
trainer/QF2 Loss                    0.104029
trainer/Policy Loss                12.8909
trainer/Q1 Predictions Mean       -13.0216
trainer/Q1 Predictions Std          0.460287
trainer/Q1 Predictions Max        -12.8032
trainer/Q1 Predictions Min        -15.5406
trainer/Q2 Predictions Mean       -13.0132
trainer/Q2 Predictions Std          0.455004
trainer/Q2 Predictions Max        -12.8323
trainer/Q2 Predictions Min        -15.5115
trainer/Q Targets Mean            -13.2736
trainer/Q Targets Std               0.483557
trainer/Q Targets Max             -12.8809
trainer/Q Targets Min             -15.6725
trainer/Bellman Errors 1 Mean       0.100652
trainer/Bellman Errors 1 Std        0.135984
trainer/Bellman Errors 1 Max        0.652739
trainer/Bellman Errors 1 Min        9.29982e-05
trainer/Bellman Errors 2 Mean       0.104029
trainer/Bellman Errors 2 Std        0.140847
trainer/Bellman Errors 2 Max        0.686464
trainer/Bellman Errors 2 Min        0.000137597
trainer/Policy Action Mean          0.00321156
trainer/Policy Action Std           0.152215
trainer/Policy Action Max           0.999607
trainer/Policy Action Min          -0.192239
exploration/num steps total     96500
exploration/num paths total       965
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.13697
exploration/Rewards Std             0.0729891
exploration/Rewards Max            -0.0198442
exploration/Rewards Min            -0.371833
exploration/Returns Mean          -13.697
exploration/Returns Std             0.355778
exploration/Returns Max           -13.3412
exploration/Returns Min           -14.0527
exploration/Actions Mean            0.00153694
exploration/Actions Std             0.142674
exploration/Actions Max             0.431932
exploration/Actions Min            -0.3897
exploration/Num Paths               2
exploration/Average Returns       -13.697
evaluation/num steps total     241000
evaluation/num paths total       2410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0656917
evaluation/Rewards Std              0.00546927
evaluation/Rewards Max             -0.0594832
evaluation/Rewards Min             -0.140497
evaluation/Returns Mean            -6.56917
evaluation/Returns Std              0.0243913
evaluation/Returns Max             -6.52622
evaluation/Returns Min             -6.59893
evaluation/Actions Mean             0.0043315
evaluation/Actions Std              0.0655697
evaluation/Actions Max              0.953712
evaluation/Actions Min             -0.88276
evaluation/Num Paths                5
evaluation/Average Returns         -6.56917
time/data storing (s)               0.0011876
time/evaluation sampling (s)        0.0766071
time/exploration sampling (s)       0.0323757
time/logging (s)                    0.00248594
time/saving (s)                     0.00226233
time/training (s)                   0.472314
time/epoch (s)                      0.587232
time/total (s)                    288.875
Epoch                             481
-----------------------------  ----------------
2019-04-13 17:03:24.872742 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 482 finished
-----------------------------  ----------------
replay_buffer/size              96700
trainer/QF1 Loss                    0.0342226
trainer/QF2 Loss                    0.0350547
trainer/Policy Loss                13.1249
trainer/Q1 Predictions Mean       -13.2012
trainer/Q1 Predictions Std          0.434789
trainer/Q1 Predictions Max        -13.0186
trainer/Q1 Predictions Min        -15.5887
trainer/Q2 Predictions Mean       -13.1822
trainer/Q2 Predictions Std          0.426029
trainer/Q2 Predictions Max        -13.0218
trainer/Q2 Predictions Min        -15.5288
trainer/Q Targets Mean            -13.1989
trainer/Q Targets Std               0.531286
trainer/Q Targets Max             -12.8425
trainer/Q Targets Min             -15.9485
trainer/Bellman Errors 1 Mean       0.0342226
trainer/Bellman Errors 1 Std        0.0461675
trainer/Bellman Errors 1 Max        0.229899
trainer/Bellman Errors 1 Min        3.09658e-05
trainer/Bellman Errors 2 Mean       0.0350547
trainer/Bellman Errors 2 Std        0.0484192
trainer/Bellman Errors 2 Max        0.21434
trainer/Bellman Errors 2 Min        6.80664e-05
trainer/Policy Action Mean          0.00854091
trainer/Policy Action Std           0.155132
trainer/Policy Action Max           0.999474
trainer/Policy Action Min          -0.181463
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.14025
exploration/Rewards Std             0.0878468
exploration/Rewards Max            -0.0162296
exploration/Rewards Min            -0.711643
exploration/Returns Mean          -14.025
exploration/Returns Std             0.264982
exploration/Returns Max           -13.76
exploration/Returns Min           -14.29
exploration/Actions Mean            0.0104273
exploration/Actions Std             0.161888
exploration/Actions Max             1
exploration/Actions Min            -0.367228
exploration/Num Paths               2
exploration/Average Returns       -14.025
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0379911
evaluation/Rewards Std              0.0204592
evaluation/Rewards Max             -0.0338674
evaluation/Rewards Min             -0.396722
evaluation/Returns Mean            -3.79911
evaluation/Returns Std              0.119317
evaluation/Returns Max             -3.65918
evaluation/Returns Min             -4.00754
evaluation/Actions Mean             0.00682239
evaluation/Actions Std              0.0690523
evaluation/Actions Max              0.998022
evaluation/Actions Min             -0.216483
evaluation/Num Paths                5
evaluation/Average Returns         -3.79911
time/data storing (s)               0.00111076
time/evaluation sampling (s)        0.0761992
time/exploration sampling (s)       0.0339409
time/logging (s)                    0.00246642
time/saving (s)                     0.00228767
time/training (s)                   0.459072
time/epoch (s)                      0.575077
time/total (s)                    289.454
Epoch                             482
-----------------------------  ----------------
2019-04-13 17:03:25.464817 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 483 finished
-----------------------------  ----------------
replay_buffer/size              96900
trainer/QF1 Loss                    5.38743
trainer/QF2 Loss                    5.34614
trainer/Policy Loss                13.1439
trainer/Q1 Predictions Mean       -13.3074
trainer/Q1 Predictions Std          0.158213
trainer/Q1 Predictions Max        -13.15
trainer/Q1 Predictions Min        -13.8904
trainer/Q2 Predictions Mean       -13.3002
trainer/Q2 Predictions Std          0.15297
trainer/Q2 Predictions Max        -13.151
trainer/Q2 Predictions Min        -13.841
trainer/Q Targets Mean            -12.7953
trainer/Q Targets Std               2.27757
trainer/Q Targets Max              -0.155404
trainer/Q Targets Min             -13.7267
trainer/Bellman Errors 1 Mean       5.38743
trainer/Bellman Errors 1 Std       29.7908
trainer/Bellman Errors 1 Max      171.256
trainer/Bellman Errors 1 Min        4.98039e-07
trainer/Bellman Errors 2 Mean       5.34614
trainer/Bellman Errors 2 Std       29.5868
trainer/Bellman Errors 2 Max      170.078
trainer/Bellman Errors 2 Min        0.000141291
trainer/Policy Action Mean         -0.0137011
trainer/Policy Action Std           0.140083
trainer/Policy Action Max           0.42212
trainer/Policy Action Min          -0.447591
exploration/num steps total     96900
exploration/num paths total       969
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.146667
exploration/Rewards Std             0.0806653
exploration/Rewards Max            -0.00837716
exploration/Rewards Min            -0.608826
exploration/Returns Mean          -14.6667
exploration/Returns Std             0.262191
exploration/Returns Max           -14.4045
exploration/Returns Min           -14.9289
exploration/Actions Mean            0.00950417
exploration/Actions Std             0.166933
exploration/Actions Max             1
exploration/Actions Min            -0.544367
exploration/Num Paths               2
exploration/Average Returns       -14.6667
evaluation/num steps total     242000
evaluation/num paths total       2420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0584062
evaluation/Rewards Std              0.0365876
evaluation/Rewards Max             -0.0513314
evaluation/Rewards Min             -0.736585
evaluation/Returns Mean            -5.84062
evaluation/Returns Std              0.286888
evaluation/Returns Max             -5.52771
evaluation/Returns Min             -6.32066
evaluation/Actions Mean             0.00342853
evaluation/Actions Std              0.0694254
evaluation/Actions Max              0.999988
evaluation/Actions Min             -0.946039
evaluation/Num Paths                5
evaluation/Average Returns         -5.84062
time/data storing (s)               0.00110243
time/evaluation sampling (s)        0.0768782
time/exploration sampling (s)       0.0329076
time/logging (s)                    0.00247513
time/saving (s)                     0.00228406
time/training (s)                   0.465556
time/epoch (s)                      0.581204
time/total (s)                    290.039
Epoch                             483
-----------------------------  ----------------
2019-04-13 17:03:26.043433 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 484 finished
-----------------------------  ----------------
replay_buffer/size              97100
trainer/QF1 Loss                    0.0327771
trainer/QF2 Loss                    0.0372203
trainer/Policy Loss                12.9825
trainer/Q1 Predictions Mean       -13.0999
trainer/Q1 Predictions Std          0.140268
trainer/Q1 Predictions Max        -12.9394
trainer/Q1 Predictions Min        -13.7273
trainer/Q2 Predictions Mean       -13.0888
trainer/Q2 Predictions Std          0.133122
trainer/Q2 Predictions Max        -12.9184
trainer/Q2 Predictions Min        -13.6499
trainer/Q Targets Mean            -13.1915
trainer/Q Targets Std               0.203797
trainer/Q Targets Max             -12.9062
trainer/Q Targets Min             -13.7927
trainer/Bellman Errors 1 Mean       0.0327771
trainer/Bellman Errors 1 Std        0.0767537
trainer/Bellman Errors 1 Max        0.424587
trainer/Bellman Errors 1 Min        6.86305e-06
trainer/Bellman Errors 2 Mean       0.0372203
trainer/Bellman Errors 2 Std        0.0851449
trainer/Bellman Errors 2 Max        0.47639
trainer/Bellman Errors 2 Min        1.86389e-05
trainer/Policy Action Mean          0.0062679
trainer/Policy Action Std           0.136417
trainer/Policy Action Max           0.521372
trainer/Policy Action Min          -0.496318
exploration/num steps total     97100
exploration/num paths total       971
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.139655
exploration/Rewards Std             0.109334
exploration/Rewards Max            -0.00644738
exploration/Rewards Min            -1.16503
exploration/Returns Mean          -13.9655
exploration/Returns Std             0.0116354
exploration/Returns Max           -13.9539
exploration/Returns Min           -13.9771
exploration/Actions Mean            0.0107131
exploration/Actions Std             0.16733
exploration/Actions Max             1
exploration/Actions Min            -0.367413
exploration/Num Paths               2
exploration/Average Returns       -13.9655
evaluation/num steps total     242500
evaluation/num paths total       2425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0351251
evaluation/Rewards Std              0.0707182
evaluation/Rewards Max             -0.0261226
evaluation/Rewards Min             -0.986239
evaluation/Returns Mean            -3.51251
evaluation/Returns Std              0.42424
evaluation/Returns Max             -2.97484
evaluation/Returns Min             -3.90683
evaluation/Actions Mean             0.00402394
evaluation/Actions Std              0.0910988
evaluation/Actions Max              1
evaluation/Actions Min             -0.957682
evaluation/Num Paths                5
evaluation/Average Returns         -3.51251
time/data storing (s)               0.0011214
time/evaluation sampling (s)        0.0726194
time/exploration sampling (s)       0.0347753
time/logging (s)                    0.00247201
time/saving (s)                     0.00227669
time/training (s)                   0.454668
time/epoch (s)                      0.567933
time/total (s)                    290.611
Epoch                             484
-----------------------------  ----------------
2019-04-13 17:03:26.629441 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 485 finished
-----------------------------  ----------------
replay_buffer/size              97300
trainer/QF1 Loss                    5.58304
trainer/QF2 Loss                    5.5744
trainer/Policy Loss                13.2977
trainer/Q1 Predictions Mean       -13.4898
trainer/Q1 Predictions Std          0.436255
trainer/Q1 Predictions Max        -13.3131
trainer/Q1 Predictions Min        -15.8759
trainer/Q2 Predictions Mean       -13.4783
trainer/Q2 Predictions Std          0.439211
trainer/Q2 Predictions Max        -13.2933
trainer/Q2 Predictions Min        -15.8769
trainer/Q Targets Mean            -12.8109
trainer/Q Targets Std               2.33378
trainer/Q Targets Max              -0.0900823
trainer/Q Targets Min             -15.7046
trainer/Bellman Errors 1 Mean       5.58304
trainer/Bellman Errors 1 Std       30.5223
trainer/Bellman Errors 1 Max      175.523
trainer/Bellman Errors 1 Min        0.000121287
trainer/Bellman Errors 2 Mean       5.5744
trainer/Bellman Errors 2 Std       30.5134
trainer/Bellman Errors 2 Max      175.465
trainer/Bellman Errors 2 Min        0.000450621
trainer/Policy Action Mean         -0.0170254
trainer/Policy Action Std           0.168466
trainer/Policy Action Max           0.999584
trainer/Policy Action Min          -0.309452
exploration/num steps total     97300
exploration/num paths total       973
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.124719
exploration/Rewards Std             0.0656216
exploration/Rewards Max            -0.00587821
exploration/Rewards Min            -0.312174
exploration/Returns Mean          -12.4719
exploration/Returns Std             0.00836837
exploration/Returns Max           -12.4635
exploration/Returns Min           -12.4802
exploration/Actions Mean            0.00250723
exploration/Actions Std             0.154751
exploration/Actions Max             0.823701
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.4719
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0218969
evaluation/Rewards Std              0.0409307
evaluation/Rewards Max             -0.0185224
evaluation/Rewards Min             -0.848596
evaluation/Returns Mean            -2.18969
evaluation/Returns Std              0.287529
evaluation/Returns Max             -1.98132
evaluation/Returns Min             -2.752
evaluation/Actions Mean             0.0006778
evaluation/Actions Std              0.0976235
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.999159
evaluation/Num Paths                5
evaluation/Average Returns         -2.18969
time/data storing (s)               0.00108393
time/evaluation sampling (s)        0.0753058
time/exploration sampling (s)       0.0335634
time/logging (s)                    0.00247871
time/saving (s)                     0.00224996
time/training (s)                   0.460667
time/epoch (s)                      0.575349
time/total (s)                    291.19
Epoch                             485
-----------------------------  ----------------
2019-04-13 17:03:27.230885 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 486 finished
-----------------------------  ----------------
replay_buffer/size              97500
trainer/QF1 Loss                    0.0235454
trainer/QF2 Loss                    0.0237897
trainer/Policy Loss                13.0681
trainer/Q1 Predictions Mean       -13.1514
trainer/Q1 Predictions Std          0.0793693
trainer/Q1 Predictions Max        -13.0421
trainer/Q1 Predictions Min        -13.3941
trainer/Q2 Predictions Mean       -13.146
trainer/Q2 Predictions Std          0.086466
trainer/Q2 Predictions Max        -13.0333
trainer/Q2 Predictions Min        -13.4096
trainer/Q Targets Mean            -13.1213
trainer/Q Targets Std               0.180734
trainer/Q Targets Max             -12.8659
trainer/Q Targets Min             -13.5063
trainer/Bellman Errors 1 Mean       0.0235454
trainer/Bellman Errors 1 Std        0.0257397
trainer/Bellman Errors 1 Max        0.113357
trainer/Bellman Errors 1 Min        0.00104847
trainer/Bellman Errors 2 Mean       0.0237897
trainer/Bellman Errors 2 Std        0.026729
trainer/Bellman Errors 2 Max        0.117021
trainer/Bellman Errors 2 Min        0.000766521
trainer/Policy Action Mean          0.0129781
trainer/Policy Action Std           0.133118
trainer/Policy Action Max           0.562504
trainer/Policy Action Min          -0.203659
exploration/num steps total     97500
exploration/num paths total       975
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12697
exploration/Rewards Std             0.0684859
exploration/Rewards Max            -0.00646557
exploration/Rewards Min            -0.408632
exploration/Returns Mean          -12.697
exploration/Returns Std             0.055405
exploration/Returns Max           -12.6416
exploration/Returns Min           -12.7524
exploration/Actions Mean            0.000121065
exploration/Actions Std             0.164367
exploration/Actions Max             0.888974
exploration/Actions Min            -1
exploration/Num Paths               2
exploration/Average Returns       -12.697
evaluation/num steps total     243500
evaluation/num paths total       2435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0120356
evaluation/Rewards Std              0.03431
evaluation/Rewards Max             -0.00512627
evaluation/Rewards Min             -0.6574
evaluation/Returns Mean            -1.20356
evaluation/Returns Std              0.222242
evaluation/Returns Max             -0.945486
evaluation/Returns Min             -1.61226
evaluation/Actions Mean             0.00345311
evaluation/Actions Std              0.0866558
evaluation/Actions Max              0.999946
evaluation/Actions Min             -0.997078
evaluation/Num Paths                5
evaluation/Average Returns         -1.20356
time/data storing (s)               0.00112308
time/evaluation sampling (s)        0.0723752
time/exploration sampling (s)       0.033618
time/logging (s)                    0.00250879
time/saving (s)                     0.00227383
time/training (s)                   0.478936
time/epoch (s)                      0.590835
time/total (s)                    291.785
Epoch                             486
-----------------------------  ----------------
2019-04-13 17:03:27.816854 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 487 finished
-----------------------------  ---------------
replay_buffer/size              97700
trainer/QF1 Loss                    0.13511
trainer/QF2 Loss                    0.138139
trainer/Policy Loss                12.7052
trainer/Q1 Predictions Mean       -12.8073
trainer/Q1 Predictions Std          0.0778746
trainer/Q1 Predictions Max        -12.7069
trainer/Q1 Predictions Min        -13.0469
trainer/Q2 Predictions Mean       -12.8044
trainer/Q2 Predictions Std          0.0787294
trainer/Q2 Predictions Max        -12.7088
trainer/Q2 Predictions Min        -13.0533
trainer/Q Targets Mean            -13.1348
trainer/Q Targets Std               0.168542
trainer/Q Targets Max             -12.8663
trainer/Q Targets Min             -13.5575
trainer/Bellman Errors 1 Mean       0.13511
trainer/Bellman Errors 1 Std        0.138386
trainer/Bellman Errors 1 Max        0.637724
trainer/Bellman Errors 1 Min        0.0160443
trainer/Bellman Errors 2 Mean       0.138139
trainer/Bellman Errors 2 Std        0.145674
trainer/Bellman Errors 2 Max        0.680593
trainer/Bellman Errors 2 Min        0.0165373
trainer/Policy Action Mean          0.00998826
trainer/Policy Action Std           0.105774
trainer/Policy Action Max           0.270949
trainer/Policy Action Min          -0.187649
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.12859
exploration/Rewards Std             0.0811981
exploration/Rewards Max            -0.0133034
exploration/Rewards Min            -0.850949
exploration/Returns Mean          -12.859
exploration/Returns Std             0.360484
exploration/Returns Max           -12.4985
exploration/Returns Min           -13.2194
exploration/Actions Mean            0.0070312
exploration/Actions Std             0.155266
exploration/Actions Max             1
exploration/Actions Min            -0.382421
exploration/Num Paths               2
exploration/Average Returns       -12.859
evaluation/num steps total     244000
evaluation/num paths total       2440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0214735
evaluation/Rewards Std              0.0414754
evaluation/Rewards Max             -0.00944431
evaluation/Rewards Min             -0.848964
evaluation/Returns Mean            -2.14735
evaluation/Returns Std              0.297622
evaluation/Returns Max             -1.88039
evaluation/Returns Min             -2.70378
evaluation/Actions Mean             0.00436181
evaluation/Actions Std              0.0771231
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.871076
evaluation/Num Paths                5
evaluation/Average Returns         -2.14735
time/data storing (s)               0.00113649
time/evaluation sampling (s)        0.0715983
time/exploration sampling (s)       0.0336119
time/logging (s)                    0.00248664
time/saving (s)                     0.00223454
time/training (s)                   0.46421
time/epoch (s)                      0.575278
time/total (s)                    292.364
Epoch                             487
-----------------------------  ---------------
2019-04-13 17:03:28.415794 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 488 finished
-----------------------------  ----------------
replay_buffer/size              97900
trainer/QF1 Loss                    0.0639254
trainer/QF2 Loss                    0.065044
trainer/Policy Loss                12.8701
trainer/Q1 Predictions Mean       -12.9707
trainer/Q1 Predictions Std          0.0803243
trainer/Q1 Predictions Max        -12.8603
trainer/Q1 Predictions Min        -13.1574
trainer/Q2 Predictions Mean       -12.9735
trainer/Q2 Predictions Std          0.0846851
trainer/Q2 Predictions Max        -12.8403
trainer/Q2 Predictions Min        -13.2117
trainer/Q Targets Mean            -13.1691
trainer/Q Targets Std               0.158693
trainer/Q Targets Max             -12.8485
trainer/Q Targets Min             -13.4882
trainer/Bellman Errors 1 Mean       0.0639254
trainer/Bellman Errors 1 Std        0.0639731
trainer/Bellman Errors 1 Max        0.224239
trainer/Bellman Errors 1 Min        6.06335e-05
trainer/Bellman Errors 2 Mean       0.065044
trainer/Bellman Errors 2 Std        0.0629772
trainer/Bellman Errors 2 Max        0.225865
trainer/Bellman Errors 2 Min        4.62748e-05
trainer/Policy Action Mean         -0.0292724
trainer/Policy Action Std           0.0995387
trainer/Policy Action Max           0.208649
trainer/Policy Action Min          -0.235362
exploration/num steps total     97900
exploration/num paths total       979
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.123044
exploration/Rewards Std             0.0666305
exploration/Rewards Max            -0.00950438
exploration/Rewards Min            -0.360288
exploration/Returns Mean          -12.3044
exploration/Returns Std             0.507276
exploration/Returns Max           -11.7972
exploration/Returns Min           -12.8117
exploration/Actions Mean            0.00313657
exploration/Actions Std             0.147771
exploration/Actions Max             0.988057
exploration/Actions Min            -0.374991
exploration/Num Paths               2
exploration/Average Returns       -12.3044
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0288519
evaluation/Rewards Std              0.038256
evaluation/Rewards Max             -0.0251535
evaluation/Rewards Min             -0.840961
evaluation/Returns Mean            -2.88519
evaluation/Returns Std              0.321997
evaluation/Returns Max             -2.66162
evaluation/Returns Min             -3.49756
evaluation/Actions Mean             0.00422289
evaluation/Actions Std              0.0722353
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.997144
evaluation/Num Paths                5
evaluation/Average Returns         -2.88519
time/data storing (s)               0.00115289
time/evaluation sampling (s)        0.0761028
time/exploration sampling (s)       0.0326497
time/logging (s)                    0.00242277
time/saving (s)                     0.00221415
time/training (s)                   0.473635
time/epoch (s)                      0.588178
time/total (s)                    292.956
Epoch                             488
-----------------------------  ----------------
2019-04-13 17:03:29.003189 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 489 finished
-----------------------------  ----------------
replay_buffer/size              98100
trainer/QF1 Loss                    0.0332031
trainer/QF2 Loss                    0.0338303
trainer/Policy Loss                13.1373
trainer/Q1 Predictions Mean       -13.2325
trainer/Q1 Predictions Std          0.0923093
trainer/Q1 Predictions Max        -13.1352
trainer/Q1 Predictions Min        -13.5952
trainer/Q2 Predictions Mean       -13.2365
trainer/Q2 Predictions Std          0.0935633
trainer/Q2 Predictions Max        -13.1326
trainer/Q2 Predictions Min        -13.5889
trainer/Q Targets Mean            -13.1691
trainer/Q Targets Std               0.177432
trainer/Q Targets Max             -12.8428
trainer/Q Targets Min             -13.6149
trainer/Bellman Errors 1 Mean       0.0332031
trainer/Bellman Errors 1 Std        0.0392022
trainer/Bellman Errors 1 Max        0.153663
trainer/Bellman Errors 1 Min        2.91411e-06
trainer/Bellman Errors 2 Mean       0.0338303
trainer/Bellman Errors 2 Std        0.0395976
trainer/Bellman Errors 2 Max        0.137018
trainer/Bellman Errors 2 Min        2.92393e-05
trainer/Policy Action Mean         -0.0428433
trainer/Policy Action Std           0.110907
trainer/Policy Action Max           0.171442
trainer/Policy Action Min          -0.304605
exploration/num steps total     98100
exploration/num paths total       981
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.160807
exploration/Rewards Std             0.0924463
exploration/Rewards Max            -0.0240533
exploration/Rewards Min            -0.942039
exploration/Returns Mean          -16.0807
exploration/Returns Std             0.426655
exploration/Returns Max           -15.654
exploration/Returns Min           -16.5073
exploration/Actions Mean            0.00815725
exploration/Actions Std             0.16105
exploration/Actions Max             0.900566
exploration/Actions Min            -0.377766
exploration/Num Paths               2
exploration/Average Returns       -16.0807
evaluation/num steps total     245000
evaluation/num paths total       2450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.100794
evaluation/Rewards Std              0.0424544
evaluation/Rewards Max             -0.0412744
evaluation/Rewards Min             -0.870171
evaluation/Returns Mean           -10.0794
evaluation/Returns Std              0.293684
evaluation/Returns Max             -9.71101
evaluation/Returns Min            -10.5332
evaluation/Actions Mean             0.00366389
evaluation/Actions Std              0.0875081
evaluation/Actions Max              1
evaluation/Actions Min             -0.999809
evaluation/Num Paths                5
evaluation/Average Returns        -10.0794
time/data storing (s)               0.00111771
time/evaluation sampling (s)        0.0735452
time/exploration sampling (s)       0.0336647
time/logging (s)                    0.00249787
time/saving (s)                     0.00221706
time/training (s)                   0.463714
time/epoch (s)                      0.576757
time/total (s)                    293.537
Epoch                             489
-----------------------------  ----------------
2019-04-13 17:03:29.599461 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 490 finished
-----------------------------  ----------------
replay_buffer/size              98300
trainer/QF1 Loss                    5.2147
trainer/QF2 Loss                    5.16415
trainer/Policy Loss                12.9242
trainer/Q1 Predictions Mean       -13.1491
trainer/Q1 Predictions Std          0.324348
trainer/Q1 Predictions Max        -12.9394
trainer/Q1 Predictions Min        -14.8094
trainer/Q2 Predictions Mean       -13.1521
trainer/Q2 Predictions Std          0.341746
trainer/Q2 Predictions Max        -12.9397
trainer/Q2 Predictions Min        -14.9202
trainer/Q Targets Mean            -12.7877
trainer/Q Targets Std               2.31146
trainer/Q Targets Max              -0.146455
trainer/Q Targets Min             -15.3519
trainer/Bellman Errors 1 Mean       5.2147
trainer/Bellman Errors 1 Std       28.8606
trainer/Bellman Errors 1 Max      165.903
trainer/Bellman Errors 1 Min        3.55612e-05
trainer/Bellman Errors 2 Mean       5.16415
trainer/Bellman Errors 2 Std       28.5741
trainer/Bellman Errors 2 Max      164.258
trainer/Bellman Errors 2 Min        1.13524e-05
trainer/Policy Action Mean         -0.0209164
trainer/Policy Action Std           0.206548
trainer/Policy Action Max           0.997249
trainer/Policy Action Min          -0.488505
exploration/num steps total     98300
exploration/num paths total       983
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.134538
exploration/Rewards Std             0.0860594
exploration/Rewards Max            -0.0145527
exploration/Rewards Min            -0.71417
exploration/Returns Mean          -13.4538
exploration/Returns Std             0.295901
exploration/Returns Max           -13.1579
exploration/Returns Min           -13.7497
exploration/Actions Mean            0.00667229
exploration/Actions Std             0.158578
exploration/Actions Max             1
exploration/Actions Min            -0.516927
exploration/Num Paths               2
exploration/Average Returns       -13.4538
evaluation/num steps total     245500
evaluation/num paths total       2455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0368989
evaluation/Rewards Std              0.0528326
evaluation/Rewards Max             -0.0329315
evaluation/Rewards Min             -1.11685
evaluation/Returns Mean            -3.68989
evaluation/Returns Std              0.405396
evaluation/Returns Max             -3.34261
evaluation/Returns Min             -4.45702
evaluation/Actions Mean             0.00435854
evaluation/Actions Std              0.0835954
evaluation/Actions Max              1
evaluation/Actions Min             -0.989538
evaluation/Num Paths                5
evaluation/Average Returns         -3.68989
time/data storing (s)               0.00114801
time/evaluation sampling (s)        0.074652
time/exploration sampling (s)       0.0341762
time/logging (s)                    0.00191672
time/saving (s)                     0.00178569
time/training (s)                   0.471126
time/epoch (s)                      0.584805
time/total (s)                    294.125
Epoch                             490
-----------------------------  ----------------
2019-04-13 17:03:30.185839 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 491 finished
-----------------------------  ----------------
replay_buffer/size              98500
trainer/QF1 Loss                    0.0298622
trainer/QF2 Loss                    0.0311548
trainer/Policy Loss                13.0089
trainer/Q1 Predictions Mean       -13.1181
trainer/Q1 Predictions Std          0.0808407
trainer/Q1 Predictions Max        -13.0122
trainer/Q1 Predictions Min        -13.4428
trainer/Q2 Predictions Mean       -13.1157
trainer/Q2 Predictions Std          0.0818407
trainer/Q2 Predictions Max        -13.0028
trainer/Q2 Predictions Min        -13.4337
trainer/Q Targets Mean            -13.1633
trainer/Q Targets Std               0.180665
trainer/Q Targets Max             -12.9128
trainer/Q Targets Min             -13.6168
trainer/Bellman Errors 1 Mean       0.0298622
trainer/Bellman Errors 1 Std        0.0402038
trainer/Bellman Errors 1 Max        0.168592
trainer/Bellman Errors 1 Min        4.34213e-06
trainer/Bellman Errors 2 Mean       0.0311549
trainer/Bellman Errors 2 Std        0.0418069
trainer/Bellman Errors 2 Max        0.172308
trainer/Bellman Errors 2 Min        2.78533e-06
trainer/Policy Action Mean         -0.0159242
trainer/Policy Action Std           0.0995154
trainer/Policy Action Max           0.232364
trainer/Policy Action Min          -0.228845
exploration/num steps total     98500
exploration/num paths total       985
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.133866
exploration/Rewards Std             0.072337
exploration/Rewards Max            -0.00975833
exploration/Rewards Min            -0.552582
exploration/Returns Mean          -13.3866
exploration/Returns Std             0.184128
exploration/Returns Max           -13.2025
exploration/Returns Min           -13.5708
exploration/Actions Mean            0.00814095
exploration/Actions Std             0.15468
exploration/Actions Max             1
exploration/Actions Min            -0.338683
exploration/Num Paths               2
exploration/Average Returns       -13.3866
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.03657
evaluation/Rewards Std              0.04356
evaluation/Rewards Max             -0.0332685
evaluation/Rewards Min             -0.865093
evaluation/Returns Mean            -3.657
evaluation/Returns Std              0.302588
evaluation/Returns Max             -3.36811
evaluation/Returns Min             -4.17305
evaluation/Actions Mean             0.00365092
evaluation/Actions Std              0.0820417
evaluation/Actions Max              1
evaluation/Actions Min             -0.97601
evaluation/Num Paths                5
evaluation/Average Returns         -3.657
time/data storing (s)               0.00108999
time/evaluation sampling (s)        0.0722616
time/exploration sampling (s)       0.0325207
time/logging (s)                    0.00256505
time/saving (s)                     0.00226413
time/training (s)                   0.466666
time/epoch (s)                      0.577367
time/total (s)                    294.707
Epoch                             491
-----------------------------  ----------------
2019-04-13 17:03:30.777944 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 492 finished
-----------------------------  ----------------
replay_buffer/size              98700
trainer/QF1 Loss                    5.32616
trainer/QF2 Loss                    5.33454
trainer/Policy Loss                13.0784
trainer/Q1 Predictions Mean       -13.1965
trainer/Q1 Predictions Std          0.0604977
trainer/Q1 Predictions Max        -13.1179
trainer/Q1 Predictions Min        -13.3798
trainer/Q2 Predictions Mean       -13.2009
trainer/Q2 Predictions Std          0.0600475
trainer/Q2 Predictions Max        -13.0917
trainer/Q2 Predictions Min        -13.3659
trainer/Q Targets Mean            -12.7779
trainer/Q Targets Std               2.27043
trainer/Q Targets Max              -0.17013
trainer/Q Targets Min             -13.5161
trainer/Bellman Errors 1 Mean       5.32616
trainer/Bellman Errors 1 Std       29.4853
trainer/Bellman Errors 1 Max      169.493
trainer/Bellman Errors 1 Min        1.85074e-05
trainer/Bellman Errors 2 Mean       5.33454
trainer/Bellman Errors 2 Std       29.528
trainer/Bellman Errors 2 Max      169.739
trainer/Bellman Errors 2 Min        7.76169e-05
trainer/Policy Action Mean         -0.0155976
trainer/Policy Action Std           0.10657
trainer/Policy Action Max           0.31685
trainer/Policy Action Min          -0.276593
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136047
exploration/Rewards Std             0.0874074
exploration/Rewards Max            -0.00894232
exploration/Rewards Min            -0.808498
exploration/Returns Mean          -13.6047
exploration/Returns Std             0.173345
exploration/Returns Max           -13.4313
exploration/Returns Min           -13.778
exploration/Actions Mean            0.00882694
exploration/Actions Std             0.155365
exploration/Actions Max             1
exploration/Actions Min            -0.41128
exploration/Num Paths               2
exploration/Average Returns       -13.6047
evaluation/num steps total     246500
evaluation/num paths total       2465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0651957
evaluation/Rewards Std              0.0499912
evaluation/Rewards Max             -0.0501892
evaluation/Rewards Min             -1.01569
evaluation/Returns Mean            -6.51957
evaluation/Returns Std              0.386473
evaluation/Returns Max             -6.20964
evaluation/Returns Min             -7.14904
evaluation/Actions Mean             0.00504787
evaluation/Actions Std              0.0675052
evaluation/Actions Max              1
evaluation/Actions Min             -0.411019
evaluation/Num Paths                5
evaluation/Average Returns         -6.51957
time/data storing (s)               0.00109584
time/evaluation sampling (s)        0.0776064
time/exploration sampling (s)       0.0330667
time/logging (s)                    0.00240526
time/saving (s)                     0.00217884
time/training (s)                   0.464728
time/epoch (s)                      0.581081
time/total (s)                    295.292
Epoch                             492
-----------------------------  ----------------
2019-04-13 17:03:31.370133 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 493 finished
-----------------------------  ----------------
replay_buffer/size              98900
trainer/QF1 Loss                    0.0275385
trainer/QF2 Loss                    0.0263871
trainer/Policy Loss                12.9339
trainer/Q1 Predictions Mean       -13.119
trainer/Q1 Predictions Std          0.0812136
trainer/Q1 Predictions Max        -12.988
trainer/Q1 Predictions Min        -13.3356
trainer/Q2 Predictions Mean       -13.1299
trainer/Q2 Predictions Std          0.0799665
trainer/Q2 Predictions Max        -13.0022
trainer/Q2 Predictions Min        -13.3351
trainer/Q Targets Mean            -13.1521
trainer/Q Targets Std               0.174908
trainer/Q Targets Max             -12.8345
trainer/Q Targets Min             -13.5935
trainer/Bellman Errors 1 Mean       0.0275385
trainer/Bellman Errors 1 Std        0.0284475
trainer/Bellman Errors 1 Max        0.105816
trainer/Bellman Errors 1 Min        0.000148244
trainer/Bellman Errors 2 Mean       0.0263871
trainer/Bellman Errors 2 Std        0.0272605
trainer/Bellman Errors 2 Max        0.10346
trainer/Bellman Errors 2 Min        1.72495e-05
trainer/Policy Action Mean          0.0135588
trainer/Policy Action Std           0.120313
trainer/Policy Action Max           0.375936
trainer/Policy Action Min          -0.204931
exploration/num steps total     98900
exploration/num paths total       989
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.127516
exploration/Rewards Std             0.0703671
exploration/Rewards Max            -0.010281
exploration/Rewards Min            -0.389007
exploration/Returns Mean          -12.7516
exploration/Returns Std             0.674526
exploration/Returns Max           -12.0771
exploration/Returns Min           -13.4261
exploration/Actions Mean            0.000769806
exploration/Actions Std             0.139934
exploration/Actions Max             0.428838
exploration/Actions Min            -0.524581
exploration/Num Paths               2
exploration/Average Returns       -12.7516
evaluation/num steps total     247000
evaluation/num paths total       2470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0246157
evaluation/Rewards Std              0.0361853
evaluation/Rewards Max             -0.00458341
evaluation/Rewards Min             -0.77765
evaluation/Returns Mean            -2.46157
evaluation/Returns Std              0.273623
evaluation/Returns Max             -2.2739
evaluation/Returns Min             -3.00303
evaluation/Actions Mean             0.00331401
evaluation/Actions Std              0.0886635
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.995363
evaluation/Num Paths                5
evaluation/Average Returns         -2.46157
time/data storing (s)               0.00112131
time/evaluation sampling (s)        0.073304
time/exploration sampling (s)       0.032726
time/logging (s)                    0.00247144
time/saving (s)                     0.00222662
time/training (s)                   0.469909
time/epoch (s)                      0.581758
time/total (s)                    295.878
Epoch                             493
-----------------------------  ----------------
2019-04-13 17:03:31.961623 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 494 finished
-----------------------------  ----------------
replay_buffer/size              99100
trainer/QF1 Loss                    5.19039
trainer/QF2 Loss                    5.18969
trainer/Policy Loss                12.713
trainer/Q1 Predictions Mean       -12.8889
trainer/Q1 Predictions Std          0.0813574
trainer/Q1 Predictions Max        -12.7645
trainer/Q1 Predictions Min        -13.0986
trainer/Q2 Predictions Mean       -12.9082
trainer/Q2 Predictions Std          0.0764722
trainer/Q2 Predictions Max        -12.798
trainer/Q2 Predictions Min        -13.1204
trainer/Q Targets Mean            -12.7405
trainer/Q Targets Std               2.25599
trainer/Q Targets Max              -0.214139
trainer/Q Targets Min             -13.6122
trainer/Bellman Errors 1 Mean       5.19039
trainer/Bellman Errors 1 Std       28.4226
trainer/Bellman Errors 1 Max      163.44
trainer/Bellman Errors 1 Min        0.00203868
trainer/Bellman Errors 2 Mean       5.18969
trainer/Bellman Errors 2 Std       28.4753
trainer/Bellman Errors 2 Max      163.733
trainer/Bellman Errors 2 Min        0.000501243
trainer/Policy Action Mean          0.00645983
trainer/Policy Action Std           0.100438
trainer/Policy Action Max           0.220132
trainer/Policy Action Min          -0.203144
exploration/num steps total     99100
exploration/num paths total       991
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.136447
exploration/Rewards Std             0.0696614
exploration/Rewards Max            -0.00556081
exploration/Rewards Min            -0.33364
exploration/Returns Mean          -13.6447
exploration/Returns Std             0.774511
exploration/Returns Max           -12.8702
exploration/Returns Min           -14.4192
exploration/Actions Mean            0.00170861
exploration/Actions Std             0.160451
exploration/Actions Max             0.954625
exploration/Actions Min            -0.755337
exploration/Num Paths               2
exploration/Average Returns       -13.6447
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0232063
evaluation/Rewards Std              0.0529511
evaluation/Rewards Max             -0.0120622
evaluation/Rewards Min             -0.719924
evaluation/Returns Mean            -2.32063
evaluation/Returns Std              0.276608
evaluation/Returns Max             -1.87915
evaluation/Returns Min             -2.5678
evaluation/Actions Mean             0.00533212
evaluation/Actions Std              0.082449
evaluation/Actions Max              0.999999
evaluation/Actions Min             -0.89218
evaluation/Num Paths                5
evaluation/Average Returns         -2.32063
time/data storing (s)               0.0011524
time/evaluation sampling (s)        0.0748653
time/exploration sampling (s)       0.0336623
time/logging (s)                    0.00240846
time/saving (s)                     0.0017762
time/training (s)                   0.467638
time/epoch (s)                      0.581503
time/total (s)                    296.463
Epoch                             494
-----------------------------  ----------------
2019-04-13 17:03:32.537514 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 495 finished
-----------------------------  ----------------
replay_buffer/size              99300
trainer/QF1 Loss                    0.0423226
trainer/QF2 Loss                    0.0367804
trainer/Policy Loss                13.159
trainer/Q1 Predictions Mean       -13.2747
trainer/Q1 Predictions Std          0.147433
trainer/Q1 Predictions Max        -13.1245
trainer/Q1 Predictions Min        -13.8289
trainer/Q2 Predictions Mean       -13.2596
trainer/Q2 Predictions Std          0.130884
trainer/Q2 Predictions Max        -13.1352
trainer/Q2 Predictions Min        -13.8036
trainer/Q Targets Mean            -13.1651
trainer/Q Targets Std               0.238261
trainer/Q Targets Max             -12.8259
trainer/Q Targets Min             -14.2064
trainer/Bellman Errors 1 Mean       0.0423226
trainer/Bellman Errors 1 Std        0.048276
trainer/Bellman Errors 1 Max        0.172282
trainer/Bellman Errors 1 Min        1.07376e-05
trainer/Bellman Errors 2 Mean       0.0367804
trainer/Bellman Errors 2 Std        0.0411565
trainer/Bellman Errors 2 Max        0.162188
trainer/Bellman Errors 2 Min        8.75262e-05
trainer/Policy Action Mean         -0.00201811
trainer/Policy Action Std           0.18625
trainer/Policy Action Max           0.977208
trainer/Policy Action Min          -0.536549
exploration/num steps total     99300
exploration/num paths total       993
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.126509
exploration/Rewards Std             0.0746195
exploration/Rewards Max            -0.0134407
exploration/Rewards Min            -0.566536
exploration/Returns Mean          -12.6509
exploration/Returns Std             0.0768182
exploration/Returns Max           -12.5741
exploration/Returns Min           -12.7277
exploration/Actions Mean            0.00433262
exploration/Actions Std             0.162053
exploration/Actions Max             1
exploration/Actions Min            -0.617935
exploration/Num Paths               2
exploration/Average Returns       -12.6509
evaluation/num steps total     248000
evaluation/num paths total       2480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0165241
evaluation/Rewards Std              0.0220328
evaluation/Rewards Max             -0.00973576
evaluation/Rewards Min             -0.36139
evaluation/Returns Mean            -1.65241
evaluation/Returns Std              0.128873
evaluation/Returns Max             -1.5213
evaluation/Returns Min             -1.82173
evaluation/Actions Mean             0.00614605
evaluation/Actions Std              0.0674758
evaluation/Actions Max              0.999056
evaluation/Actions Min             -0.326837
evaluation/Num Paths                5
evaluation/Average Returns         -1.65241
time/data storing (s)               0.00120039
time/evaluation sampling (s)        0.0740912
time/exploration sampling (s)       0.0340049
time/logging (s)                    0.00187997
time/saving (s)                     0.00199057
time/training (s)                   0.451197
time/epoch (s)                      0.564364
time/total (s)                    297.031
Epoch                             495
-----------------------------  ----------------
2019-04-13 17:03:33.127735 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 496 finished
-----------------------------  ----------------
replay_buffer/size              99500
trainer/QF1 Loss                    0.0160857
trainer/QF2 Loss                    0.0155976
trainer/Policy Loss                13.1328
trainer/Q1 Predictions Mean       -13.2463
trainer/Q1 Predictions Std          0.403969
trainer/Q1 Predictions Max        -13.0817
trainer/Q1 Predictions Min        -15.3263
trainer/Q2 Predictions Mean       -13.2339
trainer/Q2 Predictions Std          0.402719
trainer/Q2 Predictions Max        -13.0592
trainer/Q2 Predictions Min        -15.3134
trainer/Q Targets Mean            -13.1916
trainer/Q Targets Std               0.392502
trainer/Q Targets Max             -12.8787
trainer/Q Targets Min             -15.1486
trainer/Bellman Errors 1 Mean       0.0160857
trainer/Bellman Errors 1 Std        0.0140957
trainer/Bellman Errors 1 Max        0.0560901
trainer/Bellman Errors 1 Min        4.49864e-05
trainer/Bellman Errors 2 Mean       0.0155976
trainer/Bellman Errors 2 Std        0.0139163
trainer/Bellman Errors 2 Max        0.0558871
trainer/Bellman Errors 2 Min        8.48278e-06
trainer/Policy Action Mean         -0.00286432
trainer/Policy Action Std           0.182454
trainer/Policy Action Max           0.996909
trainer/Policy Action Min          -0.514754
exploration/num steps total     99500
exploration/num paths total       995
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.128666
exploration/Rewards Std             0.0715239
exploration/Rewards Max            -0.012503
exploration/Rewards Min            -0.524593
exploration/Returns Mean          -12.8666
exploration/Returns Std             0.319495
exploration/Returns Max           -12.5471
exploration/Returns Min           -13.1861
exploration/Actions Mean            0.00870735
exploration/Actions Std             0.160242
exploration/Actions Max             0.98907
exploration/Actions Min            -0.447428
exploration/Num Paths               2
exploration/Average Returns       -12.8666
evaluation/num steps total     248500
evaluation/num paths total       2485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0249189
evaluation/Rewards Std              0.0468416
evaluation/Rewards Max             -0.0204135
evaluation/Rewards Min             -0.778243
evaluation/Returns Mean            -2.49189
evaluation/Returns Std              0.339264
evaluation/Returns Max             -2.15587
evaluation/Returns Min             -2.92706
evaluation/Actions Mean             0.0074453
evaluation/Actions Std              0.070999
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.0901818
evaluation/Num Paths                5
evaluation/Average Returns         -2.49189
time/data storing (s)               0.00112321
time/evaluation sampling (s)        0.073841
time/exploration sampling (s)       0.0316864
time/logging (s)                    0.0024946
time/saving (s)                     0.00779151
time/training (s)                   0.46344
time/epoch (s)                      0.580377
time/total (s)                    297.614
Epoch                             496
-----------------------------  ----------------
2019-04-13 17:03:33.707047 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 497 finished
-----------------------------  ----------------
replay_buffer/size              99700
trainer/QF1 Loss                    5.3145
trainer/QF2 Loss                    5.32194
trainer/Policy Loss                13.0624
trainer/Q1 Predictions Mean       -13.2249
trainer/Q1 Predictions Std          0.262011
trainer/Q1 Predictions Max        -13.0668
trainer/Q1 Predictions Min        -14.6162
trainer/Q2 Predictions Mean       -13.2288
trainer/Q2 Predictions Std          0.260049
trainer/Q2 Predictions Max        -13.0683
trainer/Q2 Predictions Min        -14.6053
trainer/Q Targets Mean            -12.7837
trainer/Q Targets Std               2.27404
trainer/Q Targets Max              -0.258494
trainer/Q Targets Min             -14.8916
trainer/Bellman Errors 1 Mean       5.3145
trainer/Bellman Errors 1 Std       29.4784
trainer/Bellman Errors 1 Max      169.443
trainer/Bellman Errors 1 Min        1.20438e-05
trainer/Bellman Errors 2 Mean       5.32194
trainer/Bellman Errors 2 Std       29.5143
trainer/Bellman Errors 2 Max      169.651
trainer/Bellman Errors 2 Min        2.00139e-05
trainer/Policy Action Mean         -0.00947576
trainer/Policy Action Std           0.155567
trainer/Policy Action Max           0.685322
trainer/Policy Action Min          -0.533021
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.123906
exploration/Rewards Std             0.065739
exploration/Rewards Max            -0.00385481
exploration/Rewards Min            -0.319225
exploration/Returns Mean          -12.3906
exploration/Returns Std             0.733546
exploration/Returns Max           -11.6571
exploration/Returns Min           -13.1242
exploration/Actions Mean            0.00292352
exploration/Actions Std             0.1357
exploration/Actions Max             0.648439
exploration/Actions Min            -0.359169
exploration/Num Paths               2
exploration/Average Returns       -12.3906
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.02887
evaluation/Rewards Std              0.043034
evaluation/Rewards Max             -0.0242937
evaluation/Rewards Min             -0.81527
evaluation/Returns Mean            -2.887
evaluation/Returns Std              0.292746
evaluation/Returns Max             -2.55439
evaluation/Returns Min             -3.36009
evaluation/Actions Mean             0.00555538
evaluation/Actions Std              0.0799261
evaluation/Actions Max              0.999998
evaluation/Actions Min             -0.960599
evaluation/Num Paths                5
evaluation/Average Returns         -2.887
time/data storing (s)               0.00122329
time/evaluation sampling (s)        0.0741395
time/exploration sampling (s)       0.0324164
time/logging (s)                    0.00249576
time/saving (s)                     0.00221352
time/training (s)                   0.457841
time/epoch (s)                      0.570329
time/total (s)                    298.188
Epoch                             497
-----------------------------  ----------------
2019-04-13 17:03:34.291848 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 498 finished
-----------------------------  ----------------
replay_buffer/size              99900
trainer/QF1 Loss                    0.118481
trainer/QF2 Loss                    0.109978
trainer/Policy Loss                12.6994
trainer/Q1 Predictions Mean       -12.8201
trainer/Q1 Predictions Std          0.0683926
trainer/Q1 Predictions Max        -12.7014
trainer/Q1 Predictions Min        -13.0002
trainer/Q2 Predictions Mean       -12.8338
trainer/Q2 Predictions Std          0.0652357
trainer/Q2 Predictions Max        -12.7262
trainer/Q2 Predictions Min        -13.0029
trainer/Q Targets Mean            -13.1388
trainer/Q Targets Std               0.138407
trainer/Q Targets Max             -12.9496
trainer/Q Targets Min             -13.4826
trainer/Bellman Errors 1 Mean       0.118481
trainer/Bellman Errors 1 Std        0.0918354
trainer/Bellman Errors 1 Max        0.397891
trainer/Bellman Errors 1 Min        0.00216138
trainer/Bellman Errors 2 Mean       0.109978
trainer/Bellman Errors 2 Std        0.0870715
trainer/Bellman Errors 2 Max        0.344833
trainer/Bellman Errors 2 Min        0.000930217
trainer/Policy Action Mean          0.049727
trainer/Policy Action Std           0.114536
trainer/Policy Action Max           0.280768
trainer/Policy Action Min          -0.369414
exploration/num steps total     99900
exploration/num paths total       999
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.140875
exploration/Rewards Std             0.0791453
exploration/Rewards Max            -0.00548323
exploration/Rewards Min            -0.380936
exploration/Returns Mean          -14.0875
exploration/Returns Std             0.262488
exploration/Returns Max           -13.825
exploration/Returns Min           -14.35
exploration/Actions Mean            0.00452793
exploration/Actions Std             0.13984
exploration/Actions Max             0.743801
exploration/Actions Min            -0.431
exploration/Num Paths               2
exploration/Average Returns       -14.0875
evaluation/num steps total     249500
evaluation/num paths total       2495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0992972
evaluation/Rewards Std              0.0510458
evaluation/Rewards Max             -0.0846573
evaluation/Rewards Min             -0.919597
evaluation/Returns Mean            -9.92972
evaluation/Returns Std              0.379581
evaluation/Returns Max             -9.5457
evaluation/Returns Min            -10.4096
evaluation/Actions Mean             0.00539947
evaluation/Actions Std              0.0829095
evaluation/Actions Max              1
evaluation/Actions Min             -0.692747
evaluation/Num Paths                5
evaluation/Average Returns         -9.92972
time/data storing (s)               0.00112409
time/evaluation sampling (s)        0.075366
time/exploration sampling (s)       0.0343858
time/logging (s)                    0.00188484
time/saving (s)                     0.00177625
time/training (s)                   0.458746
time/epoch (s)                      0.573283
time/total (s)                    298.765
Epoch                             498
-----------------------------  ----------------
2019-04-13 17:03:34.881695 PDT | [td3-pointmass-singletask_2019_04_13_16_58_33_0000--s-0] Epoch 499 finished
-----------------------------  ----------------
replay_buffer/size             100100
trainer/QF1 Loss                    0.0453261
trainer/QF2 Loss                    0.0487455
trainer/Policy Loss                12.9801
trainer/Q1 Predictions Mean       -13.1224
trainer/Q1 Predictions Std          0.283417
trainer/Q1 Predictions Max        -12.9316
trainer/Q1 Predictions Min        -14.3589
trainer/Q2 Predictions Mean       -13.1053
trainer/Q2 Predictions Std          0.288199
trainer/Q2 Predictions Max        -12.9051
trainer/Q2 Predictions Min        -14.4323
trainer/Q Targets Mean            -13.2528
trainer/Q Targets Std               0.300155
trainer/Q Targets Max             -12.8074
trainer/Q Targets Min             -14.5056
trainer/Bellman Errors 1 Mean       0.0453261
trainer/Bellman Errors 1 Std        0.0545781
trainer/Bellman Errors 1 Max        0.213434
trainer/Bellman Errors 1 Min        9.11315e-07
trainer/Bellman Errors 2 Mean       0.0487455
trainer/Bellman Errors 2 Std        0.0585666
trainer/Bellman Errors 2 Max        0.208304
trainer/Bellman Errors 2 Min        0.000142359
trainer/Policy Action Mean          0.0344037
trainer/Policy Action Std           0.171498
trainer/Policy Action Max           0.752621
trainer/Policy Action Min          -0.560387
exploration/num steps total    100100
exploration/num paths total      1001
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.156907
exploration/Rewards Std             0.103446
exploration/Rewards Max            -0.0114823
exploration/Rewards Min            -0.950891
exploration/Returns Mean          -15.6907
exploration/Returns Std             0.264778
exploration/Returns Max           -15.426
exploration/Returns Min           -15.9555
exploration/Actions Mean            0.0088371
exploration/Actions Std             0.178899
exploration/Actions Max             1
exploration/Actions Min            -0.500703
exploration/Num Paths               2
exploration/Average Returns       -15.6907
evaluation/num steps total     250000
evaluation/num paths total       2500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.0749047
evaluation/Rewards Std              0.030115
evaluation/Rewards Max             -0.0474285
evaluation/Rewards Min             -0.55403
evaluation/Returns Mean            -7.49047
evaluation/Returns Std              0.177092
evaluation/Returns Max             -7.32356
evaluation/Returns Min             -7.72757
evaluation/Actions Mean             0.00247391
evaluation/Actions Std              0.0810136
evaluation/Actions Max              0.999986
evaluation/Actions Min             -0.938048
evaluation/Num Paths                5
evaluation/Average Returns         -7.49047
time/data storing (s)               0.00112978
time/evaluation sampling (s)        0.075514
time/exploration sampling (s)       0.0317933
time/logging (s)                    0.00254243
time/saving (s)                     0.00227375
time/training (s)                   0.467245
time/epoch (s)                      0.580498
time/total (s)                    299.35
Epoch                             499
-----------------------------  ----------------
