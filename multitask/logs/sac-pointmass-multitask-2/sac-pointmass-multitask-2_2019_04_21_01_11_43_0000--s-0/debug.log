2019-04-21 01:11:44.351673 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               400
trainer/QF1 Loss                  71.8949
trainer/QF2 Loss                  71.8931
trainer/Policy Loss               -1.34421
trainer/Q1 Predictions Mean       -0.00361716
trainer/Q1 Predictions Std         0.00193459
trainer/Q1 Predictions Max         0.000331273
trainer/Q1 Predictions Min        -0.00715399
trainer/Q2 Predictions Mean       -0.00389623
trainer/Q2 Predictions Std         0.00121027
trainer/Q2 Predictions Max        -0.000601742
trainer/Q2 Predictions Min        -0.00541653
trainer/Q Targets Mean            -8.17906
trainer/Q Targets Std              2.24945
trainer/Q Targets Max             -3.56819
trainer/Q Targets Min            -12.2566
trainer/Log Pis Mean              -1.34861
trainer/Log Pis Std                0.30973
trainer/Log Pis Max               -0.541307
trainer/Log Pis Min               -2.3944
trainer/Policy mu Mean            -0.000473806
trainer/Policy mu Std              0.000528315
trainer/Policy mu Max              0.000499489
trainer/Policy mu Min             -0.00145527
trainer/Policy log std Mean       -0.000383939
trainer/Policy log std Std         0.000363626
trainer/Policy log std Max         0.000591593
trainer/Policy log std Min        -0.00123557
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      400
exploration/num paths total        4
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -9.26165
exploration/Rewards Std            2.21063
exploration/Rewards Max           -4.7217
exploration/Rewards Min          -12.6348
exploration/Returns Mean        -926.165
exploration/Returns Std           85.5761
exploration/Returns Max         -840.589
exploration/Returns Min        -1011.74
exploration/Actions Mean           0.0201665
exploration/Actions Std            0.629342
exploration/Actions Max            0.993983
exploration/Actions Min           -0.998061
exploration/Num Paths              2
exploration/Average Returns     -926.165
evaluation/num steps total      1000
evaluation/num paths total        10
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -6.81634
evaluation/Rewards Std             3.5356
evaluation/Rewards Max            -2.00759
evaluation/Rewards Min           -11.9932
evaluation/Returns Mean         -681.634
evaluation/Returns Std           353.556
evaluation/Returns Max          -200.972
evaluation/Returns Min         -1197.63
evaluation/Actions Mean           -0.00020575
evaluation/Actions Std             0.000528252
evaluation/Actions Max             0.000434994
evaluation/Actions Min            -0.00139738
evaluation/Num Paths              10
evaluation/Average Returns      -681.634
time/data storing (s)              0.00115044
time/evaluation sampling (s)       0.200976
time/exploration sampling (s)      0.0598139
time/logging (s)                   0.00367917
time/saving (s)                    0.00208235
time/training (s)                  0.787343
time/epoch (s)                     1.05505
time/total (s)                     1.27025
Epoch                              0
-----------------------------  ---------------
2019-04-21 01:11:45.442175 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size               600
trainer/QF1 Loss                   2.1164
trainer/QF2 Loss                   2.56895
trainer/Policy Loss                7.74938
trainer/Q1 Predictions Mean       -8.88682
trainer/Q1 Predictions Std         2.50853
trainer/Q1 Predictions Max        -5.30335
trainer/Q1 Predictions Min       -14.4139
trainer/Q2 Predictions Mean       -8.72271
trainer/Q2 Predictions Std         2.2033
trainer/Q2 Predictions Max        -5.2645
trainer/Q2 Predictions Min       -14.0626
trainer/Q Targets Mean            -9.32391
trainer/Q Targets Std              2.28326
trainer/Q Targets Max             -4.60592
trainer/Q Targets Min            -13.8508
trainer/Log Pis Mean              -1.32464
trainer/Log Pis Std                0.254925
trainer/Log Pis Max               -0.73649
trainer/Log Pis Min               -1.83704
trainer/Policy mu Mean            -0.0653226
trainer/Policy mu Std              0.129935
trainer/Policy mu Max              0.111501
trainer/Policy mu Min             -0.263274
trainer/Policy log std Mean       -0.149988
trainer/Policy log std Std         0.0217979
trainer/Policy log std Max        -0.109926
trainer/Policy log std Min        -0.209626
trainer/Alpha                      0.941539
trainer/Alpha Loss                -0.199285
exploration/num steps total      600
exploration/num paths total        6
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -7.96369
exploration/Rewards Std            2.18766
exploration/Rewards Max           -3.94985
exploration/Rewards Min          -11.9805
exploration/Returns Mean        -796.369
exploration/Returns Std          168.822
exploration/Returns Max         -627.547
exploration/Returns Min         -965.191
exploration/Actions Mean          -0.0685054
exploration/Actions Std            0.578057
exploration/Actions Max            0.987168
exploration/Actions Min           -0.99531
exploration/Num Paths              2
exploration/Average Returns     -796.369
evaluation/num steps total      2000
evaluation/num paths total        20
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -5.29665
evaluation/Rewards Std             3.61255
evaluation/Rewards Max            -0.454526
evaluation/Rewards Min           -12.1264
evaluation/Returns Mean         -529.665
evaluation/Returns Std           338.441
evaluation/Returns Max          -123.21
evaluation/Returns Min         -1145.53
evaluation/Actions Mean           -0.0765864
evaluation/Actions Std             0.143801
evaluation/Actions Max             0.0986799
evaluation/Actions Min            -0.282893
evaluation/Num Paths              10
evaluation/Average Returns      -529.665
time/data storing (s)              0.0011961
time/evaluation sampling (s)       0.251758
time/exploration sampling (s)      0.0634631
time/logging (s)                   0.00331692
time/saving (s)                    0.00187396
time/training (s)                  0.762951
time/epoch (s)                     1.08456
time/total (s)                     2.35959
Epoch                              1
-----------------------------  --------------
2019-04-21 01:11:46.548722 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 2 finished
-----------------------------  --------------
replay_buffer/size               800
trainer/QF1 Loss                   1.52055
trainer/QF2 Loss                   1.62362
trainer/Policy Loss               11.9339
trainer/Q1 Predictions Mean      -13.2931
trainer/Q1 Predictions Std         3.64714
trainer/Q1 Predictions Max        -8.04287
trainer/Q1 Predictions Min       -21.7212
trainer/Q2 Predictions Mean      -13.3978
trainer/Q2 Predictions Std         3.56931
trainer/Q2 Predictions Max        -8.11973
trainer/Q2 Predictions Min       -21.6055
trainer/Q Targets Mean           -13.4568
trainer/Q Targets Std              3.80726
trainer/Q Targets Max             -7.32058
trainer/Q Targets Min            -21.7135
trainer/Log Pis Mean              -1.27737
trainer/Log Pis Std                0.512088
trainer/Log Pis Max               -0.156481
trainer/Log Pis Min               -2.93633
trainer/Policy mu Mean            -0.113493
trainer/Policy mu Std              0.2794
trainer/Policy mu Max              0.302288
trainer/Policy mu Min             -0.681137
trainer/Policy log std Mean       -0.190811
trainer/Policy log std Std         0.0367017
trainer/Policy log std Max        -0.128487
trainer/Policy log std Min        -0.296478
trainer/Alpha                      0.887336
trainer/Alpha Loss                -0.39079
exploration/num steps total      800
exploration/num paths total        8
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.97558
exploration/Rewards Std            1.34719
exploration/Rewards Max           -1.23014
exploration/Rewards Min           -8.69585
exploration/Returns Mean        -497.558
exploration/Returns Std           10.3388
exploration/Returns Max         -487.219
exploration/Returns Min         -507.896
exploration/Actions Mean          -0.00284319
exploration/Actions Std            0.567051
exploration/Actions Max            0.984373
exploration/Actions Min           -0.990222
exploration/Num Paths              2
exploration/Average Returns     -497.558
evaluation/num steps total      3000
evaluation/num paths total        30
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -8.76539
evaluation/Rewards Std             4.0172
evaluation/Rewards Max            -0.144962
evaluation/Rewards Min           -12.7037
evaluation/Returns Mean         -876.539
evaluation/Returns Std           378.641
evaluation/Returns Max          -196.766
evaluation/Returns Min         -1253.19
evaluation/Actions Mean           -0.0348574
evaluation/Actions Std             0.230118
evaluation/Actions Max             0.312552
evaluation/Actions Min            -0.493395
evaluation/Num Paths              10
evaluation/Average Returns      -876.539
time/data storing (s)              0.00123969
time/evaluation sampling (s)       0.244104
time/exploration sampling (s)      0.0680268
time/logging (s)                   0.00333898
time/saving (s)                    0.0104317
time/training (s)                  0.775206
time/epoch (s)                     1.10235
time/total (s)                     3.46544
Epoch                              2
-----------------------------  --------------
2019-04-21 01:11:47.688530 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             1000
trainer/QF1 Loss                  2.50026
trainer/QF2 Loss                  2.62096
trainer/Policy Loss              15.3619
trainer/Q1 Predictions Mean     -16.8442
trainer/Q1 Predictions Std        4.07782
trainer/Q1 Predictions Max      -11.3798
trainer/Q1 Predictions Min      -29.0777
trainer/Q2 Predictions Mean     -16.8689
trainer/Q2 Predictions Std        4.08124
trainer/Q2 Predictions Max      -11.1277
trainer/Q2 Predictions Min      -28.9924
trainer/Q Targets Mean          -17.3272
trainer/Q Targets Std             4.30647
trainer/Q Targets Max            -5.47644
trainer/Q Targets Min           -29.123
trainer/Log Pis Mean             -1.11138
trainer/Log Pis Std               0.750754
trainer/Log Pis Max               0.883984
trainer/Log Pis Min              -3.60201
trainer/Policy mu Mean            0.0510182
trainer/Policy mu Std             0.395487
trainer/Policy mu Max             0.693715
trainer/Policy mu Min            -0.963201
trainer/Policy log std Mean      -0.235319
trainer/Policy log std Std        0.0508562
trainer/Policy log std Max       -0.135443
trainer/Policy log std Min       -0.372047
trainer/Alpha                     0.83744
trainer/Alpha Loss               -0.551097
exploration/num steps total    1000
exploration/num paths total      10
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -6.60048
exploration/Rewards Std           1.4544
exploration/Rewards Max          -3.2766
exploration/Rewards Min         -11.1289
exploration/Returns Mean       -660.048
exploration/Returns Std          94.6787
exploration/Returns Max        -565.37
exploration/Returns Min        -754.727
exploration/Actions Mean          0.0291009
exploration/Actions Std           0.571835
exploration/Actions Max           0.986181
exploration/Actions Min          -0.989879
exploration/Num Paths             2
exploration/Average Returns    -660.048
evaluation/num steps total     4000
evaluation/num paths total       40
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -7.6274
evaluation/Rewards Std            2.47595
evaluation/Rewards Max           -0.748811
evaluation/Rewards Min          -10.6866
evaluation/Returns Mean        -762.74
evaluation/Returns Std          174.911
evaluation/Returns Max         -524.927
evaluation/Returns Min         -973.198
evaluation/Actions Mean           0.0323162
evaluation/Actions Std            0.130742
evaluation/Actions Max            0.488421
evaluation/Actions Min           -0.57974
evaluation/Num Paths             10
evaluation/Average Returns     -762.74
time/data storing (s)             0.00157359
time/evaluation sampling (s)      0.241583
time/exploration sampling (s)     0.0896919
time/logging (s)                  0.00343279
time/saving (s)                   0.0121123
time/training (s)                 0.786559
time/epoch (s)                    1.13495
time/total (s)                    4.60459
Epoch                             3
-----------------------------  -------------
2019-04-21 01:11:48.771757 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             1200
trainer/QF1 Loss                  1.20117
trainer/QF2 Loss                  1.22864
trainer/Policy Loss              20.8476
trainer/Q1 Predictions Mean     -22.3935
trainer/Q1 Predictions Std        5.08732
trainer/Q1 Predictions Max      -14.4407
trainer/Q1 Predictions Min      -35.9478
trainer/Q2 Predictions Mean     -22.4159
trainer/Q2 Predictions Std        5.08602
trainer/Q2 Predictions Max      -14.3668
trainer/Q2 Predictions Min      -35.9951
trainer/Q Targets Mean          -22.6968
trainer/Q Targets Std             5.3686
trainer/Q Targets Max           -13.4383
trainer/Q Targets Min           -36.0199
trainer/Log Pis Mean             -0.966349
trainer/Log Pis Std               0.728909
trainer/Log Pis Max               0.846591
trainer/Log Pis Min              -2.68245
trainer/Policy mu Mean            0.0147174
trainer/Policy mu Std             0.49169
trainer/Policy mu Max             0.998696
trainer/Policy mu Min            -1.13534
trainer/Policy log std Mean      -0.273684
trainer/Policy log std Std        0.0456322
trainer/Policy log std Max       -0.176559
trainer/Policy log std Min       -0.393828
trainer/Alpha                     0.791643
trainer/Alpha Loss               -0.692252
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.79361
exploration/Rewards Std           1.28326
exploration/Rewards Max          -2.28337
exploration/Rewards Min          -9.42403
exploration/Returns Mean       -479.361
exploration/Returns Std          92.4215
exploration/Returns Max        -386.939
exploration/Returns Min        -571.782
exploration/Actions Mean          0.0231963
exploration/Actions Std           0.547854
exploration/Actions Max           0.989537
exploration/Actions Min          -0.976274
exploration/Num Paths             2
exploration/Average Returns    -479.361
evaluation/num steps total     5000
evaluation/num paths total       50
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.0075
evaluation/Rewards Std            1.3998
evaluation/Rewards Max           -3.01755
evaluation/Rewards Min          -11.1662
evaluation/Returns Mean        -400.75
evaluation/Returns Std          109.465
evaluation/Returns Max         -303.188
evaluation/Returns Min         -598.454
evaluation/Actions Mean           0.00134857
evaluation/Actions Std            0.115755
evaluation/Actions Max            0.575007
evaluation/Actions Min           -0.841657
evaluation/Num Paths             10
evaluation/Average Returns     -400.75
time/data storing (s)             0.00145981
time/evaluation sampling (s)      0.23028
time/exploration sampling (s)     0.0625673
time/logging (s)                  0.00335789
time/saving (s)                   0.00196138
time/training (s)                 0.778146
time/epoch (s)                    1.07777
time/total (s)                    5.687
Epoch                             4
-----------------------------  -------------
2019-04-21 01:11:49.837714 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             1400
trainer/QF1 Loss                  3.05921
trainer/QF2 Loss                  3.25077
trainer/Policy Loss              22.9697
trainer/Q1 Predictions Mean     -24.5652
trainer/Q1 Predictions Std        5.21876
trainer/Q1 Predictions Max      -16.2646
trainer/Q1 Predictions Min      -42.634
trainer/Q2 Predictions Mean     -24.6392
trainer/Q2 Predictions Std        5.20831
trainer/Q2 Predictions Max      -16.7031
trainer/Q2 Predictions Min      -42.7783
trainer/Q Targets Mean          -24.7018
trainer/Q Targets Std             5.93004
trainer/Q Targets Max            -3.36787
trainer/Q Targets Min           -45.182
trainer/Log Pis Mean             -0.923202
trainer/Log Pis Std               0.828898
trainer/Log Pis Max               2.09845
trainer/Log Pis Min              -3.05514
trainer/Policy mu Mean           -0.0869327
trainer/Policy mu Std             0.586961
trainer/Policy mu Max             1.0657
trainer/Policy mu Min            -1.45039
trainer/Policy log std Mean      -0.326723
trainer/Policy log std Std        0.0578161
trainer/Policy log std Max       -0.210143
trainer/Policy log std Min       -0.477294
trainer/Alpha                     0.749747
trainer/Alpha Loss               -0.841159
exploration/num steps total    1400
exploration/num paths total      14
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.31683
exploration/Rewards Std           1.23834
exploration/Rewards Max          -2.11866
exploration/Rewards Min          -8.49632
exploration/Returns Mean       -431.683
exploration/Returns Std          57.0848
exploration/Returns Max        -374.599
exploration/Returns Min        -488.768
exploration/Actions Mean         -0.00722668
exploration/Actions Std           0.579316
exploration/Actions Max           0.99477
exploration/Actions Min          -0.988529
exploration/Num Paths             2
exploration/Average Returns    -431.683
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.93328
evaluation/Rewards Std            0.926946
evaluation/Rewards Max           -2.71379
evaluation/Rewards Min           -8.15109
evaluation/Returns Mean        -393.328
evaluation/Returns Std           85.7154
evaluation/Returns Max         -300.663
evaluation/Returns Min         -491.83
evaluation/Actions Mean          -0.00470041
evaluation/Actions Std            0.12102
evaluation/Actions Max            0.737344
evaluation/Actions Min           -0.833597
evaluation/Num Paths             10
evaluation/Average Returns     -393.328
time/data storing (s)             0.00162953
time/evaluation sampling (s)      0.227644
time/exploration sampling (s)     0.0636799
time/logging (s)                  0.00332204
time/saving (s)                   0.00194797
time/training (s)                 0.76286
time/epoch (s)                    1.06108
time/total (s)                    6.75214
Epoch                             5
-----------------------------  -------------
2019-04-21 01:11:50.902610 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 6 finished
-----------------------------  -------------
replay_buffer/size             1600
trainer/QF1 Loss                  1.37517
trainer/QF2 Loss                  1.22961
trainer/Policy Loss              26.8673
trainer/Q1 Predictions Mean     -28.5682
trainer/Q1 Predictions Std        8.26356
trainer/Q1 Predictions Max      -18.7532
trainer/Q1 Predictions Min      -54.6453
trainer/Q2 Predictions Mean     -28.6051
trainer/Q2 Predictions Std        8.2006
trainer/Q2 Predictions Max      -19.0248
trainer/Q2 Predictions Min      -54.5062
trainer/Q Targets Mean          -28.8701
trainer/Q Targets Std             8.14974
trainer/Q Targets Max           -19.3894
trainer/Q Targets Min           -52.9792
trainer/Log Pis Mean             -0.721809
trainer/Log Pis Std               1.11551
trainer/Log Pis Max               2.20081
trainer/Log Pis Min              -3.56538
trainer/Policy mu Mean           -0.0369041
trainer/Policy mu Std             0.669249
trainer/Policy mu Max             1.31639
trainer/Policy mu Min            -1.4681
trainer/Policy log std Mean      -0.36739
trainer/Policy log std Std        0.0616908
trainer/Policy log std Max       -0.246612
trainer/Policy log std Min       -0.567084
trainer/Alpha                     0.711152
trainer/Alpha Loss               -0.927079
exploration/num steps total    1600
exploration/num paths total      16
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.06602
exploration/Rewards Std           0.765
exploration/Rewards Max          -1.38325
exploration/Rewards Min          -6.79896
exploration/Returns Mean       -306.602
exploration/Returns Std           0.869492
exploration/Returns Max        -305.733
exploration/Returns Min        -307.472
exploration/Actions Mean         -0.0102851
exploration/Actions Std           0.550888
exploration/Actions Max           0.986742
exploration/Actions Min          -0.990942
exploration/Num Paths             2
exploration/Average Returns    -306.602
evaluation/num steps total     7000
evaluation/num paths total       70
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.86348
evaluation/Rewards Std            0.943349
evaluation/Rewards Max           -2.78547
evaluation/Rewards Min          -10.7755
evaluation/Returns Mean        -386.348
evaluation/Returns Std           76.081
evaluation/Returns Max         -286.319
evaluation/Returns Min         -473.163
evaluation/Actions Mean           0.00281937
evaluation/Actions Std            0.128708
evaluation/Actions Max            0.805542
evaluation/Actions Min           -0.897828
evaluation/Num Paths             10
evaluation/Average Returns     -386.348
time/data storing (s)             0.00126774
time/evaluation sampling (s)      0.223839
time/exploration sampling (s)     0.0634594
time/logging (s)                  0.00338421
time/saving (s)                   0.00183279
time/training (s)                 0.766242
time/epoch (s)                    1.06002
time/total (s)                    7.81632
Epoch                             6
-----------------------------  -------------
2019-04-21 01:11:51.967310 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 7 finished
-----------------------------  -------------
replay_buffer/size             1800
trainer/QF1 Loss                  1.02047
trainer/QF2 Loss                  0.940307
trainer/Policy Loss              32.107
trainer/Q1 Predictions Mean     -33.8864
trainer/Q1 Predictions Std        9.80834
trainer/Q1 Predictions Max      -21.9408
trainer/Q1 Predictions Min      -57.2695
trainer/Q2 Predictions Mean     -33.8881
trainer/Q2 Predictions Std        9.81087
trainer/Q2 Predictions Max      -22.3805
trainer/Q2 Predictions Min      -57.1241
trainer/Q Targets Mean          -34.1093
trainer/Q Targets Std             9.99312
trainer/Q Targets Max           -22.0812
trainer/Q Targets Min           -56.9703
trainer/Log Pis Mean             -0.554592
trainer/Log Pis Std               1.20801
trainer/Log Pis Max               2.01344
trainer/Log Pis Min              -4.05172
trainer/Policy mu Mean           -0.084283
trainer/Policy mu Std             0.772441
trainer/Policy mu Max             1.54555
trainer/Policy mu Min            -1.50379
trainer/Policy log std Mean      -0.411909
trainer/Policy log std Std        0.0770336
trainer/Policy log std Max       -0.264373
trainer/Policy log std Min       -0.64808
trainer/Alpha                     0.67482
trainer/Alpha Loss               -1.00408
exploration/num steps total    1800
exploration/num paths total      18
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.02963
exploration/Rewards Std           1.4596
exploration/Rewards Max          -1.69543
exploration/Rewards Min         -10.9706
exploration/Returns Mean       -402.963
exploration/Returns Std          56.8769
exploration/Returns Max        -346.086
exploration/Returns Min        -459.84
exploration/Actions Mean         -0.0301793
exploration/Actions Std           0.530859
exploration/Actions Max           0.988781
exploration/Actions Min          -0.983565
exploration/Num Paths             2
exploration/Average Returns    -402.963
evaluation/num steps total     8000
evaluation/num paths total       80
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.68473
evaluation/Rewards Std            0.941028
evaluation/Rewards Max           -2.1767
evaluation/Rewards Min          -10.4177
evaluation/Returns Mean        -368.473
evaluation/Returns Std           64.925
evaluation/Returns Max         -278.889
evaluation/Returns Min         -434.286
evaluation/Actions Mean          -0.0050303
evaluation/Actions Std            0.14497
evaluation/Actions Max            0.901512
evaluation/Actions Min           -0.895426
evaluation/Num Paths             10
evaluation/Average Returns     -368.473
time/data storing (s)             0.00123778
time/evaluation sampling (s)      0.219106
time/exploration sampling (s)     0.0631188
time/logging (s)                  0.00249627
time/saving (s)                   0.00169249
time/training (s)                 0.771327
time/epoch (s)                    1.05898
time/total (s)                    8.8793
Epoch                             7
-----------------------------  -------------
2019-04-21 01:11:53.031899 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 8 finished
-----------------------------  -------------
replay_buffer/size             2000
trainer/QF1 Loss                 14.0906
trainer/QF2 Loss                 14.1341
trainer/Policy Loss              32.9094
trainer/Q1 Predictions Mean     -34.4993
trainer/Q1 Predictions Std        8.99737
trainer/Q1 Predictions Max      -24.1161
trainer/Q1 Predictions Min      -69.8272
trainer/Q2 Predictions Mean     -34.5064
trainer/Q2 Predictions Std        8.9705
trainer/Q2 Predictions Max      -24.3453
trainer/Q2 Predictions Min      -69.1364
trainer/Q Targets Mean          -34.2415
trainer/Q Targets Std            10.052
trainer/Q Targets Max            -2.98549
trainer/Q Targets Min           -67.3321
trainer/Log Pis Mean             -0.541844
trainer/Log Pis Std               1.03196
trainer/Log Pis Max               2.04583
trainer/Log Pis Min              -4.75748
trainer/Policy mu Mean            0.0160931
trainer/Policy mu Std             0.67611
trainer/Policy mu Max             1.53812
trainer/Policy mu Min            -1.56271
trainer/Policy log std Mean      -0.43182
trainer/Policy log std Std        0.0643049
trainer/Policy log std Max       -0.295761
trainer/Policy log std Min       -0.613602
trainer/Alpha                     0.640213
trainer/Alpha Loss               -1.13287
exploration/num steps total    2000
exploration/num paths total      20
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.19998
exploration/Rewards Std           0.895829
exploration/Rewards Max          -1.28654
exploration/Rewards Min          -6.78802
exploration/Returns Mean       -319.998
exploration/Returns Std          60.2974
exploration/Returns Max        -259.7
exploration/Returns Min        -380.295
exploration/Actions Mean          0.0155164
exploration/Actions Std           0.534404
exploration/Actions Max           0.983943
exploration/Actions Min          -0.972681
exploration/Num Paths             2
exploration/Average Returns    -319.998
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.28737
evaluation/Rewards Std            0.924579
evaluation/Rewards Max           -2.38551
evaluation/Rewards Min          -10.2533
evaluation/Returns Mean        -328.737
evaluation/Returns Std           68.9176
evaluation/Returns Max         -247.73
evaluation/Returns Min         -416.204
evaluation/Actions Mean           0.00444447
evaluation/Actions Std            0.135985
evaluation/Actions Max            0.911198
evaluation/Actions Min           -0.908703
evaluation/Num Paths             10
evaluation/Average Returns     -328.737
time/data storing (s)             0.00121431
time/evaluation sampling (s)      0.222096
time/exploration sampling (s)     0.0638589
time/logging (s)                  0.00334999
time/saving (s)                   0.00154073
time/training (s)                 0.769403
time/epoch (s)                    1.06146
time/total (s)                    9.94418
Epoch                             8
-----------------------------  -------------
2019-04-21 01:11:54.088535 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              2200
trainer/QF1 Loss                  31.9283
trainer/QF2 Loss                  31.7802
trainer/Policy Loss               35.4728
trainer/Q1 Predictions Mean      -37.2932
trainer/Q1 Predictions Std        10.5279
trainer/Q1 Predictions Max       -26.0899
trainer/Q1 Predictions Min       -71.2021
trainer/Q2 Predictions Mean      -37.3174
trainer/Q2 Predictions Std        10.5501
trainer/Q2 Predictions Max       -26.356
trainer/Q2 Predictions Min       -70.978
trainer/Q Targets Mean           -36.6046
trainer/Q Targets Std             11.9463
trainer/Q Targets Max             -3.16473
trainer/Q Targets Min            -71.2559
trainer/Log Pis Mean              -0.454981
trainer/Log Pis Std                1.31114
trainer/Log Pis Max                3.02214
trainer/Log Pis Min               -4.76815
trainer/Policy mu Mean            -0.0479928
trainer/Policy mu Std              0.731375
trainer/Policy mu Max              1.50626
trainer/Policy mu Min             -1.64584
trainer/Policy log std Mean       -0.459211
trainer/Policy log std Std         0.0683223
trainer/Policy log std Max        -0.305005
trainer/Policy log std Min        -0.652714
trainer/Alpha                      0.607311
trainer/Alpha Loss                -1.22369
exploration/num steps total     2200
exploration/num paths total       22
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.11027
exploration/Rewards Std            0.715874
exploration/Rewards Max           -1.43471
exploration/Rewards Min           -4.77835
exploration/Returns Mean        -311.027
exploration/Returns Std           43.9803
exploration/Returns Max         -267.047
exploration/Returns Min         -355.008
exploration/Actions Mean           0.0130782
exploration/Actions Std            0.523307
exploration/Actions Max            0.971866
exploration/Actions Min           -0.973193
exploration/Num Paths              2
exploration/Average Returns     -311.027
evaluation/num steps total     10000
evaluation/num paths total       100
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.3022
evaluation/Rewards Std             0.755699
evaluation/Rewards Max            -2.18823
evaluation/Rewards Min           -10.2951
evaluation/Returns Mean         -330.22
evaluation/Returns Std            45.5909
evaluation/Returns Max          -267.919
evaluation/Returns Min          -384.611
evaluation/Actions Mean            0.0040581
evaluation/Actions Std             0.137949
evaluation/Actions Max             0.922799
evaluation/Actions Min            -0.941372
evaluation/Num Paths              10
evaluation/Average Returns      -330.22
time/data storing (s)              0.00124739
time/evaluation sampling (s)       0.217025
time/exploration sampling (s)      0.064116
time/logging (s)                   0.00316824
time/saving (s)                    0.0015846
time/training (s)                  0.764403
time/epoch (s)                     1.05154
time/total (s)                    10.9998
Epoch                              9
-----------------------------  --------------
2019-04-21 01:11:55.130208 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              2400
trainer/QF1 Loss                   1.09217
trainer/QF2 Loss                   1.07969
trainer/Policy Loss               38.2053
trainer/Q1 Predictions Mean      -40.0726
trainer/Q1 Predictions Std        10.3912
trainer/Q1 Predictions Max       -28.0258
trainer/Q1 Predictions Min       -77.0395
trainer/Q2 Predictions Mean      -40.0671
trainer/Q2 Predictions Std        10.3701
trainer/Q2 Predictions Max       -28.1536
trainer/Q2 Predictions Min       -76.9039
trainer/Q Targets Mean           -40.5414
trainer/Q Targets Std             10.2553
trainer/Q Targets Max            -28.2294
trainer/Q Targets Min            -72.8887
trainer/Log Pis Mean              -0.485415
trainer/Log Pis Std                1.39833
trainer/Log Pis Max                3.31302
trainer/Log Pis Min               -5.60045
trainer/Policy mu Mean            -0.0916058
trainer/Policy mu Std              0.796099
trainer/Policy mu Max              1.75857
trainer/Policy mu Min             -1.77471
trainer/Policy log std Mean       -0.484656
trainer/Policy log std Std         0.0799112
trainer/Policy log std Max        -0.302757
trainer/Policy log std Min        -0.739327
trainer/Alpha                      0.575887
trainer/Alpha Loss                -1.3709
exploration/num steps total     2400
exploration/num paths total       24
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.27697
exploration/Rewards Std            0.931785
exploration/Rewards Max           -1.50215
exploration/Rewards Min           -9.19649
exploration/Returns Mean        -327.697
exploration/Returns Std           22.8735
exploration/Returns Max         -304.824
exploration/Returns Min         -350.571
exploration/Actions Mean          -0.0348262
exploration/Actions Std            0.499974
exploration/Actions Max            0.967895
exploration/Actions Min           -0.994713
exploration/Num Paths              2
exploration/Average Returns     -327.697
evaluation/num steps total     11000
evaluation/num paths total       110
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.15244
evaluation/Rewards Std             0.546147
evaluation/Rewards Max            -2.2287
evaluation/Rewards Min            -8.8236
evaluation/Returns Mean         -315.244
evaluation/Returns Std            36.7675
evaluation/Returns Max          -266.921
evaluation/Returns Min          -358.768
evaluation/Actions Mean           -0.00425926
evaluation/Actions Std             0.144917
evaluation/Actions Max             0.889346
evaluation/Actions Min            -0.909916
evaluation/Num Paths              10
evaluation/Average Returns      -315.244
time/data storing (s)              0.00130954
time/evaluation sampling (s)       0.220629
time/exploration sampling (s)      0.0644821
time/logging (s)                   0.00338109
time/saving (s)                    0.00198859
time/training (s)                  0.745343
time/epoch (s)                     1.03713
time/total (s)                    12.041
Epoch                             10
-----------------------------  --------------
2019-04-21 01:11:56.198524 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              2600
trainer/QF1 Loss                  18.7951
trainer/QF2 Loss                  18.3665
trainer/Policy Loss               40.3465
trainer/Q1 Predictions Mean      -42.0077
trainer/Q1 Predictions Std        10.2803
trainer/Q1 Predictions Max       -30.0104
trainer/Q1 Predictions Min       -76.6324
trainer/Q2 Predictions Mean      -41.9547
trainer/Q2 Predictions Std        10.262
trainer/Q2 Predictions Max       -30.2356
trainer/Q2 Predictions Min       -76.4833
trainer/Q Targets Mean           -42.1214
trainer/Q Targets Std             11.1414
trainer/Q Targets Max             -7.01677
trainer/Q Targets Min            -79.1274
trainer/Log Pis Mean              -0.196667
trainer/Log Pis Std                1.34854
trainer/Log Pis Max                3.82882
trainer/Log Pis Min               -2.57406
trainer/Policy mu Mean            -0.0983679
trainer/Policy mu Std              0.774259
trainer/Policy mu Max              1.6733
trainer/Policy mu Min             -1.84226
trainer/Policy log std Mean       -0.472709
trainer/Policy log std Std         0.0872578
trainer/Policy log std Max        -0.297372
trainer/Policy log std Min        -0.712666
trainer/Alpha                      0.545925
trainer/Alpha Loss                -1.32901
exploration/num steps total     2600
exploration/num paths total       26
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.05236
exploration/Rewards Std            0.828024
exploration/Rewards Max           -0.984906
exploration/Rewards Min           -5.08908
exploration/Returns Mean        -305.236
exploration/Returns Std           57.7573
exploration/Returns Max         -247.479
exploration/Returns Min         -362.994
exploration/Actions Mean           0.0147951
exploration/Actions Std            0.517047
exploration/Actions Max            0.976819
exploration/Actions Min           -0.951983
exploration/Num Paths              2
exploration/Average Returns     -305.236
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.26998
evaluation/Rewards Std             0.706293
evaluation/Rewards Max            -2.48646
evaluation/Rewards Min           -10.3681
evaluation/Returns Mean         -326.998
evaluation/Returns Std            45.8075
evaluation/Returns Max          -251.386
evaluation/Returns Min          -374.159
evaluation/Actions Mean            0.00443929
evaluation/Actions Std             0.129925
evaluation/Actions Max             0.919904
evaluation/Actions Min            -0.94141
evaluation/Num Paths              10
evaluation/Average Returns      -326.998
time/data storing (s)              0.00138984
time/evaluation sampling (s)       0.231936
time/exploration sampling (s)      0.0666394
time/logging (s)                   0.00341278
time/saving (s)                    0.00197342
time/training (s)                  0.758033
time/epoch (s)                     1.06338
time/total (s)                    13.1085
Epoch                             11
-----------------------------  --------------
2019-04-21 01:11:57.257588 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              2800
trainer/QF1 Loss                  68.0409
trainer/QF2 Loss                  68.0271
trainer/Policy Loss               43.0177
trainer/Q1 Predictions Mean      -44.6417
trainer/Q1 Predictions Std        12.4666
trainer/Q1 Predictions Max       -31.7679
trainer/Q1 Predictions Min       -85.0775
trainer/Q2 Predictions Mean      -44.6497
trainer/Q2 Predictions Std        12.4516
trainer/Q2 Predictions Max       -31.9831
trainer/Q2 Predictions Min       -85.1272
trainer/Q Targets Mean           -43.979
trainer/Q Targets Std             12.9945
trainer/Q Targets Max             -4.64841
trainer/Q Targets Min            -81.3005
trainer/Log Pis Mean              -0.235973
trainer/Log Pis Std                1.26822
trainer/Log Pis Max                2.68267
trainer/Log Pis Min               -3.97038
trainer/Policy mu Mean            -0.00176865
trainer/Policy mu Std              0.772181
trainer/Policy mu Max              1.8341
trainer/Policy mu Min             -1.87836
trainer/Policy log std Mean       -0.496446
trainer/Policy log std Std         0.0988282
trainer/Policy log std Max        -0.311553
trainer/Policy log std Min        -0.687468
trainer/Alpha                      0.517356
trainer/Alpha Loss                -1.47297
exploration/num steps total     2800
exploration/num paths total       28
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.79512
exploration/Rewards Std            0.594215
exploration/Rewards Max           -1.32737
exploration/Rewards Min           -4.20003
exploration/Returns Mean        -279.512
exploration/Returns Std           30.4435
exploration/Returns Max         -249.068
exploration/Returns Min         -309.955
exploration/Actions Mean           0.00784528
exploration/Actions Std            0.511192
exploration/Actions Max            0.96066
exploration/Actions Min           -0.970748
exploration/Num Paths              2
exploration/Average Returns     -279.512
evaluation/num steps total     13000
evaluation/num paths total       130
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.96559
evaluation/Rewards Std             0.892904
evaluation/Rewards Max            -1.54908
evaluation/Rewards Min           -11.1335
evaluation/Returns Mean         -296.559
evaluation/Returns Std            28.4362
evaluation/Returns Max          -249.325
evaluation/Returns Min          -347.278
evaluation/Actions Mean           -0.005474
evaluation/Actions Std             0.160772
evaluation/Actions Max             0.942136
evaluation/Actions Min            -0.953094
evaluation/Num Paths              10
evaluation/Average Returns      -296.559
time/data storing (s)              0.00123305
time/evaluation sampling (s)       0.222528
time/exploration sampling (s)      0.0646196
time/logging (s)                   0.00337003
time/saving (s)                    0.00194096
time/training (s)                  0.760441
time/epoch (s)                     1.05413
time/total (s)                    14.1667
Epoch                             12
-----------------------------  --------------
2019-04-21 01:11:58.321437 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              3000
trainer/QF1 Loss                   1.14153
trainer/QF2 Loss                   1.03955
trainer/Policy Loss               44.7648
trainer/Q1 Predictions Mean      -46.2768
trainer/Q1 Predictions Std        12.3399
trainer/Q1 Predictions Max       -33.8905
trainer/Q1 Predictions Min       -85.11
trainer/Q2 Predictions Mean      -46.3114
trainer/Q2 Predictions Std        12.3493
trainer/Q2 Predictions Max       -33.8909
trainer/Q2 Predictions Min       -85.0301
trainer/Q Targets Mean           -46.7494
trainer/Q Targets Std             12.6816
trainer/Q Targets Max            -34.0446
trainer/Q Targets Min            -87.878
trainer/Log Pis Mean              -0.0744719
trainer/Log Pis Std                1.26239
trainer/Log Pis Max                3.81714
trainer/Log Pis Min               -3.2706
trainer/Policy mu Mean            -0.124617
trainer/Policy mu Std              0.79303
trainer/Policy mu Max              1.69752
trainer/Policy mu Min             -1.86165
trainer/Policy log std Mean       -0.540374
trainer/Policy log std Std         0.0865253
trainer/Policy log std Max        -0.35057
trainer/Policy log std Min        -0.752529
trainer/Alpha                      0.490047
trainer/Alpha Loss                -1.47906
exploration/num steps total     3000
exploration/num paths total       30
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.40878
exploration/Rewards Std            1.06154
exploration/Rewards Max           -0.583372
exploration/Rewards Min           -9.56988
exploration/Returns Mean        -240.878
exploration/Returns Std           17.693
exploration/Returns Max         -223.185
exploration/Returns Min         -258.571
exploration/Actions Mean          -0.0324179
exploration/Actions Std            0.502572
exploration/Actions Max            0.948642
exploration/Actions Min           -0.993176
exploration/Num Paths              2
exploration/Average Returns     -240.878
evaluation/num steps total     14000
evaluation/num paths total       140
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.71873
evaluation/Rewards Std             0.680501
evaluation/Rewards Max            -0.766763
evaluation/Rewards Min            -8.16024
evaluation/Returns Mean         -271.873
evaluation/Returns Std            48.8883
evaluation/Returns Max          -210.826
evaluation/Returns Min          -332.634
evaluation/Actions Mean           -0.0120256
evaluation/Actions Std             0.132507
evaluation/Actions Max             0.917757
evaluation/Actions Min            -0.951251
evaluation/Num Paths              10
evaluation/Average Returns      -271.873
time/data storing (s)              0.00124436
time/evaluation sampling (s)       0.226054
time/exploration sampling (s)      0.065295
time/logging (s)                   0.00338218
time/saving (s)                    0.00196352
time/training (s)                  0.761002
time/epoch (s)                     1.05894
time/total (s)                    15.2297
Epoch                             13
-----------------------------  --------------
2019-04-21 01:11:59.385755 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              3200
trainer/QF1 Loss                  12.1226
trainer/QF2 Loss                  12.244
trainer/Policy Loss               45.4816
trainer/Q1 Predictions Mean      -47.0655
trainer/Q1 Predictions Std        11.7854
trainer/Q1 Predictions Max       -35.3487
trainer/Q1 Predictions Min       -87.1414
trainer/Q2 Predictions Mean      -46.9969
trainer/Q2 Predictions Std        11.8252
trainer/Q2 Predictions Max       -35.2777
trainer/Q2 Predictions Min       -87.1642
trainer/Q Targets Mean           -46.9905
trainer/Q Targets Std             12.7318
trainer/Q Targets Max             -2.14368
trainer/Q Targets Min            -87.4174
trainer/Log Pis Mean              -0.373652
trainer/Log Pis Std                1.30135
trainer/Log Pis Max                3.2573
trainer/Log Pis Min               -4.34844
trainer/Policy mu Mean            -0.0797116
trainer/Policy mu Std              0.757608
trainer/Policy mu Max              1.87717
trainer/Policy mu Min             -1.85187
trainer/Policy log std Mean       -0.553018
trainer/Policy log std Std         0.0877964
trainer/Policy log std Max        -0.359398
trainer/Policy log std Min        -0.755746
trainer/Alpha                      0.464232
trainer/Alpha Loss                -1.82083
exploration/num steps total     3200
exploration/num paths total       32
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.33914
exploration/Rewards Std            0.959882
exploration/Rewards Max           -2.01857
exploration/Rewards Min           -8.72803
exploration/Returns Mean        -333.914
exploration/Returns Std            9.57337
exploration/Returns Max         -324.341
exploration/Returns Min         -343.488
exploration/Actions Mean           0.00337539
exploration/Actions Std            0.523251
exploration/Actions Max            0.959917
exploration/Actions Min           -0.966
exploration/Num Paths              2
exploration/Average Returns     -333.914
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.86806
evaluation/Rewards Std             0.73714
evaluation/Rewards Max            -1.04734
evaluation/Rewards Min           -10.4413
evaluation/Returns Mean         -286.806
evaluation/Returns Std            29.6525
evaluation/Returns Max          -244.302
evaluation/Returns Min          -336.505
evaluation/Actions Mean           -0.00863358
evaluation/Actions Std             0.167694
evaluation/Actions Max             0.963058
evaluation/Actions Min            -0.951683
evaluation/Num Paths              10
evaluation/Average Returns      -286.806
time/data storing (s)              0.00122526
time/evaluation sampling (s)       0.221636
time/exploration sampling (s)      0.0632634
time/logging (s)                   0.00331073
time/saving (s)                    0.00197477
time/training (s)                  0.767972
time/epoch (s)                     1.05938
time/total (s)                    16.2931
Epoch                             14
-----------------------------  --------------
2019-04-21 01:12:00.423640 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              3400
trainer/QF1 Loss                  13.6284
trainer/QF2 Loss                  13.732
trainer/Policy Loss               49.9081
trainer/Q1 Predictions Mean      -51.9197
trainer/Q1 Predictions Std        13.4255
trainer/Q1 Predictions Max       -37.2705
trainer/Q1 Predictions Min       -91.0591
trainer/Q2 Predictions Mean      -51.9088
trainer/Q2 Predictions Std        13.4353
trainer/Q2 Predictions Max       -37.2267
trainer/Q2 Predictions Min       -91.1009
trainer/Q Targets Mean           -51.91
trainer/Q Targets Std             14.4298
trainer/Q Targets Max             -2.13847
trainer/Q Targets Min            -92.209
trainer/Log Pis Mean              -0.0737512
trainer/Log Pis Std                1.72193
trainer/Log Pis Max                4.32994
trainer/Log Pis Min               -5.29311
trainer/Policy mu Mean            -0.0892114
trainer/Policy mu Std              0.888633
trainer/Policy mu Max              1.91977
trainer/Policy mu Min             -2.05237
trainer/Policy log std Mean       -0.582638
trainer/Policy log std Std         0.101007
trainer/Policy log std Max        -0.368564
trainer/Policy log std Min        -0.84909
trainer/Alpha                      0.439864
trainer/Alpha Loss                -1.70259
exploration/num steps total     3400
exploration/num paths total       34
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.29176
exploration/Rewards Std            0.582295
exploration/Rewards Max           -1.14657
exploration/Rewards Min           -5.91758
exploration/Returns Mean        -229.176
exploration/Returns Std            9.11372
exploration/Returns Max         -220.062
exploration/Returns Min         -238.29
exploration/Actions Mean          -0.00934241
exploration/Actions Std            0.482933
exploration/Actions Max            0.93596
exploration/Actions Min           -0.983706
exploration/Num Paths              2
exploration/Average Returns     -229.176
evaluation/num steps total     16000
evaluation/num paths total       160
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.16764
evaluation/Rewards Std             0.898754
evaluation/Rewards Max            -2.24994
evaluation/Rewards Min           -11.4571
evaluation/Returns Mean         -316.764
evaluation/Returns Std            30.7952
evaluation/Returns Max          -232.768
evaluation/Returns Min          -345.73
evaluation/Actions Mean            0.0163885
evaluation/Actions Std             0.166451
evaluation/Actions Max             0.963312
evaluation/Actions Min            -0.943344
evaluation/Num Paths              10
evaluation/Average Returns      -316.764
time/data storing (s)              0.00122088
time/evaluation sampling (s)       0.220452
time/exploration sampling (s)      0.0639429
time/logging (s)                   0.0025113
time/saving (s)                    0.00194086
time/training (s)                  0.741854
time/epoch (s)                     1.03192
time/total (s)                    17.329
Epoch                             15
-----------------------------  --------------
2019-04-21 01:12:01.467904 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              3600
trainer/QF1 Loss                   0.850922
trainer/QF2 Loss                   0.965268
trainer/Policy Loss               50.1243
trainer/Q1 Predictions Mean      -51.9777
trainer/Q1 Predictions Std        12.4046
trainer/Q1 Predictions Max       -38.4126
trainer/Q1 Predictions Min       -98.0499
trainer/Q2 Predictions Mean      -51.9644
trainer/Q2 Predictions Std        12.4145
trainer/Q2 Predictions Max       -38.4463
trainer/Q2 Predictions Min       -98.193
trainer/Q Targets Mean           -52.4508
trainer/Q Targets Std             12.4251
trainer/Q Targets Max            -39.0547
trainer/Q Targets Min            -99.0172
trainer/Log Pis Mean              -0.0924642
trainer/Log Pis Std                1.46135
trainer/Log Pis Max                4.82669
trainer/Log Pis Min               -5.609
trainer/Policy mu Mean             0.0224023
trainer/Policy mu Std              0.812688
trainer/Policy mu Max              1.94511
trainer/Policy mu Min             -1.92939
trainer/Policy log std Mean       -0.588474
trainer/Policy log std Std         0.108608
trainer/Policy log std Max        -0.390687
trainer/Policy log std Min        -0.853428
trainer/Alpha                      0.416623
trainer/Alpha Loss                -1.83153
exploration/num steps total     3600
exploration/num paths total       36
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.8229
exploration/Rewards Std            0.823402
exploration/Rewards Max           -1.41774
exploration/Rewards Min           -6.9657
exploration/Returns Mean        -282.29
exploration/Returns Std           31.738
exploration/Returns Max         -250.552
exploration/Returns Min         -314.028
exploration/Actions Mean          -0.0225998
exploration/Actions Std            0.499801
exploration/Actions Max            0.956608
exploration/Actions Min           -0.980403
exploration/Num Paths              2
exploration/Average Returns     -282.29
evaluation/num steps total     17000
evaluation/num paths total       170
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.77219
evaluation/Rewards Std             0.672762
evaluation/Rewards Max            -0.182233
evaluation/Rewards Min            -9.7056
evaluation/Returns Mean         -277.219
evaluation/Returns Std            30.8336
evaluation/Returns Max          -235.858
evaluation/Returns Min          -323.243
evaluation/Actions Mean            0.0039711
evaluation/Actions Std             0.15526
evaluation/Actions Max             0.958963
evaluation/Actions Min            -0.934458
evaluation/Num Paths              10
evaluation/Average Returns      -277.219
time/data storing (s)              0.00148258
time/evaluation sampling (s)       0.224435
time/exploration sampling (s)      0.0655721
time/logging (s)                   0.00339932
time/saving (s)                    0.00197347
time/training (s)                  0.744045
time/epoch (s)                     1.04091
time/total (s)                    18.3735
Epoch                             16
-----------------------------  --------------
2019-04-21 01:12:02.535714 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              3800
trainer/QF1 Loss                  16.5467
trainer/QF2 Loss                  16.4183
trainer/Policy Loss               50.942
trainer/Q1 Predictions Mean      -52.7031
trainer/Q1 Predictions Std        12.6247
trainer/Q1 Predictions Max       -39.965
trainer/Q1 Predictions Min      -100.476
trainer/Q2 Predictions Mean      -52.7071
trainer/Q2 Predictions Std        12.6361
trainer/Q2 Predictions Max       -39.966
trainer/Q2 Predictions Min      -100.292
trainer/Q Targets Mean           -52.9905
trainer/Q Targets Std             13.8107
trainer/Q Targets Max             -2.08764
trainer/Q Targets Min            -98.182
trainer/Log Pis Mean              -0.129124
trainer/Log Pis Std                1.31946
trainer/Log Pis Max                3.23465
trainer/Log Pis Min               -2.72714
trainer/Policy mu Mean             0.0435004
trainer/Policy mu Std              0.810922
trainer/Policy mu Max              1.99213
trainer/Policy mu Min             -1.96871
trainer/Policy log std Mean       -0.561023
trainer/Policy log std Std         0.118529
trainer/Policy log std Max        -0.310432
trainer/Policy log std Min        -0.797126
trainer/Alpha                      0.394445
trainer/Alpha Loss                -1.98009
exploration/num steps total     3800
exploration/num paths total       38
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.66713
exploration/Rewards Std            0.606366
exploration/Rewards Max           -1.27764
exploration/Rewards Min           -5.06689
exploration/Returns Mean        -266.713
exploration/Returns Std           16.6128
exploration/Returns Max         -250.101
exploration/Returns Min         -283.326
exploration/Actions Mean          -0.00371609
exploration/Actions Std            0.497415
exploration/Actions Max            0.944853
exploration/Actions Min           -0.97747
exploration/Num Paths              2
exploration/Average Returns     -266.713
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.66222
evaluation/Rewards Std             0.748806
evaluation/Rewards Max            -2.20977
evaluation/Rewards Min            -9.17554
evaluation/Returns Mean         -266.222
evaluation/Returns Std            26.3575
evaluation/Returns Max          -233.446
evaluation/Returns Min          -304.171
evaluation/Actions Mean            0.00691351
evaluation/Actions Std             0.166651
evaluation/Actions Max             0.955861
evaluation/Actions Min            -0.967904
evaluation/Num Paths              10
evaluation/Average Returns      -266.222
time/data storing (s)              0.00121306
time/evaluation sampling (s)       0.216871
time/exploration sampling (s)      0.0648677
time/logging (s)                   0.00345836
time/saving (s)                    0.00202003
time/training (s)                  0.774389
time/epoch (s)                     1.06282
time/total (s)                    19.4404
Epoch                             17
-----------------------------  --------------
2019-04-21 01:12:03.599548 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              4000
trainer/QF1 Loss                  16.571
trainer/QF2 Loss                  16.3345
trainer/Policy Loss               52.292
trainer/Q1 Predictions Mean      -53.8427
trainer/Q1 Predictions Std        12.5079
trainer/Q1 Predictions Max       -41.1386
trainer/Q1 Predictions Min       -97.5592
trainer/Q2 Predictions Mean      -53.8588
trainer/Q2 Predictions Std        12.5315
trainer/Q2 Predictions Max       -41.0295
trainer/Q2 Predictions Min       -98.2306
trainer/Q Targets Mean           -53.8432
trainer/Q Targets Std             13.3761
trainer/Q Targets Max             -3.36787
trainer/Q Targets Min            -96.1077
trainer/Log Pis Mean              -0.152358
trainer/Log Pis Std                1.16396
trainer/Log Pis Max                2.48303
trainer/Log Pis Min               -4.07828
trainer/Policy mu Mean            -0.107267
trainer/Policy mu Std              0.792865
trainer/Policy mu Max              1.95614
trainer/Policy mu Min             -2.13534
trainer/Policy log std Mean       -0.618379
trainer/Policy log std Std         0.12213
trainer/Policy log std Max        -0.386116
trainer/Policy log std Min        -0.848356
trainer/Alpha                      0.373338
trainer/Alpha Loss                -2.12009
exploration/num steps total     4000
exploration/num paths total       40
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.03434
exploration/Rewards Std            1.14406
exploration/Rewards Max           -1.34176
exploration/Rewards Min           -9.74184
exploration/Returns Mean        -303.434
exploration/Returns Std           46.7078
exploration/Returns Max         -256.726
exploration/Returns Min         -350.142
exploration/Actions Mean          -0.0289798
exploration/Actions Std            0.52649
exploration/Actions Max            0.991756
exploration/Actions Min           -0.977499
exploration/Num Paths              2
exploration/Average Returns     -303.434
evaluation/num steps total     19000
evaluation/num paths total       190
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.74128
evaluation/Rewards Std             0.788655
evaluation/Rewards Max            -2.04574
evaluation/Rewards Min            -9.57004
evaluation/Returns Mean         -274.128
evaluation/Returns Std            41.905
evaluation/Returns Max          -226.677
evaluation/Returns Min          -334.407
evaluation/Actions Mean           -0.00221962
evaluation/Actions Std             0.152147
evaluation/Actions Max             0.957771
evaluation/Actions Min            -0.976355
evaluation/Num Paths              10
evaluation/Average Returns      -274.128
time/data storing (s)              0.00123944
time/evaluation sampling (s)       0.221791
time/exploration sampling (s)      0.0637678
time/logging (s)                   0.00250885
time/saving (s)                    0.0015877
time/training (s)                  0.76749
time/epoch (s)                     1.05838
time/total (s)                    20.5023
Epoch                             18
-----------------------------  --------------
2019-04-21 01:12:04.668982 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                  34.0805
trainer/QF2 Loss                  34.0167
trainer/Policy Loss               52.4568
trainer/Q1 Predictions Mean      -53.5507
trainer/Q1 Predictions Std        11.6485
trainer/Q1 Predictions Max       -42.3645
trainer/Q1 Predictions Min       -90.9795
trainer/Q2 Predictions Mean      -53.551
trainer/Q2 Predictions Std        11.655
trainer/Q2 Predictions Max       -42.2828
trainer/Q2 Predictions Min       -91.1052
trainer/Q Targets Mean           -53.4143
trainer/Q Targets Std             13.7686
trainer/Q Targets Max             -1.7792
trainer/Q Targets Min            -92.0946
trainer/Log Pis Mean              -0.170509
trainer/Log Pis Std                1.25292
trainer/Log Pis Max                4.38741
trainer/Log Pis Min               -3.53815
trainer/Policy mu Mean            -0.111459
trainer/Policy mu Std              0.770008
trainer/Policy mu Max              1.74125
trainer/Policy mu Min             -2.3072
trainer/Policy log std Mean       -0.658234
trainer/Policy log std Std         0.132325
trainer/Policy log std Max        -0.358287
trainer/Policy log std Min        -0.915451
trainer/Alpha                      0.353518
trainer/Alpha Loss                -2.25632
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.64413
exploration/Rewards Std            1.22022
exploration/Rewards Max           -1.04606
exploration/Rewards Min           -9.88415
exploration/Returns Mean        -264.413
exploration/Returns Std           39.2037
exploration/Returns Max         -225.209
exploration/Returns Min         -303.616
exploration/Actions Mean           0.004065
exploration/Actions Std            0.480196
exploration/Actions Max            0.98795
exploration/Actions Min           -0.991924
exploration/Num Paths              2
exploration/Average Returns     -264.413
evaluation/num steps total     20000
evaluation/num paths total       200
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.55682
evaluation/Rewards Std             0.700206
evaluation/Rewards Max            -1.98298
evaluation/Rewards Min           -10.2737
evaluation/Returns Mean         -255.682
evaluation/Returns Std            43.4785
evaluation/Returns Max          -206.444
evaluation/Returns Min          -319.832
evaluation/Actions Mean           -0.00901893
evaluation/Actions Std             0.146647
evaluation/Actions Max             0.962376
evaluation/Actions Min            -0.980038
evaluation/Num Paths              10
evaluation/Average Returns      -255.682
time/data storing (s)              0.00121664
time/evaluation sampling (s)       0.2255
time/exploration sampling (s)      0.064281
time/logging (s)                   0.0033898
time/saving (s)                    0.00198939
time/training (s)                  0.770027
time/epoch (s)                     1.0664
time/total (s)                    21.572
Epoch                             19
-----------------------------  --------------
2019-04-21 01:12:05.733976 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size              4400
trainer/QF1 Loss                  65.846
trainer/QF2 Loss                  66.1475
trainer/Policy Loss               57.5164
trainer/Q1 Predictions Mean      -59.0217
trainer/Q1 Predictions Std        14.0427
trainer/Q1 Predictions Max       -44.0191
trainer/Q1 Predictions Min      -107.361
trainer/Q2 Predictions Mean      -59.0332
trainer/Q2 Predictions Std        14.0619
trainer/Q2 Predictions Max       -43.9722
trainer/Q2 Predictions Min      -106.947
trainer/Q Targets Mean           -58.2428
trainer/Q Targets Std             16.0623
trainer/Q Targets Max             -3.22991
trainer/Q Targets Min           -103.99
trainer/Log Pis Mean               0.0481516
trainer/Log Pis Std                1.54511
trainer/Log Pis Max                3.58499
trainer/Log Pis Min               -7.64731
trainer/Policy mu Mean             0.0504211
trainer/Policy mu Std              0.8899
trainer/Policy mu Max              2.17273
trainer/Policy mu Min             -2.03629
trainer/Policy log std Mean       -0.672201
trainer/Policy log std Std         0.113723
trainer/Policy log std Max        -0.417924
trainer/Policy log std Min        -0.879759
trainer/Alpha                      0.33465
trainer/Alpha Loss                -2.13611
exploration/num steps total     4400
exploration/num paths total       44
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.39102
exploration/Rewards Std            0.49976
exploration/Rewards Max           -1.45047
exploration/Rewards Min           -5.35315
exploration/Returns Mean        -239.102
exploration/Returns Std            5.57116
exploration/Returns Max         -233.53
exploration/Returns Min         -244.673
exploration/Actions Mean           0.0199465
exploration/Actions Std            0.458452
exploration/Actions Max            0.953717
exploration/Actions Min           -0.832323
exploration/Num Paths              2
exploration/Average Returns     -239.102
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.67693
evaluation/Rewards Std             0.63344
evaluation/Rewards Max            -0.74502
evaluation/Rewards Min            -9.91518
evaluation/Returns Mean         -267.693
evaluation/Returns Std            24.9186
evaluation/Returns Max          -228.672
evaluation/Returns Min          -305.245
evaluation/Actions Mean           -0.00578422
evaluation/Actions Std             0.146265
evaluation/Actions Max             0.972355
evaluation/Actions Min            -0.962075
evaluation/Num Paths              10
evaluation/Average Returns      -267.693
time/data storing (s)              0.00124992
time/evaluation sampling (s)       0.22239
time/exploration sampling (s)      0.0642727
time/logging (s)                   0.00339948
time/saving (s)                    0.00198376
time/training (s)                  0.766672
time/epoch (s)                     1.05997
time/total (s)                    22.636
Epoch                             20
-----------------------------  --------------
2019-04-21 01:12:06.782146 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size              4600
trainer/QF1 Loss                  20.7777
trainer/QF2 Loss                  21.0422
trainer/Policy Loss               54.8208
trainer/Q1 Predictions Mean      -56.1439
trainer/Q1 Predictions Std        11.0927
trainer/Q1 Predictions Max       -43.7239
trainer/Q1 Predictions Min       -95.5033
trainer/Q2 Predictions Mean      -56.1193
trainer/Q2 Predictions Std        11.0614
trainer/Q2 Predictions Max       -43.7713
trainer/Q2 Predictions Min       -95.2626
trainer/Q Targets Mean           -57.0988
trainer/Q Targets Std             12.3364
trainer/Q Targets Max             -2.13847
trainer/Q Targets Min           -100.309
trainer/Log Pis Mean              -0.190752
trainer/Log Pis Std                1.38745
trainer/Log Pis Max                3.80662
trainer/Log Pis Min               -5.36834
trainer/Policy mu Mean            -0.0553816
trainer/Policy mu Std              0.794645
trainer/Policy mu Max              1.93832
trainer/Policy mu Min             -1.85246
trainer/Policy log std Mean       -0.663992
trainer/Policy log std Std         0.132812
trainer/Policy log std Max        -0.405411
trainer/Policy log std Min        -0.879894
trainer/Alpha                      0.316826
trainer/Alpha Loss                -2.51746
exploration/num steps total     4600
exploration/num paths total       46
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.55616
exploration/Rewards Std            0.735897
exploration/Rewards Max           -1.18009
exploration/Rewards Min           -7.85882
exploration/Returns Mean        -255.616
exploration/Returns Std           23.4218
exploration/Returns Max         -232.194
exploration/Returns Min         -279.038
exploration/Actions Mean           0.00651142
exploration/Actions Std            0.467711
exploration/Actions Max            0.962869
exploration/Actions Min           -0.980022
exploration/Num Paths              2
exploration/Average Returns     -255.616
evaluation/num steps total     22000
evaluation/num paths total       220
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.81719
evaluation/Rewards Std             0.765452
evaluation/Rewards Max            -1.51087
evaluation/Rewards Min           -10.103
evaluation/Returns Mean         -281.719
evaluation/Returns Std            32.9023
evaluation/Returns Max          -219.406
evaluation/Returns Min          -316.525
evaluation/Actions Mean            0.0139257
evaluation/Actions Std             0.165536
evaluation/Actions Max             0.972673
evaluation/Actions Min            -0.888081
evaluation/Num Paths              10
evaluation/Average Returns      -281.719
time/data storing (s)              0.00128229
time/evaluation sampling (s)       0.215031
time/exploration sampling (s)      0.0610844
time/logging (s)                   0.00336183
time/saving (s)                    0.00165295
time/training (s)                  0.760666
time/epoch (s)                     1.04308
time/total (s)                    23.6831
Epoch                             21
-----------------------------  --------------
2019-04-21 01:12:07.851079 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size              4800
trainer/QF1 Loss                   0.774963
trainer/QF2 Loss                   0.74251
trainer/Policy Loss               57.3173
trainer/Q1 Predictions Mean      -58.7394
trainer/Q1 Predictions Std        12.4486
trainer/Q1 Predictions Max       -46.139
trainer/Q1 Predictions Min       -98.035
trainer/Q2 Predictions Mean      -58.7592
trainer/Q2 Predictions Std        12.4767
trainer/Q2 Predictions Max       -45.8947
trainer/Q2 Predictions Min       -98.3626
trainer/Q Targets Mean           -59.2032
trainer/Q Targets Std             12.481
trainer/Q Targets Max            -46.3523
trainer/Q Targets Min           -100.179
trainer/Log Pis Mean              -0.0500828
trainer/Log Pis Std                1.36439
trainer/Log Pis Max                3.77228
trainer/Log Pis Min               -3.50671
trainer/Policy mu Mean            -0.0921067
trainer/Policy mu Std              0.843303
trainer/Policy mu Max              2.16358
trainer/Policy mu Min             -2.17449
trainer/Policy log std Mean       -0.71026
trainer/Policy log std Std         0.134627
trainer/Policy log std Max        -0.436324
trainer/Policy log std Min        -0.955503
trainer/Alpha                      0.299749
trainer/Alpha Loss                -2.46939
exploration/num steps total     4800
exploration/num paths total       48
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.48038
exploration/Rewards Std            0.658198
exploration/Rewards Max           -0.938635
exploration/Rewards Min           -5.7839
exploration/Returns Mean        -248.038
exploration/Returns Std           36.291
exploration/Returns Max         -211.747
exploration/Returns Min         -284.329
exploration/Actions Mean          -0.0178165
exploration/Actions Std            0.46964
exploration/Actions Max            0.964878
exploration/Actions Min           -0.961196
exploration/Num Paths              2
exploration/Average Returns     -248.038
evaluation/num steps total     23000
evaluation/num paths total       230
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.59663
evaluation/Rewards Std             0.918054
evaluation/Rewards Max            -1.91815
evaluation/Rewards Min           -10.897
evaluation/Returns Mean         -259.663
evaluation/Returns Std            46.2122
evaluation/Returns Max          -192.514
evaluation/Returns Min          -315.828
evaluation/Actions Mean           -0.00227383
evaluation/Actions Std             0.16465
evaluation/Actions Max             0.975208
evaluation/Actions Min            -0.972335
evaluation/Num Paths              10
evaluation/Average Returns      -259.663
time/data storing (s)              0.00131648
time/evaluation sampling (s)       0.225786
time/exploration sampling (s)      0.0623646
time/logging (s)                   0.00337798
time/saving (s)                    0.0019639
time/training (s)                  0.769104
time/epoch (s)                     1.06391
time/total (s)                    24.7511
Epoch                             22
-----------------------------  --------------
2019-04-21 01:12:08.918146 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size              5000
trainer/QF1 Loss                   0.816714
trainer/QF2 Loss                   0.791993
trainer/Policy Loss               59.1242
trainer/Q1 Predictions Mean      -60.0832
trainer/Q1 Predictions Std        11.5362
trainer/Q1 Predictions Max       -47.9201
trainer/Q1 Predictions Min      -105.364
trainer/Q2 Predictions Mean      -60.073
trainer/Q2 Predictions Std        11.4581
trainer/Q2 Predictions Max       -47.8938
trainer/Q2 Predictions Min      -104.871
trainer/Q Targets Mean           -60.5118
trainer/Q Targets Std             11.7094
trainer/Q Targets Max            -47.4237
trainer/Q Targets Min           -106.099
trainer/Log Pis Mean               0.16222
trainer/Log Pis Std                1.43197
trainer/Log Pis Max                4.24135
trainer/Log Pis Min               -4.58068
trainer/Policy mu Mean             0.0591901
trainer/Policy mu Std              0.837583
trainer/Policy mu Max              2.23211
trainer/Policy mu Min             -1.94356
trainer/Policy log std Mean       -0.738392
trainer/Policy log std Std         0.124272
trainer/Policy log std Max        -0.491767
trainer/Policy log std Min        -0.999747
trainer/Alpha                      0.283674
trainer/Alpha Loss                -2.31498
exploration/num steps total     5000
exploration/num paths total       50
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.67973
exploration/Rewards Std            1.12047
exploration/Rewards Max           -1.40394
exploration/Rewards Min          -10.8686
exploration/Returns Mean        -267.973
exploration/Returns Std           25.82
exploration/Returns Max         -242.153
exploration/Returns Min         -293.793
exploration/Actions Mean           0.00792612
exploration/Actions Std            0.487236
exploration/Actions Max            0.997986
exploration/Actions Min           -0.947445
exploration/Num Paths              2
exploration/Average Returns     -267.973
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.61213
evaluation/Rewards Std             0.626684
evaluation/Rewards Max            -1.16283
evaluation/Rewards Min           -10.2522
evaluation/Returns Mean         -261.213
evaluation/Returns Std            13.5188
evaluation/Returns Max          -243.207
evaluation/Returns Min          -295.759
evaluation/Actions Mean           -0.0107764
evaluation/Actions Std             0.157989
evaluation/Actions Max             0.968903
evaluation/Actions Min            -0.977851
evaluation/Num Paths              10
evaluation/Average Returns      -261.213
time/data storing (s)              0.00139945
time/evaluation sampling (s)       0.224262
time/exploration sampling (s)      0.0669752
time/logging (s)                   0.00336717
time/saving (s)                    0.00196622
time/training (s)                  0.764013
time/epoch (s)                     1.06198
time/total (s)                    25.8171
Epoch                             23
-----------------------------  --------------
2019-04-21 01:12:09.980962 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                  40.6016
trainer/QF2 Loss                  40.5278
trainer/Policy Loss               59.1671
trainer/Q1 Predictions Mean      -60.3512
trainer/Q1 Predictions Std        13.2151
trainer/Q1 Predictions Max       -48.715
trainer/Q1 Predictions Min      -102.755
trainer/Q2 Predictions Mean      -60.3785
trainer/Q2 Predictions Std        13.1702
trainer/Q2 Predictions Max       -48.7007
trainer/Q2 Predictions Min      -102.482
trainer/Q Targets Mean           -60.2774
trainer/Q Targets Std             14.2745
trainer/Q Targets Max             -4.08413
trainer/Q Targets Min           -102.932
trainer/Log Pis Mean              -0.0913428
trainer/Log Pis Std                1.30063
trainer/Log Pis Max                5.35925
trainer/Log Pis Min               -3.21327
trainer/Policy mu Mean            -0.0247332
trainer/Policy mu Std              0.794167
trainer/Policy mu Max              2.02448
trainer/Policy mu Min             -2.37585
trainer/Policy log std Mean       -0.752194
trainer/Policy log std Std         0.119173
trainer/Policy log std Max        -0.464292
trainer/Policy log std Min        -0.951264
trainer/Alpha                      0.268611
trainer/Alpha Loss                -2.74848
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.14134
exploration/Rewards Std            0.460482
exploration/Rewards Max           -0.979916
exploration/Rewards Min           -4.32528
exploration/Returns Mean        -214.134
exploration/Returns Std            2.74615
exploration/Returns Max         -211.388
exploration/Returns Min         -216.88
exploration/Actions Mean           0.00145786
exploration/Actions Std            0.446201
exploration/Actions Max            0.922854
exploration/Actions Min           -0.960377
exploration/Num Paths              2
exploration/Average Returns     -214.134
evaluation/num steps total     25000
evaluation/num paths total       250
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.50736
evaluation/Rewards Std             0.79558
evaluation/Rewards Max            -1.92144
evaluation/Rewards Min           -10.1663
evaluation/Returns Mean         -250.736
evaluation/Returns Std            34.4548
evaluation/Returns Max          -204.013
evaluation/Returns Min          -302.145
evaluation/Actions Mean           -0.00592024
evaluation/Actions Std             0.166607
evaluation/Actions Max             0.96303
evaluation/Actions Min            -0.984122
evaluation/Num Paths              10
evaluation/Average Returns      -250.736
time/data storing (s)              0.00143307
time/evaluation sampling (s)       0.21969
time/exploration sampling (s)      0.0647877
time/logging (s)                   0.00336117
time/saving (s)                    0.00197084
time/training (s)                  0.766471
time/epoch (s)                     1.05771
time/total (s)                    26.8789
Epoch                             24
-----------------------------  --------------
2019-04-21 01:12:11.047738 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size              5400
trainer/QF1 Loss                  63.2196
trainer/QF2 Loss                  63.9118
trainer/Policy Loss               61.7471
trainer/Q1 Predictions Mean      -62.8765
trainer/Q1 Predictions Std        13.0781
trainer/Q1 Predictions Max       -49.5385
trainer/Q1 Predictions Min      -109.175
trainer/Q2 Predictions Mean      -62.8689
trainer/Q2 Predictions Std        13.0493
trainer/Q2 Predictions Max       -49.6456
trainer/Q2 Predictions Min      -108.932
trainer/Q Targets Mean           -62.3536
trainer/Q Targets Std             15.598
trainer/Q Targets Max             -2.30383
trainer/Q Targets Min           -113.323
trainer/Log Pis Mean               0.564187
trainer/Log Pis Std                1.32034
trainer/Log Pis Max                3.42922
trainer/Log Pis Min               -3.52559
trainer/Policy mu Mean            -0.0190281
trainer/Policy mu Std              0.976023
trainer/Policy mu Max              2.13535
trainer/Policy mu Min             -2.14723
trainer/Policy log std Mean       -0.780887
trainer/Policy log std Std         0.127747
trainer/Policy log std Max        -0.490879
trainer/Policy log std Min        -1.00457
trainer/Alpha                      0.25413
trainer/Alpha Loss                -1.96656
exploration/num steps total     5400
exploration/num paths total       54
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.5397
exploration/Rewards Std            0.911734
exploration/Rewards Max           -1.0572
exploration/Rewards Min           -9.04682
exploration/Returns Mean        -253.97
exploration/Returns Std           14.364
exploration/Returns Max         -239.606
exploration/Returns Min         -268.334
exploration/Actions Mean          -0.00456303
exploration/Actions Std            0.456472
exploration/Actions Max            0.97585
exploration/Actions Min           -0.982631
exploration/Num Paths              2
exploration/Average Returns     -253.97
evaluation/num steps total     26000
evaluation/num paths total       260
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.43883
evaluation/Rewards Std             0.57994
evaluation/Rewards Max            -0.843957
evaluation/Rewards Min            -9.79806
evaluation/Returns Mean         -243.883
evaluation/Returns Std            14.8585
evaluation/Returns Max          -227.17
evaluation/Returns Min          -279.502
evaluation/Actions Mean           -0.00611885
evaluation/Actions Std             0.167036
evaluation/Actions Max             0.973174
evaluation/Actions Min            -0.971168
evaluation/Num Paths              10
evaluation/Average Returns      -243.883
time/data storing (s)              0.0012986
time/evaluation sampling (s)       0.222067
time/exploration sampling (s)      0.0634046
time/logging (s)                   0.0033617
time/saving (s)                    0.00193694
time/training (s)                  0.769619
time/epoch (s)                     1.06169
time/total (s)                    27.9447
Epoch                             25
-----------------------------  --------------
2019-04-21 01:12:12.113302 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size              5600
trainer/QF1 Loss                   1.41089
trainer/QF2 Loss                   1.3466
trainer/Policy Loss               60.9923
trainer/Q1 Predictions Mean      -62.1069
trainer/Q1 Predictions Std        12.4634
trainer/Q1 Predictions Max       -50.9064
trainer/Q1 Predictions Min      -101.097
trainer/Q2 Predictions Mean      -62.1347
trainer/Q2 Predictions Std        12.4639
trainer/Q2 Predictions Max       -50.8815
trainer/Q2 Predictions Min      -100.518
trainer/Q Targets Mean           -63.0805
trainer/Q Targets Std             12.5756
trainer/Q Targets Max            -50.9422
trainer/Q Targets Min           -100.98
trainer/Log Pis Mean               0.12082
trainer/Log Pis Std                1.58872
trainer/Log Pis Max                5.38037
trainer/Log Pis Min               -5.32104
trainer/Policy mu Mean            -0.020902
trainer/Policy mu Std              0.831863
trainer/Policy mu Max              2.15865
trainer/Policy mu Min             -2.10288
trainer/Policy log std Mean       -0.832436
trainer/Policy log std Std         0.128027
trainer/Policy log std Max        -0.523606
trainer/Policy log std Min        -1.01321
trainer/Alpha                      0.240759
trainer/Alpha Loss                -2.67537
exploration/num steps total     5600
exploration/num paths total       56
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.47336
exploration/Rewards Std            1.09416
exploration/Rewards Max           -1.39225
exploration/Rewards Min          -10.8514
exploration/Returns Mean        -247.336
exploration/Returns Std           20.121
exploration/Returns Max         -227.215
exploration/Returns Min         -267.457
exploration/Actions Mean          -0.0436455
exploration/Actions Std            0.437025
exploration/Actions Max            0.961231
exploration/Actions Min           -0.974141
exploration/Num Paths              2
exploration/Average Returns     -247.336
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.38892
evaluation/Rewards Std             0.550376
evaluation/Rewards Max            -1.31199
evaluation/Rewards Min            -9.12986
evaluation/Returns Mean         -238.892
evaluation/Returns Std            14.5426
evaluation/Returns Max          -218.695
evaluation/Returns Min          -266.038
evaluation/Actions Mean           -0.00802792
evaluation/Actions Std             0.156142
evaluation/Actions Max             0.973316
evaluation/Actions Min            -0.959267
evaluation/Num Paths              10
evaluation/Average Returns      -238.892
time/data storing (s)              0.00131613
time/evaluation sampling (s)       0.224365
time/exploration sampling (s)      0.0638423
time/logging (s)                   0.00256011
time/saving (s)                    0.00196123
time/training (s)                  0.76569
time/epoch (s)                     1.05974
time/total (s)                    29.0083
Epoch                             26
-----------------------------  --------------
2019-04-21 01:12:13.174654 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size              5800
trainer/QF1 Loss                   0.94011
trainer/QF2 Loss                   0.875136
trainer/Policy Loss               63.6378
trainer/Q1 Predictions Mean      -64.4636
trainer/Q1 Predictions Std        12.9761
trainer/Q1 Predictions Max       -52.3172
trainer/Q1 Predictions Min      -121.241
trainer/Q2 Predictions Mean      -64.4363
trainer/Q2 Predictions Std        12.9657
trainer/Q2 Predictions Max       -52.1956
trainer/Q2 Predictions Min      -120.765
trainer/Q Targets Mean           -65.0526
trainer/Q Targets Std             12.9753
trainer/Q Targets Max            -52.4953
trainer/Q Targets Min           -117.874
trainer/Log Pis Mean               0.210485
trainer/Log Pis Std                1.33821
trainer/Log Pis Max                4.09235
trainer/Log Pis Min               -3.08539
trainer/Policy mu Mean             0.0454972
trainer/Policy mu Std              0.833145
trainer/Policy mu Max              2.28837
trainer/Policy mu Min             -2.26074
trainer/Policy log std Mean       -0.824482
trainer/Policy log std Std         0.130204
trainer/Policy log std Max        -0.457844
trainer/Policy log std Min        -1.02409
trainer/Alpha                      0.228081
trainer/Alpha Loss                -2.64451
exploration/num steps total     5800
exploration/num paths total       58
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.07207
exploration/Rewards Std            0.958703
exploration/Rewards Max           -0.929118
exploration/Rewards Min           -8.94725
exploration/Returns Mean        -207.207
exploration/Returns Std            6.65498
exploration/Returns Max         -200.552
exploration/Returns Min         -213.862
exploration/Actions Mean          -0.0235621
exploration/Actions Std            0.440529
exploration/Actions Max            0.971177
exploration/Actions Min           -0.991269
exploration/Num Paths              2
exploration/Average Returns     -207.207
evaluation/num steps total     28000
evaluation/num paths total       280
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.34071
evaluation/Rewards Std             0.823914
evaluation/Rewards Max            -1.07835
evaluation/Rewards Min            -9.4526
evaluation/Returns Mean         -234.071
evaluation/Returns Std            29.206
evaluation/Returns Max          -184.47
evaluation/Returns Min          -269.477
evaluation/Actions Mean           -0.00520902
evaluation/Actions Std             0.180539
evaluation/Actions Max             0.975031
evaluation/Actions Min            -0.982706
evaluation/Num Paths              10
evaluation/Average Returns      -234.071
time/data storing (s)              0.00129098
time/evaluation sampling (s)       0.217104
time/exploration sampling (s)      0.0637242
time/logging (s)                   0.00336264
time/saving (s)                    0.00195909
time/training (s)                  0.770729
time/epoch (s)                     1.05817
time/total (s)                    30.0698
Epoch                             27
-----------------------------  --------------
2019-04-21 01:12:14.218523 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size              6000
trainer/QF1 Loss                   1.04703
trainer/QF2 Loss                   1.10503
trainer/Policy Loss               62.6756
trainer/Q1 Predictions Mean      -63.731
trainer/Q1 Predictions Std        12.224
trainer/Q1 Predictions Max       -52.9141
trainer/Q1 Predictions Min      -120.782
trainer/Q2 Predictions Mean      -63.7135
trainer/Q2 Predictions Std        12.1811
trainer/Q2 Predictions Max       -52.9798
trainer/Q2 Predictions Min      -121.037
trainer/Q Targets Mean           -64.3776
trainer/Q Targets Std             12.37
trainer/Q Targets Max            -53.1658
trainer/Q Targets Min           -123.248
trainer/Log Pis Mean               0.0392514
trainer/Log Pis Std                1.5
trainer/Log Pis Max                4.37662
trainer/Log Pis Min               -5.24048
trainer/Policy mu Mean             0.148405
trainer/Policy mu Std              0.826214
trainer/Policy mu Max              2.25767
trainer/Policy mu Min             -1.85175
trainer/Policy log std Mean       -0.836243
trainer/Policy log std Std         0.145196
trainer/Policy log std Max        -0.462496
trainer/Policy log std Min        -1.03299
trainer/Alpha                      0.216403
trainer/Alpha Loss                -3.00062
exploration/num steps total     6000
exploration/num paths total       60
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.27737
exploration/Rewards Std            0.723859
exploration/Rewards Max           -1.31117
exploration/Rewards Min           -7.57452
exploration/Returns Mean        -227.737
exploration/Returns Std            9.66299
exploration/Returns Max         -218.074
exploration/Returns Min         -237.4
exploration/Actions Mean          -0.0202877
exploration/Actions Std            0.422668
exploration/Actions Max            0.913529
exploration/Actions Min           -0.98042
exploration/Num Paths              2
exploration/Average Returns     -227.737
evaluation/num steps total     29000
evaluation/num paths total       290
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.31135
evaluation/Rewards Std             0.799746
evaluation/Rewards Max            -2.11485
evaluation/Rewards Min           -10.0988
evaluation/Returns Mean         -231.135
evaluation/Returns Std            12.3463
evaluation/Returns Max          -215.76
evaluation/Returns Min          -258.303
evaluation/Actions Mean           -0.00669413
evaluation/Actions Std             0.171575
evaluation/Actions Max             0.97973
evaluation/Actions Min            -0.979844
evaluation/Num Paths              10
evaluation/Average Returns      -231.135
time/data storing (s)              0.00119674
time/evaluation sampling (s)       0.22001
time/exploration sampling (s)      0.0631727
time/logging (s)                   0.00335682
time/saving (s)                    0.00195788
time/training (s)                  0.748988
time/epoch (s)                     1.03868
time/total (s)                    31.1126
Epoch                             28
-----------------------------  --------------
2019-04-21 01:12:15.251781 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                  79.7831
trainer/QF2 Loss                  79.4369
trainer/Policy Loss               64.0358
trainer/Q1 Predictions Mean      -64.6626
trainer/Q1 Predictions Std        12.2648
trainer/Q1 Predictions Max       -53.3482
trainer/Q1 Predictions Min      -102.333
trainer/Q2 Predictions Mean      -64.6395
trainer/Q2 Predictions Std        12.2205
trainer/Q2 Predictions Max       -53.3103
trainer/Q2 Predictions Min      -102.859
trainer/Q Targets Mean           -64.2069
trainer/Q Targets Std             14.7641
trainer/Q Targets Max             -1.82859
trainer/Q Targets Min           -101.738
trainer/Log Pis Mean               0.43926
trainer/Log Pis Std                1.56117
trainer/Log Pis Max                5.86419
trainer/Log Pis Min               -3.40316
trainer/Policy mu Mean            -0.175275
trainer/Policy mu Std              0.888433
trainer/Policy mu Max              2.23395
trainer/Policy mu Min             -2.41323
trainer/Policy log std Mean       -0.897183
trainer/Policy log std Std         0.148481
trainer/Policy log std Max        -0.525726
trainer/Policy log std Min        -1.12772
trainer/Alpha                      0.204877
trainer/Alpha Loss                -2.47389
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.33329
exploration/Rewards Std            1.11439
exploration/Rewards Max           -1.011
exploration/Rewards Min           -9.73887
exploration/Returns Mean        -233.329
exploration/Returns Std           57.1414
exploration/Returns Max         -176.188
exploration/Returns Min         -290.471
exploration/Actions Mean          -0.00117396
exploration/Actions Std            0.410438
exploration/Actions Max            0.990564
exploration/Actions Min           -0.873507
exploration/Num Paths              2
exploration/Average Returns     -233.329
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.13675
evaluation/Rewards Std             0.727881
evaluation/Rewards Max            -0.602074
evaluation/Rewards Min           -10.5674
evaluation/Returns Mean         -213.675
evaluation/Returns Std            35.062
evaluation/Returns Max          -173.857
evaluation/Returns Min          -259.416
evaluation/Actions Mean           -0.0152877
evaluation/Actions Std             0.155478
evaluation/Actions Max             0.917113
evaluation/Actions Min            -0.99051
evaluation/Num Paths              10
evaluation/Average Returns      -213.675
time/data storing (s)              0.00122996
time/evaluation sampling (s)       0.220508
time/exploration sampling (s)      0.0646549
time/logging (s)                   0.00334699
time/saving (s)                    0.00195585
time/training (s)                  0.73647
time/epoch (s)                     1.02817
time/total (s)                    32.1448
Epoch                             29
-----------------------------  --------------
2019-04-21 01:12:16.312347 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size              6400
trainer/QF1 Loss                 131.486
trainer/QF2 Loss                 130.764
trainer/Policy Loss               65.8341
trainer/Q1 Predictions Mean      -66.5653
trainer/Q1 Predictions Std        12.3508
trainer/Q1 Predictions Max       -54.9904
trainer/Q1 Predictions Min      -110.264
trainer/Q2 Predictions Mean      -66.5947
trainer/Q2 Predictions Std        12.3354
trainer/Q2 Predictions Max       -54.9169
trainer/Q2 Predictions Min      -109.884
trainer/Q Targets Mean           -65.4792
trainer/Q Targets Std             16.6817
trainer/Q Targets Max             -1.29316
trainer/Q Targets Min           -109.889
trainer/Log Pis Mean               0.447753
trainer/Log Pis Std                1.39483
trainer/Log Pis Max                3.85055
trainer/Log Pis Min               -2.28165
trainer/Policy mu Mean             0.0190644
trainer/Policy mu Std              0.864066
trainer/Policy mu Max              2.25891
trainer/Policy mu Min             -2.39014
trainer/Policy log std Mean       -0.871277
trainer/Policy log std Std         0.161758
trainer/Policy log std Max        -0.494318
trainer/Policy log std Min        -1.09051
trainer/Alpha                      0.193913
trainer/Alpha Loss                -2.54581
exploration/num steps total     6400
exploration/num paths total       64
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.19424
exploration/Rewards Std            0.670722
exploration/Rewards Max           -1.23544
exploration/Rewards Min           -6.43579
exploration/Returns Mean        -219.424
exploration/Returns Std           18.3274
exploration/Returns Max         -201.097
exploration/Returns Min         -237.752
exploration/Actions Mean          -0.0219042
exploration/Actions Std            0.412121
exploration/Actions Max            0.952889
exploration/Actions Min           -0.977994
exploration/Num Paths              2
exploration/Average Returns     -219.424
evaluation/num steps total     31000
evaluation/num paths total       310
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.05395
evaluation/Rewards Std             0.748268
evaluation/Rewards Max            -0.405357
evaluation/Rewards Min           -10.5924
evaluation/Returns Mean         -205.395
evaluation/Returns Std            20.8895
evaluation/Returns Max          -180.253
evaluation/Returns Min          -245.645
evaluation/Actions Mean           -0.0216847
evaluation/Actions Std             0.174535
evaluation/Actions Max             0.97905
evaluation/Actions Min            -0.984226
evaluation/Num Paths              10
evaluation/Average Returns      -205.395
time/data storing (s)              0.00119769
time/evaluation sampling (s)       0.22557
time/exploration sampling (s)      0.0658188
time/logging (s)                   0.00337527
time/saving (s)                    0.00193841
time/training (s)                  0.757748
time/epoch (s)                     1.05565
time/total (s)                    33.2043
Epoch                             30
-----------------------------  --------------
2019-04-21 01:12:17.379425 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size              6600
trainer/QF1 Loss                  51.9756
trainer/QF2 Loss                  51.7197
trainer/Policy Loss               67.1652
trainer/Q1 Predictions Mean      -67.7946
trainer/Q1 Predictions Std        12.4215
trainer/Q1 Predictions Max       -55.6295
trainer/Q1 Predictions Min      -113.815
trainer/Q2 Predictions Mean      -67.7892
trainer/Q2 Predictions Std        12.4374
trainer/Q2 Predictions Max       -55.5801
trainer/Q2 Predictions Min      -114.158
trainer/Q Targets Mean           -67.656
trainer/Q Targets Std             13.8239
trainer/Q Targets Max             -2.9829
trainer/Q Targets Min           -110.817
trainer/Log Pis Mean               0.632151
trainer/Log Pis Std                1.2827
trainer/Log Pis Max                4.55671
trainer/Log Pis Min               -3.79434
trainer/Policy mu Mean             0.0464054
trainer/Policy mu Std              0.882509
trainer/Policy mu Max              2.29442
trainer/Policy mu Min             -2.41594
trainer/Policy log std Mean       -0.971664
trainer/Policy log std Std         0.139922
trainer/Policy log std Max        -0.554346
trainer/Policy log std Min        -1.20204
trainer/Alpha                      0.183534
trainer/Alpha Loss                -2.31863
exploration/num steps total     6600
exploration/num paths total       66
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.20457
exploration/Rewards Std            0.391565
exploration/Rewards Max           -1.34055
exploration/Rewards Min           -4.51522
exploration/Returns Mean        -220.457
exploration/Returns Std            3.3167
exploration/Returns Max         -217.14
exploration/Returns Min         -223.774
exploration/Actions Mean          -0.0120957
exploration/Actions Std            0.393551
exploration/Actions Max            0.903272
exploration/Actions Min           -0.910783
exploration/Num Paths              2
exploration/Average Returns     -220.457
evaluation/num steps total     32000
evaluation/num paths total       320
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.22872
evaluation/Rewards Std             0.769014
evaluation/Rewards Max            -0.251304
evaluation/Rewards Min           -11.3594
evaluation/Returns Mean         -222.872
evaluation/Returns Std            14.1767
evaluation/Returns Max          -205.718
evaluation/Returns Min          -252.119
evaluation/Actions Mean           -0.0114311
evaluation/Actions Std             0.172257
evaluation/Actions Max             0.975736
evaluation/Actions Min            -0.983871
evaluation/Num Paths              10
evaluation/Average Returns      -222.872
time/data storing (s)              0.00127942
time/evaluation sampling (s)       0.22863
time/exploration sampling (s)      0.0650403
time/logging (s)                   0.00337897
time/saving (s)                    0.00161246
time/training (s)                  0.762152
time/epoch (s)                     1.06209
time/total (s)                    34.2703
Epoch                             31
-----------------------------  --------------
2019-04-21 01:12:18.423869 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 32 finished
-----------------------------  ---------------
replay_buffer/size              6800
trainer/QF1 Loss                  83.8468
trainer/QF2 Loss                  84.7886
trainer/Policy Loss               66.6594
trainer/Q1 Predictions Mean      -67.7071
trainer/Q1 Predictions Std        11.9697
trainer/Q1 Predictions Max       -57.076
trainer/Q1 Predictions Min      -120.956
trainer/Q2 Predictions Mean      -67.6834
trainer/Q2 Predictions Std        11.9455
trainer/Q2 Predictions Max       -57.1526
trainer/Q2 Predictions Min      -120.102
trainer/Q Targets Mean           -67.135
trainer/Q Targets Std             14.8638
trainer/Q Targets Max             -2.46569
trainer/Q Targets Min           -117.402
trainer/Log Pis Mean               0.169934
trainer/Log Pis Std                1.34357
trainer/Log Pis Max                5.49003
trainer/Log Pis Min               -3.5483
trainer/Policy mu Mean             0.061912
trainer/Policy mu Std              0.830386
trainer/Policy mu Max              2.25101
trainer/Policy mu Min             -2.41671
trainer/Policy log std Mean       -0.922882
trainer/Policy log std Std         0.152231
trainer/Policy log std Max        -0.442077
trainer/Policy log std Min        -1.16117
trainer/Alpha                      0.174066
trainer/Alpha Loss                -3.19905
exploration/num steps total     6800
exploration/num paths total       68
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.84094
exploration/Rewards Std            0.517704
exploration/Rewards Max           -0.630575
exploration/Rewards Min           -5.30906
exploration/Returns Mean        -184.094
exploration/Returns Std           12.9528
exploration/Returns Max         -171.141
exploration/Returns Min         -197.046
exploration/Actions Mean          -0.0230713
exploration/Actions Std            0.39603
exploration/Actions Max            0.820512
exploration/Actions Min           -0.946724
exploration/Num Paths              2
exploration/Average Returns     -184.094
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.89061
evaluation/Rewards Std             0.758359
evaluation/Rewards Max            -1.20298
evaluation/Rewards Min            -9.99116
evaluation/Returns Mean         -189.061
evaluation/Returns Std            12.4745
evaluation/Returns Max          -172.447
evaluation/Returns Min          -219.719
evaluation/Actions Mean            0.000634967
evaluation/Actions Std             0.162295
evaluation/Actions Max             0.9864
evaluation/Actions Min            -0.991171
evaluation/Num Paths              10
evaluation/Average Returns      -189.061
time/data storing (s)              0.00130251
time/evaluation sampling (s)       0.225505
time/exploration sampling (s)      0.0645423
time/logging (s)                   0.0025122
time/saving (s)                    0.00155798
time/training (s)                  0.742532
time/epoch (s)                     1.03795
time/total (s)                    35.3124
Epoch                             32
-----------------------------  ---------------
2019-04-21 01:12:19.474189 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size              7000
trainer/QF1 Loss                   0.662059
trainer/QF2 Loss                   0.733269
trainer/Policy Loss               68.2187
trainer/Q1 Predictions Mean      -68.9872
trainer/Q1 Predictions Std        12.5649
trainer/Q1 Predictions Max       -58.6167
trainer/Q1 Predictions Min      -115.938
trainer/Q2 Predictions Mean      -68.9941
trainer/Q2 Predictions Std        12.6204
trainer/Q2 Predictions Max       -58.623
trainer/Q2 Predictions Min      -116.615
trainer/Q Targets Mean           -69.3302
trainer/Q Targets Std             12.8249
trainer/Q Targets Max            -57.8087
trainer/Q Targets Min           -116.783
trainer/Log Pis Mean               0.443135
trainer/Log Pis Std                1.59081
trainer/Log Pis Max                3.79352
trainer/Log Pis Min               -7.84244
trainer/Policy mu Mean            -0.0807252
trainer/Policy mu Std              0.840339
trainer/Policy mu Max              2.51388
trainer/Policy mu Min             -2.60518
trainer/Policy log std Mean       -1.02379
trainer/Policy log std Std         0.160472
trainer/Policy log std Max        -0.62626
trainer/Policy log std Min        -1.27716
trainer/Alpha                      0.164984
trainer/Alpha Loss                -2.80492
exploration/num steps total     7000
exploration/num paths total       70
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.27952
exploration/Rewards Std            0.960218
exploration/Rewards Max           -1.13374
exploration/Rewards Min           -9.56796
exploration/Returns Mean        -227.952
exploration/Returns Std           16.1391
exploration/Returns Max         -211.813
exploration/Returns Min         -244.091
exploration/Actions Mean           0.0194402
exploration/Actions Std            0.370039
exploration/Actions Max            0.99761
exploration/Actions Min           -0.936132
exploration/Num Paths              2
exploration/Average Returns     -227.952
evaluation/num steps total     34000
evaluation/num paths total       340
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.27596
evaluation/Rewards Std             0.900528
evaluation/Rewards Max            -1.95619
evaluation/Rewards Min           -10.9679
evaluation/Returns Mean         -227.596
evaluation/Returns Std            14.0492
evaluation/Returns Max          -207.893
evaluation/Returns Min          -252.351
evaluation/Actions Mean            0.0120431
evaluation/Actions Std             0.188633
evaluation/Actions Max             0.990745
evaluation/Actions Min            -0.978762
evaluation/Num Paths              10
evaluation/Average Returns      -227.596
time/data storing (s)              0.001232
time/evaluation sampling (s)       0.221704
time/exploration sampling (s)      0.0629675
time/logging (s)                   0.00334673
time/saving (s)                    0.00194836
time/training (s)                  0.755433
time/epoch (s)                     1.04663
time/total (s)                    36.3628
Epoch                             33
-----------------------------  --------------
2019-04-21 01:12:20.527770 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                 174.288
trainer/QF2 Loss                 174.15
trainer/Policy Loss               69.7772
trainer/Q1 Predictions Mean      -70.4697
trainer/Q1 Predictions Std        12.9434
trainer/Q1 Predictions Max       -58.6334
trainer/Q1 Predictions Min      -130.288
trainer/Q2 Predictions Mean      -70.5242
trainer/Q2 Predictions Std        12.9358
trainer/Q2 Predictions Max       -58.6259
trainer/Q2 Predictions Min      -130.278
trainer/Q Targets Mean           -69.7369
trainer/Q Targets Std             14.7267
trainer/Q Targets Max             -1.8662
trainer/Q Targets Min           -123.208
trainer/Log Pis Mean               0.399853
trainer/Log Pis Std                1.53582
trainer/Log Pis Max                4.70551
trainer/Log Pis Min               -3.55143
trainer/Policy mu Mean             0.0884961
trainer/Policy mu Std              0.88286
trainer/Policy mu Max              2.50733
trainer/Policy mu Min             -2.39179
trainer/Policy log std Mean       -0.965596
trainer/Policy log std Std         0.182439
trainer/Policy log std Max        -0.530578
trainer/Policy log std Min        -1.23904
trainer/Alpha                      0.156488
trainer/Alpha Loss                -2.96748
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.96233
exploration/Rewards Std            1.06035
exploration/Rewards Max           -0.983892
exploration/Rewards Min           -8.94866
exploration/Returns Mean        -196.233
exploration/Returns Std           20.0747
exploration/Returns Max         -176.158
exploration/Returns Min         -216.308
exploration/Actions Mean          -0.0138433
exploration/Actions Std            0.409007
exploration/Actions Max            0.99572
exploration/Actions Min           -0.988764
exploration/Num Paths              2
exploration/Average Returns     -196.233
evaluation/num steps total     35000
evaluation/num paths total       350
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.75339
evaluation/Rewards Std             0.528565
evaluation/Rewards Max            -1.18375
evaluation/Rewards Min            -8.28205
evaluation/Returns Mean         -175.339
evaluation/Returns Std            17.8125
evaluation/Returns Max          -157.367
evaluation/Returns Min          -211.98
evaluation/Actions Mean            0.00111465
evaluation/Actions Std             0.145109
evaluation/Actions Max             0.978626
evaluation/Actions Min            -0.97938
evaluation/Num Paths              10
evaluation/Average Returns      -175.339
time/data storing (s)              0.00120888
time/evaluation sampling (s)       0.221282
time/exploration sampling (s)      0.0622239
time/logging (s)                   0.00334073
time/saving (s)                    0.00195457
time/training (s)                  0.75811
time/epoch (s)                     1.04812
time/total (s)                    37.4153
Epoch                             34
-----------------------------  --------------
2019-04-21 01:12:21.575324 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size              7400
trainer/QF1 Loss                   2.73435
trainer/QF2 Loss                   2.59662
trainer/Policy Loss               65.7816
trainer/Q1 Predictions Mean      -66.2353
trainer/Q1 Predictions Std        11.4924
trainer/Q1 Predictions Max       -58.8812
trainer/Q1 Predictions Min      -129.865
trainer/Q2 Predictions Mean      -66.2583
trainer/Q2 Predictions Std        11.5175
trainer/Q2 Predictions Max       -58.8758
trainer/Q2 Predictions Min      -129.365
trainer/Q Targets Mean           -67.6737
trainer/Q Targets Std             11.6403
trainer/Q Targets Max            -59.4259
trainer/Q Targets Min           -127.449
trainer/Log Pis Mean               0.358481
trainer/Log Pis Std                1.3554
trainer/Log Pis Max                4.13008
trainer/Log Pis Min               -3.93331
trainer/Policy mu Mean             0.0641816
trainer/Policy mu Std              0.836515
trainer/Policy mu Max              2.64091
trainer/Policy mu Min             -2.50456
trainer/Policy log std Mean       -0.991814
trainer/Policy log std Std         0.173964
trainer/Policy log std Max        -0.548934
trainer/Policy log std Min        -1.3082
trainer/Alpha                      0.148543
trainer/Alpha Loss                -3.12975
exploration/num steps total     7400
exploration/num paths total       74
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.90453
exploration/Rewards Std            0.403312
exploration/Rewards Max           -0.43159
exploration/Rewards Min           -4.47277
exploration/Returns Mean        -190.453
exploration/Returns Std            4.03307
exploration/Returns Max         -186.42
exploration/Returns Min         -194.486
exploration/Actions Mean          -0.00558964
exploration/Actions Std            0.382583
exploration/Actions Max            0.903081
exploration/Actions Min           -0.988814
exploration/Num Paths              2
exploration/Average Returns     -190.453
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.92011
evaluation/Rewards Std             1.14813
evaluation/Rewards Max            -0.516868
evaluation/Rewards Min           -11.0906
evaluation/Returns Mean         -192.011
evaluation/Returns Std            22.8647
evaluation/Returns Max          -155.127
evaluation/Returns Min          -225.704
evaluation/Actions Mean            0.00474962
evaluation/Actions Std             0.204199
evaluation/Actions Max             0.98817
evaluation/Actions Min            -0.990027
evaluation/Num Paths              10
evaluation/Average Returns      -192.011
time/data storing (s)              0.00137805
time/evaluation sampling (s)       0.22342
time/exploration sampling (s)      0.0632266
time/logging (s)                   0.00339595
time/saving (s)                    0.00209682
time/training (s)                  0.748469
time/epoch (s)                     1.04199
time/total (s)                    38.4617
Epoch                             35
-----------------------------  --------------
2019-04-21 01:12:22.638709 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size              7600
trainer/QF1 Loss                  94.6511
trainer/QF2 Loss                  94.8234
trainer/Policy Loss               71.6431
trainer/Q1 Predictions Mean      -72.2278
trainer/Q1 Predictions Std        11.687
trainer/Q1 Predictions Max       -60.4271
trainer/Q1 Predictions Min      -116.736
trainer/Q2 Predictions Mean      -72.2716
trainer/Q2 Predictions Std        11.7199
trainer/Q2 Predictions Max       -60.4158
trainer/Q2 Predictions Min      -117.162
trainer/Q Targets Mean           -71.6289
trainer/Q Targets Std             15.283
trainer/Q Targets Max             -2.22069
trainer/Q Targets Min           -115.102
trainer/Log Pis Mean               0.756828
trainer/Log Pis Std                1.51135
trainer/Log Pis Max                5.7718
trainer/Log Pis Min               -3.46874
trainer/Policy mu Mean            -0.0423179
trainer/Policy mu Std              0.948741
trainer/Policy mu Max              2.25782
trainer/Policy mu Min             -2.66012
trainer/Policy log std Mean       -1.00124
trainer/Policy log std Std         0.223102
trainer/Policy log std Max        -0.582941
trainer/Policy log std Min        -1.33385
trainer/Alpha                      0.140845
trainer/Alpha Loss                -2.43642
exploration/num steps total     7600
exploration/num paths total       76
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.6344
exploration/Rewards Std            0.508282
exploration/Rewards Max           -0.764605
exploration/Rewards Min           -5.20183
exploration/Returns Mean        -163.44
exploration/Returns Std            5.38524
exploration/Returns Max         -158.054
exploration/Returns Min         -168.825
exploration/Actions Mean           0.0101542
exploration/Actions Std            0.337564
exploration/Actions Max            0.975884
exploration/Actions Min           -0.939088
exploration/Num Paths              2
exploration/Average Returns     -163.44
evaluation/num steps total     37000
evaluation/num paths total       370
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.77657
evaluation/Rewards Std             0.765133
evaluation/Rewards Max            -0.631658
evaluation/Rewards Min            -9.5414
evaluation/Returns Mean         -177.657
evaluation/Returns Std            25.7064
evaluation/Returns Max          -131.818
evaluation/Returns Min          -209.919
evaluation/Actions Mean            0.0174447
evaluation/Actions Std             0.153386
evaluation/Actions Max             0.987545
evaluation/Actions Min            -0.943441
evaluation/Num Paths              10
evaluation/Average Returns      -177.657
time/data storing (s)              0.00124579
time/evaluation sampling (s)       0.221439
time/exploration sampling (s)      0.0623237
time/logging (s)                   0.00338468
time/saving (s)                    0.00198231
time/training (s)                  0.767126
time/epoch (s)                     1.0575
time/total (s)                    39.5239
Epoch                             36
-----------------------------  --------------
2019-04-21 01:12:23.704095 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size              7800
trainer/QF1 Loss                   0.755175
trainer/QF2 Loss                   0.80122
trainer/Policy Loss               70.6818
trainer/Q1 Predictions Mean      -71.2644
trainer/Q1 Predictions Std        13.5539
trainer/Q1 Predictions Max       -60.8712
trainer/Q1 Predictions Min      -120.298
trainer/Q2 Predictions Mean      -71.2488
trainer/Q2 Predictions Std        13.5571
trainer/Q2 Predictions Max       -60.8079
trainer/Q2 Predictions Min      -120.573
trainer/Q Targets Mean           -71.7422
trainer/Q Targets Std             13.5755
trainer/Q Targets Max            -60.9064
trainer/Q Targets Min           -121.826
trainer/Log Pis Mean               0.685881
trainer/Log Pis Std                1.27193
trainer/Log Pis Max                5.32961
trainer/Log Pis Min               -2.21721
trainer/Policy mu Mean            -0.0589199
trainer/Policy mu Std              0.942859
trainer/Policy mu Max              2.45971
trainer/Policy mu Min             -2.77202
trainer/Policy log std Mean       -1.06658
trainer/Policy log std Std         0.226983
trainer/Policy log std Max        -0.566061
trainer/Policy log std Min        -1.71212
trainer/Alpha                      0.133808
trainer/Alpha Loss                -2.64283
exploration/num steps total     7800
exploration/num paths total       78
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.64779
exploration/Rewards Std            1.26628
exploration/Rewards Max           -0.333036
exploration/Rewards Min          -10.4454
exploration/Returns Mean        -164.779
exploration/Returns Std           17.6513
exploration/Returns Max         -147.127
exploration/Returns Min         -182.43
exploration/Actions Mean           0.0363423
exploration/Actions Std            0.368282
exploration/Actions Max            0.984688
exploration/Actions Min           -0.930808
exploration/Num Paths              2
exploration/Average Returns     -164.779
evaluation/num steps total     38000
evaluation/num paths total       380
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.49115
evaluation/Rewards Std             0.709162
evaluation/Rewards Max            -0.939279
evaluation/Rewards Min            -9.1847
evaluation/Returns Mean         -149.115
evaluation/Returns Std            12.2486
evaluation/Returns Max          -135.757
evaluation/Returns Min          -177.478
evaluation/Actions Mean           -0.0154181
evaluation/Actions Std             0.166659
evaluation/Actions Max             0.987399
evaluation/Actions Min            -0.97775
evaluation/Num Paths              10
evaluation/Average Returns      -149.115
time/data storing (s)              0.00119384
time/evaluation sampling (s)       0.218947
time/exploration sampling (s)      0.0629317
time/logging (s)                   0.00336605
time/saving (s)                    0.0019888
time/training (s)                  0.771415
time/epoch (s)                     1.05984
time/total (s)                    40.5881
Epoch                             37
-----------------------------  --------------
2019-04-21 01:12:24.772376 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size              8000
trainer/QF1 Loss                   2.32696
trainer/QF2 Loss                   2.32984
trainer/Policy Loss               73.3556
trainer/Q1 Predictions Mean      -73.5437
trainer/Q1 Predictions Std        14.8436
trainer/Q1 Predictions Max       -61.4644
trainer/Q1 Predictions Min      -133.792
trainer/Q2 Predictions Mean      -73.5508
trainer/Q2 Predictions Std        14.7872
trainer/Q2 Predictions Max       -61.4957
trainer/Q2 Predictions Min      -134.359
trainer/Q Targets Mean           -74.6695
trainer/Q Targets Std             15.086
trainer/Q Targets Max            -61.9031
trainer/Q Targets Min           -134.068
trainer/Log Pis Mean               1.02906
trainer/Log Pis Std                1.43651
trainer/Log Pis Max                6.59059
trainer/Log Pis Min               -2.43781
trainer/Policy mu Mean             0.157132
trainer/Policy mu Std              0.957396
trainer/Policy mu Max              2.56288
trainer/Policy mu Min             -2.58967
trainer/Policy log std Mean       -1.1369
trainer/Policy log std Std         0.255073
trainer/Policy log std Max        -0.541211
trainer/Policy log std Min        -1.54491
trainer/Alpha                      0.127211
trainer/Alpha Loss                -2.00178
exploration/num steps total     8000
exploration/num paths total       80
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.80906
exploration/Rewards Std            0.285212
exploration/Rewards Max           -0.921591
exploration/Rewards Min           -3.29196
exploration/Returns Mean        -180.906
exploration/Returns Std            5.38087
exploration/Returns Max         -175.525
exploration/Returns Min         -186.286
exploration/Actions Mean           0.00826903
exploration/Actions Std            0.285557
exploration/Actions Max            0.978457
exploration/Actions Min           -0.721044
exploration/Num Paths              2
exploration/Average Returns     -180.906
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.74005
evaluation/Rewards Std             0.782736
evaluation/Rewards Max            -0.858592
evaluation/Rewards Min           -10.4498
evaluation/Returns Mean         -174.005
evaluation/Returns Std            27.4538
evaluation/Returns Max          -134.115
evaluation/Returns Min          -220.283
evaluation/Actions Mean           -0.00376964
evaluation/Actions Std             0.159447
evaluation/Actions Max             0.987456
evaluation/Actions Min            -0.9892
evaluation/Num Paths              10
evaluation/Average Returns      -174.005
time/data storing (s)              0.0013197
time/evaluation sampling (s)       0.225659
time/exploration sampling (s)      0.0662134
time/logging (s)                   0.00335501
time/saving (s)                    0.00195653
time/training (s)                  0.76413
time/epoch (s)                     1.06263
time/total (s)                    41.6552
Epoch                             38
-----------------------------  --------------
2019-04-21 01:12:25.826924 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                  75.2366
trainer/QF2 Loss                  74.9916
trainer/Policy Loss               73.986
trainer/Q1 Predictions Mean      -74.4302
trainer/Q1 Predictions Std        11.511
trainer/Q1 Predictions Max       -62.8491
trainer/Q1 Predictions Min      -120.272
trainer/Q2 Predictions Mean      -74.4161
trainer/Q2 Predictions Std        11.5351
trainer/Q2 Predictions Max       -62.8797
trainer/Q2 Predictions Min      -120.266
trainer/Q Targets Mean           -73.3884
trainer/Q Targets Std             15.3542
trainer/Q Targets Max             -2.29644
trainer/Q Targets Min           -122.417
trainer/Log Pis Mean               0.85373
trainer/Log Pis Std                1.26062
trainer/Log Pis Max                4.46868
trainer/Log Pis Min               -2.66508
trainer/Policy mu Mean             0.0489131
trainer/Policy mu Std              0.931994
trainer/Policy mu Max              2.74634
trainer/Policy mu Min             -2.59855
trainer/Policy log std Mean       -1.16396
trainer/Policy log std Std         0.258738
trainer/Policy log std Max        -0.573676
trainer/Policy log std Min        -1.63096
trainer/Alpha                      0.121203
trainer/Alpha Loss                -2.41869
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.61518
exploration/Rewards Std            0.811215
exploration/Rewards Max           -0.802983
exploration/Rewards Min           -7.68999
exploration/Returns Mean        -161.518
exploration/Returns Std            4.56928
exploration/Returns Max         -156.949
exploration/Returns Min         -166.087
exploration/Actions Mean          -0.0282418
exploration/Actions Std            0.358911
exploration/Actions Max            0.812093
exploration/Actions Min           -0.995648
exploration/Num Paths              2
exploration/Average Returns     -161.518
evaluation/num steps total     40000
evaluation/num paths total       400
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.60463
evaluation/Rewards Std             0.75172
evaluation/Rewards Max            -0.865326
evaluation/Rewards Min           -11.1478
evaluation/Returns Mean         -160.463
evaluation/Returns Std            15.8349
evaluation/Returns Max          -140.6
evaluation/Returns Min          -187.924
evaluation/Actions Mean           -0.00319786
evaluation/Actions Std             0.155806
evaluation/Actions Max             0.984054
evaluation/Actions Min            -0.994707
evaluation/Num Paths              10
evaluation/Average Returns      -160.463
time/data storing (s)              0.00123355
time/evaluation sampling (s)       0.212437
time/exploration sampling (s)      0.0638252
time/logging (s)                   0.00298025
time/saving (s)                    0.00197185
time/training (s)                  0.766282
time/epoch (s)                     1.04873
time/total (s)                    42.7081
Epoch                             39
-----------------------------  --------------
2019-04-21 01:12:26.892761 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size              8400
trainer/QF1 Loss                  76.5319
trainer/QF2 Loss                  76.5061
trainer/Policy Loss               72.7994
trainer/Q1 Predictions Mean      -72.8654
trainer/Q1 Predictions Std        13.4462
trainer/Q1 Predictions Max       -63.1191
trainer/Q1 Predictions Min      -135.985
trainer/Q2 Predictions Mean      -72.9098
trainer/Q2 Predictions Std        13.4485
trainer/Q2 Predictions Max       -63.1598
trainer/Q2 Predictions Min      -136.479
trainer/Q Targets Mean           -72.1169
trainer/Q Targets Std             16.7401
trainer/Q Targets Max             -2.14368
trainer/Q Targets Min           -135.588
trainer/Log Pis Mean               1.02378
trainer/Log Pis Std                1.47551
trainer/Log Pis Max                5.06042
trainer/Log Pis Min               -3.61793
trainer/Policy mu Mean            -0.129989
trainer/Policy mu Std              0.929351
trainer/Policy mu Max              2.64944
trainer/Policy mu Min             -2.57702
trainer/Policy log std Mean       -1.17359
trainer/Policy log std Std         0.302893
trainer/Policy log std Max        -0.557813
trainer/Policy log std Min        -1.70747
trainer/Alpha                      0.115626
trainer/Alpha Loss                -2.1059
exploration/num steps total     8400
exploration/num paths total       84
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.4995
exploration/Rewards Std            1.15205
exploration/Rewards Max           -0.637051
exploration/Rewards Min           -9.14699
exploration/Returns Mean        -149.95
exploration/Returns Std            6.92627
exploration/Returns Max         -143.024
exploration/Returns Min         -156.876
exploration/Actions Mean          -0.0359833
exploration/Actions Std            0.366106
exploration/Actions Max            0.842241
exploration/Actions Min           -0.996527
exploration/Num Paths              2
exploration/Average Returns     -149.95
evaluation/num steps total     41000
evaluation/num paths total       410
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.67254
evaluation/Rewards Std             0.672097
evaluation/Rewards Max            -0.478199
evaluation/Rewards Min            -7.75451
evaluation/Returns Mean         -167.254
evaluation/Returns Std            45.2365
evaluation/Returns Max          -124.18
evaluation/Returns Min          -229.752
evaluation/Actions Mean           -0.00453995
evaluation/Actions Std             0.155305
evaluation/Actions Max             0.983052
evaluation/Actions Min            -0.985127
evaluation/Num Paths              10
evaluation/Average Returns      -167.254
time/data storing (s)              0.00142995
time/evaluation sampling (s)       0.225285
time/exploration sampling (s)      0.0643276
time/logging (s)                   0.00257306
time/saving (s)                    0.00156632
time/training (s)                  0.76498
time/epoch (s)                     1.06016
time/total (s)                    43.7724
Epoch                             40
-----------------------------  --------------
2019-04-21 01:12:27.963819 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 41 finished
-----------------------------  ---------------
replay_buffer/size              8600
trainer/QF1 Loss                   1.12738
trainer/QF2 Loss                   1.23036
trainer/Policy Loss               73.1291
trainer/Q1 Predictions Mean      -73.4533
trainer/Q1 Predictions Std        13.2069
trainer/Q1 Predictions Max       -63.7433
trainer/Q1 Predictions Min      -133.297
trainer/Q2 Predictions Mean      -73.4825
trainer/Q2 Predictions Std        13.1836
trainer/Q2 Predictions Max       -63.7299
trainer/Q2 Predictions Min      -133.43
trainer/Q Targets Mean           -74.02
trainer/Q Targets Std             13.1996
trainer/Q Targets Max            -63.567
trainer/Q Targets Min           -136.617
trainer/Log Pis Mean               0.717206
trainer/Log Pis Std                1.46994
trainer/Log Pis Max                5.37359
trainer/Log Pis Min               -2.73088
trainer/Policy mu Mean             0.0604873
trainer/Policy mu Std              0.877608
trainer/Policy mu Max              2.81243
trainer/Policy mu Min             -2.58509
trainer/Policy log std Mean       -1.2357
trainer/Policy log std Std         0.283575
trainer/Policy log std Max        -0.463952
trainer/Policy log std Min        -1.7842
trainer/Alpha                      0.110419
trainer/Alpha Loss                -2.82629
exploration/num steps total     8600
exploration/num paths total       86
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.12663
exploration/Rewards Std            0.461792
exploration/Rewards Max           -1.38427
exploration/Rewards Min           -6.02522
exploration/Returns Mean        -212.663
exploration/Returns Std            6.82223
exploration/Returns Max         -205.841
exploration/Returns Min         -219.485
exploration/Actions Mean           0.000173225
exploration/Actions Std            0.316511
exploration/Actions Max            0.997834
exploration/Actions Min           -0.91187
exploration/Num Paths              2
exploration/Average Returns     -212.663
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.12046
evaluation/Rewards Std             0.829468
evaluation/Rewards Max            -1.84389
evaluation/Rewards Min           -10.6398
evaluation/Returns Mean         -212.046
evaluation/Returns Std            14.5887
evaluation/Returns Max          -191.649
evaluation/Returns Min          -241.757
evaluation/Actions Mean           -0.00798222
evaluation/Actions Std             0.193554
evaluation/Actions Max             0.991798
evaluation/Actions Min            -0.989912
evaluation/Num Paths              10
evaluation/Average Returns      -212.046
time/data storing (s)              0.00127811
time/evaluation sampling (s)       0.228524
time/exploration sampling (s)      0.0643777
time/logging (s)                   0.00342616
time/saving (s)                    0.00195506
time/training (s)                  0.767226
time/epoch (s)                     1.06679
time/total (s)                    44.8431
Epoch                             41
-----------------------------  ---------------
2019-04-21 01:12:29.021030 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size              8800
trainer/QF1 Loss                   0.601041
trainer/QF2 Loss                   0.568995
trainer/Policy Loss               75.3081
trainer/Q1 Predictions Mean      -75.2343
trainer/Q1 Predictions Std        11.6998
trainer/Q1 Predictions Max       -64.6558
trainer/Q1 Predictions Min      -114.875
trainer/Q2 Predictions Mean      -75.2159
trainer/Q2 Predictions Std        11.6657
trainer/Q2 Predictions Max       -64.6591
trainer/Q2 Predictions Min      -115.044
trainer/Q Targets Mean           -75.574
trainer/Q Targets Std             11.7463
trainer/Q Targets Max            -64.2673
trainer/Q Targets Min           -115.618
trainer/Log Pis Mean               0.916333
trainer/Log Pis Std                1.3723
trainer/Log Pis Max                5.01062
trainer/Log Pis Min               -2.7611
trainer/Policy mu Mean             0.0318441
trainer/Policy mu Std              0.945767
trainer/Policy mu Max              2.76364
trainer/Policy mu Min             -2.78082
trainer/Policy log std Mean       -1.19535
trainer/Policy log std Std         0.311399
trainer/Policy log std Max        -0.431877
trainer/Policy log std Min        -1.81958
trainer/Alpha                      0.105086
trainer/Alpha Loss                -2.44121
exploration/num steps total     8800
exploration/num paths total       88
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.57544
exploration/Rewards Std            0.571618
exploration/Rewards Max           -0.763628
exploration/Rewards Min           -6.35271
exploration/Returns Mean        -157.544
exploration/Returns Std           18.072
exploration/Returns Max         -139.472
exploration/Returns Min         -175.616
exploration/Actions Mean           0.00771111
exploration/Actions Std            0.29241
exploration/Actions Max            0.986658
exploration/Actions Min           -0.75217
exploration/Num Paths              2
exploration/Average Returns     -157.544
evaluation/num steps total     43000
evaluation/num paths total       430
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.65276
evaluation/Rewards Std             0.722001
evaluation/Rewards Max            -0.336077
evaluation/Rewards Min            -9.45005
evaluation/Returns Mean         -165.276
evaluation/Returns Std            10.4934
evaluation/Returns Max          -149.339
evaluation/Returns Min          -189.645
evaluation/Actions Mean            0.00035943
evaluation/Actions Std             0.181668
evaluation/Actions Max             0.987666
evaluation/Actions Min            -0.991133
evaluation/Num Paths              10
evaluation/Average Returns      -165.276
time/data storing (s)              0.00155133
time/evaluation sampling (s)       0.222312
time/exploration sampling (s)      0.0620092
time/logging (s)                   0.00252823
time/saving (s)                    0.0019727
time/training (s)                  0.760665
time/epoch (s)                     1.05104
time/total (s)                    45.8981
Epoch                             42
-----------------------------  --------------
2019-04-21 01:12:30.079132 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size              9000
trainer/QF1 Loss                 187.225
trainer/QF2 Loss                 188.328
trainer/Policy Loss               75.6596
trainer/Q1 Predictions Mean      -75.9622
trainer/Q1 Predictions Std        12.8571
trainer/Q1 Predictions Max       -65.0368
trainer/Q1 Predictions Min      -134.181
trainer/Q2 Predictions Mean      -75.9683
trainer/Q2 Predictions Std        12.7997
trainer/Q2 Predictions Max       -64.9813
trainer/Q2 Predictions Min      -133.863
trainer/Q Targets Mean           -74.0196
trainer/Q Targets Std             17.9238
trainer/Q Targets Max             -2.9829
trainer/Q Targets Min           -134.883
trainer/Log Pis Mean               1.07263
trainer/Log Pis Std                1.67361
trainer/Log Pis Max                6.37113
trainer/Log Pis Min               -3.10736
trainer/Policy mu Mean            -0.0784468
trainer/Policy mu Std              1.03972
trainer/Policy mu Max              2.81622
trainer/Policy mu Min             -2.91334
trainer/Policy log std Mean       -1.17795
trainer/Policy log std Std         0.292958
trainer/Policy log std Max        -0.418099
trainer/Policy log std Min        -1.77651
trainer/Alpha                      0.100443
trainer/Alpha Loss                -2.13106
exploration/num steps total     9000
exploration/num paths total       90
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.8641
exploration/Rewards Std            1.07548
exploration/Rewards Max           -0.831658
exploration/Rewards Min           -9.93744
exploration/Returns Mean        -186.41
exploration/Returns Std           16.7541
exploration/Returns Max         -169.656
exploration/Returns Min         -203.164
exploration/Actions Mean           0.0256788
exploration/Actions Std            0.298
exploration/Actions Max            0.998765
exploration/Actions Min           -0.761747
exploration/Num Paths              2
exploration/Average Returns     -186.41
evaluation/num steps total     44000
evaluation/num paths total       440
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.4914
evaluation/Rewards Std             1.00301
evaluation/Rewards Max            -0.69845
evaluation/Rewards Min            -9.67538
evaluation/Returns Mean         -149.14
evaluation/Returns Std            22.5274
evaluation/Returns Max          -117.769
evaluation/Returns Min          -196.111
evaluation/Actions Mean           -0.0205244
evaluation/Actions Std             0.187832
evaluation/Actions Max             0.985936
evaluation/Actions Min            -0.995743
evaluation/Num Paths              10
evaluation/Average Returns      -149.14
time/data storing (s)              0.00136096
time/evaluation sampling (s)       0.222997
time/exploration sampling (s)      0.0646644
time/logging (s)                   0.00343127
time/saving (s)                    0.00210143
time/training (s)                  0.760108
time/epoch (s)                     1.05466
time/total (s)                    46.9562
Epoch                             43
-----------------------------  --------------
2019-04-21 01:12:31.137303 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                  41.3655
trainer/QF2 Loss                  41.3491
trainer/Policy Loss               74.4197
trainer/Q1 Predictions Mean      -74.2456
trainer/Q1 Predictions Std        11.1359
trainer/Q1 Predictions Max       -64.5482
trainer/Q1 Predictions Min      -121.999
trainer/Q2 Predictions Mean      -74.2951
trainer/Q2 Predictions Std        11.2304
trainer/Q2 Predictions Max       -64.5832
trainer/Q2 Predictions Min      -122.476
trainer/Q Targets Mean           -74.5614
trainer/Q Targets Std             13.4627
trainer/Q Targets Max             -2.22673
trainer/Q Targets Min           -126.323
trainer/Log Pis Mean               1.13918
trainer/Log Pis Std                1.30843
trainer/Log Pis Max                5.22809
trainer/Log Pis Min               -4.3203
trainer/Policy mu Mean            -0.0164505
trainer/Policy mu Std              0.935884
trainer/Policy mu Max              2.91716
trainer/Policy mu Min             -2.9816
trainer/Policy log std Mean       -1.28025
trainer/Policy log std Std         0.288282
trainer/Policy log std Max        -0.407743
trainer/Policy log std Min        -1.82893
trainer/Alpha                      0.0956275
trainer/Alpha Loss                -2.02042
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.26751
exploration/Rewards Std            0.339953
exploration/Rewards Max           -0.300976
exploration/Rewards Min           -2.11909
exploration/Returns Mean        -126.751
exploration/Returns Std           18.0951
exploration/Returns Max         -108.656
exploration/Returns Min         -144.846
exploration/Actions Mean          -0.00605664
exploration/Actions Std            0.288868
exploration/Actions Max            0.723661
exploration/Actions Min           -0.96419
exploration/Num Paths              2
exploration/Average Returns     -126.751
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.44072
evaluation/Rewards Std             0.963314
evaluation/Rewards Max            -0.936543
evaluation/Rewards Min            -9.64477
evaluation/Returns Mean         -144.072
evaluation/Returns Std            19.243
evaluation/Returns Max          -117.989
evaluation/Returns Min          -175.784
evaluation/Actions Mean            0.00242655
evaluation/Actions Std             0.191486
evaluation/Actions Max             0.99156
evaluation/Actions Min            -0.995667
evaluation/Num Paths              10
evaluation/Average Returns      -144.072
time/data storing (s)              0.00122107
time/evaluation sampling (s)       0.223696
time/exploration sampling (s)      0.0653102
time/logging (s)                   0.00302117
time/saving (s)                    0.00196975
time/training (s)                  0.757162
time/epoch (s)                     1.05238
time/total (s)                    48.0127
Epoch                             44
-----------------------------  --------------
2019-04-21 01:12:32.200085 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 45 finished
-----------------------------  ---------------
replay_buffer/size              9400
trainer/QF1 Loss                  63.7495
trainer/QF2 Loss                  63.7526
trainer/Policy Loss               76.8804
trainer/Q1 Predictions Mean      -76.4942
trainer/Q1 Predictions Std        12.6899
trainer/Q1 Predictions Max       -65.6564
trainer/Q1 Predictions Min      -131.325
trainer/Q2 Predictions Mean      -76.414
trainer/Q2 Predictions Std        12.6721
trainer/Q2 Predictions Max       -65.7706
trainer/Q2 Predictions Min      -130.807
trainer/Q Targets Mean           -75.9678
trainer/Q Targets Std             14.9788
trainer/Q Targets Max             -1.94741
trainer/Q Targets Min           -134.222
trainer/Log Pis Mean               1.33409
trainer/Log Pis Std                1.42997
trainer/Log Pis Max                5.08814
trainer/Log Pis Min               -1.7977
trainer/Policy mu Mean            -0.11735
trainer/Policy mu Std              1.0116
trainer/Policy mu Max              2.77771
trainer/Policy mu Min             -2.8934
trainer/Policy log std Mean       -1.32693
trainer/Policy log std Std         0.375435
trainer/Policy log std Max        -0.343487
trainer/Policy log std Min        -1.9038
trainer/Alpha                      0.091903
trainer/Alpha Loss                -1.58942
exploration/num steps total     9400
exploration/num paths total       94
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.30151
exploration/Rewards Std            0.590016
exploration/Rewards Max           -0.59059
exploration/Rewards Min           -6.14636
exploration/Returns Mean        -130.151
exploration/Returns Std            3.60132
exploration/Returns Max         -126.549
exploration/Returns Min         -133.752
exploration/Actions Mean          -0.00883015
exploration/Actions Std            0.321893
exploration/Actions Max            0.980045
exploration/Actions Min           -0.995034
exploration/Num Paths              2
exploration/Average Returns     -130.151
evaluation/num steps total     46000
evaluation/num paths total       460
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.64311
evaluation/Rewards Std             0.806301
evaluation/Rewards Max            -1.13875
evaluation/Rewards Min            -9.15908
evaluation/Returns Mean         -164.311
evaluation/Returns Std            34.8841
evaluation/Returns Max          -117.936
evaluation/Returns Min          -212.284
evaluation/Actions Mean           -0.000201666
evaluation/Actions Std             0.174509
evaluation/Actions Max             0.99083
evaluation/Actions Min            -0.99492
evaluation/Num Paths              10
evaluation/Average Returns      -164.311
time/data storing (s)              0.00124178
time/evaluation sampling (s)       0.231808
time/exploration sampling (s)      0.0641379
time/logging (s)                   0.0025283
time/saving (s)                    0.00204667
time/training (s)                  0.755178
time/epoch (s)                     1.05694
time/total (s)                    49.0736
Epoch                             45
-----------------------------  ---------------
2019-04-21 01:12:33.275815 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size              9600
trainer/QF1 Loss                   1.17929
trainer/QF2 Loss                   1.17081
trainer/Policy Loss               77.3308
trainer/Q1 Predictions Mean      -76.9542
trainer/Q1 Predictions Std        12.2715
trainer/Q1 Predictions Max       -65.4176
trainer/Q1 Predictions Min      -129.239
trainer/Q2 Predictions Mean      -76.9697
trainer/Q2 Predictions Std        12.3343
trainer/Q2 Predictions Max       -65.3183
trainer/Q2 Predictions Min      -129.24
trainer/Q Targets Mean           -77.7847
trainer/Q Targets Std             12.554
trainer/Q Targets Max            -65.65
trainer/Q Targets Min           -133.596
trainer/Log Pis Mean               1.36213
trainer/Log Pis Std                1.63532
trainer/Log Pis Max                5.69148
trainer/Log Pis Min               -4.01627
trainer/Policy mu Mean             0.111979
trainer/Policy mu Std              1.02224
trainer/Policy mu Max              3.08973
trainer/Policy mu Min             -2.94945
trainer/Policy log std Mean       -1.35554
trainer/Policy log std Std         0.351921
trainer/Policy log std Max        -0.455276
trainer/Policy log std Min        -2.0017
trainer/Alpha                      0.0883548
trainer/Alpha Loss                -1.54761
exploration/num steps total     9600
exploration/num paths total       96
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.67441
exploration/Rewards Std            1.24817
exploration/Rewards Max           -0.642863
exploration/Rewards Min           -9.82258
exploration/Returns Mean        -167.441
exploration/Returns Std           10.9249
exploration/Returns Max         -156.516
exploration/Returns Min         -178.366
exploration/Actions Mean          -0.049434
exploration/Actions Std            0.34484
exploration/Actions Max            0.725635
exploration/Actions Min           -0.998015
exploration/Num Paths              2
exploration/Average Returns     -167.441
evaluation/num steps total     47000
evaluation/num paths total       470
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.636
evaluation/Rewards Std             0.8235
evaluation/Rewards Max            -0.436496
evaluation/Rewards Min           -10.385
evaluation/Returns Mean         -163.6
evaluation/Returns Std            23.5133
evaluation/Returns Max          -133.887
evaluation/Returns Min          -202.983
evaluation/Actions Mean           -0.00916813
evaluation/Actions Std             0.171929
evaluation/Actions Max             0.992064
evaluation/Actions Min            -0.994655
evaluation/Num Paths              10
evaluation/Average Returns      -163.6
time/data storing (s)              0.00122495
time/evaluation sampling (s)       0.222703
time/exploration sampling (s)      0.0637689
time/logging (s)                   0.00253084
time/saving (s)                    0.00195059
time/training (s)                  0.778954
time/epoch (s)                     1.07113
time/total (s)                    50.1481
Epoch                             46
-----------------------------  --------------
2019-04-21 01:12:34.331372 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size              9800
trainer/QF1 Loss                  41.9394
trainer/QF2 Loss                  42.0888
trainer/Policy Loss               74.264
trainer/Q1 Predictions Mean      -73.6952
trainer/Q1 Predictions Std         8.849
trainer/Q1 Predictions Max       -65.0127
trainer/Q1 Predictions Min      -105.833
trainer/Q2 Predictions Mean      -73.6797
trainer/Q2 Predictions Std         8.8102
trainer/Q2 Predictions Max       -65.0848
trainer/Q2 Predictions Min      -106.178
trainer/Q Targets Mean           -74.0625
trainer/Q Targets Std             11.4867
trainer/Q Targets Max             -1.51225
trainer/Q Targets Min           -106.998
trainer/Log Pis Mean               1.16654
trainer/Log Pis Std                1.39526
trainer/Log Pis Max                4.41882
trainer/Log Pis Min               -4.0616
trainer/Policy mu Mean            -0.0561885
trainer/Policy mu Std              0.869709
trainer/Policy mu Max              2.6507
trainer/Policy mu Min             -2.83672
trainer/Policy log std Mean       -1.38965
trainer/Policy log std Std         0.335806
trainer/Policy log std Max        -0.319948
trainer/Policy log std Min        -1.86742
trainer/Alpha                      0.0851777
trainer/Alpha Loss                -2.05266
exploration/num steps total     9800
exploration/num paths total       98
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.09497
exploration/Rewards Std            1.29649
exploration/Rewards Max           -1.10803
exploration/Rewards Min          -10.234
exploration/Returns Mean        -209.497
exploration/Returns Std            0.330604
exploration/Returns Max         -209.166
exploration/Returns Min         -209.828
exploration/Actions Mean           0.0352537
exploration/Actions Std            0.318858
exploration/Actions Max            0.99955
exploration/Actions Min           -0.86113
exploration/Num Paths              2
exploration/Average Returns     -209.497
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.53934
evaluation/Rewards Std             0.902781
evaluation/Rewards Max            -1.12814
evaluation/Rewards Min           -10.4534
evaluation/Returns Mean         -153.934
evaluation/Returns Std            31.4099
evaluation/Returns Max          -120.836
evaluation/Returns Min          -217.895
evaluation/Actions Mean           -0.00520636
evaluation/Actions Std             0.180205
evaluation/Actions Max             0.993931
evaluation/Actions Min            -0.997419
evaluation/Num Paths              10
evaluation/Average Returns      -153.934
time/data storing (s)              0.00132992
time/evaluation sampling (s)       0.221815
time/exploration sampling (s)      0.0668554
time/logging (s)                   0.00337791
time/saving (s)                    0.00158363
time/training (s)                  0.756922
time/epoch (s)                     1.05188
time/total (s)                    51.2037
Epoch                             47
-----------------------------  --------------
2019-04-21 01:12:35.387583 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             10000
trainer/QF1 Loss                   1.17786
trainer/QF2 Loss                   1.14039
trainer/Policy Loss               75.5127
trainer/Q1 Predictions Mean      -74.9193
trainer/Q1 Predictions Std        10.816
trainer/Q1 Predictions Max       -66.0022
trainer/Q1 Predictions Min      -116.905
trainer/Q2 Predictions Mean      -74.9531
trainer/Q2 Predictions Std        10.8525
trainer/Q2 Predictions Max       -66.0313
trainer/Q2 Predictions Min      -116.231
trainer/Q Targets Mean           -75.6971
trainer/Q Targets Std             11.2846
trainer/Q Targets Max            -65.9866
trainer/Q Targets Min           -119.563
trainer/Log Pis Mean               1.6951
trainer/Log Pis Std                1.2939
trainer/Log Pis Max                5.34258
trainer/Log Pis Min               -2.32209
trainer/Policy mu Mean            -0.0788544
trainer/Policy mu Std              0.970024
trainer/Policy mu Max              2.62548
trainer/Policy mu Min             -2.91587
trainer/Policy log std Mean       -1.39733
trainer/Policy log std Std         0.354754
trainer/Policy log std Max        -0.511136
trainer/Policy log std Min        -2.00113
trainer/Alpha                      0.082105
trainer/Alpha Loss                -0.762141
exploration/num steps total    10000
exploration/num paths total      100
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.2954
exploration/Rewards Std            1.04626
exploration/Rewards Max           -0.617439
exploration/Rewards Min           -9.2763
exploration/Returns Mean        -129.54
exploration/Returns Std           19.8026
exploration/Returns Max         -109.737
exploration/Returns Min         -149.342
exploration/Actions Mean          -0.0225843
exploration/Actions Std            0.285098
exploration/Actions Max            0.575816
exploration/Actions Min           -0.998043
exploration/Num Paths              2
exploration/Average Returns     -129.54
evaluation/num steps total     49000
evaluation/num paths total       490
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.55514
evaluation/Rewards Std             1.11048
evaluation/Rewards Max            -0.885442
evaluation/Rewards Min           -10.63
evaluation/Returns Mean         -155.514
evaluation/Returns Std            29.7803
evaluation/Returns Max          -114.277
evaluation/Returns Min          -207.978
evaluation/Actions Mean           -0.00992571
evaluation/Actions Std             0.199037
evaluation/Actions Max             0.995888
evaluation/Actions Min            -0.997479
evaluation/Num Paths              10
evaluation/Average Returns      -155.514
time/data storing (s)              0.00133222
time/evaluation sampling (s)       0.218146
time/exploration sampling (s)      0.0637933
time/logging (s)                   0.00334858
time/saving (s)                    0.00194557
time/training (s)                  0.762248
time/epoch (s)                     1.05081
time/total (s)                    52.2585
Epoch                             48
-----------------------------  --------------
2019-04-21 01:12:36.446399 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   0.559312
trainer/QF2 Loss                   0.526288
trainer/Policy Loss               78.0099
trainer/Q1 Predictions Mean      -77.2069
trainer/Q1 Predictions Std        13.5171
trainer/Q1 Predictions Max       -66.0191
trainer/Q1 Predictions Min      -139.107
trainer/Q2 Predictions Mean      -77.2974
trainer/Q2 Predictions Std        13.6022
trainer/Q2 Predictions Max       -66.0423
trainer/Q2 Predictions Min      -139.753
trainer/Q Targets Mean           -77.7743
trainer/Q Targets Std             13.6013
trainer/Q Targets Max            -66.067
trainer/Q Targets Min           -139.576
trainer/Log Pis Mean               1.80807
trainer/Log Pis Std                1.45803
trainer/Log Pis Max                6.1479
trainer/Log Pis Min               -1.38944
trainer/Policy mu Mean            -0.0844774
trainer/Policy mu Std              1.05177
trainer/Policy mu Max              2.93769
trainer/Policy mu Min             -3.15896
trainer/Policy log std Mean       -1.48315
trainer/Policy log std Std         0.369145
trainer/Policy log std Max        -0.563731
trainer/Policy log std Min        -2.15
trainer/Alpha                      0.079481
trainer/Alpha Loss                -0.485972
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.18886
exploration/Rewards Std            0.638131
exploration/Rewards Max           -0.582412
exploration/Rewards Min           -7.09465
exploration/Returns Mean        -118.886
exploration/Returns Std           10.4928
exploration/Returns Max         -108.393
exploration/Returns Min         -129.379
exploration/Actions Mean           0.00641639
exploration/Actions Std            0.29671
exploration/Actions Max            0.987399
exploration/Actions Min           -0.992249
exploration/Num Paths              2
exploration/Average Returns     -118.886
evaluation/num steps total     50000
evaluation/num paths total       500
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.48687
evaluation/Rewards Std             0.919301
evaluation/Rewards Max            -0.713553
evaluation/Rewards Min           -10.1512
evaluation/Returns Mean         -148.687
evaluation/Returns Std            24.0801
evaluation/Returns Max          -115.674
evaluation/Returns Min          -190.494
evaluation/Actions Mean            0.0115919
evaluation/Actions Std             0.189635
evaluation/Actions Max             0.994157
evaluation/Actions Min            -0.995374
evaluation/Num Paths              10
evaluation/Average Returns      -148.687
time/data storing (s)              0.00123931
time/evaluation sampling (s)       0.214525
time/exploration sampling (s)      0.0646095
time/logging (s)                   0.00253892
time/saving (s)                    0.00196119
time/training (s)                  0.767721
time/epoch (s)                     1.0526
time/total (s)                    53.3151
Epoch                             49
-----------------------------  --------------
2019-04-21 01:12:37.507850 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 50 finished
-----------------------------  ---------------
replay_buffer/size             10400
trainer/QF1 Loss                  65.7277
trainer/QF2 Loss                  65.409
trainer/Policy Loss               76.8259
trainer/Q1 Predictions Mean      -76.3212
trainer/Q1 Predictions Std        10.8664
trainer/Q1 Predictions Max       -65.6931
trainer/Q1 Predictions Min      -115.087
trainer/Q2 Predictions Mean      -76.3374
trainer/Q2 Predictions Std        10.8604
trainer/Q2 Predictions Max       -65.6994
trainer/Q2 Predictions Min      -115.817
trainer/Q Targets Mean           -76.3759
trainer/Q Targets Std             13.0746
trainer/Q Targets Max             -2.9829
trainer/Q Targets Min           -117.252
trainer/Log Pis Mean               1.51109
trainer/Log Pis Std                1.55059
trainer/Log Pis Max                6.08007
trainer/Log Pis Min               -4.45754
trainer/Policy mu Mean            -0.038522
trainer/Policy mu Std              1.03122
trainer/Policy mu Max              2.75282
trainer/Policy mu Min             -3.02223
trainer/Policy log std Mean       -1.45212
trainer/Policy log std Std         0.390442
trainer/Policy log std Max        -0.351084
trainer/Policy log std Min        -2.12505
trainer/Alpha                      0.0768374
trainer/Alpha Loss                -1.25449
exploration/num steps total    10400
exploration/num paths total      104
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.68113
exploration/Rewards Std            0.937866
exploration/Rewards Max           -0.8502
exploration/Rewards Min           -7.58689
exploration/Returns Mean        -168.113
exploration/Returns Std           24.0258
exploration/Returns Max         -144.087
exploration/Returns Min         -192.139
exploration/Actions Mean          -0.00723525
exploration/Actions Std            0.281218
exploration/Actions Max            0.991575
exploration/Actions Min           -0.996435
exploration/Num Paths              2
exploration/Average Returns     -168.113
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.62755
evaluation/Rewards Std             0.839661
evaluation/Rewards Max            -0.607131
evaluation/Rewards Min            -9.95873
evaluation/Returns Mean         -162.755
evaluation/Returns Std            26.274
evaluation/Returns Max          -118.073
evaluation/Returns Min          -205.23
evaluation/Actions Mean            0.000208017
evaluation/Actions Std             0.184078
evaluation/Actions Max             0.995135
evaluation/Actions Min            -0.991069
evaluation/Num Paths              10
evaluation/Average Returns      -162.755
time/data storing (s)              0.00137895
time/evaluation sampling (s)       0.217282
time/exploration sampling (s)      0.0634715
time/logging (s)                   0.00344194
time/saving (s)                    0.00196177
time/training (s)                  0.76973
time/epoch (s)                     1.05727
time/total (s)                    54.3765
Epoch                             50
-----------------------------  ---------------
2019-04-21 01:12:38.572888 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             10600
trainer/QF1 Loss                   0.41506
trainer/QF2 Loss                   0.492989
trainer/Policy Loss               77.5021
trainer/Q1 Predictions Mean      -76.7801
trainer/Q1 Predictions Std        11.955
trainer/Q1 Predictions Max       -66.3454
trainer/Q1 Predictions Min      -126.27
trainer/Q2 Predictions Mean      -76.7212
trainer/Q2 Predictions Std        11.8796
trainer/Q2 Predictions Max       -66.3981
trainer/Q2 Predictions Min      -125.648
trainer/Q Targets Mean           -77.1631
trainer/Q Targets Std             12.0935
trainer/Q Targets Max            -66.4556
trainer/Q Targets Min           -129.592
trainer/Log Pis Mean               1.85546
trainer/Log Pis Std                1.29921
trainer/Log Pis Max                5.96432
trainer/Log Pis Min               -0.982091
trainer/Policy mu Mean             0.0537669
trainer/Policy mu Std              0.933376
trainer/Policy mu Max              2.90839
trainer/Policy mu Min             -2.39103
trainer/Policy log std Mean       -1.54836
trainer/Policy log std Std         0.369696
trainer/Policy log std Max        -0.592374
trainer/Policy log std Min        -2.03505
trainer/Alpha                      0.0747341
trainer/Alpha Loss                -0.374889
exploration/num steps total    10600
exploration/num paths total      106
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.4332
exploration/Rewards Std            0.575954
exploration/Rewards Max           -0.657374
exploration/Rewards Min           -6.31675
exploration/Returns Mean        -143.32
exploration/Returns Std           32.3369
exploration/Returns Max         -110.983
exploration/Returns Min         -175.657
exploration/Actions Mean          -0.0105226
exploration/Actions Std            0.256753
exploration/Actions Max            0.986191
exploration/Actions Min           -0.949939
exploration/Num Paths              2
exploration/Average Returns     -143.32
evaluation/num steps total     52000
evaluation/num paths total       520
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.36278
evaluation/Rewards Std             0.670645
evaluation/Rewards Max            -1.02783
evaluation/Rewards Min            -8.32438
evaluation/Returns Mean         -136.278
evaluation/Returns Std            29.0619
evaluation/Returns Max          -108.583
evaluation/Returns Min          -185.454
evaluation/Actions Mean            0.00449827
evaluation/Actions Std             0.164192
evaluation/Actions Max             0.985675
evaluation/Actions Min            -0.996196
evaluation/Num Paths              10
evaluation/Average Returns      -136.278
time/data storing (s)              0.00120915
time/evaluation sampling (s)       0.22846
time/exploration sampling (s)      0.0637352
time/logging (s)                   0.00333242
time/saving (s)                    0.00194058
time/training (s)                  0.761068
time/epoch (s)                     1.05975
time/total (s)                    55.44
Epoch                             51
-----------------------------  --------------
2019-04-21 01:12:39.637142 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             10800
trainer/QF1 Loss                   0.943787
trainer/QF2 Loss                   0.752181
trainer/Policy Loss               78.7201
trainer/Q1 Predictions Mean      -78.0146
trainer/Q1 Predictions Std        13.2399
trainer/Q1 Predictions Max       -66.8508
trainer/Q1 Predictions Min      -129.308
trainer/Q2 Predictions Mean      -78.003
trainer/Q2 Predictions Std        13.1743
trainer/Q2 Predictions Max       -66.957
trainer/Q2 Predictions Min      -129.305
trainer/Q Targets Mean           -78.3331
trainer/Q Targets Std             13.3608
trainer/Q Targets Max            -66.5565
trainer/Q Targets Min           -130.838
trainer/Log Pis Mean               1.8594
trainer/Log Pis Std                1.83548
trainer/Log Pis Max                6.61561
trainer/Log Pis Min               -4.30602
trainer/Policy mu Mean            -0.065194
trainer/Policy mu Std              1.14458
trainer/Policy mu Max              3.18298
trainer/Policy mu Min             -3.02876
trainer/Policy log std Mean       -1.44147
trainer/Policy log std Std         0.491067
trainer/Policy log std Max        -0.215297
trainer/Policy log std Min        -2.24453
trainer/Alpha                      0.0730242
trainer/Alpha Loss                -0.36793
exploration/num steps total    10800
exploration/num paths total      108
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.83962
exploration/Rewards Std            0.717413
exploration/Rewards Max           -0.68266
exploration/Rewards Min           -7.77304
exploration/Returns Mean        -183.962
exploration/Returns Std            7.50353
exploration/Returns Max         -176.458
exploration/Returns Min         -191.465
exploration/Actions Mean          -0.0104714
exploration/Actions Std            0.255111
exploration/Actions Max            0.993686
exploration/Actions Min           -0.983788
exploration/Num Paths              2
exploration/Average Returns     -183.962
evaluation/num steps total     53000
evaluation/num paths total       530
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.65008
evaluation/Rewards Std             0.823868
evaluation/Rewards Max            -0.421179
evaluation/Rewards Min            -9.59213
evaluation/Returns Mean         -165.008
evaluation/Returns Std            33.4491
evaluation/Returns Max          -117.88
evaluation/Returns Min          -209.498
evaluation/Actions Mean            0.0140218
evaluation/Actions Std             0.180098
evaluation/Actions Max             0.995165
evaluation/Actions Min            -0.991348
evaluation/Num Paths              10
evaluation/Average Returns      -165.008
time/data storing (s)              0.00129135
time/evaluation sampling (s)       0.22493
time/exploration sampling (s)      0.0652446
time/logging (s)                   0.00339386
time/saving (s)                    0.00196213
time/training (s)                  0.762053
time/epoch (s)                     1.05887
time/total (s)                    56.503
Epoch                             52
-----------------------------  --------------
2019-04-21 01:12:40.701760 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             11000
trainer/QF1 Loss                 109.776
trainer/QF2 Loss                 110.029
trainer/Policy Loss               79.6766
trainer/Q1 Predictions Mean      -78.8411
trainer/Q1 Predictions Std        13.5263
trainer/Q1 Predictions Max       -66.002
trainer/Q1 Predictions Min      -138.818
trainer/Q2 Predictions Mean      -78.8348
trainer/Q2 Predictions Std        13.5047
trainer/Q2 Predictions Max       -66.0732
trainer/Q2 Predictions Min      -139.079
trainer/Q Targets Mean           -78.4291
trainer/Q Targets Std             17.4797
trainer/Q Targets Max             -1.53454
trainer/Q Targets Min           -140.218
trainer/Log Pis Mean               1.7804
trainer/Log Pis Std                1.38736
trainer/Log Pis Max                6.25801
trainer/Log Pis Min               -1.68387
trainer/Policy mu Mean            -0.0158673
trainer/Policy mu Std              0.916913
trainer/Policy mu Max              3.10177
trainer/Policy mu Min             -2.75755
trainer/Policy log std Mean       -1.61815
trainer/Policy log std Std         0.428882
trainer/Policy log std Max        -0.0651027
trainer/Policy log std Min        -2.12482
trainer/Alpha                      0.0715586
trainer/Alpha Loss                -0.579103
exploration/num steps total    11000
exploration/num paths total      110
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.97354
exploration/Rewards Std            1.03224
exploration/Rewards Max           -0.86311
exploration/Rewards Min           -9.43188
exploration/Returns Mean        -197.354
exploration/Returns Std           20.4176
exploration/Returns Max         -176.937
exploration/Returns Min         -217.772
exploration/Actions Mean          -0.0365203
exploration/Actions Std            0.272665
exploration/Actions Max            0.62888
exploration/Actions Min           -0.999412
exploration/Num Paths              2
exploration/Average Returns     -197.354
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.1229
evaluation/Rewards Std             0.658141
evaluation/Rewards Max            -0.342847
evaluation/Rewards Min            -9.44638
evaluation/Returns Mean         -212.29
evaluation/Returns Std            34.8679
evaluation/Returns Max          -142.611
evaluation/Returns Min          -248.532
evaluation/Actions Mean            0.00759209
evaluation/Actions Std             0.158308
evaluation/Actions Max             0.996164
evaluation/Actions Min            -0.972161
evaluation/Num Paths              10
evaluation/Average Returns      -212.29
time/data storing (s)              0.00122462
time/evaluation sampling (s)       0.234112
time/exploration sampling (s)      0.0664278
time/logging (s)                   0.00338898
time/saving (s)                    0.00195802
time/training (s)                  0.752102
time/epoch (s)                     1.05921
time/total (s)                    57.5664
Epoch                             53
-----------------------------  --------------
2019-04-21 01:12:41.770807 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   1.12283
trainer/QF2 Loss                   1.18951
trainer/Policy Loss               76.848
trainer/Q1 Predictions Mean      -75.7558
trainer/Q1 Predictions Std        10.3761
trainer/Q1 Predictions Max       -65.9106
trainer/Q1 Predictions Min      -113.887
trainer/Q2 Predictions Mean      -75.7647
trainer/Q2 Predictions Std        10.386
trainer/Q2 Predictions Max       -65.8903
trainer/Q2 Predictions Min      -114.627
trainer/Q Targets Mean           -76.5624
trainer/Q Targets Std             10.1471
trainer/Q Targets Max            -66.816
trainer/Q Targets Min           -113.697
trainer/Log Pis Mean               1.83435
trainer/Log Pis Std                1.41072
trainer/Log Pis Max                5.82302
trainer/Log Pis Min               -1.613
trainer/Policy mu Mean            -0.111483
trainer/Policy mu Std              1.00285
trainer/Policy mu Max              2.96617
trainer/Policy mu Min             -3.01562
trainer/Policy log std Mean       -1.59026
trainer/Policy log std Std         0.483623
trainer/Policy log std Max        -0.297345
trainer/Policy log std Min        -2.25582
trainer/Alpha                      0.0701936
trainer/Alpha Loss                -0.440024
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.67961
exploration/Rewards Std            0.67808
exploration/Rewards Max           -0.882012
exploration/Rewards Min           -6.61878
exploration/Returns Mean        -167.961
exploration/Returns Std           41.9108
exploration/Returns Max         -126.05
exploration/Returns Min         -209.872
exploration/Actions Mean           0.0035536
exploration/Actions Std            0.264623
exploration/Actions Max            0.994758
exploration/Actions Min           -0.98604
exploration/Num Paths              2
exploration/Average Returns     -167.961
evaluation/num steps total     55000
evaluation/num paths total       550
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.58414
evaluation/Rewards Std             0.786091
evaluation/Rewards Max            -1.00422
evaluation/Rewards Min           -10.4518
evaluation/Returns Mean         -158.414
evaluation/Returns Std            45.6477
evaluation/Returns Max          -118.37
evaluation/Returns Min          -231.871
evaluation/Actions Mean            0.00257923
evaluation/Actions Std             0.171598
evaluation/Actions Max             0.996123
evaluation/Actions Min            -0.985944
evaluation/Num Paths              10
evaluation/Average Returns      -158.414
time/data storing (s)              0.0012407
time/evaluation sampling (s)       0.224086
time/exploration sampling (s)      0.0645357
time/logging (s)                   0.00341434
time/saving (s)                    0.00197203
time/training (s)                  0.768209
time/epoch (s)                     1.06346
time/total (s)                    58.6337
Epoch                             54
-----------------------------  --------------
2019-04-21 01:12:42.835418 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             11400
trainer/QF1 Loss                   1.03879
trainer/QF2 Loss                   1.17771
trainer/Policy Loss               78.189
trainer/Q1 Predictions Mean      -77.3039
trainer/Q1 Predictions Std        11.88
trainer/Q1 Predictions Max       -66.5861
trainer/Q1 Predictions Min      -122.941
trainer/Q2 Predictions Mean      -77.2861
trainer/Q2 Predictions Std        11.7969
trainer/Q2 Predictions Max       -66.7167
trainer/Q2 Predictions Min      -122.909
trainer/Q Targets Mean           -78.0124
trainer/Q Targets Std             11.9543
trainer/Q Targets Max            -66.7578
trainer/Q Targets Min           -123.321
trainer/Log Pis Mean               1.68931
trainer/Log Pis Std                1.33574
trainer/Log Pis Max                7.14618
trainer/Log Pis Min               -1.13787
trainer/Policy mu Mean             0.0839563
trainer/Policy mu Std              0.973368
trainer/Policy mu Max              3.12019
trainer/Policy mu Min             -2.89836
trainer/Policy log std Mean       -1.61808
trainer/Policy log std Std         0.449453
trainer/Policy log std Max        -0.395117
trainer/Policy log std Min        -2.24349
trainer/Alpha                      0.0689691
trainer/Alpha Loss                -0.830794
exploration/num steps total    11400
exploration/num paths total      114
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.40806
exploration/Rewards Std            0.32816
exploration/Rewards Max           -0.758237
exploration/Rewards Min           -3.5935
exploration/Returns Mean        -140.806
exploration/Returns Std           20.4196
exploration/Returns Max         -120.386
exploration/Returns Min         -161.226
exploration/Actions Mean           0.00436603
exploration/Actions Std            0.210146
exploration/Actions Max            0.878625
exploration/Actions Min           -0.982343
exploration/Num Paths              2
exploration/Average Returns     -140.806
evaluation/num steps total     56000
evaluation/num paths total       560
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.5633
evaluation/Rewards Std             1.13737
evaluation/Rewards Max            -0.446587
evaluation/Rewards Min           -10.5043
evaluation/Returns Mean         -156.33
evaluation/Returns Std            29.2245
evaluation/Returns Max          -117.115
evaluation/Returns Min          -199.305
evaluation/Actions Mean           -0.0014787
evaluation/Actions Std             0.20526
evaluation/Actions Max             0.99636
evaluation/Actions Min            -0.996103
evaluation/Num Paths              10
evaluation/Average Returns      -156.33
time/data storing (s)              0.00125879
time/evaluation sampling (s)       0.220013
time/exploration sampling (s)      0.0647268
time/logging (s)                   0.00336629
time/saving (s)                    0.00154838
time/training (s)                  0.768209
time/epoch (s)                     1.05912
time/total (s)                    59.6969
Epoch                             55
-----------------------------  --------------
2019-04-21 01:12:43.896600 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             11600
trainer/QF1 Loss                 128.256
trainer/QF2 Loss                 128.859
trainer/Policy Loss               77.8045
trainer/Q1 Predictions Mean      -76.9713
trainer/Q1 Predictions Std        12.3152
trainer/Q1 Predictions Max       -65.9162
trainer/Q1 Predictions Min      -130.628
trainer/Q2 Predictions Mean      -77.0291
trainer/Q2 Predictions Std        12.3534
trainer/Q2 Predictions Max       -66.0565
trainer/Q2 Predictions Min      -130.008
trainer/Q Targets Mean           -75.8761
trainer/Q Targets Std             18.0116
trainer/Q Targets Max             -0.940922
trainer/Q Targets Min           -132.696
trainer/Log Pis Mean               1.81847
trainer/Log Pis Std                1.47548
trainer/Log Pis Max                6.19141
trainer/Log Pis Min               -3.64634
trainer/Policy mu Mean            -0.0291745
trainer/Policy mu Std              1.03436
trainer/Policy mu Max              3.07467
trainer/Policy mu Min             -3.07908
trainer/Policy log std Mean       -1.6707
trainer/Policy log std Std         0.505271
trainer/Policy log std Max        -0.228761
trainer/Policy log std Min        -2.2967
trainer/Alpha                      0.067874
trainer/Alpha Loss                -0.488338
exploration/num steps total    11600
exploration/num paths total      116
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.22057
exploration/Rewards Std            0.740473
exploration/Rewards Max           -0.769003
exploration/Rewards Min           -6.38025
exploration/Returns Mean        -122.057
exploration/Returns Std            1.07234
exploration/Returns Max         -120.985
exploration/Returns Min         -123.13
exploration/Actions Mean          -0.0108726
exploration/Actions Std            0.252003
exploration/Actions Max            0.933899
exploration/Actions Min           -0.999083
exploration/Num Paths              2
exploration/Average Returns     -122.057
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.63693
evaluation/Rewards Std             0.726896
evaluation/Rewards Max            -0.998276
evaluation/Rewards Min            -9.47742
evaluation/Returns Mean         -163.693
evaluation/Returns Std            29.2384
evaluation/Returns Max          -106.259
evaluation/Returns Min          -196.889
evaluation/Actions Mean            0.021347
evaluation/Actions Std             0.162588
evaluation/Actions Max             0.995657
evaluation/Actions Min            -0.991108
evaluation/Num Paths              10
evaluation/Average Returns      -163.693
time/data storing (s)              0.00123076
time/evaluation sampling (s)       0.218581
time/exploration sampling (s)      0.0631075
time/logging (s)                   0.00336828
time/saving (s)                    0.00197416
time/training (s)                  0.767443
time/epoch (s)                     1.0557
time/total (s)                    60.7567
Epoch                             56
-----------------------------  --------------
2019-04-21 01:12:44.938870 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             11800
trainer/QF1 Loss                  87.3021
trainer/QF2 Loss                  87.0467
trainer/Policy Loss               78.1125
trainer/Q1 Predictions Mean      -77.4262
trainer/Q1 Predictions Std        12.7551
trainer/Q1 Predictions Max       -65.969
trainer/Q1 Predictions Min      -131.424
trainer/Q2 Predictions Mean      -77.4263
trainer/Q2 Predictions Std        12.7318
trainer/Q2 Predictions Max       -66.088
trainer/Q2 Predictions Min      -131.746
trainer/Q Targets Mean           -77.0359
trainer/Q Targets Std             16.7769
trainer/Q Targets Max             -2.08764
trainer/Q Targets Min           -134.968
trainer/Log Pis Mean               1.73869
trainer/Log Pis Std                1.33765
trainer/Log Pis Max                5.1004
trainer/Log Pis Min               -3.53694
trainer/Policy mu Mean             0.123283
trainer/Policy mu Std              0.942747
trainer/Policy mu Max              2.92576
trainer/Policy mu Min             -2.09797
trainer/Policy log std Mean       -1.72263
trainer/Policy log std Std         0.498179
trainer/Policy log std Max        -0.54133
trainer/Policy log std Min        -2.32362
trainer/Alpha                      0.0675992
trainer/Alpha Loss                -0.704013
exploration/num steps total    11800
exploration/num paths total      118
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.42119
exploration/Rewards Std            0.631741
exploration/Rewards Max           -0.819826
exploration/Rewards Min           -5.56941
exploration/Returns Mean        -142.119
exploration/Returns Std           19.7527
exploration/Returns Max         -122.366
exploration/Returns Min         -161.872
exploration/Actions Mean           0.00413966
exploration/Actions Std            0.225295
exploration/Actions Max            0.988615
exploration/Actions Min           -0.999369
exploration/Num Paths              2
exploration/Average Returns     -142.119
evaluation/num steps total     58000
evaluation/num paths total       580
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.38688
evaluation/Rewards Std             0.661784
evaluation/Rewards Max            -0.426629
evaluation/Rewards Min            -8.3974
evaluation/Returns Mean         -138.688
evaluation/Returns Std            18.2741
evaluation/Returns Max          -107.884
evaluation/Returns Min          -157.356
evaluation/Actions Mean           -0.0113688
evaluation/Actions Std             0.153217
evaluation/Actions Max             0.978448
evaluation/Actions Min            -0.996623
evaluation/Num Paths              10
evaluation/Average Returns      -138.688
time/data storing (s)              0.00121629
time/evaluation sampling (s)       0.224367
time/exploration sampling (s)      0.0657965
time/logging (s)                   0.00340771
time/saving (s)                    0.00197634
time/training (s)                  0.740072
time/epoch (s)                     1.03684
time/total (s)                    61.7975
Epoch                             57
-----------------------------  --------------
2019-04-21 01:12:45.989558 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             12000
trainer/QF1 Loss                  44.5433
trainer/QF2 Loss                  44.1664
trainer/Policy Loss               78.0681
trainer/Q1 Predictions Mean      -77.0581
trainer/Q1 Predictions Std        11.9542
trainer/Q1 Predictions Max       -65.9318
trainer/Q1 Predictions Min      -129.745
trainer/Q2 Predictions Mean      -77.048
trainer/Q2 Predictions Std        11.9625
trainer/Q2 Predictions Max       -66.0187
trainer/Q2 Predictions Min      -130.076
trainer/Q Targets Mean           -77.1172
trainer/Q Targets Std             14.0956
trainer/Q Targets Max             -2.49714
trainer/Q Targets Min           -130.436
trainer/Log Pis Mean               1.8182
trainer/Log Pis Std                1.44087
trainer/Log Pis Max                5.85758
trainer/Log Pis Min               -3.21165
trainer/Policy mu Mean             0.0577801
trainer/Policy mu Std              1.02855
trainer/Policy mu Max              3.1845
trainer/Policy mu Min             -2.88972
trainer/Policy log std Mean       -1.60205
trainer/Policy log std Std         0.496337
trainer/Policy log std Max        -0.176334
trainer/Policy log std Min        -2.29764
trainer/Alpha                      0.0674581
trainer/Alpha Loss                -0.490162
exploration/num steps total    12000
exploration/num paths total      120
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.36638
exploration/Rewards Std            0.78016
exploration/Rewards Max           -0.804343
exploration/Rewards Min           -7.95986
exploration/Returns Mean        -136.638
exploration/Returns Std            8.63435
exploration/Returns Max         -128.004
exploration/Returns Min         -145.273
exploration/Actions Mean          -0.0120006
exploration/Actions Std            0.255279
exploration/Actions Max            0.940356
exploration/Actions Min           -0.993943
exploration/Num Paths              2
exploration/Average Returns     -136.638
evaluation/num steps total     59000
evaluation/num paths total       590
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.38497
evaluation/Rewards Std             0.880728
evaluation/Rewards Max            -0.94191
evaluation/Rewards Min            -9.70458
evaluation/Returns Mean         -138.497
evaluation/Returns Std            12.6339
evaluation/Returns Max          -121.068
evaluation/Returns Min          -158.186
evaluation/Actions Mean            0.0010342
evaluation/Actions Std             0.188878
evaluation/Actions Max             0.996233
evaluation/Actions Min            -0.995688
evaluation/Num Paths              10
evaluation/Average Returns      -138.497
time/data storing (s)              0.00131444
time/evaluation sampling (s)       0.22669
time/exploration sampling (s)      0.0649287
time/logging (s)                   0.00336112
time/saving (s)                    0.00195945
time/training (s)                  0.746844
time/epoch (s)                     1.0451
time/total (s)                    62.8467
Epoch                             58
-----------------------------  --------------
2019-04-21 01:12:47.070831 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   1.19335
trainer/QF2 Loss                   1.10011
trainer/Policy Loss               80.5733
trainer/Q1 Predictions Mean      -79.891
trainer/Q1 Predictions Std        15.3223
trainer/Q1 Predictions Max       -65.4138
trainer/Q1 Predictions Min      -141.086
trainer/Q2 Predictions Mean      -79.9303
trainer/Q2 Predictions Std        15.4024
trainer/Q2 Predictions Max       -65.4733
trainer/Q2 Predictions Min      -141.289
trainer/Q Targets Mean           -80.5089
trainer/Q Targets Std             15.4087
trainer/Q Targets Max            -66.2731
trainer/Q Targets Min           -142.268
trainer/Log Pis Mean               2.12186
trainer/Log Pis Std                1.26919
trainer/Log Pis Max                6.00887
trainer/Log Pis Min               -0.636987
trainer/Policy mu Mean             0.0552186
trainer/Policy mu Std              1.02779
trainer/Policy mu Max              3.05101
trainer/Policy mu Min             -2.86859
trainer/Policy log std Mean       -1.72021
trainer/Policy log std Std         0.515547
trainer/Policy log std Max        -0.177007
trainer/Policy log std Min        -2.35879
trainer/Alpha                      0.0670031
trainer/Alpha Loss                 0.329386
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.58603
exploration/Rewards Std            0.450802
exploration/Rewards Max           -0.474007
exploration/Rewards Min           -5.46038
exploration/Returns Mean        -158.603
exploration/Returns Std            0.510216
exploration/Returns Max         -158.093
exploration/Returns Min         -159.113
exploration/Actions Mean          -0.0104759
exploration/Actions Std            0.232133
exploration/Actions Max            0.979318
exploration/Actions Min           -0.97152
exploration/Num Paths              2
exploration/Average Returns     -158.603
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.54891
evaluation/Rewards Std             0.926385
evaluation/Rewards Max            -0.407602
evaluation/Rewards Min            -9.9909
evaluation/Returns Mean         -154.891
evaluation/Returns Std            17.2244
evaluation/Returns Max          -116.77
evaluation/Returns Min          -185.242
evaluation/Actions Mean           -0.00652218
evaluation/Actions Std             0.193464
evaluation/Actions Max             0.994711
evaluation/Actions Min            -0.995645
evaluation/Num Paths              10
evaluation/Average Returns      -154.891
time/data storing (s)              0.00124987
time/evaluation sampling (s)       0.220577
time/exploration sampling (s)      0.0638376
time/logging (s)                   0.00340353
time/saving (s)                    0.00663003
time/training (s)                  0.780115
time/epoch (s)                     1.07581
time/total (s)                    63.9266
Epoch                             59
-----------------------------  --------------
2019-04-21 01:12:48.118589 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             12400
trainer/QF1 Loss                   1.71727
trainer/QF2 Loss                   1.75866
trainer/Policy Loss               78.2206
trainer/Q1 Predictions Mean      -77.1895
trainer/Q1 Predictions Std        11.8725
trainer/Q1 Predictions Max       -65.4759
trainer/Q1 Predictions Min      -125.551
trainer/Q2 Predictions Mean      -77.1969
trainer/Q2 Predictions Std        11.8597
trainer/Q2 Predictions Max       -65.5706
trainer/Q2 Predictions Min      -125.152
trainer/Q Targets Mean           -78.2858
trainer/Q Targets Std             12.2793
trainer/Q Targets Max            -66.0307
trainer/Q Targets Min           -129.208
trainer/Log Pis Mean               2.17944
trainer/Log Pis Std                1.46142
trainer/Log Pis Max                6.62047
trainer/Log Pis Min               -1.18441
trainer/Policy mu Mean            -0.0737285
trainer/Policy mu Std              1.06923
trainer/Policy mu Max              2.62633
trainer/Policy mu Min             -3.12238
trainer/Policy log std Mean       -1.69429
trainer/Policy log std Std         0.533218
trainer/Policy log std Max        -0.213576
trainer/Policy log std Min        -2.36742
trainer/Alpha                      0.0672713
trainer/Alpha Loss                 0.484323
exploration/num steps total    12400
exploration/num paths total      124
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.52947
exploration/Rewards Std            1.2098
exploration/Rewards Max           -0.877079
exploration/Rewards Min          -10.6128
exploration/Returns Mean        -152.947
exploration/Returns Std           32.5648
exploration/Returns Max         -120.383
exploration/Returns Min         -185.512
exploration/Actions Mean           0.0284556
exploration/Actions Std            0.25123
exploration/Actions Max            0.998552
exploration/Actions Min           -0.9721
exploration/Num Paths              2
exploration/Average Returns     -152.947
evaluation/num steps total     61000
evaluation/num paths total       610
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.44509
evaluation/Rewards Std             0.944522
evaluation/Rewards Max            -0.421097
evaluation/Rewards Min           -10.6668
evaluation/Returns Mean         -144.509
evaluation/Returns Std            17.2659
evaluation/Returns Max          -125.297
evaluation/Returns Min          -185.67
evaluation/Actions Mean           -0.0203186
evaluation/Actions Std             0.199742
evaluation/Actions Max             0.996777
evaluation/Actions Min            -0.992649
evaluation/Num Paths              10
evaluation/Average Returns      -144.509
time/data storing (s)              0.0012628
time/evaluation sampling (s)       0.223794
time/exploration sampling (s)      0.0642297
time/logging (s)                   0.00333526
time/saving (s)                    0.00158857
time/training (s)                  0.747535
time/epoch (s)                     1.04174
time/total (s)                    64.9726
Epoch                             60
-----------------------------  --------------
2019-04-21 01:12:49.155029 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             12600
trainer/QF1 Loss                 152.366
trainer/QF2 Loss                 152.365
trainer/Policy Loss               75.2008
trainer/Q1 Predictions Mean      -74.29
trainer/Q1 Predictions Std        11.0386
trainer/Q1 Predictions Max       -65.3273
trainer/Q1 Predictions Min      -122.836
trainer/Q2 Predictions Mean      -74.2984
trainer/Q2 Predictions Std        11.0349
trainer/Q2 Predictions Max       -65.4535
trainer/Q2 Predictions Min      -122.974
trainer/Q Targets Mean           -73.3
trainer/Q Targets Std             16.834
trainer/Q Targets Max             -1.94741
trainer/Q Targets Min           -123.559
trainer/Log Pis Mean               2.06225
trainer/Log Pis Std                1.18476
trainer/Log Pis Max                4.89773
trainer/Log Pis Min               -1.9317
trainer/Policy mu Mean            -0.0301348
trainer/Policy mu Std              0.99898
trainer/Policy mu Max              2.98514
trainer/Policy mu Min             -2.66818
trainer/Policy log std Mean       -1.72205
trainer/Policy log std Std         0.526775
trainer/Policy log std Max        -0.198727
trainer/Policy log std Min        -2.44369
trainer/Alpha                      0.0673856
trainer/Alpha Loss                 0.167917
exploration/num steps total    12600
exploration/num paths total      126
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.46552
exploration/Rewards Std            0.653654
exploration/Rewards Max           -0.803685
exploration/Rewards Min           -6.44246
exploration/Returns Mean        -146.552
exploration/Returns Std           18.3084
exploration/Returns Max         -128.244
exploration/Returns Min         -164.86
exploration/Actions Mean          -0.0319272
exploration/Actions Std            0.242286
exploration/Actions Max            0.969653
exploration/Actions Min           -0.997065
exploration/Num Paths              2
exploration/Average Returns     -146.552
evaluation/num steps total     62000
evaluation/num paths total       620
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.65018
evaluation/Rewards Std             0.943825
evaluation/Rewards Max            -1.05406
evaluation/Rewards Min           -10.1461
evaluation/Returns Mean         -165.018
evaluation/Returns Std            22.903
evaluation/Returns Max          -125.332
evaluation/Returns Min          -197.549
evaluation/Actions Mean            0.00144566
evaluation/Actions Std             0.189252
evaluation/Actions Max             0.996689
evaluation/Actions Min            -0.994608
evaluation/Num Paths              10
evaluation/Average Returns      -165.018
time/data storing (s)              0.00123289
time/evaluation sampling (s)       0.22299
time/exploration sampling (s)      0.0633038
time/logging (s)                   0.0033532
time/saving (s)                    0.0019444
time/training (s)                  0.737937
time/epoch (s)                     1.03076
time/total (s)                    66.0078
Epoch                             61
-----------------------------  --------------
2019-04-21 01:12:50.225772 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             12800
trainer/QF1 Loss                  43.2544
trainer/QF2 Loss                  43.0929
trainer/Policy Loss               78.7112
trainer/Q1 Predictions Mean      -77.6597
trainer/Q1 Predictions Std         9.50791
trainer/Q1 Predictions Max       -65.801
trainer/Q1 Predictions Min      -110.232
trainer/Q2 Predictions Mean      -77.6726
trainer/Q2 Predictions Std         9.53088
trainer/Q2 Predictions Max       -65.7604
trainer/Q2 Predictions Min      -110.224
trainer/Q Targets Mean           -77.6536
trainer/Q Targets Std             12.2312
trainer/Q Targets Max             -1.75876
trainer/Q Targets Min           -110.314
trainer/Log Pis Mean               1.89273
trainer/Log Pis Std                1.33469
trainer/Log Pis Max                5.95868
trainer/Log Pis Min               -2.3179
trainer/Policy mu Mean             0.0721027
trainer/Policy mu Std              0.855397
trainer/Policy mu Max              3.00235
trainer/Policy mu Min             -2.52736
trainer/Policy log std Mean       -1.80082
trainer/Policy log std Std         0.492585
trainer/Policy log std Max        -0.447274
trainer/Policy log std Min        -2.35788
trainer/Alpha                      0.0671268
trainer/Alpha Loss                -0.28974
exploration/num steps total    12800
exploration/num paths total      128
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.65248
exploration/Rewards Std            0.335079
exploration/Rewards Max           -0.886213
exploration/Rewards Min           -3.15881
exploration/Returns Mean        -165.248
exploration/Returns Std           26.5846
exploration/Returns Max         -138.663
exploration/Returns Min         -191.833
exploration/Actions Mean           0.00067122
exploration/Actions Std            0.196726
exploration/Actions Max            0.630116
exploration/Actions Min           -0.893568
exploration/Num Paths              2
exploration/Average Returns     -165.248
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.78877
evaluation/Rewards Std             0.916698
evaluation/Rewards Max            -1.16642
evaluation/Rewards Min           -10.4617
evaluation/Returns Mean         -178.877
evaluation/Returns Std            29.1152
evaluation/Returns Max          -136.663
evaluation/Returns Min          -226.041
evaluation/Actions Mean           -0.00660074
evaluation/Actions Std             0.192724
evaluation/Actions Max             0.997899
evaluation/Actions Min            -0.986199
evaluation/Num Paths              10
evaluation/Average Returns      -178.877
time/data storing (s)              0.00146018
time/evaluation sampling (s)       0.224556
time/exploration sampling (s)      0.0642603
time/logging (s)                   0.00335748
time/saving (s)                    0.00197177
time/training (s)                  0.769258
time/epoch (s)                     1.06486
time/total (s)                    67.077
Epoch                             62
-----------------------------  --------------
2019-04-21 01:12:51.297619 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size             13000
trainer/QF1 Loss                  67.6124
trainer/QF2 Loss                  67.5316
trainer/Policy Loss               74.8487
trainer/Q1 Predictions Mean      -73.753
trainer/Q1 Predictions Std         9.44801
trainer/Q1 Predictions Max       -64.7247
trainer/Q1 Predictions Min      -111.197
trainer/Q2 Predictions Mean      -73.7467
trainer/Q2 Predictions Std         9.47081
trainer/Q2 Predictions Max       -64.7322
trainer/Q2 Predictions Min      -111.146
trainer/Q Targets Mean           -73.9049
trainer/Q Targets Std             11.7165
trainer/Q Targets Max             -2.04206
trainer/Q Targets Min           -112.918
trainer/Log Pis Mean               1.65335
trainer/Log Pis Std                1.21247
trainer/Log Pis Max                5.98012
trainer/Log Pis Min               -2.36698
trainer/Policy mu Mean            -0.0454596
trainer/Policy mu Std              0.739016
trainer/Policy mu Max              3.02518
trainer/Policy mu Min             -2.23823
trainer/Policy log std Mean       -1.82302
trainer/Policy log std Std         0.435393
trainer/Policy log std Max        -0.431943
trainer/Policy log std Min        -2.51045
trainer/Alpha                      0.0661594
trainer/Alpha Loss                -0.941347
exploration/num steps total    13000
exploration/num paths total      130
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.52504
exploration/Rewards Std            0.284871
exploration/Rewards Max           -0.908281
exploration/Rewards Min           -2.37231
exploration/Returns Mean        -152.504
exploration/Returns Std           23.6938
exploration/Returns Max         -128.81
exploration/Returns Min         -176.198
exploration/Actions Mean          -9.90595e-05
exploration/Actions Std            0.175889
exploration/Actions Max            0.537606
exploration/Actions Min           -0.770842
exploration/Num Paths              2
exploration/Average Returns     -152.504
evaluation/num steps total     64000
evaluation/num paths total       640
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.71933
evaluation/Rewards Std             0.811487
evaluation/Rewards Max            -0.154947
evaluation/Rewards Min            -9.50974
evaluation/Returns Mean         -171.933
evaluation/Returns Std            18.5473
evaluation/Returns Max          -136.67
evaluation/Returns Min          -200.38
evaluation/Actions Mean           -0.00871483
evaluation/Actions Std             0.19253
evaluation/Actions Max             0.997072
evaluation/Actions Min            -0.986753
evaluation/Num Paths              10
evaluation/Average Returns      -171.933
time/data storing (s)              0.00140807
time/evaluation sampling (s)       0.220261
time/exploration sampling (s)      0.0657319
time/logging (s)                   0.00332785
time/saving (s)                    0.00196031
time/training (s)                  0.773261
time/epoch (s)                     1.06595
time/total (s)                    68.1473
Epoch                             63
-----------------------------  ---------------
2019-04-21 01:12:52.362077 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                  68.2996
trainer/QF2 Loss                  68.6269
trainer/Policy Loss               77.961
trainer/Q1 Predictions Mean      -76.8748
trainer/Q1 Predictions Std        12.7345
trainer/Q1 Predictions Max       -64.8225
trainer/Q1 Predictions Min      -125.014
trainer/Q2 Predictions Mean      -76.8256
trainer/Q2 Predictions Std        12.6881
trainer/Q2 Predictions Max       -64.8182
trainer/Q2 Predictions Min      -124.134
trainer/Q Targets Mean           -76.6457
trainer/Q Targets Std             14.5711
trainer/Q Targets Max             -2.42146
trainer/Q Targets Min           -125.915
trainer/Log Pis Mean               2.16591
trainer/Log Pis Std                1.24965
trainer/Log Pis Max                5.671
trainer/Log Pis Min               -2.11569
trainer/Policy mu Mean            -0.0893332
trainer/Policy mu Std              1.03233
trainer/Policy mu Max              2.99577
trainer/Policy mu Min             -2.9234
trainer/Policy log std Mean       -1.73293
trainer/Policy log std Std         0.556887
trainer/Policy log std Max        -0.164995
trainer/Policy log std Min        -2.43119
trainer/Alpha                      0.0653307
trainer/Alpha Loss                 0.452635
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.19741
exploration/Rewards Std            0.407879
exploration/Rewards Max           -0.782962
exploration/Rewards Min           -5.11157
exploration/Returns Mean        -119.741
exploration/Returns Std            3.15954
exploration/Returns Max         -116.581
exploration/Returns Min         -122.9
exploration/Actions Mean          -0.00446432
exploration/Actions Std            0.216928
exploration/Actions Max            0.8598
exploration/Actions Min           -0.977979
exploration/Num Paths              2
exploration/Average Returns     -119.741
evaluation/num steps total     65000
evaluation/num paths total       650
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.42882
evaluation/Rewards Std             0.628997
evaluation/Rewards Max            -0.723243
evaluation/Rewards Min            -9.6039
evaluation/Returns Mean         -142.882
evaluation/Returns Std            21.2017
evaluation/Returns Max          -111.279
evaluation/Returns Min          -181.699
evaluation/Actions Mean           -0.0012947
evaluation/Actions Std             0.160416
evaluation/Actions Max             0.995474
evaluation/Actions Min            -0.989057
evaluation/Num Paths              10
evaluation/Average Returns      -142.882
time/data storing (s)              0.00123765
time/evaluation sampling (s)       0.225099
time/exploration sampling (s)      0.0642465
time/logging (s)                   0.00343926
time/saving (s)                    0.00196089
time/training (s)                  0.76277
time/epoch (s)                     1.05875
time/total (s)                    69.2104
Epoch                             64
-----------------------------  --------------
2019-04-21 01:12:53.426094 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             13400
trainer/QF1 Loss                 108.998
trainer/QF2 Loss                 109.329
trainer/Policy Loss               77.1764
trainer/Q1 Predictions Mean      -76.1691
trainer/Q1 Predictions Std        12.0131
trainer/Q1 Predictions Max       -65.0134
trainer/Q1 Predictions Min      -129.931
trainer/Q2 Predictions Mean      -76.1893
trainer/Q2 Predictions Std        12.057
trainer/Q2 Predictions Max       -64.945
trainer/Q2 Predictions Min      -129.921
trainer/Q Targets Mean           -75.4317
trainer/Q Targets Std             15.9167
trainer/Q Targets Max             -1.44067
trainer/Q Targets Min           -128.372
trainer/Log Pis Mean               2.04283
trainer/Log Pis Std                1.33573
trainer/Log Pis Max                5.85771
trainer/Log Pis Min               -1.05498
trainer/Policy mu Mean            -0.0959915
trainer/Policy mu Std              0.980566
trainer/Policy mu Max              2.70012
trainer/Policy mu Min             -2.75185
trainer/Policy log std Mean       -1.71288
trainer/Policy log std Std         0.534242
trainer/Policy log std Max        -0.32797
trainer/Policy log std Min        -2.41153
trainer/Alpha                      0.0646558
trainer/Alpha Loss                 0.117303
exploration/num steps total    13400
exploration/num paths total      134
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.89569
exploration/Rewards Std            0.951835
exploration/Rewards Max           -1.11337
exploration/Rewards Min           -9.48258
exploration/Returns Mean        -189.569
exploration/Returns Std           18.4332
exploration/Returns Max         -171.136
exploration/Returns Min         -208.002
exploration/Actions Mean           0.0113861
exploration/Actions Std            0.219725
exploration/Actions Max            0.997831
exploration/Actions Min           -0.864598
exploration/Num Paths              2
exploration/Average Returns     -189.569
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.66162
evaluation/Rewards Std             0.725044
evaluation/Rewards Max            -0.362597
evaluation/Rewards Min            -9.12962
evaluation/Returns Mean         -166.162
evaluation/Returns Std            27.446
evaluation/Returns Max          -127.115
evaluation/Returns Min          -205.603
evaluation/Actions Mean           -0.00303277
evaluation/Actions Std             0.182083
evaluation/Actions Max             0.995899
evaluation/Actions Min            -0.98815
evaluation/Num Paths              10
evaluation/Average Returns      -166.162
time/data storing (s)              0.00123574
time/evaluation sampling (s)       0.225111
time/exploration sampling (s)      0.0641068
time/logging (s)                   0.00336751
time/saving (s)                    0.00197444
time/training (s)                  0.762275
time/epoch (s)                     1.05807
time/total (s)                    70.2728
Epoch                             65
-----------------------------  --------------
2019-04-21 01:12:54.474421 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 66 finished
-----------------------------  --------------
replay_buffer/size             13600
trainer/QF1 Loss                   1.82215
trainer/QF2 Loss                   1.71729
trainer/Policy Loss               76.1939
trainer/Q1 Predictions Mean      -74.9022
trainer/Q1 Predictions Std         9.8185
trainer/Q1 Predictions Max       -64.6303
trainer/Q1 Predictions Min      -104.4
trainer/Q2 Predictions Mean      -74.933
trainer/Q2 Predictions Std         9.83024
trainer/Q2 Predictions Max       -64.6714
trainer/Q2 Predictions Min      -104.307
trainer/Q Targets Mean           -76.1248
trainer/Q Targets Std              9.80578
trainer/Q Targets Max            -65.4263
trainer/Q Targets Min           -104.119
trainer/Log Pis Mean               1.97179
trainer/Log Pis Std                1.12865
trainer/Log Pis Max                5.37877
trainer/Log Pis Min               -1.67923
trainer/Policy mu Mean            -0.0205579
trainer/Policy mu Std              0.900142
trainer/Policy mu Max              2.782
trainer/Policy mu Min             -2.58741
trainer/Policy log std Mean       -1.78939
trainer/Policy log std Std         0.505787
trainer/Policy log std Max        -0.365937
trainer/Policy log std Min        -2.45768
trainer/Alpha                      0.0640469
trainer/Alpha Loss                -0.077536
exploration/num steps total    13600
exploration/num paths total      136
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.4851
exploration/Rewards Std            0.536209
exploration/Rewards Max           -0.880005
exploration/Rewards Min           -5.01391
exploration/Returns Mean        -148.51
exploration/Returns Std           20.4821
exploration/Returns Max         -128.028
exploration/Returns Min         -168.992
exploration/Actions Mean          -0.0153636
exploration/Actions Std            0.212179
exploration/Actions Max            0.941037
exploration/Actions Min           -0.975635
exploration/Num Paths              2
exploration/Average Returns     -148.51
evaluation/num steps total     67000
evaluation/num paths total       670
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.59009
evaluation/Rewards Std             0.834225
evaluation/Rewards Max            -1.04011
evaluation/Rewards Min           -10.7332
evaluation/Returns Mean         -159.009
evaluation/Returns Std            31.7515
evaluation/Returns Max          -113.049
evaluation/Returns Min          -206.85
evaluation/Actions Mean            0.00581564
evaluation/Actions Std             0.179146
evaluation/Actions Max             0.995429
evaluation/Actions Min            -0.985731
evaluation/Num Paths              10
evaluation/Average Returns      -159.009
time/data storing (s)              0.00135143
time/evaluation sampling (s)       0.223648
time/exploration sampling (s)      0.0654987
time/logging (s)                   0.00333053
time/saving (s)                    0.00157735
time/training (s)                  0.747039
time/epoch (s)                     1.04244
time/total (s)                    71.3195
Epoch                             66
-----------------------------  --------------
2019-04-21 01:12:55.538353 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 67 finished
-----------------------------  --------------
replay_buffer/size             13800
trainer/QF1 Loss                 168.711
trainer/QF2 Loss                 168.581
trainer/Policy Loss               74.9274
trainer/Q1 Predictions Mean      -74.0523
trainer/Q1 Predictions Std         9.33174
trainer/Q1 Predictions Max       -65.2533
trainer/Q1 Predictions Min       -96.6907
trainer/Q2 Predictions Mean      -74.0415
trainer/Q2 Predictions Std         9.35747
trainer/Q2 Predictions Max       -65.2608
trainer/Q2 Predictions Min       -96.8658
trainer/Q Targets Mean           -71.9719
trainer/Q Targets Std             17.1096
trainer/Q Targets Max             -1.24734
trainer/Q Targets Min            -96.7719
trainer/Log Pis Mean               1.70935
trainer/Log Pis Std                1.43647
trainer/Log Pis Max                6.34539
trainer/Log Pis Min               -3.81301
trainer/Policy mu Mean            -0.0966295
trainer/Policy mu Std              0.859962
trainer/Policy mu Max              2.58833
trainer/Policy mu Min             -2.91654
trainer/Policy log std Mean       -1.8136
trainer/Policy log std Std         0.502284
trainer/Policy log std Max        -0.18879
trainer/Policy log std Min        -2.35912
trainer/Alpha                      0.0641623
trainer/Alpha Loss                -0.798163
exploration/num steps total    13800
exploration/num paths total      138
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.21135
exploration/Rewards Std            0.459704
exploration/Rewards Max           -0.853398
exploration/Rewards Min           -5.26961
exploration/Returns Mean        -121.135
exploration/Returns Std            5.13211
exploration/Returns Max         -116.002
exploration/Returns Min         -126.267
exploration/Actions Mean          -0.0105543
exploration/Actions Std            0.216238
exploration/Actions Max            0.821058
exploration/Actions Min           -0.999311
exploration/Num Paths              2
exploration/Average Returns     -121.135
evaluation/num steps total     68000
evaluation/num paths total       680
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.52173
evaluation/Rewards Std             0.766612
evaluation/Rewards Max            -0.57164
evaluation/Rewards Min            -9.15013
evaluation/Returns Mean         -152.173
evaluation/Returns Std            22.9597
evaluation/Returns Max          -112.923
evaluation/Returns Min          -188.238
evaluation/Actions Mean           -0.0105946
evaluation/Actions Std             0.177751
evaluation/Actions Max             0.995918
evaluation/Actions Min            -0.991667
evaluation/Num Paths              10
evaluation/Average Returns      -152.173
time/data storing (s)              0.00122183
time/evaluation sampling (s)       0.225401
time/exploration sampling (s)      0.0655753
time/logging (s)                   0.00341514
time/saving (s)                    0.00156059
time/training (s)                  0.760998
time/epoch (s)                     1.05817
time/total (s)                    72.382
Epoch                             67
-----------------------------  --------------
2019-04-21 01:12:56.596287 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 68 finished
-----------------------------  --------------
replay_buffer/size             14000
trainer/QF1 Loss                  84.715
trainer/QF2 Loss                  84.9619
trainer/Policy Loss               77.5328
trainer/Q1 Predictions Mean      -76.5512
trainer/Q1 Predictions Std        14.0606
trainer/Q1 Predictions Max       -65.1248
trainer/Q1 Predictions Min      -135.773
trainer/Q2 Predictions Mean      -76.5286
trainer/Q2 Predictions Std        13.9595
trainer/Q2 Predictions Max       -65.2074
trainer/Q2 Predictions Min      -134.904
trainer/Q Targets Mean           -75.3852
trainer/Q Targets Std             17.4944
trainer/Q Targets Max             -1.19891
trainer/Q Targets Min           -138.654
trainer/Log Pis Mean               2.28268
trainer/Log Pis Std                1.5537
trainer/Log Pis Max                6.39424
trainer/Log Pis Min               -3.00289
trainer/Policy mu Mean             0.0143794
trainer/Policy mu Std              1.0197
trainer/Policy mu Max              3.0982
trainer/Policy mu Min             -3.2192
trainer/Policy log std Mean       -1.7744
trainer/Policy log std Std         0.536559
trainer/Policy log std Max        -0.0752913
trainer/Policy log std Min        -2.51893
trainer/Alpha                      0.0641281
trainer/Alpha Loss                 0.776532
exploration/num steps total    14000
exploration/num paths total      140
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.56205
exploration/Rewards Std            0.807588
exploration/Rewards Max           -1.00728
exploration/Rewards Min           -8.05243
exploration/Returns Mean        -156.205
exploration/Returns Std           10.0297
exploration/Returns Max         -146.176
exploration/Returns Min         -166.235
exploration/Actions Mean           0.0211919
exploration/Actions Std            0.238061
exploration/Actions Max            0.994854
exploration/Actions Min           -0.796579
exploration/Num Paths              2
exploration/Average Returns     -156.205
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.43931
evaluation/Rewards Std             1.04583
evaluation/Rewards Max            -1.00531
evaluation/Rewards Min           -10.6428
evaluation/Returns Mean         -143.931
evaluation/Returns Std            30.3254
evaluation/Returns Max          -107.204
evaluation/Returns Min          -182.476
evaluation/Actions Mean            0.0178339
evaluation/Actions Std             0.196515
evaluation/Actions Max             0.995941
evaluation/Actions Min            -0.993542
evaluation/Num Paths              10
evaluation/Average Returns      -143.931
time/data storing (s)              0.00124312
time/evaluation sampling (s)       0.228231
time/exploration sampling (s)      0.0633484
time/logging (s)                   0.0027148
time/saving (s)                    0.00198036
time/training (s)                  0.75361
time/epoch (s)                     1.05113
time/total (s)                    73.4373
Epoch                             68
-----------------------------  --------------
2019-04-21 01:12:57.666200 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 69 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                 123.36
trainer/QF2 Loss                 123.381
trainer/Policy Loss               75.8489
trainer/Q1 Predictions Mean      -74.4853
trainer/Q1 Predictions Std        11.1199
trainer/Q1 Predictions Max       -64.3384
trainer/Q1 Predictions Min      -127.481
trainer/Q2 Predictions Mean      -74.5349
trainer/Q2 Predictions Std        11.1229
trainer/Q2 Predictions Max       -64.4404
trainer/Q2 Predictions Min      -126.947
trainer/Q Targets Mean           -73.3928
trainer/Q Targets Std             16.8095
trainer/Q Targets Max             -0.839071
trainer/Q Targets Min           -131.235
trainer/Log Pis Mean               2.22663
trainer/Log Pis Std                1.16552
trainer/Log Pis Max                6.79767
trainer/Log Pis Min               -0.870258
trainer/Policy mu Mean            -0.122071
trainer/Policy mu Std              0.94914
trainer/Policy mu Max              2.8073
trainer/Policy mu Min             -2.92278
trainer/Policy log std Mean       -1.78941
trainer/Policy log std Std         0.537966
trainer/Policy log std Max        -0.098941
trainer/Policy log std Min        -2.47825
trainer/Alpha                      0.064784
trainer/Alpha Loss                 0.620232
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.24834
exploration/Rewards Std            0.748839
exploration/Rewards Max           -0.853711
exploration/Rewards Min           -7.26153
exploration/Returns Mean        -124.834
exploration/Returns Std            7.84488
exploration/Returns Max         -116.989
exploration/Returns Min         -132.679
exploration/Actions Mean          -0.035563
exploration/Actions Std            0.231894
exploration/Actions Max            0.921776
exploration/Actions Min           -0.99476
exploration/Num Paths              2
exploration/Average Returns     -124.834
evaluation/num steps total     70000
evaluation/num paths total       700
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.62196
evaluation/Rewards Std             1.03889
evaluation/Rewards Max            -0.620839
evaluation/Rewards Min           -11.0742
evaluation/Returns Mean         -162.196
evaluation/Returns Std            23.3269
evaluation/Returns Max          -121.974
evaluation/Returns Min          -206.375
evaluation/Actions Mean           -0.0163193
evaluation/Actions Std             0.196196
evaluation/Actions Max             0.997449
evaluation/Actions Min            -0.997958
evaluation/Num Paths              10
evaluation/Average Returns      -162.196
time/data storing (s)              0.00143325
time/evaluation sampling (s)       0.229087
time/exploration sampling (s)      0.0640574
time/logging (s)                   0.00335411
time/saving (s)                    0.00158046
time/training (s)                  0.766274
time/epoch (s)                     1.06579
time/total (s)                    74.5069
Epoch                             69
-----------------------------  --------------
2019-04-21 01:12:58.736605 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 70 finished
-----------------------------  --------------
replay_buffer/size             14400
trainer/QF1 Loss                 151.605
trainer/QF2 Loss                 151.633
trainer/Policy Loss               77.0509
trainer/Q1 Predictions Mean      -75.9316
trainer/Q1 Predictions Std        11.0624
trainer/Q1 Predictions Max       -64.8247
trainer/Q1 Predictions Min      -120.976
trainer/Q2 Predictions Mean      -75.9225
trainer/Q2 Predictions Std        11.035
trainer/Q2 Predictions Max       -64.9277
trainer/Q2 Predictions Min      -120.979
trainer/Q Targets Mean           -73.9509
trainer/Q Targets Std             16.8081
trainer/Q Targets Max             -1.82859
trainer/Q Targets Min           -123.278
trainer/Log Pis Mean               2.12764
trainer/Log Pis Std                1.25762
trainer/Log Pis Max                5.5659
trainer/Log Pis Min               -1.31814
trainer/Policy mu Mean             0.0366304
trainer/Policy mu Std              0.898342
trainer/Policy mu Max              2.8287
trainer/Policy mu Min             -2.91968
trainer/Policy log std Mean       -1.8598
trainer/Policy log std Std         0.545937
trainer/Policy log std Max        -0.196531
trainer/Policy log std Min        -2.60933
trainer/Alpha                      0.0655929
trainer/Alpha Loss                 0.347746
exploration/num steps total    14400
exploration/num paths total      144
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.53211
exploration/Rewards Std            0.366514
exploration/Rewards Max           -1.10779
exploration/Rewards Min           -4.73258
exploration/Returns Mean        -153.211
exploration/Returns Std            3.985
exploration/Returns Max         -149.226
exploration/Returns Min         -157.196
exploration/Actions Mean           0.0206673
exploration/Actions Std            0.189288
exploration/Actions Max            0.874815
exploration/Actions Min           -0.480827
exploration/Num Paths              2
exploration/Average Returns     -153.211
evaluation/num steps total     71000
evaluation/num paths total       710
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.47767
evaluation/Rewards Std             0.890593
evaluation/Rewards Max            -0.649142
evaluation/Rewards Min            -9.85758
evaluation/Returns Mean         -147.767
evaluation/Returns Std            28.2805
evaluation/Returns Max          -105.734
evaluation/Returns Min          -185.493
evaluation/Actions Mean            0.0125273
evaluation/Actions Std             0.171119
evaluation/Actions Max             0.99483
evaluation/Actions Min            -0.992355
evaluation/Num Paths              10
evaluation/Average Returns      -147.767
time/data storing (s)              0.00123849
time/evaluation sampling (s)       0.227978
time/exploration sampling (s)      0.0634866
time/logging (s)                   0.00337358
time/saving (s)                    0.00201147
time/training (s)                  0.7672
time/epoch (s)                     1.06529
time/total (s)                    75.5757
Epoch                             70
-----------------------------  --------------
2019-04-21 01:12:59.807548 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 71 finished
-----------------------------  --------------
replay_buffer/size             14600
trainer/QF1 Loss                  68.0971
trainer/QF2 Loss                  68.3774
trainer/Policy Loss               76.5795
trainer/Q1 Predictions Mean      -75.5991
trainer/Q1 Predictions Std        11.6688
trainer/Q1 Predictions Max       -64.25
trainer/Q1 Predictions Min      -119.836
trainer/Q2 Predictions Mean      -75.5548
trainer/Q2 Predictions Std        11.6076
trainer/Q2 Predictions Max       -64.2942
trainer/Q2 Predictions Min      -119.375
trainer/Q Targets Mean           -75.3682
trainer/Q Targets Std             13.9512
trainer/Q Targets Max             -1.64171
trainer/Q Targets Min           -122.329
trainer/Log Pis Mean               1.81987
trainer/Log Pis Std                1.39371
trainer/Log Pis Max                5.6156
trainer/Log Pis Min               -4.9429
trainer/Policy mu Mean            -0.0108149
trainer/Policy mu Std              0.88796
trainer/Policy mu Max              2.88012
trainer/Policy mu Min             -2.70072
trainer/Policy log std Mean       -1.79715
trainer/Policy log std Std         0.539711
trainer/Policy log std Max        -0.20744
trainer/Policy log std Min        -2.49184
trainer/Alpha                      0.0658117
trainer/Alpha Loss                -0.490152
exploration/num steps total    14600
exploration/num paths total      146
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.48452
exploration/Rewards Std            0.853501
exploration/Rewards Max           -0.797812
exploration/Rewards Min           -7.67791
exploration/Returns Mean        -148.452
exploration/Returns Std           29.2121
exploration/Returns Max         -119.24
exploration/Returns Min         -177.664
exploration/Actions Mean          -0.00932025
exploration/Actions Std            0.249039
exploration/Actions Max            0.997284
exploration/Actions Min           -0.990694
exploration/Num Paths              2
exploration/Average Returns     -148.452
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.57028
evaluation/Rewards Std             0.949098
evaluation/Rewards Max            -0.622746
evaluation/Rewards Min            -9.90315
evaluation/Returns Mean         -157.028
evaluation/Returns Std            17.3392
evaluation/Returns Max          -121.9
evaluation/Returns Min          -182.373
evaluation/Actions Mean           -0.00503966
evaluation/Actions Std             0.191918
evaluation/Actions Max             0.993354
evaluation/Actions Min            -0.995834
evaluation/Num Paths              10
evaluation/Average Returns      -157.028
time/data storing (s)              0.00160847
time/evaluation sampling (s)       0.225838
time/exploration sampling (s)      0.0647244
time/logging (s)                   0.00345162
time/saving (s)                    0.00155115
time/training (s)                  0.767398
time/epoch (s)                     1.06457
time/total (s)                    76.6451
Epoch                             71
-----------------------------  --------------
2019-04-21 01:13:00.868244 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 72 finished
-----------------------------  --------------
replay_buffer/size             14800
trainer/QF1 Loss                  41.0685
trainer/QF2 Loss                  40.9386
trainer/Policy Loss               75.3707
trainer/Q1 Predictions Mean      -74.2084
trainer/Q1 Predictions Std        10.6928
trainer/Q1 Predictions Max       -64.0851
trainer/Q1 Predictions Min      -103.235
trainer/Q2 Predictions Mean      -74.1897
trainer/Q2 Predictions Std        10.6791
trainer/Q2 Predictions Max       -64.2186
trainer/Q2 Predictions Min      -102.79
trainer/Q Targets Mean           -73.9163
trainer/Q Targets Std             12.6357
trainer/Q Targets Max             -1.80132
trainer/Q Targets Min           -104.041
trainer/Log Pis Mean               2.19825
trainer/Log Pis Std                1.11133
trainer/Log Pis Max                5.34935
trainer/Log Pis Min               -1.22267
trainer/Policy mu Mean            -0.073688
trainer/Policy mu Std              0.913411
trainer/Policy mu Max              2.58604
trainer/Policy mu Min             -2.93616
trainer/Policy log std Mean       -1.84504
trainer/Policy log std Std         0.556687
trainer/Policy log std Max        -0.350548
trainer/Policy log std Min        -2.52864
trainer/Alpha                      0.0663215
trainer/Alpha Loss                 0.537918
exploration/num steps total    14800
exploration/num paths total      148
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.42957
exploration/Rewards Std            1.08129
exploration/Rewards Max           -0.801503
exploration/Rewards Min           -8.58108
exploration/Returns Mean        -142.957
exploration/Returns Std           17.8268
exploration/Returns Max         -125.13
exploration/Returns Min         -160.784
exploration/Actions Mean           0.0130289
exploration/Actions Std            0.258981
exploration/Actions Max            0.999674
exploration/Actions Min           -0.99969
exploration/Num Paths              2
exploration/Average Returns     -142.957
evaluation/num steps total     73000
evaluation/num paths total       730
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.21952
evaluation/Rewards Std             0.643554
evaluation/Rewards Max            -0.938971
evaluation/Rewards Min            -8.97604
evaluation/Returns Mean         -121.952
evaluation/Returns Std            11.0547
evaluation/Returns Max          -108.683
evaluation/Returns Min          -138.838
evaluation/Actions Mean           -0.0193788
evaluation/Actions Std             0.174096
evaluation/Actions Max             0.980804
evaluation/Actions Min            -0.994763
evaluation/Num Paths              10
evaluation/Average Returns      -121.952
time/data storing (s)              0.00154453
time/evaluation sampling (s)       0.220429
time/exploration sampling (s)      0.0642745
time/logging (s)                   0.00336159
time/saving (s)                    0.00156004
time/training (s)                  0.76342
time/epoch (s)                     1.05459
time/total (s)                    77.704
Epoch                             72
-----------------------------  --------------
2019-04-21 01:13:01.940358 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 73 finished
-----------------------------  --------------
replay_buffer/size             15000
trainer/QF1 Loss                   0.878606
trainer/QF2 Loss                   0.96651
trainer/Policy Loss               78.8272
trainer/Q1 Predictions Mean      -77.8298
trainer/Q1 Predictions Std        14.4162
trainer/Q1 Predictions Max       -64.1
trainer/Q1 Predictions Min      -130.095
trainer/Q2 Predictions Mean      -77.7966
trainer/Q2 Predictions Std        14.4064
trainer/Q2 Predictions Max       -63.9496
trainer/Q2 Predictions Min      -129.555
trainer/Q Targets Mean           -78.2528
trainer/Q Targets Std             14.4259
trainer/Q Targets Max            -64.5794
trainer/Q Targets Min           -132.774
trainer/Log Pis Mean               1.99413
trainer/Log Pis Std                1.11289
trainer/Log Pis Max                4.8747
trainer/Log Pis Min               -1.53206
trainer/Policy mu Mean             0.0259819
trainer/Policy mu Std              0.95794
trainer/Policy mu Max              2.9643
trainer/Policy mu Min             -2.87993
trainer/Policy log std Mean       -1.74213
trainer/Policy log std Std         0.533341
trainer/Policy log std Max        -0.305263
trainer/Policy log std Min        -2.36304
trainer/Alpha                      0.0649868
trainer/Alpha Loss                -0.0160538
exploration/num steps total    15000
exploration/num paths total      150
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.51847
exploration/Rewards Std            0.686068
exploration/Rewards Max           -0.922374
exploration/Rewards Min           -7.43369
exploration/Returns Mean        -151.847
exploration/Returns Std            4.65363
exploration/Returns Max         -147.194
exploration/Returns Min         -156.501
exploration/Actions Mean          -0.00580776
exploration/Actions Std            0.221818
exploration/Actions Max            0.908014
exploration/Actions Min           -0.995498
exploration/Num Paths              2
exploration/Average Returns     -151.847
evaluation/num steps total     74000
evaluation/num paths total       740
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.53
evaluation/Rewards Std             0.806299
evaluation/Rewards Max            -1.15335
evaluation/Rewards Min           -10.083
evaluation/Returns Mean         -153
evaluation/Returns Std            17.6064
evaluation/Returns Max          -127.997
evaluation/Returns Min          -179.976
evaluation/Actions Mean           -0.0115127
evaluation/Actions Std             0.187075
evaluation/Actions Max             0.995592
evaluation/Actions Min            -0.992801
evaluation/Num Paths              10
evaluation/Average Returns      -153
time/data storing (s)              0.00123208
time/evaluation sampling (s)       0.222318
time/exploration sampling (s)      0.0628485
time/logging (s)                   0.00338131
time/saving (s)                    0.0019523
time/training (s)                  0.774457
time/epoch (s)                     1.06619
time/total (s)                    78.7745
Epoch                             73
-----------------------------  --------------
2019-04-21 01:13:03.005239 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size             15200
trainer/QF1 Loss                 239.649
trainer/QF2 Loss                 239.103
trainer/Policy Loss               76.4073
trainer/Q1 Predictions Mean      -75.2865
trainer/Q1 Predictions Std        13.51
trainer/Q1 Predictions Max       -63.9472
trainer/Q1 Predictions Min      -143.241
trainer/Q2 Predictions Mean      -75.3182
trainer/Q2 Predictions Std        13.5234
trainer/Q2 Predictions Max       -63.9037
trainer/Q2 Predictions Min      -143.089
trainer/Q Targets Mean           -73.8847
trainer/Q Targets Std             15.2572
trainer/Q Targets Max             -1.76061
trainer/Q Targets Min           -137.914
trainer/Log Pis Mean               1.80058
trainer/Log Pis Std                1.04771
trainer/Log Pis Max                4.50316
trainer/Log Pis Min               -2.93489
trainer/Policy mu Mean             0.102958
trainer/Policy mu Std              0.774195
trainer/Policy mu Max              3.07257
trainer/Policy mu Min             -2.46505
trainer/Policy log std Mean       -1.88004
trainer/Policy log std Std         0.456608
trainer/Policy log std Max        -0.349865
trainer/Policy log std Min        -2.3814
trainer/Alpha                      0.0636411
trainer/Alpha Loss                -0.549293
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.42055
exploration/Rewards Std            0.49756
exploration/Rewards Max           -0.333766
exploration/Rewards Min           -4.86604
exploration/Returns Mean        -142.055
exploration/Returns Std           16.9996
exploration/Returns Max         -125.055
exploration/Returns Min         -159.054
exploration/Actions Mean          -0.0222831
exploration/Actions Std            0.227868
exploration/Actions Max            0.985553
exploration/Actions Min           -0.998144
exploration/Num Paths              2
exploration/Average Returns     -142.055
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.5076
evaluation/Rewards Std             0.636945
evaluation/Rewards Max            -0.362176
evaluation/Rewards Min            -8.85444
evaluation/Returns Mean         -150.76
evaluation/Returns Std            24.5872
evaluation/Returns Max          -115.499
evaluation/Returns Min          -190.115
evaluation/Actions Mean           -0.000206775
evaluation/Actions Std             0.156728
evaluation/Actions Max             0.993214
evaluation/Actions Min            -0.989667
evaluation/Num Paths              10
evaluation/Average Returns      -150.76
time/data storing (s)              0.00121974
time/evaluation sampling (s)       0.216244
time/exploration sampling (s)      0.0663367
time/logging (s)                   0.00337155
time/saving (s)                    0.00198259
time/training (s)                  0.769763
time/epoch (s)                     1.05892
time/total (s)                    79.8378
Epoch                             74
-----------------------------  ---------------
2019-04-21 01:13:04.076378 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 75 finished
-----------------------------  --------------
replay_buffer/size             15400
trainer/QF1 Loss                   1.63653
trainer/QF2 Loss                   1.72138
trainer/Policy Loss               76.5906
trainer/Q1 Predictions Mean      -75.3431
trainer/Q1 Predictions Std        13.0311
trainer/Q1 Predictions Max       -63.0136
trainer/Q1 Predictions Min      -114.193
trainer/Q2 Predictions Mean      -75.3308
trainer/Q2 Predictions Std        13.0824
trainer/Q2 Predictions Max       -63.077
trainer/Q2 Predictions Min      -114.9
trainer/Q Targets Mean           -76.3419
trainer/Q Targets Std             13.028
trainer/Q Targets Max            -64.3795
trainer/Q Targets Min           -117.438
trainer/Log Pis Mean               2.34307
trainer/Log Pis Std                1.17348
trainer/Log Pis Max                6.43777
trainer/Log Pis Min               -1.18666
trainer/Policy mu Mean            -0.119636
trainer/Policy mu Std              0.945211
trainer/Policy mu Max              2.63009
trainer/Policy mu Min             -2.98617
trainer/Policy log std Mean       -1.8259
trainer/Policy log std Std         0.56004
trainer/Policy log std Max        -0.232476
trainer/Policy log std Min        -2.47955
trainer/Alpha                      0.064243
trainer/Alpha Loss                 0.941788
exploration/num steps total    15400
exploration/num paths total      154
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.4051
exploration/Rewards Std            1.35809
exploration/Rewards Max           -0.75726
exploration/Rewards Min          -10.3282
exploration/Returns Mean        -140.51
exploration/Returns Std           10.4234
exploration/Returns Max         -130.086
exploration/Returns Min         -150.933
exploration/Actions Mean          -0.0127212
exploration/Actions Std            0.271184
exploration/Actions Max            0.985345
exploration/Actions Min           -0.998452
exploration/Num Paths              2
exploration/Average Returns     -140.51
evaluation/num steps total     76000
evaluation/num paths total       760
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.47102
evaluation/Rewards Std             0.604945
evaluation/Rewards Max            -0.859256
evaluation/Rewards Min            -9.36639
evaluation/Returns Mean         -147.102
evaluation/Returns Std            18.697
evaluation/Returns Max          -106.807
evaluation/Returns Min          -165.085
evaluation/Actions Mean            0.00279756
evaluation/Actions Std             0.159445
evaluation/Actions Max             0.987154
evaluation/Actions Min            -0.995552
evaluation/Num Paths              10
evaluation/Average Returns      -147.102
time/data storing (s)              0.00124155
time/evaluation sampling (s)       0.22758
time/exploration sampling (s)      0.0646348
time/logging (s)                   0.00334458
time/saving (s)                    0.00196196
time/training (s)                  0.766305
time/epoch (s)                     1.06507
time/total (s)                    80.9072
Epoch                             75
-----------------------------  --------------
2019-04-21 01:13:05.122053 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 76 finished
-----------------------------  --------------
replay_buffer/size             15600
trainer/QF1 Loss                  39.9484
trainer/QF2 Loss                  40.2028
trainer/Policy Loss               75.5494
trainer/Q1 Predictions Mean      -74.2455
trainer/Q1 Predictions Std        10.9872
trainer/Q1 Predictions Max       -63.859
trainer/Q1 Predictions Min      -113.321
trainer/Q2 Predictions Mean      -74.2558
trainer/Q2 Predictions Std        10.9817
trainer/Q2 Predictions Max       -63.9181
trainer/Q2 Predictions Min      -112.87
trainer/Q Targets Mean           -74.0226
trainer/Q Targets Std             13.0552
trainer/Q Targets Max             -1.77029
trainer/Q Targets Min           -114.821
trainer/Log Pis Mean               2.06159
trainer/Log Pis Std                1.12009
trainer/Log Pis Max                5.53132
trainer/Log Pis Min               -1.45232
trainer/Policy mu Mean            -0.0513507
trainer/Policy mu Std              0.852876
trainer/Policy mu Max              2.73609
trainer/Policy mu Min             -2.89187
trainer/Policy log std Mean       -1.88901
trainer/Policy log std Std         0.516406
trainer/Policy log std Max        -0.156318
trainer/Policy log std Min        -2.47008
trainer/Alpha                      0.0648228
trainer/Alpha Loss                 0.168509
exploration/num steps total    15600
exploration/num paths total      156
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.4213
exploration/Rewards Std            0.251417
exploration/Rewards Max           -0.757841
exploration/Rewards Min           -3.61695
exploration/Returns Mean        -142.13
exploration/Returns Std            2.86753
exploration/Returns Max         -139.262
exploration/Returns Min         -144.997
exploration/Actions Mean           0.00327457
exploration/Actions Std            0.185047
exploration/Actions Max            0.976164
exploration/Actions Min           -0.957986
exploration/Num Paths              2
exploration/Average Returns     -142.13
evaluation/num steps total     77000
evaluation/num paths total       770
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.3176
evaluation/Rewards Std             0.698633
evaluation/Rewards Max            -0.84452
evaluation/Rewards Min            -8.50856
evaluation/Returns Mean         -131.76
evaluation/Returns Std            21.7089
evaluation/Returns Max          -105.833
evaluation/Returns Min          -167.759
evaluation/Actions Mean            0.00845533
evaluation/Actions Std             0.176135
evaluation/Actions Max             0.991139
evaluation/Actions Min            -0.994364
evaluation/Num Paths              10
evaluation/Average Returns      -131.76
time/data storing (s)              0.00123864
time/evaluation sampling (s)       0.228724
time/exploration sampling (s)      0.0644614
time/logging (s)                   0.00335836
time/saving (s)                    0.00197146
time/training (s)                  0.739937
time/epoch (s)                     1.03969
time/total (s)                    81.9512
Epoch                             76
-----------------------------  --------------
2019-04-21 01:13:06.170418 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 77 finished
-----------------------------  --------------
replay_buffer/size             15800
trainer/QF1 Loss                   2.00077
trainer/QF2 Loss                   2.25871
trainer/Policy Loss               78.4899
trainer/Q1 Predictions Mean      -77.6478
trainer/Q1 Predictions Std        14.0121
trainer/Q1 Predictions Max       -62.6573
trainer/Q1 Predictions Min      -126.962
trainer/Q2 Predictions Mean      -77.6292
trainer/Q2 Predictions Std        14.0446
trainer/Q2 Predictions Max       -62.5796
trainer/Q2 Predictions Min      -127.129
trainer/Q Targets Mean           -78.6098
trainer/Q Targets Std             13.5732
trainer/Q Targets Max            -64.0048
trainer/Q Targets Min           -127.696
trainer/Log Pis Mean               2.12477
trainer/Log Pis Std                1.35426
trainer/Log Pis Max                6.03705
trainer/Log Pis Min               -2.58355
trainer/Policy mu Mean            -0.0254658
trainer/Policy mu Std              1.02482
trainer/Policy mu Max              3.08042
trainer/Policy mu Min             -2.87385
trainer/Policy log std Mean       -1.76038
trainer/Policy log std Std         0.567728
trainer/Policy log std Max        -0.291772
trainer/Policy log std Min        -2.3797
trainer/Alpha                      0.0650303
trainer/Alpha Loss                 0.340973
exploration/num steps total    15800
exploration/num paths total      158
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.22341
exploration/Rewards Std            0.410897
exploration/Rewards Max           -0.856244
exploration/Rewards Min           -5.06449
exploration/Returns Mean        -122.341
exploration/Returns Std            6.67071
exploration/Returns Max         -115.67
exploration/Returns Min         -129.012
exploration/Actions Mean          -0.0179274
exploration/Actions Std            0.204208
exploration/Actions Max            0.637837
exploration/Actions Min           -0.988066
exploration/Num Paths              2
exploration/Average Returns     -122.341
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.46434
evaluation/Rewards Std             0.927994
evaluation/Rewards Max            -0.477876
evaluation/Rewards Min            -9.90295
evaluation/Returns Mean         -146.434
evaluation/Returns Std            15.5855
evaluation/Returns Max          -116.679
evaluation/Returns Min          -174.132
evaluation/Actions Mean           -0.0109789
evaluation/Actions Std             0.187861
evaluation/Actions Max             0.993265
evaluation/Actions Min            -0.992976
evaluation/Num Paths              10
evaluation/Average Returns      -146.434
time/data storing (s)              0.0012958
time/evaluation sampling (s)       0.229236
time/exploration sampling (s)      0.0643484
time/logging (s)                   0.00337295
time/saving (s)                    0.00195408
time/training (s)                  0.742342
time/epoch (s)                     1.04255
time/total (s)                    82.9979
Epoch                             77
-----------------------------  --------------
2019-04-21 01:13:07.232956 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 78 finished
-----------------------------  --------------
replay_buffer/size             16000
trainer/QF1 Loss                 145.935
trainer/QF2 Loss                 145.5
trainer/Policy Loss               75.8143
trainer/Q1 Predictions Mean      -74.6689
trainer/Q1 Predictions Std        11.7523
trainer/Q1 Predictions Max       -63.1767
trainer/Q1 Predictions Min      -119.999
trainer/Q2 Predictions Mean      -74.6612
trainer/Q2 Predictions Std        11.7423
trainer/Q2 Predictions Max       -63.2232
trainer/Q2 Predictions Min      -119.036
trainer/Q Targets Mean           -72.8742
trainer/Q Targets Std             16.9475
trainer/Q Targets Max             -0.839071
trainer/Q Targets Min           -117.667
trainer/Log Pis Mean               1.91531
trainer/Log Pis Std                1.56484
trainer/Log Pis Max                5.69335
trainer/Log Pis Min               -2.59648
trainer/Policy mu Mean            -0.121856
trainer/Policy mu Std              0.925689
trainer/Policy mu Max              2.743
trainer/Policy mu Min             -3.09595
trainer/Policy log std Mean       -1.89295
trainer/Policy log std Std         0.5869
trainer/Policy log std Max        -0.315451
trainer/Policy log std Min        -2.53609
trainer/Alpha                      0.066253
trainer/Alpha Loss                -0.229867
exploration/num steps total    16000
exploration/num paths total      160
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.14841
exploration/Rewards Std            0.472082
exploration/Rewards Max           -0.793377
exploration/Rewards Min           -5.59669
exploration/Returns Mean        -114.841
exploration/Returns Std            5.2151
exploration/Returns Max         -109.626
exploration/Returns Min         -120.056
exploration/Actions Mean           0.0216685
exploration/Actions Std            0.204862
exploration/Actions Max            0.98998
exploration/Actions Min           -0.723235
exploration/Num Paths              2
exploration/Average Returns     -114.841
evaluation/num steps total     79000
evaluation/num paths total       790
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.42242
evaluation/Rewards Std             0.925044
evaluation/Rewards Max            -1.02925
evaluation/Rewards Min           -11.2228
evaluation/Returns Mean         -142.242
evaluation/Returns Std            25.9192
evaluation/Returns Max          -107.47
evaluation/Returns Min          -192.022
evaluation/Actions Mean            0.00402975
evaluation/Actions Std             0.179207
evaluation/Actions Max             0.995558
evaluation/Actions Min            -0.995462
evaluation/Num Paths              10
evaluation/Average Returns      -142.242
time/data storing (s)              0.00139637
time/evaluation sampling (s)       0.228295
time/exploration sampling (s)      0.0654031
time/logging (s)                   0.00336965
time/saving (s)                    0.00196746
time/training (s)                  0.756363
time/epoch (s)                     1.05679
time/total (s)                    84.0587
Epoch                             78
-----------------------------  --------------
2019-04-21 01:13:08.305040 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 79 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                  39.3229
trainer/QF2 Loss                  39.592
trainer/Policy Loss               75.7391
trainer/Q1 Predictions Mean      -75.1574
trainer/Q1 Predictions Std        13.8596
trainer/Q1 Predictions Max       -62.926
trainer/Q1 Predictions Min      -139.299
trainer/Q2 Predictions Mean      -75.1585
trainer/Q2 Predictions Std        13.8287
trainer/Q2 Predictions Max       -63.002
trainer/Q2 Predictions Min      -138.494
trainer/Q Targets Mean           -75.3519
trainer/Q Targets Std             15.8864
trainer/Q Targets Max             -1.107
trainer/Q Targets Min           -141.39
trainer/Log Pis Mean               1.87593
trainer/Log Pis Std                1.22982
trainer/Log Pis Max                4.68447
trainer/Log Pis Min               -2.13668
trainer/Policy mu Mean             0.114663
trainer/Policy mu Std              0.869189
trainer/Policy mu Max              3.18024
trainer/Policy mu Min             -2.79194
trainer/Policy log std Mean       -1.83802
trainer/Policy log std Std         0.52952
trainer/Policy log std Max        -0.395845
trainer/Policy log std Min        -2.47618
trainer/Alpha                      0.0669687
trainer/Alpha Loss                -0.335434
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.21578
exploration/Rewards Std            0.918476
exploration/Rewards Max           -0.433168
exploration/Rewards Min           -8.46402
exploration/Returns Mean        -121.578
exploration/Returns Std           14.6057
exploration/Returns Max         -106.972
exploration/Returns Min         -136.184
exploration/Actions Mean           0.0292377
exploration/Actions Std            0.253122
exploration/Actions Max            0.996142
exploration/Actions Min           -0.862238
exploration/Num Paths              2
exploration/Average Returns     -121.578
evaluation/num steps total     80000
evaluation/num paths total       800
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.2255
evaluation/Rewards Std             0.953627
evaluation/Rewards Max            -0.472038
evaluation/Rewards Min            -9.83568
evaluation/Returns Mean         -122.55
evaluation/Returns Std            14.3539
evaluation/Returns Max           -99.9663
evaluation/Returns Min          -142.439
evaluation/Actions Mean            0.0176422
evaluation/Actions Std             0.193775
evaluation/Actions Max             0.99641
evaluation/Actions Min            -0.965632
evaluation/Num Paths              10
evaluation/Average Returns      -122.55
time/data storing (s)              0.00135793
time/evaluation sampling (s)       0.226899
time/exploration sampling (s)      0.0648331
time/logging (s)                   0.00258139
time/saving (s)                    0.00198102
time/training (s)                  0.767809
time/epoch (s)                     1.06546
time/total (s)                    85.1281
Epoch                             79
-----------------------------  --------------
2019-04-21 01:13:09.377481 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 80 finished
-----------------------------  --------------
replay_buffer/size             16400
trainer/QF1 Loss                 207.83
trainer/QF2 Loss                 207.51
trainer/Policy Loss               75.4421
trainer/Q1 Predictions Mean      -74.5324
trainer/Q1 Predictions Std        15.9102
trainer/Q1 Predictions Max       -62.379
trainer/Q1 Predictions Min      -135.994
trainer/Q2 Predictions Mean      -74.4531
trainer/Q2 Predictions Std        15.8132
trainer/Q2 Predictions Max       -62.3284
trainer/Q2 Predictions Min      -135.411
trainer/Q Targets Mean           -73.0677
trainer/Q Targets Std             19.7838
trainer/Q Targets Max             -2.42146
trainer/Q Targets Min           -139.737
trainer/Log Pis Mean               2.12752
trainer/Log Pis Std                1.56501
trainer/Log Pis Max                7.02065
trainer/Log Pis Min               -1.57593
trainer/Policy mu Mean            -0.0280886
trainer/Policy mu Std              0.961548
trainer/Policy mu Max              3.02899
trainer/Policy mu Min             -3.14763
trainer/Policy log std Mean       -1.8628
trainer/Policy log std Std         0.586518
trainer/Policy log std Max        -0.1257
trainer/Policy log std Min        -2.54864
trainer/Alpha                      0.066532
trainer/Alpha Loss                 0.345595
exploration/num steps total    16400
exploration/num paths total      164
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.41704
exploration/Rewards Std            0.891725
exploration/Rewards Max           -0.831703
exploration/Rewards Min           -8.42522
exploration/Returns Mean        -141.704
exploration/Returns Std           27.0927
exploration/Returns Max         -114.611
exploration/Returns Min         -168.796
exploration/Actions Mean           0.0291195
exploration/Actions Std            0.224584
exploration/Actions Max            0.996764
exploration/Actions Min           -0.642868
exploration/Num Paths              2
exploration/Average Returns     -141.704
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.47364
evaluation/Rewards Std             0.882628
evaluation/Rewards Max            -0.740838
evaluation/Rewards Min            -9.79108
evaluation/Returns Mean         -147.364
evaluation/Returns Std            15.2509
evaluation/Returns Max          -128.645
evaluation/Returns Min          -177.132
evaluation/Actions Mean            0.00423361
evaluation/Actions Std             0.160509
evaluation/Actions Max             0.994783
evaluation/Actions Min            -0.994697
evaluation/Num Paths              10
evaluation/Average Returns      -147.364
time/data storing (s)              0.00122619
time/evaluation sampling (s)       0.22156
time/exploration sampling (s)      0.0643322
time/logging (s)                   0.00250239
time/saving (s)                    0.00194933
time/training (s)                  0.776199
time/epoch (s)                     1.06777
time/total (s)                    86.1993
Epoch                             80
-----------------------------  --------------
2019-04-21 01:13:10.443875 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 81 finished
-----------------------------  --------------
replay_buffer/size             16600
trainer/QF1 Loss                  69.3468
trainer/QF2 Loss                  69.038
trainer/Policy Loss               75.5455
trainer/Q1 Predictions Mean      -74.4793
trainer/Q1 Predictions Std        10.334
trainer/Q1 Predictions Max       -62.7708
trainer/Q1 Predictions Min      -101.692
trainer/Q2 Predictions Mean      -74.4639
trainer/Q2 Predictions Std        10.3247
trainer/Q2 Predictions Max       -62.7929
trainer/Q2 Predictions Min      -101.364
trainer/Q Targets Mean           -73.8
trainer/Q Targets Std             12.4087
trainer/Q Targets Max             -0.874327
trainer/Q Targets Min            -99.2092
trainer/Log Pis Mean               1.59558
trainer/Log Pis Std                1.39045
trainer/Log Pis Max                4.31763
trainer/Log Pis Min               -4.55295
trainer/Policy mu Mean            -0.0300536
trainer/Policy mu Std              0.723846
trainer/Policy mu Max              2.71609
trainer/Policy mu Min             -2.21626
trainer/Policy log std Mean       -1.92279
trainer/Policy log std Std         0.484604
trainer/Policy log std Max        -0.487798
trainer/Policy log std Min        -2.5382
trainer/Alpha                      0.0669061
trainer/Alpha Loss                -1.09365
exploration/num steps total    16600
exploration/num paths total      166
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.56363
exploration/Rewards Std            1.13203
exploration/Rewards Max           -0.640014
exploration/Rewards Min           -9.83579
exploration/Returns Mean        -156.363
exploration/Returns Std            2.89505
exploration/Returns Max         -153.467
exploration/Returns Min         -159.258
exploration/Actions Mean          -0.0337376
exploration/Actions Std            0.244528
exploration/Actions Max            0.816468
exploration/Actions Min           -0.999273
exploration/Num Paths              2
exploration/Average Returns     -156.363
evaluation/num steps total     82000
evaluation/num paths total       820
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.41224
evaluation/Rewards Std             0.760277
evaluation/Rewards Max            -1.13189
evaluation/Rewards Min            -9.44481
evaluation/Returns Mean         -141.224
evaluation/Returns Std            25.8356
evaluation/Returns Max          -115.198
evaluation/Returns Min          -186.048
evaluation/Actions Mean            0.00942326
evaluation/Actions Std             0.16095
evaluation/Actions Max             0.995464
evaluation/Actions Min            -0.993488
evaluation/Num Paths              10
evaluation/Average Returns      -141.224
time/data storing (s)              0.00139385
time/evaluation sampling (s)       0.221423
time/exploration sampling (s)      0.0649047
time/logging (s)                   0.00333958
time/saving (s)                    0.00193664
time/training (s)                  0.768477
time/epoch (s)                     1.06147
time/total (s)                    87.2648
Epoch                             81
-----------------------------  --------------
2019-04-21 01:13:11.497020 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size             16800
trainer/QF1 Loss                   2.16574
trainer/QF2 Loss                   2.03974
trainer/Policy Loss               75.727
trainer/Q1 Predictions Mean      -74.568
trainer/Q1 Predictions Std        13.9099
trainer/Q1 Predictions Max       -61.6779
trainer/Q1 Predictions Min      -133.534
trainer/Q2 Predictions Mean      -74.6156
trainer/Q2 Predictions Std        13.9668
trainer/Q2 Predictions Max       -61.7364
trainer/Q2 Predictions Min      -133.593
trainer/Q Targets Mean           -75.9202
trainer/Q Targets Std             14.2705
trainer/Q Targets Max            -62.9552
trainer/Q Targets Min           -137.918
trainer/Log Pis Mean               2.04981
trainer/Log Pis Std                1.26977
trainer/Log Pis Max                5.68041
trainer/Log Pis Min               -2.875
trainer/Policy mu Mean            -0.019292
trainer/Policy mu Std              0.85115
trainer/Policy mu Max              3.11232
trainer/Policy mu Min             -2.86859
trainer/Policy log std Mean       -1.9259
trainer/Policy log std Std         0.542645
trainer/Policy log std Max        -0.387786
trainer/Policy log std Min        -2.56237
trainer/Alpha                      0.0668265
trainer/Alpha Loss                 0.134772
exploration/num steps total    16800
exploration/num paths total      168
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.09976
exploration/Rewards Std            0.22407
exploration/Rewards Max           -0.834705
exploration/Rewards Min           -3.50936
exploration/Returns Mean        -109.976
exploration/Returns Std            2.17148
exploration/Returns Max         -107.805
exploration/Returns Min         -112.148
exploration/Actions Mean          -0.00959654
exploration/Actions Std            0.164491
exploration/Actions Max            0.763102
exploration/Actions Min           -0.997561
exploration/Num Paths              2
exploration/Average Returns     -109.976
evaluation/num steps total     83000
evaluation/num paths total       830
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.36467
evaluation/Rewards Std             0.667179
evaluation/Rewards Max            -0.160565
evaluation/Rewards Min            -8.96749
evaluation/Returns Mean         -136.467
evaluation/Returns Std            21.0798
evaluation/Returns Max          -115.682
evaluation/Returns Min          -179.332
evaluation/Actions Mean            6.02958e-05
evaluation/Actions Std             0.174049
evaluation/Actions Max             0.993226
evaluation/Actions Min            -0.990183
evaluation/Num Paths              10
evaluation/Average Returns      -136.467
time/data storing (s)              0.00157166
time/evaluation sampling (s)       0.224323
time/exploration sampling (s)      0.0652424
time/logging (s)                   0.00340046
time/saving (s)                    0.00219952
time/training (s)                  0.750659
time/epoch (s)                     1.0474
time/total (s)                    88.3162
Epoch                             82
-----------------------------  ---------------
2019-04-21 01:13:12.563549 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size             17000
trainer/QF1 Loss                  38.0645
trainer/QF2 Loss                  38.3236
trainer/Policy Loss               72.8435
trainer/Q1 Predictions Mean      -71.8945
trainer/Q1 Predictions Std        11.8091
trainer/Q1 Predictions Max       -61.9372
trainer/Q1 Predictions Min      -109.693
trainer/Q2 Predictions Mean      -71.9362
trainer/Q2 Predictions Std        11.7954
trainer/Q2 Predictions Max       -61.9848
trainer/Q2 Predictions Min      -110.104
trainer/Q Targets Mean           -72.0564
trainer/Q Targets Std             13.7026
trainer/Q Targets Max             -1.32633
trainer/Q Targets Min           -112.806
trainer/Log Pis Mean               1.93267
trainer/Log Pis Std                1.09234
trainer/Log Pis Max                4.41836
trainer/Log Pis Min               -2.05475
trainer/Policy mu Mean             0.000710892
trainer/Policy mu Std              0.739088
trainer/Policy mu Max              2.67095
trainer/Policy mu Min             -2.76675
trainer/Policy log std Mean       -2.00874
trainer/Policy log std Std         0.503678
trainer/Policy log std Max        -0.485423
trainer/Policy log std Min        -2.55574
trainer/Alpha                      0.0672442
trainer/Alpha Loss                -0.181773
exploration/num steps total    17000
exploration/num paths total      170
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.2412
exploration/Rewards Std            0.45699
exploration/Rewards Max           -0.325273
exploration/Rewards Min           -4.7283
exploration/Returns Mean        -124.12
exploration/Returns Std            2.57721
exploration/Returns Max         -121.543
exploration/Returns Min         -126.697
exploration/Actions Mean          -0.0235054
exploration/Actions Std            0.207967
exploration/Actions Max            0.872493
exploration/Actions Min           -0.993041
exploration/Num Paths              2
exploration/Average Returns     -124.12
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.34701
evaluation/Rewards Std             0.832853
evaluation/Rewards Max            -0.525909
evaluation/Rewards Min            -9.66468
evaluation/Returns Mean         -134.701
evaluation/Returns Std            10.6593
evaluation/Returns Max          -119.082
evaluation/Returns Min          -153.593
evaluation/Actions Mean           -0.0196932
evaluation/Actions Std             0.188984
evaluation/Actions Max             0.992114
evaluation/Actions Min            -0.994951
evaluation/Num Paths              10
evaluation/Average Returns      -134.701
time/data storing (s)              0.00123331
time/evaluation sampling (s)       0.2197
time/exploration sampling (s)      0.06569
time/logging (s)                   0.00275817
time/saving (s)                    0.00195122
time/training (s)                  0.768787
time/epoch (s)                     1.06012
time/total (s)                    89.3803
Epoch                             83
-----------------------------  ---------------
2019-04-21 01:13:13.632910 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 84 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                 105.133
trainer/QF2 Loss                 105.27
trainer/Policy Loss               76.4524
trainer/Q1 Predictions Mean      -75.2694
trainer/Q1 Predictions Std        12.0965
trainer/Q1 Predictions Max       -62.2286
trainer/Q1 Predictions Min      -126.092
trainer/Q2 Predictions Mean      -75.2904
trainer/Q2 Predictions Std        12.0971
trainer/Q2 Predictions Max       -62.2296
trainer/Q2 Predictions Min      -125.473
trainer/Q Targets Mean           -74.1508
trainer/Q Targets Std             15.953
trainer/Q Targets Max             -1.79784
trainer/Q Targets Min           -129.548
trainer/Log Pis Mean               1.98328
trainer/Log Pis Std                1.36497
trainer/Log Pis Max                5.26124
trainer/Log Pis Min               -1.64682
trainer/Policy mu Mean             0.0212788
trainer/Policy mu Std              0.837837
trainer/Policy mu Max              2.95501
trainer/Policy mu Min             -2.76194
trainer/Policy log std Mean       -1.93292
trainer/Policy log std Std         0.550382
trainer/Policy log std Max        -0.376163
trainer/Policy log std Min        -2.65885
trainer/Alpha                      0.0691206
trainer/Alpha Loss                -0.0446856
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.18868
exploration/Rewards Std            0.605339
exploration/Rewards Max           -0.582723
exploration/Rewards Min           -5.92621
exploration/Returns Mean        -118.868
exploration/Returns Std            0.97192
exploration/Returns Max         -117.896
exploration/Returns Min         -119.84
exploration/Actions Mean           0.00864989
exploration/Actions Std            0.232787
exploration/Actions Max            0.94083
exploration/Actions Min           -0.958357
exploration/Num Paths              2
exploration/Average Returns     -118.868
evaluation/num steps total     85000
evaluation/num paths total       850
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.15988
evaluation/Rewards Std             0.643381
evaluation/Rewards Max            -0.678573
evaluation/Rewards Min            -8.77143
evaluation/Returns Mean         -115.988
evaluation/Returns Std             9.29096
evaluation/Returns Max          -104.047
evaluation/Returns Min          -137.035
evaluation/Actions Mean           -0.0186006
evaluation/Actions Std             0.169401
evaluation/Actions Max             0.979711
evaluation/Actions Min            -0.992865
evaluation/Num Paths              10
evaluation/Average Returns      -115.988
time/data storing (s)              0.00120409
time/evaluation sampling (s)       0.225678
time/exploration sampling (s)      0.0633547
time/logging (s)                   0.0033637
time/saving (s)                    0.00195074
time/training (s)                  0.768662
time/epoch (s)                     1.06421
time/total (s)                    90.4485
Epoch                             84
-----------------------------  --------------
2019-04-21 01:13:14.702472 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 85 finished
-----------------------------  --------------
replay_buffer/size             17400
trainer/QF1 Loss                  95.063
trainer/QF2 Loss                  94.8796
trainer/Policy Loss               75.4224
trainer/Q1 Predictions Mean      -74.4567
trainer/Q1 Predictions Std        12.1983
trainer/Q1 Predictions Max       -62.3436
trainer/Q1 Predictions Min      -123.616
trainer/Q2 Predictions Mean      -74.4131
trainer/Q2 Predictions Std        12.1358
trainer/Q2 Predictions Max       -62.3541
trainer/Q2 Predictions Min      -123.71
trainer/Q Targets Mean           -73.4258
trainer/Q Targets Std             15.8743
trainer/Q Targets Max             -0.980997
trainer/Q Targets Min           -125.19
trainer/Log Pis Mean               1.81547
trainer/Log Pis Std                1.42111
trainer/Log Pis Max                6.41661
trainer/Log Pis Min               -3.09079
trainer/Policy mu Mean             0.0130201
trainer/Policy mu Std              0.80169
trainer/Policy mu Max              2.20735
trainer/Policy mu Min             -3.06664
trainer/Policy log std Mean       -1.93923
trainer/Policy log std Std         0.527829
trainer/Policy log std Max        -0.493612
trainer/Policy log std Min        -2.56151
trainer/Alpha                      0.0694705
trainer/Alpha Loss                -0.492094
exploration/num steps total    17400
exploration/num paths total      174
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.10348
exploration/Rewards Std            0.155184
exploration/Rewards Max           -0.805906
exploration/Rewards Min           -2.4921
exploration/Returns Mean        -110.348
exploration/Returns Std            1.33362
exploration/Returns Max         -109.014
exploration/Returns Min         -111.681
exploration/Actions Mean           0.00469813
exploration/Actions Std            0.152112
exploration/Actions Max            0.971711
exploration/Actions Min           -0.482841
exploration/Num Paths              2
exploration/Average Returns     -110.348
evaluation/num steps total     86000
evaluation/num paths total       860
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.12943
evaluation/Rewards Std             0.760721
evaluation/Rewards Max            -0.209993
evaluation/Rewards Min           -11.1931
evaluation/Returns Mean         -112.943
evaluation/Returns Std            12.6874
evaluation/Returns Max           -98.5943
evaluation/Returns Min          -141.654
evaluation/Actions Mean            0.00689721
evaluation/Actions Std             0.169181
evaluation/Actions Max             0.996273
evaluation/Actions Min            -0.987879
evaluation/Num Paths              10
evaluation/Average Returns      -112.943
time/data storing (s)              0.00148307
time/evaluation sampling (s)       0.229137
time/exploration sampling (s)      0.0654586
time/logging (s)                   0.0030357
time/saving (s)                    0.00199539
time/training (s)                  0.762224
time/epoch (s)                     1.06333
time/total (s)                    91.5159
Epoch                             85
-----------------------------  --------------
2019-04-21 01:13:15.767991 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 86 finished
-----------------------------  --------------
replay_buffer/size             17600
trainer/QF1 Loss                  66.5143
trainer/QF2 Loss                  66.7412
trainer/Policy Loss               73.5417
trainer/Q1 Predictions Mean      -72.2325
trainer/Q1 Predictions Std        10.3306
trainer/Q1 Predictions Max       -61.4059
trainer/Q1 Predictions Min       -98.2442
trainer/Q2 Predictions Mean      -72.2068
trainer/Q2 Predictions Std        10.3221
trainer/Q2 Predictions Max       -61.4029
trainer/Q2 Predictions Min       -98.2051
trainer/Q Targets Mean           -72.2142
trainer/Q Targets Std             12.3646
trainer/Q Targets Max             -1.28409
trainer/Q Targets Min            -99.8377
trainer/Log Pis Mean               1.92964
trainer/Log Pis Std                1.12878
trainer/Log Pis Max                4.58453
trainer/Log Pis Min               -3.08926
trainer/Policy mu Mean            -0.0247513
trainer/Policy mu Std              0.695951
trainer/Policy mu Max              2.38399
trainer/Policy mu Min             -2.62481
trainer/Policy log std Mean       -1.97441
trainer/Policy log std Std         0.49677
trainer/Policy log std Max        -0.156493
trainer/Policy log std Min        -2.5987
trainer/Alpha                      0.0689373
trainer/Alpha Loss                -0.188167
exploration/num steps total    17600
exploration/num paths total      176
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.4687
exploration/Rewards Std            1.15595
exploration/Rewards Max           -0.745191
exploration/Rewards Min           -8.79598
exploration/Returns Mean        -146.87
exploration/Returns Std            3.25895
exploration/Returns Max         -143.611
exploration/Returns Min         -150.129
exploration/Actions Mean          -0.00957119
exploration/Actions Std            0.266138
exploration/Actions Max            0.997835
exploration/Actions Min           -0.988768
exploration/Num Paths              2
exploration/Average Returns     -146.87
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.24326
evaluation/Rewards Std             0.503094
evaluation/Rewards Max            -0.580588
evaluation/Rewards Min            -7.09946
evaluation/Returns Mean         -124.326
evaluation/Returns Std             7.28521
evaluation/Returns Max          -114.908
evaluation/Returns Min          -138.877
evaluation/Actions Mean           -0.00100241
evaluation/Actions Std             0.157365
evaluation/Actions Max             0.991463
evaluation/Actions Min            -0.988631
evaluation/Num Paths              10
evaluation/Average Returns      -124.326
time/data storing (s)              0.00133578
time/evaluation sampling (s)       0.221328
time/exploration sampling (s)      0.0640595
time/logging (s)                   0.00338721
time/saving (s)                    0.00198215
time/training (s)                  0.767902
time/epoch (s)                     1.06
time/total (s)                    92.58
Epoch                             86
-----------------------------  --------------
2019-04-21 01:13:16.827569 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 87 finished
-----------------------------  --------------
replay_buffer/size             17800
trainer/QF1 Loss                   1.11503
trainer/QF2 Loss                   1.20536
trainer/Policy Loss               74.6811
trainer/Q1 Predictions Mean      -73.8937
trainer/Q1 Predictions Std        13.3759
trainer/Q1 Predictions Max       -61.5022
trainer/Q1 Predictions Min      -127.861
trainer/Q2 Predictions Mean      -73.9023
trainer/Q2 Predictions Std        13.4427
trainer/Q2 Predictions Max       -61.5099
trainer/Q2 Predictions Min      -128.186
trainer/Q Targets Mean           -74.749
trainer/Q Targets Std             13.3401
trainer/Q Targets Max            -62.1719
trainer/Q Targets Min           -125.678
trainer/Log Pis Mean               1.93474
trainer/Log Pis Std                1.10284
trainer/Log Pis Max                4.82907
trainer/Log Pis Min               -0.7115
trainer/Policy mu Mean            -0.0674379
trainer/Policy mu Std              0.893795
trainer/Policy mu Max              2.56957
trainer/Policy mu Min             -2.87998
trainer/Policy log std Mean       -1.85793
trainer/Policy log std Std         0.575963
trainer/Policy log std Max        -0.165873
trainer/Policy log std Min        -2.57311
trainer/Alpha                      0.067196
trainer/Alpha Loss                -0.176218
exploration/num steps total    17800
exploration/num paths total      178
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.23617
exploration/Rewards Std            0.4964
exploration/Rewards Max           -0.615987
exploration/Rewards Min           -5.75727
exploration/Returns Mean        -123.617
exploration/Returns Std            8.34046
exploration/Returns Max         -115.277
exploration/Returns Min         -131.958
exploration/Actions Mean           0.0143515
exploration/Actions Std            0.196415
exploration/Actions Max            0.976742
exploration/Actions Min           -0.964742
exploration/Num Paths              2
exploration/Average Returns     -123.617
evaluation/num steps total     88000
evaluation/num paths total       880
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.26919
evaluation/Rewards Std             0.874986
evaluation/Rewards Max            -0.826668
evaluation/Rewards Min            -9.71051
evaluation/Returns Mean         -126.919
evaluation/Returns Std            10.2641
evaluation/Returns Max          -112.794
evaluation/Returns Min          -144.08
evaluation/Actions Mean            0.0117959
evaluation/Actions Std             0.186901
evaluation/Actions Max             0.995962
evaluation/Actions Min            -0.977668
evaluation/Num Paths              10
evaluation/Average Returns      -126.919
time/data storing (s)              0.00128907
time/evaluation sampling (s)       0.224806
time/exploration sampling (s)      0.0627653
time/logging (s)                   0.00357227
time/saving (s)                    0.00197408
time/training (s)                  0.759486
time/epoch (s)                     1.05389
time/total (s)                    93.6381
Epoch                             87
-----------------------------  --------------
2019-04-21 01:13:17.913756 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 88 finished
-----------------------------  --------------
replay_buffer/size             18000
trainer/QF1 Loss                 190.376
trainer/QF2 Loss                 189.593
trainer/Policy Loss               75.4793
trainer/Q1 Predictions Mean      -74.2677
trainer/Q1 Predictions Std        12.2676
trainer/Q1 Predictions Max       -61.3
trainer/Q1 Predictions Min      -114.856
trainer/Q2 Predictions Mean      -74.2443
trainer/Q2 Predictions Std        12.2505
trainer/Q2 Predictions Max       -61.3342
trainer/Q2 Predictions Min      -114.763
trainer/Q Targets Mean           -72.4805
trainer/Q Targets Std             16.8009
trainer/Q Targets Max             -2.16532
trainer/Q Targets Min           -114.531
trainer/Log Pis Mean               1.81935
trainer/Log Pis Std                1.39539
trainer/Log Pis Max                5.37574
trainer/Log Pis Min               -2.66265
trainer/Policy mu Mean             0.0089503
trainer/Policy mu Std              0.852985
trainer/Policy mu Max              2.79307
trainer/Policy mu Min             -2.74683
trainer/Policy log std Mean       -1.86555
trainer/Policy log std Std         0.531471
trainer/Policy log std Max        -0.439919
trainer/Policy log std Min        -2.53429
trainer/Alpha                      0.0652583
trainer/Alpha Loss                -0.493043
exploration/num steps total    18000
exploration/num paths total      180
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.55962
exploration/Rewards Std            0.97606
exploration/Rewards Max           -0.864569
exploration/Rewards Min           -7.66336
exploration/Returns Mean        -155.962
exploration/Returns Std           25.3815
exploration/Returns Max         -130.58
exploration/Returns Min         -181.343
exploration/Actions Mean           0.00196511
exploration/Actions Std            0.259574
exploration/Actions Max            0.995803
exploration/Actions Min           -0.997788
exploration/Num Paths              2
exploration/Average Returns     -155.962
evaluation/num steps total     89000
evaluation/num paths total       890
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.32962
evaluation/Rewards Std             0.631435
evaluation/Rewards Max            -0.996484
evaluation/Rewards Min            -7.01362
evaluation/Returns Mean         -132.962
evaluation/Returns Std            28.3402
evaluation/Returns Max          -103.14
evaluation/Returns Min          -174.064
evaluation/Actions Mean           -0.00225496
evaluation/Actions Std             0.165122
evaluation/Actions Max             0.989777
evaluation/Actions Min            -0.991647
evaluation/Num Paths              10
evaluation/Average Returns      -132.962
time/data storing (s)              0.00137299
time/evaluation sampling (s)       0.236226
time/exploration sampling (s)      0.0622972
time/logging (s)                   0.00317126
time/saving (s)                    0.00991378
time/training (s)                  0.766576
time/epoch (s)                     1.07956
time/total (s)                    94.7217
Epoch                             88
-----------------------------  --------------
2019-04-21 01:13:18.978894 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 89 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                 102.464
trainer/QF2 Loss                 101.831
trainer/Policy Loss               74.7149
trainer/Q1 Predictions Mean      -73.4913
trainer/Q1 Predictions Std        12.6208
trainer/Q1 Predictions Max       -61.3854
trainer/Q1 Predictions Min      -129.988
trainer/Q2 Predictions Mean      -73.4819
trainer/Q2 Predictions Std        12.5964
trainer/Q2 Predictions Max       -61.3986
trainer/Q2 Predictions Min      -129.879
trainer/Q Targets Mean           -72.7958
trainer/Q Targets Std             16.095
trainer/Q Targets Max             -1.16019
trainer/Q Targets Min           -126.597
trainer/Log Pis Mean               2.09754
trainer/Log Pis Std                1.14491
trainer/Log Pis Max                5.43165
trainer/Log Pis Min               -0.839672
trainer/Policy mu Mean            -0.035436
trainer/Policy mu Std              0.834353
trainer/Policy mu Max              2.66148
trainer/Policy mu Min             -3.10978
trainer/Policy log std Mean       -1.902
trainer/Policy log std Std         0.55946
trainer/Policy log std Max        -0.254893
trainer/Policy log std Min        -2.5924
trainer/Alpha                      0.0658307
trainer/Alpha Loss                 0.265364
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.2974
exploration/Rewards Std            0.860199
exploration/Rewards Max           -0.796639
exploration/Rewards Min           -8.2745
exploration/Returns Mean        -129.74
exploration/Returns Std           24.1367
exploration/Returns Max         -105.603
exploration/Returns Min         -153.876
exploration/Actions Mean           0.024692
exploration/Actions Std            0.211394
exploration/Actions Max            0.998676
exploration/Actions Min           -0.554384
exploration/Num Paths              2
exploration/Average Returns     -129.74
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.33255
evaluation/Rewards Std             0.975807
evaluation/Rewards Max            -0.641104
evaluation/Rewards Min           -10.3804
evaluation/Returns Mean         -133.255
evaluation/Returns Std            16.8113
evaluation/Returns Max          -109.876
evaluation/Returns Min          -164.029
evaluation/Actions Mean            0.0159768
evaluation/Actions Std             0.191775
evaluation/Actions Max             0.996864
evaluation/Actions Min            -0.990882
evaluation/Num Paths              10
evaluation/Average Returns      -133.255
time/data storing (s)              0.00145114
time/evaluation sampling (s)       0.215024
time/exploration sampling (s)      0.062481
time/logging (s)                   0.00342879
time/saving (s)                    0.00194044
time/training (s)                  0.775192
time/epoch (s)                     1.05952
time/total (s)                    95.7855
Epoch                             89
-----------------------------  --------------
2019-04-21 01:13:20.049990 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 90 finished
-----------------------------  --------------
replay_buffer/size             18400
trainer/QF1 Loss                  66.4676
trainer/QF2 Loss                  66.6331
trainer/Policy Loss               74.9565
trainer/Q1 Predictions Mean      -73.5957
trainer/Q1 Predictions Std        14.7304
trainer/Q1 Predictions Max       -61.44
trainer/Q1 Predictions Min      -135.906
trainer/Q2 Predictions Mean      -73.5586
trainer/Q2 Predictions Std        14.6864
trainer/Q2 Predictions Max       -61.3492
trainer/Q2 Predictions Min      -134.845
trainer/Q Targets Mean           -73.0049
trainer/Q Targets Std             16.3779
trainer/Q Targets Max             -1.90755
trainer/Q Targets Min           -138.99
trainer/Log Pis Mean               2.39785
trainer/Log Pis Std                1.29137
trainer/Log Pis Max                6.11702
trainer/Log Pis Min               -2.67975
trainer/Policy mu Mean            -0.00703864
trainer/Policy mu Std              0.904243
trainer/Policy mu Max              2.91178
trainer/Policy mu Min             -2.86266
trainer/Policy log std Mean       -1.9609
trainer/Policy log std Std         0.572448
trainer/Policy log std Max        -0.429781
trainer/Policy log std Min        -2.65034
trainer/Alpha                      0.0645809
trainer/Alpha Loss                 1.0901
exploration/num steps total    18400
exploration/num paths total      184
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.20006
exploration/Rewards Std            0.671365
exploration/Rewards Max           -0.657168
exploration/Rewards Min           -6.06617
exploration/Returns Mean        -120.006
exploration/Returns Std            2.29473
exploration/Returns Max         -117.711
exploration/Returns Min         -122.301
exploration/Actions Mean          -0.0229279
exploration/Actions Std            0.238739
exploration/Actions Max            0.976532
exploration/Actions Min           -0.985133
exploration/Num Paths              2
exploration/Average Returns     -120.006
evaluation/num steps total     91000
evaluation/num paths total       910
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.1599
evaluation/Rewards Std             0.713169
evaluation/Rewards Max            -0.714367
evaluation/Rewards Min            -9.91561
evaluation/Returns Mean         -115.99
evaluation/Returns Std            13.9629
evaluation/Returns Max          -101.668
evaluation/Returns Min          -151.173
evaluation/Actions Mean            0.0068923
evaluation/Actions Std             0.164733
evaluation/Actions Max             0.99478
evaluation/Actions Min            -0.990791
evaluation/Num Paths              10
evaluation/Average Returns      -115.99
time/data storing (s)              0.00122117
time/evaluation sampling (s)       0.226017
time/exploration sampling (s)      0.0637781
time/logging (s)                   0.00334715
time/saving (s)                    0.0019675
time/training (s)                  0.768504
time/epoch (s)                     1.06483
time/total (s)                    96.8546
Epoch                             90
-----------------------------  --------------
2019-04-21 01:13:21.124413 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 91 finished
-----------------------------  --------------
replay_buffer/size             18600
trainer/QF1 Loss                   1.86188
trainer/QF2 Loss                   1.88953
trainer/Policy Loss               73.2504
trainer/Q1 Predictions Mean      -72.2601
trainer/Q1 Predictions Std        13.0236
trainer/Q1 Predictions Max       -60.481
trainer/Q1 Predictions Min      -121.464
trainer/Q2 Predictions Mean      -72.2916
trainer/Q2 Predictions Std        13.0094
trainer/Q2 Predictions Max       -60.4561
trainer/Q2 Predictions Min      -120.915
trainer/Q Targets Mean           -73.5205
trainer/Q Targets Std             13.0962
trainer/Q Targets Max            -61.6458
trainer/Q Targets Min           -124.179
trainer/Log Pis Mean               1.90363
trainer/Log Pis Std                1.22388
trainer/Log Pis Max                5.0632
trainer/Log Pis Min               -2.14145
trainer/Policy mu Mean             0.0308769
trainer/Policy mu Std              0.760856
trainer/Policy mu Max              2.86322
trainer/Policy mu Min             -3.00477
trainer/Policy log std Mean       -1.97596
trainer/Policy log std Std         0.537897
trainer/Policy log std Max        -0.223895
trainer/Policy log std Min        -2.62329
trainer/Alpha                      0.066405
trainer/Alpha Loss                -0.261345
exploration/num steps total    18600
exploration/num paths total      186
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.32855
exploration/Rewards Std            0.806749
exploration/Rewards Max           -0.525061
exploration/Rewards Min           -6.96806
exploration/Returns Mean        -132.855
exploration/Returns Std            0.911355
exploration/Returns Max         -131.944
exploration/Returns Min         -133.767
exploration/Actions Mean           0.0171303
exploration/Actions Std            0.263034
exploration/Actions Max            0.996343
exploration/Actions Min           -0.943658
exploration/Num Paths              2
exploration/Average Returns     -132.855
evaluation/num steps total     92000
evaluation/num paths total       920
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.31692
evaluation/Rewards Std             0.970001
evaluation/Rewards Max            -0.415822
evaluation/Rewards Min           -10.4442
evaluation/Returns Mean         -131.692
evaluation/Returns Std            17.0189
evaluation/Returns Max          -112.73
evaluation/Returns Min          -159.643
evaluation/Actions Mean           -0.0272624
evaluation/Actions Std             0.185141
evaluation/Actions Max             0.986754
evaluation/Actions Min            -0.995172
evaluation/Num Paths              10
evaluation/Average Returns      -131.692
time/data storing (s)              0.00122816
time/evaluation sampling (s)       0.221942
time/exploration sampling (s)      0.0636514
time/logging (s)                   0.00336475
time/saving (s)                    0.00744092
time/training (s)                  0.770672
time/epoch (s)                     1.0683
time/total (s)                    97.9272
Epoch                             91
-----------------------------  --------------
2019-04-21 01:13:22.190322 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 92 finished
-----------------------------  --------------
replay_buffer/size             18800
trainer/QF1 Loss                   0.308773
trainer/QF2 Loss                   0.322943
trainer/Policy Loss               73.8826
trainer/Q1 Predictions Mean      -72.6056
trainer/Q1 Predictions Std        11.9308
trainer/Q1 Predictions Max       -60.9756
trainer/Q1 Predictions Min      -117.236
trainer/Q2 Predictions Mean      -72.6328
trainer/Q2 Predictions Std        11.9231
trainer/Q2 Predictions Max       -60.9435
trainer/Q2 Predictions Min      -116.734
trainer/Q Targets Mean           -72.9292
trainer/Q Targets Std             11.9339
trainer/Q Targets Max            -61.2828
trainer/Q Targets Min           -118.221
trainer/Log Pis Mean               1.91551
trainer/Log Pis Std                1.07522
trainer/Log Pis Max                5.51494
trainer/Log Pis Min               -1.17279
trainer/Policy mu Mean             0.110292
trainer/Policy mu Std              0.65595
trainer/Policy mu Max              2.90155
trainer/Policy mu Min             -2.2562
trainer/Policy log std Mean       -2.05071
trainer/Policy log std Std         0.485947
trainer/Policy log std Max        -0.396515
trainer/Policy log std Min        -2.6025
trainer/Alpha                      0.0660482
trainer/Alpha Loss                -0.2296
exploration/num steps total    18800
exploration/num paths total      188
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.20118
exploration/Rewards Std            0.850737
exploration/Rewards Max           -0.662918
exploration/Rewards Min           -8.1968
exploration/Returns Mean        -120.118
exploration/Returns Std           14.7973
exploration/Returns Max         -105.321
exploration/Returns Min         -134.915
exploration/Actions Mean           0.0201034
exploration/Actions Std            0.225533
exploration/Actions Max            0.99918
exploration/Actions Min           -0.90778
exploration/Num Paths              2
exploration/Average Returns     -120.118
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.34362
evaluation/Rewards Std             1.00704
evaluation/Rewards Max            -0.772044
evaluation/Rewards Min           -10.9209
evaluation/Returns Mean         -134.362
evaluation/Returns Std            15.6422
evaluation/Returns Max          -117.077
evaluation/Returns Min          -164.167
evaluation/Actions Mean           -0.00720826
evaluation/Actions Std             0.201113
evaluation/Actions Max             0.995947
evaluation/Actions Min            -0.994552
evaluation/Num Paths              10
evaluation/Average Returns      -134.362
time/data storing (s)              0.00178039
time/evaluation sampling (s)       0.221945
time/exploration sampling (s)      0.0641911
time/logging (s)                   0.003338
time/saving (s)                    0.0019545
time/training (s)                  0.76646
time/epoch (s)                     1.05967
time/total (s)                    98.9912
Epoch                             92
-----------------------------  --------------
2019-04-21 01:13:23.258427 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 93 finished
-----------------------------  --------------
replay_buffer/size             19000
trainer/QF1 Loss                  97.2284
trainer/QF2 Loss                  96.0147
trainer/Policy Loss               74.3501
trainer/Q1 Predictions Mean      -73.2344
trainer/Q1 Predictions Std        14.6313
trainer/Q1 Predictions Max       -60.3001
trainer/Q1 Predictions Min      -131.175
trainer/Q2 Predictions Mean      -73.2466
trainer/Q2 Predictions Std        14.6305
trainer/Q2 Predictions Max       -60.28
trainer/Q2 Predictions Min      -131.212
trainer/Q Targets Mean           -73.3697
trainer/Q Targets Std             15.4541
trainer/Q Targets Max             -9.00678
trainer/Q Targets Min           -125.85
trainer/Log Pis Mean               2.10453
trainer/Log Pis Std                1.37427
trainer/Log Pis Max                4.96013
trainer/Log Pis Min               -2.14752
trainer/Policy mu Mean             0.056054
trainer/Policy mu Std              0.953247
trainer/Policy mu Max              2.88125
trainer/Policy mu Min             -3.23455
trainer/Policy log std Mean       -1.90021
trainer/Policy log std Std         0.620874
trainer/Policy log std Max        -0.430229
trainer/Policy log std Min        -2.62066
trainer/Alpha                      0.0662071
trainer/Alpha Loss                 0.2838
exploration/num steps total    19000
exploration/num paths total      190
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.17804
exploration/Rewards Std            0.680124
exploration/Rewards Max           -0.689979
exploration/Rewards Min           -6.05157
exploration/Returns Mean        -117.804
exploration/Returns Std            1.27928
exploration/Returns Max         -116.525
exploration/Returns Min         -119.084
exploration/Actions Mean          -0.00440833
exploration/Actions Std            0.209303
exploration/Actions Max            0.959927
exploration/Actions Min           -0.99241
exploration/Num Paths              2
exploration/Average Returns     -117.804
evaluation/num steps total     94000
evaluation/num paths total       940
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.22566
evaluation/Rewards Std             1.00524
evaluation/Rewards Max            -0.48499
evaluation/Rewards Min           -10.3296
evaluation/Returns Mean         -122.566
evaluation/Returns Std            13.223
evaluation/Returns Max          -101.665
evaluation/Returns Min          -147.545
evaluation/Actions Mean           -0.00697179
evaluation/Actions Std             0.198825
evaluation/Actions Max             0.996251
evaluation/Actions Min            -0.99134
evaluation/Num Paths              10
evaluation/Average Returns      -122.566
time/data storing (s)              0.00140595
time/evaluation sampling (s)       0.224519
time/exploration sampling (s)      0.0632612
time/logging (s)                   0.00336371
time/saving (s)                    0.00193423
time/training (s)                  0.767348
time/epoch (s)                     1.06183
time/total (s)                   100.057
Epoch                             93
-----------------------------  --------------
2019-04-21 01:13:24.336292 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 94 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   0.667285
trainer/QF2 Loss                   0.803123
trainer/Policy Loss               73.8365
trainer/Q1 Predictions Mean      -72.6487
trainer/Q1 Predictions Std        10.2375
trainer/Q1 Predictions Max       -60.3613
trainer/Q1 Predictions Min       -92.7457
trainer/Q2 Predictions Mean      -72.6176
trainer/Q2 Predictions Std        10.1961
trainer/Q2 Predictions Max       -60.3441
trainer/Q2 Predictions Min       -92.7087
trainer/Q Targets Mean           -73.269
trainer/Q Targets Std             10.0813
trainer/Q Targets Max            -61.1268
trainer/Q Targets Min            -92.7439
trainer/Log Pis Mean               1.87564
trainer/Log Pis Std                1.03115
trainer/Log Pis Max                4.7326
trainer/Log Pis Min               -1.58889
trainer/Policy mu Mean            -0.0875128
trainer/Policy mu Std              0.795007
trainer/Policy mu Max              2.59296
trainer/Policy mu Min             -2.58678
trainer/Policy log std Mean       -1.89048
trainer/Policy log std Std         0.5439
trainer/Policy log std Max        -0.299148
trainer/Policy log std Min        -2.57965
trainer/Alpha                      0.0664702
trainer/Alpha Loss                -0.337122
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.23326
exploration/Rewards Std            0.201211
exploration/Rewards Max           -0.740338
exploration/Rewards Min           -2.68242
exploration/Returns Mean        -123.326
exploration/Returns Std            0.83705
exploration/Returns Max         -122.489
exploration/Returns Min         -124.163
exploration/Actions Mean          -0.0016849
exploration/Actions Std            0.187114
exploration/Actions Max            0.956189
exploration/Actions Min           -0.872196
exploration/Num Paths              2
exploration/Average Returns     -123.326
evaluation/num steps total     95000
evaluation/num paths total       950
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.32769
evaluation/Rewards Std             0.992186
evaluation/Rewards Max            -0.821545
evaluation/Rewards Min            -9.84839
evaluation/Returns Mean         -132.769
evaluation/Returns Std            16.3401
evaluation/Returns Max          -108.429
evaluation/Returns Min          -158.9
evaluation/Actions Mean           -0.00108746
evaluation/Actions Std             0.202919
evaluation/Actions Max             0.99527
evaluation/Actions Min            -0.993654
evaluation/Num Paths              10
evaluation/Average Returns      -132.769
time/data storing (s)              0.00123269
time/evaluation sampling (s)       0.227427
time/exploration sampling (s)      0.0651402
time/logging (s)                   0.00342046
time/saving (s)                    0.00207814
time/training (s)                  0.772402
time/epoch (s)                     1.0717
time/total (s)                   101.133
Epoch                             94
-----------------------------  --------------
2019-04-21 01:13:25.388504 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 95 finished
-----------------------------  --------------
replay_buffer/size             19400
trainer/QF1 Loss                   1.03583
trainer/QF2 Loss                   0.953797
trainer/Policy Loss               71.2166
trainer/Q1 Predictions Mean      -69.9756
trainer/Q1 Predictions Std        10.983
trainer/Q1 Predictions Max       -60.3637
trainer/Q1 Predictions Min      -107.097
trainer/Q2 Predictions Mean      -70.0062
trainer/Q2 Predictions Std        10.9808
trainer/Q2 Predictions Max       -60.4219
trainer/Q2 Predictions Min      -107.528
trainer/Q Targets Mean           -70.8084
trainer/Q Targets Std             11.2705
trainer/Q Targets Max            -60.9924
trainer/Q Targets Min           -108.574
trainer/Log Pis Mean               1.83226
trainer/Log Pis Std                1.38992
trainer/Log Pis Max                5.17479
trainer/Log Pis Min               -4.53407
trainer/Policy mu Mean            -0.0325201
trainer/Policy mu Std              0.730441
trainer/Policy mu Max              2.69289
trainer/Policy mu Min             -2.19686
trainer/Policy log std Mean       -1.96646
trainer/Policy log std Std         0.507276
trainer/Policy log std Max        -0.543877
trainer/Policy log std Min        -2.53383
trainer/Alpha                      0.0660059
trainer/Alpha Loss                -0.455913
exploration/num steps total    19400
exploration/num paths total      194
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.21853
exploration/Rewards Std            0.842251
exploration/Rewards Max           -0.320411
exploration/Rewards Min           -7.84726
exploration/Returns Mean        -121.853
exploration/Returns Std            5.62222
exploration/Returns Max         -116.231
exploration/Returns Min         -127.476
exploration/Actions Mean          -0.0139622
exploration/Actions Std            0.263882
exploration/Actions Max            0.998437
exploration/Actions Min           -0.992281
exploration/Num Paths              2
exploration/Average Returns     -121.853
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.16676
evaluation/Rewards Std             0.720103
evaluation/Rewards Max            -0.997118
evaluation/Rewards Min            -8.8917
evaluation/Returns Mean         -116.676
evaluation/Returns Std            11.5205
evaluation/Returns Max          -104.97
evaluation/Returns Min          -141.671
evaluation/Actions Mean           -0.00358859
evaluation/Actions Std             0.167196
evaluation/Actions Max             0.993722
evaluation/Actions Min            -0.991697
evaluation/Num Paths              10
evaluation/Average Returns      -116.676
time/data storing (s)              0.00132085
time/evaluation sampling (s)       0.218889
time/exploration sampling (s)      0.065525
time/logging (s)                   0.00338151
time/saving (s)                    0.00196153
time/training (s)                  0.753864
time/epoch (s)                     1.04494
time/total (s)                   102.183
Epoch                             95
-----------------------------  --------------
2019-04-21 01:13:26.451162 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 96 finished
-----------------------------  --------------
replay_buffer/size             19600
trainer/QF1 Loss                  74.511
trainer/QF2 Loss                  74.7716
trainer/Policy Loss               73.7079
trainer/Q1 Predictions Mean      -72.3111
trainer/Q1 Predictions Std        12.9612
trainer/Q1 Predictions Max       -60.6266
trainer/Q1 Predictions Min      -122.756
trainer/Q2 Predictions Mean      -72.3061
trainer/Q2 Predictions Std        12.9065
trainer/Q2 Predictions Max       -60.5785
trainer/Q2 Predictions Min      -122.751
trainer/Q Targets Mean           -71.2814
trainer/Q Targets Std             16.1323
trainer/Q Targets Max             -1.8662
trainer/Q Targets Min           -122.041
trainer/Log Pis Mean               2.23786
trainer/Log Pis Std                1.26172
trainer/Log Pis Max                6.17817
trainer/Log Pis Min               -1.08313
trainer/Policy mu Mean            -0.0656042
trainer/Policy mu Std              0.903716
trainer/Policy mu Max              2.88319
trainer/Policy mu Min             -3.05018
trainer/Policy log std Mean       -1.89991
trainer/Policy log std Std         0.587215
trainer/Policy log std Max        -0.405183
trainer/Policy log std Min        -2.60884
trainer/Alpha                      0.0644496
trainer/Alpha Loss                 0.652191
exploration/num steps total    19600
exploration/num paths total      196
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.26937
exploration/Rewards Std            0.795029
exploration/Rewards Max           -0.693503
exploration/Rewards Min           -7.89133
exploration/Returns Mean        -126.937
exploration/Returns Std            7.49386
exploration/Returns Max         -119.443
exploration/Returns Min         -134.431
exploration/Actions Mean          -0.00308459
exploration/Actions Std            0.221901
exploration/Actions Max            0.962136
exploration/Actions Min           -0.997693
exploration/Num Paths              2
exploration/Average Returns     -126.937
evaluation/num steps total     97000
evaluation/num paths total       970
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.30092
evaluation/Rewards Std             0.875669
evaluation/Rewards Max            -1.054
evaluation/Rewards Min            -8.78322
evaluation/Returns Mean         -130.092
evaluation/Returns Std             9.6593
evaluation/Returns Max          -116.117
evaluation/Returns Min          -149.715
evaluation/Actions Mean           -0.00207999
evaluation/Actions Std             0.184458
evaluation/Actions Max             0.994322
evaluation/Actions Min            -0.992214
evaluation/Num Paths              10
evaluation/Average Returns      -130.092
time/data storing (s)              0.00123338
time/evaluation sampling (s)       0.226528
time/exploration sampling (s)      0.0656084
time/logging (s)                   0.00335156
time/saving (s)                    0.00196722
time/training (s)                  0.759025
time/epoch (s)                     1.05771
time/total (s)                   103.245
Epoch                             96
-----------------------------  --------------
2019-04-21 01:13:27.524291 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 97 finished
-----------------------------  --------------
replay_buffer/size             19800
trainer/QF1 Loss                 126.132
trainer/QF2 Loss                 126.132
trainer/Policy Loss               73.2239
trainer/Q1 Predictions Mean      -72.2276
trainer/Q1 Predictions Std        13.3013
trainer/Q1 Predictions Max       -59.8859
trainer/Q1 Predictions Min      -132.259
trainer/Q2 Predictions Mean      -72.2218
trainer/Q2 Predictions Std        13.289
trainer/Q2 Predictions Max       -59.8561
trainer/Q2 Predictions Min      -132.349
trainer/Q Targets Mean           -71.1218
trainer/Q Targets Std             16.2238
trainer/Q Targets Max             -1.08922
trainer/Q Targets Min           -125.219
trainer/Log Pis Mean               2.03092
trainer/Log Pis Std                1.33542
trainer/Log Pis Max                7.89422
trainer/Log Pis Min               -1.85852
trainer/Policy mu Mean             0.0362755
trainer/Policy mu Std              0.867973
trainer/Policy mu Max              2.75984
trainer/Policy mu Min             -3.13499
trainer/Policy log std Mean       -1.94729
trainer/Policy log std Std         0.534875
trainer/Policy log std Max        -0.427033
trainer/Policy log std Min        -2.5737
trainer/Alpha                      0.0657781
trainer/Alpha Loss                 0.0841427
exploration/num steps total    19800
exploration/num paths total      198
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.19013
exploration/Rewards Std            0.836502
exploration/Rewards Max           -0.429677
exploration/Rewards Min           -7.98196
exploration/Returns Mean        -119.013
exploration/Returns Std           14.094
exploration/Returns Max         -104.919
exploration/Returns Min         -133.107
exploration/Actions Mean          -0.0144478
exploration/Actions Std            0.203589
exploration/Actions Max            0.859721
exploration/Actions Min           -0.996068
exploration/Num Paths              2
exploration/Average Returns     -119.013
evaluation/num steps total     98000
evaluation/num paths total       980
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.08087
evaluation/Rewards Std             0.979997
evaluation/Rewards Max            -0.283659
evaluation/Rewards Min            -9.91581
evaluation/Returns Mean         -108.087
evaluation/Returns Std            23.8874
evaluation/Returns Max           -72.4801
evaluation/Returns Min          -147.787
evaluation/Actions Mean           -0.0169106
evaluation/Actions Std             0.188638
evaluation/Actions Max             0.993433
evaluation/Actions Min            -0.995304
evaluation/Num Paths              10
evaluation/Average Returns      -108.087
time/data storing (s)              0.00133973
time/evaluation sampling (s)       0.222037
time/exploration sampling (s)      0.0657755
time/logging (s)                   0.00336609
time/saving (s)                    0.00193614
time/training (s)                  0.772676
time/epoch (s)                     1.06713
time/total (s)                   104.316
Epoch                             97
-----------------------------  --------------
2019-04-21 01:13:28.599028 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 98 finished
-----------------------------  --------------
replay_buffer/size             20000
trainer/QF1 Loss                   1.59743
trainer/QF2 Loss                   1.51103
trainer/Policy Loss               72.8745
trainer/Q1 Predictions Mean      -71.3389
trainer/Q1 Predictions Std        10.8909
trainer/Q1 Predictions Max       -59.4554
trainer/Q1 Predictions Min      -102.615
trainer/Q2 Predictions Mean      -71.3807
trainer/Q2 Predictions Std        10.9108
trainer/Q2 Predictions Max       -59.4798
trainer/Q2 Predictions Min      -102.367
trainer/Q Targets Mean           -72.4855
trainer/Q Targets Std             10.9297
trainer/Q Targets Max            -60.511
trainer/Q Targets Min           -102.617
trainer/Log Pis Mean               2.13025
trainer/Log Pis Std                1.29844
trainer/Log Pis Max                5.75872
trainer/Log Pis Min               -1.85425
trainer/Policy mu Mean             0.00106922
trainer/Policy mu Std              0.765771
trainer/Policy mu Max              2.70697
trainer/Policy mu Min             -2.44625
trainer/Policy log std Mean       -1.96208
trainer/Policy log std Std         0.493768
trainer/Policy log std Max        -0.486982
trainer/Policy log std Min        -2.61749
trainer/Alpha                      0.0656102
trainer/Alpha Loss                 0.354804
exploration/num steps total    20000
exploration/num paths total      200
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.31072
exploration/Rewards Std            1.04987
exploration/Rewards Max           -0.720201
exploration/Rewards Min           -9.30644
exploration/Returns Mean        -131.072
exploration/Returns Std            7.24619
exploration/Returns Max         -123.826
exploration/Returns Min         -138.318
exploration/Actions Mean          -0.0263359
exploration/Actions Std            0.214501
exploration/Actions Max            0.698011
exploration/Actions Min           -0.993144
exploration/Num Paths              2
exploration/Average Returns     -131.072
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.24289
evaluation/Rewards Std             0.854777
evaluation/Rewards Max            -0.882144
evaluation/Rewards Min            -9.43186
evaluation/Returns Mean         -124.289
evaluation/Returns Std            13.906
evaluation/Returns Max          -103.235
evaluation/Returns Min          -146.423
evaluation/Actions Mean            0.00655179
evaluation/Actions Std             0.172719
evaluation/Actions Max             0.99528
evaluation/Actions Min            -0.990873
evaluation/Num Paths              10
evaluation/Average Returns      -124.289
time/data storing (s)              0.00127936
time/evaluation sampling (s)       0.223739
time/exploration sampling (s)      0.0662776
time/logging (s)                   0.00334603
time/saving (s)                    0.00195442
time/training (s)                  0.772574
time/epoch (s)                     1.06917
time/total (s)                   105.389
Epoch                             98
-----------------------------  --------------
2019-04-21 01:13:29.661664 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              20200
trainer/QF1 Loss                   69.4724
trainer/QF2 Loss                   69.5168
trainer/Policy Loss                72.4995
trainer/Q1 Predictions Mean       -71.3402
trainer/Q1 Predictions Std         12.935
trainer/Q1 Predictions Max        -59.6827
trainer/Q1 Predictions Min       -138.187
trainer/Q2 Predictions Mean       -71.3585
trainer/Q2 Predictions Std         12.8592
trainer/Q2 Predictions Max        -59.6736
trainer/Q2 Predictions Min       -137.233
trainer/Q Targets Mean            -70.4273
trainer/Q Targets Std              16.1311
trainer/Q Targets Max              -1.03713
trainer/Q Targets Min            -138.579
trainer/Log Pis Mean                1.96062
trainer/Log Pis Std                 1.22721
trainer/Log Pis Max                 5.95555
trainer/Log Pis Min                -1.88094
trainer/Policy mu Mean              0.020266
trainer/Policy mu Std               0.78212
trainer/Policy mu Max               3.0794
trainer/Policy mu Min              -2.78424
trainer/Policy log std Mean        -2.02889
trainer/Policy log std Std          0.533385
trainer/Policy log std Max         -0.200261
trainer/Policy log std Min         -2.67774
trainer/Alpha                       0.0672449
trainer/Alpha Loss                 -0.106301
exploration/num steps total     20200
exploration/num paths total       202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.25611
exploration/Rewards Std             1.16167
exploration/Rewards Max            -0.669262
exploration/Rewards Min            -9.90117
exploration/Returns Mean         -125.611
exploration/Returns Std            16.5209
exploration/Returns Max          -109.09
exploration/Returns Min          -142.132
exploration/Actions Mean            0.0355739
exploration/Actions Std             0.246208
exploration/Actions Max             0.99856
exploration/Actions Min            -0.766986
exploration/Num Paths               2
exploration/Average Returns      -125.611
evaluation/num steps total     100000
evaluation/num paths total       1000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.20391
evaluation/Rewards Std              0.962666
evaluation/Rewards Max             -0.273278
evaluation/Rewards Min             -9.74964
evaluation/Returns Mean          -120.391
evaluation/Returns Std             15.7483
evaluation/Returns Max            -93.5184
evaluation/Returns Min           -143.065
evaluation/Actions Mean            -0.0178179
evaluation/Actions Std              0.18714
evaluation/Actions Max              0.99088
evaluation/Actions Min             -0.995551
evaluation/Num Paths               10
evaluation/Average Returns       -120.391
time/data storing (s)               0.00133252
time/evaluation sampling (s)        0.214454
time/exploration sampling (s)       0.0638457
time/logging (s)                    0.0033805
time/saving (s)                     0.00196773
time/training (s)                   0.771625
time/epoch (s)                      1.05661
time/total (s)                    106.45
Epoch                              99
-----------------------------  ---------------
2019-04-21 01:13:30.731802 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              20400
trainer/QF1 Loss                   94.9301
trainer/QF2 Loss                   95.2467
trainer/Policy Loss                72.6029
trainer/Q1 Predictions Mean       -71.0185
trainer/Q1 Predictions Std         13.1013
trainer/Q1 Predictions Max        -59.5409
trainer/Q1 Predictions Min       -132.305
trainer/Q2 Predictions Mean       -71.0208
trainer/Q2 Predictions Std         13.0993
trainer/Q2 Predictions Max        -59.5435
trainer/Q2 Predictions Min       -132.138
trainer/Q Targets Mean            -70.6373
trainer/Q Targets Std              16.5455
trainer/Q Targets Max              -1.17652
trainer/Q Targets Min            -135.527
trainer/Log Pis Mean                2.12026
trainer/Log Pis Std                 1.13549
trainer/Log Pis Max                 5.78204
trainer/Log Pis Min                -1.24477
trainer/Policy mu Mean              0.0600353
trainer/Policy mu Std               0.796467
trainer/Policy mu Max               3.14916
trainer/Policy mu Min              -2.51588
trainer/Policy log std Mean        -1.96639
trainer/Policy log std Std          0.527378
trainer/Policy log std Max         -0.259696
trainer/Policy log std Min         -2.60732
trainer/Alpha                       0.0680348
trainer/Alpha Loss                  0.323229
exploration/num steps total     20400
exploration/num paths total       204
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.0017
exploration/Rewards Std             0.70505
exploration/Rewards Max            -0.170449
exploration/Rewards Min            -7.09009
exploration/Returns Mean         -100.17
exploration/Returns Std             9.32403
exploration/Returns Max           -90.846
exploration/Returns Min          -109.494
exploration/Actions Mean            0.0176458
exploration/Actions Std             0.24212
exploration/Actions Max             0.990519
exploration/Actions Min            -0.981282
exploration/Num Paths               2
exploration/Average Returns      -100.17
evaluation/num steps total     101000
evaluation/num paths total       1010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0554
evaluation/Rewards Std              0.501602
evaluation/Rewards Max             -0.226831
evaluation/Rewards Min             -7.26697
evaluation/Returns Mean          -105.54
evaluation/Returns Std              8.70708
evaluation/Returns Max            -92.0043
evaluation/Returns Min           -116.844
evaluation/Actions Mean             0.00118619
evaluation/Actions Std              0.165599
evaluation/Actions Max              0.99187
evaluation/Actions Min             -0.979128
evaluation/Num Paths               10
evaluation/Average Returns       -105.54
time/data storing (s)               0.00121174
time/evaluation sampling (s)        0.226673
time/exploration sampling (s)       0.0634013
time/logging (s)                    0.00336236
time/saving (s)                     0.00164908
time/training (s)                   0.767792
time/epoch (s)                      1.06409
time/total (s)                    107.518
Epoch                             100
-----------------------------  ---------------
2019-04-21 01:13:31.786239 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              20600
trainer/QF1 Loss                    0.684334
trainer/QF2 Loss                    0.662319
trainer/Policy Loss                73.5906
trainer/Q1 Predictions Mean       -72.3235
trainer/Q1 Predictions Std         12.7983
trainer/Q1 Predictions Max        -59.3435
trainer/Q1 Predictions Min       -119.801
trainer/Q2 Predictions Mean       -72.3321
trainer/Q2 Predictions Std         12.7554
trainer/Q2 Predictions Max        -59.2565
trainer/Q2 Predictions Min       -118.909
trainer/Q Targets Mean            -72.9133
trainer/Q Targets Std              12.886
trainer/Q Targets Max             -59.9345
trainer/Q Targets Min            -120.725
trainer/Log Pis Mean                2.01398
trainer/Log Pis Std                 1.72122
trainer/Log Pis Max                 7.95316
trainer/Log Pis Min                -3.90856
trainer/Policy mu Mean             -0.0380924
trainer/Policy mu Std               0.870718
trainer/Policy mu Max               2.96855
trainer/Policy mu Min              -2.67843
trainer/Policy log std Mean        -1.85598
trainer/Policy log std Std          0.569859
trainer/Policy log std Max         -0.284925
trainer/Policy log std Min         -2.59687
trainer/Alpha                       0.0680732
trainer/Alpha Loss                  0.0375605
exploration/num steps total     20600
exploration/num paths total       206
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.28698
exploration/Rewards Std             0.805303
exploration/Rewards Max            -0.826942
exploration/Rewards Min            -7.74039
exploration/Returns Mean         -128.698
exploration/Returns Std            18.5148
exploration/Returns Max          -110.183
exploration/Returns Min          -147.212
exploration/Actions Mean            0.00591116
exploration/Actions Std             0.227811
exploration/Actions Max             0.99529
exploration/Actions Min            -0.924752
exploration/Num Paths               2
exploration/Average Returns      -128.698
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23314
evaluation/Rewards Std              0.426049
evaluation/Rewards Max             -0.442124
evaluation/Rewards Min             -7.00308
evaluation/Returns Mean          -123.314
evaluation/Returns Std              7.30781
evaluation/Returns Max           -108.546
evaluation/Returns Min           -130.414
evaluation/Actions Mean            -0.00593184
evaluation/Actions Std              0.151876
evaluation/Actions Max              0.982163
evaluation/Actions Min             -0.98521
evaluation/Num Paths               10
evaluation/Average Returns       -123.314
time/data storing (s)               0.00121435
time/evaluation sampling (s)        0.229466
time/exploration sampling (s)       0.0645189
time/logging (s)                    0.00299014
time/saving (s)                     0.00154845
time/training (s)                   0.748989
time/epoch (s)                      1.04873
time/total (s)                    108.57
Epoch                             101
-----------------------------  ---------------
2019-04-21 01:13:32.846017 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              20800
trainer/QF1 Loss                    0.372352
trainer/QF2 Loss                    0.351551
trainer/Policy Loss                73.4391
trainer/Q1 Predictions Mean       -72.0064
trainer/Q1 Predictions Std         10.734
trainer/Q1 Predictions Max        -59.4886
trainer/Q1 Predictions Min        -98.9402
trainer/Q2 Predictions Mean       -72.0072
trainer/Q2 Predictions Std         10.7657
trainer/Q2 Predictions Max        -59.3736
trainer/Q2 Predictions Min        -98.6886
trainer/Q Targets Mean            -72.3297
trainer/Q Targets Std              10.6239
trainer/Q Targets Max             -59.8851
trainer/Q Targets Min             -98.3993
trainer/Log Pis Mean                2.1017
trainer/Log Pis Std                 1.29579
trainer/Log Pis Max                 5.63933
trainer/Log Pis Min                -0.892321
trainer/Policy mu Mean              0.0694676
trainer/Policy mu Std               0.822138
trainer/Policy mu Max               2.59355
trainer/Policy mu Min              -2.64111
trainer/Policy log std Mean        -1.98233
trainer/Policy log std Std          0.569794
trainer/Policy log std Max         -0.522636
trainer/Policy log std Min         -2.65012
trainer/Alpha                       0.0682121
trainer/Alpha Loss                  0.273117
exploration/num steps total     20800
exploration/num paths total       208
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1507
exploration/Rewards Std             0.791485
exploration/Rewards Max            -0.557879
exploration/Rewards Min            -7.78334
exploration/Returns Mean         -115.07
exploration/Returns Std             8.87589
exploration/Returns Max          -106.194
exploration/Returns Min          -123.946
exploration/Actions Mean            0.0159427
exploration/Actions Std             0.209125
exploration/Actions Max             0.989761
exploration/Actions Min            -0.688717
exploration/Num Paths               2
exploration/Average Returns      -115.07
evaluation/num steps total     103000
evaluation/num paths total       1030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.18259
evaluation/Rewards Std              0.847967
evaluation/Rewards Max             -0.584916
evaluation/Rewards Min             -9.45471
evaluation/Returns Mean          -118.259
evaluation/Returns Std             13.424
evaluation/Returns Max           -104.251
evaluation/Returns Min           -138.664
evaluation/Actions Mean             0.0011569
evaluation/Actions Std              0.180122
evaluation/Actions Max              0.995591
evaluation/Actions Min             -0.995034
evaluation/Num Paths               10
evaluation/Average Returns       -118.259
time/data storing (s)               0.00139167
time/evaluation sampling (s)        0.225156
time/exploration sampling (s)       0.064813
time/logging (s)                    0.00349019
time/saving (s)                     0.00207551
time/training (s)                   0.757252
time/epoch (s)                      1.05418
time/total (s)                    109.628
Epoch                             102
-----------------------------  ---------------
2019-04-21 01:13:33.915578 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 103 finished
-----------------------------  ----------------
replay_buffer/size              21000
trainer/QF1 Loss                    0.795376
trainer/QF2 Loss                    0.802815
trainer/Policy Loss                73.3976
trainer/Q1 Predictions Mean       -72.3211
trainer/Q1 Predictions Std         11.3084
trainer/Q1 Predictions Max        -58.9125
trainer/Q1 Predictions Min       -105.922
trainer/Q2 Predictions Mean       -72.3089
trainer/Q2 Predictions Std         11.2552
trainer/Q2 Predictions Max        -58.91
trainer/Q2 Predictions Min       -105.252
trainer/Q Targets Mean            -73.066
trainer/Q Targets Std              11.0591
trainer/Q Targets Max             -59.8352
trainer/Q Targets Min            -105.434
trainer/Log Pis Mean                1.76693
trainer/Log Pis Std                 1.48071
trainer/Log Pis Max                 5.23255
trainer/Log Pis Min                -2.85412
trainer/Policy mu Mean              0.0493398
trainer/Policy mu Std               0.684143
trainer/Policy mu Max               2.81889
trainer/Policy mu Min              -2.77268
trainer/Policy log std Mean        -2.05688
trainer/Policy log std Std          0.478645
trainer/Policy log std Max         -0.481135
trainer/Policy log std Min         -2.65815
trainer/Alpha                       0.0697898
trainer/Alpha Loss                 -0.620516
exploration/num steps total     21000
exploration/num paths total       210
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14442
exploration/Rewards Std             0.459785
exploration/Rewards Max            -0.684246
exploration/Rewards Min            -5.2715
exploration/Returns Mean         -114.442
exploration/Returns Std             3.57501
exploration/Returns Max          -110.867
exploration/Returns Min          -118.017
exploration/Actions Mean            0.00735283
exploration/Actions Std             0.199383
exploration/Actions Max             0.969022
exploration/Actions Min            -0.921421
exploration/Num Paths               2
exploration/Average Returns      -114.442
evaluation/num steps total     104000
evaluation/num paths total       1040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.19469
evaluation/Rewards Std              0.809803
evaluation/Rewards Max             -0.8033
evaluation/Rewards Min             -9.7994
evaluation/Returns Mean          -119.469
evaluation/Returns Std             11.3495
evaluation/Returns Max           -101.282
evaluation/Returns Min           -140.804
evaluation/Actions Mean             0.000809088
evaluation/Actions Std              0.188495
evaluation/Actions Max              0.993416
evaluation/Actions Min             -0.990226
evaluation/Num Paths               10
evaluation/Average Returns       -119.469
time/data storing (s)               0.00127722
time/evaluation sampling (s)        0.219959
time/exploration sampling (s)       0.0639982
time/logging (s)                    0.00336904
time/saving (s)                     0.0019512
time/training (s)                   0.772703
time/epoch (s)                      1.06326
time/total (s)                    110.696
Epoch                             103
-----------------------------  ----------------
2019-04-21 01:13:34.992168 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              21200
trainer/QF1 Loss                   70.257
trainer/QF2 Loss                   70.5539
trainer/Policy Loss                72.511
trainer/Q1 Predictions Mean       -71.2917
trainer/Q1 Predictions Std         11.6995
trainer/Q1 Predictions Max        -59.2912
trainer/Q1 Predictions Min       -109.504
trainer/Q2 Predictions Mean       -71.2727
trainer/Q2 Predictions Std         11.6752
trainer/Q2 Predictions Max        -59.3174
trainer/Q2 Predictions Min       -108.849
trainer/Q Targets Mean            -70.5159
trainer/Q Targets Std              15.4432
trainer/Q Targets Max              -1.107
trainer/Q Targets Min            -110.547
trainer/Log Pis Mean                2.2608
trainer/Log Pis Std                 1.00305
trainer/Log Pis Max                 4.60977
trainer/Log Pis Min                -0.671277
trainer/Policy mu Mean              0.0222638
trainer/Policy mu Std               0.877705
trainer/Policy mu Max               2.65767
trainer/Policy mu Min              -2.51817
trainer/Policy log std Mean        -1.94138
trainer/Policy log std Std          0.590615
trainer/Policy log std Max         -0.311839
trainer/Policy log std Min         -2.66476
trainer/Alpha                       0.0717775
trainer/Alpha Loss                  0.687064
exploration/num steps total     21200
exploration/num paths total       212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14325
exploration/Rewards Std             0.795662
exploration/Rewards Max            -0.463993
exploration/Rewards Min            -7.67088
exploration/Returns Mean         -114.325
exploration/Returns Std             7.16876
exploration/Returns Max          -107.156
exploration/Returns Min          -121.494
exploration/Actions Mean            0.0446582
exploration/Actions Std             0.241549
exploration/Actions Max             0.994943
exploration/Actions Min            -0.389988
exploration/Num Paths               2
exploration/Average Returns      -114.325
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.12217
evaluation/Rewards Std              0.877079
evaluation/Rewards Max             -0.804725
evaluation/Rewards Min            -10.176
evaluation/Returns Mean          -112.217
evaluation/Returns Std             13.3012
evaluation/Returns Max            -98.4154
evaluation/Returns Min           -143.701
evaluation/Actions Mean             0.00776565
evaluation/Actions Std              0.181737
evaluation/Actions Max              0.994683
evaluation/Actions Min             -0.993502
evaluation/Num Paths               10
evaluation/Average Returns       -112.217
time/data storing (s)               0.00138967
time/evaluation sampling (s)        0.228574
time/exploration sampling (s)       0.0665285
time/logging (s)                    0.00336501
time/saving (s)                     0.00194388
time/training (s)                   0.768737
time/epoch (s)                      1.07054
time/total (s)                    111.77
Epoch                             104
-----------------------------  ---------------
2019-04-21 01:13:36.058337 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              21400
trainer/QF1 Loss                    1.21977
trainer/QF2 Loss                    1.23778
trainer/Policy Loss                72.8632
trainer/Q1 Predictions Mean       -71.4247
trainer/Q1 Predictions Std         13.0366
trainer/Q1 Predictions Max        -58.6899
trainer/Q1 Predictions Min       -132.279
trainer/Q2 Predictions Mean       -71.4182
trainer/Q2 Predictions Std         13.0368
trainer/Q2 Predictions Max        -58.6295
trainer/Q2 Predictions Min       -132.183
trainer/Q Targets Mean            -72.3707
trainer/Q Targets Std              13.0162
trainer/Q Targets Max             -59.3383
trainer/Q Targets Min            -129.57
trainer/Log Pis Mean                2.16044
trainer/Log Pis Std                 1.3194
trainer/Log Pis Max                 7.07639
trainer/Log Pis Min                -2.67448
trainer/Policy mu Mean              0.0435524
trainer/Policy mu Std               0.802104
trainer/Policy mu Max               2.93926
trainer/Policy mu Min              -3.24667
trainer/Policy log std Mean        -1.98808
trainer/Policy log std Std          0.529205
trainer/Policy log std Max         -0.286762
trainer/Policy log std Min         -2.61932
trainer/Alpha                       0.071737
trainer/Alpha Loss                  0.422709
exploration/num steps total     21400
exploration/num paths total       214
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1786
exploration/Rewards Std             0.930436
exploration/Rewards Max            -0.684308
exploration/Rewards Min            -9.17443
exploration/Returns Mean         -117.86
exploration/Returns Std             9.46269
exploration/Returns Max          -108.397
exploration/Returns Min          -127.323
exploration/Actions Mean            0.0314726
exploration/Actions Std             0.224047
exploration/Actions Max             0.994837
exploration/Actions Min            -0.876732
exploration/Num Paths               2
exploration/Average Returns      -117.86
evaluation/num steps total     106000
evaluation/num paths total       1060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16811
evaluation/Rewards Std              0.914766
evaluation/Rewards Max             -0.166855
evaluation/Rewards Min            -10.2295
evaluation/Returns Mean          -116.811
evaluation/Returns Std             14.9528
evaluation/Returns Max            -96.0763
evaluation/Returns Min           -145.675
evaluation/Actions Mean             0.0137757
evaluation/Actions Std              0.182482
evaluation/Actions Max              0.996264
evaluation/Actions Min             -0.973277
evaluation/Num Paths               10
evaluation/Average Returns       -116.811
time/data storing (s)               0.00122759
time/evaluation sampling (s)        0.225676
time/exploration sampling (s)       0.0633744
time/logging (s)                    0.00342009
time/saving (s)                     0.00194495
time/training (s)                   0.764496
time/epoch (s)                      1.06014
time/total (s)                    112.834
Epoch                             105
-----------------------------  ---------------
2019-04-21 01:13:37.119426 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size              21600
trainer/QF1 Loss                  130.295
trainer/QF2 Loss                  129.156
trainer/Policy Loss                70.8273
trainer/Q1 Predictions Mean       -69.4899
trainer/Q1 Predictions Std         10.1209
trainer/Q1 Predictions Max        -58.6135
trainer/Q1 Predictions Min       -104.984
trainer/Q2 Predictions Mean       -69.4854
trainer/Q2 Predictions Std         10.1202
trainer/Q2 Predictions Max        -58.6157
trainer/Q2 Predictions Min       -104.495
trainer/Q Targets Mean            -68.3134
trainer/Q Targets Std              15.5936
trainer/Q Targets Max              -1.05522
trainer/Q Targets Min            -107.077
trainer/Log Pis Mean                1.95366
trainer/Log Pis Std                 1.30118
trainer/Log Pis Max                 6.32262
trainer/Log Pis Min                -2.19121
trainer/Policy mu Mean             -0.00768125
trainer/Policy mu Std               0.737963
trainer/Policy mu Max               2.24661
trainer/Policy mu Min              -2.43085
trainer/Policy log std Mean        -2.01803
trainer/Policy log std Std          0.540991
trainer/Policy log std Max         -0.417992
trainer/Policy log std Min         -2.66912
trainer/Alpha                       0.0728558
trainer/Alpha Loss                 -0.121395
exploration/num steps total     21600
exploration/num paths total       216
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02288
exploration/Rewards Std             0.586287
exploration/Rewards Max            -0.47741
exploration/Rewards Min            -5.35104
exploration/Returns Mean         -102.288
exploration/Returns Std             1.84945
exploration/Returns Max          -100.439
exploration/Returns Min          -104.137
exploration/Actions Mean            0.021528
exploration/Actions Std             0.224511
exploration/Actions Max             0.99464
exploration/Actions Min            -0.777264
exploration/Num Paths               2
exploration/Average Returns      -102.288
evaluation/num steps total     107000
evaluation/num paths total       1070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06498
evaluation/Rewards Std              0.829967
evaluation/Rewards Max             -0.542722
evaluation/Rewards Min             -9.60913
evaluation/Returns Mean          -106.498
evaluation/Returns Std             11.9839
evaluation/Returns Max            -88.7401
evaluation/Returns Min           -133.27
evaluation/Actions Mean            -0.00227778
evaluation/Actions Std              0.181773
evaluation/Actions Max              0.993989
evaluation/Actions Min             -0.990779
evaluation/Num Paths               10
evaluation/Average Returns       -106.498
time/data storing (s)               0.00130621
time/evaluation sampling (s)        0.218908
time/exploration sampling (s)       0.0630641
time/logging (s)                    0.00251353
time/saving (s)                     0.00159599
time/training (s)                   0.766642
time/epoch (s)                      1.05403
time/total (s)                    113.892
Epoch                             106
-----------------------------  ---------------
2019-04-21 01:13:38.179900 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              21800
trainer/QF1 Loss                   59.4003
trainer/QF2 Loss                   59.2406
trainer/Policy Loss                72.0014
trainer/Q1 Predictions Mean       -70.8839
trainer/Q1 Predictions Std         13.0224
trainer/Q1 Predictions Max        -58.677
trainer/Q1 Predictions Min       -128.187
trainer/Q2 Predictions Mean       -70.8833
trainer/Q2 Predictions Std         12.9926
trainer/Q2 Predictions Max        -58.66
trainer/Q2 Predictions Min       -128.177
trainer/Q Targets Mean            -70.385
trainer/Q Targets Std              14.7939
trainer/Q Targets Max              -1.10285
trainer/Q Targets Min            -130.28
trainer/Log Pis Mean                1.84392
trainer/Log Pis Std                 1.22371
trainer/Log Pis Max                 6.55256
trainer/Log Pis Min                -2.93464
trainer/Policy mu Mean              0.171907
trainer/Policy mu Std               0.739097
trainer/Policy mu Max               2.97603
trainer/Policy mu Min              -1.99833
trainer/Policy log std Mean        -1.99649
trainer/Policy log std Std          0.529794
trainer/Policy log std Max         -0.344255
trainer/Policy log std Min         -2.58713
trainer/Alpha                       0.0731422
trainer/Alpha Loss                 -0.408197
exploration/num steps total     21800
exploration/num paths total       218
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26943
exploration/Rewards Std             0.859924
exploration/Rewards Max            -0.871009
exploration/Rewards Min            -7.84854
exploration/Returns Mean         -126.943
exploration/Returns Std             8.93718
exploration/Returns Max          -118.006
exploration/Returns Min          -135.881
exploration/Actions Mean           -0.033244
exploration/Actions Std             0.214409
exploration/Actions Max             0.741806
exploration/Actions Min            -0.999708
exploration/Num Paths               2
exploration/Average Returns      -126.943
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.20748
evaluation/Rewards Std              0.899369
evaluation/Rewards Max             -0.521394
evaluation/Rewards Min            -10.1906
evaluation/Returns Mean          -120.748
evaluation/Returns Std             17.5317
evaluation/Returns Max            -90.9997
evaluation/Returns Min           -153.823
evaluation/Actions Mean            -0.025206
evaluation/Actions Std              0.188692
evaluation/Actions Max              0.99093
evaluation/Actions Min             -0.996221
evaluation/Num Paths               10
evaluation/Average Returns       -120.748
time/data storing (s)               0.00122452
time/evaluation sampling (s)        0.222467
time/exploration sampling (s)       0.0642645
time/logging (s)                    0.00335869
time/saving (s)                     0.00155833
time/training (s)                   0.763384
time/epoch (s)                      1.05626
time/total (s)                    114.952
Epoch                             107
-----------------------------  ---------------
2019-04-21 01:13:39.247446 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              22000
trainer/QF1 Loss                   37.0334
trainer/QF2 Loss                   36.3216
trainer/Policy Loss                73.4767
trainer/Q1 Predictions Mean       -72.536
trainer/Q1 Predictions Std         13.5233
trainer/Q1 Predictions Max        -58.6421
trainer/Q1 Predictions Min       -133.905
trainer/Q2 Predictions Mean       -72.4983
trainer/Q2 Predictions Std         13.5791
trainer/Q2 Predictions Max        -58.6548
trainer/Q2 Predictions Min       -133.952
trainer/Q Targets Mean            -72.0855
trainer/Q Targets Std              14.6656
trainer/Q Targets Max              -2.4627
trainer/Q Targets Min            -129.712
trainer/Log Pis Mean                1.98696
trainer/Log Pis Std                 1.27697
trainer/Log Pis Max                 5.24512
trainer/Log Pis Min                -2.07239
trainer/Policy mu Mean              0.0859231
trainer/Policy mu Std               0.917638
trainer/Policy mu Max               2.84839
trainer/Policy mu Min              -3.19773
trainer/Policy log std Mean        -1.83566
trainer/Policy log std Std          0.578597
trainer/Policy log std Max         -0.212285
trainer/Policy log std Min         -2.66688
trainer/Alpha                       0.0713415
trainer/Alpha Loss                 -0.0344175
exploration/num steps total     22000
exploration/num paths total       220
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01216
exploration/Rewards Std             1.29446
exploration/Rewards Max            -0.219235
exploration/Rewards Min           -10.1909
exploration/Returns Mean         -101.216
exploration/Returns Std            23.7051
exploration/Returns Max           -77.511
exploration/Returns Min          -124.921
exploration/Actions Mean            0.0153256
exploration/Actions Std             0.244408
exploration/Actions Max             0.998301
exploration/Actions Min            -0.902393
exploration/Num Paths               2
exploration/Average Returns      -101.216
evaluation/num steps total     109000
evaluation/num paths total       1090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.986855
evaluation/Rewards Std              0.692283
evaluation/Rewards Max             -0.229885
evaluation/Rewards Min             -9.40323
evaluation/Returns Mean           -98.6855
evaluation/Returns Std             19.8465
evaluation/Returns Max            -72.5754
evaluation/Returns Min           -136.061
evaluation/Actions Mean            -0.00233052
evaluation/Actions Std              0.165941
evaluation/Actions Max              0.992181
evaluation/Actions Min             -0.990023
evaluation/Num Paths               10
evaluation/Average Returns        -98.6855
time/data storing (s)               0.00144255
time/evaluation sampling (s)        0.227141
time/exploration sampling (s)       0.0684985
time/logging (s)                    0.00321037
time/saving (s)                     0.00194651
time/training (s)                   0.759084
time/epoch (s)                      1.06132
time/total (s)                    116.017
Epoch                             108
-----------------------------  ---------------
2019-04-21 01:13:40.313071 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              22200
trainer/QF1 Loss                   33.8177
trainer/QF2 Loss                   33.82
trainer/Policy Loss                70.813
trainer/Q1 Predictions Mean       -69.4133
trainer/Q1 Predictions Std         10.1973
trainer/Q1 Predictions Max        -57.8273
trainer/Q1 Predictions Min       -105.977
trainer/Q2 Predictions Mean       -69.3929
trainer/Q2 Predictions Std         10.21
trainer/Q2 Predictions Max        -57.8072
trainer/Q2 Predictions Min       -105.533
trainer/Q Targets Mean            -69.7964
trainer/Q Targets Std              12.3483
trainer/Q Targets Max              -1.38349
trainer/Q Targets Min            -106.08
trainer/Log Pis Mean                2.02839
trainer/Log Pis Std                 1.17078
trainer/Log Pis Max                 4.88212
trainer/Log Pis Min                -2.76832
trainer/Policy mu Mean             -0.0581168
trainer/Policy mu Std               0.820106
trainer/Policy mu Max               2.77211
trainer/Policy mu Min              -2.48209
trainer/Policy log std Mean        -1.91843
trainer/Policy log std Std          0.55429
trainer/Policy log std Max         -0.384252
trainer/Policy log std Min         -2.63988
trainer/Alpha                       0.0724438
trainer/Alpha Loss                  0.0745263
exploration/num steps total     22200
exploration/num paths total       222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.997182
exploration/Rewards Std             0.223696
exploration/Rewards Max            -0.715877
exploration/Rewards Min            -3.32643
exploration/Returns Mean          -99.7182
exploration/Returns Std             1.18263
exploration/Returns Max           -98.5356
exploration/Returns Min          -100.901
exploration/Actions Mean           -0.0125384
exploration/Actions Std             0.162584
exploration/Actions Max             0.488407
exploration/Actions Min            -0.999246
exploration/Num Paths               2
exploration/Average Returns       -99.7182
evaluation/num steps total     110000
evaluation/num paths total       1100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.11116
evaluation/Rewards Std              0.924641
evaluation/Rewards Max             -0.582798
evaluation/Rewards Min             -9.53583
evaluation/Returns Mean          -111.116
evaluation/Returns Std             13.2064
evaluation/Returns Max            -90.1409
evaluation/Returns Min           -135.739
evaluation/Actions Mean            -0.00426413
evaluation/Actions Std              0.194272
evaluation/Actions Max              0.994841
evaluation/Actions Min             -0.994886
evaluation/Num Paths               10
evaluation/Average Returns       -111.116
time/data storing (s)               0.0012116
time/evaluation sampling (s)        0.222722
time/exploration sampling (s)       0.063738
time/logging (s)                    0.0033534
time/saving (s)                     0.00195069
time/training (s)                   0.766656
time/epoch (s)                      1.05963
time/total (s)                    117.081
Epoch                             109
-----------------------------  ---------------
2019-04-21 01:13:41.383172 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              22400
trainer/QF1 Loss                    0.514093
trainer/QF2 Loss                    0.546447
trainer/Policy Loss                70.6002
trainer/Q1 Predictions Mean       -69.4124
trainer/Q1 Predictions Std         11.2774
trainer/Q1 Predictions Max        -58.2712
trainer/Q1 Predictions Min       -116.787
trainer/Q2 Predictions Mean       -69.4441
trainer/Q2 Predictions Std         11.2546
trainer/Q2 Predictions Max        -58.2186
trainer/Q2 Predictions Min       -116.279
trainer/Q Targets Mean            -69.9112
trainer/Q Targets Std              11.6182
trainer/Q Targets Max             -58.452
trainer/Q Targets Min            -118.977
trainer/Log Pis Mean                1.89191
trainer/Log Pis Std                 1.18701
trainer/Log Pis Max                 4.17186
trainer/Log Pis Min                -3.08887
trainer/Policy mu Mean              0.13095
trainer/Policy mu Std               0.698216
trainer/Policy mu Max               2.76448
trainer/Policy mu Min              -2.65313
trainer/Policy log std Mean        -1.98922
trainer/Policy log std Std          0.498913
trainer/Policy log std Max         -0.583882
trainer/Policy log std Min         -2.59969
trainer/Alpha                       0.0731989
trainer/Alpha Loss                 -0.282608
exploration/num steps total     22400
exploration/num paths total       224
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.22035
exploration/Rewards Std             1.19504
exploration/Rewards Max            -0.740336
exploration/Rewards Min           -10.704
exploration/Returns Mean         -122.035
exploration/Returns Std            22.155
exploration/Returns Max           -99.88
exploration/Returns Min          -144.19
exploration/Actions Mean           -0.0335917
exploration/Actions Std             0.228275
exploration/Actions Max             0.602789
exploration/Actions Min            -0.994885
exploration/Num Paths               2
exploration/Average Returns      -122.035
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02045
evaluation/Rewards Std              0.820606
evaluation/Rewards Max             -0.209862
evaluation/Rewards Min             -8.86046
evaluation/Returns Mean          -102.045
evaluation/Returns Std             20.3809
evaluation/Returns Max            -76.1558
evaluation/Returns Min           -134.989
evaluation/Actions Mean            -0.0145607
evaluation/Actions Std              0.172436
evaluation/Actions Max              0.9938
evaluation/Actions Min             -0.992298
evaluation/Num Paths               10
evaluation/Average Returns       -102.045
time/data storing (s)               0.00122763
time/evaluation sampling (s)        0.225604
time/exploration sampling (s)       0.0632695
time/logging (s)                    0.00342381
time/saving (s)                     0.00159892
time/training (s)                   0.768931
time/epoch (s)                      1.06406
time/total (s)                    118.149
Epoch                             110
-----------------------------  ---------------
2019-04-21 01:13:42.453719 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              22600
trainer/QF1 Loss                   90.6747
trainer/QF2 Loss                   90.5404
trainer/Policy Loss                70.7595
trainer/Q1 Predictions Mean       -69.4283
trainer/Q1 Predictions Std         11.8665
trainer/Q1 Predictions Max        -57.876
trainer/Q1 Predictions Min       -120.994
trainer/Q2 Predictions Mean       -69.4521
trainer/Q2 Predictions Std         11.8187
trainer/Q2 Predictions Max        -57.8362
trainer/Q2 Predictions Min       -121.037
trainer/Q Targets Mean            -68.4427
trainer/Q Targets Std              15.0933
trainer/Q Targets Max              -0.95325
trainer/Q Targets Min            -120.99
trainer/Log Pis Mean                2.04351
trainer/Log Pis Std                 0.950847
trainer/Log Pis Max                 5.01347
trainer/Log Pis Min                -1.05786
trainer/Policy mu Mean              0.0290085
trainer/Policy mu Std               0.684497
trainer/Policy mu Max               2.90775
trainer/Policy mu Min              -2.53643
trainer/Policy log std Mean        -2.05796
trainer/Policy log std Std          0.47559
trainer/Policy log std Max         -0.439405
trainer/Policy log std Min         -2.59747
trainer/Alpha                       0.0733085
trainer/Alpha Loss                  0.113704
exploration/num steps total     22600
exploration/num paths total       226
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10254
exploration/Rewards Std             0.645814
exploration/Rewards Max            -0.66923
exploration/Rewards Min            -6.10001
exploration/Returns Mean         -110.254
exploration/Returns Std             1.77061
exploration/Returns Max          -108.483
exploration/Returns Min          -112.024
exploration/Actions Mean            0.0108568
exploration/Actions Std             0.221529
exploration/Actions Max             0.997975
exploration/Actions Min            -0.928235
exploration/Num Paths               2
exploration/Average Returns      -110.254
evaluation/num steps total     112000
evaluation/num paths total       1120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09265
evaluation/Rewards Std              0.926149
evaluation/Rewards Max             -0.20254
evaluation/Rewards Min             -9.7045
evaluation/Returns Mean          -109.265
evaluation/Returns Std             13.6727
evaluation/Returns Max            -93.8394
evaluation/Returns Min           -133.194
evaluation/Actions Mean             0.00934449
evaluation/Actions Std              0.187036
evaluation/Actions Max              0.995968
evaluation/Actions Min             -0.989039
evaluation/Num Paths               10
evaluation/Average Returns       -109.265
time/data storing (s)               0.00122997
time/evaluation sampling (s)        0.221367
time/exploration sampling (s)       0.064026
time/logging (s)                    0.00331004
time/saving (s)                     0.00194717
time/training (s)                   0.772684
time/epoch (s)                      1.06456
time/total (s)                    119.217
Epoch                             111
-----------------------------  ---------------
2019-04-21 01:13:43.528752 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              22800
trainer/QF1 Loss                  155.72
trainer/QF2 Loss                  156.492
trainer/Policy Loss                69.9338
trainer/Q1 Predictions Mean       -68.6411
trainer/Q1 Predictions Std         10.4871
trainer/Q1 Predictions Max        -58.0637
trainer/Q1 Predictions Min       -105.678
trainer/Q2 Predictions Mean       -68.6336
trainer/Q2 Predictions Std         10.5058
trainer/Q2 Predictions Max        -58.005
trainer/Q2 Predictions Min       -105.598
trainer/Q Targets Mean            -66.8911
trainer/Q Targets Std              15.3582
trainer/Q Targets Max              -1.04283
trainer/Q Targets Min            -106.235
trainer/Log Pis Mean                2.05255
trainer/Log Pis Std                 1.291
trainer/Log Pis Max                 5.52463
trainer/Log Pis Min                -2.78646
trainer/Policy mu Mean              0.135897
trainer/Policy mu Std               0.754228
trainer/Policy mu Max               2.8677
trainer/Policy mu Min              -2.25497
trainer/Policy log std Mean        -2.02198
trainer/Policy log std Std          0.5282
trainer/Policy log std Max         -0.58439
trainer/Policy log std Min         -2.69213
trainer/Alpha                       0.073304
trainer/Alpha Loss                  0.137327
exploration/num steps total     22800
exploration/num paths total       228
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14618
exploration/Rewards Std             1.31533
exploration/Rewards Max            -0.418173
exploration/Rewards Min           -11.0777
exploration/Returns Mean         -114.618
exploration/Returns Std            15.9333
exploration/Returns Max           -98.6852
exploration/Returns Min          -130.552
exploration/Actions Mean            0.0489275
exploration/Actions Std             0.240827
exploration/Actions Max             0.995822
exploration/Actions Min            -0.642718
exploration/Num Paths               2
exploration/Average Returns      -114.618
evaluation/num steps total     113000
evaluation/num paths total       1130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16757
evaluation/Rewards Std              1.14969
evaluation/Rewards Max             -0.39259
evaluation/Rewards Min            -10.8276
evaluation/Returns Mean          -116.757
evaluation/Returns Std             16.5023
evaluation/Returns Max            -85.1241
evaluation/Returns Min           -141.526
evaluation/Actions Mean            -0.00615792
evaluation/Actions Std              0.213113
evaluation/Actions Max              0.996116
evaluation/Actions Min             -0.993941
evaluation/Num Paths               10
evaluation/Average Returns       -116.757
time/data storing (s)               0.00143087
time/evaluation sampling (s)        0.224318
time/exploration sampling (s)       0.0646686
time/logging (s)                    0.00332241
time/saving (s)                     0.00197033
time/training (s)                   0.77372
time/epoch (s)                      1.06943
time/total (s)                    120.291
Epoch                             112
-----------------------------  ---------------
2019-04-21 01:13:44.598030 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              23000
trainer/QF1 Loss                   90.0428
trainer/QF2 Loss                   90.1843
trainer/Policy Loss                67.5736
trainer/Q1 Predictions Mean       -66.2709
trainer/Q1 Predictions Std          9.40384
trainer/Q1 Predictions Max        -58.3567
trainer/Q1 Predictions Min        -84.9817
trainer/Q2 Predictions Mean       -66.2804
trainer/Q2 Predictions Std          9.35039
trainer/Q2 Predictions Max        -58.2376
trainer/Q2 Predictions Min        -84.5909
trainer/Q Targets Mean            -65.089
trainer/Q Targets Std              13.0411
trainer/Q Targets Max              -1.04659
trainer/Q Targets Min             -85.8503
trainer/Log Pis Mean                1.89836
trainer/Log Pis Std                 1.18956
trainer/Log Pis Max                 5.40145
trainer/Log Pis Min                -2.52591
trainer/Policy mu Mean              0.0161515
trainer/Policy mu Std               0.70348
trainer/Policy mu Max               2.42926
trainer/Policy mu Min              -2.49179
trainer/Policy log std Mean        -1.96965
trainer/Policy log std Std          0.490565
trainer/Policy log std Max         -0.38685
trainer/Policy log std Min         -2.5055
trainer/Alpha                       0.07216
trainer/Alpha Loss                 -0.267182
exploration/num steps total     23000
exploration/num paths total       230
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09943
exploration/Rewards Std             0.943193
exploration/Rewards Max            -0.510816
exploration/Rewards Min            -8.42938
exploration/Returns Mean         -109.943
exploration/Returns Std            23.7211
exploration/Returns Max           -86.2216
exploration/Returns Min          -133.664
exploration/Actions Mean           -0.0176497
exploration/Actions Std             0.222896
exploration/Actions Max             0.988426
exploration/Actions Min            -0.997789
exploration/Num Paths               2
exploration/Average Returns      -109.943
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.07838
evaluation/Rewards Std              0.805491
evaluation/Rewards Max             -0.300316
evaluation/Rewards Min             -9.49142
evaluation/Returns Mean          -107.838
evaluation/Returns Std             15.3549
evaluation/Returns Max            -85.1958
evaluation/Returns Min           -141.278
evaluation/Actions Mean            -0.00038142
evaluation/Actions Std              0.180822
evaluation/Actions Max              0.993049
evaluation/Actions Min             -0.993759
evaluation/Num Paths               10
evaluation/Average Returns       -107.838
time/data storing (s)               0.00121461
time/evaluation sampling (s)        0.223053
time/exploration sampling (s)       0.0640429
time/logging (s)                    0.00358278
time/saving (s)                     0.00197314
time/training (s)                   0.769202
time/epoch (s)                      1.06307
time/total (s)                    121.358
Epoch                             113
-----------------------------  ---------------
2019-04-21 01:13:45.651112 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              23200
trainer/QF1 Loss                    0.535181
trainer/QF2 Loss                    0.527484
trainer/Policy Loss                69.054
trainer/Q1 Predictions Mean       -67.7011
trainer/Q1 Predictions Std         11.0294
trainer/Q1 Predictions Max        -57.5957
trainer/Q1 Predictions Min       -105.918
trainer/Q2 Predictions Mean       -67.7023
trainer/Q2 Predictions Std         11.0218
trainer/Q2 Predictions Max        -57.5951
trainer/Q2 Predictions Min       -105.195
trainer/Q Targets Mean            -68.1608
trainer/Q Targets Std              10.9487
trainer/Q Targets Max             -58.0348
trainer/Q Targets Min            -106.457
trainer/Log Pis Mean                2.2152
trainer/Log Pis Std                 1.19288
trainer/Log Pis Max                 6.09546
trainer/Log Pis Min                -1.2545
trainer/Policy mu Mean              0.00411868
trainer/Policy mu Std               0.831085
trainer/Policy mu Max               2.70133
trainer/Policy mu Min              -2.96777
trainer/Policy log std Mean        -1.99888
trainer/Policy log std Std          0.556179
trainer/Policy log std Max         -0.484662
trainer/Policy log std Min         -2.59749
trainer/Alpha                       0.0716744
trainer/Alpha Loss                  0.567185
exploration/num steps total     23200
exploration/num paths total       232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.926085
exploration/Rewards Std             1.28285
exploration/Rewards Max            -0.198521
exploration/Rewards Min           -10.3217
exploration/Returns Mean          -92.6085
exploration/Returns Std            25.3351
exploration/Returns Max           -67.2735
exploration/Returns Min          -117.944
exploration/Actions Mean            0.00467685
exploration/Actions Std             0.241552
exploration/Actions Max             0.997179
exploration/Actions Min            -0.937774
exploration/Num Paths               2
exploration/Average Returns       -92.6085
evaluation/num steps total     115000
evaluation/num paths total       1150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.93625
evaluation/Rewards Std              0.95576
evaluation/Rewards Max             -0.576581
evaluation/Rewards Min             -9.54804
evaluation/Returns Mean           -93.625
evaluation/Returns Std             15.7537
evaluation/Returns Max            -68.7137
evaluation/Returns Min           -113.311
evaluation/Actions Mean             0.0259686
evaluation/Actions Std              0.175594
evaluation/Actions Max              0.995277
evaluation/Actions Min             -0.984192
evaluation/Num Paths               10
evaluation/Average Returns        -93.625
time/data storing (s)               0.00133232
time/evaluation sampling (s)        0.218549
time/exploration sampling (s)       0.0651881
time/logging (s)                    0.00334569
time/saving (s)                     0.00195136
time/training (s)                   0.756641
time/epoch (s)                      1.04701
time/total (s)                    122.409
Epoch                             114
-----------------------------  ---------------
2019-04-21 01:13:46.721300 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              23400
trainer/QF1 Loss                   53.6995
trainer/QF2 Loss                   53.8863
trainer/Policy Loss                68.9482
trainer/Q1 Predictions Mean       -67.542
trainer/Q1 Predictions Std         11.1267
trainer/Q1 Predictions Max        -57.9896
trainer/Q1 Predictions Min       -128.007
trainer/Q2 Predictions Mean       -67.5257
trainer/Q2 Predictions Std         11.103
trainer/Q2 Predictions Max        -58.0073
trainer/Q2 Predictions Min       -127.759
trainer/Q Targets Mean            -67.0847
trainer/Q Targets Std              13.1351
trainer/Q Targets Max              -0.918035
trainer/Q Targets Min            -129.345
trainer/Log Pis Mean                2.02705
trainer/Log Pis Std                 1.10249
trainer/Log Pis Max                 5.71186
trainer/Log Pis Min                -1.70813
trainer/Policy mu Mean              0.0411967
trainer/Policy mu Std               0.731727
trainer/Policy mu Max               3.09523
trainer/Policy mu Min              -2.07371
trainer/Policy log std Mean        -2.00932
trainer/Policy log std Std          0.517256
trainer/Policy log std Max         -0.197579
trainer/Policy log std Min         -2.54018
trainer/Alpha                       0.0704997
trainer/Alpha Loss                  0.0717214
exploration/num steps total     23400
exploration/num paths total       234
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.34695
exploration/Rewards Std             1.34509
exploration/Rewards Max            -0.763519
exploration/Rewards Min           -10.0051
exploration/Returns Mean         -134.695
exploration/Returns Std            13.0824
exploration/Returns Max          -121.613
exploration/Returns Min          -147.778
exploration/Actions Mean           -0.0362584
exploration/Actions Std             0.234784
exploration/Actions Max             0.714124
exploration/Actions Min            -0.998602
exploration/Num Paths               2
exploration/Average Returns      -134.695
evaluation/num steps total     116000
evaluation/num paths total       1160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.1187
evaluation/Rewards Std              0.810014
evaluation/Rewards Max             -0.663907
evaluation/Rewards Min            -10.9259
evaluation/Returns Mean          -111.87
evaluation/Returns Std             12.8953
evaluation/Returns Max            -94.0968
evaluation/Returns Min           -141.146
evaluation/Actions Mean             0.0109745
evaluation/Actions Std              0.185623
evaluation/Actions Max              0.995336
evaluation/Actions Min             -0.985073
evaluation/Num Paths               10
evaluation/Average Returns       -111.87
time/data storing (s)               0.00134987
time/evaluation sampling (s)        0.223505
time/exploration sampling (s)       0.0661805
time/logging (s)                    0.0033639
time/saving (s)                     0.00192895
time/training (s)                   0.767613
time/epoch (s)                      1.06394
time/total (s)                    123.477
Epoch                             115
-----------------------------  ---------------
2019-04-21 01:13:47.827069 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              23600
trainer/QF1 Loss                  140.13
trainer/QF2 Loss                  140.056
trainer/Policy Loss                68.1168
trainer/Q1 Predictions Mean       -66.9189
trainer/Q1 Predictions Std          9.3437
trainer/Q1 Predictions Max        -57.729
trainer/Q1 Predictions Min        -95.7817
trainer/Q2 Predictions Mean       -66.877
trainer/Q2 Predictions Std          9.29066
trainer/Q2 Predictions Max        -57.7689
trainer/Q2 Predictions Min        -96.1626
trainer/Q Targets Mean            -65.4594
trainer/Q Targets Std              14.8043
trainer/Q Targets Max              -1.05668
trainer/Q Targets Min             -96.3511
trainer/Log Pis Mean                1.94969
trainer/Log Pis Std                 1.13162
trainer/Log Pis Max                 4.91544
trainer/Log Pis Min                -1.58043
trainer/Policy mu Mean              0.139525
trainer/Policy mu Std               0.693849
trainer/Policy mu Max               2.75365
trainer/Policy mu Min              -2.62671
trainer/Policy log std Mean        -2.03172
trainer/Policy log std Std          0.505032
trainer/Policy log std Max         -0.568798
trainer/Policy log std Min         -2.57081
trainer/Alpha                       0.070828
trainer/Alpha Loss                 -0.133204
exploration/num steps total     23600
exploration/num paths total       236
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.96658
exploration/Rewards Std             0.230656
exploration/Rewards Max            -0.7474
exploration/Rewards Min            -3.07943
exploration/Returns Mean          -96.658
exploration/Returns Std             1.80002
exploration/Returns Max           -94.8579
exploration/Returns Min           -98.458
exploration/Actions Mean            0.00148209
exploration/Actions Std             0.162145
exploration/Actions Max             0.991598
exploration/Actions Min            -0.971329
exploration/Num Paths               2
exploration/Average Returns       -96.658
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.894385
evaluation/Rewards Std              1.24506
evaluation/Rewards Max             -0.380906
evaluation/Rewards Min            -11.1123
evaluation/Returns Mean           -89.4385
evaluation/Returns Std             28.9419
evaluation/Returns Max            -46.7923
evaluation/Returns Min           -142.847
evaluation/Actions Mean             0.00258377
evaluation/Actions Std              0.212197
evaluation/Actions Max              0.994864
evaluation/Actions Min             -0.996235
evaluation/Num Paths               10
evaluation/Average Returns        -89.4385
time/data storing (s)               0.00130887
time/evaluation sampling (s)        0.238623
time/exploration sampling (s)       0.0794966
time/logging (s)                    0.00335223
time/saving (s)                     0.0124002
time/training (s)                   0.764243
time/epoch (s)                      1.09942
time/total (s)                    124.58
Epoch                             116
-----------------------------  ---------------
2019-04-21 01:13:48.893024 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              23800
trainer/QF1 Loss                    1.60473
trainer/QF2 Loss                    1.51194
trainer/Policy Loss                69.5013
trainer/Q1 Predictions Mean       -68.1383
trainer/Q1 Predictions Std          9.32842
trainer/Q1 Predictions Max        -56.445
trainer/Q1 Predictions Min        -92.7081
trainer/Q2 Predictions Mean       -68.1649
trainer/Q2 Predictions Std          9.34188
trainer/Q2 Predictions Max        -56.4667
trainer/Q2 Predictions Min        -92.8772
trainer/Q Targets Mean            -69.292
trainer/Q Targets Std               9.27962
trainer/Q Targets Max             -57.6022
trainer/Q Targets Min             -94.689
trainer/Log Pis Mean                2.07577
trainer/Log Pis Std                 1.32558
trainer/Log Pis Max                 5.96019
trainer/Log Pis Min                -2.82644
trainer/Policy mu Mean              0.0939427
trainer/Policy mu Std               0.894724
trainer/Policy mu Max               2.71256
trainer/Policy mu Min              -2.54888
trainer/Policy log std Mean        -1.82905
trainer/Policy log std Std          0.532865
trainer/Policy log std Max         -0.513169
trainer/Policy log std Min         -2.52603
trainer/Alpha                       0.0709877
trainer/Alpha Loss                  0.200431
exploration/num steps total     23800
exploration/num paths total       238
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19438
exploration/Rewards Std             0.830616
exploration/Rewards Max            -0.698642
exploration/Rewards Min            -6.45593
exploration/Returns Mean         -119.438
exploration/Returns Std             0.250536
exploration/Returns Max          -119.188
exploration/Returns Min          -119.689
exploration/Actions Mean           -0.0314325
exploration/Actions Std             0.219212
exploration/Actions Max             0.653477
exploration/Actions Min            -0.994752
exploration/Num Paths               2
exploration/Average Returns      -119.438
evaluation/num steps total     118000
evaluation/num paths total       1180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04326
evaluation/Rewards Std              0.923805
evaluation/Rewards Max             -0.458469
evaluation/Rewards Min            -10.31
evaluation/Returns Mean          -104.326
evaluation/Returns Std             27.9544
evaluation/Returns Max            -68.9635
evaluation/Returns Min           -147.471
evaluation/Actions Mean            -0.00654191
evaluation/Actions Std              0.176987
evaluation/Actions Max              0.992483
evaluation/Actions Min             -0.996424
evaluation/Num Paths               10
evaluation/Average Returns       -104.326
time/data storing (s)               0.00123014
time/evaluation sampling (s)        0.223722
time/exploration sampling (s)       0.0636827
time/logging (s)                    0.00338216
time/saving (s)                     0.00191301
time/training (s)                   0.765505
time/epoch (s)                      1.05944
time/total (s)                    125.644
Epoch                             117
-----------------------------  ---------------
2019-04-21 01:13:49.963154 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              24000
trainer/QF1 Loss                   31.7416
trainer/QF2 Loss                   31.7901
trainer/Policy Loss                68.6347
trainer/Q1 Predictions Mean       -67.2873
trainer/Q1 Predictions Std          9.46722
trainer/Q1 Predictions Max        -57.0006
trainer/Q1 Predictions Min        -94.1153
trainer/Q2 Predictions Mean       -67.3085
trainer/Q2 Predictions Std          9.43666
trainer/Q2 Predictions Max        -57.0007
trainer/Q2 Predictions Min        -93.5548
trainer/Q Targets Mean            -67.2038
trainer/Q Targets Std              11.5729
trainer/Q Targets Max              -1.22081
trainer/Q Targets Min             -95.3408
trainer/Log Pis Mean                2.06362
trainer/Log Pis Std                 0.926967
trainer/Log Pis Max                 5.21168
trainer/Log Pis Min                -0.245733
trainer/Policy mu Mean              0.139359
trainer/Policy mu Std               0.752391
trainer/Policy mu Max               2.52444
trainer/Policy mu Min              -2.16839
trainer/Policy log std Mean        -1.95528
trainer/Policy log std Std          0.506321
trainer/Policy log std Max         -0.587922
trainer/Policy log std Min         -2.59668
trainer/Alpha                       0.0705088
trainer/Alpha Loss                  0.168729
exploration/num steps total     24000
exploration/num paths total       240
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.859429
exploration/Rewards Std             0.643726
exploration/Rewards Max            -0.282098
exploration/Rewards Min            -6.13016
exploration/Returns Mean          -85.9429
exploration/Returns Std            16.0486
exploration/Returns Max           -69.8943
exploration/Returns Min          -101.992
exploration/Actions Mean            0.0275904
exploration/Actions Std             0.202983
exploration/Actions Max             0.997962
exploration/Actions Min            -0.440283
exploration/Num Paths               2
exploration/Average Returns       -85.9429
evaluation/num steps total     119000
evaluation/num paths total       1190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.990415
evaluation/Rewards Std              1.02782
evaluation/Rewards Max             -0.401521
evaluation/Rewards Min            -10.2286
evaluation/Returns Mean           -99.0415
evaluation/Returns Std             34.0392
evaluation/Returns Max            -45.7293
evaluation/Returns Min           -143.942
evaluation/Actions Mean            -0.0197056
evaluation/Actions Std              0.193433
evaluation/Actions Max              0.994809
evaluation/Actions Min             -0.995718
evaluation/Num Paths               10
evaluation/Average Returns        -99.0415
time/data storing (s)               0.00122009
time/evaluation sampling (s)        0.220743
time/exploration sampling (s)       0.066334
time/logging (s)                    0.00376353
time/saving (s)                     0.00224234
time/training (s)                   0.769587
time/epoch (s)                      1.06389
time/total (s)                    126.712
Epoch                             118
-----------------------------  ---------------
2019-04-21 01:13:51.040614 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size              24200
trainer/QF1 Loss                   63.5312
trainer/QF2 Loss                   63.6915
trainer/Policy Loss                67.4319
trainer/Q1 Predictions Mean       -65.8877
trainer/Q1 Predictions Std         10.9221
trainer/Q1 Predictions Max        -56.5573
trainer/Q1 Predictions Min       -124.405
trainer/Q2 Predictions Mean       -65.8969
trainer/Q2 Predictions Std         10.8798
trainer/Q2 Predictions Max        -56.5642
trainer/Q2 Predictions Min       -123.359
trainer/Q Targets Mean            -65.3613
trainer/Q Targets Std              14.2152
trainer/Q Targets Max              -0.992345
trainer/Q Targets Min            -127.902
trainer/Log Pis Mean                2.26015
trainer/Log Pis Std                 1.21248
trainer/Log Pis Max                 6.52469
trainer/Log Pis Min                -1.89837
trainer/Policy mu Mean              0.0927907
trainer/Policy mu Std               0.814378
trainer/Policy mu Max               3.01071
trainer/Policy mu Min              -2.37765
trainer/Policy log std Mean        -1.97435
trainer/Policy log std Std          0.555387
trainer/Policy log std Max         -0.4394
trainer/Policy log std Min         -2.62456
trainer/Alpha                       0.0697243
trainer/Alpha Loss                  0.692826
exploration/num steps total     24200
exploration/num paths total       242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02023
exploration/Rewards Std             1.14694
exploration/Rewards Max            -0.266257
exploration/Rewards Min            -8.26563
exploration/Returns Mean         -102.023
exploration/Returns Std            22.8908
exploration/Returns Max           -79.1325
exploration/Returns Min          -124.914
exploration/Actions Mean            0.0217573
exploration/Actions Std             0.260209
exploration/Actions Max             0.999378
exploration/Actions Min            -0.991815
exploration/Num Paths               2
exploration/Average Returns      -102.023
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.890666
evaluation/Rewards Std              1.07339
evaluation/Rewards Max             -0.279054
evaluation/Rewards Min             -9.51043
evaluation/Returns Mean           -89.0666
evaluation/Returns Std             27.5573
evaluation/Returns Max            -54.8183
evaluation/Returns Min           -139.497
evaluation/Actions Mean             0.0153596
evaluation/Actions Std              0.201996
evaluation/Actions Max              0.993914
evaluation/Actions Min             -0.994059
evaluation/Num Paths               10
evaluation/Average Returns        -89.0666
time/data storing (s)               0.00126931
time/evaluation sampling (s)        0.224616
time/exploration sampling (s)       0.0660069
time/logging (s)                    0.0034502
time/saving (s)                     0.00195507
time/training (s)                   0.773341
time/epoch (s)                      1.07064
time/total (s)                    127.787
Epoch                             119
-----------------------------  ---------------
2019-04-21 01:13:52.110903 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              24400
trainer/QF1 Loss                    0.380611
trainer/QF2 Loss                    0.47018
trainer/Policy Loss                67.7713
trainer/Q1 Predictions Mean       -66.7352
trainer/Q1 Predictions Std         12.8196
trainer/Q1 Predictions Max        -56.8455
trainer/Q1 Predictions Min       -129.25
trainer/Q2 Predictions Mean       -66.7245
trainer/Q2 Predictions Std         12.7469
trainer/Q2 Predictions Max        -56.9571
trainer/Q2 Predictions Min       -128.482
trainer/Q Targets Mean            -67.1176
trainer/Q Targets Std              13.0498
trainer/Q Targets Max             -57.1178
trainer/Q Targets Min            -131.949
trainer/Log Pis Mean                2.3196
trainer/Log Pis Std                 1.15548
trainer/Log Pis Max                 5.90326
trainer/Log Pis Min                -0.941757
trainer/Policy mu Mean             -0.0723092
trainer/Policy mu Std               0.95006
trainer/Policy mu Max               2.92635
trainer/Policy mu Min              -2.72627
trainer/Policy log std Mean        -1.86934
trainer/Policy log std Std          0.588287
trainer/Policy log std Max         -0.390843
trainer/Policy log std Min         -2.58113
trainer/Alpha                       0.0714185
trainer/Alpha Loss                  0.843522
exploration/num steps total     24400
exploration/num paths total       244
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.774405
exploration/Rewards Std             0.813843
exploration/Rewards Max            -0.239271
exploration/Rewards Min            -7.35547
exploration/Returns Mean          -77.4405
exploration/Returns Std             8.97295
exploration/Returns Max           -68.4675
exploration/Returns Min           -86.4135
exploration/Actions Mean            0.0100015
exploration/Actions Std             0.220206
exploration/Actions Max             0.998072
exploration/Actions Min            -0.787343
exploration/Num Paths               2
exploration/Average Returns       -77.4405
evaluation/num steps total     121000
evaluation/num paths total       1210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.973445
evaluation/Rewards Std              0.933106
evaluation/Rewards Max             -0.579192
evaluation/Rewards Min             -8.99474
evaluation/Returns Mean           -97.3445
evaluation/Returns Std             15.0245
evaluation/Returns Max            -65.7381
evaluation/Returns Min           -118.291
evaluation/Actions Mean            -0.00147597
evaluation/Actions Std              0.196151
evaluation/Actions Max              0.993223
evaluation/Actions Min             -0.991738
evaluation/Num Paths               10
evaluation/Average Returns        -97.3445
time/data storing (s)               0.00124137
time/evaluation sampling (s)        0.227596
time/exploration sampling (s)       0.0641113
time/logging (s)                    0.00336974
time/saving (s)                     0.00194523
time/training (s)                   0.765553
time/epoch (s)                      1.06382
time/total (s)                    128.855
Epoch                             120
-----------------------------  ---------------
2019-04-21 01:13:53.184268 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              24600
trainer/QF1 Loss                   52.6906
trainer/QF2 Loss                   52.8311
trainer/Policy Loss                68.1617
trainer/Q1 Predictions Mean       -66.7635
trainer/Q1 Predictions Std         11.4135
trainer/Q1 Predictions Max        -56.6618
trainer/Q1 Predictions Min       -119.958
trainer/Q2 Predictions Mean       -66.7798
trainer/Q2 Predictions Std         11.4412
trainer/Q2 Predictions Max        -56.6667
trainer/Q2 Predictions Min       -120.115
trainer/Q Targets Mean            -66.3876
trainer/Q Targets Std              13.1014
trainer/Q Targets Max              -2.2588
trainer/Q Targets Min            -120.462
trainer/Log Pis Mean                2.2852
trainer/Log Pis Std                 1.16179
trainer/Log Pis Max                 5.68655
trainer/Log Pis Min                -2.49875
trainer/Policy mu Mean              0.084365
trainer/Policy mu Std               0.793502
trainer/Policy mu Max               2.63335
trainer/Policy mu Min              -3.18711
trainer/Policy log std Mean        -2.01099
trainer/Policy log std Std          0.539831
trainer/Policy log std Max         -0.549693
trainer/Policy log std Min         -2.60617
trainer/Alpha                       0.0726371
trainer/Alpha Loss                  0.74791
exploration/num steps total     24600
exploration/num paths total       246
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.910898
exploration/Rewards Std             1.19952
exploration/Rewards Max            -0.333352
exploration/Rewards Min            -9.27318
exploration/Returns Mean          -91.0898
exploration/Returns Std            15.2297
exploration/Returns Max           -75.8601
exploration/Returns Min          -106.32
exploration/Actions Mean            0.044196
exploration/Actions Std             0.226978
exploration/Actions Max             0.998829
exploration/Actions Min            -0.485508
exploration/Num Paths               2
exploration/Average Returns       -91.0898
evaluation/num steps total     122000
evaluation/num paths total       1220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.07768
evaluation/Rewards Std              1.02583
evaluation/Rewards Max             -0.601965
evaluation/Rewards Min            -10.394
evaluation/Returns Mean          -107.768
evaluation/Returns Std             24.32
evaluation/Returns Max            -61.8156
evaluation/Returns Min           -148.148
evaluation/Actions Mean             0.00527284
evaluation/Actions Std              0.193363
evaluation/Actions Max              0.994632
evaluation/Actions Min             -0.993459
evaluation/Num Paths               10
evaluation/Average Returns       -107.768
time/data storing (s)               0.00124472
time/evaluation sampling (s)        0.224309
time/exploration sampling (s)       0.0632524
time/logging (s)                    0.00337885
time/saving (s)                     0.00196804
time/training (s)                   0.772647
time/epoch (s)                      1.0668
time/total (s)                    129.926
Epoch                             121
-----------------------------  ---------------
2019-04-21 01:13:54.259175 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              24800
trainer/QF1 Loss                    0.269136
trainer/QF2 Loss                    0.29223
trainer/Policy Loss                66.6819
trainer/Q1 Predictions Mean       -65.2573
trainer/Q1 Predictions Std         10.2281
trainer/Q1 Predictions Max        -56.5665
trainer/Q1 Predictions Min       -101.733
trainer/Q2 Predictions Mean       -65.2773
trainer/Q2 Predictions Std         10.2593
trainer/Q2 Predictions Max        -56.5795
trainer/Q2 Predictions Min       -101.33
trainer/Q Targets Mean            -65.5684
trainer/Q Targets Std              10.1929
trainer/Q Targets Max             -56.8301
trainer/Q Targets Min            -101.633
trainer/Log Pis Mean                2.13431
trainer/Log Pis Std                 1.32045
trainer/Log Pis Max                 4.90046
trainer/Log Pis Min                -3.50808
trainer/Policy mu Mean              0.0890924
trainer/Policy mu Std               0.835202
trainer/Policy mu Max               2.84886
trainer/Policy mu Min              -2.49646
trainer/Policy log std Mean        -2.00814
trainer/Policy log std Std          0.57009
trainer/Policy log std Max         -0.451856
trainer/Policy log std Min         -2.59633
trainer/Alpha                       0.0746045
trainer/Alpha Loss                  0.348625
exploration/num steps total     24800
exploration/num paths total       248
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10617
exploration/Rewards Std             1.15527
exploration/Rewards Max            -0.241415
exploration/Rewards Min            -8.74094
exploration/Returns Mean         -110.617
exploration/Returns Std            21.5936
exploration/Returns Max           -89.023
exploration/Returns Min          -132.21
exploration/Actions Mean           -0.0339429
exploration/Actions Std             0.256964
exploration/Actions Max             0.994758
exploration/Actions Min            -0.99199
exploration/Num Paths               2
exploration/Average Returns      -110.617
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0748
evaluation/Rewards Std              1.09102
evaluation/Rewards Max             -0.554788
evaluation/Rewards Min            -10.0997
evaluation/Returns Mean          -107.48
evaluation/Returns Std             21.645
evaluation/Returns Max            -71.9539
evaluation/Returns Min           -140.271
evaluation/Actions Mean             0.0154765
evaluation/Actions Std              0.212403
evaluation/Actions Max              0.995993
evaluation/Actions Min             -0.993817
evaluation/Num Paths               10
evaluation/Average Returns       -107.48
time/data storing (s)               0.00145147
time/evaluation sampling (s)        0.227325
time/exploration sampling (s)       0.0650039
time/logging (s)                    0.00338305
time/saving (s)                     0.00157993
time/training (s)                   0.769453
time/epoch (s)                      1.0682
time/total (s)                    130.999
Epoch                             122
-----------------------------  ---------------
2019-04-21 01:13:55.331679 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              25000
trainer/QF1 Loss                    0.516911
trainer/QF2 Loss                    0.541201
trainer/Policy Loss                66.4909
trainer/Q1 Predictions Mean       -65.3626
trainer/Q1 Predictions Std         11.4173
trainer/Q1 Predictions Max        -56.1974
trainer/Q1 Predictions Min       -114.657
trainer/Q2 Predictions Mean       -65.36
trainer/Q2 Predictions Std         11.4076
trainer/Q2 Predictions Max        -56.2072
trainer/Q2 Predictions Min       -114.502
trainer/Q Targets Mean            -65.8956
trainer/Q Targets Std              11.6089
trainer/Q Targets Max             -56.5785
trainer/Q Targets Min            -116.933
trainer/Log Pis Mean                2.0318
trainer/Log Pis Std                 1.31095
trainer/Log Pis Max                 6.62578
trainer/Log Pis Min                -2.31289
trainer/Policy mu Mean              0.0495247
trainer/Policy mu Std               0.834751
trainer/Policy mu Max               2.88799
trainer/Policy mu Min              -2.56842
trainer/Policy log std Mean        -1.96278
trainer/Policy log std Std          0.54202
trainer/Policy log std Max         -0.471217
trainer/Policy log std Min         -2.60304
trainer/Alpha                       0.0730445
trainer/Alpha Loss                  0.0832028
exploration/num steps total     25000
exploration/num paths total       250
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.21666
exploration/Rewards Std             1.58578
exploration/Rewards Max            -0.244124
exploration/Rewards Min            -9.88995
exploration/Returns Mean         -121.666
exploration/Returns Std            18.7315
exploration/Returns Max          -102.935
exploration/Returns Min          -140.398
exploration/Actions Mean            0.00793549
exploration/Actions Std             0.263123
exploration/Actions Max             0.995808
exploration/Actions Min            -0.997971
exploration/Num Paths               2
exploration/Average Returns      -121.666
evaluation/num steps total     124000
evaluation/num paths total       1240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01115
evaluation/Rewards Std              0.862929
evaluation/Rewards Max             -0.404153
evaluation/Rewards Min            -10.5851
evaluation/Returns Mean          -101.115
evaluation/Returns Std             14.5812
evaluation/Returns Max            -59.0055
evaluation/Returns Min           -115.356
evaluation/Actions Mean             0.00492904
evaluation/Actions Std              0.172938
evaluation/Actions Max              0.997363
evaluation/Actions Min             -0.988715
evaluation/Num Paths               10
evaluation/Average Returns       -101.115
time/data storing (s)               0.00124974
time/evaluation sampling (s)        0.222297
time/exploration sampling (s)       0.062582
time/logging (s)                    0.00340226
time/saving (s)                     0.00195374
time/training (s)                   0.774407
time/epoch (s)                      1.06589
time/total (s)                    132.069
Epoch                             123
-----------------------------  ---------------
2019-04-21 01:13:56.386746 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              25200
trainer/QF1 Loss                   49.9142
trainer/QF2 Loss                   49.6
trainer/Policy Loss                65.8012
trainer/Q1 Predictions Mean       -64.4611
trainer/Q1 Predictions Std         11.1917
trainer/Q1 Predictions Max        -55.5888
trainer/Q1 Predictions Min       -133.718
trainer/Q2 Predictions Mean       -64.4754
trainer/Q2 Predictions Std         11.2009
trainer/Q2 Predictions Max        -55.5603
trainer/Q2 Predictions Min       -133.337
trainer/Q Targets Mean            -64.3097
trainer/Q Targets Std              12.3945
trainer/Q Targets Max              -0.877416
trainer/Q Targets Min            -129.352
trainer/Log Pis Mean                2.05341
trainer/Log Pis Std                 1.52168
trainer/Log Pis Max                 8.41121
trainer/Log Pis Min                -2.22563
trainer/Policy mu Mean             -0.0165515
trainer/Policy mu Std               0.881663
trainer/Policy mu Max               2.93644
trainer/Policy mu Min              -3.19395
trainer/Policy log std Mean        -1.91181
trainer/Policy log std Std          0.560615
trainer/Policy log std Max         -0.485278
trainer/Policy log std Min         -2.53486
trainer/Alpha                       0.0734134
trainer/Alpha Loss                  0.139479
exploration/num steps total     25200
exploration/num paths total       252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.691204
exploration/Rewards Std             0.745753
exploration/Rewards Max            -0.194854
exploration/Rewards Min            -6.08497
exploration/Returns Mean          -69.1204
exploration/Returns Std             3.74563
exploration/Returns Max           -65.3748
exploration/Returns Min           -72.8661
exploration/Actions Mean            0.0332261
exploration/Actions Std             0.212641
exploration/Actions Max             0.999414
exploration/Actions Min            -0.549593
exploration/Num Paths               2
exploration/Average Returns       -69.1204
evaluation/num steps total     125000
evaluation/num paths total       1250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.839349
evaluation/Rewards Std              0.927351
evaluation/Rewards Max             -0.291392
evaluation/Rewards Min             -9.51771
evaluation/Returns Mean           -83.9349
evaluation/Returns Std             25.0868
evaluation/Returns Max            -52.7668
evaluation/Returns Min           -134.595
evaluation/Actions Mean             0.0128805
evaluation/Actions Std              0.171539
evaluation/Actions Max              0.995396
evaluation/Actions Min             -0.988487
evaluation/Num Paths               10
evaluation/Average Returns        -83.9349
time/data storing (s)               0.00130519
time/evaluation sampling (s)        0.227701
time/exploration sampling (s)       0.0638438
time/logging (s)                    0.00337674
time/saving (s)                     0.00195644
time/training (s)                   0.7502
time/epoch (s)                      1.04838
time/total (s)                    133.122
Epoch                             124
-----------------------------  ---------------
2019-04-21 01:13:57.461489 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 125 finished
-----------------------------  ----------------
replay_buffer/size              25400
trainer/QF1 Loss                   89.0144
trainer/QF2 Loss                   87.8198
trainer/Policy Loss                66.7318
trainer/Q1 Predictions Mean       -65.7468
trainer/Q1 Predictions Std         10.6224
trainer/Q1 Predictions Max        -55.7197
trainer/Q1 Predictions Min       -121.433
trainer/Q2 Predictions Mean       -65.7732
trainer/Q2 Predictions Std         10.599
trainer/Q2 Predictions Max        -55.6996
trainer/Q2 Predictions Min       -120.495
trainer/Q Targets Mean            -65.1381
trainer/Q Targets Std              13.9137
trainer/Q Targets Max              -2.16532
trainer/Q Targets Min            -123.839
trainer/Log Pis Mean                1.8861
trainer/Log Pis Std                 1.35504
trainer/Log Pis Max                 5.49106
trainer/Log Pis Min                -3.61994
trainer/Policy mu Mean              0.0649512
trainer/Policy mu Std               0.922602
trainer/Policy mu Max               3.02623
trainer/Policy mu Min              -2.58946
trainer/Policy log std Mean        -1.79374
trainer/Policy log std Std          0.569184
trainer/Policy log std Max         -0.388443
trainer/Policy log std Min         -2.48893
trainer/Alpha                       0.0726642
trainer/Alpha Loss                 -0.298604
exploration/num steps total     25400
exploration/num paths total       254
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.602269
exploration/Rewards Std             0.700497
exploration/Rewards Max            -0.231596
exploration/Rewards Min            -6.56756
exploration/Returns Mean          -60.2269
exploration/Returns Std            10.313
exploration/Returns Max           -49.9139
exploration/Returns Min           -70.5399
exploration/Actions Mean            0.0147055
exploration/Actions Std             0.177754
exploration/Actions Max             0.997385
exploration/Actions Min            -0.547157
exploration/Num Paths               2
exploration/Average Returns       -60.2269
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.922875
evaluation/Rewards Std              0.950513
evaluation/Rewards Max             -0.459909
evaluation/Rewards Min            -10.74
evaluation/Returns Mean           -92.2875
evaluation/Returns Std             30.0235
evaluation/Returns Max            -57.3591
evaluation/Returns Min           -145.177
evaluation/Actions Mean            -0.000450298
evaluation/Actions Std              0.19422
evaluation/Actions Max              0.994027
evaluation/Actions Min             -0.994801
evaluation/Num Paths               10
evaluation/Average Returns        -92.2875
time/data storing (s)               0.0014725
time/evaluation sampling (s)        0.225194
time/exploration sampling (s)       0.0643644
time/logging (s)                    0.0033747
time/saving (s)                     0.00196961
time/training (s)                   0.771748
time/epoch (s)                      1.06812
time/total (s)                    134.194
Epoch                             125
-----------------------------  ----------------
2019-04-21 01:13:58.514185 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 126 finished
-----------------------------  ----------------
replay_buffer/size              25600
trainer/QF1 Loss                    0.801099
trainer/QF2 Loss                    0.726628
trainer/Policy Loss                65.9257
trainer/Q1 Predictions Mean       -65.0301
trainer/Q1 Predictions Std          7.68341
trainer/Q1 Predictions Max        -55.6008
trainer/Q1 Predictions Min        -89.2217
trainer/Q2 Predictions Mean       -65.0528
trainer/Q2 Predictions Std          7.68321
trainer/Q2 Predictions Max        -55.6365
trainer/Q2 Predictions Min        -89.1085
trainer/Q Targets Mean            -65.8009
trainer/Q Targets Std               7.70439
trainer/Q Targets Max             -56.1093
trainer/Q Targets Min             -87.445
trainer/Log Pis Mean                1.55441
trainer/Log Pis Std                 1.43678
trainer/Log Pis Max                 4.0664
trainer/Log Pis Min                -3.95415
trainer/Policy mu Mean              0.113082
trainer/Policy mu Std               0.724308
trainer/Policy mu Max               2.4969
trainer/Policy mu Min              -2.5488
trainer/Policy log std Mean        -1.96549
trainer/Policy log std Std          0.510248
trainer/Policy log std Max         -0.396134
trainer/Policy log std Min         -2.59283
trainer/Alpha                       0.0728861
trainer/Alpha Loss                 -1.16693
exploration/num steps total     25600
exploration/num paths total       256
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.791527
exploration/Rewards Std             0.298638
exploration/Rewards Max            -0.325082
exploration/Rewards Min            -2.50395
exploration/Returns Mean          -79.1527
exploration/Returns Std            18.8811
exploration/Returns Max           -60.2716
exploration/Returns Min           -98.0338
exploration/Actions Mean            0.000363943
exploration/Actions Std             0.164878
exploration/Actions Max             0.722083
exploration/Actions Min            -0.908879
exploration/Num Paths               2
exploration/Average Returns       -79.1527
evaluation/num steps total     127000
evaluation/num paths total       1270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.757731
evaluation/Rewards Std              0.58877
evaluation/Rewards Max             -0.269219
evaluation/Rewards Min             -6.81769
evaluation/Returns Mean           -75.7731
evaluation/Returns Std             24.0751
evaluation/Returns Max            -48.5994
evaluation/Returns Min           -109.16
evaluation/Actions Mean            -1.79639e-05
evaluation/Actions Std              0.154354
evaluation/Actions Max              0.989936
evaluation/Actions Min             -0.991382
evaluation/Num Paths               10
evaluation/Average Returns        -75.7731
time/data storing (s)               0.0014259
time/evaluation sampling (s)        0.22206
time/exploration sampling (s)       0.0674237
time/logging (s)                    0.00339982
time/saving (s)                     0.00196028
time/training (s)                   0.750173
time/epoch (s)                      1.04644
time/total (s)                    135.245
Epoch                             126
-----------------------------  ----------------
2019-04-21 01:13:59.592211 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              25800
trainer/QF1 Loss                    0.433885
trainer/QF2 Loss                    0.476563
trainer/Policy Loss                65.1964
trainer/Q1 Predictions Mean       -63.872
trainer/Q1 Predictions Std          8.36063
trainer/Q1 Predictions Max        -55.74
trainer/Q1 Predictions Min       -112.029
trainer/Q2 Predictions Mean       -63.8606
trainer/Q2 Predictions Std          8.38752
trainer/Q2 Predictions Max        -55.7261
trainer/Q2 Predictions Min       -112.478
trainer/Q Targets Mean            -64.3456
trainer/Q Targets Std               8.48336
trainer/Q Targets Max             -55.8913
trainer/Q Targets Min            -111.302
trainer/Log Pis Mean                2.1809
trainer/Log Pis Std                 0.996847
trainer/Log Pis Max                 5.09973
trainer/Log Pis Min                -1.7627
trainer/Policy mu Mean              0.01301
trainer/Policy mu Std               0.832025
trainer/Policy mu Max               2.49463
trainer/Policy mu Min              -3.20314
trainer/Policy log std Mean        -1.86634
trainer/Policy log std Std          0.525356
trainer/Policy log std Max         -0.346385
trainer/Policy log std Min         -2.54582
trainer/Alpha                       0.0733036
trainer/Alpha Loss                  0.472733
exploration/num steps total     25800
exploration/num paths total       258
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.950142
exploration/Rewards Std             1.29057
exploration/Rewards Max            -0.161807
exploration/Rewards Min           -10.2117
exploration/Returns Mean          -95.0142
exploration/Returns Std             1.95901
exploration/Returns Max           -93.0552
exploration/Returns Min           -96.9733
exploration/Actions Mean            0.0305119
exploration/Actions Std             0.23712
exploration/Actions Max             0.999243
exploration/Actions Min            -0.849494
exploration/Num Paths               2
exploration/Average Returns       -95.0142
evaluation/num steps total     128000
evaluation/num paths total       1280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.735686
evaluation/Rewards Std              0.942084
evaluation/Rewards Max             -0.331298
evaluation/Rewards Min             -8.74216
evaluation/Returns Mean           -73.5686
evaluation/Returns Std             21.7484
evaluation/Returns Max            -40.4819
evaluation/Returns Min           -107.818
evaluation/Actions Mean             0.0127783
evaluation/Actions Std              0.187476
evaluation/Actions Max              0.994287
evaluation/Actions Min             -0.981466
evaluation/Num Paths               10
evaluation/Average Returns        -73.5686
time/data storing (s)               0.00125148
time/evaluation sampling (s)        0.224756
time/exploration sampling (s)       0.0647654
time/logging (s)                    0.00339328
time/saving (s)                     0.00196083
time/training (s)                   0.775234
time/epoch (s)                      1.07136
time/total (s)                    136.321
Epoch                             127
-----------------------------  ---------------
2019-04-21 01:14:00.659173 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              26000
trainer/QF1 Loss                   61.1831
trainer/QF2 Loss                   61.6358
trainer/Policy Loss                65.2095
trainer/Q1 Predictions Mean       -63.9554
trainer/Q1 Predictions Std          9.97065
trainer/Q1 Predictions Max        -55.6667
trainer/Q1 Predictions Min       -119.184
trainer/Q2 Predictions Mean       -63.9585
trainer/Q2 Predictions Std          9.92104
trainer/Q2 Predictions Max        -55.6751
trainer/Q2 Predictions Min       -119.124
trainer/Q Targets Mean            -63.3909
trainer/Q Targets Std              13.4842
trainer/Q Targets Max              -1.51225
trainer/Q Targets Min            -122.62
trainer/Log Pis Mean                1.9671
trainer/Log Pis Std                 1.14244
trainer/Log Pis Max                 4.71214
trainer/Log Pis Min                -2.34861
trainer/Policy mu Mean              0.144938
trainer/Policy mu Std               0.728052
trainer/Policy mu Max               2.94427
trainer/Policy mu Min              -2.21388
trainer/Policy log std Mean        -1.99975
trainer/Policy log std Std          0.47953
trainer/Policy log std Max         -0.580082
trainer/Policy log std Min         -2.51147
trainer/Alpha                       0.0734402
trainer/Alpha Loss                 -0.0858998
exploration/num steps total     26000
exploration/num paths total       260
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.811254
exploration/Rewards Std             0.84888
exploration/Rewards Max            -0.133324
exploration/Rewards Min            -6.80027
exploration/Returns Mean          -81.1254
exploration/Returns Std            31.8472
exploration/Returns Max           -49.2782
exploration/Returns Min          -112.973
exploration/Actions Mean            0.0118276
exploration/Actions Std             0.223444
exploration/Actions Max             0.979421
exploration/Actions Min            -0.994692
exploration/Num Paths               2
exploration/Average Returns       -81.1254
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.762036
evaluation/Rewards Std              0.935043
evaluation/Rewards Max             -0.336415
evaluation/Rewards Min             -9.13906
evaluation/Returns Mean           -76.2036
evaluation/Returns Std             34.5144
evaluation/Returns Max            -37.6188
evaluation/Returns Min           -131.529
evaluation/Actions Mean            -0.00116238
evaluation/Actions Std              0.176842
evaluation/Actions Max              0.994347
evaluation/Actions Min             -0.993494
evaluation/Num Paths               10
evaluation/Average Returns        -76.2036
time/data storing (s)               0.00121559
time/evaluation sampling (s)        0.222995
time/exploration sampling (s)       0.0635001
time/logging (s)                    0.00339394
time/saving (s)                     0.00194957
time/training (s)                   0.767177
time/epoch (s)                      1.06023
time/total (s)                    137.385
Epoch                             128
-----------------------------  ---------------
2019-04-21 01:14:01.726693 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              26200
trainer/QF1 Loss                   77.9515
trainer/QF2 Loss                   77.9482
trainer/Policy Loss                63.0607
trainer/Q1 Predictions Mean       -61.303
trainer/Q1 Predictions Std          7.6866
trainer/Q1 Predictions Max        -55.4426
trainer/Q1 Predictions Min        -90.531
trainer/Q2 Predictions Mean       -61.3026
trainer/Q2 Predictions Std          7.6981
trainer/Q2 Predictions Max        -55.4001
trainer/Q2 Predictions Min        -90.2116
trainer/Q Targets Mean            -60.483
trainer/Q Targets Std              11.1987
trainer/Q Targets Max              -1.19891
trainer/Q Targets Min             -88.4637
trainer/Log Pis Mean                2.26565
trainer/Log Pis Std                 0.942932
trainer/Log Pis Max                 5.30575
trainer/Log Pis Min                -0.778308
trainer/Policy mu Mean              0.0232122
trainer/Policy mu Std               0.742792
trainer/Policy mu Max               2.57771
trainer/Policy mu Min              -2.75323
trainer/Policy log std Mean        -2.03833
trainer/Policy log std Std          0.522098
trainer/Policy log std Max         -0.378881
trainer/Policy log std Min         -2.52646
trainer/Alpha                       0.0728056
trainer/Alpha Loss                  0.696011
exploration/num steps total     26200
exploration/num paths total       262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.86843
exploration/Rewards Std             1.18034
exploration/Rewards Max            -0.204461
exploration/Rewards Min            -9.42645
exploration/Returns Mean          -86.843
exploration/Returns Std            36.4112
exploration/Returns Max           -50.4318
exploration/Returns Min          -123.254
exploration/Actions Mean           -0.0341634
exploration/Actions Std             0.230453
exploration/Actions Max             0.988527
exploration/Actions Min            -0.99724
exploration/Num Paths               2
exploration/Average Returns       -86.843
evaluation/num steps total     130000
evaluation/num paths total       1300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.865339
evaluation/Rewards Std              0.892304
evaluation/Rewards Max             -0.368061
evaluation/Rewards Min            -10.0386
evaluation/Returns Mean           -86.5339
evaluation/Returns Std             19.3188
evaluation/Returns Max            -43.9191
evaluation/Returns Min           -120.736
evaluation/Actions Mean             0.0124281
evaluation/Actions Std              0.193665
evaluation/Actions Max              0.993765
evaluation/Actions Min             -0.9939
evaluation/Num Paths               10
evaluation/Average Returns        -86.5339
time/data storing (s)               0.001457
time/evaluation sampling (s)        0.221517
time/exploration sampling (s)       0.0648708
time/logging (s)                    0.00331423
time/saving (s)                     0.001943
time/training (s)                   0.767567
time/epoch (s)                      1.06067
time/total (s)                    138.45
Epoch                             129
-----------------------------  ---------------
2019-04-21 01:14:02.787543 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              26400
trainer/QF1 Loss                    0.782349
trainer/QF2 Loss                    0.787068
trainer/Policy Loss                64.27
trainer/Q1 Predictions Mean       -63.1937
trainer/Q1 Predictions Std          7.49631
trainer/Q1 Predictions Max        -54.8261
trainer/Q1 Predictions Min        -92.5799
trainer/Q2 Predictions Mean       -63.196
trainer/Q2 Predictions Std          7.46958
trainer/Q2 Predictions Max        -54.8451
trainer/Q2 Predictions Min        -92.0384
trainer/Q Targets Mean            -63.9105
trainer/Q Targets Std               7.50653
trainer/Q Targets Max             -55.5696
trainer/Q Targets Min             -96.4156
trainer/Log Pis Mean                1.91663
trainer/Log Pis Std                 1.38038
trainer/Log Pis Max                 5.96186
trainer/Log Pis Min                -3.85333
trainer/Policy mu Mean              0.165623
trainer/Policy mu Std               0.742913
trainer/Policy mu Max               2.4651
trainer/Policy mu Min              -2.38846
trainer/Policy log std Mean        -1.93922
trainer/Policy log std Std          0.518498
trainer/Policy log std Max         -0.392395
trainer/Policy log std Min         -2.56676
trainer/Alpha                       0.0737115
trainer/Alpha Loss                 -0.217404
exploration/num steps total     26400
exploration/num paths total       264
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.06195
exploration/Rewards Std             1.2981
exploration/Rewards Max            -0.189919
exploration/Rewards Min            -8.72413
exploration/Returns Mean         -106.195
exploration/Returns Std            15.4712
exploration/Returns Max           -90.7237
exploration/Returns Min          -121.666
exploration/Actions Mean            0.00723665
exploration/Actions Std             0.245014
exploration/Actions Max             0.998176
exploration/Actions Min            -0.999135
exploration/Num Paths               2
exploration/Average Returns      -106.195
evaluation/num steps total     131000
evaluation/num paths total       1310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.029
evaluation/Rewards Std              1.07272
evaluation/Rewards Max             -0.496747
evaluation/Rewards Min            -10.3161
evaluation/Returns Mean          -102.9
evaluation/Returns Std             23.5531
evaluation/Returns Max            -61.4831
evaluation/Returns Min           -142.084
evaluation/Actions Mean             0.0061232
evaluation/Actions Std              0.19471
evaluation/Actions Max              0.995076
evaluation/Actions Min             -0.995161
evaluation/Num Paths               10
evaluation/Average Returns       -102.9
time/data storing (s)               0.00132381
time/evaluation sampling (s)        0.22611
time/exploration sampling (s)       0.0656519
time/logging (s)                    0.00334447
time/saving (s)                     0.00193192
time/training (s)                   0.755721
time/epoch (s)                      1.05408
time/total (s)                    139.509
Epoch                             130
-----------------------------  ---------------
2019-04-21 01:14:03.853305 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              26600
trainer/QF1 Loss                    0.261665
trainer/QF2 Loss                    0.207104
trainer/Policy Loss                64.5257
trainer/Q1 Predictions Mean       -63.4645
trainer/Q1 Predictions Std          9.40846
trainer/Q1 Predictions Max        -55.5609
trainer/Q1 Predictions Min       -118.475
trainer/Q2 Predictions Mean       -63.4713
trainer/Q2 Predictions Std          9.40717
trainer/Q2 Predictions Max        -55.4654
trainer/Q2 Predictions Min       -118.361
trainer/Q Targets Mean            -63.6477
trainer/Q Targets Std               9.48731
trainer/Q Targets Max             -55.5606
trainer/Q Targets Min            -119.241
trainer/Log Pis Mean                2.15427
trainer/Log Pis Std                 1.29688
trainer/Log Pis Max                 6.90304
trainer/Log Pis Min                -2.07325
trainer/Policy mu Mean              0.0241737
trainer/Policy mu Std               0.928301
trainer/Policy mu Max               2.63959
trainer/Policy mu Min              -3.30046
trainer/Policy log std Mean        -1.84959
trainer/Policy log std Std          0.570373
trainer/Policy log std Max         -0.446132
trainer/Policy log std Min         -2.54628
trainer/Alpha                       0.0743766
trainer/Alpha Loss                  0.400924
exploration/num steps total     26600
exploration/num paths total       266
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.914056
exploration/Rewards Std             1.04625
exploration/Rewards Max            -0.163657
exploration/Rewards Min            -8.2043
exploration/Returns Mean          -91.4056
exploration/Returns Std            30.7851
exploration/Returns Max           -60.6204
exploration/Returns Min          -122.191
exploration/Actions Mean           -0.0303047
exploration/Actions Std             0.22442
exploration/Actions Max             0.935948
exploration/Actions Min            -0.984498
exploration/Num Paths               2
exploration/Average Returns       -91.4056
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.801999
evaluation/Rewards Std              0.841051
evaluation/Rewards Max             -0.408258
evaluation/Rewards Min             -8.85372
evaluation/Returns Mean           -80.1999
evaluation/Returns Std             28.2667
evaluation/Returns Max            -41.7421
evaluation/Returns Min           -125.131
evaluation/Actions Mean             0.00254799
evaluation/Actions Std              0.168482
evaluation/Actions Max              0.994328
evaluation/Actions Min             -0.992899
evaluation/Num Paths               10
evaluation/Average Returns        -80.1999
time/data storing (s)               0.00122991
time/evaluation sampling (s)        0.218886
time/exploration sampling (s)       0.0643264
time/logging (s)                    0.00335652
time/saving (s)                     0.00194758
time/training (s)                   0.76928
time/epoch (s)                      1.05903
time/total (s)                    140.572
Epoch                             131
-----------------------------  ---------------
2019-04-21 01:14:04.918086 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              26800
trainer/QF1 Loss                    0.315974
trainer/QF2 Loss                    0.281774
trainer/Policy Loss                63.9552
trainer/Q1 Predictions Mean       -62.5354
trainer/Q1 Predictions Std          8.69803
trainer/Q1 Predictions Max        -54.8153
trainer/Q1 Predictions Min       -106.81
trainer/Q2 Predictions Mean       -62.5491
trainer/Q2 Predictions Std          8.68823
trainer/Q2 Predictions Max        -54.8153
trainer/Q2 Predictions Min       -106.563
trainer/Q Targets Mean            -62.9847
trainer/Q Targets Std               8.65069
trainer/Q Targets Max             -55.2304
trainer/Q Targets Min            -106.838
trainer/Log Pis Mean                2.08478
trainer/Log Pis Std                 0.896816
trainer/Log Pis Max                 4.14144
trainer/Log Pis Min                -0.112618
trainer/Policy mu Mean              0.160125
trainer/Policy mu Std               0.739717
trainer/Policy mu Max               2.86313
trainer/Policy mu Min              -1.94347
trainer/Policy log std Mean        -1.98528
trainer/Policy log std Std          0.498431
trainer/Policy log std Max         -0.697999
trainer/Policy log std Min         -2.58505
trainer/Alpha                       0.0761871
trainer/Alpha Loss                  0.21829
exploration/num steps total     26800
exploration/num paths total       268
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.79734
exploration/Rewards Std             0.688755
exploration/Rewards Max            -0.165446
exploration/Rewards Min            -6.7941
exploration/Returns Mean          -79.734
exploration/Returns Std            35.7012
exploration/Returns Max           -44.0327
exploration/Returns Min          -115.435
exploration/Actions Mean            0.00918952
exploration/Actions Std             0.198868
exploration/Actions Max             0.997263
exploration/Actions Min            -0.987659
exploration/Num Paths               2
exploration/Average Returns       -79.734
evaluation/num steps total     133000
evaluation/num paths total       1330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.93187
evaluation/Rewards Std              0.791878
evaluation/Rewards Max             -0.0474304
evaluation/Rewards Min             -9.93123
evaluation/Returns Mean           -93.187
evaluation/Returns Std             33.0535
evaluation/Returns Max            -40.3432
evaluation/Returns Min           -139.395
evaluation/Actions Mean            -0.00711399
evaluation/Actions Std              0.161666
evaluation/Actions Max              0.986577
evaluation/Actions Min             -0.994861
evaluation/Num Paths               10
evaluation/Average Returns        -93.187
time/data storing (s)               0.00142771
time/evaluation sampling (s)        0.22184
time/exploration sampling (s)       0.0639283
time/logging (s)                    0.00333515
time/saving (s)                     0.00196117
time/training (s)                   0.765607
time/epoch (s)                      1.0581
time/total (s)                    141.634
Epoch                             132
-----------------------------  ---------------
2019-04-21 01:14:05.982004 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              27000
trainer/QF1 Loss                  127.945
trainer/QF2 Loss                  127.946
trainer/Policy Loss                64.1089
trainer/Q1 Predictions Mean       -63.0592
trainer/Q1 Predictions Std         10.6048
trainer/Q1 Predictions Max        -54.7799
trainer/Q1 Predictions Min       -117.86
trainer/Q2 Predictions Mean       -63.0669
trainer/Q2 Predictions Std         10.6248
trainer/Q2 Predictions Max        -54.7243
trainer/Q2 Predictions Min       -117.981
trainer/Q Targets Mean            -61.2652
trainer/Q Targets Std              16.2695
trainer/Q Targets Max              -0.902575
trainer/Q Targets Min            -121.304
trainer/Log Pis Mean                2.11625
trainer/Log Pis Std                 1.17916
trainer/Log Pis Max                 5.2129
trainer/Log Pis Min                -1.06218
trainer/Policy mu Mean              0.187065
trainer/Policy mu Std               0.875437
trainer/Policy mu Max               3.07645
trainer/Policy mu Min              -2.71956
trainer/Policy log std Mean        -1.93608
trainer/Policy log std Std          0.567658
trainer/Policy log std Max         -0.415325
trainer/Policy log std Min         -2.60596
trainer/Alpha                       0.0760006
trainer/Alpha Loss                  0.299574
exploration/num steps total     27000
exploration/num paths total       270
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.64276
exploration/Rewards Std             0.345889
exploration/Rewards Max            -0.123242
exploration/Rewards Min            -1.1927
exploration/Returns Mean          -64.276
exploration/Returns Std            32.9752
exploration/Returns Max           -31.3008
exploration/Returns Min           -97.2512
exploration/Actions Mean            0.0091805
exploration/Actions Std             0.14091
exploration/Actions Max             0.834579
exploration/Actions Min            -0.297402
exploration/Num Paths               2
exploration/Average Returns       -64.276
evaluation/num steps total     134000
evaluation/num paths total       1340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.663106
evaluation/Rewards Std              0.691153
evaluation/Rewards Max             -0.278618
evaluation/Rewards Min             -7.77625
evaluation/Returns Mean           -66.3106
evaluation/Returns Std             35.3737
evaluation/Returns Max            -30.0435
evaluation/Returns Min           -119.396
evaluation/Actions Mean             0.00322399
evaluation/Actions Std              0.158185
evaluation/Actions Max              0.993874
evaluation/Actions Min             -0.987202
evaluation/Num Paths               10
evaluation/Average Returns        -66.3106
time/data storing (s)               0.00148578
time/evaluation sampling (s)        0.224316
time/exploration sampling (s)       0.0667745
time/logging (s)                    0.00338847
time/saving (s)                     0.00193138
time/training (s)                   0.759527
time/epoch (s)                      1.05742
time/total (s)                    142.696
Epoch                             133
-----------------------------  ---------------
2019-04-21 01:14:07.047706 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              27200
trainer/QF1 Loss                    0.253744
trainer/QF2 Loss                    0.236864
trainer/Policy Loss                63.5179
trainer/Q1 Predictions Mean       -62.2811
trainer/Q1 Predictions Std          7.33233
trainer/Q1 Predictions Max        -54.7294
trainer/Q1 Predictions Min       -109.917
trainer/Q2 Predictions Mean       -62.275
trainer/Q2 Predictions Std          7.35533
trainer/Q2 Predictions Max        -54.7311
trainer/Q2 Predictions Min       -109.798
trainer/Q Targets Mean            -62.5997
trainer/Q Targets Std               7.36655
trainer/Q Targets Max             -55.1105
trainer/Q Targets Min            -110.949
trainer/Log Pis Mean                1.96139
trainer/Log Pis Std                 1.2016
trainer/Log Pis Max                 6.24727
trainer/Log Pis Min                -2.89238
trainer/Policy mu Mean              0.177173
trainer/Policy mu Std               0.763605
trainer/Policy mu Max               3.03413
trainer/Policy mu Min              -2.6255
trainer/Policy log std Mean        -1.98653
trainer/Policy log std Std          0.542242
trainer/Policy log std Max         -0.318258
trainer/Policy log std Min         -2.62875
trainer/Alpha                       0.0760085
trainer/Alpha Loss                 -0.099497
exploration/num steps total     27200
exploration/num paths total       272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.870087
exploration/Rewards Std             1.01925
exploration/Rewards Max            -0.155336
exploration/Rewards Min            -8.48533
exploration/Returns Mean          -87.0087
exploration/Returns Std            43.6477
exploration/Returns Max           -43.361
exploration/Returns Min          -130.656
exploration/Actions Mean           -0.0150158
exploration/Actions Std             0.211696
exploration/Actions Max             0.915689
exploration/Actions Min            -0.996789
exploration/Num Paths               2
exploration/Average Returns       -87.0087
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.849291
evaluation/Rewards Std              1.16516
evaluation/Rewards Max             -0.374743
evaluation/Rewards Min            -10.7801
evaluation/Returns Mean           -84.9291
evaluation/Returns Std             30.2548
evaluation/Returns Max            -38.0855
evaluation/Returns Min           -139.219
evaluation/Actions Mean             0.0197822
evaluation/Actions Std              0.194332
evaluation/Actions Max              0.996669
evaluation/Actions Min             -0.993725
evaluation/Num Paths               10
evaluation/Average Returns        -84.9291
time/data storing (s)               0.00125904
time/evaluation sampling (s)        0.224635
time/exploration sampling (s)       0.0694448
time/logging (s)                    0.00337686
time/saving (s)                     0.00198153
time/training (s)                   0.758195
time/epoch (s)                      1.05889
time/total (s)                    143.759
Epoch                             134
-----------------------------  ---------------
2019-04-21 01:14:08.120099 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              27400
trainer/QF1 Loss                   28.8624
trainer/QF2 Loss                   29.0131
trainer/Policy Loss                63.3468
trainer/Q1 Predictions Mean       -62.2086
trainer/Q1 Predictions Std          8.67918
trainer/Q1 Predictions Max        -53.8437
trainer/Q1 Predictions Min        -99.5936
trainer/Q2 Predictions Mean       -62.1781
trainer/Q2 Predictions Std          8.65537
trainer/Q2 Predictions Max        -53.76
trainer/Q2 Predictions Min        -98.9681
trainer/Q Targets Mean            -62.2781
trainer/Q Targets Std              10.5299
trainer/Q Targets Max              -1.7304
trainer/Q Targets Min            -102.514
trainer/Log Pis Mean                1.97028
trainer/Log Pis Std                 1.10668
trainer/Log Pis Max                 5.28814
trainer/Log Pis Min                -1.22134
trainer/Policy mu Mean              0.0866353
trainer/Policy mu Std               0.838952
trainer/Policy mu Max               2.85257
trainer/Policy mu Min              -2.38228
trainer/Policy log std Mean        -1.93412
trainer/Policy log std Std          0.559425
trainer/Policy log std Max         -0.446061
trainer/Policy log std Min         -2.61865
trainer/Alpha                       0.0773354
trainer/Alpha Loss                 -0.0760642
exploration/num steps total     27400
exploration/num paths total       274
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02511
exploration/Rewards Std             1.28541
exploration/Rewards Max            -0.296262
exploration/Rewards Min            -8.49681
exploration/Returns Mean         -102.511
exploration/Returns Std            23.8455
exploration/Returns Max           -78.6656
exploration/Returns Min          -126.357
exploration/Actions Mean            0.0135133
exploration/Actions Std             0.253157
exploration/Actions Max             0.995128
exploration/Actions Min            -0.997994
exploration/Num Paths               2
exploration/Average Returns      -102.511
evaluation/num steps total     136000
evaluation/num paths total       1360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.798349
evaluation/Rewards Std              1.15752
evaluation/Rewards Max             -0.425445
evaluation/Rewards Min            -10.4981
evaluation/Returns Mean           -79.8349
evaluation/Returns Std             25.3424
evaluation/Returns Max            -47.0528
evaluation/Returns Min           -127.75
evaluation/Actions Mean             0.0127864
evaluation/Actions Std              0.196975
evaluation/Actions Max              0.997035
evaluation/Actions Min             -0.992647
evaluation/Num Paths               10
evaluation/Average Returns        -79.8349
time/data storing (s)               0.00123373
time/evaluation sampling (s)        0.218022
time/exploration sampling (s)       0.0644733
time/logging (s)                    0.00335143
time/saving (s)                     0.00195654
time/training (s)                   0.776846
time/epoch (s)                      1.06588
time/total (s)                    144.829
Epoch                             135
-----------------------------  ---------------
2019-04-21 01:14:09.187046 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              27600
trainer/QF1 Loss                    1.58547
trainer/QF2 Loss                    1.59044
trainer/Policy Loss                61.8754
trainer/Q1 Predictions Mean       -60.8046
trainer/Q1 Predictions Std         10.7561
trainer/Q1 Predictions Max        -54.0799
trainer/Q1 Predictions Min       -123.665
trainer/Q2 Predictions Mean       -60.794
trainer/Q2 Predictions Std         10.6918
trainer/Q2 Predictions Max        -54.0658
trainer/Q2 Predictions Min       -123.762
trainer/Q Targets Mean            -61.8346
trainer/Q Targets Std              10.6262
trainer/Q Targets Max             -54.6092
trainer/Q Targets Min            -121.629
trainer/Log Pis Mean                2.07792
trainer/Log Pis Std                 1.12392
trainer/Log Pis Max                 5.47869
trainer/Log Pis Min                -2.97198
trainer/Policy mu Mean              0.127039
trainer/Policy mu Std               0.848919
trainer/Policy mu Max               3.17277
trainer/Policy mu Min              -3.04152
trainer/Policy log std Mean        -1.87349
trainer/Policy log std Std          0.542833
trainer/Policy log std Max         -0.365356
trainer/Policy log std Min         -2.73893
trainer/Alpha                       0.0767338
trainer/Alpha Loss                  0.200043
exploration/num steps total     27600
exploration/num paths total       276
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.698662
exploration/Rewards Std             0.368158
exploration/Rewards Max            -0.118937
exploration/Rewards Min            -1.93919
exploration/Returns Mean          -69.8662
exploration/Returns Std            32.754
exploration/Returns Max           -37.1121
exploration/Returns Min          -102.62
exploration/Actions Mean            0.0144115
exploration/Actions Std             0.159962
exploration/Actions Max             0.947519
exploration/Actions Min            -0.514028
exploration/Num Paths               2
exploration/Average Returns       -69.8662
evaluation/num steps total     137000
evaluation/num paths total       1370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.764944
evaluation/Rewards Std              0.961847
evaluation/Rewards Max             -0.141453
evaluation/Rewards Min             -9.09706
evaluation/Returns Mean           -76.4944
evaluation/Returns Std             35.1728
evaluation/Returns Max            -33.7595
evaluation/Returns Min           -130.986
evaluation/Actions Mean             0.00239784
evaluation/Actions Std              0.177594
evaluation/Actions Max              0.994389
evaluation/Actions Min             -0.989234
evaluation/Num Paths               10
evaluation/Average Returns        -76.4944
time/data storing (s)               0.0012416
time/evaluation sampling (s)        0.221142
time/exploration sampling (s)       0.0622105
time/logging (s)                    0.00340626
time/saving (s)                     0.00197187
time/training (s)                   0.770549
time/epoch (s)                      1.06052
time/total (s)                    145.894
Epoch                             136
-----------------------------  ---------------
2019-04-21 01:14:10.261994 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              27800
trainer/QF1 Loss                    0.942144
trainer/QF2 Loss                    1.1033
trainer/Policy Loss                63.3543
trainer/Q1 Predictions Mean       -62.1105
trainer/Q1 Predictions Std         12.5635
trainer/Q1 Predictions Max        -54.0192
trainer/Q1 Predictions Min       -120.823
trainer/Q2 Predictions Mean       -62.1004
trainer/Q2 Predictions Std         12.5074
trainer/Q2 Predictions Max        -54.1111
trainer/Q2 Predictions Min       -119.81
trainer/Q Targets Mean            -62.9236
trainer/Q Targets Std              12.7336
trainer/Q Targets Max             -54.6633
trainer/Q Targets Min            -124.16
trainer/Log Pis Mean                2.04945
trainer/Log Pis Std                 1.24524
trainer/Log Pis Max                 6.59345
trainer/Log Pis Min                -1.25047
trainer/Policy mu Mean              0.0978552
trainer/Policy mu Std               0.909634
trainer/Policy mu Max               3.03911
trainer/Policy mu Min              -2.88078
trainer/Policy log std Mean        -1.8649
trainer/Policy log std Std          0.586413
trainer/Policy log std Max         -0.313846
trainer/Policy log std Min         -2.64141
trainer/Alpha                       0.0770792
trainer/Alpha Loss                  0.12674
exploration/num steps total     27800
exploration/num paths total       278
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.554341
exploration/Rewards Std             0.758032
exploration/Rewards Max            -0.126072
exploration/Rewards Min            -5.74689
exploration/Returns Mean          -55.4341
exploration/Returns Std             0.520835
exploration/Returns Max           -54.9133
exploration/Returns Min           -55.955
exploration/Actions Mean            0.0223968
exploration/Actions Std             0.215565
exploration/Actions Max             0.994522
exploration/Actions Min            -0.857896
exploration/Num Paths               2
exploration/Average Returns       -55.4341
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.790783
evaluation/Rewards Std              0.706712
evaluation/Rewards Max             -0.364545
evaluation/Rewards Min             -7.66749
evaluation/Returns Mean           -79.0783
evaluation/Returns Std             22.7989
evaluation/Returns Max            -43.1772
evaluation/Returns Min           -108.793
evaluation/Actions Mean             0.00151375
evaluation/Actions Std              0.176617
evaluation/Actions Max              0.990434
evaluation/Actions Min             -0.987692
evaluation/Num Paths               10
evaluation/Average Returns        -79.0783
time/data storing (s)               0.00146882
time/evaluation sampling (s)        0.221973
time/exploration sampling (s)       0.0650091
time/logging (s)                    0.0032923
time/saving (s)                     0.00156685
time/training (s)                   0.774824
time/epoch (s)                      1.06813
time/total (s)                    146.966
Epoch                             137
-----------------------------  ---------------
2019-04-21 01:14:11.335952 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              28000
trainer/QF1 Loss                    0.897128
trainer/QF2 Loss                    0.887831
trainer/Policy Loss                61.0801
trainer/Q1 Predictions Mean       -60.1769
trainer/Q1 Predictions Std          7.42248
trainer/Q1 Predictions Max        -53.738
trainer/Q1 Predictions Min        -95.902
trainer/Q2 Predictions Mean       -60.2317
trainer/Q2 Predictions Std          7.45978
trainer/Q2 Predictions Max        -53.7836
trainer/Q2 Predictions Min        -96.2092
trainer/Q Targets Mean            -60.9392
trainer/Q Targets Std               7.72376
trainer/Q Targets Max             -54.3664
trainer/Q Targets Min             -98.3716
trainer/Log Pis Mean                1.99123
trainer/Log Pis Std                 1.10701
trainer/Log Pis Max                 5.54666
trainer/Log Pis Min                -1.97072
trainer/Policy mu Mean              0.126839
trainer/Policy mu Std               0.820131
trainer/Policy mu Max               2.58764
trainer/Policy mu Min              -2.48905
trainer/Policy log std Mean        -1.89535
trainer/Policy log std Std          0.536852
trainer/Policy log std Max         -0.306171
trainer/Policy log std Min         -2.59165
trainer/Alpha                       0.0785074
trainer/Alpha Loss                 -0.0223152
exploration/num steps total     28000
exploration/num paths total       280
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.744958
exploration/Rewards Std             0.478111
exploration/Rewards Max            -0.273549
exploration/Rewards Min            -4.12164
exploration/Returns Mean          -74.4958
exploration/Returns Std            15.131
exploration/Returns Max           -59.3648
exploration/Returns Min           -89.6268
exploration/Actions Mean            0.0010932
exploration/Actions Std             0.187839
exploration/Actions Max             0.983821
exploration/Actions Min            -0.961513
exploration/Num Paths               2
exploration/Average Returns       -74.4958
evaluation/num steps total     139000
evaluation/num paths total       1390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.882519
evaluation/Rewards Std              0.980216
evaluation/Rewards Max             -0.463034
evaluation/Rewards Min            -10.3771
evaluation/Returns Mean           -88.2519
evaluation/Returns Std             24.2172
evaluation/Returns Max            -53.0631
evaluation/Returns Min           -125.362
evaluation/Actions Mean            -0.00981818
evaluation/Actions Std              0.196297
evaluation/Actions Max              0.992469
evaluation/Actions Min             -0.99605
evaluation/Num Paths               10
evaluation/Average Returns        -88.2519
time/data storing (s)               0.0012629
time/evaluation sampling (s)        0.221938
time/exploration sampling (s)       0.0661507
time/logging (s)                    0.0034187
time/saving (s)                     0.00196407
time/training (s)                   0.772856
time/epoch (s)                      1.06759
time/total (s)                    148.038
Epoch                             138
-----------------------------  ---------------
2019-04-21 01:14:12.412503 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 139 finished
-----------------------------  ----------------
replay_buffer/size              28200
trainer/QF1 Loss                   66.3429
trainer/QF2 Loss                   65.8827
trainer/Policy Loss                62.1852
trainer/Q1 Predictions Mean       -61.2606
trainer/Q1 Predictions Std         11.1915
trainer/Q1 Predictions Max        -53.9431
trainer/Q1 Predictions Min       -117.4
trainer/Q2 Predictions Mean       -61.2734
trainer/Q2 Predictions Std         11.2541
trainer/Q2 Predictions Max        -53.9522
trainer/Q2 Predictions Min       -117.504
trainer/Q Targets Mean            -60.679
trainer/Q Targets Std              14.2271
trainer/Q Targets Max              -1.00234
trainer/Q Targets Min            -118.882
trainer/Log Pis Mean                2.19553
trainer/Log Pis Std                 1.35161
trainer/Log Pis Max                 6.00116
trainer/Log Pis Min                -3.44181
trainer/Policy mu Mean              0.089816
trainer/Policy mu Std               0.894022
trainer/Policy mu Max               2.95489
trainer/Policy mu Min              -3.0029
trainer/Policy log std Mean        -1.93353
trainer/Policy log std Std          0.568552
trainer/Policy log std Max         -0.376805
trainer/Policy log std Min         -2.61365
trainer/Alpha                       0.0790403
trainer/Alpha Loss                  0.496272
exploration/num steps total     28200
exploration/num paths total       282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.636411
exploration/Rewards Std             0.225774
exploration/Rewards Max            -0.293652
exploration/Rewards Min            -1.91029
exploration/Returns Mean          -63.6411
exploration/Returns Std            18.9808
exploration/Returns Max           -44.6603
exploration/Returns Min           -82.6218
exploration/Actions Mean           -0.000759383
exploration/Actions Std             0.147804
exploration/Actions Max             0.826985
exploration/Actions Min            -0.958415
exploration/Num Paths               2
exploration/Average Returns       -63.6411
evaluation/num steps total     140000
evaluation/num paths total       1400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.820762
evaluation/Rewards Std              1.04192
evaluation/Rewards Max             -0.440344
evaluation/Rewards Min            -10.8132
evaluation/Returns Mean           -82.0762
evaluation/Returns Std             21.5292
evaluation/Returns Max            -51.7309
evaluation/Returns Min           -130.244
evaluation/Actions Mean            -0.00351264
evaluation/Actions Std              0.195212
evaluation/Actions Max              0.994851
evaluation/Actions Min             -0.9966
evaluation/Num Paths               10
evaluation/Average Returns        -82.0762
time/data storing (s)               0.00181166
time/evaluation sampling (s)        0.22722
time/exploration sampling (s)       0.0652811
time/logging (s)                    0.00350436
time/saving (s)                     0.00195905
time/training (s)                   0.770236
time/epoch (s)                      1.07001
time/total (s)                    149.112
Epoch                             139
-----------------------------  ----------------
2019-04-21 01:14:13.485442 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              28400
trainer/QF1 Loss                   84.9008
trainer/QF2 Loss                   84.781
trainer/Policy Loss                59.4699
trainer/Q1 Predictions Mean       -58.6048
trainer/Q1 Predictions Std          5.79693
trainer/Q1 Predictions Max        -53.9238
trainer/Q1 Predictions Min        -95.7798
trainer/Q2 Predictions Mean       -58.6258
trainer/Q2 Predictions Std          5.87312
trainer/Q2 Predictions Max        -53.9185
trainer/Q2 Predictions Min        -95.7965
trainer/Q Targets Mean            -57.4971
trainer/Q Targets Std              11.4727
trainer/Q Targets Max              -0.886842
trainer/Q Targets Min             -95.3086
trainer/Log Pis Mean                1.77233
trainer/Log Pis Std                 1.26818
trainer/Log Pis Max                 4.32218
trainer/Log Pis Min                -4.27599
trainer/Policy mu Mean              0.116399
trainer/Policy mu Std               0.795208
trainer/Policy mu Max               2.77651
trainer/Policy mu Min              -2.02301
trainer/Policy log std Mean        -1.90152
trainer/Policy log std Std          0.529797
trainer/Policy log std Max         -0.559535
trainer/Policy log std Min         -2.64758
trainer/Alpha                       0.0806329
trainer/Alpha Loss                 -0.573266
exploration/num steps total     28400
exploration/num paths total       284
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.998104
exploration/Rewards Std             1.23614
exploration/Rewards Max            -0.32655
exploration/Rewards Min            -9.32131
exploration/Returns Mean          -99.8104
exploration/Returns Std            33.3771
exploration/Returns Max           -66.4332
exploration/Returns Min          -133.188
exploration/Actions Mean           -0.00146453
exploration/Actions Std             0.246838
exploration/Actions Max             0.993496
exploration/Actions Min            -0.997503
exploration/Num Paths               2
exploration/Average Returns       -99.8104
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.757812
evaluation/Rewards Std              0.807388
evaluation/Rewards Max             -0.349871
evaluation/Rewards Min             -8.27788
evaluation/Returns Mean           -75.7812
evaluation/Returns Std             23.9566
evaluation/Returns Max            -47.3099
evaluation/Returns Min           -112.664
evaluation/Actions Mean             0.0138982
evaluation/Actions Std              0.16863
evaluation/Actions Max              0.993641
evaluation/Actions Min             -0.986258
evaluation/Num Paths               10
evaluation/Average Returns        -75.7812
time/data storing (s)               0.00138457
time/evaluation sampling (s)        0.220869
time/exploration sampling (s)       0.0650047
time/logging (s)                    0.00336703
time/saving (s)                     0.00196874
time/training (s)                   0.773571
time/epoch (s)                      1.06616
time/total (s)                    150.182
Epoch                             140
-----------------------------  ---------------
2019-04-21 01:14:14.560783 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              28600
trainer/QF1 Loss                   28.2107
trainer/QF2 Loss                   28.1956
trainer/Policy Loss                60.9725
trainer/Q1 Predictions Mean       -59.9002
trainer/Q1 Predictions Std         11.168
trainer/Q1 Predictions Max        -53.4209
trainer/Q1 Predictions Min       -116.938
trainer/Q2 Predictions Mean       -59.9348
trainer/Q2 Predictions Std         11.1931
trainer/Q2 Predictions Max        -53.4396
trainer/Q2 Predictions Min       -117.419
trainer/Q Targets Mean            -59.9886
trainer/Q Targets Std              12.7132
trainer/Q Targets Max              -0.935285
trainer/Q Targets Min            -119.001
trainer/Log Pis Mean                1.93017
trainer/Log Pis Std                 1.4401
trainer/Log Pis Max                 5.77149
trainer/Log Pis Min                -3.30584
trainer/Policy mu Mean              0.131357
trainer/Policy mu Std               0.836058
trainer/Policy mu Max               3.15021
trainer/Policy mu Min              -2.92107
trainer/Policy log std Mean        -1.91143
trainer/Policy log std Std          0.553368
trainer/Policy log std Max         -0.215077
trainer/Policy log std Min         -2.72168
trainer/Alpha                       0.0812641
trainer/Alpha Loss                 -0.175288
exploration/num steps total     28600
exploration/num paths total       286
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.795253
exploration/Rewards Std             0.514686
exploration/Rewards Max            -0.210519
exploration/Rewards Min            -5.05452
exploration/Returns Mean          -79.5253
exploration/Returns Std            34.6143
exploration/Returns Max           -44.911
exploration/Returns Min          -114.14
exploration/Actions Mean            0.00414128
exploration/Actions Std             0.179046
exploration/Actions Max             0.996322
exploration/Actions Min            -0.702856
exploration/Num Paths               2
exploration/Average Returns       -79.5253
evaluation/num steps total     142000
evaluation/num paths total       1420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.974494
evaluation/Rewards Std              1.19126
evaluation/Rewards Max             -0.295861
evaluation/Rewards Min            -11.277
evaluation/Returns Mean           -97.4494
evaluation/Returns Std             36.2619
evaluation/Returns Max            -43.6538
evaluation/Returns Min           -144.528
evaluation/Actions Mean             0.00318901
evaluation/Actions Std              0.201633
evaluation/Actions Max              0.998142
evaluation/Actions Min             -0.994419
evaluation/Num Paths               10
evaluation/Average Returns        -97.4494
time/data storing (s)               0.00145773
time/evaluation sampling (s)        0.226974
time/exploration sampling (s)       0.0661952
time/logging (s)                    0.00363715
time/saving (s)                     0.00197559
time/training (s)                   0.769602
time/epoch (s)                      1.06984
time/total (s)                    151.255
Epoch                             141
-----------------------------  ---------------
2019-04-21 01:14:15.629339 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              28800
trainer/QF1 Loss                    0.40833
trainer/QF2 Loss                    0.369159
trainer/Policy Loss                59.3893
trainer/Q1 Predictions Mean       -58.2211
trainer/Q1 Predictions Std          8.24426
trainer/Q1 Predictions Max        -53.9215
trainer/Q1 Predictions Min       -128.7
trainer/Q2 Predictions Mean       -58.1985
trainer/Q2 Predictions Std          8.13414
trainer/Q2 Predictions Max        -53.8875
trainer/Q2 Predictions Min       -127.569
trainer/Q Targets Mean            -58.4799
trainer/Q Targets Std               7.96587
trainer/Q Targets Max             -53.7539
trainer/Q Targets Min            -124.946
trainer/Log Pis Mean                1.99514
trainer/Log Pis Std                 1.12001
trainer/Log Pis Max                 5.47021
trainer/Log Pis Min                -0.740321
trainer/Policy mu Mean              0.0499485
trainer/Policy mu Std               0.741996
trainer/Policy mu Max               2.97552
trainer/Policy mu Min              -2.4468
trainer/Policy log std Mean        -1.97837
trainer/Policy log std Std          0.513737
trainer/Policy log std Max         -0.388799
trainer/Policy log std Min         -2.64728
trainer/Alpha                       0.0795758
trainer/Alpha Loss                 -0.0122887
exploration/num steps total     28800
exploration/num paths total       288
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.704315
exploration/Rewards Std             0.416987
exploration/Rewards Max            -0.246525
exploration/Rewards Min            -4.13142
exploration/Returns Mean          -70.4315
exploration/Returns Std            27.2431
exploration/Returns Max           -43.1884
exploration/Returns Min           -97.6746
exploration/Actions Mean           -0.0139465
exploration/Actions Std             0.156512
exploration/Actions Max             0.440147
exploration/Actions Min            -0.994642
exploration/Num Paths               2
exploration/Average Returns       -70.4315
evaluation/num steps total     143000
evaluation/num paths total       1430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.790864
evaluation/Rewards Std              1.0911
evaluation/Rewards Max             -0.378458
evaluation/Rewards Min            -10.9687
evaluation/Returns Mean           -79.0864
evaluation/Returns Std             25.2679
evaluation/Returns Max            -41.939
evaluation/Returns Min           -131.299
evaluation/Actions Mean             0.00759228
evaluation/Actions Std              0.191246
evaluation/Actions Max              0.997771
evaluation/Actions Min             -0.995333
evaluation/Num Paths               10
evaluation/Average Returns        -79.0864
time/data storing (s)               0.00130137
time/evaluation sampling (s)        0.223563
time/exploration sampling (s)       0.0628067
time/logging (s)                    0.00335561
time/saving (s)                     0.00196398
time/training (s)                   0.769086
time/epoch (s)                      1.06208
time/total (s)                    152.321
Epoch                             142
-----------------------------  ---------------
2019-04-21 01:14:16.707357 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              29000
trainer/QF1 Loss                  125.703
trainer/QF2 Loss                  125.54
trainer/Policy Loss                58.0607
trainer/Q1 Predictions Mean       -56.922
trainer/Q1 Predictions Std          5.03067
trainer/Q1 Predictions Max        -53.4758
trainer/Q1 Predictions Min        -82.7754
trainer/Q2 Predictions Mean       -56.8987
trainer/Q2 Predictions Std          4.97864
trainer/Q2 Predictions Max        -53.4023
trainer/Q2 Predictions Min        -82.5892
trainer/Q Targets Mean            -55.1022
trainer/Q Targets Std              12.0467
trainer/Q Targets Max              -0.375303
trainer/Q Targets Min             -82.3715
trainer/Log Pis Mean                1.71746
trainer/Log Pis Std                 1.30595
trainer/Log Pis Max                 5.8985
trainer/Log Pis Min                -2.50918
trainer/Policy mu Mean             -0.0579935
trainer/Policy mu Std               0.690661
trainer/Policy mu Max               2.60013
trainer/Policy mu Min              -2.46539
trainer/Policy log std Mean        -2.01383
trainer/Policy log std Std          0.506116
trainer/Policy log std Max         -0.45935
trainer/Policy log std Min         -2.63639
trainer/Alpha                       0.0800379
trainer/Alpha Loss                 -0.713439
exploration/num steps total     29000
exploration/num paths total       290
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.761145
exploration/Rewards Std             0.528592
exploration/Rewards Max            -0.259344
exploration/Rewards Min            -4.77894
exploration/Returns Mean          -76.1145
exploration/Returns Std            18.0067
exploration/Returns Max           -58.1079
exploration/Returns Min           -94.1212
exploration/Actions Mean           -0.0152733
exploration/Actions Std             0.190118
exploration/Actions Max             0.965274
exploration/Actions Min            -0.985451
exploration/Num Paths               2
exploration/Average Returns       -76.1145
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.807618
evaluation/Rewards Std              0.6949
evaluation/Rewards Max             -0.394809
evaluation/Rewards Min             -8.03881
evaluation/Returns Mean           -80.7618
evaluation/Returns Std             22.3627
evaluation/Returns Max            -48.1341
evaluation/Returns Min           -107.872
evaluation/Actions Mean            -0.00183926
evaluation/Actions Std              0.155389
evaluation/Actions Max              0.99254
evaluation/Actions Min             -0.989245
evaluation/Num Paths               10
evaluation/Average Returns        -80.7618
time/data storing (s)               0.00133914
time/evaluation sampling (s)        0.224341
time/exploration sampling (s)       0.0691487
time/logging (s)                    0.00338532
time/saving (s)                     0.00194905
time/training (s)                   0.771324
time/epoch (s)                      1.07149
time/total (s)                    153.397
Epoch                             143
-----------------------------  ---------------
2019-04-21 01:14:17.804614 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              29200
trainer/QF1 Loss                   31.8113
trainer/QF2 Loss                   31.8816
trainer/Policy Loss                60.3281
trainer/Q1 Predictions Mean       -59.159
trainer/Q1 Predictions Std         11.4753
trainer/Q1 Predictions Max        -53.1779
trainer/Q1 Predictions Min       -112.951
trainer/Q2 Predictions Mean       -59.1596
trainer/Q2 Predictions Std         11.3766
trainer/Q2 Predictions Max        -53.2262
trainer/Q2 Predictions Min       -113.22
trainer/Q Targets Mean            -59.2144
trainer/Q Targets Std              13.0359
trainer/Q Targets Max              -0.388022
trainer/Q Targets Min            -115.399
trainer/Log Pis Mean                2.15215
trainer/Log Pis Std                 1.11415
trainer/Log Pis Max                 6.44626
trainer/Log Pis Min                -1.25364
trainer/Policy mu Mean              0.00904963
trainer/Policy mu Std               0.906016
trainer/Policy mu Max               3.06788
trainer/Policy mu Min              -2.99164
trainer/Policy log std Mean        -1.85301
trainer/Policy log std Std          0.539652
trainer/Policy log std Max         -0.471328
trainer/Policy log std Min         -2.5845
trainer/Alpha                       0.0790111
trainer/Alpha Loss                  0.386185
exploration/num steps total     29200
exploration/num paths total       292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.881536
exploration/Rewards Std             0.389641
exploration/Rewards Max            -0.51141
exploration/Rewards Min            -4.31088
exploration/Returns Mean          -88.1536
exploration/Returns Std             2.57861
exploration/Returns Max           -85.575
exploration/Returns Min           -90.7323
exploration/Actions Mean           -0.00392142
exploration/Actions Std             0.19877
exploration/Actions Max             0.9952
exploration/Actions Min            -0.996857
exploration/Num Paths               2
exploration/Average Returns       -88.1536
evaluation/num steps total     145000
evaluation/num paths total       1450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.813633
evaluation/Rewards Std              1.09069
evaluation/Rewards Max             -0.36451
evaluation/Rewards Min            -10.1142
evaluation/Returns Mean           -81.3633
evaluation/Returns Std             26.4675
evaluation/Returns Max            -41.677
evaluation/Returns Min           -119.294
evaluation/Actions Mean            -0.00534689
evaluation/Actions Std              0.201715
evaluation/Actions Max              0.996282
evaluation/Actions Min             -0.994684
evaluation/Num Paths               10
evaluation/Average Returns        -81.3633
time/data storing (s)               0.00131047
time/evaluation sampling (s)        0.248551
time/exploration sampling (s)       0.070863
time/logging (s)                    0.00336426
time/saving (s)                     0.0119257
time/training (s)                   0.754521
time/epoch (s)                      1.09054
time/total (s)                    154.491
Epoch                             144
-----------------------------  ---------------
2019-04-21 01:14:18.884165 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              29400
trainer/QF1 Loss                   32.8714
trainer/QF2 Loss                   32.9526
trainer/Policy Loss                57.7178
trainer/Q1 Predictions Mean       -56.6602
trainer/Q1 Predictions Std          4.92072
trainer/Q1 Predictions Max        -53.2232
trainer/Q1 Predictions Min        -90.7926
trainer/Q2 Predictions Mean       -56.6854
trainer/Q2 Predictions Std          4.90675
trainer/Q2 Predictions Max        -53.217
trainer/Q2 Predictions Min        -90.5211
trainer/Q Targets Mean            -56.645
trainer/Q Targets Std               7.40969
trainer/Q Targets Max              -2.04206
trainer/Q Targets Min             -92.1428
trainer/Log Pis Mean                1.85688
trainer/Log Pis Std                 0.992903
trainer/Log Pis Max                 4.27622
trainer/Log Pis Min                -1.69086
trainer/Policy mu Mean              0.135194
trainer/Policy mu Std               0.715166
trainer/Policy mu Max               2.6868
trainer/Policy mu Min              -2.20515
trainer/Policy log std Mean        -1.92903
trainer/Policy log std Std          0.499409
trainer/Policy log std Max         -0.569385
trainer/Policy log std Min         -2.67779
trainer/Alpha                       0.0779139
trainer/Alpha Loss                 -0.365221
exploration/num steps total     29400
exploration/num paths total       294
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26685
exploration/Rewards Std             1.20832
exploration/Rewards Max            -0.611858
exploration/Rewards Min            -8.90851
exploration/Returns Mean         -126.685
exploration/Returns Std             5.85182
exploration/Returns Max          -120.833
exploration/Returns Min          -132.537
exploration/Actions Mean           -0.0199881
exploration/Actions Std             0.268663
exploration/Actions Max             0.974236
exploration/Actions Min            -0.995956
exploration/Num Paths               2
exploration/Average Returns      -126.685
evaluation/num steps total     146000
evaluation/num paths total       1460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.914292
evaluation/Rewards Std              0.932285
evaluation/Rewards Max             -0.33789
evaluation/Rewards Min             -9.75422
evaluation/Returns Mean           -91.4292
evaluation/Returns Std             29.2411
evaluation/Returns Max            -42.8454
evaluation/Returns Min           -137.524
evaluation/Actions Mean            -0.00231926
evaluation/Actions Std              0.175254
evaluation/Actions Max              0.992886
evaluation/Actions Min             -0.994354
evaluation/Num Paths               10
evaluation/Average Returns        -91.4292
time/data storing (s)               0.00144871
time/evaluation sampling (s)        0.216693
time/exploration sampling (s)       0.0783173
time/logging (s)                    0.00339728
time/saving (s)                     0.00199257
time/training (s)                   0.770787
time/epoch (s)                      1.07264
time/total (s)                    155.568
Epoch                             145
-----------------------------  ---------------
2019-04-21 01:14:19.957024 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              29600
trainer/QF1 Loss                    0.801582
trainer/QF2 Loss                    0.806921
trainer/Policy Loss                58.2941
trainer/Q1 Predictions Mean       -56.9729
trainer/Q1 Predictions Std          8.92938
trainer/Q1 Predictions Max        -52.8149
trainer/Q1 Predictions Min       -107.715
trainer/Q2 Predictions Mean       -56.9884
trainer/Q2 Predictions Std          8.85644
trainer/Q2 Predictions Max        -52.8546
trainer/Q2 Predictions Min       -106.93
trainer/Q Targets Mean            -57.8083
trainer/Q Targets Std               9.12377
trainer/Q Targets Max             -53.3524
trainer/Q Targets Min            -109.446
trainer/Log Pis Mean                2.02624
trainer/Log Pis Std                 1.20279
trainer/Log Pis Max                 6.80376
trainer/Log Pis Min                -1.17674
trainer/Policy mu Mean              0.199864
trainer/Policy mu Std               0.744924
trainer/Policy mu Max               2.83718
trainer/Policy mu Min              -2.30621
trainer/Policy log std Mean        -1.9839
trainer/Policy log std Std          0.496153
trainer/Policy log std Max         -0.520292
trainer/Policy log std Min         -2.70392
trainer/Alpha                       0.0787185
trainer/Alpha Loss                  0.0667095
exploration/num steps total     29600
exploration/num paths total       296
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.867964
exploration/Rewards Std             1.16518
exploration/Rewards Max            -0.25176
exploration/Rewards Min            -9.89767
exploration/Returns Mean          -86.7964
exploration/Returns Std             2.05387
exploration/Returns Max           -84.7425
exploration/Returns Min           -88.8502
exploration/Actions Mean            0.0462334
exploration/Actions Std             0.237109
exploration/Actions Max             0.997948
exploration/Actions Min            -0.397296
exploration/Num Paths               2
exploration/Average Returns       -86.7964
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.584975
evaluation/Rewards Std              0.822958
evaluation/Rewards Max             -0.380042
evaluation/Rewards Min             -8.89102
evaluation/Returns Mean           -58.4975
evaluation/Returns Std             14.6494
evaluation/Returns Max            -39.9011
evaluation/Returns Min            -92.2047
evaluation/Actions Mean             0.0287177
evaluation/Actions Std              0.187381
evaluation/Actions Max              0.991485
evaluation/Actions Min             -0.955194
evaluation/Num Paths               10
evaluation/Average Returns        -58.4975
time/data storing (s)               0.0012973
time/evaluation sampling (s)        0.225243
time/exploration sampling (s)       0.0621444
time/logging (s)                    0.00336399
time/saving (s)                     0.00196329
time/training (s)                   0.771892
time/epoch (s)                      1.0659
time/total (s)                    156.639
Epoch                             146
-----------------------------  ---------------
2019-04-21 01:14:21.025384 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              29800
trainer/QF1 Loss                   60.7168
trainer/QF2 Loss                   60.6613
trainer/Policy Loss                57.8197
trainer/Q1 Predictions Mean       -56.624
trainer/Q1 Predictions Std          5.02696
trainer/Q1 Predictions Max        -53.1864
trainer/Q1 Predictions Min        -86.7169
trainer/Q2 Predictions Mean       -56.6272
trainer/Q2 Predictions Std          4.99322
trainer/Q2 Predictions Max        -53.0752
trainer/Q2 Predictions Min        -86.6644
trainer/Q Targets Mean            -56.3089
trainer/Q Targets Std               6.2265
trainer/Q Targets Max              -9.00678
trainer/Q Targets Min             -74.9373
trainer/Log Pis Mean                2.16482
trainer/Log Pis Std                 1.42737
trainer/Log Pis Max                 6.31776
trainer/Log Pis Min                -2.79435
trainer/Policy mu Mean              0.151003
trainer/Policy mu Std               0.916837
trainer/Policy mu Max               2.72392
trainer/Policy mu Min              -2.48681
trainer/Policy log std Mean        -1.91378
trainer/Policy log std Std          0.608222
trainer/Policy log std Max         -0.27192
trainer/Policy log std Min         -2.78104
trainer/Alpha                       0.0793849
trainer/Alpha Loss                  0.417592
exploration/num steps total     29800
exploration/num paths total       298
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.452047
exploration/Rewards Std             0.309758
exploration/Rewards Max            -0.090828
exploration/Rewards Min            -3.70722
exploration/Returns Mean          -45.2047
exploration/Returns Std             3.57589
exploration/Returns Max           -41.6288
exploration/Returns Min           -48.7806
exploration/Actions Mean           -0.00115892
exploration/Actions Std             0.146632
exploration/Actions Max             0.977494
exploration/Actions Min            -0.79123
exploration/Num Paths               2
exploration/Average Returns       -45.2047
evaluation/num steps total     148000
evaluation/num paths total       1480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.804639
evaluation/Rewards Std              1.17319
evaluation/Rewards Max             -0.392749
evaluation/Rewards Min            -10.5922
evaluation/Returns Mean           -80.4639
evaluation/Returns Std             27.353
evaluation/Returns Max            -47.4946
evaluation/Returns Min           -122.919
evaluation/Actions Mean             0.00751001
evaluation/Actions Std              0.215364
evaluation/Actions Max              0.991352
evaluation/Actions Min             -0.997022
evaluation/Num Paths               10
evaluation/Average Returns        -80.4639
time/data storing (s)               0.00124974
time/evaluation sampling (s)        0.226937
time/exploration sampling (s)       0.0646582
time/logging (s)                    0.00334472
time/saving (s)                     0.00198584
time/training (s)                   0.763168
time/epoch (s)                      1.06134
time/total (s)                    157.704
Epoch                             147
-----------------------------  ---------------
2019-04-21 01:14:22.098862 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 148 finished
-----------------------------  ----------------
replay_buffer/size              30000
trainer/QF1 Loss                    0.563544
trainer/QF2 Loss                    0.532939
trainer/Policy Loss                57.623
trainer/Q1 Predictions Mean       -56.2042
trainer/Q1 Predictions Std          7.89863
trainer/Q1 Predictions Max        -52.3794
trainer/Q1 Predictions Min       -109.164
trainer/Q2 Predictions Mean       -56.2216
trainer/Q2 Predictions Std          7.91227
trainer/Q2 Predictions Max        -52.3791
trainer/Q2 Predictions Min       -109.205
trainer/Q Targets Mean            -56.657
trainer/Q Targets Std               8.09549
trainer/Q Targets Max             -53.1279
trainer/Q Targets Min            -112.602
trainer/Log Pis Mean                1.9957
trainer/Log Pis Std                 1.2448
trainer/Log Pis Max                 5.79717
trainer/Log Pis Min                -2.89847
trainer/Policy mu Mean              0.0520482
trainer/Policy mu Std               0.712937
trainer/Policy mu Max               2.74333
trainer/Policy mu Min              -2.79275
trainer/Policy log std Mean        -2.02084
trainer/Policy log std Std          0.52113
trainer/Policy log std Max         -0.416934
trainer/Policy log std Min         -2.68584
trainer/Alpha                       0.0818652
trainer/Alpha Loss                 -0.0107576
exploration/num steps total     30000
exploration/num paths total       300
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.537372
exploration/Rewards Std             0.716451
exploration/Rewards Max            -0.21508
exploration/Rewards Min            -6.39616
exploration/Returns Mean          -53.7372
exploration/Returns Std             8.17983
exploration/Returns Max           -45.5573
exploration/Returns Min           -61.917
exploration/Actions Mean            0.0303615
exploration/Actions Std             0.196446
exploration/Actions Max             0.994039
exploration/Actions Min            -0.549323
exploration/Num Paths               2
exploration/Average Returns       -53.7372
evaluation/num steps total     149000
evaluation/num paths total       1490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.928667
evaluation/Rewards Std              0.722284
evaluation/Rewards Max             -0.36974
evaluation/Rewards Min             -8.95168
evaluation/Returns Mean           -92.8667
evaluation/Returns Std              8.33644
evaluation/Returns Max            -79.6137
evaluation/Returns Min           -110.497
evaluation/Actions Mean             0.000671003
evaluation/Actions Std              0.166995
evaluation/Actions Max              0.991125
evaluation/Actions Min             -0.989981
evaluation/Num Paths               10
evaluation/Average Returns        -92.8667
time/data storing (s)               0.00125221
time/evaluation sampling (s)        0.227529
time/exploration sampling (s)       0.0627085
time/logging (s)                    0.00347933
time/saving (s)                     0.00224942
time/training (s)                   0.769459
time/epoch (s)                      1.06668
time/total (s)                    158.775
Epoch                             148
-----------------------------  ----------------
2019-04-21 01:14:23.161871 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              30200
trainer/QF1 Loss                   28.1186
trainer/QF2 Loss                   27.8274
trainer/Policy Loss                57.1599
trainer/Q1 Predictions Mean       -55.8574
trainer/Q1 Predictions Std          6.37259
trainer/Q1 Predictions Max        -52.2734
trainer/Q1 Predictions Min       -102.737
trainer/Q2 Predictions Mean       -55.8531
trainer/Q2 Predictions Std          6.36488
trainer/Q2 Predictions Max        -52.2485
trainer/Q2 Predictions Min       -102.705
trainer/Q Targets Mean            -55.9506
trainer/Q Targets Std               8.45468
trainer/Q Targets Max              -2.14327
trainer/Q Targets Min            -105.187
trainer/Log Pis Mean                2.08289
trainer/Log Pis Std                 1.16443
trainer/Log Pis Max                 5.96384
trainer/Log Pis Min                -2.52274
trainer/Policy mu Mean              0.0619466
trainer/Policy mu Std               0.842891
trainer/Policy mu Max               2.87466
trainer/Policy mu Min              -2.37298
trainer/Policy log std Mean        -1.92373
trainer/Policy log std Std          0.567892
trainer/Policy log std Max         -0.44906
trainer/Policy log std Min         -2.72438
trainer/Alpha                       0.0808922
trainer/Alpha Loss                  0.208459
exploration/num steps total     30200
exploration/num paths total       302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.646878
exploration/Rewards Std             1.04438
exploration/Rewards Max            -0.272439
exploration/Rewards Min            -8.52415
exploration/Returns Mean          -64.6878
exploration/Returns Std            17.2835
exploration/Returns Max           -47.4043
exploration/Returns Min           -81.9713
exploration/Actions Mean            0.0119131
exploration/Actions Std             0.207143
exploration/Actions Max             0.997063
exploration/Actions Min            -0.975829
exploration/Num Paths               2
exploration/Average Returns       -64.6878
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.812657
evaluation/Rewards Std              1.07662
evaluation/Rewards Max             -0.415825
evaluation/Rewards Min            -10.2635
evaluation/Returns Mean           -81.2657
evaluation/Returns Std             24.1494
evaluation/Returns Max            -48.1441
evaluation/Returns Min           -122.57
evaluation/Actions Mean             0.00322833
evaluation/Actions Std              0.193268
evaluation/Actions Max              0.996214
evaluation/Actions Min             -0.994041
evaluation/Num Paths               10
evaluation/Average Returns        -81.2657
time/data storing (s)               0.00122679
time/evaluation sampling (s)        0.222846
time/exploration sampling (s)       0.0618746
time/logging (s)                    0.00339675
time/saving (s)                     0.00198222
time/training (s)                   0.764698
time/epoch (s)                      1.05602
time/total (s)                    159.836
Epoch                             149
-----------------------------  ---------------
2019-04-21 01:14:24.231473 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              30400
trainer/QF1 Loss                   53.7109
trainer/QF2 Loss                   53.6029
trainer/Policy Loss                56.7097
trainer/Q1 Predictions Mean       -55.5683
trainer/Q1 Predictions Std          7.05999
trainer/Q1 Predictions Max        -52.1845
trainer/Q1 Predictions Min       -109.214
trainer/Q2 Predictions Mean       -55.5549
trainer/Q2 Predictions Std          7.05834
trainer/Q2 Predictions Max        -52.0732
trainer/Q2 Predictions Min       -109.121
trainer/Q Targets Mean            -55.0243
trainer/Q Targets Std              10.3952
trainer/Q Targets Max              -0.834148
trainer/Q Targets Min            -110.186
trainer/Log Pis Mean                1.94534
trainer/Log Pis Std                 1.17229
trainer/Log Pis Max                 5.39775
trainer/Log Pis Min                -2.86363
trainer/Policy mu Mean              0.0408071
trainer/Policy mu Std               0.788238
trainer/Policy mu Max               2.55393
trainer/Policy mu Min              -2.86005
trainer/Policy log std Mean        -1.91654
trainer/Policy log std Std          0.553525
trainer/Policy log std Max         -0.453559
trainer/Policy log std Min         -2.72041
trainer/Alpha                       0.0820194
trainer/Alpha Loss                 -0.136695
exploration/num steps total     30400
exploration/num paths total       304
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.802982
exploration/Rewards Std             0.769737
exploration/Rewards Max            -0.274179
exploration/Rewards Min            -7.40368
exploration/Returns Mean          -80.2982
exploration/Returns Std            13.9193
exploration/Returns Max           -66.3789
exploration/Returns Min           -94.2175
exploration/Actions Mean            0.0429349
exploration/Actions Std             0.225367
exploration/Actions Max             0.994762
exploration/Actions Min            -0.458324
exploration/Num Paths               2
exploration/Average Returns       -80.2982
evaluation/num steps total     151000
evaluation/num paths total       1510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.743128
evaluation/Rewards Std              0.71384
evaluation/Rewards Max             -0.398006
evaluation/Rewards Min             -9.24067
evaluation/Returns Mean           -74.3128
evaluation/Returns Std             26.8087
evaluation/Returns Max            -43.4912
evaluation/Returns Min           -123.935
evaluation/Actions Mean            -0.00550297
evaluation/Actions Std              0.143238
evaluation/Actions Max              0.993829
evaluation/Actions Min             -0.992029
evaluation/Num Paths               10
evaluation/Average Returns        -74.3128
time/data storing (s)               0.00131839
time/evaluation sampling (s)        0.227556
time/exploration sampling (s)       0.0682756
time/logging (s)                    0.00337236
time/saving (s)                     0.00198834
time/training (s)                   0.760745
time/epoch (s)                      1.06326
time/total (s)                    160.903
Epoch                             150
-----------------------------  ---------------
2019-04-21 01:14:25.307518 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              30600
trainer/QF1 Loss                    1.19903
trainer/QF2 Loss                    1.20722
trainer/Policy Loss                57.6139
trainer/Q1 Predictions Mean       -56.6555
trainer/Q1 Predictions Std          9.84918
trainer/Q1 Predictions Max        -51.2429
trainer/Q1 Predictions Min       -111.479
trainer/Q2 Predictions Mean       -56.6309
trainer/Q2 Predictions Std          9.86834
trainer/Q2 Predictions Max        -51.2808
trainer/Q2 Predictions Min       -111.82
trainer/Q Targets Mean            -57.6313
trainer/Q Targets Std               9.9828
trainer/Q Targets Max             -52.0497
trainer/Q Targets Min            -113.973
trainer/Log Pis Mean                2.15369
trainer/Log Pis Std                 1.35385
trainer/Log Pis Max                 6.4576
trainer/Log Pis Min                -2.6322
trainer/Policy mu Mean              0.0726402
trainer/Policy mu Std               0.959
trainer/Policy mu Max               3.03785
trainer/Policy mu Min              -2.91403
trainer/Policy log std Mean        -1.83793
trainer/Policy log std Std          0.616659
trainer/Policy log std Max         -0.519656
trainer/Policy log std Min         -2.64736
trainer/Alpha                       0.0813761
trainer/Alpha Loss                  0.385581
exploration/num steps total     30600
exploration/num paths total       306
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.708454
exploration/Rewards Std             1.01573
exploration/Rewards Max            -0.285477
exploration/Rewards Min            -8.76091
exploration/Returns Mean          -70.8454
exploration/Returns Std            10.6221
exploration/Returns Max           -60.2233
exploration/Returns Min           -81.4675
exploration/Actions Mean            0.0166742
exploration/Actions Std             0.222573
exploration/Actions Max             0.997817
exploration/Actions Min            -0.934945
exploration/Num Paths               2
exploration/Average Returns       -70.8454
evaluation/num steps total     152000
evaluation/num paths total       1520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.936907
evaluation/Rewards Std              0.914545
evaluation/Rewards Max             -0.471479
evaluation/Rewards Min             -9.61826
evaluation/Returns Mean           -93.6907
evaluation/Returns Std             20.926
evaluation/Returns Max            -59.8526
evaluation/Returns Min           -131.084
evaluation/Actions Mean            -0.00752219
evaluation/Actions Std              0.172625
evaluation/Actions Max              0.992722
evaluation/Actions Min             -0.994415
evaluation/Num Paths               10
evaluation/Average Returns        -93.6907
time/data storing (s)               0.00121364
time/evaluation sampling (s)        0.225861
time/exploration sampling (s)       0.063423
time/logging (s)                    0.00332583
time/saving (s)                     0.00197528
time/training (s)                   0.774635
time/epoch (s)                      1.07043
time/total (s)                    161.976
Epoch                             151
-----------------------------  ---------------
2019-04-21 01:14:26.377251 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              30800
trainer/QF1 Loss                   53.2226
trainer/QF2 Loss                   53.3309
trainer/Policy Loss                54.9126
trainer/Q1 Predictions Mean       -53.6936
trainer/Q1 Predictions Std          4.7421
trainer/Q1 Predictions Max        -51.2849
trainer/Q1 Predictions Min        -78.4325
trainer/Q2 Predictions Mean       -53.679
trainer/Q2 Predictions Std          4.72412
trainer/Q2 Predictions Max        -51.2482
trainer/Q2 Predictions Min        -78.5596
trainer/Q Targets Mean            -53.5784
trainer/Q Targets Std               8.87672
trainer/Q Targets Max              -0.570683
trainer/Q Targets Min             -79.3893
trainer/Log Pis Mean                1.86101
trainer/Log Pis Std                 1.09913
trainer/Log Pis Max                 4.83634
trainer/Log Pis Min                -2.62295
trainer/Policy mu Mean             -0.00757303
trainer/Policy mu Std               0.716929
trainer/Policy mu Max               2.45863
trainer/Policy mu Min              -2.6037
trainer/Policy log std Mean        -1.98909
trainer/Policy log std Std          0.53367
trainer/Policy log std Max         -0.374093
trainer/Policy log std Min         -2.66015
trainer/Alpha                       0.0816501
trainer/Alpha Loss                 -0.348218
exploration/num steps total     30800
exploration/num paths total       308
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00211
exploration/Rewards Std             0.723379
exploration/Rewards Max            -0.458186
exploration/Rewards Min            -6.77875
exploration/Returns Mean         -100.211
exploration/Returns Std             4.84784
exploration/Returns Max           -95.3631
exploration/Returns Min          -105.059
exploration/Actions Mean           -0.0270708
exploration/Actions Std             0.234825
exploration/Actions Max             0.969398
exploration/Actions Min            -0.998941
exploration/Num Paths               2
exploration/Average Returns      -100.211
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.781043
evaluation/Rewards Std              1.17429
evaluation/Rewards Max             -0.440967
evaluation/Rewards Min            -10.0956
evaluation/Returns Mean           -78.1043
evaluation/Returns Std             18.8673
evaluation/Returns Max            -46.1917
evaluation/Returns Min            -98.1061
evaluation/Actions Mean             0.025219
evaluation/Actions Std              0.194597
evaluation/Actions Max              0.994254
evaluation/Actions Min             -0.983891
evaluation/Num Paths               10
evaluation/Average Returns        -78.1043
time/data storing (s)               0.00122406
time/evaluation sampling (s)        0.217834
time/exploration sampling (s)       0.0628588
time/logging (s)                    0.00333775
time/saving (s)                     0.00194888
time/training (s)                   0.775793
time/epoch (s)                      1.063
time/total (s)                    163.043
Epoch                             152
-----------------------------  ---------------
2019-04-21 01:14:27.449346 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              31000
trainer/QF1 Loss                   27.4736
trainer/QF2 Loss                   27.3925
trainer/Policy Loss                57.0574
trainer/Q1 Predictions Mean       -55.88
trainer/Q1 Predictions Std         11.1651
trainer/Q1 Predictions Max        -50.9405
trainer/Q1 Predictions Min       -122.741
trainer/Q2 Predictions Mean       -55.8913
trainer/Q2 Predictions Std         11.1328
trainer/Q2 Predictions Max        -50.9911
trainer/Q2 Predictions Min       -122.531
trainer/Q Targets Mean            -55.4439
trainer/Q Targets Std              12.1954
trainer/Q Targets Max              -1.65958
trainer/Q Targets Min            -119.823
trainer/Log Pis Mean                2.0898
trainer/Log Pis Std                 1.27401
trainer/Log Pis Max                 6.07482
trainer/Log Pis Min                -2.7423
trainer/Policy mu Mean              0.0688741
trainer/Policy mu Std               0.834345
trainer/Policy mu Max               2.88125
trainer/Policy mu Min              -3.10784
trainer/Policy log std Mean        -1.93665
trainer/Policy log std Std          0.565481
trainer/Policy log std Max         -0.324144
trainer/Policy log std Min         -2.71949
trainer/Alpha                       0.0808252
trainer/Alpha Loss                  0.225872
exploration/num steps total     31000
exploration/num paths total       310
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.703069
exploration/Rewards Std             0.593716
exploration/Rewards Max            -0.199088
exploration/Rewards Min            -6.04296
exploration/Returns Mean          -70.3069
exploration/Returns Std            24.8154
exploration/Returns Max           -45.4914
exploration/Returns Min           -95.1223
exploration/Actions Mean           -0.0263074
exploration/Actions Std             0.202352
exploration/Actions Max             0.629545
exploration/Actions Min            -0.981412
exploration/Num Paths               2
exploration/Average Returns       -70.3069
evaluation/num steps total     154000
evaluation/num paths total       1540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.785943
evaluation/Rewards Std              1.15593
evaluation/Rewards Max             -0.38714
evaluation/Rewards Min            -10.3896
evaluation/Returns Mean           -78.5943
evaluation/Returns Std             23.112
evaluation/Returns Max            -44.9049
evaluation/Returns Min           -124.1
evaluation/Actions Mean             0.0131593
evaluation/Actions Std              0.202039
evaluation/Actions Max              0.994003
evaluation/Actions Min             -0.995269
evaluation/Num Paths               10
evaluation/Average Returns        -78.5943
time/data storing (s)               0.00127657
time/evaluation sampling (s)        0.218358
time/exploration sampling (s)       0.0643301
time/logging (s)                    0.00334145
time/saving (s)                     0.00158425
time/training (s)                   0.776477
time/epoch (s)                      1.06537
time/total (s)                    164.113
Epoch                             153
-----------------------------  ---------------
2019-04-21 01:14:28.539156 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              31200
trainer/QF1 Loss                   53.5877
trainer/QF2 Loss                   53.3501
trainer/Policy Loss                55.3712
trainer/Q1 Predictions Mean       -54.1235
trainer/Q1 Predictions Std          8.5783
trainer/Q1 Predictions Max        -49.3662
trainer/Q1 Predictions Min       -116.578
trainer/Q2 Predictions Mean       -54.1097
trainer/Q2 Predictions Std          8.54059
trainer/Q2 Predictions Max        -49.3936
trainer/Q2 Predictions Min       -116.726
trainer/Q Targets Mean            -53.9357
trainer/Q Targets Std              11.2927
trainer/Q Targets Max              -1.7302
trainer/Q Targets Min            -117.898
trainer/Log Pis Mean                1.98829
trainer/Log Pis Std                 1.39749
trainer/Log Pis Max                 5.9443
trainer/Log Pis Min                -4.24705
trainer/Policy mu Mean              0.175985
trainer/Policy mu Std               0.767476
trainer/Policy mu Max               3.03805
trainer/Policy mu Min              -2.30182
trainer/Policy log std Mean        -1.99026
trainer/Policy log std Std          0.528182
trainer/Policy log std Max         -0.3415
trainer/Policy log std Min         -2.71302
trainer/Alpha                       0.0776683
trainer/Alpha Loss                 -0.0299307
exploration/num steps total     31200
exploration/num paths total       312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.679339
exploration/Rewards Std             0.84013
exploration/Rewards Max            -0.244419
exploration/Rewards Min            -7.18203
exploration/Returns Mean          -67.9339
exploration/Returns Std             7.05397
exploration/Returns Max           -60.88
exploration/Returns Min           -74.9879
exploration/Actions Mean           -0.010491
exploration/Actions Std             0.208615
exploration/Actions Max             0.987172
exploration/Actions Min            -0.990189
exploration/Num Paths               2
exploration/Average Returns       -67.9339
evaluation/num steps total     155000
evaluation/num paths total       1550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.808181
evaluation/Rewards Std              1.03201
evaluation/Rewards Max             -0.397079
evaluation/Rewards Min             -9.95336
evaluation/Returns Mean           -80.8181
evaluation/Returns Std             19.2033
evaluation/Returns Max            -51.862
evaluation/Returns Min           -123.291
evaluation/Actions Mean             0.00929005
evaluation/Actions Std              0.180561
evaluation/Actions Max              0.994067
evaluation/Actions Min             -0.994099
evaluation/Num Paths               10
evaluation/Average Returns        -80.8181
time/data storing (s)               0.00133383
time/evaluation sampling (s)        0.222133
time/exploration sampling (s)       0.0649506
time/logging (s)                    0.00336912
time/saving (s)                     0.00196824
time/training (s)                   0.789289
time/epoch (s)                      1.08304
time/total (s)                    165.2
Epoch                             154
-----------------------------  ---------------
2019-04-21 01:14:29.628296 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              31400
trainer/QF1 Loss                   52.2067
trainer/QF2 Loss                   52.1728
trainer/Policy Loss                55.2544
trainer/Q1 Predictions Mean       -53.9209
trainer/Q1 Predictions Std          6.0697
trainer/Q1 Predictions Max        -49.2635
trainer/Q1 Predictions Min        -90.7355
trainer/Q2 Predictions Mean       -53.8846
trainer/Q2 Predictions Std          6.00016
trainer/Q2 Predictions Max        -49.3459
trainer/Q2 Predictions Min        -90.629
trainer/Q Targets Mean            -53.4537
trainer/Q Targets Std               9.55768
trainer/Q Targets Max              -0.950803
trainer/Q Targets Min             -91.0226
trainer/Log Pis Mean                2.17324
trainer/Log Pis Std                 1.19841
trainer/Log Pis Max                 5.56684
trainer/Log Pis Min                -2.61124
trainer/Policy mu Mean              0.0628418
trainer/Policy mu Std               0.860662
trainer/Policy mu Max               2.72746
trainer/Policy mu Min              -2.34397
trainer/Policy log std Mean        -1.89101
trainer/Policy log std Std          0.576996
trainer/Policy log std Max         -0.318653
trainer/Policy log std Min         -2.70389
trainer/Alpha                       0.0787505
trainer/Alpha Loss                  0.440324
exploration/num steps total     31400
exploration/num paths total       314
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.702892
exploration/Rewards Std             1.16496
exploration/Rewards Max            -0.247166
exploration/Rewards Min            -9.65939
exploration/Returns Mean          -70.2892
exploration/Returns Std            14.1234
exploration/Returns Max           -56.1658
exploration/Returns Min           -84.4125
exploration/Actions Mean            0.0419518
exploration/Actions Std             0.230611
exploration/Actions Max             0.997981
exploration/Actions Min            -0.644085
exploration/Num Paths               2
exploration/Average Returns       -70.2892
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.785366
evaluation/Rewards Std              0.705618
evaluation/Rewards Max             -0.433716
evaluation/Rewards Min             -7.947
evaluation/Returns Mean           -78.5366
evaluation/Returns Std             15.407
evaluation/Returns Max            -53.2717
evaluation/Returns Min            -96.7946
evaluation/Actions Mean            -0.0033185
evaluation/Actions Std              0.167699
evaluation/Actions Max              0.991946
evaluation/Actions Min             -0.983504
evaluation/Num Paths               10
evaluation/Average Returns        -78.5366
time/data storing (s)               0.00126256
time/evaluation sampling (s)        0.23192
time/exploration sampling (s)       0.0672871
time/logging (s)                    0.00284567
time/saving (s)                     0.00200285
time/training (s)                   0.776568
time/epoch (s)                      1.08189
time/total (s)                    166.286
Epoch                             155
-----------------------------  ---------------
2019-04-21 01:14:30.705614 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              31600
trainer/QF1 Loss                    0.372012
trainer/QF2 Loss                    0.365276
trainer/Policy Loss                54.0509
trainer/Q1 Predictions Mean       -52.9309
trainer/Q1 Predictions Std          6.20822
trainer/Q1 Predictions Max        -48.8009
trainer/Q1 Predictions Min        -97.8962
trainer/Q2 Predictions Mean       -52.9043
trainer/Q2 Predictions Std          6.15575
trainer/Q2 Predictions Max        -48.8097
trainer/Q2 Predictions Min        -97.274
trainer/Q Targets Mean            -53.3419
trainer/Q Targets Std               6.18936
trainer/Q Targets Max             -49.2649
trainer/Q Targets Min             -96.8324
trainer/Log Pis Mean                2.12183
trainer/Log Pis Std                 1.28439
trainer/Log Pis Max                 5.33312
trainer/Log Pis Min                -3.54823
trainer/Policy mu Mean              0.0679393
trainer/Policy mu Std               0.779785
trainer/Policy mu Max               2.62117
trainer/Policy mu Min              -2.92434
trainer/Policy log std Mean        -1.98787
trainer/Policy log std Std          0.553532
trainer/Policy log std Max         -0.274228
trainer/Policy log std Min         -2.60284
trainer/Alpha                       0.080083
trainer/Alpha Loss                  0.307602
exploration/num steps total     31600
exploration/num paths total       316
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.661897
exploration/Rewards Std             0.829615
exploration/Rewards Max            -0.313514
exploration/Rewards Min            -7.68852
exploration/Returns Mean          -66.1897
exploration/Returns Std            11.4589
exploration/Returns Max           -54.7308
exploration/Returns Min           -77.6486
exploration/Actions Mean            0.0379622
exploration/Actions Std             0.205552
exploration/Actions Max             0.998234
exploration/Actions Min            -0.326763
exploration/Num Paths               2
exploration/Average Returns       -66.1897
evaluation/num steps total     157000
evaluation/num paths total       1570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.811899
evaluation/Rewards Std              1.07613
evaluation/Rewards Max             -0.485276
evaluation/Rewards Min            -10.4845
evaluation/Returns Mean           -81.1899
evaluation/Returns Std             19.1123
evaluation/Returns Max            -52.5457
evaluation/Returns Min           -111.67
evaluation/Actions Mean             0.00519162
evaluation/Actions Std              0.190835
evaluation/Actions Max              0.995411
evaluation/Actions Min             -0.993689
evaluation/Num Paths               10
evaluation/Average Returns        -81.1899
time/data storing (s)               0.0012377
time/evaluation sampling (s)        0.227703
time/exploration sampling (s)       0.0647612
time/logging (s)                    0.00335776
time/saving (s)                     0.00158808
time/training (s)                   0.772439
time/epoch (s)                      1.07109
time/total (s)                    167.361
Epoch                             156
-----------------------------  ---------------
2019-04-21 01:14:31.785689 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              31800
trainer/QF1 Loss                   50.6373
trainer/QF2 Loss                   50.8993
trainer/Policy Loss                53.8135
trainer/Q1 Predictions Mean       -52.6831
trainer/Q1 Predictions Std          7.1126
trainer/Q1 Predictions Max        -48.3783
trainer/Q1 Predictions Min       -107.849
trainer/Q2 Predictions Mean       -52.6712
trainer/Q2 Predictions Std          7.04499
trainer/Q2 Predictions Max        -48.4785
trainer/Q2 Predictions Min       -107.34
trainer/Q Targets Mean            -52.3408
trainer/Q Targets Std              10.3905
trainer/Q Targets Max              -0.839071
trainer/Q Targets Min            -110.921
trainer/Log Pis Mean                1.84698
trainer/Log Pis Std                 1.37716
trainer/Log Pis Max                 5.39157
trainer/Log Pis Min                -5.41001
trainer/Policy mu Mean              0.0921823
trainer/Policy mu Std               0.71324
trainer/Policy mu Max               2.91294
trainer/Policy mu Min              -2.43296
trainer/Policy log std Mean        -2.00624
trainer/Policy log std Std          0.514387
trainer/Policy log std Max         -0.289591
trainer/Policy log std Min         -2.56612
trainer/Alpha                       0.0814373
trainer/Alpha Loss                 -0.383776
exploration/num steps total     31800
exploration/num paths total       318
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.0835
exploration/Rewards Std             1.52697
exploration/Rewards Max            -0.289101
exploration/Rewards Min           -10.0323
exploration/Returns Mean         -108.35
exploration/Returns Std            19.3043
exploration/Returns Max           -89.0461
exploration/Returns Min          -127.655
exploration/Actions Mean            0.0135504
exploration/Actions Std             0.26932
exploration/Actions Max             0.998077
exploration/Actions Min            -0.994104
exploration/Num Paths               2
exploration/Average Returns      -108.35
evaluation/num steps total     158000
evaluation/num paths total       1580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.778145
evaluation/Rewards Std              0.881816
evaluation/Rewards Max             -0.52218
evaluation/Rewards Min             -9.16343
evaluation/Returns Mean           -77.8145
evaluation/Returns Std             18.6649
evaluation/Returns Max            -55.7172
evaluation/Returns Min           -118.493
evaluation/Actions Mean             0.00935615
evaluation/Actions Std              0.183732
evaluation/Actions Max              0.992902
evaluation/Actions Min             -0.993402
evaluation/Num Paths               10
evaluation/Average Returns        -77.8145
time/data storing (s)               0.00125863
time/evaluation sampling (s)        0.225951
time/exploration sampling (s)       0.0704212
time/logging (s)                    0.00336037
time/saving (s)                     0.00175344
time/training (s)                   0.770527
time/epoch (s)                      1.07327
time/total (s)                    168.438
Epoch                             157
-----------------------------  ---------------
2019-04-21 01:14:32.853750 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              32000
trainer/QF1 Loss                    0.566154
trainer/QF2 Loss                    0.603258
trainer/Policy Loss                54.089
trainer/Q1 Predictions Mean       -52.7624
trainer/Q1 Predictions Std         10.2025
trainer/Q1 Predictions Max        -47.1664
trainer/Q1 Predictions Min       -115.226
trainer/Q2 Predictions Mean       -52.7393
trainer/Q2 Predictions Std         10.195
trainer/Q2 Predictions Max        -47.1651
trainer/Q2 Predictions Min       -115.264
trainer/Q Targets Mean            -53.3515
trainer/Q Targets Std              10.2618
trainer/Q Targets Max             -48.1186
trainer/Q Targets Min            -117.22
trainer/Log Pis Mean                2.12605
trainer/Log Pis Std                 0.897887
trainer/Log Pis Max                 5.42755
trainer/Log Pis Min                -1.20175
trainer/Policy mu Mean             -0.00229385
trainer/Policy mu Std               0.72329
trainer/Policy mu Max               2.75741
trainer/Policy mu Min              -3.24225
trainer/Policy log std Mean        -2.01851
trainer/Policy log std Std          0.483426
trainer/Policy log std Max         -0.553654
trainer/Policy log std Min         -2.5422
trainer/Alpha                       0.0809253
trainer/Alpha Loss                  0.316925
exploration/num steps total     32000
exploration/num paths total       320
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.807532
exploration/Rewards Std             1.0719
exploration/Rewards Max            -0.289951
exploration/Rewards Min            -9.24036
exploration/Returns Mean          -80.7532
exploration/Returns Std            27.7609
exploration/Returns Max           -52.9924
exploration/Returns Min          -108.514
exploration/Actions Mean           -0.0422688
exploration/Actions Std             0.229159
exploration/Actions Max             0.397673
exploration/Actions Min            -0.994418
exploration/Num Paths               2
exploration/Average Returns       -80.7532
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.808057
evaluation/Rewards Std              1.03268
evaluation/Rewards Max             -0.414731
evaluation/Rewards Min             -9.70055
evaluation/Returns Mean           -80.8057
evaluation/Returns Std             16.2546
evaluation/Returns Max            -45.9504
evaluation/Returns Min            -97.1478
evaluation/Actions Mean            -0.00408349
evaluation/Actions Std              0.201385
evaluation/Actions Max              0.994004
evaluation/Actions Min             -0.99483
evaluation/Num Paths               10
evaluation/Average Returns        -80.8057
time/data storing (s)               0.00129973
time/evaluation sampling (s)        0.223298
time/exploration sampling (s)       0.0641958
time/logging (s)                    0.00337682
time/saving (s)                     0.0016076
time/training (s)                   0.767539
time/epoch (s)                      1.06132
time/total (s)                    169.504
Epoch                             158
-----------------------------  ---------------
2019-04-21 01:14:33.925306 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 159 finished
-----------------------------  ----------------
replay_buffer/size              32200
trainer/QF1 Loss                   23.7682
trainer/QF2 Loss                   23.9036
trainer/Policy Loss                53.7505
trainer/Q1 Predictions Mean       -52.5815
trainer/Q1 Predictions Std          7.89611
trainer/Q1 Predictions Max        -46.9684
trainer/Q1 Predictions Min       -101.813
trainer/Q2 Predictions Mean       -52.5678
trainer/Q2 Predictions Std          7.8257
trainer/Q2 Predictions Max        -47.1588
trainer/Q2 Predictions Min       -101.063
trainer/Q Targets Mean            -52.7137
trainer/Q Targets Std               9.766
trainer/Q Targets Max              -1.22919
trainer/Q Targets Min            -105.153
trainer/Log Pis Mean                1.975
trainer/Log Pis Std                 1.05124
trainer/Log Pis Max                 4.67925
trainer/Log Pis Min                -1.73112
trainer/Policy mu Mean              0.000561609
trainer/Policy mu Std               0.777141
trainer/Policy mu Max               2.85008
trainer/Policy mu Min              -2.39915
trainer/Policy log std Mean        -1.93034
trainer/Policy log std Std          0.506167
trainer/Policy log std Max         -0.554598
trainer/Policy log std Min         -2.55132
trainer/Alpha                       0.0784367
trainer/Alpha Loss                 -0.0636285
exploration/num steps total     32200
exploration/num paths total       322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.676306
exploration/Rewards Std             0.610805
exploration/Rewards Max            -0.187671
exploration/Rewards Min            -6.12569
exploration/Returns Mean          -67.6306
exploration/Returns Std            14.9291
exploration/Returns Max           -52.7015
exploration/Returns Min           -82.5598
exploration/Actions Mean           -0.00714166
exploration/Actions Std             0.196981
exploration/Actions Max             0.992048
exploration/Actions Min            -0.97791
exploration/Num Paths               2
exploration/Average Returns       -67.6306
evaluation/num steps total     160000
evaluation/num paths total       1600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.706233
evaluation/Rewards Std              0.993703
evaluation/Rewards Max             -0.308347
evaluation/Rewards Min             -9.70825
evaluation/Returns Mean           -70.6233
evaluation/Returns Std             31.1198
evaluation/Returns Max            -35.2022
evaluation/Returns Min           -121.205
evaluation/Actions Mean            -0.00669374
evaluation/Actions Std              0.185639
evaluation/Actions Max              0.993856
evaluation/Actions Min             -0.995775
evaluation/Num Paths               10
evaluation/Average Returns        -70.6233
time/data storing (s)               0.00145804
time/evaluation sampling (s)        0.222575
time/exploration sampling (s)       0.0661767
time/logging (s)                    0.00336359
time/saving (s)                     0.00196349
time/training (s)                   0.769176
time/epoch (s)                      1.06471
time/total (s)                    170.573
Epoch                             159
-----------------------------  ----------------
2019-04-21 01:14:34.999091 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              32400
trainer/QF1 Loss                   25.3921
trainer/QF2 Loss                   25.3859
trainer/Policy Loss                52.5534
trainer/Q1 Predictions Mean       -51.639
trainer/Q1 Predictions Std          6.42171
trainer/Q1 Predictions Max        -47.0465
trainer/Q1 Predictions Min       -104.567
trainer/Q2 Predictions Mean       -51.6638
trainer/Q2 Predictions Std          6.52398
trainer/Q2 Predictions Max        -47.2153
trainer/Q2 Predictions Min       -105.599
trainer/Q Targets Mean            -51.4719
trainer/Q Targets Std               8.20323
trainer/Q Targets Max              -1.22081
trainer/Q Targets Min            -104.652
trainer/Log Pis Mean                1.80755
trainer/Log Pis Std                 1.20495
trainer/Log Pis Max                 5.77971
trainer/Log Pis Min                -1.42119
trainer/Policy mu Mean              0.0694371
trainer/Policy mu Std               0.728351
trainer/Policy mu Max               2.61694
trainer/Policy mu Min              -2.67976
trainer/Policy log std Mean        -1.98197
trainer/Policy log std Std          0.520519
trainer/Policy log std Max         -0.505109
trainer/Policy log std Min         -2.56645
trainer/Alpha                       0.0785762
trainer/Alpha Loss                 -0.489541
exploration/num steps total     32400
exploration/num paths total       324
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.707893
exploration/Rewards Std             0.588606
exploration/Rewards Max            -0.212832
exploration/Rewards Min            -5.77323
exploration/Returns Mean          -70.7893
exploration/Returns Std             6.25362
exploration/Returns Max           -64.5357
exploration/Returns Min           -77.0429
exploration/Actions Mean            0.0116951
exploration/Actions Std             0.180963
exploration/Actions Max             0.997491
exploration/Actions Min            -0.777874
exploration/Num Paths               2
exploration/Average Returns       -70.7893
evaluation/num steps total     161000
evaluation/num paths total       1610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.74316
evaluation/Rewards Std              0.940688
evaluation/Rewards Max             -0.419403
evaluation/Rewards Min             -9.0244
evaluation/Returns Mean           -74.316
evaluation/Returns Std             19.8678
evaluation/Returns Max            -46.962
evaluation/Returns Min           -113.661
evaluation/Actions Mean             0.0020986
evaluation/Actions Std              0.187667
evaluation/Actions Max              0.992021
evaluation/Actions Min             -0.990396
evaluation/Num Paths               10
evaluation/Average Returns        -74.316
time/data storing (s)               0.00127917
time/evaluation sampling (s)        0.231198
time/exploration sampling (s)       0.0650045
time/logging (s)                    0.00356905
time/saving (s)                     0.00159969
time/training (s)                   0.764308
time/epoch (s)                      1.06696
time/total (s)                    171.644
Epoch                             160
-----------------------------  ---------------
2019-04-21 01:14:36.057226 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              32600
trainer/QF1 Loss                   23.5071
trainer/QF2 Loss                   23.3778
trainer/Policy Loss                52.4969
trainer/Q1 Predictions Mean       -51.0148
trainer/Q1 Predictions Std          5.41351
trainer/Q1 Predictions Max        -46.2652
trainer/Q1 Predictions Min        -79.4338
trainer/Q2 Predictions Mean       -50.9986
trainer/Q2 Predictions Std          5.39107
trainer/Q2 Predictions Max        -46.4425
trainer/Q2 Predictions Min        -79.3516
trainer/Q Targets Mean            -50.937
trainer/Q Targets Std               7.44244
trainer/Q Targets Max              -1.83959
trainer/Q Targets Min             -79.0749
trainer/Log Pis Mean                2.16717
trainer/Log Pis Std                 1.32924
trainer/Log Pis Max                 6.4742
trainer/Log Pis Min                -4.92911
trainer/Policy mu Mean              0.0365108
trainer/Policy mu Std               0.752258
trainer/Policy mu Max               2.42537
trainer/Policy mu Min              -2.69685
trainer/Policy log std Mean        -2.00934
trainer/Policy log std Std          0.539504
trainer/Policy log std Max         -0.286816
trainer/Policy log std Min         -2.58217
trainer/Alpha                       0.0786894
trainer/Alpha Loss                  0.424994
exploration/num steps total     32600
exploration/num paths total       326
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03324
exploration/Rewards Std             1.38104
exploration/Rewards Max            -0.493759
exploration/Rewards Min           -10.8582
exploration/Returns Mean         -103.324
exploration/Returns Std            17.007
exploration/Returns Max           -86.3169
exploration/Returns Min          -120.331
exploration/Actions Mean           -0.0182289
exploration/Actions Std             0.250168
exploration/Actions Max             0.992353
exploration/Actions Min            -0.99808
exploration/Num Paths               2
exploration/Average Returns      -103.324
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.730595
evaluation/Rewards Std              0.889965
evaluation/Rewards Max             -0.470874
evaluation/Rewards Min             -9.97689
evaluation/Returns Mean           -73.0595
evaluation/Returns Std             16.9455
evaluation/Returns Max            -51.2955
evaluation/Returns Min           -104.514
evaluation/Actions Mean             0.0135746
evaluation/Actions Std              0.178207
evaluation/Actions Max              0.994148
evaluation/Actions Min             -0.989001
evaluation/Num Paths               10
evaluation/Average Returns        -73.0595
time/data storing (s)               0.00129854
time/evaluation sampling (s)        0.222206
time/exploration sampling (s)       0.0650039
time/logging (s)                    0.00337696
time/saving (s)                     0.0019618
time/training (s)                   0.757483
time/epoch (s)                      1.05133
time/total (s)                    172.699
Epoch                             161
-----------------------------  ---------------
2019-04-21 01:14:37.127708 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              32800
trainer/QF1 Loss                   47.738
trainer/QF2 Loss                   47.3675
trainer/Policy Loss                52.724
trainer/Q1 Predictions Mean       -51.6177
trainer/Q1 Predictions Std          7.2083
trainer/Q1 Predictions Max        -45.5437
trainer/Q1 Predictions Min       -101.36
trainer/Q2 Predictions Mean       -51.6057
trainer/Q2 Predictions Std          7.21508
trainer/Q2 Predictions Max        -45.6594
trainer/Q2 Predictions Min       -101.159
trainer/Q Targets Mean            -50.9558
trainer/Q Targets Std               9.92938
trainer/Q Targets Max              -0.435125
trainer/Q Targets Min            -100.179
trainer/Log Pis Mean                1.89207
trainer/Log Pis Std                 1.55302
trainer/Log Pis Max                 6.4967
trainer/Log Pis Min                -4.54294
trainer/Policy mu Mean             -0.0966197
trainer/Policy mu Std               0.804377
trainer/Policy mu Max               1.95796
trainer/Policy mu Min              -3.04137
trainer/Policy log std Mean        -1.94404
trainer/Policy log std Std          0.55603
trainer/Policy log std Max         -0.357045
trainer/Policy log std Min         -2.56682
trainer/Alpha                       0.0782137
trainer/Alpha Loss                 -0.275032
exploration/num steps total     32800
exploration/num paths total       328
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.792891
exploration/Rewards Std             0.857667
exploration/Rewards Max            -0.372852
exploration/Rewards Min            -8.36837
exploration/Returns Mean          -79.2891
exploration/Returns Std             5.88027
exploration/Returns Max           -73.4088
exploration/Returns Min           -85.1694
exploration/Actions Mean            0.0304617
exploration/Actions Std             0.223056
exploration/Actions Max             0.996193
exploration/Actions Min            -0.93172
exploration/Num Paths               2
exploration/Average Returns       -79.2891
evaluation/num steps total     163000
evaluation/num paths total       1630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.860621
evaluation/Rewards Std              1.05745
evaluation/Rewards Max             -0.437993
evaluation/Rewards Min            -10.9904
evaluation/Returns Mean           -86.0621
evaluation/Returns Std             21.2542
evaluation/Returns Max            -56.7558
evaluation/Returns Min           -123.582
evaluation/Actions Mean            -0.00685354
evaluation/Actions Std              0.190104
evaluation/Actions Max              0.992822
evaluation/Actions Min             -0.997828
evaluation/Num Paths               10
evaluation/Average Returns        -86.0621
time/data storing (s)               0.00127402
time/evaluation sampling (s)        0.226565
time/exploration sampling (s)       0.0646878
time/logging (s)                    0.00336984
time/saving (s)                     0.00200805
time/training (s)                   0.765993
time/epoch (s)                      1.0639
time/total (s)                    173.767
Epoch                             162
-----------------------------  ---------------
2019-04-21 01:14:38.194992 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              33000
trainer/QF1 Loss                   25.5793
trainer/QF2 Loss                   25.8452
trainer/Policy Loss                52.3982
trainer/Q1 Predictions Mean       -51.1822
trainer/Q1 Predictions Std          6.59228
trainer/Q1 Predictions Max        -44.8282
trainer/Q1 Predictions Min        -85.8468
trainer/Q2 Predictions Mean       -51.1688
trainer/Q2 Predictions Std          6.56913
trainer/Q2 Predictions Max        -45.0362
trainer/Q2 Predictions Min        -85.922
trainer/Q Targets Mean            -51.0942
trainer/Q Targets Std               8.33906
trainer/Q Targets Max              -0.752348
trainer/Q Targets Min             -87.7167
trainer/Log Pis Mean                2.14541
trainer/Log Pis Std                 1.37167
trainer/Log Pis Max                 6.61349
trainer/Log Pis Min                -5.69068
trainer/Policy mu Mean              0.0303626
trainer/Policy mu Std               0.858739
trainer/Policy mu Max               2.78905
trainer/Policy mu Min              -2.67295
trainer/Policy log std Mean        -1.95217
trainer/Policy log std Std          0.593891
trainer/Policy log std Max         -0.449689
trainer/Policy log std Min         -2.6899
trainer/Alpha                       0.0788864
trainer/Alpha Loss                  0.369322
exploration/num steps total     33000
exploration/num paths total       330
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.99173
exploration/Rewards Std             1.14364
exploration/Rewards Max            -0.360299
exploration/Rewards Min            -8.38943
exploration/Returns Mean          -99.173
exploration/Returns Std             4.73181
exploration/Returns Max           -94.4412
exploration/Returns Min          -103.905
exploration/Actions Mean           -0.0517974
exploration/Actions Std             0.241094
exploration/Actions Max             0.394866
exploration/Actions Min            -0.993825
exploration/Num Paths               2
exploration/Average Returns       -99.173
evaluation/num steps total     164000
evaluation/num paths total       1640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.727268
evaluation/Rewards Std              0.777998
evaluation/Rewards Max             -0.190842
evaluation/Rewards Min             -9.08401
evaluation/Returns Mean           -72.7268
evaluation/Returns Std             16.4785
evaluation/Returns Max            -50.7277
evaluation/Returns Min           -104.591
evaluation/Actions Mean             0.00593692
evaluation/Actions Std              0.175685
evaluation/Actions Max              0.99414
evaluation/Actions Min             -0.993848
evaluation/Num Paths               10
evaluation/Average Returns        -72.7268
time/data storing (s)               0.0013202
time/evaluation sampling (s)        0.219759
time/exploration sampling (s)       0.0630081
time/logging (s)                    0.00256802
time/saving (s)                     0.00160242
time/training (s)                   0.771299
time/epoch (s)                      1.05956
time/total (s)                    174.831
Epoch                             163
-----------------------------  ---------------
2019-04-21 01:14:39.330806 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              33200
trainer/QF1 Loss                    0.189276
trainer/QF2 Loss                    0.181611
trainer/Policy Loss                52.1747
trainer/Q1 Predictions Mean       -50.8077
trainer/Q1 Predictions Std          6.69984
trainer/Q1 Predictions Max        -44.8847
trainer/Q1 Predictions Min        -93.7606
trainer/Q2 Predictions Mean       -50.8168
trainer/Q2 Predictions Std          6.6905
trainer/Q2 Predictions Max        -45.0501
trainer/Q2 Predictions Min        -93.1932
trainer/Q Targets Mean            -51.0242
trainer/Q Targets Std               6.69443
trainer/Q Targets Max             -45.1887
trainer/Q Targets Min             -93.7982
trainer/Log Pis Mean                1.90389
trainer/Log Pis Std                 1.13006
trainer/Log Pis Max                 4.89982
trainer/Log Pis Min                -3.85804
trainer/Policy mu Mean              0.0675714
trainer/Policy mu Std               0.728636
trainer/Policy mu Max               2.84181
trainer/Policy mu Min              -2.45331
trainer/Policy log std Mean        -1.99666
trainer/Policy log std Std          0.48784
trainer/Policy log std Max         -0.544871
trainer/Policy log std Min         -2.67285
trainer/Alpha                       0.0796517
trainer/Alpha Loss                 -0.243164
exploration/num steps total     33200
exploration/num paths total       332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.07423
exploration/Rewards Std             1.17542
exploration/Rewards Max            -0.484712
exploration/Rewards Min            -9.1353
exploration/Returns Mean         -107.423
exploration/Returns Std            12.2034
exploration/Returns Max           -95.2199
exploration/Returns Min          -119.627
exploration/Actions Mean           -0.0409348
exploration/Actions Std             0.240452
exploration/Actions Max             0.705294
exploration/Actions Min            -0.996849
exploration/Num Paths               2
exploration/Average Returns      -107.423
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.861898
evaluation/Rewards Std              1.16221
evaluation/Rewards Max             -0.418948
evaluation/Rewards Min            -10.6447
evaluation/Returns Mean           -86.1898
evaluation/Returns Std             24.1976
evaluation/Returns Max            -51.051
evaluation/Returns Min           -128.985
evaluation/Actions Mean            -0.00438658
evaluation/Actions Std              0.204324
evaluation/Actions Max              0.995337
evaluation/Actions Min             -0.996817
evaluation/Num Paths               10
evaluation/Average Returns        -86.1898
time/data storing (s)               0.00134616
time/evaluation sampling (s)        0.217278
time/exploration sampling (s)       0.0658373
time/logging (s)                    0.00335498
time/saving (s)                     0.00196766
time/training (s)                   0.839968
time/epoch (s)                      1.12975
time/total (s)                    175.964
Epoch                             164
-----------------------------  ---------------
2019-04-21 01:14:40.404878 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              33400
trainer/QF1 Loss                   21.6515
trainer/QF2 Loss                   21.6385
trainer/Policy Loss                50.7838
trainer/Q1 Predictions Mean       -49.3161
trainer/Q1 Predictions Std          4.14881
trainer/Q1 Predictions Max        -44.6658
trainer/Q1 Predictions Min        -71.734
trainer/Q2 Predictions Mean       -49.29
trainer/Q2 Predictions Std          4.16285
trainer/Q2 Predictions Max        -44.7191
trainer/Q2 Predictions Min        -71.919
trainer/Q Targets Mean            -48.9826
trainer/Q Targets Std               6.29987
trainer/Q Targets Max              -1.70532
trainer/Q Targets Min             -70.731
trainer/Log Pis Mean                1.98029
trainer/Log Pis Std                 1.00419
trainer/Log Pis Max                 4.02616
trainer/Log Pis Min                -1.60012
trainer/Policy mu Mean              0.0290615
trainer/Policy mu Std               0.648904
trainer/Policy mu Max               2.53597
trainer/Policy mu Min              -2.40481
trainer/Policy log std Mean        -2.04684
trainer/Policy log std Std          0.501676
trainer/Policy log std Max         -0.533547
trainer/Policy log std Min         -2.63776
trainer/Alpha                       0.0805894
trainer/Alpha Loss                 -0.0496432
exploration/num steps total     33400
exploration/num paths total       334
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.890554
exploration/Rewards Std             1.46301
exploration/Rewards Max            -0.31239
exploration/Rewards Min           -10.775
exploration/Returns Mean          -89.0554
exploration/Returns Std            13.7218
exploration/Returns Max           -75.3336
exploration/Returns Min          -102.777
exploration/Actions Mean            0.0386059
exploration/Actions Std             0.256766
exploration/Actions Max             0.999062
exploration/Actions Min            -0.973306
exploration/Num Paths               2
exploration/Average Returns       -89.0554
evaluation/num steps total     166000
evaluation/num paths total       1660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.81015
evaluation/Rewards Std              0.838009
evaluation/Rewards Max             -0.525107
evaluation/Rewards Min             -8.52972
evaluation/Returns Mean           -81.015
evaluation/Returns Std             14.6886
evaluation/Returns Max            -56.923
evaluation/Returns Min           -110.365
evaluation/Actions Mean             0.0117829
evaluation/Actions Std              0.185218
evaluation/Actions Max              0.991923
evaluation/Actions Min             -0.989405
evaluation/Num Paths               10
evaluation/Average Returns        -81.015
time/data storing (s)               0.00118229
time/evaluation sampling (s)        0.227542
time/exploration sampling (s)       0.0636689
time/logging (s)                    0.00334674
time/saving (s)                     0.00201352
time/training (s)                   0.769627
time/epoch (s)                      1.06738
time/total (s)                    177.036
Epoch                             165
-----------------------------  ---------------
2019-04-21 01:14:41.455682 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              33600
trainer/QF1 Loss                   21.4473
trainer/QF2 Loss                   21.5083
trainer/Policy Loss                50.746
trainer/Q1 Predictions Mean       -49.7323
trainer/Q1 Predictions Std          5.6074
trainer/Q1 Predictions Max        -43.7108
trainer/Q1 Predictions Min        -78.7253
trainer/Q2 Predictions Mean       -49.7758
trainer/Q2 Predictions Std          5.69295
trainer/Q2 Predictions Max        -43.7586
trainer/Q2 Predictions Min        -79.3249
trainer/Q Targets Mean            -50.0514
trainer/Q Targets Std               7.45827
trainer/Q Targets Max              -1.76973
trainer/Q Targets Min             -80.1636
trainer/Log Pis Mean                1.81851
trainer/Log Pis Std                 1.31895
trainer/Log Pis Max                 4.97581
trainer/Log Pis Min                -4.0659
trainer/Policy mu Mean              0.0413417
trainer/Policy mu Std               0.792036
trainer/Policy mu Max               2.68316
trainer/Policy mu Min              -2.2079
trainer/Policy log std Mean        -1.93015
trainer/Policy log std Std          0.553443
trainer/Policy log std Max         -0.472558
trainer/Policy log std Min         -2.7425
trainer/Alpha                       0.0812059
trainer/Alpha Loss                 -0.45568
exploration/num steps total     33600
exploration/num paths total       336
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.958447
exploration/Rewards Std             0.747371
exploration/Rewards Max            -0.546144
exploration/Rewards Min            -7.3379
exploration/Returns Mean          -95.8447
exploration/Returns Std             9.18577
exploration/Returns Max           -86.659
exploration/Returns Min          -105.031
exploration/Actions Mean           -0.0214807
exploration/Actions Std             0.22068
exploration/Actions Max             0.965772
exploration/Actions Min            -0.996377
exploration/Num Paths               2
exploration/Average Returns       -95.8447
evaluation/num steps total     167000
evaluation/num paths total       1670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.879736
evaluation/Rewards Std              0.99623
evaluation/Rewards Max             -0.470582
evaluation/Rewards Min            -10.5147
evaluation/Returns Mean           -87.9736
evaluation/Returns Std             19.3336
evaluation/Returns Max            -60.4523
evaluation/Returns Min           -112.294
evaluation/Actions Mean             0.00479931
evaluation/Actions Std              0.201115
evaluation/Actions Max              0.995566
evaluation/Actions Min             -0.993609
evaluation/Num Paths               10
evaluation/Average Returns        -87.9736
time/data storing (s)               0.00149748
time/evaluation sampling (s)        0.220777
time/exploration sampling (s)       0.0660071
time/logging (s)                    0.00335283
time/saving (s)                     0.00196931
time/training (s)                   0.750233
time/epoch (s)                      1.04384
time/total (s)                    178.084
Epoch                             166
-----------------------------  ---------------
2019-04-21 01:14:42.517581 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              33800
trainer/QF1 Loss                   43.9944
trainer/QF2 Loss                   43.9492
trainer/Policy Loss                50.6297
trainer/Q1 Predictions Mean       -49.5714
trainer/Q1 Predictions Std          5.14999
trainer/Q1 Predictions Max        -43.1966
trainer/Q1 Predictions Min        -72.2455
trainer/Q2 Predictions Mean       -49.5851
trainer/Q2 Predictions Std          5.1519
trainer/Q2 Predictions Max        -43.3182
trainer/Q2 Predictions Min        -72.2499
trainer/Q Targets Mean            -49.4659
trainer/Q Targets Std               8.61022
trainer/Q Targets Max              -1.12686
trainer/Q Targets Min             -72.5197
trainer/Log Pis Mean                1.90758
trainer/Log Pis Std                 1.38097
trainer/Log Pis Max                 4.85483
trainer/Log Pis Min                -5.15123
trainer/Policy mu Mean             -0.0518962
trainer/Policy mu Std               0.846647
trainer/Policy mu Max               2.61345
trainer/Policy mu Min              -2.57351
trainer/Policy log std Mean        -1.89837
trainer/Policy log std Std          0.570789
trainer/Policy log std Max         -0.415104
trainer/Policy log std Min         -2.6622
trainer/Alpha                       0.081761
trainer/Alpha Loss                 -0.231422
exploration/num steps total     33800
exploration/num paths total       338
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.989974
exploration/Rewards Std             1.48349
exploration/Rewards Max            -0.270505
exploration/Rewards Min           -10.4171
exploration/Returns Mean          -98.9974
exploration/Returns Std            22.8414
exploration/Returns Max           -76.156
exploration/Returns Min          -121.839
exploration/Actions Mean            0.016972
exploration/Actions Std             0.266414
exploration/Actions Max             0.996417
exploration/Actions Min            -0.99879
exploration/Num Paths               2
exploration/Average Returns       -98.9974
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.683478
evaluation/Rewards Std              0.542258
evaluation/Rewards Max             -0.485385
evaluation/Rewards Min             -8.64564
evaluation/Returns Mean           -68.3478
evaluation/Returns Std             12.4615
evaluation/Returns Max            -50.9529
evaluation/Returns Min            -95.6642
evaluation/Actions Mean             0.00438826
evaluation/Actions Std              0.15295
evaluation/Actions Max              0.986736
evaluation/Actions Min             -0.993222
evaluation/Num Paths               10
evaluation/Average Returns        -68.3478
time/data storing (s)               0.00155766
time/evaluation sampling (s)        0.221087
time/exploration sampling (s)       0.0653769
time/logging (s)                    0.00339082
time/saving (s)                     0.00199262
time/training (s)                   0.761453
time/epoch (s)                      1.05486
time/total (s)                    179.143
Epoch                             167
-----------------------------  ---------------
2019-04-21 01:14:43.590581 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              34000
trainer/QF1 Loss                   44.3197
trainer/QF2 Loss                   44.3677
trainer/Policy Loss                50.0507
trainer/Q1 Predictions Mean       -48.7693
trainer/Q1 Predictions Std          7.49801
trainer/Q1 Predictions Max        -43.118
trainer/Q1 Predictions Min       -108.003
trainer/Q2 Predictions Mean       -48.8037
trainer/Q2 Predictions Std          7.49469
trainer/Q2 Predictions Max        -43.2466
trainer/Q2 Predictions Min       -108.048
trainer/Q Targets Mean            -48.1537
trainer/Q Targets Std               9.96308
trainer/Q Targets Max              -1.02673
trainer/Q Targets Min            -107.527
trainer/Log Pis Mean                1.99037
trainer/Log Pis Std                 1.08107
trainer/Log Pis Max                 6.92228
trainer/Log Pis Min                -2.05388
trainer/Policy mu Mean              0.108623
trainer/Policy mu Std               0.7106
trainer/Policy mu Max               2.71427
trainer/Policy mu Min              -3.16132
trainer/Policy log std Mean        -1.97087
trainer/Policy log std Std          0.512662
trainer/Policy log std Max         -0.596204
trainer/Policy log std Min         -2.65094
trainer/Alpha                       0.0806649
trainer/Alpha Loss                 -0.0242412
exploration/num steps total     34000
exploration/num paths total       340
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.821209
exploration/Rewards Std             1.02728
exploration/Rewards Max            -0.255355
exploration/Rewards Min            -8.92075
exploration/Returns Mean          -82.1209
exploration/Returns Std             2.87509
exploration/Returns Max           -79.2458
exploration/Returns Min           -84.996
exploration/Actions Mean            0.026796
exploration/Actions Std             0.235705
exploration/Actions Max             0.997059
exploration/Actions Min            -0.941555
exploration/Num Paths               2
exploration/Average Returns       -82.1209
evaluation/num steps total     169000
evaluation/num paths total       1690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.776533
evaluation/Rewards Std              1.11116
evaluation/Rewards Max             -0.434219
evaluation/Rewards Min            -10.3322
evaluation/Returns Mean           -77.6533
evaluation/Returns Std             20.3527
evaluation/Returns Max            -49.063
evaluation/Returns Min           -116.978
evaluation/Actions Mean             0.00419674
evaluation/Actions Std              0.194781
evaluation/Actions Max              0.997251
evaluation/Actions Min             -0.992004
evaluation/Num Paths               10
evaluation/Average Returns        -77.6533
time/data storing (s)               0.00126935
time/evaluation sampling (s)        0.228346
time/exploration sampling (s)       0.0653597
time/logging (s)                    0.00336224
time/saving (s)                     0.00194945
time/training (s)                   0.76571
time/epoch (s)                      1.066
time/total (s)                    180.213
Epoch                             168
-----------------------------  ---------------
2019-04-21 01:14:44.661701 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                    0.294219
trainer/QF2 Loss                    0.327916
trainer/Policy Loss                51.5435
trainer/Q1 Predictions Mean       -50.5873
trainer/Q1 Predictions Std         10.8473
trainer/Q1 Predictions Max        -42.3376
trainer/Q1 Predictions Min       -113.168
trainer/Q2 Predictions Mean       -50.5712
trainer/Q2 Predictions Std         10.8613
trainer/Q2 Predictions Max        -42.5004
trainer/Q2 Predictions Min       -113.075
trainer/Q Targets Mean            -50.9697
trainer/Q Targets Std              10.8728
trainer/Q Targets Max             -43.1761
trainer/Q Targets Min            -114.517
trainer/Log Pis Mean                1.94032
trainer/Log Pis Std                 1.69022
trainer/Log Pis Max                 8.14295
trainer/Log Pis Min                -3.36879
trainer/Policy mu Mean             -0.0195073
trainer/Policy mu Std               0.89522
trainer/Policy mu Max               2.60898
trainer/Policy mu Min              -3.33623
trainer/Policy log std Mean        -1.91241
trainer/Policy log std Std          0.558575
trainer/Policy log std Max         -0.419209
trainer/Policy log std Min         -2.67043
trainer/Alpha                       0.0813035
trainer/Alpha Loss                 -0.149779
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.963263
exploration/Rewards Std             1.40361
exploration/Rewards Max            -0.343637
exploration/Rewards Min           -10.0832
exploration/Returns Mean          -96.3263
exploration/Returns Std            21.3676
exploration/Returns Max           -74.9587
exploration/Returns Min          -117.694
exploration/Actions Mean           -0.011523
exploration/Actions Std             0.247329
exploration/Actions Max             0.997982
exploration/Actions Min            -0.999203
exploration/Num Paths               2
exploration/Average Returns       -96.3263
evaluation/num steps total     170000
evaluation/num paths total       1700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.765952
evaluation/Rewards Std              0.884898
evaluation/Rewards Max             -0.483966
evaluation/Rewards Min             -9.46153
evaluation/Returns Mean           -76.5952
evaluation/Returns Std             17.4944
evaluation/Returns Max            -50.6324
evaluation/Returns Min           -112.73
evaluation/Actions Mean             0.00161812
evaluation/Actions Std              0.184306
evaluation/Actions Max              0.990923
evaluation/Actions Min             -0.993539
evaluation/Num Paths               10
evaluation/Average Returns        -76.5952
time/data storing (s)               0.00120861
time/evaluation sampling (s)        0.22629
time/exploration sampling (s)       0.0648423
time/logging (s)                    0.00348127
time/saving (s)                     0.00199964
time/training (s)                   0.76644
time/epoch (s)                      1.06426
time/total (s)                    181.281
Epoch                             169
-----------------------------  ---------------
2019-04-21 01:14:45.742444 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              34400
trainer/QF1 Loss                    0.646271
trainer/QF2 Loss                    0.626983
trainer/Policy Loss                50.9409
trainer/Q1 Predictions Mean       -49.8454
trainer/Q1 Predictions Std          8.90573
trainer/Q1 Predictions Max        -41.9873
trainer/Q1 Predictions Min        -97.2372
trainer/Q2 Predictions Mean       -49.8727
trainer/Q2 Predictions Std          8.91816
trainer/Q2 Predictions Max        -42.0617
trainer/Q2 Predictions Min        -98.0011
trainer/Q Targets Mean            -50.339
trainer/Q Targets Std               8.56918
trainer/Q Targets Max             -42.6183
trainer/Q Targets Min             -97.5598
trainer/Log Pis Mean                1.99019
trainer/Log Pis Std                 1.35899
trainer/Log Pis Max                 5.08493
trainer/Log Pis Min                -3.17254
trainer/Policy mu Mean              0.0422937
trainer/Policy mu Std               0.858727
trainer/Policy mu Max               2.73085
trainer/Policy mu Min              -2.76792
trainer/Policy log std Mean        -1.86537
trainer/Policy log std Std          0.559221
trainer/Policy log std Max         -0.449413
trainer/Policy log std Min         -2.66565
trainer/Alpha                       0.081237
trainer/Alpha Loss                 -0.0246339
exploration/num steps total     34400
exploration/num paths total       344
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.589974
exploration/Rewards Std             0.792539
exploration/Rewards Max            -0.224713
exploration/Rewards Min            -6.11313
exploration/Returns Mean          -58.9974
exploration/Returns Std             1.84177
exploration/Returns Max           -57.1556
exploration/Returns Min           -60.8391
exploration/Actions Mean            0.0177649
exploration/Actions Std             0.215782
exploration/Actions Max             0.997632
exploration/Actions Min            -0.952379
exploration/Num Paths               2
exploration/Average Returns       -58.9974
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.710454
evaluation/Rewards Std              0.841626
evaluation/Rewards Max             -0.393612
evaluation/Rewards Min            -11.0412
evaluation/Returns Mean           -71.0454
evaluation/Returns Std             22.888
evaluation/Returns Max            -45.5271
evaluation/Returns Min           -102.708
evaluation/Actions Mean            -0.00257997
evaluation/Actions Std              0.169267
evaluation/Actions Max              0.996587
evaluation/Actions Min             -0.993054
evaluation/Num Paths               10
evaluation/Average Returns        -71.0454
time/data storing (s)               0.0012257
time/evaluation sampling (s)        0.229276
time/exploration sampling (s)       0.0633222
time/logging (s)                    0.00335188
time/saving (s)                     0.00198883
time/training (s)                   0.774567
time/epoch (s)                      1.07373
time/total (s)                    182.359
Epoch                             170
-----------------------------  ---------------
2019-04-21 01:14:46.813546 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 171 finished
-----------------------------  ----------------
replay_buffer/size              34600
trainer/QF1 Loss                   17.8637
trainer/QF2 Loss                   17.8687
trainer/Policy Loss                50.1113
trainer/Q1 Predictions Mean       -48.9357
trainer/Q1 Predictions Std          8.68166
trainer/Q1 Predictions Max        -42.0132
trainer/Q1 Predictions Min       -105.715
trainer/Q2 Predictions Mean       -48.9189
trainer/Q2 Predictions Std          8.73047
trainer/Q2 Predictions Max        -41.963
trainer/Q2 Predictions Min       -105.714
trainer/Q Targets Mean            -49.0068
trainer/Q Targets Std              10.0275
trainer/Q Targets Max              -0.683028
trainer/Q Targets Min            -106.93
trainer/Log Pis Mean                2.28434
trainer/Log Pis Std                 1.19636
trainer/Log Pis Max                 6.44814
trainer/Log Pis Min                -1.25596
trainer/Policy mu Mean              0.0641795
trainer/Policy mu Std               0.83841
trainer/Policy mu Max               2.67511
trainer/Policy mu Min              -2.70351
trainer/Policy log std Mean        -1.95166
trainer/Policy log std Std          0.569244
trainer/Policy log std Max         -0.450322
trainer/Policy log std Min         -2.65016
trainer/Alpha                       0.0836956
trainer/Alpha Loss                  0.705403
exploration/num steps total     34600
exploration/num paths total       346
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.473912
exploration/Rewards Std             0.521536
exploration/Rewards Max            -0.181928
exploration/Rewards Min            -4.29322
exploration/Returns Mean          -47.3912
exploration/Returns Std             0.332285
exploration/Returns Max           -47.0589
exploration/Returns Min           -47.7234
exploration/Actions Mean            0.0225569
exploration/Actions Std             0.179676
exploration/Actions Max             0.998517
exploration/Actions Min            -0.521182
exploration/Num Paths               2
exploration/Average Returns       -47.3912
evaluation/num steps total     172000
evaluation/num paths total       1720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.723612
evaluation/Rewards Std              0.924632
evaluation/Rewards Max             -0.337916
evaluation/Rewards Min             -8.67521
evaluation/Returns Mean           -72.3612
evaluation/Returns Std             16.2643
evaluation/Returns Max            -43.132
evaluation/Returns Min            -96.5939
evaluation/Actions Mean            -8.94182e-05
evaluation/Actions Std              0.181909
evaluation/Actions Max              0.994193
evaluation/Actions Min             -0.994018
evaluation/Num Paths               10
evaluation/Average Returns        -72.3612
time/data storing (s)               0.00131942
time/evaluation sampling (s)        0.222041
time/exploration sampling (s)       0.0650703
time/logging (s)                    0.00337265
time/saving (s)                     0.00200825
time/training (s)                   0.770284
time/epoch (s)                      1.0641
time/total (s)                    183.427
Epoch                             171
-----------------------------  ----------------
2019-04-21 01:14:47.899328 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              34800
trainer/QF1 Loss                    0.248778
trainer/QF2 Loss                    0.244406
trainer/Policy Loss                49.8194
trainer/Q1 Predictions Mean       -48.8544
trainer/Q1 Predictions Std          8.64308
trainer/Q1 Predictions Max        -41.6144
trainer/Q1 Predictions Min       -111.588
trainer/Q2 Predictions Mean       -48.8289
trainer/Q2 Predictions Std          8.66503
trainer/Q2 Predictions Max        -41.6178
trainer/Q2 Predictions Min       -112.298
trainer/Q Targets Mean            -49.176
trainer/Q Targets Std               8.69036
trainer/Q Targets Max             -41.9561
trainer/Q Targets Min            -113.57
trainer/Log Pis Mean                1.84418
trainer/Log Pis Std                 1.50705
trainer/Log Pis Max                 6.28915
trainer/Log Pis Min                -4.08517
trainer/Policy mu Mean              0.0854568
trainer/Policy mu Std               0.837443
trainer/Policy mu Max               2.70308
trainer/Policy mu Min              -2.86432
trainer/Policy log std Mean        -1.88188
trainer/Policy log std Std          0.574836
trainer/Policy log std Max         -0.540006
trainer/Policy log std Min         -2.70377
trainer/Alpha                       0.0840115
trainer/Alpha Loss                 -0.385913
exploration/num steps total     34800
exploration/num paths total       348
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.522948
exploration/Rewards Std             0.469186
exploration/Rewards Max            -0.237976
exploration/Rewards Min            -4.17913
exploration/Returns Mean          -52.2948
exploration/Returns Std             0.491536
exploration/Returns Max           -51.8033
exploration/Returns Min           -52.7863
exploration/Actions Mean            0.0208199
exploration/Actions Std             0.195039
exploration/Actions Max             0.988464
exploration/Actions Min            -0.915409
exploration/Num Paths               2
exploration/Average Returns       -52.2948
evaluation/num steps total     173000
evaluation/num paths total       1730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.732893
evaluation/Rewards Std              1.0836
evaluation/Rewards Max             -0.392127
evaluation/Rewards Min             -9.29214
evaluation/Returns Mean           -73.2893
evaluation/Returns Std             20.6009
evaluation/Returns Max            -42.0205
evaluation/Returns Min            -97.9729
evaluation/Actions Mean            -0.00367226
evaluation/Actions Std              0.201684
evaluation/Actions Max              0.995205
evaluation/Actions Min             -0.994423
evaluation/Num Paths               10
evaluation/Average Returns        -73.2893
time/data storing (s)               0.00120714
time/evaluation sampling (s)        0.227927
time/exploration sampling (s)       0.0622317
time/logging (s)                    0.00336851
time/saving (s)                     0.0102643
time/training (s)                   0.774313
time/epoch (s)                      1.07931
time/total (s)                    184.51
Epoch                             172
-----------------------------  ---------------
2019-04-21 01:14:48.967457 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              35000
trainer/QF1 Loss                   42.1147
trainer/QF2 Loss                   42.1678
trainer/Policy Loss                49.5352
trainer/Q1 Predictions Mean       -48.635
trainer/Q1 Predictions Std          8.5003
trainer/Q1 Predictions Max        -40.8994
trainer/Q1 Predictions Min       -109.918
trainer/Q2 Predictions Mean       -48.6359
trainer/Q2 Predictions Std          8.44824
trainer/Q2 Predictions Max        -40.9842
trainer/Q2 Predictions Min       -109.363
trainer/Q Targets Mean            -48.563
trainer/Q Targets Std              10.7873
trainer/Q Targets Max              -1.13506
trainer/Q Targets Min            -108.2
trainer/Log Pis Mean                1.97414
trainer/Log Pis Std                 1.23494
trainer/Log Pis Max                 4.84265
trainer/Log Pis Min                -3.0551
trainer/Policy mu Mean              0.0320338
trainer/Policy mu Std               0.892501
trainer/Policy mu Max               2.81522
trainer/Policy mu Min              -2.42545
trainer/Policy log std Mean        -1.78917
trainer/Policy log std Std          0.567926
trainer/Policy log std Max         -0.305685
trainer/Policy log std Min         -2.48588
trainer/Alpha                       0.0843426
trainer/Alpha Loss                 -0.0639527
exploration/num steps total     35000
exploration/num paths total       350
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.763482
exploration/Rewards Std             0.564023
exploration/Rewards Max            -0.35126
exploration/Rewards Min            -5.54904
exploration/Returns Mean          -76.3482
exploration/Returns Std             5.43178
exploration/Returns Max           -70.9164
exploration/Returns Min           -81.78
exploration/Actions Mean           -0.00766749
exploration/Actions Std             0.201195
exploration/Actions Max             0.97334
exploration/Actions Min            -0.993122
exploration/Num Paths               2
exploration/Average Returns       -76.3482
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.758503
evaluation/Rewards Std              0.952038
evaluation/Rewards Max             -0.521318
evaluation/Rewards Min             -9.91591
evaluation/Returns Mean           -75.8503
evaluation/Returns Std             14.7268
evaluation/Returns Max            -56.1658
evaluation/Returns Min           -102.447
evaluation/Actions Mean            -0.00180696
evaluation/Actions Std              0.184464
evaluation/Actions Max              0.995058
evaluation/Actions Min             -0.984369
evaluation/Num Paths               10
evaluation/Average Returns        -75.8503
time/data storing (s)               0.00126271
time/evaluation sampling (s)        0.220347
time/exploration sampling (s)       0.0663294
time/logging (s)                    0.00339835
time/saving (s)                     0.00193158
time/training (s)                   0.767667
time/epoch (s)                      1.06094
time/total (s)                    185.575
Epoch                             173
-----------------------------  ---------------
2019-04-21 01:14:50.023653 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                   40.5284
trainer/QF2 Loss                   40.467
trainer/Policy Loss                48.9048
trainer/Q1 Predictions Mean       -47.6998
trainer/Q1 Predictions Std          8.78889
trainer/Q1 Predictions Max        -40.6864
trainer/Q1 Predictions Min       -103.26
trainer/Q2 Predictions Mean       -47.7237
trainer/Q2 Predictions Std          8.83182
trainer/Q2 Predictions Max        -40.7197
trainer/Q2 Predictions Min       -103.523
trainer/Q Targets Mean            -47.4258
trainer/Q Targets Std              10.9979
trainer/Q Targets Max              -0.710254
trainer/Q Targets Min            -104.174
trainer/Log Pis Mean                2.06542
trainer/Log Pis Std                 1.07732
trainer/Log Pis Max                 5.46202
trainer/Log Pis Min                -1.70044
trainer/Policy mu Mean             -0.031543
trainer/Policy mu Std               0.74928
trainer/Policy mu Max               2.43429
trainer/Policy mu Min              -2.9295
trainer/Policy log std Mean        -2.01633
trainer/Policy log std Std          0.514048
trainer/Policy log std Max         -0.395325
trainer/Policy log std Min         -2.628
trainer/Alpha                       0.0833136
trainer/Alpha Loss                  0.162575
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.657823
exploration/Rewards Std             0.736341
exploration/Rewards Max            -0.264394
exploration/Rewards Min            -6.53685
exploration/Returns Mean          -65.7823
exploration/Returns Std             4.76258
exploration/Returns Max           -61.0197
exploration/Returns Min           -70.5449
exploration/Actions Mean            0.00822787
exploration/Actions Std             0.205839
exploration/Actions Max             0.994093
exploration/Actions Min            -0.963756
exploration/Num Paths               2
exploration/Average Returns       -65.7823
evaluation/num steps total     175000
evaluation/num paths total       1750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.699647
evaluation/Rewards Std              0.846744
evaluation/Rewards Max             -0.471897
evaluation/Rewards Min            -10.309
evaluation/Returns Mean           -69.9647
evaluation/Returns Std             16.4161
evaluation/Returns Max            -50.3823
evaluation/Returns Min           -102.69
evaluation/Actions Mean             0.00420104
evaluation/Actions Std              0.17828
evaluation/Actions Max              0.994083
evaluation/Actions Min             -0.987164
evaluation/Num Paths               10
evaluation/Average Returns        -69.9647
time/data storing (s)               0.00124775
time/evaluation sampling (s)        0.219453
time/exploration sampling (s)       0.0650317
time/logging (s)                    0.00342212
time/saving (s)                     0.00207692
time/training (s)                   0.757739
time/epoch (s)                      1.04897
time/total (s)                    186.629
Epoch                             174
-----------------------------  ---------------
2019-04-21 01:14:51.110564 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              35400
trainer/QF1 Loss                   39.3066
trainer/QF2 Loss                   39.3161
trainer/Policy Loss                48.8834
trainer/Q1 Predictions Mean       -47.8147
trainer/Q1 Predictions Std          6.29837
trainer/Q1 Predictions Max        -40.5548
trainer/Q1 Predictions Min        -70.6811
trainer/Q2 Predictions Mean       -47.819
trainer/Q2 Predictions Std          6.30235
trainer/Q2 Predictions Max        -40.5658
trainer/Q2 Predictions Min        -70.8087
trainer/Q Targets Mean            -47.3349
trainer/Q Targets Std               9.17174
trainer/Q Targets Max              -0.394584
trainer/Q Targets Min             -71.0267
trainer/Log Pis Mean                2.01065
trainer/Log Pis Std                 1.03821
trainer/Log Pis Max                 4.83468
trainer/Log Pis Min                -1.55162
trainer/Policy mu Mean              0.0273003
trainer/Policy mu Std               0.792127
trainer/Policy mu Max               2.69353
trainer/Policy mu Min              -2.61633
trainer/Policy log std Mean        -1.94409
trainer/Policy log std Std          0.538436
trainer/Policy log std Max         -0.481629
trainer/Policy log std Min         -2.52293
trainer/Alpha                       0.0822728
trainer/Alpha Loss                  0.0265991
exploration/num steps total     35400
exploration/num paths total       354
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.941662
exploration/Rewards Std             1.00208
exploration/Rewards Max            -0.305448
exploration/Rewards Min            -8.15368
exploration/Returns Mean          -94.1662
exploration/Returns Std            10.1341
exploration/Returns Max           -84.032
exploration/Returns Min          -104.3
exploration/Actions Mean           -0.00379207
exploration/Actions Std             0.233639
exploration/Actions Max             0.991321
exploration/Actions Min            -0.99149
exploration/Num Paths               2
exploration/Average Returns       -94.1662
evaluation/num steps total     176000
evaluation/num paths total       1760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.792007
evaluation/Rewards Std              0.885777
evaluation/Rewards Max             -0.173141
evaluation/Rewards Min             -8.84522
evaluation/Returns Mean           -79.2007
evaluation/Returns Std             20.7545
evaluation/Returns Max            -41.9824
evaluation/Returns Min           -108.375
evaluation/Actions Mean            -0.0115292
evaluation/Actions Std              0.18248
evaluation/Actions Max              0.991195
evaluation/Actions Min             -0.991346
evaluation/Num Paths               10
evaluation/Average Returns        -79.2007
time/data storing (s)               0.00124054
time/evaluation sampling (s)        0.22785
time/exploration sampling (s)       0.0656801
time/logging (s)                    0.00337369
time/saving (s)                     0.00195377
time/training (s)                   0.779384
time/epoch (s)                      1.07948
time/total (s)                    187.713
Epoch                             175
-----------------------------  ---------------
2019-04-21 01:14:52.165507 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              35600
trainer/QF1 Loss                    0.403389
trainer/QF2 Loss                    0.404396
trainer/Policy Loss                48.2072
trainer/Q1 Predictions Mean       -46.9368
trainer/Q1 Predictions Std          7.45753
trainer/Q1 Predictions Max        -39.8146
trainer/Q1 Predictions Min        -79.8843
trainer/Q2 Predictions Mean       -46.9235
trainer/Q2 Predictions Std          7.41064
trainer/Q2 Predictions Max        -39.8862
trainer/Q2 Predictions Min        -79.7402
trainer/Q Targets Mean            -47.2463
trainer/Q Targets Std               7.32857
trainer/Q Targets Max             -40.3425
trainer/Q Targets Min             -81.0641
trainer/Log Pis Mean                2.11298
trainer/Log Pis Std                 1.319
trainer/Log Pis Max                 6.48124
trainer/Log Pis Min                -1.97744
trainer/Policy mu Mean              0.117666
trainer/Policy mu Std               0.872883
trainer/Policy mu Max               2.71537
trainer/Policy mu Min              -2.37251
trainer/Policy log std Mean        -1.90411
trainer/Policy log std Std          0.579808
trainer/Policy log std Max         -0.471968
trainer/Policy log std Min         -2.54794
trainer/Alpha                       0.0823152
trainer/Alpha Loss                  0.282148
exploration/num steps total     35600
exploration/num paths total       356
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.819359
exploration/Rewards Std             1.08272
exploration/Rewards Max            -0.241682
exploration/Rewards Min            -8.68245
exploration/Returns Mean          -81.9359
exploration/Returns Std             4.62478
exploration/Returns Max           -77.3112
exploration/Returns Min           -86.5607
exploration/Actions Mean            0.0313419
exploration/Actions Std             0.244631
exploration/Actions Max             0.997998
exploration/Actions Min            -0.939129
exploration/Num Paths               2
exploration/Average Returns       -81.9359
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.810011
evaluation/Rewards Std              0.951155
evaluation/Rewards Max             -0.436049
evaluation/Rewards Min             -9.52374
evaluation/Returns Mean           -81.0011
evaluation/Returns Std             13.9865
evaluation/Returns Max            -56.8337
evaluation/Returns Min           -108.827
evaluation/Actions Mean            -0.00664679
evaluation/Actions Std              0.190084
evaluation/Actions Max              0.99194
evaluation/Actions Min             -0.994532
evaluation/Num Paths               10
evaluation/Average Returns        -81.0011
time/data storing (s)               0.00119972
time/evaluation sampling (s)        0.222772
time/exploration sampling (s)       0.0653746
time/logging (s)                    0.00339399
time/saving (s)                     0.00196044
time/training (s)                   0.753004
time/epoch (s)                      1.0477
time/total (s)                    188.765
Epoch                             176
-----------------------------  ---------------
2019-04-21 01:14:53.235717 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 177 finished
-----------------------------  ----------------
replay_buffer/size              35800
trainer/QF1 Loss                   56.5638
trainer/QF2 Loss                   56.9661
trainer/Policy Loss                48.0766
trainer/Q1 Predictions Mean       -46.932
trainer/Q1 Predictions Std          9.75353
trainer/Q1 Predictions Max        -39.4362
trainer/Q1 Predictions Min       -105.989
trainer/Q2 Predictions Mean       -46.9295
trainer/Q2 Predictions Std          9.79941
trainer/Q2 Predictions Max        -39.3655
trainer/Q2 Predictions Min       -106.355
trainer/Q Targets Mean            -46.3156
trainer/Q Targets Std              11.4139
trainer/Q Targets Max              -1.00666
trainer/Q Targets Min            -106.868
trainer/Log Pis Mean                1.8153
trainer/Log Pis Std                 1.28427
trainer/Log Pis Max                 4.84846
trainer/Log Pis Min                -1.78196
trainer/Policy mu Mean              0.000305223
trainer/Policy mu Std               0.719097
trainer/Policy mu Max               3.0869
trainer/Policy mu Min              -2.87811
trainer/Policy log std Mean        -2.06731
trainer/Policy log std Std          0.518076
trainer/Policy log std Max         -0.426358
trainer/Policy log std Min         -2.74492
trainer/Alpha                       0.0842397
trainer/Alpha Loss                 -0.456967
exploration/num steps total     35800
exploration/num paths total       358
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.991846
exploration/Rewards Std             1.60287
exploration/Rewards Max            -0.157964
exploration/Rewards Min           -10.0293
exploration/Returns Mean          -99.1846
exploration/Returns Std            11.163
exploration/Returns Max           -88.0216
exploration/Returns Min          -110.348
exploration/Actions Mean            0.0207069
exploration/Actions Std             0.278174
exploration/Actions Max             0.995915
exploration/Actions Min            -0.993262
exploration/Num Paths               2
exploration/Average Returns       -99.1846
evaluation/num steps total     178000
evaluation/num paths total       1780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.761611
evaluation/Rewards Std              1.00846
evaluation/Rewards Max             -0.386663
evaluation/Rewards Min            -10.1586
evaluation/Returns Mean           -76.1611
evaluation/Returns Std             24.6066
evaluation/Returns Max            -42.7542
evaluation/Returns Min           -111.014
evaluation/Actions Mean            -0.018232
evaluation/Actions Std              0.188632
evaluation/Actions Max              0.991468
evaluation/Actions Min             -0.995024
evaluation/Num Paths               10
evaluation/Average Returns        -76.1611
time/data storing (s)               0.00128256
time/evaluation sampling (s)        0.219145
time/exploration sampling (s)       0.065198
time/logging (s)                    0.00256419
time/saving (s)                     0.00204939
time/training (s)                   0.77291
time/epoch (s)                      1.06315
time/total (s)                    189.831
Epoch                             177
-----------------------------  ----------------
2019-04-21 01:14:54.299012 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              36000
trainer/QF1 Loss                   22.568
trainer/QF2 Loss                   22.5674
trainer/Policy Loss                46.9731
trainer/Q1 Predictions Mean       -45.7628
trainer/Q1 Predictions Std          7.99333
trainer/Q1 Predictions Max        -39.0622
trainer/Q1 Predictions Min       -103.592
trainer/Q2 Predictions Mean       -45.7318
trainer/Q2 Predictions Std          7.98914
trainer/Q2 Predictions Max        -39.0554
trainer/Q2 Predictions Min       -103.647
trainer/Q Targets Mean            -45.7607
trainer/Q Targets Std               9.12472
trainer/Q Targets Max              -1.22259
trainer/Q Targets Min            -104.377
trainer/Log Pis Mean                1.79798
trainer/Log Pis Std                 1.14762
trainer/Log Pis Max                 5.42809
trainer/Log Pis Min                -2.64383
trainer/Policy mu Mean              0.0564484
trainer/Policy mu Std               0.712703
trainer/Policy mu Max               2.80187
trainer/Policy mu Min              -2.78388
trainer/Policy log std Mean        -1.99039
trainer/Policy log std Std          0.554922
trainer/Policy log std Max         -0.555185
trainer/Policy log std Min         -2.72653
trainer/Alpha                       0.0844641
trainer/Alpha Loss                 -0.499279
exploration/num steps total     36000
exploration/num paths total       360
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.856427
exploration/Rewards Std             1.37995
exploration/Rewards Max            -0.249435
exploration/Rewards Min           -11.0097
exploration/Returns Mean          -85.6427
exploration/Returns Std            11.2327
exploration/Returns Max           -74.41
exploration/Returns Min           -96.8755
exploration/Actions Mean            0.0390921
exploration/Actions Std             0.228533
exploration/Actions Max             0.999269
exploration/Actions Min            -0.837316
exploration/Num Paths               2
exploration/Average Returns       -85.6427
evaluation/num steps total     179000
evaluation/num paths total       1790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.819773
evaluation/Rewards Std              0.836375
evaluation/Rewards Max             -0.38613
evaluation/Rewards Min            -10.0577
evaluation/Returns Mean           -81.9773
evaluation/Returns Std             12.5322
evaluation/Returns Max            -51.886
evaluation/Returns Min           -100.503
evaluation/Actions Mean            -0.00363204
evaluation/Actions Std              0.182979
evaluation/Actions Max              0.995204
evaluation/Actions Min             -0.994244
evaluation/Num Paths               10
evaluation/Average Returns        -81.9773
time/data storing (s)               0.00121567
time/evaluation sampling (s)        0.221745
time/exploration sampling (s)       0.0639865
time/logging (s)                    0.00309723
time/saving (s)                     0.00197074
time/training (s)                   0.763984
time/epoch (s)                      1.056
time/total (s)                    190.892
Epoch                             178
-----------------------------  ---------------
2019-04-21 01:14:55.365264 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                   44.1806
trainer/QF2 Loss                   44.1671
trainer/Policy Loss                47.6979
trainer/Q1 Predictions Mean       -46.3491
trainer/Q1 Predictions Std          6.6071
trainer/Q1 Predictions Max        -38.5362
trainer/Q1 Predictions Min        -85.6996
trainer/Q2 Predictions Mean       -46.3586
trainer/Q2 Predictions Std          6.59455
trainer/Q2 Predictions Max        -38.5829
trainer/Q2 Predictions Min        -85.5027
trainer/Q Targets Mean            -46.0817
trainer/Q Targets Std               9.02447
trainer/Q Targets Max              -0.992513
trainer/Q Targets Min             -87.2562
trainer/Log Pis Mean                1.91161
trainer/Log Pis Std                 1.21912
trainer/Log Pis Max                 5.00414
trainer/Log Pis Min                -1.83213
trainer/Policy mu Mean              0.017997
trainer/Policy mu Std               0.684584
trainer/Policy mu Max               2.90023
trainer/Policy mu Min              -2.4333
trainer/Policy log std Mean        -2.04622
trainer/Policy log std Std          0.507861
trainer/Policy log std Max         -0.480223
trainer/Policy log std Min         -2.73945
trainer/Alpha                       0.0837255
trainer/Alpha Loss                 -0.219235
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.700549
exploration/Rewards Std             0.809365
exploration/Rewards Max            -0.193803
exploration/Rewards Min            -7.23527
exploration/Returns Mean          -70.0549
exploration/Returns Std            19.7999
exploration/Returns Max           -50.2551
exploration/Returns Min           -89.8548
exploration/Actions Mean           -0.0030824
exploration/Actions Std             0.211823
exploration/Actions Max             0.942179
exploration/Actions Min            -0.997287
exploration/Num Paths               2
exploration/Average Returns       -70.0549
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.702888
evaluation/Rewards Std              1.12978
evaluation/Rewards Max             -0.393885
evaluation/Rewards Min            -11.3132
evaluation/Returns Mean           -70.2888
evaluation/Returns Std             16.7765
evaluation/Returns Max            -41.3358
evaluation/Returns Min            -96.252
evaluation/Actions Mean             0.0174492
evaluation/Actions Std              0.202709
evaluation/Actions Max              0.996524
evaluation/Actions Min             -0.984054
evaluation/Num Paths               10
evaluation/Average Returns        -70.2888
time/data storing (s)               0.00125908
time/evaluation sampling (s)        0.223605
time/exploration sampling (s)       0.0670617
time/logging (s)                    0.00339248
time/saving (s)                     0.00196322
time/training (s)                   0.761899
time/epoch (s)                      1.05918
time/total (s)                    191.956
Epoch                             179
-----------------------------  ---------------
2019-04-21 01:14:56.440517 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 180 finished
-----------------------------  ----------------
replay_buffer/size              36400
trainer/QF1 Loss                   15.4205
trainer/QF2 Loss                   15.4588
trainer/Policy Loss                47.2352
trainer/Q1 Predictions Mean       -45.7737
trainer/Q1 Predictions Std          8.46249
trainer/Q1 Predictions Max        -38.4067
trainer/Q1 Predictions Min        -93.1704
trainer/Q2 Predictions Mean       -45.8028
trainer/Q2 Predictions Std          8.55395
trainer/Q2 Predictions Max        -38.4236
trainer/Q2 Predictions Min        -94.3427
trainer/Q Targets Mean            -45.9638
trainer/Q Targets Std               9.6601
trainer/Q Targets Max              -1.10285
trainer/Q Targets Min             -94.6986
trainer/Log Pis Mean                1.95753
trainer/Log Pis Std                 1.34431
trainer/Log Pis Max                 6.19781
trainer/Log Pis Min                -3.34106
trainer/Policy mu Mean              0.00398645
trainer/Policy mu Std               0.74751
trainer/Policy mu Max               2.67826
trainer/Policy mu Min              -2.87664
trainer/Policy log std Mean        -2.02917
trainer/Policy log std Std          0.530767
trainer/Policy log std Max         -0.441456
trainer/Policy log std Min         -2.70216
trainer/Alpha                       0.084685
trainer/Alpha Loss                 -0.104841
exploration/num steps total     36400
exploration/num paths total       364
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.552906
exploration/Rewards Std             0.320275
exploration/Rewards Max            -0.227101
exploration/Rewards Min            -3.0487
exploration/Returns Mean          -55.2906
exploration/Returns Std             0.302273
exploration/Returns Max           -54.9883
exploration/Returns Min           -55.5929
exploration/Actions Mean           -0.000227437
exploration/Actions Std             0.17328
exploration/Actions Max             0.939313
exploration/Actions Min            -0.985319
exploration/Num Paths               2
exploration/Average Returns       -55.2906
evaluation/num steps total     181000
evaluation/num paths total       1810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.717244
evaluation/Rewards Std              1.00388
evaluation/Rewards Max             -0.466985
evaluation/Rewards Min            -10.7485
evaluation/Returns Mean           -71.7244
evaluation/Returns Std             17.0935
evaluation/Returns Max            -50.6543
evaluation/Returns Min           -102.436
evaluation/Actions Mean             0.0176039
evaluation/Actions Std              0.193457
evaluation/Actions Max              0.995305
evaluation/Actions Min             -0.989401
evaluation/Num Paths               10
evaluation/Average Returns        -71.7244
time/data storing (s)               0.00124571
time/evaluation sampling (s)        0.229338
time/exploration sampling (s)       0.0724764
time/logging (s)                    0.00339167
time/saving (s)                     0.00195403
time/training (s)                   0.759549
time/epoch (s)                      1.06795
time/total (s)                    193.028
Epoch                             180
-----------------------------  ----------------
2019-04-21 01:14:57.500481 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              36600
trainer/QF1 Loss                    0.315238
trainer/QF2 Loss                    0.340138
trainer/Policy Loss                46.8123
trainer/Q1 Predictions Mean       -45.4314
trainer/Q1 Predictions Std          7.71945
trainer/Q1 Predictions Max        -38.1973
trainer/Q1 Predictions Min        -85.6721
trainer/Q2 Predictions Mean       -45.4684
trainer/Q2 Predictions Std          7.81978
trainer/Q2 Predictions Max        -38.1945
trainer/Q2 Predictions Min        -86.6052
trainer/Q Targets Mean            -45.8755
trainer/Q Targets Std               7.52757
trainer/Q Targets Max             -38.4808
trainer/Q Targets Min             -84.7005
trainer/Log Pis Mean                2.04341
trainer/Log Pis Std                 1.22518
trainer/Log Pis Max                 5.81029
trainer/Log Pis Min                -2.17019
trainer/Policy mu Mean              0.0147922
trainer/Policy mu Std               0.709831
trainer/Policy mu Max               2.74595
trainer/Policy mu Min              -2.56704
trainer/Policy log std Mean        -2.00809
trainer/Policy log std Std          0.539501
trainer/Policy log std Max         -0.426324
trainer/Policy log std Min         -2.68172
trainer/Alpha                       0.0848316
trainer/Alpha Loss                  0.107104
exploration/num steps total     36600
exploration/num paths total       366
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.653322
exploration/Rewards Std             0.602104
exploration/Rewards Max            -0.242497
exploration/Rewards Min            -5.94314
exploration/Returns Mean          -65.3322
exploration/Returns Std             4.47881
exploration/Returns Max           -60.8534
exploration/Returns Min           -69.811
exploration/Actions Mean           -0.00981861
exploration/Actions Std             0.206378
exploration/Actions Max             0.995583
exploration/Actions Min            -0.97162
exploration/Num Paths               2
exploration/Average Returns       -65.3322
evaluation/num steps total     182000
evaluation/num paths total       1820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.777685
evaluation/Rewards Std              1.21222
evaluation/Rewards Max             -0.409124
evaluation/Rewards Min            -10.8928
evaluation/Returns Mean           -77.7685
evaluation/Returns Std             21.4966
evaluation/Returns Max            -48.4237
evaluation/Returns Min           -108.103
evaluation/Actions Mean             0.00586385
evaluation/Actions Std              0.204892
evaluation/Actions Max              0.997055
evaluation/Actions Min             -0.996366
evaluation/Num Paths               10
evaluation/Average Returns        -77.7685
time/data storing (s)               0.00127122
time/evaluation sampling (s)        0.225869
time/exploration sampling (s)       0.0664726
time/logging (s)                    0.00252947
time/saving (s)                     0.00199934
time/training (s)                   0.753508
time/epoch (s)                      1.05165
time/total (s)                    194.084
Epoch                             181
-----------------------------  ---------------
2019-04-21 01:14:58.571165 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              36800
trainer/QF1 Loss                   21.9931
trainer/QF2 Loss                   22.0372
trainer/Policy Loss                46.3658
trainer/Q1 Predictions Mean       -44.9517
trainer/Q1 Predictions Std          5.81515
trainer/Q1 Predictions Max        -37.6271
trainer/Q1 Predictions Min        -66.9862
trainer/Q2 Predictions Mean       -44.9611
trainer/Q2 Predictions Std          5.82447
trainer/Q2 Predictions Max        -37.6524
trainer/Q2 Predictions Min        -66.7643
trainer/Q Targets Mean            -44.81
trainer/Q Targets Std               7.19625
trainer/Q Targets Max              -1.00225
trainer/Q Targets Min             -67.9999
trainer/Log Pis Mean                2.02252
trainer/Log Pis Std                 1.09942
trainer/Log Pis Max                 4.87066
trainer/Log Pis Min                -1.64422
trainer/Policy mu Mean              0.0554629
trainer/Policy mu Std               0.704003
trainer/Policy mu Max               2.61169
trainer/Policy mu Min              -2.43937
trainer/Policy log std Mean        -2.05144
trainer/Policy log std Std          0.533194
trainer/Policy log std Max         -0.511498
trainer/Policy log std Min         -2.76885
trainer/Alpha                       0.0873963
trainer/Alpha Loss                  0.0548884
exploration/num steps total     36800
exploration/num paths total       368
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.552944
exploration/Rewards Std             0.271349
exploration/Rewards Max            -0.230273
exploration/Rewards Min            -3.13893
exploration/Returns Mean          -55.2944
exploration/Returns Std            10.7311
exploration/Returns Max           -44.5633
exploration/Returns Min           -66.0255
exploration/Actions Mean           -0.00683782
exploration/Actions Std             0.155426
exploration/Actions Max             0.898963
exploration/Actions Min            -0.981953
exploration/Num Paths               2
exploration/Average Returns       -55.2944
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.622696
evaluation/Rewards Std              0.648381
evaluation/Rewards Max             -0.110248
evaluation/Rewards Min             -7.87723
evaluation/Returns Mean           -62.2696
evaluation/Returns Std             13.725
evaluation/Returns Max            -44.8428
evaluation/Returns Min            -88.7291
evaluation/Actions Mean            -0.00521515
evaluation/Actions Std              0.151054
evaluation/Actions Max              0.992676
evaluation/Actions Min             -0.986954
evaluation/Num Paths               10
evaluation/Average Returns        -62.2696
time/data storing (s)               0.0013642
time/evaluation sampling (s)        0.226356
time/exploration sampling (s)       0.0673205
time/logging (s)                    0.00338748
time/saving (s)                     0.00201024
time/training (s)                   0.764649
time/epoch (s)                      1.06509
time/total (s)                    195.154
Epoch                             182
-----------------------------  ---------------
2019-04-21 01:14:59.642353 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              37000
trainer/QF1 Loss                   21.9092
trainer/QF2 Loss                   21.943
trainer/Policy Loss                47.4687
trainer/Q1 Predictions Mean       -46.2765
trainer/Q1 Predictions Std          8.19022
trainer/Q1 Predictions Max        -37.5438
trainer/Q1 Predictions Min        -95.5879
trainer/Q2 Predictions Mean       -46.2674
trainer/Q2 Predictions Std          8.16037
trainer/Q2 Predictions Max        -37.5273
trainer/Q2 Predictions Min        -95.3251
trainer/Q Targets Mean            -45.9964
trainer/Q Targets Std               9.32173
trainer/Q Targets Max              -0.563264
trainer/Q Targets Min             -95.0646
trainer/Log Pis Mean                2.15114
trainer/Log Pis Std                 1.05603
trainer/Log Pis Max                 5.75526
trainer/Log Pis Min                -0.571378
trainer/Policy mu Mean             -0.0588951
trainer/Policy mu Std               0.798209
trainer/Policy mu Max               2.60884
trainer/Policy mu Min              -3.03938
trainer/Policy log std Mean        -2.00328
trainer/Policy log std Std          0.557697
trainer/Policy log std Max         -0.488603
trainer/Policy log std Min         -2.69684
trainer/Alpha                       0.089538
trainer/Alpha Loss                  0.364746
exploration/num steps total     37000
exploration/num paths total       370
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.618133
exploration/Rewards Std             0.191558
exploration/Rewards Max            -0.322924
exploration/Rewards Min            -2.59312
exploration/Returns Mean          -61.8133
exploration/Returns Std             0.994438
exploration/Returns Max           -60.8188
exploration/Returns Min           -62.8077
exploration/Actions Mean           -0.0100558
exploration/Actions Std             0.149064
exploration/Actions Max             0.663801
exploration/Actions Min            -0.947311
exploration/Num Paths               2
exploration/Average Returns       -61.8133
evaluation/num steps total     184000
evaluation/num paths total       1840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.54398
evaluation/Rewards Std              0.533628
evaluation/Rewards Max             -0.414633
evaluation/Rewards Min             -6.35369
evaluation/Returns Mean           -54.398
evaluation/Returns Std             11.6273
evaluation/Returns Max            -43.5162
evaluation/Returns Min            -78.5939
evaluation/Actions Mean             0.00373075
evaluation/Actions Std              0.145256
evaluation/Actions Max              0.985665
evaluation/Actions Min             -0.989749
evaluation/Num Paths               10
evaluation/Average Returns        -54.398
time/data storing (s)               0.0011799
time/evaluation sampling (s)        0.218485
time/exploration sampling (s)       0.0635515
time/logging (s)                    0.00309261
time/saving (s)                     0.0019631
time/training (s)                   0.775247
time/epoch (s)                      1.06352
time/total (s)                    196.221
Epoch                             183
-----------------------------  ---------------
2019-04-21 01:15:00.701484 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    1.13523
trainer/QF2 Loss                    1.14637
trainer/Policy Loss                47.3284
trainer/Q1 Predictions Mean       -46.2306
trainer/Q1 Predictions Std         11.719
trainer/Q1 Predictions Max        -36.7955
trainer/Q1 Predictions Min       -109.046
trainer/Q2 Predictions Mean       -46.2418
trainer/Q2 Predictions Std         11.7404
trainer/Q2 Predictions Max        -36.751
trainer/Q2 Predictions Min       -109
trainer/Q Targets Mean            -47.0814
trainer/Q Targets Std              12.1359
trainer/Q Targets Max             -37.5099
trainer/Q Targets Min            -111.152
trainer/Log Pis Mean                2.13231
trainer/Log Pis Std                 1.32924
trainer/Log Pis Max                 6.82662
trainer/Log Pis Min                -1.10263
trainer/Policy mu Mean              0.0519461
trainer/Policy mu Std               0.933306
trainer/Policy mu Max               2.93709
trainer/Policy mu Min              -3.19326
trainer/Policy log std Mean        -1.87965
trainer/Policy log std Std          0.632305
trainer/Policy log std Max         -0.422717
trainer/Policy log std Min         -2.7048
trainer/Alpha                       0.091826
trainer/Alpha Loss                  0.315934
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.575489
exploration/Rewards Std             0.315027
exploration/Rewards Max            -0.284793
exploration/Rewards Min            -3.5549
exploration/Returns Mean          -57.5489
exploration/Returns Std             6.90929
exploration/Returns Max           -50.6396
exploration/Returns Min           -64.4582
exploration/Actions Mean            0.00269237
exploration/Actions Std             0.172313
exploration/Actions Max             0.838962
exploration/Actions Min            -0.978662
exploration/Num Paths               2
exploration/Average Returns       -57.5489
evaluation/num steps total     185000
evaluation/num paths total       1850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.776095
evaluation/Rewards Std              1.15555
evaluation/Rewards Max             -0.235436
evaluation/Rewards Min            -10.0468
evaluation/Returns Mean           -77.6095
evaluation/Returns Std             19.9229
evaluation/Returns Max            -49.4929
evaluation/Returns Min           -107.464
evaluation/Actions Mean            -0.0180347
evaluation/Actions Std              0.19321
evaluation/Actions Max              0.991809
evaluation/Actions Min             -0.996081
evaluation/Num Paths               10
evaluation/Average Returns        -77.6095
time/data storing (s)               0.00132773
time/evaluation sampling (s)        0.226861
time/exploration sampling (s)       0.0622228
time/logging (s)                    0.00252328
time/saving (s)                     0.00166691
time/training (s)                   0.758049
time/epoch (s)                      1.05265
time/total (s)                    197.277
Epoch                             184
-----------------------------  ---------------
2019-04-21 01:15:01.782303 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              37400
trainer/QF1 Loss                   13.6353
trainer/QF2 Loss                   13.6378
trainer/Policy Loss                45.8184
trainer/Q1 Predictions Mean       -44.8504
trainer/Q1 Predictions Std         10.6844
trainer/Q1 Predictions Max        -36.5775
trainer/Q1 Predictions Min       -100.515
trainer/Q2 Predictions Mean       -44.8573
trainer/Q2 Predictions Std         10.7062
trainer/Q2 Predictions Max        -36.5921
trainer/Q2 Predictions Min       -100.959
trainer/Q Targets Mean            -44.9763
trainer/Q Targets Std              11.482
trainer/Q Targets Max              -0.397508
trainer/Q Targets Min            -100.527
trainer/Log Pis Mean                2.00177
trainer/Log Pis Std                 1.18501
trainer/Log Pis Max                 6.32898
trainer/Log Pis Min                -2.88188
trainer/Policy mu Mean              0.127587
trainer/Policy mu Std               0.801759
trainer/Policy mu Max               2.89409
trainer/Policy mu Min              -2.81956
trainer/Policy log std Mean        -1.93304
trainer/Policy log std Std          0.59393
trainer/Policy log std Max         -0.485789
trainer/Policy log std Min         -2.66239
trainer/Alpha                       0.0916439
trainer/Alpha Loss                  0.00422522
exploration/num steps total     37400
exploration/num paths total       374
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.868984
exploration/Rewards Std             1.32639
exploration/Rewards Max            -0.211815
exploration/Rewards Min            -9.85049
exploration/Returns Mean          -86.8984
exploration/Returns Std            28.5843
exploration/Returns Max           -58.314
exploration/Returns Min          -115.483
exploration/Actions Mean           -0.0212564
exploration/Actions Std             0.246623
exploration/Actions Max             0.957899
exploration/Actions Min            -0.995574
exploration/Num Paths               2
exploration/Average Returns       -86.8984
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.633722
evaluation/Rewards Std              0.639783
evaluation/Rewards Max             -0.323276
evaluation/Rewards Min             -8.06039
evaluation/Returns Mean           -63.3722
evaluation/Returns Std             12.3808
evaluation/Returns Max            -41.5362
evaluation/Returns Min            -79.1546
evaluation/Actions Mean             0.0231736
evaluation/Actions Std              0.158274
evaluation/Actions Max              0.991479
evaluation/Actions Min             -0.792053
evaluation/Num Paths               10
evaluation/Average Returns        -63.3722
time/data storing (s)               0.00132971
time/evaluation sampling (s)        0.226086
time/exploration sampling (s)       0.0680316
time/logging (s)                    0.00345874
time/saving (s)                     0.0019418
time/training (s)                   0.775226
time/epoch (s)                      1.07607
time/total (s)                    198.357
Epoch                             185
-----------------------------  ---------------
2019-04-21 01:15:02.856297 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              37600
trainer/QF1 Loss                   21.2708
trainer/QF2 Loss                   21.3315
trainer/Policy Loss                46.5595
trainer/Q1 Predictions Mean       -45.0463
trainer/Q1 Predictions Std          7.81569
trainer/Q1 Predictions Max        -36.8582
trainer/Q1 Predictions Min        -82.2809
trainer/Q2 Predictions Mean       -45.0354
trainer/Q2 Predictions Std          7.77125
trainer/Q2 Predictions Max        -36.8589
trainer/Q2 Predictions Min        -81.6736
trainer/Q Targets Mean            -44.6757
trainer/Q Targets Std               8.83919
trainer/Q Targets Max              -0.961966
trainer/Q Targets Min             -79.2251
trainer/Log Pis Mean                2.35756
trainer/Log Pis Std                 1.25398
trainer/Log Pis Max                 6.92831
trainer/Log Pis Min                -1.22988
trainer/Policy mu Mean              0.173479
trainer/Policy mu Std               0.909623
trainer/Policy mu Max               2.73196
trainer/Policy mu Min              -2.55287
trainer/Policy log std Mean        -1.94956
trainer/Policy log std Std          0.623498
trainer/Policy log std Max         -0.4453
trainer/Policy log std Min         -2.74676
trainer/Alpha                       0.0920155
trainer/Alpha Loss                  0.853154
exploration/num steps total     37600
exploration/num paths total       376
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.91253
exploration/Rewards Std             1.03424
exploration/Rewards Max            -0.412593
exploration/Rewards Min            -8.70172
exploration/Returns Mean          -91.253
exploration/Returns Std             8.27759
exploration/Returns Max           -82.9754
exploration/Returns Min           -99.5306
exploration/Actions Mean           -0.0254415
exploration/Actions Std             0.245849
exploration/Actions Max             0.98716
exploration/Actions Min            -0.995409
exploration/Num Paths               2
exploration/Average Returns       -91.253
evaluation/num steps total     187000
evaluation/num paths total       1870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.755983
evaluation/Rewards Std              1.05522
evaluation/Rewards Max             -0.368999
evaluation/Rewards Min            -10.513
evaluation/Returns Mean           -75.5983
evaluation/Returns Std             23.5076
evaluation/Returns Max            -38.7236
evaluation/Returns Min           -114.716
evaluation/Actions Mean            -0.00877507
evaluation/Actions Std              0.192324
evaluation/Actions Max              0.99371
evaluation/Actions Min             -0.997452
evaluation/Num Paths               10
evaluation/Average Returns        -75.5983
time/data storing (s)               0.00139468
time/evaluation sampling (s)        0.225773
time/exploration sampling (s)       0.0666626
time/logging (s)                    0.00335004
time/saving (s)                     0.00195581
time/training (s)                   0.767373
time/epoch (s)                      1.06651
time/total (s)                    199.428
Epoch                             186
-----------------------------  ---------------
2019-04-21 01:15:03.914131 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              37800
trainer/QF1 Loss                    0.46936
trainer/QF2 Loss                    0.40213
trainer/Policy Loss                45.6606
trainer/Q1 Predictions Mean       -44.5931
trainer/Q1 Predictions Std          9.7133
trainer/Q1 Predictions Max        -36.0732
trainer/Q1 Predictions Min        -95.1077
trainer/Q2 Predictions Mean       -44.5939
trainer/Q2 Predictions Std          9.69919
trainer/Q2 Predictions Max        -36.1065
trainer/Q2 Predictions Min        -95.3456
trainer/Q Targets Mean            -45.0477
trainer/Q Targets Std               9.63771
trainer/Q Targets Max             -36.6102
trainer/Q Targets Min             -94.6955
trainer/Log Pis Mean                2.22197
trainer/Log Pis Std                 1.24544
trainer/Log Pis Max                 7.12122
trainer/Log Pis Min                -0.984269
trainer/Policy mu Mean              0.128522
trainer/Policy mu Std               0.847853
trainer/Policy mu Max               2.79296
trainer/Policy mu Min              -2.87455
trainer/Policy log std Mean        -1.90208
trainer/Policy log std Std          0.560959
trainer/Policy log std Max         -0.404502
trainer/Policy log std Min         -2.62725
trainer/Alpha                       0.092965
trainer/Alpha Loss                  0.527318
exploration/num steps total     37800
exploration/num paths total       378
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.663684
exploration/Rewards Std             1.04324
exploration/Rewards Max            -0.195217
exploration/Rewards Min            -7.08631
exploration/Returns Mean          -66.3684
exploration/Returns Std             2.35879
exploration/Returns Max           -64.0097
exploration/Returns Min           -68.7272
exploration/Actions Mean            0.0249346
exploration/Actions Std             0.222533
exploration/Actions Max             0.998294
exploration/Actions Min            -0.836041
exploration/Num Paths               2
exploration/Average Returns       -66.3684
evaluation/num steps total     188000
evaluation/num paths total       1880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.630847
evaluation/Rewards Std              0.856157
evaluation/Rewards Max             -0.307927
evaluation/Rewards Min            -10.2417
evaluation/Returns Mean           -63.0847
evaluation/Returns Std             22.8726
evaluation/Returns Max            -34.8428
evaluation/Returns Min           -111.921
evaluation/Actions Mean            -0.0126726
evaluation/Actions Std              0.167267
evaluation/Actions Max              0.988413
evaluation/Actions Min             -0.995046
evaluation/Num Paths               10
evaluation/Average Returns        -63.0847
time/data storing (s)               0.00137057
time/evaluation sampling (s)        0.221379
time/exploration sampling (s)       0.0644331
time/logging (s)                    0.00343615
time/saving (s)                     0.00195677
time/training (s)                   0.757961
time/epoch (s)                      1.05054
time/total (s)                    200.483
Epoch                             187
-----------------------------  ---------------
2019-04-21 01:15:04.980779 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 188 finished
-----------------------------  ----------------
replay_buffer/size              38000
trainer/QF1 Loss                   21.7092
trainer/QF2 Loss                   21.6451
trainer/Policy Loss                46.6178
trainer/Q1 Predictions Mean       -45.6221
trainer/Q1 Predictions Std          9.88754
trainer/Q1 Predictions Max        -35.7861
trainer/Q1 Predictions Min       -119.97
trainer/Q2 Predictions Mean       -45.6515
trainer/Q2 Predictions Std          9.88285
trainer/Q2 Predictions Max        -35.7389
trainer/Q2 Predictions Min       -119.668
trainer/Q Targets Mean            -45.4414
trainer/Q Targets Std              10.3962
trainer/Q Targets Max              -1.9802
trainer/Q Targets Min            -115.55
trainer/Log Pis Mean                2.02858
trainer/Log Pis Std                 1.25217
trainer/Log Pis Max                 5.34163
trainer/Log Pis Min                -2.41003
trainer/Policy mu Mean             -0.0274214
trainer/Policy mu Std               0.845198
trainer/Policy mu Max               2.63237
trainer/Policy mu Min              -3.11612
trainer/Policy log std Mean        -1.89979
trainer/Policy log std Std          0.587643
trainer/Policy log std Max         -0.486208
trainer/Policy log std Min         -2.71706
trainer/Alpha                       0.0919639
trainer/Alpha Loss                  0.0681927
exploration/num steps total     38000
exploration/num paths total       380
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.685498
exploration/Rewards Std             0.79299
exploration/Rewards Max            -0.118486
exploration/Rewards Min            -6.57072
exploration/Returns Mean          -68.5498
exploration/Returns Std            14.6287
exploration/Returns Max           -53.921
exploration/Returns Min           -83.1785
exploration/Actions Mean            0.000169763
exploration/Actions Std             0.22164
exploration/Actions Max             0.997442
exploration/Actions Min            -0.994378
exploration/Num Paths               2
exploration/Average Returns       -68.5498
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.615203
evaluation/Rewards Std              0.61973
evaluation/Rewards Max             -0.371329
evaluation/Rewards Min             -7.31144
evaluation/Returns Mean           -61.5203
evaluation/Returns Std             14.9124
evaluation/Returns Max            -37.4176
evaluation/Returns Min            -81.1723
evaluation/Actions Mean             0.00170205
evaluation/Actions Std              0.156469
evaluation/Actions Max              0.990054
evaluation/Actions Min             -0.995426
evaluation/Num Paths               10
evaluation/Average Returns        -61.5203
time/data storing (s)               0.00127265
time/evaluation sampling (s)        0.219248
time/exploration sampling (s)       0.0630113
time/logging (s)                    0.00338047
time/saving (s)                     0.00194451
time/training (s)                   0.77064
time/epoch (s)                      1.0595
time/total (s)                    201.546
Epoch                             188
-----------------------------  ----------------
2019-04-21 01:15:06.049130 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                   33.0311
trainer/QF2 Loss                   33.0903
trainer/Policy Loss                43.123
trainer/Q1 Predictions Mean       -41.8744
trainer/Q1 Predictions Std          6.78322
trainer/Q1 Predictions Max        -35.4744
trainer/Q1 Predictions Min        -80.3046
trainer/Q2 Predictions Mean       -41.8687
trainer/Q2 Predictions Std          6.79447
trainer/Q2 Predictions Max        -35.4795
trainer/Q2 Predictions Min        -80.4875
trainer/Q Targets Mean            -41.7675
trainer/Q Targets Std               8.98539
trainer/Q Targets Max              -0.463993
trainer/Q Targets Min             -79.8506
trainer/Log Pis Mean                1.95436
trainer/Log Pis Std                 1.28862
trainer/Log Pis Max                 4.81599
trainer/Log Pis Min                -3.37487
trainer/Policy mu Mean              0.0253033
trainer/Policy mu Std               0.647111
trainer/Policy mu Max               2.56931
trainer/Policy mu Min              -2.69866
trainer/Policy log std Mean        -2.12151
trainer/Policy log std Std          0.499043
trainer/Policy log std Max         -0.498066
trainer/Policy log std Min         -2.7093
trainer/Alpha                       0.0914691
trainer/Alpha Loss                 -0.109172
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.502851
exploration/Rewards Std             0.477033
exploration/Rewards Max            -0.228406
exploration/Rewards Min            -4.09547
exploration/Returns Mean          -50.2851
exploration/Returns Std             1.59509
exploration/Returns Max           -48.69
exploration/Returns Min           -51.8802
exploration/Actions Mean            0.00590216
exploration/Actions Std             0.183474
exploration/Actions Max             0.997788
exploration/Actions Min            -0.970628
exploration/Num Paths               2
exploration/Average Returns       -50.2851
evaluation/num steps total     190000
evaluation/num paths total       1900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.571291
evaluation/Rewards Std              0.615773
evaluation/Rewards Max             -0.37577
evaluation/Rewards Min             -7.90629
evaluation/Returns Mean           -57.1291
evaluation/Returns Std              8.63883
evaluation/Returns Max            -44.7808
evaluation/Returns Min            -70.6164
evaluation/Actions Mean             0.00147837
evaluation/Actions Std              0.156319
evaluation/Actions Max              0.993088
evaluation/Actions Min             -0.986965
evaluation/Num Paths               10
evaluation/Average Returns        -57.1291
time/data storing (s)               0.00129435
time/evaluation sampling (s)        0.221476
time/exploration sampling (s)       0.0682832
time/logging (s)                    0.00335016
time/saving (s)                     0.00739914
time/training (s)                   0.759294
time/epoch (s)                      1.0611
time/total (s)                    202.611
Epoch                             189
-----------------------------  ---------------
2019-04-21 01:15:07.095532 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              38400
trainer/QF1 Loss                    0.364241
trainer/QF2 Loss                    0.318042
trainer/Policy Loss                44.417
trainer/Q1 Predictions Mean       -42.7197
trainer/Q1 Predictions Std          5.96724
trainer/Q1 Predictions Max        -35.1603
trainer/Q1 Predictions Min        -65.7509
trainer/Q2 Predictions Mean       -42.727
trainer/Q2 Predictions Std          5.96928
trainer/Q2 Predictions Max        -35.2155
trainer/Q2 Predictions Min        -65.8004
trainer/Q Targets Mean            -43.1951
trainer/Q Targets Std               5.81689
trainer/Q Targets Max             -35.7312
trainer/Q Targets Min             -65.4193
trainer/Log Pis Mean                2.17976
trainer/Log Pis Std                 1.14302
trainer/Log Pis Max                 6.37338
trainer/Log Pis Min                -3.36355
trainer/Policy mu Mean              0.105055
trainer/Policy mu Std               0.788852
trainer/Policy mu Max               2.68403
trainer/Policy mu Min              -2.17494
trainer/Policy log std Mean        -1.94826
trainer/Policy log std Std          0.570875
trainer/Policy log std Max         -0.518452
trainer/Policy log std Min         -2.61576
trainer/Alpha                       0.093264
trainer/Alpha Loss                  0.426456
exploration/num steps total     38400
exploration/num paths total       384
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.687216
exploration/Rewards Std             1.40853
exploration/Rewards Max            -0.111361
exploration/Rewards Min           -10.3052
exploration/Returns Mean          -68.7216
exploration/Returns Std            22.986
exploration/Returns Max           -45.7356
exploration/Returns Min           -91.7076
exploration/Actions Mean            0.0423017
exploration/Actions Std             0.231845
exploration/Actions Max             0.997334
exploration/Actions Min            -0.51673
exploration/Num Paths               2
exploration/Average Returns       -68.7216
evaluation/num steps total     191000
evaluation/num paths total       1910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.611659
evaluation/Rewards Std              0.653758
evaluation/Rewards Max             -0.312469
evaluation/Rewards Min             -7.14018
evaluation/Returns Mean           -61.1659
evaluation/Returns Std             17.3834
evaluation/Returns Max            -35.281
evaluation/Returns Min            -85.7129
evaluation/Actions Mean             0.00374757
evaluation/Actions Std              0.167667
evaluation/Actions Max              0.990295
evaluation/Actions Min             -0.989217
evaluation/Num Paths               10
evaluation/Average Returns        -61.1659
time/data storing (s)               0.00122416
time/evaluation sampling (s)        0.222817
time/exploration sampling (s)       0.0657723
time/logging (s)                    0.00337934
time/saving (s)                     0.00710325
time/training (s)                   0.739034
time/epoch (s)                      1.03933
time/total (s)                    203.655
Epoch                             190
-----------------------------  ---------------
2019-04-21 01:15:08.157435 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              38600
trainer/QF1 Loss                    0.380813
trainer/QF2 Loss                    0.411023
trainer/Policy Loss                44.8488
trainer/Q1 Predictions Mean       -43.533
trainer/Q1 Predictions Std          8.81895
trainer/Q1 Predictions Max        -35.5485
trainer/Q1 Predictions Min        -83.6094
trainer/Q2 Predictions Mean       -43.4886
trainer/Q2 Predictions Std          8.72123
trainer/Q2 Predictions Max        -35.5981
trainer/Q2 Predictions Min        -83.2602
trainer/Q Targets Mean            -43.9073
trainer/Q Targets Std               8.95962
trainer/Q Targets Max             -35.476
trainer/Q Targets Min             -84.666
trainer/Log Pis Mean                1.98614
trainer/Log Pis Std                 1.1487
trainer/Log Pis Max                 6.16318
trainer/Log Pis Min                -2.18889
trainer/Policy mu Mean              0.0364265
trainer/Policy mu Std               0.779045
trainer/Policy mu Max               2.87871
trainer/Policy mu Min              -2.40629
trainer/Policy log std Mean        -1.95207
trainer/Policy log std Std          0.567315
trainer/Policy log std Max         -0.419571
trainer/Policy log std Min         -2.66167
trainer/Alpha                       0.0916993
trainer/Alpha Loss                 -0.0331081
exploration/num steps total     38600
exploration/num paths total       386
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.971952
exploration/Rewards Std             1.30797
exploration/Rewards Max            -0.453491
exploration/Rewards Min           -10.73
exploration/Returns Mean          -97.1952
exploration/Returns Std            26.9807
exploration/Returns Max           -70.2145
exploration/Returns Min          -124.176
exploration/Actions Mean           -0.0330791
exploration/Actions Std             0.236231
exploration/Actions Max             0.736058
exploration/Actions Min            -0.999023
exploration/Num Paths               2
exploration/Average Returns       -97.1952
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.743287
evaluation/Rewards Std              0.981473
evaluation/Rewards Max             -0.353813
evaluation/Rewards Min            -10.8896
evaluation/Returns Mean           -74.3287
evaluation/Returns Std             10.9813
evaluation/Returns Max            -48.3016
evaluation/Returns Min            -92.8233
evaluation/Actions Mean             0.0151592
evaluation/Actions Std              0.181239
evaluation/Actions Max              0.997249
evaluation/Actions Min             -0.984933
evaluation/Num Paths               10
evaluation/Average Returns        -74.3287
time/data storing (s)               0.00124584
time/evaluation sampling (s)        0.224594
time/exploration sampling (s)       0.0658331
time/logging (s)                    0.00256541
time/saving (s)                     0.00157061
time/training (s)                   0.758074
time/epoch (s)                      1.05388
time/total (s)                    204.712
Epoch                             191
-----------------------------  ---------------
2019-04-21 01:15:09.235387 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              38800
trainer/QF1 Loss                   25.124
trainer/QF2 Loss                   25.15
trainer/Policy Loss                42.6899
trainer/Q1 Predictions Mean       -41.2824
trainer/Q1 Predictions Std          5.90101
trainer/Q1 Predictions Max        -35.2735
trainer/Q1 Predictions Min        -73.0292
trainer/Q2 Predictions Mean       -41.2799
trainer/Q2 Predictions Std          5.89888
trainer/Q2 Predictions Max        -35.2814
trainer/Q2 Predictions Min        -72.9069
trainer/Q Targets Mean            -41.0263
trainer/Q Targets Std               8.35939
trainer/Q Targets Max              -0.20377
trainer/Q Targets Min             -72.1963
trainer/Log Pis Mean                1.90139
trainer/Log Pis Std                 1.0228
trainer/Log Pis Max                 4.91521
trainer/Log Pis Min                -1.54351
trainer/Policy mu Mean             -0.00963959
trainer/Policy mu Std               0.706349
trainer/Policy mu Max               2.50535
trainer/Policy mu Min              -2.76674
trainer/Policy log std Mean        -1.9654
trainer/Policy log std Std          0.523716
trainer/Policy log std Max         -0.45017
trainer/Policy log std Min         -2.57636
trainer/Alpha                       0.0904176
trainer/Alpha Loss                 -0.236978
exploration/num steps total     38800
exploration/num paths total       388
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.444636
exploration/Rewards Std             0.289788
exploration/Rewards Max            -0.158539
exploration/Rewards Min            -3.12326
exploration/Returns Mean          -44.4636
exploration/Returns Std             1.23698
exploration/Returns Max           -43.2266
exploration/Returns Min           -45.7006
exploration/Actions Mean            0.00527998
exploration/Actions Std             0.153424
exploration/Actions Max             0.869542
exploration/Actions Min            -0.932089
exploration/Num Paths               2
exploration/Average Returns       -44.4636
evaluation/num steps total     193000
evaluation/num paths total       1930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.698655
evaluation/Rewards Std              1.08982
evaluation/Rewards Max             -0.103909
evaluation/Rewards Min            -10.7251
evaluation/Returns Mean           -69.8655
evaluation/Returns Std             18.6316
evaluation/Returns Max            -39.8504
evaluation/Returns Min           -112.262
evaluation/Actions Mean             0.0242745
evaluation/Actions Std              0.191801
evaluation/Actions Max              0.99282
evaluation/Actions Min             -0.996721
evaluation/Num Paths               10
evaluation/Average Returns        -69.8655
time/data storing (s)               0.00132456
time/evaluation sampling (s)        0.225254
time/exploration sampling (s)       0.0647287
time/logging (s)                    0.00337571
time/saving (s)                     0.00194408
time/training (s)                   0.775865
time/epoch (s)                      1.07249
time/total (s)                    205.789
Epoch                             192
-----------------------------  ---------------
2019-04-21 01:15:10.308892 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              39000
trainer/QF1 Loss                    0.238687
trainer/QF2 Loss                    0.280112
trainer/Policy Loss                43.3056
trainer/Q1 Predictions Mean       -42.3083
trainer/Q1 Predictions Std          8.61478
trainer/Q1 Predictions Max        -34.9247
trainer/Q1 Predictions Min        -98.6019
trainer/Q2 Predictions Mean       -42.3347
trainer/Q2 Predictions Std          8.73474
trainer/Q2 Predictions Max        -34.9222
trainer/Q2 Predictions Min        -99.6219
trainer/Q Targets Mean            -42.566
trainer/Q Targets Std               8.66759
trainer/Q Targets Max             -35.0681
trainer/Q Targets Min             -98.5027
trainer/Log Pis Mean                1.74095
trainer/Log Pis Std                 1.08697
trainer/Log Pis Max                 5.57833
trainer/Log Pis Min                -2.15239
trainer/Policy mu Mean             -0.0220972
trainer/Policy mu Std               0.635421
trainer/Policy mu Max               2.12584
trainer/Policy mu Min              -2.94818
trainer/Policy log std Mean        -2.06351
trainer/Policy log std Std          0.491864
trainer/Policy log std Max         -0.266026
trainer/Policy log std Min         -2.6858
trainer/Alpha                       0.0893202
trainer/Alpha Loss                 -0.62573
exploration/num steps total     39000
exploration/num paths total       390
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.613144
exploration/Rewards Std             0.587512
exploration/Rewards Max            -0.199243
exploration/Rewards Min            -5.78037
exploration/Returns Mean          -61.3144
exploration/Returns Std             2.67618
exploration/Returns Max           -58.6382
exploration/Returns Min           -63.9906
exploration/Actions Mean            0.0017218
exploration/Actions Std             0.197629
exploration/Actions Max             0.843789
exploration/Actions Min            -0.978466
exploration/Num Paths               2
exploration/Average Returns       -61.3144
evaluation/num steps total     194000
evaluation/num paths total       1940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.686007
evaluation/Rewards Std              0.904844
evaluation/Rewards Max             -0.394246
evaluation/Rewards Min             -9.62067
evaluation/Returns Mean           -68.6007
evaluation/Returns Std             17.5213
evaluation/Returns Max            -43.5094
evaluation/Returns Min            -99.8993
evaluation/Actions Mean             0.00275561
evaluation/Actions Std              0.173239
evaluation/Actions Max              0.993214
evaluation/Actions Min             -0.995447
evaluation/Num Paths               10
evaluation/Average Returns        -68.6007
time/data storing (s)               0.00123622
time/evaluation sampling (s)        0.226748
time/exploration sampling (s)       0.0655729
time/logging (s)                    0.00337642
time/saving (s)                     0.00198918
time/training (s)                   0.767373
time/epoch (s)                      1.0663
time/total (s)                    206.859
Epoch                             193
-----------------------------  ---------------
2019-04-21 01:15:11.381483 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                   98.392
trainer/QF2 Loss                   98.1918
trainer/Policy Loss                43.861
trainer/Q1 Predictions Mean       -42.7368
trainer/Q1 Predictions Std          8.37634
trainer/Q1 Predictions Max        -34.6211
trainer/Q1 Predictions Min        -85.4323
trainer/Q2 Predictions Mean       -42.7698
trainer/Q2 Predictions Std          8.46926
trainer/Q2 Predictions Max        -34.6427
trainer/Q2 Predictions Min        -86.56
trainer/Q Targets Mean            -40.7962
trainer/Q Targets Std              12.4902
trainer/Q Targets Max              -0.506494
trainer/Q Targets Min             -87.7416
trainer/Log Pis Mean                1.96898
trainer/Log Pis Std                 1.26843
trainer/Log Pis Max                 5.33846
trainer/Log Pis Min                -1.49604
trainer/Policy mu Mean              0.0249476
trainer/Policy mu Std               0.835514
trainer/Policy mu Max               2.77353
trainer/Policy mu Min              -2.5916
trainer/Policy log std Mean        -1.9118
trainer/Policy log std Std          0.613731
trainer/Policy log std Max         -0.415907
trainer/Policy log std Min         -2.66992
trainer/Alpha                       0.0889418
trainer/Alpha Loss                 -0.0750671
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.725531
exploration/Rewards Std             1.12344
exploration/Rewards Max            -0.165484
exploration/Rewards Min            -9.11103
exploration/Returns Mean          -72.5531
exploration/Returns Std            25.9266
exploration/Returns Max           -46.6265
exploration/Returns Min           -98.4797
exploration/Actions Mean           -0.0133636
exploration/Actions Std             0.244246
exploration/Actions Max             0.993653
exploration/Actions Min            -0.998042
exploration/Num Paths               2
exploration/Average Returns       -72.5531
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.531349
evaluation/Rewards Std              0.774662
evaluation/Rewards Max             -0.111367
evaluation/Rewards Min             -7.86465
evaluation/Returns Mean           -53.1349
evaluation/Returns Std             16.1538
evaluation/Returns Max            -28.8174
evaluation/Returns Min            -83.3245
evaluation/Actions Mean             0.0136402
evaluation/Actions Std              0.163469
evaluation/Actions Max              0.991007
evaluation/Actions Min             -0.982123
evaluation/Num Paths               10
evaluation/Average Returns        -53.1349
time/data storing (s)               0.00134602
time/evaluation sampling (s)        0.22426
time/exploration sampling (s)       0.0630506
time/logging (s)                    0.00339402
time/saving (s)                     0.0019947
time/training (s)                   0.771979
time/epoch (s)                      1.06603
time/total (s)                    207.929
Epoch                             194
-----------------------------  ---------------
2019-04-21 01:15:12.454230 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              39400
trainer/QF1 Loss                   19.2293
trainer/QF2 Loss                   19.2466
trainer/Policy Loss                43.6652
trainer/Q1 Predictions Mean       -42.2573
trainer/Q1 Predictions Std          9.28568
trainer/Q1 Predictions Max        -34.486
trainer/Q1 Predictions Min       -106.432
trainer/Q2 Predictions Mean       -42.2512
trainer/Q2 Predictions Std          9.2889
trainer/Q2 Predictions Max        -34.4839
trainer/Q2 Predictions Min       -106.183
trainer/Q Targets Mean            -42.1038
trainer/Q Targets Std              10.2835
trainer/Q Targets Max              -0.629546
trainer/Q Targets Min            -106.386
trainer/Log Pis Mean                1.99178
trainer/Log Pis Std                 1.24103
trainer/Log Pis Max                 6.49855
trainer/Log Pis Min                -2.55937
trainer/Policy mu Mean             -0.00816246
trainer/Policy mu Std               0.712359
trainer/Policy mu Max               2.60777
trainer/Policy mu Min              -3.44565
trainer/Policy log std Mean        -2.07253
trainer/Policy log std Std          0.565829
trainer/Policy log std Max         -0.166775
trainer/Policy log std Min         -2.74832
trainer/Alpha                       0.0899042
trainer/Alpha Loss                 -0.0198079
exploration/num steps total     39400
exploration/num paths total       394
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.871651
exploration/Rewards Std             1.36348
exploration/Rewards Max            -0.211609
exploration/Rewards Min            -9.45333
exploration/Returns Mean          -87.1651
exploration/Returns Std            19.1456
exploration/Returns Max           -68.0195
exploration/Returns Min          -106.311
exploration/Actions Mean           -0.0231712
exploration/Actions Std             0.263679
exploration/Actions Max             0.995665
exploration/Actions Min            -0.998236
exploration/Num Paths               2
exploration/Average Returns       -87.1651
evaluation/num steps total     196000
evaluation/num paths total       1960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.676345
evaluation/Rewards Std              0.978566
evaluation/Rewards Max             -0.32567
evaluation/Rewards Min             -9.39491
evaluation/Returns Mean           -67.6345
evaluation/Returns Std             26.061
evaluation/Returns Max            -37.3844
evaluation/Returns Min           -111.455
evaluation/Actions Mean             0.00451823
evaluation/Actions Std              0.189591
evaluation/Actions Max              0.99402
evaluation/Actions Min             -0.994229
evaluation/Num Paths               10
evaluation/Average Returns        -67.6345
time/data storing (s)               0.00122989
time/evaluation sampling (s)        0.221327
time/exploration sampling (s)       0.0657955
time/logging (s)                    0.00337046
time/saving (s)                     0.00195462
time/training (s)                   0.771699
time/epoch (s)                      1.06538
time/total (s)                    208.999
Epoch                             195
-----------------------------  ---------------
2019-04-21 01:15:13.519126 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              39600
trainer/QF1 Loss                   19.1622
trainer/QF2 Loss                   19.3574
trainer/Policy Loss                42.3999
trainer/Q1 Predictions Mean       -41.0503
trainer/Q1 Predictions Std          5.05004
trainer/Q1 Predictions Max        -34.2777
trainer/Q1 Predictions Min        -51.4158
trainer/Q2 Predictions Mean       -41.0544
trainer/Q2 Predictions Std          5.05697
trainer/Q2 Predictions Max        -34.2701
trainer/Q2 Predictions Min        -52.4382
trainer/Q Targets Mean            -40.8468
trainer/Q Targets Std               6.52215
trainer/Q Targets Max              -0.752348
trainer/Q Targets Min             -51.8177
trainer/Log Pis Mean                1.86988
trainer/Log Pis Std                 1.07911
trainer/Log Pis Max                 3.8083
trainer/Log Pis Min                -3.03375
trainer/Policy mu Mean             -0.012056
trainer/Policy mu Std               0.554263
trainer/Policy mu Max               2.30278
trainer/Policy mu Min              -2.1885
trainer/Policy log std Mean        -2.09393
trainer/Policy log std Std          0.457874
trainer/Policy log std Max         -0.544553
trainer/Policy log std Min         -2.64774
trainer/Alpha                       0.0891731
trainer/Alpha Loss                 -0.314513
exploration/num steps total     39600
exploration/num paths total       396
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.583948
exploration/Rewards Std             0.296299
exploration/Rewards Max            -0.230021
exploration/Rewards Min            -3.013
exploration/Returns Mean          -58.3948
exploration/Returns Std            12.1344
exploration/Returns Max           -46.2604
exploration/Returns Min           -70.5292
exploration/Actions Mean           -0.00472089
exploration/Actions Std             0.184965
exploration/Actions Max             0.930411
exploration/Actions Min            -0.990725
exploration/Num Paths               2
exploration/Average Returns       -58.3948
evaluation/num steps total     197000
evaluation/num paths total       1970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.66309
evaluation/Rewards Std              0.823779
evaluation/Rewards Max             -0.404485
evaluation/Rewards Min             -8.35872
evaluation/Returns Mean           -66.309
evaluation/Returns Std             15.3295
evaluation/Returns Max            -43.5604
evaluation/Returns Min            -94.2549
evaluation/Actions Mean             0.00651375
evaluation/Actions Std              0.187004
evaluation/Actions Max              0.992991
evaluation/Actions Min             -0.991926
evaluation/Num Paths               10
evaluation/Average Returns        -66.309
time/data storing (s)               0.00121174
time/evaluation sampling (s)        0.218556
time/exploration sampling (s)       0.0631359
time/logging (s)                    0.00338641
time/saving (s)                     0.00196274
time/training (s)                   0.769349
time/epoch (s)                      1.0576
time/total (s)                    210.06
Epoch                             196
-----------------------------  ---------------
2019-04-21 01:15:14.607738 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              39800
trainer/QF1 Loss                   12.8352
trainer/QF2 Loss                   12.6443
trainer/Policy Loss                44.0486
trainer/Q1 Predictions Mean       -42.4964
trainer/Q1 Predictions Std          8.24642
trainer/Q1 Predictions Max        -33.7938
trainer/Q1 Predictions Min        -75.7998
trainer/Q2 Predictions Mean       -42.5197
trainer/Q2 Predictions Std          8.27409
trainer/Q2 Predictions Max        -33.7884
trainer/Q2 Predictions Min        -76.5936
trainer/Q Targets Mean            -42.3223
trainer/Q Targets Std               9.0574
trainer/Q Targets Max              -1.99425
trainer/Q Targets Min             -76.0386
trainer/Log Pis Mean                2.25935
trainer/Log Pis Std                 1.19764
trainer/Log Pis Max                 5.46155
trainer/Log Pis Min                -2.04701
trainer/Policy mu Mean              0.0349999
trainer/Policy mu Std               0.894329
trainer/Policy mu Max               2.83264
trainer/Policy mu Min              -2.68006
trainer/Policy log std Mean        -1.90002
trainer/Policy log std Std          0.636291
trainer/Policy log std Max         -0.496376
trainer/Policy log std Min         -2.7232
trainer/Alpha                       0.0897833
trainer/Alpha Loss                  0.625106
exploration/num steps total     39800
exploration/num paths total       398
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.674365
exploration/Rewards Std             1.27232
exploration/Rewards Max            -0.163019
exploration/Rewards Min            -9.38828
exploration/Returns Mean          -67.4365
exploration/Returns Std            16.9938
exploration/Returns Max           -50.4428
exploration/Returns Min           -84.4303
exploration/Actions Mean            0.0228377
exploration/Actions Std             0.230329
exploration/Actions Max             0.998457
exploration/Actions Min            -0.994171
exploration/Num Paths               2
exploration/Average Returns       -67.4365
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.570149
evaluation/Rewards Std              0.885517
evaluation/Rewards Max             -0.345248
evaluation/Rewards Min            -10.1732
evaluation/Returns Mean           -57.0149
evaluation/Returns Std             21.6996
evaluation/Returns Max            -36.7814
evaluation/Returns Min           -100.635
evaluation/Actions Mean             0.00840888
evaluation/Actions Std              0.164484
evaluation/Actions Max              0.993503
evaluation/Actions Min             -0.990153
evaluation/Num Paths               10
evaluation/Average Returns        -57.0149
time/data storing (s)               0.00163664
time/evaluation sampling (s)        0.224407
time/exploration sampling (s)       0.0661748
time/logging (s)                    0.00336771
time/saving (s)                     0.00193939
time/training (s)                   0.783695
time/epoch (s)                      1.08122
time/total (s)                    211.146
Epoch                             197
-----------------------------  ---------------
2019-04-21 01:15:15.701518 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 198 finished
-----------------------------  ----------------
replay_buffer/size              40000
trainer/QF1 Loss                   42.1959
trainer/QF2 Loss                   41.6268
trainer/Policy Loss                44.2332
trainer/Q1 Predictions Mean       -43.1373
trainer/Q1 Predictions Std         10.4801
trainer/Q1 Predictions Max        -33.5977
trainer/Q1 Predictions Min        -88.9702
trainer/Q2 Predictions Mean       -43.1201
trainer/Q2 Predictions Std         10.44
trainer/Q2 Predictions Max        -33.5541
trainer/Q2 Predictions Min        -89.2888
trainer/Q Targets Mean            -42.5912
trainer/Q Targets Std              11.8326
trainer/Q Targets Max              -2.6555
trainer/Q Targets Min             -88.3607
trainer/Log Pis Mean                2.01761
trainer/Log Pis Std                 1.35728
trainer/Log Pis Max                 7.19341
trainer/Log Pis Min                -1.91571
trainer/Policy mu Mean              0.0661328
trainer/Policy mu Std               0.915504
trainer/Policy mu Max               2.90887
trainer/Policy mu Min              -2.84486
trainer/Policy log std Mean        -1.85007
trainer/Policy log std Std          0.621733
trainer/Policy log std Max         -0.421214
trainer/Policy log std Min         -2.61331
trainer/Alpha                       0.0888749
trainer/Alpha Loss                  0.0426247
exploration/num steps total     40000
exploration/num paths total       400
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.755845
exploration/Rewards Std             1.0801
exploration/Rewards Max            -0.192856
exploration/Rewards Min            -7.72946
exploration/Returns Mean          -75.5845
exploration/Returns Std            13.8009
exploration/Returns Max           -61.7836
exploration/Returns Min           -89.3853
exploration/Actions Mean           -0.0168414
exploration/Actions Std             0.239193
exploration/Actions Max             0.998328
exploration/Actions Min            -0.993125
exploration/Num Paths               2
exploration/Average Returns       -75.5845
evaluation/num steps total     199000
evaluation/num paths total       1990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.585187
evaluation/Rewards Std              0.717397
evaluation/Rewards Max             -0.369675
evaluation/Rewards Min             -8.73417
evaluation/Returns Mean           -58.5187
evaluation/Returns Std             15.8727
evaluation/Returns Max            -37.8769
evaluation/Returns Min            -91.3607
evaluation/Actions Mean            -7.10998e-05
evaluation/Actions Std              0.17498
evaluation/Actions Max              0.991031
evaluation/Actions Min             -0.994767
evaluation/Num Paths               10
evaluation/Average Returns        -58.5187
time/data storing (s)               0.00126015
time/evaluation sampling (s)        0.226031
time/exploration sampling (s)       0.0652058
time/logging (s)                    0.00344106
time/saving (s)                     0.00198805
time/training (s)                   0.788796
time/epoch (s)                      1.08672
time/total (s)                    212.236
Epoch                             198
-----------------------------  ----------------
2019-04-21 01:15:16.783517 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    0.317646
trainer/QF2 Loss                    0.344217
trainer/Policy Loss                42.768
trainer/Q1 Predictions Mean       -41.205
trainer/Q1 Predictions Std          5.73921
trainer/Q1 Predictions Max        -32.8355
trainer/Q1 Predictions Min        -59.8312
trainer/Q2 Predictions Mean       -41.1927
trainer/Q2 Predictions Std          5.7387
trainer/Q2 Predictions Max        -32.8165
trainer/Q2 Predictions Min        -59.7896
trainer/Q Targets Mean            -41.6704
trainer/Q Targets Std               5.55852
trainer/Q Targets Max             -33.6007
trainer/Q Targets Min             -60.5654
trainer/Log Pis Mean                1.96154
trainer/Log Pis Std                 1.01241
trainer/Log Pis Max                 4.86305
trainer/Log Pis Min                -1.48681
trainer/Policy mu Mean             -0.0343149
trainer/Policy mu Std               0.700862
trainer/Policy mu Max               2.70622
trainer/Policy mu Min              -2.22001
trainer/Policy log std Mean        -2.02266
trainer/Policy log std Std          0.525432
trainer/Policy log std Max         -0.620087
trainer/Policy log std Min         -2.71393
trainer/Alpha                       0.0883211
trainer/Alpha Loss                 -0.0933378
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.717976
exploration/Rewards Std             0.368805
exploration/Rewards Max            -0.442188
exploration/Rewards Min            -3.91232
exploration/Returns Mean          -71.7976
exploration/Returns Std             2.56138
exploration/Returns Max           -69.2362
exploration/Returns Min           -74.359
exploration/Actions Mean           -0.00438219
exploration/Actions Std             0.193811
exploration/Actions Max             0.993533
exploration/Actions Min            -0.996286
exploration/Num Paths               2
exploration/Average Returns       -71.7976
evaluation/num steps total     200000
evaluation/num paths total       2000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.608483
evaluation/Rewards Std              0.913675
evaluation/Rewards Max             -0.128074
evaluation/Rewards Min            -10.1248
evaluation/Returns Mean           -60.8483
evaluation/Returns Std             21.1824
evaluation/Returns Max            -31.0726
evaluation/Returns Min           -101.871
evaluation/Actions Mean             0.01653
evaluation/Actions Std              0.176053
evaluation/Actions Max              0.995183
evaluation/Actions Min             -0.992631
evaluation/Num Paths               10
evaluation/Average Returns        -60.8483
time/data storing (s)               0.0014694
time/evaluation sampling (s)        0.226747
time/exploration sampling (s)       0.0649056
time/logging (s)                    0.00337489
time/saving (s)                     0.00194573
time/training (s)                   0.776824
time/epoch (s)                      1.07527
time/total (s)                    213.315
Epoch                             199
-----------------------------  ---------------
2019-04-21 01:15:17.857498 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 200 finished
-----------------------------  ---------------
replay_buffer/size              40400
trainer/QF1 Loss                   32.3479
trainer/QF2 Loss                   32.4979
trainer/Policy Loss                41.3084
trainer/Q1 Predictions Mean       -39.8573
trainer/Q1 Predictions Std          5.97442
trainer/Q1 Predictions Max        -32.9263
trainer/Q1 Predictions Min        -56.1909
trainer/Q2 Predictions Mean       -39.8336
trainer/Q2 Predictions Std          5.96268
trainer/Q2 Predictions Max        -32.8588
trainer/Q2 Predictions Min        -55.3853
trainer/Q Targets Mean            -39.5883
trainer/Q Targets Std               8.11417
trainer/Q Targets Max              -0.966699
trainer/Q Targets Min             -57.0093
trainer/Log Pis Mean                2.09231
trainer/Log Pis Std                 1.09095
trainer/Log Pis Max                 4.01134
trainer/Log Pis Min                -3.33782
trainer/Policy mu Mean             -0.0125105
trainer/Policy mu Std               0.677233
trainer/Policy mu Max               2.36805
trainer/Policy mu Min              -2.22709
trainer/Policy log std Mean        -2.0389
trainer/Policy log std Std          0.529255
trainer/Policy log std Max         -0.619416
trainer/Policy log std Min         -2.67223
trainer/Alpha                       0.0883246
trainer/Alpha Loss                  0.224016
exploration/num steps total     40400
exploration/num paths total       404
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.60773
exploration/Rewards Std             1.02305
exploration/Rewards Max            -0.153423
exploration/Rewards Min            -8.09771
exploration/Returns Mean          -60.773
exploration/Returns Std            11.5016
exploration/Returns Max           -49.2714
exploration/Returns Min           -72.2747
exploration/Actions Mean            0.0298045
exploration/Actions Std             0.21843
exploration/Actions Max             0.996239
exploration/Actions Min            -0.870164
exploration/Num Paths               2
exploration/Average Returns       -60.773
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.716466
evaluation/Rewards Std              1.02464
evaluation/Rewards Max             -0.335567
evaluation/Rewards Min            -10.1536
evaluation/Returns Mean           -71.6466
evaluation/Returns Std             19.5141
evaluation/Returns Max            -38.265
evaluation/Returns Min           -103.481
evaluation/Actions Mean            -0.00748686
evaluation/Actions Std              0.207146
evaluation/Actions Max              0.992035
evaluation/Actions Min             -0.998463
evaluation/Num Paths               10
evaluation/Average Returns        -71.6466
time/data storing (s)               0.0012707
time/evaluation sampling (s)        0.236774
time/exploration sampling (s)       0.0693782
time/logging (s)                    0.00337257
time/saving (s)                     0.00198552
time/training (s)                   0.754827
time/epoch (s)                      1.06761
time/total (s)                    214.386
Epoch                             200
-----------------------------  ---------------
2019-04-21 01:15:18.932451 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 201 finished
-----------------------------  ---------------
replay_buffer/size              40600
trainer/QF1 Loss                    0.330809
trainer/QF2 Loss                    0.377125
trainer/Policy Loss                43.237
trainer/Q1 Predictions Mean       -41.8633
trainer/Q1 Predictions Std         10.918
trainer/Q1 Predictions Max        -32.7068
trainer/Q1 Predictions Min       -113.084
trainer/Q2 Predictions Mean       -41.8837
trainer/Q2 Predictions Std         11.0222
trainer/Q2 Predictions Max        -32.6782
trainer/Q2 Predictions Min       -113.199
trainer/Q Targets Mean            -42.1917
trainer/Q Targets Std              10.7692
trainer/Q Targets Max             -33.0044
trainer/Q Targets Min            -109.82
trainer/Log Pis Mean                2.12309
trainer/Log Pis Std                 1.32568
trainer/Log Pis Max                 6.5001
trainer/Log Pis Min                -3.0868
trainer/Policy mu Mean             -0.0289808
trainer/Policy mu Std               0.868205
trainer/Policy mu Max               2.58307
trainer/Policy mu Min              -3.5161
trainer/Policy log std Mean        -2.01452
trainer/Policy log std Std          0.613917
trainer/Policy log std Max         -0.423995
trainer/Policy log std Min         -2.78048
trainer/Alpha                       0.0881037
trainer/Alpha Loss                  0.299029
exploration/num steps total     40600
exploration/num paths total       406
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.783078
exploration/Rewards Std             0.607026
exploration/Rewards Max            -0.350517
exploration/Rewards Min            -6.15121
exploration/Returns Mean          -78.3078
exploration/Returns Std             8.48611
exploration/Returns Max           -69.8217
exploration/Returns Min           -86.7939
exploration/Actions Mean           -0.01976
exploration/Actions Std             0.19983
exploration/Actions Max             0.552862
exploration/Actions Min            -0.995386
exploration/Num Paths               2
exploration/Average Returns       -78.3078
evaluation/num steps total     202000
evaluation/num paths total       2020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.623148
evaluation/Rewards Std              0.663184
evaluation/Rewards Max             -0.264228
evaluation/Rewards Min             -8.51769
evaluation/Returns Mean           -62.3148
evaluation/Returns Std             17.1085
evaluation/Returns Max            -33.761
evaluation/Returns Min            -81.2229
evaluation/Actions Mean             0.0146475
evaluation/Actions Std              0.160697
evaluation/Actions Max              0.992734
evaluation/Actions Min             -0.981042
evaluation/Num Paths               10
evaluation/Average Returns        -62.3148
time/data storing (s)               0.00124058
time/evaluation sampling (s)        0.23089
time/exploration sampling (s)       0.0627958
time/logging (s)                    0.00289361
time/saving (s)                     0.00196166
time/training (s)                   0.767541
time/epoch (s)                      1.06732
time/total (s)                    215.458
Epoch                             201
-----------------------------  ---------------
2019-04-21 01:15:20.008387 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 202 finished
-----------------------------  ---------------
replay_buffer/size              40800
trainer/QF1 Loss                   40.4347
trainer/QF2 Loss                   40.4247
trainer/Policy Loss                41.2016
trainer/Q1 Predictions Mean       -39.6485
trainer/Q1 Predictions Std          7.78405
trainer/Q1 Predictions Max        -32.7385
trainer/Q1 Predictions Min        -80.4858
trainer/Q2 Predictions Mean       -39.6582
trainer/Q2 Predictions Std          7.83465
trainer/Q2 Predictions Max        -32.7271
trainer/Q2 Predictions Min        -80.6033
trainer/Q Targets Mean            -38.8039
trainer/Q Targets Std              10.3008
trainer/Q Targets Max              -0.657316
trainer/Q Targets Min             -79.1292
trainer/Log Pis Mean                2.18273
trainer/Log Pis Std                 0.973585
trainer/Log Pis Max                 4.63351
trainer/Log Pis Min                -1.02125
trainer/Policy mu Mean              0.0648095
trainer/Policy mu Std               0.706126
trainer/Policy mu Max               2.63692
trainer/Policy mu Min              -2.70734
trainer/Policy log std Mean        -2.06899
trainer/Policy log std Std          0.551342
trainer/Policy log std Max         -0.170268
trainer/Policy log std Min         -2.67953
trainer/Alpha                       0.0886576
trainer/Alpha Loss                  0.442756
exploration/num steps total     40800
exploration/num paths total       408
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.336372
exploration/Rewards Std             0.279105
exploration/Rewards Max            -0.12992
exploration/Rewards Min            -2.86131
exploration/Returns Mean          -33.6372
exploration/Returns Std             1.22489
exploration/Returns Max           -32.4123
exploration/Returns Min           -34.8621
exploration/Actions Mean            0.0142298
exploration/Actions Std             0.153693
exploration/Actions Max             0.970855
exploration/Actions Min            -0.633114
exploration/Num Paths               2
exploration/Average Returns       -33.6372
evaluation/num steps total     203000
evaluation/num paths total       2030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.583804
evaluation/Rewards Std              0.914267
evaluation/Rewards Max             -0.265059
evaluation/Rewards Min            -10.9226
evaluation/Returns Mean           -58.3804
evaluation/Returns Std             26.4374
evaluation/Returns Max            -27.363
evaluation/Returns Min           -112.208
evaluation/Actions Mean            -0.00367856
evaluation/Actions Std              0.174097
evaluation/Actions Max              0.994417
evaluation/Actions Min             -0.998271
evaluation/Num Paths               10
evaluation/Average Returns        -58.3804
time/data storing (s)               0.00122852
time/evaluation sampling (s)        0.222725
time/exploration sampling (s)       0.0655944
time/logging (s)                    0.00332377
time/saving (s)                     0.00196657
time/training (s)                   0.773813
time/epoch (s)                      1.06865
time/total (s)                    216.531
Epoch                             202
-----------------------------  ---------------
2019-04-21 01:15:21.082941 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 203 finished
-----------------------------  ---------------
replay_buffer/size              41000
trainer/QF1 Loss                    0.376558
trainer/QF2 Loss                    0.324923
trainer/Policy Loss                42.1544
trainer/Q1 Predictions Mean       -40.8694
trainer/Q1 Predictions Std          9.07293
trainer/Q1 Predictions Max        -32.4533
trainer/Q1 Predictions Min        -91.8584
trainer/Q2 Predictions Mean       -40.8816
trainer/Q2 Predictions Std          9.16946
trainer/Q2 Predictions Max        -32.4622
trainer/Q2 Predictions Min        -94.134
trainer/Q Targets Mean            -41.1971
trainer/Q Targets Std               9.42566
trainer/Q Targets Max             -32.4972
trainer/Q Targets Min             -94.8737
trainer/Log Pis Mean                2.12227
trainer/Log Pis Std                 1.46047
trainer/Log Pis Max                 9.29485
trainer/Log Pis Min                -1.62086
trainer/Policy mu Mean              0.0986601
trainer/Policy mu Std               0.932384
trainer/Policy mu Max               2.66393
trainer/Policy mu Min              -3.44352
trainer/Policy log std Mean        -1.90503
trainer/Policy log std Std          0.631858
trainer/Policy log std Max         -0.373472
trainer/Policy log std Min         -2.65937
trainer/Alpha                       0.0903472
trainer/Alpha Loss                  0.293978
exploration/num steps total     41000
exploration/num paths total       410
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.876458
exploration/Rewards Std             1.18452
exploration/Rewards Max            -0.330892
exploration/Rewards Min            -9.36665
exploration/Returns Mean          -87.6458
exploration/Returns Std            17.8213
exploration/Returns Max           -69.8245
exploration/Returns Min          -105.467
exploration/Actions Mean           -0.0349783
exploration/Actions Std             0.237165
exploration/Actions Max             0.800764
exploration/Actions Min            -0.99633
exploration/Num Paths               2
exploration/Average Returns       -87.6458
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.58439
evaluation/Rewards Std              0.979261
evaluation/Rewards Max             -0.295478
evaluation/Rewards Min            -10.2092
evaluation/Returns Mean           -58.439
evaluation/Returns Std             20.9627
evaluation/Returns Max            -39.8137
evaluation/Returns Min           -107.241
evaluation/Actions Mean             0.00395244
evaluation/Actions Std              0.191673
evaluation/Actions Max              0.992338
evaluation/Actions Min             -0.997128
evaluation/Num Paths               10
evaluation/Average Returns        -58.439
time/data storing (s)               0.00125485
time/evaluation sampling (s)        0.225226
time/exploration sampling (s)       0.0679117
time/logging (s)                    0.00334419
time/saving (s)                     0.00193037
time/training (s)                   0.767309
time/epoch (s)                      1.06698
time/total (s)                    217.602
Epoch                             203
-----------------------------  ---------------
2019-04-21 01:15:22.156421 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 204 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                   20.4402
trainer/QF2 Loss                   20.2775
trainer/Policy Loss                40.7193
trainer/Q1 Predictions Mean       -39.5067
trainer/Q1 Predictions Std          6.20712
trainer/Q1 Predictions Max        -31.9396
trainer/Q1 Predictions Min        -62.5504
trainer/Q2 Predictions Mean       -39.5184
trainer/Q2 Predictions Std          6.28915
trainer/Q2 Predictions Max        -31.9029
trainer/Q2 Predictions Min        -64.4969
trainer/Q Targets Mean            -38.9389
trainer/Q Targets Std               8.26552
trainer/Q Targets Max              -0.189569
trainer/Q Targets Min             -66.3808
trainer/Log Pis Mean                2.14989
trainer/Log Pis Std                 1.11492
trainer/Log Pis Max                 5.8842
trainer/Log Pis Min                -0.980128
trainer/Policy mu Mean              0.139361
trainer/Policy mu Std               0.687725
trainer/Policy mu Max               2.63719
trainer/Policy mu Min              -2.1665
trainer/Policy log std Mean        -2.06645
trainer/Policy log std Std          0.543219
trainer/Policy log std Max         -0.488343
trainer/Policy log std Min         -2.78215
trainer/Alpha                       0.0908075
trainer/Alpha Loss                  0.359603
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.664605
exploration/Rewards Std             0.256673
exploration/Rewards Max            -0.421045
exploration/Rewards Min            -3.09564
exploration/Returns Mean          -66.4605
exploration/Returns Std             2.05028
exploration/Returns Max           -64.4102
exploration/Returns Min           -68.5108
exploration/Actions Mean           -0.00670617
exploration/Actions Std             0.184491
exploration/Actions Max             0.966199
exploration/Actions Min            -0.980158
exploration/Num Paths               2
exploration/Average Returns       -66.4605
evaluation/num steps total     205000
evaluation/num paths total       2050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.596796
evaluation/Rewards Std              0.617365
evaluation/Rewards Max             -0.218241
evaluation/Rewards Min             -7.79431
evaluation/Returns Mean           -59.6796
evaluation/Returns Std             17.7846
evaluation/Returns Max            -33.3259
evaluation/Returns Min            -90.5975
evaluation/Actions Mean            -0.00496169
evaluation/Actions Std              0.155876
evaluation/Actions Max              0.994299
evaluation/Actions Min             -0.992615
evaluation/Num Paths               10
evaluation/Average Returns        -59.6796
time/data storing (s)               0.00122423
time/evaluation sampling (s)        0.222859
time/exploration sampling (s)       0.0642873
time/logging (s)                    0.00335023
time/saving (s)                     0.00195257
time/training (s)                   0.772431
time/epoch (s)                      1.0661
time/total (s)                    218.672
Epoch                             204
-----------------------------  ---------------
2019-04-21 01:15:23.213957 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 205 finished
-----------------------------  ---------------
replay_buffer/size              41400
trainer/QF1 Loss                    1.2105
trainer/QF2 Loss                    1.0708
trainer/Policy Loss                40.9286
trainer/Q1 Predictions Mean       -39.7452
trainer/Q1 Predictions Std         10.6465
trainer/Q1 Predictions Max        -31.3339
trainer/Q1 Predictions Min       -107.64
trainer/Q2 Predictions Mean       -39.775
trainer/Q2 Predictions Std         10.6814
trainer/Q2 Predictions Max        -31.4014
trainer/Q2 Predictions Min       -107.768
trainer/Q Targets Mean            -40.6642
trainer/Q Targets Std              10.9119
trainer/Q Targets Max             -31.9605
trainer/Q Targets Min            -109.979
trainer/Log Pis Mean                1.98791
trainer/Log Pis Std                 1.25023
trainer/Log Pis Max                 5.49538
trainer/Log Pis Min                -2.6514
trainer/Policy mu Mean              0.108143
trainer/Policy mu Std               0.798985
trainer/Policy mu Max               2.72296
trainer/Policy mu Min              -2.86425
trainer/Policy log std Mean        -1.97287
trainer/Policy log std Std          0.57046
trainer/Policy log std Max         -0.461852
trainer/Policy log std Min         -2.70001
trainer/Alpha                       0.0919038
trainer/Alpha Loss                 -0.0288613
exploration/num steps total     41400
exploration/num paths total       414
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.847987
exploration/Rewards Std             0.979619
exploration/Rewards Max            -0.376127
exploration/Rewards Min            -8.35389
exploration/Returns Mean          -84.7987
exploration/Returns Std            11.8566
exploration/Returns Max           -72.9421
exploration/Returns Min           -96.6553
exploration/Actions Mean           -0.0306574
exploration/Actions Std             0.235884
exploration/Actions Max             0.912167
exploration/Actions Min            -0.997648
exploration/Num Paths               2
exploration/Average Returns       -84.7987
evaluation/num steps total     206000
evaluation/num paths total       2060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.636315
evaluation/Rewards Std              0.862472
evaluation/Rewards Max             -0.360032
evaluation/Rewards Min             -9.58723
evaluation/Returns Mean           -63.6315
evaluation/Returns Std             16.5128
evaluation/Returns Max            -39.6949
evaluation/Returns Min            -87.8342
evaluation/Actions Mean             0.00360471
evaluation/Actions Std              0.183683
evaluation/Actions Max              0.99589
evaluation/Actions Min             -0.993293
evaluation/Num Paths               10
evaluation/Average Returns        -63.6315
time/data storing (s)               0.00125555
time/evaluation sampling (s)        0.221876
time/exploration sampling (s)       0.0650073
time/logging (s)                    0.00338956
time/saving (s)                     0.00741698
time/training (s)                   0.751086
time/epoch (s)                      1.05003
time/total (s)                    219.727
Epoch                             205
-----------------------------  ---------------
2019-04-21 01:15:24.273470 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 206 finished
-----------------------------  ---------------
replay_buffer/size              41600
trainer/QF1 Loss                   17.9802
trainer/QF2 Loss                   17.953
trainer/Policy Loss                40.2046
trainer/Q1 Predictions Mean       -39.0021
trainer/Q1 Predictions Std          7.69113
trainer/Q1 Predictions Max        -31.6221
trainer/Q1 Predictions Min        -68.993
trainer/Q2 Predictions Mean       -39.0164
trainer/Q2 Predictions Std          7.65695
trainer/Q2 Predictions Max        -31.6548
trainer/Q2 Predictions Min        -68.6794
trainer/Q Targets Mean            -38.8207
trainer/Q Targets Std               8.6198
trainer/Q Targets Max              -0.621063
trainer/Q Targets Min             -70.3862
trainer/Log Pis Mean                1.78349
trainer/Log Pis Std                 1.23945
trainer/Log Pis Max                 4.64546
trainer/Log Pis Min                -1.75731
trainer/Policy mu Mean              0.115663
trainer/Policy mu Std               0.694281
trainer/Policy mu Max               2.70143
trainer/Policy mu Min              -2.45514
trainer/Policy log std Mean        -2.01698
trainer/Policy log std Std          0.528985
trainer/Policy log std Max         -0.725137
trainer/Policy log std Min         -2.66883
trainer/Alpha                       0.0894172
trainer/Alpha Loss                 -0.522663
exploration/num steps total     41600
exploration/num paths total       416
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.681074
exploration/Rewards Std             0.362582
exploration/Rewards Max            -0.368122
exploration/Rewards Min            -4.33953
exploration/Returns Mean          -68.1074
exploration/Returns Std             4.7976
exploration/Returns Max           -63.3098
exploration/Returns Min           -72.905
exploration/Actions Mean           -0.0019559
exploration/Actions Std             0.184012
exploration/Actions Max             0.884974
exploration/Actions Min            -0.996685
exploration/Num Paths               2
exploration/Average Returns       -68.1074
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.586147
evaluation/Rewards Std              0.704359
evaluation/Rewards Max             -0.232876
evaluation/Rewards Min             -8.01302
evaluation/Returns Mean           -58.6147
evaluation/Returns Std             18.7935
evaluation/Returns Max            -36.9108
evaluation/Returns Min            -92.8679
evaluation/Actions Mean            -0.00831711
evaluation/Actions Std              0.157224
evaluation/Actions Max              0.991012
evaluation/Actions Min             -0.992549
evaluation/Num Paths               10
evaluation/Average Returns        -58.6147
time/data storing (s)               0.00123279
time/evaluation sampling (s)        0.220621
time/exploration sampling (s)       0.0629695
time/logging (s)                    0.00335846
time/saving (s)                     0.0017441
time/training (s)                   0.7621
time/epoch (s)                      1.05203
time/total (s)                    220.783
Epoch                             206
-----------------------------  ---------------
2019-04-21 01:15:25.349016 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 207 finished
-----------------------------  ---------------
replay_buffer/size              41800
trainer/QF1 Loss                   19.4045
trainer/QF2 Loss                   19.4385
trainer/Policy Loss                40.321
trainer/Q1 Predictions Mean       -39.0214
trainer/Q1 Predictions Std          9.28342
trainer/Q1 Predictions Max        -31.2915
trainer/Q1 Predictions Min        -92.591
trainer/Q2 Predictions Mean       -39.0451
trainer/Q2 Predictions Std          9.25622
trainer/Q2 Predictions Max        -31.3279
trainer/Q2 Predictions Min        -92.8409
trainer/Q Targets Mean            -38.4937
trainer/Q Targets Std              10.6154
trainer/Q Targets Max              -0.397508
trainer/Q Targets Min             -92.7861
trainer/Log Pis Mean                1.92365
trainer/Log Pis Std                 1.51895
trainer/Log Pis Max                 6.77555
trainer/Log Pis Min                -4.75788
trainer/Policy mu Mean              0.0752104
trainer/Policy mu Std               0.740883
trainer/Policy mu Max               2.84985
trainer/Policy mu Min              -2.64192
trainer/Policy log std Mean        -2.05177
trainer/Policy log std Std          0.550314
trainer/Policy log std Max         -0.489647
trainer/Policy log std Min         -2.68783
trainer/Alpha                       0.0885476
trainer/Alpha Loss                 -0.1851
exploration/num steps total     41800
exploration/num paths total       418
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.636773
exploration/Rewards Std             1.07039
exploration/Rewards Max            -0.181073
exploration/Rewards Min            -9.29973
exploration/Returns Mean          -63.6773
exploration/Returns Std            15.955
exploration/Returns Max           -47.7223
exploration/Returns Min           -79.6323
exploration/Actions Mean            0.0124371
exploration/Actions Std             0.221327
exploration/Actions Max             0.994302
exploration/Actions Min            -0.996729
exploration/Num Paths               2
exploration/Average Returns       -63.6773
evaluation/num steps total     208000
evaluation/num paths total       2080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.634102
evaluation/Rewards Std              0.736633
evaluation/Rewards Max             -0.400271
evaluation/Rewards Min             -9.28959
evaluation/Returns Mean           -63.4102
evaluation/Returns Std             15.19
evaluation/Returns Max            -42.186
evaluation/Returns Min            -96.7723
evaluation/Actions Mean            -0.00157751
evaluation/Actions Std              0.163481
evaluation/Actions Max              0.991397
evaluation/Actions Min             -0.994875
evaluation/Num Paths               10
evaluation/Average Returns        -63.4102
time/data storing (s)               0.00135014
time/evaluation sampling (s)        0.225385
time/exploration sampling (s)       0.0627597
time/logging (s)                    0.00343601
time/saving (s)                     0.00197098
time/training (s)                   0.773429
time/epoch (s)                      1.06833
time/total (s)                    221.855
Epoch                             207
-----------------------------  ---------------
2019-04-21 01:15:26.430717 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 208 finished
-----------------------------  ---------------
replay_buffer/size              42000
trainer/QF1 Loss                   34.5091
trainer/QF2 Loss                   34.5287
trainer/Policy Loss                40.2446
trainer/Q1 Predictions Mean       -38.8612
trainer/Q1 Predictions Std          7.51186
trainer/Q1 Predictions Max        -31.1459
trainer/Q1 Predictions Min        -76.7435
trainer/Q2 Predictions Mean       -38.8706
trainer/Q2 Predictions Std          7.52113
trainer/Q2 Predictions Max        -31.1256
trainer/Q2 Predictions Min        -76.3658
trainer/Q Targets Mean            -38.6183
trainer/Q Targets Std               9.49537
trainer/Q Targets Max              -0.978327
trainer/Q Targets Min             -79.4845
trainer/Log Pis Mean                1.94258
trainer/Log Pis Std                 1.16249
trainer/Log Pis Max                 4.88156
trainer/Log Pis Min                -3.93784
trainer/Policy mu Mean              0.0107601
trainer/Policy mu Std               0.72686
trainer/Policy mu Max               2.76762
trainer/Policy mu Min              -2.32496
trainer/Policy log std Mean        -2.04561
trainer/Policy log std Std          0.548399
trainer/Policy log std Max         -0.571172
trainer/Policy log std Min         -2.68242
trainer/Alpha                       0.0889506
trainer/Alpha Loss                 -0.138943
exploration/num steps total     42000
exploration/num paths total       420
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00467
exploration/Rewards Std             1.37591
exploration/Rewards Max            -0.481983
exploration/Rewards Min           -10.1985
exploration/Returns Mean         -100.467
exploration/Returns Std            17.54
exploration/Returns Max           -82.9268
exploration/Returns Min          -118.007
exploration/Actions Mean           -0.0426942
exploration/Actions Std             0.239699
exploration/Actions Max             0.502082
exploration/Actions Min            -0.999501
exploration/Num Paths               2
exploration/Average Returns      -100.467
evaluation/num steps total     209000
evaluation/num paths total       2090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.578705
evaluation/Rewards Std              0.869222
evaluation/Rewards Max             -0.210685
evaluation/Rewards Min             -9.92221
evaluation/Returns Mean           -57.8705
evaluation/Returns Std             18.9956
evaluation/Returns Max            -31.9603
evaluation/Returns Min            -85.8337
evaluation/Actions Mean             0.00360704
evaluation/Actions Std              0.182722
evaluation/Actions Max              0.996913
evaluation/Actions Min             -0.993534
evaluation/Num Paths               10
evaluation/Average Returns        -57.8705
time/data storing (s)               0.00133062
time/evaluation sampling (s)        0.225844
time/exploration sampling (s)       0.064388
time/logging (s)                    0.00349075
time/saving (s)                     0.00195306
time/training (s)                   0.777221
time/epoch (s)                      1.07423
time/total (s)                    222.933
Epoch                             208
-----------------------------  ---------------
2019-04-21 01:15:27.497594 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 209 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                    0.155017
trainer/QF2 Loss                    0.168406
trainer/Policy Loss                40.2967
trainer/Q1 Predictions Mean       -38.9805
trainer/Q1 Predictions Std          8.33686
trainer/Q1 Predictions Max        -30.9682
trainer/Q1 Predictions Min        -78.7187
trainer/Q2 Predictions Mean       -38.9963
trainer/Q2 Predictions Std          8.35578
trainer/Q2 Predictions Max        -30.9314
trainer/Q2 Predictions Min        -79.1351
trainer/Q Targets Mean            -39.2659
trainer/Q Targets Std               8.37317
trainer/Q Targets Max             -31.2323
trainer/Q Targets Min             -78.8717
trainer/Log Pis Mean                1.87142
trainer/Log Pis Std                 1.71644
trainer/Log Pis Max                 6.79969
trainer/Log Pis Min                -5.02617
trainer/Policy mu Mean              0.0511353
trainer/Policy mu Std               0.76363
trainer/Policy mu Max               2.92482
trainer/Policy mu Min              -2.6376
trainer/Policy log std Mean        -2.03839
trainer/Policy log std Std          0.55276
trainer/Policy log std Max         -0.2901
trainer/Policy log std Min         -2.68067
trainer/Alpha                       0.0896041
trainer/Alpha Loss                 -0.310197
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.442394
exploration/Rewards Std             0.504121
exploration/Rewards Max            -0.0276303
exploration/Rewards Min            -5.53554
exploration/Returns Mean          -44.2394
exploration/Returns Std             7.12084
exploration/Returns Max           -37.1186
exploration/Returns Min           -51.3603
exploration/Actions Mean            0.0212979
exploration/Actions Std             0.171315
exploration/Actions Max             0.993033
exploration/Actions Min            -0.485864
exploration/Num Paths               2
exploration/Average Returns       -44.2394
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.710513
evaluation/Rewards Std              0.847145
evaluation/Rewards Max             -0.354078
evaluation/Rewards Min             -9.90583
evaluation/Returns Mean           -71.0513
evaluation/Returns Std             20.8222
evaluation/Returns Max            -40.5477
evaluation/Returns Min           -104.717
evaluation/Actions Mean            -0.0236563
evaluation/Actions Std              0.180168
evaluation/Actions Max              0.987291
evaluation/Actions Min             -0.997259
evaluation/Num Paths               10
evaluation/Average Returns        -71.0513
time/data storing (s)               0.00122229
time/evaluation sampling (s)        0.222506
time/exploration sampling (s)       0.0638081
time/logging (s)                    0.00338058
time/saving (s)                     0.0015732
time/training (s)                   0.766674
time/epoch (s)                      1.05916
time/total (s)                    223.997
Epoch                             209
-----------------------------  ---------------
2019-04-21 01:15:28.555357 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 210 finished
-----------------------------  ---------------
replay_buffer/size              42400
trainer/QF1 Loss                   26.6543
trainer/QF2 Loss                   26.5864
trainer/Policy Loss                39.5515
trainer/Q1 Predictions Mean       -38.1393
trainer/Q1 Predictions Std          8.30961
trainer/Q1 Predictions Max        -30.6388
trainer/Q1 Predictions Min        -79.3304
trainer/Q2 Predictions Mean       -38.106
trainer/Q2 Predictions Std          8.27545
trainer/Q2 Predictions Max        -30.5274
trainer/Q2 Predictions Min        -78.5876
trainer/Q Targets Mean            -37.8964
trainer/Q Targets Std               9.93969
trainer/Q Targets Max              -0.375303
trainer/Q Targets Min             -81.6832
trainer/Log Pis Mean                1.86756
trainer/Log Pis Std                 1.25464
trainer/Log Pis Max                 5.61302
trainer/Log Pis Min                -2.33679
trainer/Policy mu Mean              0.0841805
trainer/Policy mu Std               0.726826
trainer/Policy mu Max               2.91274
trainer/Policy mu Min              -2.69778
trainer/Policy log std Mean        -1.99959
trainer/Policy log std Std          0.568839
trainer/Policy log std Max         -0.541198
trainer/Policy log std Min         -2.70813
trainer/Alpha                       0.0902805
trainer/Alpha Loss                 -0.318482
exploration/num steps total     42400
exploration/num paths total       424
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.737133
exploration/Rewards Std             1.16006
exploration/Rewards Max            -0.113878
exploration/Rewards Min            -9.30863
exploration/Returns Mean          -73.7133
exploration/Returns Std            37.8913
exploration/Returns Max           -35.822
exploration/Returns Min          -111.605
exploration/Actions Mean           -0.019912
exploration/Actions Std             0.215165
exploration/Actions Max             0.942349
exploration/Actions Min            -0.99666
exploration/Num Paths               2
exploration/Average Returns       -73.7133
evaluation/num steps total     211000
evaluation/num paths total       2110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.654881
evaluation/Rewards Std              1.0558
evaluation/Rewards Max             -0.324381
evaluation/Rewards Min             -9.79239
evaluation/Returns Mean           -65.4881
evaluation/Returns Std             24.5197
evaluation/Returns Max            -35.7922
evaluation/Returns Min           -111.014
evaluation/Actions Mean             0.00927801
evaluation/Actions Std              0.185803
evaluation/Actions Max              0.994264
evaluation/Actions Min             -0.994847
evaluation/Num Paths               10
evaluation/Average Returns        -65.4881
time/data storing (s)               0.00122152
time/evaluation sampling (s)        0.218863
time/exploration sampling (s)       0.0638986
time/logging (s)                    0.00332347
time/saving (s)                     0.00195299
time/training (s)                   0.761024
time/epoch (s)                      1.05028
time/total (s)                    225.051
Epoch                             210
-----------------------------  ---------------
2019-04-21 01:15:29.627724 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 211 finished
-----------------------------  ---------------
replay_buffer/size              42600
trainer/QF1 Loss                    0.622821
trainer/QF2 Loss                    0.527254
trainer/Policy Loss                41.95
trainer/Q1 Predictions Mean       -40.7577
trainer/Q1 Predictions Std         12.3419
trainer/Q1 Predictions Max        -30.348
trainer/Q1 Predictions Min       -112.353
trainer/Q2 Predictions Mean       -40.7796
trainer/Q2 Predictions Std         12.3897
trainer/Q2 Predictions Max        -30.3438
trainer/Q2 Predictions Min       -112.464
trainer/Q Targets Mean            -41.3189
trainer/Q Targets Std              12.3385
trainer/Q Targets Max             -30.6618
trainer/Q Targets Min            -111.176
trainer/Log Pis Mean                2.08539
trainer/Log Pis Std                 1.41976
trainer/Log Pis Max                 6.89164
trainer/Log Pis Min                -5.29511
trainer/Policy mu Mean              0.0110804
trainer/Policy mu Std               0.888806
trainer/Policy mu Max               2.6614
trainer/Policy mu Min              -3.16632
trainer/Policy log std Mean        -1.89871
trainer/Policy log std Std          0.620521
trainer/Policy log std Max         -0.241734
trainer/Policy log std Min         -2.74802
trainer/Alpha                       0.0898818
trainer/Alpha Loss                  0.20572
exploration/num steps total     42600
exploration/num paths total       426
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.576794
exploration/Rewards Std             0.459979
exploration/Rewards Max            -0.220826
exploration/Rewards Min            -5.16661
exploration/Returns Mean          -57.6794
exploration/Returns Std             5.795
exploration/Returns Max           -51.8844
exploration/Returns Min           -63.4744
exploration/Actions Mean            0.0112978
exploration/Actions Std             0.197306
exploration/Actions Max             0.985738
exploration/Actions Min            -0.925306
exploration/Num Paths               2
exploration/Average Returns       -57.6794
evaluation/num steps total     212000
evaluation/num paths total       2120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.657403
evaluation/Rewards Std              0.947071
evaluation/Rewards Max             -0.372796
evaluation/Rewards Min            -10.027
evaluation/Returns Mean           -65.7403
evaluation/Returns Std             19.3385
evaluation/Returns Max            -39.6034
evaluation/Returns Min           -101.403
evaluation/Actions Mean            -0.00245876
evaluation/Actions Std              0.192891
evaluation/Actions Max              0.993129
evaluation/Actions Min             -0.997539
evaluation/Num Paths               10
evaluation/Average Returns        -65.7403
time/data storing (s)               0.0016354
time/evaluation sampling (s)        0.222933
time/exploration sampling (s)       0.0638516
time/logging (s)                    0.00333208
time/saving (s)                     0.00184312
time/training (s)                   0.771872
time/epoch (s)                      1.06547
time/total (s)                    226.12
Epoch                             211
-----------------------------  ---------------
2019-04-21 01:15:30.699184 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size              42800
trainer/QF1 Loss                    0.11063
trainer/QF2 Loss                    0.108866
trainer/Policy Loss                41.582
trainer/Q1 Predictions Mean       -39.8898
trainer/Q1 Predictions Std          9.38367
trainer/Q1 Predictions Max        -30.5695
trainer/Q1 Predictions Min        -86.0004
trainer/Q2 Predictions Mean       -39.8792
trainer/Q2 Predictions Std          9.34797
trainer/Q2 Predictions Max        -30.5357
trainer/Q2 Predictions Min        -86.0262
trainer/Q Targets Mean            -40.0273
trainer/Q Targets Std               9.30521
trainer/Q Targets Max             -30.5781
trainer/Q Targets Min             -84.2061
trainer/Log Pis Mean                2.15983
trainer/Log Pis Std                 0.992486
trainer/Log Pis Max                 5.04715
trainer/Log Pis Min                -1.0792
trainer/Policy mu Mean             -0.0230803
trainer/Policy mu Std               0.769134
trainer/Policy mu Max               2.74669
trainer/Policy mu Min              -3.00534
trainer/Policy log std Mean        -2.02537
trainer/Policy log std Std          0.557046
trainer/Policy log std Max         -0.333451
trainer/Policy log std Min         -2.69799
trainer/Alpha                       0.0876799
trainer/Alpha Loss                  0.389037
exploration/num steps total     42800
exploration/num paths total       428
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.997163
exploration/Rewards Std             1.39082
exploration/Rewards Max            -0.358209
exploration/Rewards Min            -9.53254
exploration/Returns Mean          -99.7163
exploration/Returns Std             6.63431
exploration/Returns Max           -93.082
exploration/Returns Min          -106.351
exploration/Actions Mean           -0.0339292
exploration/Actions Std             0.251534
exploration/Actions Max             0.883224
exploration/Actions Min            -0.99509
exploration/Num Paths               2
exploration/Average Returns       -99.7163
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.686301
evaluation/Rewards Std              0.734663
evaluation/Rewards Max             -0.429452
evaluation/Rewards Min             -9.50816
evaluation/Returns Mean           -68.6301
evaluation/Returns Std             11.3771
evaluation/Returns Max            -58.537
evaluation/Returns Min            -90.8936
evaluation/Actions Mean             0.0086134
evaluation/Actions Std              0.157496
evaluation/Actions Max              0.993696
evaluation/Actions Min             -0.994763
evaluation/Num Paths               10
evaluation/Average Returns        -68.6301
time/data storing (s)               0.00121318
time/evaluation sampling (s)        0.22511
time/exploration sampling (s)       0.0633898
time/logging (s)                    0.00336519
time/saving (s)                     0.00157847
time/training (s)                   0.769303
time/epoch (s)                      1.06396
time/total (s)                    227.188
Epoch                             212
-----------------------------  ---------------
2019-04-21 01:15:31.772776 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 213 finished
-----------------------------  ---------------
replay_buffer/size              43000
trainer/QF1 Loss                   17.221
trainer/QF2 Loss                   17.2761
trainer/Policy Loss                39.4602
trainer/Q1 Predictions Mean       -37.9521
trainer/Q1 Predictions Std          8.37444
trainer/Q1 Predictions Max        -30.1149
trainer/Q1 Predictions Min        -68.4126
trainer/Q2 Predictions Mean       -37.937
trainer/Q2 Predictions Std          8.36794
trainer/Q2 Predictions Max        -30.0756
trainer/Q2 Predictions Min        -68.297
trainer/Q Targets Mean            -38.2041
trainer/Q Targets Std               9.3816
trainer/Q Targets Max              -0.961966
trainer/Q Targets Min             -68.6265
trainer/Log Pis Mean                2.1599
trainer/Log Pis Std                 1.19564
trainer/Log Pis Max                 6.43675
trainer/Log Pis Min                -1.53394
trainer/Policy mu Mean              0.0588142
trainer/Policy mu Std               0.74877
trainer/Policy mu Max               2.66933
trainer/Policy mu Min              -2.66242
trainer/Policy log std Mean        -2.03047
trainer/Policy log std Std          0.574655
trainer/Policy log std Max         -0.454546
trainer/Policy log std Min         -2.79847
trainer/Alpha                       0.0869005
trainer/Alpha Loss                  0.390628
exploration/num steps total     43000
exploration/num paths total       430
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.94499
exploration/Rewards Std             1.53701
exploration/Rewards Max            -0.186561
exploration/Rewards Min            -9.8553
exploration/Returns Mean          -94.499
exploration/Returns Std             7.77461
exploration/Returns Max           -86.7244
exploration/Returns Min          -102.274
exploration/Actions Mean            0.014847
exploration/Actions Std             0.260858
exploration/Actions Max             0.992545
exploration/Actions Min            -0.9901
exploration/Num Paths               2
exploration/Average Returns       -94.499
evaluation/num steps total     214000
evaluation/num paths total       2140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.816684
evaluation/Rewards Std              0.99117
evaluation/Rewards Max             -0.326962
evaluation/Rewards Min            -10.0342
evaluation/Returns Mean           -81.6684
evaluation/Returns Std             15.5403
evaluation/Returns Max            -58.7721
evaluation/Returns Min           -117.354
evaluation/Actions Mean            -0.0105984
evaluation/Actions Std              0.192991
evaluation/Actions Max              0.992773
evaluation/Actions Min             -0.993922
evaluation/Num Paths               10
evaluation/Average Returns        -81.6684
time/data storing (s)               0.0013499
time/evaluation sampling (s)        0.225822
time/exploration sampling (s)       0.0645963
time/logging (s)                    0.00336535
time/saving (s)                     0.0019779
time/training (s)                   0.768879
time/epoch (s)                      1.06599
time/total (s)                    228.258
Epoch                             213
-----------------------------  ---------------
2019-04-21 01:15:32.826536 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 214 finished
-----------------------------  ----------------
replay_buffer/size              43200
trainer/QF1 Loss                    8.84578
trainer/QF2 Loss                    8.84193
trainer/Policy Loss                38.4665
trainer/Q1 Predictions Mean       -36.9104
trainer/Q1 Predictions Std          9.19174
trainer/Q1 Predictions Max        -29.8752
trainer/Q1 Predictions Min       -105.864
trainer/Q2 Predictions Mean       -36.9206
trainer/Q2 Predictions Std          9.22326
trainer/Q2 Predictions Max        -29.8855
trainer/Q2 Predictions Min       -106.277
trainer/Q Targets Mean            -36.7292
trainer/Q Targets Std               9.81683
trainer/Q Targets Max              -0.466936
trainer/Q Targets Min            -107.099
trainer/Log Pis Mean                2.06925
trainer/Log Pis Std                 1.12294
trainer/Log Pis Max                 5.06503
trainer/Log Pis Min                -2.34261
trainer/Policy mu Mean              0.0751324
trainer/Policy mu Std               0.632732
trainer/Policy mu Max               2.12905
trainer/Policy mu Min              -3.28841
trainer/Policy log std Mean        -2.11818
trainer/Policy log std Std          0.529512
trainer/Policy log std Max         -0.586085
trainer/Policy log std Min         -2.83913
trainer/Alpha                       0.0876502
trainer/Alpha Loss                  0.168571
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.854968
exploration/Rewards Std             1.44522
exploration/Rewards Max            -0.243961
exploration/Rewards Min           -11.2508
exploration/Returns Mean          -85.4968
exploration/Returns Std             9.56342
exploration/Returns Max           -75.9333
exploration/Returns Min           -95.0602
exploration/Actions Mean           -0.00755842
exploration/Actions Std             0.25256
exploration/Actions Max             0.999404
exploration/Actions Min            -0.985894
exploration/Num Paths               2
exploration/Average Returns       -85.4968
evaluation/num steps total     215000
evaluation/num paths total       2150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.665377
evaluation/Rewards Std              0.769104
evaluation/Rewards Max             -0.371607
evaluation/Rewards Min             -8.76726
evaluation/Returns Mean           -66.5377
evaluation/Returns Std             13.2006
evaluation/Returns Max            -47.4161
evaluation/Returns Min            -92.8677
evaluation/Actions Mean             0.000960734
evaluation/Actions Std              0.18436
evaluation/Actions Max              0.993877
evaluation/Actions Min             -0.99508
evaluation/Num Paths               10
evaluation/Average Returns        -66.5377
time/data storing (s)               0.00124298
time/evaluation sampling (s)        0.227455
time/exploration sampling (s)       0.0644089
time/logging (s)                    0.00332236
time/saving (s)                     0.00194981
time/training (s)                   0.749145
time/epoch (s)                      1.04752
time/total (s)                    229.309
Epoch                             214
-----------------------------  ----------------
2019-04-21 01:15:33.891883 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 215 finished
-----------------------------  ---------------
replay_buffer/size              43400
trainer/QF1 Loss                    0.248478
trainer/QF2 Loss                    0.237369
trainer/Policy Loss                40.1478
trainer/Q1 Predictions Mean       -39.0492
trainer/Q1 Predictions Std          9.29244
trainer/Q1 Predictions Max        -29.6661
trainer/Q1 Predictions Min        -73.2859
trainer/Q2 Predictions Mean       -39.0437
trainer/Q2 Predictions Std          9.26647
trainer/Q2 Predictions Max        -29.6541
trainer/Q2 Predictions Min        -73.3798
trainer/Q Targets Mean            -39.3925
trainer/Q Targets Std               9.23473
trainer/Q Targets Max             -29.9216
trainer/Q Targets Min             -74.6411
trainer/Log Pis Mean                1.96042
trainer/Log Pis Std                 1.54474
trainer/Log Pis Max                 6.87728
trainer/Log Pis Min                -2.78317
trainer/Policy mu Mean              0.17754
trainer/Policy mu Std               0.855593
trainer/Policy mu Max               2.90909
trainer/Policy mu Min              -2.70967
trainer/Policy log std Mean        -1.961
trainer/Policy log std Std          0.614796
trainer/Policy log std Max         -0.454821
trainer/Policy log std Min         -2.75773
trainer/Alpha                       0.0881714
trainer/Alpha Loss                 -0.0961193
exploration/num steps total     43400
exploration/num paths total       434
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.586935
exploration/Rewards Std             0.86581
exploration/Rewards Max            -0.18183
exploration/Rewards Min            -7.35506
exploration/Returns Mean          -58.6935
exploration/Returns Std             6.09019
exploration/Returns Max           -52.6033
exploration/Returns Min           -64.7837
exploration/Actions Mean            0.0190612
exploration/Actions Std             0.210121
exploration/Actions Max             0.990696
exploration/Actions Min            -0.903575
exploration/Num Paths               2
exploration/Average Returns       -58.6935
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.696919
evaluation/Rewards Std              0.927455
evaluation/Rewards Max             -0.385314
evaluation/Rewards Min            -10.2459
evaluation/Returns Mean           -69.6919
evaluation/Returns Std             22.3885
evaluation/Returns Max            -39.9182
evaluation/Returns Min           -117.768
evaluation/Actions Mean            -0.00387604
evaluation/Actions Std              0.161864
evaluation/Actions Max              0.990896
evaluation/Actions Min             -0.995222
evaluation/Num Paths               10
evaluation/Average Returns        -69.6919
time/data storing (s)               0.00128497
time/evaluation sampling (s)        0.224756
time/exploration sampling (s)       0.0630674
time/logging (s)                    0.00335327
time/saving (s)                     0.00197142
time/training (s)                   0.76343
time/epoch (s)                      1.05786
time/total (s)                    230.371
Epoch                             215
-----------------------------  ---------------
2019-04-21 01:15:34.962464 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 216 finished
-----------------------------  ---------------
replay_buffer/size              43600
trainer/QF1 Loss                   17.4936
trainer/QF2 Loss                   17.4544
trainer/Policy Loss                39.675
trainer/Q1 Predictions Mean       -38.4601
trainer/Q1 Predictions Std         10.2192
trainer/Q1 Predictions Max        -29.1419
trainer/Q1 Predictions Min       -101.14
trainer/Q2 Predictions Mean       -38.4881
trainer/Q2 Predictions Std         10.2304
trainer/Q2 Predictions Max        -29.1974
trainer/Q2 Predictions Min       -101.566
trainer/Q Targets Mean            -38.511
trainer/Q Targets Std              10.7413
trainer/Q Targets Max              -1.02673
trainer/Q Targets Min            -102.457
trainer/Log Pis Mean                1.93214
trainer/Log Pis Std                 1.38621
trainer/Log Pis Max                 7.19097
trainer/Log Pis Min                -2.72941
trainer/Policy mu Mean             -0.111634
trainer/Policy mu Std               0.733328
trainer/Policy mu Max               2.63351
trainer/Policy mu Min              -3.27247
trainer/Policy log std Mean        -2.05587
trainer/Policy log std Std          0.551465
trainer/Policy log std Max         -0.515687
trainer/Policy log std Min         -2.69786
trainer/Alpha                       0.0901093
trainer/Alpha Loss                 -0.163311
exploration/num steps total     43600
exploration/num paths total       436
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.772811
exploration/Rewards Std             1.25751
exploration/Rewards Max            -0.161885
exploration/Rewards Min           -10.0153
exploration/Returns Mean          -77.2811
exploration/Returns Std            15.0185
exploration/Returns Max           -62.2626
exploration/Returns Min           -92.2996
exploration/Actions Mean            0.0367198
exploration/Actions Std             0.222119
exploration/Actions Max             0.998446
exploration/Actions Min            -0.813999
exploration/Num Paths               2
exploration/Average Returns       -77.2811
evaluation/num steps total     217000
evaluation/num paths total       2170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.697652
evaluation/Rewards Std              0.787516
evaluation/Rewards Max             -0.27757
evaluation/Rewards Min             -9.22745
evaluation/Returns Mean           -69.7652
evaluation/Returns Std             11.5786
evaluation/Returns Max            -44.5932
evaluation/Returns Min            -83.0911
evaluation/Actions Mean            -0.00774227
evaluation/Actions Std              0.172379
evaluation/Actions Max              0.991685
evaluation/Actions Min             -0.989439
evaluation/Num Paths               10
evaluation/Average Returns        -69.7652
time/data storing (s)               0.00131849
time/evaluation sampling (s)        0.229157
time/exploration sampling (s)       0.0656043
time/logging (s)                    0.00336176
time/saving (s)                     0.00195834
time/training (s)                   0.761731
time/epoch (s)                      1.06313
time/total (s)                    231.438
Epoch                             216
-----------------------------  ---------------
2019-04-21 01:15:36.034027 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 217 finished
-----------------------------  ---------------
replay_buffer/size              43800
trainer/QF1 Loss                   26.856
trainer/QF2 Loss                   26.8421
trainer/Policy Loss                39.8156
trainer/Q1 Predictions Mean       -38.5317
trainer/Q1 Predictions Std          8.93366
trainer/Q1 Predictions Max        -29.6454
trainer/Q1 Predictions Min        -90.2564
trainer/Q2 Predictions Mean       -38.5459
trainer/Q2 Predictions Std          8.92979
trainer/Q2 Predictions Max        -29.6059
trainer/Q2 Predictions Min        -90.2938
trainer/Q Targets Mean            -37.7962
trainer/Q Targets Std              10.236
trainer/Q Targets Max              -1.24734
trainer/Q Targets Min             -89.1729
trainer/Log Pis Mean                2.06073
trainer/Log Pis Std                 0.984398
trainer/Log Pis Max                 4.481
trainer/Log Pis Min                -1.13911
trainer/Policy mu Mean              0.0304971
trainer/Policy mu Std               0.688582
trainer/Policy mu Max               2.65085
trainer/Policy mu Min              -2.84469
trainer/Policy log std Mean        -2.07021
trainer/Policy log std Std          0.515257
trainer/Policy log std Max         -0.479978
trainer/Policy log std Min         -2.66121
trainer/Alpha                       0.0911928
trainer/Alpha Loss                  0.145433
exploration/num steps total     43800
exploration/num paths total       438
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.938499
exploration/Rewards Std             1.36967
exploration/Rewards Max            -0.281922
exploration/Rewards Min           -10.5943
exploration/Returns Mean          -93.8499
exploration/Returns Std            16.6308
exploration/Returns Max           -77.2191
exploration/Returns Min          -110.481
exploration/Actions Mean           -0.0618543
exploration/Actions Std             0.268693
exploration/Actions Max             0.482676
exploration/Actions Min            -0.997008
exploration/Num Paths               2
exploration/Average Returns       -93.8499
evaluation/num steps total     218000
evaluation/num paths total       2180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.709622
evaluation/Rewards Std              0.965548
evaluation/Rewards Max             -0.338852
evaluation/Rewards Min            -10.3523
evaluation/Returns Mean           -70.9622
evaluation/Returns Std             17.1861
evaluation/Returns Max            -41.5579
evaluation/Returns Min           -103.937
evaluation/Actions Mean            -0.00933501
evaluation/Actions Std              0.195726
evaluation/Actions Max              0.992873
evaluation/Actions Min             -0.997212
evaluation/Num Paths               10
evaluation/Average Returns        -70.9622
time/data storing (s)               0.0012308
time/evaluation sampling (s)        0.22199
time/exploration sampling (s)       0.0645625
time/logging (s)                    0.0033618
time/saving (s)                     0.00171729
time/training (s)                   0.771428
time/epoch (s)                      1.06429
time/total (s)                    232.507
Epoch                             217
-----------------------------  ---------------
2019-04-21 01:15:37.105534 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 218 finished
-----------------------------  ---------------
replay_buffer/size              44000
trainer/QF1 Loss                   17.0914
trainer/QF2 Loss                   17.1111
trainer/Policy Loss                40.7687
trainer/Q1 Predictions Mean       -39.5973
trainer/Q1 Predictions Std         12.458
trainer/Q1 Predictions Max        -29.1989
trainer/Q1 Predictions Min       -102.02
trainer/Q2 Predictions Mean       -39.596
trainer/Q2 Predictions Std         12.4562
trainer/Q2 Predictions Max        -29.248
trainer/Q2 Predictions Min       -102.345
trainer/Q Targets Mean            -39.3003
trainer/Q Targets Std              13.6773
trainer/Q Targets Max              -0.509385
trainer/Q Targets Min            -103.179
trainer/Log Pis Mean                2.01472
trainer/Log Pis Std                 1.38479
trainer/Log Pis Max                 5.4303
trainer/Log Pis Min                -5.10421
trainer/Policy mu Mean             -0.00966309
trainer/Policy mu Std               0.948495
trainer/Policy mu Max               2.71426
trainer/Policy mu Min              -3.03306
trainer/Policy log std Mean        -1.86768
trainer/Policy log std Std          0.667806
trainer/Policy log std Max         -0.326714
trainer/Policy log std Min         -2.69601
trainer/Alpha                       0.0921019
trainer/Alpha Loss                  0.0351097
exploration/num steps total     44000
exploration/num paths total       440
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.614649
exploration/Rewards Std             1.22687
exploration/Rewards Max            -0.110828
exploration/Rewards Min            -9.25223
exploration/Returns Mean          -61.4649
exploration/Returns Std            14.9922
exploration/Returns Max           -46.4727
exploration/Returns Min           -76.457
exploration/Actions Mean            0.0389076
exploration/Actions Std             0.240857
exploration/Actions Max             0.992129
exploration/Actions Min            -0.797667
exploration/Num Paths               2
exploration/Average Returns       -61.4649
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.570789
evaluation/Rewards Std              0.757847
evaluation/Rewards Max             -0.302662
evaluation/Rewards Min             -8.21139
evaluation/Returns Mean           -57.0789
evaluation/Returns Std             19.7719
evaluation/Returns Max            -31.5043
evaluation/Returns Min            -85.5358
evaluation/Actions Mean            -0.00697371
evaluation/Actions Std              0.161739
evaluation/Actions Max              0.989259
evaluation/Actions Min             -0.993742
evaluation/Num Paths               10
evaluation/Average Returns        -57.0789
time/data storing (s)               0.00175411
time/evaluation sampling (s)        0.22357
time/exploration sampling (s)       0.0681044
time/logging (s)                    0.003344
time/saving (s)                     0.00160001
time/training (s)                   0.765502
time/epoch (s)                      1.06387
time/total (s)                    233.575
Epoch                             218
-----------------------------  ---------------
2019-04-21 01:15:38.168312 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 219 finished
-----------------------------  ---------------
replay_buffer/size              44200
trainer/QF1 Loss                    0.230887
trainer/QF2 Loss                    0.227931
trainer/Policy Loss                40.1942
trainer/Q1 Predictions Mean       -38.9288
trainer/Q1 Predictions Std          9.21116
trainer/Q1 Predictions Max        -29.2161
trainer/Q1 Predictions Min        -94.5556
trainer/Q2 Predictions Mean       -38.9644
trainer/Q2 Predictions Std          9.2279
trainer/Q2 Predictions Max        -29.2031
trainer/Q2 Predictions Min        -94.8164
trainer/Q Targets Mean            -39.1503
trainer/Q Targets Std               9.35234
trainer/Q Targets Max             -29.1957
trainer/Q Targets Min             -94.7103
trainer/Log Pis Mean                2.08665
trainer/Log Pis Std                 1.25106
trainer/Log Pis Max                 7.19539
trainer/Log Pis Min                -2.69043
trainer/Policy mu Mean              0.0371551
trainer/Policy mu Std               0.79559
trainer/Policy mu Max               2.68823
trainer/Policy mu Min              -2.66797
trainer/Policy log std Mean        -2.00642
trainer/Policy log std Std          0.594567
trainer/Policy log std Max         -0.404317
trainer/Policy log std Min         -2.8863
trainer/Alpha                       0.0925994
trainer/Alpha Loss                  0.20619
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.530721
exploration/Rewards Std             1.2676
exploration/Rewards Max            -0.0518331
exploration/Rewards Min           -10.401
exploration/Returns Mean          -53.0721
exploration/Returns Std            23.5554
exploration/Returns Max           -29.5168
exploration/Returns Min           -76.6275
exploration/Actions Mean            0.0357261
exploration/Actions Std             0.217417
exploration/Actions Max             0.998936
exploration/Actions Min            -0.915076
exploration/Num Paths               2
exploration/Average Returns       -53.0721
evaluation/num steps total     220000
evaluation/num paths total       2200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.563349
evaluation/Rewards Std              0.736262
evaluation/Rewards Max             -0.252027
evaluation/Rewards Min             -9.37485
evaluation/Returns Mean           -56.3349
evaluation/Returns Std             13.9529
evaluation/Returns Max            -35.8866
evaluation/Returns Min            -73.3829
evaluation/Actions Mean             0.00547842
evaluation/Actions Std              0.166687
evaluation/Actions Max              0.993213
evaluation/Actions Min             -0.971469
evaluation/Num Paths               10
evaluation/Average Returns        -56.3349
time/data storing (s)               0.00141747
time/evaluation sampling (s)        0.226103
time/exploration sampling (s)       0.065277
time/logging (s)                    0.00337102
time/saving (s)                     0.00193444
time/training (s)                   0.757092
time/epoch (s)                      1.05519
time/total (s)                    234.634
Epoch                             219
-----------------------------  ---------------
2019-04-21 01:15:39.214251 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 220 finished
-----------------------------  ----------------
replay_buffer/size              44400
trainer/QF1 Loss                    8.25388
trainer/QF2 Loss                    8.31544
trainer/Policy Loss                39.0456
trainer/Q1 Predictions Mean       -37.776
trainer/Q1 Predictions Std          9.89254
trainer/Q1 Predictions Max        -28.7623
trainer/Q1 Predictions Min        -95.6142
trainer/Q2 Predictions Mean       -37.7771
trainer/Q2 Predictions Std          9.8594
trainer/Q2 Predictions Max        -28.7503
trainer/Q2 Predictions Min        -95.5094
trainer/Q Targets Mean            -37.7321
trainer/Q Targets Std              10.4261
trainer/Q Targets Max              -0.477799
trainer/Q Targets Min             -96.1033
trainer/Log Pis Mean                1.9424
trainer/Log Pis Std                 1.18341
trainer/Log Pis Max                 7.36257
trainer/Log Pis Min                -2.01397
trainer/Policy mu Mean             -0.00405402
trainer/Policy mu Std               0.665231
trainer/Policy mu Max               2.56656
trainer/Policy mu Min              -3.21204
trainer/Policy log std Mean        -2.06177
trainer/Policy log std Std          0.508038
trainer/Policy log std Max         -0.342183
trainer/Policy log std Min         -2.7167
trainer/Alpha                       0.0926755
trainer/Alpha Loss                 -0.137006
exploration/num steps total     44400
exploration/num paths total       444
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.744015
exploration/Rewards Std             0.665662
exploration/Rewards Max            -0.363012
exploration/Rewards Min            -6.21027
exploration/Returns Mean          -74.4015
exploration/Returns Std             3.14368
exploration/Returns Max           -71.2578
exploration/Returns Min           -77.5452
exploration/Actions Mean            0.004279
exploration/Actions Std             0.238484
exploration/Actions Max             0.998805
exploration/Actions Min            -0.989999
exploration/Num Paths               2
exploration/Average Returns       -74.4015
evaluation/num steps total     221000
evaluation/num paths total       2210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.618326
evaluation/Rewards Std              0.947901
evaluation/Rewards Max             -0.319173
evaluation/Rewards Min             -9.52088
evaluation/Returns Mean           -61.8326
evaluation/Returns Std             23.6183
evaluation/Returns Max            -36.4496
evaluation/Returns Min           -105.702
evaluation/Actions Mean             0.000594314
evaluation/Actions Std              0.185829
evaluation/Actions Max              0.993126
evaluation/Actions Min             -0.994144
evaluation/Num Paths               10
evaluation/Average Returns        -61.8326
time/data storing (s)               0.00157142
time/evaluation sampling (s)        0.225899
time/exploration sampling (s)       0.0656609
time/logging (s)                    0.00332322
time/saving (s)                     0.00193874
time/training (s)                   0.739961
time/epoch (s)                      1.03835
time/total (s)                    235.676
Epoch                             220
-----------------------------  ----------------
2019-04-21 01:15:40.289802 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 221 finished
-----------------------------  ---------------
replay_buffer/size              44600
trainer/QF1 Loss                   16.8318
trainer/QF2 Loss                   16.769
trainer/Policy Loss                39.1052
trainer/Q1 Predictions Mean       -37.8459
trainer/Q1 Predictions Std          8.05827
trainer/Q1 Predictions Max        -28.4861
trainer/Q1 Predictions Min        -70.5143
trainer/Q2 Predictions Mean       -37.8362
trainer/Q2 Predictions Std          8.04927
trainer/Q2 Predictions Max        -28.4331
trainer/Q2 Predictions Min        -70.8941
trainer/Q Targets Mean            -37.7965
trainer/Q Targets Std               8.77908
trainer/Q Targets Max              -0.901253
trainer/Q Targets Min             -70.6738
trainer/Log Pis Mean                2.02146
trainer/Log Pis Std                 1.41461
trainer/Log Pis Max                 6.94739
trainer/Log Pis Min                -1.61655
trainer/Policy mu Mean              0.0271642
trainer/Policy mu Std               0.725239
trainer/Policy mu Max               2.4343
trainer/Policy mu Min              -2.57177
trainer/Policy log std Mean        -2.00563
trainer/Policy log std Std          0.57203
trainer/Policy log std Max         -0.333473
trainer/Policy log std Min         -2.75785
trainer/Alpha                       0.0923706
trainer/Alpha Loss                  0.051125
exploration/num steps total     44600
exploration/num paths total       446
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.850304
exploration/Rewards Std             1.35718
exploration/Rewards Max            -0.14627
exploration/Rewards Min            -9.22279
exploration/Returns Mean          -85.0304
exploration/Returns Std             8.57613
exploration/Returns Max           -76.4542
exploration/Returns Min           -93.6065
exploration/Actions Mean            0.0115536
exploration/Actions Std             0.255525
exploration/Actions Max             0.997973
exploration/Actions Min            -0.997217
exploration/Num Paths               2
exploration/Average Returns       -85.0304
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.649082
evaluation/Rewards Std              0.95062
evaluation/Rewards Max             -0.295016
evaluation/Rewards Min            -10.1355
evaluation/Returns Mean           -64.9082
evaluation/Returns Std             24.6699
evaluation/Returns Max            -31.337
evaluation/Returns Min           -104.809
evaluation/Actions Mean             0.00393446
evaluation/Actions Std              0.172768
evaluation/Actions Max              0.995661
evaluation/Actions Min             -0.994964
evaluation/Num Paths               10
evaluation/Average Returns        -64.9082
time/data storing (s)               0.00123951
time/evaluation sampling (s)        0.223203
time/exploration sampling (s)       0.0658365
time/logging (s)                    0.00337521
time/saving (s)                     0.00194536
time/training (s)                   0.772386
time/epoch (s)                      1.06799
time/total (s)                    236.748
Epoch                             221
-----------------------------  ---------------
2019-04-21 01:15:41.361011 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 222 finished
-----------------------------  ---------------
replay_buffer/size              44800
trainer/QF1 Loss                    0.423335
trainer/QF2 Loss                    0.475438
trainer/Policy Loss                38.5103
trainer/Q1 Predictions Mean       -37.2468
trainer/Q1 Predictions Std         10.994
trainer/Q1 Predictions Max        -28.1782
trainer/Q1 Predictions Min        -97.2566
trainer/Q2 Predictions Mean       -37.2375
trainer/Q2 Predictions Std         10.9564
trainer/Q2 Predictions Max        -28.1781
trainer/Q2 Predictions Min        -97.4738
trainer/Q Targets Mean            -37.84
trainer/Q Targets Std              11.1154
trainer/Q Targets Max             -28.6214
trainer/Q Targets Min             -98.0799
trainer/Log Pis Mean                1.95378
trainer/Log Pis Std                 1.53176
trainer/Log Pis Max                 8.54585
trainer/Log Pis Min                -3.08799
trainer/Policy mu Mean              0.0791043
trainer/Policy mu Std               0.798234
trainer/Policy mu Max               3.15035
trainer/Policy mu Min              -3.25259
trainer/Policy log std Mean        -2.02772
trainer/Policy log std Std          0.617822
trainer/Policy log std Max         -0.36753
trainer/Policy log std Min         -2.788
trainer/Alpha                       0.0930547
trainer/Alpha Loss                 -0.109752
exploration/num steps total     44800
exploration/num paths total       448
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.807806
exploration/Rewards Std             1.38808
exploration/Rewards Max            -0.129836
exploration/Rewards Min           -11.0521
exploration/Returns Mean          -80.7806
exploration/Returns Std            40.9975
exploration/Returns Max           -39.7831
exploration/Returns Min          -121.778
exploration/Actions Mean           -0.00363759
exploration/Actions Std             0.246442
exploration/Actions Max             0.994087
exploration/Actions Min            -0.996807
exploration/Num Paths               2
exploration/Average Returns       -80.7806
evaluation/num steps total     223000
evaluation/num paths total       2230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.639194
evaluation/Rewards Std              0.928846
evaluation/Rewards Max             -0.322512
evaluation/Rewards Min            -10.891
evaluation/Returns Mean           -63.9194
evaluation/Returns Std             13.1653
evaluation/Returns Max            -47.2279
evaluation/Returns Min            -89.3146
evaluation/Actions Mean             0.0159663
evaluation/Actions Std              0.1823
evaluation/Actions Max              0.997974
evaluation/Actions Min             -0.99527
evaluation/Num Paths               10
evaluation/Average Returns        -63.9194
time/data storing (s)               0.00136821
time/evaluation sampling (s)        0.219891
time/exploration sampling (s)       0.0648569
time/logging (s)                    0.00338991
time/saving (s)                     0.00155023
time/training (s)                   0.772771
time/epoch (s)                      1.06383
time/total (s)                    237.816
Epoch                             222
-----------------------------  ---------------
2019-04-21 01:15:42.421394 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 223 finished
-----------------------------  ---------------
replay_buffer/size              45000
trainer/QF1 Loss                    0.49556
trainer/QF2 Loss                    0.449737
trainer/Policy Loss                39.4327
trainer/Q1 Predictions Mean       -38.1562
trainer/Q1 Predictions Std         11.1074
trainer/Q1 Predictions Max        -28.1187
trainer/Q1 Predictions Min       -114.84
trainer/Q2 Predictions Mean       -38.1812
trainer/Q2 Predictions Std         11.1152
trainer/Q2 Predictions Max        -28.1381
trainer/Q2 Predictions Min       -114.847
trainer/Q Targets Mean            -38.4477
trainer/Q Targets Std              10.6927
trainer/Q Targets Max             -28.4185
trainer/Q Targets Min            -109.523
trainer/Log Pis Mean                1.94064
trainer/Log Pis Std                 1.10935
trainer/Log Pis Max                 5.89372
trainer/Log Pis Min                -2.66527
trainer/Policy mu Mean              0.00324416
trainer/Policy mu Std               0.719522
trainer/Policy mu Max               2.76483
trainer/Policy mu Min              -3.20176
trainer/Policy log std Mean        -2.02173
trainer/Policy log std Std          0.53937
trainer/Policy log std Max         -0.417855
trainer/Policy log std Min         -2.69484
trainer/Alpha                       0.0922018
trainer/Alpha Loss                 -0.141511
exploration/num steps total     45000
exploration/num paths total       450
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.701381
exploration/Rewards Std             0.980092
exploration/Rewards Max            -0.150505
exploration/Rewards Min            -7.39205
exploration/Returns Mean          -70.1381
exploration/Returns Std            16.2229
exploration/Returns Max           -53.9152
exploration/Returns Min           -86.3611
exploration/Actions Mean            0.0198537
exploration/Actions Std             0.240846
exploration/Actions Max             0.995796
exploration/Actions Min            -0.998115
exploration/Num Paths               2
exploration/Average Returns       -70.1381
evaluation/num steps total     224000
evaluation/num paths total       2240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.583019
evaluation/Rewards Std              0.906738
evaluation/Rewards Max             -0.302841
evaluation/Rewards Min             -9.07135
evaluation/Returns Mean           -58.3019
evaluation/Returns Std             14.7518
evaluation/Returns Max            -37.0887
evaluation/Returns Min            -77.923
evaluation/Actions Mean             0.0120834
evaluation/Actions Std              0.1839
evaluation/Actions Max              0.992745
evaluation/Actions Min             -0.981421
evaluation/Num Paths               10
evaluation/Average Returns        -58.3019
time/data storing (s)               0.0012421
time/evaluation sampling (s)        0.223405
time/exploration sampling (s)       0.0654294
time/logging (s)                    0.00339195
time/saving (s)                     0.00196762
time/training (s)                   0.757387
time/epoch (s)                      1.05282
time/total (s)                    238.873
Epoch                             223
-----------------------------  ---------------
2019-04-21 01:15:43.489359 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 224 finished
-----------------------------  ---------------
replay_buffer/size              45200
trainer/QF1 Loss                    0.126614
trainer/QF2 Loss                    0.12238
trainer/Policy Loss                37.9693
trainer/Q1 Predictions Mean       -36.7134
trainer/Q1 Predictions Std          7.03994
trainer/Q1 Predictions Max        -27.9316
trainer/Q1 Predictions Min        -63.033
trainer/Q2 Predictions Mean       -36.7201
trainer/Q2 Predictions Std          7.04566
trainer/Q2 Predictions Max        -27.8822
trainer/Q2 Predictions Min        -62.8046
trainer/Q Targets Mean            -36.9752
trainer/Q Targets Std               7.07233
trainer/Q Targets Max             -28.1317
trainer/Q Targets Min             -62.7357
trainer/Log Pis Mean                1.86343
trainer/Log Pis Std                 1.12161
trainer/Log Pis Max                 5.25054
trainer/Log Pis Min                -2.06555
trainer/Policy mu Mean              0.0183946
trainer/Policy mu Std               0.622849
trainer/Policy mu Max               2.75583
trainer/Policy mu Min              -2.00435
trainer/Policy log std Mean        -2.08204
trainer/Policy log std Std          0.510204
trainer/Policy log std Max         -0.613954
trainer/Policy log std Min         -2.77164
trainer/Alpha                       0.0933053
trainer/Alpha Loss                 -0.32394
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.534766
exploration/Rewards Std             0.488284
exploration/Rewards Max            -0.166373
exploration/Rewards Min            -4.98425
exploration/Returns Mean          -53.4766
exploration/Returns Std             8.12549
exploration/Returns Max           -45.3511
exploration/Returns Min           -61.6021
exploration/Actions Mean            0.0236859
exploration/Actions Std             0.185505
exploration/Actions Max             0.995664
exploration/Actions Min            -0.58037
exploration/Num Paths               2
exploration/Average Returns       -53.4766
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.626085
evaluation/Rewards Std              0.967139
evaluation/Rewards Max             -0.284048
evaluation/Rewards Min             -8.70666
evaluation/Returns Mean           -62.6085
evaluation/Returns Std             18.6313
evaluation/Returns Max            -33.3996
evaluation/Returns Min            -95.0351
evaluation/Actions Mean             0.0166572
evaluation/Actions Std              0.18846
evaluation/Actions Max              0.994087
evaluation/Actions Min             -0.990604
evaluation/Num Paths               10
evaluation/Average Returns        -62.6085
time/data storing (s)               0.00161306
time/evaluation sampling (s)        0.220435
time/exploration sampling (s)       0.0659464
time/logging (s)                    0.00335954
time/saving (s)                     0.00196093
time/training (s)                   0.766985
time/epoch (s)                      1.0603
time/total (s)                    239.937
Epoch                             224
-----------------------------  ---------------
2019-04-21 01:15:44.560073 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 225 finished
-----------------------------  ---------------
replay_buffer/size              45400
trainer/QF1 Loss                   16.3982
trainer/QF2 Loss                   16.2926
trainer/Policy Loss                38.6795
trainer/Q1 Predictions Mean       -37.2634
trainer/Q1 Predictions Std         10.1343
trainer/Q1 Predictions Max        -27.7973
trainer/Q1 Predictions Min        -88.2405
trainer/Q2 Predictions Mean       -37.3081
trainer/Q2 Predictions Std         10.2871
trainer/Q2 Predictions Max        -27.8064
trainer/Q2 Predictions Min        -89.9427
trainer/Q Targets Mean            -37.3456
trainer/Q Targets Std              11.0225
trainer/Q Targets Max              -0.694162
trainer/Q Targets Min             -90.731
trainer/Log Pis Mean                1.99656
trainer/Log Pis Std                 1.20275
trainer/Log Pis Max                 5.65853
trainer/Log Pis Min                -2.02077
trainer/Policy mu Mean              0.0017599
trainer/Policy mu Std               0.815931
trainer/Policy mu Max               2.65901
trainer/Policy mu Min              -3.22255
trainer/Policy log std Mean        -1.93553
trainer/Policy log std Std          0.603765
trainer/Policy log std Max         -0.519669
trainer/Policy log std Min         -2.77974
trainer/Alpha                       0.0939201
trainer/Alpha Loss                 -0.00814521
exploration/num steps total     45400
exploration/num paths total       454
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.776659
exploration/Rewards Std             1.27053
exploration/Rewards Max            -0.0753269
exploration/Rewards Min           -10.1532
exploration/Returns Mean          -77.6659
exploration/Returns Std             3.32288
exploration/Returns Max           -74.343
exploration/Returns Min           -80.9888
exploration/Actions Mean           -0.00714092
exploration/Actions Std             0.250449
exploration/Actions Max             0.995534
exploration/Actions Min            -0.997526
exploration/Num Paths               2
exploration/Average Returns       -77.6659
evaluation/num steps total     226000
evaluation/num paths total       2260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.653841
evaluation/Rewards Std              0.773291
evaluation/Rewards Max             -0.253066
evaluation/Rewards Min             -7.76295
evaluation/Returns Mean           -65.3841
evaluation/Returns Std             20.4659
evaluation/Returns Max            -30.9889
evaluation/Returns Min            -91.4587
evaluation/Actions Mean             0.00906154
evaluation/Actions Std              0.175694
evaluation/Actions Max              0.991759
evaluation/Actions Min             -0.991322
evaluation/Num Paths               10
evaluation/Average Returns        -65.3841
time/data storing (s)               0.00135836
time/evaluation sampling (s)        0.224016
time/exploration sampling (s)       0.0662389
time/logging (s)                    0.00343485
time/saving (s)                     0.00195891
time/training (s)                   0.767076
time/epoch (s)                      1.06408
time/total (s)                    241.005
Epoch                             225
-----------------------------  ---------------
2019-04-21 01:15:45.632921 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 226 finished
-----------------------------  ---------------
replay_buffer/size              45600
trainer/QF1 Loss                    0.669515
trainer/QF2 Loss                    0.741456
trainer/Policy Loss                39.4752
trainer/Q1 Predictions Mean       -38.0341
trainer/Q1 Predictions Std         10.356
trainer/Q1 Predictions Max        -27.5713
trainer/Q1 Predictions Min        -87.8502
trainer/Q2 Predictions Mean       -38.03
trainer/Q2 Predictions Std         10.3037
trainer/Q2 Predictions Max        -27.5919
trainer/Q2 Predictions Min        -87.2528
trainer/Q Targets Mean            -38.5979
trainer/Q Targets Std              10.7421
trainer/Q Targets Max             -27.8066
trainer/Q Targets Min             -92.59
trainer/Log Pis Mean                2.18686
trainer/Log Pis Std                 1.28559
trainer/Log Pis Max                 7.81671
trainer/Log Pis Min                -2.43527
trainer/Policy mu Mean              0.00420828
trainer/Policy mu Std               0.824851
trainer/Policy mu Max               3.01781
trainer/Policy mu Min              -2.65964
trainer/Policy log std Mean        -2.0047
trainer/Policy log std Std          0.598085
trainer/Policy log std Max         -0.301218
trainer/Policy log std Min         -2.73785
trainer/Alpha                       0.0935037
trainer/Alpha Loss                  0.442826
exploration/num steps total     45600
exploration/num paths total       456
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.713741
exploration/Rewards Std             1.25896
exploration/Rewards Max            -0.192637
exploration/Rewards Min            -9.97728
exploration/Returns Mean          -71.3741
exploration/Returns Std            13.4609
exploration/Returns Max           -57.9132
exploration/Returns Min           -84.835
exploration/Actions Mean            0.0367987
exploration/Actions Std             0.210096
exploration/Actions Max             0.998226
exploration/Actions Min            -0.376673
exploration/Num Paths               2
exploration/Average Returns       -71.3741
evaluation/num steps total     227000
evaluation/num paths total       2270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.580236
evaluation/Rewards Std              0.828893
evaluation/Rewards Max             -0.280222
evaluation/Rewards Min             -9.64427
evaluation/Returns Mean           -58.0236
evaluation/Returns Std             13.0924
evaluation/Returns Max            -30.7218
evaluation/Returns Min            -80.2437
evaluation/Actions Mean             0.0130664
evaluation/Actions Std              0.153755
evaluation/Actions Max              0.994315
evaluation/Actions Min             -0.981385
evaluation/Num Paths               10
evaluation/Average Returns        -58.0236
time/data storing (s)               0.00120984
time/evaluation sampling (s)        0.226033
time/exploration sampling (s)       0.064164
time/logging (s)                    0.00319983
time/saving (s)                     0.00194238
time/training (s)                   0.768354
time/epoch (s)                      1.0649
time/total (s)                    242.074
Epoch                             226
-----------------------------  ---------------
2019-04-21 01:15:46.704057 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 227 finished
-----------------------------  ----------------
replay_buffer/size              45800
trainer/QF1 Loss                    7.51122
trainer/QF2 Loss                    7.47255
trainer/Policy Loss                37.3567
trainer/Q1 Predictions Mean       -35.8549
trainer/Q1 Predictions Std          7.85026
trainer/Q1 Predictions Max        -27.2276
trainer/Q1 Predictions Min        -64.2678
trainer/Q2 Predictions Mean       -35.8697
trainer/Q2 Predictions Std          7.81307
trainer/Q2 Predictions Max        -27.2591
trainer/Q2 Predictions Min        -64.2823
trainer/Q Targets Mean            -35.8809
trainer/Q Targets Std               8.49659
trainer/Q Targets Max              -0.599442
trainer/Q Targets Min             -63.9142
trainer/Log Pis Mean                1.94303
trainer/Log Pis Std                 1.1917
trainer/Log Pis Max                 5.20818
trainer/Log Pis Min                -1.795
trainer/Policy mu Mean              0.0394849
trainer/Policy mu Std               0.700527
trainer/Policy mu Max               2.84173
trainer/Policy mu Min              -2.48272
trainer/Policy log std Mean        -2.04204
trainer/Policy log std Std          0.560052
trainer/Policy log std Max         -0.538979
trainer/Policy log std Min         -2.7866
trainer/Alpha                       0.0927488
trainer/Alpha Loss                 -0.135459
exploration/num steps total     45800
exploration/num paths total       458
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.388827
exploration/Rewards Std             0.333789
exploration/Rewards Max            -0.196436
exploration/Rewards Min            -3.42906
exploration/Returns Mean          -38.8827
exploration/Returns Std             2.32613
exploration/Returns Max           -36.5565
exploration/Returns Min           -41.2088
exploration/Actions Mean           -7.65946e-05
exploration/Actions Std             0.16212
exploration/Actions Max             0.937721
exploration/Actions Min            -0.977814
exploration/Num Paths               2
exploration/Average Returns       -38.8827
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.528892
evaluation/Rewards Std              0.606371
evaluation/Rewards Max             -0.25867
evaluation/Rewards Min             -7.61702
evaluation/Returns Mean           -52.8892
evaluation/Returns Std             16.2379
evaluation/Returns Max            -31.287
evaluation/Returns Min            -75.528
evaluation/Actions Mean             0.00556642
evaluation/Actions Std              0.157483
evaluation/Actions Max              0.992136
evaluation/Actions Min             -0.97558
evaluation/Num Paths               10
evaluation/Average Returns        -52.8892
time/data storing (s)               0.00122746
time/evaluation sampling (s)        0.218728
time/exploration sampling (s)       0.0655445
time/logging (s)                    0.00337505
time/saving (s)                     0.00196193
time/training (s)                   0.773859
time/epoch (s)                      1.0647
time/total (s)                    243.142
Epoch                             227
-----------------------------  ----------------
2019-04-21 01:15:47.853393 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 228 finished
-----------------------------  ---------------
replay_buffer/size              46000
trainer/QF1 Loss                   32.0927
trainer/QF2 Loss                   32.153
trainer/Policy Loss                38.5305
trainer/Q1 Predictions Mean       -37.0563
trainer/Q1 Predictions Std         12.2113
trainer/Q1 Predictions Max        -27.1316
trainer/Q1 Predictions Min       -111.315
trainer/Q2 Predictions Mean       -37.0882
trainer/Q2 Predictions Std         12.3022
trainer/Q2 Predictions Max        -27.096
trainer/Q2 Predictions Min       -111.844
trainer/Q Targets Mean            -36.6185
trainer/Q Targets Std              13.0457
trainer/Q Targets Max              -0.724903
trainer/Q Targets Min            -108.539
trainer/Log Pis Mean                2.0553
trainer/Log Pis Std                 1.37172
trainer/Log Pis Max                 6.42401
trainer/Log Pis Min                -4.4825
trainer/Policy mu Mean              0.100584
trainer/Policy mu Std               0.801621
trainer/Policy mu Max               2.69537
trainer/Policy mu Min              -3.11179
trainer/Policy log std Mean        -2.01348
trainer/Policy log std Std          0.552934
trainer/Policy log std Max         -0.524735
trainer/Policy log std Min         -2.7487
trainer/Alpha                       0.0917464
trainer/Alpha Loss                  0.132088
exploration/num steps total     46000
exploration/num paths total       460
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.592494
exploration/Rewards Std             0.763661
exploration/Rewards Max            -0.0884573
exploration/Rewards Min            -6.93981
exploration/Returns Mean          -59.2494
exploration/Returns Std            28.7688
exploration/Returns Max           -30.4805
exploration/Returns Min           -88.0182
exploration/Actions Mean           -0.0120591
exploration/Actions Std             0.189374
exploration/Actions Max             0.626308
exploration/Actions Min            -0.995625
exploration/Num Paths               2
exploration/Average Returns       -59.2494
evaluation/num steps total     229000
evaluation/num paths total       2290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.679099
evaluation/Rewards Std              0.992858
evaluation/Rewards Max             -0.272207
evaluation/Rewards Min            -10.554
evaluation/Returns Mean           -67.9099
evaluation/Returns Std              9.88836
evaluation/Returns Max            -45.6406
evaluation/Returns Min            -82.0912
evaluation/Actions Mean             0.00513908
evaluation/Actions Std              0.180219
evaluation/Actions Max              0.998007
evaluation/Actions Min             -0.991119
evaluation/Num Paths               10
evaluation/Average Returns        -67.9099
time/data storing (s)               0.00124247
time/evaluation sampling (s)        0.242013
time/exploration sampling (s)       0.0740419
time/logging (s)                    0.00290779
time/saving (s)                     0.00195176
time/training (s)                   0.818987
time/epoch (s)                      1.14114
time/total (s)                    244.287
Epoch                             228
-----------------------------  ---------------
2019-04-21 01:15:48.920027 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 229 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                    0.220592
trainer/QF2 Loss                    0.245436
trainer/Policy Loss                38.6334
trainer/Q1 Predictions Mean       -37.544
trainer/Q1 Predictions Std         10.8901
trainer/Q1 Predictions Max        -27.0305
trainer/Q1 Predictions Min       -101.636
trainer/Q2 Predictions Mean       -37.5336
trainer/Q2 Predictions Std         10.8832
trainer/Q2 Predictions Max        -27.0105
trainer/Q2 Predictions Min       -101.621
trainer/Q Targets Mean            -37.8078
trainer/Q Targets Std              11.1623
trainer/Q Targets Max             -27.1064
trainer/Q Targets Min            -103.845
trainer/Log Pis Mean                2.0538
trainer/Log Pis Std                 1.22262
trainer/Log Pis Max                 6.22466
trainer/Log Pis Min                -1.65184
trainer/Policy mu Mean             -0.00311865
trainer/Policy mu Std               0.768139
trainer/Policy mu Max               2.74446
trainer/Policy mu Min              -3.16653
trainer/Policy log std Mean        -1.98133
trainer/Policy log std Std          0.575648
trainer/Policy log std Max         -0.256758
trainer/Policy log std Min         -2.75479
trainer/Alpha                       0.0924259
trainer/Alpha Loss                  0.128126
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.917795
exploration/Rewards Std             0.982561
exploration/Rewards Max            -0.411782
exploration/Rewards Min            -8.11293
exploration/Returns Mean          -91.7795
exploration/Returns Std            11.7605
exploration/Returns Max           -80.019
exploration/Returns Min          -103.54
exploration/Actions Mean           -0.0430392
exploration/Actions Std             0.23163
exploration/Actions Max             0.491007
exploration/Actions Min            -0.991014
exploration/Num Paths               2
exploration/Average Returns       -91.7795
evaluation/num steps total     230000
evaluation/num paths total       2300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.663527
evaluation/Rewards Std              0.995427
evaluation/Rewards Max             -0.254002
evaluation/Rewards Min             -9.50422
evaluation/Returns Mean           -66.3527
evaluation/Returns Std             27.2535
evaluation/Returns Max            -30.3244
evaluation/Returns Min           -110.282
evaluation/Actions Mean            -0.00347302
evaluation/Actions Std              0.18842
evaluation/Actions Max              0.9958
evaluation/Actions Min             -0.995187
evaluation/Num Paths               10
evaluation/Average Returns        -66.3527
time/data storing (s)               0.00122868
time/evaluation sampling (s)        0.226697
time/exploration sampling (s)       0.065193
time/logging (s)                    0.00337304
time/saving (s)                     0.00195033
time/training (s)                   0.76072
time/epoch (s)                      1.05916
time/total (s)                    245.351
Epoch                             229
-----------------------------  ---------------
2019-04-21 01:15:49.990252 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 230 finished
-----------------------------  ---------------
replay_buffer/size              46400
trainer/QF1 Loss                   31.5925
trainer/QF2 Loss                   31.6493
trainer/Policy Loss                37.5444
trainer/Q1 Predictions Mean       -36.3009
trainer/Q1 Predictions Std         11.1544
trainer/Q1 Predictions Max        -26.5386
trainer/Q1 Predictions Min        -97.4702
trainer/Q2 Predictions Mean       -36.2886
trainer/Q2 Predictions Std         11.1768
trainer/Q2 Predictions Max        -26.5174
trainer/Q2 Predictions Min        -97.766
trainer/Q Targets Mean            -36.042
trainer/Q Targets Std              12.3741
trainer/Q Targets Max              -0.571474
trainer/Q Targets Min             -98.2497
trainer/Log Pis Mean                2.09312
trainer/Log Pis Std                 1.3837
trainer/Log Pis Max                 6.39043
trainer/Log Pis Min                -4.17711
trainer/Policy mu Mean              0.0805825
trainer/Policy mu Std               0.756529
trainer/Policy mu Max               2.86885
trainer/Policy mu Min              -3.111
trainer/Policy log std Mean        -2.06968
trainer/Policy log std Std          0.590196
trainer/Policy log std Max         -0.375525
trainer/Policy log std Min         -2.85491
trainer/Alpha                       0.0930351
trainer/Alpha Loss                  0.221138
exploration/num steps total     46400
exploration/num paths total       464
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.858865
exploration/Rewards Std             1.22673
exploration/Rewards Max            -0.376139
exploration/Rewards Min            -9.90146
exploration/Returns Mean          -85.8865
exploration/Returns Std            23.8472
exploration/Returns Max           -62.0393
exploration/Returns Min          -109.734
exploration/Actions Mean           -0.0111179
exploration/Actions Std             0.231579
exploration/Actions Max             0.888778
exploration/Actions Min            -0.996704
exploration/Num Paths               2
exploration/Average Returns       -85.8865
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.536528
evaluation/Rewards Std              0.814635
evaluation/Rewards Max             -0.291293
evaluation/Rewards Min             -8.22409
evaluation/Returns Mean           -53.6528
evaluation/Returns Std             16.0967
evaluation/Returns Max            -30.8806
evaluation/Returns Min            -84.2933
evaluation/Actions Mean             0.0186943
evaluation/Actions Std              0.172423
evaluation/Actions Max              0.99197
evaluation/Actions Min             -0.994313
evaluation/Num Paths               10
evaluation/Average Returns        -53.6528
time/data storing (s)               0.00135148
time/evaluation sampling (s)        0.22332
time/exploration sampling (s)       0.0656654
time/logging (s)                    0.00335657
time/saving (s)                     0.00194675
time/training (s)                   0.766538
time/epoch (s)                      1.06218
time/total (s)                    246.417
Epoch                             230
-----------------------------  ---------------
2019-04-21 01:15:51.060351 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 231 finished
-----------------------------  ---------------
replay_buffer/size              46600
trainer/QF1 Loss                   16.0367
trainer/QF2 Loss                   16.0018
trainer/Policy Loss                36.1281
trainer/Q1 Predictions Mean       -34.8081
trainer/Q1 Predictions Std          9.62244
trainer/Q1 Predictions Max        -26.3977
trainer/Q1 Predictions Min        -79.8104
trainer/Q2 Predictions Mean       -34.7569
trainer/Q2 Predictions Std          9.55115
trainer/Q2 Predictions Max        -26.3997
trainer/Q2 Predictions Min        -79.5248
trainer/Q Targets Mean            -34.828
trainer/Q Targets Std              10.2096
trainer/Q Targets Max              -1.04136
trainer/Q Targets Min             -82.5706
trainer/Log Pis Mean                2.22182
trainer/Log Pis Std                 1.1189
trainer/Log Pis Max                 6.39812
trainer/Log Pis Min                -2.01398
trainer/Policy mu Mean              0.0730336
trainer/Policy mu Std               0.692635
trainer/Policy mu Max               2.8837
trainer/Policy mu Min              -2.7418
trainer/Policy log std Mean        -2.12813
trainer/Policy log std Std          0.566174
trainer/Policy log std Max         -0.460155
trainer/Policy log std Min         -2.79903
trainer/Alpha                       0.0959951
trainer/Alpha Loss                  0.519872
exploration/num steps total     46600
exploration/num paths total       466
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.53985
exploration/Rewards Std             0.498675
exploration/Rewards Max            -0.154632
exploration/Rewards Min            -5.03442
exploration/Returns Mean          -53.985
exploration/Returns Std             7.37066
exploration/Returns Max           -46.6144
exploration/Returns Min           -61.3557
exploration/Actions Mean            0.00788778
exploration/Actions Std             0.158632
exploration/Actions Max             0.98913
exploration/Actions Min            -0.73248
exploration/Num Paths               2
exploration/Average Returns       -53.985
evaluation/num steps total     232000
evaluation/num paths total       2320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.618789
evaluation/Rewards Std              0.891101
evaluation/Rewards Max             -0.295082
evaluation/Rewards Min            -10.4578
evaluation/Returns Mean           -61.8789
evaluation/Returns Std             16.9145
evaluation/Returns Max            -32.0166
evaluation/Returns Min            -80.3154
evaluation/Actions Mean             0.0153094
evaluation/Actions Std              0.185074
evaluation/Actions Max              0.997676
evaluation/Actions Min             -0.986222
evaluation/Num Paths               10
evaluation/Average Returns        -61.8789
time/data storing (s)               0.00125431
time/evaluation sampling (s)        0.225597
time/exploration sampling (s)       0.0658173
time/logging (s)                    0.00336562
time/saving (s)                     0.00196948
time/training (s)                   0.764152
time/epoch (s)                      1.06216
time/total (s)                    247.484
Epoch                             231
-----------------------------  ---------------
2019-04-21 01:15:52.138822 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 232 finished
-----------------------------  ---------------
replay_buffer/size              46800
trainer/QF1 Loss                   24.2535
trainer/QF2 Loss                   24.3559
trainer/Policy Loss                35.6231
trainer/Q1 Predictions Mean       -34.2254
trainer/Q1 Predictions Std          7.56036
trainer/Q1 Predictions Max        -26.4945
trainer/Q1 Predictions Min        -61.4848
trainer/Q2 Predictions Mean       -34.2177
trainer/Q2 Predictions Std          7.53762
trainer/Q2 Predictions Max        -26.4692
trainer/Q2 Predictions Min        -61.0841
trainer/Q Targets Mean            -33.7228
trainer/Q Targets Std               9.4481
trainer/Q Targets Max              -0.386857
trainer/Q Targets Min             -61.5479
trainer/Log Pis Mean                1.99614
trainer/Log Pis Std                 1.06774
trainer/Log Pis Max                 4.67071
trainer/Log Pis Min                -1.31638
trainer/Policy mu Mean              0.131408
trainer/Policy mu Std               0.716532
trainer/Policy mu Max               2.76074
trainer/Policy mu Min              -2.44948
trainer/Policy log std Mean        -2.03829
trainer/Policy log std Std          0.581719
trainer/Policy log std Max         -0.493448
trainer/Policy log std Min         -2.7759
trainer/Alpha                       0.0974788
trainer/Alpha Loss                 -0.00898456
exploration/num steps total     46800
exploration/num paths total       468
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.592026
exploration/Rewards Std             0.696771
exploration/Rewards Max            -0.140589
exploration/Rewards Min            -6.6708
exploration/Returns Mean          -59.2026
exploration/Returns Std             9.98284
exploration/Returns Max           -49.2198
exploration/Returns Min           -69.1855
exploration/Actions Mean           -0.00212622
exploration/Actions Std             0.222456
exploration/Actions Max             0.992545
exploration/Actions Min            -0.957357
exploration/Num Paths               2
exploration/Average Returns       -59.2026
evaluation/num steps total     233000
evaluation/num paths total       2330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.611617
evaluation/Rewards Std              0.892483
evaluation/Rewards Max             -0.257091
evaluation/Rewards Min             -9.31479
evaluation/Returns Mean           -61.1617
evaluation/Returns Std             17.1743
evaluation/Returns Max            -28.4295
evaluation/Returns Min            -88.5488
evaluation/Actions Mean             0.00513693
evaluation/Actions Std              0.181446
evaluation/Actions Max              0.995046
evaluation/Actions Min             -0.99161
evaluation/Num Paths               10
evaluation/Average Returns        -61.1617
time/data storing (s)               0.00166072
time/evaluation sampling (s)        0.225957
time/exploration sampling (s)       0.0640005
time/logging (s)                    0.00251909
time/saving (s)                     0.00158353
time/training (s)                   0.773907
time/epoch (s)                      1.06963
time/total (s)                    248.558
Epoch                             232
-----------------------------  ---------------
2019-04-21 01:15:53.215997 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 233 finished
-----------------------------  ---------------
replay_buffer/size              47000
trainer/QF1 Loss                    0.340155
trainer/QF2 Loss                    0.357047
trainer/Policy Loss                37.5431
trainer/Q1 Predictions Mean       -36.14
trainer/Q1 Predictions Std         10.8073
trainer/Q1 Predictions Max        -25.9406
trainer/Q1 Predictions Min       -100.39
trainer/Q2 Predictions Mean       -36.1248
trainer/Q2 Predictions Std         10.8205
trainer/Q2 Predictions Max        -25.9222
trainer/Q2 Predictions Min       -100.801
trainer/Q Targets Mean            -36.6183
trainer/Q Targets Std              10.9873
trainer/Q Targets Max             -26.3261
trainer/Q Targets Min            -102.128
trainer/Log Pis Mean                2.23546
trainer/Log Pis Std                 1.15469
trainer/Log Pis Max                 7.51739
trainer/Log Pis Min                -1.95119
trainer/Policy mu Mean              0.0992269
trainer/Policy mu Std               0.787324
trainer/Policy mu Max               3.13308
trainer/Policy mu Min              -2.83855
trainer/Policy log std Mean        -1.99391
trainer/Policy log std Std          0.607387
trainer/Policy log std Max         -0.217587
trainer/Policy log std Min         -2.82606
trainer/Alpha                       0.0976471
trainer/Alpha Loss                  0.547792
exploration/num steps total     47000
exploration/num paths total       470
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.485347
exploration/Rewards Std             0.320595
exploration/Rewards Max            -0.0914766
exploration/Rewards Min            -3.03883
exploration/Returns Mean          -48.5347
exploration/Returns Std            16.2982
exploration/Returns Max           -32.2365
exploration/Returns Min           -64.833
exploration/Actions Mean            0.0189802
exploration/Actions Std             0.176084
exploration/Actions Max             0.978867
exploration/Actions Min            -0.438185
exploration/Num Paths               2
exploration/Average Returns       -48.5347
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.648686
evaluation/Rewards Std              1.1631
evaluation/Rewards Max             -0.237733
evaluation/Rewards Min             -9.91921
evaluation/Returns Mean           -64.8686
evaluation/Returns Std             24.2597
evaluation/Returns Max            -24.3601
evaluation/Returns Min           -109.295
evaluation/Actions Mean             0.00419663
evaluation/Actions Std              0.196136
evaluation/Actions Max              0.994536
evaluation/Actions Min             -0.994936
evaluation/Num Paths               10
evaluation/Average Returns        -64.8686
time/data storing (s)               0.00121964
time/evaluation sampling (s)        0.225401
time/exploration sampling (s)       0.0644837
time/logging (s)                    0.00335448
time/saving (s)                     0.00167665
time/training (s)                   0.77382
time/epoch (s)                      1.06995
time/total (s)                    249.632
Epoch                             233
-----------------------------  ---------------
2019-04-21 01:15:54.286461 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 234 finished
-----------------------------  ---------------
replay_buffer/size              47200
trainer/QF1 Loss                    7.65801
trainer/QF2 Loss                    7.55233
trainer/Policy Loss                37.2989
trainer/Q1 Predictions Mean       -35.8299
trainer/Q1 Predictions Std         11.2772
trainer/Q1 Predictions Max        -25.7917
trainer/Q1 Predictions Min        -93.1468
trainer/Q2 Predictions Mean       -35.8412
trainer/Q2 Predictions Std         11.2975
trainer/Q2 Predictions Max        -25.8226
trainer/Q2 Predictions Min        -93.139
trainer/Q Targets Mean            -36.0204
trainer/Q Targets Std              11.8716
trainer/Q Targets Max              -1.37281
trainer/Q Targets Min             -92.8821
trainer/Log Pis Mean                2.29245
trainer/Log Pis Std                 1.20798
trainer/Log Pis Max                 6.97765
trainer/Log Pis Min                -1.13214
trainer/Policy mu Mean              0.110248
trainer/Policy mu Std               0.868343
trainer/Policy mu Max               2.98265
trainer/Policy mu Min              -3.29533
trainer/Policy log std Mean        -1.93833
trainer/Policy log std Std          0.649415
trainer/Policy log std Max         -0.379689
trainer/Policy log std Min         -2.80367
trainer/Alpha                       0.0962638
trainer/Alpha Loss                  0.684548
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.58148
exploration/Rewards Std             0.70394
exploration/Rewards Max            -0.1324
exploration/Rewards Min            -6.90719
exploration/Returns Mean          -58.148
exploration/Returns Std            26.5857
exploration/Returns Max           -31.5623
exploration/Returns Min           -84.7337
exploration/Actions Mean           -0.0224837
exploration/Actions Std             0.201004
exploration/Actions Max             0.785642
exploration/Actions Min            -0.990887
exploration/Num Paths               2
exploration/Average Returns       -58.148
evaluation/num steps total     235000
evaluation/num paths total       2350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.75502
evaluation/Rewards Std              0.75945
evaluation/Rewards Max             -0.298581
evaluation/Rewards Min             -8.35793
evaluation/Returns Mean           -75.502
evaluation/Returns Std             14.7882
evaluation/Returns Max            -38.66
evaluation/Returns Min            -92.7064
evaluation/Actions Mean            -0.0239381
evaluation/Actions Std              0.183665
evaluation/Actions Max              0.992686
evaluation/Actions Min             -0.993222
evaluation/Num Paths               10
evaluation/Average Returns        -75.502
time/data storing (s)               0.00128052
time/evaluation sampling (s)        0.222463
time/exploration sampling (s)       0.0643065
time/logging (s)                    0.00336781
time/saving (s)                     0.00198268
time/training (s)                   0.769033
time/epoch (s)                      1.06243
time/total (s)                    250.699
Epoch                             234
-----------------------------  ---------------
2019-04-21 01:15:55.362300 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 235 finished
-----------------------------  ----------------
replay_buffer/size              47400
trainer/QF1 Loss                    0.444947
trainer/QF2 Loss                    0.433217
trainer/Policy Loss                36.8403
trainer/Q1 Predictions Mean       -35.568
trainer/Q1 Predictions Std          9.24291
trainer/Q1 Predictions Max        -25.76
trainer/Q1 Predictions Min        -84.7575
trainer/Q2 Predictions Mean       -35.5807
trainer/Q2 Predictions Std          9.25255
trainer/Q2 Predictions Max        -25.7734
trainer/Q2 Predictions Min        -84.9397
trainer/Q Targets Mean            -36.0364
trainer/Q Targets Std               9.44616
trainer/Q Targets Max             -26.0498
trainer/Q Targets Min             -89.5582
trainer/Log Pis Mean                1.91732
trainer/Log Pis Std                 1.08284
trainer/Log Pis Max                 7.26291
trainer/Log Pis Min                -0.782403
trainer/Policy mu Mean              0.0802666
trainer/Policy mu Std               0.667057
trainer/Policy mu Max               3.00438
trainer/Policy mu Min              -2.58502
trainer/Policy log std Mean        -2.05596
trainer/Policy log std Std          0.528583
trainer/Policy log std Max         -0.28162
trainer/Policy log std Min         -2.68264
trainer/Alpha                       0.0935762
trainer/Alpha Loss                 -0.195859
exploration/num steps total     47400
exploration/num paths total       474
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.63283
exploration/Rewards Std             0.835577
exploration/Rewards Max            -0.11638
exploration/Rewards Min            -6.59944
exploration/Returns Mean          -63.283
exploration/Returns Std            16.174
exploration/Returns Max           -47.1089
exploration/Returns Min           -79.457
exploration/Actions Mean           -0.000476903
exploration/Actions Std             0.213325
exploration/Actions Max             0.975959
exploration/Actions Min            -0.994551
exploration/Num Paths               2
exploration/Average Returns       -63.283
evaluation/num steps total     236000
evaluation/num paths total       2360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.605314
evaluation/Rewards Std              0.682338
evaluation/Rewards Max             -0.312214
evaluation/Rewards Min             -8.04718
evaluation/Returns Mean           -60.5314
evaluation/Returns Std             11.8961
evaluation/Returns Max            -43.9965
evaluation/Returns Min            -82.0126
evaluation/Actions Mean             0.00379165
evaluation/Actions Std              0.169131
evaluation/Actions Max              0.992254
evaluation/Actions Min             -0.993855
evaluation/Num Paths               10
evaluation/Average Returns        -60.5314
time/data storing (s)               0.00147496
time/evaluation sampling (s)        0.224907
time/exploration sampling (s)       0.0643379
time/logging (s)                    0.00353941
time/saving (s)                     0.00190902
time/training (s)                   0.771751
time/epoch (s)                      1.06792
time/total (s)                    251.771
Epoch                             235
-----------------------------  ----------------
2019-04-21 01:15:56.428116 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 236 finished
-----------------------------  ---------------
replay_buffer/size              47600
trainer/QF1 Loss                    7.58657
trainer/QF2 Loss                    7.59559
trainer/Policy Loss                35.4608
trainer/Q1 Predictions Mean       -33.9963
trainer/Q1 Predictions Std          8.824
trainer/Q1 Predictions Max        -25.8662
trainer/Q1 Predictions Min        -83.0386
trainer/Q2 Predictions Mean       -34.0372
trainer/Q2 Predictions Std          8.8967
trainer/Q2 Predictions Max        -25.8836
trainer/Q2 Predictions Min        -84.6892
trainer/Q Targets Mean            -34.0567
trainer/Q Targets Std               9.49522
trainer/Q Targets Max              -1.65384
trainer/Q Targets Min             -84.7262
trainer/Log Pis Mean                2.04513
trainer/Log Pis Std                 1.0301
trainer/Log Pis Max                 5.71209
trainer/Log Pis Min                -0.621397
trainer/Policy mu Mean              0.0508216
trainer/Policy mu Std               0.696815
trainer/Policy mu Max               2.29731
trainer/Policy mu Min              -2.9838
trainer/Policy log std Mean        -2.00445
trainer/Policy log std Std          0.55952
trainer/Policy log std Max         -0.435155
trainer/Policy log std Min         -2.78886
trainer/Alpha                       0.0908563
trainer/Alpha Loss                  0.108238
exploration/num steps total     47600
exploration/num paths total       476
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.649304
exploration/Rewards Std             1.28958
exploration/Rewards Max            -0.14802
exploration/Rewards Min            -8.92203
exploration/Returns Mean          -64.9304
exploration/Returns Std             3.11952
exploration/Returns Max           -61.8109
exploration/Returns Min           -68.0499
exploration/Actions Mean            0.0388643
exploration/Actions Std             0.258828
exploration/Actions Max             0.996994
exploration/Actions Min            -0.985485
exploration/Num Paths               2
exploration/Average Returns       -64.9304
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.608235
evaluation/Rewards Std              0.762474
evaluation/Rewards Max             -0.293727
evaluation/Rewards Min            -10.0387
evaluation/Returns Mean           -60.8235
evaluation/Returns Std             24.5877
evaluation/Returns Max            -29.4629
evaluation/Returns Min           -111.085
evaluation/Actions Mean            -0.00634167
evaluation/Actions Std              0.161036
evaluation/Actions Max              0.9756
evaluation/Actions Min             -0.994865
evaluation/Num Paths               10
evaluation/Average Returns        -60.8235
time/data storing (s)               0.00122697
time/evaluation sampling (s)        0.225707
time/exploration sampling (s)       0.0637533
time/logging (s)                    0.00250764
time/saving (s)                     0.0015974
time/training (s)                   0.761681
time/epoch (s)                      1.05647
time/total (s)                    252.832
Epoch                             236
-----------------------------  ---------------
2019-04-21 01:15:57.521058 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 237 finished
-----------------------------  ---------------
replay_buffer/size              47800
trainer/QF1 Loss                   13.1958
trainer/QF2 Loss                   13.1885
trainer/Policy Loss                36.792
trainer/Q1 Predictions Mean       -35.6358
trainer/Q1 Predictions Std          6.77769
trainer/Q1 Predictions Max        -25.2296
trainer/Q1 Predictions Min        -59.8584
trainer/Q2 Predictions Mean       -35.6447
trainer/Q2 Predictions Std          6.77044
trainer/Q2 Predictions Max        -25.3324
trainer/Q2 Predictions Min        -59.6753
trainer/Q Targets Mean            -35.5809
trainer/Q Targets Std               8.18944
trainer/Q Targets Max              -0.412077
trainer/Q Targets Min             -59.7461
trainer/Log Pis Mean                1.82546
trainer/Log Pis Std                 1.15934
trainer/Log Pis Max                 5.40049
trainer/Log Pis Min                -1.67731
trainer/Policy mu Mean              0.0996883
trainer/Policy mu Std               0.659737
trainer/Policy mu Max               2.746
trainer/Policy mu Min              -2.2112
trainer/Policy log std Mean        -1.97942
trainer/Policy log std Std          0.526869
trainer/Policy log std Max         -0.466449
trainer/Policy log std Min         -2.77629
trainer/Alpha                       0.0892963
trainer/Alpha Loss                 -0.421611
exploration/num steps total     47800
exploration/num paths total       478
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.341638
exploration/Rewards Std             0.469797
exploration/Rewards Max            -0.0743336
exploration/Rewards Min            -4.80039
exploration/Returns Mean          -34.1638
exploration/Returns Std             5.17164
exploration/Returns Max           -28.9922
exploration/Returns Min           -39.3355
exploration/Actions Mean            0.0315729
exploration/Actions Std             0.1741
exploration/Actions Max             0.98944
exploration/Actions Min            -0.276561
exploration/Num Paths               2
exploration/Average Returns       -34.1638
evaluation/num steps total     238000
evaluation/num paths total       2380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.649726
evaluation/Rewards Std              1.05094
evaluation/Rewards Max             -0.233018
evaluation/Rewards Min            -11.3137
evaluation/Returns Mean           -64.9726
evaluation/Returns Std             27.0329
evaluation/Returns Max            -26.7731
evaluation/Returns Min           -115.275
evaluation/Actions Mean             0.00728719
evaluation/Actions Std              0.188505
evaluation/Actions Max              0.99649
evaluation/Actions Min             -0.994503
evaluation/Num Paths               10
evaluation/Average Returns        -64.9726
time/data storing (s)               0.00124174
time/evaluation sampling (s)        0.22783
time/exploration sampling (s)       0.0634334
time/logging (s)                    0.00338721
time/saving (s)                     0.00200446
time/training (s)                   0.788224
time/epoch (s)                      1.08612
time/total (s)                    253.923
Epoch                             237
-----------------------------  ---------------
2019-04-21 01:15:58.639388 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 238 finished
-----------------------------  ---------------
replay_buffer/size              48000
trainer/QF1 Loss                   22.4452
trainer/QF2 Loss                   22.8227
trainer/Policy Loss                35.8822
trainer/Q1 Predictions Mean       -34.4859
trainer/Q1 Predictions Std          9.49356
trainer/Q1 Predictions Max        -25.4053
trainer/Q1 Predictions Min        -93.2817
trainer/Q2 Predictions Mean       -34.4839
trainer/Q2 Predictions Std          9.44657
trainer/Q2 Predictions Max        -25.4265
trainer/Q2 Predictions Min        -92.5591
trainer/Q Targets Mean            -34.4655
trainer/Q Targets Std              10.6396
trainer/Q Targets Max              -0.502392
trainer/Q Targets Min             -91.716
trainer/Log Pis Mean                2.04745
trainer/Log Pis Std                 1.20528
trainer/Log Pis Max                 5.40866
trainer/Log Pis Min                -2.72018
trainer/Policy mu Mean              0.0104051
trainer/Policy mu Std               0.730177
trainer/Policy mu Max               2.97165
trainer/Policy mu Min              -2.83348
trainer/Policy log std Mean        -1.96652
trainer/Policy log std Std          0.566835
trainer/Policy log std Max         -0.521952
trainer/Policy log std Min         -2.68994
trainer/Alpha                       0.0894899
trainer/Alpha Loss                  0.114528
exploration/num steps total     48000
exploration/num paths total       480
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.808924
exploration/Rewards Std             1.41025
exploration/Rewards Max            -0.138271
exploration/Rewards Min           -10.4648
exploration/Returns Mean          -80.8924
exploration/Returns Std            34.4264
exploration/Returns Max           -46.4661
exploration/Returns Min          -115.319
exploration/Actions Mean           -0.0298836
exploration/Actions Std             0.242466
exploration/Actions Max             0.949586
exploration/Actions Min            -0.997936
exploration/Num Paths               2
exploration/Average Returns       -80.8924
evaluation/num steps total     239000
evaluation/num paths total       2390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.641633
evaluation/Rewards Std              0.961735
evaluation/Rewards Max             -0.301862
evaluation/Rewards Min            -10.5627
evaluation/Returns Mean           -64.1633
evaluation/Returns Std             17.2579
evaluation/Returns Max            -32.1516
evaluation/Returns Min            -85.1606
evaluation/Actions Mean             0.00826626
evaluation/Actions Std              0.191195
evaluation/Actions Max              0.996441
evaluation/Actions Min             -0.994397
evaluation/Num Paths               10
evaluation/Average Returns        -64.1633
time/data storing (s)               0.00138823
time/evaluation sampling (s)        0.243813
time/exploration sampling (s)       0.0730596
time/logging (s)                    0.00334905
time/saving (s)                     0.00198859
time/training (s)                   0.786541
time/epoch (s)                      1.11014
time/total (s)                    255.037
Epoch                             238
-----------------------------  ---------------
2019-04-21 01:15:59.715178 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 239 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                   27.0867
trainer/QF2 Loss                   28.9175
trainer/Policy Loss                35.6183
trainer/Q1 Predictions Mean       -34.1923
trainer/Q1 Predictions Std          9.91485
trainer/Q1 Predictions Max        -25.4869
trainer/Q1 Predictions Min        -80.8696
trainer/Q2 Predictions Mean       -34.187
trainer/Q2 Predictions Std          9.94123
trainer/Q2 Predictions Max        -25.4435
trainer/Q2 Predictions Min        -80.6189
trainer/Q Targets Mean            -34.0178
trainer/Q Targets Std              10.318
trainer/Q Targets Max              -5.95615
trainer/Q Targets Min             -84.0028
trainer/Log Pis Mean                2.052
trainer/Log Pis Std                 1.26842
trainer/Log Pis Max                 5.47278
trainer/Log Pis Min                -1.85635
trainer/Policy mu Mean              0.108711
trainer/Policy mu Std               0.718801
trainer/Policy mu Max               2.9222
trainer/Policy mu Min              -2.40367
trainer/Policy log std Mean        -2.07014
trainer/Policy log std Std          0.584006
trainer/Policy log std Max         -0.4284
trainer/Policy log std Min         -2.79345
trainer/Alpha                       0.0882768
trainer/Alpha Loss                  0.126209
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.552626
exploration/Rewards Std             0.42402
exploration/Rewards Max            -0.216552
exploration/Rewards Min            -4.1786
exploration/Returns Mean          -55.2626
exploration/Returns Std            16.5969
exploration/Returns Max           -38.6657
exploration/Returns Min           -71.8595
exploration/Actions Mean           -0.0143239
exploration/Actions Std             0.189023
exploration/Actions Max             0.890005
exploration/Actions Min            -0.998127
exploration/Num Paths               2
exploration/Average Returns       -55.2626
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.532069
evaluation/Rewards Std              0.675443
evaluation/Rewards Max             -0.325507
evaluation/Rewards Min             -8.06758
evaluation/Returns Mean           -53.2069
evaluation/Returns Std             17.9241
evaluation/Returns Max            -34.2495
evaluation/Returns Min            -93.5216
evaluation/Actions Mean            -0.00193582
evaluation/Actions Std              0.168536
evaluation/Actions Max              0.990071
evaluation/Actions Min             -0.993693
evaluation/Num Paths               10
evaluation/Average Returns        -53.2069
time/data storing (s)               0.00124323
time/evaluation sampling (s)        0.22758
time/exploration sampling (s)       0.0655071
time/logging (s)                    0.00340212
time/saving (s)                     0.00198608
time/training (s)                   0.767917
time/epoch (s)                      1.06764
time/total (s)                    256.109
Epoch                             239
-----------------------------  ---------------
2019-04-21 01:16:00.780480 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 240 finished
-----------------------------  ---------------
replay_buffer/size              48400
trainer/QF1 Loss                   14.8604
trainer/QF2 Loss                   14.8249
trainer/Policy Loss                34.9499
trainer/Q1 Predictions Mean       -33.3889
trainer/Q1 Predictions Std          8.72373
trainer/Q1 Predictions Max        -25.1339
trainer/Q1 Predictions Min        -71.8734
trainer/Q2 Predictions Mean       -33.3881
trainer/Q2 Predictions Std          8.73032
trainer/Q2 Predictions Max        -25.1163
trainer/Q2 Predictions Min        -72.395
trainer/Q Targets Mean            -33.2804
trainer/Q Targets Std               9.90692
trainer/Q Targets Max              -1.67667
trainer/Q Targets Min             -72.3091
trainer/Log Pis Mean                2.17197
trainer/Log Pis Std                 1.22638
trainer/Log Pis Max                 6.27383
trainer/Log Pis Min                -1.61595
trainer/Policy mu Mean              0.0986752
trainer/Policy mu Std               0.781002
trainer/Policy mu Max               2.63687
trainer/Policy mu Min              -2.88295
trainer/Policy log std Mean        -2.00616
trainer/Policy log std Std          0.613318
trainer/Policy log std Max         -0.407631
trainer/Policy log std Min         -2.83467
trainer/Alpha                       0.0891797
trainer/Alpha Loss                  0.415714
exploration/num steps total     48400
exploration/num paths total       484
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.612759
exploration/Rewards Std             0.824766
exploration/Rewards Max            -0.153555
exploration/Rewards Min            -7.83149
exploration/Returns Mean          -61.2759
exploration/Returns Std             0.0926367
exploration/Returns Max           -61.1833
exploration/Returns Min           -61.3685
exploration/Actions Mean            0.00425678
exploration/Actions Std             0.208153
exploration/Actions Max             0.997789
exploration/Actions Min            -0.995352
exploration/Num Paths               2
exploration/Average Returns       -61.2759
evaluation/num steps total     241000
evaluation/num paths total       2410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.695001
evaluation/Rewards Std              1.06035
evaluation/Rewards Max             -0.313279
evaluation/Rewards Min            -10.4346
evaluation/Returns Mean           -69.5001
evaluation/Returns Std             19.5622
evaluation/Returns Max            -36.4442
evaluation/Returns Min            -92.1924
evaluation/Actions Mean            -0.00243736
evaluation/Actions Std              0.181288
evaluation/Actions Max              0.997891
evaluation/Actions Min             -0.991139
evaluation/Num Paths               10
evaluation/Average Returns        -69.5001
time/data storing (s)               0.00127388
time/evaluation sampling (s)        0.220548
time/exploration sampling (s)       0.066316
time/logging (s)                    0.00333856
time/saving (s)                     0.00198362
time/training (s)                   0.763617
time/epoch (s)                      1.05708
time/total (s)                    257.171
Epoch                             240
-----------------------------  ---------------
2019-04-21 01:16:01.847825 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 241 finished
-----------------------------  ---------------
replay_buffer/size              48600
trainer/QF1 Loss                   30.9167
trainer/QF2 Loss                   31.0323
trainer/Policy Loss                35.6674
trainer/Q1 Predictions Mean       -34.2449
trainer/Q1 Predictions Std          9.36351
trainer/Q1 Predictions Max        -24.8308
trainer/Q1 Predictions Min        -89.4977
trainer/Q2 Predictions Mean       -34.2419
trainer/Q2 Predictions Std          9.30685
trainer/Q2 Predictions Max        -24.86
trainer/Q2 Predictions Min        -88.5659
trainer/Q Targets Mean            -33.6401
trainer/Q Targets Std              10.3501
trainer/Q Targets Max              -0.715799
trainer/Q Targets Min             -90.964
trainer/Log Pis Mean                2.0805
trainer/Log Pis Std                 1.10091
trainer/Log Pis Max                 4.96296
trainer/Log Pis Min                -2.80553
trainer/Policy mu Mean              0.0564114
trainer/Policy mu Std               0.678883
trainer/Policy mu Max               2.81334
trainer/Policy mu Min              -2.22304
trainer/Policy log std Mean        -2.04344
trainer/Policy log std Std          0.545901
trainer/Policy log std Max         -0.530812
trainer/Policy log std Min         -2.78079
trainer/Alpha                       0.0893298
trainer/Alpha Loss                  0.194442
exploration/num steps total     48600
exploration/num paths total       486
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.632652
exploration/Rewards Std             1.24133
exploration/Rewards Max            -0.141975
exploration/Rewards Min            -9.09545
exploration/Returns Mean          -63.2652
exploration/Returns Std            14.7801
exploration/Returns Max           -48.4851
exploration/Returns Min           -78.0452
exploration/Actions Mean            0.0105978
exploration/Actions Std             0.213378
exploration/Actions Max             0.997508
exploration/Actions Min            -0.995072
exploration/Num Paths               2
exploration/Average Returns       -63.2652
evaluation/num steps total     242000
evaluation/num paths total       2420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.6386
evaluation/Rewards Std              1.067
evaluation/Rewards Max             -0.30491
evaluation/Rewards Min            -10.5392
evaluation/Returns Mean           -63.86
evaluation/Returns Std             20.1171
evaluation/Returns Max            -31.2694
evaluation/Returns Min            -98.6944
evaluation/Actions Mean            -0.00796543
evaluation/Actions Std              0.187206
evaluation/Actions Max              0.997804
evaluation/Actions Min             -0.995918
evaluation/Num Paths               10
evaluation/Average Returns        -63.86
time/data storing (s)               0.00144858
time/evaluation sampling (s)        0.227603
time/exploration sampling (s)       0.0658849
time/logging (s)                    0.00291978
time/saving (s)                     0.00196498
time/training (s)                   0.758927
time/epoch (s)                      1.05875
time/total (s)                    258.233
Epoch                             241
-----------------------------  ---------------
2019-04-21 01:16:02.923117 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 242 finished
-----------------------------  ---------------
replay_buffer/size              48800
trainer/QF1 Loss                   14.1195
trainer/QF2 Loss                   14.0582
trainer/Policy Loss                35.2583
trainer/Q1 Predictions Mean       -33.9115
trainer/Q1 Predictions Std          8.38472
trainer/Q1 Predictions Max        -24.8491
trainer/Q1 Predictions Min        -73.1159
trainer/Q2 Predictions Mean       -33.9499
trainer/Q2 Predictions Std          8.37465
trainer/Q2 Predictions Max        -24.8334
trainer/Q2 Predictions Min        -73.1737
trainer/Q Targets Mean            -33.5745
trainer/Q Targets Std               9.36976
trainer/Q Targets Max              -0.599442
trainer/Q Targets Min             -72.1053
trainer/Log Pis Mean                1.97204
trainer/Log Pis Std                 1.15126
trainer/Log Pis Max                 6.57021
trainer/Log Pis Min                -1.47057
trainer/Policy mu Mean              0.118371
trainer/Policy mu Std               0.749477
trainer/Policy mu Max               2.76498
trainer/Policy mu Min              -2.57786
trainer/Policy log std Mean        -2.01007
trainer/Policy log std Std          0.591831
trainer/Policy log std Max         -0.536583
trainer/Policy log std Min         -2.76819
trainer/Alpha                       0.0900936
trainer/Alpha Loss                 -0.0673055
exploration/num steps total     48800
exploration/num paths total       488
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.828362
exploration/Rewards Std             1.52703
exploration/Rewards Max            -0.114166
exploration/Rewards Min           -10.6148
exploration/Returns Mean          -82.8362
exploration/Returns Std            22.3384
exploration/Returns Max           -60.4979
exploration/Returns Min          -105.175
exploration/Actions Mean           -0.0194639
exploration/Actions Std             0.265084
exploration/Actions Max             0.997203
exploration/Actions Min            -0.998862
exploration/Num Paths               2
exploration/Average Returns       -82.8362
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.606108
evaluation/Rewards Std              1.04942
evaluation/Rewards Max             -0.289841
evaluation/Rewards Min             -9.79106
evaluation/Returns Mean           -60.6108
evaluation/Returns Std             14.1526
evaluation/Returns Max            -31.4558
evaluation/Returns Min            -82.524
evaluation/Actions Mean             0.0142578
evaluation/Actions Std              0.199293
evaluation/Actions Max              0.994753
evaluation/Actions Min             -0.993417
evaluation/Num Paths               10
evaluation/Average Returns        -60.6108
time/data storing (s)               0.0018602
time/evaluation sampling (s)        0.226869
time/exploration sampling (s)       0.0662938
time/logging (s)                    0.00336222
time/saving (s)                     0.00198704
time/training (s)                   0.768143
time/epoch (s)                      1.06852
time/total (s)                    259.307
Epoch                             242
-----------------------------  ---------------
2019-04-21 01:16:04.000921 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 243 finished
-----------------------------  ---------------
replay_buffer/size              49000
trainer/QF1 Loss                    0.191681
trainer/QF2 Loss                    0.1967
trainer/Policy Loss                37.1847
trainer/Q1 Predictions Mean       -35.8662
trainer/Q1 Predictions Std         10.8
trainer/Q1 Predictions Max        -24.9422
trainer/Q1 Predictions Min        -94.9522
trainer/Q2 Predictions Mean       -35.8841
trainer/Q2 Predictions Std         10.8487
trainer/Q2 Predictions Max        -24.9106
trainer/Q2 Predictions Min        -95.2471
trainer/Q Targets Mean            -36.1713
trainer/Q Targets Std              10.8242
trainer/Q Targets Max             -24.9633
trainer/Q Targets Min             -94.9312
trainer/Log Pis Mean                1.80184
trainer/Log Pis Std                 1.65511
trainer/Log Pis Max                 5.67399
trainer/Log Pis Min                -4.32219
trainer/Policy mu Mean             -0.125896
trainer/Policy mu Std               0.733316
trainer/Policy mu Max               2.62791
trainer/Policy mu Min              -3.05777
trainer/Policy log std Mean        -2.09688
trainer/Policy log std Std          0.570379
trainer/Policy log std Max         -0.563889
trainer/Policy log std Min         -2.79341
trainer/Alpha                       0.0898454
trainer/Alpha Loss                 -0.477508
exploration/num steps total     49000
exploration/num paths total       490
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33208
exploration/Rewards Std             0.444563
exploration/Rewards Max            -0.0766161
exploration/Rewards Min            -4.68824
exploration/Returns Mean          -33.208
exploration/Returns Std             4.66562
exploration/Returns Max           -28.5424
exploration/Returns Min           -37.8737
exploration/Actions Mean            0.00199466
exploration/Actions Std             0.168496
exploration/Actions Max             0.89363
exploration/Actions Min            -0.964369
exploration/Num Paths               2
exploration/Average Returns       -33.208
evaluation/num steps total     244000
evaluation/num paths total       2440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.68131
evaluation/Rewards Std              1.0358
evaluation/Rewards Max             -0.242185
evaluation/Rewards Min             -9.68912
evaluation/Returns Mean           -68.131
evaluation/Returns Std             20.951
evaluation/Returns Max            -24.3758
evaluation/Returns Min           -102.381
evaluation/Actions Mean            -0.0133659
evaluation/Actions Std              0.191985
evaluation/Actions Max              0.995273
evaluation/Actions Min             -0.995835
evaluation/Num Paths               10
evaluation/Average Returns        -68.131
time/data storing (s)               0.00123618
time/evaluation sampling (s)        0.228101
time/exploration sampling (s)       0.064412
time/logging (s)                    0.00259342
time/saving (s)                     0.00200434
time/training (s)                   0.771169
time/epoch (s)                      1.06952
time/total (s)                    260.38
Epoch                             243
-----------------------------  ---------------
2019-04-21 01:16:05.068649 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 244 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                    0.117506
trainer/QF2 Loss                    0.097524
trainer/Policy Loss                36.2709
trainer/Q1 Predictions Mean       -34.7519
trainer/Q1 Predictions Std          8.14761
trainer/Q1 Predictions Max        -24.5216
trainer/Q1 Predictions Min        -64.6079
trainer/Q2 Predictions Mean       -34.7642
trainer/Q2 Predictions Std          8.12793
trainer/Q2 Predictions Max        -24.4846
trainer/Q2 Predictions Min        -64.6937
trainer/Q Targets Mean            -34.956
trainer/Q Targets Std               7.98379
trainer/Q Targets Max             -24.7972
trainer/Q Targets Min             -64.3127
trainer/Log Pis Mean                1.93732
trainer/Log Pis Std                 1.18211
trainer/Log Pis Max                 6.54008
trainer/Log Pis Min                -1.54274
trainer/Policy mu Mean              0.0105633
trainer/Policy mu Std               0.751507
trainer/Policy mu Max               2.8514
trainer/Policy mu Min              -2.33265
trainer/Policy log std Mean        -1.9827
trainer/Policy log std Std          0.592613
trainer/Policy log std Max         -0.4792
trainer/Policy log std Min         -2.75292
trainer/Alpha                       0.0912726
trainer/Alpha Loss                 -0.150043
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.47691
exploration/Rewards Std             0.385315
exploration/Rewards Max            -0.0708888
exploration/Rewards Min            -3.56812
exploration/Returns Mean          -47.691
exploration/Returns Std            19.3222
exploration/Returns Max           -28.3688
exploration/Returns Min           -67.0132
exploration/Actions Mean            0.0142851
exploration/Actions Std             0.177604
exploration/Actions Max             0.971288
exploration/Actions Min            -0.882427
exploration/Num Paths               2
exploration/Average Returns       -47.691
evaluation/num steps total     245000
evaluation/num paths total       2450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.58256
evaluation/Rewards Std              1.05355
evaluation/Rewards Max             -0.210939
evaluation/Rewards Min            -10.1754
evaluation/Returns Mean           -58.256
evaluation/Returns Std             23.8579
evaluation/Returns Max            -26.3296
evaluation/Returns Min           -106.117
evaluation/Actions Mean             0.0158698
evaluation/Actions Std              0.191687
evaluation/Actions Max              0.99478
evaluation/Actions Min             -0.994675
evaluation/Num Paths               10
evaluation/Average Returns        -58.256
time/data storing (s)               0.0012543
time/evaluation sampling (s)        0.218807
time/exploration sampling (s)       0.0639982
time/logging (s)                    0.00254843
time/saving (s)                     0.00198359
time/training (s)                   0.771795
time/epoch (s)                      1.06039
time/total (s)                    261.444
Epoch                             244
-----------------------------  ---------------
2019-04-21 01:16:06.142665 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 245 finished
-----------------------------  ---------------
replay_buffer/size              49400
trainer/QF1 Loss                    6.1098
trainer/QF2 Loss                    6.16472
trainer/Policy Loss                33.4952
trainer/Q1 Predictions Mean       -32.0359
trainer/Q1 Predictions Std          6.92838
trainer/Q1 Predictions Max        -24.3927
trainer/Q1 Predictions Min        -46.1777
trainer/Q2 Predictions Mean       -32.0379
trainer/Q2 Predictions Std          6.90533
trainer/Q2 Predictions Max        -24.3853
trainer/Q2 Predictions Min        -46.1889
trainer/Q Targets Mean            -32.321
trainer/Q Targets Std               7.6294
trainer/Q Targets Max              -0.48028
trainer/Q Targets Min             -45.246
trainer/Log Pis Mean                2.05072
trainer/Log Pis Std                 1.01064
trainer/Log Pis Max                 5.03745
trainer/Log Pis Min                -1.80637
trainer/Policy mu Mean              0.11503
trainer/Policy mu Std               0.635568
trainer/Policy mu Max               2.50761
trainer/Policy mu Min              -2.07754
trainer/Policy log std Mean        -2.07663
trainer/Policy log std Std          0.544691
trainer/Policy log std Max         -0.616654
trainer/Policy log std Min         -2.76513
trainer/Alpha                       0.0923438
trainer/Alpha Loss                  0.12083
exploration/num steps total     49400
exploration/num paths total       494
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378879
exploration/Rewards Std             0.512401
exploration/Rewards Max            -0.0825455
exploration/Rewards Min            -4.97214
exploration/Returns Mean          -37.8879
exploration/Returns Std             4.01194
exploration/Returns Max           -33.876
exploration/Returns Min           -41.8998
exploration/Actions Mean            0.0355795
exploration/Actions Std             0.191507
exploration/Actions Max             0.984017
exploration/Actions Min            -0.310533
exploration/Num Paths               2
exploration/Average Returns       -37.8879
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.658752
evaluation/Rewards Std              0.769243
evaluation/Rewards Max             -0.258925
evaluation/Rewards Min             -8.7732
evaluation/Returns Mean           -65.8752
evaluation/Returns Std              8.20995
evaluation/Returns Max            -57.4289
evaluation/Returns Min            -85.7657
evaluation/Actions Mean            -0.0177485
evaluation/Actions Std              0.188273
evaluation/Actions Max              0.992349
evaluation/Actions Min             -0.995245
evaluation/Num Paths               10
evaluation/Average Returns        -65.8752
time/data storing (s)               0.00145921
time/evaluation sampling (s)        0.22382
time/exploration sampling (s)       0.0662973
time/logging (s)                    0.00336244
time/saving (s)                     0.0019853
time/training (s)                   0.770053
time/epoch (s)                      1.06698
time/total (s)                    262.515
Epoch                             245
-----------------------------  ---------------
2019-04-21 01:16:07.217984 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 246 finished
-----------------------------  ---------------
replay_buffer/size              49600
trainer/QF1 Loss                   49.2647
trainer/QF2 Loss                   48.9705
trainer/Policy Loss                35.9481
trainer/Q1 Predictions Mean       -34.4428
trainer/Q1 Predictions Std          9.11227
trainer/Q1 Predictions Max        -24.2429
trainer/Q1 Predictions Min        -80.0497
trainer/Q2 Predictions Mean       -34.457
trainer/Q2 Predictions Std          9.16168
trainer/Q2 Predictions Max        -24.2244
trainer/Q2 Predictions Min        -80.8174
trainer/Q Targets Mean            -33.7433
trainer/Q Targets Std              10.3392
trainer/Q Targets Max              -0.227292
trainer/Q Targets Min             -80.3721
trainer/Log Pis Mean                2.15842
trainer/Log Pis Std                 1.04039
trainer/Log Pis Max                 5.07182
trainer/Log Pis Min                -0.676122
trainer/Policy mu Mean              0.00862292
trainer/Policy mu Std               0.693229
trainer/Policy mu Max               2.67613
trainer/Policy mu Min              -2.88442
trainer/Policy log std Mean        -2.08094
trainer/Policy log std Std          0.530947
trainer/Policy log std Max         -0.495297
trainer/Policy log std Min         -2.73069
trainer/Alpha                       0.0937491
trainer/Alpha Loss                  0.375045
exploration/num steps total     49600
exploration/num paths total       496
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.763414
exploration/Rewards Std             0.923345
exploration/Rewards Max            -0.317393
exploration/Rewards Min            -7.82626
exploration/Returns Mean          -76.3414
exploration/Returns Std            10.6957
exploration/Returns Max           -65.6457
exploration/Returns Min           -87.0371
exploration/Actions Mean           -0.00759111
exploration/Actions Std             0.217191
exploration/Actions Max             0.967395
exploration/Actions Min            -0.998215
exploration/Num Paths               2
exploration/Average Returns       -76.3414
evaluation/num steps total     247000
evaluation/num paths total       2470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.474668
evaluation/Rewards Std              0.618019
evaluation/Rewards Max             -0.245319
evaluation/Rewards Min             -7.70546
evaluation/Returns Mean           -47.4668
evaluation/Returns Std             17.5482
evaluation/Returns Max            -29.9451
evaluation/Returns Min            -80.5767
evaluation/Actions Mean            -0.00406679
evaluation/Actions Std              0.162195
evaluation/Actions Max              0.988921
evaluation/Actions Min             -0.993274
evaluation/Num Paths               10
evaluation/Average Returns        -47.4668
time/data storing (s)               0.00124662
time/evaluation sampling (s)        0.224249
time/exploration sampling (s)       0.0636051
time/logging (s)                    0.00344181
time/saving (s)                     0.00163781
time/training (s)                   0.773119
time/epoch (s)                      1.0673
time/total (s)                    263.587
Epoch                             246
-----------------------------  ---------------
2019-04-21 01:16:08.295542 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 247 finished
-----------------------------  ---------------
replay_buffer/size              49800
trainer/QF1 Loss                    0.442275
trainer/QF2 Loss                    0.456331
trainer/Policy Loss                31.8846
trainer/Q1 Predictions Mean       -30.5189
trainer/Q1 Predictions Std          8.39728
trainer/Q1 Predictions Max        -23.7858
trainer/Q1 Predictions Min        -67.4316
trainer/Q2 Predictions Mean       -30.4984
trainer/Q2 Predictions Std          8.39793
trainer/Q2 Predictions Max        -23.6978
trainer/Q2 Predictions Min        -66.974
trainer/Q Targets Mean            -31.147
trainer/Q Targets Std               8.42809
trainer/Q Targets Max             -24.3345
trainer/Q Targets Min             -67.5452
trainer/Log Pis Mean                2.00607
trainer/Log Pis Std                 1.17099
trainer/Log Pis Max                 5.09921
trainer/Log Pis Min                -3.27623
trainer/Policy mu Mean              0.169412
trainer/Policy mu Std               0.586667
trainer/Policy mu Max               2.70644
trainer/Policy mu Min              -2.68326
trainer/Policy log std Mean        -2.20116
trainer/Policy log std Std          0.544944
trainer/Policy log std Max         -0.599588
trainer/Policy log std Min         -2.89117
trainer/Alpha                       0.0950798
trainer/Alpha Loss                  0.0142844
exploration/num steps total     49800
exploration/num paths total       498
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.727793
exploration/Rewards Std             0.600493
exploration/Rewards Max            -0.428493
exploration/Rewards Min            -6.55588
exploration/Returns Mean          -72.7793
exploration/Returns Std             7.82171
exploration/Returns Max           -64.9576
exploration/Returns Min           -80.601
exploration/Actions Mean            0.00170106
exploration/Actions Std             0.218069
exploration/Actions Max             0.996688
exploration/Actions Min            -0.986868
exploration/Num Paths               2
exploration/Average Returns       -72.7793
evaluation/num steps total     248000
evaluation/num paths total       2480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.642244
evaluation/Rewards Std              0.978858
evaluation/Rewards Max             -0.194014
evaluation/Rewards Min            -10.5173
evaluation/Returns Mean           -64.2244
evaluation/Returns Std             31.1414
evaluation/Returns Max            -24.561
evaluation/Returns Min           -111.124
evaluation/Actions Mean            -0.0036374
evaluation/Actions Std              0.186142
evaluation/Actions Max              0.992667
evaluation/Actions Min             -0.997963
evaluation/Num Paths               10
evaluation/Average Returns        -64.2244
time/data storing (s)               0.00124241
time/evaluation sampling (s)        0.22697
time/exploration sampling (s)       0.0676723
time/logging (s)                    0.00338386
time/saving (s)                     0.00196213
time/training (s)                   0.768344
time/epoch (s)                      1.06957
time/total (s)                    264.661
Epoch                             247
-----------------------------  ---------------
2019-04-21 01:16:09.359219 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 248 finished
-----------------------------  ----------------
replay_buffer/size              50000
trainer/QF1 Loss                    8.75819
trainer/QF2 Loss                    8.82657
trainer/Policy Loss                35.7727
trainer/Q1 Predictions Mean       -34.1105
trainer/Q1 Predictions Std          9.97111
trainer/Q1 Predictions Max        -23.8914
trainer/Q1 Predictions Min        -91.6667
trainer/Q2 Predictions Mean       -34.1181
trainer/Q2 Predictions Std         10.0088
trainer/Q2 Predictions Max        -23.8977
trainer/Q2 Predictions Min        -92.2475
trainer/Q Targets Mean            -34.2479
trainer/Q Targets Std              10.4297
trainer/Q Targets Max              -3.67701
trainer/Q Targets Min             -91.3683
trainer/Log Pis Mean                2.05176
trainer/Log Pis Std                 1.12593
trainer/Log Pis Max                 6.84223
trainer/Log Pis Min                -0.716436
trainer/Policy mu Mean              0.0295507
trainer/Policy mu Std               0.69226
trainer/Policy mu Max               2.861
trainer/Policy mu Min              -3.04652
trainer/Policy log std Mean        -2.11277
trainer/Policy log std Std          0.550572
trainer/Policy log std Max         -0.379429
trainer/Policy log std Min         -2.79095
trainer/Alpha                       0.0957493
trainer/Alpha Loss                  0.121441
exploration/num steps total     50000
exploration/num paths total       500
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.514294
exploration/Rewards Std             0.479486
exploration/Rewards Max            -0.098499
exploration/Rewards Min            -3.94889
exploration/Returns Mean          -51.4294
exploration/Returns Std            15.5823
exploration/Returns Max           -35.8472
exploration/Returns Min           -67.0117
exploration/Actions Mean            0.0109699
exploration/Actions Std             0.200332
exploration/Actions Max             0.986881
exploration/Actions Min            -0.975906
exploration/Num Paths               2
exploration/Average Returns       -51.4294
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.535371
evaluation/Rewards Std              0.786232
evaluation/Rewards Max             -0.239625
evaluation/Rewards Min             -9.71082
evaluation/Returns Mean           -53.5371
evaluation/Returns Std             20.0754
evaluation/Returns Max            -25.4508
evaluation/Returns Min            -97.4351
evaluation/Actions Mean            -2.34551e-05
evaluation/Actions Std              0.155468
evaluation/Actions Max              0.991948
evaluation/Actions Min             -0.996163
evaluation/Num Paths               10
evaluation/Average Returns        -53.5371
time/data storing (s)               0.00127542
time/evaluation sampling (s)        0.225335
time/exploration sampling (s)       0.0645963
time/logging (s)                    0.00336773
time/saving (s)                     0.00197851
time/training (s)                   0.759166
time/epoch (s)                      1.05572
time/total (s)                    265.72
Epoch                             248
-----------------------------  ----------------
2019-04-21 01:16:10.415399 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 249 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                    5.80762
trainer/QF2 Loss                    5.79223
trainer/Policy Loss                33.3942
trainer/Q1 Predictions Mean       -31.9052
trainer/Q1 Predictions Std          8.34186
trainer/Q1 Predictions Max        -23.6662
trainer/Q1 Predictions Min        -70.1781
trainer/Q2 Predictions Mean       -31.9208
trainer/Q2 Predictions Std          8.32355
trainer/Q2 Predictions Max        -23.6432
trainer/Q2 Predictions Min        -69.7114
trainer/Q Targets Mean            -31.8729
trainer/Q Targets Std               8.66265
trainer/Q Targets Max              -0.662256
trainer/Q Targets Min             -70.9182
trainer/Log Pis Mean                2.13341
trainer/Log Pis Std                 1.06831
trainer/Log Pis Max                 6.04866
trainer/Log Pis Min                -1.21545
trainer/Policy mu Mean              0.113287
trainer/Policy mu Std               0.744693
trainer/Policy mu Max               2.66836
trainer/Policy mu Min              -2.48701
trainer/Policy log std Mean        -1.96948
trainer/Policy log std Std          0.604598
trainer/Policy log std Max         -0.425025
trainer/Policy log std Min         -2.76398
trainer/Alpha                       0.0962932
trainer/Alpha Loss                  0.312223
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.464692
exploration/Rewards Std             0.515475
exploration/Rewards Max            -0.0738682
exploration/Rewards Min            -4.9692
exploration/Returns Mean          -46.4692
exploration/Returns Std            24.2269
exploration/Returns Max           -22.2423
exploration/Returns Min           -70.6961
exploration/Actions Mean            0.0169303
exploration/Actions Std             0.173662
exploration/Actions Max             0.988273
exploration/Actions Min            -0.485627
exploration/Num Paths               2
exploration/Average Returns       -46.4692
evaluation/num steps total     250000
evaluation/num paths total       2500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.398925
evaluation/Rewards Std              0.761836
evaluation/Rewards Max             -0.208343
evaluation/Rewards Min            -10.0051
evaluation/Returns Mean           -39.8925
evaluation/Returns Std             22.9366
evaluation/Returns Max            -21.718
evaluation/Returns Min            -99.1517
evaluation/Actions Mean             0.00505378
evaluation/Actions Std              0.157216
evaluation/Actions Max              0.992398
evaluation/Actions Min             -0.995662
evaluation/Num Paths               10
evaluation/Average Returns        -39.8925
time/data storing (s)               0.00125573
time/evaluation sampling (s)        0.224859
time/exploration sampling (s)       0.0652008
time/logging (s)                    0.00336825
time/saving (s)                     0.00199282
time/training (s)                   0.751557
time/epoch (s)                      1.04823
time/total (s)                    266.773
Epoch                             249
-----------------------------  ---------------
2019-04-21 01:16:11.488301 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 250 finished
-----------------------------  ---------------
replay_buffer/size              50400
trainer/QF1 Loss                    8.29837
trainer/QF2 Loss                    8.31227
trainer/Policy Loss                33.8219
trainer/Q1 Predictions Mean       -32.5827
trainer/Q1 Predictions Std          8.66059
trainer/Q1 Predictions Max        -23.5849
trainer/Q1 Predictions Min        -63.5562
trainer/Q2 Predictions Mean       -32.5893
trainer/Q2 Predictions Std          8.67462
trainer/Q2 Predictions Max        -23.5992
trainer/Q2 Predictions Min        -63.9644
trainer/Q Targets Mean            -32.5677
trainer/Q Targets Std               9.07383
trainer/Q Targets Max              -3.46849
trainer/Q Targets Min             -63.6931
trainer/Log Pis Mean                1.96662
trainer/Log Pis Std                 1.13031
trainer/Log Pis Max                 4.019
trainer/Log Pis Min                -2.93667
trainer/Policy mu Mean             -0.0265805
trainer/Policy mu Std               0.767009
trainer/Policy mu Max               2.51776
trainer/Policy mu Min              -2.50717
trainer/Policy log std Mean        -1.98353
trainer/Policy log std Std          0.614845
trainer/Policy log std Max         -0.606954
trainer/Policy log std Min         -2.79186
trainer/Alpha                       0.0964264
trainer/Alpha Loss                 -0.0780785
exploration/num steps total     50400
exploration/num paths total       504
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.639678
exploration/Rewards Std             1.08792
exploration/Rewards Max            -0.0925287
exploration/Rewards Min            -8.72733
exploration/Returns Mean          -63.9678
exploration/Returns Std             2.48346
exploration/Returns Max           -61.4844
exploration/Returns Min           -66.4513
exploration/Actions Mean            0.0247581
exploration/Actions Std             0.236121
exploration/Actions Max             0.997125
exploration/Actions Min            -0.983255
exploration/Num Paths               2
exploration/Average Returns       -63.9678
evaluation/num steps total     251000
evaluation/num paths total       2510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.584144
evaluation/Rewards Std              1.05488
evaluation/Rewards Max             -0.205694
evaluation/Rewards Min            -10.0971
evaluation/Returns Mean           -58.4144
evaluation/Returns Std             27.1454
evaluation/Returns Max            -22.9161
evaluation/Returns Min           -104.787
evaluation/Actions Mean            -0.0108228
evaluation/Actions Std              0.181448
evaluation/Actions Max              0.995629
evaluation/Actions Min             -0.995505
evaluation/Num Paths               10
evaluation/Average Returns        -58.4144
time/data storing (s)               0.00127542
time/evaluation sampling (s)        0.221147
time/exploration sampling (s)       0.0647412
time/logging (s)                    0.00336716
time/saving (s)                     0.00198474
time/training (s)                   0.772795
time/epoch (s)                      1.06531
time/total (s)                    267.842
Epoch                             250
-----------------------------  ---------------
2019-04-21 01:16:12.564347 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 251 finished
-----------------------------  ---------------
replay_buffer/size              50600
trainer/QF1 Loss                   14.0515
trainer/QF2 Loss                   14.0221
trainer/Policy Loss                33.6203
trainer/Q1 Predictions Mean       -32.0535
trainer/Q1 Predictions Std         10.3303
trainer/Q1 Predictions Max        -23.6077
trainer/Q1 Predictions Min        -99.4478
trainer/Q2 Predictions Mean       -32.0583
trainer/Q2 Predictions Std         10.3175
trainer/Q2 Predictions Max        -23.6107
trainer/Q2 Predictions Min        -99.4444
trainer/Q Targets Mean            -32.1622
trainer/Q Targets Std              11.0676
trainer/Q Targets Max              -1.03706
trainer/Q Targets Min            -101.015
trainer/Log Pis Mean                2.17454
trainer/Log Pis Std                 0.987428
trainer/Log Pis Max                 5.90668
trainer/Log Pis Min                -0.842502
trainer/Policy mu Mean             -0.0112742
trainer/Policy mu Std               0.652013
trainer/Policy mu Max               2.49719
trainer/Policy mu Min              -3.26224
trainer/Policy log std Mean        -2.18045
trainer/Policy log std Std          0.552961
trainer/Policy log std Max         -0.422285
trainer/Policy log std Min         -2.81951
trainer/Alpha                       0.0969294
trainer/Alpha Loss                  0.40738
exploration/num steps total     50600
exploration/num paths total       506
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.425139
exploration/Rewards Std             0.261041
exploration/Rewards Max            -0.077444
exploration/Rewards Min            -1.92939
exploration/Returns Mean          -42.5139
exploration/Returns Std            18.2604
exploration/Returns Max           -24.2535
exploration/Returns Min           -60.7743
exploration/Actions Mean            0.0101498
exploration/Actions Std             0.154742
exploration/Actions Max             0.99505
exploration/Actions Min            -0.543948
exploration/Num Paths               2
exploration/Average Returns       -42.5139
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.528067
evaluation/Rewards Std              0.876505
evaluation/Rewards Max             -0.0947483
evaluation/Rewards Min             -9.86665
evaluation/Returns Mean           -52.8067
evaluation/Returns Std             25.6153
evaluation/Returns Max            -19.1558
evaluation/Returns Min            -98.0159
evaluation/Actions Mean            -0.00788481
evaluation/Actions Std              0.16586
evaluation/Actions Max              0.995891
evaluation/Actions Min             -0.995776
evaluation/Num Paths               10
evaluation/Average Returns        -52.8067
time/data storing (s)               0.00125238
time/evaluation sampling (s)        0.227522
time/exploration sampling (s)       0.0620807
time/logging (s)                    0.00336914
time/saving (s)                     0.00196005
time/training (s)                   0.772221
time/epoch (s)                      1.0684
time/total (s)                    268.914
Epoch                             251
-----------------------------  ---------------
2019-04-21 01:16:13.644661 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 252 finished
-----------------------------  ---------------
replay_buffer/size              50800
trainer/QF1 Loss                   13.8166
trainer/QF2 Loss                   13.8169
trainer/Policy Loss                32.9854
trainer/Q1 Predictions Mean       -31.6542
trainer/Q1 Predictions Std          6.87316
trainer/Q1 Predictions Max        -23.1714
trainer/Q1 Predictions Min        -42.7942
trainer/Q2 Predictions Mean       -31.6554
trainer/Q2 Predictions Std          6.88046
trainer/Q2 Predictions Max        -23.1406
trainer/Q2 Predictions Min        -43.0844
trainer/Q Targets Mean            -31.6948
trainer/Q Targets Std               7.60768
trainer/Q Targets Max              -0.645206
trainer/Q Targets Min             -43.4816
trainer/Log Pis Mean                1.80575
trainer/Log Pis Std                 0.901447
trainer/Log Pis Max                 3.54532
trainer/Log Pis Min                -1.51739
trainer/Policy mu Mean              0.0956078
trainer/Policy mu Std               0.540291
trainer/Policy mu Max               2.6724
trainer/Policy mu Min              -1.89301
trainer/Policy log std Mean        -2.14561
trainer/Policy log std Std          0.512985
trainer/Policy log std Max         -0.514379
trainer/Policy log std Min         -2.93401
trainer/Alpha                       0.0971835
trainer/Alpha Loss                 -0.452814
exploration/num steps total     50800
exploration/num paths total       508
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.485872
exploration/Rewards Std             1.16285
exploration/Rewards Max            -0.0824188
exploration/Rewards Min            -8.97768
exploration/Returns Mean          -48.5872
exploration/Returns Std            18.3951
exploration/Returns Max           -30.1921
exploration/Returns Min           -66.9823
exploration/Actions Mean            0.0216582
exploration/Actions Std             0.209358
exploration/Actions Max             0.998787
exploration/Actions Min            -0.993164
exploration/Num Paths               2
exploration/Average Returns       -48.5872
evaluation/num steps total     253000
evaluation/num paths total       2530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.733599
evaluation/Rewards Std              1.04509
evaluation/Rewards Max             -0.214932
evaluation/Rewards Min            -10.4537
evaluation/Returns Mean           -73.3599
evaluation/Returns Std             23.3125
evaluation/Returns Max            -27.6721
evaluation/Returns Min           -108.948
evaluation/Actions Mean            -0.0132195
evaluation/Actions Std              0.205207
evaluation/Actions Max              0.992543
evaluation/Actions Min             -0.996737
evaluation/Num Paths               10
evaluation/Average Returns        -73.3599
time/data storing (s)               0.00128423
time/evaluation sampling (s)        0.228224
time/exploration sampling (s)       0.0619258
time/logging (s)                    0.00341558
time/saving (s)                     0.00197082
time/training (s)                   0.776063
time/epoch (s)                      1.07288
time/total (s)                    269.991
Epoch                             252
-----------------------------  ---------------
2019-04-21 01:16:14.716540 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 253 finished
-----------------------------  ---------------
replay_buffer/size              51000
trainer/QF1 Loss                    0.537561
trainer/QF2 Loss                    0.631259
trainer/Policy Loss                35.2409
trainer/Q1 Predictions Mean       -33.7524
trainer/Q1 Predictions Std         12.8553
trainer/Q1 Predictions Max        -23.1341
trainer/Q1 Predictions Min       -111.452
trainer/Q2 Predictions Mean       -33.7393
trainer/Q2 Predictions Std         12.8787
trainer/Q2 Predictions Max        -23.1539
trainer/Q2 Predictions Min       -111.644
trainer/Q Targets Mean            -34.0521
trainer/Q Targets Std              12.7489
trainer/Q Targets Max             -23.3633
trainer/Q Targets Min            -106.346
trainer/Log Pis Mean                2.15975
trainer/Log Pis Std                 1.14281
trainer/Log Pis Max                 5.05835
trainer/Log Pis Min                -3.18137
trainer/Policy mu Mean             -0.0484218
trainer/Policy mu Std               0.708285
trainer/Policy mu Max               2.82607
trainer/Policy mu Min              -3.14112
trainer/Policy log std Mean        -2.08547
trainer/Policy log std Std          0.558587
trainer/Policy log std Max         -0.57112
trainer/Policy log std Min         -2.80792
trainer/Alpha                       0.0972513
trainer/Alpha Loss                  0.372331
exploration/num steps total     51000
exploration/num paths total       510
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.639138
exploration/Rewards Std             0.88968
exploration/Rewards Max            -0.0840574
exploration/Rewards Min            -7.26552
exploration/Returns Mean          -63.9138
exploration/Returns Std             7.87475
exploration/Returns Max           -56.039
exploration/Returns Min           -71.7885
exploration/Actions Mean            0.00660694
exploration/Actions Std             0.22312
exploration/Actions Max             0.999021
exploration/Actions Min            -0.985381
exploration/Num Paths               2
exploration/Average Returns       -63.9138
evaluation/num steps total     254000
evaluation/num paths total       2540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.758995
evaluation/Rewards Std              1.16678
evaluation/Rewards Max             -0.239628
evaluation/Rewards Min            -10.6067
evaluation/Returns Mean           -75.8995
evaluation/Returns Std             27.1047
evaluation/Returns Max            -38.9544
evaluation/Returns Min           -114.834
evaluation/Actions Mean            -0.009511
evaluation/Actions Std              0.199158
evaluation/Actions Max              0.991344
evaluation/Actions Min             -0.997616
evaluation/Num Paths               10
evaluation/Average Returns        -75.8995
time/data storing (s)               0.00122372
time/evaluation sampling (s)        0.222728
time/exploration sampling (s)       0.0641618
time/logging (s)                    0.00336111
time/saving (s)                     0.00197917
time/training (s)                   0.770372
time/epoch (s)                      1.06383
time/total (s)                    271.058
Epoch                             253
-----------------------------  ---------------
2019-04-21 01:16:15.791582 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 254 finished
-----------------------------  ---------------
replay_buffer/size              51200
trainer/QF1 Loss                    0.113499
trainer/QF2 Loss                    0.106114
trainer/Policy Loss                34.5546
trainer/Q1 Predictions Mean       -33.2409
trainer/Q1 Predictions Std          9.36525
trainer/Q1 Predictions Max        -23.1537
trainer/Q1 Predictions Min        -89.6932
trainer/Q2 Predictions Mean       -33.2499
trainer/Q2 Predictions Std          9.39436
trainer/Q2 Predictions Max        -23.1155
trainer/Q2 Predictions Min        -90.2128
trainer/Q Targets Mean            -33.4399
trainer/Q Targets Std               9.50549
trainer/Q Targets Max             -23.1477
trainer/Q Targets Min             -90.2756
trainer/Log Pis Mean                1.85207
trainer/Log Pis Std                 1.09948
trainer/Log Pis Max                 5.03755
trainer/Log Pis Min                -1.71495
trainer/Policy mu Mean             -0.0726338
trainer/Policy mu Std               0.609197
trainer/Policy mu Max               2.0389
trainer/Policy mu Min              -2.88745
trainer/Policy log std Mean        -2.11176
trainer/Policy log std Std          0.509089
trainer/Policy log std Max         -0.603698
trainer/Policy log std Min         -2.82177
trainer/Alpha                       0.0985646
trainer/Alpha Loss                 -0.342763
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.477659
exploration/Rewards Std             0.972523
exploration/Rewards Max            -0.0760809
exploration/Rewards Min            -7.9654
exploration/Returns Mean          -47.7659
exploration/Returns Std            14.7974
exploration/Returns Max           -32.9685
exploration/Returns Min           -62.5633
exploration/Actions Mean            0.0232528
exploration/Actions Std             0.207854
exploration/Actions Max             0.997917
exploration/Actions Min            -0.978304
exploration/Num Paths               2
exploration/Average Returns       -47.7659
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.657961
evaluation/Rewards Std              0.833151
evaluation/Rewards Max             -0.239479
evaluation/Rewards Min             -9.60046
evaluation/Returns Mean           -65.7961
evaluation/Returns Std             21.3236
evaluation/Returns Max            -28.4344
evaluation/Returns Min           -101.986
evaluation/Actions Mean            -0.0132908
evaluation/Actions Std              0.178868
evaluation/Actions Max              0.989182
evaluation/Actions Min             -0.995085
evaluation/Num Paths               10
evaluation/Average Returns        -65.7961
time/data storing (s)               0.00124131
time/evaluation sampling (s)        0.221279
time/exploration sampling (s)       0.063651
time/logging (s)                    0.00340685
time/saving (s)                     0.00200513
time/training (s)                   0.775487
time/epoch (s)                      1.06707
time/total (s)                    272.129
Epoch                             254
-----------------------------  ---------------
2019-04-21 01:16:16.859415 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 255 finished
-----------------------------  ---------------
replay_buffer/size              51400
trainer/QF1 Loss                   18.7535
trainer/QF2 Loss                   18.81
trainer/Policy Loss                33.9773
trainer/Q1 Predictions Mean       -32.9157
trainer/Q1 Predictions Std          9.89743
trainer/Q1 Predictions Max        -22.7816
trainer/Q1 Predictions Min        -88.2718
trainer/Q2 Predictions Mean       -32.9165
trainer/Q2 Predictions Std          9.92509
trainer/Q2 Predictions Max        -22.8401
trainer/Q2 Predictions Min        -88.5381
trainer/Q Targets Mean            -32.5223
trainer/Q Targets Std              10.776
trainer/Q Targets Max              -0.657104
trainer/Q Targets Min             -88.0098
trainer/Log Pis Mean                1.77623
trainer/Log Pis Std                 1.56824
trainer/Log Pis Max                 6.7786
trainer/Log Pis Min                -3.24635
trainer/Policy mu Mean             -0.00207694
trainer/Policy mu Std               0.759739
trainer/Policy mu Max               2.5751
trainer/Policy mu Min              -2.90841
trainer/Policy log std Mean        -1.96369
trainer/Policy log std Std          0.592923
trainer/Policy log std Max         -0.546589
trainer/Policy log std Min         -2.72312
trainer/Alpha                       0.0984162
trainer/Alpha Loss                 -0.518792
exploration/num steps total     51400
exploration/num paths total       514
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.605796
exploration/Rewards Std             0.699513
exploration/Rewards Max            -0.0898756
exploration/Rewards Min            -6.28213
exploration/Returns Mean          -60.5796
exploration/Returns Std            23.9749
exploration/Returns Max           -36.6047
exploration/Returns Min           -84.5545
exploration/Actions Mean           -0.0251791
exploration/Actions Std             0.213957
exploration/Actions Max             0.808791
exploration/Actions Min            -0.997606
exploration/Num Paths               2
exploration/Average Returns       -60.5796
evaluation/num steps total     256000
evaluation/num paths total       2560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.560013
evaluation/Rewards Std              0.948988
evaluation/Rewards Max             -0.273175
evaluation/Rewards Min            -10.2505
evaluation/Returns Mean           -56.0013
evaluation/Returns Std             23.811
evaluation/Returns Max            -27.8865
evaluation/Returns Min           -103.506
evaluation/Actions Mean             0.00934667
evaluation/Actions Std              0.179967
evaluation/Actions Max              0.997156
evaluation/Actions Min             -0.991615
evaluation/Num Paths               10
evaluation/Average Returns        -56.0013
time/data storing (s)               0.00148718
time/evaluation sampling (s)        0.220553
time/exploration sampling (s)       0.0629414
time/logging (s)                    0.00337513
time/saving (s)                     0.00195284
time/training (s)                   0.770146
time/epoch (s)                      1.06046
time/total (s)                    273.194
Epoch                             255
-----------------------------  ---------------
2019-04-21 01:16:17.938765 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 256 finished
-----------------------------  ----------------
replay_buffer/size              51600
trainer/QF1 Loss                    0.309506
trainer/QF2 Loss                    0.352281
trainer/Policy Loss                34.6188
trainer/Q1 Predictions Mean       -33.4142
trainer/Q1 Predictions Std          9.90795
trainer/Q1 Predictions Max        -22.9345
trainer/Q1 Predictions Min        -81.8244
trainer/Q2 Predictions Mean       -33.4065
trainer/Q2 Predictions Std          9.84224
trainer/Q2 Predictions Max        -22.8963
trainer/Q2 Predictions Min        -81.7989
trainer/Q Targets Mean            -33.6511
trainer/Q Targets Std              10.2117
trainer/Q Targets Max             -22.8551
trainer/Q Targets Min             -85.2496
trainer/Log Pis Mean                2.00066
trainer/Log Pis Std                 1.24624
trainer/Log Pis Max                 6.43929
trainer/Log Pis Min                -2.35107
trainer/Policy mu Mean              0.0228434
trainer/Policy mu Std               0.804409
trainer/Policy mu Max               2.94832
trainer/Policy mu Min              -2.85705
trainer/Policy log std Mean        -1.92201
trainer/Policy log std Std          0.631408
trainer/Policy log std Max         -0.322213
trainer/Policy log std Min         -2.80351
trainer/Alpha                       0.0994919
trainer/Alpha Loss                  0.00151769
exploration/num steps total     51600
exploration/num paths total       516
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.346781
exploration/Rewards Std             0.648642
exploration/Rewards Max            -0.0407657
exploration/Rewards Min            -5.7273
exploration/Returns Mean          -34.6781
exploration/Returns Std             4.12925
exploration/Returns Max           -30.5489
exploration/Returns Min           -38.8074
exploration/Actions Mean            0.0319226
exploration/Actions Std             0.197483
exploration/Actions Max             0.993473
exploration/Actions Min            -0.764828
exploration/Num Paths               2
exploration/Average Returns       -34.6781
evaluation/num steps total     257000
evaluation/num paths total       2570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.737998
evaluation/Rewards Std              1.18172
evaluation/Rewards Max             -0.195
evaluation/Rewards Min            -10.5831
evaluation/Returns Mean           -73.7998
evaluation/Returns Std             22.0638
evaluation/Returns Max            -36.0517
evaluation/Returns Min           -105.327
evaluation/Actions Mean             0.000150823
evaluation/Actions Std              0.211773
evaluation/Actions Max              0.995387
evaluation/Actions Min             -0.997071
evaluation/Num Paths               10
evaluation/Average Returns        -73.7998
time/data storing (s)               0.00150849
time/evaluation sampling (s)        0.232959
time/exploration sampling (s)       0.0626574
time/logging (s)                    0.00339163
time/saving (s)                     0.00199956
time/training (s)                   0.769477
time/epoch (s)                      1.07199
time/total (s)                    274.27
Epoch                             256
-----------------------------  ----------------
2019-04-21 01:16:19.012072 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 257 finished
-----------------------------  ---------------
replay_buffer/size              51800
trainer/QF1 Loss                   11.1638
trainer/QF2 Loss                   11.1393
trainer/Policy Loss                34.5609
trainer/Q1 Predictions Mean       -33.5399
trainer/Q1 Predictions Std         11.6013
trainer/Q1 Predictions Max        -22.4745
trainer/Q1 Predictions Min       -104.794
trainer/Q2 Predictions Mean       -33.5048
trainer/Q2 Predictions Std         11.5577
trainer/Q2 Predictions Max        -22.4785
trainer/Q2 Predictions Min       -104.568
trainer/Q Targets Mean            -33.4114
trainer/Q Targets Std              12.654
trainer/Q Targets Max              -0.632718
trainer/Q Targets Min            -106.999
trainer/Log Pis Mean                1.81049
trainer/Log Pis Std                 1.2904
trainer/Log Pis Max                 6.80162
trainer/Log Pis Min                -2.11067
trainer/Policy mu Mean             -0.0304606
trainer/Policy mu Std               0.779883
trainer/Policy mu Max               2.9693
trainer/Policy mu Min              -3.14161
trainer/Policy log std Mean        -1.98373
trainer/Policy log std Std          0.606165
trainer/Policy log std Max         -0.402569
trainer/Policy log std Min         -2.82636
trainer/Alpha                       0.0990816
trainer/Alpha Loss                 -0.438128
exploration/num steps total     51800
exploration/num paths total       518
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.632011
exploration/Rewards Std             0.903672
exploration/Rewards Max            -0.108184
exploration/Rewards Min            -7.24955
exploration/Returns Mean          -63.2011
exploration/Returns Std            20.7438
exploration/Returns Max           -42.4572
exploration/Returns Min           -83.9449
exploration/Actions Mean            0.00664389
exploration/Actions Std             0.230804
exploration/Actions Max             0.999309
exploration/Actions Min            -0.995926
exploration/Num Paths               2
exploration/Average Returns       -63.2011
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.705977
evaluation/Rewards Std              1.14193
evaluation/Rewards Max             -0.23652
evaluation/Rewards Min            -10.9887
evaluation/Returns Mean           -70.5977
evaluation/Returns Std             30.1359
evaluation/Returns Max            -32.4189
evaluation/Returns Min           -114.167
evaluation/Actions Mean            -0.027882
evaluation/Actions Std              0.2012
evaluation/Actions Max              0.992619
evaluation/Actions Min             -0.997316
evaluation/Num Paths               10
evaluation/Average Returns        -70.5977
time/data storing (s)               0.00130808
time/evaluation sampling (s)        0.224668
time/exploration sampling (s)       0.0643836
time/logging (s)                    0.0033941
time/saving (s)                     0.00196893
time/training (s)                   0.769663
time/epoch (s)                      1.06539
time/total (s)                    275.339
Epoch                             257
-----------------------------  ---------------
2019-04-21 01:16:20.079757 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 258 finished
-----------------------------  ---------------
replay_buffer/size              52000
trainer/QF1 Loss                   18.5176
trainer/QF2 Loss                   18.5373
trainer/Policy Loss                33.3195
trainer/Q1 Predictions Mean       -31.8173
trainer/Q1 Predictions Std         10.0628
trainer/Q1 Predictions Max        -22.5999
trainer/Q1 Predictions Min        -75.0788
trainer/Q2 Predictions Mean       -31.7833
trainer/Q2 Predictions Std         10.0799
trainer/Q2 Predictions Max        -22.6438
trainer/Q2 Predictions Min        -75.521
trainer/Q Targets Mean            -31.5035
trainer/Q Targets Std              11.1709
trainer/Q Targets Max              -0.605523
trainer/Q Targets Min             -75.298
trainer/Log Pis Mean                2.01523
trainer/Log Pis Std                 1.30678
trainer/Log Pis Max                 5.94659
trainer/Log Pis Min                -2.91319
trainer/Policy mu Mean              0.0306398
trainer/Policy mu Std               0.728774
trainer/Policy mu Max               2.77216
trainer/Policy mu Min              -2.90016
trainer/Policy log std Mean        -2.0553
trainer/Policy log std Std          0.591178
trainer/Policy log std Max         -0.380474
trainer/Policy log std Min         -2.83245
trainer/Alpha                       0.0985827
trainer/Alpha Loss                  0.0352805
exploration/num steps total     52000
exploration/num paths total       520
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.54469
exploration/Rewards Std             0.490265
exploration/Rewards Max            -0.0785559
exploration/Rewards Min            -4.39518
exploration/Returns Mean          -54.469
exploration/Returns Std            17.9901
exploration/Returns Max           -36.4789
exploration/Returns Min           -72.4591
exploration/Actions Mean           -0.0182407
exploration/Actions Std             0.189948
exploration/Actions Max             0.824164
exploration/Actions Min            -0.984029
exploration/Num Paths               2
exploration/Average Returns       -54.469
evaluation/num steps total     259000
evaluation/num paths total       2590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.530721
evaluation/Rewards Std              1.00978
evaluation/Rewards Max             -0.228475
evaluation/Rewards Min             -9.21101
evaluation/Returns Mean           -53.0721
evaluation/Returns Std             19.2333
evaluation/Returns Max            -29.2102
evaluation/Returns Min            -85.023
evaluation/Actions Mean             0.0216234
evaluation/Actions Std              0.192565
evaluation/Actions Max              0.993193
evaluation/Actions Min             -0.993284
evaluation/Num Paths               10
evaluation/Average Returns        -53.0721
time/data storing (s)               0.00132083
time/evaluation sampling (s)        0.216828
time/exploration sampling (s)       0.0663994
time/logging (s)                    0.00338949
time/saving (s)                     0.00195773
time/training (s)                   0.769356
time/epoch (s)                      1.05925
time/total (s)                    276.403
Epoch                             258
-----------------------------  ---------------
2019-04-21 01:16:21.156552 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 259 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                    6.27983
trainer/QF2 Loss                    6.36995
trainer/Policy Loss                32.2031
trainer/Q1 Predictions Mean       -30.8453
trainer/Q1 Predictions Std          6.91559
trainer/Q1 Predictions Max        -22.6301
trainer/Q1 Predictions Min        -52.9866
trainer/Q2 Predictions Mean       -30.8256
trainer/Q2 Predictions Std          6.91974
trainer/Q2 Predictions Max        -22.5231
trainer/Q2 Predictions Min        -53.0673
trainer/Q Targets Mean            -30.7835
trainer/Q Targets Std               7.74693
trainer/Q Targets Max              -1.94741
trainer/Q Targets Min             -52.7505
trainer/Log Pis Mean                1.87357
trainer/Log Pis Std                 1.03627
trainer/Log Pis Max                 3.8807
trainer/Log Pis Min                -2.00516
trainer/Policy mu Mean              0.0999934
trainer/Policy mu Std               0.63137
trainer/Policy mu Max               2.6914
trainer/Policy mu Min              -2.24216
trainer/Policy log std Mean        -2.03614
trainer/Policy log std Std          0.54052
trainer/Policy log std Max         -0.557687
trainer/Policy log std Min         -2.83308
trainer/Alpha                       0.0973484
trainer/Alpha Loss                 -0.294517
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.667625
exploration/Rewards Std             1.05406
exploration/Rewards Max            -0.116235
exploration/Rewards Min            -8.74094
exploration/Returns Mean          -66.7625
exploration/Returns Std             3.04039
exploration/Returns Max           -63.7221
exploration/Returns Min           -69.8029
exploration/Actions Mean            0.0151403
exploration/Actions Std             0.240097
exploration/Actions Max             0.994549
exploration/Actions Min            -0.984375
exploration/Num Paths               2
exploration/Average Returns       -66.7625
evaluation/num steps total     260000
evaluation/num paths total       2600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.597519
evaluation/Rewards Std              0.705292
evaluation/Rewards Max             -0.105233
evaluation/Rewards Min             -7.2241
evaluation/Returns Mean           -59.7519
evaluation/Returns Std             14.5853
evaluation/Returns Max            -26.0602
evaluation/Returns Min            -79.2518
evaluation/Actions Mean            -0.00995236
evaluation/Actions Std              0.174193
evaluation/Actions Max              0.990723
evaluation/Actions Min             -0.991015
evaluation/Num Paths               10
evaluation/Average Returns        -59.7519
time/data storing (s)               0.00124567
time/evaluation sampling (s)        0.223458
time/exploration sampling (s)       0.0651035
time/logging (s)                    0.00335566
time/saving (s)                     0.00197467
time/training (s)                   0.773327
time/epoch (s)                      1.06846
time/total (s)                    277.476
Epoch                             259
-----------------------------  ---------------
2019-04-21 01:16:22.215850 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 260 finished
-----------------------------  ---------------
replay_buffer/size              52400
trainer/QF1 Loss                   38.793
trainer/QF2 Loss                   38.8611
trainer/Policy Loss                34.5831
trainer/Q1 Predictions Mean       -33.1872
trainer/Q1 Predictions Std         11.8823
trainer/Q1 Predictions Max        -22.2681
trainer/Q1 Predictions Min       -108.363
trainer/Q2 Predictions Mean       -33.1794
trainer/Q2 Predictions Std         11.8572
trainer/Q2 Predictions Max        -22.2069
trainer/Q2 Predictions Min       -108.739
trainer/Q Targets Mean            -32.6173
trainer/Q Targets Std              13.1338
trainer/Q Targets Max              -0.635554
trainer/Q Targets Min            -105.317
trainer/Log Pis Mean                1.96226
trainer/Log Pis Std                 1.29771
trainer/Log Pis Max                 6.61007
trainer/Log Pis Min                -1.00235
trainer/Policy mu Mean             -0.0323663
trainer/Policy mu Std               0.744785
trainer/Policy mu Max               3.16825
trainer/Policy mu Min              -3.15053
trainer/Policy log std Mean        -2.0448
trainer/Policy log std Std          0.601616
trainer/Policy log std Max         -0.461259
trainer/Policy log std Min         -2.7938
trainer/Alpha                       0.0969067
trainer/Alpha Loss                 -0.0880727
exploration/num steps total     52400
exploration/num paths total       524
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.892715
exploration/Rewards Std             1.08888
exploration/Rewards Max            -0.4544
exploration/Rewards Min            -9.72365
exploration/Returns Mean          -89.2715
exploration/Returns Std            18.1628
exploration/Returns Max           -71.1087
exploration/Returns Min          -107.434
exploration/Actions Mean           -0.00877117
exploration/Actions Std             0.245258
exploration/Actions Max             0.897258
exploration/Actions Min            -0.998959
exploration/Num Paths               2
exploration/Average Returns       -89.2715
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.67433
evaluation/Rewards Std              0.891187
evaluation/Rewards Max             -0.255211
evaluation/Rewards Min             -9.4804
evaluation/Returns Mean           -67.433
evaluation/Returns Std             19.9724
evaluation/Returns Max            -29.6594
evaluation/Returns Min            -93.2501
evaluation/Actions Mean             0.00414393
evaluation/Actions Std              0.184773
evaluation/Actions Max              0.991193
evaluation/Actions Min             -0.990813
evaluation/Num Paths               10
evaluation/Average Returns        -67.433
time/data storing (s)               0.00134272
time/evaluation sampling (s)        0.223852
time/exploration sampling (s)       0.0621688
time/logging (s)                    0.00339251
time/saving (s)                     0.00196579
time/training (s)                   0.75861
time/epoch (s)                      1.05133
time/total (s)                    278.531
Epoch                             260
-----------------------------  ---------------
2019-04-21 01:16:23.290668 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 261 finished
-----------------------------  ----------------
replay_buffer/size              52600
trainer/QF1 Loss                   25.7936
trainer/QF2 Loss                   25.7587
trainer/Policy Loss                33.4054
trainer/Q1 Predictions Mean       -32.1425
trainer/Q1 Predictions Std          8.71628
trainer/Q1 Predictions Max        -22.0599
trainer/Q1 Predictions Min        -84.2117
trainer/Q2 Predictions Mean       -32.1634
trainer/Q2 Predictions Std          8.83806
trainer/Q2 Predictions Max        -22.0656
trainer/Q2 Predictions Min        -86.5101
trainer/Q Targets Mean            -31.7281
trainer/Q Targets Std               9.94412
trainer/Q Targets Max              -0.671286
trainer/Q Targets Min             -86.7234
trainer/Log Pis Mean                2.01041
trainer/Log Pis Std                 1.14327
trainer/Log Pis Max                 7.34553
trainer/Log Pis Min                -1.44269
trainer/Policy mu Mean              0.0940364
trainer/Policy mu Std               0.709375
trainer/Policy mu Max               2.6976
trainer/Policy mu Min              -3.32604
trainer/Policy log std Mean        -1.98292
trainer/Policy log std Std          0.607999
trainer/Policy log std Max         -0.405848
trainer/Policy log std Min         -2.92347
trainer/Alpha                       0.0973773
trainer/Alpha Loss                  0.0242389
exploration/num steps total     52600
exploration/num paths total       526
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.740849
exploration/Rewards Std             0.368401
exploration/Rewards Max            -0.458949
exploration/Rewards Min            -4.54534
exploration/Returns Mean          -74.0849
exploration/Returns Std             2.80651
exploration/Returns Max           -71.2783
exploration/Returns Min           -76.8914
exploration/Actions Mean           -0.000524703
exploration/Actions Std             0.213898
exploration/Actions Max             0.97654
exploration/Actions Min            -0.997151
exploration/Num Paths               2
exploration/Average Returns       -74.0849
evaluation/num steps total     262000
evaluation/num paths total       2620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.612384
evaluation/Rewards Std              0.755432
evaluation/Rewards Max             -0.199904
evaluation/Rewards Min             -9.05417
evaluation/Returns Mean           -61.2384
evaluation/Returns Std             25.0983
evaluation/Returns Max            -24.3344
evaluation/Returns Min           -105.317
evaluation/Actions Mean            -0.00138019
evaluation/Actions Std              0.160912
evaluation/Actions Max              0.991505
evaluation/Actions Min             -0.994491
evaluation/Num Paths               10
evaluation/Average Returns        -61.2384
time/data storing (s)               0.00123967
time/evaluation sampling (s)        0.220647
time/exploration sampling (s)       0.0634739
time/logging (s)                    0.00337399
time/saving (s)                     0.00201213
time/training (s)                   0.776436
time/epoch (s)                      1.06718
time/total (s)                    279.603
Epoch                             261
-----------------------------  ----------------
2019-04-21 01:16:24.365120 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 262 finished
-----------------------------  ----------------
replay_buffer/size              52800
trainer/QF1 Loss                    5.26058
trainer/QF2 Loss                    5.24795
trainer/Policy Loss                30.5651
trainer/Q1 Predictions Mean       -29.217
trainer/Q1 Predictions Std          6.85534
trainer/Q1 Predictions Max        -21.8787
trainer/Q1 Predictions Min        -48.4528
trainer/Q2 Predictions Mean       -29.2006
trainer/Q2 Predictions Std          6.86949
trainer/Q2 Predictions Max        -21.7889
trainer/Q2 Predictions Min        -48.6723
trainer/Q Targets Mean            -29.4598
trainer/Q Targets Std               7.62812
trainer/Q Targets Max              -0.874327
trainer/Q Targets Min             -48.7648
trainer/Log Pis Mean                2.0375
trainer/Log Pis Std                 0.952908
trainer/Log Pis Max                 4.45351
trainer/Log Pis Min                -1.07628
trainer/Policy mu Mean              0.114925
trainer/Policy mu Std               0.571608
trainer/Policy mu Max               2.15343
trainer/Policy mu Min              -2.03123
trainer/Policy log std Mean        -2.08574
trainer/Policy log std Std          0.534238
trainer/Policy log std Max         -0.549944
trainer/Policy log std Min         -2.80031
trainer/Alpha                       0.0996126
trainer/Alpha Loss                  0.0864918
exploration/num steps total     52800
exploration/num paths total       528
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.647672
exploration/Rewards Std             1.05608
exploration/Rewards Max            -0.097422
exploration/Rewards Min            -8.58993
exploration/Returns Mean          -64.7672
exploration/Returns Std             0.128384
exploration/Returns Max           -64.6388
exploration/Returns Min           -64.8956
exploration/Actions Mean            0.0213502
exploration/Actions Std             0.217252
exploration/Actions Max             0.99611
exploration/Actions Min            -0.90111
exploration/Num Paths               2
exploration/Average Returns       -64.7672
evaluation/num steps total     263000
evaluation/num paths total       2630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.670639
evaluation/Rewards Std              1.08456
evaluation/Rewards Max             -0.233113
evaluation/Rewards Min             -9.86576
evaluation/Returns Mean           -67.0639
evaluation/Returns Std             20.767
evaluation/Returns Max            -31.1184
evaluation/Returns Min            -99.1962
evaluation/Actions Mean            -0.000737049
evaluation/Actions Std              0.198188
evaluation/Actions Max              0.9937
evaluation/Actions Min             -0.994846
evaluation/Num Paths               10
evaluation/Average Returns        -67.0639
time/data storing (s)               0.00143226
time/evaluation sampling (s)        0.222659
time/exploration sampling (s)       0.063177
time/logging (s)                    0.00345851
time/saving (s)                     0.00201352
time/training (s)                   0.773973
time/epoch (s)                      1.06671
time/total (s)                    280.673
Epoch                             262
-----------------------------  ----------------
2019-04-21 01:16:25.452929 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 263 finished
-----------------------------  ---------------
replay_buffer/size              53000
trainer/QF1 Loss                   13.0178
trainer/QF2 Loss                   13.0611
trainer/Policy Loss                31.6208
trainer/Q1 Predictions Mean       -30.12
trainer/Q1 Predictions Std          9.2143
trainer/Q1 Predictions Max        -21.6625
trainer/Q1 Predictions Min        -68.9712
trainer/Q2 Predictions Mean       -30.1496
trainer/Q2 Predictions Std          9.22964
trainer/Q2 Predictions Max        -21.6765
trainer/Q2 Predictions Min        -69.0574
trainer/Q Targets Mean            -30.0406
trainer/Q Targets Std               9.68489
trainer/Q Targets Max              -1.107
trainer/Q Targets Min             -69.1176
trainer/Log Pis Mean                2.01338
trainer/Log Pis Std                 1.0547
trainer/Log Pis Max                 5.18316
trainer/Log Pis Min                -1.09048
trainer/Policy mu Mean              0.0764154
trainer/Policy mu Std               0.642482
trainer/Policy mu Max               2.8024
trainer/Policy mu Min              -3.09842
trainer/Policy log std Mean        -2.12875
trainer/Policy log std Std          0.578107
trainer/Policy log std Max         -0.427186
trainer/Policy log std Min         -2.92337
trainer/Alpha                       0.0992085
trainer/Alpha Loss                  0.0309217
exploration/num steps total     53000
exploration/num paths total       530
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.29754
exploration/Rewards Std             0.389211
exploration/Rewards Max            -0.039992
exploration/Rewards Min            -4.14378
exploration/Returns Mean          -29.754
exploration/Returns Std             5.67206
exploration/Returns Max           -24.082
exploration/Returns Min           -35.4261
exploration/Actions Mean            0.0125342
exploration/Actions Std             0.149955
exploration/Actions Max             0.992097
exploration/Actions Min            -0.589712
exploration/Num Paths               2
exploration/Average Returns       -29.754
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.555407
evaluation/Rewards Std              0.797504
evaluation/Rewards Max             -0.219717
evaluation/Rewards Min             -8.25276
evaluation/Returns Mean           -55.5407
evaluation/Returns Std             16.6341
evaluation/Returns Max            -25.5903
evaluation/Returns Min            -82.1137
evaluation/Actions Mean             0.0136675
evaluation/Actions Std              0.176661
evaluation/Actions Max              0.991413
evaluation/Actions Min             -0.986985
evaluation/Num Paths               10
evaluation/Average Returns        -55.5407
time/data storing (s)               0.0014741
time/evaluation sampling (s)        0.228821
time/exploration sampling (s)       0.0638733
time/logging (s)                    0.00339464
time/saving (s)                     0.00197913
time/training (s)                   0.780255
time/epoch (s)                      1.0798
time/total (s)                    281.757
Epoch                             263
-----------------------------  ---------------
2019-04-21 01:16:26.535799 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 264 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                    0.363572
trainer/QF2 Loss                    0.344215
trainer/Policy Loss                30.2596
trainer/Q1 Predictions Mean       -28.6051
trainer/Q1 Predictions Std          8.19908
trainer/Q1 Predictions Max        -21.1709
trainer/Q1 Predictions Min        -56.5008
trainer/Q2 Predictions Mean       -28.6207
trainer/Q2 Predictions Std          8.15401
trainer/Q2 Predictions Max        -21.1962
trainer/Q2 Predictions Min        -56.1571
trainer/Q Targets Mean            -29.1744
trainer/Q Targets Std               8.18315
trainer/Q Targets Max             -21.7132
trainer/Q Targets Min             -56.6829
trainer/Log Pis Mean                2.04289
trainer/Log Pis Std                 1.09548
trainer/Log Pis Max                 4.70544
trainer/Log Pis Min                -1.09948
trainer/Policy mu Mean              0.104469
trainer/Policy mu Std               0.556446
trainer/Policy mu Max               2.67329
trainer/Policy mu Min              -2.59222
trainer/Policy log std Mean        -2.20381
trainer/Policy log std Std          0.545208
trainer/Policy log std Max         -0.629036
trainer/Policy log std Min         -2.94759
trainer/Alpha                       0.0985698
trainer/Alpha Loss                  0.0993704
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.746276
exploration/Rewards Std             0.402178
exploration/Rewards Max            -0.447579
exploration/Rewards Min            -3.95255
exploration/Returns Mean          -74.6276
exploration/Returns Std             0.951366
exploration/Returns Max           -73.6762
exploration/Returns Min           -75.5789
exploration/Actions Mean           -0.00649821
exploration/Actions Std             0.201159
exploration/Actions Max             0.989843
exploration/Actions Min            -0.978709
exploration/Num Paths               2
exploration/Average Returns       -74.6276
evaluation/num steps total     265000
evaluation/num paths total       2650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.609473
evaluation/Rewards Std              0.943932
evaluation/Rewards Max             -0.211673
evaluation/Rewards Min            -10.3803
evaluation/Returns Mean           -60.9473
evaluation/Returns Std             26.602
evaluation/Returns Max            -23.2902
evaluation/Returns Min           -116.105
evaluation/Actions Mean            -0.00259932
evaluation/Actions Std              0.181846
evaluation/Actions Max              0.993863
evaluation/Actions Min             -0.996086
evaluation/Num Paths               10
evaluation/Average Returns        -60.9473
time/data storing (s)               0.00142844
time/evaluation sampling (s)        0.228609
time/exploration sampling (s)       0.0654743
time/logging (s)                    0.00260867
time/saving (s)                     0.00158125
time/training (s)                   0.774417
time/epoch (s)                      1.07412
time/total (s)                    282.835
Epoch                             264
-----------------------------  ---------------
2019-04-21 01:16:27.606893 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 265 finished
-----------------------------  ----------------
replay_buffer/size              53400
trainer/QF1 Loss                    0.257068
trainer/QF2 Loss                    0.258826
trainer/Policy Loss                32.9453
trainer/Q1 Predictions Mean       -31.3216
trainer/Q1 Predictions Std          8.53759
trainer/Q1 Predictions Max        -21.6304
trainer/Q1 Predictions Min        -59.3354
trainer/Q2 Predictions Mean       -31.3237
trainer/Q2 Predictions Std          8.5112
trainer/Q2 Predictions Max        -21.5852
trainer/Q2 Predictions Min        -58.8455
trainer/Q Targets Mean            -31.6739
trainer/Q Targets Std               8.75251
trainer/Q Targets Max             -21.5944
trainer/Q Targets Min             -59.4147
trainer/Log Pis Mean                2.14646
trainer/Log Pis Std                 1.08627
trainer/Log Pis Max                 5.15414
trainer/Log Pis Min                -1.14551
trainer/Policy mu Mean              0.0612607
trainer/Policy mu Std               0.716719
trainer/Policy mu Max               2.8054
trainer/Policy mu Min              -2.03208
trainer/Policy log std Mean        -2.0509
trainer/Policy log std Std          0.626679
trainer/Policy log std Max         -0.480571
trainer/Policy log std Min         -2.90021
trainer/Alpha                       0.0974482
trainer/Alpha Loss                  0.341028
exploration/num steps total     53400
exploration/num paths total       534
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.340601
exploration/Rewards Std             0.711052
exploration/Rewards Max            -0.0659805
exploration/Rewards Min            -6.40554
exploration/Returns Mean          -34.0601
exploration/Returns Std            11.7588
exploration/Returns Max           -22.3014
exploration/Returns Min           -45.8189
exploration/Actions Mean            0.0151917
exploration/Actions Std             0.164813
exploration/Actions Max             0.997801
exploration/Actions Min            -0.789269
exploration/Num Paths               2
exploration/Average Returns       -34.0601
evaluation/num steps total     266000
evaluation/num paths total       2660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.533609
evaluation/Rewards Std              0.772367
evaluation/Rewards Max             -0.192143
evaluation/Rewards Min             -8.78789
evaluation/Returns Mean           -53.3609
evaluation/Returns Std             24.1983
evaluation/Returns Max            -22.8396
evaluation/Returns Min            -98.4404
evaluation/Actions Mean            -0.000371132
evaluation/Actions Std              0.165446
evaluation/Actions Max              0.993651
evaluation/Actions Min             -0.9913
evaluation/Num Paths               10
evaluation/Average Returns        -53.3609
time/data storing (s)               0.00122449
time/evaluation sampling (s)        0.228687
time/exploration sampling (s)       0.0676525
time/logging (s)                    0.00336165
time/saving (s)                     0.00196183
time/training (s)                   0.760744
time/epoch (s)                      1.06363
time/total (s)                    283.903
Epoch                             265
-----------------------------  ----------------
2019-04-21 01:16:28.668658 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 266 finished
-----------------------------  ----------------
replay_buffer/size              53600
trainer/QF1 Loss                   74.9469
trainer/QF2 Loss                   74.9176
trainer/Policy Loss                33.4062
trainer/Q1 Predictions Mean       -32.0852
trainer/Q1 Predictions Std         10.3741
trainer/Q1 Predictions Max        -21.355
trainer/Q1 Predictions Min        -90.6867
trainer/Q2 Predictions Mean       -32.0678
trainer/Q2 Predictions Std         10.3215
trainer/Q2 Predictions Max        -21.3468
trainer/Q2 Predictions Min        -90.623
trainer/Q Targets Mean            -31.2373
trainer/Q Targets Std               9.49353
trainer/Q Targets Max              -1.06518
trainer/Q Targets Min             -80.2056
trainer/Log Pis Mean                1.95805
trainer/Log Pis Std                 1.27443
trainer/Log Pis Max                 6.87017
trainer/Log Pis Min                -2.4533
trainer/Policy mu Mean              0.0688935
trainer/Policy mu Std               0.675174
trainer/Policy mu Max               3.06584
trainer/Policy mu Min              -2.14962
trainer/Policy log std Mean        -2.01424
trainer/Policy log std Std          0.561445
trainer/Policy log std Max         -0.462139
trainer/Policy log std Min         -2.8348
trainer/Alpha                       0.0976688
trainer/Alpha Loss                 -0.0975771
exploration/num steps total     53600
exploration/num paths total       536
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.498884
exploration/Rewards Std             1.12037
exploration/Rewards Max            -0.0678139
exploration/Rewards Min            -8.51391
exploration/Returns Mean          -49.8884
exploration/Returns Std            12.7637
exploration/Returns Max           -37.1247
exploration/Returns Min           -62.6521
exploration/Actions Mean           -0.000810494
exploration/Actions Std             0.213362
exploration/Actions Max             0.998618
exploration/Actions Min            -0.996229
exploration/Num Paths               2
exploration/Average Returns       -49.8884
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.797269
evaluation/Rewards Std              1.04555
evaluation/Rewards Max             -0.202933
evaluation/Rewards Min            -11.0979
evaluation/Returns Mean           -79.7269
evaluation/Returns Std             23.5447
evaluation/Returns Max            -28.0887
evaluation/Returns Min           -115.959
evaluation/Actions Mean            -0.0286651
evaluation/Actions Std              0.187667
evaluation/Actions Max              0.984414
evaluation/Actions Min             -0.996403
evaluation/Num Paths               10
evaluation/Average Returns        -79.7269
time/data storing (s)               0.00124326
time/evaluation sampling (s)        0.225075
time/exploration sampling (s)       0.0646147
time/logging (s)                    0.00343849
time/saving (s)                     0.00201898
time/training (s)                   0.7569
time/epoch (s)                      1.05329
time/total (s)                    284.96
Epoch                             266
-----------------------------  ----------------
2019-04-21 01:16:29.766059 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 267 finished
-----------------------------  ---------------
replay_buffer/size              53800
trainer/QF1 Loss                    5.6051
trainer/QF2 Loss                    5.66993
trainer/Policy Loss                33.0014
trainer/Q1 Predictions Mean       -31.3877
trainer/Q1 Predictions Std         11.9126
trainer/Q1 Predictions Max        -21.2076
trainer/Q1 Predictions Min       -102.208
trainer/Q2 Predictions Mean       -31.398
trainer/Q2 Predictions Std         11.9404
trainer/Q2 Predictions Max        -21.1967
trainer/Q2 Predictions Min       -102.627
trainer/Q Targets Mean            -31.4269
trainer/Q Targets Std              12.2565
trainer/Q Targets Max              -1.82859
trainer/Q Targets Min            -103.293
trainer/Log Pis Mean                2.1924
trainer/Log Pis Std                 1.36774
trainer/Log Pis Max                 7.01866
trainer/Log Pis Min                -3.61644
trainer/Policy mu Mean              0.0385824
trainer/Policy mu Std               0.713294
trainer/Policy mu Max               2.89848
trainer/Policy mu Min              -2.99128
trainer/Policy log std Mean        -2.08232
trainer/Policy log std Std          0.589197
trainer/Policy log std Max         -0.420146
trainer/Policy log std Min         -2.89764
trainer/Alpha                       0.0955283
trainer/Alpha Loss                  0.451848
exploration/num steps total     53800
exploration/num paths total       538
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.862823
exploration/Rewards Std             1.50299
exploration/Rewards Max            -0.0983052
exploration/Rewards Min            -9.19697
exploration/Returns Mean          -86.2823
exploration/Returns Std            21.9902
exploration/Returns Max           -64.292
exploration/Returns Min          -108.273
exploration/Actions Mean           -0.0208427
exploration/Actions Std             0.265978
exploration/Actions Max             0.998925
exploration/Actions Min            -0.994684
exploration/Num Paths               2
exploration/Average Returns       -86.2823
evaluation/num steps total     268000
evaluation/num paths total       2680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.591791
evaluation/Rewards Std              0.896674
evaluation/Rewards Max             -0.197303
evaluation/Rewards Min            -10.2304
evaluation/Returns Mean           -59.1791
evaluation/Returns Std             20.6714
evaluation/Returns Max            -22.0151
evaluation/Returns Min            -96.6503
evaluation/Actions Mean             0.0152486
evaluation/Actions Std              0.171374
evaluation/Actions Max              0.99473
evaluation/Actions Min             -0.991755
evaluation/Num Paths               10
evaluation/Average Returns        -59.1791
time/data storing (s)               0.00123129
time/evaluation sampling (s)        0.2276
time/exploration sampling (s)       0.063607
time/logging (s)                    0.00358821
time/saving (s)                     0.00225906
time/training (s)                   0.790813
time/epoch (s)                      1.0891
time/total (s)                    286.054
Epoch                             267
-----------------------------  ---------------
2019-04-21 01:16:30.843720 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 268 finished
-----------------------------  ---------------
replay_buffer/size              54000
trainer/QF1 Loss                   12.5519
trainer/QF2 Loss                   12.574
trainer/Policy Loss                33.1473
trainer/Q1 Predictions Mean       -31.8093
trainer/Q1 Predictions Std          8.64596
trainer/Q1 Predictions Max        -21.2712
trainer/Q1 Predictions Min        -59.6302
trainer/Q2 Predictions Mean       -31.8078
trainer/Q2 Predictions Std          8.62717
trainer/Q2 Predictions Max        -21.2225
trainer/Q2 Predictions Min        -59.6114
trainer/Q Targets Mean            -31.9505
trainer/Q Targets Std               9.4779
trainer/Q Targets Max              -0.731011
trainer/Q Targets Min             -60.6412
trainer/Log Pis Mean                2.03085
trainer/Log Pis Std                 1.32906
trainer/Log Pis Max                 6.63153
trainer/Log Pis Min                -2.21778
trainer/Policy mu Mean              0.0730364
trainer/Policy mu Std               0.793735
trainer/Policy mu Max               2.98797
trainer/Policy mu Min              -2.33493
trainer/Policy log std Mean        -2.03298
trainer/Policy log std Std          0.664219
trainer/Policy log std Max         -0.3787
trainer/Policy log std Min         -2.90423
trainer/Alpha                       0.0964905
trainer/Alpha Loss                  0.0721509
exploration/num steps total     54000
exploration/num paths total       540
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.8024
exploration/Rewards Std             1.4562
exploration/Rewards Max            -0.0336175
exploration/Rewards Min            -9.27013
exploration/Returns Mean          -80.24
exploration/Returns Std            25.0225
exploration/Returns Max           -55.2175
exploration/Returns Min          -105.263
exploration/Actions Mean            0.00758471
exploration/Actions Std             0.257143
exploration/Actions Max             0.998451
exploration/Actions Min            -0.997288
exploration/Num Paths               2
exploration/Average Returns       -80.24
evaluation/num steps total     269000
evaluation/num paths total       2690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.490701
evaluation/Rewards Std              1.00493
evaluation/Rewards Max             -0.146024
evaluation/Rewards Min             -9.71462
evaluation/Returns Mean           -49.0701
evaluation/Returns Std             24.9398
evaluation/Returns Max            -22.3138
evaluation/Returns Min           -107.323
evaluation/Actions Mean             0.00216803
evaluation/Actions Std              0.184062
evaluation/Actions Max              0.994493
evaluation/Actions Min             -0.995371
evaluation/Num Paths               10
evaluation/Average Returns        -49.0701
time/data storing (s)               0.00152854
time/evaluation sampling (s)        0.229795
time/exploration sampling (s)       0.0642273
time/logging (s)                    0.00337921
time/saving (s)                     0.00196476
time/training (s)                   0.76852
time/epoch (s)                      1.06942
time/total (s)                    287.127
Epoch                             268
-----------------------------  ---------------
2019-04-21 01:16:31.904240 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 269 finished
-----------------------------  ---------------
replay_buffer/size              54200
trainer/QF1 Loss                   12.6446
trainer/QF2 Loss                   12.6314
trainer/Policy Loss                32.2895
trainer/Q1 Predictions Mean       -30.6851
trainer/Q1 Predictions Std          7.54012
trainer/Q1 Predictions Max        -20.9524
trainer/Q1 Predictions Min        -41.3832
trainer/Q2 Predictions Mean       -30.6557
trainer/Q2 Predictions Std          7.5411
trainer/Q2 Predictions Max        -20.895
trainer/Q2 Predictions Min        -41.424
trainer/Q Targets Mean            -30.809
trainer/Q Targets Std               8.29712
trainer/Q Targets Max              -0.935285
trainer/Q Targets Min             -41.86
trainer/Log Pis Mean                2.13254
trainer/Log Pis Std                 1.10811
trainer/Log Pis Max                 4.45857
trainer/Log Pis Min                -2.71977
trainer/Policy mu Mean             -0.0792342
trainer/Policy mu Std               0.665133
trainer/Policy mu Max               2.59514
trainer/Policy mu Min              -2.16236
trainer/Policy log std Mean        -2.08853
trainer/Policy log std Std          0.594944
trainer/Policy log std Max         -0.668674
trainer/Policy log std Min         -2.95328
trainer/Alpha                       0.0968263
trainer/Alpha Loss                  0.309483
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.319255
exploration/Rewards Std             0.373426
exploration/Rewards Max            -0.120404
exploration/Rewards Min            -3.84249
exploration/Returns Mean          -31.9255
exploration/Returns Std             3.37071
exploration/Returns Max           -28.5548
exploration/Returns Min           -35.2962
exploration/Actions Mean            0.0177219
exploration/Actions Std             0.164496
exploration/Actions Max             0.997242
exploration/Actions Min            -0.899816
exploration/Num Paths               2
exploration/Average Returns       -31.9255
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.648105
evaluation/Rewards Std              1.11857
evaluation/Rewards Max             -0.226455
evaluation/Rewards Min             -9.87929
evaluation/Returns Mean           -64.8105
evaluation/Returns Std             26.4856
evaluation/Returns Max            -32.495
evaluation/Returns Min           -108.791
evaluation/Actions Mean            -0.0101282
evaluation/Actions Std              0.194496
evaluation/Actions Max              0.993905
evaluation/Actions Min             -0.995138
evaluation/Num Paths               10
evaluation/Average Returns        -64.8105
time/data storing (s)               0.00136366
time/evaluation sampling (s)        0.215268
time/exploration sampling (s)       0.0636453
time/logging (s)                    0.00338015
time/saving (s)                     0.00195971
time/training (s)                   0.766565
time/epoch (s)                      1.05218
time/total (s)                    288.184
Epoch                             269
-----------------------------  ---------------
2019-04-21 01:16:32.971480 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 270 finished
-----------------------------  ---------------
replay_buffer/size              54400
trainer/QF1 Loss                    0.215628
trainer/QF2 Loss                    0.225017
trainer/Policy Loss                31.2079
trainer/Q1 Predictions Mean       -29.7162
trainer/Q1 Predictions Std          7.98667
trainer/Q1 Predictions Max        -20.8835
trainer/Q1 Predictions Min        -54.2187
trainer/Q2 Predictions Mean       -29.7276
trainer/Q2 Predictions Std          7.99155
trainer/Q2 Predictions Max        -20.9231
trainer/Q2 Predictions Min        -54.9494
trainer/Q Targets Mean            -30.0519
trainer/Q Targets Std               8.0476
trainer/Q Targets Max             -21.0338
trainer/Q Targets Min             -55.5875
trainer/Log Pis Mean                2.05675
trainer/Log Pis Std                 1.03643
trainer/Log Pis Max                 5.12032
trainer/Log Pis Min                -1.39528
trainer/Policy mu Mean              0.105692
trainer/Policy mu Std               0.738943
trainer/Policy mu Max               2.68866
trainer/Policy mu Min              -2.20068
trainer/Policy log std Mean        -1.99737
trainer/Policy log std Std          0.616475
trainer/Policy log std Max         -0.544672
trainer/Policy log std Min         -2.92625
trainer/Alpha                       0.0962091
trainer/Alpha Loss                  0.132845
exploration/num steps total     54400
exploration/num paths total       544
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.516456
exploration/Rewards Std             0.27626
exploration/Rewards Max            -0.131269
exploration/Rewards Min            -2.30923
exploration/Returns Mean          -51.6456
exploration/Returns Std            18.3149
exploration/Returns Max           -33.3308
exploration/Returns Min           -69.9605
exploration/Actions Mean            0.00126306
exploration/Actions Std             0.166358
exploration/Actions Max             0.946395
exploration/Actions Min            -0.936449
exploration/Num Paths               2
exploration/Average Returns       -51.6456
evaluation/num steps total     271000
evaluation/num paths total       2710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.665382
evaluation/Rewards Std              1.00701
evaluation/Rewards Max             -0.25677
evaluation/Rewards Min            -10.2094
evaluation/Returns Mean           -66.5382
evaluation/Returns Std             20.0599
evaluation/Returns Max            -30.867
evaluation/Returns Min            -93.9617
evaluation/Actions Mean             0.0053219
evaluation/Actions Std              0.19862
evaluation/Actions Max              0.995277
evaluation/Actions Min             -0.994206
evaluation/Num Paths               10
evaluation/Average Returns        -66.5382
time/data storing (s)               0.00131682
time/evaluation sampling (s)        0.222071
time/exploration sampling (s)       0.0663275
time/logging (s)                    0.00335727
time/saving (s)                     0.0019702
time/training (s)                   0.764063
time/epoch (s)                      1.05911
time/total (s)                    289.247
Epoch                             270
-----------------------------  ---------------
2019-04-21 01:16:34.046483 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 271 finished
-----------------------------  ----------------
replay_buffer/size              54600
trainer/QF1 Loss                    0.187116
trainer/QF2 Loss                    0.170165
trainer/Policy Loss                30.9641
trainer/Q1 Predictions Mean       -29.5629
trainer/Q1 Predictions Std          7.93635
trainer/Q1 Predictions Max        -20.4204
trainer/Q1 Predictions Min        -53.1564
trainer/Q2 Predictions Mean       -29.605
trainer/Q2 Predictions Std          7.98463
trainer/Q2 Predictions Max        -20.4977
trainer/Q2 Predictions Min        -55.1046
trainer/Q Targets Mean            -29.9557
trainer/Q Targets Std               7.88598
trainer/Q Targets Max             -20.8352
trainer/Q Targets Min             -54.136
trainer/Log Pis Mean                1.98361
trainer/Log Pis Std                 1.10233
trainer/Log Pis Max                 5.73456
trainer/Log Pis Min                -1.70574
trainer/Policy mu Mean              0.0824625
trainer/Policy mu Std               0.653856
trainer/Policy mu Max               2.46059
trainer/Policy mu Min              -2.2902
trainer/Policy log std Mean        -2.04333
trainer/Policy log std Std          0.595207
trainer/Policy log std Max         -0.660418
trainer/Policy log std Min         -2.90146
trainer/Alpha                       0.0954517
trainer/Alpha Loss                 -0.0385104
exploration/num steps total     54600
exploration/num paths total       546
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.490407
exploration/Rewards Std             0.509139
exploration/Rewards Max            -0.0571437
exploration/Rewards Min            -4.73434
exploration/Returns Mean          -49.0407
exploration/Returns Std            10.574
exploration/Returns Max           -38.4668
exploration/Returns Min           -59.6147
exploration/Actions Mean           -0.000792158
exploration/Actions Std             0.189731
exploration/Actions Max             0.969443
exploration/Actions Min            -0.99648
exploration/Num Paths               2
exploration/Average Returns       -49.0407
evaluation/num steps total     272000
evaluation/num paths total       2720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.638923
evaluation/Rewards Std              1.01559
evaluation/Rewards Max             -0.202263
evaluation/Rewards Min            -10.2004
evaluation/Returns Mean           -63.8923
evaluation/Returns Std             20.9798
evaluation/Returns Max            -34.3334
evaluation/Returns Min           -104.89
evaluation/Actions Mean            -0.0110116
evaluation/Actions Std              0.193278
evaluation/Actions Max              0.994469
evaluation/Actions Min             -0.996305
evaluation/Num Paths               10
evaluation/Average Returns        -63.8923
time/data storing (s)               0.00124685
time/evaluation sampling (s)        0.226186
time/exploration sampling (s)       0.0648586
time/logging (s)                    0.00355111
time/saving (s)                     0.00224408
time/training (s)                   0.768906
time/epoch (s)                      1.06699
time/total (s)                    290.318
Epoch                             271
-----------------------------  ----------------
2019-04-21 01:16:35.118374 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 272 finished
-----------------------------  ---------------
replay_buffer/size              54800
trainer/QF1 Loss                   19.06
trainer/QF2 Loss                   18.8494
trainer/Policy Loss                32.0004
trainer/Q1 Predictions Mean       -30.7689
trainer/Q1 Predictions Std          9.75884
trainer/Q1 Predictions Max        -20.4563
trainer/Q1 Predictions Min        -79.6711
trainer/Q2 Predictions Mean       -30.7916
trainer/Q2 Predictions Std          9.80499
trainer/Q2 Predictions Max        -20.4861
trainer/Q2 Predictions Min        -80.8614
trainer/Q Targets Mean            -30.4053
trainer/Q Targets Std              10.5115
trainer/Q Targets Max              -2.04206
trainer/Q Targets Min             -80.6132
trainer/Log Pis Mean                1.93997
trainer/Log Pis Std                 1.02442
trainer/Log Pis Max                 5.38785
trainer/Log Pis Min                -0.887393
trainer/Policy mu Mean             -0.0317635
trainer/Policy mu Std               0.699282
trainer/Policy mu Max               2.55794
trainer/Policy mu Min              -2.59812
trainer/Policy log std Mean        -2.04828
trainer/Policy log std Std          0.607993
trainer/Policy log std Max         -0.526917
trainer/Policy log std Min         -2.88902
trainer/Alpha                       0.0957156
trainer/Alpha Loss                 -0.14086
exploration/num steps total     54800
exploration/num paths total       548
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.483161
exploration/Rewards Std             0.554244
exploration/Rewards Max            -0.0501441
exploration/Rewards Min            -5.28943
exploration/Returns Mean          -48.3161
exploration/Returns Std            26.6673
exploration/Returns Max           -21.6489
exploration/Returns Min           -74.9834
exploration/Actions Mean            0.0089294
exploration/Actions Std             0.183103
exploration/Actions Max             0.998736
exploration/Actions Min            -0.901375
exploration/Num Paths               2
exploration/Average Returns       -48.3161
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.458251
evaluation/Rewards Std              1.00484
evaluation/Rewards Max             -0.179899
evaluation/Rewards Min            -10.1754
evaluation/Returns Mean           -45.8251
evaluation/Returns Std             22.3138
evaluation/Returns Max            -20.3909
evaluation/Returns Min            -81.0356
evaluation/Actions Mean             0.0154983
evaluation/Actions Std              0.175963
evaluation/Actions Max              0.995461
evaluation/Actions Min             -0.990071
evaluation/Num Paths               10
evaluation/Average Returns        -45.8251
time/data storing (s)               0.00121372
time/evaluation sampling (s)        0.228235
time/exploration sampling (s)       0.0660929
time/logging (s)                    0.00333286
time/saving (s)                     0.00203647
time/training (s)                   0.762827
time/epoch (s)                      1.06374
time/total (s)                    291.385
Epoch                             272
-----------------------------  ---------------
2019-04-21 01:16:36.188355 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 273 finished
-----------------------------  ---------------
replay_buffer/size              55000
trainer/QF1 Loss                   12.607
trainer/QF2 Loss                   12.5902
trainer/Policy Loss                31.1005
trainer/Q1 Predictions Mean       -29.5669
trainer/Q1 Predictions Std          7.64804
trainer/Q1 Predictions Max        -20.2908
trainer/Q1 Predictions Min        -46.5007
trainer/Q2 Predictions Mean       -29.5979
trainer/Q2 Predictions Std          7.66073
trainer/Q2 Predictions Max        -20.2749
trainer/Q2 Predictions Min        -46.6204
trainer/Q Targets Mean            -29.5926
trainer/Q Targets Std               8.14208
trainer/Q Targets Max              -1.13189
trainer/Q Targets Min             -46.8966
trainer/Log Pis Mean                1.8822
trainer/Log Pis Std                 0.980236
trainer/Log Pis Max                 3.24365
trainer/Log Pis Min                -1.7882
trainer/Policy mu Mean             -0.0264406
trainer/Policy mu Std               0.42354
trainer/Policy mu Max               1.56688
trainer/Policy mu Min              -2.34192
trainer/Policy log std Mean        -2.22802
trainer/Policy log std Std          0.424394
trainer/Policy log std Max         -0.596742
trainer/Policy log std Min         -2.83028
trainer/Alpha                       0.0973634
trainer/Alpha Loss                 -0.274394
exploration/num steps total     55000
exploration/num paths total       550
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.591865
exploration/Rewards Std             0.903507
exploration/Rewards Max            -0.0971424
exploration/Rewards Min            -8.10556
exploration/Returns Mean          -59.1865
exploration/Returns Std             5.26854
exploration/Returns Max           -53.918
exploration/Returns Min           -64.455
exploration/Actions Mean           -0.0105043
exploration/Actions Std             0.22807
exploration/Actions Max             0.990759
exploration/Actions Min            -0.995789
exploration/Num Paths               2
exploration/Average Returns       -59.1865
evaluation/num steps total     274000
evaluation/num paths total       2740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.485589
evaluation/Rewards Std              0.725826
evaluation/Rewards Max             -0.218107
evaluation/Rewards Min             -8.41748
evaluation/Returns Mean           -48.5589
evaluation/Returns Std             15.9475
evaluation/Returns Max            -29.9078
evaluation/Returns Min            -69.5925
evaluation/Actions Mean             0.0108859
evaluation/Actions Std              0.174259
evaluation/Actions Max              0.993973
evaluation/Actions Min             -0.978664
evaluation/Num Paths               10
evaluation/Average Returns        -48.5589
time/data storing (s)               0.00126047
time/evaluation sampling (s)        0.227085
time/exploration sampling (s)       0.0653128
time/logging (s)                    0.00335081
time/saving (s)                     0.00196656
time/training (s)                   0.762976
time/epoch (s)                      1.06195
time/total (s)                    292.451
Epoch                             273
-----------------------------  ---------------
2019-04-21 01:16:37.254885 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 274 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                   24.9281
trainer/QF2 Loss                   24.9666
trainer/Policy Loss                32.1931
trainer/Q1 Predictions Mean       -31.1526
trainer/Q1 Predictions Std         11.1249
trainer/Q1 Predictions Max        -20.3098
trainer/Q1 Predictions Min        -99.7491
trainer/Q2 Predictions Mean       -31.1279
trainer/Q2 Predictions Std         11.1424
trainer/Q2 Predictions Max        -20.2398
trainer/Q2 Predictions Min       -100.066
trainer/Q Targets Mean            -30.5992
trainer/Q Targets Std              12.7727
trainer/Q Targets Max              -0.341984
trainer/Q Targets Min            -101.531
trainer/Log Pis Mean                1.81927
trainer/Log Pis Std                 1.46115
trainer/Log Pis Max                 6.98828
trainer/Log Pis Min                -2.69501
trainer/Policy mu Mean              0.0222953
trainer/Policy mu Std               0.725834
trainer/Policy mu Max               2.8939
trainer/Policy mu Min              -2.84869
trainer/Policy log std Mean        -2.00201
trainer/Policy log std Std          0.613749
trainer/Policy log std Max         -0.343051
trainer/Policy log std Min         -2.81867
trainer/Alpha                       0.0987038
trainer/Alpha Loss                 -0.418503
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.90484
exploration/Rewards Std             1.23911
exploration/Rewards Max            -0.331132
exploration/Rewards Min            -9.22978
exploration/Returns Mean          -90.484
exploration/Returns Std            13.6641
exploration/Returns Max           -76.8199
exploration/Returns Min          -104.148
exploration/Actions Mean           -0.023471
exploration/Actions Std             0.260826
exploration/Actions Max             0.971525
exploration/Actions Min            -0.995311
exploration/Num Paths               2
exploration/Average Returns       -90.484
evaluation/num steps total     275000
evaluation/num paths total       2750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.497887
evaluation/Rewards Std              0.979993
evaluation/Rewards Max             -0.14528
evaluation/Rewards Min             -9.73186
evaluation/Returns Mean           -49.7887
evaluation/Returns Std             28.1383
evaluation/Returns Max            -19.0305
evaluation/Returns Min           -105.876
evaluation/Actions Mean             0.00936037
evaluation/Actions Std              0.184198
evaluation/Actions Max              0.993489
evaluation/Actions Min             -0.995349
evaluation/Num Paths               10
evaluation/Average Returns        -49.7887
time/data storing (s)               0.00126032
time/evaluation sampling (s)        0.224946
time/exploration sampling (s)       0.0646942
time/logging (s)                    0.00332433
time/saving (s)                     0.00192283
time/training (s)                   0.761941
time/epoch (s)                      1.05809
time/total (s)                    293.513
Epoch                             274
-----------------------------  ---------------
2019-04-21 01:16:38.324252 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 275 finished
-----------------------------  ---------------
replay_buffer/size              55400
trainer/QF1 Loss                    0.449499
trainer/QF2 Loss                    0.411401
trainer/Policy Loss                31.2331
trainer/Q1 Predictions Mean       -29.671
trainer/Q1 Predictions Std          9.48778
trainer/Q1 Predictions Max        -20.2892
trainer/Q1 Predictions Min        -86.5473
trainer/Q2 Predictions Mean       -29.6804
trainer/Q2 Predictions Std          9.48821
trainer/Q2 Predictions Max        -20.2738
trainer/Q2 Predictions Min        -86.4982
trainer/Q Targets Mean            -30.1804
trainer/Q Targets Std               9.73707
trainer/Q Targets Max             -20.3788
trainer/Q Targets Min             -87.3947
trainer/Log Pis Mean                2.04851
trainer/Log Pis Std                 0.92111
trainer/Log Pis Max                 4.42788
trainer/Log Pis Min                -1.17904
trainer/Policy mu Mean              0.106872
trainer/Policy mu Std               0.629492
trainer/Policy mu Max               3.02042
trainer/Policy mu Min              -2.09058
trainer/Policy log std Mean        -2.06619
trainer/Policy log std Std          0.558968
trainer/Policy log std Max         -0.201951
trainer/Policy log std Min         -2.84943
trainer/Alpha                       0.0986878
trainer/Alpha Loss                  0.112342
exploration/num steps total     55400
exploration/num paths total       554
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.744058
exploration/Rewards Std             0.530688
exploration/Rewards Max            -0.370881
exploration/Rewards Min            -5.49763
exploration/Returns Mean          -74.4058
exploration/Returns Std             5.93014
exploration/Returns Max           -68.4757
exploration/Returns Min           -80.3359
exploration/Actions Mean           -0.00691669
exploration/Actions Std             0.208943
exploration/Actions Max             0.989831
exploration/Actions Min            -0.996379
exploration/Num Paths               2
exploration/Average Returns       -74.4058
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.624315
evaluation/Rewards Std              0.918395
evaluation/Rewards Max             -0.181927
evaluation/Rewards Min             -9.45579
evaluation/Returns Mean           -62.4315
evaluation/Returns Std             26.6621
evaluation/Returns Max            -25.0673
evaluation/Returns Min           -105.028
evaluation/Actions Mean            -0.00174365
evaluation/Actions Std              0.187455
evaluation/Actions Max              0.991266
evaluation/Actions Min             -0.994156
evaluation/Num Paths               10
evaluation/Average Returns        -62.4315
time/data storing (s)               0.00128772
time/evaluation sampling (s)        0.225225
time/exploration sampling (s)       0.0637662
time/logging (s)                    0.00334574
time/saving (s)                     0.00158025
time/training (s)                   0.76597
time/epoch (s)                      1.06118
time/total (s)                    294.579
Epoch                             275
-----------------------------  ---------------
2019-04-21 01:16:39.379644 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 276 finished
-----------------------------  ---------------
replay_buffer/size              55600
trainer/QF1 Loss                   24.5944
trainer/QF2 Loss                   24.5277
trainer/Policy Loss                31.4822
trainer/Q1 Predictions Mean       -30.1326
trainer/Q1 Predictions Std         10.8256
trainer/Q1 Predictions Max        -19.8719
trainer/Q1 Predictions Min        -83.7828
trainer/Q2 Predictions Mean       -30.1147
trainer/Q2 Predictions Std         10.7932
trainer/Q2 Predictions Max        -19.9058
trainer/Q2 Predictions Min        -83.9214
trainer/Q Targets Mean            -29.9584
trainer/Q Targets Std              11.7172
trainer/Q Targets Max              -1.05668
trainer/Q Targets Min             -87.65
trainer/Log Pis Mean                1.93053
trainer/Log Pis Std                 1.50096
trainer/Log Pis Max                 6.98312
trainer/Log Pis Min                -2.2912
trainer/Policy mu Mean              0.0378277
trainer/Policy mu Std               0.747617
trainer/Policy mu Max               2.95124
trainer/Policy mu Min              -2.59401
trainer/Policy log std Mean        -2.06588
trainer/Policy log std Std          0.607473
trainer/Policy log std Max         -0.404748
trainer/Policy log std Min         -2.82689
trainer/Alpha                       0.0982556
trainer/Alpha Loss                 -0.161199
exploration/num steps total     55600
exploration/num paths total       556
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.704278
exploration/Rewards Std             0.601228
exploration/Rewards Max            -0.388249
exploration/Rewards Min            -5.67403
exploration/Returns Mean          -70.4278
exploration/Returns Std             4.03904
exploration/Returns Max           -66.3887
exploration/Returns Min           -74.4668
exploration/Actions Mean           -0.00174161
exploration/Actions Std             0.221537
exploration/Actions Max             0.990549
exploration/Actions Min            -0.982955
exploration/Num Paths               2
exploration/Average Returns       -70.4278
evaluation/num steps total     277000
evaluation/num paths total       2770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.663033
evaluation/Rewards Std              0.861581
evaluation/Rewards Max             -0.20307
evaluation/Rewards Min             -9.48444
evaluation/Returns Mean           -66.3033
evaluation/Returns Std             18.0835
evaluation/Returns Max            -32.055
evaluation/Returns Min            -95.5659
evaluation/Actions Mean            -0.0128977
evaluation/Actions Std              0.187615
evaluation/Actions Max              0.990175
evaluation/Actions Min             -0.994555
evaluation/Num Paths               10
evaluation/Average Returns        -66.3033
time/data storing (s)               0.00120465
time/evaluation sampling (s)        0.219199
time/exploration sampling (s)       0.0614254
time/logging (s)                    0.0033964
time/saving (s)                     0.00198983
time/training (s)                   0.760217
time/epoch (s)                      1.04743
time/total (s)                    295.63
Epoch                             276
-----------------------------  ---------------
2019-04-21 01:16:40.453559 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 277 finished
-----------------------------  ---------------
replay_buffer/size              55800
trainer/QF1 Loss                   12.3347
trainer/QF2 Loss                   12.2382
trainer/Policy Loss                31.1044
trainer/Q1 Predictions Mean       -29.66
trainer/Q1 Predictions Std          8.60452
trainer/Q1 Predictions Max        -19.9822
trainer/Q1 Predictions Min        -64.5752
trainer/Q2 Predictions Mean       -29.6713
trainer/Q2 Predictions Std          8.60772
trainer/Q2 Predictions Max        -20.0416
trainer/Q2 Predictions Min        -64.6234
trainer/Q Targets Mean            -29.5072
trainer/Q Targets Std               9.17103
trainer/Q Targets Max              -0.464937
trainer/Q Targets Min             -65.6107
trainer/Log Pis Mean                1.98462
trainer/Log Pis Std                 1.28162
trainer/Log Pis Max                 6.30457
trainer/Log Pis Min                -1.55071
trainer/Policy mu Mean              0.0403952
trainer/Policy mu Std               0.624433
trainer/Policy mu Max               2.80882
trainer/Policy mu Min              -2.51519
trainer/Policy log std Mean        -2.1783
trainer/Policy log std Std          0.557258
trainer/Policy log std Max         -0.429194
trainer/Policy log std Min         -2.92693
trainer/Alpha                       0.0988082
trainer/Alpha Loss                 -0.0356074
exploration/num steps total     55800
exploration/num paths total       558
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.707172
exploration/Rewards Std             1.29792
exploration/Rewards Max            -0.0547786
exploration/Rewards Min           -10.0533
exploration/Returns Mean          -70.7172
exploration/Returns Std             2.82614
exploration/Returns Max           -67.8911
exploration/Returns Min           -73.5433
exploration/Actions Mean            0.0275761
exploration/Actions Std             0.250514
exploration/Actions Max             0.997567
exploration/Actions Min            -0.987464
exploration/Num Paths               2
exploration/Average Returns       -70.7172
evaluation/num steps total     278000
evaluation/num paths total       2780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.485314
evaluation/Rewards Std              0.781687
evaluation/Rewards Max             -0.192627
evaluation/Rewards Min             -8.49218
evaluation/Returns Mean           -48.5314
evaluation/Returns Std             17.2571
evaluation/Returns Max            -22.6293
evaluation/Returns Min            -71.8794
evaluation/Actions Mean             0.0157666
evaluation/Actions Std              0.174044
evaluation/Actions Max              0.992869
evaluation/Actions Min             -0.978228
evaluation/Num Paths               10
evaluation/Average Returns        -48.5314
time/data storing (s)               0.00150375
time/evaluation sampling (s)        0.228975
time/exploration sampling (s)       0.0644951
time/logging (s)                    0.00337722
time/saving (s)                     0.00196483
time/training (s)                   0.765156
time/epoch (s)                      1.06547
time/total (s)                    296.699
Epoch                             277
-----------------------------  ---------------
2019-04-21 01:16:41.508886 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 278 finished
-----------------------------  ---------------
replay_buffer/size              56000
trainer/QF1 Loss                    8.43224
trainer/QF2 Loss                    8.35952
trainer/Policy Loss                30.7283
trainer/Q1 Predictions Mean       -29.3305
trainer/Q1 Predictions Std          8.03381
trainer/Q1 Predictions Max        -19.6221
trainer/Q1 Predictions Min        -44.6181
trainer/Q2 Predictions Mean       -29.3049
trainer/Q2 Predictions Std          8.00768
trainer/Q2 Predictions Max        -19.6322
trainer/Q2 Predictions Min        -44.8641
trainer/Q Targets Mean            -29.0076
trainer/Q Targets Std               8.75275
trainer/Q Targets Max              -0.139978
trainer/Q Targets Min             -45.0198
trainer/Log Pis Mean                2.02253
trainer/Log Pis Std                 1.29563
trainer/Log Pis Max                 5.47551
trainer/Log Pis Min                -3.10987
trainer/Policy mu Mean              0.0166564
trainer/Policy mu Std               0.64508
trainer/Policy mu Max               2.54223
trainer/Policy mu Min              -2.02528
trainer/Policy log std Mean        -2.07227
trainer/Policy log std Std          0.605255
trainer/Policy log std Max         -0.527815
trainer/Policy log std Min         -2.86993
trainer/Alpha                       0.0989926
trainer/Alpha Loss                  0.0521158
exploration/num steps total     56000
exploration/num paths total       560
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.698843
exploration/Rewards Std             1.20124
exploration/Rewards Max            -0.0346337
exploration/Rewards Min            -8.79876
exploration/Returns Mean          -69.8843
exploration/Returns Std            27.7825
exploration/Returns Max           -42.1018
exploration/Returns Min           -97.6668
exploration/Actions Mean           -0.0172404
exploration/Actions Std             0.22981
exploration/Actions Max             0.995122
exploration/Actions Min            -0.997964
exploration/Num Paths               2
exploration/Average Returns       -69.8843
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.64023
evaluation/Rewards Std              1.01314
evaluation/Rewards Max             -0.188464
evaluation/Rewards Min            -10.7396
evaluation/Returns Mean           -64.023
evaluation/Returns Std             22.9077
evaluation/Returns Max            -23.3732
evaluation/Returns Min           -102.795
evaluation/Actions Mean            -0.00617235
evaluation/Actions Std              0.184647
evaluation/Actions Max              0.997729
evaluation/Actions Min             -0.997734
evaluation/Num Paths               10
evaluation/Average Returns        -64.023
time/data storing (s)               0.0014898
time/evaluation sampling (s)        0.214406
time/exploration sampling (s)       0.0647573
time/logging (s)                    0.00337776
time/saving (s)                     0.00196802
time/training (s)                   0.760702
time/epoch (s)                      1.0467
time/total (s)                    297.75
Epoch                             278
-----------------------------  ---------------
2019-04-21 01:16:42.567141 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 279 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                    0.167804
trainer/QF2 Loss                    0.190179
trainer/Policy Loss                30.1391
trainer/Q1 Predictions Mean       -28.761
trainer/Q1 Predictions Std          8.13562
trainer/Q1 Predictions Max        -19.7112
trainer/Q1 Predictions Min        -56.6679
trainer/Q2 Predictions Mean       -28.7439
trainer/Q2 Predictions Std          8.1104
trainer/Q2 Predictions Max        -19.6691
trainer/Q2 Predictions Min        -56.2496
trainer/Q Targets Mean            -29.0179
trainer/Q Targets Std               8.30892
trainer/Q Targets Max             -19.7383
trainer/Q Targets Min             -59.0565
trainer/Log Pis Mean                2.09338
trainer/Log Pis Std                 1.13321
trainer/Log Pis Max                 5.95293
trainer/Log Pis Min                -0.903389
trainer/Policy mu Mean              0.0847277
trainer/Policy mu Std               0.734221
trainer/Policy mu Max               2.58316
trainer/Policy mu Min              -2.40618
trainer/Policy log std Mean        -2.02153
trainer/Policy log std Std          0.626919
trainer/Policy log std Max         -0.333186
trainer/Policy log std Min         -2.93134
trainer/Alpha                       0.097101
trainer/Alpha Loss                  0.217769
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.627441
exploration/Rewards Std             0.537163
exploration/Rewards Max            -0.306497
exploration/Rewards Min            -5.40604
exploration/Returns Mean          -62.7441
exploration/Returns Std             5.34588
exploration/Returns Max           -57.3982
exploration/Returns Min           -68.09
exploration/Actions Mean            0.00409384
exploration/Actions Std             0.214308
exploration/Actions Max             0.997551
exploration/Actions Min            -0.966135
exploration/Num Paths               2
exploration/Average Returns       -62.7441
evaluation/num steps total     280000
evaluation/num paths total       2800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.49326
evaluation/Rewards Std              0.602918
evaluation/Rewards Max             -0.203733
evaluation/Rewards Min             -7.10183
evaluation/Returns Mean           -49.326
evaluation/Returns Std             17.3209
evaluation/Returns Max            -21.5296
evaluation/Returns Min            -75.3412
evaluation/Actions Mean            -0.00790667
evaluation/Actions Std              0.1593
evaluation/Actions Max              0.989561
evaluation/Actions Min             -0.990176
evaluation/Num Paths               10
evaluation/Average Returns        -49.326
time/data storing (s)               0.00125208
time/evaluation sampling (s)        0.223673
time/exploration sampling (s)       0.0659305
time/logging (s)                    0.00336057
time/saving (s)                     0.00197203
time/training (s)                   0.753716
time/epoch (s)                      1.0499
time/total (s)                    298.804
Epoch                             279
-----------------------------  ---------------
2019-04-21 01:16:43.643692 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 280 finished
-----------------------------  ---------------
replay_buffer/size              56400
trainer/QF1 Loss                   24.5788
trainer/QF2 Loss                   24.7336
trainer/Policy Loss                32.8968
trainer/Q1 Predictions Mean       -31.6668
trainer/Q1 Predictions Std         11.7835
trainer/Q1 Predictions Max        -19.4402
trainer/Q1 Predictions Min        -99.0288
trainer/Q2 Predictions Mean       -31.6995
trainer/Q2 Predictions Std         11.8127
trainer/Q2 Predictions Max        -19.431
trainer/Q2 Predictions Min        -98.9659
trainer/Q Targets Mean            -31.0422
trainer/Q Targets Std              12.5875
trainer/Q Targets Max              -0.621495
trainer/Q Targets Min            -101.482
trainer/Log Pis Mean                1.82889
trainer/Log Pis Std                 1.32814
trainer/Log Pis Max                 7.17617
trainer/Log Pis Min                -3.12241
trainer/Policy mu Mean             -0.0450876
trainer/Policy mu Std               0.751125
trainer/Policy mu Max               2.61863
trainer/Policy mu Min              -2.96363
trainer/Policy log std Mean        -1.92415
trainer/Policy log std Std          0.583205
trainer/Policy log std Max         -0.493963
trainer/Policy log std Min         -2.89719
trainer/Alpha                       0.0944478
trainer/Alpha Loss                 -0.403721
exploration/num steps total     56400
exploration/num paths total       564
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.578054
exploration/Rewards Std             0.75352
exploration/Rewards Max            -0.0730386
exploration/Rewards Min            -5.76448
exploration/Returns Mean          -57.8054
exploration/Returns Std            22.802
exploration/Returns Max           -35.0034
exploration/Returns Min           -80.6074
exploration/Actions Mean           -0.00412571
exploration/Actions Std             0.230035
exploration/Actions Max             0.996781
exploration/Actions Min            -0.989626
exploration/Num Paths               2
exploration/Average Returns       -57.8054
evaluation/num steps total     281000
evaluation/num paths total       2810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.65418
evaluation/Rewards Std              1.16316
evaluation/Rewards Max             -0.159274
evaluation/Rewards Min            -10.5178
evaluation/Returns Mean           -65.418
evaluation/Returns Std             27.4805
evaluation/Returns Max            -18.6386
evaluation/Returns Min           -117.504
evaluation/Actions Mean             0.0115473
evaluation/Actions Std              0.199863
evaluation/Actions Max              0.994648
evaluation/Actions Min             -0.995347
evaluation/Num Paths               10
evaluation/Average Returns        -65.418
time/data storing (s)               0.00154821
time/evaluation sampling (s)        0.225085
time/exploration sampling (s)       0.0652339
time/logging (s)                    0.003348
time/saving (s)                     0.00197849
time/training (s)                   0.771071
time/epoch (s)                      1.06826
time/total (s)                    299.877
Epoch                             280
-----------------------------  ---------------
2019-04-21 01:16:44.700064 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 281 finished
-----------------------------  ---------------
replay_buffer/size              56600
trainer/QF1 Loss                   12.4005
trainer/QF2 Loss                   12.4048
trainer/Policy Loss                31.6105
trainer/Q1 Predictions Mean       -30.1679
trainer/Q1 Predictions Std         10.5207
trainer/Q1 Predictions Max        -19.4231
trainer/Q1 Predictions Min        -75.0547
trainer/Q2 Predictions Mean       -30.1966
trainer/Q2 Predictions Std         10.5805
trainer/Q2 Predictions Max        -19.4351
trainer/Q2 Predictions Min        -75.3799
trainer/Q Targets Mean            -29.8252
trainer/Q Targets Std              10.8855
trainer/Q Targets Max              -1.17111
trainer/Q Targets Min             -73.8738
trainer/Log Pis Mean                1.95938
trainer/Log Pis Std                 1.24919
trainer/Log Pis Max                 6.05858
trainer/Log Pis Min                -1.40581
trainer/Policy mu Mean              0.0252807
trainer/Policy mu Std               0.708738
trainer/Policy mu Max               2.65258
trainer/Policy mu Min              -2.96128
trainer/Policy log std Mean        -2.07081
trainer/Policy log std Std          0.586949
trainer/Policy log std Max         -0.49491
trainer/Policy log std Min         -2.88964
trainer/Alpha                       0.0917875
trainer/Alpha Loss                 -0.097006
exploration/num steps total     56600
exploration/num paths total       566
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370452
exploration/Rewards Std             0.899429
exploration/Rewards Max            -0.0415792
exploration/Rewards Min            -8.04362
exploration/Returns Mean          -37.0452
exploration/Returns Std            13.0989
exploration/Returns Max           -23.9463
exploration/Returns Min           -50.1441
exploration/Actions Mean            0.044585
exploration/Actions Std             0.204246
exploration/Actions Max             0.997075
exploration/Actions Min            -0.256204
exploration/Num Paths               2
exploration/Average Returns       -37.0452
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.512308
evaluation/Rewards Std              0.815112
evaluation/Rewards Max             -0.172865
evaluation/Rewards Min             -8.67768
evaluation/Returns Mean           -51.2308
evaluation/Returns Std             28.1255
evaluation/Returns Max            -22.3104
evaluation/Returns Min            -96.771
evaluation/Actions Mean            -0.0142403
evaluation/Actions Std              0.180352
evaluation/Actions Max              0.989854
evaluation/Actions Min             -0.99379
evaluation/Num Paths               10
evaluation/Average Returns        -51.2308
time/data storing (s)               0.00123026
time/evaluation sampling (s)        0.222884
time/exploration sampling (s)       0.0662471
time/logging (s)                    0.00338079
time/saving (s)                     0.00196221
time/training (s)                   0.752445
time/epoch (s)                      1.04815
time/total (s)                    300.929
Epoch                             281
-----------------------------  ---------------
2019-04-21 01:16:45.770808 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 282 finished
-----------------------------  ---------------
replay_buffer/size              56800
trainer/QF1 Loss                   12.3163
trainer/QF2 Loss                   12.3167
trainer/Policy Loss                31.3927
trainer/Q1 Predictions Mean       -30.1931
trainer/Q1 Predictions Std          9.24781
trainer/Q1 Predictions Max        -19.2857
trainer/Q1 Predictions Min        -70.7091
trainer/Q2 Predictions Mean       -30.1887
trainer/Q2 Predictions Std          9.20929
trainer/Q2 Predictions Max        -19.2394
trainer/Q2 Predictions Min        -70.7141
trainer/Q Targets Mean            -29.9066
trainer/Q Targets Std               9.78682
trainer/Q Targets Max              -0.980997
trainer/Q Targets Min             -72.3602
trainer/Log Pis Mean                1.71146
trainer/Log Pis Std                 1.25606
trainer/Log Pis Max                 6.34059
trainer/Log Pis Min                -2.5042
trainer/Policy mu Mean              0.0664516
trainer/Policy mu Std               0.657425
trainer/Policy mu Max               2.77242
trainer/Policy mu Min              -2.44225
trainer/Policy log std Mean        -1.9932
trainer/Policy log std Std          0.574068
trainer/Policy log std Max         -0.329492
trainer/Policy log std Min         -2.85565
trainer/Alpha                       0.0907918
trainer/Alpha Loss                 -0.692192
exploration/num steps total     56800
exploration/num paths total       568
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.821488
exploration/Rewards Std             0.910577
exploration/Rewards Max            -0.34106
exploration/Rewards Min            -8.02253
exploration/Returns Mean          -82.1488
exploration/Returns Std             5.81641
exploration/Returns Max           -76.3324
exploration/Returns Min           -87.9652
exploration/Actions Mean           -0.02816
exploration/Actions Std             0.260914
exploration/Actions Max             0.986008
exploration/Actions Min            -0.998337
exploration/Num Paths               2
exploration/Average Returns       -82.1488
evaluation/num steps total     283000
evaluation/num paths total       2830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.540593
evaluation/Rewards Std              0.930099
evaluation/Rewards Max             -0.171027
evaluation/Rewards Min             -8.78818
evaluation/Returns Mean           -54.0593
evaluation/Returns Std             23.6322
evaluation/Returns Max            -21.7948
evaluation/Returns Min           -100.495
evaluation/Actions Mean             0.0109494
evaluation/Actions Std              0.188819
evaluation/Actions Max              0.993913
evaluation/Actions Min             -0.992655
evaluation/Num Paths               10
evaluation/Average Returns        -54.0593
time/data storing (s)               0.00118844
time/evaluation sampling (s)        0.223397
time/exploration sampling (s)       0.0621884
time/logging (s)                    0.00339477
time/saving (s)                     0.00197867
time/training (s)                   0.770155
time/epoch (s)                      1.0623
time/total (s)                    301.995
Epoch                             282
-----------------------------  ---------------
2019-04-21 01:16:46.841791 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 283 finished
-----------------------------  ---------------
replay_buffer/size              57000
trainer/QF1 Loss                   58.614
trainer/QF2 Loss                   58.6216
trainer/Policy Loss                29.899
trainer/Q1 Predictions Mean       -28.48
trainer/Q1 Predictions Std          9.9497
trainer/Q1 Predictions Max        -18.8766
trainer/Q1 Predictions Min        -88.4077
trainer/Q2 Predictions Mean       -28.4677
trainer/Q2 Predictions Std          9.94131
trainer/Q2 Predictions Max        -18.8236
trainer/Q2 Predictions Min        -88.3905
trainer/Q Targets Mean            -28.0413
trainer/Q Targets Std               8.19362
trainer/Q Targets Max             -11.9805
trainer/Q Targets Min             -47.9318
trainer/Log Pis Mean                2.1178
trainer/Log Pis Std                 0.917447
trainer/Log Pis Max                 5.3321
trainer/Log Pis Min                -0.831803
trainer/Policy mu Mean              0.0694588
trainer/Policy mu Std               0.707242
trainer/Policy mu Max               3.01013
trainer/Policy mu Min              -2.16245
trainer/Policy log std Mean        -2.05245
trainer/Policy log std Std          0.59272
trainer/Policy log std Max         -0.394874
trainer/Policy log std Min         -2.89285
trainer/Alpha                       0.0904253
trainer/Alpha Loss                  0.283103
exploration/num steps total     57000
exploration/num paths total       570
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.287765
exploration/Rewards Std             0.39197
exploration/Rewards Max            -0.0651416
exploration/Rewards Min            -4.04134
exploration/Returns Mean          -28.7765
exploration/Returns Std             3.04433
exploration/Returns Max           -25.7322
exploration/Returns Min           -31.8209
exploration/Actions Mean            0.00386708
exploration/Actions Std             0.156689
exploration/Actions Max             0.981628
exploration/Actions Min            -0.949112
exploration/Num Paths               2
exploration/Average Returns       -28.7765
evaluation/num steps total     284000
evaluation/num paths total       2840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.572569
evaluation/Rewards Std              1.04063
evaluation/Rewards Max             -0.195449
evaluation/Rewards Min             -8.90063
evaluation/Returns Mean           -57.2569
evaluation/Returns Std             19.4944
evaluation/Returns Max            -20.3978
evaluation/Returns Min            -90.4844
evaluation/Actions Mean             0.00798362
evaluation/Actions Std              0.194454
evaluation/Actions Max              0.993552
evaluation/Actions Min             -0.992718
evaluation/Num Paths               10
evaluation/Average Returns        -57.2569
time/data storing (s)               0.00128216
time/evaluation sampling (s)        0.224882
time/exploration sampling (s)       0.0653341
time/logging (s)                    0.00335683
time/saving (s)                     0.00193229
time/training (s)                   0.765692
time/epoch (s)                      1.06248
time/total (s)                    303.062
Epoch                             283
-----------------------------  ---------------
2019-04-21 01:16:47.897925 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 284 finished
-----------------------------  ---------------
replay_buffer/size              57200
trainer/QF1 Loss                    0.465802
trainer/QF2 Loss                    0.485347
trainer/Policy Loss                29.5985
trainer/Q1 Predictions Mean       -28.2529
trainer/Q1 Predictions Std          7.63584
trainer/Q1 Predictions Max        -18.9073
trainer/Q1 Predictions Min        -43.6694
trainer/Q2 Predictions Mean       -28.2397
trainer/Q2 Predictions Std          7.60728
trainer/Q2 Predictions Max        -18.9517
trainer/Q2 Predictions Min        -42.8432
trainer/Q Targets Mean            -28.7273
trainer/Q Targets Std               8.04784
trainer/Q Targets Max             -18.938
trainer/Q Targets Min             -43.36
trainer/Log Pis Mean                1.753
trainer/Log Pis Std                 1.18619
trainer/Log Pis Max                 4.13709
trainer/Log Pis Min                -2.13059
trainer/Policy mu Mean              0.0402269
trainer/Policy mu Std               0.506241
trainer/Policy mu Max               2.27696
trainer/Policy mu Min              -2.14682
trainer/Policy log std Mean        -2.12352
trainer/Policy log std Std          0.529609
trainer/Policy log std Max         -0.467917
trainer/Policy log std Min         -2.90068
trainer/Alpha                       0.0922225
trainer/Alpha Loss                 -0.588736
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.411065
exploration/Rewards Std             0.999668
exploration/Rewards Max            -0.0302549
exploration/Rewards Min            -7.1325
exploration/Returns Mean          -41.1065
exploration/Returns Std             1.59685
exploration/Returns Max           -39.5097
exploration/Returns Min           -42.7034
exploration/Actions Mean            0.0545957
exploration/Actions Std             0.229565
exploration/Actions Max             0.999317
exploration/Actions Min            -0.554916
exploration/Num Paths               2
exploration/Average Returns       -41.1065
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.570911
evaluation/Rewards Std              1.15789
evaluation/Rewards Max             -0.135799
evaluation/Rewards Min            -10.3826
evaluation/Returns Mean           -57.0911
evaluation/Returns Std             33.6579
evaluation/Returns Max            -15.4068
evaluation/Returns Min           -114.586
evaluation/Actions Mean             0.00248862
evaluation/Actions Std              0.191293
evaluation/Actions Max              0.994961
evaluation/Actions Min             -0.996702
evaluation/Num Paths               10
evaluation/Average Returns        -57.0911
time/data storing (s)               0.00123221
time/evaluation sampling (s)        0.229417
time/exploration sampling (s)       0.0648265
time/logging (s)                    0.00333557
time/saving (s)                     0.0106227
time/training (s)                   0.739629
time/epoch (s)                      1.04906
time/total (s)                    304.114
Epoch                             284
-----------------------------  ---------------
2019-04-21 01:16:48.962442 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 285 finished
-----------------------------  ---------------
replay_buffer/size              57400
trainer/QF1 Loss                    8.55846
trainer/QF2 Loss                    8.64112
trainer/Policy Loss                29.2184
trainer/Q1 Predictions Mean       -27.7738
trainer/Q1 Predictions Std          8.5835
trainer/Q1 Predictions Max        -18.7074
trainer/Q1 Predictions Min        -53.6634
trainer/Q2 Predictions Mean       -27.8015
trainer/Q2 Predictions Std          8.62003
trainer/Q2 Predictions Max        -18.7538
trainer/Q2 Predictions Min        -55.2818
trainer/Q Targets Mean            -27.8464
trainer/Q Targets Std               9.03769
trainer/Q Targets Max              -4.9354
trainer/Q Targets Min             -56.2631
trainer/Log Pis Mean                2.11847
trainer/Log Pis Std                 1.10204
trainer/Log Pis Max                 5.67304
trainer/Log Pis Min                -2.30969
trainer/Policy mu Mean              0.0132232
trainer/Policy mu Std               0.682024
trainer/Policy mu Max               2.56406
trainer/Policy mu Min              -2.39748
trainer/Policy log std Mean        -2.11965
trainer/Policy log std Std          0.600985
trainer/Policy log std Max         -0.540363
trainer/Policy log std Min         -2.86475
trainer/Alpha                       0.0927522
trainer/Alpha Loss                  0.281714
exploration/num steps total     57400
exploration/num paths total       574
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.575178
exploration/Rewards Std             0.833519
exploration/Rewards Max            -0.0874795
exploration/Rewards Min            -7.32039
exploration/Returns Mean          -57.5178
exploration/Returns Std             8.76826
exploration/Returns Max           -48.7496
exploration/Returns Min           -66.2861
exploration/Actions Mean            0.0135367
exploration/Actions Std             0.219995
exploration/Actions Max             0.993911
exploration/Actions Min            -0.993413
exploration/Num Paths               2
exploration/Average Returns       -57.5178
evaluation/num steps total     286000
evaluation/num paths total       2860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.510263
evaluation/Rewards Std              0.836976
evaluation/Rewards Max             -0.214887
evaluation/Rewards Min             -9.59363
evaluation/Returns Mean           -51.0263
evaluation/Returns Std             15.7034
evaluation/Returns Max            -24.5731
evaluation/Returns Min            -70.8518
evaluation/Actions Mean             0.0130911
evaluation/Actions Std              0.177763
evaluation/Actions Max              0.993353
evaluation/Actions Min             -0.984849
evaluation/Num Paths               10
evaluation/Average Returns        -51.0263
time/data storing (s)               0.00156344
time/evaluation sampling (s)        0.215884
time/exploration sampling (s)       0.0627738
time/logging (s)                    0.00340285
time/saving (s)                     0.00195137
time/training (s)                   0.770574
time/epoch (s)                      1.05615
time/total (s)                    305.174
Epoch                             285
-----------------------------  ---------------
2019-04-21 01:16:50.034846 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 286 finished
-----------------------------  ----------------
replay_buffer/size              57600
trainer/QF1 Loss                    9.93532
trainer/QF2 Loss                    9.99449
trainer/Policy Loss                32.0751
trainer/Q1 Predictions Mean       -30.797
trainer/Q1 Predictions Std         10.7975
trainer/Q1 Predictions Max        -18.6573
trainer/Q1 Predictions Min        -90.9365
trainer/Q2 Predictions Mean       -30.7776
trainer/Q2 Predictions Std         10.8113
trainer/Q2 Predictions Max        -18.6157
trainer/Q2 Predictions Min        -91.5733
trainer/Q Targets Mean            -30.6328
trainer/Q Targets Std              11.5372
trainer/Q Targets Max              -0.155862
trainer/Q Targets Min             -91.8182
trainer/Log Pis Mean                1.98862
trainer/Log Pis Std                 1.40365
trainer/Log Pis Max                 6.49535
trainer/Log Pis Min                -4.44073
trainer/Policy mu Mean              0.0220268
trainer/Policy mu Std               0.78896
trainer/Policy mu Max               2.85912
trainer/Policy mu Min              -3.10199
trainer/Policy log std Mean        -2.02141
trainer/Policy log std Std          0.660306
trainer/Policy log std Max         -0.548914
trainer/Policy log std Min         -2.91181
trainer/Alpha                       0.0958555
trainer/Alpha Loss                 -0.0266858
exploration/num steps total     57600
exploration/num paths total       576
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.551419
exploration/Rewards Std             1.33816
exploration/Rewards Max            -0.0816437
exploration/Rewards Min            -9.9346
exploration/Returns Mean          -55.1419
exploration/Returns Std            20.1174
exploration/Returns Max           -35.0246
exploration/Returns Min           -75.2593
exploration/Actions Mean            0.0249871
exploration/Actions Std             0.220729
exploration/Actions Max             0.998857
exploration/Actions Min            -0.873032
exploration/Num Paths               2
exploration/Average Returns       -55.1419
evaluation/num steps total     287000
evaluation/num paths total       2870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.576702
evaluation/Rewards Std              0.65244
evaluation/Rewards Max             -0.201141
evaluation/Rewards Min             -7.1244
evaluation/Returns Mean           -57.6702
evaluation/Returns Std             13.8103
evaluation/Returns Max            -33.2971
evaluation/Returns Min            -80.7034
evaluation/Actions Mean            -0.000673134
evaluation/Actions Std              0.153263
evaluation/Actions Max              0.993183
evaluation/Actions Min             -0.992423
evaluation/Num Paths               10
evaluation/Average Returns        -57.6702
time/data storing (s)               0.00124003
time/evaluation sampling (s)        0.223305
time/exploration sampling (s)       0.0646765
time/logging (s)                    0.00289255
time/saving (s)                     0.00159604
time/training (s)                   0.770056
time/epoch (s)                      1.06377
time/total (s)                    306.243
Epoch                             286
-----------------------------  ----------------
2019-04-21 01:16:51.106308 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 287 finished
-----------------------------  ---------------
replay_buffer/size              57800
trainer/QF1 Loss                   11.8468
trainer/QF2 Loss                   11.8978
trainer/Policy Loss                30.9535
trainer/Q1 Predictions Mean       -29.3888
trainer/Q1 Predictions Std          8.40181
trainer/Q1 Predictions Max        -18.4479
trainer/Q1 Predictions Min        -52.5958
trainer/Q2 Predictions Mean       -29.3883
trainer/Q2 Predictions Std          8.35178
trainer/Q2 Predictions Max        -18.4535
trainer/Q2 Predictions Min        -52.242
trainer/Q Targets Mean            -29.2683
trainer/Q Targets Std               8.83636
trainer/Q Targets Max              -1.02084
trainer/Q Targets Min             -53.8029
trainer/Log Pis Mean                2.08501
trainer/Log Pis Std                 1.04936
trainer/Log Pis Max                 5.66874
trainer/Log Pis Min                -1.48241
trainer/Policy mu Mean              0.0174582
trainer/Policy mu Std               0.684231
trainer/Policy mu Max               2.9079
trainer/Policy mu Min              -2.47564
trainer/Policy log std Mean        -2.04828
trainer/Policy log std Std          0.602869
trainer/Policy log std Max         -0.490951
trainer/Policy log std Min         -2.83482
trainer/Alpha                       0.0973459
trainer/Alpha Loss                  0.198043
exploration/num steps total     57800
exploration/num paths total       578
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.664415
exploration/Rewards Std             1.22585
exploration/Rewards Max            -0.0393773
exploration/Rewards Min            -9.26308
exploration/Returns Mean          -66.4415
exploration/Returns Std            31.8306
exploration/Returns Max           -34.6109
exploration/Returns Min           -98.2721
exploration/Actions Mean           -0.0242749
exploration/Actions Std             0.246132
exploration/Actions Max             0.992504
exploration/Actions Min            -0.996952
exploration/Num Paths               2
exploration/Average Returns       -66.4415
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.523017
evaluation/Rewards Std              1.1616
evaluation/Rewards Max             -0.170954
evaluation/Rewards Min            -10.8236
evaluation/Returns Mean           -52.3017
evaluation/Returns Std             21.1159
evaluation/Returns Max            -25.2268
evaluation/Returns Min            -92.0764
evaluation/Actions Mean             0.0235693
evaluation/Actions Std              0.197455
evaluation/Actions Max              0.996939
evaluation/Actions Min             -0.994796
evaluation/Num Paths               10
evaluation/Average Returns        -52.3017
time/data storing (s)               0.00124706
time/evaluation sampling (s)        0.218457
time/exploration sampling (s)       0.0655167
time/logging (s)                    0.00337976
time/saving (s)                     0.00189279
time/training (s)                   0.772713
time/epoch (s)                      1.06321
time/total (s)                    307.31
Epoch                             287
-----------------------------  ---------------
2019-04-21 01:16:52.176671 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 288 finished
-----------------------------  ---------------
replay_buffer/size              58000
trainer/QF1 Loss                    6.01434
trainer/QF2 Loss                    6.09893
trainer/Policy Loss                30.0748
trainer/Q1 Predictions Mean       -28.6878
trainer/Q1 Predictions Std         10.8319
trainer/Q1 Predictions Max        -18.4539
trainer/Q1 Predictions Min        -77.1031
trainer/Q2 Predictions Mean       -28.6801
trainer/Q2 Predictions Std         10.7814
trainer/Q2 Predictions Max        -18.4984
trainer/Q2 Predictions Min        -76.7336
trainer/Q Targets Mean            -28.5719
trainer/Q Targets Std              11.1718
trainer/Q Targets Max              -3.67701
trainer/Q Targets Min             -79.875
trainer/Log Pis Mean                2.03748
trainer/Log Pis Std                 1.32515
trainer/Log Pis Max                 6.8703
trainer/Log Pis Min                -1.97758
trainer/Policy mu Mean              0.105037
trainer/Policy mu Std               0.771415
trainer/Policy mu Max               2.92367
trainer/Policy mu Min              -2.54228
trainer/Policy log std Mean        -1.99068
trainer/Policy log std Std          0.639274
trainer/Policy log std Max         -0.459702
trainer/Policy log std Min         -2.88223
trainer/Alpha                       0.0981643
trainer/Alpha Loss                  0.0869935
exploration/num steps total     58000
exploration/num paths total       580
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.542261
exploration/Rewards Std             0.67136
exploration/Rewards Max            -0.0956176
exploration/Rewards Min            -5.07067
exploration/Returns Mean          -54.2261
exploration/Returns Std            15.6951
exploration/Returns Max           -38.531
exploration/Returns Min           -69.9212
exploration/Actions Mean            0.00319074
exploration/Actions Std             0.215356
exploration/Actions Max             0.995327
exploration/Actions Min            -0.997184
exploration/Num Paths               2
exploration/Average Returns       -54.2261
evaluation/num steps total     289000
evaluation/num paths total       2890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.521969
evaluation/Rewards Std              0.978723
evaluation/Rewards Max             -0.187974
evaluation/Rewards Min            -10.2106
evaluation/Returns Mean           -52.1969
evaluation/Returns Std             15.9197
evaluation/Returns Max            -24.141
evaluation/Returns Min            -78.1967
evaluation/Actions Mean             0.0122009
evaluation/Actions Std              0.183524
evaluation/Actions Max              0.993912
evaluation/Actions Min             -0.988777
evaluation/Num Paths               10
evaluation/Average Returns        -52.1969
time/data storing (s)               0.00125546
time/evaluation sampling (s)        0.223482
time/exploration sampling (s)       0.0665053
time/logging (s)                    0.00336872
time/saving (s)                     0.00197733
time/training (s)                   0.76512
time/epoch (s)                      1.06171
time/total (s)                    308.376
Epoch                             288
-----------------------------  ---------------
2019-04-21 01:16:53.253818 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 289 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                    3.58069
trainer/QF2 Loss                    3.60225
trainer/Policy Loss                29.0918
trainer/Q1 Predictions Mean       -27.6587
trainer/Q1 Predictions Std          9.68992
trainer/Q1 Predictions Max        -18.4654
trainer/Q1 Predictions Min        -73.4917
trainer/Q2 Predictions Mean       -27.6457
trainer/Q2 Predictions Std          9.68458
trainer/Q2 Predictions Max        -18.473
trainer/Q2 Predictions Min        -73.3629
trainer/Q Targets Mean            -27.6312
trainer/Q Targets Std              10.2276
trainer/Q Targets Max              -0.437092
trainer/Q Targets Min             -77.5633
trainer/Log Pis Mean                1.84158
trainer/Log Pis Std                 1.18603
trainer/Log Pis Max                 6.34106
trainer/Log Pis Min                -1.87759
trainer/Policy mu Mean              0.145565
trainer/Policy mu Std               0.667158
trainer/Policy mu Max               2.92549
trainer/Policy mu Min              -2.12873
trainer/Policy log std Mean        -2.09276
trainer/Policy log std Std          0.575631
trainer/Policy log std Max         -0.557788
trainer/Policy log std Min         -2.83809
trainer/Alpha                       0.0975309
trainer/Alpha Loss                 -0.368744
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.716928
exploration/Rewards Std             1.432
exploration/Rewards Max            -0.0299284
exploration/Rewards Min            -9.97647
exploration/Returns Mean          -71.6928
exploration/Returns Std            32.1732
exploration/Returns Max           -39.5196
exploration/Returns Min          -103.866
exploration/Actions Mean           -0.0248438
exploration/Actions Std             0.248367
exploration/Actions Max             0.907368
exploration/Actions Min            -0.998814
exploration/Num Paths               2
exploration/Average Returns       -71.6928
evaluation/num steps total     290000
evaluation/num paths total       2900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.593672
evaluation/Rewards Std              1.1241
evaluation/Rewards Max             -0.0699499
evaluation/Rewards Min            -11.3392
evaluation/Returns Mean           -59.3672
evaluation/Returns Std             31.7953
evaluation/Returns Max            -16.772
evaluation/Returns Min           -106.825
evaluation/Actions Mean            -0.0107834
evaluation/Actions Std              0.192215
evaluation/Actions Max              0.992224
evaluation/Actions Min             -0.998751
evaluation/Num Paths               10
evaluation/Average Returns        -59.3672
time/data storing (s)               0.00179924
time/evaluation sampling (s)        0.223852
time/exploration sampling (s)       0.0712983
time/logging (s)                    0.00336674
time/saving (s)                     0.00196067
time/training (s)                   0.766078
time/epoch (s)                      1.06836
time/total (s)                    309.449
Epoch                             289
-----------------------------  ---------------
2019-04-21 01:16:54.328296 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 290 finished
-----------------------------  ---------------
replay_buffer/size              58400
trainer/QF1 Loss                    3.63044
trainer/QF2 Loss                    3.62066
trainer/Policy Loss                29.7721
trainer/Q1 Predictions Mean       -28.0896
trainer/Q1 Predictions Std          8.59973
trainer/Q1 Predictions Max        -18.1214
trainer/Q1 Predictions Min        -50.155
trainer/Q2 Predictions Mean       -28.0907
trainer/Q2 Predictions Std          8.58532
trainer/Q2 Predictions Max        -18.1743
trainer/Q2 Predictions Min        -50.2351
trainer/Q Targets Mean            -28.4441
trainer/Q Targets Std               9.16896
trainer/Q Targets Max              -0.346639
trainer/Q Targets Min             -51.2302
trainer/Log Pis Mean                2.0395
trainer/Log Pis Std                 1.09734
trainer/Log Pis Max                 5.25545
trainer/Log Pis Min                -2.40587
trainer/Policy mu Mean             -0.0879368
trainer/Policy mu Std               0.572239
trainer/Policy mu Max               2.66244
trainer/Policy mu Min              -2.13077
trainer/Policy log std Mean        -2.14975
trainer/Policy log std Std          0.530781
trainer/Policy log std Max         -0.569875
trainer/Policy log std Min         -2.8364
trainer/Alpha                       0.0973476
trainer/Alpha Loss                  0.0920101
exploration/num steps total     58400
exploration/num paths total       584
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.59566
exploration/Rewards Std             1.31448
exploration/Rewards Max            -0.0674321
exploration/Rewards Min            -8.62665
exploration/Returns Mean          -59.566
exploration/Returns Std             3.84601
exploration/Returns Max           -55.72
exploration/Returns Min           -63.412
exploration/Actions Mean            0.0359116
exploration/Actions Std             0.242475
exploration/Actions Max             0.99807
exploration/Actions Min            -0.990805
exploration/Num Paths               2
exploration/Average Returns       -59.566
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.5839
evaluation/Rewards Std              0.760717
evaluation/Rewards Max             -0.232064
evaluation/Rewards Min             -8.60422
evaluation/Returns Mean           -58.39
evaluation/Returns Std             21.759
evaluation/Returns Max            -32.5627
evaluation/Returns Min            -95.7397
evaluation/Actions Mean            -0.00739252
evaluation/Actions Std              0.170773
evaluation/Actions Max              0.988205
evaluation/Actions Min             -0.992289
evaluation/Num Paths               10
evaluation/Average Returns        -58.39
time/data storing (s)               0.0013617
time/evaluation sampling (s)        0.226122
time/exploration sampling (s)       0.0628648
time/logging (s)                    0.00343302
time/saving (s)                     0.00197741
time/training (s)                   0.770075
time/epoch (s)                      1.06583
time/total (s)                    310.519
Epoch                             290
-----------------------------  ---------------
2019-04-21 01:16:55.400572 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 291 finished
-----------------------------  ---------------
replay_buffer/size              58600
trainer/QF1 Loss                   25.9199
trainer/QF2 Loss                   25.9636
trainer/Policy Loss                29.441
trainer/Q1 Predictions Mean       -28.0573
trainer/Q1 Predictions Std          8.57719
trainer/Q1 Predictions Max        -18.2652
trainer/Q1 Predictions Min        -58.5899
trainer/Q2 Predictions Mean       -28.0651
trainer/Q2 Predictions Std          8.60698
trainer/Q2 Predictions Max        -18.2387
trainer/Q2 Predictions Min        -58.9932
trainer/Q Targets Mean            -27.4732
trainer/Q Targets Std               9.88451
trainer/Q Targets Max              -0.466936
trainer/Q Targets Min             -59.3696
trainer/Log Pis Mean                1.99307
trainer/Log Pis Std                 1.1594
trainer/Log Pis Max                 5.93909
trainer/Log Pis Min                -3.62328
trainer/Policy mu Mean              0.109274
trainer/Policy mu Std               0.755198
trainer/Policy mu Max               2.76887
trainer/Policy mu Min              -2.42428
trainer/Policy log std Mean        -1.95267
trainer/Policy log std Std          0.633577
trainer/Policy log std Max         -0.519628
trainer/Policy log std Min         -2.8892
trainer/Alpha                       0.0968567
trainer/Alpha Loss                 -0.0161835
exploration/num steps total     58600
exploration/num paths total       586
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.70866
exploration/Rewards Std             0.204071
exploration/Rewards Max            -0.386197
exploration/Rewards Min            -2.51321
exploration/Returns Mean          -70.866
exploration/Returns Std             1.60943
exploration/Returns Max           -69.2566
exploration/Returns Min           -72.4755
exploration/Actions Mean            0.0104895
exploration/Actions Std             0.204905
exploration/Actions Max             0.989912
exploration/Actions Min            -0.950409
exploration/Num Paths               2
exploration/Average Returns       -70.866
evaluation/num steps total     292000
evaluation/num paths total       2920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.549401
evaluation/Rewards Std              1.07918
evaluation/Rewards Max             -0.167925
evaluation/Rewards Min             -9.63107
evaluation/Returns Mean           -54.9401
evaluation/Returns Std             21.5382
evaluation/Returns Max            -19.762
evaluation/Returns Min            -91.2738
evaluation/Actions Mean             0.0228729
evaluation/Actions Std              0.19547
evaluation/Actions Max              0.994136
evaluation/Actions Min             -0.990459
evaluation/Num Paths               10
evaluation/Average Returns        -54.9401
time/data storing (s)               0.00124594
time/evaluation sampling (s)        0.219878
time/exploration sampling (s)       0.0648498
time/logging (s)                    0.00335633
time/saving (s)                     0.00194644
time/training (s)                   0.772027
time/epoch (s)                      1.0633
time/total (s)                    311.587
Epoch                             291
-----------------------------  ---------------
2019-04-21 01:16:56.470784 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 292 finished
-----------------------------  ---------------
replay_buffer/size              58800
trainer/QF1 Loss                   15.14
trainer/QF2 Loss                   15.0452
trainer/Policy Loss                30.7322
trainer/Q1 Predictions Mean       -28.9889
trainer/Q1 Predictions Std         12.6315
trainer/Q1 Predictions Max        -18.0132
trainer/Q1 Predictions Min        -83.5057
trainer/Q2 Predictions Mean       -29.0003
trainer/Q2 Predictions Std         12.7234
trainer/Q2 Predictions Max        -18.0156
trainer/Q2 Predictions Min        -84.9911
trainer/Q Targets Mean            -28.7007
trainer/Q Targets Std              13.3964
trainer/Q Targets Max              -0.710254
trainer/Q Targets Min             -85.6029
trainer/Log Pis Mean                2.3339
trainer/Log Pis Std                 1.21481
trainer/Log Pis Max                 6.83209
trainer/Log Pis Min                -2.25689
trainer/Policy mu Mean              0.0177046
trainer/Policy mu Std               0.84651
trainer/Policy mu Max               2.73229
trainer/Policy mu Min              -3.10327
trainer/Policy log std Mean        -2.00972
trainer/Policy log std Std          0.656542
trainer/Policy log std Max         -0.358444
trainer/Policy log std Min         -2.84638
trainer/Alpha                       0.0960171
trainer/Alpha Loss                  0.78243
exploration/num steps total     58800
exploration/num paths total       588
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.799384
exploration/Rewards Std             1.65388
exploration/Rewards Max            -0.00764336
exploration/Rewards Min           -11.0304
exploration/Returns Mean          -79.9384
exploration/Returns Std             2.11418
exploration/Returns Max           -77.8243
exploration/Returns Min           -82.0526
exploration/Actions Mean           -0.0191061
exploration/Actions Std             0.282276
exploration/Actions Max             0.998838
exploration/Actions Min            -0.994382
exploration/Num Paths               2
exploration/Average Returns       -79.9384
evaluation/num steps total     293000
evaluation/num paths total       2930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.394069
evaluation/Rewards Std              0.704978
evaluation/Rewards Max             -0.092395
evaluation/Rewards Min             -8.55134
evaluation/Returns Mean           -39.4069
evaluation/Returns Std             22.0821
evaluation/Returns Max            -18.3253
evaluation/Returns Min            -86.1562
evaluation/Actions Mean             0.00561905
evaluation/Actions Std              0.161331
evaluation/Actions Max              0.991276
evaluation/Actions Min             -0.992868
evaluation/Num Paths               10
evaluation/Average Returns        -39.4069
time/data storing (s)               0.00123068
time/evaluation sampling (s)        0.220982
time/exploration sampling (s)       0.0634448
time/logging (s)                    0.00335802
time/saving (s)                     0.00197795
time/training (s)                   0.770677
time/epoch (s)                      1.06167
time/total (s)                    312.653
Epoch                             292
-----------------------------  ---------------
2019-04-21 01:16:57.540371 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 293 finished
-----------------------------  ---------------
replay_buffer/size              59000
trainer/QF1 Loss                   26.1513
trainer/QF2 Loss                   26.1351
trainer/Policy Loss                30.5448
trainer/Q1 Predictions Mean       -29.1938
trainer/Q1 Predictions Std          8.87322
trainer/Q1 Predictions Max        -17.7541
trainer/Q1 Predictions Min        -55.5288
trainer/Q2 Predictions Mean       -29.2079
trainer/Q2 Predictions Std          8.87655
trainer/Q2 Predictions Max        -17.7807
trainer/Q2 Predictions Min        -55.4825
trainer/Q Targets Mean            -28.5664
trainer/Q Targets Std               9.98035
trainer/Q Targets Max              -0.2365
trainer/Q Targets Min             -56.0519
trainer/Log Pis Mean                1.95571
trainer/Log Pis Std                 1.2364
trainer/Log Pis Max                 5.92821
trainer/Log Pis Min                -2.05078
trainer/Policy mu Mean              0.042715
trainer/Policy mu Std               0.750642
trainer/Policy mu Max               2.95749
trainer/Policy mu Min              -2.17444
trainer/Policy log std Mean        -2.00764
trainer/Policy log std Std          0.612398
trainer/Policy log std Max         -0.343244
trainer/Policy log std Min         -2.90054
trainer/Alpha                       0.0956206
trainer/Alpha Loss                 -0.103968
exploration/num steps total     59000
exploration/num paths total       590
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.507702
exploration/Rewards Std             1.26302
exploration/Rewards Max            -0.0403574
exploration/Rewards Min            -9.48222
exploration/Returns Mean          -50.7702
exploration/Returns Std            16.3092
exploration/Returns Max           -34.461
exploration/Returns Min           -67.0794
exploration/Actions Mean            0.054661
exploration/Actions Std             0.236186
exploration/Actions Max             0.999241
exploration/Actions Min            -0.372907
exploration/Num Paths               2
exploration/Average Returns       -50.7702
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.607776
evaluation/Rewards Std              0.743802
evaluation/Rewards Max             -0.170184
evaluation/Rewards Min             -9.00965
evaluation/Returns Mean           -60.7776
evaluation/Returns Std             18.1982
evaluation/Returns Max            -23.3834
evaluation/Returns Min            -91.8501
evaluation/Actions Mean            -0.0151077
evaluation/Actions Std              0.163208
evaluation/Actions Max              0.980753
evaluation/Actions Min             -0.995254
evaluation/Num Paths               10
evaluation/Average Returns        -60.7776
time/data storing (s)               0.0013745
time/evaluation sampling (s)        0.225886
time/exploration sampling (s)       0.0643226
time/logging (s)                    0.00254257
time/saving (s)                     0.00167798
time/training (s)                   0.764935
time/epoch (s)                      1.06074
time/total (s)                    313.717
Epoch                             293
-----------------------------  ---------------
2019-04-21 01:16:58.609483 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 294 finished
-----------------------------  ---------------
replay_buffer/size              59200
trainer/QF1 Loss                    0.285113
trainer/QF2 Loss                    0.299811
trainer/Policy Loss                29.9471
trainer/Q1 Predictions Mean       -28.4389
trainer/Q1 Predictions Std          9.58258
trainer/Q1 Predictions Max        -17.8938
trainer/Q1 Predictions Min        -77.169
trainer/Q2 Predictions Mean       -28.4202
trainer/Q2 Predictions Std          9.58254
trainer/Q2 Predictions Max        -17.8676
trainer/Q2 Predictions Min        -77.1523
trainer/Q Targets Mean            -28.7686
trainer/Q Targets Std               9.93211
trainer/Q Targets Max             -17.9477
trainer/Q Targets Min             -80.2552
trainer/Log Pis Mean                1.99317
trainer/Log Pis Std                 1.10632
trainer/Log Pis Max                 6.53906
trainer/Log Pis Min                -1.57709
trainer/Policy mu Mean              0.0286052
trainer/Policy mu Std               0.652824
trainer/Policy mu Max               2.99153
trainer/Policy mu Min              -2.22206
trainer/Policy log std Mean        -2.03466
trainer/Policy log std Std          0.55269
trainer/Policy log std Max         -0.215988
trainer/Policy log std Min         -2.89072
trainer/Alpha                       0.0947949
trainer/Alpha Loss                 -0.0160977
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.571207
exploration/Rewards Std             0.943434
exploration/Rewards Max            -0.0447754
exploration/Rewards Min            -7.79261
exploration/Returns Mean          -57.1207
exploration/Returns Std            36.1336
exploration/Returns Max           -20.9871
exploration/Returns Min           -93.2543
exploration/Actions Mean           -0.0106298
exploration/Actions Std             0.207858
exploration/Actions Max             0.939223
exploration/Actions Min            -0.99618
exploration/Num Paths               2
exploration/Average Returns       -57.1207
evaluation/num steps total     295000
evaluation/num paths total       2950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.470904
evaluation/Rewards Std              0.804222
evaluation/Rewards Max             -0.1445
evaluation/Rewards Min             -8.44317
evaluation/Returns Mean           -47.0904
evaluation/Returns Std             27.6809
evaluation/Returns Max            -18.0592
evaluation/Returns Min            -93.2244
evaluation/Actions Mean            -0.00202933
evaluation/Actions Std              0.176639
evaluation/Actions Max              0.992164
evaluation/Actions Min             -0.992418
evaluation/Num Paths               10
evaluation/Average Returns        -47.0904
time/data storing (s)               0.00137015
time/evaluation sampling (s)        0.217398
time/exploration sampling (s)       0.0642458
time/logging (s)                    0.00337744
time/saving (s)                     0.00201728
time/training (s)                   0.77313
time/epoch (s)                      1.06154
time/total (s)                    314.783
Epoch                             294
-----------------------------  ---------------
2019-04-21 01:16:59.675100 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 295 finished
-----------------------------  ---------------
replay_buffer/size              59400
trainer/QF1 Loss                    0.184886
trainer/QF2 Loss                    0.182786
trainer/Policy Loss                27.9928
trainer/Q1 Predictions Mean       -26.3375
trainer/Q1 Predictions Std          9.80373
trainer/Q1 Predictions Max        -17.4958
trainer/Q1 Predictions Min        -66.8233
trainer/Q2 Predictions Mean       -26.3368
trainer/Q2 Predictions Std          9.76078
trainer/Q2 Predictions Max        -17.4585
trainer/Q2 Predictions Min        -66.8933
trainer/Q Targets Mean            -26.7094
trainer/Q Targets Std               9.80001
trainer/Q Targets Max             -17.7921
trainer/Q Targets Min             -67.0585
trainer/Log Pis Mean                2.00995
trainer/Log Pis Std                 1.21507
trainer/Log Pis Max                 5.223
trainer/Log Pis Min                -2.3439
trainer/Policy mu Mean              0.0777382
trainer/Policy mu Std               0.606474
trainer/Policy mu Max               2.45757
trainer/Policy mu Min              -2.73792
trainer/Policy log std Mean        -2.14752
trainer/Policy log std Std          0.581697
trainer/Policy log std Max         -0.644469
trainer/Policy log std Min         -2.99476
trainer/Alpha                       0.0940822
trainer/Alpha Loss                  0.0235153
exploration/num steps total     59400
exploration/num paths total       594
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.597043
exploration/Rewards Std             1.43565
exploration/Rewards Max            -0.0905969
exploration/Rewards Min           -10.0981
exploration/Returns Mean          -59.7043
exploration/Returns Std            12.6278
exploration/Returns Max           -47.0765
exploration/Returns Min           -72.3321
exploration/Actions Mean            0.0552183
exploration/Actions Std             0.239915
exploration/Actions Max             0.997536
exploration/Actions Min            -0.374917
exploration/Num Paths               2
exploration/Average Returns       -59.7043
evaluation/num steps total     296000
evaluation/num paths total       2960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.599537
evaluation/Rewards Std              1.02909
evaluation/Rewards Max             -0.1941
evaluation/Rewards Min            -10.7109
evaluation/Returns Mean           -59.9537
evaluation/Returns Std             33.1749
evaluation/Returns Max            -20.9807
evaluation/Returns Min           -110.069
evaluation/Actions Mean            -0.0115144
evaluation/Actions Std              0.184243
evaluation/Actions Max              0.993013
evaluation/Actions Min             -0.996723
evaluation/Num Paths               10
evaluation/Average Returns        -59.9537
time/data storing (s)               0.00123916
time/evaluation sampling (s)        0.219972
time/exploration sampling (s)       0.0648559
time/logging (s)                    0.00335561
time/saving (s)                     0.0015758
time/training (s)                   0.765834
time/epoch (s)                      1.05683
time/total (s)                    315.844
Epoch                             295
-----------------------------  ---------------
2019-04-21 01:17:00.737680 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 296 finished
-----------------------------  ---------------
replay_buffer/size              59600
trainer/QF1 Loss                    0.16011
trainer/QF2 Loss                    0.169825
trainer/Policy Loss                28.9385
trainer/Q1 Predictions Mean       -27.5364
trainer/Q1 Predictions Std          8.14251
trainer/Q1 Predictions Max        -17.7359
trainer/Q1 Predictions Min        -45.8392
trainer/Q2 Predictions Mean       -27.5473
trainer/Q2 Predictions Std          8.14414
trainer/Q2 Predictions Max        -17.6772
trainer/Q2 Predictions Min        -46.1882
trainer/Q Targets Mean            -27.7611
trainer/Q Targets Std               8.32144
trainer/Q Targets Max             -17.6141
trainer/Q Targets Min             -45.3866
trainer/Log Pis Mean                1.86515
trainer/Log Pis Std                 1.18871
trainer/Log Pis Max                 5.25873
trainer/Log Pis Min                -1.74921
trainer/Policy mu Mean              0.0801107
trainer/Policy mu Std               0.584319
trainer/Policy mu Max               2.57218
trainer/Policy mu Min              -2.16064
trainer/Policy log std Mean        -2.06472
trainer/Policy log std Std          0.516463
trainer/Policy log std Max         -0.407424
trainer/Policy log std Min         -2.85601
trainer/Alpha                       0.0928648
trainer/Alpha Loss                 -0.320459
exploration/num steps total     59600
exploration/num paths total       596
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.624728
exploration/Rewards Std             0.971491
exploration/Rewards Max            -0.0355611
exploration/Rewards Min            -6.98514
exploration/Returns Mean          -62.4728
exploration/Returns Std            16.1867
exploration/Returns Max           -46.2861
exploration/Returns Min           -78.6594
exploration/Actions Mean            0.00654934
exploration/Actions Std             0.24238
exploration/Actions Max             0.998536
exploration/Actions Min            -0.994099
exploration/Num Paths               2
exploration/Average Returns       -62.4728
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.507077
evaluation/Rewards Std              0.989861
evaluation/Rewards Max             -0.142032
evaluation/Rewards Min            -10.9511
evaluation/Returns Mean           -50.7077
evaluation/Returns Std             31.04
evaluation/Returns Max            -14.6117
evaluation/Returns Min            -94.0247
evaluation/Actions Mean             0.00979019
evaluation/Actions Std              0.181491
evaluation/Actions Max              0.994714
evaluation/Actions Min             -0.993951
evaluation/Num Paths               10
evaluation/Average Returns        -50.7077
time/data storing (s)               0.00122682
time/evaluation sampling (s)        0.220366
time/exploration sampling (s)       0.0654385
time/logging (s)                    0.00337061
time/saving (s)                     0.00196828
time/training (s)                   0.76146
time/epoch (s)                      1.05383
time/total (s)                    316.902
Epoch                             296
-----------------------------  ---------------
2019-04-21 01:17:01.821110 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 297 finished
-----------------------------  ---------------
replay_buffer/size              59800
trainer/QF1 Loss                    0.213532
trainer/QF2 Loss                    0.169456
trainer/Policy Loss                29.8539
trainer/Q1 Predictions Mean       -28.8461
trainer/Q1 Predictions Std         10.645
trainer/Q1 Predictions Max        -17.3804
trainer/Q1 Predictions Min        -86.98
trainer/Q2 Predictions Mean       -28.8458
trainer/Q2 Predictions Std         10.5596
trainer/Q2 Predictions Max        -17.4052
trainer/Q2 Predictions Min        -85.8525
trainer/Q Targets Mean            -29.0685
trainer/Q Targets Std              10.5186
trainer/Q Targets Max             -17.487
trainer/Q Targets Min             -83.8293
trainer/Log Pis Mean                1.81043
trainer/Log Pis Std                 1.28132
trainer/Log Pis Max                 4.94044
trainer/Log Pis Min                -1.70109
trainer/Policy mu Mean              0.0532612
trainer/Policy mu Std               0.738137
trainer/Policy mu Max               2.87275
trainer/Policy mu Min              -2.14963
trainer/Policy log std Mean        -2
trainer/Policy log std Std          0.603072
trainer/Policy log std Max         -0.320699
trainer/Policy log std Min         -2.84952
trainer/Alpha                       0.0926633
trainer/Alpha Loss                 -0.450941
exploration/num steps total     59800
exploration/num paths total       598
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.390909
exploration/Rewards Std             0.678151
exploration/Rewards Max            -0.0563292
exploration/Rewards Min            -4.90824
exploration/Returns Mean          -39.0909
exploration/Returns Std             1.59168
exploration/Returns Max           -37.4993
exploration/Returns Min           -40.6826
exploration/Actions Mean            0.0286324
exploration/Actions Std             0.19288
exploration/Actions Max             0.990801
exploration/Actions Min            -0.770285
exploration/Num Paths               2
exploration/Average Returns       -39.0909
evaluation/num steps total     298000
evaluation/num paths total       2980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.521419
evaluation/Rewards Std              0.800318
evaluation/Rewards Max             -0.190412
evaluation/Rewards Min             -8.66167
evaluation/Returns Mean           -52.1419
evaluation/Returns Std             25.7284
evaluation/Returns Max            -20.3814
evaluation/Returns Min            -95.5531
evaluation/Actions Mean            -0.0128084
evaluation/Actions Std              0.16213
evaluation/Actions Max              0.989801
evaluation/Actions Min             -0.993997
evaluation/Num Paths               10
evaluation/Average Returns        -52.1419
time/data storing (s)               0.00122569
time/evaluation sampling (s)        0.225953
time/exploration sampling (s)       0.0658185
time/logging (s)                    0.0033383
time/saving (s)                     0.00737643
time/training (s)                   0.771089
time/epoch (s)                      1.0748
time/total (s)                    317.981
Epoch                             297
-----------------------------  ---------------
2019-04-21 01:17:02.890446 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 298 finished
-----------------------------  ---------------
replay_buffer/size              60000
trainer/QF1 Loss                    3.06249
trainer/QF2 Loss                    3.05865
trainer/Policy Loss                27.931
trainer/Q1 Predictions Mean       -26.7008
trainer/Q1 Predictions Std          8.93776
trainer/Q1 Predictions Max        -17.3955
trainer/Q1 Predictions Min        -57.4204
trainer/Q2 Predictions Mean       -26.7128
trainer/Q2 Predictions Std          8.92314
trainer/Q2 Predictions Max        -17.3655
trainer/Q2 Predictions Min        -57.5137
trainer/Q Targets Mean            -26.6969
trainer/Q Targets Std               9.28736
trainer/Q Targets Max              -0.424551
trainer/Q Targets Min             -58.558
trainer/Log Pis Mean                1.70114
trainer/Log Pis Std                 1.39255
trainer/Log Pis Max                 6.37013
trainer/Log Pis Min                -3.91334
trainer/Policy mu Mean              0.0245146
trainer/Policy mu Std               0.561921
trainer/Policy mu Max               2.53945
trainer/Policy mu Min              -2.53573
trainer/Policy log std Mean        -2.07431
trainer/Policy log std Std          0.522991
trainer/Policy log std Max         -0.405063
trainer/Policy log std Min         -2.83623
trainer/Alpha                       0.0916906
trainer/Alpha Loss                 -0.713997
exploration/num steps total     60000
exploration/num paths total       600
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.839619
exploration/Rewards Std             1.5476
exploration/Rewards Max            -0.0546228
exploration/Rewards Min            -9.26642
exploration/Returns Mean          -83.9619
exploration/Returns Std            22.2709
exploration/Returns Max           -61.691
exploration/Returns Min          -106.233
exploration/Actions Mean            0.0040813
exploration/Actions Std             0.279519
exploration/Actions Max             0.998542
exploration/Actions Min            -0.998212
exploration/Num Paths               2
exploration/Average Returns       -83.9619
evaluation/num steps total     299000
evaluation/num paths total       2990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.732583
evaluation/Rewards Std              0.779561
evaluation/Rewards Max             -0.165037
evaluation/Rewards Min             -8.85258
evaluation/Returns Mean           -73.2583
evaluation/Returns Std             18.2362
evaluation/Returns Max            -27.2956
evaluation/Returns Min            -95.4662
evaluation/Actions Mean            -0.0227689
evaluation/Actions Std              0.181744
evaluation/Actions Max              0.98636
evaluation/Actions Min             -0.994532
evaluation/Num Paths               10
evaluation/Average Returns        -73.2583
time/data storing (s)               0.0013245
time/evaluation sampling (s)        0.217617
time/exploration sampling (s)       0.0620226
time/logging (s)                    0.00308052
time/saving (s)                     0.00197737
time/training (s)                   0.774562
time/epoch (s)                      1.06058
time/total (s)                    319.046
Epoch                             298
-----------------------------  ---------------
2019-04-21 01:17:03.957875 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 299 finished
-----------------------------  ---------------
replay_buffer/size              60200
trainer/QF1 Loss                   11.1645
trainer/QF2 Loss                   11.2546
trainer/Policy Loss                31.0263
trainer/Q1 Predictions Mean       -29.4623
trainer/Q1 Predictions Std          9.95985
trainer/Q1 Predictions Max        -17.2936
trainer/Q1 Predictions Min        -54.2891
trainer/Q2 Predictions Mean       -29.4585
trainer/Q2 Predictions Std          9.94591
trainer/Q2 Predictions Max        -17.2773
trainer/Q2 Predictions Min        -54.7591
trainer/Q Targets Mean            -29.5212
trainer/Q Targets Std              10.5556
trainer/Q Targets Max              -0.805572
trainer/Q Targets Min             -55.7708
trainer/Log Pis Mean                2.22446
trainer/Log Pis Std                 1.22914
trainer/Log Pis Max                 7.6347
trainer/Log Pis Min                -0.801564
trainer/Policy mu Mean              0.0539091
trainer/Policy mu Std               0.842363
trainer/Policy mu Max               2.73734
trainer/Policy mu Min              -2.46983
trainer/Policy log std Mean        -1.9915
trainer/Policy log std Std          0.638089
trainer/Policy log std Max         -0.525078
trainer/Policy log std Min         -2.89328
trainer/Alpha                       0.0912348
trainer/Alpha Loss                  0.537445
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396019
exploration/Rewards Std             0.588816
exploration/Rewards Max            -0.139073
exploration/Rewards Min            -4.56339
exploration/Returns Mean          -39.6019
exploration/Returns Std             0.145854
exploration/Returns Max           -39.4561
exploration/Returns Min           -39.7478
exploration/Actions Mean            0.0340455
exploration/Actions Std             0.185667
exploration/Actions Max             0.998162
exploration/Actions Min            -0.318354
exploration/Num Paths               2
exploration/Average Returns       -39.6019
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.559459
evaluation/Rewards Std              0.871291
evaluation/Rewards Max             -0.175752
evaluation/Rewards Min             -9.50155
evaluation/Returns Mean           -55.9459
evaluation/Returns Std             20.0326
evaluation/Returns Max            -26.0072
evaluation/Returns Min            -92.9019
evaluation/Actions Mean             0.00569623
evaluation/Actions Std              0.177725
evaluation/Actions Max              0.993617
evaluation/Actions Min             -0.997034
evaluation/Num Paths               10
evaluation/Average Returns        -55.9459
time/data storing (s)               0.00120581
time/evaluation sampling (s)        0.225125
time/exploration sampling (s)       0.0629806
time/logging (s)                    0.00335089
time/saving (s)                     0.00195592
time/training (s)                   0.764877
time/epoch (s)                      1.0595
time/total (s)                    320.11
Epoch                             299
-----------------------------  ---------------
2019-04-21 01:17:05.035240 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 300 finished
-----------------------------  ---------------
replay_buffer/size              60400
trainer/QF1 Loss                   11.3712
trainer/QF2 Loss                   11.3766
trainer/Policy Loss                28.7818
trainer/Q1 Predictions Mean       -27.3441
trainer/Q1 Predictions Std          9.47589
trainer/Q1 Predictions Max        -17.3034
trainer/Q1 Predictions Min        -55.93
trainer/Q2 Predictions Mean       -27.3403
trainer/Q2 Predictions Std          9.44662
trainer/Q2 Predictions Max        -17.2812
trainer/Q2 Predictions Min        -55.2356
trainer/Q Targets Mean            -27.1807
trainer/Q Targets Std               9.82084
trainer/Q Targets Max              -0.714746
trainer/Q Targets Min             -55.0021
trainer/Log Pis Mean                1.89472
trainer/Log Pis Std                 1.46814
trainer/Log Pis Max                 5.9885
trainer/Log Pis Min                -5.10698
trainer/Policy mu Mean              0.055683
trainer/Policy mu Std               0.650447
trainer/Policy mu Max               2.90668
trainer/Policy mu Min              -2.49718
trainer/Policy log std Mean        -2.05891
trainer/Policy log std Std          0.564904
trainer/Policy log std Max         -0.46127
trainer/Policy log std Min         -2.91072
trainer/Alpha                       0.0904116
trainer/Alpha Loss                 -0.253015
exploration/num steps total     60400
exploration/num paths total       604
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297071
exploration/Rewards Std             0.491381
exploration/Rewards Max            -0.0435357
exploration/Rewards Min            -4.32343
exploration/Returns Mean          -29.7071
exploration/Returns Std             0.995841
exploration/Returns Max           -28.7112
exploration/Returns Min           -30.7029
exploration/Actions Mean           -0.00576669
exploration/Actions Std             0.188356
exploration/Actions Max             0.993641
exploration/Actions Min            -0.997337
exploration/Num Paths               2
exploration/Average Returns       -29.7071
evaluation/num steps total     301000
evaluation/num paths total       3010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.49259
evaluation/Rewards Std              0.849394
evaluation/Rewards Max             -0.174785
evaluation/Rewards Min             -9.30086
evaluation/Returns Mean           -49.259
evaluation/Returns Std             20.4691
evaluation/Returns Max            -18.8643
evaluation/Returns Min            -77.1142
evaluation/Actions Mean             0.00525185
evaluation/Actions Std              0.185866
evaluation/Actions Max              0.994803
evaluation/Actions Min             -0.991627
evaluation/Num Paths               10
evaluation/Average Returns        -49.259
time/data storing (s)               0.00152731
time/evaluation sampling (s)        0.218215
time/exploration sampling (s)       0.0635374
time/logging (s)                    0.00335605
time/saving (s)                     0.00156919
time/training (s)                   0.781343
time/epoch (s)                      1.06955
time/total (s)                    321.183
Epoch                             300
-----------------------------  ---------------
2019-04-21 01:17:06.102232 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 301 finished
-----------------------------  ---------------
replay_buffer/size              60600
trainer/QF1 Loss                    0.528994
trainer/QF2 Loss                    0.506094
trainer/Policy Loss                28.7244
trainer/Q1 Predictions Mean       -27.0422
trainer/Q1 Predictions Std          9.77557
trainer/Q1 Predictions Max        -16.8912
trainer/Q1 Predictions Min        -68.9403
trainer/Q2 Predictions Mean       -27.0627
trainer/Q2 Predictions Std          9.80054
trainer/Q2 Predictions Max        -16.863
trainer/Q2 Predictions Min        -69.3223
trainer/Q Targets Mean            -27.7158
trainer/Q Targets Std               9.96103
trainer/Q Targets Max             -17.2603
trainer/Q Targets Min             -69.6095
trainer/Log Pis Mean                2.21161
trainer/Log Pis Std                 0.841184
trainer/Log Pis Max                 5.53253
trainer/Log Pis Min                -0.988718
trainer/Policy mu Mean              0.0473668
trainer/Policy mu Std               0.649225
trainer/Policy mu Max               2.87501
trainer/Policy mu Min              -2.97525
trainer/Policy log std Mean        -2.08359
trainer/Policy log std Std          0.534363
trainer/Policy log std Max         -0.575687
trainer/Policy log std Min         -2.90234
trainer/Alpha                       0.0902176
trainer/Alpha Loss                  0.509047
exploration/num steps total     60600
exploration/num paths total       606
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.692928
exploration/Rewards Std             1.12561
exploration/Rewards Max            -0.105021
exploration/Rewards Min            -7.8454
exploration/Returns Mean          -69.2928
exploration/Returns Std            25.1235
exploration/Returns Max           -44.1693
exploration/Returns Min           -94.4163
exploration/Actions Mean           -0.0223724
exploration/Actions Std             0.253296
exploration/Actions Max             0.996549
exploration/Actions Min            -0.998163
exploration/Num Paths               2
exploration/Average Returns       -69.2928
evaluation/num steps total     302000
evaluation/num paths total       3020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.443343
evaluation/Rewards Std              0.935726
evaluation/Rewards Max             -0.182031
evaluation/Rewards Min             -9.87719
evaluation/Returns Mean           -44.3343
evaluation/Returns Std             23.6212
evaluation/Returns Max            -20.8269
evaluation/Returns Min            -92.6885
evaluation/Actions Mean             0.0066059
evaluation/Actions Std              0.171279
evaluation/Actions Max              0.995185
evaluation/Actions Min             -0.993368
evaluation/Num Paths               10
evaluation/Average Returns        -44.3343
time/data storing (s)               0.0013054
time/evaluation sampling (s)        0.216958
time/exploration sampling (s)       0.063686
time/logging (s)                    0.00334608
time/saving (s)                     0.00195098
time/training (s)                   0.771146
time/epoch (s)                      1.05839
time/total (s)                    322.245
Epoch                             301
-----------------------------  ---------------
2019-04-21 01:17:07.173560 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 302 finished
-----------------------------  ---------------
replay_buffer/size              60800
trainer/QF1 Loss                   11.2744
trainer/QF2 Loss                   11.2628
trainer/Policy Loss                27.0131
trainer/Q1 Predictions Mean       -25.341
trainer/Q1 Predictions Std         10.9918
trainer/Q1 Predictions Max        -16.9966
trainer/Q1 Predictions Min        -95.1305
trainer/Q2 Predictions Mean       -25.3612
trainer/Q2 Predictions Std         11.0301
trainer/Q2 Predictions Max        -16.9805
trainer/Q2 Predictions Min        -95.5942
trainer/Q Targets Mean            -25.4937
trainer/Q Targets Std              11.5588
trainer/Q Targets Max              -0.979191
trainer/Q Targets Min             -97.7216
trainer/Log Pis Mean                2.13051
trainer/Log Pis Std                 1.26974
trainer/Log Pis Max                 7.58535
trainer/Log Pis Min                -2.12497
trainer/Policy mu Mean              0.102483
trainer/Policy mu Std               0.66087
trainer/Policy mu Max               2.87356
trainer/Policy mu Min              -3.09098
trainer/Policy log std Mean        -2.16337
trainer/Policy log std Std          0.578119
trainer/Policy log std Max         -0.518198
trainer/Policy log std Min         -2.93203
trainer/Alpha                       0.0906319
trainer/Alpha Loss                  0.313348
exploration/num steps total     60800
exploration/num paths total       608
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.393971
exploration/Rewards Std             1.02909
exploration/Rewards Max            -0.0248459
exploration/Rewards Min            -8.66576
exploration/Returns Mean          -39.3971
exploration/Returns Std            11.6997
exploration/Returns Max           -27.6974
exploration/Returns Min           -51.0968
exploration/Actions Mean            0.0192276
exploration/Actions Std             0.220671
exploration/Actions Max             0.99706
exploration/Actions Min            -0.987008
exploration/Num Paths               2
exploration/Average Returns       -39.3971
evaluation/num steps total     303000
evaluation/num paths total       3030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.486205
evaluation/Rewards Std              1.04959
evaluation/Rewards Max             -0.154409
evaluation/Rewards Min            -10.0994
evaluation/Returns Mean           -48.6205
evaluation/Returns Std             24.8982
evaluation/Returns Max            -23.2028
evaluation/Returns Min           -104.902
evaluation/Actions Mean             0.0215187
evaluation/Actions Std              0.195027
evaluation/Actions Max              0.996268
evaluation/Actions Min             -0.996229
evaluation/Num Paths               10
evaluation/Average Returns        -48.6205
time/data storing (s)               0.00126971
time/evaluation sampling (s)        0.216919
time/exploration sampling (s)       0.0644211
time/logging (s)                    0.00336522
time/saving (s)                     0.00195517
time/training (s)                   0.774798
time/epoch (s)                      1.06273
time/total (s)                    323.312
Epoch                             302
-----------------------------  ---------------
2019-04-21 01:17:08.249753 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 303 finished
-----------------------------  ---------------
replay_buffer/size              61000
trainer/QF1 Loss                    0.139197
trainer/QF2 Loss                    0.155172
trainer/Policy Loss                27.8148
trainer/Q1 Predictions Mean       -26.0626
trainer/Q1 Predictions Std          9.83914
trainer/Q1 Predictions Max        -16.8142
trainer/Q1 Predictions Min        -61.0247
trainer/Q2 Predictions Mean       -26.0795
trainer/Q2 Predictions Std          9.82016
trainer/Q2 Predictions Max        -16.8352
trainer/Q2 Predictions Min        -61.0299
trainer/Q Targets Mean            -26.3597
trainer/Q Targets Std               9.86169
trainer/Q Targets Max             -17.0171
trainer/Q Targets Min             -61.0402
trainer/Log Pis Mean                2.32086
trainer/Log Pis Std                 1.13316
trainer/Log Pis Max                 6.32352
trainer/Log Pis Min                -1.27911
trainer/Policy mu Mean              0.062721
trainer/Policy mu Std               0.736732
trainer/Policy mu Max               2.63335
trainer/Policy mu Min              -2.51938
trainer/Policy log std Mean        -2.1193
trainer/Policy log std Std          0.627119
trainer/Policy log std Max         -0.439067
trainer/Policy log std Min         -2.87373
trainer/Alpha                       0.0925413
trainer/Alpha Loss                  0.763749
exploration/num steps total     61000
exploration/num paths total       610
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.653731
exploration/Rewards Std             0.648835
exploration/Rewards Max            -0.373931
exploration/Rewards Min            -6.40638
exploration/Returns Mean          -65.3731
exploration/Returns Std             8.10607
exploration/Returns Max           -57.267
exploration/Returns Min           -73.4792
exploration/Actions Mean           -0.0157351
exploration/Actions Std             0.207927
exploration/Actions Max             0.939512
exploration/Actions Min            -0.995464
exploration/Num Paths               2
exploration/Average Returns       -65.3731
evaluation/num steps total     304000
evaluation/num paths total       3040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.462941
evaluation/Rewards Std              0.739098
evaluation/Rewards Max             -0.107215
evaluation/Rewards Min             -8.55373
evaluation/Returns Mean           -46.2941
evaluation/Returns Std             21.7168
evaluation/Returns Max            -16.3806
evaluation/Returns Min            -88.7065
evaluation/Actions Mean            -0.00119538
evaluation/Actions Std              0.168427
evaluation/Actions Max              0.991976
evaluation/Actions Min             -0.992411
evaluation/Num Paths               10
evaluation/Average Returns        -46.2941
time/data storing (s)               0.00124087
time/evaluation sampling (s)        0.22243
time/exploration sampling (s)       0.0652512
time/logging (s)                    0.00253421
time/saving (s)                     0.00199424
time/training (s)                   0.773351
time/epoch (s)                      1.0668
time/total (s)                    324.383
Epoch                             303
-----------------------------  ---------------
2019-04-21 01:17:09.315230 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 304 finished
-----------------------------  ---------------
replay_buffer/size              61200
trainer/QF1 Loss                    0.661661
trainer/QF2 Loss                    0.649674
trainer/Policy Loss                28.1753
trainer/Q1 Predictions Mean       -26.5144
trainer/Q1 Predictions Std         10.4419
trainer/Q1 Predictions Max        -16.8242
trainer/Q1 Predictions Min        -86.1209
trainer/Q2 Predictions Mean       -26.5229
trainer/Q2 Predictions Std         10.4563
trainer/Q2 Predictions Max        -16.8172
trainer/Q2 Predictions Min        -86.3407
trainer/Q Targets Mean            -27.1639
trainer/Q Targets Std              10.8739
trainer/Q Targets Max             -16.9375
trainer/Q Targets Min             -87.9753
trainer/Log Pis Mean                2.0887
trainer/Log Pis Std                 1.19073
trainer/Log Pis Max                 6.06318
trainer/Log Pis Min                -4.49985
trainer/Policy mu Mean             -0.0750501
trainer/Policy mu Std               0.664378
trainer/Policy mu Max               2.14091
trainer/Policy mu Min              -3.05009
trainer/Policy log std Mean        -2.0831
trainer/Policy log std Std          0.578443
trainer/Policy log std Max         -0.428013
trainer/Policy log std Min         -2.81761
trainer/Alpha                       0.0946889
trainer/Alpha Loss                  0.2091
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.355182
exploration/Rewards Std             0.761817
exploration/Rewards Max            -0.0115189
exploration/Rewards Min            -5.7673
exploration/Returns Mean          -35.5182
exploration/Returns Std             2.83958
exploration/Returns Max           -32.6787
exploration/Returns Min           -38.3578
exploration/Actions Mean            0.031389
exploration/Actions Std             0.199196
exploration/Actions Max             0.997545
exploration/Actions Min            -0.481325
exploration/Num Paths               2
exploration/Average Returns       -35.5182
evaluation/num steps total     305000
evaluation/num paths total       3050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.485138
evaluation/Rewards Std              1.21506
evaluation/Rewards Max             -0.0975374
evaluation/Rewards Min            -10.259
evaluation/Returns Mean           -48.5138
evaluation/Returns Std             31.0096
evaluation/Returns Max            -15.3078
evaluation/Returns Min           -108.05
evaluation/Actions Mean             0.0169457
evaluation/Actions Std              0.190694
evaluation/Actions Max              0.994877
evaluation/Actions Min             -0.996901
evaluation/Num Paths               10
evaluation/Average Returns        -48.5138
time/data storing (s)               0.00120787
time/evaluation sampling (s)        0.220517
time/exploration sampling (s)       0.0645975
time/logging (s)                    0.00252591
time/saving (s)                     0.00198311
time/training (s)                   0.767714
time/epoch (s)                      1.05855
time/total (s)                    325.445
Epoch                             304
-----------------------------  ---------------
2019-04-21 01:17:10.392108 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 305 finished
-----------------------------  ---------------
replay_buffer/size              61400
trainer/QF1 Loss                    0.182052
trainer/QF2 Loss                    0.186488
trainer/Policy Loss                26.7308
trainer/Q1 Predictions Mean       -25.1282
trainer/Q1 Predictions Std          9.28463
trainer/Q1 Predictions Max        -16.5374
trainer/Q1 Predictions Min        -68.5488
trainer/Q2 Predictions Mean       -25.1443
trainer/Q2 Predictions Std          9.27002
trainer/Q2 Predictions Max        -16.5556
trainer/Q2 Predictions Min        -69.0064
trainer/Q Targets Mean            -25.5034
trainer/Q Targets Std               9.36078
trainer/Q Targets Max             -16.8052
trainer/Q Targets Min             -68.7247
trainer/Log Pis Mean                2.0278
trainer/Log Pis Std                 1.32164
trainer/Log Pis Max                 7.02909
trainer/Log Pis Min                -3.27268
trainer/Policy mu Mean              0.0180877
trainer/Policy mu Std               0.639641
trainer/Policy mu Max               2.0103
trainer/Policy mu Min              -2.74428
trainer/Policy log std Mean        -2.12411
trainer/Policy log std Std          0.583825
trainer/Policy log std Max         -0.521636
trainer/Policy log std Min         -2.91106
trainer/Alpha                       0.0939996
trainer/Alpha Loss                  0.0657389
exploration/num steps total     61400
exploration/num paths total       614
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.481528
exploration/Rewards Std             1.35915
exploration/Rewards Max            -0.0112153
exploration/Rewards Min           -10.0484
exploration/Returns Mean          -48.1528
exploration/Returns Std            24.9028
exploration/Returns Max           -23.25
exploration/Returns Min           -73.0556
exploration/Actions Mean            0.0335522
exploration/Actions Std             0.214758
exploration/Actions Max             0.997253
exploration/Actions Min            -0.741074
exploration/Num Paths               2
exploration/Average Returns       -48.1528
evaluation/num steps total     306000
evaluation/num paths total       3060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.563869
evaluation/Rewards Std              1.25758
evaluation/Rewards Max             -0.146321
evaluation/Rewards Min            -10.5677
evaluation/Returns Mean           -56.3869
evaluation/Returns Std             29.5748
evaluation/Returns Max            -21.6199
evaluation/Returns Min           -102.013
evaluation/Actions Mean             0.00100149
evaluation/Actions Std              0.207549
evaluation/Actions Max              0.99288
evaluation/Actions Min             -0.998261
evaluation/Num Paths               10
evaluation/Average Returns        -56.3869
time/data storing (s)               0.00120564
time/evaluation sampling (s)        0.221137
time/exploration sampling (s)       0.0620121
time/logging (s)                    0.00338083
time/saving (s)                     0.00744133
time/training (s)                   0.774878
time/epoch (s)                      1.07005
time/total (s)                    326.519
Epoch                             305
-----------------------------  ---------------
2019-04-21 01:17:11.453343 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 306 finished
-----------------------------  ---------------
replay_buffer/size              61600
trainer/QF1 Loss                   21.8984
trainer/QF2 Loss                   21.9072
trainer/Policy Loss                29.8319
trainer/Q1 Predictions Mean       -28.5924
trainer/Q1 Predictions Std         11.5171
trainer/Q1 Predictions Max        -16.6693
trainer/Q1 Predictions Min        -97.6252
trainer/Q2 Predictions Mean       -28.6151
trainer/Q2 Predictions Std         11.5514
trainer/Q2 Predictions Max        -16.6579
trainer/Q2 Predictions Min        -97.8267
trainer/Q Targets Mean            -28.2763
trainer/Q Targets Std              12.3053
trainer/Q Targets Max              -0.648392
trainer/Q Targets Min             -99.109
trainer/Log Pis Mean                2.05914
trainer/Log Pis Std                 1.09546
trainer/Log Pis Max                 6.8269
trainer/Log Pis Min                -1.17894
trainer/Policy mu Mean             -0.0272779
trainer/Policy mu Std               0.780055
trainer/Policy mu Max               2.46056
trainer/Policy mu Min              -3.01859
trainer/Policy log std Mean        -2.0045
trainer/Policy log std Std          0.618668
trainer/Policy log std Max         -0.471193
trainer/Policy log std Min         -2.83171
trainer/Alpha                       0.0926973
trainer/Alpha Loss                  0.140662
exploration/num steps total     61600
exploration/num paths total       616
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.651745
exploration/Rewards Std             1.19819
exploration/Rewards Max            -0.0640187
exploration/Rewards Min            -8.66843
exploration/Returns Mean          -65.1745
exploration/Returns Std             2.01644
exploration/Returns Max           -63.1581
exploration/Returns Min           -67.191
exploration/Actions Mean            0.0272417
exploration/Actions Std             0.255144
exploration/Actions Max             0.99739
exploration/Actions Min            -0.99638
exploration/Num Paths               2
exploration/Average Returns       -65.1745
evaluation/num steps total     307000
evaluation/num paths total       3070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.566999
evaluation/Rewards Std              1.00039
evaluation/Rewards Max             -0.181225
evaluation/Rewards Min             -9.32719
evaluation/Returns Mean           -56.6999
evaluation/Returns Std             23.5278
evaluation/Returns Max            -19.0226
evaluation/Returns Min            -92.1376
evaluation/Actions Mean            -0.00383081
evaluation/Actions Std              0.177916
evaluation/Actions Max              0.993526
evaluation/Actions Min             -0.996418
evaluation/Num Paths               10
evaluation/Average Returns        -56.6999
time/data storing (s)               0.00124624
time/evaluation sampling (s)        0.225174
time/exploration sampling (s)       0.0639808
time/logging (s)                    0.00339495
time/saving (s)                     0.00197184
time/training (s)                   0.756895
time/epoch (s)                      1.05266
time/total (s)                    327.576
Epoch                             306
-----------------------------  ---------------
2019-04-21 01:17:12.515073 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 307 finished
-----------------------------  ---------------
replay_buffer/size              61800
trainer/QF1 Loss                    0.249421
trainer/QF2 Loss                    0.315317
trainer/Policy Loss                28.0854
trainer/Q1 Predictions Mean       -26.619
trainer/Q1 Predictions Std          9.0391
trainer/Q1 Predictions Max        -16.3834
trainer/Q1 Predictions Min        -51.6343
trainer/Q2 Predictions Mean       -26.6246
trainer/Q2 Predictions Std          9.05315
trainer/Q2 Predictions Max        -16.4048
trainer/Q2 Predictions Min        -52.6439
trainer/Q Targets Mean            -26.9738
trainer/Q Targets Std               9.10897
trainer/Q Targets Max             -16.766
trainer/Q Targets Min             -52.9884
trainer/Log Pis Mean                1.97727
trainer/Log Pis Std                 1.2805
trainer/Log Pis Max                 5.809
trainer/Log Pis Min                -5.14978
trainer/Policy mu Mean              0.118739
trainer/Policy mu Std               0.653956
trainer/Policy mu Max               2.72045
trainer/Policy mu Min              -2.69798
trainer/Policy log std Mean        -2.05314
trainer/Policy log std Std          0.556958
trainer/Policy log std Max         -0.449075
trainer/Policy log std Min         -2.90143
trainer/Alpha                       0.0934092
trainer/Alpha Loss                 -0.0538944
exploration/num steps total     61800
exploration/num paths total       618
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.487466
exploration/Rewards Std             0.777191
exploration/Rewards Max            -0.0217721
exploration/Rewards Min            -6.88577
exploration/Returns Mean          -48.7466
exploration/Returns Std            30.6621
exploration/Returns Max           -18.0845
exploration/Returns Min           -79.4087
exploration/Actions Mean           -0.0276414
exploration/Actions Std             0.198755
exploration/Actions Max             0.51671
exploration/Actions Min            -0.986701
exploration/Num Paths               2
exploration/Average Returns       -48.7466
evaluation/num steps total     308000
evaluation/num paths total       3080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.622281
evaluation/Rewards Std              0.970524
evaluation/Rewards Max             -0.152474
evaluation/Rewards Min             -9.44508
evaluation/Returns Mean           -62.2281
evaluation/Returns Std             18.9907
evaluation/Returns Max            -31.9162
evaluation/Returns Min            -99.1148
evaluation/Actions Mean            -0.00225071
evaluation/Actions Std              0.189495
evaluation/Actions Max              0.993278
evaluation/Actions Min             -0.99667
evaluation/Num Paths               10
evaluation/Average Returns        -62.2281
time/data storing (s)               0.00140592
time/evaluation sampling (s)        0.22448
time/exploration sampling (s)       0.0632982
time/logging (s)                    0.00338467
time/saving (s)                     0.00217199
time/training (s)                   0.75817
time/epoch (s)                      1.05291
time/total (s)                    328.633
Epoch                             307
-----------------------------  ---------------
2019-04-21 01:17:13.572662 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 308 finished
-----------------------------  ---------------
replay_buffer/size              62000
trainer/QF1 Loss                    0.144498
trainer/QF2 Loss                    0.168126
trainer/Policy Loss                29.4226
trainer/Q1 Predictions Mean       -28.3272
trainer/Q1 Predictions Std         13.2781
trainer/Q1 Predictions Max        -16.5955
trainer/Q1 Predictions Min       -101.21
trainer/Q2 Predictions Mean       -28.3475
trainer/Q2 Predictions Std         13.317
trainer/Q2 Predictions Max        -16.5916
trainer/Q2 Predictions Min       -101.634
trainer/Q Targets Mean            -28.521
trainer/Q Targets Std              13.3757
trainer/Q Targets Max             -16.6035
trainer/Q Targets Min            -101.096
trainer/Log Pis Mean                1.86794
trainer/Log Pis Std                 1.44555
trainer/Log Pis Max                 7.97859
trainer/Log Pis Min                -4.28689
trainer/Policy mu Mean              0.0847495
trainer/Policy mu Std               0.842201
trainer/Policy mu Max               2.74616
trainer/Policy mu Min              -3.32603
trainer/Policy log std Mean        -1.91847
trainer/Policy log std Std          0.664152
trainer/Policy log std Max         -0.0332686
trainer/Policy log std Min         -2.8799
trainer/Alpha                       0.0936147
trainer/Alpha Loss                 -0.312797
exploration/num steps total     62000
exploration/num paths total       620
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.212984
exploration/Rewards Std             0.256823
exploration/Rewards Max            -0.0331131
exploration/Rewards Min            -2.52746
exploration/Returns Mean          -21.2984
exploration/Returns Std             2.62734
exploration/Returns Max           -18.671
exploration/Returns Min           -23.9257
exploration/Actions Mean           -0.00277297
exploration/Actions Std             0.154922
exploration/Actions Max             0.988569
exploration/Actions Min            -0.896968
exploration/Num Paths               2
exploration/Average Returns       -21.2984
evaluation/num steps total     309000
evaluation/num paths total       3090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.441891
evaluation/Rewards Std              0.968846
evaluation/Rewards Max             -0.133048
evaluation/Rewards Min             -9.75269
evaluation/Returns Mean           -44.1891
evaluation/Returns Std             23.3588
evaluation/Returns Max            -15.4693
evaluation/Returns Min            -96.6263
evaluation/Actions Mean             0.00940976
evaluation/Actions Std              0.182298
evaluation/Actions Max              0.992413
evaluation/Actions Min             -0.995953
evaluation/Num Paths               10
evaluation/Average Returns        -44.1891
time/data storing (s)               0.00119592
time/evaluation sampling (s)        0.21971
time/exploration sampling (s)       0.0625836
time/logging (s)                    0.00249562
time/saving (s)                     0.00197556
time/training (s)                   0.760449
time/epoch (s)                      1.04841
time/total (s)                    329.686
Epoch                             308
-----------------------------  ---------------
2019-04-21 01:17:14.623326 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 309 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                    0.178705
trainer/QF2 Loss                    0.190261
trainer/Policy Loss                28.5149
trainer/Q1 Predictions Mean       -26.923
trainer/Q1 Predictions Std          9.41605
trainer/Q1 Predictions Max        -16.2102
trainer/Q1 Predictions Min        -58.1086
trainer/Q2 Predictions Mean       -26.9113
trainer/Q2 Predictions Std          9.40904
trainer/Q2 Predictions Max        -16.2028
trainer/Q2 Predictions Min        -57.6129
trainer/Q Targets Mean            -27.2204
trainer/Q Targets Std               9.44967
trainer/Q Targets Max             -16.3642
trainer/Q Targets Min             -58.5868
trainer/Log Pis Mean                1.96868
trainer/Log Pis Std                 1.18172
trainer/Log Pis Max                 7.19005
trainer/Log Pis Min                -1.57206
trainer/Policy mu Mean              0.0791837
trainer/Policy mu Std               0.72047
trainer/Policy mu Max               2.80097
trainer/Policy mu Min              -2.55135
trainer/Policy log std Mean        -2.0884
trainer/Policy log std Std          0.601936
trainer/Policy log std Max         -0.287992
trainer/Policy log std Min         -2.97848
trainer/Alpha                       0.0928473
trainer/Alpha Loss                 -0.0744398
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.468985
exploration/Rewards Std             0.753602
exploration/Rewards Max            -0.040055
exploration/Rewards Min            -7.16358
exploration/Returns Mean          -46.8985
exploration/Returns Std             4.48579
exploration/Returns Max           -42.4127
exploration/Returns Min           -51.3843
exploration/Actions Mean           -0.0022609
exploration/Actions Std             0.208206
exploration/Actions Max             0.996792
exploration/Actions Min            -0.981457
exploration/Num Paths               2
exploration/Average Returns       -46.8985
evaluation/num steps total     310000
evaluation/num paths total       3100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.493875
evaluation/Rewards Std              0.939794
evaluation/Rewards Max             -0.150621
evaluation/Rewards Min            -11.0228
evaluation/Returns Mean           -49.3875
evaluation/Returns Std             23.6034
evaluation/Returns Max            -15.4561
evaluation/Returns Min            -82.9958
evaluation/Actions Mean             0.00739051
evaluation/Actions Std              0.181335
evaluation/Actions Max              0.994227
evaluation/Actions Min             -0.99328
evaluation/Num Paths               10
evaluation/Average Returns        -49.3875
time/data storing (s)               0.0012767
time/evaluation sampling (s)        0.223518
time/exploration sampling (s)       0.0653741
time/logging (s)                    0.00336866
time/saving (s)                     0.00199746
time/training (s)                   0.747947
time/epoch (s)                      1.04348
time/total (s)                    330.733
Epoch                             309
-----------------------------  ---------------
2019-04-21 01:17:15.689354 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 310 finished
-----------------------------  ---------------
replay_buffer/size              62400
trainer/QF1 Loss                    0.112935
trainer/QF2 Loss                    0.114591
trainer/Policy Loss                26.2677
trainer/Q1 Predictions Mean       -24.7933
trainer/Q1 Predictions Std          8.99834
trainer/Q1 Predictions Max        -16.173
trainer/Q1 Predictions Min        -56.7552
trainer/Q2 Predictions Mean       -24.8308
trainer/Q2 Predictions Std          8.98726
trainer/Q2 Predictions Max        -16.2175
trainer/Q2 Predictions Min        -56.3668
trainer/Q Targets Mean            -25.0313
trainer/Q Targets Std               9.08847
trainer/Q Targets Max             -16.2882
trainer/Q Targets Min             -57.3161
trainer/Log Pis Mean                1.97213
trainer/Log Pis Std                 1.24016
trainer/Log Pis Max                 4.60254
trainer/Log Pis Min                -1.6433
trainer/Policy mu Mean              0.0324583
trainer/Policy mu Std               0.644146
trainer/Policy mu Max               2.45625
trainer/Policy mu Min              -2.3262
trainer/Policy log std Mean        -2.16132
trainer/Policy log std Std          0.567217
trainer/Policy log std Max         -0.621982
trainer/Policy log std Min         -2.96222
trainer/Alpha                       0.095474
trainer/Alpha Loss                 -0.0654674
exploration/num steps total     62400
exploration/num paths total       624
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31965
exploration/Rewards Std             0.922979
exploration/Rewards Max            -0.00649346
exploration/Rewards Min            -7.70274
exploration/Returns Mean          -31.965
exploration/Returns Std            12.2273
exploration/Returns Max           -19.7377
exploration/Returns Min           -44.1924
exploration/Actions Mean            0.0450039
exploration/Actions Std             0.20845
exploration/Actions Max             0.995778
exploration/Actions Min            -0.556013
exploration/Num Paths               2
exploration/Average Returns       -31.965
evaluation/num steps total     311000
evaluation/num paths total       3110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.562835
evaluation/Rewards Std              0.903753
evaluation/Rewards Max             -0.0860308
evaluation/Rewards Min            -10.5001
evaluation/Returns Mean           -56.2835
evaluation/Returns Std              8.12209
evaluation/Returns Max            -45.3538
evaluation/Returns Min            -71.1554
evaluation/Actions Mean            -0.0146014
evaluation/Actions Std              0.177666
evaluation/Actions Max              0.996951
evaluation/Actions Min             -0.991799
evaluation/Num Paths               10
evaluation/Average Returns        -56.2835
time/data storing (s)               0.0012584
time/evaluation sampling (s)        0.219537
time/exploration sampling (s)       0.0629205
time/logging (s)                    0.00335924
time/saving (s)                     0.00199147
time/training (s)                   0.768506
time/epoch (s)                      1.05757
time/total (s)                    331.795
Epoch                             310
-----------------------------  ---------------
2019-04-21 01:17:16.771958 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 311 finished
-----------------------------  ---------------
replay_buffer/size              62600
trainer/QF1 Loss                   14.684
trainer/QF2 Loss                   14.85
trainer/Policy Loss                27.244
trainer/Q1 Predictions Mean       -25.6844
trainer/Q1 Predictions Std          8.80614
trainer/Q1 Predictions Max        -16.1405
trainer/Q1 Predictions Min        -43.4694
trainer/Q2 Predictions Mean       -25.6666
trainer/Q2 Predictions Std          8.82039
trainer/Q2 Predictions Max        -16.1414
trainer/Q2 Predictions Min        -43.8524
trainer/Q Targets Mean            -25.205
trainer/Q Targets Std               9.40962
trainer/Q Targets Max              -0.553933
trainer/Q Targets Min             -44.0493
trainer/Log Pis Mean                2.06218
trainer/Log Pis Std                 1.11588
trainer/Log Pis Max                 4.4956
trainer/Log Pis Min                -1.60878
trainer/Policy mu Mean              0.0403024
trainer/Policy mu Std               0.668198
trainer/Policy mu Max               2.54428
trainer/Policy mu Min              -2.15994
trainer/Policy log std Mean        -2.0398
trainer/Policy log std Std          0.604937
trainer/Policy log std Max         -0.603078
trainer/Policy log std Min         -2.87902
trainer/Alpha                       0.0965607
trainer/Alpha Loss                  0.145349
exploration/num steps total     62600
exploration/num paths total       626
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.606085
exploration/Rewards Std             1.03298
exploration/Rewards Max            -0.0539326
exploration/Rewards Min            -8.44236
exploration/Returns Mean          -60.6085
exploration/Returns Std            28.5178
exploration/Returns Max           -32.0907
exploration/Returns Min           -89.1263
exploration/Actions Mean           -0.00686219
exploration/Actions Std             0.233154
exploration/Actions Max             0.959997
exploration/Actions Min            -0.994535
exploration/Num Paths               2
exploration/Average Returns       -60.6085
evaluation/num steps total     312000
evaluation/num paths total       3120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.473361
evaluation/Rewards Std              0.80106
evaluation/Rewards Max             -0.174541
evaluation/Rewards Min             -9.24704
evaluation/Returns Mean           -47.3361
evaluation/Returns Std             13.839
evaluation/Returns Max            -23.0819
evaluation/Returns Min            -62.7302
evaluation/Actions Mean             0.0124625
evaluation/Actions Std              0.176611
evaluation/Actions Max              0.995934
evaluation/Actions Min             -0.979985
evaluation/Num Paths               10
evaluation/Average Returns        -47.3361
time/data storing (s)               0.0014377
time/evaluation sampling (s)        0.241131
time/exploration sampling (s)       0.0717549
time/logging (s)                    0.00337791
time/saving (s)                     0.00747078
time/training (s)                   0.748663
time/epoch (s)                      1.07383
time/total (s)                    332.872
Epoch                             311
-----------------------------  ---------------
2019-04-21 01:17:17.851505 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 312 finished
-----------------------------  ---------------
replay_buffer/size              62800
trainer/QF1 Loss                   13.2257
trainer/QF2 Loss                   13.2386
trainer/Policy Loss                26.9756
trainer/Q1 Predictions Mean       -25.4456
trainer/Q1 Predictions Std          8.68387
trainer/Q1 Predictions Max        -15.9614
trainer/Q1 Predictions Min        -57.9998
trainer/Q2 Predictions Mean       -25.4439
trainer/Q2 Predictions Std          8.68335
trainer/Q2 Predictions Max        -15.9316
trainer/Q2 Predictions Min        -57.9895
trainer/Q Targets Mean            -25.3299
trainer/Q Targets Std               9.46703
trainer/Q Targets Max              -0.224838
trainer/Q Targets Min             -57.8213
trainer/Log Pis Mean                2.07783
trainer/Log Pis Std                 0.965196
trainer/Log Pis Max                 4.87059
trainer/Log Pis Min                -1.87192
trainer/Policy mu Mean              0.0987168
trainer/Policy mu Std               0.603928
trainer/Policy mu Max               2.50108
trainer/Policy mu Min              -2.47708
trainer/Policy log std Mean        -2.1081
trainer/Policy log std Std          0.546465
trainer/Policy log std Max         -0.603464
trainer/Policy log std Min         -2.89976
trainer/Alpha                       0.0975309
trainer/Alpha Loss                  0.181156
exploration/num steps total     62800
exploration/num paths total       628
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.554802
exploration/Rewards Std             1.03817
exploration/Rewards Max            -0.0913871
exploration/Rewards Min            -8.73541
exploration/Returns Mean          -55.4802
exploration/Returns Std            35.5877
exploration/Returns Max           -19.8924
exploration/Returns Min           -91.0679
exploration/Actions Mean           -0.0309024
exploration/Actions Std             0.21381
exploration/Actions Max             0.802361
exploration/Actions Min            -0.995166
exploration/Num Paths               2
exploration/Average Returns       -55.4802
evaluation/num steps total     313000
evaluation/num paths total       3130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.577979
evaluation/Rewards Std              1.02599
evaluation/Rewards Max             -0.163149
evaluation/Rewards Min            -10.282
evaluation/Returns Mean           -57.7979
evaluation/Returns Std             14.1814
evaluation/Returns Max            -17.63
evaluation/Returns Min            -70.599
evaluation/Actions Mean             0.0114182
evaluation/Actions Std              0.181089
evaluation/Actions Max              0.994745
evaluation/Actions Min             -0.987443
evaluation/Num Paths               10
evaluation/Average Returns        -57.7979
time/data storing (s)               0.00123082
time/evaluation sampling (s)        0.246678
time/exploration sampling (s)       0.0693885
time/logging (s)                    0.00335857
time/saving (s)                     0.0101714
time/training (s)                   0.74056
time/epoch (s)                      1.07139
time/total (s)                    333.948
Epoch                             312
-----------------------------  ---------------
2019-04-21 01:17:18.906590 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 313 finished
-----------------------------  ---------------
replay_buffer/size              63000
trainer/QF1 Loss                    0.0912242
trainer/QF2 Loss                    0.0832764
trainer/Policy Loss                28.4629
trainer/Q1 Predictions Mean       -27.1276
trainer/Q1 Predictions Std          8.2886
trainer/Q1 Predictions Max        -16.1814
trainer/Q1 Predictions Min        -37.6441
trainer/Q2 Predictions Mean       -27.1118
trainer/Q2 Predictions Std          8.26518
trainer/Q2 Predictions Max        -16.099
trainer/Q2 Predictions Min        -37.4807
trainer/Q Targets Mean            -27.2374
trainer/Q Targets Std               8.40537
trainer/Q Targets Max             -16.0152
trainer/Q Targets Min             -38.0614
trainer/Log Pis Mean                1.93294
trainer/Log Pis Std                 1.09047
trainer/Log Pis Max                 5.02468
trainer/Log Pis Min                -2.38328
trainer/Policy mu Mean              0.00125435
trainer/Policy mu Std               0.618535
trainer/Policy mu Max               2.24843
trainer/Policy mu Min              -2.17374
trainer/Policy log std Mean        -2.04972
trainer/Policy log std Std          0.553331
trainer/Policy log std Max         -0.548735
trainer/Policy log std Min         -2.8493
trainer/Alpha                       0.0991398
trainer/Alpha Loss                 -0.154978
exploration/num steps total     63000
exploration/num paths total       630
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387517
exploration/Rewards Std             1.00081
exploration/Rewards Max            -0.0149595
exploration/Rewards Min            -7.48906
exploration/Returns Mean          -38.7517
exploration/Returns Std             2.85731
exploration/Returns Max           -35.8944
exploration/Returns Min           -41.609
exploration/Actions Mean            0.00553787
exploration/Actions Std             0.239878
exploration/Actions Max             0.992351
exploration/Actions Min            -0.99186
exploration/Num Paths               2
exploration/Average Returns       -38.7517
evaluation/num steps total     314000
evaluation/num paths total       3140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.386273
evaluation/Rewards Std              0.786358
evaluation/Rewards Max             -0.108384
evaluation/Rewards Min             -9.6874
evaluation/Returns Mean           -38.6273
evaluation/Returns Std             24.4729
evaluation/Returns Max            -12.5254
evaluation/Returns Min            -88.9712
evaluation/Actions Mean             0.00901087
evaluation/Actions Std              0.17048
evaluation/Actions Max              0.989673
evaluation/Actions Min             -0.997998
evaluation/Num Paths               10
evaluation/Average Returns        -38.6273
time/data storing (s)               0.00123647
time/evaluation sampling (s)        0.225726
time/exploration sampling (s)       0.0671902
time/logging (s)                    0.00340411
time/saving (s)                     0.0019709
time/training (s)                   0.746536
time/epoch (s)                      1.04606
time/total (s)                    334.999
Epoch                             313
-----------------------------  ---------------
2019-04-21 01:17:19.981915 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 314 finished
-----------------------------  ---------------
replay_buffer/size              63200
trainer/QF1 Loss                    2.65937
trainer/QF2 Loss                    2.67654
trainer/Policy Loss                29.3415
trainer/Q1 Predictions Mean       -27.9574
trainer/Q1 Predictions Std          9.19597
trainer/Q1 Predictions Max        -15.9242
trainer/Q1 Predictions Min        -62.8814
trainer/Q2 Predictions Mean       -27.9382
trainer/Q2 Predictions Std          9.17916
trainer/Q2 Predictions Max        -15.8679
trainer/Q2 Predictions Min        -62.7673
trainer/Q Targets Mean            -28.009
trainer/Q Targets Std               9.62746
trainer/Q Targets Max              -0.419695
trainer/Q Targets Min             -63.2548
trainer/Log Pis Mean                1.99345
trainer/Log Pis Std                 1.36208
trainer/Log Pis Max                 6.67362
trainer/Log Pis Min                -2.4202
trainer/Policy mu Mean              0.0618954
trainer/Policy mu Std               0.76457
trainer/Policy mu Max               2.79437
trainer/Policy mu Min              -2.72803
trainer/Policy log std Mean        -1.9803
trainer/Policy log std Std          0.603773
trainer/Policy log std Max         -0.406802
trainer/Policy log std Min         -2.93561
trainer/Alpha                       0.0975492
trainer/Alpha Loss                 -0.0152528
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.37888
exploration/Rewards Std             0.28208
exploration/Rewards Max            -0.0291955
exploration/Rewards Min            -2.73969
exploration/Returns Mean          -37.888
exploration/Returns Std            21.3876
exploration/Returns Max           -16.5004
exploration/Returns Min           -59.2756
exploration/Actions Mean           -0.00299258
exploration/Actions Std             0.156616
exploration/Actions Max             0.989578
exploration/Actions Min            -0.803356
exploration/Num Paths               2
exploration/Average Returns       -37.888
evaluation/num steps total     315000
evaluation/num paths total       3150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.530345
evaluation/Rewards Std              1.02556
evaluation/Rewards Max             -0.140162
evaluation/Rewards Min            -10.1715
evaluation/Returns Mean           -53.0345
evaluation/Returns Std             31.0328
evaluation/Returns Max            -15.4361
evaluation/Returns Min           -101.286
evaluation/Actions Mean            -0.00649722
evaluation/Actions Std              0.181292
evaluation/Actions Max              0.991492
evaluation/Actions Min             -0.997922
evaluation/Num Paths               10
evaluation/Average Returns        -53.0345
time/data storing (s)               0.00125335
time/evaluation sampling (s)        0.223753
time/exploration sampling (s)       0.0640068
time/logging (s)                    0.00336586
time/saving (s)                     0.001992
time/training (s)                   0.771839
time/epoch (s)                      1.06621
time/total (s)                    336.069
Epoch                             314
-----------------------------  ---------------
2019-04-21 01:17:21.060280 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 315 finished
-----------------------------  ---------------
replay_buffer/size              63400
trainer/QF1 Loss                    0.137907
trainer/QF2 Loss                    0.129726
trainer/Policy Loss                29.3965
trainer/Q1 Predictions Mean       -27.8337
trainer/Q1 Predictions Std          9.41828
trainer/Q1 Predictions Max        -15.7116
trainer/Q1 Predictions Min        -61.946
trainer/Q2 Predictions Mean       -27.8507
trainer/Q2 Predictions Std          9.41108
trainer/Q2 Predictions Max        -15.6948
trainer/Q2 Predictions Min        -61.8858
trainer/Q Targets Mean            -28.1155
trainer/Q Targets Std               9.37483
trainer/Q Targets Max             -15.9865
trainer/Q Targets Min             -61.3606
trainer/Log Pis Mean                2.0219
trainer/Log Pis Std                 1.18907
trainer/Log Pis Max                 5.16075
trainer/Log Pis Min                -3.16541
trainer/Policy mu Mean              0.0386253
trainer/Policy mu Std               0.770773
trainer/Policy mu Max               2.76891
trainer/Policy mu Min              -2.67262
trainer/Policy log std Mean        -2.00127
trainer/Policy log std Std          0.603441
trainer/Policy log std Max         -0.470198
trainer/Policy log std Min         -2.83383
trainer/Alpha                       0.095842
trainer/Alpha Loss                  0.0513654
exploration/num steps total     63400
exploration/num paths total       634
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.528396
exploration/Rewards Std             1.38322
exploration/Rewards Max            -0.01921
exploration/Rewards Min            -9.71045
exploration/Returns Mean          -52.8396
exploration/Returns Std             9.03785
exploration/Returns Max           -43.8017
exploration/Returns Min           -61.8774
exploration/Actions Mean            0.0567111
exploration/Actions Std             0.23947
exploration/Actions Max             0.996511
exploration/Actions Min            -0.557059
exploration/Num Paths               2
exploration/Average Returns       -52.8396
evaluation/num steps total     316000
evaluation/num paths total       3160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.481765
evaluation/Rewards Std              1.00697
evaluation/Rewards Max             -0.121655
evaluation/Rewards Min             -9.37758
evaluation/Returns Mean           -48.1765
evaluation/Returns Std             24.6422
evaluation/Returns Max            -14.4863
evaluation/Returns Min            -92.9325
evaluation/Actions Mean             0.00638475
evaluation/Actions Std              0.180971
evaluation/Actions Max              0.991785
evaluation/Actions Min             -0.994861
evaluation/Num Paths               10
evaluation/Average Returns        -48.1765
time/data storing (s)               0.00121756
time/evaluation sampling (s)        0.222955
time/exploration sampling (s)       0.0632784
time/logging (s)                    0.00334889
time/saving (s)                     0.001947
time/training (s)                   0.776526
time/epoch (s)                      1.06927
time/total (s)                    337.143
Epoch                             315
-----------------------------  ---------------
2019-04-21 01:17:22.134126 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 316 finished
-----------------------------  ---------------
replay_buffer/size              63600
trainer/QF1 Loss                    0.171891
trainer/QF2 Loss                    0.12078
trainer/Policy Loss                29.8982
trainer/Q1 Predictions Mean       -28.3061
trainer/Q1 Predictions Std         12.1702
trainer/Q1 Predictions Max        -15.7728
trainer/Q1 Predictions Min        -85.2387
trainer/Q2 Predictions Mean       -28.281
trainer/Q2 Predictions Std         12.1111
trainer/Q2 Predictions Max        -15.7662
trainer/Q2 Predictions Min        -84.1004
trainer/Q Targets Mean            -28.4005
trainer/Q Targets Std              12.001
trainer/Q Targets Max             -15.8332
trainer/Q Targets Min             -81.7855
trainer/Log Pis Mean                2.09955
trainer/Log Pis Std                 1.31816
trainer/Log Pis Max                 5.99762
trainer/Log Pis Min                -4.02964
trainer/Policy mu Mean             -0.0576292
trainer/Policy mu Std               0.730243
trainer/Policy mu Max               2.85618
trainer/Policy mu Min              -2.74533
trainer/Policy log std Mean        -2.08614
trainer/Policy log std Std          0.582427
trainer/Policy log std Max         -0.324416
trainer/Policy log std Min         -2.81142
trainer/Alpha                       0.095704
trainer/Alpha Loss                  0.233585
exploration/num steps total     63600
exploration/num paths total       636
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.706509
exploration/Rewards Std             0.907982
exploration/Rewards Max            -0.322748
exploration/Rewards Min            -8.1291
exploration/Returns Mean          -70.6509
exploration/Returns Std            15.5982
exploration/Returns Max           -55.0528
exploration/Returns Min           -86.2491
exploration/Actions Mean           -0.0230436
exploration/Actions Std             0.216941
exploration/Actions Max             0.982652
exploration/Actions Min            -0.993024
exploration/Num Paths               2
exploration/Average Returns       -70.6509
evaluation/num steps total     317000
evaluation/num paths total       3170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.580113
evaluation/Rewards Std              1.14823
evaluation/Rewards Max             -0.180659
evaluation/Rewards Min            -10.0374
evaluation/Returns Mean           -58.0113
evaluation/Returns Std             25.083
evaluation/Returns Max            -21.2106
evaluation/Returns Min            -99.5201
evaluation/Actions Mean            -0.00724135
evaluation/Actions Std              0.19441
evaluation/Actions Max              0.994117
evaluation/Actions Min             -0.996288
evaluation/Num Paths               10
evaluation/Average Returns        -58.0113
time/data storing (s)               0.00122905
time/evaluation sampling (s)        0.21867
time/exploration sampling (s)       0.0661366
time/logging (s)                    0.00336013
time/saving (s)                     0.00198473
time/training (s)                   0.773416
time/epoch (s)                      1.0648
time/total (s)                    338.212
Epoch                             316
-----------------------------  ---------------
2019-04-21 01:17:23.197229 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 317 finished
-----------------------------  ---------------
replay_buffer/size              63800
trainer/QF1 Loss                    0.211072
trainer/QF2 Loss                    0.19704
trainer/Policy Loss                28.2507
trainer/Q1 Predictions Mean       -26.8397
trainer/Q1 Predictions Std         12.5462
trainer/Q1 Predictions Max        -15.617
trainer/Q1 Predictions Min        -89.7687
trainer/Q2 Predictions Mean       -26.844
trainer/Q2 Predictions Std         12.6003
trainer/Q2 Predictions Max        -15.5645
trainer/Q2 Predictions Min        -90.0114
trainer/Q Targets Mean            -27.1822
trainer/Q Targets Std              12.6363
trainer/Q Targets Max             -15.7794
trainer/Q Targets Min             -90.0965
trainer/Log Pis Mean                1.95682
trainer/Log Pis Std                 1.04492
trainer/Log Pis Max                 4.63447
trainer/Log Pis Min                -2.31907
trainer/Policy mu Mean             -0.0404048
trainer/Policy mu Std               0.69132
trainer/Policy mu Max               2.56337
trainer/Policy mu Min              -2.96636
trainer/Policy log std Mean        -2.05387
trainer/Policy log std Std          0.555859
trainer/Policy log std Max         -0.557718
trainer/Policy log std Min         -2.75738
trainer/Alpha                       0.0959775
trainer/Alpha Loss                 -0.101183
exploration/num steps total     63800
exploration/num paths total       638
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.72913
exploration/Rewards Std             1.07234
exploration/Rewards Max            -0.32741
exploration/Rewards Min            -9.24178
exploration/Returns Mean          -72.913
exploration/Returns Std            15.495
exploration/Returns Max           -57.4181
exploration/Returns Min           -88.408
exploration/Actions Mean           -0.0428883
exploration/Actions Std             0.234756
exploration/Actions Max             0.462019
exploration/Actions Min            -0.99963
exploration/Num Paths               2
exploration/Average Returns       -72.913
evaluation/num steps total     318000
evaluation/num paths total       3180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.361513
evaluation/Rewards Std              0.810705
evaluation/Rewards Max             -0.109231
evaluation/Rewards Min             -9.0265
evaluation/Returns Mean           -36.1513
evaluation/Returns Std             20.513
evaluation/Returns Max            -12.3001
evaluation/Returns Min            -74.006
evaluation/Actions Mean             0.0077909
evaluation/Actions Std              0.162521
evaluation/Actions Max              0.99285
evaluation/Actions Min             -0.988382
evaluation/Num Paths               10
evaluation/Average Returns        -36.1513
time/data storing (s)               0.00131045
time/evaluation sampling (s)        0.215849
time/exploration sampling (s)       0.062389
time/logging (s)                    0.00343275
time/saving (s)                     0.00213371
time/training (s)                   0.768964
time/epoch (s)                      1.05408
time/total (s)                    339.27
Epoch                             317
-----------------------------  ---------------
2019-04-21 01:17:24.247865 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 318 finished
-----------------------------  ---------------
replay_buffer/size              64000
trainer/QF1 Loss                   23.6932
trainer/QF2 Loss                   23.746
trainer/Policy Loss                27.2067
trainer/Q1 Predictions Mean       -25.599
trainer/Q1 Predictions Std          9.81894
trainer/Q1 Predictions Max        -15.6299
trainer/Q1 Predictions Min        -68.5227
trainer/Q2 Predictions Mean       -25.6153
trainer/Q2 Predictions Std          9.80072
trainer/Q2 Predictions Max        -15.5941
trainer/Q2 Predictions Min        -68.3822
trainer/Q Targets Mean            -24.9521
trainer/Q Targets Std              10.6631
trainer/Q Targets Max              -0.701675
trainer/Q Targets Min             -69.982
trainer/Log Pis Mean                2.17769
trainer/Log Pis Std                 0.959601
trainer/Log Pis Max                 5.44793
trainer/Log Pis Min                -0.818529
trainer/Policy mu Mean              0.0628405
trainer/Policy mu Std               0.69131
trainer/Policy mu Max               2.85514
trainer/Policy mu Min              -2.27503
trainer/Policy log std Mean        -2.02388
trainer/Policy log std Std          0.596169
trainer/Policy log std Max         -0.136957
trainer/Policy log std Min         -2.80502
trainer/Alpha                       0.0948623
trainer/Alpha Loss                  0.418512
exploration/num steps total     64000
exploration/num paths total       640
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.643655
exploration/Rewards Std             1.31895
exploration/Rewards Max            -0.0158827
exploration/Rewards Min           -10.3124
exploration/Returns Mean          -64.3655
exploration/Returns Std            35.5197
exploration/Returns Max           -28.8458
exploration/Returns Min           -99.8851
exploration/Actions Mean           -0.0189702
exploration/Actions Std             0.252849
exploration/Actions Max             0.995383
exploration/Actions Min            -0.999244
exploration/Num Paths               2
exploration/Average Returns       -64.3655
evaluation/num steps total     319000
evaluation/num paths total       3190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.525819
evaluation/Rewards Std              1.01599
evaluation/Rewards Max             -0.108376
evaluation/Rewards Min             -9.05339
evaluation/Returns Mean           -52.5819
evaluation/Returns Std             17.9586
evaluation/Returns Max            -25.0985
evaluation/Returns Min            -92.3895
evaluation/Actions Mean             0.00996557
evaluation/Actions Std              0.185373
evaluation/Actions Max              0.99236
evaluation/Actions Min             -0.994098
evaluation/Num Paths               10
evaluation/Average Returns        -52.5819
time/data storing (s)               0.00138108
time/evaluation sampling (s)        0.219494
time/exploration sampling (s)       0.0666729
time/logging (s)                    0.00313103
time/saving (s)                     0.00198035
time/training (s)                   0.748555
time/epoch (s)                      1.04121
time/total (s)                    340.316
Epoch                             318
-----------------------------  ---------------
2019-04-21 01:17:25.301981 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 319 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    0.272364
trainer/QF2 Loss                    0.302382
trainer/Policy Loss                29.4542
trainer/Q1 Predictions Mean       -28.0111
trainer/Q1 Predictions Std          9.37755
trainer/Q1 Predictions Max        -15.6138
trainer/Q1 Predictions Min        -62.5594
trainer/Q2 Predictions Mean       -28.0029
trainer/Q2 Predictions Std          9.38983
trainer/Q2 Predictions Max        -15.5594
trainer/Q2 Predictions Min        -62.582
trainer/Q Targets Mean            -28.3638
trainer/Q Targets Std               9.54702
trainer/Q Targets Max             -15.7163
trainer/Q Targets Min             -63.0216
trainer/Log Pis Mean                1.92829
trainer/Log Pis Std                 1.38042
trainer/Log Pis Max                 5.28655
trainer/Log Pis Min                -2.42696
trainer/Policy mu Mean             -0.0358969
trainer/Policy mu Std               0.781139
trainer/Policy mu Max               2.73215
trainer/Policy mu Min              -2.57359
trainer/Policy log std Mean        -1.98389
trainer/Policy log std Std          0.628722
trainer/Policy log std Max         -0.489612
trainer/Policy log std Min         -2.80277
trainer/Alpha                       0.0941938
trainer/Alpha Loss                 -0.169416
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.367176
exploration/Rewards Std             0.291094
exploration/Rewards Max            -0.0212913
exploration/Rewards Min            -2.88493
exploration/Returns Mean          -36.7176
exploration/Returns Std            19.2572
exploration/Returns Max           -17.4604
exploration/Returns Min           -55.9747
exploration/Actions Mean           -0.0139543
exploration/Actions Std             0.159303
exploration/Actions Max             0.505375
exploration/Actions Min            -0.958377
exploration/Num Paths               2
exploration/Average Returns       -36.7176
evaluation/num steps total     320000
evaluation/num paths total       3200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.535991
evaluation/Rewards Std              0.818135
evaluation/Rewards Max             -0.132191
evaluation/Rewards Min             -9.54956
evaluation/Returns Mean           -53.5991
evaluation/Returns Std             21.2892
evaluation/Returns Max            -17.2627
evaluation/Returns Min            -89.6445
evaluation/Actions Mean            -0.00647164
evaluation/Actions Std              0.179612
evaluation/Actions Max              0.994341
evaluation/Actions Min             -0.995222
evaluation/Num Paths               10
evaluation/Average Returns        -53.5991
time/data storing (s)               0.00139806
time/evaluation sampling (s)        0.217861
time/exploration sampling (s)       0.0639011
time/logging (s)                    0.00335169
time/saving (s)                     0.00197789
time/training (s)                   0.756728
time/epoch (s)                      1.04522
time/total (s)                    341.366
Epoch                             319
-----------------------------  ---------------
2019-04-21 01:17:26.364821 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 320 finished
-----------------------------  ----------------
replay_buffer/size              64400
trainer/QF1 Loss                    0.0899961
trainer/QF2 Loss                    0.100538
trainer/Policy Loss                27.6256
trainer/Q1 Predictions Mean       -25.9953
trainer/Q1 Predictions Std          9.80839
trainer/Q1 Predictions Max        -15.5344
trainer/Q1 Predictions Min        -55.9436
trainer/Q2 Predictions Mean       -25.9908
trainer/Q2 Predictions Std          9.81447
trainer/Q2 Predictions Max        -15.497
trainer/Q2 Predictions Min        -56.6313
trainer/Q Targets Mean            -26.1428
trainer/Q Targets Std               9.88232
trainer/Q Targets Max             -15.5661
trainer/Q Targets Min             -56.9067
trainer/Log Pis Mean                2.13224
trainer/Log Pis Std                 1.0358
trainer/Log Pis Max                 5.88394
trainer/Log Pis Min                -1.90324
trainer/Policy mu Mean             -0.00141951
trainer/Policy mu Std               0.678331
trainer/Policy mu Max               2.59244
trainer/Policy mu Min              -2.56993
trainer/Policy log std Mean        -2.04306
trainer/Policy log std Std          0.552778
trainer/Policy log std Max         -0.393137
trainer/Policy log std Min         -2.78379
trainer/Alpha                       0.0930986
trainer/Alpha Loss                  0.313957
exploration/num steps total     64400
exploration/num paths total       644
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.420222
exploration/Rewards Std             0.460225
exploration/Rewards Max            -0.0672865
exploration/Rewards Min            -4.79572
exploration/Returns Mean          -42.0222
exploration/Returns Std             8.51363
exploration/Returns Max           -33.5086
exploration/Returns Min           -50.5358
exploration/Actions Mean            0.0037787
exploration/Actions Std             0.178064
exploration/Actions Max             0.974709
exploration/Actions Min            -0.853646
exploration/Num Paths               2
exploration/Average Returns       -42.0222
evaluation/num steps total     321000
evaluation/num paths total       3210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.544355
evaluation/Rewards Std              1.06955
evaluation/Rewards Max             -0.163753
evaluation/Rewards Min             -9.97173
evaluation/Returns Mean           -54.4355
evaluation/Returns Std             20.1447
evaluation/Returns Max            -16.9962
evaluation/Returns Min            -80.377
evaluation/Actions Mean            -0.000188265
evaluation/Actions Std              0.191254
evaluation/Actions Max              0.996436
evaluation/Actions Min             -0.994569
evaluation/Num Paths               10
evaluation/Average Returns        -54.4355
time/data storing (s)               0.00134319
time/evaluation sampling (s)        0.21804
time/exploration sampling (s)       0.0616775
time/logging (s)                    0.00336502
time/saving (s)                     0.00198354
time/training (s)                   0.768261
time/epoch (s)                      1.05467
time/total (s)                    342.424
Epoch                             320
-----------------------------  ----------------
2019-04-21 01:17:27.409430 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 321 finished
-----------------------------  ---------------
replay_buffer/size              64600
trainer/QF1 Loss                   10.3927
trainer/QF2 Loss                   10.431
trainer/Policy Loss                27.0048
trainer/Q1 Predictions Mean       -25.6237
trainer/Q1 Predictions Std          8.90738
trainer/Q1 Predictions Max        -15.2993
trainer/Q1 Predictions Min        -47.9545
trainer/Q2 Predictions Mean       -25.6289
trainer/Q2 Predictions Std          8.89887
trainer/Q2 Predictions Max        -15.2953
trainer/Q2 Predictions Min        -48.494
trainer/Q Targets Mean            -25.4479
trainer/Q Targets Std               9.10024
trainer/Q Targets Max              -0.676321
trainer/Q Targets Min             -47.7762
trainer/Log Pis Mean                1.80749
trainer/Log Pis Std                 1.27537
trainer/Log Pis Max                 5.15837
trainer/Log Pis Min                -3.91016
trainer/Policy mu Mean             -0.00183715
trainer/Policy mu Std               0.595392
trainer/Policy mu Max               2.01391
trainer/Policy mu Min              -2.29985
trainer/Policy log std Mean        -2.09565
trainer/Policy log std Std          0.539394
trainer/Policy log std Max         -0.539501
trainer/Policy log std Min         -2.85982
trainer/Alpha                       0.0931775
trainer/Alpha Loss                 -0.456869
exploration/num steps total     64600
exploration/num paths total       646
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.22819
exploration/Rewards Std             0.426344
exploration/Rewards Max            -0.0319802
exploration/Rewards Min            -4.08608
exploration/Returns Mean          -22.819
exploration/Returns Std             2.85853
exploration/Returns Max           -19.9605
exploration/Returns Min           -25.6775
exploration/Actions Mean            0.00963774
exploration/Actions Std             0.161237
exploration/Actions Max             0.975102
exploration/Actions Min            -0.89009
exploration/Num Paths               2
exploration/Average Returns       -22.819
evaluation/num steps total     322000
evaluation/num paths total       3220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.525318
evaluation/Rewards Std              0.987244
evaluation/Rewards Max             -0.107535
evaluation/Rewards Min            -10.275
evaluation/Returns Mean           -52.5318
evaluation/Returns Std             26.4302
evaluation/Returns Max            -13.2107
evaluation/Returns Min            -94.5336
evaluation/Actions Mean            -0.0142321
evaluation/Actions Std              0.193292
evaluation/Actions Max              0.990838
evaluation/Actions Min             -0.997162
evaluation/Num Paths               10
evaluation/Average Returns        -52.5318
time/data storing (s)               0.00128892
time/evaluation sampling (s)        0.22528
time/exploration sampling (s)       0.0654812
time/logging (s)                    0.0027026
time/saving (s)                     0.00158312
time/training (s)                   0.738697
time/epoch (s)                      1.03503
time/total (s)                    343.463
Epoch                             321
-----------------------------  ---------------
2019-04-21 01:17:28.465635 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 322 finished
-----------------------------  ---------------
replay_buffer/size              64800
trainer/QF1 Loss                    0.231511
trainer/QF2 Loss                    0.248295
trainer/Policy Loss                26.9418
trainer/Q1 Predictions Mean       -25.6589
trainer/Q1 Predictions Std          8.93291
trainer/Q1 Predictions Max        -15.1596
trainer/Q1 Predictions Min        -47.2668
trainer/Q2 Predictions Mean       -25.6504
trainer/Q2 Predictions Std          8.93395
trainer/Q2 Predictions Max        -15.1636
trainer/Q2 Predictions Min        -47.4098
trainer/Q Targets Mean            -26.0943
trainer/Q Targets Std               9.03744
trainer/Q Targets Max             -15.415
trainer/Q Targets Min             -47.8992
trainer/Log Pis Mean                1.78261
trainer/Log Pis Std                 1.38948
trainer/Log Pis Max                 5.6027
trainer/Log Pis Min                -7.16148
trainer/Policy mu Mean              0.0247612
trainer/Policy mu Std               0.731772
trainer/Policy mu Max               2.65179
trainer/Policy mu Min              -2.38978
trainer/Policy log std Mean        -1.96588
trainer/Policy log std Std          0.598196
trainer/Policy log std Max         -0.502739
trainer/Policy log std Min         -2.80773
trainer/Alpha                       0.0929255
trainer/Alpha Loss                 -0.51648
exploration/num steps total     64800
exploration/num paths total       648
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.579846
exploration/Rewards Std             1.04155
exploration/Rewards Max            -0.0146591
exploration/Rewards Min            -7.60089
exploration/Returns Mean          -57.9846
exploration/Returns Std            22.8141
exploration/Returns Max           -35.1705
exploration/Returns Min           -80.7987
exploration/Actions Mean           -0.0257198
exploration/Actions Std             0.250713
exploration/Actions Max             0.994422
exploration/Actions Min            -0.996592
exploration/Num Paths               2
exploration/Average Returns       -57.9846
evaluation/num steps total     323000
evaluation/num paths total       3230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.455998
evaluation/Rewards Std              0.984724
evaluation/Rewards Max             -0.0855172
evaluation/Rewards Min            -10.4477
evaluation/Returns Mean           -45.5998
evaluation/Returns Std             29.2358
evaluation/Returns Max            -11.2616
evaluation/Returns Min            -92.5188
evaluation/Actions Mean             0.00318822
evaluation/Actions Std              0.183694
evaluation/Actions Max              0.994592
evaluation/Actions Min             -0.99418
evaluation/Num Paths               10
evaluation/Average Returns        -45.5998
time/data storing (s)               0.00129267
time/evaluation sampling (s)        0.227903
time/exploration sampling (s)       0.0643878
time/logging (s)                    0.00335953
time/saving (s)                     0.00197058
time/training (s)                   0.749825
time/epoch (s)                      1.04874
time/total (s)                    344.516
Epoch                             322
-----------------------------  ---------------
2019-04-21 01:17:29.539659 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 323 finished
-----------------------------  ---------------
replay_buffer/size              65000
trainer/QF1 Loss                    0.0331827
trainer/QF2 Loss                    0.0367496
trainer/Policy Loss                28.2257
trainer/Q1 Predictions Mean       -26.6906
trainer/Q1 Predictions Std         10.5387
trainer/Q1 Predictions Max        -15.3805
trainer/Q1 Predictions Min        -86.1709
trainer/Q2 Predictions Mean       -26.6962
trainer/Q2 Predictions Std         10.5805
trainer/Q2 Predictions Max        -15.3698
trainer/Q2 Predictions Min        -86.7475
trainer/Q Targets Mean            -26.6734
trainer/Q Targets Std              10.4993
trainer/Q Targets Max             -15.3104
trainer/Q Targets Min             -86.613
trainer/Log Pis Mean                1.94644
trainer/Log Pis Std                 1.1237
trainer/Log Pis Max                 5.27516
trainer/Log Pis Min                -1.93885
trainer/Policy mu Mean             -0.0291309
trainer/Policy mu Std               0.690456
trainer/Policy mu Max               2.52379
trainer/Policy mu Min              -3.06034
trainer/Policy log std Mean        -2.08897
trainer/Policy log std Std          0.542271
trainer/Policy log std Max         -0.531083
trainer/Policy log std Min         -2.76605
trainer/Alpha                       0.0909162
trainer/Alpha Loss                 -0.128426
exploration/num steps total     65000
exploration/num paths total       650
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.567453
exploration/Rewards Std             1.11236
exploration/Rewards Max            -0.0199205
exploration/Rewards Min            -8.72226
exploration/Returns Mean          -56.7453
exploration/Returns Std             0.331966
exploration/Returns Max           -56.4133
exploration/Returns Min           -57.0773
exploration/Actions Mean            0.0141761
exploration/Actions Std             0.236966
exploration/Actions Max             0.998396
exploration/Actions Min            -0.98424
exploration/Num Paths               2
exploration/Average Returns       -56.7453
evaluation/num steps total     324000
evaluation/num paths total       3240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.29023
evaluation/Rewards Std              0.513931
evaluation/Rewards Max             -0.126651
evaluation/Rewards Min             -5.86248
evaluation/Returns Mean           -29.023
evaluation/Returns Std             14.1847
evaluation/Returns Max            -16.3711
evaluation/Returns Min            -59.5787
evaluation/Actions Mean             0.00513516
evaluation/Actions Std              0.150806
evaluation/Actions Max              0.990365
evaluation/Actions Min             -0.982012
evaluation/Num Paths               10
evaluation/Average Returns        -29.023
time/data storing (s)               0.00118463
time/evaluation sampling (s)        0.221635
time/exploration sampling (s)       0.0641308
time/logging (s)                    0.00336732
time/saving (s)                     0.00196518
time/training (s)                   0.77299
time/epoch (s)                      1.06527
time/total (s)                    345.585
Epoch                             323
-----------------------------  ---------------
2019-04-21 01:17:30.603057 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 324 finished
-----------------------------  ---------------
replay_buffer/size              65200
trainer/QF1 Loss                   12.772
trainer/QF2 Loss                   12.7865
trainer/Policy Loss                26.3011
trainer/Q1 Predictions Mean       -24.6563
trainer/Q1 Predictions Std          9.36756
trainer/Q1 Predictions Max        -15.0656
trainer/Q1 Predictions Min        -48.4931
trainer/Q2 Predictions Mean       -24.6368
trainer/Q2 Predictions Std          9.37118
trainer/Q2 Predictions Max        -15.0301
trainer/Q2 Predictions Min        -48.4365
trainer/Q Targets Mean            -24.3404
trainer/Q Targets Std               9.76459
trainer/Q Targets Max              -0.677703
trainer/Q Targets Min             -47.4612
trainer/Log Pis Mean                2.12816
trainer/Log Pis Std                 0.929792
trainer/Log Pis Max                 3.89144
trainer/Log Pis Min                -1.58874
trainer/Policy mu Mean              0.0342262
trainer/Policy mu Std               0.761843
trainer/Policy mu Max               2.826
trainer/Policy mu Min              -2.28612
trainer/Policy log std Mean        -2.00867
trainer/Policy log std Std          0.604221
trainer/Policy log std Max         -0.374449
trainer/Policy log std Min         -2.85474
trainer/Alpha                       0.091527
trainer/Alpha Loss                  0.306455
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.380631
exploration/Rewards Std             0.242812
exploration/Rewards Max            -0.0145083
exploration/Rewards Min            -1.77582
exploration/Returns Mean          -38.0631
exploration/Returns Std            19.5407
exploration/Returns Max           -18.5224
exploration/Returns Min           -57.6039
exploration/Actions Mean           -0.0065676
exploration/Actions Std             0.148272
exploration/Actions Max             0.543521
exploration/Actions Min            -0.926105
exploration/Num Paths               2
exploration/Average Returns       -38.0631
evaluation/num steps total     325000
evaluation/num paths total       3250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.393256
evaluation/Rewards Std              0.869805
evaluation/Rewards Max             -0.121441
evaluation/Rewards Min            -10.9601
evaluation/Returns Mean           -39.3256
evaluation/Returns Std             25.0999
evaluation/Returns Max            -12.6301
evaluation/Returns Min            -79.9994
evaluation/Actions Mean             0.00951111
evaluation/Actions Std              0.168286
evaluation/Actions Max              0.997904
evaluation/Actions Min             -0.987449
evaluation/Num Paths               10
evaluation/Average Returns        -39.3256
time/data storing (s)               0.00124458
time/evaluation sampling (s)        0.224331
time/exploration sampling (s)       0.0642782
time/logging (s)                    0.00338135
time/saving (s)                     0.00198195
time/training (s)                   0.759007
time/epoch (s)                      1.05422
time/total (s)                    346.644
Epoch                             324
-----------------------------  ---------------
2019-04-21 01:17:31.673386 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 325 finished
-----------------------------  ---------------
replay_buffer/size              65400
trainer/QF1 Loss                   10.4242
trainer/QF2 Loss                   10.3521
trainer/Policy Loss                26.0963
trainer/Q1 Predictions Mean       -24.5326
trainer/Q1 Predictions Std          8.92675
trainer/Q1 Predictions Max        -15.0879
trainer/Q1 Predictions Min        -50.299
trainer/Q2 Predictions Mean       -24.544
trainer/Q2 Predictions Std          8.98749
trainer/Q2 Predictions Max        -15.0253
trainer/Q2 Predictions Min        -51.6238
trainer/Q Targets Mean            -24.5081
trainer/Q Targets Std               9.26137
trainer/Q Targets Max              -0.499607
trainer/Q Targets Min             -52.8404
trainer/Log Pis Mean                2.08192
trainer/Log Pis Std                 1.04506
trainer/Log Pis Max                 6.50916
trainer/Log Pis Min                -0.750696
trainer/Policy mu Mean              0.0764505
trainer/Policy mu Std               0.637979
trainer/Policy mu Max               2.17268
trainer/Policy mu Min              -2.30255
trainer/Policy log std Mean        -2.07488
trainer/Policy log std Std          0.546942
trainer/Policy log std Max         -0.589411
trainer/Policy log std Min         -2.87008
trainer/Alpha                       0.091281
trainer/Alpha Loss                  0.196112
exploration/num steps total     65400
exploration/num paths total       654
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.487372
exploration/Rewards Std             0.763697
exploration/Rewards Max            -0.0250148
exploration/Rewards Min            -6.71589
exploration/Returns Mean          -48.7372
exploration/Returns Std            24.3281
exploration/Returns Max           -24.4091
exploration/Returns Min           -73.0652
exploration/Actions Mean           -0.00905487
exploration/Actions Std             0.212748
exploration/Actions Max             0.993951
exploration/Actions Min            -0.971123
exploration/Num Paths               2
exploration/Average Returns       -48.7372
evaluation/num steps total     326000
evaluation/num paths total       3260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.490901
evaluation/Rewards Std              0.728365
evaluation/Rewards Max             -0.111454
evaluation/Rewards Min             -7.45613
evaluation/Returns Mean           -49.0901
evaluation/Returns Std             15.4065
evaluation/Returns Max            -18.1585
evaluation/Returns Min            -66.1698
evaluation/Actions Mean             0.0123178
evaluation/Actions Std              0.183693
evaluation/Actions Max              0.993238
evaluation/Actions Min             -0.976639
evaluation/Num Paths               10
evaluation/Average Returns        -49.0901
time/data storing (s)               0.00124478
time/evaluation sampling (s)        0.22104
time/exploration sampling (s)       0.0654722
time/logging (s)                    0.00338155
time/saving (s)                     0.00196797
time/training (s)                   0.768128
time/epoch (s)                      1.06123
time/total (s)                    347.709
Epoch                             325
-----------------------------  ---------------
2019-04-21 01:17:32.752189 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 326 finished
-----------------------------  ---------------
replay_buffer/size              65600
trainer/QF1 Loss                    0.146116
trainer/QF2 Loss                    0.225202
trainer/Policy Loss                28.7547
trainer/Q1 Predictions Mean       -27.3372
trainer/Q1 Predictions Std         11.1155
trainer/Q1 Predictions Max        -15.1599
trainer/Q1 Predictions Min        -74.1855
trainer/Q2 Predictions Mean       -27.2979
trainer/Q2 Predictions Std         11.0472
trainer/Q2 Predictions Max        -15.0895
trainer/Q2 Predictions Min        -73.6583
trainer/Q Targets Mean            -27.3774
trainer/Q Targets Std              11.1829
trainer/Q Targets Max             -15.1626
trainer/Q Targets Min             -76.603
trainer/Log Pis Mean                1.8845
trainer/Log Pis Std                 1.2435
trainer/Log Pis Max                 4.73802
trainer/Log Pis Min                -1.32005
trainer/Policy mu Mean              0.0307628
trainer/Policy mu Std               0.769
trainer/Policy mu Max               2.92422
trainer/Policy mu Min              -2.53771
trainer/Policy log std Mean        -1.96132
trainer/Policy log std Std          0.591838
trainer/Policy log std Max         -0.199815
trainer/Policy log std Min         -2.77372
trainer/Alpha                       0.0904897
trainer/Alpha Loss                 -0.277489
exploration/num steps total     65600
exploration/num paths total       656
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.429458
exploration/Rewards Std             0.58528
exploration/Rewards Max            -0.0198188
exploration/Rewards Min            -5.61531
exploration/Returns Mean          -42.9458
exploration/Returns Std            10.7
exploration/Returns Max           -32.2458
exploration/Returns Min           -53.6458
exploration/Actions Mean            0.0118517
exploration/Actions Std             0.191286
exploration/Actions Max             0.991278
exploration/Actions Min            -0.736485
exploration/Num Paths               2
exploration/Average Returns       -42.9458
evaluation/num steps total     327000
evaluation/num paths total       3270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.637339
evaluation/Rewards Std              0.981848
evaluation/Rewards Max             -0.102646
evaluation/Rewards Min            -10.6202
evaluation/Returns Mean           -63.7339
evaluation/Returns Std             21.9062
evaluation/Returns Max            -21.5844
evaluation/Returns Min           -104.845
evaluation/Actions Mean            -0.0199869
evaluation/Actions Std              0.190828
evaluation/Actions Max              0.990739
evaluation/Actions Min             -0.997253
evaluation/Num Paths               10
evaluation/Average Returns        -63.7339
time/data storing (s)               0.00149611
time/evaluation sampling (s)        0.222139
time/exploration sampling (s)       0.0621964
time/logging (s)                    0.00337144
time/saving (s)                     0.00160592
time/training (s)                   0.779715
time/epoch (s)                      1.07052
time/total (s)                    348.784
Epoch                             326
-----------------------------  ---------------
2019-04-21 01:17:33.820436 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 327 finished
-----------------------------  ---------------
replay_buffer/size              65800
trainer/QF1 Loss                   30.6374
trainer/QF2 Loss                   30.5163
trainer/Policy Loss                27.5726
trainer/Q1 Predictions Mean       -26.2777
trainer/Q1 Predictions Std         10.8298
trainer/Q1 Predictions Max        -15.1214
trainer/Q1 Predictions Min        -97.217
trainer/Q2 Predictions Mean       -26.2927
trainer/Q2 Predictions Std         10.7891
trainer/Q2 Predictions Max        -15.1243
trainer/Q2 Predictions Min        -96.4297
trainer/Q Targets Mean            -25.6697
trainer/Q Targets Std              11.6012
trainer/Q Targets Max              -0.653857
trainer/Q Targets Min             -95.0028
trainer/Log Pis Mean                1.85034
trainer/Log Pis Std                 1.25508
trainer/Log Pis Max                 7.43987
trainer/Log Pis Min                -1.40079
trainer/Policy mu Mean             -0.0395001
trainer/Policy mu Std               0.724436
trainer/Policy mu Max               2.1194
trainer/Policy mu Min              -3.30665
trainer/Policy log std Mean        -2.02619
trainer/Policy log std Std          0.586815
trainer/Policy log std Max         -0.558209
trainer/Policy log std Min         -2.90229
trainer/Alpha                       0.0914319
trainer/Alpha Loss                 -0.358002
exploration/num steps total     65800
exploration/num paths total       658
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.60017
exploration/Rewards Std             0.407963
exploration/Rewards Max            -0.260583
exploration/Rewards Min            -4.16707
exploration/Returns Mean          -60.017
exploration/Returns Std             0.742074
exploration/Returns Max           -59.2749
exploration/Returns Min           -60.7591
exploration/Actions Mean           -0.0287973
exploration/Actions Std             0.210971
exploration/Actions Max             0.553831
exploration/Actions Min            -0.989932
exploration/Num Paths               2
exploration/Average Returns       -60.017
evaluation/num steps total     328000
evaluation/num paths total       3280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.55456
evaluation/Rewards Std              1.11725
evaluation/Rewards Max             -0.130316
evaluation/Rewards Min            -10.2648
evaluation/Returns Mean           -55.456
evaluation/Returns Std             30.6125
evaluation/Returns Max            -16.4213
evaluation/Returns Min           -103.563
evaluation/Actions Mean            -0.00673431
evaluation/Actions Std              0.198317
evaluation/Actions Max              0.990382
evaluation/Actions Min             -0.997126
evaluation/Num Paths               10
evaluation/Average Returns        -55.456
time/data storing (s)               0.00122629
time/evaluation sampling (s)        0.217664
time/exploration sampling (s)       0.0632488
time/logging (s)                    0.00327421
time/saving (s)                     0.00195791
time/training (s)                   0.771885
time/epoch (s)                      1.05926
time/total (s)                    349.847
Epoch                             327
-----------------------------  ---------------
2019-04-21 01:17:34.884505 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 328 finished
-----------------------------  ---------------
replay_buffer/size              66000
trainer/QF1 Loss                   10.3412
trainer/QF2 Loss                   10.3308
trainer/Policy Loss                26.523
trainer/Q1 Predictions Mean       -24.9962
trainer/Q1 Predictions Std         10.1795
trainer/Q1 Predictions Max        -14.8609
trainer/Q1 Predictions Min        -60.9696
trainer/Q2 Predictions Mean       -25.0033
trainer/Q2 Predictions Std         10.1398
trainer/Q2 Predictions Max        -14.8634
trainer/Q2 Predictions Min        -60.866
trainer/Q Targets Mean            -24.911
trainer/Q Targets Std              10.373
trainer/Q Targets Max              -1.18362
trainer/Q Targets Min             -60.2018
trainer/Log Pis Mean                1.85549
trainer/Log Pis Std                 1.23563
trainer/Log Pis Max                 4.55083
trainer/Log Pis Min                -4.20104
trainer/Policy mu Mean              0.00186503
trainer/Policy mu Std               0.609659
trainer/Policy mu Max               2.87748
trainer/Policy mu Min              -2.69945
trainer/Policy log std Mean        -2.12301
trainer/Policy log std Std          0.51018
trainer/Policy log std Max         -0.670093
trainer/Policy log std Min         -2.80389
trainer/Alpha                       0.0911817
trainer/Alpha Loss                 -0.346077
exploration/num steps total     66000
exploration/num paths total       660
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.585557
exploration/Rewards Std             1.0787
exploration/Rewards Max            -0.0249207
exploration/Rewards Min            -8.10308
exploration/Returns Mean          -58.5557
exploration/Returns Std            27.2152
exploration/Returns Max           -31.3405
exploration/Returns Min           -85.7709
exploration/Actions Mean           -0.021921
exploration/Actions Std             0.229505
exploration/Actions Max             0.98254
exploration/Actions Min            -0.998629
exploration/Num Paths               2
exploration/Average Returns       -58.5557
evaluation/num steps total     329000
evaluation/num paths total       3290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.583762
evaluation/Rewards Std              1.3085
evaluation/Rewards Max             -0.142619
evaluation/Rewards Min            -11.1182
evaluation/Returns Mean           -58.3762
evaluation/Returns Std             30.0148
evaluation/Returns Max            -15.9773
evaluation/Returns Min           -105.566
evaluation/Actions Mean            -0.00332843
evaluation/Actions Std              0.212167
evaluation/Actions Max              0.997293
evaluation/Actions Min             -0.998444
evaluation/Num Paths               10
evaluation/Average Returns        -58.3762
time/data storing (s)               0.00123683
time/evaluation sampling (s)        0.226924
time/exploration sampling (s)       0.0660149
time/logging (s)                    0.00337904
time/saving (s)                     0.00196502
time/training (s)                   0.756083
time/epoch (s)                      1.0556
time/total (s)                    350.907
Epoch                             328
-----------------------------  ---------------
2019-04-21 01:17:35.964761 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 329 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    0.0954282
trainer/QF2 Loss                    0.0914258
trainer/Policy Loss                26.4976
trainer/Q1 Predictions Mean       -25.0089
trainer/Q1 Predictions Std          9.52884
trainer/Q1 Predictions Max        -14.9909
trainer/Q1 Predictions Min        -52.0345
trainer/Q2 Predictions Mean       -24.9837
trainer/Q2 Predictions Std          9.50388
trainer/Q2 Predictions Max        -14.9392
trainer/Q2 Predictions Min        -51.8523
trainer/Q Targets Mean            -25.0961
trainer/Q Targets Std               9.6236
trainer/Q Targets Max             -14.8599
trainer/Q Targets Min             -51.744
trainer/Log Pis Mean                1.92082
trainer/Log Pis Std                 1.12877
trainer/Log Pis Max                 4.10915
trainer/Log Pis Min                -2.0881
trainer/Policy mu Mean              0.0695
trainer/Policy mu Std               0.647208
trainer/Policy mu Max               2.74452
trainer/Policy mu Min              -2.47819
trainer/Policy log std Mean        -2.04598
trainer/Policy log std Std          0.557916
trainer/Policy log std Max         -0.557973
trainer/Policy log std Min         -2.78898
trainer/Alpha                       0.0918284
trainer/Alpha Loss                 -0.189058
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.535268
exploration/Rewards Std             1.03899
exploration/Rewards Max            -0.0223924
exploration/Rewards Min            -9.07203
exploration/Returns Mean          -53.5268
exploration/Returns Std             0.434095
exploration/Returns Max           -53.0927
exploration/Returns Min           -53.9609
exploration/Actions Mean            0.00192052
exploration/Actions Std             0.22324
exploration/Actions Max             0.997595
exploration/Actions Min            -0.991869
exploration/Num Paths               2
exploration/Average Returns       -53.5268
evaluation/num steps total     330000
evaluation/num paths total       3300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.553321
evaluation/Rewards Std              0.875166
evaluation/Rewards Max             -0.110731
evaluation/Rewards Min             -9.42985
evaluation/Returns Mean           -55.3321
evaluation/Returns Std             22.6422
evaluation/Returns Max            -13.1563
evaluation/Returns Min            -88.6476
evaluation/Actions Mean            -0.0127432
evaluation/Actions Std              0.187353
evaluation/Actions Max              0.992936
evaluation/Actions Min             -0.996337
evaluation/Num Paths               10
evaluation/Average Returns        -55.3321
time/data storing (s)               0.00122062
time/evaluation sampling (s)        0.223171
time/exploration sampling (s)       0.0633372
time/logging (s)                    0.00336365
time/saving (s)                     0.00192697
time/training (s)                   0.777971
time/epoch (s)                      1.07099
time/total (s)                    351.982
Epoch                             329
-----------------------------  ---------------
2019-04-21 01:17:37.024344 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 330 finished
-----------------------------  ---------------
replay_buffer/size              66400
trainer/QF1 Loss                   12.4233
trainer/QF2 Loss                   12.5131
trainer/Policy Loss                25.2667
trainer/Q1 Predictions Mean       -23.8616
trainer/Q1 Predictions Std          9.71109
trainer/Q1 Predictions Max        -14.7241
trainer/Q1 Predictions Min        -70.5181
trainer/Q2 Predictions Mean       -23.8435
trainer/Q2 Predictions Std          9.64213
trainer/Q2 Predictions Max        -14.7097
trainer/Q2 Predictions Min        -69.2193
trainer/Q Targets Mean            -23.5386
trainer/Q Targets Std              10.3349
trainer/Q Targets Max              -0.226267
trainer/Q Targets Min             -73.7283
trainer/Log Pis Mean                1.76787
trainer/Log Pis Std                 1.47768
trainer/Log Pis Max                 4.88243
trainer/Log Pis Min                -5.7569
trainer/Policy mu Mean              0.0952415
trainer/Policy mu Std               0.598947
trainer/Policy mu Max               2.99317
trainer/Policy mu Min              -2.06274
trainer/Policy log std Mean        -2.10486
trainer/Policy log std Std          0.528804
trainer/Policy log std Max         -0.554603
trainer/Policy log std Min         -2.85318
trainer/Alpha                       0.0939965
trainer/Alpha Loss                 -0.548875
exploration/num steps total     66400
exploration/num paths total       664
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.483196
exploration/Rewards Std             1.29544
exploration/Rewards Max            -0.0313049
exploration/Rewards Min            -9.84847
exploration/Returns Mean          -48.3196
exploration/Returns Std            17.4043
exploration/Returns Max           -30.9154
exploration/Returns Min           -65.7239
exploration/Actions Mean            0.0269598
exploration/Actions Std             0.232861
exploration/Actions Max             0.998356
exploration/Actions Min            -0.944013
exploration/Num Paths               2
exploration/Average Returns       -48.3196
evaluation/num steps total     331000
evaluation/num paths total       3310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.571956
evaluation/Rewards Std              0.903772
evaluation/Rewards Max             -0.153153
evaluation/Rewards Min             -8.7716
evaluation/Returns Mean           -57.1956
evaluation/Returns Std             27.0985
evaluation/Returns Max            -17.3955
evaluation/Returns Min            -86.7402
evaluation/Actions Mean            -0.0141431
evaluation/Actions Std              0.176054
evaluation/Actions Max              0.989432
evaluation/Actions Min             -0.99566
evaluation/Num Paths               10
evaluation/Average Returns        -57.1956
time/data storing (s)               0.00130334
time/evaluation sampling (s)        0.225721
time/exploration sampling (s)       0.0660768
time/logging (s)                    0.00334481
time/saving (s)                     0.00195713
time/training (s)                   0.752894
time/epoch (s)                      1.0513
time/total (s)                    353.037
Epoch                             330
-----------------------------  ---------------
2019-04-21 01:17:38.090691 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 331 finished
-----------------------------  ---------------
replay_buffer/size              66600
trainer/QF1 Loss                    0.0370943
trainer/QF2 Loss                    0.0591881
trainer/Policy Loss                25.0419
trainer/Q1 Predictions Mean       -23.4104
trainer/Q1 Predictions Std          9.23229
trainer/Q1 Predictions Max        -14.8073
trainer/Q1 Predictions Min        -43.979
trainer/Q2 Predictions Mean       -23.4231
trainer/Q2 Predictions Std          9.25859
trainer/Q2 Predictions Max        -14.7552
trainer/Q2 Predictions Min        -43.9941
trainer/Q Targets Mean            -23.452
trainer/Q Targets Std               9.2133
trainer/Q Targets Max             -14.8403
trainer/Q Targets Min             -43.611
trainer/Log Pis Mean                1.98132
trainer/Log Pis Std                 1.19679
trainer/Log Pis Max                 5.56791
trainer/Log Pis Min                -1.67735
trainer/Policy mu Mean              0.0240583
trainer/Policy mu Std               0.622529
trainer/Policy mu Max               2.60246
trainer/Policy mu Min              -2.54223
trainer/Policy log std Mean        -2.14582
trainer/Policy log std Std          0.579885
trainer/Policy log std Max         -0.610755
trainer/Policy log std Min         -2.87019
trainer/Alpha                       0.0927599
trainer/Alpha Loss                 -0.0444212
exploration/num steps total     66600
exploration/num paths total       666
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.711895
exploration/Rewards Std             1.474
exploration/Rewards Max            -0.0152767
exploration/Rewards Min           -11.3469
exploration/Returns Mean          -71.1895
exploration/Returns Std            43.1608
exploration/Returns Max           -28.0288
exploration/Returns Min          -114.35
exploration/Actions Mean           -0.030259
exploration/Actions Std             0.259054
exploration/Actions Max             0.953521
exploration/Actions Min            -0.997306
exploration/Num Paths               2
exploration/Average Returns       -71.1895
evaluation/num steps total     332000
evaluation/num paths total       3320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.492309
evaluation/Rewards Std              0.851672
evaluation/Rewards Max             -0.0751081
evaluation/Rewards Min             -9.72581
evaluation/Returns Mean           -49.2309
evaluation/Returns Std             26.97
evaluation/Returns Max            -14.724
evaluation/Returns Min            -98.6603
evaluation/Actions Mean             0.00167741
evaluation/Actions Std              0.168389
evaluation/Actions Max              0.992534
evaluation/Actions Min             -0.994063
evaluation/Num Paths               10
evaluation/Average Returns        -49.2309
time/data storing (s)               0.00139445
time/evaluation sampling (s)        0.21929
time/exploration sampling (s)       0.0633502
time/logging (s)                    0.00337076
time/saving (s)                     0.00196221
time/training (s)                   0.767793
time/epoch (s)                      1.05716
time/total (s)                    354.099
Epoch                             331
-----------------------------  ---------------
2019-04-21 01:17:39.141737 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 332 finished
-----------------------------  ---------------
replay_buffer/size              66800
trainer/QF1 Loss                   26.307
trainer/QF2 Loss                   26.1182
trainer/Policy Loss                26.7042
trainer/Q1 Predictions Mean       -25.3124
trainer/Q1 Predictions Std          9.64585
trainer/Q1 Predictions Max        -14.6426
trainer/Q1 Predictions Min        -49.872
trainer/Q2 Predictions Mean       -25.3411
trainer/Q2 Predictions Std          9.62775
trainer/Q2 Predictions Max        -14.6502
trainer/Q2 Predictions Min        -49.9558
trainer/Q Targets Mean            -24.7631
trainer/Q Targets Std               9.80086
trainer/Q Targets Max              -0.499607
trainer/Q Targets Min             -49.813
trainer/Log Pis Mean                1.94518
trainer/Log Pis Std                 1.29461
trainer/Log Pis Max                 6.78378
trainer/Log Pis Min                -2.19136
trainer/Policy mu Mean              0.0602799
trainer/Policy mu Std               0.698225
trainer/Policy mu Max               2.7762
trainer/Policy mu Min              -2.28988
trainer/Policy log std Mean        -2.10317
trainer/Policy log std Std          0.582435
trainer/Policy log std Max         -0.527257
trainer/Policy log std Min         -2.89018
trainer/Alpha                       0.0926264
trainer/Alpha Loss                 -0.13042
exploration/num steps total     66800
exploration/num paths total       668
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.290902
exploration/Rewards Std             0.800251
exploration/Rewards Max            -0.00832473
exploration/Rewards Min            -6.98822
exploration/Returns Mean          -29.0902
exploration/Returns Std            12.0034
exploration/Returns Max           -17.0869
exploration/Returns Min           -41.0936
exploration/Actions Mean            0.0380146
exploration/Actions Std             0.19996
exploration/Actions Max             0.999189
exploration/Actions Min            -0.482986
exploration/Num Paths               2
exploration/Average Returns       -29.0902
evaluation/num steps total     333000
evaluation/num paths total       3330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.444942
evaluation/Rewards Std              0.667197
evaluation/Rewards Max             -0.0929265
evaluation/Rewards Min             -6.886
evaluation/Returns Mean           -44.4942
evaluation/Returns Std             24.755
evaluation/Returns Max            -10.5658
evaluation/Returns Min            -72.7725
evaluation/Actions Mean            -0.0295746
evaluation/Actions Std              0.16604
evaluation/Actions Max              0.932842
evaluation/Actions Min             -0.994557
evaluation/Num Paths               10
evaluation/Average Returns        -44.4942
time/data storing (s)               0.00125987
time/evaluation sampling (s)        0.225203
time/exploration sampling (s)       0.0655089
time/logging (s)                    0.00271918
time/saving (s)                     0.00155955
time/training (s)                   0.744732
time/epoch (s)                      1.04098
time/total (s)                    355.144
Epoch                             332
-----------------------------  ---------------
2019-04-21 01:17:40.190489 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 333 finished
-----------------------------  ---------------
replay_buffer/size              67000
trainer/QF1 Loss                    0.172386
trainer/QF2 Loss                    0.199543
trainer/Policy Loss                27.8777
trainer/Q1 Predictions Mean       -26.2761
trainer/Q1 Predictions Std         12.2325
trainer/Q1 Predictions Max        -14.5036
trainer/Q1 Predictions Min        -82.2884
trainer/Q2 Predictions Mean       -26.296
trainer/Q2 Predictions Std         12.2411
trainer/Q2 Predictions Max        -14.5199
trainer/Q2 Predictions Min        -82.6685
trainer/Q Targets Mean            -26.4445
trainer/Q Targets Std              12.4315
trainer/Q Targets Max             -14.5656
trainer/Q Targets Min             -83.0398
trainer/Log Pis Mean                2.14661
trainer/Log Pis Std                 1.32498
trainer/Log Pis Max                 7.34075
trainer/Log Pis Min                -1.40209
trainer/Policy mu Mean              0.125019
trainer/Policy mu Std               0.775256
trainer/Policy mu Max               2.96897
trainer/Policy mu Min              -2.97499
trainer/Policy log std Mean        -2.0037
trainer/Policy log std Std          0.607846
trainer/Policy log std Max         -0.211588
trainer/Policy log std Min         -2.90885
trainer/Alpha                       0.0933055
trainer/Alpha Loss                  0.347749
exploration/num steps total     67000
exploration/num paths total       670
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.621287
exploration/Rewards Std             1.01646
exploration/Rewards Max            -0.0201071
exploration/Rewards Min            -7.09049
exploration/Returns Mean          -62.1287
exploration/Returns Std            15.7975
exploration/Returns Max           -46.3312
exploration/Returns Min           -77.9262
exploration/Actions Mean            0.0132181
exploration/Actions Std             0.235173
exploration/Actions Max             0.998698
exploration/Actions Min            -0.998461
exploration/Num Paths               2
exploration/Average Returns       -62.1287
evaluation/num steps total     334000
evaluation/num paths total       3340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.411728
evaluation/Rewards Std              1.03366
evaluation/Rewards Max             -0.110669
evaluation/Rewards Min            -10.23
evaluation/Returns Mean           -41.1728
evaluation/Returns Std             26.3561
evaluation/Returns Max            -13.1948
evaluation/Returns Min            -91.8548
evaluation/Actions Mean             0.00486643
evaluation/Actions Std              0.180225
evaluation/Actions Max              0.993809
evaluation/Actions Min             -0.99167
evaluation/Num Paths               10
evaluation/Average Returns        -41.1728
time/data storing (s)               0.00123856
time/evaluation sampling (s)        0.223439
time/exploration sampling (s)       0.0636602
time/logging (s)                    0.00335629
time/saving (s)                     0.00199945
time/training (s)                   0.746661
time/epoch (s)                      1.04035
time/total (s)                    356.189
Epoch                             333
-----------------------------  ---------------
2019-04-21 01:17:41.265339 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 334 finished
-----------------------------  ---------------
replay_buffer/size              67200
trainer/QF1 Loss                    2.42334
trainer/QF2 Loss                    2.44869
trainer/Policy Loss                26.1383
trainer/Q1 Predictions Mean       -24.4049
trainer/Q1 Predictions Std         11.8375
trainer/Q1 Predictions Max        -14.4118
trainer/Q1 Predictions Min        -79.3769
trainer/Q2 Predictions Mean       -24.422
trainer/Q2 Predictions Std         11.8243
trainer/Q2 Predictions Max        -14.4576
trainer/Q2 Predictions Min        -79.6053
trainer/Q Targets Mean            -24.4271
trainer/Q Targets Std              12.0519
trainer/Q Targets Max              -1.08561
trainer/Q Targets Min             -79.079
trainer/Log Pis Mean                2.21394
trainer/Log Pis Std                 1.24364
trainer/Log Pis Max                 7.32746
trainer/Log Pis Min                -1.6033
trainer/Policy mu Mean              0.111156
trainer/Policy mu Std               0.739821
trainer/Policy mu Max               2.85694
trainer/Policy mu Min              -2.98248
trainer/Policy log std Mean        -2.07281
trainer/Policy log std Std          0.603868
trainer/Policy log std Max         -0.390382
trainer/Policy log std Min         -2.85085
trainer/Alpha                       0.0940179
trainer/Alpha Loss                  0.505776
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.856853
exploration/Rewards Std             1.3997
exploration/Rewards Max            -0.310063
exploration/Rewards Min           -10.2234
exploration/Returns Mean          -85.6853
exploration/Returns Std            15.5023
exploration/Returns Max           -70.183
exploration/Returns Min          -101.188
exploration/Actions Mean           -0.0441248
exploration/Actions Std             0.261248
exploration/Actions Max             0.840273
exploration/Actions Min            -0.998468
exploration/Num Paths               2
exploration/Average Returns       -85.6853
evaluation/num steps total     335000
evaluation/num paths total       3350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.354914
evaluation/Rewards Std              0.637734
evaluation/Rewards Max             -0.0754598
evaluation/Rewards Min             -7.51558
evaluation/Returns Mean           -35.4914
evaluation/Returns Std             21.3383
evaluation/Returns Max            -10.9062
evaluation/Returns Min            -65.4421
evaluation/Actions Mean             0.012981
evaluation/Actions Std              0.169137
evaluation/Actions Max              0.989027
evaluation/Actions Min             -0.977256
evaluation/Num Paths               10
evaluation/Average Returns        -35.4914
time/data storing (s)               0.00141647
time/evaluation sampling (s)        0.218882
time/exploration sampling (s)       0.0624937
time/logging (s)                    0.0033874
time/saving (s)                     0.00200467
time/training (s)                   0.776736
time/epoch (s)                      1.06492
time/total (s)                    357.259
Epoch                             334
-----------------------------  ---------------
2019-04-21 01:17:42.343010 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 335 finished
-----------------------------  ---------------
replay_buffer/size              67400
trainer/QF1 Loss                    0.236121
trainer/QF2 Loss                    0.226624
trainer/Policy Loss                25.2867
trainer/Q1 Predictions Mean       -23.7872
trainer/Q1 Predictions Std          9.33569
trainer/Q1 Predictions Max        -13.919
trainer/Q1 Predictions Min        -53.3212
trainer/Q2 Predictions Mean       -23.8048
trainer/Q2 Predictions Std          9.31264
trainer/Q2 Predictions Max        -13.9705
trainer/Q2 Predictions Min        -53.0019
trainer/Q Targets Mean            -24.2438
trainer/Q Targets Std               9.29987
trainer/Q Targets Max             -14.3931
trainer/Q Targets Min             -53.6199
trainer/Log Pis Mean                1.85165
trainer/Log Pis Std                 1.28779
trainer/Log Pis Max                 4.19693
trainer/Log Pis Min                -3.76876
trainer/Policy mu Mean              0.0329867
trainer/Policy mu Std               0.641009
trainer/Policy mu Max               2.17503
trainer/Policy mu Min              -2.54255
trainer/Policy log std Mean        -2.09295
trainer/Policy log std Std          0.586584
trainer/Policy log std Max         -0.547428
trainer/Policy log std Min         -2.8304
trainer/Alpha                       0.0942252
trainer/Alpha Loss                 -0.350421
exploration/num steps total     67400
exploration/num paths total       674
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.802727
exploration/Rewards Std             1.30624
exploration/Rewards Max            -0.27192
exploration/Rewards Min            -9.917
exploration/Returns Mean          -80.2727
exploration/Returns Std            20.7497
exploration/Returns Max           -59.523
exploration/Returns Min          -101.022
exploration/Actions Mean           -0.0165379
exploration/Actions Std             0.237332
exploration/Actions Max             0.998836
exploration/Actions Min            -0.99702
exploration/Num Paths               2
exploration/Average Returns       -80.2727
evaluation/num steps total     336000
evaluation/num paths total       3360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.553146
evaluation/Rewards Std              0.746309
evaluation/Rewards Max             -0.130201
evaluation/Rewards Min             -8.51639
evaluation/Returns Mean           -55.3146
evaluation/Returns Std             16.1135
evaluation/Returns Max            -25.8205
evaluation/Returns Min            -85.29
evaluation/Actions Mean            -0.011591
evaluation/Actions Std              0.170754
evaluation/Actions Max              0.990877
evaluation/Actions Min             -0.995089
evaluation/Num Paths               10
evaluation/Average Returns        -55.3146
time/data storing (s)               0.00139508
time/evaluation sampling (s)        0.221689
time/exploration sampling (s)       0.0635009
time/logging (s)                    0.00336075
time/saving (s)                     0.00195275
time/training (s)                   0.776454
time/epoch (s)                      1.06835
time/total (s)                    358.331
Epoch                             335
-----------------------------  ---------------
2019-04-21 01:17:43.412311 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 336 finished
-----------------------------  ----------------
replay_buffer/size              67600
trainer/QF1 Loss                    0.276904
trainer/QF2 Loss                    0.267688
trainer/Policy Loss                28.2234
trainer/Q1 Predictions Mean       -26.996
trainer/Q1 Predictions Std         12.1205
trainer/Q1 Predictions Max        -13.943
trainer/Q1 Predictions Min        -90.516
trainer/Q2 Predictions Mean       -26.9923
trainer/Q2 Predictions Std         12.15
trainer/Q2 Predictions Max        -13.9309
trainer/Q2 Predictions Min        -90.6605
trainer/Q Targets Mean            -27.3238
trainer/Q Targets Std              12.2308
trainer/Q Targets Max             -14.2308
trainer/Q Targets Min             -93.2327
trainer/Log Pis Mean                1.96723
trainer/Log Pis Std                 1.31488
trainer/Log Pis Max                 5.71172
trainer/Log Pis Min                -2.14997
trainer/Policy mu Mean              0.0702063
trainer/Policy mu Std               0.859189
trainer/Policy mu Max               2.64153
trainer/Policy mu Min              -2.94263
trainer/Policy log std Mean        -1.88269
trainer/Policy log std Std          0.63448
trainer/Policy log std Max         -0.345499
trainer/Policy log std Min         -2.78986
trainer/Alpha                       0.0962135
trainer/Alpha Loss                 -0.0767121
exploration/num steps total     67600
exploration/num paths total       676
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.449991
exploration/Rewards Std             0.726744
exploration/Rewards Max            -0.0210019
exploration/Rewards Min            -6.03475
exploration/Returns Mean          -44.9991
exploration/Returns Std            25.8262
exploration/Returns Max           -19.173
exploration/Returns Min           -70.8253
exploration/Actions Mean            0.000330361
exploration/Actions Std             0.200555
exploration/Actions Max             0.971393
exploration/Actions Min            -0.993231
exploration/Num Paths               2
exploration/Average Returns       -44.9991
evaluation/num steps total     337000
evaluation/num paths total       3370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.57675
evaluation/Rewards Std              1.19204
evaluation/Rewards Max             -0.0622419
evaluation/Rewards Min            -10.5132
evaluation/Returns Mean           -57.675
evaluation/Returns Std             26.5982
evaluation/Returns Max             -7.04225
evaluation/Returns Min           -102.823
evaluation/Actions Mean             0.00239518
evaluation/Actions Std              0.213886
evaluation/Actions Max              0.992922
evaluation/Actions Min             -0.995945
evaluation/Num Paths               10
evaluation/Average Returns        -57.675
time/data storing (s)               0.00136732
time/evaluation sampling (s)        0.218105
time/exploration sampling (s)       0.0631597
time/logging (s)                    0.00336905
time/saving (s)                     0.00198522
time/training (s)                   0.772001
time/epoch (s)                      1.05999
time/total (s)                    359.396
Epoch                             336
-----------------------------  ----------------
2019-04-21 01:17:44.483436 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 337 finished
-----------------------------  ---------------
replay_buffer/size              67800
trainer/QF1 Loss                    2.29595
trainer/QF2 Loss                    2.33729
trainer/Policy Loss                25.745
trainer/Q1 Predictions Mean       -24.2077
trainer/Q1 Predictions Std         10.5593
trainer/Q1 Predictions Max        -13.9054
trainer/Q1 Predictions Min        -75.2809
trainer/Q2 Predictions Mean       -24.2595
trainer/Q2 Predictions Std         10.5234
trainer/Q2 Predictions Max        -13.9536
trainer/Q2 Predictions Min        -74.4546
trainer/Q Targets Mean            -24.3627
trainer/Q Targets Std              10.9039
trainer/Q Targets Max              -0.961338
trainer/Q Targets Min             -77.9537
trainer/Log Pis Mean                2.17086
trainer/Log Pis Std                 1.18508
trainer/Log Pis Max                 6.57862
trainer/Log Pis Min                -1.30492
trainer/Policy mu Mean              0.155045
trainer/Policy mu Std               0.704647
trainer/Policy mu Max               2.88967
trainer/Policy mu Min              -2.62389
trainer/Policy log std Mean        -2.04808
trainer/Policy log std Std          0.592246
trainer/Policy log std Max         -0.464519
trainer/Policy log std Min         -2.8242
trainer/Alpha                       0.0947353
trainer/Alpha Loss                  0.402674
exploration/num steps total     67800
exploration/num paths total       678
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.651888
exploration/Rewards Std             1.72901
exploration/Rewards Max            -0.0125414
exploration/Rewards Min            -9.99745
exploration/Returns Mean          -65.1888
exploration/Returns Std             3.87379
exploration/Returns Max           -61.315
exploration/Returns Min           -69.0626
exploration/Actions Mean            0.046816
exploration/Actions Std             0.253016
exploration/Actions Max             0.998905
exploration/Actions Min            -0.819716
exploration/Num Paths               2
exploration/Average Returns       -65.1888
evaluation/num steps total     338000
evaluation/num paths total       3380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.43481
evaluation/Rewards Std              0.735419
evaluation/Rewards Max             -0.125716
evaluation/Rewards Min            -10.0235
evaluation/Returns Mean           -43.481
evaluation/Returns Std             19.5642
evaluation/Returns Max            -13.8147
evaluation/Returns Min            -68.9605
evaluation/Actions Mean             0.0124826
evaluation/Actions Std              0.148364
evaluation/Actions Max              0.9956
evaluation/Actions Min             -0.897395
evaluation/Num Paths               10
evaluation/Average Returns        -43.481
time/data storing (s)               0.00129709
time/evaluation sampling (s)        0.215521
time/exploration sampling (s)       0.0629151
time/logging (s)                    0.00337617
time/saving (s)                     0.00197154
time/training (s)                   0.776725
time/epoch (s)                      1.06181
time/total (s)                    360.462
Epoch                             337
-----------------------------  ---------------
2019-04-21 01:17:45.530595 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 338 finished
-----------------------------  ---------------
replay_buffer/size              68000
trainer/QF1 Loss                    0.0687174
trainer/QF2 Loss                    0.08168
trainer/Policy Loss                25.3923
trainer/Q1 Predictions Mean       -24.0997
trainer/Q1 Predictions Std          9.6053
trainer/Q1 Predictions Max        -13.9674
trainer/Q1 Predictions Min        -56.8704
trainer/Q2 Predictions Mean       -24.1003
trainer/Q2 Predictions Std          9.56368
trainer/Q2 Predictions Max        -13.958
trainer/Q2 Predictions Min        -56.3792
trainer/Q Targets Mean            -24.2741
trainer/Q Targets Std               9.66842
trainer/Q Targets Max             -14.1359
trainer/Q Targets Min             -57.5572
trainer/Log Pis Mean                2.00799
trainer/Log Pis Std                 1.11043
trainer/Log Pis Max                 5.99338
trainer/Log Pis Min                -1.67453
trainer/Policy mu Mean              0.100616
trainer/Policy mu Std               0.70357
trainer/Policy mu Max               2.89389
trainer/Policy mu Min              -2.58387
trainer/Policy log std Mean        -2.01535
trainer/Policy log std Std          0.606359
trainer/Policy log std Max         -0.200728
trainer/Policy log std Min         -2.81794
trainer/Alpha                       0.0940561
trainer/Alpha Loss                  0.0188775
exploration/num steps total     68000
exploration/num paths total       680
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.661311
exploration/Rewards Std             1.44438
exploration/Rewards Max            -0.0235364
exploration/Rewards Min           -10.5887
exploration/Returns Mean          -66.1311
exploration/Returns Std            33.7
exploration/Returns Max           -32.4311
exploration/Returns Min           -99.8311
exploration/Actions Mean           -0.0127906
exploration/Actions Std             0.26602
exploration/Actions Max             0.996695
exploration/Actions Min            -0.99928
exploration/Num Paths               2
exploration/Average Returns       -66.1311
evaluation/num steps total     339000
evaluation/num paths total       3390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.399704
evaluation/Rewards Std              0.942109
evaluation/Rewards Max             -0.103031
evaluation/Rewards Min             -9.02278
evaluation/Returns Mean           -39.9704
evaluation/Returns Std             16.651
evaluation/Returns Max            -11.7491
evaluation/Returns Min            -57.059
evaluation/Actions Mean             0.00948417
evaluation/Actions Std              0.17653
evaluation/Actions Max              0.992724
evaluation/Actions Min             -0.986622
evaluation/Num Paths               10
evaluation/Average Returns        -39.9704
time/data storing (s)               0.00137072
time/evaluation sampling (s)        0.217765
time/exploration sampling (s)       0.0662644
time/logging (s)                    0.00336672
time/saving (s)                     0.00199802
time/training (s)                   0.747094
time/epoch (s)                      1.03786
time/total (s)                    361.504
Epoch                             338
-----------------------------  ---------------
2019-04-21 01:17:46.585393 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 339 finished
-----------------------------  ----------------
replay_buffer/size              68200
trainer/QF1 Loss                    5.57155
trainer/QF2 Loss                    5.54995
trainer/Policy Loss                24.3308
trainer/Q1 Predictions Mean       -23.0921
trainer/Q1 Predictions Std         11.3125
trainer/Q1 Predictions Max        -13.886
trainer/Q1 Predictions Min        -85.3819
trainer/Q2 Predictions Mean       -23.1171
trainer/Q2 Predictions Std         11.3236
trainer/Q2 Predictions Max        -13.887
trainer/Q2 Predictions Min        -85.5215
trainer/Q Targets Mean            -22.9843
trainer/Q Targets Std              11.4122
trainer/Q Targets Max              -4.64841
trainer/Q Targets Min             -84.8931
trainer/Log Pis Mean                2.00168
trainer/Log Pis Std                 1.10198
trainer/Log Pis Max                 4.69485
trainer/Log Pis Min                -0.792387
trainer/Policy mu Mean              0.105481
trainer/Policy mu Std               0.651688
trainer/Policy mu Max               2.42676
trainer/Policy mu Min              -2.77369
trainer/Policy log std Mean        -2.12224
trainer/Policy log std Std          0.555536
trainer/Policy log std Max         -0.568299
trainer/Policy log std Min         -2.7935
trainer/Alpha                       0.0957203
trainer/Alpha Loss                  0.00395276
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.389225
exploration/Rewards Std             0.596386
exploration/Rewards Max            -0.0289677
exploration/Rewards Min            -5.91165
exploration/Returns Mean          -38.9225
exploration/Returns Std            22.6549
exploration/Returns Max           -16.2676
exploration/Returns Min           -61.5773
exploration/Actions Mean           -0.0245661
exploration/Actions Std             0.174524
exploration/Actions Max             0.302062
exploration/Actions Min            -0.990342
exploration/Num Paths               2
exploration/Average Returns       -38.9225
evaluation/num steps total     340000
evaluation/num paths total       3400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.411701
evaluation/Rewards Std              0.748096
evaluation/Rewards Max             -0.112519
evaluation/Rewards Min             -8.154
evaluation/Returns Mean           -41.1701
evaluation/Returns Std             16.7416
evaluation/Returns Max            -13.7075
evaluation/Returns Min            -70.8355
evaluation/Actions Mean             0.000339776
evaluation/Actions Std              0.176768
evaluation/Actions Max              0.991451
evaluation/Actions Min             -0.994461
evaluation/Num Paths               10
evaluation/Average Returns        -41.1701
time/data storing (s)               0.00124291
time/evaluation sampling (s)        0.226865
time/exploration sampling (s)       0.072155
time/logging (s)                    0.00339609
time/saving (s)                     0.00157814
time/training (s)                   0.740671
time/epoch (s)                      1.04591
time/total (s)                    362.554
Epoch                             339
-----------------------------  ----------------
2019-04-21 01:17:47.659721 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 340 finished
-----------------------------  ---------------
replay_buffer/size              68400
trainer/QF1 Loss                    5.85644
trainer/QF2 Loss                    5.85914
trainer/Policy Loss                26.6539
trainer/Q1 Predictions Mean       -25.2573
trainer/Q1 Predictions Std         11.1329
trainer/Q1 Predictions Max        -13.787
trainer/Q1 Predictions Min        -66.6466
trainer/Q2 Predictions Mean       -25.2607
trainer/Q2 Predictions Std         11.1415
trainer/Q2 Predictions Max        -13.7906
trainer/Q2 Predictions Min        -66.3633
trainer/Q Targets Mean            -25.0888
trainer/Q Targets Std              11.7798
trainer/Q Targets Max              -0.360384
trainer/Q Targets Min             -66.1566
trainer/Log Pis Mean                2.10394
trainer/Log Pis Std                 1.39555
trainer/Log Pis Max                 7.32338
trainer/Log Pis Min                -1.51335
trainer/Policy mu Mean              0.0560505
trainer/Policy mu Std               0.829234
trainer/Policy mu Max               2.50413
trainer/Policy mu Min              -2.9074
trainer/Policy log std Mean        -1.99917
trainer/Policy log std Std          0.607265
trainer/Policy log std Max         -0.500236
trainer/Policy log std Min         -2.78094
trainer/Alpha                       0.0954845
trainer/Alpha Loss                  0.244124
exploration/num steps total     68400
exploration/num paths total       684
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.771627
exploration/Rewards Std             1.28602
exploration/Rewards Max            -0.322156
exploration/Rewards Min           -10.0812
exploration/Returns Mean          -77.1627
exploration/Returns Std            25.6568
exploration/Returns Max           -51.5059
exploration/Returns Min          -102.82
exploration/Actions Mean           -0.0253965
exploration/Actions Std             0.204574
exploration/Actions Max             0.697783
exploration/Actions Min            -0.999721
exploration/Num Paths               2
exploration/Average Returns       -77.1627
evaluation/num steps total     341000
evaluation/num paths total       3410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.471938
evaluation/Rewards Std              0.91664
evaluation/Rewards Max             -0.11175
evaluation/Rewards Min             -9.86274
evaluation/Returns Mean           -47.1938
evaluation/Returns Std             27.4965
evaluation/Returns Max            -13.05
evaluation/Returns Min            -99.4389
evaluation/Actions Mean            -0.00166779
evaluation/Actions Std              0.181001
evaluation/Actions Max              0.993726
evaluation/Actions Min             -0.995415
evaluation/Num Paths               10
evaluation/Average Returns        -47.1938
time/data storing (s)               0.00141975
time/evaluation sampling (s)        0.222422
time/exploration sampling (s)       0.0643359
time/logging (s)                    0.00336873
time/saving (s)                     0.0110012
time/training (s)                   0.762514
time/epoch (s)                      1.06506
time/total (s)                    363.623
Epoch                             340
-----------------------------  ---------------
2019-04-21 01:17:48.732827 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 341 finished
-----------------------------  ---------------
replay_buffer/size              68600
trainer/QF1 Loss                    0.145665
trainer/QF2 Loss                    0.15141
trainer/Policy Loss                26.714
trainer/Q1 Predictions Mean       -25.0178
trainer/Q1 Predictions Std         10.9773
trainer/Q1 Predictions Max        -13.7158
trainer/Q1 Predictions Min        -58.4689
trainer/Q2 Predictions Mean       -25.0017
trainer/Q2 Predictions Std         11.0151
trainer/Q2 Predictions Max        -13.6337
trainer/Q2 Predictions Min        -58.7675
trainer/Q Targets Mean            -25.264
trainer/Q Targets Std              11.0911
trainer/Q Targets Max             -13.7664
trainer/Q Targets Min             -58.6426
trainer/Log Pis Mean                2.30661
trainer/Log Pis Std                 1.22449
trainer/Log Pis Max                 7.79402
trainer/Log Pis Min                -1.40111
trainer/Policy mu Mean              0.0367224
trainer/Policy mu Std               0.81266
trainer/Policy mu Max               2.87258
trainer/Policy mu Min              -2.8826
trainer/Policy log std Mean        -2.01828
trainer/Policy log std Std          0.625343
trainer/Policy log std Max         -0.54887
trainer/Policy log std Min         -2.85648
trainer/Alpha                       0.0941929
trainer/Alpha Loss                  0.724366
exploration/num steps total     68600
exploration/num paths total       686
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.525681
exploration/Rewards Std             0.119102
exploration/Rewards Max            -0.313425
exploration/Rewards Min            -1.65894
exploration/Returns Mean          -52.5681
exploration/Returns Std             0.642984
exploration/Returns Max           -51.9251
exploration/Returns Min           -53.211
exploration/Actions Mean            0.0131418
exploration/Actions Std             0.165025
exploration/Actions Max             0.984455
exploration/Actions Min            -0.388946
exploration/Num Paths               2
exploration/Average Returns       -52.5681
evaluation/num steps total     342000
evaluation/num paths total       3420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.511143
evaluation/Rewards Std              0.749083
evaluation/Rewards Max             -0.122927
evaluation/Rewards Min             -9.25174
evaluation/Returns Mean           -51.1143
evaluation/Returns Std             19.472
evaluation/Returns Max            -17.4363
evaluation/Returns Min            -88.6413
evaluation/Actions Mean            -0.0098687
evaluation/Actions Std              0.171989
evaluation/Actions Max              0.992911
evaluation/Actions Min             -0.992188
evaluation/Num Paths               10
evaluation/Average Returns        -51.1143
time/data storing (s)               0.00123273
time/evaluation sampling (s)        0.221555
time/exploration sampling (s)       0.0646582
time/logging (s)                    0.00337092
time/saving (s)                     0.00199125
time/training (s)                   0.771001
time/epoch (s)                      1.06381
time/total (s)                    364.691
Epoch                             341
-----------------------------  ---------------
2019-04-21 01:17:49.807286 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 342 finished
-----------------------------  ---------------
replay_buffer/size              68800
trainer/QF1 Loss                   11.5652
trainer/QF2 Loss                   11.6138
trainer/Policy Loss                25.9106
trainer/Q1 Predictions Mean       -24.5679
trainer/Q1 Predictions Std          9.98361
trainer/Q1 Predictions Max        -13.7049
trainer/Q1 Predictions Min        -53.4559
trainer/Q2 Predictions Mean       -24.5838
trainer/Q2 Predictions Std          9.97473
trainer/Q2 Predictions Max        -13.7048
trainer/Q2 Predictions Min        -53.8514
trainer/Q Targets Mean            -24.2973
trainer/Q Targets Std              10.533
trainer/Q Targets Max              -0.166498
trainer/Q Targets Min             -53.6781
trainer/Log Pis Mean                1.81161
trainer/Log Pis Std                 1.20339
trainer/Log Pis Max                 3.7486
trainer/Log Pis Min                -3.21299
trainer/Policy mu Mean             -0.0490548
trainer/Policy mu Std               0.677281
trainer/Policy mu Max               2.19738
trainer/Policy mu Min              -2.51223
trainer/Policy log std Mean        -2.04791
trainer/Policy log std Std          0.576941
trainer/Policy log std Max         -0.423461
trainer/Policy log std Min         -2.78198
trainer/Alpha                       0.0935134
trainer/Alpha Loss                 -0.446393
exploration/num steps total     68800
exploration/num paths total       688
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.450184
exploration/Rewards Std             0.788508
exploration/Rewards Max            -0.0129198
exploration/Rewards Min            -6.47343
exploration/Returns Mean          -45.0184
exploration/Returns Std            12.1613
exploration/Returns Max           -32.8571
exploration/Returns Min           -57.1797
exploration/Actions Mean           -0.0146491
exploration/Actions Std             0.23153
exploration/Actions Max             0.984292
exploration/Actions Min            -0.990133
exploration/Num Paths               2
exploration/Average Returns       -45.0184
evaluation/num steps total     343000
evaluation/num paths total       3430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.377798
evaluation/Rewards Std              0.936441
evaluation/Rewards Max             -0.0587062
evaluation/Rewards Min             -9.90483
evaluation/Returns Mean           -37.7798
evaluation/Returns Std             23.5282
evaluation/Returns Max             -6.70042
evaluation/Returns Min            -72.9244
evaluation/Actions Mean             0.00551516
evaluation/Actions Std              0.191015
evaluation/Actions Max              0.994542
evaluation/Actions Min             -0.996233
evaluation/Num Paths               10
evaluation/Average Returns        -37.7798
time/data storing (s)               0.00141661
time/evaluation sampling (s)        0.217722
time/exploration sampling (s)       0.0607124
time/logging (s)                    0.00334554
time/saving (s)                     0.00197536
time/training (s)                   0.77976
time/epoch (s)                      1.06493
time/total (s)                    365.761
Epoch                             342
-----------------------------  ---------------
2019-04-21 01:17:50.872444 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 343 finished
-----------------------------  ----------------
replay_buffer/size              69000
trainer/QF1 Loss                    0.0371592
trainer/QF2 Loss                    0.036891
trainer/Policy Loss                26.1332
trainer/Q1 Predictions Mean       -24.9657
trainer/Q1 Predictions Std          9.18892
trainer/Q1 Predictions Max        -13.7202
trainer/Q1 Predictions Min        -49.8946
trainer/Q2 Predictions Mean       -24.9832
trainer/Q2 Predictions Std          9.1771
trainer/Q2 Predictions Max        -13.6611
trainer/Q2 Predictions Min        -49.4401
trainer/Q Targets Mean            -25.0186
trainer/Q Targets Std               9.1492
trainer/Q Targets Max             -13.7526
trainer/Q Targets Min             -49.6946
trainer/Log Pis Mean                1.78905
trainer/Log Pis Std                 0.935873
trainer/Log Pis Max                 4.3176
trainer/Log Pis Min                -1.27667
trainer/Policy mu Mean              0.0942041
trainer/Policy mu Std               0.654173
trainer/Policy mu Max               2.75603
trainer/Policy mu Min              -2.42559
trainer/Policy log std Mean        -1.97867
trainer/Policy log std Std          0.522533
trainer/Policy log std Max         -0.388127
trainer/Policy log std Min         -2.72536
trainer/Alpha                       0.0920057
trainer/Alpha Loss                 -0.503301
exploration/num steps total     69000
exploration/num paths total       690
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.492636
exploration/Rewards Std             1.42434
exploration/Rewards Max            -0.0154132
exploration/Rewards Min           -10.1997
exploration/Returns Mean          -49.2636
exploration/Returns Std            23.4075
exploration/Returns Max           -25.8562
exploration/Returns Min           -72.6711
exploration/Actions Mean            0.0440466
exploration/Actions Std             0.230805
exploration/Actions Max             0.997623
exploration/Actions Min            -0.543242
exploration/Num Paths               2
exploration/Average Returns       -49.2636
evaluation/num steps total     344000
evaluation/num paths total       3440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.424117
evaluation/Rewards Std              0.942749
evaluation/Rewards Max             -0.0737703
evaluation/Rewards Min             -9.67387
evaluation/Returns Mean           -42.4117
evaluation/Returns Std             22.1926
evaluation/Returns Max             -9.09477
evaluation/Returns Min            -89.6404
evaluation/Actions Mean            -0.000701791
evaluation/Actions Std              0.18646
evaluation/Actions Max              0.993926
evaluation/Actions Min             -0.995222
evaluation/Num Paths               10
evaluation/Average Returns        -42.4117
time/data storing (s)               0.00122977
time/evaluation sampling (s)        0.222455
time/exploration sampling (s)       0.06417
time/logging (s)                    0.00338166
time/saving (s)                     0.00197736
time/training (s)                   0.762446
time/epoch (s)                      1.05566
time/total (s)                    366.821
Epoch                             343
-----------------------------  ----------------
2019-04-21 01:17:51.950020 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 344 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                   11.4675
trainer/QF2 Loss                   11.4935
trainer/Policy Loss                27.218
trainer/Q1 Predictions Mean       -26.0426
trainer/Q1 Predictions Std         14.5967
trainer/Q1 Predictions Max        -13.5259
trainer/Q1 Predictions Min        -95.4259
trainer/Q2 Predictions Mean       -26.0415
trainer/Q2 Predictions Std         14.5681
trainer/Q2 Predictions Max        -13.5223
trainer/Q2 Predictions Min        -95.0807
trainer/Q Targets Mean            -26.0327
trainer/Q Targets Std              15.2744
trainer/Q Targets Max              -0.150307
trainer/Q Targets Min             -98.0364
trainer/Log Pis Mean                2.08286
trainer/Log Pis Std                 1.44299
trainer/Log Pis Max                 6.3022
trainer/Log Pis Min                -3.05689
trainer/Policy mu Mean             -0.00535798
trainer/Policy mu Std               0.807238
trainer/Policy mu Max               2.68302
trainer/Policy mu Min              -3.18677
trainer/Policy log std Mean        -2.04626
trainer/Policy log std Std          0.591327
trainer/Policy log std Max         -0.497326
trainer/Policy log std Min         -2.84566
trainer/Alpha                       0.0928799
trainer/Alpha Loss                  0.196922
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.454191
exploration/Rewards Std             0.724411
exploration/Rewards Max            -0.0550569
exploration/Rewards Min            -6.73592
exploration/Returns Mean          -45.4191
exploration/Returns Std             3.84927
exploration/Returns Max           -41.5698
exploration/Returns Min           -49.2684
exploration/Actions Mean            0.0392209
exploration/Actions Std             0.209181
exploration/Actions Max             0.995644
exploration/Actions Min            -0.375403
exploration/Num Paths               2
exploration/Average Returns       -45.4191
evaluation/num steps total     345000
evaluation/num paths total       3450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.467757
evaluation/Rewards Std              0.779512
evaluation/Rewards Max             -0.136689
evaluation/Rewards Min             -9.53017
evaluation/Returns Mean           -46.7757
evaluation/Returns Std             16.9763
evaluation/Returns Max            -17.8901
evaluation/Returns Min            -63.9418
evaluation/Actions Mean            -0.00758475
evaluation/Actions Std              0.179493
evaluation/Actions Max              0.995712
evaluation/Actions Min             -0.994938
evaluation/Num Paths               10
evaluation/Average Returns        -46.7757
time/data storing (s)               0.00142217
time/evaluation sampling (s)        0.221338
time/exploration sampling (s)       0.0623381
time/logging (s)                    0.0033348
time/saving (s)                     0.00198022
time/training (s)                   0.77768
time/epoch (s)                      1.06809
time/total (s)                    367.893
Epoch                             344
-----------------------------  ---------------
2019-04-21 01:17:53.021903 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 345 finished
-----------------------------  ---------------
replay_buffer/size              69400
trainer/QF1 Loss                    1.84489
trainer/QF2 Loss                    1.85593
trainer/Policy Loss                25.1577
trainer/Q1 Predictions Mean       -23.8856
trainer/Q1 Predictions Std          9.87029
trainer/Q1 Predictions Max        -13.397
trainer/Q1 Predictions Min        -63.167
trainer/Q2 Predictions Mean       -23.8837
trainer/Q2 Predictions Std          9.86623
trainer/Q2 Predictions Max        -13.3625
trainer/Q2 Predictions Min        -63.2134
trainer/Q Targets Mean            -23.8947
trainer/Q Targets Std              10.0027
trainer/Q Targets Max              -0.20377
trainer/Q Targets Min             -62.7429
trainer/Log Pis Mean                1.63145
trainer/Log Pis Std                 1.40923
trainer/Log Pis Max                 6.83951
trainer/Log Pis Min                -3.37294
trainer/Policy mu Mean              0.0447034
trainer/Policy mu Std               0.635201
trainer/Policy mu Max               2.52736
trainer/Policy mu Min              -2.67005
trainer/Policy log std Mean        -1.95444
trainer/Policy log std Std          0.54582
trainer/Policy log std Max         -0.341452
trainer/Policy log std Min         -2.77444
trainer/Alpha                       0.0908196
trainer/Alpha Loss                 -0.883931
exploration/num steps total     69400
exploration/num paths total       694
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.366385
exploration/Rewards Std             0.944421
exploration/Rewards Max            -0.00676619
exploration/Rewards Min            -7.28444
exploration/Returns Mean          -36.6385
exploration/Returns Std             4.93116
exploration/Returns Max           -31.7073
exploration/Returns Min           -41.5697
exploration/Actions Mean            0.0334504
exploration/Actions Std             0.240245
exploration/Actions Max             0.996315
exploration/Actions Min            -0.992695
exploration/Num Paths               2
exploration/Average Returns       -36.6385
evaluation/num steps total     346000
evaluation/num paths total       3460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.625991
evaluation/Rewards Std              1.21747
evaluation/Rewards Max             -0.104728
evaluation/Rewards Min             -9.93424
evaluation/Returns Mean           -62.5991
evaluation/Returns Std             24.8981
evaluation/Returns Max            -14.5066
evaluation/Returns Min           -100.826
evaluation/Actions Mean            -0.00498996
evaluation/Actions Std              0.201256
evaluation/Actions Max              0.993677
evaluation/Actions Min             -0.994942
evaluation/Num Paths               10
evaluation/Average Returns        -62.5991
time/data storing (s)               0.00133755
time/evaluation sampling (s)        0.216186
time/exploration sampling (s)       0.0649894
time/logging (s)                    0.0033544
time/saving (s)                     0.00198046
time/training (s)                   0.774647
time/epoch (s)                      1.06249
time/total (s)                    368.96
Epoch                             345
-----------------------------  ---------------
2019-04-21 01:17:54.068251 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 346 finished
-----------------------------  ---------------
replay_buffer/size              69600
trainer/QF1 Loss                   12.2138
trainer/QF2 Loss                   11.9948
trainer/Policy Loss                23.5302
trainer/Q1 Predictions Mean       -21.9514
trainer/Q1 Predictions Std          8.7767
trainer/Q1 Predictions Max        -13.5553
trainer/Q1 Predictions Min        -48.6113
trainer/Q2 Predictions Mean       -21.9437
trainer/Q2 Predictions Std          8.77449
trainer/Q2 Predictions Max        -13.5255
trainer/Q2 Predictions Min        -48.4586
trainer/Q Targets Mean            -21.7854
trainer/Q Targets Std               9.39171
trainer/Q Targets Max              -0.181419
trainer/Q Targets Min             -48.8807
trainer/Log Pis Mean                1.97159
trainer/Log Pis Std                 1.0699
trainer/Log Pis Max                 4.61688
trainer/Log Pis Min                -1.70641
trainer/Policy mu Mean              0.101663
trainer/Policy mu Std               0.594386
trainer/Policy mu Max               2.65989
trainer/Policy mu Min              -2.24208
trainer/Policy log std Mean        -2.15285
trainer/Policy log std Std          0.51986
trainer/Policy log std Max         -0.591763
trainer/Policy log std Min         -2.8013
trainer/Alpha                       0.0899412
trainer/Alpha Loss                 -0.0684404
exploration/num steps total     69600
exploration/num paths total       696
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.480582
exploration/Rewards Std             0.750739
exploration/Rewards Max            -0.0224725
exploration/Rewards Min            -6.17787
exploration/Returns Mean          -48.0582
exploration/Returns Std            10.0871
exploration/Returns Max           -37.9711
exploration/Returns Min           -58.1453
exploration/Actions Mean            0.0354475
exploration/Actions Std             0.213261
exploration/Actions Max             0.991824
exploration/Actions Min            -0.490377
exploration/Num Paths               2
exploration/Average Returns       -48.0582
evaluation/num steps total     347000
evaluation/num paths total       3470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.569932
evaluation/Rewards Std              0.983895
evaluation/Rewards Max             -0.0766936
evaluation/Rewards Min             -9.07035
evaluation/Returns Mean           -56.9932
evaluation/Returns Std             19.7183
evaluation/Returns Max            -24.8813
evaluation/Returns Min            -87.9883
evaluation/Actions Mean            -0.0135531
evaluation/Actions Std              0.201228
evaluation/Actions Max              0.994568
evaluation/Actions Min             -0.993846
evaluation/Num Paths               10
evaluation/Average Returns        -56.9932
time/data storing (s)               0.0011948
time/evaluation sampling (s)        0.223495
time/exploration sampling (s)       0.0631463
time/logging (s)                    0.00336831
time/saving (s)                     0.00195303
time/training (s)                   0.743727
time/epoch (s)                      1.03688
time/total (s)                    370.001
Epoch                             346
-----------------------------  ---------------
2019-04-21 01:17:55.129773 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 347 finished
-----------------------------  ----------------
replay_buffer/size              69800
trainer/QF1 Loss                    0.2351
trainer/QF2 Loss                    0.260659
trainer/Policy Loss                24.1933
trainer/Q1 Predictions Mean       -22.868
trainer/Q1 Predictions Std          9.19051
trainer/Q1 Predictions Max        -13.1808
trainer/Q1 Predictions Min        -48.2569
trainer/Q2 Predictions Mean       -22.8432
trainer/Q2 Predictions Std          9.16441
trainer/Q2 Predictions Max        -13.1347
trainer/Q2 Predictions Min        -47.8127
trainer/Q Targets Mean            -23.2458
trainer/Q Targets Std               9.34423
trainer/Q Targets Max             -13.3317
trainer/Q Targets Min             -48.2115
trainer/Log Pis Mean                1.89613
trainer/Log Pis Std                 1.14952
trainer/Log Pis Max                 5.91297
trainer/Log Pis Min                -2.47913
trainer/Policy mu Mean              0.0966313
trainer/Policy mu Std               0.670297
trainer/Policy mu Max               2.68378
trainer/Policy mu Min              -2.4789
trainer/Policy log std Mean        -2.06875
trainer/Policy log std Std          0.57168
trainer/Policy log std Max         -0.583943
trainer/Policy log std Min         -2.85389
trainer/Alpha                       0.0915447
trainer/Alpha Loss                 -0.248348
exploration/num steps total     69800
exploration/num paths total       698
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.516199
exploration/Rewards Std             0.390192
exploration/Rewards Max            -0.189128
exploration/Rewards Min            -3.72775
exploration/Returns Mean          -51.6199
exploration/Returns Std             0.361705
exploration/Returns Max           -51.2582
exploration/Returns Min           -51.9816
exploration/Actions Mean           -0.0213416
exploration/Actions Std             0.207706
exploration/Actions Max             0.866327
exploration/Actions Min            -0.980062
exploration/Num Paths               2
exploration/Average Returns       -51.6199
evaluation/num steps total     348000
evaluation/num paths total       3480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.518119
evaluation/Rewards Std              0.836907
evaluation/Rewards Max             -0.118511
evaluation/Rewards Min             -7.41852
evaluation/Returns Mean           -51.8119
evaluation/Returns Std             16.8008
evaluation/Returns Max            -22.3091
evaluation/Returns Min            -72.9731
evaluation/Actions Mean            -0.000545353
evaluation/Actions Std              0.197385
evaluation/Actions Max              0.994349
evaluation/Actions Min             -0.992451
evaluation/Num Paths               10
evaluation/Average Returns        -51.8119
time/data storing (s)               0.00156042
time/evaluation sampling (s)        0.221927
time/exploration sampling (s)       0.0619203
time/logging (s)                    0.00333601
time/saving (s)                     0.00195509
time/training (s)                   0.761354
time/epoch (s)                      1.05205
time/total (s)                    371.058
Epoch                             347
-----------------------------  ----------------
2019-04-21 01:17:56.203284 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 348 finished
-----------------------------  ---------------
replay_buffer/size              70000
trainer/QF1 Loss                    9.671
trainer/QF2 Loss                    9.67503
trainer/Policy Loss                27.1491
trainer/Q1 Predictions Mean       -25.4692
trainer/Q1 Predictions Std         10.8026
trainer/Q1 Predictions Max        -13.303
trainer/Q1 Predictions Min        -59.2344
trainer/Q2 Predictions Mean       -25.4392
trainer/Q2 Predictions Std         10.717
trainer/Q2 Predictions Max        -13.3184
trainer/Q2 Predictions Min        -58.4445
trainer/Q Targets Mean            -25.6919
trainer/Q Targets Std              11.3954
trainer/Q Targets Max              -0.637083
trainer/Q Targets Min             -61.0312
trainer/Log Pis Mean                2.01671
trainer/Log Pis Std                 1.4567
trainer/Log Pis Max                 6.74014
trainer/Log Pis Min                -3.45176
trainer/Policy mu Mean              0.0897216
trainer/Policy mu Std               0.845209
trainer/Policy mu Max               3.00121
trainer/Policy mu Min              -2.65336
trainer/Policy log std Mean        -1.93049
trainer/Policy log std Std          0.624299
trainer/Policy log std Max         -0.424741
trainer/Policy log std Min         -2.80629
trainer/Alpha                       0.0915437
trainer/Alpha Loss                  0.0399524
exploration/num steps total     70000
exploration/num paths total       700
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.523222
exploration/Rewards Std             0.821754
exploration/Rewards Max            -0.00175799
exploration/Rewards Min            -6.08799
exploration/Returns Mean          -52.3222
exploration/Returns Std            20.5399
exploration/Returns Max           -31.7823
exploration/Returns Min           -72.8621
exploration/Actions Mean           -0.00454859
exploration/Actions Std             0.230862
exploration/Actions Max             0.988405
exploration/Actions Min            -0.996251
exploration/Num Paths               2
exploration/Average Returns       -52.3222
evaluation/num steps total     349000
evaluation/num paths total       3490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.406497
evaluation/Rewards Std              1.1281
evaluation/Rewards Max             -0.0876548
evaluation/Rewards Min            -10.7932
evaluation/Returns Mean           -40.6497
evaluation/Returns Std             23.6131
evaluation/Returns Max             -9.59533
evaluation/Returns Min            -79.9183
evaluation/Actions Mean             0.0208943
evaluation/Actions Std              0.194198
evaluation/Actions Max              0.996102
evaluation/Actions Min             -0.988411
evaluation/Num Paths               10
evaluation/Average Returns        -40.6497
time/data storing (s)               0.00119579
time/evaluation sampling (s)        0.221339
time/exploration sampling (s)       0.06551
time/logging (s)                    0.00278179
time/saving (s)                     0.00205158
time/training (s)                   0.770697
time/epoch (s)                      1.06357
time/total (s)                    372.125
Epoch                             348
-----------------------------  ---------------
2019-04-21 01:17:57.268895 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 349 finished
-----------------------------  ---------------
replay_buffer/size              70200
trainer/QF1 Loss                    0.131243
trainer/QF2 Loss                    0.140034
trainer/Policy Loss                26.1632
trainer/Q1 Predictions Mean       -24.5608
trainer/Q1 Predictions Std          9.65378
trainer/Q1 Predictions Max        -12.9952
trainer/Q1 Predictions Min        -50.2812
trainer/Q2 Predictions Mean       -24.5995
trainer/Q2 Predictions Std          9.6363
trainer/Q2 Predictions Max        -13.0603
trainer/Q2 Predictions Min        -49.8656
trainer/Q Targets Mean            -24.7788
trainer/Q Targets Std               9.63314
trainer/Q Targets Max             -13.1411
trainer/Q Targets Min             -51.9358
trainer/Log Pis Mean                2.15222
trainer/Log Pis Std                 1.32451
trainer/Log Pis Max                 6.92124
trainer/Log Pis Min                -1.96355
trainer/Policy mu Mean              0.0308528
trainer/Policy mu Std               0.787247
trainer/Policy mu Max               2.70537
trainer/Policy mu Min              -2.32098
trainer/Policy log std Mean        -2.0145
trainer/Policy log std Std          0.645332
trainer/Policy log std Max         -0.39013
trainer/Policy log std Min         -2.84532
trainer/Alpha                       0.090076
trainer/Alpha Loss                  0.366393
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.347342
exploration/Rewards Std             0.216972
exploration/Rewards Max            -0.0214378
exploration/Rewards Min            -1.57451
exploration/Returns Mean          -34.7342
exploration/Returns Std            16.804
exploration/Returns Max           -17.9302
exploration/Returns Min           -51.5382
exploration/Actions Mean            0.00286045
exploration/Actions Std             0.149685
exploration/Actions Max             0.978246
exploration/Actions Min            -0.935695
exploration/Num Paths               2
exploration/Average Returns       -34.7342
evaluation/num steps total     350000
evaluation/num paths total       3500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.529975
evaluation/Rewards Std              1.07555
evaluation/Rewards Max             -0.120122
evaluation/Rewards Min             -9.90344
evaluation/Returns Mean           -52.9975
evaluation/Returns Std             18.867
evaluation/Returns Max            -15.1097
evaluation/Returns Min            -86.4757
evaluation/Actions Mean             0.0117071
evaluation/Actions Std              0.18917
evaluation/Actions Max              0.993316
evaluation/Actions Min             -0.993643
evaluation/Num Paths               10
evaluation/Average Returns        -52.9975
time/data storing (s)               0.00144916
time/evaluation sampling (s)        0.219847
time/exploration sampling (s)       0.0622129
time/logging (s)                    0.00336933
time/saving (s)                     0.00196541
time/training (s)                   0.76876
time/epoch (s)                      1.0576
time/total (s)                    373.188
Epoch                             349
-----------------------------  ---------------
2019-04-21 01:17:58.344480 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 350 finished
-----------------------------  ---------------
replay_buffer/size              70400
trainer/QF1 Loss                    0.354692
trainer/QF2 Loss                    0.309637
trainer/Policy Loss                26.0751
trainer/Q1 Predictions Mean       -24.5761
trainer/Q1 Predictions Std         12.4588
trainer/Q1 Predictions Max        -13.1143
trainer/Q1 Predictions Min        -77.1431
trainer/Q2 Predictions Mean       -24.6041
trainer/Q2 Predictions Std         12.4715
trainer/Q2 Predictions Max        -13.1212
trainer/Q2 Predictions Min        -76.9388
trainer/Q Targets Mean            -24.9008
trainer/Q Targets Std              12.7557
trainer/Q Targets Max             -13.0953
trainer/Q Targets Min             -80.4102
trainer/Log Pis Mean                1.98192
trainer/Log Pis Std                 1.3477
trainer/Log Pis Max                 6.96005
trainer/Log Pis Min                -2.22128
trainer/Policy mu Mean              0.0552734
trainer/Policy mu Std               0.71825
trainer/Policy mu Max               2.99212
trainer/Policy mu Min              -2.98754
trainer/Policy log std Mean        -2.06517
trainer/Policy log std Std          0.568133
trainer/Policy log std Max         -0.535847
trainer/Policy log std Min         -2.88775
trainer/Alpha                       0.0894029
trainer/Alpha Loss                 -0.0436448
exploration/num steps total     70400
exploration/num paths total       704
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.676999
exploration/Rewards Std             1.27177
exploration/Rewards Max            -0.0187535
exploration/Rewards Min            -8.35144
exploration/Returns Mean          -67.6999
exploration/Returns Std            17.0554
exploration/Returns Max           -50.6445
exploration/Returns Min           -84.7553
exploration/Actions Mean            0.00882758
exploration/Actions Std             0.259308
exploration/Actions Max             0.99787
exploration/Actions Min            -0.999564
exploration/Num Paths               2
exploration/Average Returns       -67.6999
evaluation/num steps total     351000
evaluation/num paths total       3510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.454549
evaluation/Rewards Std              0.935617
evaluation/Rewards Max             -0.126512
evaluation/Rewards Min            -10.3183
evaluation/Returns Mean           -45.4549
evaluation/Returns Std             29.093
evaluation/Returns Max            -17.4403
evaluation/Returns Min           -106.842
evaluation/Actions Mean            -0.00303227
evaluation/Actions Std              0.172333
evaluation/Actions Max              0.996106
evaluation/Actions Min             -0.997028
evaluation/Num Paths               10
evaluation/Average Returns        -45.4549
time/data storing (s)               0.00152201
time/evaluation sampling (s)        0.22488
time/exploration sampling (s)       0.0613467
time/logging (s)                    0.0038551
time/saving (s)                     0.00200494
time/training (s)                   0.772937
time/epoch (s)                      1.06655
time/total (s)                    374.258
Epoch                             350
-----------------------------  ---------------
2019-04-21 01:17:59.403002 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 351 finished
-----------------------------  ---------------
replay_buffer/size              70600
trainer/QF1 Loss                   11.0742
trainer/QF2 Loss                   11.113
trainer/Policy Loss                24.6498
trainer/Q1 Predictions Mean       -23.0654
trainer/Q1 Predictions Std         10.859
trainer/Q1 Predictions Max        -13.037
trainer/Q1 Predictions Min        -69.4196
trainer/Q2 Predictions Mean       -23.057
trainer/Q2 Predictions Std         10.8782
trainer/Q2 Predictions Max        -13.0076
trainer/Q2 Predictions Min        -69.4319
trainer/Q Targets Mean            -22.8374
trainer/Q Targets Std              11.2338
trainer/Q Targets Max              -0.318942
trainer/Q Targets Min             -68.6586
trainer/Log Pis Mean                2.0956
trainer/Log Pis Std                 1.33766
trainer/Log Pis Max                 6.84474
trainer/Log Pis Min                -3.06501
trainer/Policy mu Mean              0.0490921
trainer/Policy mu Std               0.795534
trainer/Policy mu Max               2.60303
trainer/Policy mu Min              -3.07271
trainer/Policy log std Mean        -1.99406
trainer/Policy log std Std          0.636624
trainer/Policy log std Max         -0.465821
trainer/Policy log std Min         -2.8394
trainer/Alpha                       0.0897274
trainer/Alpha Loss                  0.230497
exploration/num steps total     70600
exploration/num paths total       706
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.596549
exploration/Rewards Std             1.17183
exploration/Rewards Max            -0.0135056
exploration/Rewards Min            -9.1554
exploration/Returns Mean          -59.6549
exploration/Returns Std             1.2085
exploration/Returns Max           -58.4464
exploration/Returns Min           -60.8634
exploration/Actions Mean            0.0134888
exploration/Actions Std             0.249328
exploration/Actions Max             0.996445
exploration/Actions Min            -0.995981
exploration/Num Paths               2
exploration/Average Returns       -59.6549
evaluation/num steps total     352000
evaluation/num paths total       3520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.378928
evaluation/Rewards Std              0.768051
evaluation/Rewards Max             -0.0610196
evaluation/Rewards Min             -9.86573
evaluation/Returns Mean           -37.8928
evaluation/Returns Std             22.8588
evaluation/Returns Max            -11.175
evaluation/Returns Min            -64.9446
evaluation/Actions Mean             0.00728508
evaluation/Actions Std              0.156655
evaluation/Actions Max              0.99345
evaluation/Actions Min             -0.988591
evaluation/Num Paths               10
evaluation/Average Returns        -37.8928
time/data storing (s)               0.00123159
time/evaluation sampling (s)        0.220051
time/exploration sampling (s)       0.0637663
time/logging (s)                    0.00285327
time/saving (s)                     0.0019634
time/training (s)                   0.758382
time/epoch (s)                      1.04825
time/total (s)                    375.311
Epoch                             351
-----------------------------  ---------------
2019-04-21 01:18:00.470433 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 352 finished
-----------------------------  ---------------
replay_buffer/size              70800
trainer/QF1 Loss                    0.124417
trainer/QF2 Loss                    0.126482
trainer/Policy Loss                26.2507
trainer/Q1 Predictions Mean       -24.4915
trainer/Q1 Predictions Std         10.5376
trainer/Q1 Predictions Max        -13.0037
trainer/Q1 Predictions Min        -66.7346
trainer/Q2 Predictions Mean       -24.5094
trainer/Q2 Predictions Std         10.5521
trainer/Q2 Predictions Max        -13.0135
trainer/Q2 Predictions Min        -66.6721
trainer/Q Targets Mean            -24.6614
trainer/Q Targets Std              10.6222
trainer/Q Targets Max             -12.9941
trainer/Q Targets Min             -68.7751
trainer/Log Pis Mean                2.17706
trainer/Log Pis Std                 0.96663
trainer/Log Pis Max                 6.48038
trainer/Log Pis Min                -1.22096
trainer/Policy mu Mean              0.00699374
trainer/Policy mu Std               0.757753
trainer/Policy mu Max               3.01136
trainer/Policy mu Min              -2.52803
trainer/Policy log std Mean        -1.99268
trainer/Policy log std Std          0.592316
trainer/Policy log std Max         -0.414565
trainer/Policy log std Min         -2.84478
trainer/Alpha                       0.0872298
trainer/Alpha Loss                  0.43184
exploration/num steps total     70800
exploration/num paths total       708
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.825769
exploration/Rewards Std             1.33065
exploration/Rewards Max            -0.313356
exploration/Rewards Min           -10.1385
exploration/Returns Mean          -82.5769
exploration/Returns Std            23.8596
exploration/Returns Max           -58.7173
exploration/Returns Min          -106.436
exploration/Actions Mean           -0.0418915
exploration/Actions Std             0.240755
exploration/Actions Max             0.716427
exploration/Actions Min            -0.996806
exploration/Num Paths               2
exploration/Average Returns       -82.5769
evaluation/num steps total     353000
evaluation/num paths total       3530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.514233
evaluation/Rewards Std              0.845452
evaluation/Rewards Max             -0.101001
evaluation/Rewards Min             -7.75743
evaluation/Returns Mean           -51.4233
evaluation/Returns Std             23.3354
evaluation/Returns Max            -15.298
evaluation/Returns Min            -82.3578
evaluation/Actions Mean            -0.0130382
evaluation/Actions Std              0.192705
evaluation/Actions Max              0.994132
evaluation/Actions Min             -0.992903
evaluation/Num Paths               10
evaluation/Average Returns        -51.4233
time/data storing (s)               0.00127021
time/evaluation sampling (s)        0.222793
time/exploration sampling (s)       0.0651778
time/logging (s)                    0.00335992
time/saving (s)                     0.00198876
time/training (s)                   0.764159
time/epoch (s)                      1.05875
time/total (s)                    376.374
Epoch                             352
-----------------------------  ---------------
2019-04-21 01:18:01.536868 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 353 finished
-----------------------------  ---------------
replay_buffer/size              71000
trainer/QF1 Loss                   11.4959
trainer/QF2 Loss                   11.5605
trainer/Policy Loss                26.7527
trainer/Q1 Predictions Mean       -25.0942
trainer/Q1 Predictions Std         10.5097
trainer/Q1 Predictions Max        -13.0459
trainer/Q1 Predictions Min        -70.0514
trainer/Q2 Predictions Mean       -25.0908
trainer/Q2 Predictions Std         10.5104
trainer/Q2 Predictions Max        -13.0247
trainer/Q2 Predictions Min        -69.4773
trainer/Q Targets Mean            -24.7087
trainer/Q Targets Std              11.0053
trainer/Q Targets Max              -0.647887
trainer/Q Targets Min             -72.7798
trainer/Log Pis Mean                2.14825
trainer/Log Pis Std                 0.806144
trainer/Log Pis Max                 4.49053
trainer/Log Pis Min                -0.66272
trainer/Policy mu Mean              0.0350807
trainer/Policy mu Std               0.623852
trainer/Policy mu Max               2.87387
trainer/Policy mu Min              -2.77471
trainer/Policy log std Mean        -2.14946
trainer/Policy log std Std          0.502596
trainer/Policy log std Max         -0.522143
trainer/Policy log std Min         -2.80742
trainer/Alpha                       0.0870372
trainer/Alpha Loss                  0.361971
exploration/num steps total     71000
exploration/num paths total       710
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.648752
exploration/Rewards Std             1.33377
exploration/Rewards Max            -0.0359067
exploration/Rewards Min            -9.2556
exploration/Returns Mean          -64.8752
exploration/Returns Std            23.8205
exploration/Returns Max           -41.0547
exploration/Returns Min           -88.6958
exploration/Actions Mean           -0.01045
exploration/Actions Std             0.239708
exploration/Actions Max             0.992325
exploration/Actions Min            -0.998879
exploration/Num Paths               2
exploration/Average Returns       -64.8752
evaluation/num steps total     354000
evaluation/num paths total       3540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.538504
evaluation/Rewards Std              0.994022
evaluation/Rewards Max             -0.14537
evaluation/Rewards Min             -9.3419
evaluation/Returns Mean           -53.8504
evaluation/Returns Std             15.5312
evaluation/Returns Max            -20.5847
evaluation/Returns Min            -77.618
evaluation/Actions Mean            -0.00436042
evaluation/Actions Std              0.197774
evaluation/Actions Max              0.993072
evaluation/Actions Min             -0.993741
evaluation/Num Paths               10
evaluation/Average Returns        -53.8504
time/data storing (s)               0.00120343
time/evaluation sampling (s)        0.21401
time/exploration sampling (s)       0.0629126
time/logging (s)                    0.00338209
time/saving (s)                     0.00197841
time/training (s)                   0.773479
time/epoch (s)                      1.05697
time/total (s)                    377.436
Epoch                             353
-----------------------------  ---------------
2019-04-21 01:18:02.612629 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 354 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                    0.338751
trainer/QF2 Loss                    0.320803
trainer/Policy Loss                26.4503
trainer/Q1 Predictions Mean       -24.8457
trainer/Q1 Predictions Std          9.38611
trainer/Q1 Predictions Max        -13.0275
trainer/Q1 Predictions Min        -56.207
trainer/Q2 Predictions Mean       -24.8352
trainer/Q2 Predictions Std          9.38798
trainer/Q2 Predictions Max        -13.0039
trainer/Q2 Predictions Min        -56.0182
trainer/Q Targets Mean            -25.2418
trainer/Q Targets Std               9.56306
trainer/Q Targets Max             -13.0038
trainer/Q Targets Min             -54.8041
trainer/Log Pis Mean                2.09077
trainer/Log Pis Std                 1.02639
trainer/Log Pis Max                 4.61707
trainer/Log Pis Min                -1.77335
trainer/Policy mu Mean              0.0925181
trainer/Policy mu Std               0.728599
trainer/Policy mu Max               2.78386
trainer/Policy mu Min              -2.67582
trainer/Policy log std Mean        -2.07476
trainer/Policy log std Std          0.579827
trainer/Policy log std Max         -0.518447
trainer/Policy log std Min         -2.87558
trainer/Alpha                       0.0888987
trainer/Alpha Loss                  0.219699
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.181404
exploration/Rewards Std             0.283409
exploration/Rewards Max            -0.00995685
exploration/Rewards Min            -3.3207
exploration/Returns Mean          -18.1404
exploration/Returns Std             3.28225
exploration/Returns Max           -14.8581
exploration/Returns Min           -21.4226
exploration/Actions Mean            0.0187036
exploration/Actions Std             0.152896
exploration/Actions Max             0.966047
exploration/Actions Min            -0.300425
exploration/Num Paths               2
exploration/Average Returns       -18.1404
evaluation/num steps total     355000
evaluation/num paths total       3550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.5521
evaluation/Rewards Std              0.988317
evaluation/Rewards Max             -0.100258
evaluation/Rewards Min            -10.6014
evaluation/Returns Mean           -55.21
evaluation/Returns Std             23.8611
evaluation/Returns Max            -11.0881
evaluation/Returns Min            -93.2934
evaluation/Actions Mean            -0.00320064
evaluation/Actions Std              0.175168
evaluation/Actions Max              0.996332
evaluation/Actions Min             -0.995019
evaluation/Num Paths               10
evaluation/Average Returns        -55.21
time/data storing (s)               0.00135041
time/evaluation sampling (s)        0.220109
time/exploration sampling (s)       0.0636472
time/logging (s)                    0.00338189
time/saving (s)                     0.00743395
time/training (s)                   0.771511
time/epoch (s)                      1.06743
time/total (s)                    378.507
Epoch                             354
-----------------------------  ---------------
2019-04-21 01:18:03.671895 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 355 finished
-----------------------------  ---------------
replay_buffer/size              71400
trainer/QF1 Loss                    1.75606
trainer/QF2 Loss                    1.73875
trainer/Policy Loss                23.8769
trainer/Q1 Predictions Mean       -22.1654
trainer/Q1 Predictions Std          9.78234
trainer/Q1 Predictions Max        -12.7657
trainer/Q1 Predictions Min        -50.5424
trainer/Q2 Predictions Mean       -22.1751
trainer/Q2 Predictions Std          9.79278
trainer/Q2 Predictions Max        -12.7593
trainer/Q2 Predictions Min        -50.2034
trainer/Q Targets Mean            -22.3062
trainer/Q Targets Std              10.0158
trainer/Q Targets Max              -0.233659
trainer/Q Targets Min             -50.3567
trainer/Log Pis Mean                2.1908
trainer/Log Pis Std                 1.17599
trainer/Log Pis Max                 6.4674
trainer/Log Pis Min                -5.0324
trainer/Policy mu Mean              0.0932163
trainer/Policy mu Std               0.687682
trainer/Policy mu Max               2.7205
trainer/Policy mu Min              -2.35498
trainer/Policy log std Mean        -2.12419
trainer/Policy log std Std          0.605329
trainer/Policy log std Max         -0.617711
trainer/Policy log std Min         -2.8838
trainer/Alpha                       0.0891024
trainer/Alpha Loss                  0.461321
exploration/num steps total     71400
exploration/num paths total       714
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.607369
exploration/Rewards Std             1.28929
exploration/Rewards Max            -0.0131822
exploration/Rewards Min           -10.208
exploration/Returns Mean          -60.7369
exploration/Returns Std             6.28149
exploration/Returns Max           -54.4554
exploration/Returns Min           -67.0184
exploration/Actions Mean            0.0407764
exploration/Actions Std             0.223786
exploration/Actions Max             0.997946
exploration/Actions Min            -0.566977
exploration/Num Paths               2
exploration/Average Returns       -60.7369
evaluation/num steps total     356000
evaluation/num paths total       3560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.593689
evaluation/Rewards Std              1.27475
evaluation/Rewards Max             -0.0869106
evaluation/Rewards Min            -10.2959
evaluation/Returns Mean           -59.3689
evaluation/Returns Std             26.9099
evaluation/Returns Max            -11.0415
evaluation/Returns Min           -101.403
evaluation/Actions Mean             0.00351055
evaluation/Actions Std              0.219263
evaluation/Actions Max              0.994061
evaluation/Actions Min             -0.998256
evaluation/Num Paths               10
evaluation/Average Returns        -59.3689
time/data storing (s)               0.00118705
time/evaluation sampling (s)        0.221244
time/exploration sampling (s)       0.0633286
time/logging (s)                    0.00253591
time/saving (s)                     0.00198495
time/training (s)                   0.758452
time/epoch (s)                      1.04873
time/total (s)                    379.56
Epoch                             355
-----------------------------  ---------------
2019-04-21 01:18:04.741488 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 356 finished
-----------------------------  ---------------
replay_buffer/size              71600
trainer/QF1 Loss                   12.2898
trainer/QF2 Loss                   12.019
trainer/Policy Loss                24.7834
trainer/Q1 Predictions Mean       -23.3139
trainer/Q1 Predictions Std         10.4795
trainer/Q1 Predictions Max        -12.6788
trainer/Q1 Predictions Min        -59.9447
trainer/Q2 Predictions Mean       -23.3295
trainer/Q2 Predictions Std         10.4619
trainer/Q2 Predictions Max        -12.7083
trainer/Q2 Predictions Min        -59.9204
trainer/Q Targets Mean            -22.9893
trainer/Q Targets Std              10.6939
trainer/Q Targets Max              -1.51177
trainer/Q Targets Min             -58.9512
trainer/Log Pis Mean                1.95237
trainer/Log Pis Std                 1.1519
trainer/Log Pis Max                 5.72364
trainer/Log Pis Min                -1.15775
trainer/Policy mu Mean              0.0659733
trainer/Policy mu Std               0.766879
trainer/Policy mu Max               2.76611
trainer/Policy mu Min              -2.79997
trainer/Policy log std Mean        -2.01586
trainer/Policy log std Std          0.590898
trainer/Policy log std Max         -0.585093
trainer/Policy log std Min         -2.76972
trainer/Alpha                       0.0904688
trainer/Alpha Loss                 -0.114443
exploration/num steps total     71600
exploration/num paths total       716
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.651669
exploration/Rewards Std             1.36505
exploration/Rewards Max            -0.0325241
exploration/Rewards Min            -9.73924
exploration/Returns Mean          -65.1669
exploration/Returns Std            30.4797
exploration/Returns Max           -34.6872
exploration/Returns Min           -95.6466
exploration/Actions Mean           -0.00621631
exploration/Actions Std             0.241861
exploration/Actions Max             0.996551
exploration/Actions Min            -0.999179
exploration/Num Paths               2
exploration/Average Returns       -65.1669
evaluation/num steps total     357000
evaluation/num paths total       3570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.525244
evaluation/Rewards Std              0.926905
evaluation/Rewards Max             -0.0893955
evaluation/Rewards Min            -10.879
evaluation/Returns Mean           -52.5244
evaluation/Returns Std             24.6248
evaluation/Returns Max            -10.6078
evaluation/Returns Min           -102.092
evaluation/Actions Mean            -0.0206974
evaluation/Actions Std              0.181735
evaluation/Actions Max              0.993435
evaluation/Actions Min             -0.99715
evaluation/Num Paths               10
evaluation/Average Returns        -52.5244
time/data storing (s)               0.00165005
time/evaluation sampling (s)        0.225375
time/exploration sampling (s)       0.0625765
time/logging (s)                    0.0033348
time/saving (s)                     0.0019781
time/training (s)                   0.767615
time/epoch (s)                      1.06253
time/total (s)                    380.625
Epoch                             356
-----------------------------  ---------------
2019-04-21 01:18:05.810902 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 357 finished
-----------------------------  ----------------
replay_buffer/size              71800
trainer/QF1 Loss                    0.358854
trainer/QF2 Loss                    0.342858
trainer/Policy Loss                23.137
trainer/Q1 Predictions Mean       -21.3789
trainer/Q1 Predictions Std          9.657
trainer/Q1 Predictions Max        -12.7371
trainer/Q1 Predictions Min        -66.0525
trainer/Q2 Predictions Mean       -21.4042
trainer/Q2 Predictions Std          9.69722
trainer/Q2 Predictions Max        -12.7425
trainer/Q2 Predictions Min        -66.4816
trainer/Q Targets Mean            -21.8215
trainer/Q Targets Std               9.94475
trainer/Q Targets Max             -12.8275
trainer/Q Targets Min             -65.7904
trainer/Log Pis Mean                2.14811
trainer/Log Pis Std                 0.889764
trainer/Log Pis Max                 5.94713
trainer/Log Pis Min                -0.468423
trainer/Policy mu Mean              0.0709214
trainer/Policy mu Std               0.616329
trainer/Policy mu Max               2.74205
trainer/Policy mu Min              -2.72972
trainer/Policy log std Mean        -2.13445
trainer/Policy log std Std          0.531197
trainer/Policy log std Max         -0.388282
trainer/Policy log std Min         -2.83394
trainer/Alpha                       0.0909512
trainer/Alpha Loss                  0.355096
exploration/num steps total     71800
exploration/num paths total       718
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.474777
exploration/Rewards Std             0.860413
exploration/Rewards Max            -0.0159423
exploration/Rewards Min            -7.41641
exploration/Returns Mean          -47.4777
exploration/Returns Std             1.17795
exploration/Returns Max           -46.2998
exploration/Returns Min           -48.6557
exploration/Actions Mean            0.0348445
exploration/Actions Std             0.215289
exploration/Actions Max             0.998515
exploration/Actions Min            -0.46366
exploration/Num Paths               2
exploration/Average Returns       -47.4777
evaluation/num steps total     358000
evaluation/num paths total       3580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.482964
evaluation/Rewards Std              0.712137
evaluation/Rewards Max             -0.102389
evaluation/Rewards Min             -9.07128
evaluation/Returns Mean           -48.2964
evaluation/Returns Std             20.6829
evaluation/Returns Max            -16.9917
evaluation/Returns Min            -84.9006
evaluation/Actions Mean             0.000441492
evaluation/Actions Std              0.171258
evaluation/Actions Max              0.993604
evaluation/Actions Min             -0.996747
evaluation/Num Paths               10
evaluation/Average Returns        -48.2964
time/data storing (s)               0.00122008
time/evaluation sampling (s)        0.222193
time/exploration sampling (s)       0.064346
time/logging (s)                    0.00334194
time/saving (s)                     0.0019584
time/training (s)                   0.76842
time/epoch (s)                      1.06148
time/total (s)                    381.691
Epoch                             357
-----------------------------  ----------------
2019-04-21 01:18:06.854059 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 358 finished
-----------------------------  ---------------
replay_buffer/size              72000
trainer/QF1 Loss                   18.1728
trainer/QF2 Loss                   18.2086
trainer/Policy Loss                24.5072
trainer/Q1 Predictions Mean       -23.0923
trainer/Q1 Predictions Std          9.47369
trainer/Q1 Predictions Max        -12.6557
trainer/Q1 Predictions Min        -51.2291
trainer/Q2 Predictions Mean       -23.0624
trainer/Q2 Predictions Std          9.51387
trainer/Q2 Predictions Max        -12.64
trainer/Q2 Predictions Min        -52.6354
trainer/Q Targets Mean            -22.7741
trainer/Q Targets Std              10.1457
trainer/Q Targets Max              -0.786538
trainer/Q Targets Min             -53.6328
trainer/Log Pis Mean                2.00236
trainer/Log Pis Std                 1.18221
trainer/Log Pis Max                 6.15581
trainer/Log Pis Min                -2.66437
trainer/Policy mu Mean              0.119769
trainer/Policy mu Std               0.637029
trainer/Policy mu Max               2.67542
trainer/Policy mu Min              -2.04956
trainer/Policy log std Mean        -2.02566
trainer/Policy log std Std          0.553835
trainer/Policy log std Max         -0.437079
trainer/Policy log std Min         -2.82874
trainer/Alpha                       0.0909587
trainer/Alpha Loss                  0.00566764
exploration/num steps total     72000
exploration/num paths total       720
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.660418
exploration/Rewards Std             1.43023
exploration/Rewards Max            -0.0044416
exploration/Rewards Min           -10.2508
exploration/Returns Mean          -66.0418
exploration/Returns Std             3.79693
exploration/Returns Max           -62.2449
exploration/Returns Min           -69.8387
exploration/Actions Mean            0.0115311
exploration/Actions Std             0.236309
exploration/Actions Max             0.996206
exploration/Actions Min            -0.990867
exploration/Num Paths               2
exploration/Average Returns       -66.0418
evaluation/num steps total     359000
evaluation/num paths total       3590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.453989
evaluation/Rewards Std              0.981869
evaluation/Rewards Max             -0.0663715
evaluation/Rewards Min            -10.3121
evaluation/Returns Mean           -45.3989
evaluation/Returns Std             33.4161
evaluation/Returns Max             -7.24089
evaluation/Returns Min            -99.1361
evaluation/Actions Mean            -0.00622446
evaluation/Actions Std              0.180757
evaluation/Actions Max              0.990766
evaluation/Actions Min             -0.998154
evaluation/Num Paths               10
evaluation/Average Returns        -45.3989
time/data storing (s)               0.0012336
time/evaluation sampling (s)        0.221673
time/exploration sampling (s)       0.0646084
time/logging (s)                    0.00334194
time/saving (s)                     0.00168309
time/training (s)                   0.741075
time/epoch (s)                      1.03362
time/total (s)                    382.729
Epoch                             358
-----------------------------  ---------------
2019-04-21 01:18:07.922411 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 359 finished
-----------------------------  ---------------
replay_buffer/size              72200
trainer/QF1 Loss                    0.0930771
trainer/QF2 Loss                    0.111879
trainer/Policy Loss                26.2148
trainer/Q1 Predictions Mean       -24.5469
trainer/Q1 Predictions Std         10.9634
trainer/Q1 Predictions Max        -12.5055
trainer/Q1 Predictions Min        -65.9576
trainer/Q2 Predictions Mean       -24.5512
trainer/Q2 Predictions Std         10.958
trainer/Q2 Predictions Max        -12.5374
trainer/Q2 Predictions Min        -66.2303
trainer/Q Targets Mean            -24.6651
trainer/Q Targets Std              10.9134
trainer/Q Targets Max             -12.5943
trainer/Q Targets Min             -65.503
trainer/Log Pis Mean                1.95058
trainer/Log Pis Std                 1.26274
trainer/Log Pis Max                 7.09704
trainer/Log Pis Min                -1.59266
trainer/Policy mu Mean              0.0368994
trainer/Policy mu Std               0.802111
trainer/Policy mu Max               2.79582
trainer/Policy mu Min              -2.8744
trainer/Policy log std Mean        -1.97963
trainer/Policy log std Std          0.603786
trainer/Policy log std Max         -0.342586
trainer/Policy log std Min         -2.77625
trainer/Alpha                       0.0888869
trainer/Alpha Loss                 -0.119607
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.488348
exploration/Rewards Std             0.706248
exploration/Rewards Max            -0.0102811
exploration/Rewards Min            -6.72315
exploration/Returns Mean          -48.8348
exploration/Returns Std            13.5271
exploration/Returns Max           -35.3077
exploration/Returns Min           -62.3618
exploration/Actions Mean            0.018222
exploration/Actions Std             0.214245
exploration/Actions Max             0.994451
exploration/Actions Min            -0.975781
exploration/Num Paths               2
exploration/Average Returns       -48.8348
evaluation/num steps total     360000
evaluation/num paths total       3600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.684379
evaluation/Rewards Std              0.84551
evaluation/Rewards Max             -0.0632186
evaluation/Rewards Min             -8.88264
evaluation/Returns Mean           -68.4379
evaluation/Returns Std             17.5284
evaluation/Returns Max            -32.4616
evaluation/Returns Min            -93.273
evaluation/Actions Mean            -0.0101389
evaluation/Actions Std              0.175609
evaluation/Actions Max              0.991546
evaluation/Actions Min             -0.996757
evaluation/Num Paths               10
evaluation/Average Returns        -68.4379
time/data storing (s)               0.00138944
time/evaluation sampling (s)        0.212922
time/exploration sampling (s)       0.0618
time/logging (s)                    0.00337822
time/saving (s)                     0.00198685
time/training (s)                   0.777379
time/epoch (s)                      1.05886
time/total (s)                    383.792
Epoch                             359
-----------------------------  ---------------
2019-04-21 01:18:08.998742 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 360 finished
-----------------------------  ---------------
replay_buffer/size              72400
trainer/QF1 Loss                    0.313367
trainer/QF2 Loss                    0.32376
trainer/Policy Loss                27.0613
trainer/Q1 Predictions Mean       -25.549
trainer/Q1 Predictions Std         11.8448
trainer/Q1 Predictions Max        -12.1836
trainer/Q1 Predictions Min        -75.2885
trainer/Q2 Predictions Mean       -25.5657
trainer/Q2 Predictions Std         11.8862
trainer/Q2 Predictions Max        -12.172
trainer/Q2 Predictions Min        -75.6833
trainer/Q Targets Mean            -26.0248
trainer/Q Targets Std              11.8731
trainer/Q Targets Max             -12.3892
trainer/Q Targets Min             -75.268
trainer/Log Pis Mean                2.16896
trainer/Log Pis Std                 1.24684
trainer/Log Pis Max                 6.77209
trainer/Log Pis Min                -2.48312
trainer/Policy mu Mean              0.0653063
trainer/Policy mu Std               0.827437
trainer/Policy mu Max               2.64277
trainer/Policy mu Min              -2.92614
trainer/Policy log std Mean        -1.96807
trainer/Policy log std Std          0.627843
trainer/Policy log std Max         -0.402326
trainer/Policy log std Min         -2.8872
trainer/Alpha                       0.0887195
trainer/Alpha Loss                  0.409295
exploration/num steps total     72400
exploration/num paths total       724
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.45358
exploration/Rewards Std             0.669959
exploration/Rewards Max            -0.00508281
exploration/Rewards Min            -5.20687
exploration/Returns Mean          -45.358
exploration/Returns Std            19.5427
exploration/Returns Max           -25.8153
exploration/Returns Min           -64.9007
exploration/Actions Mean            0.00180007
exploration/Actions Std             0.211625
exploration/Actions Max             0.995728
exploration/Actions Min            -0.995076
exploration/Num Paths               2
exploration/Average Returns       -45.358
evaluation/num steps total     361000
evaluation/num paths total       3610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.47523
evaluation/Rewards Std              0.9938
evaluation/Rewards Max             -0.0927388
evaluation/Rewards Min             -9.78345
evaluation/Returns Mean           -47.523
evaluation/Returns Std             22.0608
evaluation/Returns Max            -11.5329
evaluation/Returns Min            -94.8591
evaluation/Actions Mean             0.00640751
evaluation/Actions Std              0.183957
evaluation/Actions Max              0.993915
evaluation/Actions Min             -0.994537
evaluation/Num Paths               10
evaluation/Average Returns        -47.523
time/data storing (s)               0.00137798
time/evaluation sampling (s)        0.219897
time/exploration sampling (s)       0.0643322
time/logging (s)                    0.00336943
time/saving (s)                     0.00195592
time/training (s)                   0.775696
time/epoch (s)                      1.06663
time/total (s)                    384.863
Epoch                             360
-----------------------------  ---------------
2019-04-21 01:18:10.075493 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 361 finished
-----------------------------  ---------------
replay_buffer/size              72600
trainer/QF1 Loss                    1.88704
trainer/QF2 Loss                    1.92345
trainer/Policy Loss                24.9493
trainer/Q1 Predictions Mean       -23.4921
trainer/Q1 Predictions Std         11.8307
trainer/Q1 Predictions Max        -12.2744
trainer/Q1 Predictions Min        -92.2843
trainer/Q2 Predictions Mean       -23.4814
trainer/Q2 Predictions Std         11.8189
trainer/Q2 Predictions Max        -12.2455
trainer/Q2 Predictions Min        -92.5714
trainer/Q Targets Mean            -23.8808
trainer/Q Targets Std              12.2793
trainer/Q Targets Max              -0.32742
trainer/Q Targets Min             -94.0819
trainer/Log Pis Mean                2.01
trainer/Log Pis Std                 1.38066
trainer/Log Pis Max                 7.69496
trainer/Log Pis Min                -1.90241
trainer/Policy mu Mean              0.0526859
trainer/Policy mu Std               0.682582
trainer/Policy mu Max               2.74975
trainer/Policy mu Min              -3.13793
trainer/Policy log std Mean        -2.11529
trainer/Policy log std Std          0.564319
trainer/Policy log std Max         -0.511999
trainer/Policy log std Min         -2.87494
trainer/Alpha                       0.0905194
trainer/Alpha Loss                  0.0240309
exploration/num steps total     72600
exploration/num paths total       726
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.476946
exploration/Rewards Std             0.98063
exploration/Rewards Max            -0.0204088
exploration/Rewards Min            -8.24407
exploration/Returns Mean          -47.6946
exploration/Returns Std            30.5016
exploration/Returns Max           -17.1929
exploration/Returns Min           -78.1962
exploration/Actions Mean           -0.00164511
exploration/Actions Std             0.219371
exploration/Actions Max             0.991768
exploration/Actions Min            -0.993165
exploration/Num Paths               2
exploration/Average Returns       -47.6946
evaluation/num steps total     362000
evaluation/num paths total       3620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.433096
evaluation/Rewards Std              0.923217
evaluation/Rewards Max             -0.0648186
evaluation/Rewards Min             -9.52652
evaluation/Returns Mean           -43.3096
evaluation/Returns Std             27.5336
evaluation/Returns Max             -8.51082
evaluation/Returns Min            -87.2561
evaluation/Actions Mean             0.00266347
evaluation/Actions Std              0.180342
evaluation/Actions Max              0.991301
evaluation/Actions Min             -0.998073
evaluation/Num Paths               10
evaluation/Average Returns        -43.3096
time/data storing (s)               0.00135614
time/evaluation sampling (s)        0.224237
time/exploration sampling (s)       0.064244
time/logging (s)                    0.00340528
time/saving (s)                     0.00195953
time/training (s)                   0.771911
time/epoch (s)                      1.06711
time/total (s)                    385.934
Epoch                             361
-----------------------------  ---------------
2019-04-21 01:18:11.141834 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 362 finished
-----------------------------  ---------------
replay_buffer/size              72800
trainer/QF1 Loss                   17.8154
trainer/QF2 Loss                   17.9171
trainer/Policy Loss                25.5259
trainer/Q1 Predictions Mean       -24.1287
trainer/Q1 Predictions Std          9.80938
trainer/Q1 Predictions Max        -12.3358
trainer/Q1 Predictions Min        -57.8548
trainer/Q2 Predictions Mean       -24.1102
trainer/Q2 Predictions Std          9.76581
trainer/Q2 Predictions Max        -12.2737
trainer/Q2 Predictions Min        -57.2804
trainer/Q Targets Mean            -23.9292
trainer/Q Targets Std              10.5684
trainer/Q Targets Max              -0.492109
trainer/Q Targets Min             -59.5502
trainer/Log Pis Mean                2.03594
trainer/Log Pis Std                 1.21371
trainer/Log Pis Max                 7.00814
trainer/Log Pis Min                -0.583547
trainer/Policy mu Mean              0.0808846
trainer/Policy mu Std               0.762695
trainer/Policy mu Max               2.78539
trainer/Policy mu Min              -2.6522
trainer/Policy log std Mean        -2.0252
trainer/Policy log std Std          0.626677
trainer/Policy log std Max         -0.528669
trainer/Policy log std Min         -2.82681
trainer/Alpha                       0.0913269
trainer/Alpha Loss                  0.086017
exploration/num steps total     72800
exploration/num paths total       728
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.579713
exploration/Rewards Std             1.29185
exploration/Rewards Max            -0.0225459
exploration/Rewards Min            -9.7929
exploration/Returns Mean          -57.9713
exploration/Returns Std             9.76192
exploration/Returns Max           -48.2094
exploration/Returns Min           -67.7332
exploration/Actions Mean            0.0213419
exploration/Actions Std             0.226214
exploration/Actions Max             0.996451
exploration/Actions Min            -0.955163
exploration/Num Paths               2
exploration/Average Returns       -57.9713
evaluation/num steps total     363000
evaluation/num paths total       3630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.45313
evaluation/Rewards Std              1.03642
evaluation/Rewards Max             -0.0643947
evaluation/Rewards Min             -9.48772
evaluation/Returns Mean           -45.313
evaluation/Returns Std             22.5528
evaluation/Returns Max            -15.6522
evaluation/Returns Min            -92.3265
evaluation/Actions Mean             0.00523531
evaluation/Actions Std              0.200508
evaluation/Actions Max              0.99456
evaluation/Actions Min             -0.995768
evaluation/Num Paths               10
evaluation/Average Returns        -45.313
time/data storing (s)               0.00124713
time/evaluation sampling (s)        0.219808
time/exploration sampling (s)       0.0638118
time/logging (s)                    0.00338583
time/saving (s)                     0.00198294
time/training (s)                   0.767643
time/epoch (s)                      1.05788
time/total (s)                    386.996
Epoch                             362
-----------------------------  ---------------
2019-04-21 01:18:12.200614 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 363 finished
-----------------------------  ---------------
replay_buffer/size              73000
trainer/QF1 Loss                    9.02261
trainer/QF2 Loss                    9.09428
trainer/Policy Loss                25.2874
trainer/Q1 Predictions Mean       -23.6663
trainer/Q1 Predictions Std         10.3415
trainer/Q1 Predictions Max        -12.3177
trainer/Q1 Predictions Min        -65.4934
trainer/Q2 Predictions Mean       -23.6539
trainer/Q2 Predictions Std         10.3551
trainer/Q2 Predictions Max        -12.2292
trainer/Q2 Predictions Min        -64.1239
trainer/Q Targets Mean            -23.4559
trainer/Q Targets Std              10.7015
trainer/Q Targets Max              -0.556531
trainer/Q Targets Min             -67.1985
trainer/Log Pis Mean                2.13543
trainer/Log Pis Std                 1.08131
trainer/Log Pis Max                 4.7685
trainer/Log Pis Min                -1.62603
trainer/Policy mu Mean              0.0768169
trainer/Policy mu Std               0.723258
trainer/Policy mu Max               2.92586
trainer/Policy mu Min              -2.32756
trainer/Policy log std Mean        -2.08606
trainer/Policy log std Std          0.612133
trainer/Policy log std Max         -0.537958
trainer/Policy log std Min         -2.83008
trainer/Alpha                       0.0938043
trainer/Alpha Loss                  0.320515
exploration/num steps total     73000
exploration/num paths total       730
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.242939
exploration/Rewards Std             0.546652
exploration/Rewards Max            -0.00805801
exploration/Rewards Min            -5.37633
exploration/Returns Mean          -24.2939
exploration/Returns Std             4.67508
exploration/Returns Max           -19.6188
exploration/Returns Min           -28.969
exploration/Actions Mean            0.0154856
exploration/Actions Std             0.197723
exploration/Actions Max             0.991888
exploration/Actions Min            -0.973268
exploration/Num Paths               2
exploration/Average Returns       -24.2939
evaluation/num steps total     364000
evaluation/num paths total       3640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.444835
evaluation/Rewards Std              1.04953
evaluation/Rewards Max             -0.0931389
evaluation/Rewards Min             -9.64874
evaluation/Returns Mean           -44.4835
evaluation/Returns Std             27.9947
evaluation/Returns Max            -12.0862
evaluation/Returns Min            -81.6572
evaluation/Actions Mean            -0.0192726
evaluation/Actions Std              0.198322
evaluation/Actions Max              0.995933
evaluation/Actions Min             -0.996849
evaluation/Num Paths               10
evaluation/Average Returns        -44.4835
time/data storing (s)               0.00150525
time/evaluation sampling (s)        0.218632
time/exploration sampling (s)       0.0628556
time/logging (s)                    0.00338573
time/saving (s)                     0.00199828
time/training (s)                   0.760866
time/epoch (s)                      1.04924
time/total (s)                    388.05
Epoch                             363
-----------------------------  ---------------
2019-04-21 01:18:13.266151 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 364 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                    1.50666
trainer/QF2 Loss                    1.50301
trainer/Policy Loss                24.0273
trainer/Q1 Predictions Mean       -22.6768
trainer/Q1 Predictions Std         10.8592
trainer/Q1 Predictions Max        -12.0803
trainer/Q1 Predictions Min        -72.4478
trainer/Q2 Predictions Mean       -22.6945
trainer/Q2 Predictions Std         10.8974
trainer/Q2 Predictions Max        -12.0008
trainer/Q2 Predictions Min        -73.1787
trainer/Q Targets Mean            -22.7328
trainer/Q Targets Std              11.0322
trainer/Q Targets Max              -0.148102
trainer/Q Targets Min             -73.75
trainer/Log Pis Mean                1.94547
trainer/Log Pis Std                 1.36631
trainer/Log Pis Max                 5.51784
trainer/Log Pis Min                -4.88983
trainer/Policy mu Mean              0.0541355
trainer/Policy mu Std               0.695061
trainer/Policy mu Max               2.70018
trainer/Policy mu Min              -3.02035
trainer/Policy log std Mean        -2.11171
trainer/Policy log std Std          0.598102
trainer/Policy log std Max         -0.517945
trainer/Policy log std Min         -2.82062
trainer/Alpha                       0.0959338
trainer/Alpha Loss                 -0.127825
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.193529
exploration/Rewards Std             0.388707
exploration/Rewards Max            -0.00771023
exploration/Rewards Min            -3.99815
exploration/Returns Mean          -19.3529
exploration/Returns Std             4.32745
exploration/Returns Max           -15.0255
exploration/Returns Min           -23.6804
exploration/Actions Mean           -0.0126657
exploration/Actions Std             0.16127
exploration/Actions Max             0.683817
exploration/Actions Min            -0.9875
exploration/Num Paths               2
exploration/Average Returns       -19.3529
evaluation/num steps total     365000
evaluation/num paths total       3650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.394361
evaluation/Rewards Std              0.903257
evaluation/Rewards Max             -0.0815415
evaluation/Rewards Min             -9.55359
evaluation/Returns Mean           -39.4361
evaluation/Returns Std             27.1379
evaluation/Returns Max            -11.8364
evaluation/Returns Min            -85.1894
evaluation/Actions Mean             0.00125382
evaluation/Actions Std              0.178223
evaluation/Actions Max              0.994149
evaluation/Actions Min             -0.998073
evaluation/Num Paths               10
evaluation/Average Returns        -39.4361
time/data storing (s)               0.00122587
time/evaluation sampling (s)        0.213933
time/exploration sampling (s)       0.0640938
time/logging (s)                    0.00339107
time/saving (s)                     0.00199157
time/training (s)                   0.771917
time/epoch (s)                      1.05655
time/total (s)                    389.11
Epoch                             364
-----------------------------  ---------------
2019-04-21 01:18:14.327394 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 365 finished
-----------------------------  ----------------
replay_buffer/size              73400
trainer/QF1 Loss                   17.5255
trainer/QF2 Loss                   17.5935
trainer/Policy Loss                26.2294
trainer/Q1 Predictions Mean       -24.9529
trainer/Q1 Predictions Std          9.03613
trainer/Q1 Predictions Max        -12.1926
trainer/Q1 Predictions Min        -51.8468
trainer/Q2 Predictions Mean       -24.9586
trainer/Q2 Predictions Std          9.03638
trainer/Q2 Predictions Max        -12.1221
trainer/Q2 Predictions Min        -51.7103
trainer/Q Targets Mean            -24.572
trainer/Q Targets Std               9.69926
trainer/Q Targets Max              -0.710254
trainer/Q Targets Min             -51.6049
trainer/Log Pis Mean                1.82132
trainer/Log Pis Std                 1.4297
trainer/Log Pis Max                 5.74264
trainer/Log Pis Min                -6.02134
trainer/Policy mu Mean             -0.0246717
trainer/Policy mu Std               0.666305
trainer/Policy mu Max               2.70264
trainer/Policy mu Min              -2.6015
trainer/Policy log std Mean        -2.08749
trainer/Policy log std Std          0.588766
trainer/Policy log std Max         -0.489325
trainer/Policy log std Min         -2.78723
trainer/Alpha                       0.0972412
trainer/Alpha Loss                 -0.416442
exploration/num steps total     73400
exploration/num paths total       734
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.358873
exploration/Rewards Std             0.295429
exploration/Rewards Max            -0.0100393
exploration/Rewards Min            -2.78561
exploration/Returns Mean          -35.8873
exploration/Returns Std            12.7687
exploration/Returns Max           -23.1186
exploration/Returns Min           -48.656
exploration/Actions Mean            0.000136974
exploration/Actions Std             0.152691
exploration/Actions Max             0.917975
exploration/Actions Min            -0.978169
exploration/Num Paths               2
exploration/Average Returns       -35.8873
evaluation/num steps total     366000
evaluation/num paths total       3660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.528335
evaluation/Rewards Std              1.00977
evaluation/Rewards Max             -0.120604
evaluation/Rewards Min            -10.2272
evaluation/Returns Mean           -52.8335
evaluation/Returns Std             14.3589
evaluation/Returns Max            -21.4778
evaluation/Returns Min            -75.1123
evaluation/Actions Mean             0.00402974
evaluation/Actions Std              0.196004
evaluation/Actions Max              0.994634
evaluation/Actions Min             -0.993247
evaluation/Num Paths               10
evaluation/Average Returns        -52.8335
time/data storing (s)               0.00191984
time/evaluation sampling (s)        0.220036
time/exploration sampling (s)       0.0638612
time/logging (s)                    0.00333809
time/saving (s)                     0.00195817
time/training (s)                   0.760327
time/epoch (s)                      1.05144
time/total (s)                    390.166
Epoch                             365
-----------------------------  ----------------
2019-04-21 01:18:15.396318 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 366 finished
-----------------------------  ---------------
replay_buffer/size              73600
trainer/QF1 Loss                    1.59044
trainer/QF2 Loss                    1.62961
trainer/Policy Loss                24.7379
trainer/Q1 Predictions Mean       -23.3054
trainer/Q1 Predictions Std         10.9658
trainer/Q1 Predictions Max        -11.8877
trainer/Q1 Predictions Min        -78.0648
trainer/Q2 Predictions Mean       -23.3241
trainer/Q2 Predictions Std         10.8812
trainer/Q2 Predictions Max        -11.9042
trainer/Q2 Predictions Min        -77.1118
trainer/Q Targets Mean            -23.5339
trainer/Q Targets Std              11.2846
trainer/Q Targets Max              -0.298756
trainer/Q Targets Min             -79.098
trainer/Log Pis Mean                1.91735
trainer/Log Pis Std                 1.11098
trainer/Log Pis Max                 6.13845
trainer/Log Pis Min                -2.32197
trainer/Policy mu Mean              0.179968
trainer/Policy mu Std               0.625903
trainer/Policy mu Max               2.93
trainer/Policy mu Min              -2.44083
trainer/Policy log std Mean        -2.05426
trainer/Policy log std Std          0.541742
trainer/Policy log std Max         -0.431922
trainer/Policy log std Min         -2.74834
trainer/Alpha                       0.0959807
trainer/Alpha Loss                 -0.193683
exploration/num steps total     73600
exploration/num paths total       736
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.249575
exploration/Rewards Std             0.530557
exploration/Rewards Max            -0.015981
exploration/Rewards Min            -5.47563
exploration/Returns Mean          -24.9575
exploration/Returns Std             7.13971
exploration/Returns Max           -17.8178
exploration/Returns Min           -32.0972
exploration/Actions Mean            0.0249607
exploration/Actions Std             0.197107
exploration/Actions Max             0.996459
exploration/Actions Min            -0.912572
exploration/Num Paths               2
exploration/Average Returns       -24.9575
evaluation/num steps total     367000
evaluation/num paths total       3670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.690828
evaluation/Rewards Std              0.965692
evaluation/Rewards Max             -0.117946
evaluation/Rewards Min            -10.0408
evaluation/Returns Mean           -69.0828
evaluation/Returns Std             18.6333
evaluation/Returns Max            -37.3183
evaluation/Returns Min           -104.398
evaluation/Actions Mean            -0.0179588
evaluation/Actions Std              0.188768
evaluation/Actions Max              0.989862
evaluation/Actions Min             -0.99578
evaluation/Num Paths               10
evaluation/Average Returns        -69.0828
time/data storing (s)               0.00122736
time/evaluation sampling (s)        0.217723
time/exploration sampling (s)       0.0630057
time/logging (s)                    0.00276477
time/saving (s)                     0.00196653
time/training (s)                   0.771992
time/epoch (s)                      1.05868
time/total (s)                    391.229
Epoch                             366
-----------------------------  ---------------
2019-04-21 01:18:16.455247 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 367 finished
-----------------------------  ---------------
replay_buffer/size              73800
trainer/QF1 Loss                    1.9116
trainer/QF2 Loss                    1.92174
trainer/Policy Loss                23.7181
trainer/Q1 Predictions Mean       -22.277
trainer/Q1 Predictions Std         11.1576
trainer/Q1 Predictions Max        -11.7319
trainer/Q1 Predictions Min        -67.2281
trainer/Q2 Predictions Mean       -22.3056
trainer/Q2 Predictions Std         11.1512
trainer/Q2 Predictions Max        -11.7762
trainer/Q2 Predictions Min        -67.6763
trainer/Q Targets Mean            -22.1434
trainer/Q Targets Std              11.1036
trainer/Q Targets Max              -1.50931
trainer/Q Targets Min             -68.2329
trainer/Log Pis Mean                1.94784
trainer/Log Pis Std                 1.10267
trainer/Log Pis Max                 5.19355
trainer/Log Pis Min                -2.10359
trainer/Policy mu Mean              0.120025
trainer/Policy mu Std               0.679969
trainer/Policy mu Max               2.77439
trainer/Policy mu Min              -2.67799
trainer/Policy log std Mean        -2.05955
trainer/Policy log std Std          0.584139
trainer/Policy log std Max         -0.52433
trainer/Policy log std Min         -2.84556
trainer/Alpha                       0.0944891
trainer/Alpha Loss                 -0.123053
exploration/num steps total     73800
exploration/num paths total       738
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.71638
exploration/Rewards Std             1.2043
exploration/Rewards Max            -0.241533
exploration/Rewards Min            -9.44256
exploration/Returns Mean          -71.638
exploration/Returns Std            19.5399
exploration/Returns Max           -52.0981
exploration/Returns Min           -91.1779
exploration/Actions Mean           -0.040255
exploration/Actions Std             0.231509
exploration/Actions Max             0.6894
exploration/Actions Min            -0.997281
exploration/Num Paths               2
exploration/Average Returns       -71.638
evaluation/num steps total     368000
evaluation/num paths total       3680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.45209
evaluation/Rewards Std              0.833418
evaluation/Rewards Max             -0.0871305
evaluation/Rewards Min             -9.48067
evaluation/Returns Mean           -45.209
evaluation/Returns Std             19.3719
evaluation/Returns Max            -10.4551
evaluation/Returns Min            -69.6466
evaluation/Actions Mean            -0.00482012
evaluation/Actions Std              0.18174
evaluation/Actions Max              0.992997
evaluation/Actions Min             -0.995242
evaluation/Num Paths               10
evaluation/Average Returns        -45.209
time/data storing (s)               0.00121809
time/evaluation sampling (s)        0.223199
time/exploration sampling (s)       0.0648338
time/logging (s)                    0.00333493
time/saving (s)                     0.001949
time/training (s)                   0.755654
time/epoch (s)                      1.05019
time/total (s)                    392.283
Epoch                             367
-----------------------------  ---------------
2019-04-21 01:18:17.539773 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 368 finished
-----------------------------  ---------------
replay_buffer/size              74000
trainer/QF1 Loss                    8.76353
trainer/QF2 Loss                    8.7974
trainer/Policy Loss                25.0599
trainer/Q1 Predictions Mean       -23.5323
trainer/Q1 Predictions Std         11.9237
trainer/Q1 Predictions Max        -11.7448
trainer/Q1 Predictions Min        -85.2062
trainer/Q2 Predictions Mean       -23.4978
trainer/Q2 Predictions Std         11.884
trainer/Q2 Predictions Max        -11.7567
trainer/Q2 Predictions Min        -85.3203
trainer/Q Targets Mean            -23.546
trainer/Q Targets Std              12.2751
trainer/Q Targets Max              -0.529389
trainer/Q Targets Min             -86.5403
trainer/Log Pis Mean                1.95966
trainer/Log Pis Std                 1.09343
trainer/Log Pis Max                 5.10063
trainer/Log Pis Min                -2.17299
trainer/Policy mu Mean              0.0159382
trainer/Policy mu Std               0.70517
trainer/Policy mu Max               2.98877
trainer/Policy mu Min              -2.82799
trainer/Policy log std Mean        -2.00476
trainer/Policy log std Std          0.588135
trainer/Policy log std Max         -0.386176
trainer/Policy log std Min         -2.80169
trainer/Alpha                       0.0948626
trainer/Alpha Loss                 -0.0950005
exploration/num steps total     74000
exploration/num paths total       740
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.451593
exploration/Rewards Std             0.80348
exploration/Rewards Max            -0.0136591
exploration/Rewards Min            -7.36904
exploration/Returns Mean          -45.1593
exploration/Returns Std            29.3775
exploration/Returns Max           -15.7818
exploration/Returns Min           -74.5368
exploration/Actions Mean           -0.0264858
exploration/Actions Std             0.222595
exploration/Actions Max             0.965147
exploration/Actions Min            -0.999777
exploration/Num Paths               2
exploration/Average Returns       -45.1593
evaluation/num steps total     369000
evaluation/num paths total       3690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.532166
evaluation/Rewards Std              0.962742
evaluation/Rewards Max             -0.0280204
evaluation/Rewards Min             -9.75974
evaluation/Returns Mean           -53.2166
evaluation/Returns Std             28.996
evaluation/Returns Max             -9.22971
evaluation/Returns Min            -95.936
evaluation/Actions Mean            -0.0212582
evaluation/Actions Std              0.183439
evaluation/Actions Max              0.990001
evaluation/Actions Min             -0.996242
evaluation/Num Paths               10
evaluation/Average Returns        -53.2166
time/data storing (s)               0.00122333
time/evaluation sampling (s)        0.225014
time/exploration sampling (s)       0.0645612
time/logging (s)                    0.00339179
time/saving (s)                     0.0120796
time/training (s)                   0.769667
time/epoch (s)                      1.07594
time/total (s)                    393.364
Epoch                             368
-----------------------------  ---------------
2019-04-21 01:18:18.601890 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 369 finished
-----------------------------  ---------------
replay_buffer/size              74200
trainer/QF1 Loss                    0.106186
trainer/QF2 Loss                    0.116433
trainer/Policy Loss                23.6452
trainer/Q1 Predictions Mean       -22.3475
trainer/Q1 Predictions Std          9.42693
trainer/Q1 Predictions Max        -11.7988
trainer/Q1 Predictions Min        -44.094
trainer/Q2 Predictions Mean       -22.3083
trainer/Q2 Predictions Std          9.44316
trainer/Q2 Predictions Max        -11.7705
trainer/Q2 Predictions Min        -43.9199
trainer/Q Targets Mean            -22.5523
trainer/Q Targets Std               9.50852
trainer/Q Targets Max             -11.8411
trainer/Q Targets Min             -43.2638
trainer/Log Pis Mean                1.75806
trainer/Log Pis Std                 1.38672
trainer/Log Pis Max                 5.86828
trainer/Log Pis Min                -2.58204
trainer/Policy mu Mean              0.0440437
trainer/Policy mu Std               0.668859
trainer/Policy mu Max               2.62438
trainer/Policy mu Min              -2.52242
trainer/Policy log std Mean        -2.0177
trainer/Policy log std Std          0.562211
trainer/Policy log std Max         -0.582833
trainer/Policy log std Min         -2.75139
trainer/Alpha                       0.0946824
trainer/Alpha Loss                 -0.570329
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.687717
exploration/Rewards Std             1.41718
exploration/Rewards Max            -0.00404138
exploration/Rewards Min            -8.92448
exploration/Returns Mean          -68.7717
exploration/Returns Std            17.489
exploration/Returns Max           -51.2827
exploration/Returns Min           -86.2607
exploration/Actions Mean            0.00121798
exploration/Actions Std             0.265812
exploration/Actions Max             0.994426
exploration/Actions Min            -0.99857
exploration/Num Paths               2
exploration/Average Returns       -68.7717
evaluation/num steps total     370000
evaluation/num paths total       3700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.438673
evaluation/Rewards Std              1.08847
evaluation/Rewards Max             -0.110982
evaluation/Rewards Min            -10.7988
evaluation/Returns Mean           -43.8673
evaluation/Returns Std             19.3619
evaluation/Returns Max            -15.9465
evaluation/Returns Min            -67.6109
evaluation/Actions Mean             0.0216404
evaluation/Actions Std              0.202821
evaluation/Actions Max              0.9972
evaluation/Actions Min             -0.992081
evaluation/Num Paths               10
evaluation/Average Returns        -43.8673
time/data storing (s)               0.00151807
time/evaluation sampling (s)        0.217485
time/exploration sampling (s)       0.0646822
time/logging (s)                    0.00333663
time/saving (s)                     0.00155414
time/training (s)                   0.763529
time/epoch (s)                      1.0521
time/total (s)                    394.42
Epoch                             369
-----------------------------  ---------------
2019-04-21 01:18:19.670987 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 370 finished
-----------------------------  ---------------
replay_buffer/size              74400
trainer/QF1 Loss                    1.63999
trainer/QF2 Loss                    1.71198
trainer/Policy Loss                23.3705
trainer/Q1 Predictions Mean       -21.9134
trainer/Q1 Predictions Std         10.6798
trainer/Q1 Predictions Max        -11.747
trainer/Q1 Predictions Min        -73.2152
trainer/Q2 Predictions Mean       -21.8892
trainer/Q2 Predictions Std         10.6754
trainer/Q2 Predictions Max        -11.6892
trainer/Q2 Predictions Min        -72.5514
trainer/Q Targets Mean            -21.9954
trainer/Q Targets Std              11.1067
trainer/Q Targets Max              -0.199487
trainer/Q Targets Min             -77.2452
trainer/Log Pis Mean                2.02497
trainer/Log Pis Std                 1.31428
trainer/Log Pis Max                 7.17583
trainer/Log Pis Min                -1.95887
trainer/Policy mu Mean              0.109481
trainer/Policy mu Std               0.772248
trainer/Policy mu Max               2.89159
trainer/Policy mu Min              -2.27276
trainer/Policy log std Mean        -1.97019
trainer/Policy log std Std          0.637301
trainer/Policy log std Max         -0.426337
trainer/Policy log std Min         -2.81311
trainer/Alpha                       0.0950813
trainer/Alpha Loss                  0.058747
exploration/num steps total     74400
exploration/num paths total       744
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.529633
exploration/Rewards Std             0.28414
exploration/Rewards Max            -0.295926
exploration/Rewards Min            -3.08587
exploration/Returns Mean          -52.9633
exploration/Returns Std             2.10757
exploration/Returns Max           -50.8558
exploration/Returns Min           -55.0709
exploration/Actions Mean            0.0020751
exploration/Actions Std             0.18459
exploration/Actions Max             0.957252
exploration/Actions Min            -0.967341
exploration/Num Paths               2
exploration/Average Returns       -52.9633
evaluation/num steps total     371000
evaluation/num paths total       3710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.47991
evaluation/Rewards Std              1.08173
evaluation/Rewards Max             -0.0828901
evaluation/Rewards Min            -11.2725
evaluation/Returns Mean           -47.991
evaluation/Returns Std             27.5145
evaluation/Returns Max             -8.42342
evaluation/Returns Min           -103.281
evaluation/Actions Mean            -0.0105012
evaluation/Actions Std              0.191778
evaluation/Actions Max              0.995634
evaluation/Actions Min             -0.998194
evaluation/Num Paths               10
evaluation/Average Returns        -47.991
time/data storing (s)               0.00138361
time/evaluation sampling (s)        0.218231
time/exploration sampling (s)       0.0610856
time/logging (s)                    0.00251345
time/saving (s)                     0.0016059
time/training (s)                   0.773774
time/epoch (s)                      1.05859
time/total (s)                    395.483
Epoch                             370
-----------------------------  ---------------
2019-04-21 01:18:20.743631 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 371 finished
-----------------------------  ---------------
replay_buffer/size              74600
trainer/QF1 Loss                    8.65038
trainer/QF2 Loss                    8.70637
trainer/Policy Loss                23.1679
trainer/Q1 Predictions Mean       -21.8812
trainer/Q1 Predictions Std         10.4469
trainer/Q1 Predictions Max        -11.6947
trainer/Q1 Predictions Min        -72.1531
trainer/Q2 Predictions Mean       -21.9137
trainer/Q2 Predictions Std         10.4127
trainer/Q2 Predictions Max        -11.6931
trainer/Q2 Predictions Min        -71.7558
trainer/Q Targets Mean            -22.0392
trainer/Q Targets Std              10.9888
trainer/Q Targets Max              -0.685381
trainer/Q Targets Min             -75.7768
trainer/Log Pis Mean                2.0431
trainer/Log Pis Std                 1.27223
trainer/Log Pis Max                 6.11763
trainer/Log Pis Min                -2.55634
trainer/Policy mu Mean              0.135782
trainer/Policy mu Std               0.746975
trainer/Policy mu Max               2.88532
trainer/Policy mu Min              -2.10055
trainer/Policy log std Mean        -2.00464
trainer/Policy log std Std          0.603166
trainer/Policy log std Max         -0.501031
trainer/Policy log std Min         -2.80263
trainer/Alpha                       0.0940104
trainer/Alpha Loss                  0.101913
exploration/num steps total     74600
exploration/num paths total       746
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.632984
exploration/Rewards Std             1.22369
exploration/Rewards Max            -0.0132632
exploration/Rewards Min            -9.15512
exploration/Returns Mean          -63.2984
exploration/Returns Std            26.5521
exploration/Returns Max           -36.7463
exploration/Returns Min           -89.8505
exploration/Actions Mean           -0.0300032
exploration/Actions Std             0.260585
exploration/Actions Max             0.990096
exploration/Actions Min            -0.9971
exploration/Num Paths               2
exploration/Average Returns       -63.2984
evaluation/num steps total     372000
evaluation/num paths total       3720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.432158
evaluation/Rewards Std              0.907711
evaluation/Rewards Max             -0.0799087
evaluation/Rewards Min             -9.59032
evaluation/Returns Mean           -43.2158
evaluation/Returns Std             28.4211
evaluation/Returns Max            -10.1521
evaluation/Returns Min            -94.0061
evaluation/Actions Mean             0.00916114
evaluation/Actions Std              0.179795
evaluation/Actions Max              0.99439
evaluation/Actions Min             -0.993254
evaluation/Num Paths               10
evaluation/Average Returns        -43.2158
time/data storing (s)               0.00133254
time/evaluation sampling (s)        0.221234
time/exploration sampling (s)       0.0652536
time/logging (s)                    0.00339949
time/saving (s)                     0.0019954
time/training (s)                   0.770973
time/epoch (s)                      1.06419
time/total (s)                    396.551
Epoch                             371
-----------------------------  ---------------
2019-04-21 01:18:21.813259 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 372 finished
-----------------------------  ---------------
replay_buffer/size              74800
trainer/QF1 Loss                   19.0535
trainer/QF2 Loss                   19.058
trainer/Policy Loss                23.2785
trainer/Q1 Predictions Mean       -21.7683
trainer/Q1 Predictions Std          9.85324
trainer/Q1 Predictions Max        -11.6525
trainer/Q1 Predictions Min        -57.7082
trainer/Q2 Predictions Mean       -21.789
trainer/Q2 Predictions Std          9.88427
trainer/Q2 Predictions Max        -11.6333
trainer/Q2 Predictions Min        -57.805
trainer/Q Targets Mean            -21.0969
trainer/Q Targets Std              10.2182
trainer/Q Targets Max              -0.427119
trainer/Q Targets Min             -56.7992
trainer/Log Pis Mean                1.98195
trainer/Log Pis Std                 1.33047
trainer/Log Pis Max                 5.3803
trainer/Log Pis Min                -2.90566
trainer/Policy mu Mean              0.227322
trainer/Policy mu Std               0.720428
trainer/Policy mu Max               2.77266
trainer/Policy mu Min              -2.6753
trainer/Policy log std Mean        -2.03207
trainer/Policy log std Std          0.600297
trainer/Policy log std Max         -0.386815
trainer/Policy log std Min         -2.71749
trainer/Alpha                       0.0935997
trainer/Alpha Loss                 -0.0427625
exploration/num steps total     74800
exploration/num paths total       748
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.553113
exploration/Rewards Std             0.992404
exploration/Rewards Max            -0.00996861
exploration/Rewards Min            -6.90997
exploration/Returns Mean          -55.3113
exploration/Returns Std            17.3305
exploration/Returns Max           -37.9808
exploration/Returns Min           -72.6417
exploration/Actions Mean           -0.00360325
exploration/Actions Std             0.221523
exploration/Actions Max             0.996813
exploration/Actions Min            -0.994949
exploration/Num Paths               2
exploration/Average Returns       -55.3113
evaluation/num steps total     373000
evaluation/num paths total       3730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.552723
evaluation/Rewards Std              1.09697
evaluation/Rewards Max             -0.0922432
evaluation/Rewards Min             -9.66766
evaluation/Returns Mean           -55.2723
evaluation/Returns Std             20.4205
evaluation/Returns Max            -18.0465
evaluation/Returns Min            -87.6435
evaluation/Actions Mean             0.00383327
evaluation/Actions Std              0.191668
evaluation/Actions Max              0.993124
evaluation/Actions Min             -0.996337
evaluation/Num Paths               10
evaluation/Average Returns        -55.2723
time/data storing (s)               0.00128375
time/evaluation sampling (s)        0.221241
time/exploration sampling (s)       0.0664642
time/logging (s)                    0.00341323
time/saving (s)                     0.00197336
time/training (s)                   0.765461
time/epoch (s)                      1.05984
time/total (s)                    397.616
Epoch                             372
-----------------------------  ---------------
2019-04-21 01:18:22.883703 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 373 finished
-----------------------------  ---------------
replay_buffer/size              75000
trainer/QF1 Loss                   26.6987
trainer/QF2 Loss                   26.7758
trainer/Policy Loss                25.2722
trainer/Q1 Predictions Mean       -24.016
trainer/Q1 Predictions Std         12.7807
trainer/Q1 Predictions Max        -11.6542
trainer/Q1 Predictions Min        -82.6469
trainer/Q2 Predictions Mean       -24.0344
trainer/Q2 Predictions Std         12.7932
trainer/Q2 Predictions Max        -11.7732
trainer/Q2 Predictions Min        -82.9376
trainer/Q Targets Mean            -23.3427
trainer/Q Targets Std              13.74
trainer/Q Targets Max              -0.162291
trainer/Q Targets Min             -84.1102
trainer/Log Pis Mean                1.95066
trainer/Log Pis Std                 1.18965
trainer/Log Pis Max                 5.99388
trainer/Log Pis Min                -2.53145
trainer/Policy mu Mean              0.0350347
trainer/Policy mu Std               0.88188
trainer/Policy mu Max               2.67817
trainer/Policy mu Min              -3.02157
trainer/Policy log std Mean        -1.8534
trainer/Policy log std Std          0.645726
trainer/Policy log std Max         -0.485755
trainer/Policy log std Min         -2.68905
trainer/Alpha                       0.0918174
trainer/Alpha Loss                 -0.117817
exploration/num steps total     75000
exploration/num paths total       750
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.395304
exploration/Rewards Std             0.443564
exploration/Rewards Max            -0.00755875
exploration/Rewards Min            -4.52544
exploration/Returns Mean          -39.5304
exploration/Returns Std            11.1413
exploration/Returns Max           -28.3891
exploration/Returns Min           -50.6717
exploration/Actions Mean            0.00461955
exploration/Actions Std             0.179587
exploration/Actions Max             0.991956
exploration/Actions Min            -0.928556
exploration/Num Paths               2
exploration/Average Returns       -39.5304
evaluation/num steps total     374000
evaluation/num paths total       3740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.480399
evaluation/Rewards Std              0.694348
evaluation/Rewards Max             -0.0716502
evaluation/Rewards Min             -6.95383
evaluation/Returns Mean           -48.0399
evaluation/Returns Std             17.2832
evaluation/Returns Max             -9.03034
evaluation/Returns Min            -67.3959
evaluation/Actions Mean             0.0039141
evaluation/Actions Std              0.169737
evaluation/Actions Max              0.992919
evaluation/Actions Min             -0.991256
evaluation/Num Paths               10
evaluation/Average Returns        -48.0399
time/data storing (s)               0.0011829
time/evaluation sampling (s)        0.223167
time/exploration sampling (s)       0.0635099
time/logging (s)                    0.0033876
time/saving (s)                     0.00157243
time/training (s)                   0.767856
time/epoch (s)                      1.06068
time/total (s)                    398.681
Epoch                             373
-----------------------------  ---------------
2019-04-21 01:18:23.961532 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 374 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                    0.116958
trainer/QF2 Loss                    0.135565
trainer/Policy Loss                24.05
trainer/Q1 Predictions Mean       -22.4695
trainer/Q1 Predictions Std         10.1455
trainer/Q1 Predictions Max        -11.3273
trainer/Q1 Predictions Min        -50.9643
trainer/Q2 Predictions Mean       -22.4898
trainer/Q2 Predictions Std         10.1073
trainer/Q2 Predictions Max        -11.4063
trainer/Q2 Predictions Min        -50.8708
trainer/Q Targets Mean            -22.6569
trainer/Q Targets Std               9.99412
trainer/Q Targets Max             -11.6172
trainer/Q Targets Min             -50.9238
trainer/Log Pis Mean                2.03435
trainer/Log Pis Std                 1.17835
trainer/Log Pis Max                 5.66937
trainer/Log Pis Min                -1.9816
trainer/Policy mu Mean              0.0884286
trainer/Policy mu Std               0.726477
trainer/Policy mu Max               2.6914
trainer/Policy mu Min              -2.72224
trainer/Policy log std Mean        -2.12848
trainer/Policy log std Std          0.595206
trainer/Policy log std Max         -0.466888
trainer/Policy log std Min         -2.75821
trainer/Alpha                       0.09077
trainer/Alpha Loss                  0.0824185
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.55566
exploration/Rewards Std             0.580707
exploration/Rewards Max            -0.280945
exploration/Rewards Min            -5.19857
exploration/Returns Mean          -55.566
exploration/Returns Std             0.0449851
exploration/Returns Max           -55.521
exploration/Returns Min           -55.611
exploration/Actions Mean           -0.0363458
exploration/Actions Std             0.205018
exploration/Actions Max             0.611798
exploration/Actions Min            -0.996436
exploration/Num Paths               2
exploration/Average Returns       -55.566
evaluation/num steps total     375000
evaluation/num paths total       3750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.432192
evaluation/Rewards Std              0.586794
evaluation/Rewards Max             -0.109706
evaluation/Rewards Min             -7.11005
evaluation/Returns Mean           -43.2192
evaluation/Returns Std             16.5876
evaluation/Returns Max            -11.9657
evaluation/Returns Min            -63.6178
evaluation/Actions Mean             0.00214144
evaluation/Actions Std              0.159865
evaluation/Actions Max              0.995684
evaluation/Actions Min             -0.991256
evaluation/Num Paths               10
evaluation/Average Returns        -43.2192
time/data storing (s)               0.00122196
time/evaluation sampling (s)        0.219147
time/exploration sampling (s)       0.0625009
time/logging (s)                    0.00338494
time/saving (s)                     0.00196585
time/training (s)                   0.779818
time/epoch (s)                      1.06804
time/total (s)                    399.753
Epoch                             374
-----------------------------  ---------------
2019-04-21 01:18:25.036950 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 375 finished
-----------------------------  ---------------
replay_buffer/size              75400
trainer/QF1 Loss                    8.67796
trainer/QF2 Loss                    8.72363
trainer/Policy Loss                23.555
trainer/Q1 Predictions Mean       -22.2459
trainer/Q1 Predictions Std         10.5544
trainer/Q1 Predictions Max        -11.4512
trainer/Q1 Predictions Min        -70.1435
trainer/Q2 Predictions Mean       -22.2792
trainer/Q2 Predictions Std         10.5367
trainer/Q2 Predictions Max        -11.5656
trainer/Q2 Predictions Min        -69.8629
trainer/Q Targets Mean            -22.1869
trainer/Q Targets Std              10.9907
trainer/Q Targets Max              -0.82757
trainer/Q Targets Min             -74.9244
trainer/Log Pis Mean                1.90207
trainer/Log Pis Std                 1.46634
trainer/Log Pis Max                 5.55941
trainer/Log Pis Min                -4.44344
trainer/Policy mu Mean              0.0387983
trainer/Policy mu Std               0.748531
trainer/Policy mu Max               2.81999
trainer/Policy mu Min              -2.60714
trainer/Policy log std Mean        -2.02068
trainer/Policy log std Std          0.601514
trainer/Policy log std Max         -0.49701
trainer/Policy log std Min         -2.77903
trainer/Alpha                       0.0906827
trainer/Alpha Loss                 -0.235039
exploration/num steps total     75400
exploration/num paths total       754
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.648089
exploration/Rewards Std             1.51755
exploration/Rewards Max            -0.0160805
exploration/Rewards Min           -10.3821
exploration/Returns Mean          -64.8089
exploration/Returns Std            23.029
exploration/Returns Max           -41.7799
exploration/Returns Min           -87.8379
exploration/Actions Mean           -0.00608324
exploration/Actions Std             0.271994
exploration/Actions Max             0.996778
exploration/Actions Min            -0.999244
exploration/Num Paths               2
exploration/Average Returns       -64.8089
evaluation/num steps total     376000
evaluation/num paths total       3760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.426921
evaluation/Rewards Std              1.11113
evaluation/Rewards Max             -0.0647965
evaluation/Rewards Min            -10.8143
evaluation/Returns Mean           -42.6921
evaluation/Returns Std             25.2954
evaluation/Returns Max             -8.41029
evaluation/Returns Min            -88.9946
evaluation/Actions Mean             0.00117372
evaluation/Actions Std              0.196563
evaluation/Actions Max              0.993741
evaluation/Actions Min             -0.999005
evaluation/Num Paths               10
evaluation/Average Returns        -42.6921
time/data storing (s)               0.0012859
time/evaluation sampling (s)        0.221183
time/exploration sampling (s)       0.0656067
time/logging (s)                    0.00279163
time/saving (s)                     0.00196888
time/training (s)                   0.772197
time/epoch (s)                      1.06503
time/total (s)                    400.822
Epoch                             375
-----------------------------  ---------------
2019-04-21 01:18:26.094019 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 376 finished
-----------------------------  ---------------
replay_buffer/size              75600
trainer/QF1 Loss                    2.79067
trainer/QF2 Loss                    2.77532
trainer/Policy Loss                22.7087
trainer/Q1 Predictions Mean       -21.2839
trainer/Q1 Predictions Std          9.94106
trainer/Q1 Predictions Max        -11.7355
trainer/Q1 Predictions Min        -50.0294
trainer/Q2 Predictions Mean       -21.2564
trainer/Q2 Predictions Std          9.94737
trainer/Q2 Predictions Max        -11.6414
trainer/Q2 Predictions Min        -49.5597
trainer/Q Targets Mean            -21.0612
trainer/Q Targets Std              10.3421
trainer/Q Targets Max              -0.169843
trainer/Q Targets Min             -50.2799
trainer/Log Pis Mean                1.96451
trainer/Log Pis Std                 1.31423
trainer/Log Pis Max                 6.91436
trainer/Log Pis Min                -2.37931
trainer/Policy mu Mean              0.0703151
trainer/Policy mu Std               0.682922
trainer/Policy mu Max               2.67551
trainer/Policy mu Min              -2.56916
trainer/Policy log std Mean        -2.10837
trainer/Policy log std Std          0.572585
trainer/Policy log std Max         -0.41578
trainer/Policy log std Min         -2.81786
trainer/Alpha                       0.0906042
trainer/Alpha Loss                 -0.0852264
exploration/num steps total     75600
exploration/num paths total       756
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.342547
exploration/Rewards Std             0.31195
exploration/Rewards Max            -0.00743028
exploration/Rewards Min            -3.07869
exploration/Returns Mean          -34.2547
exploration/Returns Std            10.9493
exploration/Returns Max           -23.3054
exploration/Returns Min           -45.204
exploration/Actions Mean           -0.0207791
exploration/Actions Std             0.167755
exploration/Actions Max             0.359293
exploration/Actions Min            -0.980253
exploration/Num Paths               2
exploration/Average Returns       -34.2547
evaluation/num steps total     377000
evaluation/num paths total       3770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.491418
evaluation/Rewards Std              1.00767
evaluation/Rewards Max             -0.10774
evaluation/Rewards Min            -10.2321
evaluation/Returns Mean           -49.1418
evaluation/Returns Std             20.5856
evaluation/Returns Max            -18.2587
evaluation/Returns Min            -74.2025
evaluation/Actions Mean            -0.00859443
evaluation/Actions Std              0.189704
evaluation/Actions Max              0.99454
evaluation/Actions Min             -0.993119
evaluation/Num Paths               10
evaluation/Average Returns        -49.1418
time/data storing (s)               0.00122791
time/evaluation sampling (s)        0.226652
time/exploration sampling (s)       0.0647202
time/logging (s)                    0.00334989
time/saving (s)                     0.00197077
time/training (s)                   0.750554
time/epoch (s)                      1.04847
time/total (s)                    401.876
Epoch                             376
-----------------------------  ---------------
2019-04-21 01:18:27.170673 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 377 finished
-----------------------------  ---------------
replay_buffer/size              75800
trainer/QF1 Loss                    0.119826
trainer/QF2 Loss                    0.163026
trainer/Policy Loss                22.8063
trainer/Q1 Predictions Mean       -21.2836
trainer/Q1 Predictions Std         10.3223
trainer/Q1 Predictions Max        -11.6189
trainer/Q1 Predictions Min        -62.4101
trainer/Q2 Predictions Mean       -21.2652
trainer/Q2 Predictions Std         10.2861
trainer/Q2 Predictions Max        -11.6054
trainer/Q2 Predictions Min        -61.5298
trainer/Q Targets Mean            -21.452
trainer/Q Targets Std              10.579
trainer/Q Targets Max             -11.5183
trainer/Q Targets Min             -64.1923
trainer/Log Pis Mean                2.18164
trainer/Log Pis Std                 1.05204
trainer/Log Pis Max                 7.26269
trainer/Log Pis Min                -0.511943
trainer/Policy mu Mean              0.0682267
trainer/Policy mu Std               0.689046
trainer/Policy mu Max               2.80519
trainer/Policy mu Min              -2.64801
trainer/Policy log std Mean        -2.10779
trainer/Policy log std Std          0.567793
trainer/Policy log std Max         -0.43358
trainer/Policy log std Min         -2.85315
trainer/Alpha                       0.0918891
trainer/Alpha Loss                  0.433614
exploration/num steps total     75800
exploration/num paths total       758
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.580698
exploration/Rewards Std             1.18534
exploration/Rewards Max            -0.00775786
exploration/Rewards Min            -7.93261
exploration/Returns Mean          -58.0698
exploration/Returns Std             6.29036
exploration/Returns Max           -51.7794
exploration/Returns Min           -64.3601
exploration/Actions Mean            0.00659006
exploration/Actions Std             0.233427
exploration/Actions Max             0.997511
exploration/Actions Min            -0.99492
exploration/Num Paths               2
exploration/Average Returns       -58.0698
evaluation/num steps total     378000
evaluation/num paths total       3780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.446449
evaluation/Rewards Std              1.00931
evaluation/Rewards Max             -0.100292
evaluation/Rewards Min             -9.6293
evaluation/Returns Mean           -44.6449
evaluation/Returns Std             22.6303
evaluation/Returns Max            -14.8475
evaluation/Returns Min            -81.6629
evaluation/Actions Mean            -0.00417475
evaluation/Actions Std              0.199444
evaluation/Actions Max              0.994727
evaluation/Actions Min             -0.996634
evaluation/Num Paths               10
evaluation/Average Returns        -44.6449
time/data storing (s)               0.00123057
time/evaluation sampling (s)        0.218564
time/exploration sampling (s)       0.064986
time/logging (s)                    0.00336493
time/saving (s)                     0.00197641
time/training (s)                   0.776596
time/epoch (s)                      1.06672
time/total (s)                    402.947
Epoch                             377
-----------------------------  ---------------
2019-04-21 01:18:28.236933 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 378 finished
-----------------------------  ---------------
replay_buffer/size              76000
trainer/QF1 Loss                    0.290299
trainer/QF2 Loss                    0.328682
trainer/Policy Loss                23.5568
trainer/Q1 Predictions Mean       -22.321
trainer/Q1 Predictions Std         10.6229
trainer/Q1 Predictions Max        -11.4026
trainer/Q1 Predictions Min        -60.7619
trainer/Q2 Predictions Mean       -22.3451
trainer/Q2 Predictions Std         10.5823
trainer/Q2 Predictions Max        -11.4478
trainer/Q2 Predictions Min        -60.372
trainer/Q Targets Mean            -22.6399
trainer/Q Targets Std              10.8378
trainer/Q Targets Max             -11.3774
trainer/Q Targets Min             -63.7267
trainer/Log Pis Mean                2.04822
trainer/Log Pis Std                 1.17495
trainer/Log Pis Max                 6.0774
trainer/Log Pis Min                -2.19651
trainer/Policy mu Mean              0.103841
trainer/Policy mu Std               0.794254
trainer/Policy mu Max               2.82732
trainer/Policy mu Min              -2.59749
trainer/Policy log std Mean        -1.93277
trainer/Policy log std Std          0.622256
trainer/Policy log std Max         -0.323629
trainer/Policy log std Min         -2.73988
trainer/Alpha                       0.093894
trainer/Alpha Loss                  0.114081
exploration/num steps total     76000
exploration/num paths total       760
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.412556
exploration/Rewards Std             1.1876
exploration/Rewards Max            -0.0176646
exploration/Rewards Min            -9.17649
exploration/Returns Mean          -41.2556
exploration/Returns Std            21.5411
exploration/Returns Max           -19.7145
exploration/Returns Min           -62.7968
exploration/Actions Mean            0.0229803
exploration/Actions Std             0.219864
exploration/Actions Max             0.999759
exploration/Actions Min            -0.984077
exploration/Num Paths               2
exploration/Average Returns       -41.2556
evaluation/num steps total     379000
evaluation/num paths total       3790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.474441
evaluation/Rewards Std              0.971772
evaluation/Rewards Max             -0.0830733
evaluation/Rewards Min            -10.5034
evaluation/Returns Mean           -47.4441
evaluation/Returns Std             23.2565
evaluation/Returns Max            -11.7893
evaluation/Returns Min            -91.9106
evaluation/Actions Mean            -0.00642273
evaluation/Actions Std              0.184362
evaluation/Actions Max              0.993282
evaluation/Actions Min             -0.998122
evaluation/Num Paths               10
evaluation/Average Returns        -47.4441
time/data storing (s)               0.00134038
time/evaluation sampling (s)        0.214895
time/exploration sampling (s)       0.0621678
time/logging (s)                    0.00336353
time/saving (s)                     0.00168271
time/training (s)                   0.77396
time/epoch (s)                      1.05741
time/total (s)                    404.007
Epoch                             378
-----------------------------  ---------------
2019-04-21 01:18:29.309491 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 379 finished
-----------------------------  ---------------
replay_buffer/size              76200
trainer/QF1 Loss                    0.108566
trainer/QF2 Loss                    0.0777245
trainer/Policy Loss                24.9313
trainer/Q1 Predictions Mean       -23.2057
trainer/Q1 Predictions Std         11.222
trainer/Q1 Predictions Max        -11.2873
trainer/Q1 Predictions Min        -69.8959
trainer/Q2 Predictions Mean       -23.2379
trainer/Q2 Predictions Std         11.2571
trainer/Q2 Predictions Max        -11.3063
trainer/Q2 Predictions Min        -70.6124
trainer/Q Targets Mean            -23.4387
trainer/Q Targets Std              11.338
trainer/Q Targets Max             -11.3999
trainer/Q Targets Min             -71.3303
trainer/Log Pis Mean                2.2458
trainer/Log Pis Std                 1.06857
trainer/Log Pis Max                 6.12303
trainer/Log Pis Min                -1.16653
trainer/Policy mu Mean              0.00565437
trainer/Policy mu Std               0.722792
trainer/Policy mu Max               2.33605
trainer/Policy mu Min              -3.11034
trainer/Policy log std Mean        -2.12082
trainer/Policy log std Std          0.592539
trainer/Policy log std Max         -0.488594
trainer/Policy log std Min         -2.81428
trainer/Alpha                       0.0933768
trainer/Alpha Loss                  0.582825
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.230126
exploration/Rewards Std             0.371649
exploration/Rewards Max            -0.0199645
exploration/Rewards Min            -4.07696
exploration/Returns Mean          -23.0126
exploration/Returns Std             4.52531
exploration/Returns Max           -18.4873
exploration/Returns Min           -27.5379
exploration/Actions Mean            0.0142578
exploration/Actions Std             0.177089
exploration/Actions Max             0.994752
exploration/Actions Min            -0.795257
exploration/Num Paths               2
exploration/Average Returns       -23.0126
evaluation/num steps total     380000
evaluation/num paths total       3800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.322953
evaluation/Rewards Std              0.647887
evaluation/Rewards Max             -0.12442
evaluation/Rewards Min             -7.87667
evaluation/Returns Mean           -32.2953
evaluation/Returns Std             17.8839
evaluation/Returns Max            -14.4252
evaluation/Returns Min            -72.791
evaluation/Actions Mean             0.0114636
evaluation/Actions Std              0.152432
evaluation/Actions Max              0.990098
evaluation/Actions Min             -0.989347
evaluation/Num Paths               10
evaluation/Average Returns        -32.2953
time/data storing (s)               0.00122037
time/evaluation sampling (s)        0.218068
time/exploration sampling (s)       0.0628994
time/logging (s)                    0.00339002
time/saving (s)                     0.00199297
time/training (s)                   0.776951
time/epoch (s)                      1.06452
time/total (s)                    405.076
Epoch                             379
-----------------------------  ---------------
2019-04-21 01:18:30.369910 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 380 finished
-----------------------------  ---------------
replay_buffer/size              76400
trainer/QF1 Loss                    1.30635
trainer/QF2 Loss                    1.30722
trainer/Policy Loss                24.2008
trainer/Q1 Predictions Mean       -22.716
trainer/Q1 Predictions Std          9.04293
trainer/Q1 Predictions Max        -11.1283
trainer/Q1 Predictions Min        -49.9551
trainer/Q2 Predictions Mean       -22.7274
trainer/Q2 Predictions Std          9.04179
trainer/Q2 Predictions Max        -11.1524
trainer/Q2 Predictions Min        -50.0036
trainer/Q Targets Mean            -22.8406
trainer/Q Targets Std               9.23216
trainer/Q Targets Max              -0.14355
trainer/Q Targets Min             -49.7089
trainer/Log Pis Mean                1.99615
trainer/Log Pis Std                 1.07698
trainer/Log Pis Max                 3.75897
trainer/Log Pis Min                -2.00721
trainer/Policy mu Mean             -0.0317372
trainer/Policy mu Std               0.638247
trainer/Policy mu Max               2.2174
trainer/Policy mu Min              -2.34695
trainer/Policy log std Mean        -2.13325
trainer/Policy log std Std          0.565445
trainer/Policy log std Max         -0.597965
trainer/Policy log std Min         -2.84023
trainer/Alpha                       0.0953919
trainer/Alpha Loss                 -0.00905364
exploration/num steps total     76400
exploration/num paths total       764
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.56946
exploration/Rewards Std             0.499965
exploration/Rewards Max            -0.29729
exploration/Rewards Min            -5.22865
exploration/Returns Mean          -56.946
exploration/Returns Std             3.51134
exploration/Returns Max           -53.4347
exploration/Returns Min           -60.4574
exploration/Actions Mean           -0.028737
exploration/Actions Std             0.195678
exploration/Actions Max             0.834112
exploration/Actions Min            -0.988235
exploration/Num Paths               2
exploration/Average Returns       -56.946
evaluation/num steps total     381000
evaluation/num paths total       3810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.414153
evaluation/Rewards Std              0.889028
evaluation/Rewards Max             -0.0597043
evaluation/Rewards Min             -9.13438
evaluation/Returns Mean           -41.4153
evaluation/Returns Std             17.7493
evaluation/Returns Max            -10.5548
evaluation/Returns Min            -61.3942
evaluation/Actions Mean            -0.00296212
evaluation/Actions Std              0.18491
evaluation/Actions Max              0.993161
evaluation/Actions Min             -0.988442
evaluation/Num Paths               10
evaluation/Average Returns        -41.4153
time/data storing (s)               0.00125209
time/evaluation sampling (s)        0.223958
time/exploration sampling (s)       0.0650859
time/logging (s)                    0.00336413
time/saving (s)                     0.00195478
time/training (s)                   0.754998
time/epoch (s)                      1.05061
time/total (s)                    406.131
Epoch                             380
-----------------------------  ---------------
2019-04-21 01:18:31.450079 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 381 finished
-----------------------------  ----------------
replay_buffer/size              76600
trainer/QF1 Loss                   15.8306
trainer/QF2 Loss                   15.8119
trainer/Policy Loss                23.1039
trainer/Q1 Predictions Mean       -21.7325
trainer/Q1 Predictions Std         11.6725
trainer/Q1 Predictions Max        -11.2591
trainer/Q1 Predictions Min        -84.1338
trainer/Q2 Predictions Mean       -21.7379
trainer/Q2 Predictions Std         11.6738
trainer/Q2 Predictions Max        -11.2702
trainer/Q2 Predictions Min        -84.0512
trainer/Q Targets Mean            -21.4748
trainer/Q Targets Std              12.1901
trainer/Q Targets Max              -0.736581
trainer/Q Targets Min             -85.4693
trainer/Log Pis Mean                1.94734
trainer/Log Pis Std                 1.15932
trainer/Log Pis Max                 7.39773
trainer/Log Pis Min                -1.20342
trainer/Policy mu Mean              0.0468407
trainer/Policy mu Std               0.708816
trainer/Policy mu Max               2.53277
trainer/Policy mu Min              -2.92452
trainer/Policy log std Mean        -2.04722
trainer/Policy log std Std          0.579801
trainer/Policy log std Max         -0.49496
trainer/Policy log std Min         -2.74572
trainer/Alpha                       0.0978993
trainer/Alpha Loss                 -0.122376
exploration/num steps total     76600
exploration/num paths total       766
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.712833
exploration/Rewards Std             1.16981
exploration/Rewards Max            -0.261792
exploration/Rewards Min            -9.46958
exploration/Returns Mean          -71.2833
exploration/Returns Std            18.7495
exploration/Returns Max           -52.5339
exploration/Returns Min           -90.0328
exploration/Actions Mean           -0.0236337
exploration/Actions Std             0.217051
exploration/Actions Max             0.890504
exploration/Actions Min            -0.998426
exploration/Num Paths               2
exploration/Average Returns       -71.2833
evaluation/num steps total     382000
evaluation/num paths total       3820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.609041
evaluation/Rewards Std              1.16747
evaluation/Rewards Max             -0.118021
evaluation/Rewards Min            -10.1629
evaluation/Returns Mean           -60.9041
evaluation/Returns Std             20.3038
evaluation/Returns Max            -30.6206
evaluation/Returns Min            -98.1514
evaluation/Actions Mean             0.000260342
evaluation/Actions Std              0.207386
evaluation/Actions Max              0.993384
evaluation/Actions Min             -0.996651
evaluation/Num Paths               10
evaluation/Average Returns        -60.9041
time/data storing (s)               0.00177749
time/evaluation sampling (s)        0.225316
time/exploration sampling (s)       0.0632171
time/logging (s)                    0.00338797
time/saving (s)                     0.00161842
time/training (s)                   0.775267
time/epoch (s)                      1.07058
time/total (s)                    407.206
Epoch                             381
-----------------------------  ----------------
2019-04-21 01:18:32.526271 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 382 finished
-----------------------------  ---------------
replay_buffer/size              76800
trainer/QF1 Loss                    9.74167
trainer/QF2 Loss                    9.69455
trainer/Policy Loss                22.9241
trainer/Q1 Predictions Mean       -21.4092
trainer/Q1 Predictions Std          8.73472
trainer/Q1 Predictions Max        -11.3014
trainer/Q1 Predictions Min        -46.9981
trainer/Q2 Predictions Mean       -21.3926
trainer/Q2 Predictions Std          8.76116
trainer/Q2 Predictions Max        -11.2104
trainer/Q2 Predictions Min        -47.3676
trainer/Q Targets Mean            -21.2767
trainer/Q Targets Std               9.36302
trainer/Q Targets Max              -0.360384
trainer/Q Targets Min             -47.4626
trainer/Log Pis Mean                1.94622
trainer/Log Pis Std                 1.19732
trainer/Log Pis Max                 5.85085
trainer/Log Pis Min                -1.80708
trainer/Policy mu Mean              0.0805342
trainer/Policy mu Std               0.721176
trainer/Policy mu Max               2.70149
trainer/Policy mu Min              -2.45388
trainer/Policy log std Mean        -2.0593
trainer/Policy log std Std          0.579556
trainer/Policy log std Max         -0.507963
trainer/Policy log std Min         -2.6856
trainer/Alpha                       0.097044
trainer/Alpha Loss                 -0.125455
exploration/num steps total     76800
exploration/num paths total       768
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.338405
exploration/Rewards Std             0.931654
exploration/Rewards Max            -0.0129155
exploration/Rewards Min            -7.90115
exploration/Returns Mean          -33.8405
exploration/Returns Std            12.4315
exploration/Returns Max           -21.409
exploration/Returns Min           -46.2721
exploration/Actions Mean            0.0259828
exploration/Actions Std             0.221825
exploration/Actions Max             0.997573
exploration/Actions Min            -0.994578
exploration/Num Paths               2
exploration/Average Returns       -33.8405
evaluation/num steps total     383000
evaluation/num paths total       3830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.547973
evaluation/Rewards Std              1.03745
evaluation/Rewards Max             -0.0429269
evaluation/Rewards Min             -9.17
evaluation/Returns Mean           -54.7973
evaluation/Returns Std             18.8
evaluation/Returns Max            -23.5905
evaluation/Returns Min            -91.8564
evaluation/Actions Mean             0.00449594
evaluation/Actions Std              0.201974
evaluation/Actions Max              0.99297
evaluation/Actions Min             -0.995107
evaluation/Num Paths               10
evaluation/Average Returns        -54.7973
time/data storing (s)               0.00129365
time/evaluation sampling (s)        0.224495
time/exploration sampling (s)       0.0646115
time/logging (s)                    0.00336256
time/saving (s)                     0.0019641
time/training (s)                   0.770666
time/epoch (s)                      1.06639
time/total (s)                    408.277
Epoch                             382
-----------------------------  ---------------
2019-04-21 01:18:33.585352 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 383 finished
-----------------------------  ---------------
replay_buffer/size              77000
trainer/QF1 Loss                    0.256808
trainer/QF2 Loss                    0.258489
trainer/Policy Loss                22.0084
trainer/Q1 Predictions Mean       -20.6297
trainer/Q1 Predictions Std          8.36031
trainer/Q1 Predictions Max        -11.2399
trainer/Q1 Predictions Min        -34.491
trainer/Q2 Predictions Mean       -20.6366
trainer/Q2 Predictions Std          8.36178
trainer/Q2 Predictions Max        -11.206
trainer/Q2 Predictions Min        -34.5378
trainer/Q Targets Mean            -21.0134
trainer/Q Targets Std               8.62725
trainer/Q Targets Max             -11.2682
trainer/Q Targets Min             -35.2845
trainer/Log Pis Mean                1.94281
trainer/Log Pis Std                 1.1013
trainer/Log Pis Max                 4.62959
trainer/Log Pis Min                -3.27661
trainer/Policy mu Mean              0.0743214
trainer/Policy mu Std               0.625915
trainer/Policy mu Max               2.5608
trainer/Policy mu Min              -2.12632
trainer/Policy log std Mean        -2.04153
trainer/Policy log std Std          0.556204
trainer/Policy log std Max         -0.496166
trainer/Policy log std Min         -2.62921
trainer/Alpha                       0.0970649
trainer/Alpha Loss                 -0.133367
exploration/num steps total     77000
exploration/num paths total       770
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407744
exploration/Rewards Std             0.609835
exploration/Rewards Max            -0.0187911
exploration/Rewards Min            -6.23699
exploration/Returns Mean          -40.7744
exploration/Returns Std            22.5879
exploration/Returns Max           -18.1866
exploration/Returns Min           -63.3623
exploration/Actions Mean            0.00240545
exploration/Actions Std             0.205845
exploration/Actions Max             0.978104
exploration/Actions Min            -0.987862
exploration/Num Paths               2
exploration/Average Returns       -40.7744
evaluation/num steps total     384000
evaluation/num paths total       3840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.6135
evaluation/Rewards Std              1.03411
evaluation/Rewards Max             -0.143172
evaluation/Rewards Min             -9.53336
evaluation/Returns Mean           -61.35
evaluation/Returns Std             19.3808
evaluation/Returns Max            -29.8314
evaluation/Returns Min            -87.4395
evaluation/Actions Mean            -0.00916001
evaluation/Actions Std              0.198404
evaluation/Actions Max              0.991761
evaluation/Actions Min             -0.997475
evaluation/Num Paths               10
evaluation/Average Returns        -61.35
time/data storing (s)               0.00121918
time/evaluation sampling (s)        0.227131
time/exploration sampling (s)       0.0648982
time/logging (s)                    0.00335477
time/saving (s)                     0.00197989
time/training (s)                   0.7506
time/epoch (s)                      1.04918
time/total (s)                    409.33
Epoch                             383
-----------------------------  ---------------
2019-04-21 01:18:34.660987 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 384 finished
-----------------------------  ---------------
replay_buffer/size              77200
trainer/QF1 Loss                    4.50184
trainer/QF2 Loss                    4.50307
trainer/Policy Loss                23.2339
trainer/Q1 Predictions Mean       -21.8184
trainer/Q1 Predictions Std         11.0059
trainer/Q1 Predictions Max        -11.0459
trainer/Q1 Predictions Min        -65.4202
trainer/Q2 Predictions Mean       -21.8092
trainer/Q2 Predictions Std         10.9664
trainer/Q2 Predictions Max        -11.0323
trainer/Q2 Predictions Min        -64.9951
trainer/Q Targets Mean            -21.8274
trainer/Q Targets Std              11.7536
trainer/Q Targets Max              -0.0365474
trainer/Q Targets Min             -68.4253
trainer/Log Pis Mean                2.03252
trainer/Log Pis Std                 1.15821
trainer/Log Pis Max                 6.81649
trainer/Log Pis Min                -3.45289
trainer/Policy mu Mean              0.117485
trainer/Policy mu Std               0.802273
trainer/Policy mu Max               2.83165
trainer/Policy mu Min              -2.74351
trainer/Policy log std Mean        -2.01473
trainer/Policy log std Std          0.643766
trainer/Policy log std Max         -0.406959
trainer/Policy log std Min         -2.7777
trainer/Alpha                       0.0970573
trainer/Alpha Loss                  0.0758621
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.513266
exploration/Rewards Std             1.04526
exploration/Rewards Max            -0.02069
exploration/Rewards Min            -8.50436
exploration/Returns Mean          -51.3266
exploration/Returns Std             2.10141
exploration/Returns Max           -49.2252
exploration/Returns Min           -53.428
exploration/Actions Mean            0.0173064
exploration/Actions Std             0.223031
exploration/Actions Max             0.998298
exploration/Actions Min            -0.946189
exploration/Num Paths               2
exploration/Average Returns       -51.3266
evaluation/num steps total     385000
evaluation/num paths total       3850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.519972
evaluation/Rewards Std              1.3573
evaluation/Rewards Max             -0.058931
evaluation/Rewards Min            -10.6016
evaluation/Returns Mean           -51.9972
evaluation/Returns Std             24.6531
evaluation/Returns Max            -16.4067
evaluation/Returns Min            -96.9917
evaluation/Actions Mean             0.00816278
evaluation/Actions Std              0.20583
evaluation/Actions Max              0.994702
evaluation/Actions Min             -0.997709
evaluation/Num Paths               10
evaluation/Average Returns        -51.9972
time/data storing (s)               0.00133258
time/evaluation sampling (s)        0.223014
time/exploration sampling (s)       0.0662757
time/logging (s)                    0.0035189
time/saving (s)                     0.00197293
time/training (s)                   0.769744
time/epoch (s)                      1.06586
time/total (s)                    410.4
Epoch                             384
-----------------------------  ---------------
2019-04-21 01:18:35.740700 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 385 finished
-----------------------------  ---------------
replay_buffer/size              77400
trainer/QF1 Loss                    7.7184
trainer/QF2 Loss                    7.79662
trainer/Policy Loss                24.5829
trainer/Q1 Predictions Mean       -22.9596
trainer/Q1 Predictions Std         11.8828
trainer/Q1 Predictions Max        -11.1654
trainer/Q1 Predictions Min        -88.7294
trainer/Q2 Predictions Mean       -22.9596
trainer/Q2 Predictions Std         11.8729
trainer/Q2 Predictions Max        -11.1355
trainer/Q2 Predictions Min        -88.8395
trainer/Q Targets Mean            -22.8792
trainer/Q Targets Std              12.1887
trainer/Q Targets Max              -0.492978
trainer/Q Targets Min             -89.5944
trainer/Log Pis Mean                2.20308
trainer/Log Pis Std                 1.13608
trainer/Log Pis Max                 8.20946
trainer/Log Pis Min                -1.16491
trainer/Policy mu Mean             -0.0244166
trainer/Policy mu Std               0.752617
trainer/Policy mu Max               2.75235
trainer/Policy mu Min              -3.19768
trainer/Policy log std Mean        -2.03477
trainer/Policy log std Std          0.603888
trainer/Policy log std Max         -0.338684
trainer/Policy log std Min         -2.73041
trainer/Alpha                       0.0981593
trainer/Alpha Loss                  0.471399
exploration/num steps total     77400
exploration/num paths total       774
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.223553
exploration/Rewards Std             0.400018
exploration/Rewards Max            -0.0100889
exploration/Rewards Min            -4.05152
exploration/Returns Mean          -22.3553
exploration/Returns Std             1.31388
exploration/Returns Max           -21.0414
exploration/Returns Min           -23.6692
exploration/Actions Mean            0.00979789
exploration/Actions Std             0.185961
exploration/Actions Max             0.967754
exploration/Actions Min            -0.979422
exploration/Num Paths               2
exploration/Average Returns       -22.3553
evaluation/num steps total     386000
evaluation/num paths total       3860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.400972
evaluation/Rewards Std              0.942429
evaluation/Rewards Max             -0.077118
evaluation/Rewards Min            -10.1295
evaluation/Returns Mean           -40.0972
evaluation/Returns Std             26.5783
evaluation/Returns Max             -8.8705
evaluation/Returns Min            -92.6808
evaluation/Actions Mean             0.0166246
evaluation/Actions Std              0.179113
evaluation/Actions Max              0.992913
evaluation/Actions Min             -0.996072
evaluation/Num Paths               10
evaluation/Average Returns        -40.0972
time/data storing (s)               0.00134463
time/evaluation sampling (s)        0.224376
time/exploration sampling (s)       0.066903
time/logging (s)                    0.00319886
time/saving (s)                     0.00196055
time/training (s)                   0.771552
time/epoch (s)                      1.06933
time/total (s)                    411.474
Epoch                             385
-----------------------------  ---------------
2019-04-21 01:18:36.814192 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 386 finished
-----------------------------  ---------------
replay_buffer/size              77600
trainer/QF1 Loss                    1.74805
trainer/QF2 Loss                    1.80138
trainer/Policy Loss                23.0537
trainer/Q1 Predictions Mean       -21.7488
trainer/Q1 Predictions Std         10.5192
trainer/Q1 Predictions Max        -11.0882
trainer/Q1 Predictions Min        -67.1215
trainer/Q2 Predictions Mean       -21.7631
trainer/Q2 Predictions Std         10.4978
trainer/Q2 Predictions Max        -11.0597
trainer/Q2 Predictions Min        -66.5503
trainer/Q Targets Mean            -21.9174
trainer/Q Targets Std              10.8915
trainer/Q Targets Max              -1.57573
trainer/Q Targets Min             -69.8554
trainer/Log Pis Mean                1.90756
trainer/Log Pis Std                 1.10154
trainer/Log Pis Max                 5.56503
trainer/Log Pis Min                -2.36618
trainer/Policy mu Mean              0.104105
trainer/Policy mu Std               0.739078
trainer/Policy mu Max               2.92094
trainer/Policy mu Min              -2.69296
trainer/Policy log std Mean        -1.96002
trainer/Policy log std Std          0.583592
trainer/Policy log std Max         -0.322009
trainer/Policy log std Min         -2.62609
trainer/Alpha                       0.0987813
trainer/Alpha Loss                 -0.213964
exploration/num steps total     77600
exploration/num paths total       776
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.392148
exploration/Rewards Std             1.12478
exploration/Rewards Max            -0.015708
exploration/Rewards Min            -8.51101
exploration/Returns Mean          -39.2148
exploration/Returns Std            15.0169
exploration/Returns Max           -24.1979
exploration/Returns Min           -54.2318
exploration/Actions Mean            0.0279761
exploration/Actions Std             0.218447
exploration/Actions Max             0.997274
exploration/Actions Min            -0.830639
exploration/Num Paths               2
exploration/Average Returns       -39.2148
evaluation/num steps total     387000
evaluation/num paths total       3870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.423052
evaluation/Rewards Std              1.09344
evaluation/Rewards Max             -0.0430529
evaluation/Rewards Min             -9.66263
evaluation/Returns Mean           -42.3052
evaluation/Returns Std             22.7184
evaluation/Returns Max             -4.89994
evaluation/Returns Min            -80.7888
evaluation/Actions Mean             0.0102084
evaluation/Actions Std              0.199394
evaluation/Actions Max              0.992681
evaluation/Actions Min             -0.993931
evaluation/Num Paths               10
evaluation/Average Returns        -42.3052
time/data storing (s)               0.00124086
time/evaluation sampling (s)        0.22414
time/exploration sampling (s)       0.0647467
time/logging (s)                    0.0033503
time/saving (s)                     0.00196647
time/training (s)                   0.769327
time/epoch (s)                      1.06477
time/total (s)                    412.543
Epoch                             386
-----------------------------  ---------------
2019-04-21 01:18:37.892909 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 387 finished
-----------------------------  ---------------
replay_buffer/size              77800
trainer/QF1 Loss                    0.114402
trainer/QF2 Loss                    0.100434
trainer/Policy Loss                21.445
trainer/Q1 Predictions Mean       -20.0929
trainer/Q1 Predictions Std          9.08385
trainer/Q1 Predictions Max        -11.013
trainer/Q1 Predictions Min        -44.5536
trainer/Q2 Predictions Mean       -20.1361
trainer/Q2 Predictions Std          9.10137
trainer/Q2 Predictions Max        -11.0135
trainer/Q2 Predictions Min        -44.2527
trainer/Q Targets Mean            -20.3771
trainer/Q Targets Std               9.13602
trainer/Q Targets Max             -11.1573
trainer/Q Targets Min             -44.5661
trainer/Log Pis Mean                1.87998
trainer/Log Pis Std                 0.985835
trainer/Log Pis Max                 4.44822
trainer/Log Pis Min                -1.45915
trainer/Policy mu Mean              0.0708059
trainer/Policy mu Std               0.636888
trainer/Policy mu Max               2.71093
trainer/Policy mu Min              -2.48439
trainer/Policy log std Mean        -2.04846
trainer/Policy log std Std          0.508576
trainer/Policy log std Max         -0.546767
trainer/Policy log std Min         -2.66493
trainer/Alpha                       0.0983216
trainer/Alpha Loss                 -0.278397
exploration/num steps total     77800
exploration/num paths total       778
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.471719
exploration/Rewards Std             0.903399
exploration/Rewards Max            -0.0192774
exploration/Rewards Min            -7.99923
exploration/Returns Mean          -47.1719
exploration/Returns Std            22.0412
exploration/Returns Max           -25.1307
exploration/Returns Min           -69.2131
exploration/Actions Mean           -0.01461
exploration/Actions Std             0.239079
exploration/Actions Max             0.996331
exploration/Actions Min            -0.995339
exploration/Num Paths               2
exploration/Average Returns       -47.1719
evaluation/num steps total     388000
evaluation/num paths total       3880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274402
evaluation/Rewards Std              0.591774
evaluation/Rewards Max             -0.0641544
evaluation/Rewards Min             -8.01755
evaluation/Returns Mean           -27.4402
evaluation/Returns Std             16.8702
evaluation/Returns Max             -9.88365
evaluation/Returns Min            -58.7547
evaluation/Actions Mean             0.0125257
evaluation/Actions Std              0.142505
evaluation/Actions Max              0.991474
evaluation/Actions Min             -0.986453
evaluation/Num Paths               10
evaluation/Average Returns        -27.4402
time/data storing (s)               0.00123672
time/evaluation sampling (s)        0.218303
time/exploration sampling (s)       0.0640011
time/logging (s)                    0.00341444
time/saving (s)                     0.00198252
time/training (s)                   0.779935
time/epoch (s)                      1.06887
time/total (s)                    413.616
Epoch                             387
-----------------------------  ---------------
2019-04-21 01:18:38.972229 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 388 finished
-----------------------------  ---------------
replay_buffer/size              78000
trainer/QF1 Loss                    0.125882
trainer/QF2 Loss                    0.239984
trainer/Policy Loss                24.2844
trainer/Q1 Predictions Mean       -22.9063
trainer/Q1 Predictions Std          9.46875
trainer/Q1 Predictions Max        -11.0554
trainer/Q1 Predictions Min        -52.9528
trainer/Q2 Predictions Mean       -22.8945
trainer/Q2 Predictions Std          9.51563
trainer/Q2 Predictions Max        -11.0306
trainer/Q2 Predictions Min        -52.6607
trainer/Q Targets Mean            -22.8152
trainer/Q Targets Std               9.2961
trainer/Q Targets Max             -11.071
trainer/Q Targets Min             -52.5864
trainer/Log Pis Mean                2.04572
trainer/Log Pis Std                 1.14028
trainer/Log Pis Max                 5.51495
trainer/Log Pis Min                -1.68064
trainer/Policy mu Mean              0.0266573
trainer/Policy mu Std               0.802689
trainer/Policy mu Max               2.74723
trainer/Policy mu Min              -2.25789
trainer/Policy log std Mean        -1.87781
trainer/Policy log std Std          0.606354
trainer/Policy log std Max         -0.518812
trainer/Policy log std Min         -2.64005
trainer/Alpha                       0.095399
trainer/Alpha Loss                  0.107415
exploration/num steps total     78000
exploration/num paths total       780
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.383191
exploration/Rewards Std             1.05708
exploration/Rewards Max            -0.0169508
exploration/Rewards Min            -8.38506
exploration/Returns Mean          -38.3191
exploration/Returns Std            13.0343
exploration/Returns Max           -25.2848
exploration/Returns Min           -51.3534
exploration/Actions Mean            0.0515955
exploration/Actions Std             0.239533
exploration/Actions Max             0.998213
exploration/Actions Min            -0.465781
exploration/Num Paths               2
exploration/Average Returns       -38.3191
evaluation/num steps total     389000
evaluation/num paths total       3890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.554657
evaluation/Rewards Std              1.23153
evaluation/Rewards Max             -0.0871993
evaluation/Rewards Min            -10.6593
evaluation/Returns Mean           -55.4657
evaluation/Returns Std             10.3256
evaluation/Returns Max            -40.3235
evaluation/Returns Min            -76.6878
evaluation/Actions Mean            -0.00284891
evaluation/Actions Std              0.215347
evaluation/Actions Max              0.996891
evaluation/Actions Min             -0.994297
evaluation/Num Paths               10
evaluation/Average Returns        -55.4657
time/data storing (s)               0.0012393
time/evaluation sampling (s)        0.218317
time/exploration sampling (s)       0.064517
time/logging (s)                    0.00336705
time/saving (s)                     0.0019558
time/training (s)                   0.780518
time/epoch (s)                      1.06991
time/total (s)                    414.69
Epoch                             388
-----------------------------  ---------------
2019-04-21 01:18:40.049994 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 389 finished
-----------------------------  ---------------
replay_buffer/size              78200
trainer/QF1 Loss                    0.121265
trainer/QF2 Loss                    0.117976
trainer/Policy Loss                21.6236
trainer/Q1 Predictions Mean       -19.9859
trainer/Q1 Predictions Std          9.01392
trainer/Q1 Predictions Max        -10.826
trainer/Q1 Predictions Min        -43.8567
trainer/Q2 Predictions Mean       -19.9967
trainer/Q2 Predictions Std          9.00925
trainer/Q2 Predictions Max        -10.809
trainer/Q2 Predictions Min        -43.6633
trainer/Q Targets Mean            -20.2644
trainer/Q Targets Std               9.01822
trainer/Q Targets Max             -10.9467
trainer/Q Targets Min             -43.6718
trainer/Log Pis Mean                2.07341
trainer/Log Pis Std                 0.903284
trainer/Log Pis Max                 4.91517
trainer/Log Pis Min                -1.35627
trainer/Policy mu Mean              0.032335
trainer/Policy mu Std               0.596313
trainer/Policy mu Max               2.52786
trainer/Policy mu Min              -2.57328
trainer/Policy log std Mean        -2.10244
trainer/Policy log std Std          0.5167
trainer/Policy log std Max         -0.50541
trainer/Policy log std Min         -2.76307
trainer/Alpha                       0.0933833
trainer/Alpha Loss                  0.174049
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.523504
exploration/Rewards Std             1.42889
exploration/Rewards Max            -0.0252063
exploration/Rewards Min            -9.82156
exploration/Returns Mean          -52.3504
exploration/Returns Std            12.7894
exploration/Returns Max           -39.5611
exploration/Returns Min           -65.1398
exploration/Actions Mean            0.022903
exploration/Actions Std             0.256277
exploration/Actions Max             0.996746
exploration/Actions Min            -0.993728
exploration/Num Paths               2
exploration/Average Returns       -52.3504
evaluation/num steps total     390000
evaluation/num paths total       3900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.547743
evaluation/Rewards Std              0.842403
evaluation/Rewards Max             -0.106224
evaluation/Rewards Min            -10.2201
evaluation/Returns Mean           -54.7743
evaluation/Returns Std             21.8812
evaluation/Returns Max            -14.8472
evaluation/Returns Min            -99.2736
evaluation/Actions Mean            -0.0212866
evaluation/Actions Std              0.177957
evaluation/Actions Max              0.989854
evaluation/Actions Min             -0.997095
evaluation/Num Paths               10
evaluation/Average Returns        -54.7743
time/data storing (s)               0.00124371
time/evaluation sampling (s)        0.221669
time/exploration sampling (s)       0.0634348
time/logging (s)                    0.00335022
time/saving (s)                     0.00195311
time/training (s)                   0.776104
time/epoch (s)                      1.06776
time/total (s)                    415.762
Epoch                             389
-----------------------------  ---------------
2019-04-21 01:18:41.131881 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 390 finished
-----------------------------  ---------------
replay_buffer/size              78400
trainer/QF1 Loss                    0.0838625
trainer/QF2 Loss                    0.0941076
trainer/Policy Loss                22.2026
trainer/Q1 Predictions Mean       -20.6898
trainer/Q1 Predictions Std          8.97921
trainer/Q1 Predictions Max        -10.7769
trainer/Q1 Predictions Min        -43.4687
trainer/Q2 Predictions Mean       -20.7409
trainer/Q2 Predictions Std          8.98821
trainer/Q2 Predictions Max        -10.7826
trainer/Q2 Predictions Min        -43.7712
trainer/Q Targets Mean            -20.87
trainer/Q Targets Std               8.8853
trainer/Q Targets Max             -11.0203
trainer/Q Targets Min             -43.1938
trainer/Log Pis Mean                1.96572
trainer/Log Pis Std                 1.15384
trainer/Log Pis Max                 6.24105
trainer/Log Pis Min                -0.816927
trainer/Policy mu Mean              0.104177
trainer/Policy mu Std               0.676634
trainer/Policy mu Max               2.73031
trainer/Policy mu Min              -2.37951
trainer/Policy log std Mean        -2.02681
trainer/Policy log std Std          0.543372
trainer/Policy log std Max         -0.406812
trainer/Policy log std Min         -2.63579
trainer/Alpha                       0.0916656
trainer/Alpha Loss                 -0.0819042
exploration/num steps total     78400
exploration/num paths total       784
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.629921
exploration/Rewards Std             0.827221
exploration/Rewards Max            -0.262272
exploration/Rewards Min            -6.63978
exploration/Returns Mean          -62.9921
exploration/Returns Std             3.39892
exploration/Returns Max           -59.5932
exploration/Returns Min           -66.391
exploration/Actions Mean           -0.0397827
exploration/Actions Std             0.221151
exploration/Actions Max             0.5057
exploration/Actions Min            -0.993519
exploration/Num Paths               2
exploration/Average Returns       -62.9921
evaluation/num steps total     391000
evaluation/num paths total       3910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.445267
evaluation/Rewards Std              1.0678
evaluation/Rewards Max             -0.0965809
evaluation/Rewards Min            -10.1116
evaluation/Returns Mean           -44.5267
evaluation/Returns Std             20.1167
evaluation/Returns Max            -12.5679
evaluation/Returns Min            -85.0558
evaluation/Actions Mean             0.00442071
evaluation/Actions Std              0.198446
evaluation/Actions Max              0.994407
evaluation/Actions Min             -0.996949
evaluation/Num Paths               10
evaluation/Average Returns        -44.5267
time/data storing (s)               0.00130535
time/evaluation sampling (s)        0.225036
time/exploration sampling (s)       0.0667122
time/logging (s)                    0.00252665
time/saving (s)                     0.00195686
time/training (s)                   0.773564
time/epoch (s)                      1.0711
time/total (s)                    416.837
Epoch                             390
-----------------------------  ---------------
2019-04-21 01:18:42.206991 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 391 finished
-----------------------------  ----------------
replay_buffer/size              78600
trainer/QF1 Loss                    0.185447
trainer/QF2 Loss                    0.210924
trainer/Policy Loss                21.6518
trainer/Q1 Predictions Mean       -20.1302
trainer/Q1 Predictions Std         10.6235
trainer/Q1 Predictions Max        -11.0844
trainer/Q1 Predictions Min        -75.8692
trainer/Q2 Predictions Mean       -20.1425
trainer/Q2 Predictions Std         10.6224
trainer/Q2 Predictions Max        -11.095
trainer/Q2 Predictions Min        -75.9014
trainer/Q Targets Mean            -20.2822
trainer/Q Targets Std              10.8422
trainer/Q Targets Max             -10.8825
trainer/Q Targets Min             -76.4276
trainer/Log Pis Mean                1.98244
trainer/Log Pis Std                 1.04352
trainer/Log Pis Max                 5.94357
trainer/Log Pis Min                -0.905293
trainer/Policy mu Mean              0.0365896
trainer/Policy mu Std               0.728746
trainer/Policy mu Max               2.67389
trainer/Policy mu Min              -3.35392
trainer/Policy log std Mean        -1.99234
trainer/Policy log std Std          0.5511
trainer/Policy log std Max         -0.491039
trainer/Policy log std Min         -2.70223
trainer/Alpha                       0.0904948
trainer/Alpha Loss                 -0.042191
exploration/num steps total     78600
exploration/num paths total       786
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.404082
exploration/Rewards Std             0.586428
exploration/Rewards Max            -0.0228909
exploration/Rewards Min            -5.53219
exploration/Returns Mean          -40.4082
exploration/Returns Std            22.244
exploration/Returns Max           -18.1642
exploration/Returns Min           -62.6522
exploration/Actions Mean           -0.000638511
exploration/Actions Std             0.195636
exploration/Actions Max             0.978928
exploration/Actions Min            -0.996412
exploration/Num Paths               2
exploration/Average Returns       -40.4082
evaluation/num steps total     392000
evaluation/num paths total       3920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.309054
evaluation/Rewards Std              0.868872
evaluation/Rewards Max             -0.0506685
evaluation/Rewards Min             -9.45476
evaluation/Returns Mean           -30.9054
evaluation/Returns Std             22.5085
evaluation/Returns Max            -10.9552
evaluation/Returns Min            -89.6751
evaluation/Actions Mean             0.00532849
evaluation/Actions Std              0.175994
evaluation/Actions Max              0.99322
evaluation/Actions Min             -0.996381
evaluation/Num Paths               10
evaluation/Average Returns        -30.9054
time/data storing (s)               0.00130527
time/evaluation sampling (s)        0.221581
time/exploration sampling (s)       0.064477
time/logging (s)                    0.00252719
time/saving (s)                     0.00157096
time/training (s)                   0.775538
time/epoch (s)                      1.067
time/total (s)                    417.908
Epoch                             391
-----------------------------  ----------------
2019-04-21 01:18:43.279501 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 392 finished
-----------------------------  ---------------
replay_buffer/size              78800
trainer/QF1 Loss                    2.22414
trainer/QF2 Loss                    2.23735
trainer/Policy Loss                22.9274
trainer/Q1 Predictions Mean       -21.4569
trainer/Q1 Predictions Std         10.6613
trainer/Q1 Predictions Max        -10.9538
trainer/Q1 Predictions Min        -78.3785
trainer/Q2 Predictions Mean       -21.4606
trainer/Q2 Predictions Std         10.6438
trainer/Q2 Predictions Max        -10.9393
trainer/Q2 Predictions Min        -78.3364
trainer/Q Targets Mean            -21.3609
trainer/Q Targets Std              10.8635
trainer/Q Targets Max              -3.04956
trainer/Q Targets Min             -78.8092
trainer/Log Pis Mean                1.95568
trainer/Log Pis Std                 1.19342
trainer/Log Pis Max                 5.21444
trainer/Log Pis Min                -2.90579
trainer/Policy mu Mean              0.0780848
trainer/Policy mu Std               0.721062
trainer/Policy mu Max               2.67558
trainer/Policy mu Min              -2.69215
trainer/Policy log std Mean        -2.01962
trainer/Policy log std Std          0.582044
trainer/Policy log std Max         -0.419723
trainer/Policy log std Min         -2.70459
trainer/Alpha                       0.0895086
trainer/Alpha Loss                 -0.106947
exploration/num steps total     78800
exploration/num paths total       788
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.337775
exploration/Rewards Std             0.327277
exploration/Rewards Max            -0.0138723
exploration/Rewards Min            -3.41841
exploration/Returns Mean          -33.7775
exploration/Returns Std            13.1154
exploration/Returns Max           -20.662
exploration/Returns Min           -46.8929
exploration/Actions Mean            0.0183311
exploration/Actions Std             0.187327
exploration/Actions Max             0.977896
exploration/Actions Min            -0.599898
exploration/Num Paths               2
exploration/Average Returns       -33.7775
evaluation/num steps total     393000
evaluation/num paths total       3930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.404404
evaluation/Rewards Std              0.938696
evaluation/Rewards Max             -0.0651526
evaluation/Rewards Min             -9.39749
evaluation/Returns Mean           -40.4404
evaluation/Returns Std             18.872
evaluation/Returns Max            -14.1708
evaluation/Returns Min            -76.4306
evaluation/Actions Mean             0.014905
evaluation/Actions Std              0.193942
evaluation/Actions Max              0.992925
evaluation/Actions Min             -0.996345
evaluation/Num Paths               10
evaluation/Average Returns        -40.4404
time/data storing (s)               0.00144062
time/evaluation sampling (s)        0.221851
time/exploration sampling (s)       0.0644142
time/logging (s)                    0.0034298
time/saving (s)                     0.00196773
time/training (s)                   0.771258
time/epoch (s)                      1.06436
time/total (s)                    418.977
Epoch                             392
-----------------------------  ---------------
2019-04-21 01:18:44.350663 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 393 finished
-----------------------------  ---------------
replay_buffer/size              79000
trainer/QF1 Loss                    0.0879041
trainer/QF2 Loss                    0.0868325
trainer/Policy Loss                20.3352
trainer/Q1 Predictions Mean       -18.715
trainer/Q1 Predictions Std          8.6861
trainer/Q1 Predictions Max        -10.8308
trainer/Q1 Predictions Min        -42.1528
trainer/Q2 Predictions Mean       -18.7109
trainer/Q2 Predictions Std          8.70432
trainer/Q2 Predictions Max        -10.7952
trainer/Q2 Predictions Min        -42.4026
trainer/Q Targets Mean            -18.929
trainer/Q Targets Std               8.77837
trainer/Q Targets Max             -10.8472
trainer/Q Targets Min             -42.4115
trainer/Log Pis Mean                1.88889
trainer/Log Pis Std                 1.19353
trainer/Log Pis Max                 5.91997
trainer/Log Pis Min                -1.83264
trainer/Policy mu Mean              0.0572233
trainer/Policy mu Std               0.608433
trainer/Policy mu Max               2.70252
trainer/Policy mu Min              -2.47259
trainer/Policy log std Mean        -2.13543
trainer/Policy log std Std          0.515799
trainer/Policy log std Max         -0.623517
trainer/Policy log std Min         -2.73394
trainer/Alpha                       0.0901568
trainer/Alpha Loss                 -0.267361
exploration/num steps total     79000
exploration/num paths total       790
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.823969
exploration/Rewards Std             1.3106
exploration/Rewards Max            -0.308807
exploration/Rewards Min            -8.49823
exploration/Returns Mean          -82.3969
exploration/Returns Std             2.90161
exploration/Returns Max           -79.4953
exploration/Returns Min           -85.2986
exploration/Actions Mean           -0.0605644
exploration/Actions Std             0.257916
exploration/Actions Max             0.337439
exploration/Actions Min            -0.997972
exploration/Num Paths               2
exploration/Average Returns       -82.3969
evaluation/num steps total     394000
evaluation/num paths total       3940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.579628
evaluation/Rewards Std              1.17487
evaluation/Rewards Max             -0.0660998
evaluation/Rewards Min            -10.9313
evaluation/Returns Mean           -57.9628
evaluation/Returns Std             24.5719
evaluation/Returns Max            -10.3505
evaluation/Returns Min            -99.8182
evaluation/Actions Mean            -0.00506149
evaluation/Actions Std              0.210252
evaluation/Actions Max              0.996861
evaluation/Actions Min             -0.998804
evaluation/Num Paths               10
evaluation/Average Returns        -57.9628
time/data storing (s)               0.00119806
time/evaluation sampling (s)        0.220912
time/exploration sampling (s)       0.0639328
time/logging (s)                    0.00338834
time/saving (s)                     0.00157728
time/training (s)                   0.769991
time/epoch (s)                      1.061
time/total (s)                    420.043
Epoch                             393
-----------------------------  ---------------
2019-04-21 01:18:45.408020 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 394 finished
-----------------------------  ---------------
replay_buffer/size              79200
trainer/QF1 Loss                    7.69645
trainer/QF2 Loss                    7.68255
trainer/Policy Loss                22.2851
trainer/Q1 Predictions Mean       -20.6721
trainer/Q1 Predictions Std          8.45289
trainer/Q1 Predictions Max        -10.8165
trainer/Q1 Predictions Min        -35.6147
trainer/Q2 Predictions Mean       -20.6704
trainer/Q2 Predictions Std          8.46537
trainer/Q2 Predictions Max        -10.8163
trainer/Q2 Predictions Min        -35.6392
trainer/Q Targets Mean            -20.5421
trainer/Q Targets Std               8.71679
trainer/Q Targets Max              -1.08302
trainer/Q Targets Min             -35.6369
trainer/Log Pis Mean                1.92828
trainer/Log Pis Std                 1.03772
trainer/Log Pis Max                 4.43782
trainer/Log Pis Min                -1.70595
trainer/Policy mu Mean              0.0572781
trainer/Policy mu Std               0.664321
trainer/Policy mu Max               2.63434
trainer/Policy mu Min              -2.33752
trainer/Policy log std Mean        -2.03998
trainer/Policy log std Std          0.546664
trainer/Policy log std Max         -0.55269
trainer/Policy log std Min         -2.66598
trainer/Alpha                       0.0911097
trainer/Alpha Loss                 -0.171815
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.374581
exploration/Rewards Std             1.11211
exploration/Rewards Max            -0.0211996
exploration/Rewards Min            -8.90957
exploration/Returns Mean          -37.4581
exploration/Returns Std            18.2648
exploration/Returns Max           -19.1933
exploration/Returns Min           -55.7228
exploration/Actions Mean            0.0243355
exploration/Actions Std             0.233074
exploration/Actions Max             0.998739
exploration/Actions Min            -0.968544
exploration/Num Paths               2
exploration/Average Returns       -37.4581
evaluation/num steps total     395000
evaluation/num paths total       3950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.570629
evaluation/Rewards Std              1.11915
evaluation/Rewards Max             -0.0726521
evaluation/Rewards Min             -9.9624
evaluation/Returns Mean           -57.0629
evaluation/Returns Std             15.878
evaluation/Returns Max            -32.2879
evaluation/Returns Min            -91.7832
evaluation/Actions Mean            -0.00384225
evaluation/Actions Std              0.207953
evaluation/Actions Max              0.993949
evaluation/Actions Min             -0.997278
evaluation/Num Paths               10
evaluation/Average Returns        -57.0629
time/data storing (s)               0.00129964
time/evaluation sampling (s)        0.225127
time/exploration sampling (s)       0.0643626
time/logging (s)                    0.00336663
time/saving (s)                     0.00197843
time/training (s)                   0.751398
time/epoch (s)                      1.04753
time/total (s)                    421.094
Epoch                             394
-----------------------------  ---------------
2019-04-21 01:18:46.452550 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 395 finished
-----------------------------  ---------------
replay_buffer/size              79400
trainer/QF1 Loss                    7.71704
trainer/QF2 Loss                    7.72745
trainer/Policy Loss                22.1252
trainer/Q1 Predictions Mean       -20.4494
trainer/Q1 Predictions Std          8.55133
trainer/Q1 Predictions Max        -10.8658
trainer/Q1 Predictions Min        -37.5714
trainer/Q2 Predictions Mean       -20.429
trainer/Q2 Predictions Std          8.60386
trainer/Q2 Predictions Max        -10.796
trainer/Q2 Predictions Min        -38.098
trainer/Q Targets Mean            -20.2343
trainer/Q Targets Std               8.72869
trainer/Q Targets Max              -0.9519
trainer/Q Targets Min             -37.9185
trainer/Log Pis Mean                2.08791
trainer/Log Pis Std                 0.897042
trainer/Log Pis Max                 5.79893
trainer/Log Pis Min                -0.814406
trainer/Policy mu Mean              0.0428473
trainer/Policy mu Std               0.63466
trainer/Policy mu Max               2.61784
trainer/Policy mu Min              -2.23861
trainer/Policy log std Mean        -2.09311
trainer/Policy log std Std          0.535618
trainer/Policy log std Max         -0.611281
trainer/Policy log std Min         -2.75456
trainer/Alpha                       0.0919138
trainer/Alpha Loss                  0.209833
exploration/num steps total     79400
exploration/num paths total       794
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.298249
exploration/Rewards Std             0.763502
exploration/Rewards Max            -0.0100122
exploration/Rewards Min            -6.95626
exploration/Returns Mean          -29.8249
exploration/Returns Std             8.72132
exploration/Returns Max           -21.1036
exploration/Returns Min           -38.5463
exploration/Actions Mean           -0.00446577
exploration/Actions Std             0.224938
exploration/Actions Max             0.999016
exploration/Actions Min            -0.977208
exploration/Num Paths               2
exploration/Average Returns       -29.8249
evaluation/num steps total     396000
evaluation/num paths total       3960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.429268
evaluation/Rewards Std              1.06559
evaluation/Rewards Max             -0.0889833
evaluation/Rewards Min            -11.1075
evaluation/Returns Mean           -42.9268
evaluation/Returns Std             20.5534
evaluation/Returns Max            -10.3672
evaluation/Returns Min            -93.9313
evaluation/Actions Mean             0.00625313
evaluation/Actions Std              0.194556
evaluation/Actions Max              0.991506
evaluation/Actions Min             -0.998513
evaluation/Num Paths               10
evaluation/Average Returns        -42.9268
time/data storing (s)               0.00144167
time/evaluation sampling (s)        0.219593
time/exploration sampling (s)       0.063063
time/logging (s)                    0.00339005
time/saving (s)                     0.00196873
time/training (s)                   0.745048
time/epoch (s)                      1.0345
time/total (s)                    422.133
Epoch                             395
-----------------------------  ---------------
2019-04-21 01:18:47.522360 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 396 finished
-----------------------------  ----------------
replay_buffer/size              79600
trainer/QF1 Loss                    8.83039
trainer/QF2 Loss                    8.82928
trainer/Policy Loss                22.2393
trainer/Q1 Predictions Mean       -20.8128
trainer/Q1 Predictions Std          8.76185
trainer/Q1 Predictions Max        -10.6868
trainer/Q1 Predictions Min        -47.2222
trainer/Q2 Predictions Mean       -20.8112
trainer/Q2 Predictions Std          8.78697
trainer/Q2 Predictions Max        -10.6562
trainer/Q2 Predictions Min        -47.0804
trainer/Q Targets Mean            -20.5885
trainer/Q Targets Std               9.09075
trainer/Q Targets Max              -0.206763
trainer/Q Targets Min             -47.4387
trainer/Log Pis Mean                1.78149
trainer/Log Pis Std                 1.32664
trainer/Log Pis Max                 5.33006
trainer/Log Pis Min                -6.22116
trainer/Policy mu Mean              0.0749981
trainer/Policy mu Std               0.609769
trainer/Policy mu Max               2.75145
trainer/Policy mu Min              -2.69173
trainer/Policy log std Mean        -2.12548
trainer/Policy log std Std          0.488492
trainer/Policy log std Max         -0.55029
trainer/Policy log std Min         -2.74996
trainer/Alpha                       0.091424
trainer/Alpha Loss                 -0.522728
exploration/num steps total     79600
exploration/num paths total       796
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.781075
exploration/Rewards Std             1.42037
exploration/Rewards Max            -0.271971
exploration/Rewards Min            -9.91642
exploration/Returns Mean          -78.1075
exploration/Returns Std             5.58601
exploration/Returns Max           -72.5215
exploration/Returns Min           -83.6936
exploration/Actions Mean           -0.0546009
exploration/Actions Std             0.256635
exploration/Actions Max             0.685708
exploration/Actions Min            -0.99797
exploration/Num Paths               2
exploration/Average Returns       -78.1075
evaluation/num steps total     397000
evaluation/num paths total       3970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.423529
evaluation/Rewards Std              0.839004
evaluation/Rewards Max             -0.0802884
evaluation/Rewards Min            -10.2514
evaluation/Returns Mean           -42.3529
evaluation/Returns Std             23.8533
evaluation/Returns Max             -9.71709
evaluation/Returns Min            -94.2665
evaluation/Actions Mean            -0.000680695
evaluation/Actions Std              0.17513
evaluation/Actions Max              0.993452
evaluation/Actions Min             -0.997378
evaluation/Num Paths               10
evaluation/Average Returns        -42.3529
time/data storing (s)               0.00132035
time/evaluation sampling (s)        0.218276
time/exploration sampling (s)       0.0648974
time/logging (s)                    0.00331994
time/saving (s)                     0.0120844
time/training (s)                   0.761136
time/epoch (s)                      1.06103
time/total (s)                    423.199
Epoch                             396
-----------------------------  ----------------
2019-04-21 01:18:48.577417 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 397 finished
-----------------------------  ----------------
replay_buffer/size              79800
trainer/QF1 Loss                    1.23922
trainer/QF2 Loss                    1.24742
trainer/Policy Loss                22.0891
trainer/Q1 Predictions Mean       -20.4075
trainer/Q1 Predictions Std         11.0497
trainer/Q1 Predictions Max        -10.7411
trainer/Q1 Predictions Min        -67.3929
trainer/Q2 Predictions Mean       -20.4087
trainer/Q2 Predictions Std         11.0658
trainer/Q2 Predictions Max        -10.7426
trainer/Q2 Predictions Min        -67.3988
trainer/Q Targets Mean            -20.4596
trainer/Q Targets Std              11.2424
trainer/Q Targets Max              -0.563812
trainer/Q Targets Min             -67.187
trainer/Log Pis Mean                2.0001
trainer/Log Pis Std                 1.31505
trainer/Log Pis Max                 9.03676
trainer/Log Pis Min                -2.23124
trainer/Policy mu Mean             -0.0137803
trainer/Policy mu Std               0.718104
trainer/Policy mu Max               2.8478
trainer/Policy mu Min              -3.1239
trainer/Policy log std Mean        -2.11936
trainer/Policy log std Std          0.550374
trainer/Policy log std Max         -0.422579
trainer/Policy log std Min         -2.77703
trainer/Alpha                       0.0910606
trainer/Alpha Loss                  0.000230536
exploration/num steps total     79800
exploration/num paths total       798
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.723153
exploration/Rewards Std             1.18933
exploration/Rewards Max            -0.271939
exploration/Rewards Min            -9.46096
exploration/Returns Mean          -72.3153
exploration/Returns Std            21.9064
exploration/Returns Max           -50.4089
exploration/Returns Min           -94.2217
exploration/Actions Mean           -0.0313133
exploration/Actions Std             0.206786
exploration/Actions Max             0.563863
exploration/Actions Min            -0.998563
exploration/Num Paths               2
exploration/Average Returns       -72.3153
evaluation/num steps total     398000
evaluation/num paths total       3980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.441605
evaluation/Rewards Std              0.781271
evaluation/Rewards Max             -0.0868294
evaluation/Rewards Min             -9.20572
evaluation/Returns Mean           -44.1605
evaluation/Returns Std             23.9703
evaluation/Returns Max            -10.7904
evaluation/Returns Min            -84.5114
evaluation/Actions Mean            -0.0090432
evaluation/Actions Std              0.166851
evaluation/Actions Max              0.993822
evaluation/Actions Min             -0.996483
evaluation/Num Paths               10
evaluation/Average Returns        -44.1605
time/data storing (s)               0.00141357
time/evaluation sampling (s)        0.218747
time/exploration sampling (s)       0.0623736
time/logging (s)                    0.00336786
time/saving (s)                     0.00157379
time/training (s)                   0.758035
time/epoch (s)                      1.04551
time/total (s)                    424.248
Epoch                             397
-----------------------------  ----------------
2019-04-21 01:18:49.653990 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 398 finished
-----------------------------  ---------------
replay_buffer/size              80000
trainer/QF1 Loss                    1.19775
trainer/QF2 Loss                    1.19089
trainer/Policy Loss                23.7221
trainer/Q1 Predictions Mean       -22.0533
trainer/Q1 Predictions Std         10.7791
trainer/Q1 Predictions Max        -10.6966
trainer/Q1 Predictions Min        -74.4802
trainer/Q2 Predictions Mean       -22.0477
trainer/Q2 Predictions Std         10.7779
trainer/Q2 Predictions Max        -10.6786
trainer/Q2 Predictions Min        -74.5469
trainer/Q Targets Mean            -21.9528
trainer/Q Targets Std              10.9016
trainer/Q Targets Max              -0.266824
trainer/Q Targets Min             -74.7716
trainer/Log Pis Mean                2.12351
trainer/Log Pis Std                 1.36866
trainer/Log Pis Max                 6.74927
trainer/Log Pis Min                -2.83828
trainer/Policy mu Mean              0.0507687
trainer/Policy mu Std               0.750525
trainer/Policy mu Max               2.70976
trainer/Policy mu Min              -3.12637
trainer/Policy log std Mean        -2.08318
trainer/Policy log std Std          0.584342
trainer/Policy log std Max         -0.210517
trainer/Policy log std Min         -2.71762
trainer/Alpha                       0.0909506
trainer/Alpha Loss                  0.296105
exploration/num steps total     80000
exploration/num paths total       800
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.610779
exploration/Rewards Std             1.31985
exploration/Rewards Max            -0.00518253
exploration/Rewards Min            -8.3016
exploration/Returns Mean          -61.0779
exploration/Returns Std            10.4014
exploration/Returns Max           -50.6765
exploration/Returns Min           -71.4792
exploration/Actions Mean            0.0158557
exploration/Actions Std             0.249069
exploration/Actions Max             0.999453
exploration/Actions Min            -0.998112
exploration/Num Paths               2
exploration/Average Returns       -61.0779
evaluation/num steps total     399000
evaluation/num paths total       3990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.506457
evaluation/Rewards Std              1.05485
evaluation/Rewards Max             -0.0799778
evaluation/Rewards Min             -9.6776
evaluation/Returns Mean           -50.6457
evaluation/Returns Std             23.0093
evaluation/Returns Max            -21.1383
evaluation/Returns Min            -89.7774
evaluation/Actions Mean            -0.00827119
evaluation/Actions Std              0.201225
evaluation/Actions Max              0.993618
evaluation/Actions Min             -0.997539
evaluation/Num Paths               10
evaluation/Average Returns        -50.6457
time/data storing (s)               0.00122773
time/evaluation sampling (s)        0.222901
time/exploration sampling (s)       0.0661037
time/logging (s)                    0.00334606
time/saving (s)                     0.00196702
time/training (s)                   0.772024
time/epoch (s)                      1.06757
time/total (s)                    425.319
Epoch                             398
-----------------------------  ---------------
2019-04-21 01:18:50.717160 PDT | [sac-pointmass-multitask-2_2019_04_21_01_11_43_0000--s-0] Epoch 399 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    0.0980767
trainer/QF2 Loss                    0.117982
trainer/Policy Loss                21.3404
trainer/Q1 Predictions Mean       -19.5263
trainer/Q1 Predictions Std          8.41354
trainer/Q1 Predictions Max        -10.8739
trainer/Q1 Predictions Min        -35.9807
trainer/Q2 Predictions Mean       -19.5163
trainer/Q2 Predictions Std          8.40781
trainer/Q2 Predictions Max        -10.8295
trainer/Q2 Predictions Min        -36.005
trainer/Q Targets Mean            -19.5622
trainer/Q Targets Std               8.55138
trainer/Q Targets Max             -10.6827
trainer/Q Targets Min             -35.9204
trainer/Log Pis Mean                2.23644
trainer/Log Pis Std                 0.977293
trainer/Log Pis Max                 5.21013
trainer/Log Pis Min                 0.105623
trainer/Policy mu Mean              0.0850154
trainer/Policy mu Std               0.687628
trainer/Policy mu Max               2.77688
trainer/Policy mu Min              -2.5303
trainer/Policy log std Mean        -2.08949
trainer/Policy log std Std          0.551461
trainer/Policy log std Max         -0.454231
trainer/Policy log std Min         -2.82146
trainer/Alpha                       0.09288
trainer/Alpha Loss                  0.561918
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.571499
exploration/Rewards Std             1.16588
exploration/Rewards Max            -0.0107642
exploration/Rewards Min            -8.77146
exploration/Returns Mean          -57.1499
exploration/Returns Std             2.57255
exploration/Returns Max           -54.5773
exploration/Returns Min           -59.7224
exploration/Actions Mean            0.00679336
exploration/Actions Std             0.228278
exploration/Actions Max             0.997259
exploration/Actions Min            -0.990656
exploration/Num Paths               2
exploration/Average Returns       -57.1499
evaluation/num steps total     400000
evaluation/num paths total       4000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.471809
evaluation/Rewards Std              0.93686
evaluation/Rewards Max             -0.0821752
evaluation/Rewards Min             -9.11782
evaluation/Returns Mean           -47.1809
evaluation/Returns Std             23.0851
evaluation/Returns Max            -15.107
evaluation/Returns Min            -84.9716
evaluation/Actions Mean            -0.0226738
evaluation/Actions Std              0.187989
evaluation/Actions Max              0.989209
evaluation/Actions Min             -0.996159
evaluation/Num Paths               10
evaluation/Average Returns        -47.1809
time/data storing (s)               0.00124214
time/evaluation sampling (s)        0.227781
time/exploration sampling (s)       0.0661753
time/logging (s)                    0.00337762
time/saving (s)                     0.00186772
time/training (s)                   0.754178
time/epoch (s)                      1.05462
time/total (s)                    426.377
Epoch                             399
-----------------------------  ---------------
