2019-04-22 23:49:52.489440 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  59.2736
trainer/QF2 Loss                  59.273
trainer/Policy Loss               -1.36522
trainer/Q1 Predictions Mean       -0.000105789
trainer/Q1 Predictions Std         0.00164154
trainer/Q1 Predictions Max         0.00290803
trainer/Q1 Predictions Min        -0.00310265
trainer/Q2 Predictions Mean       -0.000678976
trainer/Q2 Predictions Std         0.00126172
trainer/Q2 Predictions Max         0.00187866
trainer/Q2 Predictions Min        -0.00300747
trainer/Q Targets Mean            -7.08913
trainer/Q Targets Std              3.00362
trainer/Q Targets Max             -0.30595
trainer/Q Targets Min            -12.8675
trainer/Log Pis Mean              -1.36678
trainer/Log Pis Std                0.30337
trainer/Log Pis Max               -0.624344
trainer/Log Pis Min               -1.83542
trainer/Policy mu Mean             0.000125392
trainer/Policy mu Std              0.000572167
trainer/Policy mu Max              0.00179916
trainer/Policy mu Min             -0.00116905
trainer/Policy log std Mean       -0.000101042
trainer/Policy log std Std         0.00185532
trainer/Policy log std Max         0.00238945
trainer/Policy log std Min        -0.00319537
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -7.18192
exploration/Rewards Std            3.32402
exploration/Rewards Max           -0.22202
exploration/Rewards Min          -12.8655
exploration/Returns Mean        -718.192
exploration/Returns Std          260.645
exploration/Returns Max         -317.53
exploration/Returns Min        -1011.97
exploration/Actions Mean          -0.0128045
exploration/Actions Std            0.634471
exploration/Actions Max            0.997371
exploration/Actions Min           -0.997648
exploration/Num Paths              5
exploration/Average Returns     -718.192
evaluation/num steps total      1500
evaluation/num paths total        15
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -4.57807
evaluation/Rewards Std             2.60711
evaluation/Rewards Max            -1.20754
evaluation/Rewards Min           -10.2131
evaluation/Returns Mean         -457.807
evaluation/Returns Std           260.709
evaluation/Returns Max          -122.06
evaluation/Returns Min         -1018.71
evaluation/Actions Mean            0.000197236
evaluation/Actions Std             0.000412016
evaluation/Actions Max             0.00131887
evaluation/Actions Min            -0.000606989
evaluation/Num Paths              15
evaluation/Average Returns      -457.807
time/data storing (s)              0.00291036
time/evaluation sampling (s)       0.339314
time/exploration sampling (s)      0.165147
time/logging (s)                   0.0049829
time/saving (s)                    0.00241559
time/training (s)                  2.20272
time/epoch (s)                     2.71749
time/total (s)                     2.94452
Epoch                              0
-----------------------------  ---------------
2019-04-22 23:49:54.936047 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size              1200
trainer/QF1 Loss                  15.337
trainer/QF2 Loss                  16.1439
trainer/Policy Loss                8.67087
trainer/Q1 Predictions Mean      -10.1144
trainer/Q1 Predictions Std         6.59344
trainer/Q1 Predictions Max        -2.9162
trainer/Q1 Predictions Min       -24.2159
trainer/Q2 Predictions Mean      -10.1063
trainer/Q2 Predictions Std         6.61309
trainer/Q2 Predictions Max        -2.69376
trainer/Q2 Predictions Min       -24.3474
trainer/Q Targets Mean           -11.7646
trainer/Q Targets Std              5.93064
trainer/Q Targets Max             -3.51796
trainer/Q Targets Min            -24.8766
trainer/Log Pis Mean              -1.02946
trainer/Log Pis Std                0.869531
trainer/Log Pis Max                1.24287
trainer/Log Pis Min               -3.36568
trainer/Policy mu Mean             0.316927
trainer/Policy mu Std              0.372395
trainer/Policy mu Max              1.00256
trainer/Policy mu Min             -0.681352
trainer/Policy log std Mean       -0.233631
trainer/Policy log std Std         0.0521627
trainer/Policy log std Max        -0.148691
trainer/Policy log std Min        -0.389986
trainer/Alpha                      0.863758
trainer/Alpha Loss                -0.442872
exploration/num steps total     1200
exploration/num paths total       12
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -5.31407
exploration/Rewards Std            4.32797
exploration/Rewards Max           -0.264393
exploration/Rewards Min          -11.6253
exploration/Returns Mean        -531.407
exploration/Returns Std          397.739
exploration/Returns Max         -142.102
exploration/Returns Min        -1054.92
exploration/Actions Mean           0.127152
exploration/Actions Std            0.579615
exploration/Actions Max            0.995059
exploration/Actions Min           -0.975028
exploration/Num Paths              5
exploration/Average Returns     -531.407
evaluation/num steps total      3000
evaluation/num paths total        30
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -5.69334
evaluation/Rewards Std             4.70481
evaluation/Rewards Max            -0.32211
evaluation/Rewards Min           -12.3288
evaluation/Returns Mean         -569.334
evaluation/Returns Std           462.887
evaluation/Returns Max          -153.638
evaluation/Returns Min         -1232.85
evaluation/Actions Mean            0.1798
evaluation/Actions Std             0.220417
evaluation/Actions Max             0.680828
evaluation/Actions Min            -0.542592
evaluation/Num Paths              15
evaluation/Average Returns      -569.334
time/data storing (s)              0.0028212
time/evaluation sampling (s)       0.354583
time/exploration sampling (s)      0.148272
time/logging (s)                   0.0049262
time/saving (s)                    0.00204916
time/training (s)                  1.92787
time/epoch (s)                     2.44052
time/total (s)                     5.39017
Epoch                              1
-----------------------------  --------------
2019-04-22 23:49:57.339325 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size             1700
trainer/QF1 Loss                  1.77669
trainer/QF2 Loss                  2.0519
trainer/Policy Loss              18.6283
trainer/Q1 Predictions Mean     -20.6683
trainer/Q1 Predictions Std        7.94602
trainer/Q1 Predictions Max       -8.99501
trainer/Q1 Predictions Min      -42.8083
trainer/Q2 Predictions Mean     -20.6242
trainer/Q2 Predictions Std        7.92445
trainer/Q2 Predictions Max       -8.66131
trainer/Q2 Predictions Min      -42.5359
trainer/Q Targets Mean          -20.8948
trainer/Q Targets Std             8.36941
trainer/Q Targets Max            -8.34429
trainer/Q Targets Min           -42.9238
trainer/Log Pis Mean             -0.614958
trainer/Log Pis Std               1.08022
trainer/Log Pis Max               2.20456
trainer/Log Pis Min              -3.44061
trainer/Policy mu Mean            0.211281
trainer/Policy mu Std             0.652211
trainer/Policy mu Max             1.39353
trainer/Policy mu Min            -1.19021
trainer/Policy log std Mean      -0.347962
trainer/Policy log std Std        0.0792622
trainer/Policy log std Max       -0.209286
trainer/Policy log std Min       -0.552269
trainer/Alpha                     0.753422
trainer/Alpha Loss               -0.739716
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -5.90523
exploration/Rewards Std           3.66352
exploration/Rewards Max          -0.180153
exploration/Rewards Min         -11.5728
exploration/Returns Mean       -590.523
exploration/Returns Std         351.629
exploration/Returns Max        -153.635
exploration/Returns Min        -896.737
exploration/Actions Mean          0.0155538
exploration/Actions Std           0.559832
exploration/Actions Max           0.987133
exploration/Actions Min          -0.980802
exploration/Num Paths             5
exploration/Average Returns    -590.523
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.59259
evaluation/Rewards Std            3.53693
evaluation/Rewards Max           -0.992219
evaluation/Rewards Min          -10.1261
evaluation/Returns Mean        -459.259
evaluation/Returns Std          346.887
evaluation/Returns Max         -118.363
evaluation/Returns Min         -859.964
evaluation/Actions Mean           0.0135038
evaluation/Actions Std            0.130521
evaluation/Actions Max            0.8573
evaluation/Actions Min           -0.844898
evaluation/Num Paths             15
evaluation/Average Returns     -459.259
time/data storing (s)             0.00279264
time/evaluation sampling (s)      0.326106
time/exploration sampling (s)     0.139957
time/logging (s)                  0.00480232
time/saving (s)                   0.00196363
time/training (s)                 1.92273
time/epoch (s)                    2.39836
time/total (s)                    7.79261
Epoch                             2
-----------------------------  -------------
2019-04-22 23:49:59.741700 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             2200
trainer/QF1 Loss                  2.01943
trainer/QF2 Loss                  2.02172
trainer/Policy Loss              27.8484
trainer/Q1 Predictions Mean     -29.8844
trainer/Q1 Predictions Std       13.3409
trainer/Q1 Predictions Max      -11.2531
trainer/Q1 Predictions Min      -57.8167
trainer/Q2 Predictions Mean     -29.9095
trainer/Q2 Predictions Std       13.3967
trainer/Q2 Predictions Max      -11.2666
trainer/Q2 Predictions Min      -58.4905
trainer/Q Targets Mean          -30.7227
trainer/Q Targets Std            13.7969
trainer/Q Targets Max           -11.5881
trainer/Q Targets Min           -58.2742
trainer/Log Pis Mean             -0.341471
trainer/Log Pis Std               1.28087
trainer/Log Pis Max               2.84175
trainer/Log Pis Min              -3.30716
trainer/Policy mu Mean            0.26767
trainer/Policy mu Std             0.718538
trainer/Policy mu Max             1.5562
trainer/Policy mu Min            -1.34057
trainer/Policy log std Mean      -0.449292
trainer/Policy log std Std        0.0864101
trainer/Policy log std Max       -0.314971
trainer/Policy log std Min       -0.626784
trainer/Alpha                     0.660475
trainer/Alpha Loss               -0.970641
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -5.41104
exploration/Rewards Std           3.30469
exploration/Rewards Max          -0.0666421
exploration/Rewards Min         -10.2362
exploration/Returns Mean       -541.104
exploration/Returns Std         310.233
exploration/Returns Max        -137.848
exploration/Returns Min        -842.264
exploration/Actions Mean          0.0480462
exploration/Actions Std           0.539106
exploration/Actions Max           0.993835
exploration/Actions Min          -0.992405
exploration/Num Paths             5
exploration/Average Returns    -541.104
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -5.41504
evaluation/Rewards Std            3.4615
evaluation/Rewards Max           -0.944944
evaluation/Rewards Min          -10.0298
evaluation/Returns Mean        -541.504
evaluation/Returns Std          335.144
evaluation/Returns Max         -114.013
evaluation/Returns Min         -830.75
evaluation/Actions Mean           0.0340973
evaluation/Actions Std            0.15961
evaluation/Actions Max            0.91141
evaluation/Actions Min           -0.908592
evaluation/Num Paths             15
evaluation/Average Returns     -541.504
time/data storing (s)             0.00293287
time/evaluation sampling (s)      0.327303
time/exploration sampling (s)     0.136554
time/logging (s)                  0.00475931
time/saving (s)                   0.00196911
time/training (s)                 1.92454
time/epoch (s)                    2.39806
time/total (s)                   10.1941
Epoch                             3
-----------------------------  -------------
2019-04-22 23:50:02.143184 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                  1.24333
trainer/QF2 Loss                  1.24459
trainer/Policy Loss              35.3064
trainer/Q1 Predictions Mean     -37.0651
trainer/Q1 Predictions Std       19.854
trainer/Q1 Predictions Max      -13.5868
trainer/Q1 Predictions Min      -71.0878
trainer/Q2 Predictions Mean     -37.0639
trainer/Q2 Predictions Std       19.8141
trainer/Q2 Predictions Max      -13.4169
trainer/Q2 Predictions Min      -70.3013
trainer/Q Targets Mean          -37.4373
trainer/Q Targets Std            19.9077
trainer/Q Targets Max           -13.8091
trainer/Q Targets Min           -68.4753
trainer/Log Pis Mean             -0.469326
trainer/Log Pis Std               1.35227
trainer/Log Pis Max               3.30053
trainer/Log Pis Min              -3.64933
trainer/Policy mu Mean            0.139716
trainer/Policy mu Std             0.71336
trainer/Policy mu Max             1.75782
trainer/Policy mu Min            -1.68527
trainer/Policy log std Mean      -0.468004
trainer/Policy log std Std        0.129924
trainer/Policy log std Max       -0.290437
trainer/Policy log std Min       -0.690351
trainer/Alpha                     0.57638
trainer/Alpha Loss               -1.35991
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.84921
exploration/Rewards Std           3.27663
exploration/Rewards Max          -0.0918588
exploration/Rewards Min         -10.9918
exploration/Returns Mean       -384.921
exploration/Returns Std         311.313
exploration/Returns Max        -111.32
exploration/Returns Min        -812.485
exploration/Actions Mean          0.0152619
exploration/Actions Std           0.521489
exploration/Actions Max           0.977996
exploration/Actions Min          -0.98128
exploration/Num Paths             5
exploration/Average Returns    -384.921
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.60571
evaluation/Rewards Std            3.14549
evaluation/Rewards Max           -0.842399
evaluation/Rewards Min           -9.87594
evaluation/Returns Mean        -360.571
evaluation/Returns Std          306.837
evaluation/Returns Max          -98.7015
evaluation/Returns Min         -746.999
evaluation/Actions Mean           0.0190965
evaluation/Actions Std            0.142302
evaluation/Actions Max            0.940078
evaluation/Actions Min           -0.887005
evaluation/Num Paths             15
evaluation/Average Returns     -360.571
time/data storing (s)             0.00282052
time/evaluation sampling (s)      0.325142
time/exploration sampling (s)     0.13751
time/logging (s)                  0.00478492
time/saving (s)                   0.00192841
time/training (s)                 1.92442
time/epoch (s)                    2.3966
time/total (s)                   12.595
Epoch                             4
-----------------------------  -------------
2019-04-22 23:50:04.540990 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             3200
trainer/QF1 Loss                  1.22632
trainer/QF2 Loss                  1.23335
trainer/Policy Loss              38.3398
trainer/Q1 Predictions Mean     -40.0708
trainer/Q1 Predictions Std       24.4145
trainer/Q1 Predictions Max      -16.0221
trainer/Q1 Predictions Min      -82.5581
trainer/Q2 Predictions Mean     -40.0438
trainer/Q2 Predictions Std       24.4085
trainer/Q2 Predictions Max      -15.7175
trainer/Q2 Predictions Min      -82.7397
trainer/Q Targets Mean          -40.0239
trainer/Q Targets Std            24.7248
trainer/Q Targets Max           -15.2947
trainer/Q Targets Min           -82.767
trainer/Log Pis Mean             -0.249671
trainer/Log Pis Std               1.3128
trainer/Log Pis Max               3.74005
trainer/Log Pis Min              -2.87549
trainer/Policy mu Mean            0.0454207
trainer/Policy mu Std             0.75649
trainer/Policy mu Max             1.87266
trainer/Policy mu Min            -1.64927
trainer/Policy log std Mean      -0.576598
trainer/Policy log std Std        0.18071
trainer/Policy log std Max       -0.248772
trainer/Policy log std Min       -0.817693
trainer/Alpha                     0.501621
trainer/Alpha Loss               -1.55147
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.14425
exploration/Rewards Std           2.39636
exploration/Rewards Max          -0.227559
exploration/Rewards Min          -9.04645
exploration/Returns Mean       -414.425
exploration/Returns Std         226.102
exploration/Returns Max        -135.294
exploration/Returns Min        -603.105
exploration/Actions Mean          0.0107578
exploration/Actions Std           0.534228
exploration/Actions Max           0.983892
exploration/Actions Min          -0.989084
exploration/Num Paths             5
exploration/Average Returns    -414.425
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.97043
evaluation/Rewards Std            2.32241
evaluation/Rewards Max           -1.02329
evaluation/Rewards Min           -9.84068
evaluation/Returns Mean        -397.043
evaluation/Returns Std          224.054
evaluation/Returns Max         -107.688
evaluation/Returns Min         -590.491
evaluation/Actions Mean           0.0237936
evaluation/Actions Std            0.151102
evaluation/Actions Max            0.94967
evaluation/Actions Min           -0.883887
evaluation/Num Paths             15
evaluation/Average Returns     -397.043
time/data storing (s)             0.0029189
time/evaluation sampling (s)      0.330659
time/exploration sampling (s)     0.138291
time/logging (s)                  0.0035634
time/saving (s)                   0.00193503
time/training (s)                 1.91429
time/epoch (s)                    2.39165
time/total (s)                   14.9907
Epoch                             5
-----------------------------  -------------
2019-04-22 23:50:06.925475 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                  45.3308
trainer/QF2 Loss                  45.7896
trainer/Policy Loss               52.3051
trainer/Q1 Predictions Mean      -53.7473
trainer/Q1 Predictions Std        30.8294
trainer/Q1 Predictions Max       -17.5597
trainer/Q1 Predictions Min       -96.3555
trainer/Q2 Predictions Mean      -53.768
trainer/Q2 Predictions Std        30.8429
trainer/Q2 Predictions Max       -17.6448
trainer/Q2 Predictions Min       -96.4494
trainer/Q Targets Mean           -53.3387
trainer/Q Targets Std             31.1689
trainer/Q Targets Max            -12.685
trainer/Q Targets Min            -95.886
trainer/Log Pis Mean              -0.0296283
trainer/Log Pis Std                1.24394
trainer/Log Pis Max                4.12934
trainer/Log Pis Min               -3.30739
trainer/Policy mu Mean            -0.141243
trainer/Policy mu Std              0.796466
trainer/Policy mu Max              1.98939
trainer/Policy mu Min             -1.74878
trainer/Policy log std Mean       -0.553539
trainer/Policy log std Std         0.175675
trainer/Policy log std Max        -0.282818
trainer/Policy log std Min        -0.833479
trainer/Alpha                      0.437444
trainer/Alpha Loss                -1.67756
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.89232
exploration/Rewards Std            1.67676
exploration/Rewards Max           -0.0637146
exploration/Rewards Min          -10.9951
exploration/Returns Mean        -389.232
exploration/Returns Std          145.965
exploration/Returns Max          -98.2044
exploration/Returns Min         -482.316
exploration/Actions Mean           0.0165749
exploration/Actions Std            0.525789
exploration/Actions Max            0.99645
exploration/Actions Min           -0.994303
exploration/Num Paths              5
exploration/Average Returns     -389.232
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.89446
evaluation/Rewards Std             1.92384
evaluation/Rewards Max            -0.786758
evaluation/Rewards Min           -10.3186
evaluation/Returns Mean         -289.446
evaluation/Returns Std           180.8
evaluation/Returns Max           -85.4165
evaluation/Returns Min          -470.913
evaluation/Actions Mean            0.00598263
evaluation/Actions Std             0.15151
evaluation/Actions Max             0.954435
evaluation/Actions Min            -0.939416
evaluation/Num Paths              15
evaluation/Average Returns      -289.446
time/data storing (s)              0.00326848
time/evaluation sampling (s)       0.320164
time/exploration sampling (s)      0.142144
time/logging (s)                   0.00485521
time/saving (s)                    0.00194151
time/training (s)                  1.90912
time/epoch (s)                     2.38149
time/total (s)                    17.376
Epoch                              6
-----------------------------  --------------
2019-04-22 23:50:09.310969 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                 216.419
trainer/QF2 Loss                 216.213
trainer/Policy Loss               60.6737
trainer/Q1 Predictions Mean      -62.4942
trainer/Q1 Predictions Std        34.2125
trainer/Q1 Predictions Max       -19.4271
trainer/Q1 Predictions Min      -109.14
trainer/Q2 Predictions Mean      -62.4893
trainer/Q2 Predictions Std        34.2659
trainer/Q2 Predictions Max       -19.2844
trainer/Q2 Predictions Min      -109.463
trainer/Q Targets Mean           -60.1784
trainer/Q Targets Std             35.8377
trainer/Q Targets Max             -3.69797
trainer/Q Targets Min           -111.692
trainer/Log Pis Mean              -0.0613597
trainer/Log Pis Std                1.34017
trainer/Log Pis Max                3.69175
trainer/Log Pis Min               -3.11882
trainer/Policy mu Mean            -0.195193
trainer/Policy mu Std              0.832883
trainer/Policy mu Max              2.13936
trainer/Policy mu Min             -1.84056
trainer/Policy log std Mean       -0.599767
trainer/Policy log std Std         0.134289
trainer/Policy log std Max        -0.368572
trainer/Policy log std Min        -0.778377
trainer/Alpha                      0.38271
trainer/Alpha Loss                -1.97936
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.42215
exploration/Rewards Std            1.41624
exploration/Rewards Max           -0.0210526
exploration/Rewards Min           -7.72023
exploration/Returns Mean        -342.215
exploration/Returns Std          131.069
exploration/Returns Max          -80.5436
exploration/Returns Min         -418.651
exploration/Actions Mean           0.00453751
exploration/Actions Std            0.496435
exploration/Actions Max            0.985672
exploration/Actions Min           -0.984023
exploration/Num Paths              5
exploration/Average Returns     -342.215
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.77558
evaluation/Rewards Std             1.7491
evaluation/Rewards Max            -0.058411
evaluation/Rewards Min           -10.5407
evaluation/Returns Mean         -177.558
evaluation/Returns Std           159.893
evaluation/Returns Max           -48.7327
evaluation/Returns Min          -420.761
evaluation/Actions Mean            0.00163986
evaluation/Actions Std             0.138951
evaluation/Actions Max             0.967297
evaluation/Actions Min            -0.950936
evaluation/Num Paths              15
evaluation/Average Returns      -177.558
time/data storing (s)              0.00280899
time/evaluation sampling (s)       0.32979
time/exploration sampling (s)      0.141121
time/logging (s)                   0.00472386
time/saving (s)                    0.00194051
time/training (s)                  1.9
time/epoch (s)                     2.38038
time/total (s)                    19.7605
Epoch                              7
-----------------------------  --------------
2019-04-22 23:50:11.703795 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                 100.324
trainer/QF2 Loss                 100.037
trainer/Policy Loss               70.0662
trainer/Q1 Predictions Mean      -71.6714
trainer/Q1 Predictions Std        34.3944
trainer/Q1 Predictions Max       -21.0461
trainer/Q1 Predictions Min      -119.236
trainer/Q2 Predictions Mean      -71.6655
trainer/Q2 Predictions Std        34.3774
trainer/Q2 Predictions Max       -20.8059
trainer/Q2 Predictions Min      -119.531
trainer/Q Targets Mean           -70.9122
trainer/Q Targets Std             35.0919
trainer/Q Targets Max            -10.1778
trainer/Q Targets Min           -117.914
trainer/Log Pis Mean               0.196966
trainer/Log Pis Std                1.23231
trainer/Log Pis Max                3.93854
trainer/Log Pis Min               -2.31173
trainer/Policy mu Mean            -0.113563
trainer/Policy mu Std              0.928584
trainer/Policy mu Max              2.03977
trainer/Policy mu Min             -1.96916
trainer/Policy log std Mean       -0.686329
trainer/Policy log std Std         0.128859
trainer/Policy log std Max        -0.43701
trainer/Policy log std Min        -0.877866
trainer/Alpha                      0.335758
trainer/Alpha Loss                -1.96732
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.75842
exploration/Rewards Std            0.725417
exploration/Rewards Max           -2.47392
exploration/Rewards Min           -9.76473
exploration/Returns Mean        -375.842
exploration/Returns Std           14.0045
exploration/Returns Max         -354.672
exploration/Returns Min         -397.247
exploration/Actions Mean          -0.00984676
exploration/Actions Std            0.462319
exploration/Actions Max            0.968228
exploration/Actions Min           -0.978057
exploration/Num Paths              5
exploration/Average Returns     -375.842
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.23399
evaluation/Rewards Std             0.978194
evaluation/Rewards Max            -0.639233
evaluation/Rewards Min            -8.53337
evaluation/Returns Mean         -323.399
evaluation/Returns Std            88.9294
evaluation/Returns Max           -92.9106
evaluation/Returns Min          -370.503
evaluation/Actions Mean            0.00413511
evaluation/Actions Std             0.13787
evaluation/Actions Max             0.921067
evaluation/Actions Min            -0.947166
evaluation/Num Paths              15
evaluation/Average Returns      -323.399
time/data storing (s)              0.00282412
time/evaluation sampling (s)       0.323541
time/exploration sampling (s)      0.138481
time/logging (s)                   0.00495421
time/saving (s)                    0.00196413
time/training (s)                  1.91686
time/epoch (s)                     2.38862
time/total (s)                    22.1527
Epoch                              8
-----------------------------  --------------
2019-04-22 23:50:14.107708 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                   2.41384
trainer/QF2 Loss                   2.43518
trainer/Policy Loss               69.3053
trainer/Q1 Predictions Mean      -70.373
trainer/Q1 Predictions Std        39.2813
trainer/Q1 Predictions Max       -21.2758
trainer/Q1 Predictions Min      -124.701
trainer/Q2 Predictions Mean      -70.3499
trainer/Q2 Predictions Std        39.2894
trainer/Q2 Predictions Max       -21.2461
trainer/Q2 Predictions Min      -124.539
trainer/Q Targets Mean           -71.4435
trainer/Q Targets Std             40.0288
trainer/Q Targets Max            -21.6006
trainer/Q Targets Min           -127.979
trainer/Log Pis Mean               0.317364
trainer/Log Pis Std                1.40338
trainer/Log Pis Max                4.60091
trainer/Log Pis Min               -2.99899
trainer/Policy mu Mean            -0.173595
trainer/Policy mu Std              0.908151
trainer/Policy mu Max              2.19948
trainer/Policy mu Min             -1.92871
trainer/Policy log std Mean       -0.677601
trainer/Policy log std Std         0.124184
trainer/Policy log std Max        -0.395881
trainer/Policy log std Min        -0.874655
trainer/Alpha                      0.294841
trainer/Alpha Loss                -2.0546
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.97962
exploration/Rewards Std            1.32558
exploration/Rewards Max           -0.0306772
exploration/Rewards Min           -9.88671
exploration/Returns Mean        -297.962
exploration/Returns Std           92.5627
exploration/Returns Max         -114.215
exploration/Returns Min         -361.935
exploration/Actions Mean           0.0158034
exploration/Actions Std            0.464276
exploration/Actions Max            0.988947
exploration/Actions Min           -0.977845
exploration/Num Paths              5
exploration/Average Returns     -297.962
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.56877
evaluation/Rewards Std             1.42475
evaluation/Rewards Max            -0.195577
evaluation/Rewards Min            -8.67547
evaluation/Returns Mean         -256.877
evaluation/Returns Std           132.309
evaluation/Returns Max           -30.9814
evaluation/Returns Min          -347.493
evaluation/Actions Mean            0.00999188
evaluation/Actions Std             0.15594
evaluation/Actions Max             0.97197
evaluation/Actions Min            -0.962462
evaluation/Num Paths              15
evaluation/Average Returns      -256.877
time/data storing (s)              0.00289394
time/evaluation sampling (s)       0.329577
time/exploration sampling (s)      0.14083
time/logging (s)                   0.00482636
time/saving (s)                    0.00198215
time/training (s)                  1.9185
time/epoch (s)                     2.39861
time/total (s)                    24.5557
Epoch                              9
-----------------------------  --------------
2019-04-22 23:50:16.582804 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                 100.598
trainer/QF2 Loss                 100.602
trainer/Policy Loss               76.1399
trainer/Q1 Predictions Mean      -77.8098
trainer/Q1 Predictions Std        40.3781
trainer/Q1 Predictions Max       -23.2697
trainer/Q1 Predictions Min      -135.742
trainer/Q2 Predictions Mean      -77.8253
trainer/Q2 Predictions Std        40.4178
trainer/Q2 Predictions Max       -23.279
trainer/Q2 Predictions Min      -136.137
trainer/Q Targets Mean           -77.3749
trainer/Q Targets Std             41.7182
trainer/Q Targets Max             -2.86121
trainer/Q Targets Min           -136.906
trainer/Log Pis Mean               0.49328
trainer/Log Pis Std                1.58533
trainer/Log Pis Max                3.97646
trainer/Log Pis Min               -3.14759
trainer/Policy mu Mean            -0.307645
trainer/Policy mu Std              1.02032
trainer/Policy mu Max              2.41964
trainer/Policy mu Min             -2.07377
trainer/Policy log std Mean       -0.693713
trainer/Policy log std Std         0.109063
trainer/Policy log std Max        -0.463584
trainer/Policy log std Min        -0.862963
trainer/Alpha                      0.259167
trainer/Alpha Loss                -2.03414
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.02228
exploration/Rewards Std            1.15676
exploration/Rewards Max           -0.0908267
exploration/Rewards Min           -7.84858
exploration/Returns Mean        -202.228
exploration/Returns Std           96.1989
exploration/Returns Max          -73.6
exploration/Returns Min         -283.113
exploration/Actions Mean           0.0120815
exploration/Actions Std            0.438656
exploration/Actions Max            0.991064
exploration/Actions Min           -0.956683
exploration/Num Paths              5
exploration/Average Returns     -202.228
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.86524
evaluation/Rewards Std             1.35197
evaluation/Rewards Max            -0.216191
evaluation/Rewards Min            -9.62285
evaluation/Returns Mean         -186.524
evaluation/Returns Std           119.663
evaluation/Returns Max           -26.6358
evaluation/Returns Min          -299.529
evaluation/Actions Mean            0.00185154
evaluation/Actions Std             0.141288
evaluation/Actions Max             0.98201
evaluation/Actions Min            -0.963813
evaluation/Num Paths              15
evaluation/Average Returns      -186.524
time/data storing (s)              0.0028665
time/evaluation sampling (s)       0.327341
time/exploration sampling (s)      0.141641
time/logging (s)                   0.004765
time/saving (s)                    0.0019559
time/training (s)                  1.99133
time/epoch (s)                     2.4699
time/total (s)                    27.0299
Epoch                             10
-----------------------------  --------------
2019-04-22 23:50:19.111849 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   3.20758
trainer/QF2 Loss                   3.12437
trainer/Policy Loss               69.606
trainer/Q1 Predictions Mean      -70.8276
trainer/Q1 Predictions Std        39.9134
trainer/Q1 Predictions Max       -23.8589
trainer/Q1 Predictions Min      -138.944
trainer/Q2 Predictions Mean      -70.808
trainer/Q2 Predictions Std        39.9494
trainer/Q2 Predictions Max       -23.9748
trainer/Q2 Predictions Min      -139.033
trainer/Q Targets Mean           -71.8997
trainer/Q Targets Std             40.9324
trainer/Q Targets Max            -23.8618
trainer/Q Targets Min           -141.219
trainer/Log Pis Mean               0.503923
trainer/Log Pis Std                1.51757
trainer/Log Pis Max                4.89403
trainer/Log Pis Min               -4.7629
trainer/Policy mu Mean            -0.122747
trainer/Policy mu Std              0.980286
trainer/Policy mu Max              2.24678
trainer/Policy mu Min             -2.09244
trainer/Policy log std Mean       -0.778309
trainer/Policy log std Std         0.11444
trainer/Policy log std Max        -0.440694
trainer/Policy log std Min        -0.945349
trainer/Alpha                      0.227745
trainer/Alpha Loss                -2.21313
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.805767
exploration/Rewards Std            1.07368
exploration/Rewards Max           -0.0490472
exploration/Rewards Min          -10.2713
exploration/Returns Mean         -80.5767
exploration/Returns Std           24.0498
exploration/Returns Max          -55.7555
exploration/Returns Min         -115.911
exploration/Actions Mean           0.0239873
exploration/Actions Std            0.415013
exploration/Actions Max            0.99596
exploration/Actions Min           -0.912556
exploration/Num Paths              5
exploration/Average Returns      -80.5767
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.79157
evaluation/Rewards Std             1.3239
evaluation/Rewards Max            -0.239784
evaluation/Rewards Min           -11.1396
evaluation/Returns Mean         -179.157
evaluation/Returns Std           118.995
evaluation/Returns Max           -24.9049
evaluation/Returns Min          -302.248
evaluation/Actions Mean            0.0014661
evaluation/Actions Std             0.148002
evaluation/Actions Max             0.977552
evaluation/Actions Min            -0.985266
evaluation/Num Paths              15
evaluation/Average Returns      -179.157
time/data storing (s)              0.00286563
time/evaluation sampling (s)       0.328877
time/exploration sampling (s)      0.142604
time/logging (s)                   0.00475252
time/saving (s)                    0.00197999
time/training (s)                  2.04299
time/epoch (s)                     2.52407
time/total (s)                    29.5583
Epoch                             11
-----------------------------  --------------
2019-04-22 23:50:21.657097 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              6700
trainer/QF1 Loss                 140.968
trainer/QF2 Loss                 140.946
trainer/Policy Loss               71.5354
trainer/Q1 Predictions Mean      -73.0996
trainer/Q1 Predictions Std        42.4053
trainer/Q1 Predictions Max       -24.7812
trainer/Q1 Predictions Min      -146.697
trainer/Q2 Predictions Mean      -73.1016
trainer/Q2 Predictions Std        42.4406
trainer/Q2 Predictions Max       -24.798
trainer/Q2 Predictions Min      -146.733
trainer/Q Targets Mean           -71.6581
trainer/Q Targets Std             43.6023
trainer/Q Targets Max             -0.475231
trainer/Q Targets Min           -147.282
trainer/Log Pis Mean               0.438274
trainer/Log Pis Std                1.4795
trainer/Log Pis Max                4.118
trainer/Log Pis Min               -3.6546
trainer/Policy mu Mean            -0.167142
trainer/Policy mu Std              0.98985
trainer/Policy mu Max              2.6099
trainer/Policy mu Min             -2.14283
trainer/Policy log std Mean       -0.850425
trainer/Policy log std Std         0.146792
trainer/Policy log std Max        -0.536612
trainer/Policy log std Min        -1.11153
trainer/Alpha                      0.200873
trainer/Alpha Loss                -2.50629
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.52016
exploration/Rewards Std            1.15315
exploration/Rewards Max           -0.046652
exploration/Rewards Min           -9.06479
exploration/Returns Mean        -252.016
exploration/Returns Std           75.5701
exploration/Returns Max         -101.52
exploration/Returns Min         -303.045
exploration/Actions Mean           0.0034456
exploration/Actions Std            0.436458
exploration/Actions Max            0.99707
exploration/Actions Min           -0.990513
exploration/Num Paths              5
exploration/Average Returns     -252.016
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.56792
evaluation/Rewards Std             1.35962
evaluation/Rewards Max            -0.0198447
evaluation/Rewards Min            -9.10725
evaluation/Returns Mean         -156.792
evaluation/Returns Std           120.577
evaluation/Returns Max           -33.691
evaluation/Returns Min          -303.341
evaluation/Actions Mean            0.00279355
evaluation/Actions Std             0.142945
evaluation/Actions Max             0.984805
evaluation/Actions Min            -0.967323
evaluation/Num Paths              15
evaluation/Average Returns      -156.792
time/data storing (s)              0.0030435
time/evaluation sampling (s)       0.3442
time/exploration sampling (s)      0.15182
time/logging (s)                   0.00397006
time/saving (s)                    0.00199651
time/training (s)                  2.03432
time/epoch (s)                     2.53935
time/total (s)                    32.1019
Epoch                             12
-----------------------------  --------------
2019-04-22 23:50:24.147421 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                 124.62
trainer/QF2 Loss                 124.156
trainer/Policy Loss               75.3641
trainer/Q1 Predictions Mean      -77.0026
trainer/Q1 Predictions Std        42.511
trainer/Q1 Predictions Max       -24.7666
trainer/Q1 Predictions Min      -152.007
trainer/Q2 Predictions Mean      -76.9973
trainer/Q2 Predictions Std        42.5462
trainer/Q2 Predictions Max       -24.5178
trainer/Q2 Predictions Min      -151.891
trainer/Q Targets Mean           -76.3026
trainer/Q Targets Std             43.6658
trainer/Q Targets Max             -2.03235
trainer/Q Targets Min           -150.989
trainer/Log Pis Mean               0.922436
trainer/Log Pis Std                1.65308
trainer/Log Pis Max                4.99473
trainer/Log Pis Min               -2.81755
trainer/Policy mu Mean            -0.0818867
trainer/Policy mu Std              1.08867
trainer/Policy mu Max              2.69542
trainer/Policy mu Min             -2.22831
trainer/Policy log std Mean       -0.866767
trainer/Policy log std Std         0.150025
trainer/Policy log std Max        -0.511825
trainer/Policy log std Min        -1.14351
trainer/Alpha                      0.176967
trainer/Alpha Loss                -1.86586
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.96938
exploration/Rewards Std            1.26419
exploration/Rewards Max           -0.0382465
exploration/Rewards Min           -4.84707
exploration/Returns Mean        -196.938
exploration/Returns Std          116.438
exploration/Returns Max          -53.8459
exploration/Returns Min         -301.098
exploration/Actions Mean          -0.0132282
exploration/Actions Std            0.408822
exploration/Actions Max            0.917677
exploration/Actions Min           -0.98277
exploration/Num Paths              5
exploration/Average Returns     -196.938
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.53021
evaluation/Rewards Std             1.45137
evaluation/Rewards Max            -0.0658124
evaluation/Rewards Min           -10.9895
evaluation/Returns Mean         -153.021
evaluation/Returns Std           123.573
evaluation/Returns Max           -21.1964
evaluation/Returns Min          -308.468
evaluation/Actions Mean            0.00491838
evaluation/Actions Std             0.158597
evaluation/Actions Max             0.985183
evaluation/Actions Min            -0.984049
evaluation/Num Paths              15
evaluation/Average Returns      -153.021
time/data storing (s)              0.00302464
time/evaluation sampling (s)       0.345274
time/exploration sampling (s)      0.15024
time/logging (s)                   0.00478965
time/saving (s)                    0.019851
time/training (s)                  1.96296
time/epoch (s)                     2.48614
time/total (s)                    34.5921
Epoch                             13
-----------------------------  --------------
2019-04-22 23:50:26.650199 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                 123.266
trainer/QF2 Loss                 123.2
trainer/Policy Loss               74.5015
trainer/Q1 Predictions Mean      -75.0681
trainer/Q1 Predictions Std        42.4028
trainer/Q1 Predictions Max       -25.6418
trainer/Q1 Predictions Min      -152.393
trainer/Q2 Predictions Mean      -75.0162
trainer/Q2 Predictions Std        42.4265
trainer/Q2 Predictions Max       -25.4125
trainer/Q2 Predictions Min      -152.588
trainer/Q Targets Mean           -74.8795
trainer/Q Targets Std             43.3393
trainer/Q Targets Max             -6.0023
trainer/Q Targets Min           -152.992
trainer/Log Pis Mean               0.808158
trainer/Log Pis Std                1.56907
trainer/Log Pis Max                4.76183
trainer/Log Pis Min               -2.36099
trainer/Policy mu Mean            -0.209915
trainer/Policy mu Std              1.0113
trainer/Policy mu Max              2.55063
trainer/Policy mu Min             -2.41279
trainer/Policy log std Mean       -0.926889
trainer/Policy log std Std         0.16728
trainer/Policy log std Max        -0.527841
trainer/Policy log std Min        -1.22409
trainer/Alpha                      0.156692
trainer/Alpha Loss                -2.20876
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.92035
exploration/Rewards Std            1.33277
exploration/Rewards Max           -0.0287625
exploration/Rewards Min          -10.3152
exploration/Returns Mean        -192.035
exploration/Returns Std          105.423
exploration/Returns Max          -57.2942
exploration/Returns Min         -297.967
exploration/Actions Mean           0.0166905
exploration/Actions Std            0.414349
exploration/Actions Max            0.99519
exploration/Actions Min           -0.990693
exploration/Num Paths              5
exploration/Average Returns     -192.035
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.2331
evaluation/Rewards Std             1.4398
evaluation/Rewards Max            -0.0758804
evaluation/Rewards Min           -11.4352
evaluation/Returns Mean         -123.31
evaluation/Returns Std            98.2965
evaluation/Returns Max           -26.3544
evaluation/Returns Min          -264.48
evaluation/Actions Mean            0.0244057
evaluation/Actions Std             0.182191
evaluation/Actions Max             0.986519
evaluation/Actions Min            -0.976028
evaluation/Num Paths              15
evaluation/Average Returns      -123.31
time/data storing (s)              0.00308007
time/evaluation sampling (s)       0.325169
time/exploration sampling (s)      0.145419
time/logging (s)                   0.00478545
time/saving (s)                    0.00198956
time/training (s)                  2.0173
time/epoch (s)                     2.49775
time/total (s)                    37.094
Epoch                             14
-----------------------------  --------------
2019-04-22 23:50:29.066908 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   4.44739
trainer/QF2 Loss                   4.29894
trainer/Policy Loss               83.4532
trainer/Q1 Predictions Mean      -84.3617
trainer/Q1 Predictions Std        41.2943
trainer/Q1 Predictions Max       -25.8923
trainer/Q1 Predictions Min      -139.394
trainer/Q2 Predictions Mean      -84.3594
trainer/Q2 Predictions Std        41.318
trainer/Q2 Predictions Max       -25.7244
trainer/Q2 Predictions Min      -139.369
trainer/Q Targets Mean           -85.9011
trainer/Q Targets Std             42.2238
trainer/Q Targets Max            -25.7063
trainer/Q Targets Min           -143.027
trainer/Log Pis Mean               1.09444
trainer/Log Pis Std                1.58825
trainer/Log Pis Max                7.08409
trainer/Log Pis Min               -2.00749
trainer/Policy mu Mean            -0.261824
trainer/Policy mu Std              1.06051
trainer/Policy mu Max              2.87475
trainer/Policy mu Min             -2.29979
trainer/Policy log std Mean       -0.976883
trainer/Policy log std Std         0.210724
trainer/Policy log std Max        -0.506628
trainer/Policy log std Min        -1.39775
trainer/Alpha                      0.138415
trainer/Alpha Loss                -1.79053
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.45565
exploration/Rewards Std            1.04807
exploration/Rewards Max           -0.19894
exploration/Rewards Min          -10.7809
exploration/Returns Mean        -245.565
exploration/Returns Std           73.5659
exploration/Returns Max         -100.516
exploration/Returns Min         -304.543
exploration/Actions Mean          -0.0124064
exploration/Actions Std            0.40154
exploration/Actions Max            0.982366
exploration/Actions Min           -0.99825
exploration/Num Paths              5
exploration/Average Returns     -245.565
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.58479
evaluation/Rewards Std             1.23768
evaluation/Rewards Max            -0.105064
evaluation/Rewards Min           -10.1866
evaluation/Returns Mean         -158.479
evaluation/Returns Std            81.904
evaluation/Returns Max           -79.6232
evaluation/Returns Min          -283.164
evaluation/Actions Mean            0.0109653
evaluation/Actions Std             0.177273
evaluation/Actions Max             0.991979
evaluation/Actions Min            -0.978524
evaluation/Num Paths              15
evaluation/Average Returns      -158.479
time/data storing (s)              0.00302529
time/evaluation sampling (s)       0.330966
time/exploration sampling (s)      0.142093
time/logging (s)                   0.00479554
time/saving (s)                    0.00196376
time/training (s)                  1.9286
time/epoch (s)                     2.41145
time/total (s)                    39.5098
Epoch                             15
-----------------------------  --------------
2019-04-22 23:50:31.499563 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 16 finished
-----------------------------  ---------------
replay_buffer/size              8700
trainer/QF1 Loss                 117.571
trainer/QF2 Loss                 117.382
trainer/Policy Loss               75.4613
trainer/Q1 Predictions Mean      -75.7879
trainer/Q1 Predictions Std        44.3016
trainer/Q1 Predictions Max       -25.7996
trainer/Q1 Predictions Min      -155.257
trainer/Q2 Predictions Mean      -75.786
trainer/Q2 Predictions Std        44.3625
trainer/Q2 Predictions Max       -25.5577
trainer/Q2 Predictions Min      -155.695
trainer/Q Targets Mean           -75.5065
trainer/Q Targets Std             45.1642
trainer/Q Targets Max             -2.97419
trainer/Q Targets Min           -155.934
trainer/Log Pis Mean               0.805201
trainer/Log Pis Std                1.29725
trainer/Log Pis Max                4.575
trainer/Log Pis Min               -1.85674
trainer/Policy mu Mean            -0.300438
trainer/Policy mu Std              0.893496
trainer/Policy mu Max              2.64549
trainer/Policy mu Min             -2.59165
trainer/Policy log std Mean       -1.1028
trainer/Policy log std Std         0.218815
trainer/Policy log std Max        -0.614121
trainer/Policy log std Min        -1.46596
trainer/Alpha                      0.121045
trainer/Alpha Loss                -2.52262
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.77802
exploration/Rewards Std            1.11472
exploration/Rewards Max           -0.0904991
exploration/Rewards Min           -7.38849
exploration/Returns Mean        -177.802
exploration/Returns Std           90.102
exploration/Returns Max          -58.9417
exploration/Returns Min         -262.791
exploration/Actions Mean           0.000413995
exploration/Actions Std            0.375096
exploration/Actions Max            0.975935
exploration/Actions Min           -0.990213
exploration/Num Paths              5
exploration/Average Returns     -177.802
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.57781
evaluation/Rewards Std             1.12297
evaluation/Rewards Max            -0.258799
evaluation/Rewards Min            -9.3457
evaluation/Returns Mean         -157.781
evaluation/Returns Std            87.7722
evaluation/Returns Max           -48.9026
evaluation/Returns Min          -249.483
evaluation/Actions Mean            0.0114787
evaluation/Actions Std             0.164757
evaluation/Actions Max             0.990159
evaluation/Actions Min            -0.982513
evaluation/Num Paths              15
evaluation/Average Returns      -157.781
time/data storing (s)              0.00293345
time/evaluation sampling (s)       0.332402
time/exploration sampling (s)      0.142897
time/logging (s)                   0.00475952
time/saving (s)                    0.00205175
time/training (s)                  1.9424
time/epoch (s)                     2.42745
time/total (s)                    41.9415
Epoch                             16
-----------------------------  ---------------
2019-04-22 23:50:33.888224 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                 248.653
trainer/QF2 Loss                 248.142
trainer/Policy Loss               83.0913
trainer/Q1 Predictions Mean      -83.7324
trainer/Q1 Predictions Std        45.1883
trainer/Q1 Predictions Max       -26.0014
trainer/Q1 Predictions Min      -156.94
trainer/Q2 Predictions Mean      -83.7535
trainer/Q2 Predictions Std        45.1833
trainer/Q2 Predictions Max       -25.8634
trainer/Q2 Predictions Min      -157.04
trainer/Q Targets Mean           -81.6343
trainer/Q Targets Std             46.8846
trainer/Q Targets Max             -1.04051
trainer/Q Targets Min           -158.032
trainer/Log Pis Mean               1.05583
trainer/Log Pis Std                1.87735
trainer/Log Pis Max                7.83171
trainer/Log Pis Min               -4.27453
trainer/Policy mu Mean            -0.224844
trainer/Policy mu Std              1.01246
trainer/Policy mu Max              2.45427
trainer/Policy mu Min             -2.82264
trainer/Policy log std Mean       -1.15647
trainer/Policy log std Std         0.234307
trainer/Policy log std Max        -0.64044
trainer/Policy log std Min        -1.58644
trainer/Alpha                      0.10791
trainer/Alpha Loss                -2.10195
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.88786
exploration/Rewards Std            1.30294
exploration/Rewards Max           -0.0229077
exploration/Rewards Min           -8.95987
exploration/Returns Mean        -188.786
exploration/Returns Std          114.44
exploration/Returns Max          -45.6276
exploration/Returns Min         -292.819
exploration/Actions Mean           0.0111866
exploration/Actions Std            0.338267
exploration/Actions Max            0.993841
exploration/Actions Min           -0.996895
exploration/Num Paths              5
exploration/Average Returns     -188.786
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.07336
evaluation/Rewards Std             1.47291
evaluation/Rewards Max            -0.0809395
evaluation/Rewards Min           -10.2242
evaluation/Returns Mean         -207.336
evaluation/Returns Std           101.777
evaluation/Returns Max           -41.4367
evaluation/Returns Min          -290.628
evaluation/Actions Mean           -0.00723786
evaluation/Actions Std             0.20842
evaluation/Actions Max             0.989659
evaluation/Actions Min            -0.992389
evaluation/Num Paths              15
evaluation/Average Returns      -207.336
time/data storing (s)              0.00269486
time/evaluation sampling (s)       0.330244
time/exploration sampling (s)      0.144437
time/logging (s)                   0.00350811
time/saving (s)                    0.00154945
time/training (s)                  1.89964
time/epoch (s)                     2.38207
time/total (s)                    44.328
Epoch                             17
-----------------------------  --------------
2019-04-22 23:50:36.330102 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                   1.16052
trainer/QF2 Loss                   1.23366
trainer/Policy Loss               82.4029
trainer/Q1 Predictions Mean      -83.1451
trainer/Q1 Predictions Std        43.1518
trainer/Q1 Predictions Max       -25.5559
trainer/Q1 Predictions Min      -160.928
trainer/Q2 Predictions Mean      -83.1537
trainer/Q2 Predictions Std        43.1407
trainer/Q2 Predictions Max       -25.3124
trainer/Q2 Predictions Min      -160.853
trainer/Q Targets Mean           -83.8253
trainer/Q Targets Std             43.3173
trainer/Q Targets Max            -25.7164
trainer/Q Targets Min           -157.614
trainer/Log Pis Mean               1.01213
trainer/Log Pis Std                1.67199
trainer/Log Pis Max                4.64042
trainer/Log Pis Min               -2.24648
trainer/Policy mu Mean            -0.138418
trainer/Policy mu Std              1.00672
trainer/Policy mu Max              2.75693
trainer/Policy mu Min             -2.56133
trainer/Policy log std Mean       -1.25465
trainer/Policy log std Std         0.262813
trainer/Policy log std Max        -0.565546
trainer/Policy log std Min        -1.68548
trainer/Alpha                      0.0966396
trainer/Alpha Loss                -2.30821
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.92607
exploration/Rewards Std            1.23043
exploration/Rewards Max           -0.034129
exploration/Rewards Min           -8.57029
exploration/Returns Mean        -192.607
exploration/Returns Std          109.728
exploration/Returns Max          -46.5964
exploration/Returns Min         -289.769
exploration/Actions Mean           0.00611828
exploration/Actions Std            0.3108
exploration/Actions Max            0.986838
exploration/Actions Min           -0.997748
exploration/Num Paths              5
exploration/Average Returns     -192.607
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.86118
evaluation/Rewards Std             1.12697
evaluation/Rewards Max            -0.0806609
evaluation/Rewards Min            -7.85562
evaluation/Returns Mean         -186.118
evaluation/Returns Std           104.811
evaluation/Returns Max           -48.2925
evaluation/Returns Min          -278.229
evaluation/Actions Mean            0.00886506
evaluation/Actions Std             0.139537
evaluation/Actions Max             0.989383
evaluation/Actions Min            -0.984828
evaluation/Num Paths              15
evaluation/Average Returns      -186.118
time/data storing (s)              0.00295223
time/evaluation sampling (s)       0.327516
time/exploration sampling (s)      0.141821
time/logging (s)                   0.00354428
time/saving (s)                    0.00194316
time/training (s)                  1.95945
time/epoch (s)                     2.43722
time/total (s)                    46.7692
Epoch                             18
-----------------------------  --------------
2019-04-22 23:50:38.711679 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                 118.952
trainer/QF2 Loss                 119.43
trainer/Policy Loss               77.2163
trainer/Q1 Predictions Mean      -77.4892
trainer/Q1 Predictions Std        44.3558
trainer/Q1 Predictions Max       -25.2901
trainer/Q1 Predictions Min      -140.399
trainer/Q2 Predictions Mean      -77.4535
trainer/Q2 Predictions Std        44.4051
trainer/Q2 Predictions Max       -25.2804
trainer/Q2 Predictions Min      -140.375
trainer/Q Targets Mean           -77.2408
trainer/Q Targets Std             45.1392
trainer/Q Targets Max             -2.88065
trainer/Q Targets Min           -140.699
trainer/Log Pis Mean               1.22151
trainer/Log Pis Std                1.72201
trainer/Log Pis Max                5.46293
trainer/Log Pis Min               -2.16172
trainer/Policy mu Mean            -0.216141
trainer/Policy mu Std              1.01599
trainer/Policy mu Max              2.83678
trainer/Policy mu Min             -2.73261
trainer/Policy log std Mean       -1.29759
trainer/Policy log std Std         0.284876
trainer/Policy log std Max        -0.621813
trainer/Policy log std Min        -1.92761
trainer/Alpha                      0.0870419
trainer/Alpha Loss                -1.9004
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.42893
exploration/Rewards Std            1.04803
exploration/Rewards Max           -0.0180489
exploration/Rewards Min           -6.99903
exploration/Returns Mean        -242.893
exploration/Returns Std           97.0132
exploration/Returns Max          -49.1702
exploration/Returns Min         -297.883
exploration/Actions Mean           0.00827826
exploration/Actions Std            0.3173
exploration/Actions Max            0.97965
exploration/Actions Min           -0.983977
exploration/Num Paths              5
exploration/Average Returns     -242.893
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.28312
evaluation/Rewards Std             1.15455
evaluation/Rewards Max            -0.249292
evaluation/Rewards Min            -8.34016
evaluation/Returns Mean         -228.312
evaluation/Returns Std           102.748
evaluation/Returns Max           -53.7845
evaluation/Returns Min          -300.498
evaluation/Actions Mean            0.00579979
evaluation/Actions Std             0.165609
evaluation/Actions Max             0.986375
evaluation/Actions Min            -0.992996
evaluation/Num Paths              15
evaluation/Average Returns      -228.312
time/data storing (s)              0.00302407
time/evaluation sampling (s)       0.332088
time/exploration sampling (s)      0.144684
time/logging (s)                   0.00474843
time/saving (s)                    0.00194279
time/training (s)                  1.89118
time/epoch (s)                     2.37767
time/total (s)                    49.151
Epoch                             19
-----------------------------  --------------
2019-04-22 23:50:41.131396 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 20 finished
-----------------------------  ---------------
replay_buffer/size             10700
trainer/QF1 Loss                   2.83947
trainer/QF2 Loss                   2.84749
trainer/Policy Loss               81.2317
trainer/Q1 Predictions Mean      -81.1227
trainer/Q1 Predictions Std        43.9662
trainer/Q1 Predictions Max       -24.5023
trainer/Q1 Predictions Min      -157.284
trainer/Q2 Predictions Mean      -81.1581
trainer/Q2 Predictions Std        43.9376
trainer/Q2 Predictions Max       -24.2972
trainer/Q2 Predictions Min      -156.97
trainer/Q Targets Mean           -82.5416
trainer/Q Targets Std             44.5759
trainer/Q Targets Max            -25.1552
trainer/Q Targets Min           -161.607
trainer/Log Pis Mean               1.19314
trainer/Log Pis Std                1.84104
trainer/Log Pis Max                6.96934
trainer/Log Pis Min               -4.67354
trainer/Policy mu Mean            -0.204357
trainer/Policy mu Std              0.976551
trainer/Policy mu Max              3.2165
trainer/Policy mu Min             -2.70915
trainer/Policy log std Mean       -1.29847
trainer/Policy log std Std         0.314556
trainer/Policy log std Max        -0.445415
trainer/Policy log std Min        -1.81509
trainer/Alpha                      0.0782557
trainer/Alpha Loss                -2.0555
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.83592
exploration/Rewards Std            1.12871
exploration/Rewards Max           -0.176046
exploration/Rewards Min          -10.327
exploration/Returns Mean        -183.592
exploration/Returns Std           93.1042
exploration/Returns Max          -68.9344
exploration/Returns Min         -274.361
exploration/Actions Mean          -0.0212935
exploration/Actions Std            0.297811
exploration/Actions Max            0.836377
exploration/Actions Min           -0.998781
exploration/Num Paths              5
exploration/Average Returns     -183.592
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.37038
evaluation/Rewards Std             1.12537
evaluation/Rewards Max            -0.186564
evaluation/Rewards Min            -9.94056
evaluation/Returns Mean         -137.038
evaluation/Returns Std            85.5474
evaluation/Returns Max           -63.855
evaluation/Returns Min          -273.819
evaluation/Actions Mean            0.000278003
evaluation/Actions Std             0.171796
evaluation/Actions Max             0.995583
evaluation/Actions Min            -0.989183
evaluation/Num Paths              15
evaluation/Average Returns      -137.038
time/data storing (s)              0.00296167
time/evaluation sampling (s)       0.336601
time/exploration sampling (s)      0.143235
time/logging (s)                   0.00482969
time/saving (s)                    0.00193904
time/training (s)                  1.92501
time/epoch (s)                     2.41457
time/total (s)                    51.5699
Epoch                             20
-----------------------------  ---------------
2019-04-22 23:50:43.533069 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   1.81953
trainer/QF2 Loss                   1.8917
trainer/Policy Loss               86.4859
trainer/Q1 Predictions Mean      -85.8277
trainer/Q1 Predictions Std        43.3376
trainer/Q1 Predictions Max       -24.6461
trainer/Q1 Predictions Min      -143.343
trainer/Q2 Predictions Mean      -85.7674
trainer/Q2 Predictions Std        43.3045
trainer/Q2 Predictions Max       -24.4315
trainer/Q2 Predictions Min      -142.59
trainer/Q Targets Mean           -86.8515
trainer/Q Targets Std             43.6425
trainer/Q Targets Max            -24.88
trainer/Q Targets Min           -142.503
trainer/Log Pis Mean               1.38656
trainer/Log Pis Std                1.77754
trainer/Log Pis Max                6.08566
trainer/Log Pis Min               -6.05779
trainer/Policy mu Mean            -0.313181
trainer/Policy mu Std              0.908098
trainer/Policy mu Max              2.87008
trainer/Policy mu Min             -2.77579
trainer/Policy log std Mean       -1.4844
trainer/Policy log std Std         0.319077
trainer/Policy log std Max        -0.642842
trainer/Policy log std Min        -1.97746
trainer/Alpha                      0.0707881
trainer/Alpha Loss                -1.62429
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.49145
exploration/Rewards Std            1.00381
exploration/Rewards Max           -0.192333
exploration/Rewards Min           -6.79385
exploration/Returns Mean        -249.145
exploration/Returns Std           86.323
exploration/Returns Max          -76.596
exploration/Returns Min         -296.911
exploration/Actions Mean          -0.00779287
exploration/Actions Std            0.269142
exploration/Actions Max            0.987162
exploration/Actions Min           -0.996622
exploration/Num Paths              5
exploration/Average Returns     -249.145
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.44619
evaluation/Rewards Std             1.38689
evaluation/Rewards Max            -0.0407722
evaluation/Rewards Min           -10.0546
evaluation/Returns Mean         -144.619
evaluation/Returns Std           107.806
evaluation/Returns Max           -53.9425
evaluation/Returns Min          -313.341
evaluation/Actions Mean            0.0184059
evaluation/Actions Std             0.195946
evaluation/Actions Max             0.994638
evaluation/Actions Min            -0.993287
evaluation/Num Paths              15
evaluation/Average Returns      -144.619
time/data storing (s)              0.00308961
time/evaluation sampling (s)       0.329147
time/exploration sampling (s)      0.146729
time/logging (s)                   0.00476577
time/saving (s)                    0.00194609
time/training (s)                  1.91081
time/epoch (s)                     2.39649
time/total (s)                    53.9705
Epoch                             21
-----------------------------  --------------
2019-04-22 23:50:45.896576 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                   0.784963
trainer/QF2 Loss                   0.713558
trainer/Policy Loss               84.5146
trainer/Q1 Predictions Mean      -84.2592
trainer/Q1 Predictions Std        46.1788
trainer/Q1 Predictions Max       -24.4352
trainer/Q1 Predictions Min      -159.939
trainer/Q2 Predictions Mean      -84.3186
trainer/Q2 Predictions Std        46.1617
trainer/Q2 Predictions Max       -24.1961
trainer/Q2 Predictions Min      -159.557
trainer/Q Targets Mean           -84.7607
trainer/Q Targets Std             46.4827
trainer/Q Targets Max            -24.4315
trainer/Q Targets Min           -160.607
trainer/Log Pis Mean               1.56925
trainer/Log Pis Std                1.93856
trainer/Log Pis Max                7.08193
trainer/Log Pis Min               -4.08992
trainer/Policy mu Mean            -0.387215
trainer/Policy mu Std              0.980876
trainer/Policy mu Max              2.84372
trainer/Policy mu Min             -2.95448
trainer/Policy log std Mean       -1.45739
trainer/Policy log std Std         0.358099
trainer/Policy log std Max        -0.574991
trainer/Policy log std Min        -1.94481
trainer/Alpha                      0.0641832
trainer/Alpha Loss                -1.18276
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.04978
exploration/Rewards Std            1.09153
exploration/Rewards Max           -0.138532
exploration/Rewards Min          -10.4259
exploration/Returns Mean        -104.978
exploration/Returns Std           69.886
exploration/Returns Max          -57.4119
exploration/Returns Min         -240.84
exploration/Actions Mean           0.0161346
exploration/Actions Std            0.247403
exploration/Actions Max            0.993042
exploration/Actions Min           -0.99306
exploration/Num Paths              5
exploration/Average Returns     -104.978
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.31233
evaluation/Rewards Std             1.0211
evaluation/Rewards Max            -0.15238
evaluation/Rewards Min            -9.59026
evaluation/Returns Mean         -131.233
evaluation/Returns Std            74.5403
evaluation/Returns Max           -57.0763
evaluation/Returns Min          -225.791
evaluation/Actions Mean            0.0110688
evaluation/Actions Std             0.159072
evaluation/Actions Max             0.994867
evaluation/Actions Min            -0.975448
evaluation/Num Paths              15
evaluation/Average Returns      -131.233
time/data storing (s)              0.00298711
time/evaluation sampling (s)       0.330178
time/exploration sampling (s)      0.140156
time/logging (s)                   0.00352474
time/saving (s)                    0.00194354
time/training (s)                  1.87799
time/epoch (s)                     2.35678
time/total (s)                    56.3317
Epoch                             22
-----------------------------  --------------
2019-04-22 23:50:48.429211 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   3.09943
trainer/QF2 Loss                   3.25211
trainer/Policy Loss               82.6597
trainer/Q1 Predictions Mean      -82.4956
trainer/Q1 Predictions Std        43.3059
trainer/Q1 Predictions Max       -24.0152
trainer/Q1 Predictions Min      -138.178
trainer/Q2 Predictions Mean      -82.4493
trainer/Q2 Predictions Std        43.3395
trainer/Q2 Predictions Max       -23.8146
trainer/Q2 Predictions Min      -138.23
trainer/Q Targets Mean           -83.9799
trainer/Q Targets Std             44.0774
trainer/Q Targets Max            -24.1302
trainer/Q Targets Min           -143.351
trainer/Log Pis Mean               1.77811
trainer/Log Pis Std                1.57914
trainer/Log Pis Max                6.72248
trainer/Log Pis Min               -2.72916
trainer/Policy mu Mean             0.00751206
trainer/Policy mu Std              0.975182
trainer/Policy mu Max              3.21845
trainer/Policy mu Min             -2.64407
trainer/Policy log std Mean       -1.52624
trainer/Policy log std Std         0.37676
trainer/Policy log std Max        -0.435694
trainer/Policy log std Min        -2.08731
trainer/Alpha                      0.0575079
trainer/Alpha Loss                -0.633626
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.92578
exploration/Rewards Std            1.1154
exploration/Rewards Max           -0.254873
exploration/Rewards Min           -6.51919
exploration/Returns Mean        -192.578
exploration/Returns Std          104.309
exploration/Returns Max          -57.4364
exploration/Returns Min         -284.843
exploration/Actions Mean           0.0172517
exploration/Actions Std            0.263367
exploration/Actions Max            0.996042
exploration/Actions Min           -0.979241
exploration/Num Paths              5
exploration/Average Returns     -192.578
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.85281
evaluation/Rewards Std             1.27185
evaluation/Rewards Max            -0.111502
evaluation/Rewards Min           -10.4545
evaluation/Returns Mean         -185.281
evaluation/Returns Std           102.274
evaluation/Returns Max           -62.213
evaluation/Returns Min          -292.343
evaluation/Actions Mean            0.0126167
evaluation/Actions Std             0.172101
evaluation/Actions Max             0.996733
evaluation/Actions Min            -0.992589
evaluation/Num Paths              15
evaluation/Average Returns      -185.281
time/data storing (s)              0.00341738
time/evaluation sampling (s)       0.358529
time/exploration sampling (s)      0.147145
time/logging (s)                   0.00481615
time/saving (s)                    0.00192985
time/training (s)                  2.01375
time/epoch (s)                     2.52959
time/total (s)                    58.8649
Epoch                             23
-----------------------------  --------------
2019-04-22 23:50:50.994525 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size             12700
trainer/QF1 Loss                   1.93819
trainer/QF2 Loss                   1.8611
trainer/Policy Loss               75.2458
trainer/Q1 Predictions Mean      -74.558
trainer/Q1 Predictions Std        46.4377
trainer/Q1 Predictions Max       -23.6645
trainer/Q1 Predictions Min      -162.173
trainer/Q2 Predictions Mean      -74.5785
trainer/Q2 Predictions Std        46.4483
trainer/Q2 Predictions Max       -23.5792
trainer/Q2 Predictions Min      -161.805
trainer/Q Targets Mean           -75.611
trainer/Q Targets Std             46.9972
trainer/Q Targets Max            -24.0104
trainer/Q Targets Min           -160.504
trainer/Log Pis Mean               1.66835
trainer/Log Pis Std                1.60595
trainer/Log Pis Max                7.61087
trainer/Log Pis Min               -2.42522
trainer/Policy mu Mean            -0.0590116
trainer/Policy mu Std              0.98467
trainer/Policy mu Max              3.09822
trainer/Policy mu Min             -2.93247
trainer/Policy log std Mean       -1.62826
trainer/Policy log std Std         0.375732
trainer/Policy log std Max        -0.412721
trainer/Policy log std Min        -2.058
trainer/Alpha                      0.0520459
trainer/Alpha Loss                -0.980187
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.886703
exploration/Rewards Std            1.28466
exploration/Rewards Max           -0.0178476
exploration/Rewards Min           -8.86107
exploration/Returns Mean         -88.6703
exploration/Returns Std          100.449
exploration/Returns Max          -23.2542
exploration/Returns Min         -287.817
exploration/Actions Mean           0.0228839
exploration/Actions Std            0.228646
exploration/Actions Max            0.996164
exploration/Actions Min           -0.816389
exploration/Num Paths              5
exploration/Average Returns      -88.6703
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.74039
evaluation/Rewards Std             1.56707
evaluation/Rewards Max            -0.0449943
evaluation/Rewards Min            -9.86744
evaluation/Returns Mean         -174.039
evaluation/Returns Std           133.448
evaluation/Returns Max           -11.3976
evaluation/Returns Min          -308.505
evaluation/Actions Mean            0.00511285
evaluation/Actions Std             0.186593
evaluation/Actions Max             0.995963
evaluation/Actions Min            -0.996157
evaluation/Num Paths              15
evaluation/Average Returns      -174.039
time/data storing (s)              0.0033011
time/evaluation sampling (s)       0.332804
time/exploration sampling (s)      0.150767
time/logging (s)                   0.00484168
time/saving (s)                    0.00194713
time/training (s)                  2.06587
time/epoch (s)                     2.55953
time/total (s)                    61.4292
Epoch                             24
-----------------------------  --------------
2019-04-22 23:50:53.419529 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   0.683042
trainer/QF2 Loss                   0.694527
trainer/Policy Loss               87.7812
trainer/Q1 Predictions Mean      -87.4712
trainer/Q1 Predictions Std        46.0785
trainer/Q1 Predictions Max       -23.8973
trainer/Q1 Predictions Min      -165.029
trainer/Q2 Predictions Mean      -87.4505
trainer/Q2 Predictions Std        46.1291
trainer/Q2 Predictions Max       -23.7241
trainer/Q2 Predictions Min      -164.849
trainer/Q Targets Mean           -87.8276
trainer/Q Targets Std             46.2854
trainer/Q Targets Max            -24.024
trainer/Q Targets Min           -161.642
trainer/Log Pis Mean               1.86508
trainer/Log Pis Std                1.77881
trainer/Log Pis Max                7.11874
trainer/Log Pis Min               -3.38184
trainer/Policy mu Mean            -0.207732
trainer/Policy mu Std              1.0513
trainer/Policy mu Max              3.13876
trainer/Policy mu Min             -3.0054
trainer/Policy log std Mean       -1.63559
trainer/Policy log std Std         0.410549
trainer/Policy log std Max        -0.668227
trainer/Policy log std Min        -2.11552
trainer/Alpha                      0.0480878
trainer/Alpha Loss                -0.409419
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.95198
exploration/Rewards Std            1.43627
exploration/Rewards Max           -0.0110108
exploration/Rewards Min           -8.86542
exploration/Returns Mean        -195.198
exploration/Returns Std          121.221
exploration/Returns Max          -32.7917
exploration/Returns Min         -295.242
exploration/Actions Mean           0.0260826
exploration/Actions Std            0.242629
exploration/Actions Max            0.998083
exploration/Actions Min           -0.994106
exploration/Num Paths              5
exploration/Average Returns     -195.198
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.55046
evaluation/Rewards Std             1.60588
evaluation/Rewards Max            -0.0624118
evaluation/Rewards Min           -10.0198
evaluation/Returns Mean         -155.046
evaluation/Returns Std           136.716
evaluation/Returns Max            -8.16849
evaluation/Returns Min          -317.146
evaluation/Actions Mean            0.00542362
evaluation/Actions Std             0.182103
evaluation/Actions Max             0.996624
evaluation/Actions Min            -0.996489
evaluation/Num Paths              15
evaluation/Average Returns      -155.046
time/data storing (s)              0.00307238
time/evaluation sampling (s)       0.335742
time/exploration sampling (s)      0.150971
time/logging (s)                   0.00459704
time/saving (s)                    0.00194459
time/training (s)                  1.92247
time/epoch (s)                     2.4188
time/total (s)                    63.8528
Epoch                             25
-----------------------------  --------------
2019-04-22 23:50:55.833588 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                   1.52212
trainer/QF2 Loss                   1.47402
trainer/Policy Loss               77.9978
trainer/Q1 Predictions Mean      -77.0259
trainer/Q1 Predictions Std        46.0333
trainer/Q1 Predictions Max       -23.7806
trainer/Q1 Predictions Min      -140.371
trainer/Q2 Predictions Mean      -77.0168
trainer/Q2 Predictions Std        46.0303
trainer/Q2 Predictions Max       -23.6062
trainer/Q2 Predictions Min      -139.835
trainer/Q Targets Mean           -77.8156
trainer/Q Targets Std             46.6188
trainer/Q Targets Max            -23.7021
trainer/Q Targets Min           -137.305
trainer/Log Pis Mean               1.92201
trainer/Log Pis Std                1.64839
trainer/Log Pis Max                7.07471
trainer/Log Pis Min               -4.46816
trainer/Policy mu Mean            -0.158837
trainer/Policy mu Std              0.914137
trainer/Policy mu Max              3.10909
trainer/Policy mu Min             -2.88043
trainer/Policy log std Mean       -1.70513
trainer/Policy log std Std         0.343502
trainer/Policy log std Max        -0.519366
trainer/Policy log std Min        -2.2065
trainer/Alpha                      0.0461896
trainer/Alpha Loss                -0.23982
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.9398
exploration/Rewards Std            0.918219
exploration/Rewards Max           -0.0903908
exploration/Rewards Min           -7.78893
exploration/Returns Mean        -193.98
exploration/Returns Std           70.5922
exploration/Returns Max          -53.3697
exploration/Returns Min         -240.834
exploration/Actions Mean          -0.00898903
exploration/Actions Std            0.25153
exploration/Actions Max            0.977684
exploration/Actions Min           -0.997698
exploration/Num Paths              5
exploration/Average Returns     -193.98
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.54014
evaluation/Rewards Std             1.28884
evaluation/Rewards Max            -0.181036
evaluation/Rewards Min           -10.0348
evaluation/Returns Mean         -154.014
evaluation/Returns Std            82.911
evaluation/Returns Max           -46.81
evaluation/Returns Min          -241.486
evaluation/Actions Mean            0.0128894
evaluation/Actions Std             0.195701
evaluation/Actions Max             0.996851
evaluation/Actions Min            -0.996103
evaluation/Num Paths              15
evaluation/Average Returns      -154.014
time/data storing (s)              0.00296799
time/evaluation sampling (s)       0.334877
time/exploration sampling (s)      0.143529
time/logging (s)                   0.00477651
time/saving (s)                    0.00194295
time/training (s)                  1.92086
time/epoch (s)                     2.40895
time/total (s)                    66.2663
Epoch                             26
-----------------------------  --------------
2019-04-22 23:50:58.235646 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 27 finished
-----------------------------  ---------------
replay_buffer/size             14200
trainer/QF1 Loss                 145.782
trainer/QF2 Loss                 145.803
trainer/Policy Loss               82.3404
trainer/Q1 Predictions Mean      -81.3746
trainer/Q1 Predictions Std        47.6629
trainer/Q1 Predictions Max       -23.2048
trainer/Q1 Predictions Min      -162.942
trainer/Q2 Predictions Mean      -81.3483
trainer/Q2 Predictions Std        47.6581
trainer/Q2 Predictions Max       -23.0929
trainer/Q2 Predictions Min      -162.815
trainer/Q Targets Mean           -80.4206
trainer/Q Targets Std             49.1048
trainer/Q Targets Max             -0.143976
trainer/Q Targets Min           -163.846
trainer/Log Pis Mean               2.02437
trainer/Log Pis Std                1.78182
trainer/Log Pis Max                7.84756
trainer/Log Pis Min               -2.36587
trainer/Policy mu Mean            -0.15154
trainer/Policy mu Std              0.967169
trainer/Policy mu Max              3.32127
trainer/Policy mu Min             -3.15137
trainer/Policy log std Mean       -1.77452
trainer/Policy log std Std         0.41302
trainer/Policy log std Max        -0.621325
trainer/Policy log std Min        -2.20168
trainer/Alpha                      0.0443173
trainer/Alpha Loss                 0.0759393
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.822236
exploration/Rewards Std            1.11435
exploration/Rewards Max           -0.00191582
exploration/Rewards Min           -7.87469
exploration/Returns Mean         -82.2236
exploration/Returns Std           84.1644
exploration/Returns Max          -30.3739
exploration/Returns Min         -249.625
exploration/Actions Mean           1.40281e-05
exploration/Actions Std            0.246598
exploration/Actions Max            0.991661
exploration/Actions Min           -0.998874
exploration/Num Paths              5
exploration/Average Returns      -82.2236
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.75157
evaluation/Rewards Std             1.19791
evaluation/Rewards Max            -0.185818
evaluation/Rewards Min            -9.28957
evaluation/Returns Mean         -175.157
evaluation/Returns Std            98.7581
evaluation/Returns Max           -25.0225
evaluation/Returns Min          -260.2
evaluation/Actions Mean            0.00597256
evaluation/Actions Std             0.172131
evaluation/Actions Max             0.996064
evaluation/Actions Min            -0.996464
evaluation/Num Paths              15
evaluation/Average Returns      -175.157
time/data storing (s)              0.00286863
time/evaluation sampling (s)       0.33136
time/exploration sampling (s)      0.144962
time/logging (s)                   0.00478831
time/saving (s)                    0.00156976
time/training (s)                  1.91076
time/epoch (s)                     2.39631
time/total (s)                    68.6673
Epoch                             27
-----------------------------  ---------------
2019-04-22 23:51:00.616120 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             14700
trainer/QF1 Loss                 141.113
trainer/QF2 Loss                 141.162
trainer/Policy Loss               78.4467
trainer/Q1 Predictions Mean      -77.3118
trainer/Q1 Predictions Std        48.5927
trainer/Q1 Predictions Max       -23.3709
trainer/Q1 Predictions Min      -161.065
trainer/Q2 Predictions Mean      -77.274
trainer/Q2 Predictions Std        48.5833
trainer/Q2 Predictions Max       -23.4005
trainer/Q2 Predictions Min      -161.498
trainer/Q Targets Mean           -76.3606
trainer/Q Targets Std             49.6559
trainer/Q Targets Max             -0.124912
trainer/Q Targets Min           -161.292
trainer/Log Pis Mean               1.92328
trainer/Log Pis Std                1.21596
trainer/Log Pis Max                6.42475
trainer/Log Pis Min               -1.90359
trainer/Policy mu Mean            -0.143336
trainer/Policy mu Std              0.834221
trainer/Policy mu Max              3.08562
trainer/Policy mu Min             -3.06222
trainer/Policy log std Mean       -1.88261
trainer/Policy log std Std         0.398812
trainer/Policy log std Max        -0.608096
trainer/Policy log std Min        -2.34294
trainer/Alpha                      0.0433577
trainer/Alpha Loss                -0.240775
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.850125
exploration/Rewards Std            1.36627
exploration/Rewards Max           -0.00265861
exploration/Rewards Min          -11.2258
exploration/Returns Mean         -85.0125
exploration/Returns Std           83.8413
exploration/Returns Max          -21.1334
exploration/Returns Min         -248.251
exploration/Actions Mean           0.0289409
exploration/Actions Std            0.241359
exploration/Actions Max            0.999069
exploration/Actions Min           -0.980387
exploration/Num Paths              5
exploration/Average Returns      -85.0125
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.23146
evaluation/Rewards Std             1.46182
evaluation/Rewards Max            -0.032191
evaluation/Rewards Min           -10.5267
evaluation/Returns Mean         -123.146
evaluation/Returns Std            98.8746
evaluation/Returns Max           -14.8566
evaluation/Returns Min          -267.028
evaluation/Actions Mean            0.0200245
evaluation/Actions Std             0.185713
evaluation/Actions Max             0.997647
evaluation/Actions Min            -0.994171
evaluation/Num Paths              15
evaluation/Average Returns      -123.146
time/data storing (s)              0.00294493
time/evaluation sampling (s)       0.334862
time/exploration sampling (s)      0.142819
time/logging (s)                   0.00480303
time/saving (s)                    0.00194799
time/training (s)                  1.88754
time/epoch (s)                     2.37491
time/total (s)                    71.0467
Epoch                             28
-----------------------------  --------------
2019-04-22 23:51:03.016963 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   6.61456
trainer/QF2 Loss                   6.55496
trainer/Policy Loss               79.4969
trainer/Q1 Predictions Mean      -78.9538
trainer/Q1 Predictions Std        47.8955
trainer/Q1 Predictions Max       -22.7236
trainer/Q1 Predictions Min      -162.938
trainer/Q2 Predictions Mean      -78.9672
trainer/Q2 Predictions Std        47.9168
trainer/Q2 Predictions Max       -22.5745
trainer/Q2 Predictions Min      -163.024
trainer/Q Targets Mean           -79.6707
trainer/Q Targets Std             48.7307
trainer/Q Targets Max             -0.564519
trainer/Q Targets Min           -164.471
trainer/Log Pis Mean               2.41187
trainer/Log Pis Std                1.80663
trainer/Log Pis Max                7.59406
trainer/Log Pis Min               -2.29503
trainer/Policy mu Mean            -0.332003
trainer/Policy mu Std              1.1092
trainer/Policy mu Max              3.12419
trainer/Policy mu Min             -3.08548
trainer/Policy log std Mean       -1.73903
trainer/Policy log std Std         0.484858
trainer/Policy log std Max        -0.625313
trainer/Policy log std Min        -2.49857
trainer/Alpha                      0.0449656
trainer/Alpha Loss                 1.2776
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.988755
exploration/Rewards Std            1.26655
exploration/Rewards Max           -0.0296165
exploration/Rewards Min          -10.1978
exploration/Returns Mean         -98.8755
exploration/Returns Std           64.6715
exploration/Returns Max          -43.5588
exploration/Returns Min         -223.255
exploration/Actions Mean           0.0194056
exploration/Actions Std            0.240064
exploration/Actions Max            0.998588
exploration/Actions Min           -0.993651
exploration/Num Paths              5
exploration/Average Returns      -98.8755
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.13878
evaluation/Rewards Std             1.01592
evaluation/Rewards Max            -0.308885
evaluation/Rewards Min           -11.3365
evaluation/Returns Mean         -213.878
evaluation/Returns Std            58.9031
evaluation/Returns Max           -48.7869
evaluation/Returns Min          -263.187
evaluation/Actions Mean           -0.0119681
evaluation/Actions Std             0.182076
evaluation/Actions Max             0.99678
evaluation/Actions Min            -0.995809
evaluation/Num Paths              15
evaluation/Average Returns      -213.878
time/data storing (s)              0.00300376
time/evaluation sampling (s)       0.330246
time/exploration sampling (s)      0.142727
time/logging (s)                   0.00482265
time/saving (s)                    0.00193351
time/training (s)                  1.91245
time/epoch (s)                     2.39518
time/total (s)                    73.4465
Epoch                             29
-----------------------------  --------------
2019-04-22 23:51:05.430036 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                   0.778946
trainer/QF2 Loss                   0.793122
trainer/Policy Loss               69.9773
trainer/Q1 Predictions Mean      -69.1694
trainer/Q1 Predictions Std        50.1416
trainer/Q1 Predictions Max       -22.5869
trainer/Q1 Predictions Min      -169.952
trainer/Q2 Predictions Mean      -69.1461
trainer/Q2 Predictions Std        50.1507
trainer/Q2 Predictions Max       -22.4665
trainer/Q2 Predictions Min      -170.06
trainer/Q Targets Mean           -69.6695
trainer/Q Targets Std             50.4
trainer/Q Targets Max            -22.6113
trainer/Q Targets Min           -167.459
trainer/Log Pis Mean               1.72432
trainer/Log Pis Std                1.78665
trainer/Log Pis Max                7.60631
trainer/Log Pis Min               -5.08961
trainer/Policy mu Mean            -0.26795
trainer/Policy mu Std              0.828276
trainer/Policy mu Max              3.11292
trainer/Policy mu Min             -3.0276
trainer/Policy log std Mean       -1.85838
trainer/Policy log std Std         0.43406
trainer/Policy log std Max        -0.530215
trainer/Policy log std Min        -2.41793
trainer/Alpha                      0.0460727
trainer/Alpha Loss                -0.848424
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.50036
exploration/Rewards Std            1.20843
exploration/Rewards Max           -0.0315421
exploration/Rewards Min          -10.0492
exploration/Returns Mean        -150.036
exploration/Returns Std           95.1434
exploration/Returns Max          -33.0177
exploration/Returns Min         -241.563
exploration/Actions Mean          -0.00790587
exploration/Actions Std            0.242105
exploration/Actions Max            0.985771
exploration/Actions Min           -0.998493
exploration/Num Paths              5
exploration/Average Returns     -150.036
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.65864
evaluation/Rewards Std             1.18609
evaluation/Rewards Max            -0.254343
evaluation/Rewards Min           -10.1584
evaluation/Returns Mean         -165.864
evaluation/Returns Std            83.7038
evaluation/Returns Max           -37.7693
evaluation/Returns Min          -243.947
evaluation/Actions Mean            0.00732423
evaluation/Actions Std             0.184328
evaluation/Actions Max             0.996102
evaluation/Actions Min            -0.996254
evaluation/Num Paths              15
evaluation/Average Returns      -165.864
time/data storing (s)              0.00282046
time/evaluation sampling (s)       0.330023
time/exploration sampling (s)      0.143144
time/logging (s)                   0.00482267
time/saving (s)                    0.00189377
time/training (s)                  1.92479
time/epoch (s)                     2.40749
time/total (s)                    75.8584
Epoch                             30
-----------------------------  --------------
2019-04-22 23:51:08.014353 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   1.39991
trainer/QF2 Loss                   1.44154
trainer/Policy Loss               74.6869
trainer/Q1 Predictions Mean      -73.8298
trainer/Q1 Predictions Std        49.2038
trainer/Q1 Predictions Max       -22.5838
trainer/Q1 Predictions Min      -153.751
trainer/Q2 Predictions Mean      -73.8062
trainer/Q2 Predictions Std        49.1945
trainer/Q2 Predictions Max       -22.5842
trainer/Q2 Predictions Min      -153.57
trainer/Q Targets Mean           -74.5322
trainer/Q Targets Std             50.0046
trainer/Q Targets Max            -22.209
trainer/Q Targets Min           -156.957
trainer/Log Pis Mean               1.92568
trainer/Log Pis Std                1.54239
trainer/Log Pis Max                8.18135
trainer/Log Pis Min               -2.40919
trainer/Policy mu Mean            -0.176107
trainer/Policy mu Std              0.927307
trainer/Policy mu Max              3.10647
trainer/Policy mu Min             -2.92292
trainer/Policy log std Mean       -1.8744
trainer/Policy log std Std         0.492729
trainer/Policy log std Max        -0.303628
trainer/Policy log std Min        -2.33838
trainer/Alpha                      0.0477176
trainer/Alpha Loss                -0.226117
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.09652
exploration/Rewards Std            1.27941
exploration/Rewards Max           -0.00355174
exploration/Rewards Min          -11.0023
exploration/Returns Mean        -109.652
exploration/Returns Std          102.358
exploration/Returns Max          -23.9675
exploration/Returns Min         -253.434
exploration/Actions Mean           0.0040152
exploration/Actions Std            0.224419
exploration/Actions Max            0.994698
exploration/Actions Min           -0.99834
exploration/Num Paths              5
exploration/Average Returns     -109.652
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.43508
evaluation/Rewards Std             1.22023
evaluation/Rewards Max            -0.0737989
evaluation/Rewards Min            -9.27643
evaluation/Returns Mean         -143.508
evaluation/Returns Std           102.207
evaluation/Returns Max            -8.90361
evaluation/Returns Min          -240.706
evaluation/Actions Mean           -0.00112209
evaluation/Actions Std             0.167239
evaluation/Actions Max             0.993966
evaluation/Actions Min            -0.995737
evaluation/Num Paths              15
evaluation/Average Returns      -143.508
time/data storing (s)              0.00292471
time/evaluation sampling (s)       0.331024
time/exploration sampling (s)      0.154538
time/logging (s)                   0.0047923
time/saving (s)                    0.00200463
time/training (s)                  2.08343
time/epoch (s)                     2.57872
time/total (s)                    78.4416
Epoch                             31
-----------------------------  --------------
2019-04-22 23:51:10.413644 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size             16700
trainer/QF1 Loss                   0.960606
trainer/QF2 Loss                   0.990272
trainer/Policy Loss               68.1662
trainer/Q1 Predictions Mean      -67.1829
trainer/Q1 Predictions Std        49.3703
trainer/Q1 Predictions Max       -21.4806
trainer/Q1 Predictions Min      -146.834
trainer/Q2 Predictions Mean      -67.1701
trainer/Q2 Predictions Std        49.3771
trainer/Q2 Predictions Max       -21.4885
trainer/Q2 Predictions Min      -146.408
trainer/Q Targets Mean           -67.9816
trainer/Q Targets Std             49.6693
trainer/Q Targets Max            -21.8632
trainer/Q Targets Min           -148.159
trainer/Log Pis Mean               1.89155
trainer/Log Pis Std                1.69135
trainer/Log Pis Max                8.24917
trainer/Log Pis Min               -8.80393
trainer/Policy mu Mean            -0.175252
trainer/Policy mu Std              0.786694
trainer/Policy mu Max              3.37552
trainer/Policy mu Min             -2.89272
trainer/Policy log std Mean       -1.94814
trainer/Policy log std Std         0.423977
trainer/Policy log std Max        -0.489565
trainer/Policy log std Min        -2.39214
trainer/Alpha                      0.0456416
trainer/Alpha Loss                -0.334793
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.85763
exploration/Rewards Std            0.895654
exploration/Rewards Max           -0.0190966
exploration/Rewards Min           -5.07967
exploration/Returns Mean        -185.763
exploration/Returns Std           84.5511
exploration/Returns Max          -16.7112
exploration/Returns Min         -231.597
exploration/Actions Mean          -0.00880401
exploration/Actions Std            0.191515
exploration/Actions Max            0.882113
exploration/Actions Min           -0.946676
exploration/Num Paths              5
exploration/Average Returns     -185.763
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.21587
evaluation/Rewards Std             1.32325
evaluation/Rewards Max            -0.0704126
evaluation/Rewards Min           -10.684
evaluation/Returns Mean         -121.587
evaluation/Returns Std           108.545
evaluation/Returns Max            -9.60982
evaluation/Returns Min          -256.78
evaluation/Actions Mean            0.00827857
evaluation/Actions Std             0.175693
evaluation/Actions Max             0.996283
evaluation/Actions Min            -0.996723
evaluation/Num Paths              15
evaluation/Average Returns      -121.587
time/data storing (s)              0.00284126
time/evaluation sampling (s)       0.330173
time/exploration sampling (s)      0.144728
time/logging (s)                   0.00475687
time/saving (s)                    0.00194552
time/training (s)                  1.90911
time/epoch (s)                     2.39356
time/total (s)                    80.8397
Epoch                             32
-----------------------------  --------------
2019-04-22 23:51:12.825931 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   8.42266
trainer/QF2 Loss                   8.4072
trainer/Policy Loss               81.1499
trainer/Q1 Predictions Mean      -79.9784
trainer/Q1 Predictions Std        48.7267
trainer/Q1 Predictions Max       -20.7812
trainer/Q1 Predictions Min      -145.853
trainer/Q2 Predictions Mean      -79.9784
trainer/Q2 Predictions Std        48.6544
trainer/Q2 Predictions Max       -20.8381
trainer/Q2 Predictions Min      -146.143
trainer/Q Targets Mean           -81.4569
trainer/Q Targets Std             49.7808
trainer/Q Targets Max             -1.4692
trainer/Q Targets Min           -151.345
trainer/Log Pis Mean               2.21461
trainer/Log Pis Std                1.56886
trainer/Log Pis Max                6.90946
trainer/Log Pis Min               -0.82388
trainer/Policy mu Mean            -0.189625
trainer/Policy mu Std              1.03994
trainer/Policy mu Max              3.13045
trainer/Policy mu Min             -2.94138
trainer/Policy log std Mean       -1.84448
trainer/Policy log std Std         0.525848
trainer/Policy log std Max        -0.559659
trainer/Policy log std Min        -2.38901
trainer/Alpha                      0.049417
trainer/Alpha Loss                 0.645467
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.62984
exploration/Rewards Std            1.13576
exploration/Rewards Max           -0.0182419
exploration/Rewards Min           -5.65774
exploration/Returns Mean        -162.984
exploration/Returns Std          104.56
exploration/Returns Max          -32.9709
exploration/Returns Min         -260.712
exploration/Actions Mean           0.0120705
exploration/Actions Std            0.201053
exploration/Actions Max            0.985135
exploration/Actions Min           -0.993677
exploration/Num Paths              5
exploration/Average Returns     -162.984
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.95247
evaluation/Rewards Std             1.19433
evaluation/Rewards Max            -0.232661
evaluation/Rewards Min           -10.0596
evaluation/Returns Mean         -195.247
evaluation/Returns Std            87.0716
evaluation/Returns Max           -25.769
evaluation/Returns Min          -271.542
evaluation/Actions Mean            0.0121025
evaluation/Actions Std             0.159379
evaluation/Actions Max             0.99697
evaluation/Actions Min            -0.995833
evaluation/Num Paths              15
evaluation/Average Returns      -195.247
time/data storing (s)              0.00292566
time/evaluation sampling (s)       0.328999
time/exploration sampling (s)      0.142718
time/logging (s)                   0.00483494
time/saving (s)                    0.00196368
time/training (s)                  1.92544
time/epoch (s)                     2.40689
time/total (s)                    83.251
Epoch                             33
-----------------------------  --------------
2019-04-22 23:51:15.219838 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                 169.321
trainer/QF2 Loss                 169.47
trainer/Policy Loss               82.4747
trainer/Q1 Predictions Mean      -81.6309
trainer/Q1 Predictions Std        48.9417
trainer/Q1 Predictions Max       -21.2991
trainer/Q1 Predictions Min      -153.235
trainer/Q2 Predictions Mean      -81.6468
trainer/Q2 Predictions Std        48.8783
trainer/Q2 Predictions Max       -21.3631
trainer/Q2 Predictions Min      -152.818
trainer/Q Targets Mean           -80.6899
trainer/Q Targets Std             49.8859
trainer/Q Targets Max             -0.871636
trainer/Q Targets Min           -152.334
trainer/Log Pis Mean               1.77385
trainer/Log Pis Std                1.40558
trainer/Log Pis Max                5.80151
trainer/Log Pis Min               -1.9453
trainer/Policy mu Mean            -0.246379
trainer/Policy mu Std              0.924007
trainer/Policy mu Max              3.19244
trainer/Policy mu Min             -2.92783
trainer/Policy log std Mean       -1.78197
trainer/Policy log std Std         0.469165
trainer/Policy log std Max        -0.442764
trainer/Policy log std Min        -2.31035
trainer/Alpha                      0.0489391
trainer/Alpha Loss                -0.682272
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.56749
exploration/Rewards Std            1.23885
exploration/Rewards Max           -0.00632876
exploration/Rewards Min           -8.79194
exploration/Returns Mean        -156.749
exploration/Returns Std          109.211
exploration/Returns Max          -22.2095
exploration/Returns Min         -255.585
exploration/Actions Mean          -0.00535701
exploration/Actions Std            0.215735
exploration/Actions Max            0.986561
exploration/Actions Min           -0.999565
exploration/Num Paths              5
exploration/Average Returns     -156.749
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.28433
evaluation/Rewards Std             1.33172
evaluation/Rewards Max            -0.123837
evaluation/Rewards Min            -9.83979
evaluation/Returns Mean         -128.433
evaluation/Returns Std           106.366
evaluation/Returns Max           -16.2126
evaluation/Returns Min          -255.806
evaluation/Actions Mean            0.00790118
evaluation/Actions Std             0.174083
evaluation/Actions Max             0.99738
evaluation/Actions Min            -0.997277
evaluation/Num Paths              15
evaluation/Average Returns      -128.433
time/data storing (s)              0.00267556
time/evaluation sampling (s)       0.32284
time/exploration sampling (s)      0.143021
time/logging (s)                   0.00476535
time/saving (s)                    0.00194991
time/training (s)                  1.91295
time/epoch (s)                     2.3882
time/total (s)                    85.6437
Epoch                             34
-----------------------------  --------------
2019-04-22 23:51:17.608272 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                 134.795
trainer/QF2 Loss                 134.731
trainer/Policy Loss               76.1889
trainer/Q1 Predictions Mean      -75.3169
trainer/Q1 Predictions Std        49.1177
trainer/Q1 Predictions Max       -20.4796
trainer/Q1 Predictions Min      -160.333
trainer/Q2 Predictions Mean      -75.335
trainer/Q2 Predictions Std        49.1436
trainer/Q2 Predictions Max       -20.4905
trainer/Q2 Predictions Min      -160.493
trainer/Q Targets Mean           -76.097
trainer/Q Targets Std             50.6982
trainer/Q Targets Max             -2.71792
trainer/Q Targets Min           -161.546
trainer/Log Pis Mean               1.89651
trainer/Log Pis Std                1.80115
trainer/Log Pis Max                8.87257
trainer/Log Pis Min               -4.86661
trainer/Policy mu Mean            -0.130929
trainer/Policy mu Std              0.883323
trainer/Policy mu Max              3.00133
trainer/Policy mu Min             -3.23704
trainer/Policy log std Mean       -1.89196
trainer/Policy log std Std         0.438178
trainer/Policy log std Max        -0.455936
trainer/Policy log std Min        -2.31362
trainer/Alpha                      0.0460655
trainer/Alpha Loss                -0.318502
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.736629
exploration/Rewards Std            0.684257
exploration/Rewards Max           -0.085349
exploration/Rewards Min           -3.52886
exploration/Returns Mean         -73.6629
exploration/Returns Std           62.3794
exploration/Returns Max          -41.0993
exploration/Returns Min         -198.41
exploration/Actions Mean          -0.00490702
exploration/Actions Std            0.187607
exploration/Actions Max            0.959461
exploration/Actions Min           -0.996455
exploration/Num Paths              5
exploration/Average Returns      -73.6629
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.25843
evaluation/Rewards Std             1.13566
evaluation/Rewards Max            -0.343379
evaluation/Rewards Min            -9.99254
evaluation/Returns Mean         -125.843
evaluation/Returns Std            74.433
evaluation/Returns Max           -40.6941
evaluation/Returns Min          -215.616
evaluation/Actions Mean            0.0108957
evaluation/Actions Std             0.175703
evaluation/Actions Max             0.994935
evaluation/Actions Min            -0.994848
evaluation/Num Paths              15
evaluation/Average Returns      -125.843
time/data storing (s)              0.00311775
time/evaluation sampling (s)       0.324917
time/exploration sampling (s)      0.14229
time/logging (s)                   0.00378416
time/saving (s)                    0.00156328
time/training (s)                  1.90623
time/epoch (s)                     2.38191
time/total (s)                    88.03
Epoch                             35
-----------------------------  --------------
2019-04-22 23:51:20.004419 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                 280.914
trainer/QF2 Loss                 280.986
trainer/Policy Loss               82.3759
trainer/Q1 Predictions Mean      -80.9917
trainer/Q1 Predictions Std        49.6238
trainer/Q1 Predictions Max       -20.2999
trainer/Q1 Predictions Min      -146.136
trainer/Q2 Predictions Mean      -81.0471
trainer/Q2 Predictions Std        49.6134
trainer/Q2 Predictions Max       -20.311
trainer/Q2 Predictions Min      -146.218
trainer/Q Targets Mean           -79.154
trainer/Q Targets Std             50.5915
trainer/Q Targets Max             -2.20698
trainer/Q Targets Min           -148.566
trainer/Log Pis Mean               2.03556
trainer/Log Pis Std                1.44546
trainer/Log Pis Max                6.82751
trainer/Log Pis Min               -1.36218
trainer/Policy mu Mean            -0.169608
trainer/Policy mu Std              0.829432
trainer/Policy mu Max              3.28077
trainer/Policy mu Min             -2.88789
trainer/Policy log std Mean       -1.89383
trainer/Policy log std Std         0.445671
trainer/Policy log std Max        -0.598537
trainer/Policy log std Min        -2.37175
trainer/Alpha                      0.0489075
trainer/Alpha Loss                 0.107309
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.46991
exploration/Rewards Std            1.17779
exploration/Rewards Max           -0.0148473
exploration/Rewards Min           -8.36318
exploration/Returns Mean        -146.991
exploration/Returns Std           94.6699
exploration/Returns Max          -25.3072
exploration/Returns Min         -231.396
exploration/Actions Mean          -0.0110657
exploration/Actions Std            0.213711
exploration/Actions Max            0.998084
exploration/Actions Min           -0.995362
exploration/Num Paths              5
exploration/Average Returns     -146.991
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.07441
evaluation/Rewards Std             1.2432
evaluation/Rewards Max            -0.0412861
evaluation/Rewards Min           -10.1454
evaluation/Returns Mean         -107.441
evaluation/Returns Std            91.3671
evaluation/Returns Max           -14.6337
evaluation/Returns Min          -230.95
evaluation/Actions Mean            0.00953731
evaluation/Actions Std             0.173967
evaluation/Actions Max             0.996836
evaluation/Actions Min            -0.995507
evaluation/Num Paths              15
evaluation/Average Returns      -107.441
time/data storing (s)              0.0029538
time/evaluation sampling (s)       0.328586
time/exploration sampling (s)      0.143572
time/logging (s)                   0.00510724
time/saving (s)                    0.00204827
time/training (s)                  1.90913
time/epoch (s)                     2.3914
time/total (s)                    90.4263
Epoch                             36
-----------------------------  --------------
2019-04-22 23:51:22.417294 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                  13.1435
trainer/QF2 Loss                  13.3002
trainer/Policy Loss               88.638
trainer/Q1 Predictions Mean      -87.3828
trainer/Q1 Predictions Std        48.3501
trainer/Q1 Predictions Max       -20.2824
trainer/Q1 Predictions Min      -167.371
trainer/Q2 Predictions Mean      -87.374
trainer/Q2 Predictions Std        48.3089
trainer/Q2 Predictions Max       -20.2687
trainer/Q2 Predictions Min      -167.293
trainer/Q Targets Mean           -87.2595
trainer/Q Targets Std             49.5765
trainer/Q Targets Max             -0.281945
trainer/Q Targets Min           -165.812
trainer/Log Pis Mean               2.04732
trainer/Log Pis Std                1.27992
trainer/Log Pis Max                6.72625
trainer/Log Pis Min               -0.981893
trainer/Policy mu Mean            -0.244708
trainer/Policy mu Std              0.800442
trainer/Policy mu Max              2.57179
trainer/Policy mu Min             -3.07083
trainer/Policy log std Mean       -1.96515
trainer/Policy log std Std         0.43904
trainer/Policy log std Max        -0.377427
trainer/Policy log std Min        -2.45379
trainer/Alpha                      0.049376
trainer/Alpha Loss                 0.142352
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.29103
exploration/Rewards Std            1.04903
exploration/Rewards Max           -0.0818634
exploration/Rewards Min           -6.20877
exploration/Returns Mean        -129.103
exploration/Returns Std           86.3456
exploration/Returns Max          -55.9425
exploration/Returns Min         -242.454
exploration/Actions Mean           0.00203567
exploration/Actions Std            0.211487
exploration/Actions Max            0.997271
exploration/Actions Min           -0.98817
exploration/Num Paths              5
exploration/Average Returns     -129.103
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.47584
evaluation/Rewards Std             1.25973
evaluation/Rewards Max            -0.148081
evaluation/Rewards Min           -10.6587
evaluation/Returns Mean         -147.584
evaluation/Returns Std            89.4815
evaluation/Returns Max           -41.3911
evaluation/Returns Min          -248.457
evaluation/Actions Mean            0.00331668
evaluation/Actions Std             0.170889
evaluation/Actions Max             0.997442
evaluation/Actions Min            -0.994354
evaluation/Num Paths              15
evaluation/Average Returns      -147.584
time/data storing (s)              0.0029937
time/evaluation sampling (s)       0.32481
time/exploration sampling (s)      0.143001
time/logging (s)                   0.00483139
time/saving (s)                    0.00195188
time/training (s)                  1.9292
time/epoch (s)                     2.40678
time/total (s)                    92.8376
Epoch                             37
-----------------------------  --------------
2019-04-22 23:51:24.823485 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                  29.5656
trainer/QF2 Loss                  28.8701
trainer/Policy Loss               73.5722
trainer/Q1 Predictions Mean      -72.4237
trainer/Q1 Predictions Std        50.5835
trainer/Q1 Predictions Max       -20.0149
trainer/Q1 Predictions Min      -154.625
trainer/Q2 Predictions Mean      -72.3782
trainer/Q2 Predictions Std        50.6729
trainer/Q2 Predictions Max       -19.9337
trainer/Q2 Predictions Min      -155.11
trainer/Q Targets Mean           -72.4192
trainer/Q Targets Std             51.8399
trainer/Q Targets Max             -0.955021
trainer/Q Targets Min           -154.235
trainer/Log Pis Mean               2.06372
trainer/Log Pis Std                1.38062
trainer/Log Pis Max                7.9951
trainer/Log Pis Min               -3.74033
trainer/Policy mu Mean            -0.272515
trainer/Policy mu Std              0.817659
trainer/Policy mu Max              2.89415
trainer/Policy mu Min             -3.17802
trainer/Policy log std Mean       -1.90804
trainer/Policy log std Std         0.453804
trainer/Policy log std Max        -0.387045
trainer/Policy log std Min        -2.49094
trainer/Alpha                      0.0502853
trainer/Alpha Loss                 0.190511
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.84616
exploration/Rewards Std            0.92198
exploration/Rewards Max           -0.0519527
exploration/Rewards Min           -7.3914
exploration/Returns Mean        -184.616
exploration/Returns Std           71.7372
exploration/Returns Max          -41.3539
exploration/Returns Min         -223.327
exploration/Actions Mean          -0.0115744
exploration/Actions Std            0.20716
exploration/Actions Max            0.972226
exploration/Actions Min           -0.996756
exploration/Num Paths              5
exploration/Average Returns     -184.616
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.2004
evaluation/Rewards Std             1.26635
evaluation/Rewards Max            -0.197283
evaluation/Rewards Min           -11.0702
evaluation/Returns Mean         -120.04
evaluation/Returns Std            83.7522
evaluation/Returns Max           -31.1636
evaluation/Returns Min          -237.132
evaluation/Actions Mean            0.0139364
evaluation/Actions Std             0.172565
evaluation/Actions Max             0.996609
evaluation/Actions Min            -0.993676
evaluation/Num Paths              15
evaluation/Average Returns      -120.04
time/data storing (s)              0.00300812
time/evaluation sampling (s)       0.328064
time/exploration sampling (s)      0.139574
time/logging (s)                   0.00477661
time/saving (s)                    0.00152369
time/training (s)                  1.92359
time/epoch (s)                     2.40054
time/total (s)                    95.2425
Epoch                             38
-----------------------------  --------------
2019-04-22 23:51:27.254987 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                 141.039
trainer/QF2 Loss                 140.801
trainer/Policy Loss               81.5103
trainer/Q1 Predictions Mean      -80.0263
trainer/Q1 Predictions Std        49.4146
trainer/Q1 Predictions Max       -19.5774
trainer/Q1 Predictions Min      -153.105
trainer/Q2 Predictions Mean      -80.0113
trainer/Q2 Predictions Std        49.4268
trainer/Q2 Predictions Max       -19.5866
trainer/Q2 Predictions Min      -152.55
trainer/Q Targets Mean           -79.1758
trainer/Q Targets Std             50.4285
trainer/Q Targets Max             -0.0990187
trainer/Q Targets Min           -154.552
trainer/Log Pis Mean               2.23336
trainer/Log Pis Std                1.06258
trainer/Log Pis Max                5.79915
trainer/Log Pis Min               -1.4213
trainer/Policy mu Mean            -0.20231
trainer/Policy mu Std              0.851648
trainer/Policy mu Max              3.16642
trainer/Policy mu Min             -3.03365
trainer/Policy log std Mean       -2.00088
trainer/Policy log std Std         0.483721
trainer/Policy log std Max        -0.392694
trainer/Policy log std Min        -2.59338
trainer/Alpha                      0.052036
trainer/Alpha Loss                 0.689806
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.50024
exploration/Rewards Std            1.0515
exploration/Rewards Max           -0.0298632
exploration/Rewards Min           -8.19468
exploration/Returns Mean        -150.024
exploration/Returns Std           78.6744
exploration/Returns Max          -42.3495
exploration/Returns Min         -221.314
exploration/Actions Mean           0.018806
exploration/Actions Std            0.208874
exploration/Actions Max            0.998498
exploration/Actions Min           -0.873645
exploration/Num Paths              5
exploration/Average Returns     -150.024
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.09528
evaluation/Rewards Std             1.05714
evaluation/Rewards Max            -0.146512
evaluation/Rewards Min            -8.51136
evaluation/Returns Mean         -109.528
evaluation/Returns Std            88.818
evaluation/Returns Max           -29.4841
evaluation/Returns Min          -229.603
evaluation/Actions Mean            0.00286317
evaluation/Actions Std             0.154249
evaluation/Actions Max             0.993846
evaluation/Actions Min            -0.994502
evaluation/Num Paths              15
evaluation/Average Returns      -109.528
time/data storing (s)              0.00302612
time/evaluation sampling (s)       0.333662
time/exploration sampling (s)      0.141234
time/logging (s)                   0.00477212
time/saving (s)                    0.0019367
time/training (s)                  1.94124
time/epoch (s)                     2.42587
time/total (s)                    97.6728
Epoch                             39
-----------------------------  --------------
2019-04-22 23:51:29.667721 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size             20700
trainer/QF1 Loss                   0.437978
trainer/QF2 Loss                   0.457244
trainer/Policy Loss               86.2145
trainer/Q1 Predictions Mean      -85.1404
trainer/Q1 Predictions Std        50.0684
trainer/Q1 Predictions Max       -19.233
trainer/Q1 Predictions Min      -162.055
trainer/Q2 Predictions Mean      -85.1407
trainer/Q2 Predictions Std        50.0344
trainer/Q2 Predictions Max       -19.2356
trainer/Q2 Predictions Min      -161.986
trainer/Q Targets Mean           -85.4836
trainer/Q Targets Std             50.078
trainer/Q Targets Max            -19.3359
trainer/Q Targets Min           -163.191
trainer/Log Pis Mean               2.03523
trainer/Log Pis Std                1.66408
trainer/Log Pis Max                6.47919
trainer/Log Pis Min               -5.27252
trainer/Policy mu Mean            -0.226823
trainer/Policy mu Std              0.959815
trainer/Policy mu Max              2.86886
trainer/Policy mu Min             -3.15111
trainer/Policy log std Mean       -1.8595
trainer/Policy log std Std         0.484018
trainer/Policy log std Max        -0.429436
trainer/Policy log std Min        -2.35915
trainer/Alpha                      0.051667
trainer/Alpha Loss                 0.104388
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.94077
exploration/Rewards Std            1.11795
exploration/Rewards Max           -0.00103213
exploration/Rewards Min           -9.22579
exploration/Returns Mean        -194.077
exploration/Returns Std           87.6359
exploration/Returns Max          -19.2767
exploration/Returns Min         -249.246
exploration/Actions Mean          -0.0137352
exploration/Actions Std            0.233145
exploration/Actions Max            0.998487
exploration/Actions Min           -0.999345
exploration/Num Paths              5
exploration/Average Returns     -194.077
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.18804
evaluation/Rewards Std             1.24684
evaluation/Rewards Max            -0.0167382
evaluation/Rewards Min            -9.10419
evaluation/Returns Mean         -118.804
evaluation/Returns Std           100.932
evaluation/Returns Max            -7.49948
evaluation/Returns Min          -238.896
evaluation/Actions Mean            0.00336534
evaluation/Actions Std             0.156545
evaluation/Actions Max             0.996691
evaluation/Actions Min            -0.996915
evaluation/Num Paths              15
evaluation/Average Returns      -118.804
time/data storing (s)              0.00305851
time/evaluation sampling (s)       0.324933
time/exploration sampling (s)      0.140186
time/logging (s)                   0.00485542
time/saving (s)                    0.00194038
time/training (s)                  1.93231
time/epoch (s)                     2.40728
time/total (s)                   100.084
Epoch                             40
-----------------------------  --------------
2019-04-22 23:51:32.046280 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                 138.001
trainer/QF2 Loss                 137.332
trainer/Policy Loss               80.7767
trainer/Q1 Predictions Mean      -79.4476
trainer/Q1 Predictions Std        48.8558
trainer/Q1 Predictions Max       -19.0605
trainer/Q1 Predictions Min      -149.5
trainer/Q2 Predictions Mean      -79.4016
trainer/Q2 Predictions Std        48.8653
trainer/Q2 Predictions Max       -19.0194
trainer/Q2 Predictions Min      -149.052
trainer/Q Targets Mean           -79.1923
trainer/Q Targets Std             49.9108
trainer/Q Targets Max             -3.69797
trainer/Q Targets Min           -150.91
trainer/Log Pis Mean               2.15686
trainer/Log Pis Std                1.52261
trainer/Log Pis Max                8.14936
trainer/Log Pis Min               -1.08458
trainer/Policy mu Mean            -0.12363
trainer/Policy mu Std              0.841528
trainer/Policy mu Max              3.10717
trainer/Policy mu Min             -2.98745
trainer/Policy log std Mean       -1.98957
trainer/Policy log std Std         0.474905
trainer/Policy log std Max        -0.243851
trainer/Policy log std Min        -2.4527
trainer/Alpha                      0.0541839
trainer/Alpha Loss                 0.457317
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.987536
exploration/Rewards Std            0.993138
exploration/Rewards Max           -0.0108102
exploration/Rewards Min           -5.09912
exploration/Returns Mean         -98.7536
exploration/Returns Std           90.3437
exploration/Returns Max          -19.4502
exploration/Returns Min         -209.956
exploration/Actions Mean           0.01643
exploration/Actions Std            0.195048
exploration/Actions Max            0.98121
exploration/Actions Min           -0.929529
exploration/Num Paths              5
exploration/Average Returns      -98.7536
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.972665
evaluation/Rewards Std             1.14256
evaluation/Rewards Max            -0.0601872
evaluation/Rewards Min           -10.5623
evaluation/Returns Mean          -97.2665
evaluation/Returns Std            93.1141
evaluation/Returns Max            -9.58257
evaluation/Returns Min          -238.115
evaluation/Actions Mean            0.0086527
evaluation/Actions Std             0.15
evaluation/Actions Max             0.996455
evaluation/Actions Min            -0.99745
evaluation/Num Paths              15
evaluation/Average Returns       -97.2665
time/data storing (s)              0.0029594
time/evaluation sampling (s)       0.330179
time/exploration sampling (s)      0.142665
time/logging (s)                   0.00477975
time/saving (s)                    0.0019562
time/training (s)                  1.89043
time/epoch (s)                     2.37297
time/total (s)                   102.462
Epoch                             41
-----------------------------  --------------
2019-04-22 23:51:34.454112 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size             21700
trainer/QF1 Loss                   3.77131
trainer/QF2 Loss                   3.8923
trainer/Policy Loss               74.479
trainer/Q1 Predictions Mean      -73.1947
trainer/Q1 Predictions Std        50.7911
trainer/Q1 Predictions Max       -18.8194
trainer/Q1 Predictions Min      -144.998
trainer/Q2 Predictions Mean      -73.1609
trainer/Q2 Predictions Std        50.7791
trainer/Q2 Predictions Max       -18.8351
trainer/Q2 Predictions Min      -144.98
trainer/Q Targets Mean           -73.1281
trainer/Q Targets Std             51.1611
trainer/Q Targets Max             -0.143976
trainer/Q Targets Min           -146.709
trainer/Log Pis Mean               1.97281
trainer/Log Pis Std                1.17624
trainer/Log Pis Max                7.31879
trainer/Log Pis Min               -1.62076
trainer/Policy mu Mean            -0.122465
trainer/Policy mu Std              0.731315
trainer/Policy mu Max              3.10204
trainer/Policy mu Min             -2.85207
trainer/Policy log std Mean       -1.99101
trainer/Policy log std Std         0.456146
trainer/Policy log std Max        -0.347175
trainer/Policy log std Min        -2.41236
trainer/Alpha                      0.0564989
trainer/Alpha Loss                -0.078116
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.785194
exploration/Rewards Std            1.22374
exploration/Rewards Max           -0.00595348
exploration/Rewards Min           -8.68727
exploration/Returns Mean         -78.5194
exploration/Returns Std           73.7671
exploration/Returns Max          -30.8045
exploration/Returns Min         -224.759
exploration/Actions Mean           0.0243831
exploration/Actions Std            0.2283
exploration/Actions Max            0.998839
exploration/Actions Min           -0.99932
exploration/Num Paths              5
exploration/Average Returns      -78.5194
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.7296
evaluation/Rewards Std             1.19423
evaluation/Rewards Max            -0.0555461
evaluation/Rewards Min           -10.4182
evaluation/Returns Mean         -172.96
evaluation/Returns Std            85.6342
evaluation/Returns Max           -19.7076
evaluation/Returns Min          -248.269
evaluation/Actions Mean           -0.00181953
evaluation/Actions Std             0.17187
evaluation/Actions Max             0.996482
evaluation/Actions Min            -0.996255
evaluation/Num Paths              15
evaluation/Average Returns      -172.96
time/data storing (s)              0.00297156
time/evaluation sampling (s)       0.326847
time/exploration sampling (s)      0.139578
time/logging (s)                   0.00477657
time/saving (s)                    0.00194056
time/training (s)                  1.92617
time/epoch (s)                     2.40229
time/total (s)                   104.868
Epoch                             42
-----------------------------  --------------
2019-04-22 23:51:36.859160 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size             22200
trainer/QF1 Loss                   2.18546
trainer/QF2 Loss                   2.29139
trainer/Policy Loss               72.7848
trainer/Q1 Predictions Mean      -71.8977
trainer/Q1 Predictions Std        50.8665
trainer/Q1 Predictions Max       -18.5794
trainer/Q1 Predictions Min      -167.048
trainer/Q2 Predictions Mean      -71.8335
trainer/Q2 Predictions Std        50.8772
trainer/Q2 Predictions Max       -18.5221
trainer/Q2 Predictions Min      -167.282
trainer/Q Targets Mean           -72.8059
trainer/Q Targets Std             51.715
trainer/Q Targets Max            -18.3916
trainer/Q Targets Min           -164.729
trainer/Log Pis Mean               1.96143
trainer/Log Pis Std                1.67695
trainer/Log Pis Max                6.52475
trainer/Log Pis Min               -3.85606
trainer/Policy mu Mean            -0.252238
trainer/Policy mu Std              0.85012
trainer/Policy mu Max              2.63721
trainer/Policy mu Min             -3.0861
trainer/Policy log std Mean       -1.94202
trainer/Policy log std Std         0.472324
trainer/Policy log std Max        -0.665001
trainer/Policy log std Min        -2.46226
trainer/Alpha                      0.0542487
trainer/Alpha Loss                -0.112422
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.62837
exploration/Rewards Std            1.35663
exploration/Rewards Max           -0.0111292
exploration/Rewards Min           -9.25534
exploration/Returns Mean        -162.837
exploration/Returns Std           96.677
exploration/Returns Max          -30.1643
exploration/Returns Min         -244.683
exploration/Actions Mean           0.0222356
exploration/Actions Std            0.238521
exploration/Actions Max            0.998647
exploration/Actions Min           -0.997568
exploration/Num Paths              5
exploration/Average Returns     -162.837
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.11523
evaluation/Rewards Std             1.22165
evaluation/Rewards Max            -0.1061
evaluation/Rewards Min            -8.80201
evaluation/Returns Mean         -111.523
evaluation/Returns Std           101.449
evaluation/Returns Max           -19.9433
evaluation/Returns Min          -246.237
evaluation/Actions Mean            0.0149764
evaluation/Actions Std             0.171581
evaluation/Actions Max             0.99563
evaluation/Actions Min            -0.996191
evaluation/Num Paths              15
evaluation/Average Returns      -111.523
time/data storing (s)              0.00280002
time/evaluation sampling (s)       0.327992
time/exploration sampling (s)      0.141922
time/logging (s)                   0.00477553
time/saving (s)                    0.00194592
time/training (s)                  1.92007
time/epoch (s)                     2.3995
time/total (s)                   107.272
Epoch                             43
-----------------------------  --------------
2019-04-22 23:51:39.259672 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             22700
trainer/QF1 Loss                 135.838
trainer/QF2 Loss                 135.462
trainer/Policy Loss               70.1042
trainer/Q1 Predictions Mean      -68.6655
trainer/Q1 Predictions Std        49.7593
trainer/Q1 Predictions Max       -18.1797
trainer/Q1 Predictions Min      -141.021
trainer/Q2 Predictions Mean      -68.6565
trainer/Q2 Predictions Std        49.7506
trainer/Q2 Predictions Max       -18.1582
trainer/Q2 Predictions Min      -141.114
trainer/Q Targets Mean           -68.2252
trainer/Q Targets Std             50.9295
trainer/Q Targets Max             -0.143976
trainer/Q Targets Min           -142.563
trainer/Log Pis Mean               2.16882
trainer/Log Pis Std                1.16697
trainer/Log Pis Max                6.12081
trainer/Log Pis Min               -1.35959
trainer/Policy mu Mean            -0.131214
trainer/Policy mu Std              0.73952
trainer/Policy mu Max              2.77713
trainer/Policy mu Min             -2.86131
trainer/Policy log std Mean       -2.01285
trainer/Policy log std Std         0.425839
trainer/Policy log std Max        -0.653472
trainer/Policy log std Min        -2.54799
trainer/Alpha                      0.0568624
trainer/Alpha Loss                 0.484067
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.984407
exploration/Rewards Std            0.961516
exploration/Rewards Max           -0.0118602
exploration/Rewards Min           -4.97299
exploration/Returns Mean         -98.4407
exploration/Returns Std           89.0024
exploration/Returns Max          -21.4576
exploration/Returns Min         -208.986
exploration/Actions Mean           0.0090372
exploration/Actions Std            0.183698
exploration/Actions Max            0.987697
exploration/Actions Min           -0.989177
exploration/Num Paths              5
exploration/Average Returns      -98.4407
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.31904
evaluation/Rewards Std             1.28443
evaluation/Rewards Max            -0.130649
evaluation/Rewards Min           -10.0726
evaluation/Returns Mean         -131.904
evaluation/Returns Std            93.855
evaluation/Returns Max           -18.8351
evaluation/Returns Min          -238.633
evaluation/Actions Mean           -0.00079326
evaluation/Actions Std             0.17298
evaluation/Actions Max             0.995641
evaluation/Actions Min            -0.995407
evaluation/Num Paths              15
evaluation/Average Returns      -131.904
time/data storing (s)              0.0028712
time/evaluation sampling (s)       0.322903
time/exploration sampling (s)      0.141801
time/logging (s)                   0.00480682
time/saving (s)                    0.00192217
time/training (s)                  1.92068
time/epoch (s)                     2.39498
time/total (s)                   109.671
Epoch                             44
-----------------------------  --------------
2019-04-22 23:51:41.653739 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                   1.90025
trainer/QF2 Loss                   1.86491
trainer/Policy Loss               78.1105
trainer/Q1 Predictions Mean      -76.9775
trainer/Q1 Predictions Std        49.6281
trainer/Q1 Predictions Max       -17.9946
trainer/Q1 Predictions Min      -158.972
trainer/Q2 Predictions Mean      -77.003
trainer/Q2 Predictions Std        49.6579
trainer/Q2 Predictions Max       -17.9921
trainer/Q2 Predictions Min      -159.222
trainer/Q Targets Mean           -77.966
trainer/Q Targets Std             50.4945
trainer/Q Targets Max            -17.9202
trainer/Q Targets Min           -160.881
trainer/Log Pis Mean               1.79625
trainer/Log Pis Std                1.19801
trainer/Log Pis Max                6.08116
trainer/Log Pis Min               -4.28197
trainer/Policy mu Mean            -0.107762
trainer/Policy mu Std              0.627952
trainer/Policy mu Max              2.00677
trainer/Policy mu Min             -2.93247
trainer/Policy log std Mean       -2.03656
trainer/Policy log std Std         0.382696
trainer/Policy log std Max        -0.510405
trainer/Policy log std Min        -2.44077
trainer/Alpha                      0.0574621
trainer/Alpha Loss                -0.582061
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.06784
exploration/Rewards Std            1.06293
exploration/Rewards Max           -0.0100354
exploration/Rewards Min           -5.73404
exploration/Returns Mean        -106.784
exploration/Returns Std           92.5634
exploration/Returns Max          -29.5504
exploration/Returns Min         -221.886
exploration/Actions Mean           0.00330334
exploration/Actions Std            0.206857
exploration/Actions Max            0.997124
exploration/Actions Min           -0.989068
exploration/Num Paths              5
exploration/Average Returns     -106.784
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.60878
evaluation/Rewards Std             1.20778
evaluation/Rewards Max            -0.0859635
evaluation/Rewards Min           -11.1565
evaluation/Returns Mean         -160.878
evaluation/Returns Std            93.1967
evaluation/Returns Max           -12.4821
evaluation/Returns Min          -255.897
evaluation/Actions Mean            0.00430841
evaluation/Actions Std             0.160924
evaluation/Actions Max             0.996992
evaluation/Actions Min            -0.997903
evaluation/Num Paths              15
evaluation/Average Returns      -160.878
time/data storing (s)              0.00308573
time/evaluation sampling (s)       0.321268
time/exploration sampling (s)      0.141725
time/logging (s)                   0.00347468
time/saving (s)                    0.00194963
time/training (s)                  1.91548
time/epoch (s)                     2.38698
time/total (s)                   112.062
Epoch                             45
-----------------------------  --------------
2019-04-22 23:51:44.045508 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                   0.257197
trainer/QF2 Loss                   0.193725
trainer/Policy Loss               61.6856
trainer/Q1 Predictions Mean      -60.6492
trainer/Q1 Predictions Std        48.9359
trainer/Q1 Predictions Max       -17.7746
trainer/Q1 Predictions Min      -134.888
trainer/Q2 Predictions Mean      -60.7019
trainer/Q2 Predictions Std        48.9257
trainer/Q2 Predictions Max       -17.8073
trainer/Q2 Predictions Min      -135.217
trainer/Q Targets Mean           -60.7152
trainer/Q Targets Std             48.981
trainer/Q Targets Max            -17.4943
trainer/Q Targets Min           -137.17
trainer/Log Pis Mean               1.7792
trainer/Log Pis Std                1.22057
trainer/Log Pis Max                6.3635
trainer/Log Pis Min               -1.98492
trainer/Policy mu Mean            -0.0239161
trainer/Policy mu Std              0.730591
trainer/Policy mu Max              3.4518
trainer/Policy mu Min             -2.69256
trainer/Policy log std Mean       -1.96859
trainer/Policy log std Std         0.40476
trainer/Policy log std Max        -0.34592
trainer/Policy log std Min        -2.40709
trainer/Alpha                      0.0563143
trainer/Alpha Loss                -0.635202
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.58042
exploration/Rewards Std            1.25296
exploration/Rewards Max           -0.0241864
exploration/Rewards Min           -9.92569
exploration/Returns Mean        -158.042
exploration/Returns Std          103.437
exploration/Returns Max          -29.2759
exploration/Returns Min         -257.886
exploration/Actions Mean          -0.00317246
exploration/Actions Std            0.226724
exploration/Actions Max            0.99586
exploration/Actions Min           -0.999162
exploration/Num Paths              5
exploration/Average Returns     -158.042
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.971497
evaluation/Rewards Std             1.39332
evaluation/Rewards Max            -0.101625
evaluation/Rewards Min           -10.0415
evaluation/Returns Mean          -97.1497
evaluation/Returns Std            85.2697
evaluation/Returns Max           -24.6551
evaluation/Returns Min          -249.705
evaluation/Actions Mean            0.0298394
evaluation/Actions Std             0.188148
evaluation/Actions Max             0.998069
evaluation/Actions Min            -0.9955
evaluation/Num Paths              15
evaluation/Average Returns       -97.1497
time/data storing (s)              0.00286141
time/evaluation sampling (s)       0.340558
time/exploration sampling (s)      0.140723
time/logging (s)                   0.00350311
time/saving (s)                    0.00160188
time/training (s)                  1.8974
time/epoch (s)                     2.38665
time/total (s)                   114.453
Epoch                             46
-----------------------------  --------------
2019-04-22 23:51:46.435786 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size             24200
trainer/QF1 Loss                   1.81663
trainer/QF2 Loss                   1.8932
trainer/Policy Loss               79.6304
trainer/Q1 Predictions Mean      -78.0586
trainer/Q1 Predictions Std        48.792
trainer/Q1 Predictions Max       -17.3885
trainer/Q1 Predictions Min      -141.449
trainer/Q2 Predictions Mean      -78.0173
trainer/Q2 Predictions Std        48.7884
trainer/Q2 Predictions Max       -17.4791
trainer/Q2 Predictions Min      -141.343
trainer/Q Targets Mean           -78.9725
trainer/Q Targets Std             49.4955
trainer/Q Targets Max            -17.2586
trainer/Q Targets Min           -143.818
trainer/Log Pis Mean               2.36457
trainer/Log Pis Std                1.42457
trainer/Log Pis Max                7.31785
trainer/Log Pis Min               -1.33634
trainer/Policy mu Mean            -0.235612
trainer/Policy mu Std              0.885722
trainer/Policy mu Max              2.89989
trainer/Policy mu Min             -2.92882
trainer/Policy log std Mean       -1.96565
trainer/Policy log std Std         0.531012
trainer/Policy log std Max        -0.25633
trainer/Policy log std Min        -2.48906
trainer/Alpha                      0.056121
trainer/Alpha Loss                 1.05009
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.70456
exploration/Rewards Std            0.955686
exploration/Rewards Max           -0.0230036
exploration/Rewards Min           -8.76931
exploration/Returns Mean        -170.456
exploration/Returns Std           64.3505
exploration/Returns Max          -43.2227
exploration/Returns Min         -220.985
exploration/Actions Mean          -0.00682551
exploration/Actions Std            0.202096
exploration/Actions Max            0.99915
exploration/Actions Min           -0.99793
exploration/Num Paths              5
exploration/Average Returns     -170.456
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.36767
evaluation/Rewards Std             1.18435
evaluation/Rewards Max            -0.130128
evaluation/Rewards Min           -10.4077
evaluation/Returns Mean         -136.767
evaluation/Returns Std            88.8102
evaluation/Returns Max           -20.457
evaluation/Returns Min          -229.003
evaluation/Actions Mean           -0.00558326
evaluation/Actions Std             0.181322
evaluation/Actions Max             0.996147
evaluation/Actions Min            -0.995285
evaluation/Num Paths              15
evaluation/Average Returns      -136.767
time/data storing (s)              0.00296869
time/evaluation sampling (s)       0.324201
time/exploration sampling (s)      0.141997
time/logging (s)                   0.00487891
time/saving (s)                    0.00197492
time/training (s)                  1.90996
time/epoch (s)                     2.38598
time/total (s)                   116.843
Epoch                             47
-----------------------------  --------------
2019-04-22 23:51:48.821372 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                 128.842
trainer/QF2 Loss                 129.129
trainer/Policy Loss               79.3363
trainer/Q1 Predictions Mean      -77.7979
trainer/Q1 Predictions Std        49.576
trainer/Q1 Predictions Max       -17.0907
trainer/Q1 Predictions Min      -146.565
trainer/Q2 Predictions Mean      -77.8092
trainer/Q2 Predictions Std        49.6022
trainer/Q2 Predictions Max       -17.1109
trainer/Q2 Predictions Min      -146.189
trainer/Q Targets Mean           -77.3303
trainer/Q Targets Std             50.5103
trainer/Q Targets Max             -2.44171
trainer/Q Targets Min           -148.989
trainer/Log Pis Mean               2.04643
trainer/Log Pis Std                1.1796
trainer/Log Pis Max                5.97505
trainer/Log Pis Min               -1.53917
trainer/Policy mu Mean            -0.19216
trainer/Policy mu Std              0.707127
trainer/Policy mu Max              2.97966
trainer/Policy mu Min             -2.98256
trainer/Policy log std Mean       -2.02867
trainer/Policy log std Std         0.431571
trainer/Policy log std Max        -0.626425
trainer/Policy log std Min        -2.47787
trainer/Alpha                      0.0540204
trainer/Alpha Loss                 0.135493
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.43901
exploration/Rewards Std            1.16581
exploration/Rewards Max           -0.0184417
exploration/Rewards Min           -9.58338
exploration/Returns Mean        -143.901
exploration/Returns Std           93.7052
exploration/Returns Max          -26.8368
exploration/Returns Min         -239.196
exploration/Actions Mean          -0.00583336
exploration/Actions Std            0.205907
exploration/Actions Max            0.990115
exploration/Actions Min           -0.999014
exploration/Num Paths              5
exploration/Average Returns     -143.901
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.36685
evaluation/Rewards Std             1.10248
evaluation/Rewards Max            -0.111972
evaluation/Rewards Min           -10.1968
evaluation/Returns Mean         -136.685
evaluation/Returns Std            96.3868
evaluation/Returns Max           -14.5928
evaluation/Returns Min          -244.305
evaluation/Actions Mean            0.00172427
evaluation/Actions Std             0.142166
evaluation/Actions Max             0.986014
evaluation/Actions Min            -0.996202
evaluation/Num Paths              15
evaluation/Average Returns      -136.685
time/data storing (s)              0.00288119
time/evaluation sampling (s)       0.326748
time/exploration sampling (s)      0.138985
time/logging (s)                   0.00483101
time/saving (s)                    0.00195836
time/training (s)                  1.90425
time/epoch (s)                     2.37966
time/total (s)                   119.228
Epoch                             48
-----------------------------  --------------
2019-04-22 23:51:51.235314 PDT | [sac-pointmass-multitask-2_2019_04_22_23_49_49_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                 257.174
trainer/QF2 Loss                 256.268
trainer/Policy Loss               79.1678
trainer/Q1 Predictions Mean      -77.7108
trainer/Q1 Predictions Std        48.9983
trainer/Q1 Predictions Max       -17.0368
trainer/Q1 Predictions Min      -138.966
trainer/Q2 Predictions Mean      -77.6865
trainer/Q2 Predictions Std        49.001
trainer/Q2 Predictions Max       -17.0784
trainer/Q2 Predictions Min      -139.257
trainer/Q Targets Mean           -75.7034
trainer/Q Targets Std             50.0136
trainer/Q Targets Max             -2.21635
trainer/Q Targets Min           -140.488
trainer/Log Pis Mean               2.03389
trainer/Log Pis Std                1.37717
trainer/Log Pis Max                6.30784
trainer/Log Pis Min               -1.56151
trainer/Policy mu Mean            -0.14066
trainer/Policy mu Std              0.734178
trainer/Policy mu Max              2.6411
trainer/Policy mu Min             -2.88333
trainer/Policy log std Mean       -2.07151
trainer/Policy log std Std         0.460698
trainer/Policy log std Max        -0.499852
trainer/Policy log std Min        -2.51651
trainer/Alpha                      0.0560371
trainer/Alpha Loss                 0.0976671
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.52868
exploration/Rewards Std            1.3182
exploration/Rewards Max           -0.040207
exploration/Rewards Min          -10.8629
exploration/Returns Mean        -152.868
exploration/Returns Std           86.9728
exploration/Returns Max          -26.5082
exploration/Returns Min         -240.884
exploration/Actions Mean           0.0103208
exploration/Actions Std            0.222515
exploration/Actions Max            0.998745
exploration/Actions Min           -0.999768
exploration/Num Paths              5
exploration/Average Returns     -152.868
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.11044
evaluation/Rewards Std             1.22218
evaluation/Rewards Max            -0.199045
evaluation/Rewards Min           -10.7758
evaluation/Returns Mean         -111.044
evaluation/Returns Std            81.9071
evaluation/Returns Max           -24.5603
evaluation/Returns Min          -217.707
evaluation/Actions Mean            0.010577
evaluation/Actions Std             0.172061
evaluation/Actions Max             0.996932
evaluation/Actions Min            -0.995067
evaluation/Num Paths              15
evaluation/Average Returns      -111.044
time/data storing (s)              0.00273147
time/evaluation sampling (s)       0.316874
time/exploration sampling (s)      0.139565
time/logging (s)                   0.00475128
time/saving (s)                    0.00194834
time/training (s)                  1.94231
time/epoch (s)                     2.40818
time/total (s)                   121.64
Epoch                             49
-----------------------------  --------------
