2019-04-22 21:38:03.580750 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 0 finished
-----------------------------  --------------
replay_buffer/size              700
trainer/QF1 Loss                 51.638
trainer/QF2 Loss                 51.6029
trainer/Policy Loss              -1.31762
trainer/Q1 Predictions Mean       0.00260988
trainer/Q1 Predictions Std        0.0017684
trainer/Q1 Predictions Max        0.00789916
trainer/Q1 Predictions Min        0.000594608
trainer/Q2 Predictions Mean      -0.000527583
trainer/Q2 Predictions Std        0.00142499
trainer/Q2 Predictions Max        0.0017292
trainer/Q2 Predictions Min       -0.00363717
trainer/Q Targets Mean           -6.54835
trainer/Q Targets Std             2.9535
trainer/Q Targets Max            -1.04022
trainer/Q Targets Min           -11.3067
trainer/Log Pis Mean             -1.31823
trainer/Log Pis Std               0.293734
trainer/Log Pis Max              -0.57831
trainer/Log Pis Min              -1.83543
trainer/Policy mu Mean           -0.000805384
trainer/Policy mu Std             0.000529773
trainer/Policy mu Max             0.000195188
trainer/Policy mu Min            -0.00201772
trainer/Policy log std Mean       0.000184237
trainer/Policy log std Std        0.000511361
trainer/Policy log std Max        0.00194609
trainer/Policy log std Min       -0.000602997
trainer/Alpha                     0.9997
trainer/Alpha Loss               -0
exploration/num steps total     700
exploration/num paths total       7
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -7.38528
exploration/Rewards Std           2.92336
exploration/Rewards Max          -0.86656
exploration/Rewards Min         -12.2359
exploration/Returns Mean       -738.528
exploration/Returns Std         252.61
exploration/Returns Max        -292.378
exploration/Returns Min        -997.347
exploration/Actions Mean         -0.0226292
exploration/Actions Std           0.623056
exploration/Actions Max           0.994956
exploration/Actions Min          -0.996791
exploration/Num Paths             5
exploration/Average Returns    -738.528
evaluation/num steps total     1500
evaluation/num paths total       15
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -5.12361
evaluation/Rewards Std            2.25186
evaluation/Rewards Max           -2.02453
evaluation/Rewards Min           -9.53928
evaluation/Returns Mean        -512.361
evaluation/Returns Std          225.171
evaluation/Returns Max         -206.505
evaluation/Returns Min         -944.386
evaluation/Actions Mean          -0.000656732
evaluation/Actions Std            0.000440012
evaluation/Actions Max            6.28083e-05
evaluation/Actions Min           -0.00140292
evaluation/Num Paths             15
evaluation/Average Returns     -512.361
time/data storing (s)             0.00320848
time/evaluation sampling (s)      0.32262
time/exploration sampling (s)     0.163723
time/logging (s)                  0.00512783
time/saving (s)                   0.00225154
time/training (s)                 2.1204
time/epoch (s)                    2.61733
time/total (s)                    2.84011
Epoch                             0
-----------------------------  --------------
2019-04-22 21:38:06.283293 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size              1200
trainer/QF1 Loss                  14.3312
trainer/QF2 Loss                  13.8719
trainer/Policy Loss               10.1141
trainer/Q1 Predictions Mean      -11.4327
trainer/Q1 Predictions Std         4.51237
trainer/Q1 Predictions Max        -6.01286
trainer/Q1 Predictions Min       -23.0245
trainer/Q2 Predictions Mean      -11.4846
trainer/Q2 Predictions Std         4.53803
trainer/Q2 Predictions Max        -6.06388
trainer/Q2 Predictions Min       -23.2266
trainer/Q Targets Mean           -13.4283
trainer/Q Targets Std              4.05696
trainer/Q Targets Max             -5.02287
trainer/Q Targets Min            -22.5429
trainer/Log Pis Mean              -1.26544
trainer/Log Pis Std                0.63557
trainer/Log Pis Max                0.296878
trainer/Log Pis Min               -3.32643
trainer/Policy mu Mean             0.163142
trainer/Policy mu Std              0.3112
trainer/Policy mu Max              0.726747
trainer/Policy mu Min             -0.676725
trainer/Policy log std Mean       -0.177348
trainer/Policy log std Std         0.041987
trainer/Policy log std Max        -0.116543
trainer/Policy log std Min        -0.28969
trainer/Alpha                      0.862032
trainer/Alpha Loss                -0.483859
exploration/num steps total     1200
exploration/num paths total       12
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -8.27591
exploration/Rewards Std            2.31016
exploration/Rewards Max           -0.898719
exploration/Rewards Min          -12.438
exploration/Returns Mean        -827.591
exploration/Returns Std          135.297
exploration/Returns Max         -642.678
exploration/Returns Min        -1038.99
exploration/Actions Mean           0.0867616
exploration/Actions Std            0.592198
exploration/Actions Max            0.996551
exploration/Actions Min           -0.992461
exploration/Num Paths              5
exploration/Average Returns     -827.591
evaluation/num steps total      3000
evaluation/num paths total        30
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -6.62339
evaluation/Rewards Std             3.70232
evaluation/Rewards Max            -0.346685
evaluation/Rewards Min           -10.8588
evaluation/Returns Mean         -662.339
evaluation/Returns Std           345.893
evaluation/Returns Max          -187.688
evaluation/Returns Min         -1085.61
evaluation/Actions Mean            0.0617115
evaluation/Actions Std             0.145342
evaluation/Actions Max             0.568743
evaluation/Actions Min            -0.442408
evaluation/Num Paths              15
evaluation/Average Returns      -662.339
time/data storing (s)              0.00315407
time/evaluation sampling (s)       0.37532
time/exploration sampling (s)      0.160888
time/logging (s)                   0.0050462
time/saving (s)                    0.00201697
time/training (s)                  2.15032
time/epoch (s)                     2.69674
time/total (s)                     5.54171
Epoch                              1
-----------------------------  --------------
2019-04-22 21:38:08.923841 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size             1700
trainer/QF1 Loss                  3.18515
trainer/QF2 Loss                  3.11894
trainer/Policy Loss              21.3221
trainer/Q1 Predictions Mean     -22.8935
trainer/Q1 Predictions Std        6.57231
trainer/Q1 Predictions Max      -11.2553
trainer/Q1 Predictions Min      -36.4299
trainer/Q2 Predictions Mean     -22.8491
trainer/Q2 Predictions Std        6.68545
trainer/Q2 Predictions Max      -10.9001
trainer/Q2 Predictions Min      -36.4195
trainer/Q Targets Mean          -22.8916
trainer/Q Targets Std             7.32968
trainer/Q Targets Max            -1.89863
trainer/Q Targets Min           -37.196
trainer/Log Pis Mean             -0.833102
trainer/Log Pis Std               0.955123
trainer/Log Pis Max               2.20239
trainer/Log Pis Min              -2.94255
trainer/Policy mu Mean            0.043274
trainer/Policy mu Std             0.650112
trainer/Policy mu Max             1.30133
trainer/Policy mu Min            -1.4899
trainer/Policy log std Mean      -0.330114
trainer/Policy log std Std        0.0685958
trainer/Policy log std Max       -0.239017
trainer/Policy log std Min       -0.541737
trainer/Alpha                     0.752933
trainer/Alpha Loss               -0.803263
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.90981
exploration/Rewards Std           1.20675
exploration/Rewards Max          -1.16159
exploration/Rewards Min          -9.94533
exploration/Returns Mean       -390.981
exploration/Returns Std          64.0752
exploration/Returns Max        -293.888
exploration/Returns Min        -476.805
exploration/Actions Mean          0.00349078
exploration/Actions Std           0.557108
exploration/Actions Max           0.989489
exploration/Actions Min          -0.977061
exploration/Num Paths             5
exploration/Average Returns    -390.981
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.37094
evaluation/Rewards Std            0.817906
evaluation/Rewards Max           -1.8251
evaluation/Rewards Min          -11.4088
evaluation/Returns Mean        -437.094
evaluation/Returns Std           67.0038
evaluation/Returns Max         -315.472
evaluation/Returns Min         -525.572
evaluation/Actions Mean           0.0107649
evaluation/Actions Std            0.116818
evaluation/Actions Max            0.868657
evaluation/Actions Min           -0.74952
evaluation/Num Paths             15
evaluation/Average Returns     -437.094
time/data storing (s)             0.00354665
time/evaluation sampling (s)      0.360724
time/exploration sampling (s)     0.162024
time/logging (s)                  0.00448733
time/saving (s)                   0.00204887
time/training (s)                 2.10206
time/epoch (s)                    2.63489
time/total (s)                    8.18093
Epoch                             2
-----------------------------  -------------
2019-04-22 21:38:11.584530 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             2200
trainer/QF1 Loss                  1.36406
trainer/QF2 Loss                  1.24779
trainer/Policy Loss              27.0977
trainer/Q1 Predictions Mean     -28.9269
trainer/Q1 Predictions Std       10.0601
trainer/Q1 Predictions Max      -15.0987
trainer/Q1 Predictions Min      -52.3495
trainer/Q2 Predictions Mean     -28.9365
trainer/Q2 Predictions Std       10.1238
trainer/Q2 Predictions Max      -15.1588
trainer/Q2 Predictions Min      -52.7653
trainer/Q Targets Mean          -29.3635
trainer/Q Targets Std            10.1969
trainer/Q Targets Max           -15.4823
trainer/Q Targets Min           -52.4352
trainer/Log Pis Mean             -0.538187
trainer/Log Pis Std               1.07388
trainer/Log Pis Max               2.32548
trainer/Log Pis Min              -3.29443
trainer/Policy mu Mean            0.10388
trainer/Policy mu Std             0.707127
trainer/Policy mu Max             1.63419
trainer/Policy mu Min            -1.70329
trainer/Policy log std Mean      -0.445939
trainer/Policy log std Std        0.0542309
trainer/Policy log std Max       -0.345288
trainer/Policy log std Min       -0.598692
trainer/Alpha                     0.662454
trainer/Alpha Loss               -1.04462
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.34953
exploration/Rewards Std           1.32744
exploration/Rewards Max          -0.780378
exploration/Rewards Min          -8.74029
exploration/Returns Mean       -334.953
exploration/Returns Std         102.339
exploration/Returns Max        -212.727
exploration/Returns Min        -461.916
exploration/Actions Mean          0.00887016
exploration/Actions Std           0.555902
exploration/Actions Max           0.992635
exploration/Actions Min          -0.989723
exploration/Num Paths             5
exploration/Average Returns    -334.953
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.2195
evaluation/Rewards Std            1.03473
evaluation/Rewards Max           -1.15046
evaluation/Rewards Min           -9.63879
evaluation/Returns Mean        -321.95
evaluation/Returns Std           77.1219
evaluation/Returns Max         -208.032
evaluation/Returns Min         -443.212
evaluation/Actions Mean           0.0213629
evaluation/Actions Std            0.134049
evaluation/Actions Max            0.926297
evaluation/Actions Min           -0.797792
evaluation/Num Paths             15
evaluation/Average Returns     -321.95
time/data storing (s)             0.00334618
time/evaluation sampling (s)      0.354198
time/exploration sampling (s)     0.165089
time/logging (s)                  0.00439737
time/saving (s)                   0.00217783
time/training (s)                 2.12619
time/epoch (s)                    2.6554
time/total (s)                   10.8407
Epoch                             3
-----------------------------  -------------
2019-04-22 21:38:14.239820 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                  2.10796
trainer/QF2 Loss                  1.87132
trainer/Policy Loss              36.5667
trainer/Q1 Predictions Mean     -38.559
trainer/Q1 Predictions Std       13.0988
trainer/Q1 Predictions Max      -17.9013
trainer/Q1 Predictions Min      -62.8966
trainer/Q2 Predictions Mean     -38.6133
trainer/Q2 Predictions Std       13.0802
trainer/Q2 Predictions Max      -17.8479
trainer/Q2 Predictions Min      -62.3467
trainer/Q Targets Mean          -39.158
trainer/Q Targets Std            13.1322
trainer/Q Targets Max           -18.9064
trainer/Q Targets Min           -64.206
trainer/Log Pis Mean             -0.0736708
trainer/Log Pis Std               1.6775
trainer/Log Pis Max               3.1808
trainer/Log Pis Min              -4.49573
trainer/Policy mu Mean            0.137425
trainer/Policy mu Std             0.925126
trainer/Policy mu Max             1.8531
trainer/Policy mu Min            -1.80603
trainer/Policy log std Mean      -0.531783
trainer/Policy log std Std        0.0782294
trainer/Policy log std Max       -0.359394
trainer/Policy log std Min       -0.697139
trainer/Alpha                     0.583749
trainer/Alpha Loss               -1.11572
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.61647
exploration/Rewards Std           1.11759
exploration/Rewards Max          -0.400591
exploration/Rewards Min          -8.52633
exploration/Returns Mean       -261.647
exploration/Returns Std          52.6414
exploration/Returns Max        -180.604
exploration/Returns Min        -345.682
exploration/Actions Mean          0.00357535
exploration/Actions Std           0.522667
exploration/Actions Max           0.989529
exploration/Actions Min          -0.983871
exploration/Num Paths             5
exploration/Average Returns    -261.647
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -2.22358
evaluation/Rewards Std            0.92012
evaluation/Rewards Max           -0.948898
evaluation/Rewards Min          -10.2545
evaluation/Returns Mean        -222.358
evaluation/Returns Std           56.4155
evaluation/Returns Max         -157.822
evaluation/Returns Min         -328.293
evaluation/Actions Mean           0.0153838
evaluation/Actions Std            0.152833
evaluation/Actions Max            0.942101
evaluation/Actions Min           -0.891191
evaluation/Num Paths             15
evaluation/Average Returns     -222.358
time/data storing (s)             0.00324031
time/evaluation sampling (s)      0.392341
time/exploration sampling (s)     0.166031
time/logging (s)                  0.00491994
time/saving (s)                   0.00201079
time/training (s)                 2.08225
time/epoch (s)                    2.6508
time/total (s)                   13.4959
Epoch                             4
-----------------------------  -------------
2019-04-22 21:38:16.890132 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             3200
trainer/QF1 Loss                 26.1864
trainer/QF2 Loss                 26.233
trainer/Policy Loss              38.8617
trainer/Q1 Predictions Mean     -40.8584
trainer/Q1 Predictions Std       13.4096
trainer/Q1 Predictions Max      -20.1241
trainer/Q1 Predictions Min      -72.3635
trainer/Q2 Predictions Mean     -40.8378
trainer/Q2 Predictions Std       13.3982
trainer/Q2 Predictions Max      -20.5653
trainer/Q2 Predictions Min      -73.0068
trainer/Q Targets Mean          -40.7092
trainer/Q Targets Std            14.7589
trainer/Q Targets Max            -2.40642
trainer/Q Targets Min           -76.7392
trainer/Log Pis Mean             -0.102614
trainer/Log Pis Std               1.59905
trainer/Log Pis Max               3.39291
trainer/Log Pis Min              -6.14604
trainer/Policy mu Mean            0.100567
trainer/Policy mu Std             0.893031
trainer/Policy mu Max             1.85795
trainer/Policy mu Min            -1.8294
trainer/Policy log std Mean      -0.563652
trainer/Policy log std Std        0.0815887
trainer/Policy log std Max       -0.345495
trainer/Policy log std Min       -0.698584
trainer/Alpha                     0.514596
trainer/Alpha Loss               -1.39641
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.56745
exploration/Rewards Std           1.06642
exploration/Rewards Max          -0.149652
exploration/Rewards Min          -9.01808
exploration/Returns Mean       -256.745
exploration/Returns Std          60.5693
exploration/Returns Max        -138.226
exploration/Returns Min        -304.227
exploration/Actions Mean         -0.0135722
exploration/Actions Std           0.505221
exploration/Actions Max           0.971315
exploration/Actions Min          -0.980853
exploration/Num Paths             5
exploration/Average Returns    -256.745
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.81838
evaluation/Rewards Std            0.970625
evaluation/Rewards Max           -1.07049
evaluation/Rewards Min           -9.28197
evaluation/Returns Mean        -181.838
evaluation/Returns Std           62.5473
evaluation/Returns Max         -116.11
evaluation/Returns Min         -284.101
evaluation/Actions Mean           0.0101417
evaluation/Actions Std            0.162536
evaluation/Actions Max            0.95666
evaluation/Actions Min           -0.926612
evaluation/Num Paths             15
evaluation/Average Returns     -181.838
time/data storing (s)             0.00317194
time/evaluation sampling (s)      0.35693
time/exploration sampling (s)     0.163369
time/logging (s)                  0.00429621
time/saving (s)                   0.00219299
time/training (s)                 2.11389
time/epoch (s)                    2.64385
time/total (s)                   16.1445
Epoch                             5
-----------------------------  -------------
2019-04-22 21:38:19.611856 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                   5.90931
trainer/QF2 Loss                   5.74754
trainer/Policy Loss               42.4867
trainer/Q1 Predictions Mean      -44.6249
trainer/Q1 Predictions Std        14.1649
trainer/Q1 Predictions Max       -21.7521
trainer/Q1 Predictions Min       -79.0409
trainer/Q2 Predictions Mean      -44.5679
trainer/Q2 Predictions Std        14.1537
trainer/Q2 Predictions Max       -22.0491
trainer/Q2 Predictions Min       -79.5534
trainer/Q Targets Mean           -44.4478
trainer/Q Targets Std             14.6205
trainer/Q Targets Max             -1.33005
trainer/Q Targets Min            -82.019
trainer/Log Pis Mean               0.0147545
trainer/Log Pis Std                1.37493
trainer/Log Pis Max                3.78477
trainer/Log Pis Min               -3.26416
trainer/Policy mu Mean             0.151042
trainer/Policy mu Std              0.908523
trainer/Policy mu Max              2.1039
trainer/Policy mu Min             -2.14992
trainer/Policy log std Mean       -0.649438
trainer/Policy log std Std         0.0825339
trainer/Policy log std Max        -0.418851
trainer/Policy log std Min        -0.781479
trainer/Alpha                      0.45349
trainer/Alpha Loss                -1.5694
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.60394
exploration/Rewards Std            1.01061
exploration/Rewards Max           -0.078402
exploration/Rewards Min           -9.06673
exploration/Returns Mean        -160.394
exploration/Returns Std           42.4704
exploration/Returns Max         -104.987
exploration/Returns Min         -232.819
exploration/Actions Mean           0.0160041
exploration/Actions Std            0.467026
exploration/Actions Max            0.988684
exploration/Actions Min           -0.987345
exploration/Num Paths              5
exploration/Average Returns     -160.394
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.55799
evaluation/Rewards Std             0.787509
evaluation/Rewards Max            -0.175118
evaluation/Rewards Min            -8.56621
evaluation/Returns Mean         -155.799
evaluation/Returns Std            50.6548
evaluation/Returns Max           -75.1914
evaluation/Returns Min          -225.631
evaluation/Actions Mean           -0.00494902
evaluation/Actions Std             0.153457
evaluation/Actions Max             0.942324
evaluation/Actions Min            -0.958971
evaluation/Num Paths              15
evaluation/Average Returns      -155.799
time/data storing (s)              0.00331938
time/evaluation sampling (s)       0.361865
time/exploration sampling (s)      0.164807
time/logging (s)                   0.00504199
time/saving (s)                    0.00216997
time/training (s)                  2.18028
time/epoch (s)                     2.71748
time/total (s)                    18.8664
Epoch                              6
-----------------------------  --------------
2019-04-22 21:38:22.299270 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   1.56934
trainer/QF2 Loss                   1.51671
trainer/Policy Loss               42.0683
trainer/Q1 Predictions Mean      -43.9201
trainer/Q1 Predictions Std        16.1953
trainer/Q1 Predictions Max       -22.8726
trainer/Q1 Predictions Min       -86.2391
trainer/Q2 Predictions Mean      -43.8969
trainer/Q2 Predictions Std        16.145
trainer/Q2 Predictions Max       -23.1182
trainer/Q2 Predictions Min       -86.422
trainer/Q Targets Mean           -44.4523
trainer/Q Targets Std             16.6407
trainer/Q Targets Max            -22.9479
trainer/Q Targets Min            -90.1232
trainer/Log Pis Mean               0.189693
trainer/Log Pis Std                1.50692
trainer/Log Pis Max                4.33977
trainer/Log Pis Min               -2.37881
trainer/Policy mu Mean             0.0592491
trainer/Policy mu Std              0.926713
trainer/Policy mu Max              2.02304
trainer/Policy mu Min             -2.11362
trainer/Policy log std Mean       -0.70868
trainer/Policy log std Std         0.101438
trainer/Policy log std Max        -0.432944
trainer/Policy log std Min        -0.865793
trainer/Alpha                      0.400291
trainer/Alpha Loss                -1.65701
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.36503
exploration/Rewards Std            0.82411
exploration/Rewards Max           -0.0264851
exploration/Rewards Min           -8.52129
exploration/Returns Mean        -136.503
exploration/Returns Std           29.3159
exploration/Returns Max          -86.4808
exploration/Returns Min         -175.578
exploration/Actions Mean           0.00576101
exploration/Actions Std            0.450422
exploration/Actions Max            0.970711
exploration/Actions Min           -0.982371
exploration/Num Paths              5
exploration/Average Returns     -136.503
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.39896
evaluation/Rewards Std             0.964454
evaluation/Rewards Max            -0.532578
evaluation/Rewards Min            -9.92294
evaluation/Returns Mean         -139.896
evaluation/Returns Std            42.4636
evaluation/Returns Max           -72.2039
evaluation/Returns Min          -217.34
evaluation/Actions Mean           -0.00146597
evaluation/Actions Std             0.173333
evaluation/Actions Max             0.970057
evaluation/Actions Min            -0.963083
evaluation/Num Paths              15
evaluation/Average Returns      -139.896
time/data storing (s)              0.00298959
time/evaluation sampling (s)       0.357599
time/exploration sampling (s)      0.161972
time/logging (s)                   0.00408117
time/saving (s)                    0.00226658
time/training (s)                  2.15205
time/epoch (s)                     2.68096
time/total (s)                    21.552
Epoch                              7
-----------------------------  --------------
2019-04-22 21:38:25.012948 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                  19.1688
trainer/QF2 Loss                  19.2598
trainer/Policy Loss               44.5133
trainer/Q1 Predictions Mean      -45.9469
trainer/Q1 Predictions Std        15.5871
trainer/Q1 Predictions Max       -23.4757
trainer/Q1 Predictions Min       -94.9599
trainer/Q2 Predictions Mean      -45.9473
trainer/Q2 Predictions Std        15.6428
trainer/Q2 Predictions Max       -23.6536
trainer/Q2 Predictions Min       -95.2089
trainer/Q Targets Mean           -46.3806
trainer/Q Targets Std             16.7388
trainer/Q Targets Max             -1.83906
trainer/Q Targets Min            -99.7289
trainer/Log Pis Mean               0.113404
trainer/Log Pis Std                1.33302
trainer/Log Pis Max                3.92297
trainer/Log Pis Min               -2.98862
trainer/Policy mu Mean             0.0284364
trainer/Policy mu Std              0.907103
trainer/Policy mu Max              2.19411
trainer/Policy mu Min             -2.33099
trainer/Policy log std Mean       -0.807722
trainer/Policy log std Std         0.153953
trainer/Policy log std Max        -0.457
trainer/Policy log std Min        -1.07746
trainer/Alpha                      0.353222
trainer/Alpha Loss                -1.96283
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.23784
exploration/Rewards Std            0.599415
exploration/Rewards Max           -0.0450553
exploration/Rewards Min           -5.06041
exploration/Returns Mean        -123.784
exploration/Returns Std           27.7795
exploration/Returns Max          -76.3864
exploration/Returns Min         -150.298
exploration/Actions Mean          -0.0155594
exploration/Actions Std            0.425866
exploration/Actions Max            0.922336
exploration/Actions Min           -0.973321
exploration/Num Paths              5
exploration/Average Returns     -123.784
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.11263
evaluation/Rewards Std             1.02024
evaluation/Rewards Max            -0.259913
evaluation/Rewards Min           -10.5455
evaluation/Returns Mean         -111.263
evaluation/Returns Std            46.5559
evaluation/Returns Max           -45.5324
evaluation/Returns Min          -178.151
evaluation/Actions Mean           -0.00884601
evaluation/Actions Std             0.175518
evaluation/Actions Max             0.980883
evaluation/Actions Min            -0.97514
evaluation/Num Paths              15
evaluation/Average Returns      -111.263
time/data storing (s)              0.00319101
time/evaluation sampling (s)       0.359786
time/exploration sampling (s)      0.158808
time/logging (s)                   0.00509813
time/saving (s)                    0.00217806
time/training (s)                  2.18045
time/epoch (s)                     2.70951
time/total (s)                    24.2661
Epoch                              8
-----------------------------  --------------
2019-04-22 21:38:27.791518 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                   7.26286
trainer/QF2 Loss                   7.19234
trainer/Policy Loss               45.8029
trainer/Q1 Predictions Mean      -47.1241
trainer/Q1 Predictions Std        16.1882
trainer/Q1 Predictions Max       -23.4532
trainer/Q1 Predictions Min       -93.8832
trainer/Q2 Predictions Mean      -47.1285
trainer/Q2 Predictions Std        16.2196
trainer/Q2 Predictions Max       -23.5977
trainer/Q2 Predictions Min       -94.1176
trainer/Q Targets Mean           -47.5138
trainer/Q Targets Std             16.9146
trainer/Q Targets Max             -1.85671
trainer/Q Targets Min            -98.578
trainer/Log Pis Mean               0.355836
trainer/Log Pis Std                1.58957
trainer/Log Pis Max                5.29509
trainer/Log Pis Min               -4.86017
trainer/Policy mu Mean             0.145552
trainer/Policy mu Std              0.907699
trainer/Policy mu Max              2.23498
trainer/Policy mu Min             -2.07417
trainer/Policy log std Mean       -0.866073
trainer/Policy log std Std         0.182948
trainer/Policy log std Max        -0.455292
trainer/Policy log std Min        -1.2271
trainer/Alpha                      0.31172
trainer/Alpha Loss                -1.9161
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.35978
exploration/Rewards Std            1.09475
exploration/Rewards Max           -0.125583
exploration/Rewards Min          -10.027
exploration/Returns Mean        -135.978
exploration/Returns Std           36.5102
exploration/Returns Max          -66.7407
exploration/Returns Min         -174.983
exploration/Actions Mean           0.00677292
exploration/Actions Std            0.427002
exploration/Actions Max            0.99028
exploration/Actions Min           -0.98913
exploration/Num Paths              5
exploration/Average Returns     -135.978
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.2116
evaluation/Rewards Std             0.934156
evaluation/Rewards Max            -0.195101
evaluation/Rewards Min           -10.585
evaluation/Returns Mean         -121.16
evaluation/Returns Std            37.4838
evaluation/Returns Max           -37.829
evaluation/Returns Min          -192.159
evaluation/Actions Mean            0.00457332
evaluation/Actions Std             0.172236
evaluation/Actions Max             0.978131
evaluation/Actions Min            -0.974497
evaluation/Num Paths              15
evaluation/Average Returns      -121.16
time/data storing (s)              0.00306695
time/evaluation sampling (s)       0.36104
time/exploration sampling (s)      0.16014
time/logging (s)                   0.00549206
time/saving (s)                    0.00206955
time/training (s)                  2.2419
time/epoch (s)                     2.77371
time/total (s)                    27.0442
Epoch                              9
-----------------------------  --------------
2019-04-22 21:38:30.677361 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                  57.0617
trainer/QF2 Loss                  56.9162
trainer/Policy Loss               48.2399
trainer/Q1 Predictions Mean      -49.636
trainer/Q1 Predictions Std        16.3669
trainer/Q1 Predictions Max       -24.3439
trainer/Q1 Predictions Min       -95.2036
trainer/Q2 Predictions Mean      -49.6847
trainer/Q2 Predictions Std        16.3708
trainer/Q2 Predictions Max       -24.5025
trainer/Q2 Predictions Min       -95.2889
trainer/Q Targets Mean           -48.6466
trainer/Q Targets Std             18.3736
trainer/Q Targets Max             -2.73372
trainer/Q Targets Min            -94.6052
trainer/Log Pis Mean               0.790547
trainer/Log Pis Std                1.59734
trainer/Log Pis Max                5.44
trainer/Log Pis Min               -4.60074
trainer/Policy mu Mean             0.105267
trainer/Policy mu Std              0.988181
trainer/Policy mu Max              2.3097
trainer/Policy mu Min             -2.41593
trainer/Policy log std Mean       -0.906079
trainer/Policy log std Std         0.189599
trainer/Policy log std Max        -0.452423
trainer/Policy log std Min        -1.24763
trainer/Alpha                      0.274666
trainer/Alpha Loss                -1.56257
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.949693
exploration/Rewards Std            0.671432
exploration/Rewards Max           -0.0241803
exploration/Rewards Min           -6.14044
exploration/Returns Mean         -94.9693
exploration/Returns Std           38.3951
exploration/Returns Max          -48.6126
exploration/Returns Min         -154.4
exploration/Actions Mean           0.0129159
exploration/Actions Std            0.393598
exploration/Actions Max            0.980009
exploration/Actions Min           -0.984008
exploration/Num Paths              5
exploration/Average Returns      -94.9693
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.880443
evaluation/Rewards Std             1.00126
evaluation/Rewards Max            -0.197023
evaluation/Rewards Min            -9.21408
evaluation/Returns Mean          -88.0443
evaluation/Returns Std            47.1014
evaluation/Returns Max           -27.638
evaluation/Returns Min          -177.489
evaluation/Actions Mean            0.00379061
evaluation/Actions Std             0.182495
evaluation/Actions Max             0.979739
evaluation/Actions Min            -0.965029
evaluation/Num Paths              15
evaluation/Average Returns       -88.0443
time/data storing (s)              0.00303111
time/evaluation sampling (s)       0.384781
time/exploration sampling (s)      0.170401
time/logging (s)                   0.00561818
time/saving (s)                    0.00199851
time/training (s)                  2.31395
time/epoch (s)                     2.87978
time/total (s)                    29.9293
Epoch                             10
-----------------------------  --------------
2019-04-22 21:38:33.417380 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   0.731502
trainer/QF2 Loss                   0.722969
trainer/Policy Loss               45.1557
trainer/Q1 Predictions Mean      -46.1375
trainer/Q1 Predictions Std        15.1151
trainer/Q1 Predictions Max       -24.0219
trainer/Q1 Predictions Min       -87.7361
trainer/Q2 Predictions Mean      -46.0796
trainer/Q2 Predictions Std        15.1549
trainer/Q2 Predictions Max       -23.9249
trainer/Q2 Predictions Min       -87.2977
trainer/Q Targets Mean           -46.6061
trainer/Q Targets Std             15.1098
trainer/Q Targets Max            -24.0705
trainer/Q Targets Min            -89.7414
trainer/Log Pis Mean               0.758058
trainer/Log Pis Std                1.58273
trainer/Log Pis Max                4.82673
trainer/Log Pis Min               -4.61063
trainer/Policy mu Mean             0.0515434
trainer/Policy mu Std              0.959403
trainer/Policy mu Max              2.35156
trainer/Policy mu Min             -2.31635
trainer/Policy log std Mean       -0.954768
trainer/Policy log std Std         0.185192
trainer/Policy log std Max        -0.56221
trainer/Policy log std Min        -1.26948
trainer/Alpha                      0.241195
trainer/Alpha Loss                -1.76591
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.28388
exploration/Rewards Std            1.07068
exploration/Rewards Max           -0.0571194
exploration/Rewards Min           -8.92839
exploration/Returns Mean        -128.388
exploration/Returns Std           45.5644
exploration/Returns Max          -58.6771
exploration/Returns Min         -166.849
exploration/Actions Mean          -0.0119795
exploration/Actions Std            0.423034
exploration/Actions Max            0.997273
exploration/Actions Min           -0.982043
exploration/Num Paths              5
exploration/Average Returns     -128.388
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.93152
evaluation/Rewards Std             1.00623
evaluation/Rewards Max            -0.0472472
evaluation/Rewards Min            -9.96077
evaluation/Returns Mean          -93.152
evaluation/Returns Std            45.6168
evaluation/Returns Max           -19.2965
evaluation/Returns Min          -159.292
evaluation/Actions Mean            0.0132805
evaluation/Actions Std             0.172758
evaluation/Actions Max             0.986967
evaluation/Actions Min            -0.975253
evaluation/Num Paths              15
evaluation/Average Returns       -93.152
time/data storing (s)              0.00370093
time/evaluation sampling (s)       0.373954
time/exploration sampling (s)      0.169699
time/logging (s)                   0.00503357
time/saving (s)                    0.0021551
time/training (s)                  2.17867
time/epoch (s)                     2.73321
time/total (s)                    32.6673
Epoch                             11
-----------------------------  --------------
2019-04-22 21:38:36.167786 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              6700
trainer/QF1 Loss                   1.77296
trainer/QF2 Loss                   1.75122
trainer/Policy Loss               46.4395
trainer/Q1 Predictions Mean      -47.1885
trainer/Q1 Predictions Std        18.2317
trainer/Q1 Predictions Max       -23.9227
trainer/Q1 Predictions Min       -98.3728
trainer/Q2 Predictions Mean      -47.1656
trainer/Q2 Predictions Std        18.204
trainer/Q2 Predictions Max       -23.8181
trainer/Q2 Predictions Min       -98.0809
trainer/Q Targets Mean           -48.0955
trainer/Q Targets Std             18.7771
trainer/Q Targets Max            -24.2321
trainer/Q Targets Min           -102.771
trainer/Log Pis Mean               0.784451
trainer/Log Pis Std                1.68465
trainer/Log Pis Max                6.45241
trainer/Log Pis Min               -2.82735
trainer/Policy mu Mean             0.104276
trainer/Policy mu Std              0.980522
trainer/Policy mu Max              2.56568
trainer/Policy mu Min             -2.2575
trainer/Policy log std Mean       -0.973514
trainer/Policy log std Std         0.221535
trainer/Policy log std Max        -0.387983
trainer/Policy log std Min        -1.29071
trainer/Alpha                      0.211508
trainer/Alpha Loss                -1.88803
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.938934
exploration/Rewards Std            0.816007
exploration/Rewards Max           -0.0119827
exploration/Rewards Min           -8.56397
exploration/Returns Mean         -93.8934
exploration/Returns Std           24.1317
exploration/Returns Max          -66.8085
exploration/Returns Min         -131.456
exploration/Actions Mean           0.00525735
exploration/Actions Std            0.369854
exploration/Actions Max            0.996806
exploration/Actions Min           -0.996651
exploration/Num Paths              5
exploration/Average Returns      -93.8934
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.07409
evaluation/Rewards Std             0.814278
evaluation/Rewards Max            -0.121798
evaluation/Rewards Min            -8.48693
evaluation/Returns Mean         -107.409
evaluation/Returns Std            41.9469
evaluation/Returns Max           -31.6121
evaluation/Returns Min          -152.33
evaluation/Actions Mean           -0.0167378
evaluation/Actions Std             0.168455
evaluation/Actions Max             0.979246
evaluation/Actions Min            -0.987313
evaluation/Num Paths              15
evaluation/Average Returns      -107.409
time/data storing (s)              0.0033175
time/evaluation sampling (s)       0.358391
time/exploration sampling (s)      0.16336
time/logging (s)                   0.0052159
time/saving (s)                    0.0018798
time/training (s)                  2.21307
time/epoch (s)                     2.74524
time/total (s)                    35.417
Epoch                             12
-----------------------------  --------------
2019-04-22 21:38:38.944692 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   6.75613
trainer/QF2 Loss                   6.74152
trainer/Policy Loss               47.999
trainer/Q1 Predictions Mean      -48.6359
trainer/Q1 Predictions Std        16.5573
trainer/Q1 Predictions Max       -23.8181
trainer/Q1 Predictions Min       -94.9336
trainer/Q2 Predictions Mean      -48.6498
trainer/Q2 Predictions Std        16.5762
trainer/Q2 Predictions Max       -23.7372
trainer/Q2 Predictions Min       -95.5028
trainer/Q Targets Mean           -48.7258
trainer/Q Targets Std             17.1556
trainer/Q Targets Max             -1.33005
trainer/Q Targets Min            -97.5951
trainer/Log Pis Mean               0.887637
trainer/Log Pis Std                1.67673
trainer/Log Pis Max                5.72854
trainer/Log Pis Min               -3.0672
trainer/Policy mu Mean             0.0443634
trainer/Policy mu Std              1.02604
trainer/Policy mu Max              2.3806
trainer/Policy mu Min             -2.43573
trainer/Policy log std Mean       -1.02991
trainer/Policy log std Std         0.238133
trainer/Policy log std Max        -0.374099
trainer/Policy log std Min        -1.38104
trainer/Alpha                      0.185943
trainer/Alpha Loss                -1.87107
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.710067
exploration/Rewards Std            0.949396
exploration/Rewards Max           -0.00353237
exploration/Rewards Min           -9.78501
exploration/Returns Mean         -71.0067
exploration/Returns Std            7.61565
exploration/Returns Max          -59.9118
exploration/Returns Min          -80.7247
exploration/Actions Mean           0.0143912
exploration/Actions Std            0.333447
exploration/Actions Max            0.997938
exploration/Actions Min           -0.988313
exploration/Num Paths              5
exploration/Average Returns      -71.0067
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.654983
evaluation/Rewards Std             0.862285
evaluation/Rewards Max            -0.0998734
evaluation/Rewards Min            -9.03495
evaluation/Returns Mean          -65.4983
evaluation/Returns Std            46.3171
evaluation/Returns Max           -12.6144
evaluation/Returns Min          -153.343
evaluation/Actions Mean            0.00462179
evaluation/Actions Std             0.162776
evaluation/Actions Max             0.987881
evaluation/Actions Min            -0.975324
evaluation/Num Paths              15
evaluation/Average Returns       -65.4983
time/data storing (s)              0.00349961
time/evaluation sampling (s)       0.374256
time/exploration sampling (s)      0.157161
time/logging (s)                   0.0054535
time/saving (s)                    0.00233142
time/training (s)                  2.22886
time/epoch (s)                     2.77156
time/total (s)                    38.1931
Epoch                             13
-----------------------------  --------------
2019-04-22 21:38:41.899121 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                   0.665561
trainer/QF2 Loss                   0.725997
trainer/Policy Loss               43.5907
trainer/Q1 Predictions Mean      -44.1055
trainer/Q1 Predictions Std        16.8684
trainer/Q1 Predictions Max       -23.4324
trainer/Q1 Predictions Min      -101.232
trainer/Q2 Predictions Mean      -44.1085
trainer/Q2 Predictions Std        16.8473
trainer/Q2 Predictions Max       -23.3998
trainer/Q2 Predictions Min      -101.484
trainer/Q Targets Mean           -44.5222
trainer/Q Targets Std             16.9789
trainer/Q Targets Max            -23.8043
trainer/Q Targets Min           -101.03
trainer/Log Pis Mean               0.988675
trainer/Log Pis Std                1.42344
trainer/Log Pis Max                4.55604
trainer/Log Pis Min               -3.18961
trainer/Policy mu Mean            -0.0705213
trainer/Policy mu Std              0.940617
trainer/Policy mu Max              2.41031
trainer/Policy mu Min             -2.72527
trainer/Policy log std Mean       -1.1452
trainer/Policy log std Std         0.250461
trainer/Policy log std Max        -0.522111
trainer/Policy log std Min        -1.47327
trainer/Alpha                      0.164068
trainer/Alpha Loss                -1.82768
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.863427
exploration/Rewards Std            1.23481
exploration/Rewards Max           -0.0192945
exploration/Rewards Min           -9.66202
exploration/Returns Mean         -86.3427
exploration/Returns Std           16.6719
exploration/Returns Max          -54.2088
exploration/Returns Min         -100.772
exploration/Actions Mean           0.020728
exploration/Actions Std            0.350752
exploration/Actions Max            0.993395
exploration/Actions Min           -0.996762
exploration/Num Paths              5
exploration/Average Returns      -86.3427
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.734588
evaluation/Rewards Std             0.75531
evaluation/Rewards Max            -0.117279
evaluation/Rewards Min            -8.61821
evaluation/Returns Mean          -73.4588
evaluation/Returns Std            17.3993
evaluation/Returns Max           -50.4392
evaluation/Returns Min          -109.958
evaluation/Actions Mean            0.00267603
evaluation/Actions Std             0.180937
evaluation/Actions Max             0.984205
evaluation/Actions Min            -0.983812
evaluation/Num Paths              15
evaluation/Average Returns       -73.4588
time/data storing (s)              0.00319114
time/evaluation sampling (s)       0.39161
time/exploration sampling (s)      0.169681
time/logging (s)                   0.00522445
time/saving (s)                    0.0379902
time/training (s)                  2.3403
time/epoch (s)                     2.948
time/total (s)                    41.1463
Epoch                             14
-----------------------------  --------------
2019-04-22 21:38:44.677485 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                  18.5565
trainer/QF2 Loss                  18.5014
trainer/Policy Loss               45.5935
trainer/Q1 Predictions Mean      -45.906
trainer/Q1 Predictions Std        18.8075
trainer/Q1 Predictions Max       -23.5441
trainer/Q1 Predictions Min      -105.851
trainer/Q2 Predictions Mean      -45.9374
trainer/Q2 Predictions Std        18.8651
trainer/Q2 Predictions Max       -23.4073
trainer/Q2 Predictions Min      -106.61
trainer/Q Targets Mean           -45.8211
trainer/Q Targets Std             19.5942
trainer/Q Targets Max             -0.108013
trainer/Q Targets Min           -106.527
trainer/Log Pis Mean               1.2388
trainer/Log Pis Std                1.7285
trainer/Log Pis Max                6.25522
trainer/Log Pis Min               -3.38126
trainer/Policy mu Mean            -0.0275714
trainer/Policy mu Std              1.03675
trainer/Policy mu Max              2.88248
trainer/Policy mu Min             -2.61228
trainer/Policy log std Mean       -1.18955
trainer/Policy log std Std         0.292518
trainer/Policy log std Max        -0.522162
trainer/Policy log std Min        -1.63794
trainer/Alpha                      0.146283
trainer/Alpha Loss                -1.46303
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.784665
exploration/Rewards Std            1.07907
exploration/Rewards Max           -0.012555
exploration/Rewards Min           -9.67863
exploration/Returns Mean         -78.4665
exploration/Returns Std           18.341
exploration/Returns Max          -52.1076
exploration/Returns Min          -98.063
exploration/Actions Mean           0.00832669
exploration/Actions Std            0.355798
exploration/Actions Max            0.999285
exploration/Actions Min           -0.978503
exploration/Num Paths              5
exploration/Average Returns      -78.4665
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.685696
evaluation/Rewards Std             0.886268
evaluation/Rewards Max            -0.140609
evaluation/Rewards Min           -11.5489
evaluation/Returns Mean          -68.5696
evaluation/Returns Std            24.1477
evaluation/Returns Max           -47.7152
evaluation/Returns Min          -130.629
evaluation/Actions Mean           -0.00706833
evaluation/Actions Std             0.171791
evaluation/Actions Max             0.994975
evaluation/Actions Min            -0.994292
evaluation/Num Paths              15
evaluation/Average Returns       -68.5696
time/data storing (s)              0.00304698
time/evaluation sampling (s)       0.385518
time/exploration sampling (s)      0.174561
time/logging (s)                   0.00542085
time/saving (s)                    0.00241315
time/training (s)                  2.20153
time/epoch (s)                     2.77249
time/total (s)                    43.9239
Epoch                             15
-----------------------------  --------------
2019-04-22 21:38:47.394616 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              8700
trainer/QF1 Loss                  49.7837
trainer/QF2 Loss                  50.1366
trainer/Policy Loss               43.5685
trainer/Q1 Predictions Mean      -43.8706
trainer/Q1 Predictions Std        18.2162
trainer/Q1 Predictions Max       -23.3942
trainer/Q1 Predictions Min      -107.921
trainer/Q2 Predictions Mean      -43.8597
trainer/Q2 Predictions Std        18.1974
trainer/Q2 Predictions Max       -23.1786
trainer/Q2 Predictions Min      -108.068
trainer/Q Targets Mean           -43.3575
trainer/Q Targets Std             18.8657
trainer/Q Targets Max             -0.468603
trainer/Q Targets Min           -105.177
trainer/Log Pis Mean               1.27411
trainer/Log Pis Std                1.57981
trainer/Log Pis Max                6.55226
trainer/Log Pis Min               -1.81951
trainer/Policy mu Mean             0.030124
trainer/Policy mu Std              0.97301
trainer/Policy mu Max              2.91276
trainer/Policy mu Min             -2.57415
trainer/Policy log std Mean       -1.28414
trainer/Policy log std Std         0.324288
trainer/Policy log std Max        -0.456972
trainer/Policy log std Min        -1.787
trainer/Alpha                      0.130542
trainer/Alpha Loss                -1.47779
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.615659
exploration/Rewards Std            1.18303
exploration/Rewards Max           -0.0316364
exploration/Rewards Min           -9.16805
exploration/Returns Mean         -61.5659
exploration/Returns Std           16.3997
exploration/Returns Max          -33.3799
exploration/Returns Min          -79.2166
exploration/Actions Mean           0.0273515
exploration/Actions Std            0.318963
exploration/Actions Max            0.997978
exploration/Actions Min           -0.988577
exploration/Num Paths              5
exploration/Average Returns      -61.5659
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.598273
evaluation/Rewards Std             1.12256
evaluation/Rewards Max            -0.0226404
evaluation/Rewards Min            -9.86942
evaluation/Returns Mean          -59.8273
evaluation/Returns Std            32.6688
evaluation/Returns Max           -16.3883
evaluation/Returns Min          -116.389
evaluation/Actions Mean            0.00366158
evaluation/Actions Std             0.196693
evaluation/Actions Max             0.996228
evaluation/Actions Min            -0.990244
evaluation/Num Paths              15
evaluation/Average Returns       -59.8273
time/data storing (s)              0.00327413
time/evaluation sampling (s)       0.367889
time/exploration sampling (s)      0.157914
time/logging (s)                   0.00609787
time/saving (s)                    0.00233776
time/training (s)                  2.17463
time/epoch (s)                     2.71214
time/total (s)                    46.6408
Epoch                             16
-----------------------------  --------------
2019-04-22 21:38:50.229181 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                  17.0037
trainer/QF2 Loss                  17.0384
trainer/Policy Loss               44.0513
trainer/Q1 Predictions Mean      -44.7113
trainer/Q1 Predictions Std        19.4732
trainer/Q1 Predictions Max       -23.0668
trainer/Q1 Predictions Min      -109.671
trainer/Q2 Predictions Mean      -44.6022
trainer/Q2 Predictions Std        19.4381
trainer/Q2 Predictions Max       -23.0241
trainer/Q2 Predictions Min      -109.761
trainer/Q Targets Mean           -44.3994
trainer/Q Targets Std             20.0929
trainer/Q Targets Max             -0.0981036
trainer/Q Targets Min           -108.613
trainer/Log Pis Mean               1.45131
trainer/Log Pis Std                1.83537
trainer/Log Pis Max                6.38384
trainer/Log Pis Min               -2.52823
trainer/Policy mu Mean             0.11811
trainer/Policy mu Std              1.11777
trainer/Policy mu Max              2.78915
trainer/Policy mu Min             -2.7614
trainer/Policy log std Mean       -1.32867
trainer/Policy log std Std         0.401038
trainer/Policy log std Max        -0.375411
trainer/Policy log std Min        -1.95884
trainer/Alpha                      0.117575
trainer/Alpha Loss                -1.17447
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.593827
exploration/Rewards Std            0.950383
exploration/Rewards Max           -0.0141216
exploration/Rewards Min           -8.52299
exploration/Returns Mean         -59.3827
exploration/Returns Std           28.1585
exploration/Returns Max          -30.957
exploration/Returns Min         -111.344
exploration/Actions Mean           0.0149288
exploration/Actions Std            0.301344
exploration/Actions Max            0.997462
exploration/Actions Min           -0.992973
exploration/Num Paths              5
exploration/Average Returns      -59.3827
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.454625
evaluation/Rewards Std             0.665443
evaluation/Rewards Max            -0.0536747
evaluation/Rewards Min            -8.34428
evaluation/Returns Mean          -45.4625
evaluation/Returns Std            35.047
evaluation/Returns Max           -15.7977
evaluation/Returns Min          -107.822
evaluation/Actions Mean           -0.00332332
evaluation/Actions Std             0.145137
evaluation/Actions Max             0.990808
evaluation/Actions Min            -0.991395
evaluation/Num Paths              15
evaluation/Average Returns       -45.4625
time/data storing (s)              0.00314275
time/evaluation sampling (s)       0.429642
time/exploration sampling (s)      0.168646
time/logging (s)                   0.00592716
time/saving (s)                    0.002278
time/training (s)                  2.21786
time/epoch (s)                     2.82749
time/total (s)                    49.4734
Epoch                             17
-----------------------------  --------------
2019-04-22 21:38:52.947041 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                   0.629067
trainer/QF2 Loss                   0.575364
trainer/Policy Loss               44.5884
trainer/Q1 Predictions Mean      -44.4816
trainer/Q1 Predictions Std        16.1425
trainer/Q1 Predictions Max       -23.0346
trainer/Q1 Predictions Min      -108.122
trainer/Q2 Predictions Mean      -44.4818
trainer/Q2 Predictions Std        16.1603
trainer/Q2 Predictions Max       -22.9676
trainer/Q2 Predictions Min      -108.519
trainer/Q Targets Mean           -44.8071
trainer/Q Targets Std             16.2772
trainer/Q Targets Max            -22.8824
trainer/Q Targets Min           -105.977
trainer/Log Pis Mean               1.49911
trainer/Log Pis Std                1.79903
trainer/Log Pis Max                6.3759
trainer/Log Pis Min               -3.15528
trainer/Policy mu Mean             0.0762321
trainer/Policy mu Std              1.05702
trainer/Policy mu Max              2.7876
trainer/Policy mu Min             -2.79198
trainer/Policy log std Mean       -1.35023
trainer/Policy log std Std         0.415668
trainer/Policy log std Max        -0.40689
trainer/Policy log std Min        -2.07083
trainer/Alpha                      0.106527
trainer/Alpha Loss                -1.12158
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.545822
exploration/Rewards Std            0.680317
exploration/Rewards Max           -0.0219696
exploration/Rewards Min           -7.49409
exploration/Returns Mean         -54.5822
exploration/Returns Std           21.7937
exploration/Returns Max          -29.78
exploration/Returns Min          -89.0707
exploration/Actions Mean          -0.0212512
exploration/Actions Std            0.307694
exploration/Actions Max            0.976854
exploration/Actions Min           -0.996635
exploration/Num Paths              5
exploration/Average Returns      -54.5822
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.544716
evaluation/Rewards Std             1.0202
evaluation/Rewards Max            -0.0462738
evaluation/Rewards Min           -10.1661
evaluation/Returns Mean          -54.4716
evaluation/Returns Std            20.0729
evaluation/Returns Max           -11.3623
evaluation/Returns Min           -87.9089
evaluation/Actions Mean            0.00735612
evaluation/Actions Std             0.194523
evaluation/Actions Max             0.995874
evaluation/Actions Min            -0.991882
evaluation/Num Paths              15
evaluation/Average Returns       -54.4716
time/data storing (s)              0.00303634
time/evaluation sampling (s)       0.378421
time/exploration sampling (s)      0.168807
time/logging (s)                   0.00439582
time/saving (s)                    0.00237692
time/training (s)                  2.15325
time/epoch (s)                     2.71029
time/total (s)                    52.1886
Epoch                             18
-----------------------------  --------------
2019-04-22 21:38:55.744498 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   1.18981
trainer/QF2 Loss                   0.943907
trainer/Policy Loss               43.3929
trainer/Q1 Predictions Mean      -43.1753
trainer/Q1 Predictions Std        18.9419
trainer/Q1 Predictions Max       -22.3095
trainer/Q1 Predictions Min      -105.72
trainer/Q2 Predictions Mean      -43.1734
trainer/Q2 Predictions Std        18.9635
trainer/Q2 Predictions Max       -22.349
trainer/Q2 Predictions Min      -106.128
trainer/Q Targets Mean           -43.4508
trainer/Q Targets Std             19.1704
trainer/Q Targets Max            -22.2588
trainer/Q Targets Min           -105.578
trainer/Log Pis Mean               1.832
trainer/Log Pis Std                1.87914
trainer/Log Pis Max                7.85359
trainer/Log Pis Min               -3.20541
trainer/Policy mu Mean             0.11334
trainer/Policy mu Std              1.07377
trainer/Policy mu Max              3.37804
trainer/Policy mu Min             -2.80875
trainer/Policy log std Mean       -1.48726
trainer/Policy log std Std         0.43005
trainer/Policy log std Max        -0.493936
trainer/Policy log std Min        -2.04016
trainer/Alpha                      0.0976686
trainer/Alpha Loss                -0.390773
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.576946
exploration/Rewards Std            0.716933
exploration/Rewards Max           -0.0335363
exploration/Rewards Min           -7.14348
exploration/Returns Mean         -57.6946
exploration/Returns Std           33.1975
exploration/Returns Max          -27.949
exploration/Returns Min         -106.146
exploration/Actions Mean          -0.00895316
exploration/Actions Std            0.287683
exploration/Actions Max            0.99324
exploration/Actions Min           -0.995737
exploration/Num Paths              5
exploration/Average Returns      -57.6946
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.543999
evaluation/Rewards Std             1.26189
evaluation/Rewards Max            -0.0620044
evaluation/Rewards Min           -12.2502
evaluation/Returns Mean          -54.3999
evaluation/Returns Std            26.1733
evaluation/Returns Max           -16.2638
evaluation/Returns Min          -108.476
evaluation/Actions Mean            0.00968782
evaluation/Actions Std             0.211638
evaluation/Actions Max             0.998696
evaluation/Actions Min            -0.989738
evaluation/Num Paths              15
evaluation/Average Returns       -54.3999
time/data storing (s)              0.0032404
time/evaluation sampling (s)       0.375251
time/exploration sampling (s)      0.167134
time/logging (s)                   0.00527182
time/saving (s)                    0.00218931
time/training (s)                  2.23908
time/epoch (s)                     2.79217
time/total (s)                    54.9859
Epoch                             19
-----------------------------  --------------
2019-04-22 21:38:58.434953 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                   0.514887
trainer/QF2 Loss                   0.556145
trainer/Policy Loss               40.9084
trainer/Q1 Predictions Mean      -40.5649
trainer/Q1 Predictions Std        16.7016
trainer/Q1 Predictions Max       -21.4996
trainer/Q1 Predictions Min      -102.727
trainer/Q2 Predictions Mean      -40.5383
trainer/Q2 Predictions Std        16.6785
trainer/Q2 Predictions Max       -21.4719
trainer/Q2 Predictions Min      -102.9
trainer/Q Targets Mean           -41.0598
trainer/Q Targets Std             16.9129
trainer/Q Targets Max            -21.6892
trainer/Q Targets Min           -104.976
trainer/Log Pis Mean               1.3956
trainer/Log Pis Std                1.72115
trainer/Log Pis Max                6.89949
trainer/Log Pis Min               -3.66467
trainer/Policy mu Mean             0.0872598
trainer/Policy mu Std              0.93313
trainer/Policy mu Max              2.9561
trainer/Policy mu Min             -2.82887
trainer/Policy log std Mean       -1.52883
trainer/Policy log std Std         0.402961
trainer/Policy log std Max        -0.41216
trainer/Policy log std Min        -2.11713
trainer/Alpha                      0.0898313
trainer/Alpha Loss                -1.45637
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.503438
exploration/Rewards Std            0.921526
exploration/Rewards Max           -0.00509962
exploration/Rewards Min           -7.50822
exploration/Returns Mean         -50.3438
exploration/Returns Std           23.8149
exploration/Returns Max          -20.1107
exploration/Returns Min          -89.5673
exploration/Actions Mean          -0.00139138
exploration/Actions Std            0.273641
exploration/Actions Max            0.99904
exploration/Actions Min           -0.998922
exploration/Num Paths              5
exploration/Average Returns      -50.3438
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.56495
evaluation/Rewards Std             0.912151
evaluation/Rewards Max            -0.0811608
evaluation/Rewards Min           -11.1799
evaluation/Returns Mean          -56.495
evaluation/Returns Std            25.7668
evaluation/Returns Max           -20.1483
evaluation/Returns Min           -92.6319
evaluation/Actions Mean           -0.00758433
evaluation/Actions Std             0.187514
evaluation/Actions Max             0.998015
evaluation/Actions Min            -0.990437
evaluation/Num Paths              15
evaluation/Average Returns       -56.495
time/data storing (s)              0.00302915
time/evaluation sampling (s)       0.357652
time/exploration sampling (s)      0.158775
time/logging (s)                   0.00530162
time/saving (s)                    0.00216193
time/training (s)                  2.15785
time/epoch (s)                     2.68477
time/total (s)                    57.6753
Epoch                             20
-----------------------------  --------------
2019-04-22 21:39:01.175937 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                  29.9315
trainer/QF2 Loss                  29.9139
trainer/Policy Loss               39.9326
trainer/Q1 Predictions Mean      -39.6403
trainer/Q1 Predictions Std        17.4185
trainer/Q1 Predictions Max       -21.272
trainer/Q1 Predictions Min      -105.33
trainer/Q2 Predictions Mean      -39.6303
trainer/Q2 Predictions Std        17.3524
trainer/Q2 Predictions Max       -21.3152
trainer/Q2 Predictions Min      -105.582
trainer/Q Targets Mean           -39.2864
trainer/Q Targets Std             17.5733
trainer/Q Targets Max             -0.745792
trainer/Q Targets Min           -103.487
trainer/Log Pis Mean               1.65807
trainer/Log Pis Std                1.7161
trainer/Log Pis Max                6.41242
trainer/Log Pis Min               -3.14272
trainer/Policy mu Mean             0.109009
trainer/Policy mu Std              1.04982
trainer/Policy mu Max              3.1125
trainer/Policy mu Min             -2.98189
trainer/Policy log std Mean       -1.60526
trainer/Policy log std Std         0.461242
trainer/Policy log std Max        -0.439669
trainer/Policy log std Min        -2.29083
trainer/Alpha                      0.0845924
trainer/Alpha Loss                -0.844483
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.528988
exploration/Rewards Std            0.676105
exploration/Rewards Max           -0.0254437
exploration/Rewards Min           -8.18138
exploration/Returns Mean         -52.8988
exploration/Returns Std           17.545
exploration/Returns Max          -28.3719
exploration/Returns Min          -72.2831
exploration/Actions Mean           0.0201278
exploration/Actions Std            0.263028
exploration/Actions Max            0.995996
exploration/Actions Min           -0.965182
exploration/Num Paths              5
exploration/Average Returns      -52.8988
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.507454
evaluation/Rewards Std             0.889465
evaluation/Rewards Max            -0.0712719
evaluation/Rewards Min           -11.3733
evaluation/Returns Mean          -50.7454
evaluation/Returns Std            19.3941
evaluation/Returns Max           -21.7877
evaluation/Returns Min           -75.6484
evaluation/Actions Mean            0.00580162
evaluation/Actions Std             0.175129
evaluation/Actions Max             0.998565
evaluation/Actions Min            -0.989752
evaluation/Num Paths              15
evaluation/Average Returns       -50.7454
time/data storing (s)              0.00309529
time/evaluation sampling (s)       0.363803
time/exploration sampling (s)      0.166782
time/logging (s)                   0.00520165
time/saving (s)                    0.00219916
time/training (s)                  2.19408
time/epoch (s)                     2.73516
time/total (s)                    60.4151
Epoch                             21
-----------------------------  --------------
2019-04-22 21:39:03.867880 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                   0.678053
trainer/QF2 Loss                   0.517859
trainer/Policy Loss               43.2869
trainer/Q1 Predictions Mean      -42.543
trainer/Q1 Predictions Std        18.1574
trainer/Q1 Predictions Max       -20.5439
trainer/Q1 Predictions Min      -108.654
trainer/Q2 Predictions Mean      -42.5864
trainer/Q2 Predictions Std        18.1698
trainer/Q2 Predictions Max       -20.6646
trainer/Q2 Predictions Min      -109.019
trainer/Q Targets Mean           -42.955
trainer/Q Targets Std             18.2333
trainer/Q Targets Max            -20.7045
trainer/Q Targets Min           -108.962
trainer/Log Pis Mean               2.20662
trainer/Log Pis Std                1.64687
trainer/Log Pis Max                7.45687
trainer/Log Pis Min               -1.64481
trainer/Policy mu Mean            -0.0860812
trainer/Policy mu Std              1.14705
trainer/Policy mu Max              2.98231
trainer/Policy mu Min             -2.96163
trainer/Policy log std Mean       -1.5622
trainer/Policy log std Std         0.505272
trainer/Policy log std Max        -0.469075
trainer/Policy log std Min        -2.29971
trainer/Alpha                      0.0792433
trainer/Alpha Loss                 0.523804
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.73926
exploration/Rewards Std            1.25614
exploration/Rewards Max           -0.00680927
exploration/Rewards Min          -10.089
exploration/Returns Mean         -73.926
exploration/Returns Std           20.807
exploration/Returns Max          -43.804
exploration/Returns Min         -105.09
exploration/Actions Mean           0.0104319
exploration/Actions Std            0.287064
exploration/Actions Max            0.999652
exploration/Actions Min           -0.998807
exploration/Num Paths              5
exploration/Average Returns      -73.926
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.651218
evaluation/Rewards Std             1.14606
evaluation/Rewards Max            -0.118495
evaluation/Rewards Min            -9.81618
evaluation/Returns Mean          -65.1218
evaluation/Returns Std            28.3493
evaluation/Returns Max           -28.8095
evaluation/Returns Min          -110.899
evaluation/Actions Mean           -0.00106248
evaluation/Actions Std             0.210242
evaluation/Actions Max             0.997526
evaluation/Actions Min            -0.993205
evaluation/Num Paths              15
evaluation/Average Returns       -65.1218
time/data storing (s)              0.00310507
time/evaluation sampling (s)       0.359938
time/exploration sampling (s)      0.15784
time/logging (s)                   0.00493025
time/saving (s)                    0.00218842
time/training (s)                  2.1591
time/epoch (s)                     2.6871
time/total (s)                    63.1059
Epoch                             22
-----------------------------  --------------
2019-04-22 21:39:06.597148 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   0.404895
trainer/QF2 Loss                   0.310088
trainer/Policy Loss               39.5713
trainer/Q1 Predictions Mean      -38.7786
trainer/Q1 Predictions Std        17.189
trainer/Q1 Predictions Max       -20.2936
trainer/Q1 Predictions Min       -95.8825
trainer/Q2 Predictions Mean      -38.7854
trainer/Q2 Predictions Std        17.1969
trainer/Q2 Predictions Max       -20.3036
trainer/Q2 Predictions Min       -95.8463
trainer/Q Targets Mean           -39.0136
trainer/Q Targets Std             17.2953
trainer/Q Targets Max            -20.3339
trainer/Q Targets Min            -97.3838
trainer/Log Pis Mean               1.777
trainer/Log Pis Std                1.67726
trainer/Log Pis Max                9.42421
trainer/Log Pis Min               -4.77008
trainer/Policy mu Mean             0.0451104
trainer/Policy mu Std              0.953093
trainer/Policy mu Max              3.0205
trainer/Policy mu Min             -3.00626
trainer/Policy log std Mean       -1.65034
trainer/Policy log std Std         0.433119
trainer/Policy log std Max        -0.442533
trainer/Policy log std Min        -2.30617
trainer/Alpha                      0.0756884
trainer/Alpha Loss                -0.575579
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.568973
exploration/Rewards Std            0.827861
exploration/Rewards Max           -0.00677009
exploration/Rewards Min           -7.42506
exploration/Returns Mean         -56.8973
exploration/Returns Std           33.0124
exploration/Returns Max          -19.7645
exploration/Returns Min         -101.046
exploration/Actions Mean          -0.0130677
exploration/Actions Std            0.263365
exploration/Actions Max            0.992965
exploration/Actions Min           -0.998391
exploration/Num Paths              5
exploration/Average Returns      -56.8973
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.61658
evaluation/Rewards Std             1.17926
evaluation/Rewards Max            -0.120751
evaluation/Rewards Min           -10.1141
evaluation/Returns Mean          -61.658
evaluation/Returns Std            30.466
evaluation/Returns Max           -20.7277
evaluation/Returns Min          -118.693
evaluation/Actions Mean           -0.00675331
evaluation/Actions Std             0.205569
evaluation/Actions Max             0.997523
evaluation/Actions Min            -0.996402
evaluation/Num Paths              15
evaluation/Average Returns       -61.658
time/data storing (s)              0.003157
time/evaluation sampling (s)       0.362647
time/exploration sampling (s)      0.161236
time/logging (s)                   0.005173
time/saving (s)                    0.00193392
time/training (s)                  2.18967
time/epoch (s)                     2.72381
time/total (s)                    65.8344
Epoch                             23
-----------------------------  --------------
2019-04-22 21:39:09.261026 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size             12700
trainer/QF1 Loss                   0.660269
trainer/QF2 Loss                   0.626464
trainer/Policy Loss               39.1063
trainer/Q1 Predictions Mean      -38.2192
trainer/Q1 Predictions Std        17.3628
trainer/Q1 Predictions Max       -19.5376
trainer/Q1 Predictions Min      -103.395
trainer/Q2 Predictions Mean      -38.2295
trainer/Q2 Predictions Std        17.3756
trainer/Q2 Predictions Max       -19.7216
trainer/Q2 Predictions Min      -104.063
trainer/Q Targets Mean           -38.7007
trainer/Q Targets Std             17.5629
trainer/Q Targets Max            -19.8103
trainer/Q Targets Min           -103.483
trainer/Log Pis Mean               1.90634
trainer/Log Pis Std                1.4379
trainer/Log Pis Max                6.17732
trainer/Log Pis Min               -4.14907
trainer/Policy mu Mean            -0.0473633
trainer/Policy mu Std              0.902878
trainer/Policy mu Max              3.255
trainer/Policy mu Min             -3.05517
trainer/Policy log std Mean       -1.77017
trainer/Policy log std Std         0.411775
trainer/Policy log std Max        -0.548665
trainer/Policy log std Min        -2.38654
trainer/Alpha                      0.0736017
trainer/Alpha Loss                -0.244378
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.391949
exploration/Rewards Std            0.643996
exploration/Rewards Max           -0.00570448
exploration/Rewards Min           -6.80892
exploration/Returns Mean         -39.1949
exploration/Returns Std           16.5819
exploration/Returns Max          -15.4256
exploration/Returns Min          -62.7929
exploration/Actions Mean           0.0175045
exploration/Actions Std            0.225991
exploration/Actions Max            0.997772
exploration/Actions Min           -0.972761
exploration/Num Paths              5
exploration/Average Returns      -39.1949
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.46065
evaluation/Rewards Std             0.960764
evaluation/Rewards Max            -0.0132012
evaluation/Rewards Min            -9.76818
evaluation/Returns Mean          -46.065
evaluation/Returns Std            18.4996
evaluation/Returns Max           -21.828
evaluation/Returns Min           -84.9339
evaluation/Actions Mean            0.00190274
evaluation/Actions Std             0.189306
evaluation/Actions Max             0.998284
evaluation/Actions Min            -0.99717
evaluation/Num Paths              15
evaluation/Average Returns       -46.065
time/data storing (s)              0.00309047
time/evaluation sampling (s)       0.357561
time/exploration sampling (s)      0.158753
time/logging (s)                   0.00448769
time/saving (s)                    0.00210516
time/training (s)                  2.13093
time/epoch (s)                     2.65693
time/total (s)                    68.4962
Epoch                             24
-----------------------------  --------------
2019-04-22 21:39:12.063688 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                  94.3727
trainer/QF2 Loss                  94.8125
trainer/Policy Loss               36.9872
trainer/Q1 Predictions Mean      -36.1679
trainer/Q1 Predictions Std        15.9846
trainer/Q1 Predictions Max       -19.2145
trainer/Q1 Predictions Min       -91.717
trainer/Q2 Predictions Mean      -36.1874
trainer/Q2 Predictions Std        15.9885
trainer/Q2 Predictions Max       -19.3352
trainer/Q2 Predictions Min       -92.084
trainer/Q Targets Mean           -35.2335
trainer/Q Targets Std             16.1297
trainer/Q Targets Max             -0.149485
trainer/Q Targets Min            -95.4194
trainer/Log Pis Mean               1.97676
trainer/Log Pis Std                1.79244
trainer/Log Pis Max                7.09619
trainer/Log Pis Min               -3.1403
trainer/Policy mu Mean            -0.192013
trainer/Policy mu Std              0.98519
trainer/Policy mu Max              2.66248
trainer/Policy mu Min             -3.23331
trainer/Policy log std Mean       -1.76052
trainer/Policy log std Std         0.479383
trainer/Policy log std Max        -0.517536
trainer/Policy log std Min        -2.58222
trainer/Alpha                      0.0714797
trainer/Alpha Loss                -0.0613215
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.591584
exploration/Rewards Std            1.01992
exploration/Rewards Max           -0.0238197
exploration/Rewards Min           -9.12861
exploration/Returns Mean         -59.1584
exploration/Returns Std           14.7109
exploration/Returns Max          -30.8393
exploration/Returns Min          -73.8974
exploration/Actions Mean          -0.0216039
exploration/Actions Std            0.255389
exploration/Actions Max            0.999019
exploration/Actions Min           -0.997754
exploration/Num Paths              5
exploration/Average Returns      -59.1584
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.447918
evaluation/Rewards Std             1.03243
evaluation/Rewards Max            -0.0794555
evaluation/Rewards Min           -10.2641
evaluation/Returns Mean          -44.7918
evaluation/Returns Std            24.5639
evaluation/Returns Max           -13.2361
evaluation/Returns Min           -91.4638
evaluation/Actions Mean            0.00316591
evaluation/Actions Std             0.183832
evaluation/Actions Max             0.997864
evaluation/Actions Min            -0.997915
evaluation/Num Paths              15
evaluation/Average Returns       -44.7918
time/data storing (s)              0.00320958
time/evaluation sampling (s)       0.362913
time/exploration sampling (s)      0.159577
time/logging (s)                   0.00545078
time/saving (s)                    0.0106521
time/training (s)                  2.25605
time/epoch (s)                     2.79785
time/total (s)                    71.2989
Epoch                             25
-----------------------------  --------------
2019-04-22 21:39:14.720356 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                   0.761916
trainer/QF2 Loss                   0.772821
trainer/Policy Loss               35.7111
trainer/Q1 Predictions Mean      -34.9609
trainer/Q1 Predictions Std        16.1464
trainer/Q1 Predictions Max       -18.9463
trainer/Q1 Predictions Min      -105.663
trainer/Q2 Predictions Mean      -34.9638
trainer/Q2 Predictions Std        16.1385
trainer/Q2 Predictions Max       -18.9997
trainer/Q2 Predictions Min      -105.848
trainer/Q Targets Mean           -35.5208
trainer/Q Targets Std             16.4626
trainer/Q Targets Max            -19.324
trainer/Q Targets Min           -104.975
trainer/Log Pis Mean               1.76076
trainer/Log Pis Std                1.4468
trainer/Log Pis Max                7.47981
trainer/Log Pis Min               -2.36753
trainer/Policy mu Mean            -0.027111
trainer/Policy mu Std              0.836804
trainer/Policy mu Max              2.9091
trainer/Policy mu Min             -3.06984
trainer/Policy log std Mean       -1.86202
trainer/Policy log std Std         0.470246
trainer/Policy log std Max        -0.407725
trainer/Policy log std Min        -2.59658
trainer/Alpha                      0.0718951
trainer/Alpha Loss                -0.629799
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.415285
exploration/Rewards Std            0.597942
exploration/Rewards Max           -0.0144468
exploration/Rewards Min           -6.9499
exploration/Returns Mean         -41.5285
exploration/Returns Std           18.5414
exploration/Returns Max          -18.3792
exploration/Returns Min          -67.5634
exploration/Actions Mean           0.00681275
exploration/Actions Std            0.230105
exploration/Actions Max            0.996967
exploration/Actions Min           -0.995218
exploration/Num Paths              5
exploration/Average Returns      -41.5285
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.368225
evaluation/Rewards Std             0.897107
evaluation/Rewards Max            -0.00272089
evaluation/Rewards Min            -9.35982
evaluation/Returns Mean          -36.8225
evaluation/Returns Std            21.204
evaluation/Returns Max            -5.3206
evaluation/Returns Min           -80.7015
evaluation/Actions Mean            0.00848984
evaluation/Actions Std             0.184747
evaluation/Actions Max             0.998398
evaluation/Actions Min            -0.993386
evaluation/Num Paths              15
evaluation/Average Returns       -36.8225
time/data storing (s)              0.00404286
time/evaluation sampling (s)       0.366265
time/exploration sampling (s)      0.163463
time/logging (s)                   0.00512551
time/saving (s)                    0.0021848
time/training (s)                  2.10936
time/epoch (s)                     2.65044
time/total (s)                    73.9542
Epoch                             26
-----------------------------  --------------
2019-04-22 21:39:17.395971 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   1.49137
trainer/QF2 Loss                   1.41009
trainer/Policy Loss               37.6328
trainer/Q1 Predictions Mean      -36.6225
trainer/Q1 Predictions Std        15.7078
trainer/Q1 Predictions Max       -18.8387
trainer/Q1 Predictions Min       -92.7045
trainer/Q2 Predictions Mean      -36.6134
trainer/Q2 Predictions Std        15.71
trainer/Q2 Predictions Max       -18.9798
trainer/Q2 Predictions Min       -93.0977
trainer/Q Targets Mean           -37.4225
trainer/Q Targets Std             16.3078
trainer/Q Targets Max            -18.9312
trainer/Q Targets Min            -96.5311
trainer/Log Pis Mean               2.0392
trainer/Log Pis Std                1.52289
trainer/Log Pis Max                6.96667
trainer/Log Pis Min               -1.27228
trainer/Policy mu Mean            -0.0749219
trainer/Policy mu Std              1.03065
trainer/Policy mu Max              3.23779
trainer/Policy mu Min             -3.12381
trainer/Policy log std Mean       -1.75956
trainer/Policy log std Std         0.531369
trainer/Policy log std Max        -0.368825
trainer/Policy log std Min        -2.56535
trainer/Alpha                      0.0729852
trainer/Alpha Loss                 0.102616
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.481938
exploration/Rewards Std            0.95765
exploration/Rewards Max           -0.0084842
exploration/Rewards Min           -8.12277
exploration/Returns Mean         -48.1938
exploration/Returns Std           19.2041
exploration/Returns Max          -19.4551
exploration/Returns Min          -79.856
exploration/Actions Mean          -0.00592165
exploration/Actions Std            0.226928
exploration/Actions Max            0.996888
exploration/Actions Min           -0.998515
exploration/Num Paths              5
exploration/Average Returns      -48.1938
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.40875
evaluation/Rewards Std             1.09009
evaluation/Rewards Max            -0.0180685
evaluation/Rewards Min           -10.7701
evaluation/Returns Mean          -40.875
evaluation/Returns Std            22.1096
evaluation/Returns Max           -13.0671
evaluation/Returns Min           -91.059
evaluation/Actions Mean            0.0092504
evaluation/Actions Std             0.1955
evaluation/Actions Max             0.999093
evaluation/Actions Min            -0.995332
evaluation/Num Paths              15
evaluation/Average Returns       -40.875
time/data storing (s)              0.00295677
time/evaluation sampling (s)       0.371774
time/exploration sampling (s)      0.165456
time/logging (s)                   0.00494867
time/saving (s)                    0.00206952
time/training (s)                  2.12229
time/epoch (s)                     2.66949
time/total (s)                    76.6286
Epoch                             27
-----------------------------  --------------
2019-04-22 21:39:20.174381 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             14700
trainer/QF1 Loss                  26.2076
trainer/QF2 Loss                  26.3051
trainer/Policy Loss               35.1439
trainer/Q1 Predictions Mean      -34.0431
trainer/Q1 Predictions Std        15.4093
trainer/Q1 Predictions Max       -18.4226
trainer/Q1 Predictions Min      -103.1
trainer/Q2 Predictions Mean      -34.0125
trainer/Q2 Predictions Std        15.4604
trainer/Q2 Predictions Max       -18.4351
trainer/Q2 Predictions Min      -103.428
trainer/Q Targets Mean           -33.5203
trainer/Q Targets Std             15.9614
trainer/Q Targets Max             -0.482087
trainer/Q Targets Min           -100.401
trainer/Log Pis Mean               2.3419
trainer/Log Pis Std                1.62146
trainer/Log Pis Max                9.43947
trainer/Log Pis Min               -0.29512
trainer/Policy mu Mean            -0.0126472
trainer/Policy mu Std              1.06706
trainer/Policy mu Max              3.47144
trainer/Policy mu Min             -3.14985
trainer/Policy log std Mean       -1.7629
trainer/Policy log std Std         0.556147
trainer/Policy log std Max        -0.391299
trainer/Policy log std Min        -2.65472
trainer/Alpha                      0.0738617
trainer/Alpha Loss                 0.890856
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.333382
exploration/Rewards Std            0.713529
exploration/Rewards Max           -0.0098118
exploration/Rewards Min           -7.07696
exploration/Returns Mean         -33.3382
exploration/Returns Std           10.3051
exploration/Returns Max          -18.8875
exploration/Returns Min          -49.295
exploration/Actions Mean          -0.0108486
exploration/Actions Std            0.234252
exploration/Actions Max            0.98429
exploration/Actions Min           -0.997037
exploration/Num Paths              5
exploration/Average Returns      -33.3382
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.37899
evaluation/Rewards Std             1.15819
evaluation/Rewards Max            -0.0743111
evaluation/Rewards Min           -10.5669
evaluation/Returns Mean          -37.899
evaluation/Returns Std            14.6198
evaluation/Returns Max           -12.803
evaluation/Returns Min           -68.1821
evaluation/Actions Mean            0.0214556
evaluation/Actions Std             0.202121
evaluation/Actions Max             0.998148
evaluation/Actions Min            -0.997768
evaluation/Num Paths              15
evaluation/Average Returns       -37.899
time/data storing (s)              0.00338692
time/evaluation sampling (s)       0.41083
time/exploration sampling (s)      0.164348
time/logging (s)                   0.00448065
time/saving (s)                    0.00207089
time/training (s)                  2.18701
time/epoch (s)                     2.77213
time/total (s)                    79.4053
Epoch                             28
-----------------------------  --------------
2019-04-22 21:39:22.957616 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   0.387665
trainer/QF2 Loss                   0.408334
trainer/Policy Loss               36.1486
trainer/Q1 Predictions Mean      -35.179
trainer/Q1 Predictions Std        16.6826
trainer/Q1 Predictions Max       -17.9988
trainer/Q1 Predictions Min      -101.964
trainer/Q2 Predictions Mean      -35.1655
trainer/Q2 Predictions Std        16.6753
trainer/Q2 Predictions Max       -18.0566
trainer/Q2 Predictions Min      -102.168
trainer/Q Targets Mean           -35.3982
trainer/Q Targets Std             16.6239
trainer/Q Targets Max            -18.2973
trainer/Q Targets Min           -101.59
trainer/Log Pis Mean               2.23405
trainer/Log Pis Std                1.4783
trainer/Log Pis Max                7.43033
trainer/Log Pis Min               -0.395606
trainer/Policy mu Mean            -0.0627556
trainer/Policy mu Std              1.06712
trainer/Policy mu Max              3.29691
trainer/Policy mu Min             -3.14013
trainer/Policy log std Mean       -1.714
trainer/Policy log std Std         0.561852
trainer/Policy log std Max        -0.307259
trainer/Policy log std Min        -2.54472
trainer/Alpha                      0.0736876
trainer/Alpha Loss                 0.61042
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.303724
exploration/Rewards Std            0.824701
exploration/Rewards Max           -0.00574674
exploration/Rewards Min           -9.38442
exploration/Returns Mean         -30.3724
exploration/Returns Std           15.8557
exploration/Returns Max          -16.2902
exploration/Returns Min          -59.5973
exploration/Actions Mean           0.00892345
exploration/Actions Std            0.21688
exploration/Actions Max            0.998641
exploration/Actions Min           -0.998373
exploration/Num Paths              5
exploration/Average Returns      -30.3724
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.353107
evaluation/Rewards Std             0.792492
evaluation/Rewards Max            -0.0799
evaluation/Rewards Min            -8.93965
evaluation/Returns Mean          -35.3107
evaluation/Returns Std            19.1677
evaluation/Returns Max           -11.0316
evaluation/Returns Min           -78.8448
evaluation/Actions Mean            0.00123766
evaluation/Actions Std             0.164053
evaluation/Actions Max             0.995285
evaluation/Actions Min            -0.995674
evaluation/Num Paths              15
evaluation/Average Returns       -35.3107
time/data storing (s)              0.00385334
time/evaluation sampling (s)       0.37271
time/exploration sampling (s)      0.213797
time/logging (s)                   0.00498196
time/saving (s)                    0.00198918
time/training (s)                  2.18017
time/epoch (s)                     2.77751
time/total (s)                    82.1878
Epoch                             29
-----------------------------  --------------
2019-04-22 21:39:25.688480 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                  47.989
trainer/QF2 Loss                  47.9928
trainer/Policy Loss               33.9451
trainer/Q1 Predictions Mean      -32.9862
trainer/Q1 Predictions Std        14.1279
trainer/Q1 Predictions Max       -17.8827
trainer/Q1 Predictions Min       -75.4674
trainer/Q2 Predictions Mean      -32.9661
trainer/Q2 Predictions Std        14.0923
trainer/Q2 Predictions Max       -17.9427
trainer/Q2 Predictions Min       -74.6564
trainer/Q Targets Mean           -32.2048
trainer/Q Targets Std             15.0378
trainer/Q Targets Max             -0.0905414
trainer/Q Targets Min            -75.0632
trainer/Log Pis Mean               1.82056
trainer/Log Pis Std                1.9795
trainer/Log Pis Max                8.87119
trainer/Log Pis Min               -6.627
trainer/Policy mu Mean            -0.0877163
trainer/Policy mu Std              0.924219
trainer/Policy mu Max              3.28313
trainer/Policy mu Min             -3.1991
trainer/Policy log std Mean       -1.83527
trainer/Policy log std Std         0.515984
trainer/Policy log std Max        -0.332387
trainer/Policy log std Min        -2.5912
trainer/Alpha                      0.0743319
trainer/Alpha Loss                -0.466386
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.502631
exploration/Rewards Std            1.13289
exploration/Rewards Max           -0.00971029
exploration/Rewards Min           -9.7078
exploration/Returns Mean         -50.2631
exploration/Returns Std           16.0891
exploration/Returns Max          -32.6511
exploration/Returns Min          -74.2111
exploration/Actions Mean          -0.00794133
exploration/Actions Std            0.248128
exploration/Actions Max            0.999602
exploration/Actions Min           -0.998992
exploration/Num Paths              5
exploration/Average Returns      -50.2631
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.328244
evaluation/Rewards Std             0.75927
evaluation/Rewards Max            -0.0724605
evaluation/Rewards Min            -9.19749
evaluation/Returns Mean          -32.8244
evaluation/Returns Std            12.5953
evaluation/Returns Max           -17.1487
evaluation/Returns Min           -60.1441
evaluation/Actions Mean            0.0145289
evaluation/Actions Std             0.16815
evaluation/Actions Max             0.995888
evaluation/Actions Min            -0.995948
evaluation/Num Paths              15
evaluation/Average Returns       -32.8244
time/data storing (s)              0.00431233
time/evaluation sampling (s)       0.369931
time/exploration sampling (s)      0.169887
time/logging (s)                   0.00490327
time/saving (s)                    0.00216685
time/training (s)                  2.17365
time/epoch (s)                     2.72485
time/total (s)                    84.9175
Epoch                             30
-----------------------------  --------------
2019-04-22 21:39:28.426663 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                  26.1599
trainer/QF2 Loss                  25.6942
trainer/Policy Loss               32.0206
trainer/Q1 Predictions Mean      -30.9214
trainer/Q1 Predictions Std        13.8948
trainer/Q1 Predictions Max       -17.3956
trainer/Q1 Predictions Min       -84.5786
trainer/Q2 Predictions Mean      -30.9184
trainer/Q2 Predictions Std        13.8798
trainer/Q2 Predictions Max       -17.4398
trainer/Q2 Predictions Min       -84.6914
trainer/Q Targets Mean           -30.5204
trainer/Q Targets Std             14.5803
trainer/Q Targets Max             -0.451118
trainer/Q Targets Min            -86.8307
trainer/Log Pis Mean               1.91622
trainer/Log Pis Std                1.4561
trainer/Log Pis Max                8.24734
trainer/Log Pis Min               -2.13205
trainer/Policy mu Mean            -0.148372
trainer/Policy mu Std              0.898942
trainer/Policy mu Max              2.91259
trainer/Policy mu Min             -3.14225
trainer/Policy log std Mean       -1.84009
trainer/Policy log std Std         0.563577
trainer/Policy log std Max        -0.407063
trainer/Policy log std Min        -2.69593
trainer/Alpha                      0.0769509
trainer/Alpha Loss                -0.214859
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.369206
exploration/Rewards Std            0.532107
exploration/Rewards Max           -0.0235905
exploration/Rewards Min           -6.19866
exploration/Returns Mean         -36.9206
exploration/Returns Std           16.5982
exploration/Returns Max          -18.4022
exploration/Returns Min          -63.2924
exploration/Actions Mean          -0.0116454
exploration/Actions Std            0.220198
exploration/Actions Max            0.991342
exploration/Actions Min           -0.997598
exploration/Num Paths              5
exploration/Average Returns      -36.9206
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.468381
evaluation/Rewards Std             1.14665
evaluation/Rewards Max            -0.0505498
evaluation/Rewards Min           -10.7105
evaluation/Returns Mean          -46.8381
evaluation/Returns Std            22.2838
evaluation/Returns Max            -7.65474
evaluation/Returns Min           -74.7797
evaluation/Actions Mean            0.00511147
evaluation/Actions Std             0.202206
evaluation/Actions Max             0.998346
evaluation/Actions Min            -0.997377
evaluation/Num Paths              15
evaluation/Average Returns       -46.8381
time/data storing (s)              0.00294992
time/evaluation sampling (s)       0.365338
time/exploration sampling (s)      0.165715
time/logging (s)                   0.00526821
time/saving (s)                    0.00227227
time/training (s)                  2.19104
time/epoch (s)                     2.73258
time/total (s)                    87.6548
Epoch                             31
-----------------------------  --------------
2019-04-22 21:39:31.170741 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size             16700
trainer/QF1 Loss                   0.804631
trainer/QF2 Loss                   0.796995
trainer/Policy Loss               33.2292
trainer/Q1 Predictions Mean      -32.2825
trainer/Q1 Predictions Std        15.458
trainer/Q1 Predictions Max       -17.1719
trainer/Q1 Predictions Min       -86.3172
trainer/Q2 Predictions Mean      -32.2487
trainer/Q2 Predictions Std        15.4485
trainer/Q2 Predictions Max       -17.2452
trainer/Q2 Predictions Min       -86.442
trainer/Q Targets Mean           -32.7173
trainer/Q Targets Std             15.8039
trainer/Q Targets Max            -17.2828
trainer/Q Targets Min            -89.5811
trainer/Log Pis Mean               2.0137
trainer/Log Pis Std                1.5934
trainer/Log Pis Max                5.91137
trainer/Log Pis Min               -3.65011
trainer/Policy mu Mean            -0.111176
trainer/Policy mu Std              0.950807
trainer/Policy mu Max              3.59773
trainer/Policy mu Min             -3.24186
trainer/Policy log std Mean       -1.80923
trainer/Policy log std Std         0.566553
trainer/Policy log std Max        -0.405694
trainer/Policy log std Min        -2.65406
trainer/Alpha                      0.0775033
trainer/Alpha Loss                 0.0350364
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.415595
exploration/Rewards Std            0.806438
exploration/Rewards Max           -0.00538241
exploration/Rewards Min           -8.589
exploration/Returns Mean         -41.5595
exploration/Returns Std           27.1535
exploration/Returns Max          -16.0971
exploration/Returns Min          -89.2266
exploration/Actions Mean           0.00684013
exploration/Actions Std            0.215682
exploration/Actions Max            0.998359
exploration/Actions Min           -0.998341
exploration/Num Paths              5
exploration/Average Returns      -41.5595
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.285199
evaluation/Rewards Std             0.842584
evaluation/Rewards Max            -0.0130966
evaluation/Rewards Min            -9.17026
evaluation/Returns Mean          -28.5199
evaluation/Returns Std            21.1147
evaluation/Returns Max            -3.4464
evaluation/Returns Min           -70.8831
evaluation/Actions Mean            0.00750884
evaluation/Actions Std             0.168557
evaluation/Actions Max             0.997399
evaluation/Actions Min            -0.996221
evaluation/Num Paths              15
evaluation/Average Returns       -28.5199
time/data storing (s)              0.0030291
time/evaluation sampling (s)       0.377401
time/exploration sampling (s)      0.164013
time/logging (s)                   0.00569026
time/saving (s)                    0.00174714
time/training (s)                  2.18597
time/epoch (s)                     2.73785
time/total (s)                    90.398
Epoch                             32
-----------------------------  --------------
2019-04-22 21:39:33.874484 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 33 finished
-----------------------------  ---------------
replay_buffer/size             17200
trainer/QF1 Loss                   3.515
trainer/QF2 Loss                   3.44872
trainer/Policy Loss               32.4794
trainer/Q1 Predictions Mean      -31.4822
trainer/Q1 Predictions Std        17.1467
trainer/Q1 Predictions Max       -17.0718
trainer/Q1 Predictions Min       -98.225
trainer/Q2 Predictions Mean      -31.5025
trainer/Q2 Predictions Std        17.1901
trainer/Q2 Predictions Max       -17.0724
trainer/Q2 Predictions Min       -98.4189
trainer/Q Targets Mean           -31.7055
trainer/Q Targets Std             17.7457
trainer/Q Targets Max             -0.132552
trainer/Q Targets Min            -97.4233
trainer/Log Pis Mean               2.05208
trainer/Log Pis Std                1.5107
trainer/Log Pis Max                6.96069
trainer/Log Pis Min               -3.90894
trainer/Policy mu Mean            -0.0880861
trainer/Policy mu Std              0.922663
trainer/Policy mu Max              3.41052
trainer/Policy mu Min             -3.18209
trainer/Policy log std Mean       -1.83699
trainer/Policy log std Std         0.524459
trainer/Policy log std Max        -0.426157
trainer/Policy log std Min        -2.59965
trainer/Alpha                      0.0779714
trainer/Alpha Loss                 0.132879
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.544058
exploration/Rewards Std            1.19939
exploration/Rewards Max           -0.00435124
exploration/Rewards Min           -9.78918
exploration/Returns Mean         -54.4058
exploration/Returns Std           20.0844
exploration/Returns Max          -21.8696
exploration/Returns Min          -82.5695
exploration/Actions Mean          -0.000659649
exploration/Actions Std            0.247511
exploration/Actions Max            0.999237
exploration/Actions Min           -0.999781
exploration/Num Paths              5
exploration/Average Returns      -54.4058
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.462181
evaluation/Rewards Std             1.17055
evaluation/Rewards Max            -0.0758244
evaluation/Rewards Min           -11.6034
evaluation/Returns Mean          -46.2181
evaluation/Returns Std            23.9892
evaluation/Returns Max            -9.56764
evaluation/Returns Min           -89.7021
evaluation/Actions Mean            0.00232454
evaluation/Actions Std             0.204208
evaluation/Actions Max             0.999064
evaluation/Actions Min            -0.996018
evaluation/Num Paths              15
evaluation/Average Returns       -46.2181
time/data storing (s)              0.00313529
time/evaluation sampling (s)       0.365041
time/exploration sampling (s)      0.163746
time/logging (s)                   0.00538176
time/saving (s)                    0.0016763
time/training (s)                  2.15797
time/epoch (s)                     2.69695
time/total (s)                    93.1
Epoch                             33
-----------------------------  ---------------
2019-04-22 21:39:36.579125 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                   8.69418
trainer/QF2 Loss                   8.63965
trainer/Policy Loss               32.5048
trainer/Q1 Predictions Mean      -31.539
trainer/Q1 Predictions Std        15.8482
trainer/Q1 Predictions Max       -16.5506
trainer/Q1 Predictions Min       -98.0166
trainer/Q2 Predictions Mean      -31.5268
trainer/Q2 Predictions Std        15.8321
trainer/Q2 Predictions Max       -16.5753
trainer/Q2 Predictions Min       -98.4707
trainer/Q Targets Mean           -31.4599
trainer/Q Targets Std             16.5673
trainer/Q Targets Max             -0.317484
trainer/Q Targets Min            -96.7848
trainer/Log Pis Mean               2.14744
trainer/Log Pis Std                1.49671
trainer/Log Pis Max                7.46261
trainer/Log Pis Min               -1.75426
trainer/Policy mu Mean            -0.00581818
trainer/Policy mu Std              0.984077
trainer/Policy mu Max              3.30089
trainer/Policy mu Min             -3.07857
trainer/Policy log std Mean       -1.78489
trainer/Policy log std Std         0.566638
trainer/Policy log std Max        -0.420313
trainer/Policy log std Min        -2.60287
trainer/Alpha                      0.0783711
trainer/Alpha Loss                 0.375422
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.503833
exploration/Rewards Std            1.18162
exploration/Rewards Max           -0.0122772
exploration/Rewards Min           -8.97207
exploration/Returns Mean         -50.3833
exploration/Returns Std           17.1478
exploration/Returns Max          -28.6817
exploration/Returns Min          -79.1633
exploration/Actions Mean          -0.00693198
exploration/Actions Std            0.269011
exploration/Actions Max            0.998993
exploration/Actions Min           -0.998418
exploration/Num Paths              5
exploration/Average Returns      -50.3833
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.395195
evaluation/Rewards Std             1.03259
evaluation/Rewards Max            -0.0619773
evaluation/Rewards Min           -11.5255
evaluation/Returns Mean          -39.5195
evaluation/Returns Std            25.8599
evaluation/Returns Max            -8.34869
evaluation/Returns Min           -85.4237
evaluation/Actions Mean           -0.0129871
evaluation/Actions Std             0.190986
evaluation/Actions Max             0.998732
evaluation/Actions Min            -0.996298
evaluation/Num Paths              15
evaluation/Average Returns       -39.5195
time/data storing (s)              0.00302899
time/evaluation sampling (s)       0.363427
time/exploration sampling (s)      0.159887
time/logging (s)                   0.00478017
time/saving (s)                    0.00178769
time/training (s)                  2.16565
time/epoch (s)                     2.69856
time/total (s)                    95.8028
Epoch                             34
-----------------------------  --------------
2019-04-22 21:39:39.244808 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   5.5827
trainer/QF2 Loss                   5.51263
trainer/Policy Loss               29.8283
trainer/Q1 Predictions Mean      -28.9539
trainer/Q1 Predictions Std        13.5958
trainer/Q1 Predictions Max       -16.344
trainer/Q1 Predictions Min       -74.4129
trainer/Q2 Predictions Mean      -28.9572
trainer/Q2 Predictions Std        13.6592
trainer/Q2 Predictions Max       -16.3515
trainer/Q2 Predictions Min       -74.5782
trainer/Q Targets Mean           -28.8865
trainer/Q Targets Std             14.0868
trainer/Q Targets Max             -0.195339
trainer/Q Targets Min            -75.3174
trainer/Log Pis Mean               2.15563
trainer/Log Pis Std                1.727
trainer/Log Pis Max                7.12266
trainer/Log Pis Min               -4.65834
trainer/Policy mu Mean             0.152675
trainer/Policy mu Std              1.07282
trainer/Policy mu Max              3.03292
trainer/Policy mu Min             -2.78028
trainer/Policy log std Mean       -1.75633
trainer/Policy log std Std         0.640943
trainer/Policy log std Max        -0.405077
trainer/Policy log std Min        -2.69899
trainer/Alpha                      0.076823
trainer/Alpha Loss                 0.39939
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.422793
exploration/Rewards Std            0.700669
exploration/Rewards Max           -0.00470826
exploration/Rewards Min           -6.55202
exploration/Returns Mean         -42.2793
exploration/Returns Std           22.0701
exploration/Returns Max          -15.7064
exploration/Returns Min          -70.6805
exploration/Actions Mean          -0.0171219
exploration/Actions Std            0.223421
exploration/Actions Max            0.997275
exploration/Actions Min           -0.992966
exploration/Num Paths              5
exploration/Average Returns      -42.2793
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.274219
evaluation/Rewards Std             0.944264
evaluation/Rewards Max            -0.0366545
evaluation/Rewards Min           -10.062
evaluation/Returns Mean          -27.4219
evaluation/Returns Std            19.3152
evaluation/Returns Max            -5.34826
evaluation/Returns Min           -67.4189
evaluation/Actions Mean            0.00621335
evaluation/Actions Std             0.178612
evaluation/Actions Max             0.997959
evaluation/Actions Min            -0.995392
evaluation/Num Paths              15
evaluation/Average Returns       -27.4219
time/data storing (s)              0.00332342
time/evaluation sampling (s)       0.364548
time/exploration sampling (s)      0.16295
time/logging (s)                   0.00445132
time/saving (s)                    0.0020024
time/training (s)                  2.12192
time/epoch (s)                     2.6592
time/total (s)                    98.4668
Epoch                             35
-----------------------------  --------------
2019-04-22 21:39:41.960613 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                   2.7832
trainer/QF2 Loss                   2.82923
trainer/Policy Loss               31.5477
trainer/Q1 Predictions Mean      -30.4291
trainer/Q1 Predictions Std        13.4774
trainer/Q1 Predictions Max       -15.9673
trainer/Q1 Predictions Min       -73.9982
trainer/Q2 Predictions Mean      -30.4163
trainer/Q2 Predictions Std        13.4707
trainer/Q2 Predictions Max       -15.9796
trainer/Q2 Predictions Min       -74.1778
trainer/Q Targets Mean           -30.5239
trainer/Q Targets Std             13.8772
trainer/Q Targets Max             -0.311045
trainer/Q Targets Min            -76.5619
trainer/Log Pis Mean               1.95121
trainer/Log Pis Std                1.47119
trainer/Log Pis Max                7.9097
trainer/Log Pis Min               -0.934785
trainer/Policy mu Mean            -0.129466
trainer/Policy mu Std              0.893679
trainer/Policy mu Max              3.24525
trainer/Policy mu Min             -3.22152
trainer/Policy log std Mean       -1.85157
trainer/Policy log std Std         0.552249
trainer/Policy log std Max        -0.349632
trainer/Policy log std Min        -2.71387
trainer/Alpha                      0.0751056
trainer/Alpha Loss                -0.1263
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.645976
exploration/Rewards Std            1.3426
exploration/Rewards Max           -0.0128109
exploration/Rewards Min           -9.90068
exploration/Returns Mean         -64.5976
exploration/Returns Std            8.92859
exploration/Returns Max          -50.0374
exploration/Returns Min          -73.8829
exploration/Actions Mean          -0.0119984
exploration/Actions Std            0.276139
exploration/Actions Max            0.998903
exploration/Actions Min           -0.999157
exploration/Num Paths              5
exploration/Average Returns      -64.5976
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.362035
evaluation/Rewards Std             0.786539
evaluation/Rewards Max            -0.136032
evaluation/Rewards Min            -8.82051
evaluation/Returns Mean          -36.2035
evaluation/Returns Std            13.8133
evaluation/Returns Max           -14.0875
evaluation/Returns Min           -61.1528
evaluation/Actions Mean            0.00478426
evaluation/Actions Std             0.167473
evaluation/Actions Max             0.99733
evaluation/Actions Min            -0.996515
evaluation/Num Paths              15
evaluation/Average Returns       -36.2035
time/data storing (s)              0.00308652
time/evaluation sampling (s)       0.365152
time/exploration sampling (s)      0.166355
time/logging (s)                   0.00412141
time/saving (s)                    0.0104263
time/training (s)                  2.16081
time/epoch (s)                     2.70995
time/total (s)                   101.181
Epoch                             36
-----------------------------  --------------
2019-04-22 21:39:44.633882 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   4.93453
trainer/QF2 Loss                   5.0067
trainer/Policy Loss               29.1199
trainer/Q1 Predictions Mean      -28.1533
trainer/Q1 Predictions Std        13.0627
trainer/Q1 Predictions Max       -15.6643
trainer/Q1 Predictions Min       -70.3374
trainer/Q2 Predictions Mean      -28.1645
trainer/Q2 Predictions Std        13.0055
trainer/Q2 Predictions Max       -15.7592
trainer/Q2 Predictions Min       -69.3744
trainer/Q Targets Mean           -28.2341
trainer/Q Targets Std             13.5273
trainer/Q Targets Max             -0.0661807
trainer/Q Targets Min            -73.7627
trainer/Log Pis Mean               2.02015
trainer/Log Pis Std                1.57203
trainer/Log Pis Max                6.67633
trainer/Log Pis Min               -1.62386
trainer/Policy mu Mean            -0.120324
trainer/Policy mu Std              0.793514
trainer/Policy mu Max              2.82341
trainer/Policy mu Min             -3.04689
trainer/Policy log std Mean       -1.96267
trainer/Policy log std Std         0.559146
trainer/Policy log std Max        -0.432924
trainer/Policy log std Min        -2.78437
trainer/Alpha                      0.0758615
trainer/Alpha Loss                 0.0519701
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.595514
exploration/Rewards Std            1.38632
exploration/Rewards Max           -0.0243033
exploration/Rewards Min           -9.85671
exploration/Returns Mean         -59.5514
exploration/Returns Std            9.58524
exploration/Returns Max          -46.7763
exploration/Returns Min          -73.2309
exploration/Actions Mean           0.0082847
exploration/Actions Std            0.261586
exploration/Actions Max            0.999792
exploration/Actions Min           -0.99745
exploration/Num Paths              5
exploration/Average Returns      -59.5514
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.380778
evaluation/Rewards Std             0.830125
evaluation/Rewards Max            -0.0785752
evaluation/Rewards Min            -8.76409
evaluation/Returns Mean          -38.0778
evaluation/Returns Std            16.2791
evaluation/Returns Max           -15.3276
evaluation/Returns Min           -70.2648
evaluation/Actions Mean           -0.00988118
evaluation/Actions Std             0.192028
evaluation/Actions Max             0.994403
evaluation/Actions Min            -0.993861
evaluation/Num Paths              15
evaluation/Average Returns       -38.0778
time/data storing (s)              0.0030371
time/evaluation sampling (s)       0.363779
time/exploration sampling (s)      0.165501
time/logging (s)                   0.00495748
time/saving (s)                    0.00205176
time/training (s)                  2.12869
time/epoch (s)                     2.66802
time/total (s)                   103.854
Epoch                             37
-----------------------------  --------------
2019-04-22 21:39:47.276541 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                   0.634955
trainer/QF2 Loss                   0.592605
trainer/Policy Loss               31.2089
trainer/Q1 Predictions Mean      -29.8888
trainer/Q1 Predictions Std        17.7273
trainer/Q1 Predictions Max       -15.3673
trainer/Q1 Predictions Min       -93.8939
trainer/Q2 Predictions Mean      -29.8814
trainer/Q2 Predictions Std        17.7136
trainer/Q2 Predictions Max       -15.4204
trainer/Q2 Predictions Min       -93.9981
trainer/Q Targets Mean           -30.0929
trainer/Q Targets Std             17.8355
trainer/Q Targets Max            -15.6528
trainer/Q Targets Min            -94.7494
trainer/Log Pis Mean               2.37573
trainer/Log Pis Std                1.76072
trainer/Log Pis Max                9.31032
trainer/Log Pis Min               -2.00588
trainer/Policy mu Mean            -0.11889
trainer/Policy mu Std              0.986086
trainer/Policy mu Max              3.67221
trainer/Policy mu Min             -3.16492
trainer/Policy log std Mean       -1.99859
trainer/Policy log std Std         0.647031
trainer/Policy log std Max        -0.364034
trainer/Policy log std Min        -2.7972
trainer/Alpha                      0.0775128
trainer/Alpha Loss                 0.960921
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.39332
exploration/Rewards Std            0.934442
exploration/Rewards Max           -0.0171567
exploration/Rewards Min           -8.78946
exploration/Returns Mean         -39.332
exploration/Returns Std           14.6098
exploration/Returns Max          -18.6656
exploration/Returns Min          -55.256
exploration/Actions Mean           0.00169731
exploration/Actions Std            0.250094
exploration/Actions Max            0.997148
exploration/Actions Min           -0.996208
exploration/Num Paths              5
exploration/Average Returns      -39.332
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.399932
evaluation/Rewards Std             1.12959
evaluation/Rewards Max            -0.00804849
evaluation/Rewards Min           -10.594
evaluation/Returns Mean          -39.9932
evaluation/Returns Std            19.7763
evaluation/Returns Max            -6.17464
evaluation/Returns Min           -66.7548
evaluation/Actions Mean           -0.00258656
evaluation/Actions Std             0.206348
evaluation/Actions Max             0.997929
evaluation/Actions Min            -0.995985
evaluation/Num Paths              15
evaluation/Average Returns       -39.9932
time/data storing (s)              0.00319162
time/evaluation sampling (s)       0.359445
time/exploration sampling (s)      0.161439
time/logging (s)                   0.00504888
time/saving (s)                    0.00203643
time/training (s)                  2.10567
time/epoch (s)                     2.63683
time/total (s)                   106.496
Epoch                             38
-----------------------------  --------------
2019-04-22 21:39:49.982648 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                   0.575102
trainer/QF2 Loss                   0.464677
trainer/Policy Loss               29.9752
trainer/Q1 Predictions Mean      -28.7947
trainer/Q1 Predictions Std        13.3589
trainer/Q1 Predictions Max       -15.2496
trainer/Q1 Predictions Min       -72.6821
trainer/Q2 Predictions Mean      -28.799
trainer/Q2 Predictions Std        13.4316
trainer/Q2 Predictions Max       -15.2348
trainer/Q2 Predictions Min       -72.795
trainer/Q Targets Mean           -29.168
trainer/Q Targets Std             13.6012
trainer/Q Targets Max            -15.3077
trainer/Q Targets Min            -73.4842
trainer/Log Pis Mean               2.12949
trainer/Log Pis Std                1.66259
trainer/Log Pis Max                7.82187
trainer/Log Pis Min               -3.24307
trainer/Policy mu Mean            -0.102918
trainer/Policy mu Std              0.899772
trainer/Policy mu Max              2.97024
trainer/Policy mu Min             -3.095
trainer/Policy log std Mean       -1.93703
trainer/Policy log std Std         0.566317
trainer/Policy log std Max        -0.507241
trainer/Policy log std Min        -2.75149
trainer/Alpha                      0.0785877
trainer/Alpha Loss                 0.329359
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.429828
exploration/Rewards Std            0.855283
exploration/Rewards Max           -0.0164125
exploration/Rewards Min           -7.65636
exploration/Returns Mean         -42.9828
exploration/Returns Std           14.8813
exploration/Returns Max          -22.216
exploration/Returns Min          -65.4145
exploration/Actions Mean           0.00463384
exploration/Actions Std            0.22516
exploration/Actions Max            0.995774
exploration/Actions Min           -0.995766
exploration/Num Paths              5
exploration/Average Returns      -42.9828
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.327333
evaluation/Rewards Std             0.949288
evaluation/Rewards Max            -0.0664111
evaluation/Rewards Min            -9.46362
evaluation/Returns Mean          -32.7333
evaluation/Returns Std            10.545
evaluation/Returns Max           -15.6939
evaluation/Returns Min           -50.9323
evaluation/Actions Mean            0.0150366
evaluation/Actions Std             0.181085
evaluation/Actions Max             0.994258
evaluation/Actions Min            -0.995237
evaluation/Num Paths              15
evaluation/Average Returns       -32.7333
time/data storing (s)              0.00323585
time/evaluation sampling (s)       0.3837
time/exploration sampling (s)      0.163675
time/logging (s)                   0.00429085
time/saving (s)                    0.00211366
time/training (s)                  2.14252
time/epoch (s)                     2.69954
time/total (s)                   109.2
Epoch                             39
-----------------------------  --------------
2019-04-22 21:39:52.634037 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size             20700
trainer/QF1 Loss                   0.153279
trainer/QF2 Loss                   0.22585
trainer/Policy Loss               28.3373
trainer/Q1 Predictions Mean      -27.1651
trainer/Q1 Predictions Std        12.2213
trainer/Q1 Predictions Max       -15.0134
trainer/Q1 Predictions Min       -73.6139
trainer/Q2 Predictions Mean      -27.1749
trainer/Q2 Predictions Std        12.1855
trainer/Q2 Predictions Max       -15.1261
trainer/Q2 Predictions Min       -72.5609
trainer/Q Targets Mean           -27.2689
trainer/Q Targets Std             12.0883
trainer/Q Targets Max            -15.1273
trainer/Q Targets Min            -74.2833
trainer/Log Pis Mean               1.8158
trainer/Log Pis Std                1.38917
trainer/Log Pis Max                5.74349
trainer/Log Pis Min               -2.38983
trainer/Policy mu Mean            -0.100573
trainer/Policy mu Std              0.766748
trainer/Policy mu Max              2.97456
trainer/Policy mu Min             -3.00723
trainer/Policy log std Mean       -1.96584
trainer/Policy log std Std         0.569031
trainer/Policy log std Max        -0.390623
trainer/Policy log std Min        -2.78278
trainer/Alpha                      0.0742684
trainer/Alpha Loss                -0.478922
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.493463
exploration/Rewards Std            1.05198
exploration/Rewards Max           -0.0185874
exploration/Rewards Min           -9.51471
exploration/Returns Mean         -49.3463
exploration/Returns Std           22.7142
exploration/Returns Max          -27.8367
exploration/Returns Min          -82.0597
exploration/Actions Mean          -0.0108805
exploration/Actions Std            0.245292
exploration/Actions Max            0.998016
exploration/Actions Min           -0.997848
exploration/Num Paths              5
exploration/Average Returns      -49.3463
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.396274
evaluation/Rewards Std             0.927488
evaluation/Rewards Max            -0.119164
evaluation/Rewards Min           -10.3944
evaluation/Returns Mean          -39.6274
evaluation/Returns Std            21.5462
evaluation/Returns Max           -14.3491
evaluation/Returns Min           -81.5618
evaluation/Actions Mean           -0.00423683
evaluation/Actions Std             0.184063
evaluation/Actions Max             0.997576
evaluation/Actions Min            -0.994998
evaluation/Num Paths              15
evaluation/Average Returns       -39.6274
time/data storing (s)              0.0034073
time/evaluation sampling (s)       0.366865
time/exploration sampling (s)      0.166217
time/logging (s)                   0.00504919
time/saving (s)                    0.00209374
time/training (s)                  2.10245
time/epoch (s)                     2.64609
time/total (s)                   111.85
Epoch                             40
-----------------------------  --------------
2019-04-22 21:39:55.351041 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                   7.4
trainer/QF2 Loss                   7.45382
trainer/Policy Loss               25.9148
trainer/Q1 Predictions Mean      -24.8402
trainer/Q1 Predictions Std        11.7538
trainer/Q1 Predictions Max       -14.8753
trainer/Q1 Predictions Min       -89.8348
trainer/Q2 Predictions Mean      -24.8531
trainer/Q2 Predictions Std        11.7772
trainer/Q2 Predictions Max       -14.8702
trainer/Q2 Predictions Min       -89.8415
trainer/Q Targets Mean           -24.4948
trainer/Q Targets Std             12.2755
trainer/Q Targets Max             -0.0905414
trainer/Q Targets Min            -91.19
trainer/Log Pis Mean               1.86113
trainer/Log Pis Std                1.36748
trainer/Log Pis Max                6.06322
trainer/Log Pis Min               -4.11816
trainer/Policy mu Mean            -0.0138442
trainer/Policy mu Std              0.833174
trainer/Policy mu Max              2.65336
trainer/Policy mu Min             -3.12004
trainer/Policy log std Mean       -1.85932
trainer/Policy log std Std         0.542089
trainer/Policy log std Max        -0.278779
trainer/Policy log std Min        -2.6115
trainer/Alpha                      0.0733433
trainer/Alpha Loss                -0.362814
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.312953
exploration/Rewards Std            0.384596
exploration/Rewards Max           -0.00823696
exploration/Rewards Min           -5.09344
exploration/Returns Mean         -31.2953
exploration/Returns Std           11.8618
exploration/Returns Max          -20.5124
exploration/Returns Min          -51.8988
exploration/Actions Mean           0.0119805
exploration/Actions Std            0.233129
exploration/Actions Max            0.996849
exploration/Actions Min           -0.996256
exploration/Num Paths              5
exploration/Average Returns      -31.2953
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.382067
evaluation/Rewards Std             0.998607
evaluation/Rewards Max            -0.062806
evaluation/Rewards Min           -10.2331
evaluation/Returns Mean          -38.2067
evaluation/Returns Std            19.0423
evaluation/Returns Max           -14.9392
evaluation/Returns Min           -67.9854
evaluation/Actions Mean           -0.00162231
evaluation/Actions Std             0.191547
evaluation/Actions Max             0.997516
evaluation/Actions Min            -0.995251
evaluation/Num Paths              15
evaluation/Average Returns       -38.2067
time/data storing (s)              0.00330953
time/evaluation sampling (s)       0.372693
time/exploration sampling (s)      0.170813
time/logging (s)                   0.00519013
time/saving (s)                    0.00241378
time/training (s)                  2.15744
time/epoch (s)                     2.71186
time/total (s)                   114.567
Epoch                             41
-----------------------------  --------------
2019-04-22 21:39:58.030334 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size             21700
trainer/QF1 Loss                  14.7571
trainer/QF2 Loss                  14.8456
trainer/Policy Loss               28.9664
trainer/Q1 Predictions Mean      -27.7963
trainer/Q1 Predictions Std        14.6526
trainer/Q1 Predictions Max       -14.4841
trainer/Q1 Predictions Min       -78.966
trainer/Q2 Predictions Mean      -27.8262
trainer/Q2 Predictions Std        14.7328
trainer/Q2 Predictions Max       -14.557
trainer/Q2 Predictions Min       -79.3318
trainer/Q Targets Mean           -27.3784
trainer/Q Targets Std             15.329
trainer/Q Targets Max             -0.142752
trainer/Q Targets Min            -81.3601
trainer/Log Pis Mean               2.35276
trainer/Log Pis Std                1.5347
trainer/Log Pis Max                7.75324
trainer/Log Pis Min               -1.58227
trainer/Policy mu Mean            -0.032082
trainer/Policy mu Std              1.07591
trainer/Policy mu Max              3.39539
trainer/Policy mu Min             -2.94937
trainer/Policy log std Mean       -1.80906
trainer/Policy log std Std         0.62214
trainer/Policy log std Max        -0.458997
trainer/Policy log std Min        -2.70829
trainer/Alpha                      0.0739434
trainer/Alpha Loss                 0.918819
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.385519
exploration/Rewards Std            0.872716
exploration/Rewards Max           -0.0110242
exploration/Rewards Min           -7.425
exploration/Returns Mean         -38.5519
exploration/Returns Std            6.27656
exploration/Returns Max          -27.2671
exploration/Returns Min          -46.0375
exploration/Actions Mean           0.0259393
exploration/Actions Std            0.245926
exploration/Actions Max            0.997197
exploration/Actions Min           -0.970874
exploration/Num Paths              5
exploration/Average Returns      -38.5519
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.435222
evaluation/Rewards Std             1.02073
evaluation/Rewards Max            -0.0121285
evaluation/Rewards Min            -9.44678
evaluation/Returns Mean          -43.5222
evaluation/Returns Std            17.2698
evaluation/Returns Max           -15.116
evaluation/Returns Min           -76.054
evaluation/Actions Mean            0.00124286
evaluation/Actions Std             0.187128
evaluation/Actions Max             0.99797
evaluation/Actions Min            -0.995707
evaluation/Num Paths              15
evaluation/Average Returns       -43.5222
time/data storing (s)              0.00329393
time/evaluation sampling (s)       0.38623
time/exploration sampling (s)      0.177047
time/logging (s)                   0.00503896
time/saving (s)                    0.00196572
time/training (s)                  2.10015
time/epoch (s)                     2.67373
time/total (s)                   117.244
Epoch                             42
-----------------------------  --------------
2019-04-22 21:40:00.728591 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size             22200
trainer/QF1 Loss                  12.0298
trainer/QF2 Loss                  12.0397
trainer/Policy Loss               23.4137
trainer/Q1 Predictions Mean      -22.1545
trainer/Q1 Predictions Std         9.78108
trainer/Q1 Predictions Max       -14.2179
trainer/Q1 Predictions Min       -69.7677
trainer/Q2 Predictions Mean      -22.1649
trainer/Q2 Predictions Std         9.78911
trainer/Q2 Predictions Max       -14.2539
trainer/Q2 Predictions Min       -69.5132
trainer/Q Targets Mean           -21.8083
trainer/Q Targets Std              9.91791
trainer/Q Targets Max             -0.491799
trainer/Q Targets Min            -70.274
trainer/Log Pis Mean               1.94986
trainer/Log Pis Std                1.25429
trainer/Log Pis Max                6.08077
trainer/Log Pis Min               -2.64556
trainer/Policy mu Mean            -0.0199981
trainer/Policy mu Std              0.776808
trainer/Policy mu Max              3.07161
trainer/Policy mu Min             -2.92031
trainer/Policy log std Mean       -1.96224
trainer/Policy log std Std         0.559084
trainer/Policy log std Max        -0.490222
trainer/Policy log std Min        -2.74277
trainer/Alpha                      0.0759872
trainer/Alpha Loss                -0.129209
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.4622
exploration/Rewards Std            1.11611
exploration/Rewards Max           -0.0101366
exploration/Rewards Min          -10.54
exploration/Returns Mean         -46.22
exploration/Returns Std           22.0287
exploration/Returns Max          -19.0583
exploration/Returns Min          -73.349
exploration/Actions Mean           0.00100658
exploration/Actions Std            0.245489
exploration/Actions Max            0.999449
exploration/Actions Min           -0.996393
exploration/Num Paths              5
exploration/Average Returns      -46.22
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.368482
evaluation/Rewards Std             0.661566
evaluation/Rewards Max            -0.040695
evaluation/Rewards Min            -8.74736
evaluation/Returns Mean          -36.8482
evaluation/Returns Std            21.2454
evaluation/Returns Max            -7.60094
evaluation/Returns Min           -64.8019
evaluation/Actions Mean           -0.0148151
evaluation/Actions Std             0.169373
evaluation/Actions Max             0.994518
evaluation/Actions Min            -0.99379
evaluation/Num Paths              15
evaluation/Average Returns       -36.8482
time/data storing (s)              0.00328758
time/evaluation sampling (s)       0.368241
time/exploration sampling (s)      0.166231
time/logging (s)                   0.00519503
time/saving (s)                    0.00220218
time/training (s)                  2.14811
time/epoch (s)                     2.69326
time/total (s)                   119.941
Epoch                             43
-----------------------------  --------------
2019-04-22 21:40:03.398169 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             22700
trainer/QF1 Loss                   0.378548
trainer/QF2 Loss                   0.366194
trainer/Policy Loss               25.4903
trainer/Q1 Predictions Mean      -24.3945
trainer/Q1 Predictions Std        13.2455
trainer/Q1 Predictions Max       -13.9951
trainer/Q1 Predictions Min       -92.4345
trainer/Q2 Predictions Mean      -24.3971
trainer/Q2 Predictions Std        13.2458
trainer/Q2 Predictions Max       -14.0359
trainer/Q2 Predictions Min       -92.2425
trainer/Q Targets Mean           -24.4816
trainer/Q Targets Std             13.3384
trainer/Q Targets Max            -14.0255
trainer/Q Targets Min            -92.365
trainer/Log Pis Mean               2.13334
trainer/Log Pis Std                1.55104
trainer/Log Pis Max                7.89501
trainer/Log Pis Min               -1.44481
trainer/Policy mu Mean            -0.00306354
trainer/Policy mu Std              0.896823
trainer/Policy mu Max              3.21537
trainer/Policy mu Min             -3.22463
trainer/Policy log std Mean       -1.87745
trainer/Policy log std Std         0.555036
trainer/Policy log std Max        -0.340718
trainer/Policy log std Min        -2.71599
trainer/Alpha                      0.0741402
trainer/Alpha Loss                 0.346902
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.447955
exploration/Rewards Std            0.976013
exploration/Rewards Max           -0.00623483
exploration/Rewards Min           -8.86346
exploration/Returns Mean         -44.7955
exploration/Returns Std           16.5975
exploration/Returns Max          -13.4628
exploration/Returns Min          -62.2535
exploration/Actions Mean           0.0118184
exploration/Actions Std            0.236168
exploration/Actions Max            0.998584
exploration/Actions Min           -0.998866
exploration/Num Paths              5
exploration/Average Returns      -44.7955
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.406704
evaluation/Rewards Std             1.01179
evaluation/Rewards Max            -0.0884231
evaluation/Rewards Min           -10.8527
evaluation/Returns Mean          -40.6704
evaluation/Returns Std            23.0304
evaluation/Returns Max           -11.6705
evaluation/Returns Min           -88.4099
evaluation/Actions Mean           -0.00410881
evaluation/Actions Std             0.187671
evaluation/Actions Max             0.998889
evaluation/Actions Min            -0.995353
evaluation/Num Paths              15
evaluation/Average Returns       -40.6704
time/data storing (s)              0.00330622
time/evaluation sampling (s)       0.370321
time/exploration sampling (s)      0.171436
time/logging (s)                   0.00513717
time/saving (s)                    0.00180024
time/training (s)                  2.11195
time/epoch (s)                     2.66396
time/total (s)                   122.61
Epoch                             44
-----------------------------  --------------
2019-04-22 21:40:06.130701 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                   0.426155
trainer/QF2 Loss                   0.434524
trainer/Policy Loss               25.1729
trainer/Q1 Predictions Mean      -24.105
trainer/Q1 Predictions Std        12.209
trainer/Q1 Predictions Max       -13.637
trainer/Q1 Predictions Min       -67.7664
trainer/Q2 Predictions Mean      -24.1164
trainer/Q2 Predictions Std        12.2097
trainer/Q2 Predictions Max       -13.6621
trainer/Q2 Predictions Min       -67.186
trainer/Q Targets Mean           -24.4825
trainer/Q Targets Std             12.5228
trainer/Q Targets Max            -13.8545
trainer/Q Targets Min            -71.433
trainer/Log Pis Mean               1.90939
trainer/Log Pis Std                1.62473
trainer/Log Pis Max                7.3359
trainer/Log Pis Min               -5.0928
trainer/Policy mu Mean            -0.0399075
trainer/Policy mu Std              0.859684
trainer/Policy mu Max              2.9492
trainer/Policy mu Min             -3.01563
trainer/Policy log std Mean       -1.89548
trainer/Policy log std Std         0.505446
trainer/Policy log std Max        -0.500149
trainer/Policy log std Min        -2.60776
trainer/Alpha                      0.0725233
trainer/Alpha Loss                -0.237735
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.477934
exploration/Rewards Std            1.04107
exploration/Rewards Max           -0.0284627
exploration/Rewards Min          -10.1056
exploration/Returns Mean         -47.7934
exploration/Returns Std           16.8894
exploration/Returns Max          -28.8541
exploration/Returns Min          -73.7607
exploration/Actions Mean           0.00388435
exploration/Actions Std            0.219454
exploration/Actions Max            0.999601
exploration/Actions Min           -0.997687
exploration/Num Paths              5
exploration/Average Returns      -47.7934
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.408863
evaluation/Rewards Std             1.11855
evaluation/Rewards Max            -0.0728639
evaluation/Rewards Min           -11.0515
evaluation/Returns Mean          -40.8863
evaluation/Returns Std            21.8037
evaluation/Returns Max            -7.79777
evaluation/Returns Min           -87.8991
evaluation/Actions Mean           -0.00773199
evaluation/Actions Std             0.202386
evaluation/Actions Max             0.995537
evaluation/Actions Min            -0.996982
evaluation/Num Paths              15
evaluation/Average Returns       -40.8863
time/data storing (s)              0.00321549
time/evaluation sampling (s)       0.370575
time/exploration sampling (s)      0.165845
time/logging (s)                   0.004627
time/saving (s)                    0.0018528
time/training (s)                  2.17991
time/epoch (s)                     2.72603
time/total (s)                   125.34
Epoch                             45
-----------------------------  --------------
2019-04-22 21:40:08.797584 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 46 finished
-----------------------------  ---------------
replay_buffer/size             23700
trainer/QF1 Loss                   0.111567
trainer/QF2 Loss                   0.123087
trainer/Policy Loss               24.1609
trainer/Q1 Predictions Mean      -22.8637
trainer/Q1 Predictions Std        10.9132
trainer/Q1 Predictions Max       -13.5729
trainer/Q1 Predictions Min       -53.6212
trainer/Q2 Predictions Mean      -22.9015
trainer/Q2 Predictions Std        10.9835
trainer/Q2 Predictions Max       -13.576
trainer/Q2 Predictions Min       -54.9244
trainer/Q Targets Mean           -22.9368
trainer/Q Targets Std             10.8355
trainer/Q Targets Max            -13.5325
trainer/Q Targets Min            -54.9322
trainer/Log Pis Mean               2.05165
trainer/Log Pis Std                1.63615
trainer/Log Pis Max                8.20009
trainer/Log Pis Min               -5.34811
trainer/Policy mu Mean            -0.0250977
trainer/Policy mu Std              0.835135
trainer/Policy mu Max              2.98816
trainer/Policy mu Min             -2.85737
trainer/Policy log std Mean       -1.90213
trainer/Policy log std Std         0.523768
trainer/Policy log std Max        -0.443111
trainer/Policy log std Min        -2.82756
trainer/Alpha                      0.0731333
trainer/Alpha Loss                 0.135083
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.337119
exploration/Rewards Std            0.502181
exploration/Rewards Max           -0.00736162
exploration/Rewards Min           -6.46021
exploration/Returns Mean         -33.7119
exploration/Returns Std           12.663
exploration/Returns Max          -19.3722
exploration/Returns Min          -53.218
exploration/Actions Mean           0.00603344
exploration/Actions Std            0.228217
exploration/Actions Max            0.998169
exploration/Actions Min           -0.993703
exploration/Num Paths              5
exploration/Average Returns      -33.7119
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.239545
evaluation/Rewards Std             0.879774
evaluation/Rewards Max            -0.0430605
evaluation/Rewards Min            -9.80482
evaluation/Returns Mean          -23.9545
evaluation/Returns Std            16.0861
evaluation/Returns Max            -4.87115
evaluation/Returns Min           -63.6103
evaluation/Actions Mean           -0.000731706
evaluation/Actions Std             0.169466
evaluation/Actions Max             0.998939
evaluation/Actions Min            -0.995197
evaluation/Num Paths              15
evaluation/Average Returns       -23.9545
time/data storing (s)              0.00325487
time/evaluation sampling (s)       0.352858
time/exploration sampling (s)      0.159919
time/logging (s)                   0.00504889
time/saving (s)                    0.00754926
time/training (s)                  2.13262
time/epoch (s)                     2.66125
time/total (s)                   128.006
Epoch                             46
-----------------------------  ---------------
2019-04-22 21:40:11.487237 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 47 finished
-----------------------------  ---------------
replay_buffer/size             24200
trainer/QF1 Loss                  12.6827
trainer/QF2 Loss                  12.7505
trainer/Policy Loss               23.6515
trainer/Q1 Predictions Mean      -22.103
trainer/Q1 Predictions Std         9.40561
trainer/Q1 Predictions Max       -13.1368
trainer/Q1 Predictions Min       -47.7928
trainer/Q2 Predictions Mean      -22.1243
trainer/Q2 Predictions Std         9.41022
trainer/Q2 Predictions Max       -13.1893
trainer/Q2 Predictions Min       -47.8952
trainer/Q Targets Mean           -21.7718
trainer/Q Targets Std              9.68214
trainer/Q Targets Max             -0.108013
trainer/Q Targets Min            -48.2976
trainer/Log Pis Mean               2.03776
trainer/Log Pis Std                1.35042
trainer/Log Pis Max                7.18145
trainer/Log Pis Min               -4.23924
trainer/Policy mu Mean            -0.0570941
trainer/Policy mu Std              0.788388
trainer/Policy mu Max              2.76303
trainer/Policy mu Min             -2.82776
trainer/Policy log std Mean       -1.96419
trainer/Policy log std Std         0.57283
trainer/Policy log std Max        -0.370005
trainer/Policy log std Min        -2.84526
trainer/Alpha                      0.0720733
trainer/Alpha Loss                 0.0993185
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.441088
exploration/Rewards Std            1.05059
exploration/Rewards Max           -0.00627246
exploration/Rewards Min           -8.1379
exploration/Returns Mean         -44.1088
exploration/Returns Std           16.3066
exploration/Returns Max          -22.3985
exploration/Returns Min          -61.5432
exploration/Actions Mean           0.00527699
exploration/Actions Std            0.244486
exploration/Actions Max            0.996544
exploration/Actions Min           -0.999096
exploration/Num Paths              5
exploration/Average Returns      -44.1088
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.420002
evaluation/Rewards Std             1.13088
evaluation/Rewards Max            -0.0171958
evaluation/Rewards Min            -9.71333
evaluation/Returns Mean          -42.0002
evaluation/Returns Std            15.095
evaluation/Returns Max           -17.5196
evaluation/Returns Min           -66.4223
evaluation/Actions Mean           -0.000748749
evaluation/Actions Std             0.203724
evaluation/Actions Max             0.998807
evaluation/Actions Min            -0.994274
evaluation/Num Paths              15
evaluation/Average Returns       -42.0002
time/data storing (s)              0.0035557
time/evaluation sampling (s)       0.361123
time/exploration sampling (s)      0.166088
time/logging (s)                   0.00490234
time/saving (s)                    0.00203925
time/training (s)                  2.14584
time/epoch (s)                     2.68355
time/total (s)                   130.694
Epoch                             47
-----------------------------  ---------------
2019-04-22 21:40:14.201318 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                  12.3621
trainer/QF2 Loss                  12.3141
trainer/Policy Loss               22.6822
trainer/Q1 Predictions Mean      -21.4666
trainer/Q1 Predictions Std        10.8315
trainer/Q1 Predictions Max       -13.1391
trainer/Q1 Predictions Min       -65.8353
trainer/Q2 Predictions Mean      -21.4614
trainer/Q2 Predictions Std        10.8217
trainer/Q2 Predictions Max       -13.1901
trainer/Q2 Predictions Min       -65.7955
trainer/Q Targets Mean           -21.1319
trainer/Q Targets Std             11.2776
trainer/Q Targets Max             -0.408109
trainer/Q Targets Min            -66.7353
trainer/Log Pis Mean               1.80111
trainer/Log Pis Std                1.72905
trainer/Log Pis Max                6.43467
trainer/Log Pis Min               -3.51481
trainer/Policy mu Mean            -0.0284644
trainer/Policy mu Std              0.844234
trainer/Policy mu Max              3.30207
trainer/Policy mu Min             -2.58165
trainer/Policy log std Mean       -1.93137
trainer/Policy log std Std         0.607232
trainer/Policy log std Max        -0.390022
trainer/Policy log std Min        -2.88565
trainer/Alpha                      0.0709711
trainer/Alpha Loss                -0.52615
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.359171
exploration/Rewards Std            0.913525
exploration/Rewards Max           -0.00597998
exploration/Rewards Min          -10.3924
exploration/Returns Mean         -35.9171
exploration/Returns Std           15.6702
exploration/Returns Max          -20.821
exploration/Returns Min          -64.6756
exploration/Actions Mean           0.00599216
exploration/Actions Std            0.218166
exploration/Actions Max            0.998733
exploration/Actions Min           -0.996323
exploration/Num Paths              5
exploration/Average Returns      -35.9171
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.327881
evaluation/Rewards Std             0.929556
evaluation/Rewards Max            -0.0446683
evaluation/Rewards Min            -9.90064
evaluation/Returns Mean          -32.7881
evaluation/Returns Std            14.8591
evaluation/Returns Max            -6.44477
evaluation/Returns Min           -53.7503
evaluation/Actions Mean           -0.0014869
evaluation/Actions Std             0.199183
evaluation/Actions Max             0.996617
evaluation/Actions Min            -0.994585
evaluation/Num Paths              15
evaluation/Average Returns       -32.7881
time/data storing (s)              0.0030881
time/evaluation sampling (s)       0.439924
time/exploration sampling (s)      0.162184
time/logging (s)                   0.00513134
time/saving (s)                    0.00204298
time/training (s)                  2.0958
time/epoch (s)                     2.70817
time/total (s)                   133.407
Epoch                             48
-----------------------------  --------------
2019-04-22 21:40:16.844171 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                   0.230165
trainer/QF2 Loss                   0.288573
trainer/Policy Loss               24.6004
trainer/Q1 Predictions Mean      -23.2987
trainer/Q1 Predictions Std        10.9374
trainer/Q1 Predictions Max       -12.9724
trainer/Q1 Predictions Min       -66.5412
trainer/Q2 Predictions Mean      -23.2969
trainer/Q2 Predictions Std        10.9372
trainer/Q2 Predictions Max       -13.0019
trainer/Q2 Predictions Min       -66.3581
trainer/Q Targets Mean           -23.4635
trainer/Q Targets Std             11.1539
trainer/Q Targets Max            -12.9637
trainer/Q Targets Min            -69.2132
trainer/Log Pis Mean               2.12913
trainer/Log Pis Std                1.41124
trainer/Log Pis Max                7.18363
trainer/Log Pis Min               -2.18752
trainer/Policy mu Mean            -0.022299
trainer/Policy mu Std              0.874777
trainer/Policy mu Max              3.37547
trainer/Policy mu Min             -2.56961
trainer/Policy log std Mean       -1.94954
trainer/Policy log std Std         0.579302
trainer/Policy log std Max        -0.386433
trainer/Policy log std Min        -2.81152
trainer/Alpha                      0.0733334
trainer/Alpha Loss                 0.337371
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.32702
exploration/Rewards Std            0.752754
exploration/Rewards Max           -0.00929744
exploration/Rewards Min           -9.56312
exploration/Returns Mean         -32.702
exploration/Returns Std           17.3206
exploration/Returns Max          -16.1212
exploration/Returns Min          -64.4004
exploration/Actions Mean          -0.0151259
exploration/Actions Std            0.220925
exploration/Actions Max            0.98097
exploration/Actions Min           -0.998484
exploration/Num Paths              5
exploration/Average Returns      -32.702
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.271298
evaluation/Rewards Std             0.931612
evaluation/Rewards Max            -0.0483445
evaluation/Rewards Min            -9.60605
evaluation/Returns Mean          -27.1298
evaluation/Returns Std            13.2954
evaluation/Returns Max           -10.4177
evaluation/Returns Min           -53.1863
evaluation/Actions Mean            0.00622295
evaluation/Actions Std             0.191714
evaluation/Actions Max             0.995211
evaluation/Actions Min            -0.994245
evaluation/Num Paths              15
evaluation/Average Returns       -27.1298
time/data storing (s)              0.00306176
time/evaluation sampling (s)       0.349603
time/exploration sampling (s)      0.160765
time/logging (s)                   0.00472157
time/saving (s)                    0.0020734
time/training (s)                  2.11615
time/epoch (s)                     2.63637
time/total (s)                   136.048
Epoch                             49
-----------------------------  --------------
2019-04-22 21:40:19.572910 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             25700
trainer/QF1 Loss                   0.222294
trainer/QF2 Loss                   0.163199
trainer/Policy Loss               23.6034
trainer/Q1 Predictions Mean      -22.4065
trainer/Q1 Predictions Std         9.46234
trainer/Q1 Predictions Max       -12.9388
trainer/Q1 Predictions Min       -57.7234
trainer/Q2 Predictions Mean      -22.4025
trainer/Q2 Predictions Std         9.47152
trainer/Q2 Predictions Max       -13.0117
trainer/Q2 Predictions Min       -58.6684
trainer/Q Targets Mean           -22.587
trainer/Q Targets Std              9.62514
trainer/Q Targets Max            -13.0189
trainer/Q Targets Min            -60.2372
trainer/Log Pis Mean               1.81886
trainer/Log Pis Std                1.53185
trainer/Log Pis Max                8.32994
trainer/Log Pis Min               -2.41824
trainer/Policy mu Mean            -0.0159268
trainer/Policy mu Std              0.872593
trainer/Policy mu Max              2.83309
trainer/Policy mu Min             -2.70528
trainer/Policy log std Mean       -1.77644
trainer/Policy log std Std         0.543785
trainer/Policy log std Max        -0.394392
trainer/Policy log std Min        -2.68857
trainer/Alpha                      0.0749606
trainer/Alpha Loss                -0.469269
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.364932
exploration/Rewards Std            0.83633
exploration/Rewards Max           -0.0301294
exploration/Rewards Min           -9.83249
exploration/Returns Mean         -36.4932
exploration/Returns Std           19.0901
exploration/Returns Max          -20.9577
exploration/Returns Min          -73.5058
exploration/Actions Mean          -0.00571777
exploration/Actions Std            0.241214
exploration/Actions Max            0.998105
exploration/Actions Min           -0.996063
exploration/Num Paths              5
exploration/Average Returns      -36.4932
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.431245
evaluation/Rewards Std             1.10257
evaluation/Rewards Max            -0.0849015
evaluation/Rewards Min           -12.0502
evaluation/Returns Mean          -43.1245
evaluation/Returns Std            17.0793
evaluation/Returns Max           -14.8893
evaluation/Returns Min           -68.1021
evaluation/Actions Mean           -0.00959365
evaluation/Actions Std             0.19767
evaluation/Actions Max             0.998678
evaluation/Actions Min            -0.995997
evaluation/Num Paths              15
evaluation/Average Returns       -43.1245
time/data storing (s)              0.00354481
time/evaluation sampling (s)       0.362974
time/exploration sampling (s)      0.166647
time/logging (s)                   0.00497892
time/saving (s)                    0.00180227
time/training (s)                  2.18283
time/epoch (s)                     2.72278
time/total (s)                   138.776
Epoch                             50
-----------------------------  --------------
2019-04-22 21:40:22.254787 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             26200
trainer/QF1 Loss                   0.362828
trainer/QF2 Loss                   0.349331
trainer/Policy Loss               23.4799
trainer/Q1 Predictions Mean      -22.1533
trainer/Q1 Predictions Std        12.3731
trainer/Q1 Predictions Max       -12.6678
trainer/Q1 Predictions Min       -83.0893
trainer/Q2 Predictions Mean      -22.149
trainer/Q2 Predictions Std        12.3562
trainer/Q2 Predictions Max       -12.7219
trainer/Q2 Predictions Min       -82.9539
trainer/Q Targets Mean           -22.4433
trainer/Q Targets Std             12.4101
trainer/Q Targets Max            -12.8431
trainer/Q Targets Min            -84.977
trainer/Log Pis Mean               2.13832
trainer/Log Pis Std                1.6553
trainer/Log Pis Max                7.91027
trainer/Log Pis Min               -1.81831
trainer/Policy mu Mean            -0.0308483
trainer/Policy mu Std              0.956332
trainer/Policy mu Max              2.82584
trainer/Policy mu Min             -3.26686
trainer/Policy log std Mean       -1.85592
trainer/Policy log std Std         0.589564
trainer/Policy log std Max        -0.377014
trainer/Policy log std Min        -2.75566
trainer/Alpha                      0.0708156
trainer/Alpha Loss                 0.366211
exploration/num steps total    26200
exploration/num paths total      262
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.402475
exploration/Rewards Std            1.10011
exploration/Rewards Max           -0.00904969
exploration/Rewards Min           -9.39562
exploration/Returns Mean         -40.2475
exploration/Returns Std           15.6093
exploration/Returns Max          -16.0638
exploration/Returns Min          -60.1847
exploration/Actions Mean           0.00690431
exploration/Actions Std            0.248887
exploration/Actions Max            0.99738
exploration/Actions Min           -0.999076
exploration/Num Paths              5
exploration/Average Returns      -40.2475
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.391942
evaluation/Rewards Std             0.889826
evaluation/Rewards Max            -0.00496734
evaluation/Rewards Min            -8.66292
evaluation/Returns Mean          -39.1942
evaluation/Returns Std            24.0686
evaluation/Returns Max            -5.50176
evaluation/Returns Min           -75.1821
evaluation/Actions Mean           -0.0139425
evaluation/Actions Std             0.180493
evaluation/Actions Max             0.993431
evaluation/Actions Min            -0.996739
evaluation/Num Paths              15
evaluation/Average Returns       -39.1942
time/data storing (s)              0.00314168
time/evaluation sampling (s)       0.355567
time/exploration sampling (s)      0.160025
time/logging (s)                   0.00358676
time/saving (s)                    0.00176594
time/training (s)                  2.15052
time/epoch (s)                     2.67461
time/total (s)                   141.454
Epoch                             51
-----------------------------  --------------
2019-04-22 21:40:24.940820 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             26700
trainer/QF1 Loss                   2.32604
trainer/QF2 Loss                   2.29467
trainer/Policy Loss               20.6467
trainer/Q1 Predictions Mean      -19.6249
trainer/Q1 Predictions Std        11.3556
trainer/Q1 Predictions Max       -12.6341
trainer/Q1 Predictions Min       -79.1746
trainer/Q2 Predictions Mean      -19.6546
trainer/Q2 Predictions Std        11.3579
trainer/Q2 Predictions Max       -12.6511
trainer/Q2 Predictions Min       -79.0051
trainer/Q Targets Mean           -19.9978
trainer/Q Targets Std             12.081
trainer/Q Targets Max             -0.197212
trainer/Q Targets Min            -83.7379
trainer/Log Pis Mean               1.65953
trainer/Log Pis Std                1.4266
trainer/Log Pis Max                7.21755
trainer/Log Pis Min               -2.35665
trainer/Policy mu Mean            -0.0209723
trainer/Policy mu Std              0.816294
trainer/Policy mu Max              2.91762
trainer/Policy mu Min             -3.21883
trainer/Policy log std Mean       -1.94849
trainer/Policy log std Std         0.567091
trainer/Policy log std Max        -0.304358
trainer/Policy log std Min        -2.66856
trainer/Alpha                      0.0713075
trainer/Alpha Loss                -0.899055
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.549544
exploration/Rewards Std            1.26242
exploration/Rewards Max           -0.0139612
exploration/Rewards Min          -10.5831
exploration/Returns Mean         -54.9544
exploration/Returns Std           15.0867
exploration/Returns Max          -32.0455
exploration/Returns Min          -71.7376
exploration/Actions Mean           0.0249742
exploration/Actions Std            0.254314
exploration/Actions Max            0.999816
exploration/Actions Min           -0.999842
exploration/Num Paths              5
exploration/Average Returns      -54.9544
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.408568
evaluation/Rewards Std             0.851993
evaluation/Rewards Max            -0.0144785
evaluation/Rewards Min           -10.5453
evaluation/Returns Mean          -40.8568
evaluation/Returns Std            21.8921
evaluation/Returns Max            -3.4045
evaluation/Returns Min           -82.7308
evaluation/Actions Mean           -0.0189777
evaluation/Actions Std             0.17375
evaluation/Actions Max             0.987359
evaluation/Actions Min            -0.997046
evaluation/Num Paths              15
evaluation/Average Returns       -40.8568
time/data storing (s)              0.00313935
time/evaluation sampling (s)       0.355857
time/exploration sampling (s)      0.158733
time/logging (s)                   0.0051785
time/saving (s)                    0.00203263
time/training (s)                  2.15641
time/epoch (s)                     2.68135
time/total (s)                   144.141
Epoch                             52
-----------------------------  --------------
2019-04-22 21:40:27.614291 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             27200
trainer/QF1 Loss                   2.00362
trainer/QF2 Loss                   2.01889
trainer/Policy Loss               22.1171
trainer/Q1 Predictions Mean      -20.619
trainer/Q1 Predictions Std         9.75945
trainer/Q1 Predictions Max       -12.4805
trainer/Q1 Predictions Min       -64.8152
trainer/Q2 Predictions Mean      -20.6244
trainer/Q2 Predictions Std         9.75927
trainer/Q2 Predictions Max       -12.4842
trainer/Q2 Predictions Min       -64.5083
trainer/Q Targets Mean           -20.6167
trainer/Q Targets Std             10.0528
trainer/Q Targets Max             -0.15114
trainer/Q Targets Min            -66.98
trainer/Log Pis Mean               2.05932
trainer/Log Pis Std                1.39363
trainer/Log Pis Max                8.08789
trainer/Log Pis Min               -2.54008
trainer/Policy mu Mean            -0.0644246
trainer/Policy mu Std              0.863941
trainer/Policy mu Max              2.8585
trainer/Policy mu Min             -3.42476
trainer/Policy log std Mean       -1.87489
trainer/Policy log std Std         0.553672
trainer/Policy log std Max        -0.415827
trainer/Policy log std Min        -2.73956
trainer/Alpha                      0.0704814
trainer/Alpha Loss                 0.157349
exploration/num steps total    27200
exploration/num paths total      272
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.198165
exploration/Rewards Std            0.387519
exploration/Rewards Max           -0.00973826
exploration/Rewards Min           -4.84121
exploration/Returns Mean         -19.8165
exploration/Returns Std            3.67577
exploration/Returns Max          -16.1998
exploration/Returns Min          -26.8212
exploration/Actions Mean           0.0191347
exploration/Actions Std            0.178934
exploration/Actions Max            0.997808
exploration/Actions Min           -0.987437
exploration/Num Paths              5
exploration/Average Returns      -19.8165
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.36091
evaluation/Rewards Std             1.02208
evaluation/Rewards Max            -0.0384893
evaluation/Rewards Min           -10.4385
evaluation/Returns Mean          -36.091
evaluation/Returns Std            16.6443
evaluation/Returns Max           -15.2263
evaluation/Returns Min           -69.7105
evaluation/Actions Mean           -0.00682403
evaluation/Actions Std             0.197075
evaluation/Actions Max             0.996641
evaluation/Actions Min            -0.996912
evaluation/Num Paths              15
evaluation/Average Returns       -36.091
time/data storing (s)              0.00317786
time/evaluation sampling (s)       0.361366
time/exploration sampling (s)      0.166069
time/logging (s)                   0.00505363
time/saving (s)                    0.00223294
time/training (s)                  2.12897
time/epoch (s)                     2.66687
time/total (s)                   146.813
Epoch                             53
-----------------------------  --------------
2019-04-22 21:40:30.340622 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             27700
trainer/QF1 Loss                  11.2521
trainer/QF2 Loss                  11.229
trainer/Policy Loss               21.7509
trainer/Q1 Predictions Mean      -20.3139
trainer/Q1 Predictions Std        10.6306
trainer/Q1 Predictions Max       -12.1738
trainer/Q1 Predictions Min       -65.6608
trainer/Q2 Predictions Mean      -20.2611
trainer/Q2 Predictions Std        10.5579
trainer/Q2 Predictions Max       -12.2188
trainer/Q2 Predictions Min       -64.8408
trainer/Q Targets Mean           -19.9937
trainer/Q Targets Std             11.0941
trainer/Q Targets Max             -0.170029
trainer/Q Targets Min            -65.456
trainer/Log Pis Mean               2.0491
trainer/Log Pis Std                1.25898
trainer/Log Pis Max                7.25777
trainer/Log Pis Min               -0.935885
trainer/Policy mu Mean            -0.0807702
trainer/Policy mu Std              0.835132
trainer/Policy mu Max              2.8028
trainer/Policy mu Min             -3.16582
trainer/Policy log std Mean       -1.98152
trainer/Policy log std Std         0.598341
trainer/Policy log std Max        -0.383682
trainer/Policy log std Min        -2.96508
trainer/Alpha                      0.0708823
trainer/Alpha Loss                 0.129963
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.396689
exploration/Rewards Std            0.818448
exploration/Rewards Max           -0.0165239
exploration/Rewards Min           -8.41749
exploration/Returns Mean         -39.6689
exploration/Returns Std           17.9927
exploration/Returns Max          -18.766
exploration/Returns Min          -70.5698
exploration/Actions Mean          -0.0114118
exploration/Actions Std            0.243683
exploration/Actions Max            0.993523
exploration/Actions Min           -0.998588
exploration/Num Paths              5
exploration/Average Returns      -39.6689
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.337187
evaluation/Rewards Std             0.974696
evaluation/Rewards Max            -0.0687971
evaluation/Rewards Min           -10.1912
evaluation/Returns Mean          -33.7187
evaluation/Returns Std            18.3823
evaluation/Returns Max            -7.01894
evaluation/Returns Min           -66.4648
evaluation/Actions Mean           -0.0045954
evaluation/Actions Std             0.192059
evaluation/Actions Max             0.996903
evaluation/Actions Min            -0.996181
evaluation/Num Paths              15
evaluation/Average Returns       -33.7187
time/data storing (s)              0.00329636
time/evaluation sampling (s)       0.35527
time/exploration sampling (s)      0.161688
time/logging (s)                   0.00503734
time/saving (s)                    0.00204498
time/training (s)                  2.19266
time/epoch (s)                     2.71999
time/total (s)                   149.537
Epoch                             54
-----------------------------  --------------
2019-04-22 21:40:33.007414 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 55 finished
-----------------------------  ---------------
replay_buffer/size             28200
trainer/QF1 Loss                   0.378292
trainer/QF2 Loss                   0.281575
trainer/Policy Loss               19.9253
trainer/Q1 Predictions Mean      -18.5742
trainer/Q1 Predictions Std         8.83177
trainer/Q1 Predictions Max       -12.1485
trainer/Q1 Predictions Min       -61.968
trainer/Q2 Predictions Mean      -18.5716
trainer/Q2 Predictions Std         8.86654
trainer/Q2 Predictions Max       -12.156
trainer/Q2 Predictions Min       -62.9056
trainer/Q Targets Mean           -18.8031
trainer/Q Targets Std              9.14842
trainer/Q Targets Max            -12.1538
trainer/Q Targets Min            -66.8139
trainer/Log Pis Mean               1.90857
trainer/Log Pis Std                1.55644
trainer/Log Pis Max                7.15072
trainer/Log Pis Min               -2.90906
trainer/Policy mu Mean             0.0893495
trainer/Policy mu Std              0.82198
trainer/Policy mu Max              3.19743
trainer/Policy mu Min             -2.65577
trainer/Policy log std Mean       -1.87861
trainer/Policy log std Std         0.568613
trainer/Policy log std Max        -0.406295
trainer/Policy log std Min        -2.66445
trainer/Alpha                      0.070409
trainer/Alpha Loss                -0.242578
exploration/num steps total    28200
exploration/num paths total      282
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.372824
exploration/Rewards Std            0.761596
exploration/Rewards Max           -0.0148341
exploration/Rewards Min           -7.76678
exploration/Returns Mean         -37.2824
exploration/Returns Std            9.29685
exploration/Returns Max          -20.3197
exploration/Returns Min          -48.4935
exploration/Actions Mean           0.00564849
exploration/Actions Std            0.23671
exploration/Actions Max            0.997191
exploration/Actions Min           -0.997762
exploration/Num Paths              5
exploration/Average Returns      -37.2824
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.359781
evaluation/Rewards Std             0.967944
evaluation/Rewards Max            -0.000689585
evaluation/Rewards Min            -9.2131
evaluation/Returns Mean          -35.9781
evaluation/Returns Std            19.3201
evaluation/Returns Max            -5.17748
evaluation/Returns Min           -69.47
evaluation/Actions Mean           -0.000547102
evaluation/Actions Std             0.195827
evaluation/Actions Max             0.995987
evaluation/Actions Min            -0.997273
evaluation/Num Paths              15
evaluation/Average Returns       -35.9781
time/data storing (s)              0.00315431
time/evaluation sampling (s)       0.368727
time/exploration sampling (s)      0.165572
time/logging (s)                   0.00507796
time/saving (s)                    0.00204734
time/training (s)                  2.11604
time/epoch (s)                     2.66061
time/total (s)                   152.203
Epoch                             55
-----------------------------  ---------------
2019-04-22 21:40:35.735500 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             28700
trainer/QF1 Loss                   3.50587
trainer/QF2 Loss                   3.50638
trainer/Policy Loss               20.0302
trainer/Q1 Predictions Mean      -18.585
trainer/Q1 Predictions Std         7.62134
trainer/Q1 Predictions Max       -12.1254
trainer/Q1 Predictions Min       -40.5702
trainer/Q2 Predictions Mean      -18.5971
trainer/Q2 Predictions Std         7.65915
trainer/Q2 Predictions Max       -12.1593
trainer/Q2 Predictions Min       -41.9335
trainer/Q Targets Mean           -18.4971
trainer/Q Targets Std              8.08496
trainer/Q Targets Max             -0.217801
trainer/Q Targets Min            -41.585
trainer/Log Pis Mean               1.91146
trainer/Log Pis Std                1.20412
trainer/Log Pis Max                5.38479
trainer/Log Pis Min               -1.13641
trainer/Policy mu Mean            -0.00178021
trainer/Policy mu Std              0.790384
trainer/Policy mu Max              2.7589
trainer/Policy mu Min             -2.81659
trainer/Policy log std Mean       -1.87809
trainer/Policy log std Std         0.514209
trainer/Policy log std Max        -0.378222
trainer/Policy log std Min        -2.76082
trainer/Alpha                      0.0684585
trainer/Alpha Loss                -0.237416
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.330973
exploration/Rewards Std            0.817211
exploration/Rewards Max           -0.00989067
exploration/Rewards Min           -8.29489
exploration/Returns Mean         -33.0973
exploration/Returns Std            7.34698
exploration/Returns Max          -20.8368
exploration/Returns Min          -43.7023
exploration/Actions Mean           0.018416
exploration/Actions Std            0.236919
exploration/Actions Max            0.998245
exploration/Actions Min           -0.977755
exploration/Num Paths              5
exploration/Average Returns      -33.0973
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.462037
evaluation/Rewards Std             1.10382
evaluation/Rewards Max            -0.033934
evaluation/Rewards Min           -10.0521
evaluation/Returns Mean          -46.2037
evaluation/Returns Std            21.6638
evaluation/Returns Max            -9.75495
evaluation/Returns Min           -77.8076
evaluation/Actions Mean           -0.0165635
evaluation/Actions Std             0.204005
evaluation/Actions Max             0.997734
evaluation/Actions Min            -0.997348
evaluation/Num Paths              15
evaluation/Average Returns       -46.2037
time/data storing (s)              0.00341092
time/evaluation sampling (s)       0.366152
time/exploration sampling (s)      0.159
time/logging (s)                   0.00492409
time/saving (s)                    0.00229232
time/training (s)                  2.18588
time/epoch (s)                     2.72166
time/total (s)                   154.929
Epoch                             56
-----------------------------  --------------
2019-04-22 21:40:38.420794 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             29200
trainer/QF1 Loss                   1.66209
trainer/QF2 Loss                   1.66948
trainer/Policy Loss               21.2059
trainer/Q1 Predictions Mean      -19.8201
trainer/Q1 Predictions Std         9.87951
trainer/Q1 Predictions Max       -12.1011
trainer/Q1 Predictions Min       -58.7092
trainer/Q2 Predictions Mean      -19.8143
trainer/Q2 Predictions Std         9.85783
trainer/Q2 Predictions Max       -12.1456
trainer/Q2 Predictions Min       -58.0204
trainer/Q Targets Mean           -19.7745
trainer/Q Targets Std              9.99924
trainer/Q Targets Max             -1.5613
trainer/Q Targets Min            -59.9033
trainer/Log Pis Mean               2.05144
trainer/Log Pis Std                1.51328
trainer/Log Pis Max                8.01194
trainer/Log Pis Min               -2.45342
trainer/Policy mu Mean             0.0500745
trainer/Policy mu Std              0.929086
trainer/Policy mu Max              3.14867
trainer/Policy mu Min             -3.03663
trainer/Policy log std Mean       -1.82137
trainer/Policy log std Std         0.573561
trainer/Policy log std Max        -0.441687
trainer/Policy log std Min        -2.7002
trainer/Alpha                      0.0676674
trainer/Alpha Loss                 0.138547
exploration/num steps total    29200
exploration/num paths total      292
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.369602
exploration/Rewards Std            0.786418
exploration/Rewards Max           -0.0217184
exploration/Rewards Min           -9.34618
exploration/Returns Mean         -36.9602
exploration/Returns Std           13.3225
exploration/Returns Max          -25.0525
exploration/Returns Min          -62.375
exploration/Actions Mean          -0.0268347
exploration/Actions Std            0.243124
exploration/Actions Max            0.968044
exploration/Actions Min           -0.997487
exploration/Num Paths              5
exploration/Average Returns      -36.9602
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.338175
evaluation/Rewards Std             1.05668
evaluation/Rewards Max            -0.0162827
evaluation/Rewards Min           -11.7737
evaluation/Returns Mean          -33.8175
evaluation/Returns Std            18.2971
evaluation/Returns Max           -10.5498
evaluation/Returns Min           -77.5297
evaluation/Actions Mean           -0.00649506
evaluation/Actions Std             0.204355
evaluation/Actions Max             0.997567
evaluation/Actions Min            -0.996912
evaluation/Num Paths              15
evaluation/Average Returns       -33.8175
time/data storing (s)              0.00320887
time/evaluation sampling (s)       0.367782
time/exploration sampling (s)      0.166335
time/logging (s)                   0.00489488
time/saving (s)                    0.00212678
time/training (s)                  2.13438
time/epoch (s)                     2.67872
time/total (s)                   157.613
Epoch                             57
-----------------------------  --------------
2019-04-22 21:40:41.098308 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             29700
trainer/QF1 Loss                   4.36345
trainer/QF2 Loss                   4.33905
trainer/Policy Loss               19.986
trainer/Q1 Predictions Mean      -19.0226
trainer/Q1 Predictions Std         9.35212
trainer/Q1 Predictions Max       -11.6511
trainer/Q1 Predictions Min       -70.8073
trainer/Q2 Predictions Mean      -19.0215
trainer/Q2 Predictions Std         9.37833
trainer/Q2 Predictions Max       -11.7089
trainer/Q2 Predictions Min       -70.8855
trainer/Q Targets Mean           -18.9033
trainer/Q Targets Std              9.88106
trainer/Q Targets Max             -0.0905414
trainer/Q Targets Min            -70.7238
trainer/Log Pis Mean               1.62114
trainer/Log Pis Std                2.05189
trainer/Log Pis Max                8.2238
trainer/Log Pis Min              -10.9343
trainer/Policy mu Mean             0.00783018
trainer/Policy mu Std              0.812198
trainer/Policy mu Max              3.1044
trainer/Policy mu Min             -2.73941
trainer/Policy log std Mean       -1.90055
trainer/Policy log std Std         0.54445
trainer/Policy log std Max        -0.360734
trainer/Policy log std Min        -2.74639
trainer/Alpha                      0.0669769
trainer/Alpha Loss                -1.02421
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.554318
exploration/Rewards Std            1.20645
exploration/Rewards Max           -0.0160037
exploration/Rewards Min           -9.16231
exploration/Returns Mean         -55.4318
exploration/Returns Std           18.9041
exploration/Returns Max          -18.0877
exploration/Returns Min          -69.1923
exploration/Actions Mean          -0.0422484
exploration/Actions Std            0.270792
exploration/Actions Max            0.983018
exploration/Actions Min           -0.999902
exploration/Num Paths              5
exploration/Average Returns      -55.4318
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.32873
evaluation/Rewards Std             0.960749
evaluation/Rewards Max            -0.0131314
evaluation/Rewards Min           -10.8213
evaluation/Returns Mean          -32.873
evaluation/Returns Std            21.2795
evaluation/Returns Max            -4.816
evaluation/Returns Min           -69.0193
evaluation/Actions Mean           -0.0198768
evaluation/Actions Std             0.188163
evaluation/Actions Max             0.997521
evaluation/Actions Min            -0.996192
evaluation/Num Paths              15
evaluation/Average Returns       -32.873
time/data storing (s)              0.00320588
time/evaluation sampling (s)       0.352811
time/exploration sampling (s)      0.162783
time/logging (s)                   0.00483216
time/saving (s)                    0.0024396
time/training (s)                  2.145
time/epoch (s)                     2.67107
time/total (s)                   160.289
Epoch                             58
-----------------------------  --------------
2019-04-22 21:40:43.828717 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             30200
trainer/QF1 Loss                   0.25841
trainer/QF2 Loss                   0.247411
trainer/Policy Loss               20.0775
trainer/Q1 Predictions Mean      -18.5854
trainer/Q1 Predictions Std         7.48203
trainer/Q1 Predictions Max       -11.773
trainer/Q1 Predictions Min       -39.7223
trainer/Q2 Predictions Mean      -18.5659
trainer/Q2 Predictions Std         7.4943
trainer/Q2 Predictions Max       -11.7666
trainer/Q2 Predictions Min       -39.9494
trainer/Q Targets Mean           -18.5866
trainer/Q Targets Std              7.37696
trainer/Q Targets Max            -11.7619
trainer/Q Targets Min            -37.1934
trainer/Log Pis Mean               2.06589
trainer/Log Pis Std                1.09587
trainer/Log Pis Max                5.28922
trainer/Log Pis Min               -1.37849
trainer/Policy mu Mean             0.0325494
trainer/Policy mu Std              0.784575
trainer/Policy mu Max              3.03359
trainer/Policy mu Min             -2.58886
trainer/Policy log std Mean       -1.98043
trainer/Policy log std Std         0.49831
trainer/Policy log std Max        -0.467215
trainer/Policy log std Min        -2.6566
trainer/Alpha                      0.0659485
trainer/Alpha Loss                 0.179137
exploration/num steps total    30200
exploration/num paths total      302
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.373377
exploration/Rewards Std            0.787623
exploration/Rewards Max           -0.0160372
exploration/Rewards Min           -7.06822
exploration/Returns Mean         -37.3377
exploration/Returns Std           14.3772
exploration/Returns Max          -15.4709
exploration/Returns Min          -58.244
exploration/Actions Mean          -0.0176928
exploration/Actions Std            0.242118
exploration/Actions Max            0.981799
exploration/Actions Min           -0.999803
exploration/Num Paths              5
exploration/Average Returns      -37.3377
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.280997
evaluation/Rewards Std             0.801674
evaluation/Rewards Max            -0.0142565
evaluation/Rewards Min           -10.879
evaluation/Returns Mean          -28.0997
evaluation/Returns Std            17.7206
evaluation/Returns Max            -6.50675
evaluation/Returns Min           -66.3772
evaluation/Actions Mean            0.0022468
evaluation/Actions Std             0.176668
evaluation/Actions Max             0.999127
evaluation/Actions Min            -0.996022
evaluation/Num Paths              15
evaluation/Average Returns       -28.0997
time/data storing (s)              0.00476817
time/evaluation sampling (s)       0.357184
time/exploration sampling (s)      0.180045
time/logging (s)                   0.0055654
time/saving (s)                    0.0134468
time/training (s)                  2.16403
time/epoch (s)                     2.72504
time/total (s)                   163.018
Epoch                             59
-----------------------------  --------------
2019-04-22 21:40:46.504641 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             30700
trainer/QF1 Loss                   0.155483
trainer/QF2 Loss                   0.15488
trainer/Policy Loss               19.2234
trainer/Q1 Predictions Mean      -17.6553
trainer/Q1 Predictions Std         9.08706
trainer/Q1 Predictions Max       -11.5753
trainer/Q1 Predictions Min       -63.7208
trainer/Q2 Predictions Mean      -17.6772
trainer/Q2 Predictions Std         9.11651
trainer/Q2 Predictions Max       -11.5982
trainer/Q2 Predictions Min       -63.3835
trainer/Q Targets Mean           -17.7453
trainer/Q Targets Std              9.12574
trainer/Q Targets Max            -11.6509
trainer/Q Targets Min            -64.5494
trainer/Log Pis Mean               2.12654
trainer/Log Pis Std                1.37457
trainer/Log Pis Max                7.79381
trainer/Log Pis Min               -1.28409
trainer/Policy mu Mean             0.0704984
trainer/Policy mu Std              0.856126
trainer/Policy mu Max              2.91114
trainer/Policy mu Min             -2.99847
trainer/Policy log std Mean       -1.96157
trainer/Policy log std Std         0.545091
trainer/Policy log std Max        -0.453144
trainer/Policy log std Min        -2.65463
trainer/Alpha                      0.0651734
trainer/Alpha Loss                 0.345548
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.331471
exploration/Rewards Std            0.638195
exploration/Rewards Max           -0.00979899
exploration/Rewards Min           -6.64292
exploration/Returns Mean         -33.1471
exploration/Returns Std            8.41229
exploration/Returns Max          -26.0374
exploration/Returns Min          -49.6831
exploration/Actions Mean          -0.00482593
exploration/Actions Std            0.225292
exploration/Actions Max            0.998017
exploration/Actions Min           -0.998827
exploration/Num Paths              5
exploration/Average Returns      -33.1471
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.394096
evaluation/Rewards Std             1.17247
evaluation/Rewards Max            -0.0477995
evaluation/Rewards Min           -11.1953
evaluation/Returns Mean          -39.4096
evaluation/Returns Std            19.1001
evaluation/Returns Max           -16.1059
evaluation/Returns Min           -67.4845
evaluation/Actions Mean           -0.00259355
evaluation/Actions Std             0.210268
evaluation/Actions Max             0.998595
evaluation/Actions Min            -0.996042
evaluation/Num Paths              15
evaluation/Average Returns       -39.4096
time/data storing (s)              0.00333806
time/evaluation sampling (s)       0.358131
time/exploration sampling (s)      0.168746
time/logging (s)                   0.0048625
time/saving (s)                    0.00186346
time/training (s)                  2.13185
time/epoch (s)                     2.6688
time/total (s)                   165.692
Epoch                             60
-----------------------------  --------------
2019-04-22 21:40:49.384999 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             31200
trainer/QF1 Loss                   8.71472
trainer/QF2 Loss                   8.73222
trainer/Policy Loss               19.8636
trainer/Q1 Predictions Mean      -18.2582
trainer/Q1 Predictions Std        10.3236
trainer/Q1 Predictions Max       -11.4764
trainer/Q1 Predictions Min       -75.4048
trainer/Q2 Predictions Mean      -18.2522
trainer/Q2 Predictions Std        10.3237
trainer/Q2 Predictions Max       -11.4645
trainer/Q2 Predictions Min       -75.0763
trainer/Q Targets Mean           -17.9499
trainer/Q Targets Std             10.9328
trainer/Q Targets Max             -0.255698
trainer/Q Targets Min            -76.1924
trainer/Log Pis Mean               2.17023
trainer/Log Pis Std                1.30431
trainer/Log Pis Max                6.96701
trainer/Log Pis Min               -0.675206
trainer/Policy mu Mean            -0.102233
trainer/Policy mu Std              0.792518
trainer/Policy mu Max              3.14849
trainer/Policy mu Min             -3.20412
trainer/Policy log std Mean       -2.03173
trainer/Policy log std Std         0.48961
trainer/Policy log std Max        -0.626295
trainer/Policy log std Min        -2.65165
trainer/Alpha                      0.0649564
trainer/Alpha Loss                 0.465414
exploration/num steps total    31200
exploration/num paths total      312
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.424982
exploration/Rewards Std            0.977692
exploration/Rewards Max           -0.021038
exploration/Rewards Min           -7.81439
exploration/Returns Mean         -42.4982
exploration/Returns Std            8.34136
exploration/Returns Max          -35.2274
exploration/Returns Min          -58.332
exploration/Actions Mean          -0.0106673
exploration/Actions Std            0.263986
exploration/Actions Max            0.995046
exploration/Actions Min           -0.997903
exploration/Num Paths              5
exploration/Average Returns      -42.4982
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.345522
evaluation/Rewards Std             1.02431
evaluation/Rewards Max            -0.0387349
evaluation/Rewards Min            -9.58458
evaluation/Returns Mean          -34.5522
evaluation/Returns Std            16.7558
evaluation/Returns Max            -9.51359
evaluation/Returns Min           -66.5807
evaluation/Actions Mean            0.00855341
evaluation/Actions Std             0.198801
evaluation/Actions Max             0.997629
evaluation/Actions Min            -0.996195
evaluation/Num Paths              15
evaluation/Average Returns       -34.5522
time/data storing (s)              0.00303617
time/evaluation sampling (s)       0.363846
time/exploration sampling (s)      0.164782
time/logging (s)                   0.00511214
time/saving (s)                    0.00205272
time/training (s)                  2.33546
time/epoch (s)                     2.87429
time/total (s)                   168.571
Epoch                             61
-----------------------------  --------------
2019-04-22 21:40:52.057167 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             31700
trainer/QF1 Loss                   1.54391
trainer/QF2 Loss                   1.5239
trainer/Policy Loss               19.1791
trainer/Q1 Predictions Mean      -17.6834
trainer/Q1 Predictions Std        10.3497
trainer/Q1 Predictions Max       -11.1379
trainer/Q1 Predictions Min       -73.7965
trainer/Q2 Predictions Mean      -17.6941
trainer/Q2 Predictions Std        10.3498
trainer/Q2 Predictions Max       -11.1675
trainer/Q2 Predictions Min       -73.9382
trainer/Q Targets Mean           -17.5565
trainer/Q Targets Std             10.3772
trainer/Q Targets Max             -0.149262
trainer/Q Targets Min            -71.6001
trainer/Log Pis Mean               2.24887
trainer/Log Pis Std                1.40596
trainer/Log Pis Max                8.45787
trainer/Log Pis Min               -0.779245
trainer/Policy mu Mean            -0.0618666
trainer/Policy mu Std              0.877909
trainer/Policy mu Max              3.2181
trainer/Policy mu Min             -3.2125
trainer/Policy log std Mean       -1.97718
trainer/Policy log std Std         0.541911
trainer/Policy log std Max        -0.489472
trainer/Policy log std Min        -2.66623
trainer/Alpha                      0.0644498
trainer/Alpha Loss                 0.682345
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.457584
exploration/Rewards Std            0.922952
exploration/Rewards Max           -0.0171204
exploration/Rewards Min           -9.07708
exploration/Returns Mean         -45.7584
exploration/Returns Std            7.87573
exploration/Returns Max          -32.9712
exploration/Returns Min          -54.2705
exploration/Actions Mean          -0.0234379
exploration/Actions Std            0.255996
exploration/Actions Max            0.994355
exploration/Actions Min           -0.998067
exploration/Num Paths              5
exploration/Average Returns      -45.7584
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.311787
evaluation/Rewards Std             0.856766
evaluation/Rewards Max            -0.016822
evaluation/Rewards Min            -9.9909
evaluation/Returns Mean          -31.1787
evaluation/Returns Std            15.433
evaluation/Returns Max            -7.19942
evaluation/Returns Min           -64.3627
evaluation/Actions Mean           -0.0079393
evaluation/Actions Std             0.179045
evaluation/Actions Max             0.999244
evaluation/Actions Min            -0.996473
evaluation/Num Paths              15
evaluation/Average Returns       -31.1787
time/data storing (s)              0.00345914
time/evaluation sampling (s)       0.355567
time/exploration sampling (s)      0.165125
time/logging (s)                   0.00497872
time/saving (s)                    0.00206697
time/training (s)                  2.13441
time/epoch (s)                     2.66561
time/total (s)                   171.241
Epoch                             62
-----------------------------  --------------
2019-04-22 21:40:54.763396 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             32200
trainer/QF1 Loss                   1.46948
trainer/QF2 Loss                   1.46585
trainer/Policy Loss               19.0546
trainer/Q1 Predictions Mean      -17.5116
trainer/Q1 Predictions Std         9.0024
trainer/Q1 Predictions Max       -10.9538
trainer/Q1 Predictions Min       -53.051
trainer/Q2 Predictions Mean      -17.4741
trainer/Q2 Predictions Std         8.92895
trainer/Q2 Predictions Max       -10.9255
trainer/Q2 Predictions Min       -52.9233
trainer/Q Targets Mean           -17.6547
trainer/Q Targets Std              9.22278
trainer/Q Targets Max             -0.449683
trainer/Q Targets Min            -52.8013
trainer/Log Pis Mean               2.13317
trainer/Log Pis Std                1.07154
trainer/Log Pis Max                6.2253
trainer/Log Pis Min               -0.492676
trainer/Policy mu Mean            -0.0697711
trainer/Policy mu Std              0.727632
trainer/Policy mu Max              3.20662
trainer/Policy mu Min             -2.94346
trainer/Policy log std Mean       -2.07512
trainer/Policy log std Std         0.478488
trainer/Policy log std Max        -0.507872
trainer/Policy log std Min        -2.64218
trainer/Alpha                      0.0663651
trainer/Alpha Loss                 0.361258
exploration/num steps total    32200
exploration/num paths total      322
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.417269
exploration/Rewards Std            1.26331
exploration/Rewards Max           -0.00691786
exploration/Rewards Min          -11.8303
exploration/Returns Mean         -41.7269
exploration/Returns Std           23.5203
exploration/Returns Max          -16.2076
exploration/Returns Min          -74.1459
exploration/Actions Mean           0.0290488
exploration/Actions Std            0.250388
exploration/Actions Max            0.999792
exploration/Actions Min           -0.995147
exploration/Num Paths              5
exploration/Average Returns      -41.7269
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.24336
evaluation/Rewards Std             0.74555
evaluation/Rewards Max            -0.0494698
evaluation/Rewards Min            -8.31655
evaluation/Returns Mean          -24.336
evaluation/Returns Std            12.2595
evaluation/Returns Max            -7.42706
evaluation/Returns Min           -50.2213
evaluation/Actions Mean           -0.00135956
evaluation/Actions Std             0.168705
evaluation/Actions Max             0.997693
evaluation/Actions Min            -0.996307
evaluation/Num Paths              15
evaluation/Average Returns       -24.336
time/data storing (s)              0.00313274
time/evaluation sampling (s)       0.35913
time/exploration sampling (s)      0.159409
time/logging (s)                   0.00497651
time/saving (s)                    0.00205343
time/training (s)                  2.1711
time/epoch (s)                     2.69981
time/total (s)                   173.946
Epoch                             63
-----------------------------  --------------
2019-04-22 21:40:57.449257 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             32700
trainer/QF1 Loss                   0.0948284
trainer/QF2 Loss                   0.0815095
trainer/Policy Loss               18.4534
trainer/Q1 Predictions Mean      -17.0181
trainer/Q1 Predictions Std         8.2844
trainer/Q1 Predictions Max       -10.911
trainer/Q1 Predictions Min       -50.2483
trainer/Q2 Predictions Mean      -17.0318
trainer/Q2 Predictions Std         8.31845
trainer/Q2 Predictions Max       -10.8828
trainer/Q2 Predictions Min       -50.6541
trainer/Q Targets Mean           -17.0802
trainer/Q Targets Std              8.28153
trainer/Q Targets Max            -10.8878
trainer/Q Targets Min            -50.8069
trainer/Log Pis Mean               2.03243
trainer/Log Pis Std                1.2277
trainer/Log Pis Max                6.52619
trainer/Log Pis Min               -3.02431
trainer/Policy mu Mean            -0.0516208
trainer/Policy mu Std              0.804037
trainer/Policy mu Max              2.85645
trainer/Policy mu Min             -3.21376
trainer/Policy log std Mean       -1.90733
trainer/Policy log std Std         0.507042
trainer/Policy log std Max        -0.426551
trainer/Policy log std Min        -2.5834
trainer/Alpha                      0.0655785
trainer/Alpha Loss                 0.08836
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.500394
exploration/Rewards Std            1.31794
exploration/Rewards Max           -0.00170145
exploration/Rewards Min           -9.76177
exploration/Returns Mean         -50.0394
exploration/Returns Std           14.8721
exploration/Returns Max          -20.9197
exploration/Returns Min          -60.8011
exploration/Actions Mean           0.00384654
exploration/Actions Std            0.281379
exploration/Actions Max            0.998845
exploration/Actions Min           -0.999317
exploration/Num Paths              5
exploration/Average Returns      -50.0394
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.344325
evaluation/Rewards Std             0.951388
evaluation/Rewards Max            -0.0355136
evaluation/Rewards Min            -9.316
evaluation/Returns Mean          -34.4325
evaluation/Returns Std            14.8627
evaluation/Returns Max           -13.3281
evaluation/Returns Min           -66.4414
evaluation/Actions Mean           -0.00363546
evaluation/Actions Std             0.192956
evaluation/Actions Max             0.996202
evaluation/Actions Min            -0.996572
evaluation/Num Paths              15
evaluation/Average Returns       -34.4325
time/data storing (s)              0.00318058
time/evaluation sampling (s)       0.362017
time/exploration sampling (s)      0.165063
time/logging (s)                   0.00516522
time/saving (s)                    0.0021402
time/training (s)                  2.14222
time/epoch (s)                     2.67979
time/total (s)                   176.63
Epoch                             64
-----------------------------  --------------
2019-04-22 21:41:00.169723 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             33200
trainer/QF1 Loss                   5.43459
trainer/QF2 Loss                   5.42192
trainer/Policy Loss               18.3346
trainer/Q1 Predictions Mean      -16.828
trainer/Q1 Predictions Std         9.99247
trainer/Q1 Predictions Max       -10.7311
trainer/Q1 Predictions Min       -76.8254
trainer/Q2 Predictions Mean      -16.8055
trainer/Q2 Predictions Std         9.98755
trainer/Q2 Predictions Max       -10.7235
trainer/Q2 Predictions Min       -76.6491
trainer/Q Targets Mean           -16.6769
trainer/Q Targets Std             10.2168
trainer/Q Targets Max             -0.750057
trainer/Q Targets Min            -79.2785
trainer/Log Pis Mean               1.99862
trainer/Log Pis Std                1.56821
trainer/Log Pis Max                7.55015
trainer/Log Pis Min               -2.50474
trainer/Policy mu Mean            -0.0190824
trainer/Policy mu Std              0.844325
trainer/Policy mu Max              2.98596
trainer/Policy mu Min             -3.34504
trainer/Policy log std Mean       -1.97618
trainer/Policy log std Std         0.516831
trainer/Policy log std Max        -0.457659
trainer/Policy log std Min        -2.60563
trainer/Alpha                      0.0661469
trainer/Alpha Loss                -0.00376085
exploration/num steps total    33200
exploration/num paths total      332
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.311377
exploration/Rewards Std            0.797113
exploration/Rewards Max           -0.00407278
exploration/Rewards Min           -7.9896
exploration/Returns Mean         -31.1377
exploration/Returns Std            9.05238
exploration/Returns Max          -16.5697
exploration/Returns Min          -42.0298
exploration/Actions Mean           0.00658732
exploration/Actions Std            0.235052
exploration/Actions Max            0.997199
exploration/Actions Min           -0.998517
exploration/Num Paths              5
exploration/Average Returns      -31.1377
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.447567
evaluation/Rewards Std             1.20983
evaluation/Rewards Max            -0.0222235
evaluation/Rewards Min            -9.84955
evaluation/Returns Mean          -44.7567
evaluation/Returns Std            16.5222
evaluation/Returns Max           -24.3782
evaluation/Returns Min           -73.9848
evaluation/Actions Mean           -0.0122708
evaluation/Actions Std             0.209309
evaluation/Actions Max             0.996345
evaluation/Actions Min            -0.996799
evaluation/Num Paths              15
evaluation/Average Returns       -44.7567
time/data storing (s)              0.00315991
time/evaluation sampling (s)       0.359447
time/exploration sampling (s)      0.161682
time/logging (s)                   0.00499404
time/saving (s)                    0.00186005
time/training (s)                  2.18313
time/epoch (s)                     2.71427
time/total (s)                   179.349
Epoch                             65
-----------------------------  --------------
2019-04-22 21:41:02.846588 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                    0.213888
trainer/QF2 Loss                    0.215684
trainer/Policy Loss                17.3003
trainer/Q1 Predictions Mean       -16.0768
trainer/Q1 Predictions Std          8.51129
trainer/Q1 Predictions Max        -10.4642
trainer/Q1 Predictions Min        -58.9325
trainer/Q2 Predictions Mean       -16.0521
trainer/Q2 Predictions Std          8.50291
trainer/Q2 Predictions Max        -10.4829
trainer/Q2 Predictions Min        -59.1733
trainer/Q Targets Mean            -16.2756
trainer/Q Targets Std               8.76283
trainer/Q Targets Max             -10.5041
trainer/Q Targets Min             -60.3651
trainer/Log Pis Mean                1.81265
trainer/Log Pis Std                 1.53217
trainer/Log Pis Max                 7.41818
trainer/Log Pis Min                -4.57653
trainer/Policy mu Mean             -0.0837159
trainer/Policy mu Std               0.768492
trainer/Policy mu Max               2.96949
trainer/Policy mu Min              -2.59116
trainer/Policy log std Mean        -1.90568
trainer/Policy log std Std          0.493222
trainer/Policy log std Max         -0.345439
trainer/Policy log std Min         -2.54006
trainer/Alpha                       0.0670275
trainer/Alpha Loss                 -0.50631
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.471254
exploration/Rewards Std             1.19967
exploration/Rewards Max            -0.00720022
exploration/Rewards Min            -9.56475
exploration/Returns Mean          -47.1254
exploration/Returns Std            12.6995
exploration/Returns Max           -23.7763
exploration/Returns Min           -59.2894
exploration/Actions Mean           -0.0212803
exploration/Actions Std             0.267045
exploration/Actions Max             0.991768
exploration/Actions Min            -0.998795
exploration/Num Paths               5
exploration/Average Returns       -47.1254
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.287372
evaluation/Rewards Std              1.0373
evaluation/Rewards Max             -0.0223176
evaluation/Rewards Min             -9.1942
evaluation/Returns Mean           -28.7372
evaluation/Returns Std             12.3362
evaluation/Returns Max             -8.05519
evaluation/Returns Min            -49.6745
evaluation/Actions Mean             0.00978066
evaluation/Actions Std              0.203099
evaluation/Actions Max              0.995767
evaluation/Actions Min             -0.996218
evaluation/Num Paths               15
evaluation/Average Returns        -28.7372
time/data storing (s)               0.00317547
time/evaluation sampling (s)        0.360552
time/exploration sampling (s)       0.160988
time/logging (s)                    0.00476906
time/saving (s)                     0.00223475
time/training (s)                   2.13915
time/epoch (s)                      2.67087
time/total (s)                    182.024
Epoch                              66
-----------------------------  ---------------
2019-04-22 21:41:05.528778 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                    1.24782
trainer/QF2 Loss                    1.27292
trainer/Policy Loss                18.8031
trainer/Q1 Predictions Mean       -17.2324
trainer/Q1 Predictions Std         10.4399
trainer/Q1 Predictions Max        -10.1715
trainer/Q1 Predictions Min        -78.4027
trainer/Q2 Predictions Mean       -17.2065
trainer/Q2 Predictions Std         10.4419
trainer/Q2 Predictions Max        -10.1844
trainer/Q2 Predictions Min        -78.4761
trainer/Q Targets Mean            -17.3369
trainer/Q Targets Std              10.5156
trainer/Q Targets Max              -0.247156
trainer/Q Targets Min             -77.9928
trainer/Log Pis Mean                2.16931
trainer/Log Pis Std                 1.50723
trainer/Log Pis Max                 7.84941
trainer/Log Pis Min                -2.69539
trainer/Policy mu Mean             -0.00394367
trainer/Policy mu Std               0.841349
trainer/Policy mu Max               3.06825
trainer/Policy mu Min              -3.18164
trainer/Policy log std Mean        -1.96289
trainer/Policy log std Std          0.520624
trainer/Policy log std Max         -0.440881
trainer/Policy log std Min         -2.62829
trainer/Alpha                       0.0668456
trainer/Alpha Loss                  0.458063
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.300561
exploration/Rewards Std             0.771523
exploration/Rewards Max            -0.00781078
exploration/Rewards Min            -7.67963
exploration/Returns Mean          -30.0561
exploration/Returns Std             8.86107
exploration/Returns Max           -18.7013
exploration/Returns Min           -41.996
exploration/Actions Mean           -0.0043086
exploration/Actions Std             0.219413
exploration/Actions Max             0.995157
exploration/Actions Min            -0.997755
exploration/Num Paths               5
exploration/Average Returns       -30.0561
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244835
evaluation/Rewards Std              0.840622
evaluation/Rewards Max             -0.0380397
evaluation/Rewards Min             -8.82681
evaluation/Returns Mean           -24.4835
evaluation/Returns Std             13.1169
evaluation/Returns Max             -5.87128
evaluation/Returns Min            -57.0131
evaluation/Actions Mean             0.00875303
evaluation/Actions Std              0.185683
evaluation/Actions Max              0.995744
evaluation/Actions Min             -0.995856
evaluation/Num Paths               15
evaluation/Average Returns        -24.4835
time/data storing (s)               0.00320062
time/evaluation sampling (s)        0.359421
time/exploration sampling (s)       0.1602
time/logging (s)                    0.00489842
time/saving (s)                     0.0020701
time/training (s)                   2.1462
time/epoch (s)                      2.67599
time/total (s)                    184.705
Epoch                              67
-----------------------------  ---------------
2019-04-22 21:41:08.255889 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                    0.381655
trainer/QF2 Loss                    0.351697
trainer/Policy Loss                19.0232
trainer/Q1 Predictions Mean       -17.3651
trainer/Q1 Predictions Std         10.8833
trainer/Q1 Predictions Max         -9.83204
trainer/Q1 Predictions Min        -74.0261
trainer/Q2 Predictions Mean       -17.3811
trainer/Q2 Predictions Std         10.9069
trainer/Q2 Predictions Max         -9.85635
trainer/Q2 Predictions Min        -73.9591
trainer/Q Targets Mean            -17.6531
trainer/Q Targets Std              11.1226
trainer/Q Targets Max             -10.091
trainer/Q Targets Min             -77.7203
trainer/Log Pis Mean                2.07373
trainer/Log Pis Std                 1.46259
trainer/Log Pis Max                 7.74219
trainer/Log Pis Min                -3.14486
trainer/Policy mu Mean              0.0297989
trainer/Policy mu Std               0.906918
trainer/Policy mu Max               3.27754
trainer/Policy mu Min              -3.22358
trainer/Policy log std Mean        -1.94319
trainer/Policy log std Std          0.57243
trainer/Policy log std Max         -0.381584
trainer/Policy log std Min         -2.56993
trainer/Alpha                       0.0676169
trainer/Alpha Loss                  0.198638
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.426611
exploration/Rewards Std             1.10974
exploration/Rewards Max            -0.010517
exploration/Rewards Min            -8.71769
exploration/Returns Mean          -42.6611
exploration/Returns Std            19.9572
exploration/Returns Max           -11.9266
exploration/Returns Min           -68.7015
exploration/Actions Mean           -0.0248188
exploration/Actions Std             0.240372
exploration/Actions Max             0.995981
exploration/Actions Min            -0.998588
exploration/Num Paths               5
exploration/Average Returns       -42.6611
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.214308
evaluation/Rewards Std              0.7281
evaluation/Rewards Max             -0.011
evaluation/Rewards Min             -7.79616
evaluation/Returns Mean           -21.4308
evaluation/Returns Std             13.7617
evaluation/Returns Max             -5.84544
evaluation/Returns Min            -55.9097
evaluation/Actions Mean            -0.00766711
evaluation/Actions Std              0.164004
evaluation/Actions Max              0.994499
evaluation/Actions Min             -0.994316
evaluation/Num Paths               15
evaluation/Average Returns        -21.4308
time/data storing (s)               0.00314005
time/evaluation sampling (s)        0.408726
time/exploration sampling (s)       0.167145
time/logging (s)                    0.00529501
time/saving (s)                     0.00217984
time/training (s)                   2.1348
time/epoch (s)                      2.72129
time/total (s)                    187.43
Epoch                              68
-----------------------------  ---------------
2019-04-22 21:41:10.903840 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                    0.260466
trainer/QF2 Loss                    0.25183
trainer/Policy Loss                19.9629
trainer/Q1 Predictions Mean       -18.8429
trainer/Q1 Predictions Std         14.0736
trainer/Q1 Predictions Max         -9.73568
trainer/Q1 Predictions Min        -80.5178
trainer/Q2 Predictions Mean       -18.8792
trainer/Q2 Predictions Std         14.0892
trainer/Q2 Predictions Max         -9.78945
trainer/Q2 Predictions Min        -80.5371
trainer/Q Targets Mean            -18.9682
trainer/Q Targets Std              14.149
trainer/Q Targets Max             -10.0039
trainer/Q Targets Min             -78.2892
trainer/Log Pis Mean                2.11089
trainer/Log Pis Std                 1.37429
trainer/Log Pis Max                 8.30018
trainer/Log Pis Min                -1.57475
trainer/Policy mu Mean             -0.221399
trainer/Policy mu Std               0.920684
trainer/Policy mu Max               2.78262
trainer/Policy mu Min              -3.21671
trainer/Policy log std Mean        -1.86029
trainer/Policy log std Std          0.596277
trainer/Policy log std Max         -0.344375
trainer/Policy log std Min         -2.63067
trainer/Alpha                       0.0690028
trainer/Alpha Loss                  0.296456
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.419357
exploration/Rewards Std             1.18467
exploration/Rewards Max            -0.00858266
exploration/Rewards Min           -10.7212
exploration/Returns Mean          -41.9357
exploration/Returns Std            14.7601
exploration/Returns Max           -24.8116
exploration/Returns Min           -66.6849
exploration/Actions Mean            0.00964909
exploration/Actions Std             0.258067
exploration/Actions Max             0.999493
exploration/Actions Min            -0.9961
exploration/Num Paths               5
exploration/Average Returns       -41.9357
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.215892
evaluation/Rewards Std              0.80856
evaluation/Rewards Max             -0.00505923
evaluation/Rewards Min             -9.14789
evaluation/Returns Mean           -21.5892
evaluation/Returns Std             15.6015
evaluation/Returns Max             -1.54659
evaluation/Returns Min            -55.21
evaluation/Actions Mean             0.00390605
evaluation/Actions Std              0.158059
evaluation/Actions Max              0.998195
evaluation/Actions Min             -0.993871
evaluation/Num Paths               15
evaluation/Average Returns        -21.5892
time/data storing (s)               0.00431916
time/evaluation sampling (s)        0.359974
time/exploration sampling (s)       0.164785
time/logging (s)                    0.00538245
time/saving (s)                     0.00159524
time/training (s)                   2.10586
time/epoch (s)                      2.64192
time/total (s)                    190.077
Epoch                              69
-----------------------------  ---------------
2019-04-22 21:41:13.614727 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 70 finished
-----------------------------  ---------------
replay_buffer/size              35700
trainer/QF1 Loss                    4.14412
trainer/QF2 Loss                    4.13115
trainer/Policy Loss                15.3296
trainer/Q1 Predictions Mean       -13.8561
trainer/Q1 Predictions Std          6.30648
trainer/Q1 Predictions Max         -9.60508
trainer/Q1 Predictions Min        -45.9676
trainer/Q2 Predictions Mean       -13.8573
trainer/Q2 Predictions Std          6.30746
trainer/Q2 Predictions Max         -9.62748
trainer/Q2 Predictions Min        -46.0746
trainer/Q Targets Mean            -13.8937
trainer/Q Targets Std               6.42864
trainer/Q Targets Max              -0.457365
trainer/Q Targets Min             -46.8324
trainer/Log Pis Mean                1.82505
trainer/Log Pis Std                 1.11583
trainer/Log Pis Max                 6.04153
trainer/Log Pis Min                -1.16258
trainer/Policy mu Mean             -0.0416335
trainer/Policy mu Std               0.621504
trainer/Policy mu Max               2.92627
trainer/Policy mu Min              -2.75157
trainer/Policy log std Mean        -2.05638
trainer/Policy log std Std          0.447164
trainer/Policy log std Max         -0.424068
trainer/Policy log std Min         -2.58335
trainer/Alpha                       0.0674868
trainer/Alpha Loss                 -0.471595
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.379936
exploration/Rewards Std             1.07968
exploration/Rewards Max            -0.0038707
exploration/Rewards Min            -8.52868
exploration/Returns Mean          -37.9936
exploration/Returns Std            12.4758
exploration/Returns Max           -15.7696
exploration/Returns Min           -49.6493
exploration/Actions Mean           -0.0171321
exploration/Actions Std             0.249486
exploration/Actions Max             0.996793
exploration/Actions Min            -0.998935
exploration/Num Paths               5
exploration/Average Returns       -37.9936
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237796
evaluation/Rewards Std              0.920202
evaluation/Rewards Max             -0.0340495
evaluation/Rewards Min            -10.1243
evaluation/Returns Mean           -23.7796
evaluation/Returns Std             14.4134
evaluation/Returns Max             -4.61142
evaluation/Returns Min            -61.0677
evaluation/Actions Mean             0.00396169
evaluation/Actions Std              0.189975
evaluation/Actions Max              0.998963
evaluation/Actions Min             -0.995369
evaluation/Num Paths               15
evaluation/Average Returns        -23.7796
time/data storing (s)               0.00345145
time/evaluation sampling (s)        0.350173
time/exploration sampling (s)       0.157138
time/logging (s)                    0.00495472
time/saving (s)                     0.00219259
time/training (s)                   2.18594
time/epoch (s)                      2.70385
time/total (s)                    192.785
Epoch                              70
-----------------------------  ---------------
2019-04-22 21:41:16.359609 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                    9.54422
trainer/QF2 Loss                    9.6131
trainer/Policy Loss                17.6526
trainer/Q1 Predictions Mean       -16.18
trainer/Q1 Predictions Std          9.33906
trainer/Q1 Predictions Max         -9.59899
trainer/Q1 Predictions Min        -69.8093
trainer/Q2 Predictions Mean       -16.1803
trainer/Q2 Predictions Std          9.3561
trainer/Q2 Predictions Max         -9.61165
trainer/Q2 Predictions Min        -69.7282
trainer/Q Targets Mean            -16.0373
trainer/Q Targets Std               9.95074
trainer/Q Targets Max              -0.118359
trainer/Q Targets Min             -74.6524
trainer/Log Pis Mean                2.0863
trainer/Log Pis Std                 1.59428
trainer/Log Pis Max                 6.89022
trainer/Log Pis Min                -4.21045
trainer/Policy mu Mean              0.0483151
trainer/Policy mu Std               0.92342
trainer/Policy mu Max               2.98104
trainer/Policy mu Min              -3.25432
trainer/Policy log std Mean        -1.92793
trainer/Policy log std Std          0.59244
trainer/Policy log std Max         -0.416984
trainer/Policy log std Min         -2.62127
trainer/Alpha                       0.0669109
trainer/Alpha Loss                  0.233393
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.352564
exploration/Rewards Std             0.935576
exploration/Rewards Max            -0.00367777
exploration/Rewards Min            -7.54239
exploration/Returns Mean          -35.2564
exploration/Returns Std            12.6871
exploration/Returns Max           -21.2462
exploration/Returns Min           -51.3298
exploration/Actions Mean           -0.0131364
exploration/Actions Std             0.230741
exploration/Actions Max             0.998379
exploration/Actions Min            -0.998008
exploration/Num Paths               5
exploration/Average Returns       -35.2564
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238526
evaluation/Rewards Std              0.857301
evaluation/Rewards Max             -0.0200514
evaluation/Rewards Min             -8.66755
evaluation/Returns Mean           -23.8526
evaluation/Returns Std             13.5511
evaluation/Returns Max             -4.15043
evaluation/Returns Min            -52.8995
evaluation/Actions Mean            -0.00361957
evaluation/Actions Std              0.179341
evaluation/Actions Max              0.99511
evaluation/Actions Min             -0.996613
evaluation/Num Paths               15
evaluation/Average Returns        -23.8526
time/data storing (s)               0.00321251
time/evaluation sampling (s)        0.361313
time/exploration sampling (s)       0.166563
time/logging (s)                    0.00507093
time/saving (s)                     0.00212746
time/training (s)                   2.20033
time/epoch (s)                      2.73862
time/total (s)                    195.529
Epoch                              71
-----------------------------  ---------------
2019-04-22 21:41:19.391000 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                    0.20496
trainer/QF2 Loss                    0.209204
trainer/Policy Loss                17.8086
trainer/Q1 Predictions Mean       -16.4748
trainer/Q1 Predictions Std          9.35023
trainer/Q1 Predictions Max         -9.49742
trainer/Q1 Predictions Min        -64.8765
trainer/Q2 Predictions Mean       -16.4654
trainer/Q2 Predictions Std          9.374
trainer/Q2 Predictions Max         -9.55782
trainer/Q2 Predictions Min        -64.5751
trainer/Q Targets Mean            -16.5496
trainer/Q Targets Std               9.387
trainer/Q Targets Max              -9.61096
trainer/Q Targets Min             -66.6359
trainer/Log Pis Mean                1.98293
trainer/Log Pis Std                 1.42261
trainer/Log Pis Max                 7.03854
trainer/Log Pis Min                -3.70584
trainer/Policy mu Mean              0.00274477
trainer/Policy mu Std               0.829932
trainer/Policy mu Max               3.33708
trainer/Policy mu Min              -2.88209
trainer/Policy log std Mean        -1.96748
trainer/Policy log std Std          0.507252
trainer/Policy log std Max         -0.37415
trainer/Policy log std Min         -2.56381
trainer/Alpha                       0.0650795
trainer/Alpha Loss                 -0.0466366
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.216433
exploration/Rewards Std             0.454251
exploration/Rewards Max            -0.0112944
exploration/Rewards Min            -5.52274
exploration/Returns Mean          -21.6433
exploration/Returns Std             7.85506
exploration/Returns Max           -12.1703
exploration/Returns Min           -31.8939
exploration/Actions Mean            0.00580206
exploration/Actions Std             0.183672
exploration/Actions Max             0.989822
exploration/Actions Min            -0.997666
exploration/Num Paths               5
exploration/Average Returns       -21.6433
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245044
evaluation/Rewards Std              0.768641
evaluation/Rewards Max             -0.0472671
evaluation/Rewards Min             -8.21882
evaluation/Returns Mean           -24.5044
evaluation/Returns Std              9.89863
evaluation/Returns Max             -9.12365
evaluation/Returns Min            -45.3616
evaluation/Actions Mean             0.00729662
evaluation/Actions Std              0.173447
evaluation/Actions Max              0.997589
evaluation/Actions Min             -0.995564
evaluation/Num Paths               15
evaluation/Average Returns        -24.5044
time/data storing (s)               0.00360649
time/evaluation sampling (s)        0.380421
time/exploration sampling (s)       0.175775
time/logging (s)                    0.00534214
time/saving (s)                     0.00263381
time/training (s)                   2.45658
time/epoch (s)                      3.02435
time/total (s)                    198.558
Epoch                              72
-----------------------------  ---------------
2019-04-22 21:41:22.174587 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    1.21109
trainer/QF2 Loss                    1.20925
trainer/Policy Loss                16.0884
trainer/Q1 Predictions Mean       -14.271
trainer/Q1 Predictions Std          6.70629
trainer/Q1 Predictions Max         -9.54278
trainer/Q1 Predictions Min        -44.8823
trainer/Q2 Predictions Mean       -14.2685
trainer/Q2 Predictions Std          6.78447
trainer/Q2 Predictions Max         -9.49199
trainer/Q2 Predictions Min        -45.6097
trainer/Q Targets Mean            -14.2793
trainer/Q Targets Std               6.96076
trainer/Q Targets Max              -0.132552
trainer/Q Targets Min             -45.3051
trainer/Log Pis Mean                2.17521
trainer/Log Pis Std                 1.24342
trainer/Log Pis Max                 7.33954
trainer/Log Pis Min                -1.00959
trainer/Policy mu Mean             -0.00382635
trainer/Policy mu Std               0.839933
trainer/Policy mu Max               2.87343
trainer/Policy mu Min              -3.06705
trainer/Policy log std Mean        -1.99052
trainer/Policy log std Std          0.546026
trainer/Policy log std Max         -0.394383
trainer/Policy log std Min         -2.55616
trainer/Alpha                       0.0652842
trainer/Alpha Loss                  0.478171
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351419
exploration/Rewards Std             1.00905
exploration/Rewards Max            -0.00892675
exploration/Rewards Min            -9.45865
exploration/Returns Mean          -35.1419
exploration/Returns Std            18.4039
exploration/Returns Max           -17.4686
exploration/Returns Min           -68.6743
exploration/Actions Mean           -0.00740584
exploration/Actions Std             0.229758
exploration/Actions Max             0.999389
exploration/Actions Min            -0.997715
exploration/Num Paths               5
exploration/Average Returns       -35.1419
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.269407
evaluation/Rewards Std              1.07559
evaluation/Rewards Max             -0.0380008
evaluation/Rewards Min            -10.5768
evaluation/Returns Mean           -26.9407
evaluation/Returns Std             17.4122
evaluation/Returns Max             -5.60136
evaluation/Returns Min            -60.7226
evaluation/Actions Mean             0.0136045
evaluation/Actions Std              0.196786
evaluation/Actions Max              0.999089
evaluation/Actions Min             -0.996359
evaluation/Num Paths               15
evaluation/Average Returns        -26.9407
time/data storing (s)               0.00347055
time/evaluation sampling (s)        0.395779
time/exploration sampling (s)       0.183906
time/logging (s)                    0.00515728
time/saving (s)                     0.00205732
time/training (s)                   2.18577
time/epoch (s)                      2.77614
time/total (s)                    201.34
Epoch                              73
-----------------------------  ---------------
2019-04-22 21:41:24.921843 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size              37700
trainer/QF1 Loss                    3.75906
trainer/QF2 Loss                    3.76042
trainer/Policy Loss                17.2212
trainer/Q1 Predictions Mean       -15.8069
trainer/Q1 Predictions Std         10.1143
trainer/Q1 Predictions Max         -9.17183
trainer/Q1 Predictions Min        -67.9247
trainer/Q2 Predictions Mean       -15.8291
trainer/Q2 Predictions Std         10.1308
trainer/Q2 Predictions Max         -9.17802
trainer/Q2 Predictions Min        -67.7999
trainer/Q Targets Mean            -15.8104
trainer/Q Targets Std              10.3164
trainer/Q Targets Max              -0.818948
trainer/Q Targets Min             -69.5144
trainer/Log Pis Mean                1.99602
trainer/Log Pis Std                 1.28264
trainer/Log Pis Max                 5.96043
trainer/Log Pis Min                -1.32226
trainer/Policy mu Mean             -0.0730292
trainer/Policy mu Std               0.794552
trainer/Policy mu Max               3.66492
trainer/Policy mu Min              -2.76719
trainer/Policy log std Mean        -1.99772
trainer/Policy log std Std          0.52631
trainer/Policy log std Max         -0.185387
trainer/Policy log std Min         -2.60041
trainer/Alpha                       0.0664314
trainer/Alpha Loss                 -0.0108062
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.368205
exploration/Rewards Std             1.18141
exploration/Rewards Max            -0.00981006
exploration/Rewards Min           -10.4414
exploration/Returns Mean          -36.8205
exploration/Returns Std            18.6115
exploration/Returns Max           -12.4481
exploration/Returns Min           -57.9684
exploration/Actions Mean           -0.0215761
exploration/Actions Std             0.231608
exploration/Actions Max             0.996288
exploration/Actions Min            -0.997624
exploration/Num Paths               5
exploration/Average Returns       -36.8205
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.230424
evaluation/Rewards Std              0.97742
evaluation/Rewards Max             -0.0121082
evaluation/Rewards Min            -10.5304
evaluation/Returns Mean           -23.0424
evaluation/Returns Std             18.1697
evaluation/Returns Max             -3.75167
evaluation/Returns Min            -60.376
evaluation/Actions Mean             0.0263154
evaluation/Actions Std              0.180172
evaluation/Actions Max              0.9986
evaluation/Actions Min             -0.991028
evaluation/Num Paths               15
evaluation/Average Returns        -23.0424
time/data storing (s)               0.00328164
time/evaluation sampling (s)        0.371653
time/exploration sampling (s)       0.171276
time/logging (s)                    0.00485655
time/saving (s)                     0.00196747
time/training (s)                   2.18704
time/epoch (s)                      2.74007
time/total (s)                    204.085
Epoch                              74
-----------------------------  ---------------
2019-04-22 21:41:27.616672 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    0.180722
trainer/QF2 Loss                    0.140498
trainer/Policy Loss                15.4195
trainer/Q1 Predictions Mean       -14.2404
trainer/Q1 Predictions Std          7.7296
trainer/Q1 Predictions Max         -9.33056
trainer/Q1 Predictions Min        -59.8996
trainer/Q2 Predictions Mean       -14.2437
trainer/Q2 Predictions Std          7.77629
trainer/Q2 Predictions Max         -9.36954
trainer/Q2 Predictions Min        -59.8391
trainer/Q Targets Mean            -14.3473
trainer/Q Targets Std               8.02811
trainer/Q Targets Max              -9.17647
trainer/Q Targets Min             -61.173
trainer/Log Pis Mean                1.60273
trainer/Log Pis Std                 1.56609
trainer/Log Pis Max                 7.58482
trainer/Log Pis Min                -3.24496
trainer/Policy mu Mean              0.102489
trainer/Policy mu Std               0.725251
trainer/Policy mu Max               2.94809
trainer/Policy mu Min              -2.73797
trainer/Policy log std Mean        -1.94383
trainer/Policy log std Std          0.485442
trainer/Policy log std Max         -0.373521
trainer/Policy log std Min         -2.60181
trainer/Alpha                       0.0672531
trainer/Alpha Loss                 -1.07227
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.34162
exploration/Rewards Std             1.03486
exploration/Rewards Max            -0.00708143
exploration/Rewards Min            -8.83887
exploration/Returns Mean          -34.162
exploration/Returns Std            14.3318
exploration/Returns Max           -14.5227
exploration/Returns Min           -48.7629
exploration/Actions Mean           -0.0158243
exploration/Actions Std             0.239794
exploration/Actions Max             0.997898
exploration/Actions Min            -0.994683
exploration/Num Paths               5
exploration/Average Returns       -34.162
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.251423
evaluation/Rewards Std              1.04935
evaluation/Rewards Max             -0.0276827
evaluation/Rewards Min            -10.2441
evaluation/Returns Mean           -25.1423
evaluation/Returns Std             18.5684
evaluation/Returns Max             -4.62134
evaluation/Returns Min            -62.6087
evaluation/Actions Mean             0.00110062
evaluation/Actions Std              0.187013
evaluation/Actions Max              0.999161
evaluation/Actions Min             -0.99759
evaluation/Num Paths               15
evaluation/Average Returns        -25.1423
time/data storing (s)               0.00329144
time/evaluation sampling (s)        0.361781
time/exploration sampling (s)       0.165387
time/logging (s)                    0.0044124
time/saving (s)                     0.00200469
time/training (s)                   2.15119
time/epoch (s)                      2.68807
time/total (s)                    206.777
Epoch                              75
-----------------------------  ---------------
2019-04-22 21:41:30.396223 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 76 finished
-----------------------------  ----------------
replay_buffer/size              38700
trainer/QF1 Loss                    1.40617
trainer/QF2 Loss                    1.42413
trainer/Policy Loss                17.6814
trainer/Q1 Predictions Mean       -16.2845
trainer/Q1 Predictions Std         11.2192
trainer/Q1 Predictions Max         -8.93803
trainer/Q1 Predictions Min        -79.5945
trainer/Q2 Predictions Mean       -16.2826
trainer/Q2 Predictions Std         11.2354
trainer/Q2 Predictions Max         -8.95911
trainer/Q2 Predictions Min        -79.7048
trainer/Q Targets Mean            -16.2708
trainer/Q Targets Std              10.8944
trainer/Q Targets Max              -0.20118
trainer/Q Targets Min             -75.5037
trainer/Log Pis Mean                2.02781
trainer/Log Pis Std                 1.31261
trainer/Log Pis Max                 5.6221
trainer/Log Pis Min                -2.6627
trainer/Policy mu Mean             -0.0955967
trainer/Policy mu Std               0.883896
trainer/Policy mu Max               3.02711
trainer/Policy mu Min              -3.29102
trainer/Policy log std Mean        -1.98048
trainer/Policy log std Std          0.582364
trainer/Policy log std Max         -0.386063
trainer/Policy log std Min         -2.65799
trainer/Alpha                       0.0689473
trainer/Alpha Loss                  0.0743894
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.365464
exploration/Rewards Std             1.02241
exploration/Rewards Max            -0.00700065
exploration/Rewards Min            -9.89541
exploration/Returns Mean          -36.5464
exploration/Returns Std            17.5082
exploration/Returns Max           -19.488
exploration/Returns Min           -67.6436
exploration/Actions Mean           -0.0155316
exploration/Actions Std             0.228684
exploration/Actions Max             0.998755
exploration/Actions Min            -0.996053
exploration/Num Paths               5
exploration/Average Returns       -36.5464
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225066
evaluation/Rewards Std              0.79283
evaluation/Rewards Max             -0.0598163
evaluation/Rewards Min             -7.84646
evaluation/Returns Mean           -22.5066
evaluation/Returns Std             13.4975
evaluation/Returns Max             -7.87286
evaluation/Returns Min            -43.9792
evaluation/Actions Mean             0.000640508
evaluation/Actions Std              0.166511
evaluation/Actions Max              0.992855
evaluation/Actions Min             -0.995678
evaluation/Num Paths               15
evaluation/Average Returns        -22.5066
time/data storing (s)               0.00312218
time/evaluation sampling (s)        0.372078
time/exploration sampling (s)       0.166298
time/logging (s)                    0.00532521
time/saving (s)                     0.00229529
time/training (s)                   2.22595
time/epoch (s)                      2.77507
time/total (s)                    209.556
Epoch                              76
-----------------------------  ----------------
2019-04-22 21:41:33.030992 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    2.66808
trainer/QF2 Loss                    2.65238
trainer/Policy Loss                16.5129
trainer/Q1 Predictions Mean       -14.8679
trainer/Q1 Predictions Std          7.96584
trainer/Q1 Predictions Max         -8.88906
trainer/Q1 Predictions Min        -47.2838
trainer/Q2 Predictions Mean       -14.8561
trainer/Q2 Predictions Std          7.95018
trainer/Q2 Predictions Max         -8.87263
trainer/Q2 Predictions Min        -47.2666
trainer/Q Targets Mean            -14.7867
trainer/Q Targets Std               8.39215
trainer/Q Targets Max              -0.0952628
trainer/Q Targets Min             -49.4626
trainer/Log Pis Mean                2.06055
trainer/Log Pis Std                 1.36958
trainer/Log Pis Max                 7.13631
trainer/Log Pis Min                -1.02505
trainer/Policy mu Mean             -0.0466584
trainer/Policy mu Std               0.876921
trainer/Policy mu Max               3.20095
trainer/Policy mu Min              -2.80211
trainer/Policy log std Mean        -1.94017
trainer/Policy log std Std          0.545715
trainer/Policy log std Max         -0.360806
trainer/Policy log std Min         -2.63706
trainer/Alpha                       0.0687927
trainer/Alpha Loss                  0.162069
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.228694
exploration/Rewards Std             0.496395
exploration/Rewards Max            -0.00923749
exploration/Rewards Min            -6.29742
exploration/Returns Mean          -22.8694
exploration/Returns Std             6.08078
exploration/Returns Max           -15.8983
exploration/Returns Min           -30.904
exploration/Actions Mean            0.0168635
exploration/Actions Std             0.20412
exploration/Actions Max             0.985381
exploration/Actions Min            -0.988898
exploration/Num Paths               5
exploration/Average Returns       -22.8694
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.383091
evaluation/Rewards Std              1.18687
evaluation/Rewards Max             -0.0816366
evaluation/Rewards Min             -9.76431
evaluation/Returns Mean           -38.3091
evaluation/Returns Std             15.5148
evaluation/Returns Max            -12.346
evaluation/Returns Min            -60.4969
evaluation/Actions Mean            -0.0013542
evaluation/Actions Std              0.217653
evaluation/Actions Max              0.996331
evaluation/Actions Min             -0.995996
evaluation/Num Paths               15
evaluation/Average Returns        -38.3091
time/data storing (s)               0.00339443
time/evaluation sampling (s)        0.363891
time/exploration sampling (s)       0.165532
time/logging (s)                    0.0047463
time/saving (s)                     0.00209758
time/training (s)                   2.08819
time/epoch (s)                      2.62785
time/total (s)                    212.189
Epoch                              77
-----------------------------  ---------------
2019-04-22 21:41:35.683266 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 78 finished
-----------------------------  ----------------
replay_buffer/size              39700
trainer/QF1 Loss                    0.834582
trainer/QF2 Loss                    0.836724
trainer/Policy Loss                14.7834
trainer/Q1 Predictions Mean       -13.1676
trainer/Q1 Predictions Std          6.04952
trainer/Q1 Predictions Max         -8.80807
trainer/Q1 Predictions Min        -56.0543
trainer/Q2 Predictions Mean       -13.1504
trainer/Q2 Predictions Std          6.03837
trainer/Q2 Predictions Max         -8.79257
trainer/Q2 Predictions Min        -55.991
trainer/Q Targets Mean            -13.2052
trainer/Q Targets Std               6.18268
trainer/Q Targets Max              -0.0762479
trainer/Q Targets Min             -56.4668
trainer/Log Pis Mean                2.03809
trainer/Log Pis Std                 1.13922
trainer/Log Pis Max                 6.9814
trainer/Log Pis Min                -2.23995
trainer/Policy mu Mean             -0.0498627
trainer/Policy mu Std               0.619838
trainer/Policy mu Max               2.92897
trainer/Policy mu Min              -2.70238
trainer/Policy log std Mean        -2.0617
trainer/Policy log std Std          0.432107
trainer/Policy log std Max         -0.58256
trainer/Policy log std Min         -2.74104
trainer/Alpha                       0.0685808
trainer/Alpha Loss                  0.102083
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.397879
exploration/Rewards Std             1.16093
exploration/Rewards Max            -0.0101933
exploration/Rewards Min           -10.3432
exploration/Returns Mean          -39.7879
exploration/Returns Std            14.2816
exploration/Returns Max           -16.3803
exploration/Returns Min           -58.4853
exploration/Actions Mean            0.000800594
exploration/Actions Std             0.261788
exploration/Actions Max             0.99807
exploration/Actions Min            -0.998319
exploration/Num Paths               5
exploration/Average Returns       -39.7879
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199866
evaluation/Rewards Std              0.88681
evaluation/Rewards Max             -0.0159283
evaluation/Rewards Min             -9.44331
evaluation/Returns Mean           -19.9866
evaluation/Returns Std             16.0126
evaluation/Returns Max             -1.63276
evaluation/Returns Min            -50.314
evaluation/Actions Mean            -0.00100444
evaluation/Actions Std              0.176596
evaluation/Actions Max              0.9951
evaluation/Actions Min             -0.995728
evaluation/Num Paths               15
evaluation/Average Returns        -19.9866
time/data storing (s)               0.00315182
time/evaluation sampling (s)        0.352521
time/exploration sampling (s)       0.162923
time/logging (s)                    0.0055465
time/saving (s)                     0.00254771
time/training (s)                   2.12003
time/epoch (s)                      2.64672
time/total (s)                    214.84
Epoch                              78
-----------------------------  ----------------
2019-04-22 21:41:38.371195 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    2.93382
trainer/QF2 Loss                    2.95838
trainer/Policy Loss                15.0504
trainer/Q1 Predictions Mean       -13.8645
trainer/Q1 Predictions Std          5.0762
trainer/Q1 Predictions Max         -8.85934
trainer/Q1 Predictions Min        -32.9519
trainer/Q2 Predictions Mean       -13.8618
trainer/Q2 Predictions Std          5.07266
trainer/Q2 Predictions Max         -8.89471
trainer/Q2 Predictions Min        -33.1452
trainer/Q Targets Mean            -13.6689
trainer/Q Targets Std               5.06841
trainer/Q Targets Max              -0.227945
trainer/Q Targets Min             -31.2546
trainer/Log Pis Mean                1.74876
trainer/Log Pis Std                 1.16806
trainer/Log Pis Max                 5.67819
trainer/Log Pis Min                -1.52501
trainer/Policy mu Mean             -0.0723532
trainer/Policy mu Std               0.654152
trainer/Policy mu Max               2.93352
trainer/Policy mu Min              -2.62474
trainer/Policy log std Mean        -2.06988
trainer/Policy log std Std          0.483961
trainer/Policy log std Max         -0.451138
trainer/Policy log std Min         -2.70351
trainer/Alpha                       0.0670153
trainer/Alpha Loss                 -0.679033
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.271264
exploration/Rewards Std             0.793582
exploration/Rewards Max            -0.00126172
exploration/Rewards Min            -8.82979
exploration/Returns Mean          -27.1264
exploration/Returns Std            17.7447
exploration/Returns Max           -14.1172
exploration/Returns Min           -62.0884
exploration/Actions Mean            0.0172275
exploration/Actions Std             0.218787
exploration/Actions Max             0.998512
exploration/Actions Min            -0.989111
exploration/Num Paths               5
exploration/Average Returns       -27.1264
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.166874
evaluation/Rewards Std              0.789752
evaluation/Rewards Max             -0.00698599
evaluation/Rewards Min             -9.63968
evaluation/Returns Mean           -16.6874
evaluation/Returns Std             13.2632
evaluation/Returns Max             -2.08526
evaluation/Returns Min            -44.8055
evaluation/Actions Mean            -0.0197719
evaluation/Actions Std              0.171738
evaluation/Actions Max              0.988821
evaluation/Actions Min             -0.99393
evaluation/Num Paths               15
evaluation/Average Returns        -16.6874
time/data storing (s)               0.00323191
time/evaluation sampling (s)        0.385817
time/exploration sampling (s)       0.158478
time/logging (s)                    0.00536237
time/saving (s)                     0.00226655
time/training (s)                   2.12569
time/epoch (s)                      2.68084
time/total (s)                    217.525
Epoch                              79
-----------------------------  ---------------
2019-04-22 21:41:41.057717 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size              40700
trainer/QF1 Loss                    1.88936
trainer/QF2 Loss                    1.90797
trainer/Policy Loss                15.1895
trainer/Q1 Predictions Mean       -13.8984
trainer/Q1 Predictions Std          8.72288
trainer/Q1 Predictions Max         -8.9033
trainer/Q1 Predictions Min        -72.27
trainer/Q2 Predictions Mean       -13.8811
trainer/Q2 Predictions Std          8.68206
trainer/Q2 Predictions Max         -8.92917
trainer/Q2 Predictions Min        -72.0312
trainer/Q Targets Mean            -13.8205
trainer/Q Targets Std               9.13058
trainer/Q Targets Max              -0.12942
trainer/Q Targets Min             -75.1478
trainer/Log Pis Mean                1.79393
trainer/Log Pis Std                 1.27917
trainer/Log Pis Max                 7.38701
trainer/Log Pis Min                -3.35744
trainer/Policy mu Mean             -0.0606695
trainer/Policy mu Std               0.709867
trainer/Policy mu Max               3.61997
trainer/Policy mu Min              -2.89776
trainer/Policy log std Mean        -2.06234
trainer/Policy log std Std          0.471379
trainer/Policy log std Max         -0.376918
trainer/Policy log std Min         -2.58965
trainer/Alpha                       0.0680086
trainer/Alpha Loss                 -0.553968
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.264239
exploration/Rewards Std             0.677397
exploration/Rewards Max            -0.00540941
exploration/Rewards Min            -5.86647
exploration/Returns Mean          -26.4239
exploration/Returns Std             3.66606
exploration/Returns Max           -20.7724
exploration/Returns Min           -31.3028
exploration/Actions Mean            0.00173578
exploration/Actions Std             0.219705
exploration/Actions Max             0.996888
exploration/Actions Min            -0.998367
exploration/Num Paths               5
exploration/Average Returns       -26.4239
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.252103
evaluation/Rewards Std              1.04431
evaluation/Rewards Max             -0.00310097
evaluation/Rewards Min            -10.5834
evaluation/Returns Mean           -25.2103
evaluation/Returns Std             16.1637
evaluation/Returns Max             -2.83478
evaluation/Returns Min            -57.7576
evaluation/Actions Mean             0.0048764
evaluation/Actions Std              0.194583
evaluation/Actions Max              0.999199
evaluation/Actions Min             -0.995286
evaluation/Num Paths               15
evaluation/Average Returns        -25.2103
time/data storing (s)               0.0031752
time/evaluation sampling (s)        0.359371
time/exploration sampling (s)       0.167757
time/logging (s)                    0.0049966
time/saving (s)                     0.00221874
time/training (s)                   2.14139
time/epoch (s)                      2.67891
time/total (s)                    220.209
Epoch                              80
-----------------------------  ---------------
2019-04-22 21:41:43.761940 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                    1.53346
trainer/QF2 Loss                    1.56728
trainer/Policy Loss                14.5183
trainer/Q1 Predictions Mean       -12.9934
trainer/Q1 Predictions Std          6.50514
trainer/Q1 Predictions Max         -8.6668
trainer/Q1 Predictions Min        -57.4689
trainer/Q2 Predictions Mean       -12.9661
trainer/Q2 Predictions Std          6.46769
trainer/Q2 Predictions Max         -8.66026
trainer/Q2 Predictions Min        -57.2105
trainer/Q Targets Mean            -12.9104
trainer/Q Targets Std               6.81456
trainer/Q Targets Max              -0.0956732
trainer/Q Targets Min             -59.2563
trainer/Log Pis Mean                1.88918
trainer/Log Pis Std                 1.12715
trainer/Log Pis Max                 5.39066
trainer/Log Pis Min                -1.72546
trainer/Policy mu Mean             -0.0189012
trainer/Policy mu Std               0.649721
trainer/Policy mu Max               3.16021
trainer/Policy mu Min              -3.19504
trainer/Policy log std Mean        -2.11392
trainer/Policy log std Std          0.462071
trainer/Policy log std Max         -0.527804
trainer/Policy log std Min         -2.68013
trainer/Alpha                       0.0686064
trainer/Alpha Loss                 -0.296936
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.322823
exploration/Rewards Std             1.029
exploration/Rewards Max            -0.003372
exploration/Rewards Min           -10.5599
exploration/Returns Mean          -32.2823
exploration/Returns Std            18.7318
exploration/Returns Max           -14.5215
exploration/Returns Min           -64.0895
exploration/Actions Mean            0.00234833
exploration/Actions Std             0.237241
exploration/Actions Max             0.999815
exploration/Actions Min            -0.997555
exploration/Num Paths               5
exploration/Average Returns       -32.2823
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.303012
evaluation/Rewards Std              1.18175
evaluation/Rewards Max             -0.0235605
evaluation/Rewards Min            -11.7015
evaluation/Returns Mean           -30.3012
evaluation/Returns Std             16.5979
evaluation/Returns Max             -6.63486
evaluation/Returns Min            -58.656
evaluation/Actions Mean             0.0040205
evaluation/Actions Std              0.215512
evaluation/Actions Max              0.998398
evaluation/Actions Min             -0.994976
evaluation/Num Paths               15
evaluation/Average Returns        -30.3012
time/data storing (s)               0.00341041
time/evaluation sampling (s)        0.364143
time/exploration sampling (s)       0.165923
time/logging (s)                    0.0050348
time/saving (s)                     0.00197764
time/training (s)                   2.15806
time/epoch (s)                      2.69855
time/total (s)                    222.912
Epoch                              81
-----------------------------  ---------------
2019-04-22 21:41:46.443450 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 82 finished
-----------------------------  ----------------
replay_buffer/size              41700
trainer/QF1 Loss                    0.091265
trainer/QF2 Loss                    0.0892106
trainer/Policy Loss                14.313
trainer/Q1 Predictions Mean       -12.5481
trainer/Q1 Predictions Std          4.66424
trainer/Q1 Predictions Max         -8.58518
trainer/Q1 Predictions Min        -36.6793
trainer/Q2 Predictions Mean       -12.5474
trainer/Q2 Predictions Std          4.68065
trainer/Q2 Predictions Max         -8.57179
trainer/Q2 Predictions Min        -36.7871
trainer/Q Targets Mean            -12.7606
trainer/Q Targets Std               4.70531
trainer/Q Targets Max              -8.6911
trainer/Q Targets Min             -36.755
trainer/Log Pis Mean                2.0694
trainer/Log Pis Std                 1.22265
trainer/Log Pis Max                 6.46902
trainer/Log Pis Min                -1.98268
trainer/Policy mu Mean             -0.104369
trainer/Policy mu Std               0.752542
trainer/Policy mu Max               2.58743
trainer/Policy mu Min              -2.88422
trainer/Policy log std Mean        -2.02685
trainer/Policy log std Std          0.547662
trainer/Policy log std Max         -0.445873
trainer/Policy log std Min         -2.7068
trainer/Alpha                       0.0687795
trainer/Alpha Loss                  0.185773
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.284632
exploration/Rewards Std             0.887245
exploration/Rewards Max            -0.00590931
exploration/Rewards Min           -10.2063
exploration/Returns Mean          -28.4632
exploration/Returns Std            20.2904
exploration/Returns Max           -12.6202
exploration/Returns Min           -67.5842
exploration/Actions Mean           -0.00409546
exploration/Actions Std             0.203078
exploration/Actions Max             0.999331
exploration/Actions Min            -0.985588
exploration/Num Paths               5
exploration/Average Returns       -28.4632
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.325427
evaluation/Rewards Std              1.12919
evaluation/Rewards Max             -0.0203205
evaluation/Rewards Min            -11.0772
evaluation/Returns Mean           -32.5427
evaluation/Returns Std             18.7234
evaluation/Returns Max             -5.77247
evaluation/Returns Min            -63.5863
evaluation/Actions Mean            -0.000420583
evaluation/Actions Std              0.199395
evaluation/Actions Max              0.997334
evaluation/Actions Min             -0.996294
evaluation/Num Paths               15
evaluation/Average Returns        -32.5427
time/data storing (s)               0.00317785
time/evaluation sampling (s)        0.358756
time/exploration sampling (s)       0.163071
time/logging (s)                    0.00504699
time/saving (s)                     0.00205793
time/training (s)                   2.14282
time/epoch (s)                      2.67493
time/total (s)                    225.591
Epoch                              82
-----------------------------  ----------------
2019-04-22 21:41:49.164235 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                    0.784965
trainer/QF2 Loss                    0.819623
trainer/Policy Loss                15.7925
trainer/Q1 Predictions Mean       -13.8842
trainer/Q1 Predictions Std          6.49144
trainer/Q1 Predictions Max         -8.69873
trainer/Q1 Predictions Min        -54.425
trainer/Q2 Predictions Mean       -13.918
trainer/Q2 Predictions Std          6.54128
trainer/Q2 Predictions Max         -8.70106
trainer/Q2 Predictions Min        -54.7764
trainer/Q Targets Mean            -13.7997
trainer/Q Targets Std               6.67172
trainer/Q Targets Max              -0.219052
trainer/Q Targets Min             -54.4696
trainer/Log Pis Mean                2.29313
trainer/Log Pis Std                 1.59126
trainer/Log Pis Max                 7.43963
trainer/Log Pis Min                -1.70184
trainer/Policy mu Mean              0.0665195
trainer/Policy mu Std               0.917807
trainer/Policy mu Max               2.97808
trainer/Policy mu Min              -2.57033
trainer/Policy log std Mean        -1.9701
trainer/Policy log std Std          0.611079
trainer/Policy log std Max         -0.22116
trainer/Policy log std Min         -2.61408
trainer/Alpha                       0.067292
trainer/Alpha Loss                  0.791077
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.442296
exploration/Rewards Std             1.28673
exploration/Rewards Max            -0.00709279
exploration/Rewards Min           -10.5716
exploration/Returns Mean          -44.2296
exploration/Returns Std            16.2094
exploration/Returns Max           -24.7618
exploration/Returns Min           -65.2486
exploration/Actions Mean            0.0334744
exploration/Actions Std             0.245649
exploration/Actions Max             0.999851
exploration/Actions Min            -0.998948
exploration/Num Paths               5
exploration/Average Returns       -44.2296
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30832
evaluation/Rewards Std              0.917153
evaluation/Rewards Max             -0.0332373
evaluation/Rewards Min             -9.41252
evaluation/Returns Mean           -30.832
evaluation/Returns Std             12.6582
evaluation/Returns Max            -12.7604
evaluation/Returns Min            -53.8887
evaluation/Actions Mean            -0.00223631
evaluation/Actions Std              0.192908
evaluation/Actions Max              0.996179
evaluation/Actions Min             -0.994824
evaluation/Num Paths               15
evaluation/Average Returns        -30.832
time/data storing (s)               0.0031567
time/evaluation sampling (s)        0.364608
time/exploration sampling (s)       0.166403
time/logging (s)                    0.00513153
time/saving (s)                     0.00223986
time/training (s)                   2.17267
time/epoch (s)                      2.71421
time/total (s)                    228.31
Epoch                              83
-----------------------------  ---------------
2019-04-22 21:41:51.854672 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                    0.137683
trainer/QF2 Loss                    0.124824
trainer/Policy Loss                14.8054
trainer/Q1 Predictions Mean       -13.1782
trainer/Q1 Predictions Std          7.37771
trainer/Q1 Predictions Max         -8.27131
trainer/Q1 Predictions Min        -59.3054
trainer/Q2 Predictions Mean       -13.1643
trainer/Q2 Predictions Std          7.36614
trainer/Q2 Predictions Max         -8.31024
trainer/Q2 Predictions Min        -59.1922
trainer/Q Targets Mean            -13.2079
trainer/Q Targets Std               7.43024
trainer/Q Targets Max              -8.5081
trainer/Q Targets Min             -60.6724
trainer/Log Pis Mean                2.07856
trainer/Log Pis Std                 1.41664
trainer/Log Pis Max                 8.4524
trainer/Log Pis Min                -1.83911
trainer/Policy mu Mean             -0.0142606
trainer/Policy mu Std               0.820807
trainer/Policy mu Max               3.23541
trainer/Policy mu Min              -2.77386
trainer/Policy log std Mean        -1.98814
trainer/Policy log std Std          0.532184
trainer/Policy log std Max         -0.476705
trainer/Policy log std Min         -2.57545
trainer/Alpha                       0.0659657
trainer/Alpha Loss                  0.21358
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.304853
exploration/Rewards Std             0.809771
exploration/Rewards Max            -0.00896371
exploration/Rewards Min            -8.09859
exploration/Returns Mean          -30.4853
exploration/Returns Std            10.8845
exploration/Returns Max           -14.6616
exploration/Returns Min           -45.971
exploration/Actions Mean            0.00437156
exploration/Actions Std             0.23734
exploration/Actions Max             0.999664
exploration/Actions Min            -0.997926
exploration/Num Paths               5
exploration/Average Returns       -30.4853
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.223534
evaluation/Rewards Std              0.801883
evaluation/Rewards Max             -0.0176118
evaluation/Rewards Min             -9.14484
evaluation/Returns Mean           -22.3534
evaluation/Returns Std             14.356
evaluation/Returns Max             -2.95228
evaluation/Returns Min            -50.2897
evaluation/Actions Mean            -0.0196656
evaluation/Actions Std              0.179599
evaluation/Actions Max              0.989749
evaluation/Actions Min             -0.995071
evaluation/Num Paths               15
evaluation/Average Returns        -22.3534
time/data storing (s)               0.00320723
time/evaluation sampling (s)        0.360282
time/exploration sampling (s)       0.160739
time/logging (s)                    0.00496777
time/saving (s)                     0.00191611
time/training (s)                   2.15293
time/epoch (s)                      2.68405
time/total (s)                    230.999
Epoch                              84
-----------------------------  ---------------
2019-04-22 21:41:54.564782 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                    2.08914
trainer/QF2 Loss                    2.07984
trainer/Policy Loss                13.8046
trainer/Q1 Predictions Mean       -12.1705
trainer/Q1 Predictions Std          4.04561
trainer/Q1 Predictions Max         -8.47429
trainer/Q1 Predictions Min        -36.0279
trainer/Q2 Predictions Mean       -12.1689
trainer/Q2 Predictions Std          4.03475
trainer/Q2 Predictions Max         -8.45547
trainer/Q2 Predictions Min        -35.9275
trainer/Q Targets Mean            -12.1229
trainer/Q Targets Std               4.23279
trainer/Q Targets Max              -0.228674
trainer/Q Targets Min             -36.7083
trainer/Log Pis Mean                1.95616
trainer/Log Pis Std                 1.12515
trainer/Log Pis Max                 6.32721
trainer/Log Pis Min                -2.82042
trainer/Policy mu Mean             -0.0356946
trainer/Policy mu Std               0.590711
trainer/Policy mu Max               2.73815
trainer/Policy mu Min              -2.68128
trainer/Policy log std Mean        -2.08733
trainer/Policy log std Std          0.425504
trainer/Policy log std Max         -0.42116
trainer/Policy log std Min         -2.52745
trainer/Alpha                       0.0662064
trainer/Alpha Loss                 -0.119034
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.420761
exploration/Rewards Std             1.22378
exploration/Rewards Max            -0.00508165
exploration/Rewards Min           -10.2827
exploration/Returns Mean          -42.0761
exploration/Returns Std            12.2288
exploration/Returns Max           -25.2247
exploration/Returns Min           -60.7055
exploration/Actions Mean           -0.0138092
exploration/Actions Std             0.257042
exploration/Actions Max             0.999438
exploration/Actions Min            -0.999277
exploration/Num Paths               5
exploration/Average Returns       -42.0761
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298106
evaluation/Rewards Std              1.21127
evaluation/Rewards Max             -0.0140995
evaluation/Rewards Min            -11.5618
evaluation/Returns Mean           -29.8106
evaluation/Returns Std             18.0439
evaluation/Returns Max             -4.36262
evaluation/Returns Min            -62.8363
evaluation/Actions Mean             0.0124956
evaluation/Actions Std              0.209504
evaluation/Actions Max              0.99899
evaluation/Actions Min             -0.993546
evaluation/Num Paths               15
evaluation/Average Returns        -29.8106
time/data storing (s)               0.00324387
time/evaluation sampling (s)        0.36755
time/exploration sampling (s)       0.168549
time/logging (s)                    0.00494933
time/saving (s)                     0.00199711
time/training (s)                   2.15674
time/epoch (s)                      2.70303
time/total (s)                    233.707
Epoch                              85
-----------------------------  ---------------
2019-04-22 21:41:57.304815 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size              43700
trainer/QF1 Loss                    0.771845
trainer/QF2 Loss                    0.778572
trainer/Policy Loss                14.1263
trainer/Q1 Predictions Mean       -12.6734
trainer/Q1 Predictions Std          6.04227
trainer/Q1 Predictions Max         -8.41407
trainer/Q1 Predictions Min        -50.0105
trainer/Q2 Predictions Mean       -12.6708
trainer/Q2 Predictions Std          6.03394
trainer/Q2 Predictions Max         -8.39082
trainer/Q2 Predictions Min        -49.4189
trainer/Q Targets Mean            -12.6502
trainer/Q Targets Std               6.16046
trainer/Q Targets Max              -0.157974
trainer/Q Targets Min             -50.8813
trainer/Log Pis Mean                1.96199
trainer/Log Pis Std                 1.43013
trainer/Log Pis Max                 6.80877
trainer/Log Pis Min                -3.12041
trainer/Policy mu Mean              0.00423157
trainer/Policy mu Std               0.760353
trainer/Policy mu Max               3.10959
trainer/Policy mu Min              -2.75744
trainer/Policy log std Mean        -2.02121
trainer/Policy log std Std          0.501455
trainer/Policy log std Max         -0.460743
trainer/Policy log std Min         -2.56387
trainer/Alpha                       0.0673143
trainer/Alpha Loss                 -0.102562
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.29589
exploration/Rewards Std             0.892789
exploration/Rewards Max            -0.00162321
exploration/Rewards Min            -8.40679
exploration/Returns Mean          -29.589
exploration/Returns Std            12.4548
exploration/Returns Max           -15.8652
exploration/Returns Min           -46.4494
exploration/Actions Mean           -0.0213008
exploration/Actions Std             0.232619
exploration/Actions Max             0.990407
exploration/Actions Min            -0.998077
exploration/Num Paths               5
exploration/Average Returns       -29.589
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.192915
evaluation/Rewards Std              0.87237
evaluation/Rewards Max             -0.00453647
evaluation/Rewards Min            -10.9231
evaluation/Returns Mean           -19.2915
evaluation/Returns Std             15.2647
evaluation/Returns Max             -3.40231
evaluation/Returns Min            -58.5944
evaluation/Actions Mean            -0.00549577
evaluation/Actions Std              0.181583
evaluation/Actions Max              0.995699
evaluation/Actions Min             -0.996847
evaluation/Num Paths               15
evaluation/Average Returns        -19.2915
time/data storing (s)               0.0031227
time/evaluation sampling (s)        0.365767
time/exploration sampling (s)       0.169687
time/logging (s)                    0.00522199
time/saving (s)                     0.00208456
time/training (s)                   2.1878
time/epoch (s)                      2.73368
time/total (s)                    236.445
Epoch                              86
-----------------------------  ---------------
2019-04-22 21:41:59.963075 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 87 finished
-----------------------------  ----------------
replay_buffer/size              44200
trainer/QF1 Loss                    1.69217
trainer/QF2 Loss                    1.72096
trainer/Policy Loss                13.6266
trainer/Q1 Predictions Mean       -12.0778
trainer/Q1 Predictions Std          6.65815
trainer/Q1 Predictions Max         -8.09435
trainer/Q1 Predictions Min        -56.151
trainer/Q2 Predictions Mean       -12.09
trainer/Q2 Predictions Std          6.70518
trainer/Q2 Predictions Max         -8.0858
trainer/Q2 Predictions Min        -56.2582
trainer/Q Targets Mean            -12.0455
trainer/Q Targets Std               6.8762
trainer/Q Targets Max              -0.198575
trainer/Q Targets Min             -56.4307
trainer/Log Pis Mean                1.86638
trainer/Log Pis Std                 1.5903
trainer/Log Pis Max                 8.0145
trainer/Log Pis Min                -5.29864
trainer/Policy mu Mean              0.0196274
trainer/Policy mu Std               0.787285
trainer/Policy mu Max               3.38138
trainer/Policy mu Min              -2.61715
trainer/Policy log std Mean        -1.95718
trainer/Policy log std Std          0.560574
trainer/Policy log std Max         -0.258905
trainer/Policy log std Min         -2.58708
trainer/Alpha                       0.0646941
trainer/Alpha Loss                 -0.365843
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.249937
exploration/Rewards Std             0.632014
exploration/Rewards Max            -0.00274047
exploration/Rewards Min            -7.26684
exploration/Returns Mean          -24.9937
exploration/Returns Std            12.4383
exploration/Returns Max           -13.556
exploration/Returns Min           -47.3488
exploration/Actions Mean            0.00509593
exploration/Actions Std             0.226096
exploration/Actions Max             0.997895
exploration/Actions Min            -0.998539
exploration/Num Paths               5
exploration/Average Returns       -24.9937
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.277501
evaluation/Rewards Std              1.16037
evaluation/Rewards Max             -0.0132627
evaluation/Rewards Min            -11.4321
evaluation/Returns Mean           -27.7501
evaluation/Returns Std             16.7574
evaluation/Returns Max             -5.46119
evaluation/Returns Min            -57.4648
evaluation/Actions Mean            -0.000546667
evaluation/Actions Std              0.207899
evaluation/Actions Max              0.99918
evaluation/Actions Min             -0.99668
evaluation/Num Paths               15
evaluation/Average Returns        -27.7501
time/data storing (s)               0.00317124
time/evaluation sampling (s)        0.355342
time/exploration sampling (s)       0.160413
time/logging (s)                    0.00493317
time/saving (s)                     0.00209206
time/training (s)                   2.12481
time/epoch (s)                      2.65076
time/total (s)                    239.101
Epoch                              87
-----------------------------  ----------------
2019-04-22 21:42:02.664477 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size              44700
trainer/QF1 Loss                    1.16366
trainer/QF2 Loss                    1.22577
trainer/Policy Loss                13.919
trainer/Q1 Predictions Mean       -12.4501
trainer/Q1 Predictions Std          8.14516
trainer/Q1 Predictions Max         -8.13229
trainer/Q1 Predictions Min        -74.0862
trainer/Q2 Predictions Mean       -12.4444
trainer/Q2 Predictions Std          8.12834
trainer/Q2 Predictions Max         -8.1274
trainer/Q2 Predictions Min        -74.4441
trainer/Q Targets Mean            -12.453
trainer/Q Targets Std               8.01306
trainer/Q Targets Max              -1.5613
trainer/Q Targets Min             -70.5613
trainer/Log Pis Mean                2.03455
trainer/Log Pis Std                 1.36768
trainer/Log Pis Max                 6.69219
trainer/Log Pis Min                -1.18044
trainer/Policy mu Mean             -0.0263002
trainer/Policy mu Std               0.766768
trainer/Policy mu Max               2.94523
trainer/Policy mu Min              -3.21353
trainer/Policy log std Mean        -2.00334
trainer/Policy log std Std          0.536735
trainer/Policy log std Max         -0.418754
trainer/Policy log std Min         -2.62526
trainer/Alpha                       0.0627293
trainer/Alpha Loss                  0.0956517
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.288695
exploration/Rewards Std             0.718595
exploration/Rewards Max            -0.0073321
exploration/Rewards Min            -6.50368
exploration/Returns Mean          -28.8695
exploration/Returns Std             9.37436
exploration/Returns Max           -11.7256
exploration/Returns Min           -37.5448
exploration/Actions Mean            0.0117084
exploration/Actions Std             0.241885
exploration/Actions Max             0.998662
exploration/Actions Min            -0.997966
exploration/Num Paths               5
exploration/Average Returns       -28.8695
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226298
evaluation/Rewards Std              0.938392
evaluation/Rewards Max             -0.0142355
evaluation/Rewards Min             -9.5146
evaluation/Returns Mean           -22.6298
evaluation/Returns Std             15.3173
evaluation/Returns Max             -3.24987
evaluation/Returns Min            -54.5278
evaluation/Actions Mean            -0.00751932
evaluation/Actions Std              0.185715
evaluation/Actions Max              0.994975
evaluation/Actions Min             -0.996727
evaluation/Num Paths               15
evaluation/Average Returns        -22.6298
time/data storing (s)               0.00316678
time/evaluation sampling (s)        0.356584
time/exploration sampling (s)       0.159836
time/logging (s)                    0.0048383
time/saving (s)                     0.00207752
time/training (s)                   2.16814
time/epoch (s)                      2.69464
time/total (s)                    241.8
Epoch                              88
-----------------------------  ---------------
2019-04-22 21:42:05.322607 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 89 finished
-----------------------------  ---------------
replay_buffer/size              45200
trainer/QF1 Loss                    1.85708
trainer/QF2 Loss                    1.87214
trainer/Policy Loss                13.7892
trainer/Q1 Predictions Mean       -12.0767
trainer/Q1 Predictions Std          6.65877
trainer/Q1 Predictions Max         -8.13167
trainer/Q1 Predictions Min        -68.3905
trainer/Q2 Predictions Mean       -12.0742
trainer/Q2 Predictions Std          6.62912
trainer/Q2 Predictions Max         -8.14016
trainer/Q2 Predictions Min        -68.0484
trainer/Q Targets Mean            -12.0152
trainer/Q Targets Std               6.96916
trainer/Q Targets Max              -0.658839
trainer/Q Targets Min             -71.0992
trainer/Log Pis Mean                2.01174
trainer/Log Pis Std                 1.22774
trainer/Log Pis Max                 6.32782
trainer/Log Pis Min                -1.02994
trainer/Policy mu Mean             -0.117341
trainer/Policy mu Std               0.681609
trainer/Policy mu Max               2.78973
trainer/Policy mu Min              -3.23903
trainer/Policy log std Mean        -2.08751
trainer/Policy log std Std          0.489408
trainer/Policy log std Max         -0.489819
trainer/Policy log std Min         -2.61793
trainer/Alpha                       0.0622314
trainer/Alpha Loss                  0.032601
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354217
exploration/Rewards Std             0.932623
exploration/Rewards Max            -0.00888596
exploration/Rewards Min            -7.38643
exploration/Returns Mean          -35.4217
exploration/Returns Std             8.48263
exploration/Returns Max           -26.1042
exploration/Returns Min           -50.2326
exploration/Actions Mean            0.00702607
exploration/Actions Std             0.255037
exploration/Actions Max             0.998161
exploration/Actions Min            -0.998344
exploration/Num Paths               5
exploration/Average Returns       -35.4217
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.202218
evaluation/Rewards Std              0.856553
evaluation/Rewards Max             -0.00779546
evaluation/Rewards Min             -9.47892
evaluation/Returns Mean           -20.2218
evaluation/Returns Std             13.3987
evaluation/Returns Max             -2.5308
evaluation/Returns Min            -45.9513
evaluation/Actions Mean             0.0092889
evaluation/Actions Std              0.186333
evaluation/Actions Max              0.998128
evaluation/Actions Min             -0.996016
evaluation/Num Paths               15
evaluation/Average Returns        -20.2218
time/data storing (s)               0.003168
time/evaluation sampling (s)        0.358689
time/exploration sampling (s)       0.162382
time/logging (s)                    0.0049016
time/saving (s)                     0.00208475
time/training (s)                   2.12089
time/epoch (s)                      2.65211
time/total (s)                    244.457
Epoch                              89
-----------------------------  ---------------
2019-04-22 21:42:08.007469 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size              45700
trainer/QF1 Loss                    0.127936
trainer/QF2 Loss                    0.0740659
trainer/Policy Loss                13.3983
trainer/Q1 Predictions Mean       -11.821
trainer/Q1 Predictions Std          5.72681
trainer/Q1 Predictions Max         -8.01018
trainer/Q1 Predictions Min        -56.8317
trainer/Q2 Predictions Mean       -11.8422
trainer/Q2 Predictions Std          5.80715
trainer/Q2 Predictions Max         -8.01378
trainer/Q2 Predictions Min        -57.7494
trainer/Q Targets Mean            -11.9594
trainer/Q Targets Std               5.99646
trainer/Q Targets Max              -8.01351
trainer/Q Targets Min             -59.9496
trainer/Log Pis Mean                2.05787
trainer/Log Pis Std                 1.53683
trainer/Log Pis Max                 6.85552
trainer/Log Pis Min                -4.87767
trainer/Policy mu Mean              0.0343128
trainer/Policy mu Std               0.798043
trainer/Policy mu Max               3.06914
trainer/Policy mu Min              -2.83707
trainer/Policy log std Mean        -2.06331
trainer/Policy log std Std          0.550628
trainer/Policy log std Max         -0.390692
trainer/Policy log std Min         -2.62031
trainer/Alpha                       0.0607877
trainer/Alpha Loss                  0.162068
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.272637
exploration/Rewards Std             0.821744
exploration/Rewards Max            -0.00436674
exploration/Rewards Min            -8.74661
exploration/Returns Mean          -27.2637
exploration/Returns Std            12.0099
exploration/Returns Max           -16.3406
exploration/Returns Min           -50.0566
exploration/Actions Mean           -0.0201398
exploration/Actions Std             0.211745
exploration/Actions Max             0.999014
exploration/Actions Min            -0.998915
exploration/Num Paths               5
exploration/Average Returns       -27.2637
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261676
evaluation/Rewards Std              0.997682
evaluation/Rewards Max             -0.00761218
evaluation/Rewards Min             -9.39452
evaluation/Returns Mean           -26.1676
evaluation/Returns Std             13.7585
evaluation/Returns Max             -6.35738
evaluation/Returns Min            -50.1083
evaluation/Actions Mean             0.0186257
evaluation/Actions Std              0.19618
evaluation/Actions Max              0.998141
evaluation/Actions Min             -0.996285
evaluation/Num Paths               15
evaluation/Average Returns        -26.1676
time/data storing (s)               0.00309723
time/evaluation sampling (s)        0.363705
time/exploration sampling (s)       0.165456
time/logging (s)                    0.00451224
time/saving (s)                     0.00198703
time/training (s)                   2.13951
time/epoch (s)                      2.67827
time/total (s)                    247.139
Epoch                              90
-----------------------------  ---------------
2019-04-22 21:42:10.669196 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                    3.15315
trainer/QF2 Loss                    3.1409
trainer/Policy Loss                13.4133
trainer/Q1 Predictions Mean       -11.974
trainer/Q1 Predictions Std          5.51713
trainer/Q1 Predictions Max         -8.03096
trainer/Q1 Predictions Min        -41.5764
trainer/Q2 Predictions Mean       -11.955
trainer/Q2 Predictions Std          5.50977
trainer/Q2 Predictions Max         -7.97225
trainer/Q2 Predictions Min        -41.4722
trainer/Q Targets Mean            -11.8327
trainer/Q Targets Std               5.7365
trainer/Q Targets Max              -0.372832
trainer/Q Targets Min             -41.9321
trainer/Log Pis Mean                2.03801
trainer/Log Pis Std                 1.38046
trainer/Log Pis Max                 5.4915
trainer/Log Pis Min                -6.04498
trainer/Policy mu Mean             -0.0663431
trainer/Policy mu Std               0.816893
trainer/Policy mu Max               3.28524
trainer/Policy mu Min              -2.66383
trainer/Policy log std Mean        -2.05726
trainer/Policy log std Std          0.56475
trainer/Policy log std Max         -0.430987
trainer/Policy log std Min         -2.66374
trainer/Alpha                       0.0639517
trainer/Alpha Loss                  0.104508
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.318853
exploration/Rewards Std             0.948302
exploration/Rewards Max            -0.00318579
exploration/Rewards Min            -8.33401
exploration/Returns Mean          -31.8853
exploration/Returns Std            15.1265
exploration/Returns Max           -13.6767
exploration/Returns Min           -52.7863
exploration/Actions Mean            0.0129213
exploration/Actions Std             0.227514
exploration/Actions Max             0.99927
exploration/Actions Min            -0.998842
exploration/Num Paths               5
exploration/Average Returns       -31.8853
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.361098
evaluation/Rewards Std              1.28992
evaluation/Rewards Max             -0.0220166
evaluation/Rewards Min            -11.051
evaluation/Returns Mean           -36.1098
evaluation/Returns Std             18.846
evaluation/Returns Max             -3.76311
evaluation/Returns Min            -62.2535
evaluation/Actions Mean            -0.0132989
evaluation/Actions Std              0.21508
evaluation/Actions Max              0.99934
evaluation/Actions Min             -0.996539
evaluation/Num Paths               15
evaluation/Average Returns        -36.1098
time/data storing (s)               0.00314137
time/evaluation sampling (s)        0.360787
time/exploration sampling (s)       0.161637
time/logging (s)                    0.00488744
time/saving (s)                     0.00202962
time/training (s)                   2.12318
time/epoch (s)                      2.65566
time/total (s)                    249.799
Epoch                              91
-----------------------------  ---------------
2019-04-22 21:42:13.366792 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size              46700
trainer/QF1 Loss                    0.0438911
trainer/QF2 Loss                    0.0851618
trainer/Policy Loss                12.9135
trainer/Q1 Predictions Mean       -11.3887
trainer/Q1 Predictions Std          5.72105
trainer/Q1 Predictions Max         -7.89961
trainer/Q1 Predictions Min        -64.1512
trainer/Q2 Predictions Mean       -11.3749
trainer/Q2 Predictions Std          5.6562
trainer/Q2 Predictions Max         -7.85683
trainer/Q2 Predictions Min        -63.3784
trainer/Q Targets Mean            -11.4383
trainer/Q Targets Std               5.84597
trainer/Q Targets Max              -7.94818
trainer/Q Targets Min             -65.6941
trainer/Log Pis Mean                1.7761
trainer/Log Pis Std                 1.41725
trainer/Log Pis Max                 5.52541
trainer/Log Pis Min                -7.40635
trainer/Policy mu Mean             -0.0163352
trainer/Policy mu Std               0.55602
trainer/Policy mu Max               2.87941
trainer/Policy mu Min              -2.66677
trainer/Policy log std Mean        -2.11898
trainer/Policy log std Std          0.447258
trainer/Policy log std Max         -0.368067
trainer/Policy log std Min         -2.61709
trainer/Alpha                       0.0652663
trainer/Alpha Loss                 -0.611074
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.352303
exploration/Rewards Std             1.09914
exploration/Rewards Max            -0.0126695
exploration/Rewards Min            -9.24518
exploration/Returns Mean          -35.2303
exploration/Returns Std            16.8458
exploration/Returns Max           -14.9737
exploration/Returns Min           -60.0755
exploration/Actions Mean           -0.0056641
exploration/Actions Std             0.233296
exploration/Actions Max             0.999503
exploration/Actions Min            -0.999795
exploration/Num Paths               5
exploration/Average Returns       -35.2303
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.271022
evaluation/Rewards Std              1.11214
evaluation/Rewards Max             -0.00744038
evaluation/Rewards Min            -11.3035
evaluation/Returns Mean           -27.1022
evaluation/Returns Std             17.7226
evaluation/Returns Max             -5.60819
evaluation/Returns Min            -61.2596
evaluation/Actions Mean            -0.00203968
evaluation/Actions Std              0.204516
evaluation/Actions Max              0.999264
evaluation/Actions Min             -0.996884
evaluation/Num Paths               15
evaluation/Average Returns        -27.1022
time/data storing (s)               0.00326676
time/evaluation sampling (s)        0.353295
time/exploration sampling (s)       0.161799
time/logging (s)                    0.00519111
time/saving (s)                     0.01022
time/training (s)                   2.15768
time/epoch (s)                      2.69145
time/total (s)                    252.495
Epoch                              92
-----------------------------  ---------------
2019-04-22 21:42:16.079834 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size              47200
trainer/QF1 Loss                    1.53401
trainer/QF2 Loss                    1.52805
trainer/Policy Loss                13.1374
trainer/Q1 Predictions Mean       -11.4724
trainer/Q1 Predictions Std          5.39118
trainer/Q1 Predictions Max         -7.70059
trainer/Q1 Predictions Min        -43.214
trainer/Q2 Predictions Mean       -11.4822
trainer/Q2 Predictions Std          5.3916
trainer/Q2 Predictions Max         -7.69408
trainer/Q2 Predictions Min        -43.2719
trainer/Q Targets Mean            -11.5716
trainer/Q Targets Std               5.51771
trainer/Q Targets Max              -0.173413
trainer/Q Targets Min             -43.8367
trainer/Log Pis Mean                1.9648
trainer/Log Pis Std                 1.32282
trainer/Log Pis Max                 6.48441
trainer/Log Pis Min                -2.231
trainer/Policy mu Mean              0.0269177
trainer/Policy mu Std               0.729034
trainer/Policy mu Max               2.87131
trainer/Policy mu Min              -2.89813
trainer/Policy log std Mean        -2.05
trainer/Policy log std Std          0.455438
trainer/Policy log std Max         -0.552694
trainer/Policy log std Min         -2.48974
trainer/Alpha                       0.0635118
trainer/Alpha Loss                 -0.0970141
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.219936
exploration/Rewards Std             0.521665
exploration/Rewards Max            -0.00690623
exploration/Rewards Min            -5.48793
exploration/Returns Mean          -21.9936
exploration/Returns Std             4.7684
exploration/Returns Max           -16.7103
exploration/Returns Min           -28.8663
exploration/Actions Mean           -0.0124287
exploration/Actions Std             0.214116
exploration/Actions Max             0.988266
exploration/Actions Min            -0.998881
exploration/Num Paths               5
exploration/Average Returns       -21.9936
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.211442
evaluation/Rewards Std              0.841427
evaluation/Rewards Max             -0.0155877
evaluation/Rewards Min             -8.7694
evaluation/Returns Mean           -21.1442
evaluation/Returns Std             11.9516
evaluation/Returns Max             -5.99125
evaluation/Returns Min            -43.4228
evaluation/Actions Mean            -0.00122523
evaluation/Actions Std              0.19322
evaluation/Actions Max              0.995747
evaluation/Actions Min             -0.995076
evaluation/Num Paths               15
evaluation/Average Returns        -21.1442
time/data storing (s)               0.0033695
time/evaluation sampling (s)        0.369844
time/exploration sampling (s)       0.173967
time/logging (s)                    0.00489486
time/saving (s)                     0.0021367
time/training (s)                   2.15193
time/epoch (s)                      2.70614
time/total (s)                    255.206
Epoch                              93
-----------------------------  ---------------
2019-04-22 21:42:18.767367 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 94 finished
-----------------------------  ----------------
replay_buffer/size              47700
trainer/QF1 Loss                    1.42134
trainer/QF2 Loss                    1.4264
trainer/Policy Loss                12.4399
trainer/Q1 Predictions Mean       -10.8196
trainer/Q1 Predictions Std          4.42055
trainer/Q1 Predictions Max         -7.74198
trainer/Q1 Predictions Min        -42.5392
trainer/Q2 Predictions Mean       -10.7916
trainer/Q2 Predictions Std          4.40099
trainer/Q2 Predictions Max         -7.72596
trainer/Q2 Predictions Min        -42.292
trainer/Q Targets Mean            -10.7848
trainer/Q Targets Std               4.45159
trainer/Q Targets Max              -0.578656
trainer/Q Targets Min             -42.1864
trainer/Log Pis Mean                2.00025
trainer/Log Pis Std                 1.28783
trainer/Log Pis Max                 7.3694
trainer/Log Pis Min                -1.88443
trainer/Policy mu Mean             -0.0360169
trainer/Policy mu Std               0.600184
trainer/Policy mu Max               2.77571
trainer/Policy mu Min              -2.76769
trainer/Policy log std Mean        -2.09878
trainer/Policy log std Std          0.444157
trainer/Policy log std Max         -0.508865
trainer/Policy log std Min         -2.6007
trainer/Alpha                       0.0631654
trainer/Alpha Loss                  0.000703335
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378516
exploration/Rewards Std             1.17269
exploration/Rewards Max            -0.00909963
exploration/Rewards Min            -9.40248
exploration/Returns Mean          -37.8516
exploration/Returns Std            19.0008
exploration/Returns Max           -15.2015
exploration/Returns Min           -61.9505
exploration/Actions Mean            9.57112e-05
exploration/Actions Std             0.245002
exploration/Actions Max             0.999336
exploration/Actions Min            -0.998175
exploration/Num Paths               5
exploration/Average Returns       -37.8516
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.173281
evaluation/Rewards Std              0.747571
evaluation/Rewards Max             -0.00711045
evaluation/Rewards Min             -8.75778
evaluation/Returns Mean           -17.3281
evaluation/Returns Std             12.6914
evaluation/Returns Max             -4.07382
evaluation/Returns Min            -48.0815
evaluation/Actions Mean             0.0101506
evaluation/Actions Std              0.169934
evaluation/Actions Max              0.998365
evaluation/Actions Min             -0.992829
evaluation/Num Paths               15
evaluation/Average Returns        -17.3281
time/data storing (s)               0.00315188
time/evaluation sampling (s)        0.35956
time/exploration sampling (s)       0.166472
time/logging (s)                    0.00503196
time/saving (s)                     0.00197142
time/training (s)                   2.14486
time/epoch (s)                      2.68104
time/total (s)                    257.892
Epoch                              94
-----------------------------  ----------------
2019-04-22 21:42:21.486993 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                    1.50225
trainer/QF2 Loss                    1.49349
trainer/Policy Loss                13.3916
trainer/Q1 Predictions Mean       -11.945
trainer/Q1 Predictions Std          7.14236
trainer/Q1 Predictions Max         -7.70173
trainer/Q1 Predictions Min        -60.0464
trainer/Q2 Predictions Mean       -11.9654
trainer/Q2 Predictions Std          7.14124
trainer/Q2 Predictions Max         -7.72417
trainer/Q2 Predictions Min        -60.1285
trainer/Q Targets Mean            -11.9299
trainer/Q Targets Std               7.41132
trainer/Q Targets Max              -0.176253
trainer/Q Targets Min             -62.2168
trainer/Log Pis Mean                1.97913
trainer/Log Pis Std                 1.44987
trainer/Log Pis Max                 5.70305
trainer/Log Pis Min                -4.48154
trainer/Policy mu Mean             -0.0452237
trainer/Policy mu Std               0.775208
trainer/Policy mu Max               2.82983
trainer/Policy mu Min              -3.23981
trainer/Policy log std Mean        -2.02372
trainer/Policy log std Std          0.527495
trainer/Policy log std Max         -0.429206
trainer/Policy log std Min         -2.61197
trainer/Alpha                       0.0654688
trainer/Alpha Loss                 -0.0568902
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.29254
exploration/Rewards Std             0.822552
exploration/Rewards Max            -0.0106878
exploration/Rewards Min            -7.25694
exploration/Returns Mean          -29.254
exploration/Returns Std             8.09255
exploration/Returns Max           -19.3571
exploration/Returns Min           -40.8274
exploration/Actions Mean           -0.00825829
exploration/Actions Std             0.236861
exploration/Actions Max             0.996674
exploration/Actions Min            -0.998104
exploration/Num Paths               5
exploration/Average Returns       -29.254
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270542
evaluation/Rewards Std              1.00912
evaluation/Rewards Max             -0.024247
evaluation/Rewards Min             -8.89004
evaluation/Returns Mean           -27.0542
evaluation/Returns Std             12.8448
evaluation/Returns Max             -4.21736
evaluation/Returns Min            -47.2139
evaluation/Actions Mean            -0.00525104
evaluation/Actions Std              0.194917
evaluation/Actions Max              0.99475
evaluation/Actions Min             -0.995681
evaluation/Num Paths               15
evaluation/Average Returns        -27.0542
time/data storing (s)               0.00324534
time/evaluation sampling (s)        0.357712
time/exploration sampling (s)       0.159464
time/logging (s)                    0.0049037
time/saving (s)                     0.00203325
time/training (s)                   2.18547
time/epoch (s)                      2.71282
time/total (s)                    260.609
Epoch                              95
-----------------------------  ---------------
2019-04-22 21:42:24.152923 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size              48700
trainer/QF1 Loss                    0.973336
trainer/QF2 Loss                    0.976174
trainer/Policy Loss                13.4283
trainer/Q1 Predictions Mean       -11.4858
trainer/Q1 Predictions Std          6.41246
trainer/Q1 Predictions Max         -7.56264
trainer/Q1 Predictions Min        -53.0121
trainer/Q2 Predictions Mean       -11.4896
trainer/Q2 Predictions Std          6.4264
trainer/Q2 Predictions Max         -7.57829
trainer/Q2 Predictions Min        -52.8112
trainer/Q Targets Mean            -11.4257
trainer/Q Targets Std               6.62177
trainer/Q Targets Max              -0.35209
trainer/Q Targets Min             -54.8464
trainer/Log Pis Mean                2.18325
trainer/Log Pis Std                 1.39084
trainer/Log Pis Max                 8.55255
trainer/Log Pis Min                -1.16471
trainer/Policy mu Mean             -0.0624455
trainer/Policy mu Std               0.783968
trainer/Policy mu Max               2.83576
trainer/Policy mu Min              -3.16663
trainer/Policy log std Mean        -2.00093
trainer/Policy log std Std          0.494497
trainer/Policy log std Max         -0.560239
trainer/Policy log std Min         -2.5582
trainer/Alpha                       0.0646468
trainer/Alpha Loss                  0.501879
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.308961
exploration/Rewards Std             0.932749
exploration/Rewards Max            -0.0045962
exploration/Rewards Min            -8.14985
exploration/Returns Mean          -30.8961
exploration/Returns Std            12.11
exploration/Returns Max           -14.5442
exploration/Returns Min           -44.5438
exploration/Actions Mean           -0.00979992
exploration/Actions Std             0.226066
exploration/Actions Max             0.994244
exploration/Actions Min            -0.999065
exploration/Num Paths               5
exploration/Average Returns       -30.8961
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22391
evaluation/Rewards Std              0.975213
evaluation/Rewards Max             -0.019671
evaluation/Rewards Min            -11.0127
evaluation/Returns Mean           -22.391
evaluation/Returns Std             16.9563
evaluation/Returns Max             -4.40709
evaluation/Returns Min            -54.7824
evaluation/Actions Mean             0.00152423
evaluation/Actions Std              0.19402
evaluation/Actions Max              0.998349
evaluation/Actions Min             -0.997437
evaluation/Num Paths               15
evaluation/Average Returns        -22.391
time/data storing (s)               0.00313349
time/evaluation sampling (s)        0.35631
time/exploration sampling (s)       0.159879
time/logging (s)                    0.00489043
time/saving (s)                     0.00173006
time/training (s)                   2.13295
time/epoch (s)                      2.65889
time/total (s)                    263.273
Epoch                              96
-----------------------------  ---------------
2019-04-22 21:42:26.879291 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 97 finished
-----------------------------  ----------------
replay_buffer/size              49200
trainer/QF1 Loss                    0.0653464
trainer/QF2 Loss                    0.0638576
trainer/Policy Loss                13.2099
trainer/Q1 Predictions Mean       -11.4359
trainer/Q1 Predictions Std          5.35524
trainer/Q1 Predictions Max         -7.54018
trainer/Q1 Predictions Min        -45.8014
trainer/Q2 Predictions Mean       -11.442
trainer/Q2 Predictions Std          5.35761
trainer/Q2 Predictions Max         -7.54283
trainer/Q2 Predictions Min        -45.7114
trainer/Q Targets Mean            -11.4482
trainer/Q Targets Std               5.44122
trainer/Q Targets Max              -7.50126
trainer/Q Targets Min             -46.714
trainer/Log Pis Mean                2.07368
trainer/Log Pis Std                 1.48345
trainer/Log Pis Max                 7.17141
trainer/Log Pis Min                -2.18859
trainer/Policy mu Mean             -0.101497
trainer/Policy mu Std               0.820716
trainer/Policy mu Max               3.13695
trainer/Policy mu Min              -3.10804
trainer/Policy log std Mean        -1.9878
trainer/Policy log std Std          0.498223
trainer/Policy log std Max         -0.504148
trainer/Policy log std Min         -2.47766
trainer/Alpha                       0.0634227
trainer/Alpha Loss                  0.203203
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.320087
exploration/Rewards Std             0.83584
exploration/Rewards Max            -0.00739836
exploration/Rewards Min            -8.66156
exploration/Returns Mean          -32.0087
exploration/Returns Std            14.5645
exploration/Returns Max           -17.2269
exploration/Returns Min           -59.1218
exploration/Actions Mean            0.000383896
exploration/Actions Std             0.235154
exploration/Actions Max             0.999465
exploration/Actions Min            -0.997788
exploration/Num Paths               5
exploration/Average Returns       -32.0087
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.325928
evaluation/Rewards Std              1.06257
evaluation/Rewards Max             -0.0539547
evaluation/Rewards Min            -10.9147
evaluation/Returns Mean           -32.5928
evaluation/Returns Std             15.627
evaluation/Returns Max            -11.2575
evaluation/Returns Min            -65.428
evaluation/Actions Mean            -0.00250159
evaluation/Actions Std              0.200251
evaluation/Actions Max              0.998694
evaluation/Actions Min             -0.99718
evaluation/Num Paths               15
evaluation/Average Returns        -32.5928
time/data storing (s)               0.00332526
time/evaluation sampling (s)        0.356853
time/exploration sampling (s)       0.160132
time/logging (s)                    0.00485741
time/saving (s)                     0.00202618
time/training (s)                   2.1925
time/epoch (s)                      2.71969
time/total (s)                    265.997
Epoch                              97
-----------------------------  ----------------
2019-04-22 21:42:29.565977 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                    0.919497
trainer/QF2 Loss                    0.925249
trainer/Policy Loss                12.1381
trainer/Q1 Predictions Mean       -10.5972
trainer/Q1 Predictions Std          4.24376
trainer/Q1 Predictions Max         -7.50613
trainer/Q1 Predictions Min        -31.6741
trainer/Q2 Predictions Mean       -10.5993
trainer/Q2 Predictions Std          4.26474
trainer/Q2 Predictions Max         -7.49773
trainer/Q2 Predictions Min        -32.0221
trainer/Q Targets Mean            -10.5593
trainer/Q Targets Std               4.24832
trainer/Q Targets Max              -0.16485
trainer/Q Targets Min             -29.9457
trainer/Log Pis Mean                2.08374
trainer/Log Pis Std                 1.47157
trainer/Log Pis Max                 7.10777
trainer/Log Pis Min                -4.91192
trainer/Policy mu Mean             -0.071179
trainer/Policy mu Std               0.732454
trainer/Policy mu Max               3.04905
trainer/Policy mu Min              -2.68295
trainer/Policy log std Mean        -2.06931
trainer/Policy log std Std          0.506095
trainer/Policy log std Max         -0.43041
trainer/Policy log std Min         -2.62644
trainer/Alpha                       0.0628051
trainer/Alpha Loss                  0.231758
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33923
exploration/Rewards Std             0.846669
exploration/Rewards Max            -0.0057385
exploration/Rewards Min            -8.49548
exploration/Returns Mean          -33.923
exploration/Returns Std            11.1384
exploration/Returns Max           -14.9662
exploration/Returns Min           -47.104
exploration/Actions Mean           -0.0105281
exploration/Actions Std             0.238571
exploration/Actions Max             0.998216
exploration/Actions Min            -0.998773
exploration/Num Paths               5
exploration/Average Returns       -33.923
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.253279
evaluation/Rewards Std              0.829239
evaluation/Rewards Max             -0.0221021
evaluation/Rewards Min            -11.264
evaluation/Returns Mean           -25.3279
evaluation/Returns Std             16.1921
evaluation/Returns Max            -11.0343
evaluation/Returns Min            -65.6406
evaluation/Actions Mean             0.00797467
evaluation/Actions Std              0.172579
evaluation/Actions Max              0.998141
evaluation/Actions Min             -0.993139
evaluation/Num Paths               15
evaluation/Average Returns        -25.3279
time/data storing (s)               0.00320806
time/evaluation sampling (s)        0.374105
time/exploration sampling (s)       0.165514
time/logging (s)                    0.00494522
time/saving (s)                     0.00203287
time/training (s)                   2.13032
time/epoch (s)                      2.68012
time/total (s)                    268.682
Epoch                              98
-----------------------------  ---------------
2019-04-22 21:42:32.261389 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                    3.16456
trainer/QF2 Loss                    3.18432
trainer/Policy Loss                12.4338
trainer/Q1 Predictions Mean       -10.5568
trainer/Q1 Predictions Std          4.07141
trainer/Q1 Predictions Max         -7.5195
trainer/Q1 Predictions Min        -35.2683
trainer/Q2 Predictions Mean       -10.561
trainer/Q2 Predictions Std          4.08801
trainer/Q2 Predictions Max         -7.54152
trainer/Q2 Predictions Min        -35.6568
trainer/Q Targets Mean            -10.2876
trainer/Q Targets Std               4.4767
trainer/Q Targets Max              -0.0444335
trainer/Q Targets Min             -35.5872
trainer/Log Pis Mean                2.09237
trainer/Log Pis Std                 1.28621
trainer/Log Pis Max                 6.83488
trainer/Log Pis Min                -2.8265
trainer/Policy mu Mean             -0.0463329
trainer/Policy mu Std               0.624675
trainer/Policy mu Max               3.02584
trainer/Policy mu Min              -2.80182
trainer/Policy log std Mean        -2.17769
trainer/Policy log std Std          0.4466
trainer/Policy log std Max         -0.417125
trainer/Policy log std Min         -2.73971
trainer/Alpha                       0.0627443
trainer/Alpha Loss                  0.25577
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.195429
exploration/Rewards Std             0.490516
exploration/Rewards Max            -0.00420513
exploration/Rewards Min            -5.25446
exploration/Returns Mean          -19.5429
exploration/Returns Std             5.05027
exploration/Returns Max           -12.6602
exploration/Returns Min           -25.0185
exploration/Actions Mean           -0.0135477
exploration/Actions Std             0.192232
exploration/Actions Max             0.980187
exploration/Actions Min            -0.998811
exploration/Num Paths               5
exploration/Average Returns       -19.5429
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.290842
evaluation/Rewards Std              1.19695
evaluation/Rewards Max             -0.0113116
evaluation/Rewards Min             -9.79736
evaluation/Returns Mean           -29.0842
evaluation/Returns Std             16.7439
evaluation/Returns Max             -2.71779
evaluation/Returns Min            -59.4836
evaluation/Actions Mean            -0.00661703
evaluation/Actions Std              0.221102
evaluation/Actions Max              0.999059
evaluation/Actions Min             -0.997671
evaluation/Num Paths               15
evaluation/Average Returns        -29.0842
time/data storing (s)               0.00323599
time/evaluation sampling (s)        0.354001
time/exploration sampling (s)       0.160703
time/logging (s)                    0.00463069
time/saving (s)                     0.0020454
time/training (s)                   2.16369
time/epoch (s)                      2.6883
time/total (s)                    271.375
Epoch                              99
-----------------------------  ---------------
2019-04-22 21:42:34.907971 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              50700
trainer/QF1 Loss                    2.01479
trainer/QF2 Loss                    2.00312
trainer/Policy Loss                12.9343
trainer/Q1 Predictions Mean       -11.2166
trainer/Q1 Predictions Std          6.97195
trainer/Q1 Predictions Max         -7.4183
trainer/Q1 Predictions Min        -50.048
trainer/Q2 Predictions Mean       -11.2118
trainer/Q2 Predictions Std          6.9795
trainer/Q2 Predictions Max         -7.43334
trainer/Q2 Predictions Min        -50.0451
trainer/Q Targets Mean            -11.0357
trainer/Q Targets Std               7.11006
trainer/Q Targets Max              -0.169016
trainer/Q Targets Min             -50.3686
trainer/Log Pis Mean                2.19207
trainer/Log Pis Std                 1.42597
trainer/Log Pis Max                 7.16023
trainer/Log Pis Min                -1.75065
trainer/Policy mu Mean             -0.0552027
trainer/Policy mu Std               0.852054
trainer/Policy mu Max               2.89557
trainer/Policy mu Min              -3.14794
trainer/Policy log std Mean        -2.0047
trainer/Policy log std Std          0.551875
trainer/Policy log std Max         -0.382155
trainer/Policy log std Min         -2.6609
trainer/Alpha                       0.0646345
trainer/Alpha Loss                  0.526094
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.361956
exploration/Rewards Std             1.02309
exploration/Rewards Max            -0.0107553
exploration/Rewards Min            -8.07214
exploration/Returns Mean          -36.1956
exploration/Returns Std            11.4645
exploration/Returns Max           -14.7402
exploration/Returns Min           -49.2548
exploration/Actions Mean            0.0101162
exploration/Actions Std             0.24836
exploration/Actions Max             0.999234
exploration/Actions Min            -0.996399
exploration/Num Paths               5
exploration/Average Returns       -36.1956
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221815
evaluation/Rewards Std              0.815843
evaluation/Rewards Max             -0.00767011
evaluation/Rewards Min             -7.4282
evaluation/Returns Mean           -22.1815
evaluation/Returns Std              9.71496
evaluation/Returns Max             -6.93123
evaluation/Returns Min            -35.7515
evaluation/Actions Mean             0.0019546
evaluation/Actions Std              0.180344
evaluation/Actions Max              0.996985
evaluation/Actions Min             -0.99699
evaluation/Num Paths               15
evaluation/Average Returns        -22.1815
time/data storing (s)               0.00305486
time/evaluation sampling (s)        0.355023
time/exploration sampling (s)       0.16181
time/logging (s)                    0.005509
time/saving (s)                     0.00228703
time/training (s)                   2.11381
time/epoch (s)                      2.64149
time/total (s)                    274.021
Epoch                             100
-----------------------------  ---------------
2019-04-22 21:42:37.590819 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              51200
trainer/QF1 Loss                   19.3098
trainer/QF2 Loss                   19.4809
trainer/Policy Loss                11.7781
trainer/Q1 Predictions Mean       -10.2318
trainer/Q1 Predictions Std          5.38054
trainer/Q1 Predictions Max         -7.31675
trainer/Q1 Predictions Min        -51.9155
trainer/Q2 Predictions Mean       -10.2332
trainer/Q2 Predictions Std          5.39197
trainer/Q2 Predictions Max         -7.32103
trainer/Q2 Predictions Min        -52.1071
trainer/Q Targets Mean             -9.84092
trainer/Q Targets Std               3.43618
trainer/Q Targets Max              -0.217273
trainer/Q Targets Min             -36.7209
trainer/Log Pis Mean                1.93434
trainer/Log Pis Std                 1.17861
trainer/Log Pis Max                 7.52129
trainer/Log Pis Min                -0.695793
trainer/Policy mu Mean             -0.098848
trainer/Policy mu Std               0.616293
trainer/Policy mu Max               2.6813
trainer/Policy mu Min              -3.02132
trainer/Policy log std Mean        -2.08655
trainer/Policy log std Std          0.440105
trainer/Policy log std Max         -0.500621
trainer/Policy log std Min         -2.71597
trainer/Alpha                       0.0636933
trainer/Alpha Loss                 -0.180817
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375404
exploration/Rewards Std             1.07188
exploration/Rewards Max            -0.010553
exploration/Rewards Min            -9.4976
exploration/Returns Mean          -37.5404
exploration/Returns Std            13.1249
exploration/Returns Max           -21.8599
exploration/Returns Min           -52.5471
exploration/Actions Mean            0.0175878
exploration/Actions Std             0.26628
exploration/Actions Max             0.998121
exploration/Actions Min            -0.992884
exploration/Num Paths               5
exploration/Average Returns       -37.5404
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.206795
evaluation/Rewards Std              0.930248
evaluation/Rewards Max             -0.0058651
evaluation/Rewards Min             -8.78503
evaluation/Returns Mean           -20.6795
evaluation/Returns Std             14.1569
evaluation/Returns Max             -2.29346
evaluation/Returns Min            -44.4886
evaluation/Actions Mean             0.0066992
evaluation/Actions Std              0.188742
evaluation/Actions Max              0.998614
evaluation/Actions Min             -0.997324
evaluation/Num Paths               15
evaluation/Average Returns        -20.6795
time/data storing (s)               0.00312395
time/evaluation sampling (s)        0.353917
time/exploration sampling (s)       0.159664
time/logging (s)                    0.00489438
time/saving (s)                     0.00210029
time/training (s)                   2.15189
time/epoch (s)                      2.67559
time/total (s)                    276.701
Epoch                             101
-----------------------------  ---------------
2019-04-22 21:42:40.312359 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              51700
trainer/QF1 Loss                    0.836614
trainer/QF2 Loss                    0.848055
trainer/Policy Loss                12.5334
trainer/Q1 Predictions Mean       -10.9093
trainer/Q1 Predictions Std          6.68376
trainer/Q1 Predictions Max         -7.4083
trainer/Q1 Predictions Min        -49.3251
trainer/Q2 Predictions Mean       -10.9364
trainer/Q2 Predictions Std          6.71034
trainer/Q2 Predictions Max         -7.4282
trainer/Q2 Predictions Min        -48.864
trainer/Q Targets Mean            -10.8422
trainer/Q Targets Std               6.77597
trainer/Q Targets Max              -0.228554
trainer/Q Targets Min             -49.4763
trainer/Log Pis Mean                2.1125
trainer/Log Pis Std                 1.20746
trainer/Log Pis Max                 5.5148
trainer/Log Pis Min                -1.76084
trainer/Policy mu Mean             -0.0284602
trainer/Policy mu Std               0.745895
trainer/Policy mu Max               3.15577
trainer/Policy mu Min              -2.72117
trainer/Policy log std Mean        -2.11576
trainer/Policy log std Std          0.499733
trainer/Policy log std Max         -0.508663
trainer/Policy log std Min         -2.65731
trainer/Alpha                       0.0631063
trainer/Alpha Loss                  0.310847
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.336997
exploration/Rewards Std             1.03684
exploration/Rewards Max            -0.0026193
exploration/Rewards Min            -9.7583
exploration/Returns Mean          -33.6997
exploration/Returns Std            16.2872
exploration/Returns Max           -18.2942
exploration/Returns Min           -63.1646
exploration/Actions Mean           -0.0180263
exploration/Actions Std             0.237955
exploration/Actions Max             0.996666
exploration/Actions Min            -0.996031
exploration/Num Paths               5
exploration/Average Returns       -33.6997
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.181254
evaluation/Rewards Std              0.792162
evaluation/Rewards Max             -0.00945346
evaluation/Rewards Min             -8.32534
evaluation/Returns Mean           -18.1254
evaluation/Returns Std             12.6339
evaluation/Returns Max             -3.44515
evaluation/Returns Min            -42.5904
evaluation/Actions Mean            -0.0123426
evaluation/Actions Std              0.174582
evaluation/Actions Max              0.995532
evaluation/Actions Min             -0.996533
evaluation/Num Paths               15
evaluation/Average Returns        -18.1254
time/data storing (s)               0.00327082
time/evaluation sampling (s)        0.405996
time/exploration sampling (s)       0.165263
time/logging (s)                    0.00507141
time/saving (s)                     0.00204937
time/training (s)                   2.13371
time/epoch (s)                      2.71536
time/total (s)                    279.42
Epoch                             102
-----------------------------  ---------------
2019-04-22 21:42:42.996335 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                    0.0917098
trainer/QF2 Loss                    0.0961226
trainer/Policy Loss                12.2365
trainer/Q1 Predictions Mean       -10.6929
trainer/Q1 Predictions Std          6.34802
trainer/Q1 Predictions Max         -7.38761
trainer/Q1 Predictions Min        -59.6984
trainer/Q2 Predictions Mean       -10.6884
trainer/Q2 Predictions Std          6.33028
trainer/Q2 Predictions Max         -7.35
trainer/Q2 Predictions Min        -59.6155
trainer/Q Targets Mean            -10.8102
trainer/Q Targets Std               6.48268
trainer/Q Targets Max              -7.40318
trainer/Q Targets Min             -62.0387
trainer/Log Pis Mean                1.92868
trainer/Log Pis Std                 1.52903
trainer/Log Pis Max                 5.31519
trainer/Log Pis Min                -6.95954
trainer/Policy mu Mean             -0.0593007
trainer/Policy mu Std               0.753952
trainer/Policy mu Max               3.41106
trainer/Policy mu Min              -3.09693
trainer/Policy log std Mean        -2.02367
trainer/Policy log std Std          0.517761
trainer/Policy log std Max         -0.407907
trainer/Policy log std Min         -2.65236
trainer/Alpha                       0.0624344
trainer/Alpha Loss                 -0.197803
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.393069
exploration/Rewards Std             1.05505
exploration/Rewards Max            -0.0114382
exploration/Rewards Min            -8.42975
exploration/Returns Mean          -39.3069
exploration/Returns Std            11.2802
exploration/Returns Max           -24.523
exploration/Returns Min           -53.4857
exploration/Actions Mean            0.0223921
exploration/Actions Std             0.251328
exploration/Actions Max             0.999251
exploration/Actions Min            -0.996022
exploration/Num Paths               5
exploration/Average Returns       -39.3069
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237912
evaluation/Rewards Std              0.970828
evaluation/Rewards Max             -0.0306384
evaluation/Rewards Min            -11.3386
evaluation/Returns Mean           -23.7912
evaluation/Returns Std             15.706
evaluation/Returns Max             -3.89055
evaluation/Returns Min            -57.8746
evaluation/Actions Mean            -0.0105685
evaluation/Actions Std              0.185366
evaluation/Actions Max              0.996445
evaluation/Actions Min             -0.997506
evaluation/Num Paths               15
evaluation/Average Returns        -23.7912
time/data storing (s)               0.00316287
time/evaluation sampling (s)        0.351108
time/exploration sampling (s)       0.160521
time/logging (s)                    0.00504372
time/saving (s)                     0.00214274
time/training (s)                   2.1551
time/epoch (s)                      2.67708
time/total (s)                    282.102
Epoch                             103
-----------------------------  ---------------
2019-04-22 21:42:45.677424 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              52700
trainer/QF1 Loss                    0.205018
trainer/QF2 Loss                    0.191225
trainer/Policy Loss                11.5864
trainer/Q1 Predictions Mean       -10.0667
trainer/Q1 Predictions Std          3.7668
trainer/Q1 Predictions Max         -7.35877
trainer/Q1 Predictions Min        -29.9071
trainer/Q2 Predictions Mean       -10.0809
trainer/Q2 Predictions Std          3.79649
trainer/Q2 Predictions Max         -7.34934
trainer/Q2 Predictions Min        -30.4107
trainer/Q Targets Mean            -10.3322
trainer/Q Targets Std               3.68162
trainer/Q Targets Max              -7.44952
trainer/Q Targets Min             -29.9
trainer/Log Pis Mean                1.99602
trainer/Log Pis Std                 1.22698
trainer/Log Pis Max                 6.2366
trainer/Log Pis Min                -1.61415
trainer/Policy mu Mean             -0.0640829
trainer/Policy mu Std               0.791238
trainer/Policy mu Max               2.88146
trainer/Policy mu Min              -2.83045
trainer/Policy log std Mean        -1.93554
trainer/Policy log std Std          0.507455
trainer/Policy log std Max         -0.496846
trainer/Policy log std Min         -2.49674
trainer/Alpha                       0.062104
trainer/Alpha Loss                 -0.0110633
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.364211
exploration/Rewards Std             1.04019
exploration/Rewards Max            -0.00786304
exploration/Rewards Min            -9.4116
exploration/Returns Mean          -36.4211
exploration/Returns Std            13.4628
exploration/Returns Max           -15.9639
exploration/Returns Min           -51.6065
exploration/Actions Mean           -0.00857686
exploration/Actions Std             0.247595
exploration/Actions Max             0.997702
exploration/Actions Min            -0.99929
exploration/Num Paths               5
exploration/Average Returns       -36.4211
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.190365
evaluation/Rewards Std              0.63092
evaluation/Rewards Max             -0.0275902
evaluation/Rewards Min             -6.55833
evaluation/Returns Mean           -19.0365
evaluation/Returns Std              7.41083
evaluation/Returns Max             -7.93319
evaluation/Returns Min            -32.5238
evaluation/Actions Mean             0.00484256
evaluation/Actions Std              0.170692
evaluation/Actions Max              0.994035
evaluation/Actions Min             -0.996898
evaluation/Num Paths               15
evaluation/Average Returns        -19.0365
time/data storing (s)               0.00325463
time/evaluation sampling (s)        0.354094
time/exploration sampling (s)       0.156713
time/logging (s)                    0.0044315
time/saving (s)                     0.0020054
time/training (s)                   2.15354
time/epoch (s)                      2.67404
time/total (s)                    284.78
Epoch                             104
-----------------------------  ---------------
2019-04-22 21:42:48.336419 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                    0.928801
trainer/QF2 Loss                    0.943727
trainer/Policy Loss                12.4841
trainer/Q1 Predictions Mean       -10.6038
trainer/Q1 Predictions Std          6.48361
trainer/Q1 Predictions Max         -7.42228
trainer/Q1 Predictions Min        -50.8673
trainer/Q2 Predictions Mean       -10.5797
trainer/Q2 Predictions Std          6.45356
trainer/Q2 Predictions Max         -7.39811
trainer/Q2 Predictions Min        -50.7528
trainer/Q Targets Mean            -10.6146
trainer/Q Targets Std               6.56125
trainer/Q Targets Max              -0.0852145
trainer/Q Targets Min             -51.4346
trainer/Log Pis Mean                2.21461
trainer/Log Pis Std                 1.33226
trainer/Log Pis Max                 7.42303
trainer/Log Pis Min                -1.05791
trainer/Policy mu Mean             -0.0690428
trainer/Policy mu Std               0.827072
trainer/Policy mu Max               3.65757
trainer/Policy mu Min              -2.80895
trainer/Policy log std Mean        -2.03286
trainer/Policy log std Std          0.531674
trainer/Policy log std Max         -0.374116
trainer/Policy log std Min         -2.56481
trainer/Alpha                       0.0613957
trainer/Alpha Loss                  0.59886
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.237576
exploration/Rewards Std             0.55624
exploration/Rewards Max            -0.00808094
exploration/Rewards Min            -6.78627
exploration/Returns Mean          -23.7576
exploration/Returns Std             8.86387
exploration/Returns Max           -15.8198
exploration/Returns Min           -41.0547
exploration/Actions Mean           -0.00221881
exploration/Actions Std             0.205762
exploration/Actions Max             0.997667
exploration/Actions Min            -0.998814
exploration/Num Paths               5
exploration/Average Returns       -23.7576
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.264844
evaluation/Rewards Std              0.941869
evaluation/Rewards Max             -0.0203727
evaluation/Rewards Min             -8.79972
evaluation/Returns Mean           -26.4844
evaluation/Returns Std             10.1539
evaluation/Returns Max             -8.19367
evaluation/Returns Min            -42.3629
evaluation/Actions Mean             0.00110157
evaluation/Actions Std              0.199286
evaluation/Actions Max              0.996137
evaluation/Actions Min             -0.996728
evaluation/Num Paths               15
evaluation/Average Returns        -26.4844
time/data storing (s)               0.00317913
time/evaluation sampling (s)        0.356693
time/exploration sampling (s)       0.163475
time/logging (s)                    0.00461014
time/saving (s)                     0.00212885
time/training (s)                   2.12229
time/epoch (s)                      2.65238
time/total (s)                    287.438
Epoch                             105
-----------------------------  ---------------
2019-04-22 21:42:51.084365 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size              53700
trainer/QF1 Loss                    0.836252
trainer/QF2 Loss                    0.847348
trainer/Policy Loss                11.334
trainer/Q1 Predictions Mean        -9.62837
trainer/Q1 Predictions Std          3.85172
trainer/Q1 Predictions Max         -7.28842
trainer/Q1 Predictions Min        -34.2687
trainer/Q2 Predictions Mean        -9.62747
trainer/Q2 Predictions Std          3.87745
trainer/Q2 Predictions Max         -7.29384
trainer/Q2 Predictions Min        -34.4801
trainer/Q Targets Mean             -9.54358
trainer/Q Targets Std               3.87088
trainer/Q Targets Max              -0.286384
trainer/Q Targets Min             -33.7222
trainer/Log Pis Mean                1.89344
trainer/Log Pis Std                 1.42576
trainer/Log Pis Max                 6.11139
trainer/Log Pis Min                -6.82683
trainer/Policy mu Mean             -0.0503111
trainer/Policy mu Std               0.594762
trainer/Policy mu Max               2.73639
trainer/Policy mu Min              -2.89689
trainer/Policy log std Mean        -2.15469
trainer/Policy log std Std          0.43576
trainer/Policy log std Max         -0.364745
trainer/Policy log std Min         -2.62775
trainer/Alpha                       0.0611472
trainer/Alpha Loss                 -0.297764
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.331645
exploration/Rewards Std             0.985191
exploration/Rewards Max            -0.00469784
exploration/Rewards Min            -8.71318
exploration/Returns Mean          -33.1645
exploration/Returns Std            14.6778
exploration/Returns Max           -20.4648
exploration/Returns Min           -53.0769
exploration/Actions Mean           -0.00185006
exploration/Actions Std             0.238062
exploration/Actions Max             0.998368
exploration/Actions Min            -0.998561
exploration/Num Paths               5
exploration/Average Returns       -33.1645
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.293396
evaluation/Rewards Std              1.15524
evaluation/Rewards Max             -0.00844197
evaluation/Rewards Min            -11.3456
evaluation/Returns Mean           -29.3396
evaluation/Returns Std             16.2593
evaluation/Returns Max             -5.91258
evaluation/Returns Min            -58.6414
evaluation/Actions Mean            -0.011644
evaluation/Actions Std              0.211742
evaluation/Actions Max              0.996649
evaluation/Actions Min             -0.99802
evaluation/Num Paths               15
evaluation/Average Returns        -29.3396
time/data storing (s)               0.00319197
time/evaluation sampling (s)        0.366646
time/exploration sampling (s)       0.168124
time/logging (s)                    0.00459965
time/saving (s)                     0.00202348
time/training (s)                   2.19654
time/epoch (s)                      2.74112
time/total (s)                    290.183
Epoch                             106
-----------------------------  ---------------
2019-04-22 21:42:53.744862 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              54200
trainer/QF1 Loss                    1.81121
trainer/QF2 Loss                    1.79957
trainer/Policy Loss                12.1096
trainer/Q1 Predictions Mean       -10.6924
trainer/Q1 Predictions Std          8.05875
trainer/Q1 Predictions Max         -7.40678
trainer/Q1 Predictions Min        -71.1332
trainer/Q2 Predictions Mean       -10.6487
trainer/Q2 Predictions Std          7.96578
trainer/Q2 Predictions Max         -7.39163
trainer/Q2 Predictions Min        -70.3248
trainer/Q Targets Mean            -10.5642
trainer/Q Targets Std               7.92045
trainer/Q Targets Max              -0.128929
trainer/Q Targets Min             -68.0088
trainer/Log Pis Mean                1.90227
trainer/Log Pis Std                 1.25288
trainer/Log Pis Max                 6.69511
trainer/Log Pis Min                -2.7014
trainer/Policy mu Mean              0.011291
trainer/Policy mu Std               0.725941
trainer/Policy mu Max               2.95714
trainer/Policy mu Min              -3.16295
trainer/Policy log std Mean        -2.06812
trainer/Policy log std Std          0.479641
trainer/Policy log std Max         -0.421932
trainer/Policy log std Min         -2.56672
trainer/Alpha                       0.0615785
trainer/Alpha Loss                 -0.272434
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.365605
exploration/Rewards Std             1.01269
exploration/Rewards Max            -0.0190773
exploration/Rewards Min            -9.30206
exploration/Returns Mean          -36.5605
exploration/Returns Std            15.9972
exploration/Returns Max           -19.7358
exploration/Returns Min           -63.3812
exploration/Actions Mean            0.0156352
exploration/Actions Std             0.265517
exploration/Actions Max             0.999244
exploration/Actions Min            -0.999139
exploration/Num Paths               5
exploration/Average Returns       -36.5605
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.232681
evaluation/Rewards Std              1.01167
evaluation/Rewards Max             -0.00256332
evaluation/Rewards Min            -10.6645
evaluation/Returns Mean           -23.2681
evaluation/Returns Std             13.8263
evaluation/Returns Max             -1.5517
evaluation/Returns Min            -59.5196
evaluation/Actions Mean            -0.00775909
evaluation/Actions Std              0.200538
evaluation/Actions Max              0.999321
evaluation/Actions Min             -0.997062
evaluation/Num Paths               15
evaluation/Average Returns        -23.2681
time/data storing (s)               0.00313495
time/evaluation sampling (s)        0.361068
time/exploration sampling (s)       0.165522
time/logging (s)                    0.00512029
time/saving (s)                     0.00206849
time/training (s)                   2.11691
time/epoch (s)                      2.65382
time/total (s)                    292.842
Epoch                             107
-----------------------------  ---------------
2019-04-22 21:42:56.440041 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              54700
trainer/QF1 Loss                    1.00552
trainer/QF2 Loss                    0.969822
trainer/Policy Loss                12.3082
trainer/Q1 Predictions Mean       -10.8015
trainer/Q1 Predictions Std          7.62538
trainer/Q1 Predictions Max         -7.0446
trainer/Q1 Predictions Min        -59.2216
trainer/Q2 Predictions Mean       -10.7816
trainer/Q2 Predictions Std          7.61183
trainer/Q2 Predictions Max         -7.00852
trainer/Q2 Predictions Min        -59.4227
trainer/Q Targets Mean            -10.7626
trainer/Q Targets Std               7.68452
trainer/Q Targets Max              -0.741465
trainer/Q Targets Min             -61.0698
trainer/Log Pis Mean                1.99236
trainer/Log Pis Std                 1.67468
trainer/Log Pis Max                 6.92046
trainer/Log Pis Min                -5.62156
trainer/Policy mu Mean              0.0846272
trainer/Policy mu Std               0.809778
trainer/Policy mu Max               3.84591
trainer/Policy mu Min              -2.80433
trainer/Policy log std Mean        -2.0711
trainer/Policy log std Std          0.505038
trainer/Policy log std Max         -0.351442
trainer/Policy log std Min         -2.60883
trainer/Alpha                       0.0635251
trainer/Alpha Loss                 -0.0210672
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.268491
exploration/Rewards Std             0.78274
exploration/Rewards Max            -0.00478162
exploration/Rewards Min            -6.59746
exploration/Returns Mean          -26.8491
exploration/Returns Std             8.47838
exploration/Returns Max           -12.5693
exploration/Returns Min           -34.579
exploration/Actions Mean           -0.0210873
exploration/Actions Std             0.211313
exploration/Actions Max             0.99457
exploration/Actions Min            -0.998981
exploration/Num Paths               5
exploration/Average Returns       -26.8491
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.178457
evaluation/Rewards Std              0.763832
evaluation/Rewards Max             -0.0024085
evaluation/Rewards Min             -8.55718
evaluation/Returns Mean           -17.8457
evaluation/Returns Std             10.9335
evaluation/Returns Max             -4.23273
evaluation/Returns Min            -39.8974
evaluation/Actions Mean             0.00888693
evaluation/Actions Std              0.176647
evaluation/Actions Max              0.997077
evaluation/Actions Min             -0.995201
evaluation/Num Paths               15
evaluation/Average Returns        -17.8457
time/data storing (s)               0.00321447
time/evaluation sampling (s)        0.36152
time/exploration sampling (s)       0.165835
time/logging (s)                    0.00485176
time/saving (s)                     0.00200975
time/training (s)                   2.15061
time/epoch (s)                      2.68804
time/total (s)                    295.535
Epoch                             108
-----------------------------  ---------------
2019-04-22 21:42:59.158601 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                    1.16577
trainer/QF2 Loss                    1.15226
trainer/Policy Loss                12.3995
trainer/Q1 Predictions Mean       -10.8433
trainer/Q1 Predictions Std          8.38138
trainer/Q1 Predictions Max         -7.32034
trainer/Q1 Predictions Min        -67.9706
trainer/Q2 Predictions Mean       -10.8598
trainer/Q2 Predictions Std          8.39094
trainer/Q2 Predictions Max         -7.33737
trainer/Q2 Predictions Min        -67.9952
trainer/Q Targets Mean            -10.6324
trainer/Q Targets Std               8.65908
trainer/Q Targets Max              -0.0304702
trainer/Q Targets Min             -68.8219
trainer/Log Pis Mean                2.18328
trainer/Log Pis Std                 1.45103
trainer/Log Pis Max                 8.56693
trainer/Log Pis Min                -1.55921
trainer/Policy mu Mean             -0.0241803
trainer/Policy mu Std               0.810106
trainer/Policy mu Max               3.11743
trainer/Policy mu Min              -3.14857
trainer/Policy log std Mean        -2.03442
trainer/Policy log std Std          0.5208
trainer/Policy log std Max         -0.334806
trainer/Policy log std Min         -2.49678
trainer/Alpha                       0.0624457
trainer/Alpha Loss                  0.508309
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.172673
exploration/Rewards Std             0.312979
exploration/Rewards Max            -0.0053388
exploration/Rewards Min            -4.09294
exploration/Returns Mean          -17.2673
exploration/Returns Std             4.37707
exploration/Returns Max           -11.405
exploration/Returns Min           -22.641
exploration/Actions Mean            0.00439423
exploration/Actions Std             0.185133
exploration/Actions Max             0.997828
exploration/Actions Min            -0.974952
exploration/Num Paths               5
exploration/Average Returns       -17.2673
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.19225
evaluation/Rewards Std              0.848368
evaluation/Rewards Max             -0.00858964
evaluation/Rewards Min             -8.76007
evaluation/Returns Mean           -19.225
evaluation/Returns Std             13.8707
evaluation/Returns Max             -1.70306
evaluation/Returns Min            -48.367
evaluation/Actions Mean            -0.0104386
evaluation/Actions Std              0.178493
evaluation/Actions Max              0.994928
evaluation/Actions Min             -0.996805
evaluation/Num Paths               15
evaluation/Average Returns        -19.225
time/data storing (s)               0.00311357
time/evaluation sampling (s)        0.399361
time/exploration sampling (s)       0.20447
time/logging (s)                    0.00402023
time/saving (s)                     0.00198792
time/training (s)                   2.09803
time/epoch (s)                      2.71098
time/total (s)                    298.25
Epoch                             109
-----------------------------  ---------------
2019-04-22 21:43:01.872444 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              55700
trainer/QF1 Loss                    0.0287601
trainer/QF2 Loss                    0.0323615
trainer/Policy Loss                10.8933
trainer/Q1 Predictions Mean        -9.29686
trainer/Q1 Predictions Std          4.24884
trainer/Q1 Predictions Max         -7.08102
trainer/Q1 Predictions Min        -48.2934
trainer/Q2 Predictions Mean        -9.28809
trainer/Q2 Predictions Std          4.22591
trainer/Q2 Predictions Max         -7.08899
trainer/Q2 Predictions Min        -48.0289
trainer/Q Targets Mean             -9.43502
trainer/Q Targets Std               4.26405
trainer/Q Targets Max              -7.20126
trainer/Q Targets Min             -48.5404
trainer/Log Pis Mean                1.81377
trainer/Log Pis Std                 1.02397
trainer/Log Pis Max                 5.93128
trainer/Log Pis Min                -1.41552
trainer/Policy mu Mean              0.0326172
trainer/Policy mu Std               0.526198
trainer/Policy mu Max               3.46106
trainer/Policy mu Min              -1.72921
trainer/Policy log std Mean        -2.15392
trainer/Policy log std Std          0.364874
trainer/Policy log std Max         -0.532903
trainer/Policy log std Min         -2.56706
trainer/Alpha                       0.0600299
trainer/Alpha Loss                 -0.523865
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.305894
exploration/Rewards Std             0.891262
exploration/Rewards Max            -0.00802662
exploration/Rewards Min            -9.29603
exploration/Returns Mean          -30.5894
exploration/Returns Std            10.3165
exploration/Returns Max           -16.1492
exploration/Returns Min           -48.0944
exploration/Actions Mean           -0.0238494
exploration/Actions Std             0.247245
exploration/Actions Max             0.99891
exploration/Actions Min            -0.998951
exploration/Num Paths               5
exploration/Average Returns       -30.5894
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.179734
evaluation/Rewards Std              0.84121
evaluation/Rewards Max             -0.012085
evaluation/Rewards Min            -10.883
evaluation/Returns Mean           -17.9734
evaluation/Returns Std             16.8612
evaluation/Returns Max             -4.09479
evaluation/Returns Min            -65.0353
evaluation/Actions Mean             0.00312026
evaluation/Actions Std              0.167205
evaluation/Actions Max              0.999265
evaluation/Actions Min             -0.995487
evaluation/Num Paths               15
evaluation/Average Returns        -17.9734
time/data storing (s)               0.00322705
time/evaluation sampling (s)        0.351215
time/exploration sampling (s)       0.161723
time/logging (s)                    0.00600935
time/saving (s)                     0.0025097
time/training (s)                   2.18453
time/epoch (s)                      2.70922
time/total (s)                    300.965
Epoch                             110
-----------------------------  ---------------
2019-04-22 21:43:04.550563 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                    0.0381185
trainer/QF2 Loss                    0.0355652
trainer/Policy Loss                10.9495
trainer/Q1 Predictions Mean        -9.53715
trainer/Q1 Predictions Std          5.04988
trainer/Q1 Predictions Max         -7.10781
trainer/Q1 Predictions Min        -47.0602
trainer/Q2 Predictions Mean        -9.5261
trainer/Q2 Predictions Std          5.05163
trainer/Q2 Predictions Max         -7.09059
trainer/Q2 Predictions Min        -47.3873
trainer/Q Targets Mean             -9.60714
trainer/Q Targets Std               5.09509
trainer/Q Targets Max              -7.16036
trainer/Q Targets Min             -47.8911
trainer/Log Pis Mean                1.84432
trainer/Log Pis Std                 1.23452
trainer/Log Pis Max                 5.85733
trainer/Log Pis Min                -2.58898
trainer/Policy mu Mean              0.0114964
trainer/Policy mu Std               0.596795
trainer/Policy mu Max               2.97255
trainer/Policy mu Min              -2.27475
trainer/Policy log std Mean        -2.11211
trainer/Policy log std Std          0.412918
trainer/Policy log std Max         -0.697253
trainer/Policy log std Min         -2.66472
trainer/Alpha                       0.0599698
trainer/Alpha Loss                 -0.438077
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.288859
exploration/Rewards Std             0.770851
exploration/Rewards Max            -0.0149859
exploration/Rewards Min            -6.31802
exploration/Returns Mean          -28.8859
exploration/Returns Std             8.02388
exploration/Returns Max           -15.5252
exploration/Returns Min           -37.1679
exploration/Actions Mean           -0.010302
exploration/Actions Std             0.218321
exploration/Actions Max             0.994648
exploration/Actions Min            -0.999132
exploration/Num Paths               5
exploration/Average Returns       -28.8859
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.307205
evaluation/Rewards Std              1.12736
evaluation/Rewards Max             -0.0108491
evaluation/Rewards Min            -10.084
evaluation/Returns Mean           -30.7205
evaluation/Returns Std             17.2569
evaluation/Returns Max             -3.37461
evaluation/Returns Min            -60.7012
evaluation/Actions Mean            -0.0186046
evaluation/Actions Std              0.214129
evaluation/Actions Max              0.998661
evaluation/Actions Min             -0.997882
evaluation/Num Paths               15
evaluation/Average Returns        -30.7205
time/data storing (s)               0.00316728
time/evaluation sampling (s)        0.366552
time/exploration sampling (s)       0.165667
time/logging (s)                    0.00438288
time/saving (s)                     0.0021476
time/training (s)                   2.1263
time/epoch (s)                      2.66822
time/total (s)                    303.638
Epoch                             111
-----------------------------  ---------------
2019-04-22 21:43:07.196030 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              56700
trainer/QF1 Loss                    4.79841
trainer/QF2 Loss                    4.86539
trainer/Policy Loss                12.0847
trainer/Q1 Predictions Mean       -10.7914
trainer/Q1 Predictions Std          8.70286
trainer/Q1 Predictions Max         -7.2025
trainer/Q1 Predictions Min        -67.7354
trainer/Q2 Predictions Mean       -10.8106
trainer/Q2 Predictions Std          8.74232
trainer/Q2 Predictions Max         -7.18729
trainer/Q2 Predictions Min        -68.3203
trainer/Q Targets Mean            -10.5954
trainer/Q Targets Std               8.51457
trainer/Q Targets Max              -6.42437
trainer/Q Targets Min             -66.8261
trainer/Log Pis Mean                1.80097
trainer/Log Pis Std                 1.25857
trainer/Log Pis Max                 5.68255
trainer/Log Pis Min                -3.01771
trainer/Policy mu Mean              0.0229901
trainer/Policy mu Std               0.779885
trainer/Policy mu Max               3.52573
trainer/Policy mu Min              -3.29378
trainer/Policy log std Mean        -1.98585
trainer/Policy log std Std          0.521463
trainer/Policy log std Max         -0.168667
trainer/Policy log std Min         -2.44123
trainer/Alpha                       0.0603586
trainer/Alpha Loss                 -0.55878
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.416237
exploration/Rewards Std             1.22039
exploration/Rewards Max            -0.00697683
exploration/Rewards Min           -11.0897
exploration/Returns Mean          -41.6237
exploration/Returns Std            15.4102
exploration/Returns Max           -18.1298
exploration/Returns Min           -66.5555
exploration/Actions Mean           -0.0103969
exploration/Actions Std             0.269797
exploration/Actions Max             0.996484
exploration/Actions Min            -0.998462
exploration/Num Paths               5
exploration/Average Returns       -41.6237
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274733
evaluation/Rewards Std              1.06851
evaluation/Rewards Max             -0.00883369
evaluation/Rewards Min             -9.19199
evaluation/Returns Mean           -27.4733
evaluation/Returns Std             13.1146
evaluation/Returns Max             -5.33998
evaluation/Returns Min            -47.7604
evaluation/Actions Mean             0.00270435
evaluation/Actions Std              0.206091
evaluation/Actions Max              0.997871
evaluation/Actions Min             -0.995766
evaluation/Num Paths               15
evaluation/Average Returns        -27.4733
time/data storing (s)               0.00323166
time/evaluation sampling (s)        0.361477
time/exploration sampling (s)       0.16593
time/logging (s)                    0.00476647
time/saving (s)                     0.00207933
time/training (s)                   2.10243
time/epoch (s)                      2.63991
time/total (s)                    306.282
Epoch                             112
-----------------------------  ---------------
2019-04-22 21:43:09.951531 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 113 finished
-----------------------------  ----------------
replay_buffer/size              57200
trainer/QF1 Loss                    0.178196
trainer/QF2 Loss                    0.150046
trainer/Policy Loss                11.8808
trainer/Q1 Predictions Mean       -10.3779
trainer/Q1 Predictions Std          6.49254
trainer/Q1 Predictions Max         -7.07144
trainer/Q1 Predictions Min        -56.7945
trainer/Q2 Predictions Mean       -10.3807
trainer/Q2 Predictions Std          6.45364
trainer/Q2 Predictions Max         -7.06512
trainer/Q2 Predictions Min        -56.3497
trainer/Q Targets Mean            -10.3994
trainer/Q Targets Std               6.11265
trainer/Q Targets Max              -7.13397
trainer/Q Targets Min             -53.7051
trainer/Log Pis Mean                2.01894
trainer/Log Pis Std                 1.32767
trainer/Log Pis Max                 7.90497
trainer/Log Pis Min                -0.839715
trainer/Policy mu Mean             -0.0982435
trainer/Policy mu Std               0.774583
trainer/Policy mu Max               2.50825
trainer/Policy mu Min              -3.48158
trainer/Policy log std Mean        -2.02237
trainer/Policy log std Std          0.492923
trainer/Policy log std Max         -0.515413
trainer/Policy log std Min         -2.68213
trainer/Alpha                       0.062448
trainer/Alpha Loss                  0.0525188
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.28816
exploration/Rewards Std             0.790348
exploration/Rewards Max            -0.0103336
exploration/Rewards Min            -6.90686
exploration/Returns Mean          -28.816
exploration/Returns Std             9.02986
exploration/Returns Max           -11.6232
exploration/Returns Min           -38.0939
exploration/Actions Mean           -0.00558836
exploration/Actions Std             0.239182
exploration/Actions Max             0.998905
exploration/Actions Min            -0.999038
exploration/Num Paths               5
exploration/Average Returns       -28.816
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225998
evaluation/Rewards Std              1.03567
evaluation/Rewards Max             -0.0185428
evaluation/Rewards Min            -11.8882
evaluation/Returns Mean           -22.5998
evaluation/Returns Std             17.1287
evaluation/Returns Max             -3.28445
evaluation/Returns Min            -60.1771
evaluation/Actions Mean            -0.000394251
evaluation/Actions Std              0.199119
evaluation/Actions Max              0.997722
evaluation/Actions Min             -0.997898
evaluation/Num Paths               15
evaluation/Average Returns        -22.5998
time/data storing (s)               0.0045462
time/evaluation sampling (s)        0.377522
time/exploration sampling (s)       0.176795
time/logging (s)                    0.00503889
time/saving (s)                     0.00222059
time/training (s)                   2.18286
time/epoch (s)                      2.74898
time/total (s)                    309.036
Epoch                             113
-----------------------------  ----------------
2019-04-22 21:43:12.632844 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              57700
trainer/QF1 Loss                    0.788824
trainer/QF2 Loss                    0.7921
trainer/Policy Loss                10.874
trainer/Q1 Predictions Mean        -9.2708
trainer/Q1 Predictions Std          4.6882
trainer/Q1 Predictions Max         -7.02243
trainer/Q1 Predictions Min        -51.4997
trainer/Q2 Predictions Mean        -9.25031
trainer/Q2 Predictions Std          4.62629
trainer/Q2 Predictions Max         -6.9917
trainer/Q2 Predictions Min        -50.844
trainer/Q Targets Mean             -9.37269
trainer/Q Targets Std               4.84836
trainer/Q Targets Max              -0.189281
trainer/Q Targets Min             -52.603
trainer/Log Pis Mean                1.91451
trainer/Log Pis Std                 1.17868
trainer/Log Pis Max                 7.32782
trainer/Log Pis Min                -1.68386
trainer/Policy mu Mean              0.0213515
trainer/Policy mu Std               0.591542
trainer/Policy mu Max               3.02778
trainer/Policy mu Min              -2.93049
trainer/Policy log std Mean        -2.103
trainer/Policy log std Std          0.409823
trainer/Policy log std Max         -0.445193
trainer/Policy log std Min         -2.65831
trainer/Alpha                       0.0620186
trainer/Alpha Loss                 -0.237695
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.363531
exploration/Rewards Std             0.991948
exploration/Rewards Max            -0.00636094
exploration/Rewards Min            -8.31794
exploration/Returns Mean          -36.3531
exploration/Returns Std             7.9655
exploration/Returns Max           -25.8868
exploration/Returns Min           -46.2796
exploration/Actions Mean           -0.0147737
exploration/Actions Std             0.256746
exploration/Actions Max             0.9988
exploration/Actions Min            -0.99936
exploration/Num Paths               5
exploration/Average Returns       -36.3531
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.227012
evaluation/Rewards Std              0.876219
evaluation/Rewards Max             -0.0332626
evaluation/Rewards Min            -10.8102
evaluation/Returns Mean           -22.7012
evaluation/Returns Std             13.4898
evaluation/Returns Max             -8.86721
evaluation/Returns Min            -58.8798
evaluation/Actions Mean            -0.00438547
evaluation/Actions Std              0.19451
evaluation/Actions Max              0.998931
evaluation/Actions Min             -0.994912
evaluation/Num Paths               15
evaluation/Average Returns        -22.7012
time/data storing (s)               0.00339829
time/evaluation sampling (s)        0.355185
time/exploration sampling (s)       0.161504
time/logging (s)                    0.00504524
time/saving (s)                     0.00226849
time/training (s)                   2.14712
time/epoch (s)                      2.67452
time/total (s)                    311.715
Epoch                             114
-----------------------------  ---------------
2019-04-22 21:43:15.341688 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                    0.863933
trainer/QF2 Loss                    0.843717
trainer/Policy Loss                11.9938
trainer/Q1 Predictions Mean       -10.6059
trainer/Q1 Predictions Std          7.89253
trainer/Q1 Predictions Max         -7.20615
trainer/Q1 Predictions Min        -69.3186
trainer/Q2 Predictions Mean       -10.606
trainer/Q2 Predictions Std          7.83387
trainer/Q2 Predictions Max         -7.17234
trainer/Q2 Predictions Min        -68.8417
trainer/Q Targets Mean            -10.4856
trainer/Q Targets Std               7.78511
trainer/Q Targets Max              -0.176253
trainer/Q Targets Min             -66.6663
trainer/Log Pis Mean                1.98371
trainer/Log Pis Std                 1.39142
trainer/Log Pis Max                 8.02962
trainer/Log Pis Min                -3.54052
trainer/Policy mu Mean             -0.136395
trainer/Policy mu Std               0.80209
trainer/Policy mu Max               2.87447
trainer/Policy mu Min              -3.21735
trainer/Policy log std Mean        -1.98631
trainer/Policy log std Std          0.522166
trainer/Policy log std Max         -0.502033
trainer/Policy log std Min         -2.54125
trainer/Alpha                       0.0620768
trainer/Alpha Loss                 -0.0452793
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.438902
exploration/Rewards Std             1.33147
exploration/Rewards Max            -0.00321782
exploration/Rewards Min           -10.4261
exploration/Returns Mean          -43.8902
exploration/Returns Std            15.559
exploration/Returns Max           -25.2519
exploration/Returns Min           -63.1551
exploration/Actions Mean           -0.0340875
exploration/Actions Std             0.264425
exploration/Actions Max             0.999844
exploration/Actions Min            -0.999129
exploration/Num Paths               5
exploration/Average Returns       -43.8902
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260897
evaluation/Rewards Std              1.03688
evaluation/Rewards Max             -0.0137584
evaluation/Rewards Min             -9.35743
evaluation/Returns Mean           -26.0897
evaluation/Returns Std             15.5216
evaluation/Returns Max             -4.51315
evaluation/Returns Min            -52.7224
evaluation/Actions Mean            -0.0201875
evaluation/Actions Std              0.196271
evaluation/Actions Max              0.998346
evaluation/Actions Min             -0.997883
evaluation/Num Paths               15
evaluation/Average Returns        -26.0897
time/data storing (s)               0.00328309
time/evaluation sampling (s)        0.360732
time/exploration sampling (s)       0.161622
time/logging (s)                    0.00486073
time/saving (s)                     0.001663
time/training (s)                   2.16941
time/epoch (s)                      2.70157
time/total (s)                    314.421
Epoch                             115
-----------------------------  ---------------
2019-04-22 21:43:17.990635 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              58700
trainer/QF1 Loss                    1.88654
trainer/QF2 Loss                    1.94268
trainer/Policy Loss                11.8259
trainer/Q1 Predictions Mean       -10.1663
trainer/Q1 Predictions Std          7.80581
trainer/Q1 Predictions Max         -6.98965
trainer/Q1 Predictions Min        -63.5711
trainer/Q2 Predictions Mean       -10.1438
trainer/Q2 Predictions Std          7.77876
trainer/Q2 Predictions Max         -6.96412
trainer/Q2 Predictions Min        -62.7147
trainer/Q Targets Mean            -10.1019
trainer/Q Targets Std               8.24618
trainer/Q Targets Max              -0.121256
trainer/Q Targets Min             -65.4086
trainer/Log Pis Mean                2.03913
trainer/Log Pis Std                 0.968733
trainer/Log Pis Max                 5.48178
trainer/Log Pis Min                -1.0805
trainer/Policy mu Mean             -0.0207466
trainer/Policy mu Std               0.694573
trainer/Policy mu Max               2.9441
trainer/Policy mu Min              -3.2558
trainer/Policy log std Mean        -2.04422
trainer/Policy log std Std          0.481118
trainer/Policy log std Max         -0.438802
trainer/Policy log std Min         -2.55529
trainer/Alpha                       0.0607686
trainer/Alpha Loss                  0.109581
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.24601
exploration/Rewards Std             0.66484
exploration/Rewards Max            -0.00448939
exploration/Rewards Min            -8.43266
exploration/Returns Mean          -24.601
exploration/Returns Std            10.5726
exploration/Returns Max           -15.6119
exploration/Returns Min           -44.4026
exploration/Actions Mean           -0.0161953
exploration/Actions Std             0.211487
exploration/Actions Max             0.998007
exploration/Actions Min            -0.998075
exploration/Num Paths               5
exploration/Average Returns       -24.601
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283797
evaluation/Rewards Std              1.14932
evaluation/Rewards Max             -0.011537
evaluation/Rewards Min            -10.1185
evaluation/Returns Mean           -28.3797
evaluation/Returns Std             18.1763
evaluation/Returns Max             -1.42355
evaluation/Returns Min            -57.3007
evaluation/Actions Mean             0.0155551
evaluation/Actions Std              0.204031
evaluation/Actions Max              0.997163
evaluation/Actions Min             -0.996135
evaluation/Num Paths               15
evaluation/Average Returns        -28.3797
time/data storing (s)               0.00328412
time/evaluation sampling (s)        0.359786
time/exploration sampling (s)       0.163529
time/logging (s)                    0.00442719
time/saving (s)                     0.00217523
time/training (s)                   2.10796
time/epoch (s)                      2.64116
time/total (s)                    317.067
Epoch                             116
-----------------------------  ---------------
2019-04-22 21:43:20.682394 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              59200
trainer/QF1 Loss                    0.0369614
trainer/QF2 Loss                    0.047135
trainer/Policy Loss                10.3377
trainer/Q1 Predictions Mean        -8.60943
trainer/Q1 Predictions Std          1.6339
trainer/Q1 Predictions Max         -7.14073
trainer/Q1 Predictions Min        -18.5263
trainer/Q2 Predictions Mean        -8.59868
trainer/Q2 Predictions Std          1.61375
trainer/Q2 Predictions Max         -7.08897
trainer/Q2 Predictions Min        -18.3181
trainer/Q Targets Mean             -8.72888
trainer/Q Targets Std               1.67704
trainer/Q Targets Max              -7.09868
trainer/Q Targets Min             -18.6955
trainer/Log Pis Mean                1.91895
trainer/Log Pis Std                 1.10502
trainer/Log Pis Max                 5.26819
trainer/Log Pis Min                -1.13508
trainer/Policy mu Mean             -0.050773
trainer/Policy mu Std               0.602205
trainer/Policy mu Max               2.49708
trainer/Policy mu Min              -2.85649
trainer/Policy log std Mean        -2.11148
trainer/Policy log std Std          0.407578
trainer/Policy log std Max         -0.522767
trainer/Policy log std Min         -2.5692
trainer/Alpha                       0.0586914
trainer/Alpha Loss                 -0.229801
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332412
exploration/Rewards Std             0.922396
exploration/Rewards Max            -0.00113851
exploration/Rewards Min            -7.46633
exploration/Returns Mean          -33.2412
exploration/Returns Std             5.08573
exploration/Returns Max           -26.3033
exploration/Returns Min           -39.5136
exploration/Actions Mean            0.0288467
exploration/Actions Std             0.243326
exploration/Actions Max             0.999524
exploration/Actions Min            -0.998919
exploration/Num Paths               5
exploration/Average Returns       -33.2412
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233773
evaluation/Rewards Std              0.972722
evaluation/Rewards Max             -0.0277992
evaluation/Rewards Min             -9.44981
evaluation/Returns Mean           -23.3773
evaluation/Returns Std             15.3132
evaluation/Returns Max             -4.29357
evaluation/Returns Min            -56.4544
evaluation/Actions Mean             0.0169393
evaluation/Actions Std              0.191117
evaluation/Actions Max              0.998512
evaluation/Actions Min             -0.996167
evaluation/Num Paths               15
evaluation/Average Returns        -23.3773
time/data storing (s)               0.00304388
time/evaluation sampling (s)        0.346048
time/exploration sampling (s)       0.157649
time/logging (s)                    0.00489909
time/saving (s)                     0.0020684
time/training (s)                   2.17168
time/epoch (s)                      2.68539
time/total (s)                    319.757
Epoch                             117
-----------------------------  ---------------
2019-04-22 21:43:23.364743 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              59700
trainer/QF1 Loss                    0.033657
trainer/QF2 Loss                    0.0214995
trainer/Policy Loss                11.1068
trainer/Q1 Predictions Mean        -9.49148
trainer/Q1 Predictions Std          5.61268
trainer/Q1 Predictions Max         -7.07236
trainer/Q1 Predictions Min        -52.0491
trainer/Q2 Predictions Mean        -9.47684
trainer/Q2 Predictions Std          5.5748
trainer/Q2 Predictions Max         -7.0307
trainer/Q2 Predictions Min        -52.2231
trainer/Q Targets Mean             -9.50591
trainer/Q Targets Std               5.58158
trainer/Q Targets Max              -6.98398
trainer/Q Targets Min             -52.2062
trainer/Log Pis Mean                1.77892
trainer/Log Pis Std                 1.69197
trainer/Log Pis Max                 8.13634
trainer/Log Pis Min                -6.07045
trainer/Policy mu Mean             -0.0404474
trainer/Policy mu Std               0.716358
trainer/Policy mu Max               3.03875
trainer/Policy mu Min              -3.04544
trainer/Policy log std Mean        -2.10679
trainer/Policy log std Std          0.477266
trainer/Policy log std Max         -0.507648
trainer/Policy log std Min         -2.64561
trainer/Alpha                       0.0578884
trainer/Alpha Loss                 -0.629917
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.291003
exploration/Rewards Std             0.843076
exploration/Rewards Max            -0.00295553
exploration/Rewards Min            -9.06973
exploration/Returns Mean          -29.1003
exploration/Returns Std            17.1489
exploration/Returns Max           -13.9668
exploration/Returns Min           -62.3581
exploration/Actions Mean            0.0112097
exploration/Actions Std             0.233729
exploration/Actions Max             0.998181
exploration/Actions Min            -0.996759
exploration/Num Paths               5
exploration/Average Returns       -29.1003
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260203
evaluation/Rewards Std              1.0015
evaluation/Rewards Max             -0.0219593
evaluation/Rewards Min             -9.33084
evaluation/Returns Mean           -26.0203
evaluation/Returns Std             13.5927
evaluation/Returns Max             -9.44085
evaluation/Returns Min            -53.6509
evaluation/Actions Mean             0.0163615
evaluation/Actions Std              0.203231
evaluation/Actions Max              0.996401
evaluation/Actions Min             -0.995801
evaluation/Num Paths               15
evaluation/Average Returns        -26.0203
time/data storing (s)               0.00325389
time/evaluation sampling (s)        0.362687
time/exploration sampling (s)       0.161716
time/logging (s)                    0.00502373
time/saving (s)                     0.00217907
time/training (s)                   2.14009
time/epoch (s)                      2.67495
time/total (s)                    322.437
Epoch                             118
-----------------------------  ---------------
2019-04-22 21:43:26.082470 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size              60200
trainer/QF1 Loss                    0.0729185
trainer/QF2 Loss                    0.0778355
trainer/Policy Loss                11.2191
trainer/Q1 Predictions Mean        -9.47915
trainer/Q1 Predictions Std          5.2782
trainer/Q1 Predictions Max         -6.8621
trainer/Q1 Predictions Min        -41.7051
trainer/Q2 Predictions Mean        -9.47702
trainer/Q2 Predictions Std          5.21786
trainer/Q2 Predictions Max         -6.81148
trainer/Q2 Predictions Min        -41.8684
trainer/Q Targets Mean             -9.66495
trainer/Q Targets Std               5.23519
trainer/Q Targets Max              -7.0586
trainer/Q Targets Min             -41.9377
trainer/Log Pis Mean                2.02004
trainer/Log Pis Std                 1.19967
trainer/Log Pis Max                 6.3857
trainer/Log Pis Min                -3.29872
trainer/Policy mu Mean             -0.0584938
trainer/Policy mu Std               0.747619
trainer/Policy mu Max               2.9556
trainer/Policy mu Min              -3.02442
trainer/Policy log std Mean        -2.04987
trainer/Policy log std Std          0.515787
trainer/Policy log std Max         -0.501842
trainer/Policy log std Min         -2.56142
trainer/Alpha                       0.0590895
trainer/Alpha Loss                  0.056683
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.363786
exploration/Rewards Std             1.13071
exploration/Rewards Max            -0.00298769
exploration/Rewards Min           -11.3802
exploration/Returns Mean          -36.3786
exploration/Returns Std            19.0612
exploration/Returns Max           -17.0516
exploration/Returns Min           -69.5725
exploration/Actions Mean           -0.016659
exploration/Actions Std             0.244822
exploration/Actions Max             0.999247
exploration/Actions Min            -0.999828
exploration/Num Paths               5
exploration/Average Returns       -36.3786
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199034
evaluation/Rewards Std              0.765205
evaluation/Rewards Max             -0.0144326
evaluation/Rewards Min             -8.10442
evaluation/Returns Mean           -19.9034
evaluation/Returns Std             10.9713
evaluation/Returns Max             -6.71334
evaluation/Returns Min            -44.8794
evaluation/Actions Mean             0.00277272
evaluation/Actions Std              0.185276
evaluation/Actions Max              0.993865
evaluation/Actions Min             -0.997463
evaluation/Num Paths               15
evaluation/Average Returns        -19.9034
time/data storing (s)               0.00344947
time/evaluation sampling (s)        0.354527
time/exploration sampling (s)       0.160189
time/logging (s)                    0.00493296
time/saving (s)                     0.00214711
time/training (s)                   2.18539
time/epoch (s)                      2.71063
time/total (s)                    325.153
Epoch                             119
-----------------------------  ---------------
2019-04-22 21:43:28.766497 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 120 finished
-----------------------------  ----------------
replay_buffer/size              60700
trainer/QF1 Loss                    0.836114
trainer/QF2 Loss                    0.784229
trainer/Policy Loss                10.7739
trainer/Q1 Predictions Mean        -9.02828
trainer/Q1 Predictions Std          3.14458
trainer/Q1 Predictions Max         -7.14633
trainer/Q1 Predictions Min        -29.1199
trainer/Q2 Predictions Mean        -9.01812
trainer/Q2 Predictions Std          3.13082
trainer/Q2 Predictions Max         -7.09507
trainer/Q2 Predictions Min        -29.8139
trainer/Q Targets Mean             -8.96029
trainer/Q Targets Std               3.28231
trainer/Q Targets Max              -0.0444335
trainer/Q Targets Min             -30.3518
trainer/Log Pis Mean                2.05224
trainer/Log Pis Std                 1.32391
trainer/Log Pis Max                 7.20241
trainer/Log Pis Min                -4.87752
trainer/Policy mu Mean              0.0290795
trainer/Policy mu Std               0.607398
trainer/Policy mu Max               2.85943
trainer/Policy mu Min              -2.50164
trainer/Policy log std Mean        -2.17289
trainer/Policy log std Std          0.420017
trainer/Policy log std Max         -0.502355
trainer/Policy log std Min         -2.69473
trainer/Alpha                       0.0596291
trainer/Alpha Loss                  0.147304
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.301974
exploration/Rewards Std             0.857149
exploration/Rewards Max            -0.00162119
exploration/Rewards Min            -8.17939
exploration/Returns Mean          -30.1974
exploration/Returns Std             9.90983
exploration/Returns Max           -12.7504
exploration/Returns Min           -43.317
exploration/Actions Mean            3.48568e-05
exploration/Actions Std             0.240472
exploration/Actions Max             0.995877
exploration/Actions Min            -0.999007
exploration/Num Paths               5
exploration/Average Returns       -30.1974
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.254913
evaluation/Rewards Std              1.09335
evaluation/Rewards Max             -0.013644
evaluation/Rewards Min            -10.2937
evaluation/Returns Mean           -25.4913
evaluation/Returns Std             16.7659
evaluation/Returns Max             -4.35073
evaluation/Returns Min            -54.936
evaluation/Actions Mean             0.00673612
evaluation/Actions Std              0.200769
evaluation/Actions Max              0.999014
evaluation/Actions Min             -0.996861
evaluation/Num Paths               15
evaluation/Average Returns        -25.4913
time/data storing (s)               0.00329632
time/evaluation sampling (s)        0.370796
time/exploration sampling (s)       0.165428
time/logging (s)                    0.00501795
time/saving (s)                     0.00213848
time/training (s)                   2.13022
time/epoch (s)                      2.6769
time/total (s)                    327.834
Epoch                             120
-----------------------------  ----------------
2019-04-22 21:43:31.439864 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              61200
trainer/QF1 Loss                   26.8848
trainer/QF2 Loss                   27.0053
trainer/Policy Loss                11.1472
trainer/Q1 Predictions Mean        -9.51556
trainer/Q1 Predictions Std          6.61911
trainer/Q1 Predictions Max         -6.81947
trainer/Q1 Predictions Min        -62.1339
trainer/Q2 Predictions Mean        -9.51555
trainer/Q2 Predictions Std          6.59384
trainer/Q2 Predictions Max         -6.81667
trainer/Q2 Predictions Min        -62.2562
trainer/Q Targets Mean             -9.11895
trainer/Q Targets Std               3.8513
trainer/Q Targets Max              -6.94859
trainer/Q Targets Min             -43.1689
trainer/Log Pis Mean                2.00432
trainer/Log Pis Std                 1.56004
trainer/Log Pis Max                 7.68931
trainer/Log Pis Min                -5.26606
trainer/Policy mu Mean             -0.0335169
trainer/Policy mu Std               0.682469
trainer/Policy mu Max               2.88177
trainer/Policy mu Min              -3.31143
trainer/Policy log std Mean        -2.09787
trainer/Policy log std Std          0.46773
trainer/Policy log std Max         -0.478295
trainer/Policy log std Min         -2.61913
trainer/Alpha                       0.0612966
trainer/Alpha Loss                  0.0120666
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.295953
exploration/Rewards Std             0.891644
exploration/Rewards Max            -0.0130223
exploration/Rewards Min           -10.4266
exploration/Returns Mean          -29.5953
exploration/Returns Std            15.8024
exploration/Returns Max           -19.6312
exploration/Returns Min           -60.9269
exploration/Actions Mean           -0.0158915
exploration/Actions Std             0.228961
exploration/Actions Max             0.992797
exploration/Actions Min            -0.999839
exploration/Num Paths               5
exploration/Average Returns       -29.5953
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207073
evaluation/Rewards Std              0.87075
evaluation/Rewards Max             -0.00694289
evaluation/Rewards Min            -10.5054
evaluation/Returns Mean           -20.7073
evaluation/Returns Std             12.9535
evaluation/Returns Max             -5.81367
evaluation/Returns Min            -50.7637
evaluation/Actions Mean            -0.0073139
evaluation/Actions Std              0.196188
evaluation/Actions Max              0.995434
evaluation/Actions Min             -0.997372
evaluation/Num Paths               15
evaluation/Average Returns        -20.7073
time/data storing (s)               0.00324712
time/evaluation sampling (s)        0.353813
time/exploration sampling (s)       0.160662
time/logging (s)                    0.00537792
time/saving (s)                     0.00233071
time/training (s)                   2.14027
time/epoch (s)                      2.6657
time/total (s)                    330.505
Epoch                             121
-----------------------------  ---------------
2019-04-22 21:43:34.151096 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              61700
trainer/QF1 Loss                    0.752962
trainer/QF2 Loss                    0.764826
trainer/Policy Loss                11.6737
trainer/Q1 Predictions Mean       -10.1401
trainer/Q1 Predictions Std          6.144
trainer/Q1 Predictions Max         -7.11236
trainer/Q1 Predictions Min        -56.0969
trainer/Q2 Predictions Mean       -10.1313
trainer/Q2 Predictions Std          6.14339
trainer/Q2 Predictions Max         -7.09272
trainer/Q2 Predictions Min        -56.2399
trainer/Q Targets Mean            -10.1134
trainer/Q Targets Std               6.29218
trainer/Q Targets Max              -0.106911
trainer/Q Targets Min             -57.7147
trainer/Log Pis Mean                1.97512
trainer/Log Pis Std                 1.37718
trainer/Log Pis Max                 7.41709
trainer/Log Pis Min                -4.47337
trainer/Policy mu Mean             -0.0741805
trainer/Policy mu Std               0.817136
trainer/Policy mu Max               2.86746
trainer/Policy mu Min              -3.23075
trainer/Policy log std Mean        -2.07978
trainer/Policy log std Std          0.548426
trainer/Policy log std Max         -0.465579
trainer/Policy log std Min         -2.69775
trainer/Alpha                       0.0608986
trainer/Alpha Loss                 -0.0696158
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.262394
exploration/Rewards Std             0.681498
exploration/Rewards Max            -0.0042363
exploration/Rewards Min            -5.90852
exploration/Returns Mean          -26.2394
exploration/Returns Std             4.49698
exploration/Returns Max           -19.1
exploration/Returns Min           -31.6679
exploration/Actions Mean            0.0143961
exploration/Actions Std             0.222326
exploration/Actions Max             0.999923
exploration/Actions Min            -0.99734
exploration/Num Paths               5
exploration/Average Returns       -26.2394
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.165501
evaluation/Rewards Std              0.624237
evaluation/Rewards Max             -0.0202431
evaluation/Rewards Min             -7.30894
evaluation/Returns Mean           -16.5501
evaluation/Returns Std              5.44624
evaluation/Returns Max             -7.603
evaluation/Returns Min            -29.4751
evaluation/Actions Mean             0.0055603
evaluation/Actions Std              0.178978
evaluation/Actions Max              0.994498
evaluation/Actions Min             -0.995435
evaluation/Num Paths               15
evaluation/Average Returns        -16.5501
time/data storing (s)               0.00323737
time/evaluation sampling (s)        0.37937
time/exploration sampling (s)       0.172575
time/logging (s)                    0.00506702
time/saving (s)                     0.00210681
time/training (s)                   2.1412
time/epoch (s)                      2.70356
time/total (s)                    333.214
Epoch                             122
-----------------------------  ---------------
2019-04-22 21:43:36.788005 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                    0.74311
trainer/QF2 Loss                    0.740236
trainer/Policy Loss                11.1603
trainer/Q1 Predictions Mean        -9.29853
trainer/Q1 Predictions Std          5.37866
trainer/Q1 Predictions Max         -6.90638
trainer/Q1 Predictions Min        -54.4982
trainer/Q2 Predictions Mean        -9.31639
trainer/Q2 Predictions Std          5.38781
trainer/Q2 Predictions Max         -6.9023
trainer/Q2 Predictions Min        -54.7524
trainer/Q Targets Mean             -9.36445
trainer/Q Targets Std               5.43532
trainer/Q Targets Max              -0.0348588
trainer/Q Targets Min             -54.8675
trainer/Log Pis Mean                2.06185
trainer/Log Pis Std                 1.19406
trainer/Log Pis Max                 5.25045
trainer/Log Pis Min                -2.39832
trainer/Policy mu Mean             -0.0437849
trainer/Policy mu Std               0.766931
trainer/Policy mu Max               3.41225
trainer/Policy mu Min              -2.66401
trainer/Policy log std Mean        -2.05918
trainer/Policy log std Std          0.541607
trainer/Policy log std Max         -0.376165
trainer/Policy log std Min         -2.64014
trainer/Alpha                       0.0627109
trainer/Alpha Loss                  0.171268
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.261618
exploration/Rewards Std             0.713097
exploration/Rewards Max            -0.00754135
exploration/Rewards Min            -6.77745
exploration/Returns Mean          -26.1618
exploration/Returns Std             9.05624
exploration/Returns Max           -13.3536
exploration/Returns Min           -37.7813
exploration/Actions Mean           -0.0222455
exploration/Actions Std             0.223302
exploration/Actions Max             0.99332
exploration/Actions Min            -0.998984
exploration/Num Paths               5
exploration/Average Returns       -26.1618
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.17667
evaluation/Rewards Std              0.79133
evaluation/Rewards Max             -0.0165145
evaluation/Rewards Min             -8.71299
evaluation/Returns Mean           -17.667
evaluation/Returns Std             13.6791
evaluation/Returns Max             -3.67322
evaluation/Returns Min            -41.2948
evaluation/Actions Mean            -0.00463409
evaluation/Actions Std              0.168924
evaluation/Actions Max              0.99573
evaluation/Actions Min             -0.995772
evaluation/Num Paths               15
evaluation/Average Returns        -17.667
time/data storing (s)               0.00320463
time/evaluation sampling (s)        0.353368
time/exploration sampling (s)       0.160274
time/logging (s)                    0.00481182
time/saving (s)                     0.00215412
time/training (s)                   2.10571
time/epoch (s)                      2.62953
time/total (s)                    335.848
Epoch                             123
-----------------------------  ---------------
2019-04-22 21:43:39.482584 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              62700
trainer/QF1 Loss                    0.781152
trainer/QF2 Loss                    0.787678
trainer/Policy Loss                11.8494
trainer/Q1 Predictions Mean       -10.3663
trainer/Q1 Predictions Std          8.58832
trainer/Q1 Predictions Max         -6.97456
trainer/Q1 Predictions Min        -60.4238
trainer/Q2 Predictions Mean       -10.3474
trainer/Q2 Predictions Std          8.57375
trainer/Q2 Predictions Max         -6.94333
trainer/Q2 Predictions Min        -60.269
trainer/Q Targets Mean            -10.3519
trainer/Q Targets Std               8.85508
trainer/Q Targets Max              -0.0786936
trainer/Q Targets Min             -63.0023
trainer/Log Pis Mean                1.9956
trainer/Log Pis Std                 1.52633
trainer/Log Pis Max                 6.77766
trainer/Log Pis Min                -2.60386
trainer/Policy mu Mean             -0.0215039
trainer/Policy mu Std               0.774633
trainer/Policy mu Max               3.77856
trainer/Policy mu Min              -3.23867
trainer/Policy log std Mean        -2.07763
trainer/Policy log std Std          0.517875
trainer/Policy log std Max         -0.163491
trainer/Policy log std Min         -2.64682
trainer/Alpha                       0.0619598
trainer/Alpha Loss                 -0.0122471
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375826
exploration/Rewards Std             1.15703
exploration/Rewards Max            -0.00307852
exploration/Rewards Min            -9.99774
exploration/Returns Mean          -37.5826
exploration/Returns Std            18.0702
exploration/Returns Max           -18.4208
exploration/Returns Min           -65.2453
exploration/Actions Mean           -0.00679984
exploration/Actions Std             0.255889
exploration/Actions Max             0.999981
exploration/Actions Min            -0.997985
exploration/Num Paths               5
exploration/Average Returns       -37.5826
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231857
evaluation/Rewards Std              0.953164
evaluation/Rewards Max             -0.0061263
evaluation/Rewards Min             -9.0371
evaluation/Returns Mean           -23.1857
evaluation/Returns Std             14.4464
evaluation/Returns Max             -1.54785
evaluation/Returns Min            -49.4567
evaluation/Actions Mean            -0.00652466
evaluation/Actions Std              0.195122
evaluation/Actions Max              0.995362
evaluation/Actions Min             -0.997324
evaluation/Num Paths               15
evaluation/Average Returns        -23.1857
time/data storing (s)               0.00335061
time/evaluation sampling (s)        0.354401
time/exploration sampling (s)       0.16105
time/logging (s)                    0.00425568
time/saving (s)                     0.00203217
time/training (s)                   2.16173
time/epoch (s)                      2.68682
time/total (s)                    338.539
Epoch                             124
-----------------------------  ---------------
2019-04-22 21:43:42.211895 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              63200
trainer/QF1 Loss                    1.48665
trainer/QF2 Loss                    1.53342
trainer/Policy Loss                11.3824
trainer/Q1 Predictions Mean        -9.7514
trainer/Q1 Predictions Std          7.84801
trainer/Q1 Predictions Max         -6.88447
trainer/Q1 Predictions Min        -70.6941
trainer/Q2 Predictions Mean        -9.75548
trainer/Q2 Predictions Std          7.90473
trainer/Q2 Predictions Max         -6.86597
trainer/Q2 Predictions Min        -71.0553
trainer/Q Targets Mean             -9.6157
trainer/Q Targets Std               7.6696
trainer/Q Targets Max              -0.0388515
trainer/Q Targets Min             -67.4003
trainer/Log Pis Mean                2.11006
trainer/Log Pis Std                 1.29919
trainer/Log Pis Max                 8.31203
trainer/Log Pis Min                -0.455869
trainer/Policy mu Mean             -0.0538707
trainer/Policy mu Std               0.724035
trainer/Policy mu Max               2.84317
trainer/Policy mu Min              -3.31676
trainer/Policy log std Mean        -2.07626
trainer/Policy log std Std          0.474022
trainer/Policy log std Max         -0.561723
trainer/Policy log std Min         -2.5548
trainer/Alpha                       0.061266
trainer/Alpha Loss                  0.307336
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332722
exploration/Rewards Std             0.991655
exploration/Rewards Max            -0.0056674
exploration/Rewards Min            -8.7689
exploration/Returns Mean          -33.2722
exploration/Returns Std            12.1972
exploration/Returns Max           -14.8338
exploration/Returns Min           -51.766
exploration/Actions Mean           -0.0300236
exploration/Actions Std             0.240227
exploration/Actions Max             0.997231
exploration/Actions Min            -0.998881
exploration/Num Paths               5
exploration/Average Returns       -33.2722
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.214475
evaluation/Rewards Std              0.887728
evaluation/Rewards Max             -0.0273646
evaluation/Rewards Min             -8.92885
evaluation/Returns Mean           -21.4475
evaluation/Returns Std             11.8969
evaluation/Returns Max             -4.71788
evaluation/Returns Min            -47.7715
evaluation/Actions Mean            -0.0110973
evaluation/Actions Std              0.190009
evaluation/Actions Max              0.995531
evaluation/Actions Min             -0.997537
evaluation/Num Paths               15
evaluation/Average Returns        -21.4475
time/data storing (s)               0.00347698
time/evaluation sampling (s)        0.36354
time/exploration sampling (s)       0.168425
time/logging (s)                    0.00525147
time/saving (s)                     0.0446716
time/training (s)                   2.13772
time/epoch (s)                      2.72308
time/total (s)                    341.267
Epoch                             125
-----------------------------  ---------------
2019-04-22 21:43:44.911363 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              63700
trainer/QF1 Loss                    0.0490895
trainer/QF2 Loss                    0.0373569
trainer/Policy Loss                10.3418
trainer/Q1 Predictions Mean        -8.76887
trainer/Q1 Predictions Std          2.89231
trainer/Q1 Predictions Max         -6.83523
trainer/Q1 Predictions Min        -29.8595
trainer/Q2 Predictions Mean        -8.77032
trainer/Q2 Predictions Std          2.82329
trainer/Q2 Predictions Max         -6.83302
trainer/Q2 Predictions Min        -29.4729
trainer/Q Targets Mean             -8.87949
trainer/Q Targets Std               2.75569
trainer/Q Targets Max              -6.89929
trainer/Q Targets Min             -28.5424
trainer/Log Pis Mean                1.88418
trainer/Log Pis Std                 1.26574
trainer/Log Pis Max                 5.91538
trainer/Log Pis Min                -2.89696
trainer/Policy mu Mean             -0.0599978
trainer/Policy mu Std               0.732598
trainer/Policy mu Max               2.63994
trainer/Policy mu Min              -2.88849
trainer/Policy log std Mean        -2.01144
trainer/Policy log std Std          0.503236
trainer/Policy log std Max         -0.431989
trainer/Policy log std Min         -2.63619
trainer/Alpha                       0.0619943
trainer/Alpha Loss                 -0.322066
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.282822
exploration/Rewards Std             0.838713
exploration/Rewards Max            -0.00748337
exploration/Rewards Min            -7.97432
exploration/Returns Mean          -28.2822
exploration/Returns Std            10.2398
exploration/Returns Max           -16.254
exploration/Returns Min           -43.3491
exploration/Actions Mean            0.00143681
exploration/Actions Std             0.235238
exploration/Actions Max             0.996384
exploration/Actions Min            -0.996319
exploration/Num Paths               5
exploration/Average Returns       -28.2822
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.202317
evaluation/Rewards Std              0.890168
evaluation/Rewards Max             -0.00738408
evaluation/Rewards Min             -8.86885
evaluation/Returns Mean           -20.2317
evaluation/Returns Std             13.7
evaluation/Returns Max             -2.46545
evaluation/Returns Min            -47.4217
evaluation/Actions Mean             0.00329511
evaluation/Actions Std              0.188746
evaluation/Actions Max              0.997348
evaluation/Actions Min             -0.994758
evaluation/Num Paths               15
evaluation/Average Returns        -20.2317
time/data storing (s)               0.00316288
time/evaluation sampling (s)        0.354889
time/exploration sampling (s)       0.159897
time/logging (s)                    0.00526501
time/saving (s)                     0.00209033
time/training (s)                   2.16676
time/epoch (s)                      2.69207
time/total (s)                    343.964
Epoch                             126
-----------------------------  ---------------
2019-04-22 21:43:47.561749 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    2.23964
trainer/QF2 Loss                    2.24026
trainer/Policy Loss                10.3919
trainer/Q1 Predictions Mean        -8.87537
trainer/Q1 Predictions Std          4.53568
trainer/Q1 Predictions Max         -6.75116
trainer/Q1 Predictions Min        -48.2175
trainer/Q2 Predictions Mean        -8.8775
trainer/Q2 Predictions Std          4.52656
trainer/Q2 Predictions Max         -6.78777
trainer/Q2 Predictions Min        -48.2426
trainer/Q Targets Mean             -8.72402
trainer/Q Targets Std               4.88439
trainer/Q Targets Max              -0.0913661
trainer/Q Targets Min             -48.4786
trainer/Log Pis Mean                1.71676
trainer/Log Pis Std                 1.43003
trainer/Log Pis Max                 5.90008
trainer/Log Pis Min                -4.51172
trainer/Policy mu Mean              0.00417061
trainer/Policy mu Std               0.627262
trainer/Policy mu Max               3.42157
trainer/Policy mu Min              -2.6571
trainer/Policy log std Mean        -2.04997
trainer/Policy log std Std          0.44122
trainer/Policy log std Max         -0.303072
trainer/Policy log std Min         -2.4308
trainer/Alpha                       0.0588109
trainer/Alpha Loss                 -0.802504
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.326004
exploration/Rewards Std             1.03201
exploration/Rewards Max            -0.00403391
exploration/Rewards Min            -9.16195
exploration/Returns Mean          -32.6004
exploration/Returns Std            19.4332
exploration/Returns Max           -13.006
exploration/Returns Min           -57.0519
exploration/Actions Mean            0.00340307
exploration/Actions Std             0.224653
exploration/Actions Max             0.998886
exploration/Actions Min            -0.99733
exploration/Num Paths               5
exploration/Average Returns       -32.6004
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222038
evaluation/Rewards Std              0.880026
evaluation/Rewards Max             -0.00298421
evaluation/Rewards Min            -10.2315
evaluation/Returns Mean           -22.2038
evaluation/Returns Std             16.7428
evaluation/Returns Max             -1.41959
evaluation/Returns Min            -57.9656
evaluation/Actions Mean             0.00897344
evaluation/Actions Std              0.175274
evaluation/Actions Max              0.999243
evaluation/Actions Min             -0.995011
evaluation/Num Paths               15
evaluation/Average Returns        -22.2038
time/data storing (s)               0.0030779
time/evaluation sampling (s)        0.365161
time/exploration sampling (s)       0.166538
time/logging (s)                    0.00475502
time/saving (s)                     0.00199764
time/training (s)                   2.10098
time/epoch (s)                      2.6425
time/total (s)                    346.611
Epoch                             127
-----------------------------  ---------------
2019-04-22 21:43:50.268853 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              64700
trainer/QF1 Loss                    2.21297
trainer/QF2 Loss                    2.24956
trainer/Policy Loss                11.6079
trainer/Q1 Predictions Mean       -10.2576
trainer/Q1 Predictions Std          8.47073
trainer/Q1 Predictions Max         -6.80338
trainer/Q1 Predictions Min        -51.3836
trainer/Q2 Predictions Mean       -10.2555
trainer/Q2 Predictions Std          8.41853
trainer/Q2 Predictions Max         -6.77166
trainer/Q2 Predictions Min        -50.6118
trainer/Q Targets Mean            -10.0487
trainer/Q Targets Std               8.75452
trainer/Q Targets Max              -0.118784
trainer/Q Targets Min             -52.5448
trainer/Log Pis Mean                1.88756
trainer/Log Pis Std                 1.54799
trainer/Log Pis Max                 7.39374
trainer/Log Pis Min                -5.23277
trainer/Policy mu Mean              0.0787836
trainer/Policy mu Std               0.762374
trainer/Policy mu Max               3.11262
trainer/Policy mu Min              -2.91359
trainer/Policy log std Mean        -2.06824
trainer/Policy log std Std          0.510268
trainer/Policy log std Max         -0.360873
trainer/Policy log std Min         -2.57374
trainer/Alpha                       0.0600714
trainer/Alpha Loss                 -0.316208
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.355194
exploration/Rewards Std             1.07036
exploration/Rewards Max            -0.00783343
exploration/Rewards Min            -9.84936
exploration/Returns Mean          -35.5194
exploration/Returns Std            17.9341
exploration/Returns Max           -14.6329
exploration/Returns Min           -60.6973
exploration/Actions Mean            0.0103426
exploration/Actions Std             0.250485
exploration/Actions Max             0.999128
exploration/Actions Min            -0.99844
exploration/Num Paths               5
exploration/Average Returns       -35.5194
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.215932
evaluation/Rewards Std              0.897858
evaluation/Rewards Max             -0.023462
evaluation/Rewards Min            -10.2301
evaluation/Returns Mean           -21.5932
evaluation/Returns Std             15.4965
evaluation/Returns Max             -2.52635
evaluation/Returns Min            -55.131
evaluation/Actions Mean            -0.00352888
evaluation/Actions Std              0.19066
evaluation/Actions Max              0.997178
evaluation/Actions Min             -0.997161
evaluation/Num Paths               15
evaluation/Average Returns        -21.5932
time/data storing (s)               0.00332789
time/evaluation sampling (s)        0.354915
time/exploration sampling (s)       0.161113
time/logging (s)                    0.00510218
time/saving (s)                     0.0021098
time/training (s)                   2.17385
time/epoch (s)                      2.70042
time/total (s)                    349.316
Epoch                             128
-----------------------------  ---------------
2019-04-22 21:43:52.957992 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              65200
trainer/QF1 Loss                    0.0777489
trainer/QF2 Loss                    0.0567562
trainer/Policy Loss                11.2603
trainer/Q1 Predictions Mean        -9.49926
trainer/Q1 Predictions Std          6.22498
trainer/Q1 Predictions Max         -6.90048
trainer/Q1 Predictions Min        -58.0764
trainer/Q2 Predictions Mean        -9.51073
trainer/Q2 Predictions Std          6.25784
trainer/Q2 Predictions Max         -6.85754
trainer/Q2 Predictions Min        -58.5761
trainer/Q Targets Mean             -9.61765
trainer/Q Targets Std               6.21829
trainer/Q Targets Max              -6.81372
trainer/Q Targets Min             -58.924
trainer/Log Pis Mean                2.16019
trainer/Log Pis Std                 1.38852
trainer/Log Pis Max                 6.77496
trainer/Log Pis Min                -4.63507
trainer/Policy mu Mean              0.0547833
trainer/Policy mu Std               0.830322
trainer/Policy mu Max               3.15398
trainer/Policy mu Min              -2.73868
trainer/Policy log std Mean        -2.05249
trainer/Policy log std Std          0.545198
trainer/Policy log std Max         -0.532384
trainer/Policy log std Min         -2.56376
trainer/Alpha                       0.0613571
trainer/Alpha Loss                  0.447116
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.328429
exploration/Rewards Std             0.899547
exploration/Rewards Max            -0.00625022
exploration/Rewards Min            -8.6847
exploration/Returns Mean          -32.8429
exploration/Returns Std            12.9924
exploration/Returns Max           -16.6519
exploration/Returns Min           -51.0786
exploration/Actions Mean           -0.0286216
exploration/Actions Std             0.231911
exploration/Actions Max             0.994364
exploration/Actions Min            -0.997753
exploration/Num Paths               5
exploration/Average Returns       -32.8429
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.307385
evaluation/Rewards Std              1.13952
evaluation/Rewards Max             -0.00847953
evaluation/Rewards Min            -11.2249
evaluation/Returns Mean           -30.7385
evaluation/Returns Std             16.565
evaluation/Returns Max             -7.59395
evaluation/Returns Min            -66.1485
evaluation/Actions Mean            -0.00705341
evaluation/Actions Std              0.206048
evaluation/Actions Max              0.998162
evaluation/Actions Min             -0.997838
evaluation/Num Paths               15
evaluation/Average Returns        -30.7385
time/data storing (s)               0.00330977
time/evaluation sampling (s)        0.362387
time/exploration sampling (s)       0.165852
time/logging (s)                    0.00505345
time/saving (s)                     0.00223783
time/training (s)                   2.14306
time/epoch (s)                      2.6819
time/total (s)                    352.003
Epoch                             129
-----------------------------  ---------------
2019-04-22 21:43:55.644789 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 130 finished
-----------------------------  ----------------
replay_buffer/size              65700
trainer/QF1 Loss                    2.81053
trainer/QF2 Loss                    2.68778
trainer/Policy Loss                11.2691
trainer/Q1 Predictions Mean        -9.40543
trainer/Q1 Predictions Std          6.85897
trainer/Q1 Predictions Max         -6.99405
trainer/Q1 Predictions Min        -68.7617
trainer/Q2 Predictions Mean        -9.40162
trainer/Q2 Predictions Std          6.8721
trainer/Q2 Predictions Max         -6.94518
trainer/Q2 Predictions Min        -68.9581
trainer/Q Targets Mean             -9.17599
trainer/Q Targets Std               7.02899
trainer/Q Targets Max              -0.0466962
trainer/Q Targets Min             -70.2104
trainer/Log Pis Mean                2.07628
trainer/Log Pis Std                 1.53723
trainer/Log Pis Max                 9.96378
trainer/Log Pis Min                -2.45249
trainer/Policy mu Mean              0.0123997
trainer/Policy mu Std               0.7777
trainer/Policy mu Max               4.06872
trainer/Policy mu Min              -2.89067
trainer/Policy log std Mean        -2.07325
trainer/Policy log std Std          0.540172
trainer/Policy log std Max          0.121546
trainer/Policy log std Min         -2.69959
trainer/Alpha                       0.0627411
trainer/Alpha Loss                  0.211189
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.457098
exploration/Rewards Std             1.3704
exploration/Rewards Max            -0.0024549
exploration/Rewards Min            -9.95148
exploration/Returns Mean          -45.7098
exploration/Returns Std            16.4472
exploration/Returns Max           -23.1171
exploration/Returns Min           -66.2927
exploration/Actions Mean           -0.00205375
exploration/Actions Std             0.261957
exploration/Actions Max             0.999759
exploration/Actions Min            -0.998828
exploration/Num Paths               5
exploration/Average Returns       -45.7098
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.217527
evaluation/Rewards Std              0.89198
evaluation/Rewards Max             -0.0218149
evaluation/Rewards Min             -8.57944
evaluation/Returns Mean           -21.7527
evaluation/Returns Std             11.1244
evaluation/Returns Max             -3.84293
evaluation/Returns Min            -40.2856
evaluation/Actions Mean            -0.000867672
evaluation/Actions Std              0.193975
evaluation/Actions Max              0.996402
evaluation/Actions Min             -0.99551
evaluation/Num Paths               15
evaluation/Average Returns        -21.7527
time/data storing (s)               0.00326135
time/evaluation sampling (s)        0.356755
time/exploration sampling (s)       0.160907
time/logging (s)                    0.0049625
time/saving (s)                     0.00197468
time/training (s)                   2.15151
time/epoch (s)                      2.67937
time/total (s)                    354.687
Epoch                             130
-----------------------------  ----------------
2019-04-22 21:43:58.386518 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    0.544247
trainer/QF2 Loss                    0.535721
trainer/Policy Loss                10.8861
trainer/Q1 Predictions Mean        -9.14982
trainer/Q1 Predictions Std          5.91279
trainer/Q1 Predictions Max         -6.73621
trainer/Q1 Predictions Min        -52.4935
trainer/Q2 Predictions Mean        -9.16991
trainer/Q2 Predictions Std          5.93712
trainer/Q2 Predictions Max         -6.70663
trainer/Q2 Predictions Min        -52.6256
trainer/Q Targets Mean             -9.19749
trainer/Q Targets Std               5.94508
trainer/Q Targets Max              -0.0819631
trainer/Q Targets Min             -53.5011
trainer/Log Pis Mean                2.14623
trainer/Log Pis Std                 1.37436
trainer/Log Pis Max                 7.74087
trainer/Log Pis Min                -3.45761
trainer/Policy mu Mean             -0.0930829
trainer/Policy mu Std               0.723002
trainer/Policy mu Max               2.87028
trainer/Policy mu Min              -3.10584
trainer/Policy log std Mean        -2.09858
trainer/Policy log std Std          0.498658
trainer/Policy log std Max         -0.453816
trainer/Policy log std Min         -2.51352
trainer/Alpha                       0.062812
trainer/Alpha Loss                  0.404705
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.434716
exploration/Rewards Std             1.34574
exploration/Rewards Max            -0.00583838
exploration/Rewards Min           -10.8896
exploration/Returns Mean          -43.4716
exploration/Returns Std            15.3141
exploration/Returns Max           -22.6646
exploration/Returns Min           -61.547
exploration/Actions Mean           -0.0176775
exploration/Actions Std             0.261303
exploration/Actions Max             0.997128
exploration/Actions Min            -0.999362
exploration/Num Paths               5
exploration/Average Returns       -43.4716
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.186514
evaluation/Rewards Std              0.804117
evaluation/Rewards Max             -0.0127863
evaluation/Rewards Min             -8.48903
evaluation/Returns Mean           -18.6514
evaluation/Returns Std             11.271
evaluation/Returns Max             -2.67778
evaluation/Returns Min            -37.9149
evaluation/Actions Mean            -0.00845034
evaluation/Actions Std              0.186557
evaluation/Actions Max              0.995119
evaluation/Actions Min             -0.994901
evaluation/Num Paths               15
evaluation/Average Returns        -18.6514
time/data storing (s)               0.00348287
time/evaluation sampling (s)        0.413681
time/exploration sampling (s)       0.165794
time/logging (s)                    0.00471579
time/saving (s)                     0.00208681
time/training (s)                   2.1446
time/epoch (s)                      2.73436
time/total (s)                    357.426
Epoch                             131
-----------------------------  ---------------
2019-04-22 21:44:01.095962 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              66700
trainer/QF1 Loss                    0.0474802
trainer/QF2 Loss                    0.0387273
trainer/Policy Loss                11.0816
trainer/Q1 Predictions Mean        -9.23979
trainer/Q1 Predictions Std          5.52971
trainer/Q1 Predictions Max         -6.81729
trainer/Q1 Predictions Min        -47.3601
trainer/Q2 Predictions Mean        -9.24963
trainer/Q2 Predictions Std          5.5859
trainer/Q2 Predictions Max         -6.76115
trainer/Q2 Predictions Min        -47.6742
trainer/Q Targets Mean             -9.34037
trainer/Q Targets Std               5.61944
trainer/Q Targets Max              -6.8682
trainer/Q Targets Min             -48.8759
trainer/Log Pis Mean                1.97707
trainer/Log Pis Std                 1.43512
trainer/Log Pis Max                 7.20208
trainer/Log Pis Min                -2.92075
trainer/Policy mu Mean             -0.040808
trainer/Policy mu Std               0.775838
trainer/Policy mu Max               3.01018
trainer/Policy mu Min              -3.12343
trainer/Policy log std Mean        -2.06535
trainer/Policy log std Std          0.52522
trainer/Policy log std Max         -0.515232
trainer/Policy log std Min         -2.59786
trainer/Alpha                       0.063625
trainer/Alpha Loss                 -0.063164
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.376533
exploration/Rewards Std             1.10589
exploration/Rewards Max            -0.00644671
exploration/Rewards Min           -11.4795
exploration/Returns Mean          -37.6533
exploration/Returns Std            16.8992
exploration/Returns Max           -26.0875
exploration/Returns Min           -70.3628
exploration/Actions Mean            0.0191021
exploration/Actions Std             0.267647
exploration/Actions Max             0.999743
exploration/Actions Min            -0.998675
exploration/Num Paths               5
exploration/Average Returns       -37.6533
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.300836
evaluation/Rewards Std              1.09248
evaluation/Rewards Max             -0.0318507
evaluation/Rewards Min             -9.50621
evaluation/Returns Mean           -30.0836
evaluation/Returns Std             13.9616
evaluation/Returns Max             -5.55602
evaluation/Returns Min            -46.077
evaluation/Actions Mean            -0.015668
evaluation/Actions Std              0.205931
evaluation/Actions Max              0.996649
evaluation/Actions Min             -0.997053
evaluation/Num Paths               15
evaluation/Average Returns        -30.0836
time/data storing (s)               0.00329613
time/evaluation sampling (s)        0.357255
time/exploration sampling (s)       0.164169
time/logging (s)                    0.00540959
time/saving (s)                     0.00216895
time/training (s)                   2.17116
time/epoch (s)                      2.70346
time/total (s)                    360.134
Epoch                             132
-----------------------------  ---------------
2019-04-22 21:44:03.780149 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              67200
trainer/QF1 Loss                    1.84674
trainer/QF2 Loss                    1.79728
trainer/Policy Loss                10.4794
trainer/Q1 Predictions Mean        -8.8619
trainer/Q1 Predictions Std          4.14975
trainer/Q1 Predictions Max         -6.93005
trainer/Q1 Predictions Min        -43.5541
trainer/Q2 Predictions Mean        -8.85304
trainer/Q2 Predictions Std          4.151
trainer/Q2 Predictions Max         -6.87201
trainer/Q2 Predictions Min        -43.9433
trainer/Q Targets Mean             -8.69031
trainer/Q Targets Std               4.21704
trainer/Q Targets Max              -0.288203
trainer/Q Targets Min             -43.6208
trainer/Log Pis Mean                1.81462
trainer/Log Pis Std                 1.44338
trainer/Log Pis Max                 9.06846
trainer/Log Pis Min                -1.42962
trainer/Policy mu Mean             -0.0334465
trainer/Policy mu Std               0.70606
trainer/Policy mu Max               2.94
trainer/Policy mu Min              -2.70321
trainer/Policy log std Mean        -2.09149
trainer/Policy log std Std          0.473955
trainer/Policy log std Max         -0.481272
trainer/Policy log std Min         -2.52374
trainer/Alpha                       0.0643064
trainer/Alpha Loss                 -0.508695
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.257813
exploration/Rewards Std             0.688626
exploration/Rewards Max            -0.00333709
exploration/Rewards Min            -7.30935
exploration/Returns Mean          -25.7813
exploration/Returns Std            12.8411
exploration/Returns Max           -11.4539
exploration/Returns Min           -48.3027
exploration/Actions Mean           -0.0123465
exploration/Actions Std             0.214873
exploration/Actions Max             0.994438
exploration/Actions Min            -0.997828
exploration/Num Paths               5
exploration/Average Returns       -25.7813
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22723
evaluation/Rewards Std              0.897795
evaluation/Rewards Max             -0.00916432
evaluation/Rewards Min             -9.23073
evaluation/Returns Mean           -22.723
evaluation/Returns Std             13.5724
evaluation/Returns Max             -1.58445
evaluation/Returns Min            -44.6947
evaluation/Actions Mean             0.00872624
evaluation/Actions Std              0.191805
evaluation/Actions Max              0.995421
evaluation/Actions Min             -0.995889
evaluation/Num Paths               15
evaluation/Average Returns        -22.723
time/data storing (s)               0.00377631
time/evaluation sampling (s)        0.360198
time/exploration sampling (s)       0.162398
time/logging (s)                    0.00418358
time/saving (s)                     0.00196872
time/training (s)                   2.14343
time/epoch (s)                      2.67595
time/total (s)                    362.814
Epoch                             133
-----------------------------  ---------------
2019-04-22 21:44:06.430898 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              67700
trainer/QF1 Loss                    0.694518
trainer/QF2 Loss                    0.677714
trainer/Policy Loss                11.2669
trainer/Q1 Predictions Mean        -9.79642
trainer/Q1 Predictions Std          7.17152
trainer/Q1 Predictions Max         -6.97381
trainer/Q1 Predictions Min        -61.1896
trainer/Q2 Predictions Mean        -9.81372
trainer/Q2 Predictions Std          7.21319
trainer/Q2 Predictions Max         -6.82297
trainer/Q2 Predictions Min        -61.2515
trainer/Q Targets Mean             -9.86175
trainer/Q Targets Std               7.48975
trainer/Q Targets Max              -0.0192467
trainer/Q Targets Min             -64.0899
trainer/Log Pis Mean                2.02735
trainer/Log Pis Std                 1.3594
trainer/Log Pis Max                 6.90288
trainer/Log Pis Min                -1.98757
trainer/Policy mu Mean             -0.00201164
trainer/Policy mu Std               0.770055
trainer/Policy mu Max               2.78717
trainer/Policy mu Min              -3.14477
trainer/Policy log std Mean        -2.02411
trainer/Policy log std Std          0.526018
trainer/Policy log std Max         -0.477473
trainer/Policy log std Min         -2.48977
trainer/Alpha                       0.0637403
trainer/Alpha Loss                  0.0752867
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.253992
exploration/Rewards Std             0.701203
exploration/Rewards Max            -0.00733735
exploration/Rewards Min            -7.48178
exploration/Returns Mean          -25.3992
exploration/Returns Std             9.19366
exploration/Returns Max           -16.5468
exploration/Returns Min           -42.6724
exploration/Actions Mean           -0.00826582
exploration/Actions Std             0.223611
exploration/Actions Max             0.995037
exploration/Actions Min            -0.999617
exploration/Num Paths               5
exploration/Average Returns       -25.3992
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228317
evaluation/Rewards Std              0.897738
evaluation/Rewards Max             -0.00500481
evaluation/Rewards Min             -9.82774
evaluation/Returns Mean           -22.8317
evaluation/Returns Std             11.2036
evaluation/Returns Max             -8.46212
evaluation/Returns Min            -46.9752
evaluation/Actions Mean            -0.0084712
evaluation/Actions Std              0.193742
evaluation/Actions Max              0.997429
evaluation/Actions Min             -0.996106
evaluation/Num Paths               15
evaluation/Average Returns        -22.8317
time/data storing (s)               0.00327471
time/evaluation sampling (s)        0.36097
time/exploration sampling (s)       0.161799
time/logging (s)                    0.00495233
time/saving (s)                     0.0020487
time/training (s)                   2.11159
time/epoch (s)                      2.64463
time/total (s)                    365.463
Epoch                             134
-----------------------------  ---------------
2019-04-22 21:44:09.136760 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                    0.607781
trainer/QF2 Loss                    0.626639
trainer/Policy Loss                 9.88121
trainer/Q1 Predictions Mean        -8.21148
trainer/Q1 Predictions Std          1.78449
trainer/Q1 Predictions Max         -6.86385
trainer/Q1 Predictions Min        -18.6707
trainer/Q2 Predictions Mean        -8.21854
trainer/Q2 Predictions Std          1.76879
trainer/Q2 Predictions Max         -6.88363
trainer/Q2 Predictions Min        -18.6425
trainer/Q Targets Mean             -8.11119
trainer/Q Targets Std               2.02688
trainer/Q Targets Max              -0.533423
trainer/Q Targets Min             -19.5505
trainer/Log Pis Mean                1.90052
trainer/Log Pis Std                 1.1326
trainer/Log Pis Max                 6.11926
trainer/Log Pis Min                -1.94218
trainer/Policy mu Mean             -0.0362108
trainer/Policy mu Std               0.530593
trainer/Policy mu Max               2.72676
trainer/Policy mu Min              -2.55979
trainer/Policy log std Mean        -2.19384
trainer/Policy log std Std          0.403376
trainer/Policy log std Max         -0.509282
trainer/Policy log std Min         -2.54573
trainer/Alpha                       0.0638471
trainer/Alpha Loss                 -0.273693
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.339473
exploration/Rewards Std             0.940469
exploration/Rewards Max            -0.00334465
exploration/Rewards Min            -9.2212
exploration/Returns Mean          -33.9473
exploration/Returns Std             9.53883
exploration/Returns Max           -24.7614
exploration/Returns Min           -49.8892
exploration/Actions Mean           -0.00508266
exploration/Actions Std             0.242462
exploration/Actions Max             0.999037
exploration/Actions Min            -0.998923
exploration/Num Paths               5
exploration/Average Returns       -33.9473
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.296197
evaluation/Rewards Std              0.960742
evaluation/Rewards Max             -0.0375315
evaluation/Rewards Min             -9.74859
evaluation/Returns Mean           -29.6197
evaluation/Returns Std             14.2643
evaluation/Returns Max             -9.11449
evaluation/Returns Min            -51.7728
evaluation/Actions Mean             0.00616336
evaluation/Actions Std              0.197927
evaluation/Actions Max              0.998211
evaluation/Actions Min             -0.997193
evaluation/Num Paths               15
evaluation/Average Returns        -29.6197
time/data storing (s)               0.00317766
time/evaluation sampling (s)        0.360451
time/exploration sampling (s)       0.168504
time/logging (s)                    0.00386005
time/saving (s)                     0.00202015
time/training (s)                   2.15954
time/epoch (s)                      2.69755
time/total (s)                    368.165
Epoch                             135
-----------------------------  ---------------
2019-04-22 21:44:11.839915 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              68700
trainer/QF1 Loss                    2.28222
trainer/QF2 Loss                    2.26879
trainer/Policy Loss                10.1557
trainer/Q1 Predictions Mean        -8.55559
trainer/Q1 Predictions Std          3.27865
trainer/Q1 Predictions Max         -6.75136
trainer/Q1 Predictions Min        -30.5068
trainer/Q2 Predictions Mean        -8.56943
trainer/Q2 Predictions Std          3.28811
trainer/Q2 Predictions Max         -6.73883
trainer/Q2 Predictions Min        -30.3892
trainer/Q Targets Mean             -8.33333
trainer/Q Targets Std               3.68424
trainer/Q Targets Max              -0.0402197
trainer/Q Targets Min             -30.4879
trainer/Log Pis Mean                1.8352
trainer/Log Pis Std                 1.19473
trainer/Log Pis Max                 5.40444
trainer/Log Pis Min                -1.62103
trainer/Policy mu Mean             -0.0244454
trainer/Policy mu Std               0.642812
trainer/Policy mu Max               2.90493
trainer/Policy mu Min              -2.80436
trainer/Policy log std Mean        -2.08376
trainer/Policy log std Std          0.489357
trainer/Policy log std Max         -0.537362
trainer/Policy log std Min         -2.52508
trainer/Alpha                       0.0643268
trainer/Alpha Loss                 -0.452163
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.341474
exploration/Rewards Std             0.980159
exploration/Rewards Max            -0.00667596
exploration/Rewards Min            -7.58833
exploration/Returns Mean          -34.1474
exploration/Returns Std            13.1878
exploration/Returns Max           -12.208
exploration/Returns Min           -47.7144
exploration/Actions Mean           -0.0089039
exploration/Actions Std             0.241828
exploration/Actions Max             0.99934
exploration/Actions Min            -0.99702
exploration/Num Paths               5
exploration/Average Returns       -34.1474
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225529
evaluation/Rewards Std              1.00031
evaluation/Rewards Max             -0.0155825
evaluation/Rewards Min            -10.3167
evaluation/Returns Mean           -22.5529
evaluation/Returns Std             15.9057
evaluation/Returns Max             -2.4702
evaluation/Returns Min            -51.9934
evaluation/Actions Mean            -0.00225612
evaluation/Actions Std              0.192115
evaluation/Actions Max              0.998766
evaluation/Actions Min             -0.996087
evaluation/Num Paths               15
evaluation/Average Returns        -22.5529
time/data storing (s)               0.00328279
time/evaluation sampling (s)        0.358237
time/exploration sampling (s)       0.168337
time/logging (s)                    0.00506195
time/saving (s)                     0.00632202
time/training (s)                   2.15636
time/epoch (s)                      2.6976
time/total (s)                    370.867
Epoch                             136
-----------------------------  ---------------
2019-04-22 21:44:14.517283 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                    0.0523595
trainer/QF2 Loss                    0.0377402
trainer/Policy Loss                11.0603
trainer/Q1 Predictions Mean        -9.27223
trainer/Q1 Predictions Std          7.7265
trainer/Q1 Predictions Max         -6.76189
trainer/Q1 Predictions Min        -65.9821
trainer/Q2 Predictions Mean        -9.26655
trainer/Q2 Predictions Std          7.69554
trainer/Q2 Predictions Max         -6.75393
trainer/Q2 Predictions Min        -65.4652
trainer/Q Targets Mean             -9.37065
trainer/Q Targets Std               7.58559
trainer/Q Targets Max              -6.79305
trainer/Q Targets Min             -64.802
trainer/Log Pis Mean                2.14152
trainer/Log Pis Std                 0.967692
trainer/Log Pis Max                 5.2725
trainer/Log Pis Min                -0.827634
trainer/Policy mu Mean             -0.0255511
trainer/Policy mu Std               0.656256
trainer/Policy mu Max               2.86219
trainer/Policy mu Min              -3.29431
trainer/Policy log std Mean        -2.19287
trainer/Policy log std Std          0.464328
trainer/Policy log std Max         -0.483307
trainer/Policy log std Min         -2.60867
trainer/Alpha                       0.0643316
trainer/Alpha Loss                  0.388301
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.232483
exploration/Rewards Std             0.642325
exploration/Rewards Max            -0.00484241
exploration/Rewards Min            -6.8147
exploration/Returns Mean          -23.2483
exploration/Returns Std             7.53299
exploration/Returns Max           -15.493
exploration/Returns Min           -36.6994
exploration/Actions Mean           -0.00848885
exploration/Actions Std             0.211529
exploration/Actions Max             0.996197
exploration/Actions Min            -0.999212
exploration/Num Paths               5
exploration/Average Returns       -23.2483
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207176
evaluation/Rewards Std              0.910749
evaluation/Rewards Max             -0.00384304
evaluation/Rewards Min             -8.72776
evaluation/Returns Mean           -20.7176
evaluation/Returns Std             13.5046
evaluation/Returns Max             -3.06663
evaluation/Returns Min            -46.4299
evaluation/Actions Mean            -0.0151154
evaluation/Actions Std              0.18815
evaluation/Actions Max              0.995398
evaluation/Actions Min             -0.99767
evaluation/Num Paths               15
evaluation/Average Returns        -20.7176
time/data storing (s)               0.00338621
time/evaluation sampling (s)        0.359868
time/exploration sampling (s)       0.162486
time/logging (s)                    0.00485436
time/saving (s)                     0.00217246
time/training (s)                   2.1371
time/epoch (s)                      2.66987
time/total (s)                    373.541
Epoch                             137
-----------------------------  ---------------
2019-04-22 21:44:17.157836 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              69700
trainer/QF1 Loss                    0.76373
trainer/QF2 Loss                    0.748856
trainer/Policy Loss                10.8513
trainer/Q1 Predictions Mean        -9.18166
trainer/Q1 Predictions Std          7.06724
trainer/Q1 Predictions Max         -6.62681
trainer/Q1 Predictions Min        -68.5075
trainer/Q2 Predictions Mean        -9.14885
trainer/Q2 Predictions Std          6.98196
trainer/Q2 Predictions Max         -6.61853
trainer/Q2 Predictions Min        -67.7779
trainer/Q Targets Mean             -9.25019
trainer/Q Targets Std               6.87827
trainer/Q Targets Max              -0.0984795
trainer/Q Targets Min             -65.9905
trainer/Log Pis Mean                2.04589
trainer/Log Pis Std                 1.52449
trainer/Log Pis Max                 5.46899
trainer/Log Pis Min                -3.55643
trainer/Policy mu Mean             -0.0408415
trainer/Policy mu Std               0.761278
trainer/Policy mu Max               2.72748
trainer/Policy mu Min              -3.2594
trainer/Policy log std Mean        -2.12998
trainer/Policy log std Std          0.549125
trainer/Policy log std Max         -0.463374
trainer/Policy log std Min         -2.66952
trainer/Alpha                       0.0654684
trainer/Alpha Loss                  0.125122
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.241442
exploration/Rewards Std             0.735301
exploration/Rewards Max            -0.00261128
exploration/Rewards Min            -6.60443
exploration/Returns Mean          -24.1442
exploration/Returns Std             8.26033
exploration/Returns Max           -13.348
exploration/Returns Min           -35.5748
exploration/Actions Mean            0.0126316
exploration/Actions Std             0.215562
exploration/Actions Max             0.997294
exploration/Actions Min            -0.998624
exploration/Num Paths               5
exploration/Average Returns       -24.1442
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.219505
evaluation/Rewards Std              1.07166
evaluation/Rewards Max             -0.00534151
evaluation/Rewards Min            -10.7421
evaluation/Returns Mean           -21.9505
evaluation/Returns Std             18.7336
evaluation/Returns Max             -0.687024
evaluation/Returns Min            -51.3457
evaluation/Actions Mean            -0.0127619
evaluation/Actions Std              0.189368
evaluation/Actions Max              0.998926
evaluation/Actions Min             -0.997533
evaluation/Num Paths               15
evaluation/Average Returns        -21.9505
time/data storing (s)               0.00314087
time/evaluation sampling (s)        0.353891
time/exploration sampling (s)       0.164425
time/logging (s)                    0.00503246
time/saving (s)                     0.00201159
time/training (s)                   2.10506
time/epoch (s)                      2.63356
time/total (s)                    376.18
Epoch                             138
-----------------------------  ---------------
2019-04-22 21:44:19.870922 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              70200
trainer/QF1 Loss                    0.0670137
trainer/QF2 Loss                    0.0685831
trainer/Policy Loss                10.0581
trainer/Q1 Predictions Mean        -8.31429
trainer/Q1 Predictions Std          3.31269
trainer/Q1 Predictions Max         -6.65724
trainer/Q1 Predictions Min        -34.9973
trainer/Q2 Predictions Mean        -8.31061
trainer/Q2 Predictions Std          3.31697
trainer/Q2 Predictions Max         -6.6375
trainer/Q2 Predictions Min        -34.9849
trainer/Q Targets Mean             -8.37851
trainer/Q Targets Std               3.48613
trainer/Q Targets Max              -6.73676
trainer/Q Targets Min             -37.2311
trainer/Log Pis Mean                2.02729
trainer/Log Pis Std                 1.22989
trainer/Log Pis Max                 7.75145
trainer/Log Pis Min                -1.3635
trainer/Policy mu Mean             -0.0181371
trainer/Policy mu Std               0.577932
trainer/Policy mu Max               2.78849
trainer/Policy mu Min              -2.56144
trainer/Policy log std Mean        -2.19056
trainer/Policy log std Std          0.451523
trainer/Policy log std Max         -0.547391
trainer/Policy log std Min         -2.69696
trainer/Alpha                       0.0649143
trainer/Alpha Loss                  0.0746308
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.225528
exploration/Rewards Std             0.646849
exploration/Rewards Max            -0.0079186
exploration/Rewards Min            -7.60422
exploration/Returns Mean          -22.5528
exploration/Returns Std            12.0558
exploration/Returns Max           -10.0259
exploration/Returns Min           -45.3223
exploration/Actions Mean            0.0134732
exploration/Actions Std             0.202514
exploration/Actions Max             0.99764
exploration/Actions Min            -0.990164
exploration/Num Paths               5
exploration/Average Returns       -22.5528
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231422
evaluation/Rewards Std              0.979545
evaluation/Rewards Max             -0.020292
evaluation/Rewards Min            -10.6842
evaluation/Returns Mean           -23.1422
evaluation/Returns Std             14.6262
evaluation/Returns Max             -3.87188
evaluation/Returns Min            -54.261
evaluation/Actions Mean            -0.0108163
evaluation/Actions Std              0.196337
evaluation/Actions Max              0.996625
evaluation/Actions Min             -0.997501
evaluation/Num Paths               15
evaluation/Average Returns        -23.1422
time/data storing (s)               0.0031388
time/evaluation sampling (s)        0.36138
time/exploration sampling (s)       0.166295
time/logging (s)                    0.00522223
time/saving (s)                     0.00213149
time/training (s)                   2.16766
time/epoch (s)                      2.70583
time/total (s)                    378.89
Epoch                             139
-----------------------------  ---------------
2019-04-22 21:44:22.627474 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 140 finished
-----------------------------  ----------------
replay_buffer/size              70700
trainer/QF1 Loss                    0.568643
trainer/QF2 Loss                    0.591153
trainer/Policy Loss                10.6518
trainer/Q1 Predictions Mean        -9.0004
trainer/Q1 Predictions Std          5.73078
trainer/Q1 Predictions Max         -6.94151
trainer/Q1 Predictions Min        -41.7699
trainer/Q2 Predictions Mean        -8.99727
trainer/Q2 Predictions Std          5.72646
trainer/Q2 Predictions Max         -6.95691
trainer/Q2 Predictions Min        -41.3576
trainer/Q Targets Mean             -9.0107
trainer/Q Targets Std               5.9133
trainer/Q Targets Max              -0.162583
trainer/Q Targets Min             -43.7019
trainer/Log Pis Mean                1.90285
trainer/Log Pis Std                 1.27542
trainer/Log Pis Max                 6.5709
trainer/Log Pis Min                -1.67165
trainer/Policy mu Mean             -0.0892161
trainer/Policy mu Std               0.715363
trainer/Policy mu Max               2.86781
trainer/Policy mu Min              -3.04272
trainer/Policy log std Mean        -2.06499
trainer/Policy log std Std          0.504162
trainer/Policy log std Max         -0.281478
trainer/Policy log std Min         -2.56161
trainer/Alpha                       0.0639133
trainer/Alpha Loss                 -0.26718
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.438178
exploration/Rewards Std             1.16743
exploration/Rewards Max            -0.00703587
exploration/Rewards Min            -9.7475
exploration/Returns Mean          -43.8178
exploration/Returns Std            15.2258
exploration/Returns Max           -22.4446
exploration/Returns Min           -67.9741
exploration/Actions Mean            0.000746191
exploration/Actions Std             0.283156
exploration/Actions Max             0.999045
exploration/Actions Min            -0.996865
exploration/Num Paths               5
exploration/Average Returns       -43.8178
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225102
evaluation/Rewards Std              0.946259
evaluation/Rewards Max             -0.0169046
evaluation/Rewards Min             -9.81294
evaluation/Returns Mean           -22.5102
evaluation/Returns Std             18.1835
evaluation/Returns Max             -2.77944
evaluation/Returns Min            -54.164
evaluation/Actions Mean             0.00785517
evaluation/Actions Std              0.181707
evaluation/Actions Max              0.998198
evaluation/Actions Min             -0.994323
evaluation/Num Paths               15
evaluation/Average Returns        -22.5102
time/data storing (s)               0.00341351
time/evaluation sampling (s)        0.389805
time/exploration sampling (s)       0.164701
time/logging (s)                    0.00535037
time/saving (s)                     0.00204156
time/training (s)                   2.18393
time/epoch (s)                      2.74924
time/total (s)                    381.644
Epoch                             140
-----------------------------  ----------------
2019-04-22 21:44:25.354740 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                    0.925371
trainer/QF2 Loss                    0.951074
trainer/Policy Loss                11.1983
trainer/Q1 Predictions Mean        -9.53847
trainer/Q1 Predictions Std          6.56393
trainer/Q1 Predictions Max         -6.61378
trainer/Q1 Predictions Min        -46.1374
trainer/Q2 Predictions Mean        -9.50754
trainer/Q2 Predictions Std          6.45233
trainer/Q2 Predictions Max         -6.58269
trainer/Q2 Predictions Min        -44.8242
trainer/Q Targets Mean             -9.52603
trainer/Q Targets Std               6.70951
trainer/Q Targets Max              -0.0769521
trainer/Q Targets Min             -45.6733
trainer/Log Pis Mean                2.18172
trainer/Log Pis Std                 1.60936
trainer/Log Pis Max                 7.76936
trainer/Log Pis Min                -2.97849
trainer/Policy mu Mean             -0.0390139
trainer/Policy mu Std               0.831283
trainer/Policy mu Max               2.8422
trainer/Policy mu Min              -3.01263
trainer/Policy log std Mean        -2.02228
trainer/Policy log std Std          0.565275
trainer/Policy log std Max         -0.246003
trainer/Policy log std Min         -2.56361
trainer/Alpha                       0.0613884
trainer/Alpha Loss                  0.507072
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.343726
exploration/Rewards Std             0.988739
exploration/Rewards Max            -0.00768673
exploration/Rewards Min            -8.38708
exploration/Returns Mean          -34.3726
exploration/Returns Std            14.0421
exploration/Returns Max           -12.8696
exploration/Returns Min           -52.1095
exploration/Actions Mean           -0.0160385
exploration/Actions Std             0.235239
exploration/Actions Max             0.998177
exploration/Actions Min            -0.999282
exploration/Num Paths               5
exploration/Average Returns       -34.3726
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261701
evaluation/Rewards Std              0.985346
evaluation/Rewards Max             -0.0226088
evaluation/Rewards Min             -9.52223
evaluation/Returns Mean           -26.1701
evaluation/Returns Std             15.612
evaluation/Returns Max             -6.95692
evaluation/Returns Min            -51.8194
evaluation/Actions Mean            -0.0208158
evaluation/Actions Std              0.18962
evaluation/Actions Max              0.993147
evaluation/Actions Min             -0.996703
evaluation/Num Paths               15
evaluation/Average Returns        -26.1701
time/data storing (s)               0.00375045
time/evaluation sampling (s)        0.388629
time/exploration sampling (s)       0.169271
time/logging (s)                    0.00494554
time/saving (s)                     0.00236219
time/training (s)                   2.15111
time/epoch (s)                      2.72007
time/total (s)                    384.369
Epoch                             141
-----------------------------  ---------------
2019-04-22 21:44:28.073115 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 142 finished
-----------------------------  ----------------
replay_buffer/size              71700
trainer/QF1 Loss                    1.02023
trainer/QF2 Loss                    1.02784
trainer/Policy Loss                10.2749
trainer/Q1 Predictions Mean        -8.37521
trainer/Q1 Predictions Std          5.48637
trainer/Q1 Predictions Max         -6.84539
trainer/Q1 Predictions Min        -57.3246
trainer/Q2 Predictions Mean        -8.38221
trainer/Q2 Predictions Std          5.47185
trainer/Q2 Predictions Max         -6.7973
trainer/Q2 Predictions Min        -57.1221
trainer/Q Targets Mean             -8.39697
trainer/Q Targets Std               5.81283
trainer/Q Targets Max              -0.23875
trainer/Q Targets Min             -59.9728
trainer/Log Pis Mean                2.1637
trainer/Log Pis Std                 0.99173
trainer/Log Pis Max                 5.21103
trainer/Log Pis Min                -0.781541
trainer/Policy mu Mean             -0.100689
trainer/Policy mu Std               0.589958
trainer/Policy mu Max               2.59603
trainer/Policy mu Min              -3.21371
trainer/Policy log std Mean        -2.1674
trainer/Policy log std Std          0.477288
trainer/Policy log std Max         -0.510701
trainer/Policy log std Min         -2.63825
trainer/Alpha                       0.0628172
trainer/Alpha Loss                  0.453042
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.336089
exploration/Rewards Std             1.03333
exploration/Rewards Max            -0.00845624
exploration/Rewards Min            -9.30228
exploration/Returns Mean          -33.6089
exploration/Returns Std            15.9429
exploration/Returns Max           -15.4047
exploration/Returns Min           -54.6306
exploration/Actions Mean            0.00612747
exploration/Actions Std             0.242568
exploration/Actions Max             0.999281
exploration/Actions Min            -0.997413
exploration/Num Paths               5
exploration/Average Returns       -33.6089
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.194771
evaluation/Rewards Std              0.916614
evaluation/Rewards Max             -0.000724433
evaluation/Rewards Min             -8.35875
evaluation/Returns Mean           -19.4771
evaluation/Returns Std             12.1403
evaluation/Returns Max             -3.47989
evaluation/Returns Min            -40.1577
evaluation/Actions Mean             0.0053285
evaluation/Actions Std              0.1957
evaluation/Actions Max              0.995613
evaluation/Actions Min             -0.996753
evaluation/Num Paths               15
evaluation/Average Returns        -19.4771
time/data storing (s)               0.00317143
time/evaluation sampling (s)        0.356472
time/exploration sampling (s)       0.178829
time/logging (s)                    0.00491033
time/saving (s)                     0.00214765
time/training (s)                   2.16511
time/epoch (s)                      2.71064
time/total (s)                    387.084
Epoch                             142
-----------------------------  ----------------
2019-04-22 21:44:30.772015 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 143 finished
-----------------------------  ----------------
replay_buffer/size              72200
trainer/QF1 Loss                    1.45511
trainer/QF2 Loss                    1.45103
trainer/Policy Loss                10.0716
trainer/Q1 Predictions Mean        -8.26223
trainer/Q1 Predictions Std          4.59562
trainer/Q1 Predictions Max         -6.7835
trainer/Q1 Predictions Min        -45.6407
trainer/Q2 Predictions Mean        -8.25573
trainer/Q2 Predictions Std          4.57707
trainer/Q2 Predictions Max         -6.76337
trainer/Q2 Predictions Min        -45.4666
trainer/Q Targets Mean             -8.1384
trainer/Q Targets Std               4.81871
trainer/Q Targets Max              -0.0257996
trainer/Q Targets Min             -46.2339
trainer/Log Pis Mean                1.8905
trainer/Log Pis Std                 1.27838
trainer/Log Pis Max                 8.78937
trainer/Log Pis Min                -1.12684
trainer/Policy mu Mean              0.00597528
trainer/Policy mu Std               0.595756
trainer/Policy mu Max               3.08372
trainer/Policy mu Min              -3.26851
trainer/Policy log std Mean        -2.10054
trainer/Policy log std Std          0.436196
trainer/Policy log std Max         -0.356626
trainer/Policy log std Min         -2.57144
trainer/Alpha                       0.0624066
trainer/Alpha Loss                 -0.303733
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.415727
exploration/Rewards Std             1.29666
exploration/Rewards Max            -0.000477115
exploration/Rewards Min           -11.024
exploration/Returns Mean          -41.5727
exploration/Returns Std            20.6563
exploration/Returns Max           -15.5971
exploration/Returns Min           -69.7129
exploration/Actions Mean            0.0150918
exploration/Actions Std             0.262734
exploration/Actions Max             0.999934
exploration/Actions Min            -0.992176
exploration/Num Paths               5
exploration/Average Returns       -41.5727
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229799
evaluation/Rewards Std              1.00301
evaluation/Rewards Max             -0.0134676
evaluation/Rewards Min             -9.72634
evaluation/Returns Mean           -22.9799
evaluation/Returns Std             15.9522
evaluation/Returns Max             -3.39444
evaluation/Returns Min            -53.9544
evaluation/Actions Mean            -0.00429399
evaluation/Actions Std              0.189782
evaluation/Actions Max              0.998207
evaluation/Actions Min             -0.997536
evaluation/Num Paths               15
evaluation/Average Returns        -22.9799
time/data storing (s)               0.00320317
time/evaluation sampling (s)        0.363941
time/exploration sampling (s)       0.163079
time/logging (s)                    0.00405202
time/saving (s)                     0.00209212
time/training (s)                   2.15431
time/epoch (s)                      2.69068
time/total (s)                    389.78
Epoch                             143
-----------------------------  ----------------
2019-04-22 21:44:33.486909 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              72700
trainer/QF1 Loss                    0.666715
trainer/QF2 Loss                    0.62449
trainer/Policy Loss                10.9511
trainer/Q1 Predictions Mean        -9.09592
trainer/Q1 Predictions Std          5.62156
trainer/Q1 Predictions Max         -6.88211
trainer/Q1 Predictions Min        -47.7278
trainer/Q2 Predictions Mean        -9.11148
trainer/Q2 Predictions Std          5.67548
trainer/Q2 Predictions Max         -6.87146
trainer/Q2 Predictions Min        -48.0485
trainer/Q Targets Mean             -9.01169
trainer/Q Targets Std               5.72992
trainer/Q Targets Max              -1.57111
trainer/Q Targets Min             -48.72
trainer/Log Pis Mean                2.04695
trainer/Log Pis Std                 1.29265
trainer/Log Pis Max                 8.22229
trainer/Log Pis Min                -1.20363
trainer/Policy mu Mean             -0.0653581
trainer/Policy mu Std               0.755079
trainer/Policy mu Max               2.81542
trainer/Policy mu Min              -3.23471
trainer/Policy log std Mean        -2.0861
trainer/Policy log std Std          0.519097
trainer/Policy log std Max         -0.519114
trainer/Policy log std Min         -2.55417
trainer/Alpha                       0.0622806
trainer/Alpha Loss                  0.130347
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297123
exploration/Rewards Std             0.855069
exploration/Rewards Max            -0.00597667
exploration/Rewards Min            -8.28113
exploration/Returns Mean          -29.7123
exploration/Returns Std            12.2816
exploration/Returns Max           -11.774
exploration/Returns Min           -43.7221
exploration/Actions Mean           -0.0193579
exploration/Actions Std             0.229218
exploration/Actions Max             0.995539
exploration/Actions Min            -0.998207
exploration/Num Paths               5
exploration/Average Returns       -29.7123
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261473
evaluation/Rewards Std              1.1517
evaluation/Rewards Max             -0.00664662
evaluation/Rewards Min            -10.338
evaluation/Returns Mean           -26.1473
evaluation/Returns Std             16.3333
evaluation/Returns Max             -4.19168
evaluation/Returns Min            -53.2069
evaluation/Actions Mean            -0.00750307
evaluation/Actions Std              0.209394
evaluation/Actions Max              0.998839
evaluation/Actions Min             -0.997452
evaluation/Num Paths               15
evaluation/Average Returns        -26.1473
time/data storing (s)               0.0035067
time/evaluation sampling (s)        0.360852
time/exploration sampling (s)       0.1656
time/logging (s)                    0.00495891
time/saving (s)                     0.00165205
time/training (s)                   2.1718
time/epoch (s)                      2.70837
time/total (s)                    392.493
Epoch                             144
-----------------------------  ---------------
2019-04-22 21:44:36.134363 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                    0.605645
trainer/QF2 Loss                    0.609239
trainer/Policy Loss                12.0309
trainer/Q1 Predictions Mean       -10.4467
trainer/Q1 Predictions Std         10.3708
trainer/Q1 Predictions Max         -6.82051
trainer/Q1 Predictions Min        -63.3197
trainer/Q2 Predictions Mean       -10.4504
trainer/Q2 Predictions Std         10.3523
trainer/Q2 Predictions Max         -6.86527
trainer/Q2 Predictions Min        -63.5445
trainer/Q Targets Mean            -10.5194
trainer/Q Targets Std              10.6567
trainer/Q Targets Max              -0.246445
trainer/Q Targets Min             -64.7209
trainer/Log Pis Mean                2.08602
trainer/Log Pis Std                 1.70676
trainer/Log Pis Max                 8.99152
trainer/Log Pis Min                -3.73762
trainer/Policy mu Mean              0.0198311
trainer/Policy mu Std               0.891093
trainer/Policy mu Max               3.81736
trainer/Policy mu Min              -3.29016
trainer/Policy log std Mean        -2.03267
trainer/Policy log std Std          0.593632
trainer/Policy log std Max         -0.363439
trainer/Policy log std Min         -2.55475
trainer/Alpha                       0.0627403
trainer/Alpha Loss                  0.238159
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.284617
exploration/Rewards Std             0.777085
exploration/Rewards Max            -0.00403387
exploration/Rewards Min            -7.06958
exploration/Returns Mean          -28.4617
exploration/Returns Std             9.352
exploration/Returns Max           -15.1258
exploration/Returns Min           -43.3077
exploration/Actions Mean           -0.015812
exploration/Actions Std             0.230503
exploration/Actions Max             0.99677
exploration/Actions Min            -0.99929
exploration/Num Paths               5
exploration/Average Returns       -28.4617
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.220451
evaluation/Rewards Std              0.960974
evaluation/Rewards Max             -0.0053422
evaluation/Rewards Min             -9.70197
evaluation/Returns Mean           -22.0451
evaluation/Returns Std             16.249
evaluation/Returns Max             -6.78268
evaluation/Returns Min            -54.24
evaluation/Actions Mean            -0.00281629
evaluation/Actions Std              0.19231
evaluation/Actions Max              0.997829
evaluation/Actions Min             -0.997924
evaluation/Num Paths               15
evaluation/Average Returns        -22.0451
time/data storing (s)               0.00317281
time/evaluation sampling (s)        0.367618
time/exploration sampling (s)       0.162854
time/logging (s)                    0.00481142
time/saving (s)                     0.00215665
time/training (s)                   2.09957
time/epoch (s)                      2.64018
time/total (s)                    395.137
Epoch                             145
-----------------------------  ---------------
2019-04-22 21:44:38.816558 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              73700
trainer/QF1 Loss                    0.126627
trainer/QF2 Loss                    0.168146
trainer/Policy Loss                10.7624
trainer/Q1 Predictions Mean        -9.09248
trainer/Q1 Predictions Std          5.61302
trainer/Q1 Predictions Max         -6.72198
trainer/Q1 Predictions Min        -37.6666
trainer/Q2 Predictions Mean        -9.07853
trainer/Q2 Predictions Std          5.57823
trainer/Q2 Predictions Max         -6.69915
trainer/Q2 Predictions Min        -37.7754
trainer/Q Targets Mean             -9.2691
trainer/Q Targets Std               5.72252
trainer/Q Targets Max              -6.81209
trainer/Q Targets Min             -39.677
trainer/Log Pis Mean                1.98089
trainer/Log Pis Std                 1.47975
trainer/Log Pis Max                 7.6522
trainer/Log Pis Min                -3.37607
trainer/Policy mu Mean             -0.058262
trainer/Policy mu Std               0.789534
trainer/Policy mu Max               2.90871
trainer/Policy mu Min              -2.94069
trainer/Policy log std Mean        -2.00886
trainer/Policy log std Std          0.540457
trainer/Policy log std Max         -0.394978
trainer/Policy log std Min         -2.51076
trainer/Alpha                       0.0655464
trainer/Alpha Loss                 -0.0520791
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.293834
exploration/Rewards Std             0.896272
exploration/Rewards Max            -0.00338699
exploration/Rewards Min           -10.6297
exploration/Returns Mean          -29.3834
exploration/Returns Std            15.225
exploration/Returns Max           -11.994
exploration/Returns Min           -57.9264
exploration/Actions Mean           -0.00552751
exploration/Actions Std             0.235116
exploration/Actions Max             0.996585
exploration/Actions Min            -0.997604
exploration/Num Paths               5
exploration/Average Returns       -29.3834
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.285391
evaluation/Rewards Std              1.07418
evaluation/Rewards Max             -0.0408698
evaluation/Rewards Min            -10.8072
evaluation/Returns Mean           -28.5391
evaluation/Returns Std             14.8822
evaluation/Returns Max             -6.60022
evaluation/Returns Min            -56.843
evaluation/Actions Mean            -0.00838484
evaluation/Actions Std              0.204661
evaluation/Actions Max              0.998507
evaluation/Actions Min             -0.995588
evaluation/Num Paths               15
evaluation/Average Returns        -28.5391
time/data storing (s)               0.00319306
time/evaluation sampling (s)        0.352298
time/exploration sampling (s)       0.162635
time/logging (s)                    0.00500646
time/saving (s)                     0.0020992
time/training (s)                   2.15033
time/epoch (s)                      2.67556
time/total (s)                    397.817
Epoch                             146
-----------------------------  ---------------
2019-04-22 21:44:41.459955 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 147 finished
-----------------------------  ----------------
replay_buffer/size              74200
trainer/QF1 Loss                    0.623404
trainer/QF2 Loss                    0.645961
trainer/Policy Loss                10.7215
trainer/Q1 Predictions Mean        -9.43142
trainer/Q1 Predictions Std          9.77197
trainer/Q1 Predictions Max         -6.5148
trainer/Q1 Predictions Min        -68.2509
trainer/Q2 Predictions Mean        -9.42767
trainer/Q2 Predictions Std          9.64844
trainer/Q2 Predictions Max         -6.63105
trainer/Q2 Predictions Min        -67.9058
trainer/Q Targets Mean             -9.44261
trainer/Q Targets Std               9.7249
trainer/Q Targets Max              -0.321417
trainer/Q Targets Min             -65.1234
trainer/Log Pis Mean                1.73434
trainer/Log Pis Std                 1.40984
trainer/Log Pis Max                 7.03575
trainer/Log Pis Min                -2.99365
trainer/Policy mu Mean             -0.000573469
trainer/Policy mu Std               0.682665
trainer/Policy mu Max               3.02651
trainer/Policy mu Min              -3.29476
trainer/Policy log std Mean        -2.09499
trainer/Policy log std Std          0.475938
trainer/Policy log std Max         -0.317591
trainer/Policy log std Min         -2.50797
trainer/Alpha                       0.0657768
trainer/Alpha Loss                 -0.722958
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.404228
exploration/Rewards Std             1.23731
exploration/Rewards Max            -0.00470562
exploration/Rewards Min            -9.7109
exploration/Returns Mean          -40.4228
exploration/Returns Std            15.5036
exploration/Returns Max           -11.114
exploration/Returns Min           -56.1357
exploration/Actions Mean           -0.0108164
exploration/Actions Std             0.259933
exploration/Actions Max             0.999091
exploration/Actions Min            -0.999819
exploration/Num Paths               5
exploration/Average Returns       -40.4228
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.202596
evaluation/Rewards Std              0.937484
evaluation/Rewards Max             -0.013012
evaluation/Rewards Min            -10.4136
evaluation/Returns Mean           -20.2596
evaluation/Returns Std             14.8512
evaluation/Returns Max             -3.23437
evaluation/Returns Min            -48.4058
evaluation/Actions Mean            -0.00871172
evaluation/Actions Std              0.191138
evaluation/Actions Max              0.996841
evaluation/Actions Min             -0.997154
evaluation/Num Paths               15
evaluation/Average Returns        -20.2596
time/data storing (s)               0.00325859
time/evaluation sampling (s)        0.34987
time/exploration sampling (s)       0.155732
time/logging (s)                    0.00516183
time/saving (s)                     0.00208824
time/training (s)                   2.12008
time/epoch (s)                      2.63619
time/total (s)                    400.458
Epoch                             147
-----------------------------  ----------------
2019-04-22 21:44:44.212145 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              74700
trainer/QF1 Loss                    0.062356
trainer/QF2 Loss                    0.0667568
trainer/Policy Loss                10.4313
trainer/Q1 Predictions Mean        -8.69438
trainer/Q1 Predictions Std          5.13117
trainer/Q1 Predictions Max         -6.80183
trainer/Q1 Predictions Min        -39.7682
trainer/Q2 Predictions Mean        -8.71349
trainer/Q2 Predictions Std          5.16246
trainer/Q2 Predictions Max         -6.74249
trainer/Q2 Predictions Min        -39.8785
trainer/Q Targets Mean             -8.67779
trainer/Q Targets Std               4.95846
trainer/Q Targets Max              -6.73253
trainer/Q Targets Min             -37.6975
trainer/Log Pis Mean                1.90769
trainer/Log Pis Std                 1.39095
trainer/Log Pis Max                 7.19751
trainer/Log Pis Min                -3.06567
trainer/Policy mu Mean              0.0176892
trainer/Policy mu Std               0.670468
trainer/Policy mu Max               3.08323
trainer/Policy mu Min              -2.70075
trainer/Policy log std Mean        -2.12276
trainer/Policy log std Std          0.472886
trainer/Policy log std Max         -0.510524
trainer/Policy log std Min         -2.62202
trainer/Alpha                       0.0636074
trainer/Alpha Loss                 -0.254302
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.338706
exploration/Rewards Std             0.894999
exploration/Rewards Max            -0.00360238
exploration/Rewards Min            -7.15392
exploration/Returns Mean          -33.8706
exploration/Returns Std             9.36032
exploration/Returns Max           -18.8825
exploration/Returns Min           -45.2206
exploration/Actions Mean            0.0159451
exploration/Actions Std             0.260909
exploration/Actions Max             0.999073
exploration/Actions Min            -0.994985
exploration/Num Paths               5
exploration/Average Returns       -33.8706
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.246359
evaluation/Rewards Std              1.11858
evaluation/Rewards Max             -0.00567062
evaluation/Rewards Min            -11.2975
evaluation/Returns Mean           -24.6359
evaluation/Returns Std             18.6809
evaluation/Returns Max             -1.21851
evaluation/Returns Min            -61.3287
evaluation/Actions Mean             0.011307
evaluation/Actions Std              0.202574
evaluation/Actions Max              0.999136
evaluation/Actions Min             -0.995883
evaluation/Num Paths               15
evaluation/Average Returns        -24.6359
time/data storing (s)               0.00328899
time/evaluation sampling (s)        0.389986
time/exploration sampling (s)       0.161611
time/logging (s)                    0.00521317
time/saving (s)                     0.00206622
time/training (s)                   2.18298
time/epoch (s)                      2.74514
time/total (s)                    403.208
Epoch                             148
-----------------------------  ---------------
2019-04-22 21:44:46.861124 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                    0.0320007
trainer/QF2 Loss                    0.0309609
trainer/Policy Loss                 9.99911
trainer/Q1 Predictions Mean        -8.06801
trainer/Q1 Predictions Std          3.1054
trainer/Q1 Predictions Max         -6.68082
trainer/Q1 Predictions Min        -33.8823
trainer/Q2 Predictions Mean        -8.08314
trainer/Q2 Predictions Std          3.11461
trainer/Q2 Predictions Max         -6.63784
trainer/Q2 Predictions Min        -34.041
trainer/Q Targets Mean             -8.16651
trainer/Q Targets Std               3.05778
trainer/Q Targets Max              -6.69946
trainer/Q Targets Min             -33.2904
trainer/Log Pis Mean                2.02254
trainer/Log Pis Std                 1.33487
trainer/Log Pis Max                 7.4764
trainer/Log Pis Min                -3.57614
trainer/Policy mu Mean              0.0380924
trainer/Policy mu Std               0.605825
trainer/Policy mu Max               2.87275
trainer/Policy mu Min              -2.48728
trainer/Policy log std Mean        -2.14542
trainer/Policy log std Std          0.433674
trainer/Policy log std Max         -0.51502
trainer/Policy log std Min         -2.53982
trainer/Alpha                       0.0640201
trainer/Alpha Loss                  0.0619491
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.186952
exploration/Rewards Std             0.364453
exploration/Rewards Max            -0.0081603
exploration/Rewards Min            -4.0143
exploration/Returns Mean          -18.6952
exploration/Returns Std             2.60634
exploration/Returns Max           -15.8323
exploration/Returns Min           -22.1217
exploration/Actions Mean            0.00223734
exploration/Actions Std             0.207181
exploration/Actions Max             0.994219
exploration/Actions Min            -0.992321
exploration/Num Paths               5
exploration/Average Returns       -18.6952
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.264145
evaluation/Rewards Std              1.06898
evaluation/Rewards Max             -0.0154437
evaluation/Rewards Min            -10.0275
evaluation/Returns Mean           -26.4145
evaluation/Returns Std             17.5357
evaluation/Returns Max             -7.35065
evaluation/Returns Min            -60.3272
evaluation/Actions Mean             0.00539808
evaluation/Actions Std              0.193718
evaluation/Actions Max              0.999139
evaluation/Actions Min             -0.995975
evaluation/Num Paths               15
evaluation/Average Returns        -26.4145
time/data storing (s)               0.00322829
time/evaluation sampling (s)        0.361326
time/exploration sampling (s)       0.161244
time/logging (s)                    0.00490371
time/saving (s)                     0.00203525
time/training (s)                   2.10875
time/epoch (s)                      2.64148
time/total (s)                    405.853
Epoch                             149
-----------------------------  ---------------
2019-04-22 21:44:49.519215 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              75700
trainer/QF1 Loss                    0.164447
trainer/QF2 Loss                    0.151526
trainer/Policy Loss                10.749
trainer/Q1 Predictions Mean        -9.11371
trainer/Q1 Predictions Std          7.57807
trainer/Q1 Predictions Max         -6.5841
trainer/Q1 Predictions Min        -56.1599
trainer/Q2 Predictions Mean        -9.11068
trainer/Q2 Predictions Std          7.62196
trainer/Q2 Predictions Max         -6.59135
trainer/Q2 Predictions Min        -56.5414
trainer/Q Targets Mean             -9.31766
trainer/Q Targets Std               7.83944
trainer/Q Targets Max              -6.73541
trainer/Q Targets Min             -59.2916
trainer/Log Pis Mean                1.82697
trainer/Log Pis Std                 1.14611
trainer/Log Pis Max                 5.97494
trainer/Log Pis Min                -0.920556
trainer/Policy mu Mean              0.0575815
trainer/Policy mu Std               0.644363
trainer/Policy mu Max               3.85256
trainer/Policy mu Min              -2.74116
trainer/Policy log std Mean        -2.06777
trainer/Policy log std Std          0.458678
trainer/Policy log std Max         -0.190866
trainer/Policy log std Min         -2.55371
trainer/Alpha                       0.0645146
trainer/Alpha Loss                 -0.474214
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.304638
exploration/Rewards Std             0.884768
exploration/Rewards Max            -0.0102908
exploration/Rewards Min            -8.59329
exploration/Returns Mean          -30.4638
exploration/Returns Std            16.0594
exploration/Returns Max           -10.1404
exploration/Returns Min           -55.1005
exploration/Actions Mean           -0.0064774
exploration/Actions Std             0.225152
exploration/Actions Max             0.9992
exploration/Actions Min            -0.99859
exploration/Num Paths               5
exploration/Average Returns       -30.4638
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.171604
evaluation/Rewards Std              0.734047
evaluation/Rewards Max             -0.022615
evaluation/Rewards Min             -7.83568
evaluation/Returns Mean           -17.1604
evaluation/Returns Std             10.7909
evaluation/Returns Max             -5.98833
evaluation/Returns Min            -38.9205
evaluation/Actions Mean            -0.0176394
evaluation/Actions Std              0.172018
evaluation/Actions Max              0.990331
evaluation/Actions Min             -0.997713
evaluation/Num Paths               15
evaluation/Average Returns        -17.1604
time/data storing (s)               0.00319249
time/evaluation sampling (s)        0.362691
time/exploration sampling (s)       0.161651
time/logging (s)                    0.00508945
time/saving (s)                     0.00204676
time/training (s)                   2.11728
time/epoch (s)                      2.65195
time/total (s)                    408.509
Epoch                             150
-----------------------------  ---------------
2019-04-22 21:44:52.260288 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              76200
trainer/QF1 Loss                    0.0974839
trainer/QF2 Loss                    0.107605
trainer/Policy Loss                10.271
trainer/Q1 Predictions Mean        -8.71198
trainer/Q1 Predictions Std          5.4267
trainer/Q1 Predictions Max         -6.73882
trainer/Q1 Predictions Min        -58.3389
trainer/Q2 Predictions Mean        -8.70146
trainer/Q2 Predictions Std          5.40552
trainer/Q2 Predictions Max         -6.73154
trainer/Q2 Predictions Min        -58.0772
trainer/Q Targets Mean             -8.75344
trainer/Q Targets Std               5.65788
trainer/Q Targets Max              -6.65574
trainer/Q Targets Min             -60.9642
trainer/Log Pis Mean                1.97815
trainer/Log Pis Std                 1.14306
trainer/Log Pis Max                 5.84345
trainer/Log Pis Min                -1.02338
trainer/Policy mu Mean             -0.0656865
trainer/Policy mu Std               0.732447
trainer/Policy mu Max               2.85899
trainer/Policy mu Min              -2.6368
trainer/Policy log std Mean        -2.03381
trainer/Policy log std Std          0.55065
trainer/Policy log std Max         -0.391429
trainer/Policy log std Min         -2.57048
trainer/Alpha                       0.0631319
trainer/Alpha Loss                 -0.0603489
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.27712
exploration/Rewards Std             0.733764
exploration/Rewards Max            -0.00484358
exploration/Rewards Min            -7.39124
exploration/Returns Mean          -27.712
exploration/Returns Std             9.9748
exploration/Returns Max           -17.198
exploration/Returns Min           -43.9877
exploration/Actions Mean            0.00492845
exploration/Actions Std             0.229006
exploration/Actions Max             0.996839
exploration/Actions Min            -0.997821
exploration/Num Paths               5
exploration/Average Returns       -27.712
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234967
evaluation/Rewards Std              0.964666
evaluation/Rewards Max             -0.00356988
evaluation/Rewards Min            -10.4339
evaluation/Returns Mean           -23.4967
evaluation/Returns Std             16.7003
evaluation/Returns Max             -1.0619
evaluation/Returns Min            -46.736
evaluation/Actions Mean             0.00185674
evaluation/Actions Std              0.187747
evaluation/Actions Max              0.997827
evaluation/Actions Min             -0.996191
evaluation/Num Paths               15
evaluation/Average Returns        -23.4967
time/data storing (s)               0.00344252
time/evaluation sampling (s)        0.391787
time/exploration sampling (s)       0.186817
time/logging (s)                    0.00530536
time/saving (s)                     0.0019815
time/training (s)                   2.14526
time/epoch (s)                      2.7346
time/total (s)                    411.248
Epoch                             151
-----------------------------  ---------------
2019-04-22 21:44:54.949284 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              76700
trainer/QF1 Loss                    0.0159059
trainer/QF2 Loss                    0.0164493
trainer/Policy Loss                 9.60006
trainer/Q1 Predictions Mean        -7.87788
trainer/Q1 Predictions Std          1.71933
trainer/Q1 Predictions Max         -6.7285
trainer/Q1 Predictions Min        -16.732
trainer/Q2 Predictions Mean        -7.88922
trainer/Q2 Predictions Std          1.72662
trainer/Q2 Predictions Max         -6.74622
trainer/Q2 Predictions Min        -17.0178
trainer/Q Targets Mean             -7.91281
trainer/Q Targets Std               1.71838
trainer/Q Targets Max              -6.65771
trainer/Q Targets Min             -16.9022
trainer/Log Pis Mean                1.8618
trainer/Log Pis Std                 1.27178
trainer/Log Pis Max                 6.38228
trainer/Log Pis Min                -5.07483
trainer/Policy mu Mean              0.0411846
trainer/Policy mu Std               0.616444
trainer/Policy mu Max               2.7989
trainer/Policy mu Min              -2.25297
trainer/Policy log std Mean        -2.08069
trainer/Policy log std Std          0.467523
trainer/Policy log std Max         -0.5129
trainer/Policy log std Min         -2.53704
trainer/Alpha                       0.0636628
trainer/Alpha Loss                 -0.380613
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.348018
exploration/Rewards Std             1.02858
exploration/Rewards Max            -0.00600082
exploration/Rewards Min           -10.1546
exploration/Returns Mean          -34.8018
exploration/Returns Std            15.6485
exploration/Returns Max           -15.1199
exploration/Returns Min           -61.1087
exploration/Actions Mean            0.0312068
exploration/Actions Std             0.253598
exploration/Actions Max             0.998896
exploration/Actions Min            -0.980071
exploration/Num Paths               5
exploration/Average Returns       -34.8018
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.308876
evaluation/Rewards Std              1.14339
evaluation/Rewards Max             -0.038399
evaluation/Rewards Min            -10.6458
evaluation/Returns Mean           -30.8876
evaluation/Returns Std             15.4133
evaluation/Returns Max             -6.14396
evaluation/Returns Min            -61.9673
evaluation/Actions Mean             0.00448809
evaluation/Actions Std              0.206778
evaluation/Actions Max              0.999169
evaluation/Actions Min             -0.994612
evaluation/Num Paths               15
evaluation/Average Returns        -30.8876
time/data storing (s)               0.00317513
time/evaluation sampling (s)        0.359896
time/exploration sampling (s)       0.164502
time/logging (s)                    0.00474232
time/saving (s)                     0.00227492
time/training (s)                   2.14661
time/epoch (s)                      2.68121
time/total (s)                    413.934
Epoch                             152
-----------------------------  ---------------
2019-04-22 21:44:57.673124 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              77200
trainer/QF1 Loss                    0.711224
trainer/QF2 Loss                    0.722505
trainer/Policy Loss                 9.39496
trainer/Q1 Predictions Mean        -7.66204
trainer/Q1 Predictions Std          1.43122
trainer/Q1 Predictions Max         -6.69127
trainer/Q1 Predictions Min        -15.2692
trainer/Q2 Predictions Mean        -7.65105
trainer/Q2 Predictions Std          1.42281
trainer/Q2 Predictions Max         -6.69284
trainer/Q2 Predictions Min        -15.0504
trainer/Q Targets Mean             -7.82207
trainer/Q Targets Std               1.76917
trainer/Q Targets Max              -0.0556356
trainer/Q Targets Min             -16.4351
trainer/Log Pis Mean                1.95158
trainer/Log Pis Std                 1.06051
trainer/Log Pis Max                 4.72779
trainer/Log Pis Min                -1.02827
trainer/Policy mu Mean             -0.0561103
trainer/Policy mu Std               0.573675
trainer/Policy mu Max               2.49749
trainer/Policy mu Min              -2.69189
trainer/Policy log std Mean        -2.11699
trainer/Policy log std Std          0.446118
trainer/Policy log std Max         -0.599898
trainer/Policy log std Min         -2.54246
trainer/Alpha                       0.0637829
trainer/Alpha Loss                 -0.133252
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.445072
exploration/Rewards Std             1.29333
exploration/Rewards Max            -0.00220992
exploration/Rewards Min           -10.5112
exploration/Returns Mean          -44.5072
exploration/Returns Std            19.8581
exploration/Returns Max           -18.3333
exploration/Returns Min           -66.8699
exploration/Actions Mean            0.0129128
exploration/Actions Std             0.263622
exploration/Actions Max             0.998943
exploration/Actions Min            -0.998769
exploration/Num Paths               5
exploration/Average Returns       -44.5072
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.239425
evaluation/Rewards Std              1.00316
evaluation/Rewards Max             -0.00369968
evaluation/Rewards Min            -10.2957
evaluation/Returns Mean           -23.9425
evaluation/Returns Std             16.6996
evaluation/Returns Max             -1.37342
evaluation/Returns Min            -51.6653
evaluation/Actions Mean             0.0131116
evaluation/Actions Std              0.188294
evaluation/Actions Max              0.998411
evaluation/Actions Min             -0.997474
evaluation/Num Paths               15
evaluation/Average Returns        -23.9425
time/data storing (s)               0.00311467
time/evaluation sampling (s)        0.36291
time/exploration sampling (s)       0.165123
time/logging (s)                    0.00461906
time/saving (s)                     0.00186242
time/training (s)                   2.17859
time/epoch (s)                      2.71622
time/total (s)                    416.654
Epoch                             153
-----------------------------  ---------------
2019-04-22 21:45:00.346062 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              77700
trainer/QF1 Loss                    0.293161
trainer/QF2 Loss                    0.261162
trainer/Policy Loss                11.2424
trainer/Q1 Predictions Mean        -9.79706
trainer/Q1 Predictions Std         10.2024
trainer/Q1 Predictions Max         -6.38498
trainer/Q1 Predictions Min        -67.435
trainer/Q2 Predictions Mean        -9.79997
trainer/Q2 Predictions Std         10.2374
trainer/Q2 Predictions Max         -6.3839
trainer/Q2 Predictions Min        -67.4938
trainer/Q Targets Mean             -9.91385
trainer/Q Targets Std              10.1011
trainer/Q Targets Max              -6.646
trainer/Q Targets Min             -63.8271
trainer/Log Pis Mean                1.97127
trainer/Log Pis Std                 1.45324
trainer/Log Pis Max                 8.45623
trainer/Log Pis Min                -2.8603
trainer/Policy mu Mean             -0.0613555
trainer/Policy mu Std               0.732235
trainer/Policy mu Max               3.09068
trainer/Policy mu Min              -3.39271
trainer/Policy log std Mean        -2.1014
trainer/Policy log std Std          0.470567
trainer/Policy log std Max         -0.431305
trainer/Policy log std Min         -2.55122
trainer/Alpha                       0.0638941
trainer/Alpha Loss                 -0.079034
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.324421
exploration/Rewards Std             0.996394
exploration/Rewards Max            -0.00772226
exploration/Rewards Min            -9.54124
exploration/Returns Mean          -32.4421
exploration/Returns Std            15.275
exploration/Returns Max           -17.3914
exploration/Returns Min           -60.4817
exploration/Actions Mean           -0.0162285
exploration/Actions Std             0.224315
exploration/Actions Max             0.998588
exploration/Actions Min            -0.99925
exploration/Num Paths               5
exploration/Average Returns       -32.4421
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.21141
evaluation/Rewards Std              0.903508
evaluation/Rewards Max             -0.0177139
evaluation/Rewards Min            -10.3214
evaluation/Returns Mean           -21.141
evaluation/Returns Std             15.6871
evaluation/Returns Max             -4.54631
evaluation/Returns Min            -62.9952
evaluation/Actions Mean            -0.00875892
evaluation/Actions Std              0.185268
evaluation/Actions Max              0.998895
evaluation/Actions Min             -0.996938
evaluation/Num Paths               15
evaluation/Average Returns        -21.141
time/data storing (s)               0.00335167
time/evaluation sampling (s)        0.356562
time/exploration sampling (s)       0.160901
time/logging (s)                    0.00488881
time/saving (s)                     0.00165431
time/training (s)                   2.13892
time/epoch (s)                      2.66628
time/total (s)                    419.325
Epoch                             154
-----------------------------  ---------------
2019-04-22 21:45:03.035869 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              78200
trainer/QF1 Loss                    0.882639
trainer/QF2 Loss                    0.864517
trainer/Policy Loss                10.4383
trainer/Q1 Predictions Mean        -8.54806
trainer/Q1 Predictions Std          5.99877
trainer/Q1 Predictions Max         -6.40647
trainer/Q1 Predictions Min        -53.2715
trainer/Q2 Predictions Mean        -8.56982
trainer/Q2 Predictions Std          6.06111
trainer/Q2 Predictions Max         -6.43515
trainer/Q2 Predictions Min        -54.2063
trainer/Q Targets Mean             -8.51311
trainer/Q Targets Std               6.13613
trainer/Q Targets Max              -0.0582321
trainer/Q Targets Min             -54.2659
trainer/Log Pis Mean                2.1401
trainer/Log Pis Std                 1.39242
trainer/Log Pis Max                 7.85487
trainer/Log Pis Min                -2.20263
trainer/Policy mu Mean              0.0283271
trainer/Policy mu Std               0.6694
trainer/Policy mu Max               2.97067
trainer/Policy mu Min              -3.08697
trainer/Policy log std Mean        -2.0824
trainer/Policy log std Std          0.507828
trainer/Policy log std Max         -0.170428
trainer/Policy log std Min         -2.56796
trainer/Alpha                       0.0624334
trainer/Alpha Loss                  0.388586
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.24075
exploration/Rewards Std             0.606155
exploration/Rewards Max            -0.00863124
exploration/Rewards Min            -6.19859
exploration/Returns Mean          -24.075
exploration/Returns Std            11.3862
exploration/Returns Max           -11.1906
exploration/Returns Min           -40.3816
exploration/Actions Mean           -0.00339498
exploration/Actions Std             0.215456
exploration/Actions Max             0.998317
exploration/Actions Min            -0.996732
exploration/Num Paths               5
exploration/Average Returns       -24.075
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.220057
evaluation/Rewards Std              0.967739
evaluation/Rewards Max             -0.00492989
evaluation/Rewards Min            -10.261
evaluation/Returns Mean           -22.0057
evaluation/Returns Std             12.7205
evaluation/Returns Max             -2.9598
evaluation/Returns Min            -46.8585
evaluation/Actions Mean            -0.00356346
evaluation/Actions Std              0.198176
evaluation/Actions Max              0.997596
evaluation/Actions Min             -0.997092
evaluation/Num Paths               15
evaluation/Average Returns        -22.0057
time/data storing (s)               0.00303234
time/evaluation sampling (s)        0.354382
time/exploration sampling (s)       0.156944
time/logging (s)                    0.00457913
time/saving (s)                     0.0020146
time/training (s)                   2.16096
time/epoch (s)                      2.68192
time/total (s)                    422.011
Epoch                             155
-----------------------------  ---------------
2019-04-22 21:45:05.682792 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 156 finished
-----------------------------  ----------------
replay_buffer/size              78700
trainer/QF1 Loss                    0.0485806
trainer/QF2 Loss                    0.0624305
trainer/Policy Loss                10.1108
trainer/Q1 Predictions Mean        -8.36629
trainer/Q1 Predictions Std          4.29497
trainer/Q1 Predictions Max         -6.54595
trainer/Q1 Predictions Min        -42.5019
trainer/Q2 Predictions Mean        -8.35421
trainer/Q2 Predictions Std          4.29807
trainer/Q2 Predictions Max         -6.5437
trainer/Q2 Predictions Min        -42.3694
trainer/Q Targets Mean             -8.47757
trainer/Q Targets Std               4.374
trainer/Q Targets Max              -6.46171
trainer/Q Targets Min             -43.4135
trainer/Log Pis Mean                2.03701
trainer/Log Pis Std                 1.07922
trainer/Log Pis Max                 7.70813
trainer/Log Pis Min                -0.196842
trainer/Policy mu Mean             -0.0299724
trainer/Policy mu Std               0.752699
trainer/Policy mu Max               2.79297
trainer/Policy mu Min              -2.68524
trainer/Policy log std Mean        -2.05908
trainer/Policy log std Std          0.521726
trainer/Policy log std Max         -0.460347
trainer/Policy log std Min         -2.51579
trainer/Alpha                       0.0607741
trainer/Alpha Loss                  0.10365
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.323617
exploration/Rewards Std             0.974108
exploration/Rewards Max            -0.000252864
exploration/Rewards Min            -8.82658
exploration/Returns Mean          -32.3617
exploration/Returns Std            14.958
exploration/Returns Max           -17.5862
exploration/Returns Min           -52.7637
exploration/Actions Mean           -0.00452224
exploration/Actions Std             0.236561
exploration/Actions Max             0.999151
exploration/Actions Min            -0.999027
exploration/Num Paths               5
exploration/Average Returns       -32.3617
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.248501
evaluation/Rewards Std              0.98913
evaluation/Rewards Max             -0.0135317
evaluation/Rewards Min             -9.35538
evaluation/Returns Mean           -24.8501
evaluation/Returns Std             12.9786
evaluation/Returns Max             -9.03322
evaluation/Returns Min            -50.2963
evaluation/Actions Mean            -0.0101192
evaluation/Actions Std              0.195567
evaluation/Actions Max              0.998457
evaluation/Actions Min             -0.997567
evaluation/Num Paths               15
evaluation/Average Returns        -24.8501
time/data storing (s)               0.00300032
time/evaluation sampling (s)        0.345232
time/exploration sampling (s)       0.157184
time/logging (s)                    0.00410114
time/saving (s)                     0.00205625
time/training (s)                   2.12793
time/epoch (s)                      2.63951
time/total (s)                    424.655
Epoch                             156
-----------------------------  ----------------
2019-04-22 21:45:08.411063 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 157 finished
-----------------------------  ----------------
replay_buffer/size              79200
trainer/QF1 Loss                    0.503726
trainer/QF2 Loss                    0.529092
trainer/Policy Loss                10.4487
trainer/Q1 Predictions Mean        -9.0009
trainer/Q1 Predictions Std          7.97221
trainer/Q1 Predictions Max         -6.59512
trainer/Q1 Predictions Min        -60.8834
trainer/Q2 Predictions Mean        -9.00134
trainer/Q2 Predictions Std          7.94924
trainer/Q2 Predictions Max         -6.56275
trainer/Q2 Predictions Min        -60.3491
trainer/Q Targets Mean             -8.97224
trainer/Q Targets Std               8.24471
trainer/Q Targets Max              -0.118784
trainer/Q Targets Min             -63.1959
trainer/Log Pis Mean                1.85657
trainer/Log Pis Std                 1.20009
trainer/Log Pis Max                 4.71687
trainer/Log Pis Min                -3.64257
trainer/Policy mu Mean             -0.115825
trainer/Policy mu Std               0.546858
trainer/Policy mu Max               3.01323
trainer/Policy mu Min              -3.28314
trainer/Policy log std Mean        -2.2388
trainer/Policy log std Std          0.374991
trainer/Policy log std Max         -0.501667
trainer/Policy log std Min         -2.59151
trainer/Alpha                       0.062224
trainer/Alpha Loss                 -0.398336
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.3346
exploration/Rewards Std             1.0042
exploration/Rewards Max            -0.00110518
exploration/Rewards Min            -9.71719
exploration/Returns Mean          -33.46
exploration/Returns Std            14.1493
exploration/Returns Max           -18.5224
exploration/Returns Min           -55.0057
exploration/Actions Mean            0.00531838
exploration/Actions Std             0.245131
exploration/Actions Max             0.999451
exploration/Actions Min            -0.998606
exploration/Num Paths               5
exploration/Average Returns       -33.46
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213392
evaluation/Rewards Std              0.89188
evaluation/Rewards Max             -0.0259876
evaluation/Rewards Min            -10.7597
evaluation/Returns Mean           -21.3392
evaluation/Returns Std             16.5383
evaluation/Returns Max             -3.37213
evaluation/Returns Min            -61.7526
evaluation/Actions Mean            -0.000221097
evaluation/Actions Std              0.182664
evaluation/Actions Max              0.998863
evaluation/Actions Min             -0.997658
evaluation/Num Paths               15
evaluation/Average Returns        -21.3392
time/data storing (s)               0.00316267
time/evaluation sampling (s)        0.360588
time/exploration sampling (s)       0.165381
time/logging (s)                    0.00492697
time/saving (s)                     0.00226855
time/training (s)                   2.18547
time/epoch (s)                      2.7218
time/total (s)                    427.381
Epoch                             157
-----------------------------  ----------------
2019-04-22 21:45:11.097362 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              79700
trainer/QF1 Loss                    0.472389
trainer/QF2 Loss                    0.477496
trainer/Policy Loss                10.8622
trainer/Q1 Predictions Mean        -9.52711
trainer/Q1 Predictions Std          9.39012
trainer/Q1 Predictions Max         -6.40388
trainer/Q1 Predictions Min        -63.9089
trainer/Q2 Predictions Mean        -9.55476
trainer/Q2 Predictions Std          9.42622
trainer/Q2 Predictions Max         -6.39147
trainer/Q2 Predictions Min        -63.8567
trainer/Q Targets Mean             -9.58543
trainer/Q Targets Std               9.57561
trainer/Q Targets Max              -0.399829
trainer/Q Targets Min             -65.2171
trainer/Log Pis Mean                1.80271
trainer/Log Pis Std                 1.32195
trainer/Log Pis Max                 7.20656
trainer/Log Pis Min                -1.82364
trainer/Policy mu Mean             -0.0947188
trainer/Policy mu Std               0.78798
trainer/Policy mu Max               3.19992
trainer/Policy mu Min              -3.30687
trainer/Policy log std Mean        -2.06073
trainer/Policy log std Std          0.541344
trainer/Policy log std Max         -0.541103
trainer/Policy log std Min         -2.54374
trainer/Alpha                       0.0626337
trainer/Alpha Loss                 -0.546576
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.35679
exploration/Rewards Std             1.14845
exploration/Rewards Max            -0.00720341
exploration/Rewards Min           -11.3016
exploration/Returns Mean          -35.679
exploration/Returns Std            16.3237
exploration/Returns Max           -18.0788
exploration/Returns Min           -62.6369
exploration/Actions Mean           -0.0274439
exploration/Actions Std             0.248073
exploration/Actions Max             0.998557
exploration/Actions Min            -0.998151
exploration/Num Paths               5
exploration/Average Returns       -35.679
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.205816
evaluation/Rewards Std              0.922909
evaluation/Rewards Max             -0.0209584
evaluation/Rewards Min             -9.76479
evaluation/Returns Mean           -20.5816
evaluation/Returns Std             13.3986
evaluation/Returns Max             -4.87241
evaluation/Returns Min            -44.6163
evaluation/Actions Mean            -0.00854593
evaluation/Actions Std              0.191732
evaluation/Actions Max              0.995858
evaluation/Actions Min             -0.996236
evaluation/Num Paths               15
evaluation/Average Returns        -20.5816
time/data storing (s)               0.00319427
time/evaluation sampling (s)        0.364187
time/exploration sampling (s)       0.166702
time/logging (s)                    0.00519615
time/saving (s)                     0.00216259
time/training (s)                   2.13846
time/epoch (s)                      2.6799
time/total (s)                    430.065
Epoch                             158
-----------------------------  ---------------
2019-04-22 21:45:13.823859 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    0.423614
trainer/QF2 Loss                    0.43823
trainer/Policy Loss                 9.65955
trainer/Q1 Predictions Mean        -7.93257
trainer/Q1 Predictions Std          2.25788
trainer/Q1 Predictions Max         -6.39711
trainer/Q1 Predictions Min        -22.2018
trainer/Q2 Predictions Mean        -7.94414
trainer/Q2 Predictions Std          2.2418
trainer/Q2 Predictions Max         -6.3855
trainer/Q2 Predictions Min        -22.2345
trainer/Q Targets Mean             -7.93279
trainer/Q Targets Std               2.31931
trainer/Q Targets Max              -0.129529
trainer/Q Targets Min             -22.13
trainer/Log Pis Mean                1.95736
trainer/Log Pis Std                 1.20904
trainer/Log Pis Max                 7.5599
trainer/Log Pis Min                -4.03079
trainer/Policy mu Mean             -0.0537246
trainer/Policy mu Std               0.595477
trainer/Policy mu Max               2.69816
trainer/Policy mu Min              -2.72316
trainer/Policy log std Mean        -2.14756
trainer/Policy log std Std          0.454106
trainer/Policy log std Max         -0.481024
trainer/Policy log std Min         -2.58612
trainer/Alpha                       0.062011
trainer/Alpha Loss                 -0.118567
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.243209
exploration/Rewards Std             0.80747
exploration/Rewards Max            -0.00428395
exploration/Rewards Min            -9.24012
exploration/Returns Mean          -24.3209
exploration/Returns Std            16.9872
exploration/Returns Max           -11.7436
exploration/Returns Min           -57.7746
exploration/Actions Mean           -0.00451207
exploration/Actions Std             0.195075
exploration/Actions Max             0.987039
exploration/Actions Min            -0.99795
exploration/Num Paths               5
exploration/Average Returns       -24.3209
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247786
evaluation/Rewards Std              1.05236
evaluation/Rewards Max             -0.0220372
evaluation/Rewards Min             -9.16204
evaluation/Returns Mean           -24.7786
evaluation/Returns Std             15.2356
evaluation/Returns Max             -2.34705
evaluation/Returns Min            -48.7938
evaluation/Actions Mean             0.0165359
evaluation/Actions Std              0.201267
evaluation/Actions Max              0.997678
evaluation/Actions Min             -0.997378
evaluation/Num Paths               15
evaluation/Average Returns        -24.7786
time/data storing (s)               0.00350857
time/evaluation sampling (s)        0.35983
time/exploration sampling (s)       0.160807
time/logging (s)                    0.00504924
time/saving (s)                     0.041441
time/training (s)                   2.14827
time/epoch (s)                      2.7189
time/total (s)                    432.788
Epoch                             159
-----------------------------  ---------------
2019-04-22 21:45:16.499238 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              80700
trainer/QF1 Loss                    0.887669
trainer/QF2 Loss                    0.902954
trainer/Policy Loss                10.4024
trainer/Q1 Predictions Mean        -8.81859
trainer/Q1 Predictions Std          6.69051
trainer/Q1 Predictions Max         -6.53563
trainer/Q1 Predictions Min        -64.4576
trainer/Q2 Predictions Mean        -8.80842
trainer/Q2 Predictions Std          6.63918
trainer/Q2 Predictions Max         -6.54002
trainer/Q2 Predictions Min        -64.1757
trainer/Q Targets Mean             -8.68073
trainer/Q Targets Std               6.76324
trainer/Q Targets Max              -0.24772
trainer/Q Targets Min             -64.443
trainer/Log Pis Mean                1.892
trainer/Log Pis Std                 1.09467
trainer/Log Pis Max                 5.88782
trainer/Log Pis Min                -1.51478
trainer/Policy mu Mean             -0.0629421
trainer/Policy mu Std               0.672498
trainer/Policy mu Max               2.99114
trainer/Policy mu Min              -3.28095
trainer/Policy log std Mean        -2.0511
trainer/Policy log std Std          0.493743
trainer/Policy log std Max         -0.514751
trainer/Policy log std Min         -2.52379
trainer/Alpha                       0.0631548
trainer/Alpha Loss                 -0.298289
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.321314
exploration/Rewards Std             0.975961
exploration/Rewards Max            -0.00671772
exploration/Rewards Min            -8.03035
exploration/Returns Mean          -32.1314
exploration/Returns Std            12.9954
exploration/Returns Max           -14.2242
exploration/Returns Min           -48.1657
exploration/Actions Mean           -0.00631594
exploration/Actions Std             0.232797
exploration/Actions Max             0.998733
exploration/Actions Min            -0.998179
exploration/Num Paths               5
exploration/Average Returns       -32.1314
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.217143
evaluation/Rewards Std              0.985225
evaluation/Rewards Max             -0.00947486
evaluation/Rewards Min            -10.529
evaluation/Returns Mean           -21.7143
evaluation/Returns Std             15.01
evaluation/Returns Max             -3.40937
evaluation/Returns Min            -54.6468
evaluation/Actions Mean            -0.00411835
evaluation/Actions Std              0.197364
evaluation/Actions Max              0.998694
evaluation/Actions Min             -0.99688
evaluation/Num Paths               15
evaluation/Average Returns        -21.7143
time/data storing (s)               0.0031036
time/evaluation sampling (s)        0.389711
time/exploration sampling (s)       0.162434
time/logging (s)                    0.00478713
time/saving (s)                     0.00200855
time/training (s)                   2.10533
time/epoch (s)                      2.66738
time/total (s)                    435.461
Epoch                             160
-----------------------------  ---------------
2019-04-22 21:45:19.140156 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              81200
trainer/QF1 Loss                    1.62544
trainer/QF2 Loss                    1.63286
trainer/Policy Loss                 9.92857
trainer/Q1 Predictions Mean        -8.09098
trainer/Q1 Predictions Std          3.661
trainer/Q1 Predictions Max         -6.29921
trainer/Q1 Predictions Min        -31.469
trainer/Q2 Predictions Mean        -8.07983
trainer/Q2 Predictions Std          3.65898
trainer/Q2 Predictions Max         -6.30678
trainer/Q2 Predictions Min        -31.499
trainer/Q Targets Mean             -7.91665
trainer/Q Targets Std               3.76696
trainer/Q Targets Max              -0.0578061
trainer/Q Targets Min             -30.1901
trainer/Log Pis Mean                2.0024
trainer/Log Pis Std                 1.42208
trainer/Log Pis Max                 7.95814
trainer/Log Pis Min                -1.7565
trainer/Policy mu Mean             -0.0165602
trainer/Policy mu Std               0.683397
trainer/Policy mu Max               2.60509
trainer/Policy mu Min              -2.90596
trainer/Policy log std Mean        -2.0688
trainer/Policy log std Std          0.49109
trainer/Policy log std Max         -0.462429
trainer/Policy log std Min         -2.54353
trainer/Alpha                       0.0626017
trainer/Alpha Loss                  0.0066461
exploration/num steps total     81200
exploration/num paths total       812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.438642
exploration/Rewards Std             1.2864
exploration/Rewards Max            -0.00942218
exploration/Rewards Min            -9.63298
exploration/Returns Mean          -43.8642
exploration/Returns Std             8.04012
exploration/Returns Max           -28.7532
exploration/Returns Min           -50.9474
exploration/Actions Mean           -0.044478
exploration/Actions Std             0.273569
exploration/Actions Max             0.996412
exploration/Actions Min            -0.999498
exploration/Num Paths               5
exploration/Average Returns       -43.8642
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.292433
evaluation/Rewards Std              1.08317
evaluation/Rewards Max             -0.0178391
evaluation/Rewards Min             -9.58885
evaluation/Returns Mean           -29.2433
evaluation/Returns Std             18.072
evaluation/Returns Max             -6.43659
evaluation/Returns Min            -61.9267
evaluation/Actions Mean             0.0148896
evaluation/Actions Std              0.193037
evaluation/Actions Max              0.998598
evaluation/Actions Min             -0.994525
evaluation/Num Paths               15
evaluation/Average Returns        -29.2433
time/data storing (s)               0.00306607
time/evaluation sampling (s)        0.351863
time/exploration sampling (s)       0.157095
time/logging (s)                    0.00535624
time/saving (s)                     0.00205319
time/training (s)                   2.11415
time/epoch (s)                      2.63358
time/total (s)                    438.099
Epoch                             161
-----------------------------  ---------------
2019-04-22 21:45:21.866075 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              81700
trainer/QF1 Loss                    0.830828
trainer/QF2 Loss                    0.815841
trainer/Policy Loss                10.0853
trainer/Q1 Predictions Mean        -8.20016
trainer/Q1 Predictions Std          3.11867
trainer/Q1 Predictions Max         -6.29359
trainer/Q1 Predictions Min        -26.4749
trainer/Q2 Predictions Mean        -8.19072
trainer/Q2 Predictions Std          3.08517
trainer/Q2 Predictions Max         -6.29566
trainer/Q2 Predictions Min        -26.3016
trainer/Q Targets Mean             -8.07256
trainer/Q Targets Std               3.26826
trainer/Q Targets Max              -0.0530746
trainer/Q Targets Min             -26.4695
trainer/Log Pis Mean                2.05603
trainer/Log Pis Std                 1.16215
trainer/Log Pis Max                 6.13523
trainer/Log Pis Min                -0.713257
trainer/Policy mu Mean              0.0543762
trainer/Policy mu Std               0.681407
trainer/Policy mu Max               2.88136
trainer/Policy mu Min              -2.78933
trainer/Policy log std Mean        -2.05029
trainer/Policy log std Std          0.532604
trainer/Policy log std Max         -0.471656
trainer/Policy log std Min         -2.60145
trainer/Alpha                       0.0619162
trainer/Alpha Loss                  0.155859
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.258012
exploration/Rewards Std             0.8776
exploration/Rewards Max            -0.00801922
exploration/Rewards Min            -9.36016
exploration/Returns Mean          -25.8012
exploration/Returns Std            16.3239
exploration/Returns Max           -11.7307
exploration/Returns Min           -56.0293
exploration/Actions Mean           -0.0137543
exploration/Actions Std             0.214739
exploration/Actions Max             0.999152
exploration/Actions Min            -0.999461
exploration/Num Paths               5
exploration/Average Returns       -25.8012
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.164434
evaluation/Rewards Std              0.727351
evaluation/Rewards Max             -0.00745691
evaluation/Rewards Min             -7.4025
evaluation/Returns Mean           -16.4434
evaluation/Returns Std              8.94632
evaluation/Returns Max             -5.09037
evaluation/Returns Min            -33.9318
evaluation/Actions Mean             0.00872142
evaluation/Actions Std              0.181211
evaluation/Actions Max              0.995508
evaluation/Actions Min             -0.997399
evaluation/Num Paths               15
evaluation/Average Returns        -16.4434
time/data storing (s)               0.00333276
time/evaluation sampling (s)        0.360208
time/exploration sampling (s)       0.161267
time/logging (s)                    0.0049658
time/saving (s)                     0.00220943
time/training (s)                   2.18588
time/epoch (s)                      2.71786
time/total (s)                    440.822
Epoch                             162
-----------------------------  ---------------
2019-04-22 21:45:24.553776 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              82200
trainer/QF1 Loss                    0.0720175
trainer/QF2 Loss                    0.0919734
trainer/Policy Loss                10.6127
trainer/Q1 Predictions Mean        -9.01166
trainer/Q1 Predictions Std          6.17025
trainer/Q1 Predictions Max         -6.09758
trainer/Q1 Predictions Min        -48.4781
trainer/Q2 Predictions Mean        -9.02032
trainer/Q2 Predictions Std          6.12305
trainer/Q2 Predictions Max         -6.13947
trainer/Q2 Predictions Min        -47.7033
trainer/Q Targets Mean             -9.22518
trainer/Q Targets Std               6.17117
trainer/Q Targets Max              -6.2805
trainer/Q Targets Min             -48.8324
trainer/Log Pis Mean                1.91061
trainer/Log Pis Std                 1.6261
trainer/Log Pis Max                 8.04819
trainer/Log Pis Min                -3.69188
trainer/Policy mu Mean             -0.0493418
trainer/Policy mu Std               0.8435
trainer/Policy mu Max               3.06749
trainer/Policy mu Min              -2.87422
trainer/Policy log std Mean        -2.05716
trainer/Policy log std Std          0.584699
trainer/Policy log std Max         -0.425772
trainer/Policy log std Min         -2.6349
trainer/Alpha                       0.0640208
trainer/Alpha Loss                 -0.245712
exploration/num steps total     82200
exploration/num paths total       822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.191653
exploration/Rewards Std             0.53082
exploration/Rewards Max            -0.00297976
exploration/Rewards Min            -6.3184
exploration/Returns Mean          -19.1653
exploration/Returns Std             7.97418
exploration/Returns Max            -9.92196
exploration/Returns Min           -32.0686
exploration/Actions Mean           -0.0205544
exploration/Actions Std             0.181126
exploration/Actions Max             0.892432
exploration/Actions Min            -0.997658
exploration/Num Paths               5
exploration/Average Returns       -19.1653
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.253822
evaluation/Rewards Std              0.962841
evaluation/Rewards Max             -0.0064212
evaluation/Rewards Min            -10.7811
evaluation/Returns Mean           -25.3822
evaluation/Returns Std             14.6996
evaluation/Returns Max            -10.6922
evaluation/Returns Min            -58.3997
evaluation/Actions Mean            -0.00681126
evaluation/Actions Std              0.188464
evaluation/Actions Max              0.99782
evaluation/Actions Min             -0.997582
evaluation/Num Paths               15
evaluation/Average Returns        -25.3822
time/data storing (s)               0.0037836
time/evaluation sampling (s)        0.366749
time/exploration sampling (s)       0.166549
time/logging (s)                    0.00506239
time/saving (s)                     0.00211698
time/training (s)                   2.13568
time/epoch (s)                      2.67994
time/total (s)                    443.507
Epoch                             163
-----------------------------  ---------------
2019-04-22 21:45:27.239470 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              82700
trainer/QF1 Loss                    0.90298
trainer/QF2 Loss                    0.90798
trainer/Policy Loss                10.314
trainer/Q1 Predictions Mean        -8.69418
trainer/Q1 Predictions Std          7.09504
trainer/Q1 Predictions Max         -6.21745
trainer/Q1 Predictions Min        -69.3339
trainer/Q2 Predictions Mean        -8.66203
trainer/Q2 Predictions Std          6.97021
trainer/Q2 Predictions Max         -6.2275
trainer/Q2 Predictions Min        -67.9974
trainer/Q Targets Mean             -8.59705
trainer/Q Targets Std               7.19778
trainer/Q Targets Max              -0.0287615
trainer/Q Targets Min             -69.7748
trainer/Log Pis Mean                1.98879
trainer/Log Pis Std                 1.51184
trainer/Log Pis Max                 9.08591
trainer/Log Pis Min                -4.889
trainer/Policy mu Mean             -0.0219589
trainer/Policy mu Std               0.706171
trainer/Policy mu Max               3.56975
trainer/Policy mu Min              -2.7869
trainer/Policy log std Mean        -2.05608
trainer/Policy log std Std          0.519882
trainer/Policy log std Max         -0.334425
trainer/Policy log std Min         -2.52651
trainer/Alpha                       0.062871
trainer/Alpha Loss                 -0.0310094
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407914
exploration/Rewards Std             1.22671
exploration/Rewards Max            -0.0076083
exploration/Rewards Min            -9.92556
exploration/Returns Mean          -40.7914
exploration/Returns Std            16.3942
exploration/Returns Max           -19.3901
exploration/Returns Min           -61.7195
exploration/Actions Mean           -0.0154288
exploration/Actions Std             0.254642
exploration/Actions Max             0.999589
exploration/Actions Min            -0.999493
exploration/Num Paths               5
exploration/Average Returns       -40.7914
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228855
evaluation/Rewards Std              0.970347
evaluation/Rewards Max             -0.00987619
evaluation/Rewards Min             -9.73032
evaluation/Returns Mean           -22.8855
evaluation/Returns Std             12.9626
evaluation/Returns Max             -1.9433
evaluation/Returns Min            -46.8351
evaluation/Actions Mean             0.0069581
evaluation/Actions Std              0.197571
evaluation/Actions Max              0.997248
evaluation/Actions Min             -0.995227
evaluation/Num Paths               15
evaluation/Average Returns        -22.8855
time/data storing (s)               0.00328574
time/evaluation sampling (s)        0.359696
time/exploration sampling (s)       0.165647
time/logging (s)                    0.00451518
time/saving (s)                     0.00201833
time/training (s)                   2.14203
time/epoch (s)                      2.67719
time/total (s)                    446.188
Epoch                             164
-----------------------------  ---------------
2019-04-22 21:45:29.927718 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              83200
trainer/QF1 Loss                    0.456073
trainer/QF2 Loss                    0.455097
trainer/Policy Loss                10.1366
trainer/Q1 Predictions Mean        -8.44479
trainer/Q1 Predictions Std          5.41943
trainer/Q1 Predictions Max         -6.3605
trainer/Q1 Predictions Min        -54.9795
trainer/Q2 Predictions Mean        -8.44251
trainer/Q2 Predictions Std          5.39708
trainer/Q2 Predictions Max         -6.38797
trainer/Q2 Predictions Min        -54.6262
trainer/Q Targets Mean             -8.40746
trainer/Q Targets Std               5.40542
trainer/Q Targets Max              -0.108585
trainer/Q Targets Min             -53.7275
trainer/Log Pis Mean                1.93454
trainer/Log Pis Std                 1.34839
trainer/Log Pis Max                 7.64561
trainer/Log Pis Min                -1.74228
trainer/Policy mu Mean             -0.0491765
trainer/Policy mu Std               0.712226
trainer/Policy mu Max               2.87892
trainer/Policy mu Min              -2.8526
trainer/Policy log std Mean        -2.0744
trainer/Policy log std Std          0.532688
trainer/Policy log std Max         -0.436769
trainer/Policy log std Min         -2.54573
trainer/Alpha                       0.0622415
trainer/Alpha Loss                 -0.181757
exploration/num steps total     83200
exploration/num paths total       832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33083
exploration/Rewards Std             0.84472
exploration/Rewards Max            -0.00570344
exploration/Rewards Min            -6.98683
exploration/Returns Mean          -33.083
exploration/Returns Std             7.27467
exploration/Returns Max           -21.1371
exploration/Returns Min           -43.0543
exploration/Actions Mean            0.0126811
exploration/Actions Std             0.25516
exploration/Actions Max             0.998914
exploration/Actions Min            -0.995783
exploration/Num Paths               5
exploration/Average Returns       -33.083
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.304889
evaluation/Rewards Std              1.23503
evaluation/Rewards Max             -0.0209198
evaluation/Rewards Min            -11.404
evaluation/Returns Mean           -30.4889
evaluation/Returns Std             16.8836
evaluation/Returns Max             -9.13516
evaluation/Returns Min            -58.0096
evaluation/Actions Mean             0.00256373
evaluation/Actions Std              0.22027
evaluation/Actions Max              0.998495
evaluation/Actions Min             -0.994955
evaluation/Num Paths               15
evaluation/Average Returns        -30.4889
time/data storing (s)               0.00303486
time/evaluation sampling (s)        0.35522
time/exploration sampling (s)       0.157211
time/logging (s)                    0.00503033
time/saving (s)                     0.0020943
time/training (s)                   2.15878
time/epoch (s)                      2.68137
time/total (s)                    448.875
Epoch                             165
-----------------------------  ---------------
2019-04-22 21:45:32.644954 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              83700
trainer/QF1 Loss                    0.0918718
trainer/QF2 Loss                    0.160823
trainer/Policy Loss                11.3026
trainer/Q1 Predictions Mean        -9.60126
trainer/Q1 Predictions Std          8.23359
trainer/Q1 Predictions Max         -6.2488
trainer/Q1 Predictions Min        -55.9806
trainer/Q2 Predictions Mean        -9.621
trainer/Q2 Predictions Std          8.32587
trainer/Q2 Predictions Max         -6.23716
trainer/Q2 Predictions Min        -55.5047
trainer/Q Targets Mean             -9.58687
trainer/Q Targets Std               8.22038
trainer/Q Targets Max              -6.23944
trainer/Q Targets Min             -57.3051
trainer/Log Pis Mean                2.20304
trainer/Log Pis Std                 1.64732
trainer/Log Pis Max                 7.0554
trainer/Log Pis Min                -2.24547
trainer/Policy mu Mean             -0.168844
trainer/Policy mu Std               0.809221
trainer/Policy mu Max               2.85802
trainer/Policy mu Min              -3.35784
trainer/Policy log std Mean        -2.07191
trainer/Policy log std Std          0.582509
trainer/Policy log std Max         -0.452391
trainer/Policy log std Min         -2.60646
trainer/Alpha                       0.0623168
trainer/Alpha Loss                  0.563586
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.314961
exploration/Rewards Std             1.04705
exploration/Rewards Max            -0.00852015
exploration/Rewards Min           -10.6018
exploration/Returns Mean          -31.4961
exploration/Returns Std            19.3125
exploration/Returns Max           -13.2936
exploration/Returns Min           -65.3692
exploration/Actions Mean            0.0292525
exploration/Actions Std             0.23722
exploration/Actions Max             0.99951
exploration/Actions Min            -0.980197
exploration/Num Paths               5
exploration/Average Returns       -31.4961
evaluation/num steps total     250500
evaluation/num paths total       2505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.195939
evaluation/Rewards Std              0.881277
evaluation/Rewards Max             -0.0197494
evaluation/Rewards Min             -8.78606
evaluation/Returns Mean           -19.5939
evaluation/Returns Std             10.6796
evaluation/Returns Max             -2.1034
evaluation/Returns Min            -37.9258
evaluation/Actions Mean            -0.0132532
evaluation/Actions Std              0.190632
evaluation/Actions Max              0.994785
evaluation/Actions Min             -0.997259
evaluation/Num Paths               15
evaluation/Average Returns        -19.5939
time/data storing (s)               0.00315987
time/evaluation sampling (s)        0.354271
time/exploration sampling (s)       0.160366
time/logging (s)                    0.00493015
time/saving (s)                     0.00209711
time/training (s)                   2.18396
time/epoch (s)                      2.70879
time/total (s)                    451.589
Epoch                             166
-----------------------------  ---------------
2019-04-22 21:45:35.329168 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              84200
trainer/QF1 Loss                    0.0432235
trainer/QF2 Loss                    0.0439118
trainer/Policy Loss                 9.68749
trainer/Q1 Predictions Mean        -8.07964
trainer/Q1 Predictions Std          2.8268
trainer/Q1 Predictions Max         -6.17543
trainer/Q1 Predictions Min        -24.5882
trainer/Q2 Predictions Mean        -8.08382
trainer/Q2 Predictions Std          2.83869
trainer/Q2 Predictions Max         -6.21243
trainer/Q2 Predictions Min        -24.7515
trainer/Q Targets Mean             -8.21608
trainer/Q Targets Std               2.85412
trainer/Q Targets Max              -6.21212
trainer/Q Targets Min             -24.7393
trainer/Log Pis Mean                1.78552
trainer/Log Pis Std                 1.21009
trainer/Log Pis Max                 4.52103
trainer/Log Pis Min                -2.80621
trainer/Policy mu Mean              0.019141
trainer/Policy mu Std               0.639949
trainer/Policy mu Max               2.86682
trainer/Policy mu Min              -2.65668
trainer/Policy log std Mean        -2.1258
trainer/Policy log std Std          0.475862
trainer/Policy log std Max         -0.573635
trainer/Policy log std Min         -2.52803
trainer/Alpha                       0.0636005
trainer/Alpha Loss                 -0.590953
exploration/num steps total     84200
exploration/num paths total       842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.371315
exploration/Rewards Std             1.1527
exploration/Rewards Max            -0.014929
exploration/Rewards Min            -9.05801
exploration/Returns Mean          -37.1315
exploration/Returns Std            15.7679
exploration/Returns Max           -11.4874
exploration/Returns Min           -56.9029
exploration/Actions Mean            0.0027071
exploration/Actions Std             0.245838
exploration/Actions Max             0.998734
exploration/Actions Min            -0.999481
exploration/Num Paths               5
exploration/Average Returns       -37.1315
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199629
evaluation/Rewards Std              0.843938
evaluation/Rewards Max             -0.0135515
evaluation/Rewards Min             -9.10071
evaluation/Returns Mean           -19.9629
evaluation/Returns Std             11.7902
evaluation/Returns Max             -3.77986
evaluation/Returns Min            -49.683
evaluation/Actions Mean             0.00865134
evaluation/Actions Std              0.187438
evaluation/Actions Max              0.996636
evaluation/Actions Min             -0.993481
evaluation/Num Paths               15
evaluation/Average Returns        -19.9629
time/data storing (s)               0.0031291
time/evaluation sampling (s)        0.36034
time/exploration sampling (s)       0.165182
time/logging (s)                    0.00501667
time/saving (s)                     0.00242071
time/training (s)                   2.14056
time/epoch (s)                      2.67665
time/total (s)                    454.27
Epoch                             167
-----------------------------  ---------------
2019-04-22 21:45:38.071783 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              84700
trainer/QF1 Loss                    0.0248094
trainer/QF2 Loss                    0.0197391
trainer/Policy Loss                10.5205
trainer/Q1 Predictions Mean        -8.95116
trainer/Q1 Predictions Std          6.56344
trainer/Q1 Predictions Max         -6.33467
trainer/Q1 Predictions Min        -49.1854
trainer/Q2 Predictions Mean        -8.94974
trainer/Q2 Predictions Std          6.59989
trainer/Q2 Predictions Max         -6.27575
trainer/Q2 Predictions Min        -49.5653
trainer/Q Targets Mean             -8.98983
trainer/Q Targets Std               6.63778
trainer/Q Targets Max              -6.15115
trainer/Q Targets Min             -50.0191
trainer/Log Pis Mean                2.05336
trainer/Log Pis Std                 1.46441
trainer/Log Pis Max                 8.3752
trainer/Log Pis Min                -3.2745
trainer/Policy mu Mean              0.0638472
trainer/Policy mu Std               0.713371
trainer/Policy mu Max               3.06494
trainer/Policy mu Min              -2.6896
trainer/Policy log std Mean        -2.08397
trainer/Policy log std Std          0.498982
trainer/Policy log std Max         -0.547611
trainer/Policy log std Min         -2.51263
trainer/Alpha                       0.0614004
trainer/Alpha Loss                  0.148873
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.324196
exploration/Rewards Std             1.07467
exploration/Rewards Max            -0.00179233
exploration/Rewards Min           -10.8183
exploration/Returns Mean          -32.4196
exploration/Returns Std            18.7386
exploration/Returns Max           -14.1303
exploration/Returns Min           -63.5431
exploration/Actions Mean           -0.0163455
exploration/Actions Std             0.240059
exploration/Actions Max             0.999685
exploration/Actions Min            -0.998257
exploration/Num Paths               5
exploration/Average Returns       -32.4196
evaluation/num steps total     253500
evaluation/num paths total       2535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.1864
evaluation/Rewards Std              0.900933
evaluation/Rewards Max             -0.00798007
evaluation/Rewards Min            -10.6775
evaluation/Returns Mean           -18.64
evaluation/Returns Std             15.8515
evaluation/Returns Max             -4.83056
evaluation/Returns Min            -48.8473
evaluation/Actions Mean            -0.0170996
evaluation/Actions Std              0.183883
evaluation/Actions Max              0.993008
evaluation/Actions Min             -0.997895
evaluation/Num Paths               15
evaluation/Average Returns        -18.64
time/data storing (s)               0.00328226
time/evaluation sampling (s)        0.35319
time/exploration sampling (s)       0.160482
time/logging (s)                    0.00590731
time/saving (s)                     0.00230589
time/training (s)                   2.21141
time/epoch (s)                      2.73658
time/total (s)                    457.011
Epoch                             168
-----------------------------  ---------------
2019-04-22 21:45:40.776438 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              85200
trainer/QF1 Loss                    0.706343
trainer/QF2 Loss                    0.701444
trainer/Policy Loss                 9.56162
trainer/Q1 Predictions Mean        -7.62025
trainer/Q1 Predictions Std          3.0383
trainer/Q1 Predictions Max         -5.90252
trainer/Q1 Predictions Min        -24.9781
trainer/Q2 Predictions Mean        -7.62352
trainer/Q2 Predictions Std          3.02315
trainer/Q2 Predictions Max         -5.91024
trainer/Q2 Predictions Min        -24.5429
trainer/Q Targets Mean             -7.73313
trainer/Q Targets Std               3.03333
trainer/Q Targets Max              -0.23929
trainer/Q Targets Min             -24.1967
trainer/Log Pis Mean                2.08598
trainer/Log Pis Std                 1.13264
trainer/Log Pis Max                 6.46675
trainer/Log Pis Min                -2.57277
trainer/Policy mu Mean             -0.0814276
trainer/Policy mu Std               0.622311
trainer/Policy mu Max               2.75775
trainer/Policy mu Min              -2.73187
trainer/Policy log std Mean        -2.17099
trainer/Policy log std Std          0.448024
trainer/Policy log std Max         -0.404339
trainer/Policy log std Min         -2.55206
trainer/Alpha                       0.0620077
trainer/Alpha Loss                  0.23909
exploration/num steps total     85200
exploration/num paths total       852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.209786
exploration/Rewards Std             0.481615
exploration/Rewards Max            -0.00328843
exploration/Rewards Min            -4.67602
exploration/Returns Mean          -20.9786
exploration/Returns Std             5.74913
exploration/Returns Max           -11.3864
exploration/Returns Min           -28.2216
exploration/Actions Mean            0.00341779
exploration/Actions Std             0.208636
exploration/Actions Max             0.996575
exploration/Actions Min            -0.996478
exploration/Num Paths               5
exploration/Average Returns       -20.9786
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.175463
evaluation/Rewards Std              0.784518
evaluation/Rewards Max             -0.0214155
evaluation/Rewards Min             -8.64556
evaluation/Returns Mean           -17.5463
evaluation/Returns Std             11.6818
evaluation/Returns Max             -4.05446
evaluation/Returns Min            -37.2027
evaluation/Actions Mean            -0.00638767
evaluation/Actions Std              0.177033
evaluation/Actions Max              0.995344
evaluation/Actions Min             -0.995944
evaluation/Num Paths               15
evaluation/Average Returns        -17.5463
time/data storing (s)               0.00323466
time/evaluation sampling (s)        0.369094
time/exploration sampling (s)       0.16577
time/logging (s)                    0.00530288
time/saving (s)                     0.00230525
time/training (s)                   2.14957
time/epoch (s)                      2.69528
time/total (s)                    459.711
Epoch                             169
-----------------------------  ---------------
2019-04-22 21:45:43.458331 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              85700
trainer/QF1 Loss                    0.695194
trainer/QF2 Loss                    0.68647
trainer/Policy Loss                10.0969
trainer/Q1 Predictions Mean        -8.31326
trainer/Q1 Predictions Std          5.73616
trainer/Q1 Predictions Max         -6.21688
trainer/Q1 Predictions Min        -46.6287
trainer/Q2 Predictions Mean        -8.32904
trainer/Q2 Predictions Std          5.70061
trainer/Q2 Predictions Max         -6.28617
trainer/Q2 Predictions Min        -46.8261
trainer/Q Targets Mean             -8.30826
trainer/Q Targets Std               5.95029
trainer/Q Targets Max              -0.303643
trainer/Q Targets Min             -48.8719
trainer/Log Pis Mean                2.03311
trainer/Log Pis Std                 1.19409
trainer/Log Pis Max                 6.70616
trainer/Log Pis Min                -2.24458
trainer/Policy mu Mean              0.0489361
trainer/Policy mu Std               0.631711
trainer/Policy mu Max               3.08562
trainer/Policy mu Min              -3.53841
trainer/Policy log std Mean        -2.14013
trainer/Policy log std Std          0.495542
trainer/Policy log std Max         -0.141576
trainer/Policy log std Min         -2.54466
trainer/Alpha                       0.061701
trainer/Alpha Loss                  0.0922404
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.279538
exploration/Rewards Std             0.797096
exploration/Rewards Max            -0.0135174
exploration/Rewards Min            -7.14335
exploration/Returns Mean          -27.9538
exploration/Returns Std            10.8754
exploration/Returns Max           -13.5446
exploration/Returns Min           -37.8215
exploration/Actions Mean            0.0113828
exploration/Actions Std             0.228481
exploration/Actions Max             0.999067
exploration/Actions Min            -0.999529
exploration/Num Paths               5
exploration/Average Returns       -27.9538
evaluation/num steps total     256500
evaluation/num paths total       2565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.210735
evaluation/Rewards Std              0.930023
evaluation/Rewards Max             -0.00788503
evaluation/Rewards Min             -8.17076
evaluation/Returns Mean           -21.0735
evaluation/Returns Std              9.79301
evaluation/Returns Max             -3.33716
evaluation/Returns Min            -38.3396
evaluation/Actions Mean             0.00881071
evaluation/Actions Std              0.204732
evaluation/Actions Max              0.995978
evaluation/Actions Min             -0.994757
evaluation/Num Paths               15
evaluation/Average Returns        -21.0735
time/data storing (s)               0.00306784
time/evaluation sampling (s)        0.366691
time/exploration sampling (s)       0.162172
time/logging (s)                    0.00496996
time/saving (s)                     0.00989769
time/training (s)                   2.1272
time/epoch (s)                      2.674
time/total (s)                    462.39
Epoch                             170
-----------------------------  ---------------
2019-04-22 21:45:46.152611 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              86200
trainer/QF1 Loss                    0.426044
trainer/QF2 Loss                    0.422894
trainer/Policy Loss                10.3047
trainer/Q1 Predictions Mean        -8.67325
trainer/Q1 Predictions Std          6.95856
trainer/Q1 Predictions Max         -6.00265
trainer/Q1 Predictions Min        -55.6746
trainer/Q2 Predictions Mean        -8.67092
trainer/Q2 Predictions Std          6.9447
trainer/Q2 Predictions Max         -6.00305
trainer/Q2 Predictions Min        -55.6383
trainer/Q Targets Mean             -8.69182
trainer/Q Targets Std               7.10433
trainer/Q Targets Max              -0.271529
trainer/Q Targets Min             -57.4004
trainer/Log Pis Mean                1.88136
trainer/Log Pis Std                 1.29492
trainer/Log Pis Max                 6.6563
trainer/Log Pis Min                -1.45991
trainer/Policy mu Mean              0.0120247
trainer/Policy mu Std               0.679927
trainer/Policy mu Max               3.08497
trainer/Policy mu Min              -3.03446
trainer/Policy log std Mean        -2.09232
trainer/Policy log std Std          0.477159
trainer/Policy log std Max         -0.450143
trainer/Policy log std Min         -2.52537
trainer/Alpha                       0.062073
trainer/Alpha Loss                 -0.329748
exploration/num steps total     86200
exploration/num paths total       862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.163184
exploration/Rewards Std             0.272565
exploration/Rewards Max            -0.00538004
exploration/Rewards Min            -4.04354
exploration/Returns Mean          -16.3184
exploration/Returns Std             3.53924
exploration/Returns Max           -13.2964
exploration/Returns Min           -22.4465
exploration/Actions Mean            0.00352934
exploration/Actions Std             0.183538
exploration/Actions Max             0.999132
exploration/Actions Min            -0.984141
exploration/Num Paths               5
exploration/Average Returns       -16.3184
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.172301
evaluation/Rewards Std              0.85948
evaluation/Rewards Max             -0.00119411
evaluation/Rewards Min             -9.73029
evaluation/Returns Mean           -17.2301
evaluation/Returns Std             16.0398
evaluation/Returns Max             -0.622775
evaluation/Returns Min            -56.8248
evaluation/Actions Mean             0.00157161
evaluation/Actions Std              0.176468
evaluation/Actions Max              0.998425
evaluation/Actions Min             -0.994497
evaluation/Num Paths               15
evaluation/Average Returns        -17.2301
time/data storing (s)               0.00451819
time/evaluation sampling (s)        0.350796
time/exploration sampling (s)       0.195682
time/logging (s)                    0.00486781
time/saving (s)                     0.00227583
time/training (s)                   2.12814
time/epoch (s)                      2.68628
time/total (s)                    465.081
Epoch                             171
-----------------------------  ---------------
2019-04-22 21:45:48.973703 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                    0.67089
trainer/QF2 Loss                    0.6772
trainer/Policy Loss                10.1274
trainer/Q1 Predictions Mean        -8.35726
trainer/Q1 Predictions Std          5.50539
trainer/Q1 Predictions Max         -6.51625
trainer/Q1 Predictions Min        -46.8913
trainer/Q2 Predictions Mean        -8.36276
trainer/Q2 Predictions Std          5.49931
trainer/Q2 Predictions Max         -6.48866
trainer/Q2 Predictions Min        -47.0266
trainer/Q Targets Mean             -8.17199
trainer/Q Targets Std               5.6283
trainer/Q Targets Max              -0.190324
trainer/Q Targets Min             -47.819
trainer/Log Pis Mean                1.97762
trainer/Log Pis Std                 1.07592
trainer/Log Pis Max                 5.41918
trainer/Log Pis Min                -2.51885
trainer/Policy mu Mean              0.0168708
trainer/Policy mu Std               0.617915
trainer/Policy mu Max               3.04629
trainer/Policy mu Min              -3.11819
trainer/Policy log std Mean        -2.13538
trainer/Policy log std Std          0.450969
trainer/Policy log std Max         -0.470919
trainer/Policy log std Min         -2.53176
trainer/Alpha                       0.0623016
trainer/Alpha Loss                 -0.0621203
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354207
exploration/Rewards Std             1.12254
exploration/Rewards Max            -0.00546173
exploration/Rewards Min           -10.5056
exploration/Returns Mean          -35.4207
exploration/Returns Std            19.5246
exploration/Returns Max           -11.0104
exploration/Returns Min           -69.4479
exploration/Actions Mean            0.0252914
exploration/Actions Std             0.238685
exploration/Actions Max             0.999646
exploration/Actions Min            -0.994867
exploration/Num Paths               5
exploration/Average Returns       -35.4207
evaluation/num steps total     259500
evaluation/num paths total       2595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.253796
evaluation/Rewards Std              1.07615
evaluation/Rewards Max             -0.0285531
evaluation/Rewards Min            -11.6933
evaluation/Returns Mean           -25.3796
evaluation/Returns Std             15.3321
evaluation/Returns Max             -3.1103
evaluation/Returns Min            -59.8819
evaluation/Actions Mean            -0.00507566
evaluation/Actions Std              0.204719
evaluation/Actions Max              0.99861
evaluation/Actions Min             -0.998134
evaluation/Num Paths               15
evaluation/Average Returns        -25.3796
time/data storing (s)               0.00316571
time/evaluation sampling (s)        0.353389
time/exploration sampling (s)       0.15896
time/logging (s)                    0.0050904
time/saving (s)                     0.00225756
time/training (s)                   2.2906
time/epoch (s)                      2.81346
time/total (s)                    467.899
Epoch                             172
-----------------------------  ---------------
2019-04-22 21:45:51.793315 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              87200
trainer/QF1 Loss                    0.281064
trainer/QF2 Loss                    0.192418
trainer/Policy Loss                10.962
trainer/Q1 Predictions Mean        -9.1268
trainer/Q1 Predictions Std          8.18595
trainer/Q1 Predictions Max         -6.12782
trainer/Q1 Predictions Min        -56.0774
trainer/Q2 Predictions Mean        -9.09973
trainer/Q2 Predictions Std          8.14228
trainer/Q2 Predictions Max         -6.12526
trainer/Q2 Predictions Min        -56.0252
trainer/Q Targets Mean             -9.16571
trainer/Q Targets Std               7.94739
trainer/Q Targets Max              -6.1734
trainer/Q Targets Min             -56.6425
trainer/Log Pis Mean                2.21894
trainer/Log Pis Std                 1.41198
trainer/Log Pis Max                 8.4164
trainer/Log Pis Min                -2.05999
trainer/Policy mu Mean              0.0309584
trainer/Policy mu Std               0.846728
trainer/Policy mu Max               3.43103
trainer/Policy mu Min              -3.06681
trainer/Policy log std Mean        -2.07168
trainer/Policy log std Std          0.5862
trainer/Policy log std Max         -0.352953
trainer/Policy log std Min         -2.57674
trainer/Alpha                       0.0622911
trainer/Alpha Loss                  0.607766
exploration/num steps total     87200
exploration/num paths total       872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.340335
exploration/Rewards Std             1.05345
exploration/Rewards Max            -0.00822791
exploration/Rewards Min            -9.55444
exploration/Returns Mean          -34.0335
exploration/Returns Std            12.4502
exploration/Returns Max           -20.0266
exploration/Returns Min           -49.3683
exploration/Actions Mean           -0.0158033
exploration/Actions Std             0.245329
exploration/Actions Max             0.997568
exploration/Actions Min            -0.997457
exploration/Num Paths               5
exploration/Average Returns       -34.0335
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.181097
evaluation/Rewards Std              0.85844
evaluation/Rewards Max             -0.00367058
evaluation/Rewards Min             -9.55376
evaluation/Returns Mean           -18.1097
evaluation/Returns Std             13.5648
evaluation/Returns Max             -2.59515
evaluation/Returns Min            -47.7744
evaluation/Actions Mean             0.00367227
evaluation/Actions Std              0.183419
evaluation/Actions Max              0.996441
evaluation/Actions Min             -0.993449
evaluation/Num Paths               15
evaluation/Average Returns        -18.1097
time/data storing (s)               0.00359845
time/evaluation sampling (s)        0.407668
time/exploration sampling (s)       0.179402
time/logging (s)                    0.00581012
time/saving (s)                     0.0025671
time/training (s)                   2.21293
time/epoch (s)                      2.81198
time/total (s)                    470.716
Epoch                             173
-----------------------------  ---------------
2019-04-22 21:45:54.499773 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              87700
trainer/QF1 Loss                    0.76219
trainer/QF2 Loss                    0.759601
trainer/Policy Loss                 9.56982
trainer/Q1 Predictions Mean        -7.71647
trainer/Q1 Predictions Std          4.56875
trainer/Q1 Predictions Max         -5.99044
trainer/Q1 Predictions Min        -47.1175
trainer/Q2 Predictions Mean        -7.72808
trainer/Q2 Predictions Std          4.53066
trainer/Q2 Predictions Max         -6.06364
trainer/Q2 Predictions Min        -46.9718
trainer/Q Targets Mean             -7.71057
trainer/Q Targets Std               4.64422
trainer/Q Targets Max              -0.151008
trainer/Q Targets Min             -46.9926
trainer/Log Pis Mean                2.11082
trainer/Log Pis Std                 1.26798
trainer/Log Pis Max                 8.31355
trainer/Log Pis Min                -2.4852
trainer/Policy mu Mean             -0.0309107
trainer/Policy mu Std               0.569872
trainer/Policy mu Max               2.87909
trainer/Policy mu Min              -2.60312
trainer/Policy log std Mean        -2.25184
trainer/Policy log std Std          0.392023
trainer/Policy log std Max         -0.655582
trainer/Policy log std Min         -2.54743
trainer/Alpha                       0.0629896
trainer/Alpha Loss                  0.306402
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.284084
exploration/Rewards Std             0.798917
exploration/Rewards Max            -0.00451656
exploration/Rewards Min            -7.84676
exploration/Returns Mean          -28.4084
exploration/Returns Std             9.71503
exploration/Returns Max           -17.1763
exploration/Returns Min           -43.8508
exploration/Actions Mean           -0.0185194
exploration/Actions Std             0.220941
exploration/Actions Max             0.980728
exploration/Actions Min            -0.998932
exploration/Num Paths               5
exploration/Average Returns       -28.4084
evaluation/num steps total     262500
evaluation/num paths total       2625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22529
evaluation/Rewards Std              0.912904
evaluation/Rewards Max             -0.0160533
evaluation/Rewards Min             -8.52715
evaluation/Returns Mean           -22.529
evaluation/Returns Std             11.9511
evaluation/Returns Max             -3.41838
evaluation/Returns Min            -39.9205
evaluation/Actions Mean            -0.0181187
evaluation/Actions Std              0.194431
evaluation/Actions Max              0.995537
evaluation/Actions Min             -0.994644
evaluation/Num Paths               15
evaluation/Average Returns        -22.529
time/data storing (s)               0.00328634
time/evaluation sampling (s)        0.386942
time/exploration sampling (s)       0.177085
time/logging (s)                    0.00501212
time/saving (s)                     0.00211699
time/training (s)                   2.12292
time/epoch (s)                      2.69736
time/total (s)                    473.419
Epoch                             174
-----------------------------  ---------------
2019-04-22 21:45:57.238091 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              88200
trainer/QF1 Loss                   12.3526
trainer/QF2 Loss                   12.1398
trainer/Policy Loss                10.5563
trainer/Q1 Predictions Mean        -8.55457
trainer/Q1 Predictions Std          5.5911
trainer/Q1 Predictions Max         -6.18757
trainer/Q1 Predictions Min        -41.7062
trainer/Q2 Predictions Mean        -8.55527
trainer/Q2 Predictions Std          5.54723
trainer/Q2 Predictions Max         -6.29245
trainer/Q2 Predictions Min        -41.3576
trainer/Q Targets Mean             -8.07372
trainer/Q Targets Std               4.47366
trainer/Q Targets Max              -0.0421681
trainer/Q Targets Min             -37.7054
trainer/Log Pis Mean                2.13926
trainer/Log Pis Std                 1.56725
trainer/Log Pis Max                 8.01685
trainer/Log Pis Min                -3.85564
trainer/Policy mu Mean              0.0414955
trainer/Policy mu Std               0.755534
trainer/Policy mu Max               3.04091
trainer/Policy mu Min              -2.71462
trainer/Policy log std Mean        -2.1651
trainer/Policy log std Std          0.530074
trainer/Policy log std Max         -0.532026
trainer/Policy log std Min         -2.58315
trainer/Alpha                       0.061622
trainer/Alpha Loss                  0.388111
exploration/num steps total     88200
exploration/num paths total       882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.190599
exploration/Rewards Std             0.565141
exploration/Rewards Max            -0.00347744
exploration/Rewards Min            -7.35499
exploration/Returns Mean          -19.0599
exploration/Returns Std             8.99202
exploration/Returns Max           -12.8027
exploration/Returns Min           -36.7012
exploration/Actions Mean           -0.0227377
exploration/Actions Std             0.187371
exploration/Actions Max             0.927076
exploration/Actions Min            -0.993665
exploration/Num Paths               5
exploration/Average Returns       -19.0599
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.265319
evaluation/Rewards Std              1.06372
evaluation/Rewards Max             -0.00628941
evaluation/Rewards Min            -11.1788
evaluation/Returns Mean           -26.5319
evaluation/Returns Std             13.8474
evaluation/Returns Max             -7.10493
evaluation/Returns Min            -54.0853
evaluation/Actions Mean             0.00731108
evaluation/Actions Std              0.21074
evaluation/Actions Max              0.997743
evaluation/Actions Min             -0.99626
evaluation/Num Paths               15
evaluation/Average Returns        -26.5319
time/data storing (s)               0.0032196
time/evaluation sampling (s)        0.372929
time/exploration sampling (s)       0.169398
time/logging (s)                    0.00543127
time/saving (s)                     0.00216657
time/training (s)                   2.17742
time/epoch (s)                      2.73056
time/total (s)                    476.154
Epoch                             175
-----------------------------  ---------------
2019-04-22 21:45:59.934290 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 176 finished
-----------------------------  ----------------
replay_buffer/size              88700
trainer/QF1 Loss                    0.107806
trainer/QF2 Loss                    0.0765016
trainer/Policy Loss                10.3982
trainer/Q1 Predictions Mean        -8.72206
trainer/Q1 Predictions Std          5.68848
trainer/Q1 Predictions Max         -6.13623
trainer/Q1 Predictions Min        -44.326
trainer/Q2 Predictions Mean        -8.7587
trainer/Q2 Predictions Std          5.64636
trainer/Q2 Predictions Max         -6.17197
trainer/Q2 Predictions Min        -43.9014
trainer/Q Targets Mean             -8.74749
trainer/Q Targets Std               5.62872
trainer/Q Targets Max              -6.15279
trainer/Q Targets Min             -44.1232
trainer/Log Pis Mean                1.90963
trainer/Log Pis Std                 1.50887
trainer/Log Pis Max                 8.63218
trainer/Log Pis Min                -1.53261
trainer/Policy mu Mean              0.0332235
trainer/Policy mu Std               0.768679
trainer/Policy mu Max               2.81832
trainer/Policy mu Min              -3.25475
trainer/Policy log std Mean        -1.9948
trainer/Policy log std Std          0.536805
trainer/Policy log std Max         -0.200415
trainer/Policy log std Min         -2.46911
trainer/Alpha                       0.0639274
trainer/Alpha Loss                 -0.248514
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.463136
exploration/Rewards Std             1.30245
exploration/Rewards Max            -0.000846095
exploration/Rewards Min            -9.41204
exploration/Returns Mean          -46.3136
exploration/Returns Std            15.5446
exploration/Returns Max           -17.8506
exploration/Returns Min           -64.2303
exploration/Actions Mean            0.0135127
exploration/Actions Std             0.260832
exploration/Actions Max             0.999242
exploration/Actions Min            -0.998885
exploration/Num Paths               5
exploration/Average Returns       -46.3136
evaluation/num steps total     265500
evaluation/num paths total       2655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.327691
evaluation/Rewards Std              1.18421
evaluation/Rewards Max             -0.0222307
evaluation/Rewards Min            -10.4454
evaluation/Returns Mean           -32.7691
evaluation/Returns Std             16.2931
evaluation/Returns Max             -8.39685
evaluation/Returns Min            -56.6166
evaluation/Actions Mean            -0.000471407
evaluation/Actions Std              0.209677
evaluation/Actions Max              0.997944
evaluation/Actions Min             -0.995929
evaluation/Num Paths               15
evaluation/Average Returns        -32.7691
time/data storing (s)               0.00393978
time/evaluation sampling (s)        0.364841
time/exploration sampling (s)       0.163877
time/logging (s)                    0.00498333
time/saving (s)                     0.00208982
time/training (s)                   2.14629
time/epoch (s)                      2.68602
time/total (s)                    478.846
Epoch                             176
-----------------------------  ----------------
2019-04-22 21:46:02.619146 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size              89200
trainer/QF1 Loss                    0.636012
trainer/QF2 Loss                    0.598215
trainer/Policy Loss                10.2927
trainer/Q1 Predictions Mean        -8.59422
trainer/Q1 Predictions Std          7.52487
trainer/Q1 Predictions Max         -6.11459
trainer/Q1 Predictions Min        -70.9547
trainer/Q2 Predictions Mean        -8.56016
trainer/Q2 Predictions Std          7.46859
trainer/Q2 Predictions Max         -6.09512
trainer/Q2 Predictions Min        -70.4822
trainer/Q Targets Mean             -8.52601
trainer/Q Targets Std               7.16332
trainer/Q Targets Max              -0.435724
trainer/Q Targets Min             -66.0706
trainer/Log Pis Mean                2.01792
trainer/Log Pis Std                 1.49812
trainer/Log Pis Max                 8.47467
trainer/Log Pis Min                -1.51376
trainer/Policy mu Mean              0.0559333
trainer/Policy mu Std               0.72632
trainer/Policy mu Max               3.16891
trainer/Policy mu Min              -3.3209
trainer/Policy log std Mean        -2.14582
trainer/Policy log std Std          0.521872
trainer/Policy log std Max         -0.47121
trainer/Policy log std Min         -2.58374
trainer/Alpha                       0.0614423
trainer/Alpha Loss                  0.049989
exploration/num steps total     89200
exploration/num paths total       892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281074
exploration/Rewards Std             0.800384
exploration/Rewards Max            -0.00335708
exploration/Rewards Min            -8.02479
exploration/Returns Mean          -28.1074
exploration/Returns Std             9.42806
exploration/Returns Max           -14.6316
exploration/Returns Min           -42.3422
exploration/Actions Mean           -0.00952764
exploration/Actions Std             0.235607
exploration/Actions Max             0.997492
exploration/Actions Min            -0.999082
exploration/Num Paths               5
exploration/Average Returns       -28.1074
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.276184
evaluation/Rewards Std              1.09136
evaluation/Rewards Max             -0.0418275
evaluation/Rewards Min            -10.3099
evaluation/Returns Mean           -27.6184
evaluation/Returns Std             17.3249
evaluation/Returns Max             -5.69945
evaluation/Returns Min            -59.289
evaluation/Actions Mean            -0.0096688
evaluation/Actions Std              0.199795
evaluation/Actions Max              0.998599
evaluation/Actions Min             -0.997537
evaluation/Num Paths               15
evaluation/Average Returns        -27.6184
time/data storing (s)               0.00314833
time/evaluation sampling (s)        0.360338
time/exploration sampling (s)       0.158608
time/logging (s)                    0.00459697
time/saving (s)                     0.00201127
time/training (s)                   2.14798
time/epoch (s)                      2.67668
time/total (s)                    481.528
Epoch                             177
-----------------------------  ---------------
2019-04-22 21:46:05.265332 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              89700
trainer/QF1 Loss                    0.0514902
trainer/QF2 Loss                    0.0515436
trainer/Policy Loss                10.5622
trainer/Q1 Predictions Mean        -8.65065
trainer/Q1 Predictions Std          6.17537
trainer/Q1 Predictions Max         -6.09158
trainer/Q1 Predictions Min        -44.5444
trainer/Q2 Predictions Mean        -8.63662
trainer/Q2 Predictions Std          6.17696
trainer/Q2 Predictions Max         -6.02882
trainer/Q2 Predictions Min        -44.4394
trainer/Q Targets Mean             -8.77684
trainer/Q Targets Std               6.24285
trainer/Q Targets Max              -6.10912
trainer/Q Targets Min             -45.0202
trainer/Log Pis Mean                2.19311
trainer/Log Pis Std                 1.35634
trainer/Log Pis Max                 7.77726
trainer/Log Pis Min                -2.32267
trainer/Policy mu Mean             -0.054915
trainer/Policy mu Std               0.6704
trainer/Policy mu Max               3.13286
trainer/Policy mu Min              -3.16997
trainer/Policy log std Mean        -2.14151
trainer/Policy log std Std          0.478286
trainer/Policy log std Max         -0.406563
trainer/Policy log std Min         -2.60663
trainer/Alpha                       0.0622251
trainer/Alpha Loss                  0.536279
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.361744
exploration/Rewards Std             1.07806
exploration/Rewards Max            -0.00516628
exploration/Rewards Min           -10.1291
exploration/Returns Mean          -36.1744
exploration/Returns Std            13.9538
exploration/Returns Max           -22.9263
exploration/Returns Min           -53.1929
exploration/Actions Mean            0.00322935
exploration/Actions Std             0.258793
exploration/Actions Max             0.996934
exploration/Actions Min            -0.999299
exploration/Num Paths               5
exploration/Average Returns       -36.1744
evaluation/num steps total     268500
evaluation/num paths total       2685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224466
evaluation/Rewards Std              1.02578
evaluation/Rewards Max             -0.00223426
evaluation/Rewards Min            -10.1569
evaluation/Returns Mean           -22.4466
evaluation/Returns Std             18.3861
evaluation/Returns Max             -1.76073
evaluation/Returns Min            -58.4755
evaluation/Actions Mean             0.014463
evaluation/Actions Std              0.177386
evaluation/Actions Max              0.998948
evaluation/Actions Min             -0.99231
evaluation/Num Paths               15
evaluation/Average Returns        -22.4466
time/data storing (s)               0.00300879
time/evaluation sampling (s)        0.345755
time/exploration sampling (s)       0.157394
time/logging (s)                    0.00524217
time/saving (s)                     0.00201897
time/training (s)                   2.12575
time/epoch (s)                      2.63916
time/total (s)                    484.172
Epoch                             178
-----------------------------  ---------------
2019-04-22 21:46:07.984340 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              90200
trainer/QF1 Loss                    0.895805
trainer/QF2 Loss                    0.905747
trainer/Policy Loss                10.9166
trainer/Q1 Predictions Mean        -9.30502
trainer/Q1 Predictions Std          8.63988
trainer/Q1 Predictions Max         -6.17364
trainer/Q1 Predictions Min        -63.1345
trainer/Q2 Predictions Mean        -9.32332
trainer/Q2 Predictions Std          8.66954
trainer/Q2 Predictions Max         -6.18835
trainer/Q2 Predictions Min        -63.1328
trainer/Q Targets Mean             -9.23438
trainer/Q Targets Std               8.8075
trainer/Q Targets Max              -0.16543
trainer/Q Targets Min             -65.159
trainer/Log Pis Mean                1.93793
trainer/Log Pis Std                 1.48316
trainer/Log Pis Max                 6.0111
trainer/Log Pis Min                -5.07817
trainer/Policy mu Mean              0.0736289
trainer/Policy mu Std               0.835435
trainer/Policy mu Max               3.46443
trainer/Policy mu Min              -3.42979
trainer/Policy log std Mean        -2.04239
trainer/Policy log std Std          0.611438
trainer/Policy log std Max         -0.101682
trainer/Policy log std Min         -2.47914
trainer/Alpha                       0.0622382
trainer/Alpha Loss                 -0.172365
exploration/num steps total     90200
exploration/num paths total       902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.172625
exploration/Rewards Std             0.360073
exploration/Rewards Max            -0.0049758
exploration/Rewards Min            -4.42453
exploration/Returns Mean          -17.2625
exploration/Returns Std             4.22657
exploration/Returns Max           -12.976
exploration/Returns Min           -24.0059
exploration/Actions Mean            0.0037427
exploration/Actions Std             0.186758
exploration/Actions Max             0.998726
exploration/Actions Min            -0.989963
exploration/Num Paths               5
exploration/Average Returns       -17.2625
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261307
evaluation/Rewards Std              1.10626
evaluation/Rewards Max             -0.0164826
evaluation/Rewards Min            -10.5225
evaluation/Returns Mean           -26.1307
evaluation/Returns Std             15.2171
evaluation/Returns Max             -5.65486
evaluation/Returns Min            -53.8967
evaluation/Actions Mean            -0.0122137
evaluation/Actions Std              0.208448
evaluation/Actions Max              0.997791
evaluation/Actions Min             -0.997195
evaluation/Num Paths               15
evaluation/Average Returns        -26.1307
time/data storing (s)               0.00312645
time/evaluation sampling (s)        0.377336
time/exploration sampling (s)       0.173904
time/logging (s)                    0.0057595
time/saving (s)                     0.00220205
time/training (s)                   2.14947
time/epoch (s)                      2.7118
time/total (s)                    486.888
Epoch                             179
-----------------------------  ---------------
2019-04-22 21:46:10.662591 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              90700
trainer/QF1 Loss                    0.0278727
trainer/QF2 Loss                    0.0266076
trainer/Policy Loss                 9.48775
trainer/Q1 Predictions Mean        -7.53226
trainer/Q1 Predictions Std          3.16848
trainer/Q1 Predictions Max         -6.13371
trainer/Q1 Predictions Min        -31.5195
trainer/Q2 Predictions Mean        -7.54213
trainer/Q2 Predictions Std          3.21378
trainer/Q2 Predictions Max         -6.13739
trainer/Q2 Predictions Min        -31.6829
trainer/Q Targets Mean             -7.57883
trainer/Q Targets Std               3.15466
trainer/Q Targets Max              -6.12708
trainer/Q Targets Min             -30.8278
trainer/Log Pis Mean                2.09954
trainer/Log Pis Std                 0.910281
trainer/Log Pis Max                 3.47394
trainer/Log Pis Min                -1.74829
trainer/Policy mu Mean             -0.0224842
trainer/Policy mu Std               0.475008
trainer/Policy mu Max               2.77512
trainer/Policy mu Min              -2.92559
trainer/Policy log std Mean        -2.24949
trainer/Policy log std Std          0.376088
trainer/Policy log std Max         -0.662237
trainer/Policy log std Min         -2.58203
trainer/Alpha                       0.0634734
trainer/Alpha Loss                  0.274452
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.437986
exploration/Rewards Std             1.37299
exploration/Rewards Max            -0.00239341
exploration/Rewards Min           -11.1196
exploration/Returns Mean          -43.7986
exploration/Returns Std            17.3236
exploration/Returns Max           -26.2361
exploration/Returns Min           -68.8488
exploration/Actions Mean           -0.00445224
exploration/Actions Std             0.258075
exploration/Actions Max             0.998886
exploration/Actions Min            -0.999758
exploration/Num Paths               5
exploration/Average Returns       -43.7986
evaluation/num steps total     271500
evaluation/num paths total       2715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.208407
evaluation/Rewards Std              0.993382
evaluation/Rewards Max             -0.0019012
evaluation/Rewards Min            -10.3752
evaluation/Returns Mean           -20.8407
evaluation/Returns Std             16.9901
evaluation/Returns Max             -2.25812
evaluation/Returns Min            -52.4052
evaluation/Actions Mean            -0.0204305
evaluation/Actions Std              0.18877
evaluation/Actions Max              0.99797
evaluation/Actions Min             -0.99736
evaluation/Num Paths               15
evaluation/Average Returns        -20.8407
time/data storing (s)               0.00334059
time/evaluation sampling (s)        0.378747
time/exploration sampling (s)       0.165854
time/logging (s)                    0.00462947
time/saving (s)                     0.00206842
time/training (s)                   2.1131
time/epoch (s)                      2.66774
time/total (s)                    489.561
Epoch                             180
-----------------------------  ---------------
2019-04-22 21:46:13.331140 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              91200
trainer/QF1 Loss                    0.0262329
trainer/QF2 Loss                    0.0174063
trainer/Policy Loss                 8.94743
trainer/Q1 Predictions Mean        -7.41108
trainer/Q1 Predictions Std          1.98817
trainer/Q1 Predictions Max         -6.10611
trainer/Q1 Predictions Min        -21.8203
trainer/Q2 Predictions Mean        -7.43488
trainer/Q2 Predictions Std          2.01249
trainer/Q2 Predictions Max         -6.10753
trainer/Q2 Predictions Min        -21.9811
trainer/Q Targets Mean             -7.45768
trainer/Q Targets Std               2.01929
trainer/Q Targets Max              -6.14061
trainer/Q Targets Min             -21.9931
trainer/Log Pis Mean                1.75952
trainer/Log Pis Std                 1.14925
trainer/Log Pis Max                 4.76315
trainer/Log Pis Min                -2.83297
trainer/Policy mu Mean              0.0273422
trainer/Policy mu Std               0.494114
trainer/Policy mu Max               2.70017
trainer/Policy mu Min              -2.35373
trainer/Policy log std Mean        -2.15758
trainer/Policy log std Std          0.382792
trainer/Policy log std Max         -0.53739
trainer/Policy log std Min         -2.43237
trainer/Alpha                       0.0640793
trainer/Alpha Loss                 -0.660692
exploration/num steps total     91200
exploration/num paths total       912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.357217
exploration/Rewards Std             0.999028
exploration/Rewards Max            -0.00299134
exploration/Rewards Min            -7.92883
exploration/Returns Mean          -35.7217
exploration/Returns Std             9.52605
exploration/Returns Max           -25.299
exploration/Returns Min           -50.8133
exploration/Actions Mean           -0.0158957
exploration/Actions Std             0.246181
exploration/Actions Max             0.997317
exploration/Actions Min            -0.997534
exploration/Num Paths               5
exploration/Average Returns       -35.7217
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.28524
evaluation/Rewards Std              1.13612
evaluation/Rewards Max             -0.00895691
evaluation/Rewards Min            -10.4208
evaluation/Returns Mean           -28.524
evaluation/Returns Std             14.0309
evaluation/Returns Max             -3.32618
evaluation/Returns Min            -51.8636
evaluation/Actions Mean            -0.0086716
evaluation/Actions Std              0.214424
evaluation/Actions Max              0.997286
evaluation/Actions Min             -0.997429
evaluation/Num Paths               15
evaluation/Average Returns        -28.524
time/data storing (s)               0.00333916
time/evaluation sampling (s)        0.355419
time/exploration sampling (s)       0.162184
time/logging (s)                    0.00498549
time/saving (s)                     0.00248191
time/training (s)                   2.13243
time/epoch (s)                      2.66084
time/total (s)                    492.227
Epoch                             181
-----------------------------  ---------------
2019-04-22 21:46:16.064364 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              91700
trainer/QF1 Loss                    0.607272
trainer/QF2 Loss                    0.621665
trainer/Policy Loss                 9.05536
trainer/Q1 Predictions Mean        -7.44587
trainer/Q1 Predictions Std          1.8407
trainer/Q1 Predictions Max         -6.25943
trainer/Q1 Predictions Min        -17.5728
trainer/Q2 Predictions Mean        -7.44452
trainer/Q2 Predictions Std          1.81283
trainer/Q2 Predictions Max         -6.26945
trainer/Q2 Predictions Min        -17.5498
trainer/Q Targets Mean             -7.45188
trainer/Q Targets Std               2.03172
trainer/Q Targets Max              -0.215288
trainer/Q Targets Min             -17.9125
trainer/Log Pis Mean                1.84427
trainer/Log Pis Std                 0.910742
trainer/Log Pis Max                 5.49775
trainer/Log Pis Min                -0.842299
trainer/Policy mu Mean             -0.0176817
trainer/Policy mu Std               0.573312
trainer/Policy mu Max               2.42422
trainer/Policy mu Min              -2.69987
trainer/Policy log std Mean        -2.09286
trainer/Policy log std Std          0.419581
trainer/Policy log std Max         -0.449242
trainer/Policy log std Min         -2.48784
trainer/Alpha                       0.0628199
trainer/Alpha Loss                 -0.430956
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.212487
exploration/Rewards Std             0.342901
exploration/Rewards Max            -0.0184861
exploration/Rewards Min            -4.20939
exploration/Returns Mean          -21.2487
exploration/Returns Std             3.65829
exploration/Returns Max           -16.6688
exploration/Returns Min           -26.1026
exploration/Actions Mean            0.00153434
exploration/Actions Std             0.203284
exploration/Actions Max             0.982672
exploration/Actions Min            -0.997355
exploration/Num Paths               5
exploration/Average Returns       -21.2487
evaluation/num steps total     274500
evaluation/num paths total       2745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.201897
evaluation/Rewards Std              0.764159
evaluation/Rewards Max             -0.0400734
evaluation/Rewards Min             -7.94565
evaluation/Returns Mean           -20.1897
evaluation/Returns Std             11.3799
evaluation/Returns Max             -6.18646
evaluation/Returns Min            -39.1717
evaluation/Actions Mean             0.00416885
evaluation/Actions Std              0.188399
evaluation/Actions Max              0.995938
evaluation/Actions Min             -0.997068
evaluation/Num Paths               15
evaluation/Average Returns        -20.1897
time/data storing (s)               0.00321858
time/evaluation sampling (s)        0.364791
time/exploration sampling (s)       0.164542
time/logging (s)                    0.00517604
time/saving (s)                     0.00224331
time/training (s)                   2.18661
time/epoch (s)                      2.72658
time/total (s)                    494.958
Epoch                             182
-----------------------------  ---------------
2019-04-22 21:46:18.759098 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              92200
trainer/QF1 Loss                    0.395182
trainer/QF2 Loss                    0.393731
trainer/Policy Loss                 9.79964
trainer/Q1 Predictions Mean        -7.91854
trainer/Q1 Predictions Std          4.03848
trainer/Q1 Predictions Max         -6.04657
trainer/Q1 Predictions Min        -39.2083
trainer/Q2 Predictions Mean        -7.9069
trainer/Q2 Predictions Std          4.04782
trainer/Q2 Predictions Max         -6.03658
trainer/Q2 Predictions Min        -39.2821
trainer/Q Targets Mean             -7.92069
trainer/Q Targets Std               4.02003
trainer/Q Targets Max              -0.301895
trainer/Q Targets Min             -38.8495
trainer/Log Pis Mean                2.05258
trainer/Log Pis Std                 1.15257
trainer/Log Pis Max                 7.5405
trainer/Log Pis Min                -0.316643
trainer/Policy mu Mean             -0.082245
trainer/Policy mu Std               0.605146
trainer/Policy mu Max               2.75654
trainer/Policy mu Min              -3.03097
trainer/Policy log std Mean        -2.15126
trainer/Policy log std Std          0.444928
trainer/Policy log std Max         -0.516634
trainer/Policy log std Min         -2.52945
trainer/Alpha                       0.0630962
trainer/Alpha Loss                  0.145293
exploration/num steps total     92200
exploration/num paths total       922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.221056
exploration/Rewards Std             0.575537
exploration/Rewards Max            -0.0100956
exploration/Rewards Min            -6.73163
exploration/Returns Mean          -22.1056
exploration/Returns Std             8.30786
exploration/Returns Max           -13.6153
exploration/Returns Min           -37.1093
exploration/Actions Mean           -0.0110463
exploration/Actions Std             0.204312
exploration/Actions Max             0.99029
exploration/Actions Min            -0.999112
exploration/Num Paths               5
exploration/Average Returns       -22.1056
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.250777
evaluation/Rewards Std              0.998185
evaluation/Rewards Max             -0.0133976
evaluation/Rewards Min             -9.6258
evaluation/Returns Mean           -25.0777
evaluation/Returns Std             13.932
evaluation/Returns Max             -5.07268
evaluation/Returns Min            -52.7739
evaluation/Actions Mean             0.00246649
evaluation/Actions Std              0.194973
evaluation/Actions Max              0.998292
evaluation/Actions Min             -0.996418
evaluation/Num Paths               15
evaluation/Average Returns        -25.0777
time/data storing (s)               0.00322963
time/evaluation sampling (s)        0.361277
time/exploration sampling (s)       0.163841
time/logging (s)                    0.00458168
time/saving (s)                     0.00188548
time/training (s)                   2.15131
time/epoch (s)                      2.68612
time/total (s)                    497.649
Epoch                             183
-----------------------------  ---------------
2019-04-22 21:46:21.448727 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              92700
trainer/QF1 Loss                    0.0232769
trainer/QF2 Loss                    0.0268523
trainer/Policy Loss                 9.99604
trainer/Q1 Predictions Mean        -8.21051
trainer/Q1 Predictions Std          4.73816
trainer/Q1 Predictions Max         -6.01978
trainer/Q1 Predictions Min        -39.3607
trainer/Q2 Predictions Mean        -8.19977
trainer/Q2 Predictions Std          4.72657
trainer/Q2 Predictions Max         -5.97153
trainer/Q2 Predictions Min        -39.2709
trainer/Q Targets Mean             -8.2292
trainer/Q Targets Std               4.69623
trainer/Q Targets Max              -6.12873
trainer/Q Targets Min             -39.2123
trainer/Log Pis Mean                2.07835
trainer/Log Pis Std                 1.22887
trainer/Log Pis Max                 7.69836
trainer/Log Pis Min                -3.04653
trainer/Policy mu Mean             -0.0541384
trainer/Policy mu Std               0.67206
trainer/Policy mu Max               3.09213
trainer/Policy mu Min              -3.07017
trainer/Policy log std Mean        -2.14207
trainer/Policy log std Std          0.473039
trainer/Policy log std Max         -0.33447
trainer/Policy log std Min         -2.57625
trainer/Alpha                       0.064584
trainer/Alpha Loss                  0.214671
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.283217
exploration/Rewards Std             0.87016
exploration/Rewards Max            -0.00348195
exploration/Rewards Min            -9.16972
exploration/Returns Mean          -28.3217
exploration/Returns Std            15.3746
exploration/Returns Max           -17.1275
exploration/Returns Min           -58.3816
exploration/Actions Mean            0.0243148
exploration/Actions Std             0.2188
exploration/Actions Max             0.999829
exploration/Actions Min            -0.961938
exploration/Num Paths               5
exploration/Average Returns       -28.3217
evaluation/num steps total     277500
evaluation/num paths total       2775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.316287
evaluation/Rewards Std              1.21977
evaluation/Rewards Max             -0.0152723
evaluation/Rewards Min            -11.6298
evaluation/Returns Mean           -31.6287
evaluation/Returns Std             18.0784
evaluation/Returns Max             -5.82116
evaluation/Returns Min            -64.3526
evaluation/Actions Mean             0.00470561
evaluation/Actions Std              0.213608
evaluation/Actions Max              0.999041
evaluation/Actions Min             -0.996776
evaluation/Num Paths               15
evaluation/Average Returns        -31.6287
time/data storing (s)               0.00305807
time/evaluation sampling (s)        0.363326
time/exploration sampling (s)       0.16241
time/logging (s)                    0.0048536
time/saving (s)                     0.00182439
time/training (s)                   2.14611
time/epoch (s)                      2.68158
time/total (s)                    500.335
Epoch                             184
-----------------------------  ---------------
2019-04-22 21:46:24.088749 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              93200
trainer/QF1 Loss                    1.59791
trainer/QF2 Loss                    1.58525
trainer/Policy Loss                 9.62725
trainer/Q1 Predictions Mean        -7.76221
trainer/Q1 Predictions Std          3.34615
trainer/Q1 Predictions Max         -6.05864
trainer/Q1 Predictions Min        -35.5604
trainer/Q2 Predictions Mean        -7.76839
trainer/Q2 Predictions Std          3.33859
trainer/Q2 Predictions Max         -6.02338
trainer/Q2 Predictions Min        -35.4984
trainer/Q Targets Mean             -7.61491
trainer/Q Targets Std               3.48243
trainer/Q Targets Max              -0.0315501
trainer/Q Targets Min             -34.4733
trainer/Log Pis Mean                1.94032
trainer/Log Pis Std                 1.64961
trainer/Log Pis Max                 6.35677
trainer/Log Pis Min                -4.94749
trainer/Policy mu Mean             -0.0919123
trainer/Policy mu Std               0.688569
trainer/Policy mu Max               3.06078
trainer/Policy mu Min              -2.58686
trainer/Policy log std Mean        -2.10984
trainer/Policy log std Std          0.495547
trainer/Policy log std Max         -0.457954
trainer/Policy log std Min         -2.552
trainer/Alpha                       0.0649517
trainer/Alpha Loss                 -0.163165
exploration/num steps total     93200
exploration/num paths total       932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.35257
exploration/Rewards Std             1.09323
exploration/Rewards Max            -0.00295249
exploration/Rewards Min           -10.6339
exploration/Returns Mean          -35.257
exploration/Returns Std            17.202
exploration/Returns Max           -18.3957
exploration/Returns Min           -68.3552
exploration/Actions Mean            0.0075976
exploration/Actions Std             0.238146
exploration/Actions Max             0.99933
exploration/Actions Min            -0.999637
exploration/Num Paths               5
exploration/Average Returns       -35.257
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.210956
evaluation/Rewards Std              0.817614
evaluation/Rewards Max             -0.00388396
evaluation/Rewards Min             -7.72275
evaluation/Returns Mean           -21.0956
evaluation/Returns Std              9.66669
evaluation/Returns Max             -1.71487
evaluation/Returns Min            -38.5823
evaluation/Actions Mean            -0.0110283
evaluation/Actions Std              0.185909
evaluation/Actions Max              0.995669
evaluation/Actions Min             -0.995727
evaluation/Num Paths               15
evaluation/Average Returns        -21.0956
time/data storing (s)               0.0032319
time/evaluation sampling (s)        0.348566
time/exploration sampling (s)       0.155456
time/logging (s)                    0.00492803
time/saving (s)                     0.00203134
time/training (s)                   2.11812
time/epoch (s)                      2.63233
time/total (s)                    502.972
Epoch                             185
-----------------------------  ---------------
2019-04-22 21:46:26.803954 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              93700
trainer/QF1 Loss                    0.527212
trainer/QF2 Loss                    0.528582
trainer/Policy Loss                10.2577
trainer/Q1 Predictions Mean        -8.54365
trainer/Q1 Predictions Std          6.09234
trainer/Q1 Predictions Max         -6.1456
trainer/Q1 Predictions Min        -58.8287
trainer/Q2 Predictions Mean        -8.53604
trainer/Q2 Predictions Std          6.09809
trainer/Q2 Predictions Max         -6.14377
trainer/Q2 Predictions Min        -58.871
trainer/Q Targets Mean             -8.48566
trainer/Q Targets Std               6.3183
trainer/Q Targets Max              -0.19017
trainer/Q Targets Min             -60.4016
trainer/Log Pis Mean                1.92588
trainer/Log Pis Std                 1.25562
trainer/Log Pis Max                 8.05172
trainer/Log Pis Min                -1.51527
trainer/Policy mu Mean             -0.0101648
trainer/Policy mu Std               0.69078
trainer/Policy mu Max               3.66024
trainer/Policy mu Min              -2.89309
trainer/Policy log std Mean        -2.14367
trainer/Policy log std Std          0.485068
trainer/Policy log std Max         -0.418271
trainer/Policy log std Min         -2.53278
trainer/Alpha                       0.0644215
trainer/Alpha Loss                 -0.203275
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.344136
exploration/Rewards Std             1.13484
exploration/Rewards Max            -0.00503143
exploration/Rewards Min           -11.5053
exploration/Returns Mean          -34.4136
exploration/Returns Std            16.0941
exploration/Returns Max           -19.9285
exploration/Returns Min           -64.5529
exploration/Actions Mean           -0.00079146
exploration/Actions Std             0.250024
exploration/Actions Max             0.997031
exploration/Actions Min            -0.9988
exploration/Num Paths               5
exploration/Average Returns       -34.4136
evaluation/num steps total     280500
evaluation/num paths total       2805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.240606
evaluation/Rewards Std              0.99563
evaluation/Rewards Max             -0.00437073
evaluation/Rewards Min             -9.77044
evaluation/Returns Mean           -24.0606
evaluation/Returns Std             15.1293
evaluation/Returns Max             -5.57231
evaluation/Returns Min            -56.0388
evaluation/Actions Mean            -0.0126331
evaluation/Actions Std              0.19927
evaluation/Actions Max              0.997315
evaluation/Actions Min             -0.997329
evaluation/Num Paths               15
evaluation/Average Returns        -24.0606
time/data storing (s)               0.00308336
time/evaluation sampling (s)        0.357322
time/exploration sampling (s)       0.16035
time/logging (s)                    0.00495619
time/saving (s)                     0.00205196
time/training (s)                   2.17974
time/epoch (s)                      2.70751
time/total (s)                    505.684
Epoch                             186
-----------------------------  ---------------
2019-04-22 21:46:29.496716 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              94200
trainer/QF1 Loss                    0.407445
trainer/QF2 Loss                    0.409535
trainer/Policy Loss                 9.08283
trainer/Q1 Predictions Mean        -7.34165
trainer/Q1 Predictions Std          2.21376
trainer/Q1 Predictions Max         -6.01289
trainer/Q1 Predictions Min        -22.8008
trainer/Q2 Predictions Mean        -7.33361
trainer/Q2 Predictions Std          2.202
trainer/Q2 Predictions Max         -6.0126
trainer/Q2 Predictions Min        -22.9249
trainer/Q Targets Mean             -7.39148
trainer/Q Targets Std               2.34287
trainer/Q Targets Max              -0.738632
trainer/Q Targets Min             -23.4663
trainer/Log Pis Mean                1.90099
trainer/Log Pis Std                 1.02238
trainer/Log Pis Max                 5.38002
trainer/Log Pis Min                -1.5523
trainer/Policy mu Mean              0.00466854
trainer/Policy mu Std               0.484884
trainer/Policy mu Max               2.85214
trainer/Policy mu Min              -2.42473
trainer/Policy log std Mean        -2.19068
trainer/Policy log std Std          0.377605
trainer/Policy log std Max         -0.571346
trainer/Policy log std Min         -2.52581
trainer/Alpha                       0.0639616
trainer/Alpha Loss                 -0.272231
exploration/num steps total     94200
exploration/num paths total       942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.379199
exploration/Rewards Std             1.19405
exploration/Rewards Max            -0.00627932
exploration/Rewards Min           -10.1294
exploration/Returns Mean          -37.9199
exploration/Returns Std            18.9749
exploration/Returns Max           -13.0125
exploration/Returns Min           -61.6297
exploration/Actions Mean            0.00149878
exploration/Actions Std             0.252083
exploration/Actions Max             0.999977
exploration/Actions Min            -0.997733
exploration/Num Paths               5
exploration/Average Returns       -37.9199
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.309499
evaluation/Rewards Std              1.2178
evaluation/Rewards Max             -0.0180755
evaluation/Rewards Min            -11.7347
evaluation/Returns Mean           -30.9499
evaluation/Returns Std             19.0127
evaluation/Returns Max             -6.62547
evaluation/Returns Min            -64.5354
evaluation/Actions Mean            -0.00681674
evaluation/Actions Std              0.21396
evaluation/Actions Max              0.998799
evaluation/Actions Min             -0.997494
evaluation/Num Paths               15
evaluation/Average Returns        -30.9499
time/data storing (s)               0.00310769
time/evaluation sampling (s)        0.355656
time/exploration sampling (s)       0.159931
time/logging (s)                    0.00481747
time/saving (s)                     0.00205661
time/training (s)                   2.1592
time/epoch (s)                      2.68477
time/total (s)                    508.374
Epoch                             187
-----------------------------  ---------------
2019-04-22 21:46:32.233694 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              94700
trainer/QF1 Loss                    0.0404501
trainer/QF2 Loss                    0.0322145
trainer/Policy Loss                10.2584
trainer/Q1 Predictions Mean        -8.44835
trainer/Q1 Predictions Std          7.51611
trainer/Q1 Predictions Max         -5.98434
trainer/Q1 Predictions Min        -63.7029
trainer/Q2 Predictions Mean        -8.47703
trainer/Q2 Predictions Std          7.61511
trainer/Q2 Predictions Max         -5.99348
trainer/Q2 Predictions Min        -63.918
trainer/Q Targets Mean             -8.55601
trainer/Q Targets Std               7.5983
trainer/Q Targets Max              -6.09335
trainer/Q Targets Min             -64.5428
trainer/Log Pis Mean                2.08711
trainer/Log Pis Std                 1.43755
trainer/Log Pis Max                 6.09595
trainer/Log Pis Min                -4.22337
trainer/Policy mu Mean             -0.0121457
trainer/Policy mu Std               0.682926
trainer/Policy mu Max               3.04007
trainer/Policy mu Min              -3.45369
trainer/Policy log std Mean        -2.1553
trainer/Policy log std Std          0.486437
trainer/Policy log std Max         -0.412378
trainer/Policy log std Min         -2.53056
trainer/Alpha                       0.0634004
trainer/Alpha Loss                  0.240284
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.308272
exploration/Rewards Std             0.902758
exploration/Rewards Max            -0.00309745
exploration/Rewards Min            -7.68383
exploration/Returns Mean          -30.8272
exploration/Returns Std             8.71584
exploration/Returns Max           -18.0441
exploration/Returns Min           -44.3425
exploration/Actions Mean           -0.00329977
exploration/Actions Std             0.240745
exploration/Actions Max             0.996541
exploration/Actions Min            -0.999607
exploration/Num Paths               5
exploration/Average Returns       -30.8272
evaluation/num steps total     283500
evaluation/num paths total       2835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199558
evaluation/Rewards Std              0.939437
evaluation/Rewards Max             -0.00134186
evaluation/Rewards Min            -11.0293
evaluation/Returns Mean           -19.9558
evaluation/Returns Std             16.1247
evaluation/Returns Max             -1.07899
evaluation/Returns Min            -50.7472
evaluation/Actions Mean            -0.0164157
evaluation/Actions Std              0.179764
evaluation/Actions Max              0.995259
evaluation/Actions Min             -0.998052
evaluation/Num Paths               15
evaluation/Average Returns        -19.9558
time/data storing (s)               0.00315355
time/evaluation sampling (s)        0.359987
time/exploration sampling (s)       0.163033
time/logging (s)                    0.00491173
time/saving (s)                     0.00182726
time/training (s)                   2.19646
time/epoch (s)                      2.72938
time/total (s)                    511.107
Epoch                             188
-----------------------------  ---------------
2019-04-22 21:46:34.919504 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              95200
trainer/QF1 Loss                    0.0645792
trainer/QF2 Loss                    0.0481752
trainer/Policy Loss                 9.5258
trainer/Q1 Predictions Mean        -7.82965
trainer/Q1 Predictions Std          6.08545
trainer/Q1 Predictions Max         -5.93387
trainer/Q1 Predictions Min        -65.4971
trainer/Q2 Predictions Mean        -7.85362
trainer/Q2 Predictions Std          6.09852
trainer/Q2 Predictions Max         -5.97339
trainer/Q2 Predictions Min        -65.7185
trainer/Q Targets Mean             -7.95976
trainer/Q Targets Std               6.23278
trainer/Q Targets Max              -6.07546
trainer/Q Targets Min             -67.33
trainer/Log Pis Mean                1.93514
trainer/Log Pis Std                 1.11675
trainer/Log Pis Max                 8.02601
trainer/Log Pis Min                -1.6005
trainer/Policy mu Mean              0.0298411
trainer/Policy mu Std               0.558403
trainer/Policy mu Max               3.21212
trainer/Policy mu Min              -2.23217
trainer/Policy log std Mean        -2.15832
trainer/Policy log std Std          0.419803
trainer/Policy log std Max         -0.4449
trainer/Policy log std Min         -2.50212
trainer/Alpha                       0.0633192
trainer/Alpha Loss                 -0.178981
exploration/num steps total     95200
exploration/num paths total       952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.208195
exploration/Rewards Std             0.509644
exploration/Rewards Max            -0.00729557
exploration/Rewards Min            -6.3146
exploration/Returns Mean          -20.8195
exploration/Returns Std             6.85429
exploration/Returns Max           -13.5861
exploration/Returns Min           -31.2469
exploration/Actions Mean           -0.0135651
exploration/Actions Std             0.195723
exploration/Actions Max             0.995735
exploration/Actions Min            -0.99743
exploration/Num Paths               5
exploration/Average Returns       -20.8195
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229233
evaluation/Rewards Std              0.993731
evaluation/Rewards Max             -0.00189239
evaluation/Rewards Min            -10.0035
evaluation/Returns Mean           -22.9233
evaluation/Returns Std             16.4311
evaluation/Returns Max             -3.80551
evaluation/Returns Min            -57.9696
evaluation/Actions Mean             0.00497785
evaluation/Actions Std              0.19132
evaluation/Actions Max              0.999031
evaluation/Actions Min             -0.994736
evaluation/Num Paths               15
evaluation/Average Returns        -22.9233
time/data storing (s)               0.00338847
time/evaluation sampling (s)        0.367174
time/exploration sampling (s)       0.166285
time/logging (s)                    0.00426974
time/saving (s)                     0.00253249
time/training (s)                   2.13294
time/epoch (s)                      2.67659
time/total (s)                    513.789
Epoch                             189
-----------------------------  ---------------
2019-04-22 21:46:37.630045 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              95700
trainer/QF1 Loss                    0.434741
trainer/QF2 Loss                    0.443032
trainer/Policy Loss                 9.16312
trainer/Q1 Predictions Mean        -7.38459
trainer/Q1 Predictions Std          3.37323
trainer/Q1 Predictions Max         -6.14022
trainer/Q1 Predictions Min        -39.2789
trainer/Q2 Predictions Mean        -7.38582
trainer/Q2 Predictions Std          3.40482
trainer/Q2 Predictions Max         -6.10668
trainer/Q2 Predictions Min        -39.5647
trainer/Q Targets Mean             -7.43222
trainer/Q Targets Std               3.45952
trainer/Q Targets Max              -0.148162
trainer/Q Targets Min             -39.4103
trainer/Log Pis Mean                1.8495
trainer/Log Pis Std                 0.920249
trainer/Log Pis Max                 4.36308
trainer/Log Pis Min                -1.58821
trainer/Policy mu Mean             -0.0351168
trainer/Policy mu Std               0.442055
trainer/Policy mu Max               2.93439
trainer/Policy mu Min              -2.75615
trainer/Policy log std Mean        -2.17227
trainer/Policy log std Std          0.358462
trainer/Policy log std Max         -0.640061
trainer/Policy log std Min         -2.57633
trainer/Alpha                       0.0641628
trainer/Alpha Loss                 -0.413306
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.337199
exploration/Rewards Std             1.00129
exploration/Rewards Max            -0.00510538
exploration/Rewards Min            -7.66338
exploration/Returns Mean          -33.7199
exploration/Returns Std            13.9657
exploration/Returns Max           -10.8392
exploration/Returns Min           -47.0949
exploration/Actions Mean           -0.0161671
exploration/Actions Std             0.227544
exploration/Actions Max             0.998934
exploration/Actions Min            -0.996233
exploration/Num Paths               5
exploration/Average Returns       -33.7199
evaluation/num steps total     286500
evaluation/num paths total       2865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.188721
evaluation/Rewards Std              0.900225
evaluation/Rewards Max             -0.00380822
evaluation/Rewards Min             -8.25096
evaluation/Returns Mean           -18.8721
evaluation/Returns Std             13.2184
evaluation/Returns Max             -1.16046
evaluation/Returns Min            -38.9582
evaluation/Actions Mean            -0.00937169
evaluation/Actions Std              0.180286
evaluation/Actions Max              0.99655
evaluation/Actions Min             -0.998179
evaluation/Num Paths               15
evaluation/Average Returns        -18.8721
time/data storing (s)               0.00315895
time/evaluation sampling (s)        0.361355
time/exploration sampling (s)       0.166182
time/logging (s)                    0.00476189
time/saving (s)                     0.00206747
time/training (s)                   2.16584
time/epoch (s)                      2.70336
time/total (s)                    516.497
Epoch                             190
-----------------------------  ---------------
2019-04-22 21:46:40.422991 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              96200
trainer/QF1 Loss                    0.411346
trainer/QF2 Loss                    0.406438
trainer/Policy Loss                 9.72139
trainer/Q1 Predictions Mean        -7.97719
trainer/Q1 Predictions Std          4.71759
trainer/Q1 Predictions Max         -6.08134
trainer/Q1 Predictions Min        -37.3346
trainer/Q2 Predictions Mean        -7.97409
trainer/Q2 Predictions Std          4.69832
trainer/Q2 Predictions Max         -6.06515
trainer/Q2 Predictions Min        -37.1236
trainer/Q Targets Mean             -7.97387
trainer/Q Targets Std               4.81915
trainer/Q Targets Max              -0.129529
trainer/Q Targets Min             -37.2526
trainer/Log Pis Mean                1.96663
trainer/Log Pis Std                 1.21253
trainer/Log Pis Max                 6.71227
trainer/Log Pis Min                -3.20446
trainer/Policy mu Mean             -0.0058507
trainer/Policy mu Std               0.655728
trainer/Policy mu Max               3.06336
trainer/Policy mu Min              -2.91802
trainer/Policy log std Mean        -2.11425
trainer/Policy log std Std          0.504876
trainer/Policy log std Max         -0.480979
trainer/Policy log std Min         -2.57333
trainer/Alpha                       0.0634907
trainer/Alpha Loss                 -0.0920054
exploration/num steps total     96200
exploration/num paths total       962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.357762
exploration/Rewards Std             1.1192
exploration/Rewards Max            -0.00386785
exploration/Rewards Min           -10.621
exploration/Returns Mean          -35.7762
exploration/Returns Std            20.0486
exploration/Returns Max           -18.1947
exploration/Returns Min           -66.0091
exploration/Actions Mean            0.0214083
exploration/Actions Std             0.250758
exploration/Actions Max             0.998995
exploration/Actions Min            -0.998255
exploration/Num Paths               5
exploration/Average Returns       -35.7762
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.26855
evaluation/Rewards Std              1.10724
evaluation/Rewards Max             -0.00857818
evaluation/Rewards Min            -10.2349
evaluation/Returns Mean           -26.855
evaluation/Returns Std             15.3581
evaluation/Returns Max             -7.09851
evaluation/Returns Min            -54.1689
evaluation/Actions Mean            -0.00581143
evaluation/Actions Std              0.209899
evaluation/Actions Max              0.998256
evaluation/Actions Min             -0.995817
evaluation/Num Paths               15
evaluation/Average Returns        -26.855
time/data storing (s)               0.00322462
time/evaluation sampling (s)        0.382894
time/exploration sampling (s)       0.200756
time/logging (s)                    0.00509565
time/saving (s)                     0.00215006
time/training (s)                   2.19111
time/epoch (s)                      2.78523
time/total (s)                    519.287
Epoch                             191
-----------------------------  ---------------
2019-04-22 21:46:43.128313 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              96700
trainer/QF1 Loss                    9.6025
trainer/QF2 Loss                    9.58516
trainer/Policy Loss                10.1331
trainer/Q1 Predictions Mean        -8.55078
trainer/Q1 Predictions Std          6.43054
trainer/Q1 Predictions Max         -6.08131
trainer/Q1 Predictions Min        -39.5712
trainer/Q2 Predictions Mean        -8.56006
trainer/Q2 Predictions Std          6.44366
trainer/Q2 Predictions Max         -6.11409
trainer/Q2 Predictions Min        -40.0998
trainer/Q Targets Mean             -8.22462
trainer/Q Targets Std               5.70011
trainer/Q Targets Max              -0.0839359
trainer/Q Targets Min             -39.5946
trainer/Log Pis Mean                1.87161
trainer/Log Pis Std                 1.57377
trainer/Log Pis Max                 8.26442
trainer/Log Pis Min                -3.95164
trainer/Policy mu Mean              0.0573115
trainer/Policy mu Std               0.718555
trainer/Policy mu Max               3.05905
trainer/Policy mu Min              -2.83763
trainer/Policy log std Mean        -2.09398
trainer/Policy log std Std          0.487747
trainer/Policy log std Max         -0.480288
trainer/Policy log std Min         -2.57752
trainer/Alpha                       0.0635229
trainer/Alpha Loss                 -0.353902
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.344837
exploration/Rewards Std             0.9031
exploration/Rewards Max            -0.0067123
exploration/Rewards Min            -9.23621
exploration/Returns Mean          -34.4837
exploration/Returns Std            14.629
exploration/Returns Max           -13.1851
exploration/Returns Min           -57.7882
exploration/Actions Mean           -0.00474203
exploration/Actions Std             0.244321
exploration/Actions Max             0.998952
exploration/Actions Min            -0.992203
exploration/Num Paths               5
exploration/Average Returns       -34.4837
evaluation/num steps total     289500
evaluation/num paths total       2895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.259016
evaluation/Rewards Std              0.871625
evaluation/Rewards Max             -0.0153601
evaluation/Rewards Min             -9.2551
evaluation/Returns Mean           -25.9016
evaluation/Returns Std             14.1018
evaluation/Returns Max             -4.56931
evaluation/Returns Min            -63.4906
evaluation/Actions Mean             0.00431262
evaluation/Actions Std              0.183711
evaluation/Actions Max              0.996965
evaluation/Actions Min             -0.998058
evaluation/Num Paths               15
evaluation/Average Returns        -25.9016
time/data storing (s)               0.00323307
time/evaluation sampling (s)        0.358232
time/exploration sampling (s)       0.158823
time/logging (s)                    0.00519469
time/saving (s)                     0.0118866
time/training (s)                   2.16022
time/epoch (s)                      2.69759
time/total (s)                    521.989
Epoch                             192
-----------------------------  ---------------
2019-04-22 21:46:45.847547 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 193 finished
-----------------------------  ----------------
replay_buffer/size              97200
trainer/QF1 Loss                    0.727744
trainer/QF2 Loss                    0.728721
trainer/Policy Loss                 9.77451
trainer/Q1 Predictions Mean        -7.94848
trainer/Q1 Predictions Std          6.17364
trainer/Q1 Predictions Max         -5.98157
trainer/Q1 Predictions Min        -60.0884
trainer/Q2 Predictions Mean        -7.94616
trainer/Q2 Predictions Std          6.16279
trainer/Q2 Predictions Max         -6.0076
trainer/Q2 Predictions Min        -60.0681
trainer/Q Targets Mean             -7.86133
trainer/Q Targets Std               6.27067
trainer/Q Targets Max              -0.0374197
trainer/Q Targets Min             -60.4726
trainer/Log Pis Mean                1.9441
trainer/Log Pis Std                 1.30506
trainer/Log Pis Max                 5.39123
trainer/Log Pis Min                -3.11724
trainer/Policy mu Mean              0.0492268
trainer/Policy mu Std               0.57587
trainer/Policy mu Max               3.20182
trainer/Policy mu Min              -1.98332
trainer/Policy log std Mean        -2.24288
trainer/Policy log std Std          0.45106
trainer/Policy log std Max         -0.621267
trainer/Policy log std Min         -2.64733
trainer/Alpha                       0.0628685
trainer/Alpha Loss                 -0.15466
exploration/num steps total     97200
exploration/num paths total       972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.42587
exploration/Rewards Std             1.31752
exploration/Rewards Max            -0.00167441
exploration/Rewards Min           -10.3003
exploration/Returns Mean          -42.587
exploration/Returns Std            16.0378
exploration/Returns Max           -18.4904
exploration/Returns Min           -62.057
exploration/Actions Mean           -0.000537807
exploration/Actions Std             0.265848
exploration/Actions Max             0.999205
exploration/Actions Min            -0.999234
exploration/Num Paths               5
exploration/Average Returns       -42.587
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.239311
evaluation/Rewards Std              1.09476
evaluation/Rewards Max             -0.0143567
evaluation/Rewards Min            -11.1101
evaluation/Returns Mean           -23.9311
evaluation/Returns Std             16.1097
evaluation/Returns Max             -2.28988
evaluation/Returns Min            -54.2678
evaluation/Actions Mean            -0.0243569
evaluation/Actions Std              0.20633
evaluation/Actions Max              0.995403
evaluation/Actions Min             -0.998487
evaluation/Num Paths               15
evaluation/Average Returns        -23.9311
time/data storing (s)               0.00313441
time/evaluation sampling (s)        0.36123
time/exploration sampling (s)       0.165198
time/logging (s)                    0.0047354
time/saving (s)                     0.00229293
time/training (s)                   2.17429
time/epoch (s)                      2.71088
time/total (s)                    524.704
Epoch                             193
-----------------------------  ----------------
2019-04-22 21:46:48.526100 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              97700
trainer/QF1 Loss                    0.0571176
trainer/QF2 Loss                    0.0469183
trainer/Policy Loss                 9.14212
trainer/Q1 Predictions Mean        -7.32831
trainer/Q1 Predictions Std          2.25312
trainer/Q1 Predictions Max         -5.72481
trainer/Q1 Predictions Min        -20.2146
trainer/Q2 Predictions Mean        -7.3412
trainer/Q2 Predictions Std          2.26809
trainer/Q2 Predictions Max         -5.71361
trainer/Q2 Predictions Min        -20.2888
trainer/Q Targets Mean             -7.42719
trainer/Q Targets Std               2.25276
trainer/Q Targets Max              -5.98219
trainer/Q Targets Min             -20.4751
trainer/Log Pis Mean                1.97738
trainer/Log Pis Std                 1.12308
trainer/Log Pis Max                 4.86403
trainer/Log Pis Min                -2.65047
trainer/Policy mu Mean             -0.00838625
trainer/Policy mu Std               0.589492
trainer/Policy mu Max               2.7383
trainer/Policy mu Min              -2.65609
trainer/Policy log std Mean        -2.16264
trainer/Policy log std Std          0.472242
trainer/Policy log std Max         -0.585892
trainer/Policy log std Min         -2.58474
trainer/Alpha                       0.0638591
trainer/Alpha Loss                 -0.0622346
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.319245
exploration/Rewards Std             0.995607
exploration/Rewards Max            -0.00473802
exploration/Rewards Min            -8.81671
exploration/Returns Mean          -31.9245
exploration/Returns Std            17.4091
exploration/Returns Max           -15.393
exploration/Returns Min           -56.3239
exploration/Actions Mean            0.0100239
exploration/Actions Std             0.229057
exploration/Actions Max             0.998714
exploration/Actions Min            -0.993596
exploration/Num Paths               5
exploration/Average Returns       -31.9245
evaluation/num steps total     292500
evaluation/num paths total       2925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207574
evaluation/Rewards Std              0.853636
evaluation/Rewards Max             -0.0255489
evaluation/Rewards Min             -9.28573
evaluation/Returns Mean           -20.7574
evaluation/Returns Std             13.0396
evaluation/Returns Max             -5.33802
evaluation/Returns Min            -51.8133
evaluation/Actions Mean            -0.00411734
evaluation/Actions Std              0.183915
evaluation/Actions Max              0.996737
evaluation/Actions Min             -0.995569
evaluation/Num Paths               15
evaluation/Average Returns        -20.7574
time/data storing (s)               0.00329263
time/evaluation sampling (s)        0.355019
time/exploration sampling (s)       0.160191
time/logging (s)                    0.00515263
time/saving (s)                     0.00206939
time/training (s)                   2.14532
time/epoch (s)                      2.67105
time/total (s)                    527.38
Epoch                             194
-----------------------------  ---------------
2019-04-22 21:46:51.254258 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              98200
trainer/QF1 Loss                    0.848564
trainer/QF2 Loss                    0.873174
trainer/Policy Loss                 9.30817
trainer/Q1 Predictions Mean        -7.66075
trainer/Q1 Predictions Std          2.86759
trainer/Q1 Predictions Max         -5.90011
trainer/Q1 Predictions Min        -25.2551
trainer/Q2 Predictions Mean        -7.65188
trainer/Q2 Predictions Std          2.8185
trainer/Q2 Predictions Max         -5.8981
trainer/Q2 Predictions Min        -24.9199
trainer/Q Targets Mean             -7.65718
trainer/Q Targets Std               2.99173
trainer/Q Targets Max              -0.268048
trainer/Q Targets Min             -24.7315
trainer/Log Pis Mean                1.98153
trainer/Log Pis Std                 1.24417
trainer/Log Pis Max                 5.88713
trainer/Log Pis Min                -2.53678
trainer/Policy mu Mean             -0.114611
trainer/Policy mu Std               0.654214
trainer/Policy mu Max               2.55162
trainer/Policy mu Min              -2.81314
trainer/Policy log std Mean        -2.14014
trainer/Policy log std Std          0.486789
trainer/Policy log std Max         -0.483294
trainer/Policy log std Min         -2.54364
trainer/Alpha                       0.0627114
trainer/Alpha Loss                 -0.0511452
exploration/num steps total     98200
exploration/num paths total       982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.369847
exploration/Rewards Std             1.15788
exploration/Rewards Max            -0.00802943
exploration/Rewards Min           -11.147
exploration/Returns Mean          -36.9847
exploration/Returns Std            18.9424
exploration/Returns Max           -16.4072
exploration/Returns Min           -66.2811
exploration/Actions Mean            0.00844858
exploration/Actions Std             0.255143
exploration/Actions Max             0.998948
exploration/Actions Min            -0.999388
exploration/Num Paths               5
exploration/Average Returns       -36.9847
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263626
evaluation/Rewards Std              1.01273
evaluation/Rewards Max             -0.0323329
evaluation/Rewards Min            -10.8835
evaluation/Returns Mean           -26.3626
evaluation/Returns Std             14.5802
evaluation/Returns Max             -6.35263
evaluation/Returns Min            -59.4127
evaluation/Actions Mean            -0.00467182
evaluation/Actions Std              0.203912
evaluation/Actions Max              0.99781
evaluation/Actions Min             -0.998418
evaluation/Num Paths               15
evaluation/Average Returns        -26.3626
time/data storing (s)               0.00315721
time/evaluation sampling (s)        0.356921
time/exploration sampling (s)       0.161449
time/logging (s)                    0.00497928
time/saving (s)                     0.00209406
time/training (s)                   2.19119
time/epoch (s)                      2.71979
time/total (s)                    530.105
Epoch                             195
-----------------------------  ---------------
2019-04-22 21:46:53.913982 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              98700
trainer/QF1 Loss                    0.400305
trainer/QF2 Loss                    0.389779
trainer/Policy Loss                 9.88689
trainer/Q1 Predictions Mean        -8.17162
trainer/Q1 Predictions Std          5.47968
trainer/Q1 Predictions Max         -5.99234
trainer/Q1 Predictions Min        -44.9086
trainer/Q2 Predictions Mean        -8.16536
trainer/Q2 Predictions Std          5.40634
trainer/Q2 Predictions Max         -6.01654
trainer/Q2 Predictions Min        -44.4039
trainer/Q Targets Mean             -8.14703
trainer/Q Targets Std               5.46894
trainer/Q Targets Max              -0.0931756
trainer/Q Targets Min             -44.0291
trainer/Log Pis Mean                2.03844
trainer/Log Pis Std                 1.31038
trainer/Log Pis Max                 7.31083
trainer/Log Pis Min                -1.37011
trainer/Policy mu Mean             -0.0411945
trainer/Policy mu Std               0.646086
trainer/Policy mu Max               2.74103
trainer/Policy mu Min              -2.94811
trainer/Policy log std Mean        -2.13611
trainer/Policy log std Std          0.456289
trainer/Policy log std Max         -0.362313
trainer/Policy log std Min         -2.52773
trainer/Alpha                       0.0617932
trainer/Alpha Loss                  0.106999
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.314719
exploration/Rewards Std             0.934798
exploration/Rewards Max            -0.00404685
exploration/Rewards Min            -8.29649
exploration/Returns Mean          -31.4719
exploration/Returns Std            13.103
exploration/Returns Max           -14.1621
exploration/Returns Min           -47.9392
exploration/Actions Mean           -0.022682
exploration/Actions Std             0.236301
exploration/Actions Max             0.998331
exploration/Actions Min            -0.998994
exploration/Num Paths               5
exploration/Average Returns       -31.4719
evaluation/num steps total     295500
evaluation/num paths total       2955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.235536
evaluation/Rewards Std              0.910189
evaluation/Rewards Max             -0.0418491
evaluation/Rewards Min             -9.84896
evaluation/Returns Mean           -23.5536
evaluation/Returns Std             17.4266
evaluation/Returns Max             -4.64607
evaluation/Returns Min            -61.8738
evaluation/Actions Mean             0.0101969
evaluation/Actions Std              0.175012
evaluation/Actions Max              0.999021
evaluation/Actions Min             -0.998269
evaluation/Num Paths               15
evaluation/Average Returns        -23.5536
time/data storing (s)               0.00315583
time/evaluation sampling (s)        0.361861
time/exploration sampling (s)       0.165936
time/logging (s)                    0.00492395
time/saving (s)                     0.00199007
time/training (s)                   2.11358
time/epoch (s)                      2.65144
time/total (s)                    532.761
Epoch                             196
-----------------------------  ---------------
2019-04-22 21:46:56.631409 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              99200
trainer/QF1 Loss                    0.636575
trainer/QF2 Loss                    0.640198
trainer/Policy Loss                 9.51786
trainer/Q1 Predictions Mean        -7.78216
trainer/Q1 Predictions Std          4.46005
trainer/Q1 Predictions Max         -5.98376
trainer/Q1 Predictions Min        -45.9869
trainer/Q2 Predictions Mean        -7.76042
trainer/Q2 Predictions Std          4.41223
trainer/Q2 Predictions Max         -5.98891
trainer/Q2 Predictions Min        -45.5293
trainer/Q Targets Mean             -7.74204
trainer/Q Targets Std               4.52895
trainer/Q Targets Max              -0.128039
trainer/Q Targets Min             -46.3136
trainer/Log Pis Mean                1.93035
trainer/Log Pis Std                 0.906356
trainer/Log Pis Max                 4.51415
trainer/Log Pis Min                -0.832136
trainer/Policy mu Mean             -0.0333525
trainer/Policy mu Std               0.58763
trainer/Policy mu Max               3.21377
trainer/Policy mu Min              -2.70785
trainer/Policy log std Mean        -2.0931
trainer/Policy log std Std          0.444935
trainer/Policy log std Max         -0.416885
trainer/Policy log std Min         -2.4494
trainer/Alpha                       0.0637027
trainer/Alpha Loss                 -0.191787
exploration/num steps total     99200
exploration/num paths total       992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.368696
exploration/Rewards Std             0.975639
exploration/Rewards Max            -0.00499497
exploration/Rewards Min            -7.38537
exploration/Returns Mean          -36.8696
exploration/Returns Std             9.08614
exploration/Returns Max           -22.3697
exploration/Returns Min           -49.7728
exploration/Actions Mean           -0.00688037
exploration/Actions Std             0.249374
exploration/Actions Max             0.995946
exploration/Actions Min            -0.997923
exploration/Num Paths               5
exploration/Average Returns       -36.8696
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260147
evaluation/Rewards Std              0.95588
evaluation/Rewards Max             -0.0325958
evaluation/Rewards Min             -9.29617
evaluation/Returns Mean           -26.0147
evaluation/Returns Std             16.4714
evaluation/Returns Max             -7.2605
evaluation/Returns Min            -60.5174
evaluation/Actions Mean             0.00526739
evaluation/Actions Std              0.195989
evaluation/Actions Max              0.99765
evaluation/Actions Min             -0.997534
evaluation/Num Paths               15
evaluation/Average Returns        -26.0147
time/data storing (s)               0.00321446
time/evaluation sampling (s)        0.355382
time/exploration sampling (s)       0.162016
time/logging (s)                    0.00491199
time/saving (s)                     0.00200689
time/training (s)                   2.1821
time/epoch (s)                      2.70963
time/total (s)                    535.475
Epoch                             197
-----------------------------  ---------------
2019-04-22 21:46:59.439428 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              99700
trainer/QF1 Loss                    9.03702
trainer/QF2 Loss                    8.41721
trainer/Policy Loss                 9.36585
trainer/Q1 Predictions Mean        -7.55983
trainer/Q1 Predictions Std          3.75128
trainer/Q1 Predictions Max         -5.94663
trainer/Q1 Predictions Min        -36.4877
trainer/Q2 Predictions Mean        -7.53565
trainer/Q2 Predictions Std          3.66202
trainer/Q2 Predictions Max         -5.9474
trainer/Q2 Predictions Min        -35.3876
trainer/Q Targets Mean             -7.21053
trainer/Q Targets Std               2.5297
trainer/Q Targets Max              -0.0530746
trainer/Q Targets Min             -23.386
trainer/Log Pis Mean                2.06806
trainer/Log Pis Std                 1.14827
trainer/Log Pis Max                 6.47308
trainer/Log Pis Min                -1.51365
trainer/Policy mu Mean             -0.0547042
trainer/Policy mu Std               0.609976
trainer/Policy mu Max               2.79158
trainer/Policy mu Min              -2.68066
trainer/Policy log std Mean        -2.16449
trainer/Policy log std Std          0.445485
trainer/Policy log std Max         -0.606975
trainer/Policy log std Min         -2.53475
trainer/Alpha                       0.0602539
trainer/Alpha Loss                  0.191176
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.335548
exploration/Rewards Std             1.01873
exploration/Rewards Max            -0.0115752
exploration/Rewards Min            -8.41245
exploration/Returns Mean          -33.5548
exploration/Returns Std            13.6688
exploration/Returns Max           -12.5707
exploration/Returns Min           -51.1388
exploration/Actions Mean           -0.00431691
exploration/Actions Std             0.239779
exploration/Actions Max             0.999031
exploration/Actions Min            -0.999582
exploration/Num Paths               5
exploration/Average Returns       -33.5548
evaluation/num steps total     298500
evaluation/num paths total       2985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.182252
evaluation/Rewards Std              0.867907
evaluation/Rewards Max             -0.00671824
evaluation/Rewards Min             -9.32566
evaluation/Returns Mean           -18.2252
evaluation/Returns Std             16.1201
evaluation/Returns Max             -3.20321
evaluation/Returns Min            -52.8779
evaluation/Actions Mean             0.00780838
evaluation/Actions Std              0.182472
evaluation/Actions Max              0.998397
evaluation/Actions Min             -0.995424
evaluation/Num Paths               15
evaluation/Average Returns        -18.2252
time/data storing (s)               0.00322656
time/evaluation sampling (s)        0.359541
time/exploration sampling (s)       0.159419
time/logging (s)                    0.00504669
time/saving (s)                     0.00204412
time/training (s)                   2.27077
time/epoch (s)                      2.80005
time/total (s)                    538.28
Epoch                             198
-----------------------------  ---------------
2019-04-22 21:47:02.135577 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.388555
trainer/QF2 Loss                    0.378898
trainer/Policy Loss                 9.46716
trainer/Q1 Predictions Mean        -7.97399
trainer/Q1 Predictions Std          4.60813
trainer/Q1 Predictions Max         -5.90222
trainer/Q1 Predictions Min        -41.9138
trainer/Q2 Predictions Mean        -7.98461
trainer/Q2 Predictions Std          4.58355
trainer/Q2 Predictions Max         -5.90836
trainer/Q2 Predictions Min        -41.8051
trainer/Q Targets Mean             -7.98338
trainer/Q Targets Std               4.64883
trainer/Q Targets Max              -0.203067
trainer/Q Targets Min             -41.1702
trainer/Log Pis Mean                1.72563
trainer/Log Pis Std                 1.26974
trainer/Log Pis Max                 6.61543
trainer/Log Pis Min                -3.44023
trainer/Policy mu Mean             -0.00960381
trainer/Policy mu Std               0.593278
trainer/Policy mu Max               3.23312
trainer/Policy mu Min              -2.78555
trainer/Policy log std Mean        -2.15511
trainer/Policy log std Std          0.443769
trainer/Policy log std Max         -0.450375
trainer/Policy log std Min         -2.54875
trainer/Alpha                       0.0583651
trainer/Alpha Loss                 -0.779475
exploration/num steps total    100200
exploration/num paths total      1002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.270296
exploration/Rewards Std             0.765792
exploration/Rewards Max            -0.0121695
exploration/Rewards Min            -8.02374
exploration/Returns Mean          -27.0296
exploration/Returns Std            11.6234
exploration/Returns Max           -10.8961
exploration/Returns Min           -47.2063
exploration/Actions Mean            0.00562216
exploration/Actions Std             0.229444
exploration/Actions Max             0.998418
exploration/Actions Min            -0.997501
exploration/Num Paths               5
exploration/Average Returns       -27.0296
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.252916
evaluation/Rewards Std              1.03346
evaluation/Rewards Max             -0.0317012
evaluation/Rewards Min            -10.0551
evaluation/Returns Mean           -25.2916
evaluation/Returns Std             15.7915
evaluation/Returns Max             -5.76705
evaluation/Returns Min            -59.627
evaluation/Actions Mean             0.00966904
evaluation/Actions Std              0.195018
evaluation/Actions Max              0.998887
evaluation/Actions Min             -0.997147
evaluation/Num Paths               15
evaluation/Average Returns        -25.2916
time/data storing (s)               0.00365511
time/evaluation sampling (s)        0.365551
time/exploration sampling (s)       0.166606
time/logging (s)                    0.00498484
time/saving (s)                     0.00205124
time/training (s)                   2.14416
time/epoch (s)                      2.68701
time/total (s)                    540.972
Epoch                             199
-----------------------------  ---------------
2019-04-22 21:47:04.884258 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 200 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.635196
trainer/QF2 Loss                    0.642333
trainer/Policy Loss                 9.63343
trainer/Q1 Predictions Mean        -7.76317
trainer/Q1 Predictions Std          3.52772
trainer/Q1 Predictions Max         -6.0504
trainer/Q1 Predictions Min        -31.8181
trainer/Q2 Predictions Mean        -7.76406
trainer/Q2 Predictions Std          3.52368
trainer/Q2 Predictions Max         -6.08007
trainer/Q2 Predictions Min        -32.177
trainer/Q Targets Mean             -7.80815
trainer/Q Targets Std               3.59739
trainer/Q Targets Max              -0.286384
trainer/Q Targets Min             -31.5079
trainer/Log Pis Mean                2.09225
trainer/Log Pis Std                 1.00539
trainer/Log Pis Max                 5.67986
trainer/Log Pis Min                -0.292796
trainer/Policy mu Mean             -0.0175764
trainer/Policy mu Std               0.667657
trainer/Policy mu Max               2.69801
trainer/Policy mu Min              -2.96196
trainer/Policy log std Mean        -2.1208
trainer/Policy log std Std          0.500035
trainer/Policy log std Max         -0.601651
trainer/Policy log std Min         -2.56572
trainer/Alpha                       0.0589311
trainer/Alpha Loss                  0.261208
exploration/num steps total    100700
exploration/num paths total      1007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.425408
exploration/Rewards Std             1.24992
exploration/Rewards Max            -0.00213801
exploration/Rewards Min           -10.4073
exploration/Returns Mean          -42.5408
exploration/Returns Std            13.9995
exploration/Returns Max           -25.94
exploration/Returns Min           -59.1084
exploration/Actions Mean            0.0189861
exploration/Actions Std             0.266248
exploration/Actions Max             0.999559
exploration/Actions Min            -0.99794
exploration/Num Paths               5
exploration/Average Returns       -42.5408
evaluation/num steps total     301500
evaluation/num paths total       3015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245811
evaluation/Rewards Std              1.0176
evaluation/Rewards Max             -0.0185421
evaluation/Rewards Min            -10.8441
evaluation/Returns Mean           -24.5811
evaluation/Returns Std             15.3024
evaluation/Returns Max             -5.29675
evaluation/Returns Min            -58.1006
evaluation/Actions Mean            -0.00755324
evaluation/Actions Std              0.19999
evaluation/Actions Max              0.997991
evaluation/Actions Min             -0.997322
evaluation/Num Paths               15
evaluation/Average Returns        -24.5811
time/data storing (s)               0.00308455
time/evaluation sampling (s)        0.370947
time/exploration sampling (s)       0.181157
time/logging (s)                    0.00508456
time/saving (s)                     0.00268939
time/training (s)                   2.17735
time/epoch (s)                      2.74032
time/total (s)                    543.717
Epoch                             200
-----------------------------  ---------------
2019-04-22 21:47:07.556511 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 201 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.81141
trainer/QF2 Loss                    1.7334
trainer/Policy Loss                 9.27624
trainer/Q1 Predictions Mean        -7.54506
trainer/Q1 Predictions Std          2.94727
trainer/Q1 Predictions Max         -6.17666
trainer/Q1 Predictions Min        -30.7259
trainer/Q2 Predictions Mean        -7.55069
trainer/Q2 Predictions Std          2.98686
trainer/Q2 Predictions Max         -6.12307
trainer/Q2 Predictions Min        -31.1436
trainer/Q Targets Mean             -7.37055
trainer/Q Targets Std               3.26798
trainer/Q Targets Max              -0.0261248
trainer/Q Targets Min             -31.661
trainer/Log Pis Mean                1.84237
trainer/Log Pis Std                 1.01926
trainer/Log Pis Max                 4.64734
trainer/Log Pis Min                -1.34597
trainer/Policy mu Mean             -0.0498926
trainer/Policy mu Std               0.531665
trainer/Policy mu Max               2.81183
trainer/Policy mu Min              -3.0367
trainer/Policy log std Mean        -2.14915
trainer/Policy log std Std          0.406293
trainer/Policy log std Max         -0.504668
trainer/Policy log std Min         -2.49167
trainer/Alpha                       0.0602558
trainer/Alpha Loss                 -0.442796
exploration/num steps total    101200
exploration/num paths total      1012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.333544
exploration/Rewards Std             0.989248
exploration/Rewards Max            -0.0133553
exploration/Rewards Min            -8.82888
exploration/Returns Mean          -33.3544
exploration/Returns Std            14.1986
exploration/Returns Max           -15.5717
exploration/Returns Min           -48.587
exploration/Actions Mean           -0.0075019
exploration/Actions Std             0.242893
exploration/Actions Max             0.997992
exploration/Actions Min            -0.999685
exploration/Num Paths               5
exploration/Average Returns       -33.3544
evaluation/num steps total     303000
evaluation/num paths total       3030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.271853
evaluation/Rewards Std              1.12077
evaluation/Rewards Max             -0.0246944
evaluation/Rewards Min            -10.3454
evaluation/Returns Mean           -27.1853
evaluation/Returns Std             19.1078
evaluation/Returns Max             -3.81226
evaluation/Returns Min            -60.1083
evaluation/Actions Mean             0.00802052
evaluation/Actions Std              0.198745
evaluation/Actions Max              0.998941
evaluation/Actions Min             -0.995617
evaluation/Num Paths               15
evaluation/Average Returns        -27.1853
time/data storing (s)               0.00327831
time/evaluation sampling (s)        0.353479
time/exploration sampling (s)       0.162535
time/logging (s)                    0.00474639
time/saving (s)                     0.00206254
time/training (s)                   2.13801
time/epoch (s)                      2.66411
time/total (s)                    546.386
Epoch                             201
-----------------------------  ---------------
2019-04-22 21:47:10.297441 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 202 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0145386
trainer/QF2 Loss                    0.0145271
trainer/Policy Loss                 9.59738
trainer/Q1 Predictions Mean        -7.73676
trainer/Q1 Predictions Std          4.03193
trainer/Q1 Predictions Max         -6.00939
trainer/Q1 Predictions Min        -39.5015
trainer/Q2 Predictions Mean        -7.73767
trainer/Q2 Predictions Std          4.02848
trainer/Q2 Predictions Max         -5.97858
trainer/Q2 Predictions Min        -39.4131
trainer/Q Targets Mean             -7.75643
trainer/Q Targets Std               3.9841
trainer/Q Targets Max              -5.97894
trainer/Q Targets Min             -39.2862
trainer/Log Pis Mean                1.93152
trainer/Log Pis Std                 1.28927
trainer/Log Pis Max                 7.3987
trainer/Log Pis Min                -1.80399
trainer/Policy mu Mean             -0.0508482
trainer/Policy mu Std               0.53314
trainer/Policy mu Max               3.05213
trainer/Policy mu Min              -2.7376
trainer/Policy log std Mean        -2.22108
trainer/Policy log std Std          0.40179
trainer/Policy log std Max         -0.499071
trainer/Policy log std Min         -2.55197
trainer/Alpha                       0.0596393
trainer/Alpha Loss                 -0.193056
exploration/num steps total    101700
exploration/num paths total      1017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.400679
exploration/Rewards Std             1.14802
exploration/Rewards Max            -0.00664006
exploration/Rewards Min            -8.17253
exploration/Returns Mean          -40.0679
exploration/Returns Std             5.83403
exploration/Returns Max           -30.9107
exploration/Returns Min           -48.1275
exploration/Actions Mean           -0.00110917
exploration/Actions Std             0.259664
exploration/Actions Max             0.99863
exploration/Actions Min            -0.998449
exploration/Num Paths               5
exploration/Average Returns       -40.0679
evaluation/num steps total     304500
evaluation/num paths total       3045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244863
evaluation/Rewards Std              1.04151
evaluation/Rewards Max             -0.0296579
evaluation/Rewards Min            -10.0461
evaluation/Returns Mean           -24.4863
evaluation/Returns Std             18.4883
evaluation/Returns Max             -4.31518
evaluation/Returns Min            -57.9401
evaluation/Actions Mean             0.0123449
evaluation/Actions Std              0.185288
evaluation/Actions Max              0.99897
evaluation/Actions Min             -0.995098
evaluation/Num Paths               15
evaluation/Average Returns        -24.4863
time/data storing (s)               0.00311662
time/evaluation sampling (s)        0.36282
time/exploration sampling (s)       0.166987
time/logging (s)                    0.00485208
time/saving (s)                     0.00200901
time/training (s)                   2.19371
time/epoch (s)                      2.7335
time/total (s)                    549.124
Epoch                             202
-----------------------------  ---------------
2019-04-22 21:47:12.997975 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 203 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.632518
trainer/QF2 Loss                    0.626985
trainer/Policy Loss                 8.56769
trainer/Q1 Predictions Mean        -6.91911
trainer/Q1 Predictions Std          0.747706
trainer/Q1 Predictions Max         -6.07855
trainer/Q1 Predictions Min         -8.1836
trainer/Q2 Predictions Mean        -6.91127
trainer/Q2 Predictions Std          0.74505
trainer/Q2 Predictions Max         -6.09163
trainer/Q2 Predictions Min         -8.15749
trainer/Q Targets Mean             -6.8416
trainer/Q Targets Std               1.06739
trainer/Q Targets Max              -0.253803
trainer/Q Targets Min              -8.33973
trainer/Log Pis Mean                1.6918
trainer/Log Pis Std                 1.08054
trainer/Log Pis Max                 3.52708
trainer/Log Pis Min                -1.8375
trainer/Policy mu Mean             -0.0368326
trainer/Policy mu Std               0.265112
trainer/Policy mu Max               1.86746
trainer/Policy mu Min              -1.53278
trainer/Policy log std Mean        -2.26546
trainer/Policy log std Std          0.266206
trainer/Policy log std Max         -0.826051
trainer/Policy log std Min         -2.59633
trainer/Alpha                       0.0608399
trainer/Alpha Loss                 -0.862764
exploration/num steps total    102200
exploration/num paths total      1022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.274938
exploration/Rewards Std             0.846587
exploration/Rewards Max            -0.00553785
exploration/Rewards Min           -10.4766
exploration/Returns Mean          -27.4938
exploration/Returns Std            17.8719
exploration/Returns Max           -13.8515
exploration/Returns Min           -62.1871
exploration/Actions Mean           -0.00532748
exploration/Actions Std             0.2306
exploration/Actions Max             0.997034
exploration/Actions Min            -0.998841
exploration/Num Paths               5
exploration/Average Returns       -27.4938
evaluation/num steps total     306000
evaluation/num paths total       3060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.339569
evaluation/Rewards Std              1.20652
evaluation/Rewards Max             -0.0430289
evaluation/Rewards Min            -11.9699
evaluation/Returns Mean           -33.9569
evaluation/Returns Std             16.641
evaluation/Returns Max             -7.41388
evaluation/Returns Min            -65.4957
evaluation/Actions Mean            -0.0143504
evaluation/Actions Std              0.210925
evaluation/Actions Max              0.998149
evaluation/Actions Min             -0.998964
evaluation/Num Paths               15
evaluation/Average Returns        -33.9569
time/data storing (s)               0.00450201
time/evaluation sampling (s)        0.358836
time/exploration sampling (s)       0.165473
time/logging (s)                    0.00509935
time/saving (s)                     0.00211999
time/training (s)                   2.15716
time/epoch (s)                      2.69319
time/total (s)                    551.822
Epoch                             203
-----------------------------  ---------------
2019-04-22 21:47:15.662521 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 204 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.60547
trainer/QF2 Loss                    1.61365
trainer/Policy Loss                 9.70227
trainer/Q1 Predictions Mean        -7.77677
trainer/Q1 Predictions Std          4.9386
trainer/Q1 Predictions Max         -5.90228
trainer/Q1 Predictions Min        -47.0769
trainer/Q2 Predictions Mean        -7.77879
trainer/Q2 Predictions Std          4.94509
trainer/Q2 Predictions Max         -5.90987
trainer/Q2 Predictions Min        -47.5561
trainer/Q Targets Mean             -7.65746
trainer/Q Targets Std               5.08183
trainer/Q Targets Max              -0.0682353
trainer/Q Targets Min             -47.179
trainer/Log Pis Mean                1.97803
trainer/Log Pis Std                 1.19314
trainer/Log Pis Max                 5.68354
trainer/Log Pis Min                -2.20102
trainer/Policy mu Mean              0.00158548
trainer/Policy mu Std               0.596434
trainer/Policy mu Max               3.33414
trainer/Policy mu Min              -2.48181
trainer/Policy log std Mean        -2.17798
trainer/Policy log std Std          0.430581
trainer/Policy log std Max         -0.587354
trainer/Policy log std Min         -2.58864
trainer/Alpha                       0.0617732
trainer/Alpha Loss                 -0.0611637
exploration/num steps total    102700
exploration/num paths total      1027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.300749
exploration/Rewards Std             0.921263
exploration/Rewards Max            -0.00649022
exploration/Rewards Min            -8.79752
exploration/Returns Mean          -30.0749
exploration/Returns Std            11.2235
exploration/Returns Max           -16.608
exploration/Returns Min           -50.3215
exploration/Actions Mean           -0.0301176
exploration/Actions Std             0.232421
exploration/Actions Max             0.995845
exploration/Actions Min            -0.9999
exploration/Num Paths               5
exploration/Average Returns       -30.0749
evaluation/num steps total     307500
evaluation/num paths total       3075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22432
evaluation/Rewards Std              0.995595
evaluation/Rewards Max             -0.00164293
evaluation/Rewards Min            -10.1038
evaluation/Returns Mean           -22.432
evaluation/Returns Std             13.6223
evaluation/Returns Max             -1.53956
evaluation/Returns Min            -44.1444
evaluation/Actions Mean             0.00392352
evaluation/Actions Std              0.199562
evaluation/Actions Max              0.995578
evaluation/Actions Min             -0.997884
evaluation/Num Paths               15
evaluation/Average Returns        -22.432
time/data storing (s)               0.00315962
time/evaluation sampling (s)        0.363676
time/exploration sampling (s)       0.16538
time/logging (s)                    0.00475868
time/saving (s)                     0.00212816
time/training (s)                   2.11709
time/epoch (s)                      2.65619
time/total (s)                    554.482
Epoch                             204
-----------------------------  ---------------
2019-04-22 21:47:18.342487 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 205 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0247176
trainer/QF2 Loss                    0.0240088
trainer/Policy Loss                 9.82295
trainer/Q1 Predictions Mean        -7.83867
trainer/Q1 Predictions Std          4.05618
trainer/Q1 Predictions Max         -6.00769
trainer/Q1 Predictions Min        -39.6989
trainer/Q2 Predictions Mean        -7.81859
trainer/Q2 Predictions Std          4.04733
trainer/Q2 Predictions Max         -5.99917
trainer/Q2 Predictions Min        -39.7657
trainer/Q Targets Mean             -7.88613
trainer/Q Targets Std               4.02113
trainer/Q Targets Max              -5.93815
trainer/Q Targets Min             -39.9652
trainer/Log Pis Mean                2.0605
trainer/Log Pis Std                 1.33894
trainer/Log Pis Max                 8.69325
trainer/Log Pis Min                -3.63773
trainer/Policy mu Mean             -0.0267616
trainer/Policy mu Std               0.678101
trainer/Policy mu Max               2.82087
trainer/Policy mu Min              -3.25101
trainer/Policy log std Mean        -2.13346
trainer/Policy log std Std          0.491184
trainer/Policy log std Max         -0.328348
trainer/Policy log std Min         -2.49357
trainer/Alpha                       0.0613439
trainer/Alpha Loss                  0.168878
exploration/num steps total    103200
exploration/num paths total      1032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.25098
exploration/Rewards Std             0.784143
exploration/Rewards Max            -0.00358726
exploration/Rewards Min            -8.82892
exploration/Returns Mean          -25.098
exploration/Returns Std            13.9668
exploration/Returns Max           -12.0415
exploration/Returns Min           -48.3384
exploration/Actions Mean            0.00762301
exploration/Actions Std             0.213074
exploration/Actions Max             0.999393
exploration/Actions Min            -0.992998
exploration/Num Paths               5
exploration/Average Returns       -25.098
evaluation/num steps total     309000
evaluation/num paths total       3090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247661
evaluation/Rewards Std              1.03733
evaluation/Rewards Max             -0.0184
evaluation/Rewards Min             -9.95657
evaluation/Returns Mean           -24.7661
evaluation/Returns Std             14.7983
evaluation/Returns Max             -5.25429
evaluation/Returns Min            -55.265
evaluation/Actions Mean             0.00267455
evaluation/Actions Std              0.203591
evaluation/Actions Max              0.998417
evaluation/Actions Min             -0.997689
evaluation/Num Paths               15
evaluation/Average Returns        -24.7661
time/data storing (s)               0.00303143
time/evaluation sampling (s)        0.365769
time/exploration sampling (s)       0.170982
time/logging (s)                    0.00492874
time/saving (s)                     0.00206892
time/training (s)                   2.12599
time/epoch (s)                      2.67277
time/total (s)                    557.159
Epoch                             205
-----------------------------  ---------------
2019-04-22 21:47:21.044498 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 206 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.627698
trainer/QF2 Loss                    0.624787
trainer/Policy Loss                 9.31153
trainer/Q1 Predictions Mean        -7.39667
trainer/Q1 Predictions Std          3.43938
trainer/Q1 Predictions Max         -5.96985
trainer/Q1 Predictions Min        -33.9058
trainer/Q2 Predictions Mean        -7.43677
trainer/Q2 Predictions Std          3.43406
trainer/Q2 Predictions Max         -6.05273
trainer/Q2 Predictions Min        -33.6709
trainer/Q Targets Mean             -7.45087
trainer/Q Targets Std               3.50435
trainer/Q Targets Max              -0.12132
trainer/Q Targets Min             -33.4772
trainer/Log Pis Mean                1.95322
trainer/Log Pis Std                 1.21533
trainer/Log Pis Max                 4.98276
trainer/Log Pis Min                -2.07119
trainer/Policy mu Mean              0.0465132
trainer/Policy mu Std               0.434754
trainer/Policy mu Max               3.0459
trainer/Policy mu Min              -1.08972
trainer/Policy log std Mean        -2.28308
trainer/Policy log std Std          0.351041
trainer/Policy log std Max         -0.641223
trainer/Policy log std Min         -2.65077
trainer/Alpha                       0.0614206
trainer/Alpha Loss                 -0.130505
exploration/num steps total    103700
exploration/num paths total      1037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.508899
exploration/Rewards Std             1.51639
exploration/Rewards Max            -0.00976504
exploration/Rewards Min           -10.9349
exploration/Returns Mean          -50.8899
exploration/Returns Std            11.593
exploration/Returns Max           -31.1727
exploration/Returns Min           -62.3493
exploration/Actions Mean           -0.00966704
exploration/Actions Std             0.282431
exploration/Actions Max             0.997937
exploration/Actions Min            -0.998534
exploration/Num Paths               5
exploration/Average Returns       -50.8899
evaluation/num steps total     310500
evaluation/num paths total       3105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224542
evaluation/Rewards Std              0.90969
evaluation/Rewards Max             -0.0087212
evaluation/Rewards Min             -9.90904
evaluation/Returns Mean           -22.4542
evaluation/Returns Std             15.8094
evaluation/Returns Max             -5.8254
evaluation/Returns Min            -58.5965
evaluation/Actions Mean             0.0130342
evaluation/Actions Std              0.189636
evaluation/Actions Max              0.997673
evaluation/Actions Min             -0.996257
evaluation/Num Paths               15
evaluation/Average Returns        -22.4542
time/data storing (s)               0.00308674
time/evaluation sampling (s)        0.361562
time/exploration sampling (s)       0.163877
time/logging (s)                    0.00519418
time/saving (s)                     0.00228214
time/training (s)                   2.15835
time/epoch (s)                      2.69435
time/total (s)                    559.858
Epoch                             206
-----------------------------  ---------------
2019-04-22 21:47:23.772512 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 207 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0172111
trainer/QF2 Loss                    0.0149927
trainer/Policy Loss                 9.48649
trainer/Q1 Predictions Mean        -7.46732
trainer/Q1 Predictions Std          4.81415
trainer/Q1 Predictions Max         -5.92811
trainer/Q1 Predictions Min        -53.1506
trainer/Q2 Predictions Mean        -7.45672
trainer/Q2 Predictions Std          4.8316
trainer/Q2 Predictions Max         -5.92838
trainer/Q2 Predictions Min        -53.3593
trainer/Q Targets Mean             -7.51088
trainer/Q Targets Std               4.8156
trainer/Q Targets Max              -5.83087
trainer/Q Targets Min             -53.1177
trainer/Log Pis Mean                2.11703
trainer/Log Pis Std                 1.06993
trainer/Log Pis Max                 4.37367
trainer/Log Pis Min                -2.90523
trainer/Policy mu Mean             -0.0152053
trainer/Policy mu Std               0.53902
trainer/Policy mu Max               3.3717
trainer/Policy mu Min              -2.70717
trainer/Policy log std Mean        -2.25641
trainer/Policy log std Std          0.382968
trainer/Policy log std Max         -0.528788
trainer/Policy log std Min         -2.56891
trainer/Alpha                       0.0646216
trainer/Alpha Loss                  0.320566
exploration/num steps total    104200
exploration/num paths total      1042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281203
exploration/Rewards Std             0.933066
exploration/Rewards Max            -0.00349977
exploration/Rewards Min            -9.23393
exploration/Returns Mean          -28.1203
exploration/Returns Std            15.6759
exploration/Returns Max           -12.3546
exploration/Returns Min           -48.9201
exploration/Actions Mean            0.0187081
exploration/Actions Std             0.228318
exploration/Actions Max             0.998443
exploration/Actions Min            -0.999419
exploration/Num Paths               5
exploration/Average Returns       -28.1203
evaluation/num steps total     312000
evaluation/num paths total       3120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270996
evaluation/Rewards Std              1.12575
evaluation/Rewards Max             -0.0105538
evaluation/Rewards Min            -11.075
evaluation/Returns Mean           -27.0996
evaluation/Returns Std             15.9257
evaluation/Returns Max             -3.58353
evaluation/Returns Min            -57.1689
evaluation/Actions Mean            -0.00989903
evaluation/Actions Std              0.212481
evaluation/Actions Max              0.998111
evaluation/Actions Min             -0.997356
evaluation/Num Paths               15
evaluation/Average Returns        -27.0996
time/data storing (s)               0.00305513
time/evaluation sampling (s)        0.360345
time/exploration sampling (s)       0.165375
time/logging (s)                    0.00495824
time/saving (s)                     0.00221707
time/training (s)                   2.18377
time/epoch (s)                      2.71972
time/total (s)                    562.582
Epoch                             207
-----------------------------  ---------------
2019-04-22 21:47:26.416948 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 208 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.413509
trainer/QF2 Loss                    0.414255
trainer/Policy Loss                 9.9538
trainer/Q1 Predictions Mean        -7.84587
trainer/Q1 Predictions Std          4.29325
trainer/Q1 Predictions Max         -5.88194
trainer/Q1 Predictions Min        -44.1357
trainer/Q2 Predictions Mean        -7.85256
trainer/Q2 Predictions Std          4.2435
trainer/Q2 Predictions Max         -5.92439
trainer/Q2 Predictions Min        -43.4715
trainer/Q Targets Mean             -7.79745
trainer/Q Targets Std               4.37042
trainer/Q Targets Max              -0.23875
trainer/Q Targets Min             -44.1272
trainer/Log Pis Mean                2.13888
trainer/Log Pis Std                 1.32034
trainer/Log Pis Max                 7.87061
trainer/Log Pis Min                -1.5385
trainer/Policy mu Mean             -0.0654649
trainer/Policy mu Std               0.61511
trainer/Policy mu Max               2.61297
trainer/Policy mu Min              -3.2009
trainer/Policy log std Mean        -2.19092
trainer/Policy log std Std          0.447193
trainer/Policy log std Max         -0.355191
trainer/Policy log std Min         -2.6031
trainer/Alpha                       0.0643328
trainer/Alpha Loss                  0.381037
exploration/num steps total    104700
exploration/num paths total      1047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.401673
exploration/Rewards Std             1.28008
exploration/Rewards Max            -0.00640452
exploration/Rewards Min           -11.0001
exploration/Returns Mean          -40.1673
exploration/Returns Std            19.333
exploration/Returns Max           -13.4935
exploration/Returns Min           -65.5577
exploration/Actions Mean           -0.0302837
exploration/Actions Std             0.246127
exploration/Actions Max             0.999014
exploration/Actions Min            -0.99954
exploration/Num Paths               5
exploration/Average Returns       -40.1673
evaluation/num steps total     313500
evaluation/num paths total       3135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.280714
evaluation/Rewards Std              1.14365
evaluation/Rewards Max             -0.0116258
evaluation/Rewards Min            -11.6068
evaluation/Returns Mean           -28.0714
evaluation/Returns Std             14.6446
evaluation/Returns Max             -3.52218
evaluation/Returns Min            -61.5939
evaluation/Actions Mean             0.00357017
evaluation/Actions Std              0.217912
evaluation/Actions Max              0.996992
evaluation/Actions Min             -0.998799
evaluation/Num Paths               15
evaluation/Average Returns        -28.0714
time/data storing (s)               0.00295325
time/evaluation sampling (s)        0.364196
time/exploration sampling (s)       0.162967
time/logging (s)                    0.00495091
time/saving (s)                     0.00204157
time/training (s)                   2.09917
time/epoch (s)                      2.63628
time/total (s)                    565.223
Epoch                             208
-----------------------------  ---------------
2019-04-22 21:47:29.109510 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 209 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0187606
trainer/QF2 Loss                    0.0194479
trainer/Policy Loss                 9.11648
trainer/Q1 Predictions Mean        -7.12943
trainer/Q1 Predictions Std          2.08792
trainer/Q1 Predictions Max         -5.69137
trainer/Q1 Predictions Min        -23.2807
trainer/Q2 Predictions Mean        -7.1257
trainer/Q2 Predictions Std          2.10305
trainer/Q2 Predictions Max         -5.70552
trainer/Q2 Predictions Min        -23.5641
trainer/Q Targets Mean             -7.15522
trainer/Q Targets Std               2.05818
trainer/Q Targets Max              -5.83377
trainer/Q Targets Min             -23.1595
trainer/Log Pis Mean                2.01694
trainer/Log Pis Std                 1.14061
trainer/Log Pis Max                 7.17304
trainer/Log Pis Min                -1.00209
trainer/Policy mu Mean              0.0226417
trainer/Policy mu Std               0.33497
trainer/Policy mu Max               2.70317
trainer/Policy mu Min              -2.6312
trainer/Policy log std Mean        -2.34539
trainer/Policy log std Std          0.253617
trainer/Policy log std Max         -0.64272
trainer/Policy log std Min         -2.63209
trainer/Alpha                       0.0642767
trainer/Alpha Loss                  0.046494
exploration/num steps total    105200
exploration/num paths total      1052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.181732
exploration/Rewards Std             0.435189
exploration/Rewards Max            -0.00272569
exploration/Rewards Min            -5.05518
exploration/Returns Mean          -18.1732
exploration/Returns Std             5.04914
exploration/Returns Max           -13.5487
exploration/Returns Min           -26.7216
exploration/Actions Mean           -0.00525143
exploration/Actions Std             0.199981
exploration/Actions Max             0.986632
exploration/Actions Min            -0.994821
exploration/Num Paths               5
exploration/Average Returns       -18.1732
evaluation/num steps total     315000
evaluation/num paths total       3150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231448
evaluation/Rewards Std              0.989502
evaluation/Rewards Max             -0.0231576
evaluation/Rewards Min            -11.0529
evaluation/Returns Mean           -23.1448
evaluation/Returns Std             16.4899
evaluation/Returns Max             -3.65213
evaluation/Returns Min            -58.6251
evaluation/Actions Mean            -0.0166033
evaluation/Actions Std              0.195477
evaluation/Actions Max              0.998065
evaluation/Actions Min             -0.99758
evaluation/Num Paths               15
evaluation/Average Returns        -23.1448
time/data storing (s)               0.00296189
time/evaluation sampling (s)        0.348318
time/exploration sampling (s)       0.156556
time/logging (s)                    0.00500097
time/saving (s)                     0.00224069
time/training (s)                   2.16972
time/epoch (s)                      2.6848
time/total (s)                    567.912
Epoch                             209
-----------------------------  ---------------
2019-04-22 21:47:31.785227 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 210 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.756407
trainer/QF2 Loss                    0.767075
trainer/Policy Loss                 9.72256
trainer/Q1 Predictions Mean        -7.61518
trainer/Q1 Predictions Std          3.54961
trainer/Q1 Predictions Max         -5.84704
trainer/Q1 Predictions Min        -30.1837
trainer/Q2 Predictions Mean        -7.61435
trainer/Q2 Predictions Std          3.56277
trainer/Q2 Predictions Max         -5.8221
trainer/Q2 Predictions Min        -29.9171
trainer/Q Targets Mean             -7.52913
trainer/Q Targets Std               3.6872
trainer/Q Targets Max              -0.18817
trainer/Q Targets Min             -30.2742
trainer/Log Pis Mean                2.12771
trainer/Log Pis Std                 1.41596
trainer/Log Pis Max                 7.64492
trainer/Log Pis Min                -3.58145
trainer/Policy mu Mean              0.0627585
trainer/Policy mu Std               0.622431
trainer/Policy mu Max               2.9584
trainer/Policy mu Min              -2.75251
trainer/Policy log std Mean        -2.21841
trainer/Policy log std Std          0.460272
trainer/Policy log std Max         -0.561445
trainer/Policy log std Min         -2.67179
trainer/Alpha                       0.0638952
trainer/Alpha Loss                  0.351277
exploration/num steps total    105700
exploration/num paths total      1057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.273267
exploration/Rewards Std             0.748407
exploration/Rewards Max            -0.00622199
exploration/Rewards Min            -7.0255
exploration/Returns Mean          -27.3267
exploration/Returns Std             6.8184
exploration/Returns Max           -19.1664
exploration/Returns Min           -38.6536
exploration/Actions Mean           -0.0173062
exploration/Actions Std             0.219013
exploration/Actions Max             0.999387
exploration/Actions Min            -0.998925
exploration/Num Paths               5
exploration/Average Returns       -27.3267
evaluation/num steps total     316500
evaluation/num paths total       3165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.246082
evaluation/Rewards Std              1.0136
evaluation/Rewards Max             -0.0120554
evaluation/Rewards Min            -11.2251
evaluation/Returns Mean           -24.6082
evaluation/Returns Std             13.9594
evaluation/Returns Max             -6.28896
evaluation/Returns Min            -56.3567
evaluation/Actions Mean            -0.016221
evaluation/Actions Std              0.200695
evaluation/Actions Max              0.993631
evaluation/Actions Min             -0.998642
evaluation/Num Paths               15
evaluation/Average Returns        -24.6082
time/data storing (s)               0.00305408
time/evaluation sampling (s)        0.361447
time/exploration sampling (s)       0.16372
time/logging (s)                    0.00505405
time/saving (s)                     0.0020658
time/training (s)                   2.13257
time/epoch (s)                      2.66791
time/total (s)                    570.585
Epoch                             210
-----------------------------  ---------------
2019-04-22 21:47:34.482315 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 211 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.753499
trainer/QF2 Loss                    0.743229
trainer/Policy Loss                 9.17637
trainer/Q1 Predictions Mean        -7.18324
trainer/Q1 Predictions Std          1.53985
trainer/Q1 Predictions Max         -5.83749
trainer/Q1 Predictions Min        -17.6764
trainer/Q2 Predictions Mean        -7.17196
trainer/Q2 Predictions Std          1.53996
trainer/Q2 Predictions Max         -5.80176
trainer/Q2 Predictions Min        -17.7176
trainer/Q Targets Mean             -7.07807
trainer/Q Targets Std               1.83975
trainer/Q Targets Max              -0.0673879
trainer/Q Targets Min             -17.7682
trainer/Log Pis Mean                2.03852
trainer/Log Pis Std                 1.07622
trainer/Log Pis Max                 7.42846
trainer/Log Pis Min                -1.98218
trainer/Policy mu Mean             -0.0428332
trainer/Policy mu Std               0.473156
trainer/Policy mu Max               2.54296
trainer/Policy mu Min              -2.56239
trainer/Policy log std Mean        -2.26001
trainer/Policy log std Std          0.322452
trainer/Policy log std Max         -0.713651
trainer/Policy log std Min         -2.58533
trainer/Alpha                       0.0638781
trainer/Alpha Loss                  0.105954
exploration/num steps total    106200
exploration/num paths total      1062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.240369
exploration/Rewards Std             0.7341
exploration/Rewards Max            -0.00952681
exploration/Rewards Min            -9.13951
exploration/Returns Mean          -24.0369
exploration/Returns Std            10.7492
exploration/Returns Max           -16.9846
exploration/Returns Min           -45.4221
exploration/Actions Mean           -0.0109143
exploration/Actions Std             0.21667
exploration/Actions Max             0.997902
exploration/Actions Min            -0.99771
exploration/Num Paths               5
exploration/Average Returns       -24.0369
evaluation/num steps total     318000
evaluation/num paths total       3180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.216037
evaluation/Rewards Std              0.939303
evaluation/Rewards Max             -0.0242647
evaluation/Rewards Min             -9.41618
evaluation/Returns Mean           -21.6037
evaluation/Returns Std             14.2451
evaluation/Returns Max             -4.24301
evaluation/Returns Min            -52.6794
evaluation/Actions Mean            -0.000199285
evaluation/Actions Std              0.187536
evaluation/Actions Max              0.997798
evaluation/Actions Min             -0.997941
evaluation/Num Paths               15
evaluation/Average Returns        -21.6037
time/data storing (s)               0.00322064
time/evaluation sampling (s)        0.352994
time/exploration sampling (s)       0.160785
time/logging (s)                    0.00509214
time/saving (s)                     0.00220154
time/training (s)                   2.1646
time/epoch (s)                      2.68889
time/total (s)                    573.278
Epoch                             211
-----------------------------  ----------------
2019-04-22 21:47:37.154616 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.70669
trainer/QF2 Loss                    0.707409
trainer/Policy Loss                 9.03868
trainer/Q1 Predictions Mean        -7.04511
trainer/Q1 Predictions Std          2.34527
trainer/Q1 Predictions Max         -5.79878
trainer/Q1 Predictions Min        -21.9297
trainer/Q2 Predictions Mean        -7.07081
trainer/Q2 Predictions Std          2.3614
trainer/Q2 Predictions Max         -5.83086
trainer/Q2 Predictions Min        -21.9035
trainer/Q Targets Mean             -6.99909
trainer/Q Targets Std               2.53893
trainer/Q Targets Max              -0.151763
trainer/Q Targets Min             -21.8907
trainer/Log Pis Mean                2.01347
trainer/Log Pis Std                 0.858564
trainer/Log Pis Max                 5.31057
trainer/Log Pis Min                -0.402477
trainer/Policy mu Mean              0.0516315
trainer/Policy mu Std               0.465531
trainer/Policy mu Max               2.8373
trainer/Policy mu Min              -2.62086
trainer/Policy log std Mean        -2.25375
trainer/Policy log std Std          0.34081
trainer/Policy log std Max         -0.559367
trainer/Policy log std Min         -2.56063
trainer/Alpha                       0.0635853
trainer/Alpha Loss                  0.0371224
exploration/num steps total    106700
exploration/num paths total      1067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.35305
exploration/Rewards Std             1.06392
exploration/Rewards Max            -0.00703971
exploration/Rewards Min           -10.3706
exploration/Returns Mean          -35.305
exploration/Returns Std            20.5814
exploration/Returns Max           -14.7528
exploration/Returns Min           -72.6272
exploration/Actions Mean            0.016471
exploration/Actions Std             0.231985
exploration/Actions Max             0.999386
exploration/Actions Min            -0.99496
exploration/Num Paths               5
exploration/Average Returns       -35.305
evaluation/num steps total     319500
evaluation/num paths total       3195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228531
evaluation/Rewards Std              0.873983
evaluation/Rewards Max             -0.0565324
evaluation/Rewards Min             -9.91474
evaluation/Returns Mean           -22.8531
evaluation/Returns Std             15.5049
evaluation/Returns Max             -7.69925
evaluation/Returns Min            -52.4039
evaluation/Actions Mean            -0.00498626
evaluation/Actions Std              0.181216
evaluation/Actions Max              0.99742
evaluation/Actions Min             -0.997181
evaluation/Num Paths               15
evaluation/Average Returns        -22.8531
time/data storing (s)               0.00314798
time/evaluation sampling (s)        0.355289
time/exploration sampling (s)       0.15826
time/logging (s)                    0.00491016
time/saving (s)                     0.00187938
time/training (s)                   2.14055
time/epoch (s)                      2.66403
time/total (s)                    575.946
Epoch                             212
-----------------------------  ---------------
2019-04-22 21:47:39.807765 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 213 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0256369
trainer/QF2 Loss                    0.021463
trainer/Policy Loss                 9.20397
trainer/Q1 Predictions Mean        -7.0071
trainer/Q1 Predictions Std          2.34895
trainer/Q1 Predictions Max         -5.85559
trainer/Q1 Predictions Min        -24.9537
trainer/Q2 Predictions Mean        -7.01262
trainer/Q2 Predictions Std          2.31487
trainer/Q2 Predictions Max         -5.8826
trainer/Q2 Predictions Min        -24.465
trainer/Q Targets Mean             -7.08172
trainer/Q Targets Std               2.29929
trainer/Q Targets Max              -5.76693
trainer/Q Targets Min             -24.3382
trainer/Log Pis Mean                2.27023
trainer/Log Pis Std                 0.963346
trainer/Log Pis Max                 5.02647
trainer/Log Pis Min                -1.20015
trainer/Policy mu Mean             -0.00729912
trainer/Policy mu Std               0.438884
trainer/Policy mu Max               2.76532
trainer/Policy mu Min              -2.82461
trainer/Policy log std Mean        -2.32653
trainer/Policy log std Std          0.320878
trainer/Policy log std Max         -0.695821
trainer/Policy log std Min         -2.59694
trainer/Alpha                       0.0618313
trainer/Alpha Loss                  0.752152
exploration/num steps total    107200
exploration/num paths total      1072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.355457
exploration/Rewards Std             1.07318
exploration/Rewards Max            -0.00357772
exploration/Rewards Min            -8.77543
exploration/Returns Mean          -35.5457
exploration/Returns Std            10.86
exploration/Returns Max           -17.1342
exploration/Returns Min           -50.5768
exploration/Actions Mean           -0.0129652
exploration/Actions Std             0.236509
exploration/Actions Max             0.99912
exploration/Actions Min            -0.999255
exploration/Num Paths               5
exploration/Average Returns       -35.5457
evaluation/num steps total     321000
evaluation/num paths total       3210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.200195
evaluation/Rewards Std              0.946794
evaluation/Rewards Max             -0.00788393
evaluation/Rewards Min             -9.43708
evaluation/Returns Mean           -20.0195
evaluation/Returns Std             15.0741
evaluation/Returns Max             -3.74928
evaluation/Returns Min            -51.0015
evaluation/Actions Mean             0.0102507
evaluation/Actions Std              0.189786
evaluation/Actions Max              0.997307
evaluation/Actions Min             -0.99641
evaluation/Num Paths               15
evaluation/Average Returns        -20.0195
time/data storing (s)               0.00296793
time/evaluation sampling (s)        0.362049
time/exploration sampling (s)       0.16177
time/logging (s)                    0.00387289
time/saving (s)                     0.00198773
time/training (s)                   2.11185
time/epoch (s)                      2.6445
time/total (s)                    578.595
Epoch                             213
-----------------------------  ---------------
2019-04-22 21:47:42.495085 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 214 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0318748
trainer/QF2 Loss                    0.0307525
trainer/Policy Loss                 9.07604
trainer/Q1 Predictions Mean        -6.9722
trainer/Q1 Predictions Std          2.66355
trainer/Q1 Predictions Max         -5.71101
trainer/Q1 Predictions Min        -26.7385
trainer/Q2 Predictions Mean        -6.97039
trainer/Q2 Predictions Std          2.66596
trainer/Q2 Predictions Max         -5.72747
trainer/Q2 Predictions Min        -26.5614
trainer/Q Targets Mean             -7.11298
trainer/Q Targets Std               2.62466
trainer/Q Targets Max              -5.78382
trainer/Q Targets Min             -26.3995
trainer/Log Pis Mean                2.14827
trainer/Log Pis Std                 0.969923
trainer/Log Pis Max                 4.78463
trainer/Log Pis Min                -1.1903
trainer/Policy mu Mean             -0.032764
trainer/Policy mu Std               0.47429
trainer/Policy mu Max               2.85247
trainer/Policy mu Min              -2.83778
trainer/Policy log std Mean        -2.2902
trainer/Policy log std Std          0.372381
trainer/Policy log std Max         -0.57794
trainer/Policy log std Min         -2.60537
trainer/Alpha                       0.0615371
trainer/Alpha Loss                  0.413388
exploration/num steps total    107700
exploration/num paths total      1077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.469527
exploration/Rewards Std             1.39637
exploration/Rewards Max            -0.00441657
exploration/Rewards Min           -10.1193
exploration/Returns Mean          -46.9527
exploration/Returns Std            11.6969
exploration/Returns Max           -31.7332
exploration/Returns Min           -61.2683
exploration/Actions Mean            0.0269351
exploration/Actions Std             0.269704
exploration/Actions Max             0.999538
exploration/Actions Min            -0.996635
exploration/Num Paths               5
exploration/Average Returns       -46.9527
evaluation/num steps total     322500
evaluation/num paths total       3225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.206838
evaluation/Rewards Std              0.922463
evaluation/Rewards Max             -0.0136127
evaluation/Rewards Min             -9.55131
evaluation/Returns Mean           -20.6838
evaluation/Returns Std             15.5064
evaluation/Returns Max             -5.77822
evaluation/Returns Min            -53.8452
evaluation/Actions Mean            -0.00170328
evaluation/Actions Std              0.191336
evaluation/Actions Max              0.998116
evaluation/Actions Min             -0.996834
evaluation/Num Paths               15
evaluation/Average Returns        -20.6838
time/data storing (s)               0.00295134
time/evaluation sampling (s)        0.388923
time/exploration sampling (s)       0.156072
time/logging (s)                    0.00511291
time/saving (s)                     0.0107784
time/training (s)                   2.11639
time/epoch (s)                      2.68022
time/total (s)                    581.28
Epoch                             214
-----------------------------  ---------------
2019-04-22 21:47:45.169998 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 215 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0183106
trainer/QF2 Loss                    0.0218713
trainer/Policy Loss                10.071
trainer/Q1 Predictions Mean        -7.80832
trainer/Q1 Predictions Std          5.29668
trainer/Q1 Predictions Max         -5.81383
trainer/Q1 Predictions Min        -47.958
trainer/Q2 Predictions Mean        -7.79967
trainer/Q2 Predictions Std          5.25455
trainer/Q2 Predictions Max         -5.8294
trainer/Q2 Predictions Min        -47.8287
trainer/Q Targets Mean             -7.87898
trainer/Q Targets Std               5.27617
trainer/Q Targets Max              -5.79029
trainer/Q Targets Min             -47.6981
trainer/Log Pis Mean                2.3352
trainer/Log Pis Std                 1.30026
trainer/Log Pis Max                 7.78701
trainer/Log Pis Min                -0.373946
trainer/Policy mu Mean              0.0457566
trainer/Policy mu Std               0.673655
trainer/Policy mu Max               3.56577
trainer/Policy mu Min              -2.9486
trainer/Policy log std Mean        -2.20483
trainer/Policy log std Std          0.449427
trainer/Policy log std Max         -0.49146
trainer/Policy log std Min         -2.48033
trainer/Alpha                       0.059613
trainer/Alpha Loss                  0.945263
exploration/num steps total    108200
exploration/num paths total      1082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.291658
exploration/Rewards Std             0.862814
exploration/Rewards Max            -0.00120994
exploration/Rewards Min            -8.31048
exploration/Returns Mean          -29.1658
exploration/Returns Std            10.5835
exploration/Returns Max           -15.594
exploration/Returns Min           -43.9411
exploration/Actions Mean           -0.000776775
exploration/Actions Std             0.244069
exploration/Actions Max             0.999432
exploration/Actions Min            -0.995243
exploration/Num Paths               5
exploration/Average Returns       -29.1658
evaluation/num steps total     324000
evaluation/num paths total       3240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.271786
evaluation/Rewards Std              1.05008
evaluation/Rewards Max             -0.00389326
evaluation/Rewards Min            -10.3558
evaluation/Returns Mean           -27.1786
evaluation/Returns Std             15.6175
evaluation/Returns Max             -7.31432
evaluation/Returns Min            -58.5996
evaluation/Actions Mean             0.0106657
evaluation/Actions Std              0.202333
evaluation/Actions Max              0.999156
evaluation/Actions Min             -0.996363
evaluation/Num Paths               15
evaluation/Average Returns        -27.1786
time/data storing (s)               0.00314802
time/evaluation sampling (s)        0.352115
time/exploration sampling (s)       0.160145
time/logging (s)                    0.00489458
time/saving (s)                     0.002098
time/training (s)                   2.14387
time/epoch (s)                      2.66627
time/total (s)                    583.951
Epoch                             215
-----------------------------  ----------------
2019-04-22 21:47:47.881617 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 216 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.66089
trainer/QF2 Loss                    1.6651
trainer/Policy Loss                10.8746
trainer/Q1 Predictions Mean        -8.61526
trainer/Q1 Predictions Std          8.37617
trainer/Q1 Predictions Max         -5.80269
trainer/Q1 Predictions Min        -57.9168
trainer/Q2 Predictions Mean        -8.63138
trainer/Q2 Predictions Std          8.42224
trainer/Q2 Predictions Max         -5.79251
trainer/Q2 Predictions Min        -58.5841
trainer/Q Targets Mean             -8.36221
trainer/Q Targets Std               8.57843
trainer/Q Targets Max              -0.124118
trainer/Q Targets Min             -58.9169
trainer/Log Pis Mean                2.28038
trainer/Log Pis Std                 1.57247
trainer/Log Pis Max                10.2106
trainer/Log Pis Min                -2.44528
trainer/Policy mu Mean             -0.0338853
trainer/Policy mu Std               0.668785
trainer/Policy mu Max               3.89595
trainer/Policy mu Min              -3.44993
trainer/Policy log std Mean        -2.22263
trainer/Policy log std Std          0.417331
trainer/Policy log std Max         -0.306579
trainer/Policy log std Min         -2.51269
trainer/Alpha                       0.0606056
trainer/Alpha Loss                  0.786021
exploration/num steps total    108700
exploration/num paths total      1087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.261399
exploration/Rewards Std             0.768284
exploration/Rewards Max            -0.00353159
exploration/Rewards Min            -7.83212
exploration/Returns Mean          -26.1399
exploration/Returns Std            10.3498
exploration/Returns Max           -13.5426
exploration/Returns Min           -39.2607
exploration/Actions Mean           -0.00922311
exploration/Actions Std             0.225857
exploration/Actions Max             0.998028
exploration/Actions Min            -0.998331
exploration/Num Paths               5
exploration/Average Returns       -26.1399
evaluation/num steps total     325500
evaluation/num paths total       3255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224577
evaluation/Rewards Std              0.949939
evaluation/Rewards Max             -0.0193652
evaluation/Rewards Min             -9.71343
evaluation/Returns Mean           -22.4577
evaluation/Returns Std             14.8977
evaluation/Returns Max             -4.33864
evaluation/Returns Min            -49.4071
evaluation/Actions Mean             0.00701009
evaluation/Actions Std              0.196176
evaluation/Actions Max              0.997968
evaluation/Actions Min             -0.997488
evaluation/Num Paths               15
evaluation/Average Returns        -22.4577
time/data storing (s)               0.00304899
time/evaluation sampling (s)        0.361189
time/exploration sampling (s)       0.161189
time/logging (s)                    0.00483912
time/saving (s)                     0.00164224
time/training (s)                   2.17112
time/epoch (s)                      2.70303
time/total (s)                    586.659
Epoch                             216
-----------------------------  ---------------
2019-04-22 21:47:50.567546 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 217 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.28375
trainer/QF2 Loss                    1.27938
trainer/Policy Loss                 9.62421
trainer/Q1 Predictions Mean        -7.55551
trainer/Q1 Predictions Std          3.93383
trainer/Q1 Predictions Max         -5.75505
trainer/Q1 Predictions Min        -31.1718
trainer/Q2 Predictions Mean        -7.54541
trainer/Q2 Predictions Std          3.93234
trainer/Q2 Predictions Max         -5.73313
trainer/Q2 Predictions Min        -31.038
trainer/Q Targets Mean             -7.44773
trainer/Q Targets Std               4.10964
trainer/Q Targets Max              -0.153822
trainer/Q Targets Min             -31.1079
trainer/Log Pis Mean                2.12407
trainer/Log Pis Std                 0.882682
trainer/Log Pis Max                 4.83758
trainer/Log Pis Min                -0.629699
trainer/Policy mu Mean             -0.0228147
trainer/Policy mu Std               0.548627
trainer/Policy mu Max               3.07121
trainer/Policy mu Min              -2.91016
trainer/Policy log std Mean        -2.20045
trainer/Policy log std Std          0.385895
trainer/Policy log std Max         -0.573862
trainer/Policy log std Min         -2.49622
trainer/Alpha                       0.0610248
trainer/Alpha Loss                  0.346926
exploration/num steps total    109200
exploration/num paths total      1092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.405753
exploration/Rewards Std             1.22486
exploration/Rewards Max            -0.00770836
exploration/Rewards Min           -10.7052
exploration/Returns Mean          -40.5753
exploration/Returns Std            18.0264
exploration/Returns Max           -13.3992
exploration/Returns Min           -61.0258
exploration/Actions Mean            0.000857966
exploration/Actions Std             0.250626
exploration/Actions Max             0.99869
exploration/Actions Min            -0.999175
exploration/Num Paths               5
exploration/Average Returns       -40.5753
evaluation/num steps total     327000
evaluation/num paths total       3270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.290075
evaluation/Rewards Std              1.05376
evaluation/Rewards Max             -0.0235976
evaluation/Rewards Min            -10.1723
evaluation/Returns Mean           -29.0075
evaluation/Returns Std             17.9275
evaluation/Returns Max             -4.61591
evaluation/Returns Min            -59.9203
evaluation/Actions Mean             0.00595803
evaluation/Actions Std              0.199109
evaluation/Actions Max              0.998242
evaluation/Actions Min             -0.997436
evaluation/Num Paths               15
evaluation/Average Returns        -29.0075
time/data storing (s)               0.00305603
time/evaluation sampling (s)        0.356849
time/exploration sampling (s)       0.164033
time/logging (s)                    0.00504265
time/saving (s)                     0.00208977
time/training (s)                   2.14654
time/epoch (s)                      2.67761
time/total (s)                    589.342
Epoch                             217
-----------------------------  ----------------
2019-04-22 21:47:53.294642 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 218 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0435883
trainer/QF2 Loss                    0.0410664
trainer/Policy Loss                 9.16684
trainer/Q1 Predictions Mean        -7.127
trainer/Q1 Predictions Std          4.31416
trainer/Q1 Predictions Max         -5.60926
trainer/Q1 Predictions Min        -44.6249
trainer/Q2 Predictions Mean        -7.13589
trainer/Q2 Predictions Std          4.31749
trainer/Q2 Predictions Max         -5.65582
trainer/Q2 Predictions Min        -44.8238
trainer/Q Targets Mean             -7.25479
trainer/Q Targets Std               4.22655
trainer/Q Targets Max              -5.74128
trainer/Q Targets Min             -44.1676
trainer/Log Pis Mean                2.05953
trainer/Log Pis Std                 1.13474
trainer/Log Pis Max                 6.43327
trainer/Log Pis Min                -1.24358
trainer/Policy mu Mean             -0.0231263
trainer/Policy mu Std               0.488291
trainer/Policy mu Max               3.3405
trainer/Policy mu Min              -2.76386
trainer/Policy log std Mean        -2.2718
trainer/Policy log std Std          0.327774
trainer/Policy log std Max         -0.601917
trainer/Policy log std Min         -2.52536
trainer/Alpha                       0.0623221
trainer/Alpha Loss                  0.165238
exploration/num steps total    109700
exploration/num paths total      1097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.438001
exploration/Rewards Std             1.31212
exploration/Rewards Max            -0.0103922
exploration/Rewards Min           -10.4688
exploration/Returns Mean          -43.8001
exploration/Returns Std             9.45215
exploration/Returns Max           -29.9174
exploration/Returns Min           -56.8909
exploration/Actions Mean           -0.0440554
exploration/Actions Std             0.255981
exploration/Actions Max             0.99664
exploration/Actions Min            -0.999352
exploration/Num Paths               5
exploration/Average Returns       -43.8001
evaluation/num steps total     328500
evaluation/num paths total       3285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213863
evaluation/Rewards Std              0.812123
evaluation/Rewards Max             -0.017405
evaluation/Rewards Min             -9.32584
evaluation/Returns Mean           -21.3863
evaluation/Returns Std             13.9933
evaluation/Returns Max             -6.80284
evaluation/Returns Min            -54.5043
evaluation/Actions Mean             0.00196786
evaluation/Actions Std              0.170816
evaluation/Actions Max              0.997458
evaluation/Actions Min             -0.996753
evaluation/Num Paths               15
evaluation/Average Returns        -21.3863
time/data storing (s)               0.00316802
time/evaluation sampling (s)        0.362663
time/exploration sampling (s)       0.166511
time/logging (s)                    0.0051274
time/saving (s)                     0.00171094
time/training (s)                   2.17956
time/epoch (s)                      2.71874
time/total (s)                    592.065
Epoch                             218
-----------------------------  ---------------
2019-04-22 21:47:55.952532 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 219 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.381268
trainer/QF2 Loss                    0.384622
trainer/Policy Loss                 9.39442
trainer/Q1 Predictions Mean        -7.3646
trainer/Q1 Predictions Std          2.9669
trainer/Q1 Predictions Max         -5.96105
trainer/Q1 Predictions Min        -28.8215
trainer/Q2 Predictions Mean        -7.36903
trainer/Q2 Predictions Std          2.99604
trainer/Q2 Predictions Max         -5.9894
trainer/Q2 Predictions Min        -28.7578
trainer/Q Targets Mean             -7.34627
trainer/Q Targets Std               3.07554
trainer/Q Targets Max              -0.132946
trainer/Q Targets Min             -28.9197
trainer/Log Pis Mean                2.06315
trainer/Log Pis Std                 1.36228
trainer/Log Pis Max                 6.84486
trainer/Log Pis Min                -3.62492
trainer/Policy mu Mean              0.0038714
trainer/Policy mu Std               0.56915
trainer/Policy mu Max               2.98446
trainer/Policy mu Min              -2.81506
trainer/Policy log std Mean        -2.23699
trainer/Policy log std Std          0.38624
trainer/Policy log std Max         -0.646325
trainer/Policy log std Min         -2.50513
trainer/Alpha                       0.0622637
trainer/Alpha Loss                  0.175328
exploration/num steps total    110200
exploration/num paths total      1102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.335615
exploration/Rewards Std             1.0681
exploration/Rewards Max            -0.00812089
exploration/Rewards Min            -8.82941
exploration/Returns Mean          -33.5615
exploration/Returns Std            15.9941
exploration/Returns Max           -13.5579
exploration/Returns Min           -51.4164
exploration/Actions Mean            0.0151425
exploration/Actions Std             0.241811
exploration/Actions Max             0.99761
exploration/Actions Min            -0.998676
exploration/Num Paths               5
exploration/Average Returns       -33.5615
evaluation/num steps total     330000
evaluation/num paths total       3300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.232975
evaluation/Rewards Std              1.05084
evaluation/Rewards Max             -0.0120966
evaluation/Rewards Min            -10.7052
evaluation/Returns Mean           -23.2975
evaluation/Returns Std             16.2282
evaluation/Returns Max             -3.44242
evaluation/Returns Min            -52.1425
evaluation/Actions Mean             0.00103697
evaluation/Actions Std              0.199694
evaluation/Actions Max              0.998579
evaluation/Actions Min             -0.997687
evaluation/Num Paths               15
evaluation/Average Returns        -23.2975
time/data storing (s)               0.00378392
time/evaluation sampling (s)        0.367991
time/exploration sampling (s)       0.164504
time/logging (s)                    0.00486239
time/saving (s)                     0.00228627
time/training (s)                   2.1065
time/epoch (s)                      2.64993
time/total (s)                    594.719
Epoch                             219
-----------------------------  ---------------
2019-04-22 21:47:58.662876 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 220 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.901073
trainer/QF2 Loss                    0.889903
trainer/Policy Loss                 8.76944
trainer/Q1 Predictions Mean        -7.06566
trainer/Q1 Predictions Std          2.02223
trainer/Q1 Predictions Max         -5.90541
trainer/Q1 Predictions Min        -21.5018
trainer/Q2 Predictions Mean        -7.05123
trainer/Q2 Predictions Std          2.03353
trainer/Q2 Predictions Max         -5.86646
trainer/Q2 Predictions Min        -21.471
trainer/Q Targets Mean             -6.93697
trainer/Q Targets Std               2.21875
trainer/Q Targets Max              -0.0970249
trainer/Q Targets Min             -21.292
trainer/Log Pis Mean                1.7266
trainer/Log Pis Std                 1.3209
trainer/Log Pis Max                 5.89822
trainer/Log Pis Min                -3.70533
trainer/Policy mu Mean             -0.0365238
trainer/Policy mu Std               0.524645
trainer/Policy mu Max               3.20911
trainer/Policy mu Min              -2.68208
trainer/Policy log std Mean        -2.24679
trainer/Policy log std Std          0.391
trainer/Policy log std Max         -0.367901
trainer/Policy log std Min         -2.54266
trainer/Alpha                       0.0600965
trainer/Alpha Loss                 -0.768666
exploration/num steps total    110700
exploration/num paths total      1107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281418
exploration/Rewards Std             0.872607
exploration/Rewards Max            -0.00367525
exploration/Rewards Min            -8.68911
exploration/Returns Mean          -28.1418
exploration/Returns Std            15.0518
exploration/Returns Max           -14.4786
exploration/Returns Min           -51.4545
exploration/Actions Mean           -0.0260709
exploration/Actions Std             0.207926
exploration/Actions Max             0.995734
exploration/Actions Min            -0.999333
exploration/Num Paths               5
exploration/Average Returns       -28.1418
evaluation/num steps total     331500
evaluation/num paths total       3315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.275594
evaluation/Rewards Std              1.02158
evaluation/Rewards Max             -0.0258069
evaluation/Rewards Min             -9.92819
evaluation/Returns Mean           -27.5594
evaluation/Returns Std             15.2955
evaluation/Returns Max            -11.4863
evaluation/Returns Min            -56.2652
evaluation/Actions Mean             0.007505
evaluation/Actions Std              0.198621
evaluation/Actions Max              0.99827
evaluation/Actions Min             -0.997829
evaluation/Num Paths               15
evaluation/Average Returns        -27.5594
time/data storing (s)               0.00301761
time/evaluation sampling (s)        0.362156
time/exploration sampling (s)       0.164878
time/logging (s)                    0.00491907
time/saving (s)                     0.00198677
time/training (s)                   2.16566
time/epoch (s)                      2.70262
time/total (s)                    597.426
Epoch                             220
-----------------------------  ---------------
2019-04-22 21:48:01.342951 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 221 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0208757
trainer/QF2 Loss                    0.021063
trainer/Policy Loss                 8.87528
trainer/Q1 Predictions Mean        -6.92312
trainer/Q1 Predictions Std          1.36413
trainer/Q1 Predictions Max         -5.77452
trainer/Q1 Predictions Min        -16.734
trainer/Q2 Predictions Mean        -6.91497
trainer/Q2 Predictions Std          1.37608
trainer/Q2 Predictions Max         -5.79631
trainer/Q2 Predictions Min        -17.1207
trainer/Q Targets Mean             -7.01285
trainer/Q Targets Std               1.39974
trainer/Q Targets Max              -5.87557
trainer/Q Targets Min             -17.166
trainer/Log Pis Mean                1.96899
trainer/Log Pis Std                 1.00113
trainer/Log Pis Max                 4.46551
trainer/Log Pis Min                -3.47327
trainer/Policy mu Mean             -0.0159425
trainer/Policy mu Std               0.379098
trainer/Policy mu Max               2.79231
trainer/Policy mu Min              -2.2144
trainer/Policy log std Mean        -2.24857
trainer/Policy log std Std          0.314995
trainer/Policy log std Max         -0.500409
trainer/Policy log std Min         -2.57228
trainer/Alpha                       0.0615572
trainer/Alpha Loss                 -0.0864487
exploration/num steps total    111200
exploration/num paths total      1112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297514
exploration/Rewards Std             0.874407
exploration/Rewards Max            -0.0084385
exploration/Rewards Min            -8.64749
exploration/Returns Mean          -29.7514
exploration/Returns Std            15.3542
exploration/Returns Max           -10.7744
exploration/Returns Min           -56.9394
exploration/Actions Mean            0.00550153
exploration/Actions Std             0.222688
exploration/Actions Max             0.999779
exploration/Actions Min            -0.997507
exploration/Num Paths               5
exploration/Average Returns       -29.7514
evaluation/num steps total     333000
evaluation/num paths total       3330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.210494
evaluation/Rewards Std              0.835425
evaluation/Rewards Max             -0.0110515
evaluation/Rewards Min             -9.24543
evaluation/Returns Mean           -21.0494
evaluation/Returns Std             13.3231
evaluation/Returns Max             -3.20024
evaluation/Returns Min            -47.1693
evaluation/Actions Mean             0.0103387
evaluation/Actions Std              0.184558
evaluation/Actions Max              0.996564
evaluation/Actions Min             -0.996327
evaluation/Num Paths               15
evaluation/Average Returns        -21.0494
time/data storing (s)               0.00347878
time/evaluation sampling (s)        0.36064
time/exploration sampling (s)       0.163481
time/logging (s)                    0.0049226
time/saving (s)                     0.00220504
time/training (s)                   2.1366
time/epoch (s)                      2.67133
time/total (s)                    600.102
Epoch                             221
-----------------------------  ---------------
2019-04-22 21:48:04.038758 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 222 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0841248
trainer/QF2 Loss                    0.0688396
trainer/Policy Loss                 9.28482
trainer/Q1 Predictions Mean        -7.43906
trainer/Q1 Predictions Std          4.78922
trainer/Q1 Predictions Max         -5.65352
trainer/Q1 Predictions Min        -47.2518
trainer/Q2 Predictions Mean        -7.45397
trainer/Q2 Predictions Std          4.89461
trainer/Q2 Predictions Max         -5.61762
trainer/Q2 Predictions Min        -48.1669
trainer/Q Targets Mean             -7.69166
trainer/Q Targets Std               4.86191
trainer/Q Targets Max              -5.80509
trainer/Q Targets Min             -48.2
trainer/Log Pis Mean                1.83179
trainer/Log Pis Std                 1.34129
trainer/Log Pis Max                 5.68544
trainer/Log Pis Min                -3.91857
trainer/Policy mu Mean             -0.00322122
trainer/Policy mu Std               0.602748
trainer/Policy mu Max               3.43551
trainer/Policy mu Min              -2.78304
trainer/Policy log std Mean        -2.22159
trainer/Policy log std Std          0.408274
trainer/Policy log std Max         -0.49761
trainer/Policy log std Min         -2.49127
trainer/Alpha                       0.0637966
trainer/Alpha Loss                 -0.46292
exploration/num steps total    111700
exploration/num paths total      1117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.326739
exploration/Rewards Std             1.08859
exploration/Rewards Max            -0.0131451
exploration/Rewards Min           -10.3977
exploration/Returns Mean          -32.6739
exploration/Returns Std            20.0484
exploration/Returns Max           -14.8017
exploration/Returns Min           -59.3402
exploration/Actions Mean            0.0139736
exploration/Actions Std             0.238644
exploration/Actions Max             0.999561
exploration/Actions Min            -0.996459
exploration/Num Paths               5
exploration/Average Returns       -32.6739
evaluation/num steps total     334500
evaluation/num paths total       3345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.191076
evaluation/Rewards Std              0.782377
evaluation/Rewards Max             -0.0268038
evaluation/Rewards Min             -7.57283
evaluation/Returns Mean           -19.1076
evaluation/Returns Std             10.4248
evaluation/Returns Max             -5.39593
evaluation/Returns Min            -35.7215
evaluation/Actions Mean             0.0158383
evaluation/Actions Std              0.181659
evaluation/Actions Max              0.996898
evaluation/Actions Min             -0.99511
evaluation/Num Paths               15
evaluation/Average Returns        -19.1076
time/data storing (s)               0.00303044
time/evaluation sampling (s)        0.364441
time/exploration sampling (s)       0.165943
time/logging (s)                    0.0056085
time/saving (s)                     0.00203137
time/training (s)                   2.14779
time/epoch (s)                      2.68885
time/total (s)                    602.795
Epoch                             222
-----------------------------  ---------------
2019-04-22 21:48:06.740873 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 223 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.564983
trainer/QF2 Loss                    0.5619
trainer/Policy Loss                 8.89849
trainer/Q1 Predictions Mean        -6.96115
trainer/Q1 Predictions Std          3.14828
trainer/Q1 Predictions Max         -5.88799
trainer/Q1 Predictions Min        -35.3653
trainer/Q2 Predictions Mean        -6.97203
trainer/Q2 Predictions Std          3.13713
trainer/Q2 Predictions Max         -5.94573
trainer/Q2 Predictions Min        -35.3376
trainer/Q Targets Mean             -6.94459
trainer/Q Targets Std               3.21674
trainer/Q Targets Max              -0.0877491
trainer/Q Targets Min             -35.3446
trainer/Log Pis Mean                1.94366
trainer/Log Pis Std                 1.06283
trainer/Log Pis Max                 5.70048
trainer/Log Pis Min                -3.16506
trainer/Policy mu Mean             -0.0670475
trainer/Policy mu Std               0.398971
trainer/Policy mu Max               0.371958
trainer/Policy mu Min              -3.06123
trainer/Policy log std Mean        -2.27129
trainer/Policy log std Std          0.272337
trainer/Policy log std Max         -0.545465
trainer/Policy log std Min         -2.48681
trainer/Alpha                       0.0636071
trainer/Alpha Loss                 -0.155223
exploration/num steps total    112200
exploration/num paths total      1122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.417917
exploration/Rewards Std             1.22087
exploration/Rewards Max            -0.0101838
exploration/Rewards Min           -10.3631
exploration/Returns Mean          -41.7917
exploration/Returns Std            12.4166
exploration/Returns Max           -20.9349
exploration/Returns Min           -59.3845
exploration/Actions Mean            9.47456e-05
exploration/Actions Std             0.266433
exploration/Actions Max             0.99981
exploration/Actions Min            -0.996477
exploration/Num Paths               5
exploration/Average Returns       -41.7917
evaluation/num steps total     336000
evaluation/num paths total       3360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.173616
evaluation/Rewards Std              0.657944
evaluation/Rewards Max             -0.0412254
evaluation/Rewards Min             -6.83739
evaluation/Returns Mean           -17.3616
evaluation/Returns Std              8.81385
evaluation/Returns Max             -5.96217
evaluation/Returns Min            -31.5922
evaluation/Actions Mean            -0.0111504
evaluation/Actions Std              0.174987
evaluation/Actions Max              0.99362
evaluation/Actions Min             -0.997399
evaluation/Num Paths               15
evaluation/Average Returns        -17.3616
time/data storing (s)               0.00305975
time/evaluation sampling (s)        0.377107
time/exploration sampling (s)       0.165816
time/logging (s)                    0.00433115
time/saving (s)                     0.00165865
time/training (s)                   2.13957
time/epoch (s)                      2.69155
time/total (s)                    605.492
Epoch                             223
-----------------------------  ----------------
2019-04-22 21:48:09.377764 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 224 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.400939
trainer/QF2 Loss                    0.397209
trainer/Policy Loss                 8.62705
trainer/Q1 Predictions Mean        -6.86684
trainer/Q1 Predictions Std          3.45738
trainer/Q1 Predictions Max         -5.80226
trainer/Q1 Predictions Min        -40.2914
trainer/Q2 Predictions Mean        -6.83394
trainer/Q2 Predictions Std          3.41519
trainer/Q2 Predictions Max         -5.76693
trainer/Q2 Predictions Min        -39.8496
trainer/Q Targets Mean             -6.8727
trainer/Q Targets Std               3.42506
trainer/Q Targets Max              -0.0653202
trainer/Q Targets Min             -39.3718
trainer/Log Pis Mean                1.79301
trainer/Log Pis Std                 1.3461
trainer/Log Pis Max                 8.76311
trainer/Log Pis Min                -3.3287
trainer/Policy mu Mean             -0.0529634
trainer/Policy mu Std               0.411927
trainer/Policy mu Max               2.92299
trainer/Policy mu Min              -3.337
trainer/Policy log std Mean        -2.2597
trainer/Policy log std Std          0.27272
trainer/Policy log std Max         -0.282208
trainer/Policy log std Min         -2.44916
trainer/Alpha                       0.0641754
trainer/Alpha Loss                 -0.568422
exploration/num steps total    112700
exploration/num paths total      1127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.391112
exploration/Rewards Std             1.17008
exploration/Rewards Max            -0.00724251
exploration/Rewards Min           -10.3123
exploration/Returns Mean          -39.1112
exploration/Returns Std            17.9188
exploration/Returns Max           -20.494
exploration/Returns Min           -69.8273
exploration/Actions Mean            0.0131016
exploration/Actions Std             0.25099
exploration/Actions Max             0.999202
exploration/Actions Min            -0.999616
exploration/Num Paths               5
exploration/Average Returns       -39.1112
evaluation/num steps total     337500
evaluation/num paths total       3375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.312612
evaluation/Rewards Std              1.18441
evaluation/Rewards Max             -0.00677556
evaluation/Rewards Min            -10.7529
evaluation/Returns Mean           -31.2612
evaluation/Returns Std             16.7981
evaluation/Returns Max             -5.33571
evaluation/Returns Min            -56.1989
evaluation/Actions Mean            -0.00630003
evaluation/Actions Std              0.207763
evaluation/Actions Max              0.998425
evaluation/Actions Min             -0.998297
evaluation/Num Paths               15
evaluation/Average Returns        -31.2612
time/data storing (s)               0.00291598
time/evaluation sampling (s)        0.353014
time/exploration sampling (s)       0.157553
time/logging (s)                    0.00506754
time/saving (s)                     0.00206973
time/training (s)                   2.10861
time/epoch (s)                      2.62923
time/total (s)                    608.126
Epoch                             224
-----------------------------  ---------------
2019-04-22 21:48:12.097368 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 225 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.754076
trainer/QF2 Loss                    0.748565
trainer/Policy Loss                 8.7601
trainer/Q1 Predictions Mean        -6.90892
trainer/Q1 Predictions Std          1.53551
trainer/Q1 Predictions Max         -5.82733
trainer/Q1 Predictions Min        -14.882
trainer/Q2 Predictions Mean        -6.89421
trainer/Q2 Predictions Std          1.53842
trainer/Q2 Predictions Max         -5.80275
trainer/Q2 Predictions Min        -15.3812
trainer/Q Targets Mean             -6.824
trainer/Q Targets Std               1.80479
trainer/Q Targets Max              -0.198498
trainer/Q Targets Min             -15.2553
trainer/Log Pis Mean                1.90031
trainer/Log Pis Std                 1.18056
trainer/Log Pis Max                 6.45775
trainer/Log Pis Min                -1.72683
trainer/Policy mu Mean             -0.026026
trainer/Policy mu Std               0.606849
trainer/Policy mu Max               2.76061
trainer/Policy mu Min              -2.44916
trainer/Policy log std Mean        -2.14987
trainer/Policy log std Std          0.448783
trainer/Policy log std Max         -0.45703
trainer/Policy log std Min         -2.49461
trainer/Alpha                       0.0639434
trainer/Alpha Loss                 -0.274107
exploration/num steps total    113200
exploration/num paths total      1132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.280378
exploration/Rewards Std             0.857435
exploration/Rewards Max            -0.00334384
exploration/Rewards Min            -8.97678
exploration/Returns Mean          -28.0378
exploration/Returns Std            16.0344
exploration/Returns Max           -15.6079
exploration/Returns Min           -59.1029
exploration/Actions Mean            0.00191833
exploration/Actions Std             0.225284
exploration/Actions Max             0.998317
exploration/Actions Min            -0.997222
exploration/Num Paths               5
exploration/Average Returns       -28.0378
evaluation/num steps total     339000
evaluation/num paths total       3390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224594
evaluation/Rewards Std              0.953005
evaluation/Rewards Max             -0.011451
evaluation/Rewards Min             -9.81986
evaluation/Returns Mean           -22.4594
evaluation/Returns Std             14.4936
evaluation/Returns Max             -3.51474
evaluation/Returns Min            -54.9058
evaluation/Actions Mean             0.00676083
evaluation/Actions Std              0.19521
evaluation/Actions Max              0.99756
evaluation/Actions Min             -0.998459
evaluation/Num Paths               15
evaluation/Average Returns        -22.4594
time/data storing (s)               0.00297851
time/evaluation sampling (s)        0.351757
time/exploration sampling (s)       0.162049
time/logging (s)                    0.00495761
time/saving (s)                     0.0114377
time/training (s)                   2.17792
time/epoch (s)                      2.7111
time/total (s)                    610.841
Epoch                             225
-----------------------------  ---------------
2019-04-22 21:48:14.774724 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 226 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0133799
trainer/QF2 Loss                    0.0190864
trainer/Policy Loss                 8.93211
trainer/Q1 Predictions Mean        -6.97973
trainer/Q1 Predictions Std          1.84977
trainer/Q1 Predictions Max         -5.88831
trainer/Q1 Predictions Min        -18.2533
trainer/Q2 Predictions Mean        -6.97529
trainer/Q2 Predictions Std          1.85124
trainer/Q2 Predictions Max         -5.85913
trainer/Q2 Predictions Min        -18.4727
trainer/Q Targets Mean             -6.99066
trainer/Q Targets Std               1.89573
trainer/Q Targets Max              -5.84293
trainer/Q Targets Min             -18.5074
trainer/Log Pis Mean                1.97244
trainer/Log Pis Std                 1.07161
trainer/Log Pis Max                 6.84328
trainer/Log Pis Min                -0.936083
trainer/Policy mu Mean             -0.134527
trainer/Policy mu Std               0.528114
trainer/Policy mu Max               2.6925
trainer/Policy mu Min              -2.73729
trainer/Policy log std Mean        -2.16822
trainer/Policy log std Std          0.370572
trainer/Policy log std Max         -0.525923
trainer/Policy log std Min         -2.41644
trainer/Alpha                       0.0606718
trainer/Alpha Loss                 -0.0772326
exploration/num steps total    113700
exploration/num paths total      1137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.330941
exploration/Rewards Std             1.07086
exploration/Rewards Max            -0.0036008
exploration/Rewards Min           -10.9002
exploration/Returns Mean          -33.0941
exploration/Returns Std            18.6358
exploration/Returns Max           -14.7443
exploration/Returns Min           -62.1924
exploration/Actions Mean           -0.00228313
exploration/Actions Std             0.233735
exploration/Actions Max             0.999626
exploration/Actions Min            -0.998335
exploration/Num Paths               5
exploration/Average Returns       -33.0941
evaluation/num steps total     340500
evaluation/num paths total       3405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.275798
evaluation/Rewards Std              1.02229
evaluation/Rewards Max             -0.045546
evaluation/Rewards Min             -9.03518
evaluation/Returns Mean           -27.5798
evaluation/Returns Std             14.4675
evaluation/Returns Max             -6.85558
evaluation/Returns Min            -51.17
evaluation/Actions Mean            -0.00242741
evaluation/Actions Std              0.198143
evaluation/Actions Max              0.99779
evaluation/Actions Min             -0.998319
evaluation/Num Paths               15
evaluation/Average Returns        -27.5798
time/data storing (s)               0.00297391
time/evaluation sampling (s)        0.357609
time/exploration sampling (s)       0.165934
time/logging (s)                    0.00503647
time/saving (s)                     0.00190941
time/training (s)                   2.13547
time/epoch (s)                      2.66893
time/total (s)                    613.515
Epoch                             226
-----------------------------  ---------------
2019-04-22 21:48:17.485359 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 227 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0230423
trainer/QF2 Loss                    0.020876
trainer/Policy Loss                 8.65486
trainer/Q1 Predictions Mean        -6.74221
trainer/Q1 Predictions Std          1.95364
trainer/Q1 Predictions Max         -5.77923
trainer/Q1 Predictions Min        -24.7125
trainer/Q2 Predictions Mean        -6.74505
trainer/Q2 Predictions Std          2.00831
trainer/Q2 Predictions Max         -5.78821
trainer/Q2 Predictions Min        -25.2633
trainer/Q Targets Mean             -6.78464
trainer/Q Targets Std               1.98678
trainer/Q Targets Max              -5.79097
trainer/Q Targets Min             -25.4375
trainer/Log Pis Mean                1.91435
trainer/Log Pis Std                 1.2192
trainer/Log Pis Max                 7.29503
trainer/Log Pis Min                -2.50838
trainer/Policy mu Mean             -0.0172322
trainer/Policy mu Std               0.372908
trainer/Policy mu Max               2.81705
trainer/Policy mu Min              -2.16032
trainer/Policy log std Mean        -2.33832
trainer/Policy log std Std          0.281926
trainer/Policy log std Max         -0.801708
trainer/Policy log std Min         -2.60312
trainer/Alpha                       0.0602913
trainer/Alpha Loss                 -0.240572
exploration/num steps total    114200
exploration/num paths total      1142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.243607
exploration/Rewards Std             0.757149
exploration/Rewards Max            -0.000696823
exploration/Rewards Min            -8.75274
exploration/Returns Mean          -24.3607
exploration/Returns Std            14.1839
exploration/Returns Max           -11.9915
exploration/Returns Min           -52.0118
exploration/Actions Mean           -0.0189195
exploration/Actions Std             0.201517
exploration/Actions Max             0.993716
exploration/Actions Min            -0.999155
exploration/Num Paths               5
exploration/Average Returns       -24.3607
evaluation/num steps total     342000
evaluation/num paths total       3420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.223523
evaluation/Rewards Std              1.01561
evaluation/Rewards Max             -0.00583577
evaluation/Rewards Min            -10.6616
evaluation/Returns Mean           -22.3523
evaluation/Returns Std             16.1935
evaluation/Returns Max             -4.39102
evaluation/Returns Min            -57.5595
evaluation/Actions Mean            -0.00460497
evaluation/Actions Std              0.203481
evaluation/Actions Max              0.998859
evaluation/Actions Min             -0.99647
evaluation/Num Paths               15
evaluation/Average Returns        -22.3523
time/data storing (s)               0.00351661
time/evaluation sampling (s)        0.366004
time/exploration sampling (s)       0.164681
time/logging (s)                    0.00502977
time/saving (s)                     0.00219335
time/training (s)                   2.16021
time/epoch (s)                      2.70164
time/total (s)                    616.222
Epoch                             227
-----------------------------  ----------------
2019-04-22 21:48:20.145138 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 228 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.352315
trainer/QF2 Loss                    0.348705
trainer/Policy Loss                 9.02491
trainer/Q1 Predictions Mean        -7.01115
trainer/Q1 Predictions Std          2.48226
trainer/Q1 Predictions Max         -5.83114
trainer/Q1 Predictions Min        -29.6817
trainer/Q2 Predictions Mean        -7.00069
trainer/Q2 Predictions Std          2.49503
trainer/Q2 Predictions Max         -5.84056
trainer/Q2 Predictions Min        -29.7916
trainer/Q Targets Mean             -6.96863
trainer/Q Targets Std               2.61018
trainer/Q Targets Max              -0.105038
trainer/Q Targets Min             -29.9833
trainer/Log Pis Mean                2.0529
trainer/Log Pis Std                 1.14438
trainer/Log Pis Max                 6.62705
trainer/Log Pis Min                -2.04939
trainer/Policy mu Mean              0.0368703
trainer/Policy mu Std               0.494991
trainer/Policy mu Max               3.01456
trainer/Policy mu Min              -2.38474
trainer/Policy log std Mean        -2.317
trainer/Policy log std Std          0.383903
trainer/Policy log std Max         -0.369602
trainer/Policy log std Min         -2.55092
trainer/Alpha                       0.0632863
trainer/Alpha Loss                  0.146009
exploration/num steps total    114700
exploration/num paths total      1147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.386743
exploration/Rewards Std             1.23615
exploration/Rewards Max            -0.008213
exploration/Rewards Min           -10.728
exploration/Returns Mean          -38.6743
exploration/Returns Std            18.7879
exploration/Returns Max           -12.7496
exploration/Returns Min           -61.9789
exploration/Actions Mean            0.0122619
exploration/Actions Std             0.238208
exploration/Actions Max             0.99956
exploration/Actions Min            -0.999872
exploration/Num Paths               5
exploration/Average Returns       -38.6743
evaluation/num steps total     343500
evaluation/num paths total       3435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260705
evaluation/Rewards Std              0.989791
evaluation/Rewards Max             -0.0269853
evaluation/Rewards Min            -10.097
evaluation/Returns Mean           -26.0705
evaluation/Returns Std             17.1178
evaluation/Returns Max             -2.9948
evaluation/Returns Min            -61.19
evaluation/Actions Mean             0.0213874
evaluation/Actions Std              0.191233
evaluation/Actions Max              0.998443
evaluation/Actions Min             -0.989048
evaluation/Num Paths               15
evaluation/Average Returns        -26.0705
time/data storing (s)               0.00306787
time/evaluation sampling (s)        0.345597
time/exploration sampling (s)       0.157452
time/logging (s)                    0.00492775
time/saving (s)                     0.00214822
time/training (s)                   2.1389
time/epoch (s)                      2.65209
time/total (s)                    618.878
Epoch                             228
-----------------------------  ---------------
2019-04-22 21:48:22.891421 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 229 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.012569
trainer/QF2 Loss                    0.0112077
trainer/Policy Loss                 9.68381
trainer/Q1 Predictions Mean        -7.73719
trainer/Q1 Predictions Std          5.60603
trainer/Q1 Predictions Max         -5.8442
trainer/Q1 Predictions Min        -46.4471
trainer/Q2 Predictions Mean        -7.7311
trainer/Q2 Predictions Std          5.58786
trainer/Q2 Predictions Max         -5.7566
trainer/Q2 Predictions Min        -46.4125
trainer/Q Targets Mean             -7.77947
trainer/Q Targets Std               5.59408
trainer/Q Targets Max              -5.81384
trainer/Q Targets Min             -46.2378
trainer/Log Pis Mean                1.96003
trainer/Log Pis Std                 1.39042
trainer/Log Pis Max                 6.32707
trainer/Log Pis Min                -3.8404
trainer/Policy mu Mean              0.0236047
trainer/Policy mu Std               0.608836
trainer/Policy mu Max               3.36211
trainer/Policy mu Min              -3.28842
trainer/Policy log std Mean        -2.22401
trainer/Policy log std Std          0.402806
trainer/Policy log std Max         -0.608563
trainer/Policy log std Min         -2.52944
trainer/Alpha                       0.0624297
trainer/Alpha Loss                 -0.110873
exploration/num steps total    115200
exploration/num paths total      1152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43889
exploration/Rewards Std             1.32886
exploration/Rewards Max            -0.00125543
exploration/Rewards Min            -9.91826
exploration/Returns Mean          -43.889
exploration/Returns Std            13.8392
exploration/Returns Max           -22.9225
exploration/Returns Min           -59.4244
exploration/Actions Mean            0.00726386
exploration/Actions Std             0.253275
exploration/Actions Max             0.999825
exploration/Actions Min            -0.998378
exploration/Num Paths               5
exploration/Average Returns       -43.889
evaluation/num steps total     345000
evaluation/num paths total       3450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.291433
evaluation/Rewards Std              1.15
evaluation/Rewards Max             -0.00605895
evaluation/Rewards Min            -10.1277
evaluation/Returns Mean           -29.1433
evaluation/Returns Std             17.6714
evaluation/Returns Max             -5.78059
evaluation/Returns Min            -57.0553
evaluation/Actions Mean             0.00187028
evaluation/Actions Std              0.207921
evaluation/Actions Max              0.998874
evaluation/Actions Min             -0.998431
evaluation/Num Paths               15
evaluation/Average Returns        -29.1433
time/data storing (s)               0.00336315
time/evaluation sampling (s)        0.363536
time/exploration sampling (s)       0.166796
time/logging (s)                    0.00552399
time/saving (s)                     0.00199102
time/training (s)                   2.19689
time/epoch (s)                      2.7381
time/total (s)                    621.621
Epoch                             229
-----------------------------  ---------------
2019-04-22 21:48:25.580994 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 230 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.581734
trainer/QF2 Loss                    0.575831
trainer/Policy Loss                 9.41171
trainer/Q1 Predictions Mean        -7.33723
trainer/Q1 Predictions Std          3.6359
trainer/Q1 Predictions Max         -5.74537
trainer/Q1 Predictions Min        -31.7738
trainer/Q2 Predictions Mean        -7.34446
trainer/Q2 Predictions Std          3.61554
trainer/Q2 Predictions Max         -5.84376
trainer/Q2 Predictions Min        -31.4219
trainer/Q Targets Mean             -7.33321
trainer/Q Targets Std               3.66256
trainer/Q Targets Max              -0.215328
trainer/Q Targets Min             -31.4936
trainer/Log Pis Mean                2.07171
trainer/Log Pis Std                 1.18478
trainer/Log Pis Max                 7.88817
trainer/Log Pis Min                -1.82175
trainer/Policy mu Mean             -0.0677458
trainer/Policy mu Std               0.591502
trainer/Policy mu Max               2.61432
trainer/Policy mu Min              -3.06524
trainer/Policy log std Mean        -2.21518
trainer/Policy log std Std          0.423921
trainer/Policy log std Max         -0.367525
trainer/Policy log std Min         -2.49273
trainer/Alpha                       0.0618128
trainer/Alpha Loss                  0.199601
exploration/num steps total    115700
exploration/num paths total      1157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.287623
exploration/Rewards Std             0.952857
exploration/Rewards Max            -0.0108552
exploration/Rewards Min           -10.8918
exploration/Returns Mean          -28.7623
exploration/Returns Std            20.282
exploration/Returns Max           -14.4106
exploration/Returns Min           -68.325
exploration/Actions Mean            0.0229904
exploration/Actions Std             0.209669
exploration/Actions Max             0.999963
exploration/Actions Min            -0.949767
exploration/Num Paths               5
exploration/Average Returns       -28.7623
evaluation/num steps total     346500
evaluation/num paths total       3465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221768
evaluation/Rewards Std              0.795699
evaluation/Rewards Max             -0.0450403
evaluation/Rewards Min             -8.68738
evaluation/Returns Mean           -22.1768
evaluation/Returns Std             10.2957
evaluation/Returns Max             -7.08427
evaluation/Returns Min            -41.0697
evaluation/Actions Mean             0.00114269
evaluation/Actions Std              0.186611
evaluation/Actions Max              0.99713
evaluation/Actions Min             -0.99768
evaluation/Num Paths               15
evaluation/Average Returns        -22.1768
time/data storing (s)               0.00315023
time/evaluation sampling (s)        0.364178
time/exploration sampling (s)       0.164748
time/logging (s)                    0.00543043
time/saving (s)                     0.00237768
time/training (s)                   2.14094
time/epoch (s)                      2.68083
time/total (s)                    624.306
Epoch                             230
-----------------------------  ---------------
2019-04-22 21:48:28.266419 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 231 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0135243
trainer/QF2 Loss                    0.0134787
trainer/Policy Loss                 8.47543
trainer/Q1 Predictions Mean        -6.58344
trainer/Q1 Predictions Std          0.976621
trainer/Q1 Predictions Max         -5.8831
trainer/Q1 Predictions Min        -12.9725
trainer/Q2 Predictions Mean        -6.57719
trainer/Q2 Predictions Std          0.973329
trainer/Q2 Predictions Max         -5.88837
trainer/Q2 Predictions Min        -12.8798
trainer/Q Targets Mean             -6.65618
trainer/Q Targets Std               0.958605
trainer/Q Targets Max              -5.85499
trainer/Q Targets Min             -12.812
trainer/Log Pis Mean                1.91047
trainer/Log Pis Std                 0.948708
trainer/Log Pis Max                 4.16038
trainer/Log Pis Min                -2.27627
trainer/Policy mu Mean             -0.047761
trainer/Policy mu Std               0.375573
trainer/Policy mu Max               2.15622
trainer/Policy mu Min              -2.53571
trainer/Policy log std Mean        -2.24777
trainer/Policy log std Std          0.268164
trainer/Policy log std Max         -0.574167
trainer/Policy log std Min         -2.43705
trainer/Alpha                       0.0612888
trainer/Alpha Loss                 -0.249971
exploration/num steps total    116200
exploration/num paths total      1162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.289543
exploration/Rewards Std             0.881817
exploration/Rewards Max            -0.0082112
exploration/Rewards Min            -9.05961
exploration/Returns Mean          -28.9543
exploration/Returns Std            13.946
exploration/Returns Max           -12.9565
exploration/Returns Min           -54.2882
exploration/Actions Mean           -0.00545834
exploration/Actions Std             0.223758
exploration/Actions Max             0.997928
exploration/Actions Min            -0.997639
exploration/Num Paths               5
exploration/Average Returns       -28.9543
evaluation/num steps total     348000
evaluation/num paths total       3480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.21445
evaluation/Rewards Std              0.95736
evaluation/Rewards Max             -0.0243163
evaluation/Rewards Min             -9.98447
evaluation/Returns Mean           -21.445
evaluation/Returns Std             15.642
evaluation/Returns Max             -4.50244
evaluation/Returns Min            -53.8185
evaluation/Actions Mean            -0.00394838
evaluation/Actions Std              0.1923
evaluation/Actions Max              0.99766
evaluation/Actions Min             -0.998841
evaluation/Num Paths               15
evaluation/Average Returns        -21.445
time/data storing (s)               0.00311121
time/evaluation sampling (s)        0.354354
time/exploration sampling (s)       0.159087
time/logging (s)                    0.00519433
time/saving (s)                     0.0019909
time/training (s)                   2.15384
time/epoch (s)                      2.67758
time/total (s)                    626.987
Epoch                             231
-----------------------------  ---------------
2019-04-22 21:48:30.907065 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 232 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.387951
trainer/QF2 Loss                    0.388211
trainer/Policy Loss                 9.22709
trainer/Q1 Predictions Mean        -7.2727
trainer/Q1 Predictions Std          3.85593
trainer/Q1 Predictions Max         -5.8784
trainer/Q1 Predictions Min        -33.796
trainer/Q2 Predictions Mean        -7.24379
trainer/Q2 Predictions Std          3.84617
trainer/Q2 Predictions Max         -5.82381
trainer/Q2 Predictions Min        -33.8046
trainer/Q Targets Mean             -7.24888
trainer/Q Targets Std               3.92604
trainer/Q Targets Max              -0.0507194
trainer/Q Targets Min             -34.3269
trainer/Log Pis Mean                1.98882
trainer/Log Pis Std                 1.13915
trainer/Log Pis Max                 5.56338
trainer/Log Pis Min                -4.11948
trainer/Policy mu Mean             -0.0250408
trainer/Policy mu Std               0.527095
trainer/Policy mu Max               2.9035
trainer/Policy mu Min              -2.94484
trainer/Policy log std Mean        -2.18042
trainer/Policy log std Std          0.344873
trainer/Policy log std Max         -0.524527
trainer/Policy log std Min         -2.41678
trainer/Alpha                       0.0616263
trainer/Alpha Loss                 -0.0311542
exploration/num steps total    116700
exploration/num paths total      1167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.384525
exploration/Rewards Std             1.18454
exploration/Rewards Max            -0.00324261
exploration/Rewards Min           -10.3249
exploration/Returns Mean          -38.4525
exploration/Returns Std            16.1135
exploration/Returns Max           -12.9118
exploration/Returns Min           -63.5772
exploration/Actions Mean            0.0195227
exploration/Actions Std             0.249288
exploration/Actions Max             0.999603
exploration/Actions Min            -0.994574
exploration/Num Paths               5
exploration/Average Returns       -38.4525
evaluation/num steps total     349500
evaluation/num paths total       3495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229413
evaluation/Rewards Std              1.01066
evaluation/Rewards Max             -0.0194714
evaluation/Rewards Min            -11.343
evaluation/Returns Mean           -22.9413
evaluation/Returns Std             16.5762
evaluation/Returns Max             -5.22182
evaluation/Returns Min            -56.8367
evaluation/Actions Mean            -0.00518825
evaluation/Actions Std              0.202545
evaluation/Actions Max              0.999008
evaluation/Actions Min             -0.998496
evaluation/Num Paths               15
evaluation/Average Returns        -22.9413
time/data storing (s)               0.00312492
time/evaluation sampling (s)        0.361601
time/exploration sampling (s)       0.165371
time/logging (s)                    0.00525022
time/saving (s)                     0.00178439
time/training (s)                   2.09521
time/epoch (s)                      2.63234
time/total (s)                    629.624
Epoch                             232
-----------------------------  ---------------
2019-04-22 21:48:33.580297 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 233 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.427821
trainer/QF2 Loss                    0.425857
trainer/Policy Loss                 9.04786
trainer/Q1 Predictions Mean        -6.9522
trainer/Q1 Predictions Std          2.58463
trainer/Q1 Predictions Max         -5.86643
trainer/Q1 Predictions Min        -23.7178
trainer/Q2 Predictions Mean        -6.95378
trainer/Q2 Predictions Std          2.61391
trainer/Q2 Predictions Max         -5.85244
trainer/Q2 Predictions Min        -23.8124
trainer/Q Targets Mean             -6.98387
trainer/Q Targets Std               2.61409
trainer/Q Targets Max              -0.112919
trainer/Q Targets Min             -22.4409
trainer/Log Pis Mean                2.12508
trainer/Log Pis Std                 1.23363
trainer/Log Pis Max                 6.35418
trainer/Log Pis Min                -4.25372
trainer/Policy mu Mean             -0.0597426
trainer/Policy mu Std               0.533184
trainer/Policy mu Max               2.33518
trainer/Policy mu Min              -2.89837
trainer/Policy log std Mean        -2.27487
trainer/Policy log std Std          0.381054
trainer/Policy log std Max         -0.444526
trainer/Policy log std Min         -2.56433
trainer/Alpha                       0.0619033
trainer/Alpha Loss                  0.348007
exploration/num steps total    117200
exploration/num paths total      1172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.282484
exploration/Rewards Std             0.881905
exploration/Rewards Max            -0.00113507
exploration/Rewards Min            -8.48851
exploration/Returns Mean          -28.2484
exploration/Returns Std            14.0114
exploration/Returns Max           -11.457
exploration/Returns Min           -52.8962
exploration/Actions Mean           -0.0139118
exploration/Actions Std             0.220259
exploration/Actions Max             0.997722
exploration/Actions Min            -0.998187
exploration/Num Paths               5
exploration/Average Returns       -28.2484
evaluation/num steps total     351000
evaluation/num paths total       3510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273919
evaluation/Rewards Std              1.12541
evaluation/Rewards Max             -0.00700473
evaluation/Rewards Min            -10.4894
evaluation/Returns Mean           -27.3919
evaluation/Returns Std             16.9187
evaluation/Returns Max             -4.48556
evaluation/Returns Min            -55.0179
evaluation/Actions Mean            -0.00768133
evaluation/Actions Std              0.201403
evaluation/Actions Max              0.997892
evaluation/Actions Min             -0.998498
evaluation/Num Paths               15
evaluation/Average Returns        -27.3919
time/data storing (s)               0.00302646
time/evaluation sampling (s)        0.35979
time/exploration sampling (s)       0.168272
time/logging (s)                    0.00517802
time/saving (s)                     0.00231578
time/training (s)                   2.12606
time/epoch (s)                      2.66464
time/total (s)                    632.294
Epoch                             233
-----------------------------  ---------------
2019-04-22 21:48:36.324822 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 234 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.806902
trainer/QF2 Loss                    0.805995
trainer/Policy Loss                 8.44359
trainer/Q1 Predictions Mean        -6.47265
trainer/Q1 Predictions Std          0.572197
trainer/Q1 Predictions Max         -5.73142
trainer/Q1 Predictions Min         -7.57471
trainer/Q2 Predictions Mean        -6.49423
trainer/Q2 Predictions Std          0.567796
trainer/Q2 Predictions Max         -5.78525
trainer/Q2 Predictions Min         -7.72459
trainer/Q Targets Mean             -6.41614
trainer/Q Targets Std               1.04334
trainer/Q Targets Max              -0.0735486
trainer/Q Targets Min              -7.59208
trainer/Log Pis Mean                1.97606
trainer/Log Pis Std                 1.07671
trainer/Log Pis Max                 3.53529
trainer/Log Pis Min                -2.56908
trainer/Policy mu Mean              0.00335137
trainer/Policy mu Std               0.190445
trainer/Policy mu Max               0.924806
trainer/Policy mu Min              -1.50789
trainer/Policy log std Mean        -2.39039
trainer/Policy log std Std          0.146091
trainer/Policy log std Max         -1.164
trainer/Policy log std Min         -2.60977
trainer/Alpha                       0.0596172
trainer/Alpha Loss                 -0.0675144
exploration/num steps total    117700
exploration/num paths total      1177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.260384
exploration/Rewards Std             0.789734
exploration/Rewards Max            -0.00541923
exploration/Rewards Min            -6.95936
exploration/Returns Mean          -26.0384
exploration/Returns Std             8.26916
exploration/Returns Max           -10.7493
exploration/Returns Min           -34.9042
exploration/Actions Mean            0.00245124
exploration/Actions Std             0.21984
exploration/Actions Max             0.997272
exploration/Actions Min            -0.998239
exploration/Num Paths               5
exploration/Average Returns       -26.0384
evaluation/num steps total     352500
evaluation/num paths total       3525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.218232
evaluation/Rewards Std              0.972563
evaluation/Rewards Max             -0.00120749
evaluation/Rewards Min             -9.74002
evaluation/Returns Mean           -21.8232
evaluation/Returns Std             15.5516
evaluation/Returns Max             -0.235145
evaluation/Returns Min            -56.6843
evaluation/Actions Mean             0.0133183
evaluation/Actions Std              0.200256
evaluation/Actions Max              0.998817
evaluation/Actions Min             -0.997143
evaluation/Num Paths               15
evaluation/Average Returns        -21.8232
time/data storing (s)               0.00299385
time/evaluation sampling (s)        0.359977
time/exploration sampling (s)       0.20002
time/logging (s)                    0.00494973
time/saving (s)                     0.00201137
time/training (s)                   2.1656
time/epoch (s)                      2.73555
time/total (s)                    635.034
Epoch                             234
-----------------------------  ---------------
2019-04-22 21:48:38.973305 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 235 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.523039
trainer/QF2 Loss                    0.514268
trainer/Policy Loss                 8.87256
trainer/Q1 Predictions Mean        -6.7574
trainer/Q1 Predictions Std          1.49116
trainer/Q1 Predictions Max         -5.76845
trainer/Q1 Predictions Min        -19.29
trainer/Q2 Predictions Mean        -6.7697
trainer/Q2 Predictions Std          1.48352
trainer/Q2 Predictions Max         -5.76275
trainer/Q2 Predictions Min        -19.2535
trainer/Q Targets Mean             -6.74868
trainer/Q Targets Std               1.60737
trainer/Q Targets Max              -0.114616
trainer/Q Targets Min             -19.4115
trainer/Log Pis Mean                2.15063
trainer/Log Pis Std                 1.05953
trainer/Log Pis Max                 7.7489
trainer/Log Pis Min                -2.48053
trainer/Policy mu Mean             -0.0287228
trainer/Policy mu Std               0.444679
trainer/Policy mu Max               2.63726
trainer/Policy mu Min              -2.55361
trainer/Policy log std Mean        -2.3105
trainer/Policy log std Std          0.32635
trainer/Policy log std Max         -0.518527
trainer/Policy log std Min         -2.56016
trainer/Alpha                       0.0633851
trainer/Alpha Loss                  0.415555
exploration/num steps total    118200
exploration/num paths total      1182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.304144
exploration/Rewards Std             0.928877
exploration/Rewards Max            -0.00758836
exploration/Rewards Min            -8.63902
exploration/Returns Mean          -30.4144
exploration/Returns Std            12.2344
exploration/Returns Max           -13.0506
exploration/Returns Min           -45.9852
exploration/Actions Mean           -0.0146599
exploration/Actions Std             0.231
exploration/Actions Max             0.997242
exploration/Actions Min            -0.998618
exploration/Num Paths               5
exploration/Average Returns       -30.4144
evaluation/num steps total     354000
evaluation/num paths total       3540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.201802
evaluation/Rewards Std              0.908214
evaluation/Rewards Max             -0.00443626
evaluation/Rewards Min             -9.32923
evaluation/Returns Mean           -20.1802
evaluation/Returns Std             16.1256
evaluation/Returns Max             -3.1254
evaluation/Returns Min            -54.0057
evaluation/Actions Mean             0.010794
evaluation/Actions Std              0.187375
evaluation/Actions Max              0.998363
evaluation/Actions Min             -0.997638
evaluation/Num Paths               15
evaluation/Average Returns        -20.1802
time/data storing (s)               0.00308525
time/evaluation sampling (s)        0.352692
time/exploration sampling (s)       0.160229
time/logging (s)                    0.00478519
time/saving (s)                     0.00211665
time/training (s)                   2.11669
time/epoch (s)                      2.63959
time/total (s)                    637.678
Epoch                             235
-----------------------------  ---------------
2019-04-22 21:48:41.666488 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 236 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.897647
trainer/QF2 Loss                    0.898086
trainer/Policy Loss                 9.23725
trainer/Q1 Predictions Mean        -7.22014
trainer/Q1 Predictions Std          3.66573
trainer/Q1 Predictions Max         -5.88712
trainer/Q1 Predictions Min        -32.7191
trainer/Q2 Predictions Mean        -7.22968
trainer/Q2 Predictions Std          3.6674
trainer/Q2 Predictions Max         -5.88847
trainer/Q2 Predictions Min        -32.6637
trainer/Q Targets Mean             -7.12589
trainer/Q Targets Std               3.81061
trainer/Q Targets Max              -0.0341377
trainer/Q Targets Min             -32.7642
trainer/Log Pis Mean                2.01723
trainer/Log Pis Std                 1.21555
trainer/Log Pis Max                 8.16069
trainer/Log Pis Min                -1.68901
trainer/Policy mu Mean             -0.0393814
trainer/Policy mu Std               0.569245
trainer/Policy mu Max               2.64242
trainer/Policy mu Min              -3.03849
trainer/Policy log std Mean        -2.22984
trainer/Policy log std Std          0.389762
trainer/Policy log std Max         -0.504187
trainer/Policy log std Min         -2.4655
trainer/Alpha                       0.0632419
trainer/Alpha Loss                  0.0475807
exploration/num steps total    118700
exploration/num paths total      1187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.253373
exploration/Rewards Std             0.71096
exploration/Rewards Max            -0.0125248
exploration/Rewards Min            -6.37603
exploration/Returns Mean          -25.3373
exploration/Returns Std             7.71632
exploration/Returns Max           -12.7048
exploration/Returns Min           -34.2771
exploration/Actions Mean           -0.0133241
exploration/Actions Std             0.220424
exploration/Actions Max             0.996309
exploration/Actions Min            -0.997596
exploration/Num Paths               5
exploration/Average Returns       -25.3373
evaluation/num steps total     355500
evaluation/num paths total       3555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.313646
evaluation/Rewards Std              1.23369
evaluation/Rewards Max             -0.0230959
evaluation/Rewards Min            -10.6478
evaluation/Returns Mean           -31.3646
evaluation/Returns Std             14.7497
evaluation/Returns Max             -3.61607
evaluation/Returns Min            -58.947
evaluation/Actions Mean            -0.00540065
evaluation/Actions Std              0.218121
evaluation/Actions Max              0.998872
evaluation/Actions Min             -0.998193
evaluation/Num Paths               15
evaluation/Average Returns        -31.3646
time/data storing (s)               0.00302704
time/evaluation sampling (s)        0.345949
time/exploration sampling (s)       0.160132
time/logging (s)                    0.00492949
time/saving (s)                     0.0022142
time/training (s)                   2.16857
time/epoch (s)                      2.68482
time/total (s)                    640.368
Epoch                             236
-----------------------------  ---------------
2019-04-22 21:48:44.354021 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 237 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0149756
trainer/QF2 Loss                    0.0147063
trainer/Policy Loss                 9.098
trainer/Q1 Predictions Mean        -7.21627
trainer/Q1 Predictions Std          4.03896
trainer/Q1 Predictions Max         -5.97163
trainer/Q1 Predictions Min        -43.0132
trainer/Q2 Predictions Mean        -7.21401
trainer/Q2 Predictions Std          4.04052
trainer/Q2 Predictions Max         -5.95761
trainer/Q2 Predictions Min        -42.9609
trainer/Q Targets Mean             -7.22817
trainer/Q Targets Std               4.05456
trainer/Q Targets Max              -5.86972
trainer/Q Targets Min             -42.8452
trainer/Log Pis Mean                1.90425
trainer/Log Pis Std                 1.43812
trainer/Log Pis Max                 7.31163
trainer/Log Pis Min                -2.56446
trainer/Policy mu Mean              0.0457811
trainer/Policy mu Std               0.473807
trainer/Policy mu Max               3.19195
trainer/Policy mu Min              -3.10227
trainer/Policy log std Mean        -2.32744
trainer/Policy log std Std          0.320235
trainer/Policy log std Max         -0.568017
trainer/Policy log std Min         -2.54533
trainer/Alpha                       0.0645331
trainer/Alpha Loss                 -0.26243
exploration/num steps total    119200
exploration/num paths total      1192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.299309
exploration/Rewards Std             0.896573
exploration/Rewards Max            -0.00542194
exploration/Rewards Min            -8.21335
exploration/Returns Mean          -29.9309
exploration/Returns Std            13.2023
exploration/Returns Max           -13.0736
exploration/Returns Min           -42.6325
exploration/Actions Mean           -0.0139929
exploration/Actions Std             0.215473
exploration/Actions Max             0.99732
exploration/Actions Min            -0.99783
exploration/Num Paths               5
exploration/Average Returns       -29.9309
evaluation/num steps total     357000
evaluation/num paths total       3570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243916
evaluation/Rewards Std              0.927775
evaluation/Rewards Max             -0.0156842
evaluation/Rewards Min             -9.89702
evaluation/Returns Mean           -24.3916
evaluation/Returns Std             14.0513
evaluation/Returns Max             -5.33704
evaluation/Returns Min            -49.5601
evaluation/Actions Mean             0.00177669
evaluation/Actions Std              0.188057
evaluation/Actions Max              0.998751
evaluation/Actions Min             -0.996252
evaluation/Num Paths               15
evaluation/Average Returns        -24.3916
time/data storing (s)               0.00309558
time/evaluation sampling (s)        0.35951
time/exploration sampling (s)       0.160974
time/logging (s)                    0.00490732
time/saving (s)                     0.00164853
time/training (s)                   2.14784
time/epoch (s)                      2.67797
time/total (s)                    643.051
Epoch                             237
-----------------------------  ---------------
2019-04-22 21:48:47.062964 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 238 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0164561
trainer/QF2 Loss                    0.0143482
trainer/Policy Loss                 8.68963
trainer/Q1 Predictions Mean        -6.70993
trainer/Q1 Predictions Std          1.05857
trainer/Q1 Predictions Max         -5.96726
trainer/Q1 Predictions Min        -14.7004
trainer/Q2 Predictions Mean        -6.70233
trainer/Q2 Predictions Std          1.02927
trainer/Q2 Predictions Max         -5.9893
trainer/Q2 Predictions Min        -14.4421
trainer/Q Targets Mean             -6.7091
trainer/Q Targets Std               1.00745
trainer/Q Targets Max              -5.91025
trainer/Q Targets Min             -14.5337
trainer/Log Pis Mean                2.00346
trainer/Log Pis Std                 1.22722
trainer/Log Pis Max                 4.12364
trainer/Log Pis Min                -5.21397
trainer/Policy mu Mean              0.0142563
trainer/Policy mu Std               0.353506
trainer/Policy mu Max               2.46105
trainer/Policy mu Min              -2.75233
trainer/Policy log std Mean        -2.3173
trainer/Policy log std Std          0.273342
trainer/Policy log std Max         -0.574896
trainer/Policy log std Min         -2.56989
trainer/Alpha                       0.0633798
trainer/Alpha Loss                  0.00953231
exploration/num steps total    119700
exploration/num paths total      1197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.566376
exploration/Rewards Std             1.66422
exploration/Rewards Max            -0.00442052
exploration/Rewards Min           -11.6968
exploration/Returns Mean          -56.6376
exploration/Returns Std            10.4362
exploration/Returns Max           -39.4716
exploration/Returns Min           -69.0147
exploration/Actions Mean            0.00300997
exploration/Actions Std             0.281542
exploration/Actions Max             0.999269
exploration/Actions Min            -0.999929
exploration/Num Paths               5
exploration/Average Returns       -56.6376
evaluation/num steps total     358500
evaluation/num paths total       3585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.354201
evaluation/Rewards Std              1.29665
evaluation/Rewards Max             -0.0242299
evaluation/Rewards Min            -11.6739
evaluation/Returns Mean           -35.4201
evaluation/Returns Std             17.8007
evaluation/Returns Max            -11.3393
evaluation/Returns Min            -65.487
evaluation/Actions Mean             0.0134128
evaluation/Actions Std              0.222724
evaluation/Actions Max              0.998752
evaluation/Actions Min             -0.998408
evaluation/Num Paths               15
evaluation/Average Returns        -35.4201
time/data storing (s)               0.00313781
time/evaluation sampling (s)        0.353687
time/exploration sampling (s)       0.159849
time/logging (s)                    0.00496713
time/saving (s)                     0.00203024
time/training (s)                   2.1767
time/epoch (s)                      2.70037
time/total (s)                    645.756
Epoch                             238
-----------------------------  ---------------
2019-04-22 21:48:49.729462 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 239 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0106681
trainer/QF2 Loss                    0.011831
trainer/Policy Loss                 8.87277
trainer/Q1 Predictions Mean        -6.81432
trainer/Q1 Predictions Std          1.94487
trainer/Q1 Predictions Max         -5.96675
trainer/Q1 Predictions Min        -21.7816
trainer/Q2 Predictions Mean        -6.80494
trainer/Q2 Predictions Std          1.95027
trainer/Q2 Predictions Max         -5.96052
trainer/Q2 Predictions Min        -21.8798
trainer/Q Targets Mean             -6.81786
trainer/Q Targets Std               1.96606
trainer/Q Targets Max              -5.86126
trainer/Q Targets Min             -21.7453
trainer/Log Pis Mean                2.08014
trainer/Log Pis Std                 0.999922
trainer/Log Pis Max                 5.60276
trainer/Log Pis Min                -1.52439
trainer/Policy mu Mean             -0.0278074
trainer/Policy mu Std               0.504135
trainer/Policy mu Max               2.69925
trainer/Policy mu Min              -2.88061
trainer/Policy log std Mean        -2.298
trainer/Policy log std Std          0.352038
trainer/Policy log std Max         -0.633674
trainer/Policy log std Min         -2.50581
trainer/Alpha                       0.0623016
trainer/Alpha Loss                  0.222467
exploration/num steps total    120200
exploration/num paths total      1202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.250116
exploration/Rewards Std             0.76515
exploration/Rewards Max            -0.00231558
exploration/Rewards Min            -8.42132
exploration/Returns Mean          -25.0116
exploration/Returns Std            13.0775
exploration/Returns Max           -13.6051
exploration/Returns Min           -50.3037
exploration/Actions Mean            0.0144896
exploration/Actions Std             0.208515
exploration/Actions Max             0.99878
exploration/Actions Min            -0.998131
exploration/Num Paths               5
exploration/Average Returns       -25.0116
evaluation/num steps total     360000
evaluation/num paths total       3600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.186977
evaluation/Rewards Std              0.79409
evaluation/Rewards Max             -0.00946261
evaluation/Rewards Min             -9.80375
evaluation/Returns Mean           -18.6977
evaluation/Returns Std             13.2319
evaluation/Returns Max             -5.84122
evaluation/Returns Min            -44.9697
evaluation/Actions Mean             0.00899336
evaluation/Actions Std              0.175019
evaluation/Actions Max              0.998473
evaluation/Actions Min             -0.998241
evaluation/Num Paths               15
evaluation/Average Returns        -18.6977
time/data storing (s)               0.00299121
time/evaluation sampling (s)        0.36338
time/exploration sampling (s)       0.16478
time/logging (s)                    0.00485372
time/saving (s)                     0.00199414
time/training (s)                   2.11945
time/epoch (s)                      2.65745
time/total (s)                    648.418
Epoch                             239
-----------------------------  ---------------
2019-04-22 21:48:52.408723 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 240 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0251038
trainer/QF2 Loss                    0.0265311
trainer/Policy Loss                 8.76108
trainer/Q1 Predictions Mean        -6.77652
trainer/Q1 Predictions Std          2.45064
trainer/Q1 Predictions Max         -5.74524
trainer/Q1 Predictions Min        -27.8019
trainer/Q2 Predictions Mean        -6.77124
trainer/Q2 Predictions Std          2.42522
trainer/Q2 Predictions Max         -5.77108
trainer/Q2 Predictions Min        -27.708
trainer/Q Targets Mean             -6.89815
trainer/Q Targets Std               2.41447
trainer/Q Targets Max              -5.88372
trainer/Q Targets Min             -27.7213
trainer/Log Pis Mean                1.99858
trainer/Log Pis Std                 1.10186
trainer/Log Pis Max                 5.67061
trainer/Log Pis Min                -1.55808
trainer/Policy mu Mean              0.022548
trainer/Policy mu Std               0.453154
trainer/Policy mu Max               2.91121
trainer/Policy mu Min              -2.7944
trainer/Policy log std Mean        -2.27121
trainer/Policy log std Std          0.322116
trainer/Policy log std Max         -0.643322
trainer/Policy log std Min         -2.48874
trainer/Alpha                       0.0625391
trainer/Alpha Loss                 -0.00394462
exploration/num steps total    120700
exploration/num paths total      1207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.486051
exploration/Rewards Std             1.44117
exploration/Rewards Max            -0.00885302
exploration/Rewards Min            -9.96362
exploration/Returns Mean          -48.6051
exploration/Returns Std            13.1645
exploration/Returns Max           -28.0317
exploration/Returns Min           -65.5209
exploration/Actions Mean            0.00651051
exploration/Actions Std             0.266376
exploration/Actions Max             0.999679
exploration/Actions Min            -0.99974
exploration/Num Paths               5
exploration/Average Returns       -48.6051
evaluation/num steps total     361500
evaluation/num paths total       3615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262166
evaluation/Rewards Std              1.03322
evaluation/Rewards Max             -0.0266261
evaluation/Rewards Min            -10.4157
evaluation/Returns Mean           -26.2166
evaluation/Returns Std             13.7296
evaluation/Returns Max             -4.01188
evaluation/Returns Min            -54.0705
evaluation/Actions Mean             0.00612215
evaluation/Actions Std              0.201803
evaluation/Actions Max              0.997899
evaluation/Actions Min             -0.998356
evaluation/Num Paths               15
evaluation/Average Returns        -26.2166
time/data storing (s)               0.00299589
time/evaluation sampling (s)        0.3507
time/exploration sampling (s)       0.156368
time/logging (s)                    0.00505257
time/saving (s)                     0.00236315
time/training (s)                   2.15358
time/epoch (s)                      2.67106
time/total (s)                    651.094
Epoch                             240
-----------------------------  ---------------
2019-04-22 21:48:55.089722 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 241 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.364082
trainer/QF2 Loss                    0.386988
trainer/Policy Loss                 9.65316
trainer/Q1 Predictions Mean        -7.52565
trainer/Q1 Predictions Std          4.9087
trainer/Q1 Predictions Max         -5.87156
trainer/Q1 Predictions Min        -43.934
trainer/Q2 Predictions Mean        -7.50853
trainer/Q2 Predictions Std          4.89117
trainer/Q2 Predictions Max         -5.86823
trainer/Q2 Predictions Min        -43.8776
trainer/Q Targets Mean             -7.50687
trainer/Q Targets Std               4.99082
trainer/Q Targets Max              -0.0473077
trainer/Q Targets Min             -44.0299
trainer/Log Pis Mean                2.13686
trainer/Log Pis Std                 1.24682
trainer/Log Pis Max                 7.0119
trainer/Log Pis Min                -1.48179
trainer/Policy mu Mean             -0.0486223
trainer/Policy mu Std               0.580768
trainer/Policy mu Max               2.7737
trainer/Policy mu Min              -3.29588
trainer/Policy log std Mean        -2.23013
trainer/Policy log std Std          0.368663
trainer/Policy log std Max         -0.455901
trainer/Policy log std Min         -2.466
trainer/Alpha                       0.0635739
trainer/Alpha Loss                  0.377097
exploration/num steps total    121200
exploration/num paths total      1212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.279542
exploration/Rewards Std             0.838865
exploration/Rewards Max            -0.00892
exploration/Rewards Min            -8.85001
exploration/Returns Mean          -27.9542
exploration/Returns Std            11.1245
exploration/Returns Max           -13.2559
exploration/Returns Min           -47.7457
exploration/Actions Mean           -0.00634898
exploration/Actions Std             0.232487
exploration/Actions Max             0.998585
exploration/Actions Min            -0.998034
exploration/Num Paths               5
exploration/Average Returns       -27.9542
evaluation/num steps total     363000
evaluation/num paths total       3630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.317443
evaluation/Rewards Std              1.21184
evaluation/Rewards Max             -0.0381083
evaluation/Rewards Min            -11.378
evaluation/Returns Mean           -31.7443
evaluation/Returns Std             19.1476
evaluation/Returns Max             -6.49328
evaluation/Returns Min            -64.334
evaluation/Actions Mean             0.0195277
evaluation/Actions Std              0.207556
evaluation/Actions Max              0.998914
evaluation/Actions Min             -0.998308
evaluation/Num Paths               15
evaluation/Average Returns        -31.7443
time/data storing (s)               0.00306769
time/evaluation sampling (s)        0.361528
time/exploration sampling (s)       0.165121
time/logging (s)                    0.00487381
time/saving (s)                     0.00205666
time/training (s)                   2.13565
time/epoch (s)                      2.67229
time/total (s)                    653.771
Epoch                             241
-----------------------------  ---------------
2019-04-22 21:48:57.781798 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 242 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.359238
trainer/QF2 Loss                    0.354613
trainer/Policy Loss                 8.97255
trainer/Q1 Predictions Mean        -7.03195
trainer/Q1 Predictions Std          2.90737
trainer/Q1 Predictions Max         -5.96266
trainer/Q1 Predictions Min        -25.4723
trainer/Q2 Predictions Mean        -7.0416
trainer/Q2 Predictions Std          2.87738
trainer/Q2 Predictions Max         -5.96458
trainer/Q2 Predictions Min        -25.0383
trainer/Q Targets Mean             -7.00123
trainer/Q Targets Std               2.94774
trainer/Q Targets Max              -0.183258
trainer/Q Targets Min             -25.2249
trainer/Log Pis Mean                1.96016
trainer/Log Pis Std                 1.38499
trainer/Log Pis Max                 7.74073
trainer/Log Pis Min                -3.64785
trainer/Policy mu Mean             -0.10877
trainer/Policy mu Std               0.495055
trainer/Policy mu Max               0.734024
trainer/Policy mu Min              -3.01105
trainer/Policy log std Mean        -2.2843
trainer/Policy log std Std          0.327117
trainer/Policy log std Max         -0.579729
trainer/Policy log std Min         -2.44788
trainer/Alpha                       0.0622562
trainer/Alpha Loss                 -0.110631
exploration/num steps total    121700
exploration/num paths total      1217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.302469
exploration/Rewards Std             0.928128
exploration/Rewards Max            -0.00977713
exploration/Rewards Min            -8.21316
exploration/Returns Mean          -30.2469
exploration/Returns Std            11.5363
exploration/Returns Max           -16.5852
exploration/Returns Min           -49.7253
exploration/Actions Mean            0.0042477
exploration/Actions Std             0.23652
exploration/Actions Max             0.99918
exploration/Actions Min            -0.99916
exploration/Num Paths               5
exploration/Average Returns       -30.2469
evaluation/num steps total     364500
evaluation/num paths total       3645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.209738
evaluation/Rewards Std              0.938569
evaluation/Rewards Max             -0.0210141
evaluation/Rewards Min             -9.06028
evaluation/Returns Mean           -20.9738
evaluation/Returns Std             14.0034
evaluation/Returns Max             -2.73321
evaluation/Returns Min            -45.8408
evaluation/Actions Mean             0.00646233
evaluation/Actions Std              0.18511
evaluation/Actions Max              0.997748
evaluation/Actions Min             -0.997947
evaluation/Num Paths               15
evaluation/Average Returns        -20.9738
time/data storing (s)               0.00325922
time/evaluation sampling (s)        0.364762
time/exploration sampling (s)       0.165008
time/logging (s)                    0.00451921
time/saving (s)                     0.00206468
time/training (s)                   2.14335
time/epoch (s)                      2.68297
time/total (s)                    656.458
Epoch                             242
-----------------------------  ---------------
2019-04-22 21:49:00.488121 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 243 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.363965
trainer/QF2 Loss                    0.370328
trainer/Policy Loss                 9.59125
trainer/Q1 Predictions Mean        -7.47358
trainer/Q1 Predictions Std          3.969
trainer/Q1 Predictions Max         -5.84385
trainer/Q1 Predictions Min        -31.5379
trainer/Q2 Predictions Mean        -7.49104
trainer/Q2 Predictions Std          4.00921
trainer/Q2 Predictions Max         -5.85634
trainer/Q2 Predictions Min        -31.9355
trainer/Q Targets Mean             -7.53223
trainer/Q Targets Std               4.05421
trainer/Q Targets Max              -0.130656
trainer/Q Targets Min             -31.5404
trainer/Log Pis Mean                2.13963
trainer/Log Pis Std                 1.13114
trainer/Log Pis Max                 7.9876
trainer/Log Pis Min                -1.79175
trainer/Policy mu Mean             -0.0437617
trainer/Policy mu Std               0.599384
trainer/Policy mu Max               2.9293
trainer/Policy mu Min              -3.22095
trainer/Policy log std Mean        -2.23376
trainer/Policy log std Std          0.387729
trainer/Policy log std Max         -0.579371
trainer/Policy log std Min         -2.48967
trainer/Alpha                       0.0618546
trainer/Alpha Loss                  0.388588
exploration/num steps total    122200
exploration/num paths total      1222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.442691
exploration/Rewards Std             1.40276
exploration/Rewards Max            -0.00474378
exploration/Rewards Min           -10.255
exploration/Returns Mean          -44.2691
exploration/Returns Std            19.285
exploration/Returns Max           -13.6244
exploration/Returns Min           -64.284
exploration/Actions Mean            0.0227256
exploration/Actions Std             0.255897
exploration/Actions Max             0.99959
exploration/Actions Min            -0.994384
exploration/Num Paths               5
exploration/Average Returns       -44.2691
evaluation/num steps total     366000
evaluation/num paths total       3660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.143918
evaluation/Rewards Std              0.674406
evaluation/Rewards Max             -0.00715214
evaluation/Rewards Min            -10.4125
evaluation/Returns Mean           -14.3918
evaluation/Returns Std             12.4567
evaluation/Returns Max             -4.03598
evaluation/Returns Min            -53.2149
evaluation/Actions Mean            -0.00415975
evaluation/Actions Std              0.157641
evaluation/Actions Max              0.994013
evaluation/Actions Min             -0.998754
evaluation/Num Paths               15
evaluation/Average Returns        -14.3918
time/data storing (s)               0.00309297
time/evaluation sampling (s)        0.375909
time/exploration sampling (s)       0.17084
time/logging (s)                    0.00494032
time/saving (s)                     0.00208822
time/training (s)                   2.14121
time/epoch (s)                      2.69808
time/total (s)                    659.161
Epoch                             243
-----------------------------  ---------------
2019-04-22 21:49:03.126914 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 244 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.09964
trainer/QF2 Loss                    1.09995
trainer/Policy Loss                 8.3339
trainer/Q1 Predictions Mean        -6.56797
trainer/Q1 Predictions Std          0.804488
trainer/Q1 Predictions Max         -5.97907
trainer/Q1 Predictions Min        -10.9756
trainer/Q2 Predictions Mean        -6.56377
trainer/Q2 Predictions Std          0.810657
trainer/Q2 Predictions Max         -5.9949
trainer/Q2 Predictions Min        -11.0266
trainer/Q Targets Mean             -6.44386
trainer/Q Targets Std               1.34721
trainer/Q Targets Max              -0.0746368
trainer/Q Targets Min             -10.8634
trainer/Log Pis Mean                1.76857
trainer/Log Pis Std                 1.16246
trainer/Log Pis Max                 5.36449
trainer/Log Pis Min                -2.06243
trainer/Policy mu Mean             -0.00398793
trainer/Policy mu Std               0.440271
trainer/Policy mu Max               2.46495
trainer/Policy mu Min              -2.62911
trainer/Policy log std Mean        -2.2166
trainer/Policy log std Std          0.336164
trainer/Policy log std Max         -0.620703
trainer/Policy log std Min         -2.47638
trainer/Alpha                       0.0626462
trainer/Alpha Loss                 -0.641079
exploration/num steps total    122700
exploration/num paths total      1227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.448588
exploration/Rewards Std             1.37948
exploration/Rewards Max            -0.00684642
exploration/Rewards Min           -10.124
exploration/Returns Mean          -44.8588
exploration/Returns Std            18.2578
exploration/Returns Max           -18.097
exploration/Returns Min           -64.4645
exploration/Actions Mean            0.0224257
exploration/Actions Std             0.259924
exploration/Actions Max             0.999553
exploration/Actions Min            -0.996473
exploration/Num Paths               5
exploration/Average Returns       -44.8588
evaluation/num steps total     367500
evaluation/num paths total       3675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.240421
evaluation/Rewards Std              1.04704
evaluation/Rewards Max             -0.0211132
evaluation/Rewards Min            -10.0312
evaluation/Returns Mean           -24.0421
evaluation/Returns Std             18.4971
evaluation/Returns Max             -3.81243
evaluation/Returns Min            -55.7581
evaluation/Actions Mean             0.000289845
evaluation/Actions Std              0.185334
evaluation/Actions Max              0.998579
evaluation/Actions Min             -0.998293
evaluation/Num Paths               15
evaluation/Average Returns        -24.0421
time/data storing (s)               0.00296913
time/evaluation sampling (s)        0.360175
time/exploration sampling (s)       0.160534
time/logging (s)                    0.00467059
time/saving (s)                     0.00179328
time/training (s)                   2.1001
time/epoch (s)                      2.63024
time/total (s)                    661.796
Epoch                             244
-----------------------------  ----------------
2019-04-22 21:49:05.811481 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 245 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0188949
trainer/QF2 Loss                    0.0288582
trainer/Policy Loss                 9.13806
trainer/Q1 Predictions Mean        -7.31351
trainer/Q1 Predictions Std          5.72451
trainer/Q1 Predictions Max         -5.8829
trainer/Q1 Predictions Min        -58.8875
trainer/Q2 Predictions Mean        -7.28651
trainer/Q2 Predictions Std          5.6345
trainer/Q2 Predictions Max         -5.87911
trainer/Q2 Predictions Min        -57.8935
trainer/Q Targets Mean             -7.35092
trainer/Q Targets Std               5.71203
trainer/Q Targets Max              -5.92542
trainer/Q Targets Min             -58.7009
trainer/Log Pis Mean                1.81844
trainer/Log Pis Std                 1.28866
trainer/Log Pis Max                 6.33199
trainer/Log Pis Min                -4.43151
trainer/Policy mu Mean             -0.0257476
trainer/Policy mu Std               0.536493
trainer/Policy mu Max               2.96269
trainer/Policy mu Min              -3.59461
trainer/Policy log std Mean        -2.22676
trainer/Policy log std Std          0.36416
trainer/Policy log std Max         -0.458746
trainer/Policy log std Min         -2.40861
trainer/Alpha                       0.0619646
trainer/Alpha Loss                 -0.504924
exploration/num steps total    123200
exploration/num paths total      1232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.313845
exploration/Rewards Std             0.978616
exploration/Rewards Max            -0.00215505
exploration/Rewards Min            -9.70943
exploration/Returns Mean          -31.3845
exploration/Returns Std            18.0983
exploration/Returns Max           -11.4924
exploration/Returns Min           -63.18
exploration/Actions Mean            0.00317088
exploration/Actions Std             0.229955
exploration/Actions Max             0.998648
exploration/Actions Min            -0.99862
exploration/Num Paths               5
exploration/Average Returns       -31.3845
evaluation/num steps total     369000
evaluation/num paths total       3690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199147
evaluation/Rewards Std              0.783155
evaluation/Rewards Max             -0.00950957
evaluation/Rewards Min             -8.79211
evaluation/Returns Mean           -19.9147
evaluation/Returns Std             11.2564
evaluation/Returns Max             -6.24454
evaluation/Returns Min            -46.8272
evaluation/Actions Mean             0.00527043
evaluation/Actions Std              0.184529
evaluation/Actions Max              0.997376
evaluation/Actions Min             -0.993577
evaluation/Num Paths               15
evaluation/Average Returns        -19.9147
time/data storing (s)               0.00290238
time/evaluation sampling (s)        0.350492
time/exploration sampling (s)       0.161498
time/logging (s)                    0.00482567
time/saving (s)                     0.00210314
time/training (s)                   2.15502
time/epoch (s)                      2.67684
time/total (s)                    664.476
Epoch                             245
-----------------------------  ---------------
2019-04-22 21:49:08.475329 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 246 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.536008
trainer/QF2 Loss                    0.527221
trainer/Policy Loss                 9.42597
trainer/Q1 Predictions Mean        -7.41505
trainer/Q1 Predictions Std          5.41549
trainer/Q1 Predictions Max         -5.91792
trainer/Q1 Predictions Min        -52.9685
trainer/Q2 Predictions Mean        -7.40872
trainer/Q2 Predictions Std          5.37205
trainer/Q2 Predictions Max         -5.90839
trainer/Q2 Predictions Min        -52.3058
trainer/Q Targets Mean             -7.36385
trainer/Q Targets Std               5.40923
trainer/Q Targets Max              -0.106933
trainer/Q Targets Min             -52.7262
trainer/Log Pis Mean                2.01503
trainer/Log Pis Std                 1.50295
trainer/Log Pis Max                 9.77609
trainer/Log Pis Min                -2.0326
trainer/Policy mu Mean             -0.0663485
trainer/Policy mu Std               0.553947
trainer/Policy mu Max               2.85307
trainer/Policy mu Min              -3.49839
trainer/Policy log std Mean        -2.23353
trainer/Policy log std Std          0.3457
trainer/Policy log std Max         -0.468115
trainer/Policy log std Min         -2.41971
trainer/Alpha                       0.0620236
trainer/Alpha Loss                  0.0417895
exploration/num steps total    123700
exploration/num paths total      1237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.348458
exploration/Rewards Std             1.03582
exploration/Rewards Max            -0.0117667
exploration/Rewards Min            -9.65849
exploration/Returns Mean          -34.8458
exploration/Returns Std            17.4065
exploration/Returns Max           -16.6943
exploration/Returns Min           -66.0709
exploration/Actions Mean            0.0123588
exploration/Actions Std             0.243005
exploration/Actions Max             0.998487
exploration/Actions Min            -0.998953
exploration/Num Paths               5
exploration/Average Returns       -34.8458
evaluation/num steps total     370500
evaluation/num paths total       3705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256913
evaluation/Rewards Std              1.01122
evaluation/Rewards Max             -0.0280972
evaluation/Rewards Min            -11.1221
evaluation/Returns Mean           -25.6913
evaluation/Returns Std             15.049
evaluation/Returns Max             -4.81792
evaluation/Returns Min            -57.1619
evaluation/Actions Mean            -0.0063276
evaluation/Actions Std              0.201766
evaluation/Actions Max              0.998278
evaluation/Actions Min             -0.998304
evaluation/Num Paths               15
evaluation/Average Returns        -25.6913
time/data storing (s)               0.00304943
time/evaluation sampling (s)        0.351755
time/exploration sampling (s)       0.1597
time/logging (s)                    0.00464887
time/saving (s)                     0.00205075
time/training (s)                   2.13473
time/epoch (s)                      2.65594
time/total (s)                    667.137
Epoch                             246
-----------------------------  ---------------
2019-04-22 21:49:11.202839 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 247 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.426591
trainer/QF2 Loss                    0.403221
trainer/Policy Loss                 9.41357
trainer/Q1 Predictions Mean        -7.47183
trainer/Q1 Predictions Std          6.07259
trainer/Q1 Predictions Max         -6.01323
trainer/Q1 Predictions Min        -60.8984
trainer/Q2 Predictions Mean        -7.4714
trainer/Q2 Predictions Std          6.15407
trainer/Q2 Predictions Max         -5.99176
trainer/Q2 Predictions Min        -61.8673
trainer/Q Targets Mean             -7.47452
trainer/Q Targets Std               6.26843
trainer/Q Targets Max              -0.129508
trainer/Q Targets Min             -62.6098
trainer/Log Pis Mean                1.93994
trainer/Log Pis Std                 1.47385
trainer/Log Pis Max                 8.31663
trainer/Log Pis Min                -7.23001
trainer/Policy mu Mean              0.0383064
trainer/Policy mu Std               0.542695
trainer/Policy mu Max               3.7056
trainer/Policy mu Min              -3.08127
trainer/Policy log std Mean        -2.25985
trainer/Policy log std Std          0.356656
trainer/Policy log std Max         -0.420516
trainer/Policy log std Min         -2.51024
trainer/Alpha                       0.0614311
trainer/Alpha Loss                 -0.167567
exploration/num steps total    124200
exploration/num paths total      1242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.203061
exploration/Rewards Std             0.567487
exploration/Rewards Max            -0.00769156
exploration/Rewards Min            -6.962
exploration/Returns Mean          -20.3061
exploration/Returns Std             9.98859
exploration/Returns Max           -10.7057
exploration/Returns Min           -39.5995
exploration/Actions Mean           -0.0186187
exploration/Actions Std             0.185316
exploration/Actions Max             0.791179
exploration/Actions Min            -0.999488
exploration/Num Paths               5
exploration/Average Returns       -20.3061
evaluation/num steps total     372000
evaluation/num paths total       3720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.136251
evaluation/Rewards Std              0.70141
evaluation/Rewards Max             -0.00757279
evaluation/Rewards Min             -9.27001
evaluation/Returns Mean           -13.6251
evaluation/Returns Std             11.4975
evaluation/Returns Max             -0.977551
evaluation/Returns Min            -48.0697
evaluation/Actions Mean            -0.0037824
evaluation/Actions Std              0.169371
evaluation/Actions Max              0.997635
evaluation/Actions Min             -0.996633
evaluation/Num Paths               15
evaluation/Average Returns        -13.6251
time/data storing (s)               0.00336342
time/evaluation sampling (s)        0.362223
time/exploration sampling (s)       0.166591
time/logging (s)                    0.00433424
time/saving (s)                     0.00181124
time/training (s)                   2.18027
time/epoch (s)                      2.7186
time/total (s)                    669.86
Epoch                             247
-----------------------------  ---------------
2019-04-22 21:49:13.908019 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 248 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0128484
trainer/QF2 Loss                    0.0126748
trainer/Policy Loss                 9.26854
trainer/Q1 Predictions Mean        -7.2298
trainer/Q1 Predictions Std          3.30376
trainer/Q1 Predictions Max         -5.93724
trainer/Q1 Predictions Min        -29.2471
trainer/Q2 Predictions Mean        -7.23599
trainer/Q2 Predictions Std          3.29695
trainer/Q2 Predictions Max         -5.94983
trainer/Q2 Predictions Min        -29.0648
trainer/Q Targets Mean             -7.23937
trainer/Q Targets Std               3.25974
trainer/Q Targets Max              -5.96225
trainer/Q Targets Min             -29.0243
trainer/Log Pis Mean                2.04992
trainer/Log Pis Std                 1.17386
trainer/Log Pis Max                 5.89905
trainer/Log Pis Min                -1.54872
trainer/Policy mu Mean              0.052574
trainer/Policy mu Std               0.551469
trainer/Policy mu Max               2.86931
trainer/Policy mu Min              -3.04569
trainer/Policy log std Mean        -2.21395
trainer/Policy log std Std          0.386727
trainer/Policy log std Max         -0.547983
trainer/Policy log std Min         -2.44978
trainer/Alpha                       0.0613611
trainer/Alpha Loss                  0.139312
exploration/num steps total    124700
exploration/num paths total      1247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.260827
exploration/Rewards Std             0.738034
exploration/Rewards Max            -0.0127839
exploration/Rewards Min            -7.53724
exploration/Returns Mean          -26.0827
exploration/Returns Std            11.6979
exploration/Returns Max           -14.6595
exploration/Returns Min           -44.9526
exploration/Actions Mean            0.00104974
exploration/Actions Std             0.221384
exploration/Actions Max             0.99962
exploration/Actions Min            -0.995435
exploration/Num Paths               5
exploration/Average Returns       -26.0827
evaluation/num steps total     373500
evaluation/num paths total       3735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.266977
evaluation/Rewards Std              1.04096
evaluation/Rewards Max             -0.013021
evaluation/Rewards Min             -9.92808
evaluation/Returns Mean           -26.6977
evaluation/Returns Std             14.6589
evaluation/Returns Max             -3.57224
evaluation/Returns Min            -45.9225
evaluation/Actions Mean             0.00357761
evaluation/Actions Std              0.197889
evaluation/Actions Max              0.998977
evaluation/Actions Min             -0.998653
evaluation/Num Paths               15
evaluation/Average Returns        -26.6977
time/data storing (s)               0.00391475
time/evaluation sampling (s)        0.359917
time/exploration sampling (s)       0.196505
time/logging (s)                    0.00512246
time/saving (s)                     0.0124839
time/training (s)                   2.11909
time/epoch (s)                      2.69704
time/total (s)                    672.562
Epoch                             248
-----------------------------  ---------------
2019-04-22 21:49:16.611239 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 249 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.00861225
trainer/QF2 Loss                    0.0097691
trainer/Policy Loss                 8.87907
trainer/Q1 Predictions Mean        -6.96278
trainer/Q1 Predictions Std          3.78486
trainer/Q1 Predictions Max         -5.90173
trainer/Q1 Predictions Min        -40.173
trainer/Q2 Predictions Mean        -6.96016
trainer/Q2 Predictions Std          3.79318
trainer/Q2 Predictions Max         -5.88791
trainer/Q2 Predictions Min        -40.2356
trainer/Q Targets Mean             -7.01048
trainer/Q Targets Std               3.7662
trainer/Q Targets Max              -5.95156
trainer/Q Targets Min             -40.1025
trainer/Log Pis Mean                1.90812
trainer/Log Pis Std                 1.33312
trainer/Log Pis Max                 8.76717
trainer/Log Pis Min                -1.83866
trainer/Policy mu Mean              0.00328308
trainer/Policy mu Std               0.425066
trainer/Policy mu Max               2.87992
trainer/Policy mu Min              -3.23113
trainer/Policy log std Mean        -2.33521
trainer/Policy log std Std          0.279309
trainer/Policy log std Max         -0.625723
trainer/Policy log std Min         -2.55021
trainer/Alpha                       0.0601582
trainer/Alpha Loss                 -0.258274
exploration/num steps total    125200
exploration/num paths total      1252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.243061
exploration/Rewards Std             0.759598
exploration/Rewards Max            -0.0034496
exploration/Rewards Min            -7.64929
exploration/Returns Mean          -24.3061
exploration/Returns Std            10.4582
exploration/Returns Max           -10.8045
exploration/Returns Min           -34.7533
exploration/Actions Mean            0.00437473
exploration/Actions Std             0.212995
exploration/Actions Max             0.998656
exploration/Actions Min            -0.997777
exploration/Num Paths               5
exploration/Average Returns       -24.3061
evaluation/num steps total     375000
evaluation/num paths total       3750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.23648
evaluation/Rewards Std              1.06195
evaluation/Rewards Max             -0.00267922
evaluation/Rewards Min            -10.1075
evaluation/Returns Mean           -23.648
evaluation/Returns Std             16.7063
evaluation/Returns Max             -2.18069
evaluation/Returns Min            -56.0864
evaluation/Actions Mean             0.0136068
evaluation/Actions Std              0.198464
evaluation/Actions Max              0.999027
evaluation/Actions Min             -0.99839
evaluation/Num Paths               15
evaluation/Average Returns        -23.648
time/data storing (s)               0.00298116
time/evaluation sampling (s)        0.348541
time/exploration sampling (s)       0.156989
time/logging (s)                    0.00391064
time/saving (s)                     0.00184287
time/training (s)                   2.17915
time/epoch (s)                      2.69342
time/total (s)                    675.259
Epoch                             249
-----------------------------  ---------------
2019-04-22 21:49:19.269328 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 250 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0166175
trainer/QF2 Loss                    0.0176971
trainer/Policy Loss                 9.16785
trainer/Q1 Predictions Mean        -7.12254
trainer/Q1 Predictions Std          4.11099
trainer/Q1 Predictions Max         -5.87668
trainer/Q1 Predictions Min        -36.7396
trainer/Q2 Predictions Mean        -7.13534
trainer/Q2 Predictions Std          4.14074
trainer/Q2 Predictions Max         -5.84354
trainer/Q2 Predictions Min        -37.1524
trainer/Q Targets Mean             -7.18965
trainer/Q Targets Std               4.07552
trainer/Q Targets Max              -5.99118
trainer/Q Targets Min             -36.662
trainer/Log Pis Mean                2.05246
trainer/Log Pis Std                 1.28207
trainer/Log Pis Max                 7.42182
trainer/Log Pis Min                -2.03311
trainer/Policy mu Mean             -0.0538251
trainer/Policy mu Std               0.464131
trainer/Policy mu Max               2.81789
trainer/Policy mu Min              -3.15668
trainer/Policy log std Mean        -2.29634
trainer/Policy log std Std          0.272726
trainer/Policy log std Max         -0.420954
trainer/Policy log std Min         -2.44612
trainer/Alpha                       0.0616906
trainer/Alpha Loss                  0.146132
exploration/num steps total    125700
exploration/num paths total      1257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.186835
exploration/Rewards Std             0.420729
exploration/Rewards Max            -0.00107136
exploration/Rewards Min            -4.88864
exploration/Returns Mean          -18.6835
exploration/Returns Std             4.265
exploration/Returns Max           -12.8184
exploration/Returns Min           -24.9299
exploration/Actions Mean            0.010018
exploration/Actions Std             0.19889
exploration/Actions Max             0.997964
exploration/Actions Min            -0.99437
exploration/Num Paths               5
exploration/Average Returns       -18.6835
evaluation/num steps total     376500
evaluation/num paths total       3765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.208556
evaluation/Rewards Std              0.903592
evaluation/Rewards Max             -0.00269923
evaluation/Rewards Min            -10.6749
evaluation/Returns Mean           -20.8556
evaluation/Returns Std             15.2694
evaluation/Returns Max             -2.62813
evaluation/Returns Min            -60.3366
evaluation/Actions Mean            -0.00684763
evaluation/Actions Std              0.185304
evaluation/Actions Max              0.998625
evaluation/Actions Min             -0.997899
evaluation/Num Paths               15
evaluation/Average Returns        -20.8556
time/data storing (s)               0.00326471
time/evaluation sampling (s)        0.354487
time/exploration sampling (s)       0.161659
time/logging (s)                    0.0052032
time/saving (s)                     0.00204342
time/training (s)                   2.1242
time/epoch (s)                      2.65086
time/total (s)                    677.914
Epoch                             250
-----------------------------  ---------------
2019-04-22 21:49:21.970227 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 251 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.508288
trainer/QF2 Loss                    0.512051
trainer/Policy Loss                 9.23316
trainer/Q1 Predictions Mean        -7.13629
trainer/Q1 Predictions Std          5.3809
trainer/Q1 Predictions Max         -5.9527
trainer/Q1 Predictions Min        -58.1583
trainer/Q2 Predictions Mean        -7.1343
trainer/Q2 Predictions Std          5.33256
trainer/Q2 Predictions Max         -5.9574
trainer/Q2 Predictions Min        -57.6008
trainer/Q Targets Mean             -7.14849
trainer/Q Targets Std               5.46684
trainer/Q Targets Max              -0.268814
trainer/Q Targets Min             -58.6891
trainer/Log Pis Mean                2.10179
trainer/Log Pis Std                 1.07947
trainer/Log Pis Max                 6.25858
trainer/Log Pis Min                -1.49143
trainer/Policy mu Mean              0.0304835
trainer/Policy mu Std               0.480981
trainer/Policy mu Max               3.93388
trainer/Policy mu Min              -2.06671
trainer/Policy log std Mean        -2.28083
trainer/Policy log std Std          0.332542
trainer/Policy log std Max         -0.212724
trainer/Policy log std Min         -2.4774
trainer/Alpha                       0.0633829
trainer/Alpha Loss                  0.280798
exploration/num steps total    126200
exploration/num paths total      1262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.323088
exploration/Rewards Std             0.995698
exploration/Rewards Max            -0.00326723
exploration/Rewards Min            -9.68993
exploration/Returns Mean          -32.3088
exploration/Returns Std            13.664
exploration/Returns Max           -16.96
exploration/Returns Min           -56.6839
exploration/Actions Mean           -0.0248174
exploration/Actions Std             0.240832
exploration/Actions Max             0.987865
exploration/Actions Min            -0.99754
exploration/Num Paths               5
exploration/Average Returns       -32.3088
evaluation/num steps total     378000
evaluation/num paths total       3780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234368
evaluation/Rewards Std              1.0258
evaluation/Rewards Max             -0.0118592
evaluation/Rewards Min             -9.99388
evaluation/Returns Mean           -23.4368
evaluation/Returns Std             14.5133
evaluation/Returns Max             -4.01168
evaluation/Returns Min            -51.0263
evaluation/Actions Mean            -0.000709604
evaluation/Actions Std              0.204755
evaluation/Actions Max              0.99905
evaluation/Actions Min             -0.99812
evaluation/Num Paths               15
evaluation/Average Returns        -23.4368
time/data storing (s)               0.00311416
time/evaluation sampling (s)        0.362167
time/exploration sampling (s)       0.166635
time/logging (s)                    0.00503992
time/saving (s)                     0.00212968
time/training (s)                   2.15255
time/epoch (s)                      2.69163
time/total (s)                    680.611
Epoch                             251
-----------------------------  ----------------
2019-04-22 21:49:24.691130 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 252 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0261234
trainer/QF2 Loss                    0.0302705
trainer/Policy Loss                 9.86694
trainer/Q1 Predictions Mean        -7.80224
trainer/Q1 Predictions Std          6.57143
trainer/Q1 Predictions Max         -5.92574
trainer/Q1 Predictions Min        -54.2848
trainer/Q2 Predictions Mean        -7.78897
trainer/Q2 Predictions Std          6.47508
trainer/Q2 Predictions Max         -5.90813
trainer/Q2 Predictions Min        -53.0829
trainer/Q Targets Mean             -7.76714
trainer/Q Targets Std               6.5104
trainer/Q Targets Max              -5.95057
trainer/Q Targets Min             -53.9068
trainer/Log Pis Mean                2.08754
trainer/Log Pis Std                 1.32392
trainer/Log Pis Max                 8.47469
trainer/Log Pis Min                -2.74991
trainer/Policy mu Mean             -0.0949371
trainer/Policy mu Std               0.548403
trainer/Policy mu Max               2.74824
trainer/Policy mu Min              -3.81056
trainer/Policy log std Mean        -2.23702
trainer/Policy log std Std          0.329238
trainer/Policy log std Max         -0.47734
trainer/Policy log std Min         -2.44736
trainer/Alpha                       0.063577
trainer/Alpha Loss                  0.241209
exploration/num steps total    126700
exploration/num paths total      1267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.367429
exploration/Rewards Std             1.06187
exploration/Rewards Max            -0.00590356
exploration/Rewards Min            -9.43242
exploration/Returns Mean          -36.7429
exploration/Returns Std            13.375
exploration/Returns Max           -14.5668
exploration/Returns Min           -52.8521
exploration/Actions Mean           -0.00165961
exploration/Actions Std             0.244736
exploration/Actions Max             0.999402
exploration/Actions Min            -0.998362
exploration/Num Paths               5
exploration/Average Returns       -36.7429
evaluation/num steps total     379500
evaluation/num paths total       3795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.312965
evaluation/Rewards Std              1.12599
evaluation/Rewards Max             -0.0650252
evaluation/Rewards Min            -10.0726
evaluation/Returns Mean           -31.2965
evaluation/Returns Std             17.0054
evaluation/Returns Max             -8.73944
evaluation/Returns Min            -65.2327
evaluation/Actions Mean            -0.0164485
evaluation/Actions Std              0.204323
evaluation/Actions Max              0.998947
evaluation/Actions Min             -0.999248
evaluation/Num Paths               15
evaluation/Average Returns        -31.2965
time/data storing (s)               0.00311423
time/evaluation sampling (s)        0.40781
time/exploration sampling (s)       0.165729
time/logging (s)                    0.00499047
time/saving (s)                     0.00217548
time/training (s)                   2.12827
time/epoch (s)                      2.71209
time/total (s)                    683.328
Epoch                             252
-----------------------------  ---------------
2019-04-22 21:49:27.335385 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 253 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.506681
trainer/QF2 Loss                    0.498134
trainer/Policy Loss                 9.28949
trainer/Q1 Predictions Mean        -7.29486
trainer/Q1 Predictions Std          4.18638
trainer/Q1 Predictions Max         -5.78602
trainer/Q1 Predictions Min        -38.648
trainer/Q2 Predictions Mean        -7.29478
trainer/Q2 Predictions Std          4.14804
trainer/Q2 Predictions Max         -5.79814
trainer/Q2 Predictions Min        -38.4722
trainer/Q Targets Mean             -7.34187
trainer/Q Targets Std               4.18529
trainer/Q Targets Max              -0.221819
trainer/Q Targets Min             -38.309
trainer/Log Pis Mean                1.99666
trainer/Log Pis Std                 1.25647
trainer/Log Pis Max                 8.36218
trainer/Log Pis Min                -2.37154
trainer/Policy mu Mean              0.0243985
trainer/Policy mu Std               0.64111
trainer/Policy mu Max               3.23878
trainer/Policy mu Min              -3.02757
trainer/Policy log std Mean        -2.20589
trainer/Policy log std Std          0.424578
trainer/Policy log std Max         -0.553638
trainer/Policy log std Min         -2.45931
trainer/Alpha                       0.0621691
trainer/Alpha Loss                 -0.0092745
exploration/num steps total    127200
exploration/num paths total      1272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.34411
exploration/Rewards Std             1.11741
exploration/Rewards Max            -0.00302266
exploration/Rewards Min            -9.65145
exploration/Returns Mean          -34.411
exploration/Returns Std            18.1097
exploration/Returns Max           -13.9079
exploration/Returns Min           -61.7134
exploration/Actions Mean           -0.00372168
exploration/Actions Std             0.234674
exploration/Actions Max             0.999204
exploration/Actions Min            -0.99709
exploration/Num Paths               5
exploration/Average Returns       -34.411
evaluation/num steps total     381000
evaluation/num paths total       3810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.240906
evaluation/Rewards Std              1.00365
evaluation/Rewards Max             -0.0249076
evaluation/Rewards Min            -10.7816
evaluation/Returns Mean           -24.0906
evaluation/Returns Std             15.1242
evaluation/Returns Max             -6.02195
evaluation/Returns Min            -55.0064
evaluation/Actions Mean            -0.0160034
evaluation/Actions Std              0.194787
evaluation/Actions Max              0.996709
evaluation/Actions Min             -0.998742
evaluation/Num Paths               15
evaluation/Average Returns        -24.0906
time/data storing (s)               0.00325237
time/evaluation sampling (s)        0.363271
time/exploration sampling (s)       0.162758
time/logging (s)                    0.00492055
time/saving (s)                     0.00199304
time/training (s)                   2.09949
time/epoch (s)                      2.63569
time/total (s)                    685.968
Epoch                             253
-----------------------------  ---------------
2019-04-22 21:49:30.049986 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 254 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.381329
trainer/QF2 Loss                    0.380702
trainer/Policy Loss                 9.20482
trainer/Q1 Predictions Mean        -7.11178
trainer/Q1 Predictions Std          3.66016
trainer/Q1 Predictions Max         -5.98323
trainer/Q1 Predictions Min        -30.1934
trainer/Q2 Predictions Mean        -7.12474
trainer/Q2 Predictions Std          3.65629
trainer/Q2 Predictions Max         -5.96231
trainer/Q2 Predictions Min        -29.7744
trainer/Q Targets Mean             -7.09936
trainer/Q Targets Std               3.71319
trainer/Q Targets Max              -0.167384
trainer/Q Targets Min             -29.8808
trainer/Log Pis Mean                2.10353
trainer/Log Pis Std                 1.02118
trainer/Log Pis Max                 5.24614
trainer/Log Pis Min                -1.69189
trainer/Policy mu Mean             -0.015743
trainer/Policy mu Std               0.458182
trainer/Policy mu Max               3.00368
trainer/Policy mu Min              -2.87342
trainer/Policy log std Mean        -2.27873
trainer/Policy log std Std          0.331748
trainer/Policy log std Max         -0.509835
trainer/Policy log std Min         -2.51915
trainer/Alpha                       0.0596419
trainer/Alpha Loss                  0.291879
exploration/num steps total    127700
exploration/num paths total      1277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.313599
exploration/Rewards Std             0.904756
exploration/Rewards Max            -0.0177163
exploration/Rewards Min            -7.67187
exploration/Returns Mean          -31.3599
exploration/Returns Std             9.89376
exploration/Returns Max           -15.302
exploration/Returns Min           -43.8628
exploration/Actions Mean           -0.0199457
exploration/Actions Std             0.225904
exploration/Actions Max             0.997817
exploration/Actions Min            -0.999725
exploration/Num Paths               5
exploration/Average Returns       -31.3599
evaluation/num steps total     382500
evaluation/num paths total       3825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.193476
evaluation/Rewards Std              0.881498
evaluation/Rewards Max             -0.00984014
evaluation/Rewards Min             -9.27314
evaluation/Returns Mean           -19.3476
evaluation/Returns Std             12.8942
evaluation/Returns Max             -3.90349
evaluation/Returns Min            -39.4016
evaluation/Actions Mean            -0.00575509
evaluation/Actions Std              0.181391
evaluation/Actions Max              0.996916
evaluation/Actions Min             -0.998259
evaluation/Num Paths               15
evaluation/Average Returns        -19.3476
time/data storing (s)               0.0032275
time/evaluation sampling (s)        0.358388
time/exploration sampling (s)       0.162318
time/logging (s)                    0.0048781
time/saving (s)                     0.00204469
time/training (s)                   2.17507
time/epoch (s)                      2.70593
time/total (s)                    688.678
Epoch                             254
-----------------------------  ---------------
2019-04-22 21:49:32.728299 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 255 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0196009
trainer/QF2 Loss                    0.0206565
trainer/Policy Loss                 8.50993
trainer/Q1 Predictions Mean        -6.68147
trainer/Q1 Predictions Std          1.55113
trainer/Q1 Predictions Max         -5.96014
trainer/Q1 Predictions Min        -20.8657
trainer/Q2 Predictions Mean        -6.66533
trainer/Q2 Predictions Std          1.54866
trainer/Q2 Predictions Max         -5.89749
trainer/Q2 Predictions Min        -20.86
trainer/Q Targets Mean             -6.76766
trainer/Q Targets Std               1.55946
trainer/Q Targets Max              -5.94914
trainer/Q Targets Min             -20.9895
trainer/Log Pis Mean                1.85169
trainer/Log Pis Std                 0.95684
trainer/Log Pis Max                 4.29404
trainer/Log Pis Min                -1.62767
trainer/Policy mu Mean             -0.000410717
trainer/Policy mu Std               0.347024
trainer/Policy mu Max               2.89831
trainer/Policy mu Min              -2.43084
trainer/Policy log std Mean        -2.29898
trainer/Policy log std Std          0.246421
trainer/Policy log std Max         -0.563723
trainer/Policy log std Min         -2.4878
trainer/Alpha                       0.0578327
trainer/Alpha Loss                 -0.422738
exploration/num steps total    128200
exploration/num paths total      1282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.406577
exploration/Rewards Std             1.19884
exploration/Rewards Max            -0.00564277
exploration/Rewards Min            -8.86519
exploration/Returns Mean          -40.6577
exploration/Returns Std            11.9351
exploration/Returns Max           -18.6295
exploration/Returns Min           -54.9428
exploration/Actions Mean           -0.0104684
exploration/Actions Std             0.247084
exploration/Actions Max             0.99953
exploration/Actions Min            -0.999342
exploration/Num Paths               5
exploration/Average Returns       -40.6577
evaluation/num steps total     384000
evaluation/num paths total       3840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.218154
evaluation/Rewards Std              0.83557
evaluation/Rewards Max             -0.0235069
evaluation/Rewards Min             -7.48491
evaluation/Returns Mean           -21.8154
evaluation/Returns Std              9.63742
evaluation/Returns Max             -5.6367
evaluation/Returns Min            -36.9218
evaluation/Actions Mean            -0.00680094
evaluation/Actions Std              0.185944
evaluation/Actions Max              0.997108
evaluation/Actions Min             -0.997629
evaluation/Num Paths               15
evaluation/Average Returns        -21.8154
time/data storing (s)               0.00309332
time/evaluation sampling (s)        0.365041
time/exploration sampling (s)       0.164889
time/logging (s)                    0.00495939
time/saving (s)                     0.0021021
time/training (s)                   2.12896
time/epoch (s)                      2.66904
time/total (s)                    691.352
Epoch                             255
-----------------------------  ----------------
2019-04-22 21:49:35.410302 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 256 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.472648
trainer/QF2 Loss                    0.465134
trainer/Policy Loss                 9.05537
trainer/Q1 Predictions Mean        -7.0447
trainer/Q1 Predictions Std          3.27646
trainer/Q1 Predictions Max         -5.97333
trainer/Q1 Predictions Min        -29.0988
trainer/Q2 Predictions Mean        -7.04026
trainer/Q2 Predictions Std          3.2495
trainer/Q2 Predictions Max         -5.97944
trainer/Q2 Predictions Min        -28.6968
trainer/Q Targets Mean             -7.03168
trainer/Q Targets Std               3.3683
trainer/Q Targets Max              -0.13417
trainer/Q Targets Min             -29.1647
trainer/Log Pis Mean                2.0152
trainer/Log Pis Std                 1.05783
trainer/Log Pis Max                 5.01647
trainer/Log Pis Min                -2.07781
trainer/Policy mu Mean              0.0670644
trainer/Policy mu Std               0.504486
trainer/Policy mu Max               3.03607
trainer/Policy mu Min              -2.39376
trainer/Policy log std Mean        -2.27066
trainer/Policy log std Std          0.322731
trainer/Policy log std Max         -0.647247
trainer/Policy log std Min         -2.44498
trainer/Alpha                       0.0591542
trainer/Alpha Loss                  0.0429816
exploration/num steps total    128700
exploration/num paths total      1287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.359238
exploration/Rewards Std             1.20573
exploration/Rewards Max            -0.00654077
exploration/Rewards Min           -10.7707
exploration/Returns Mean          -35.9238
exploration/Returns Std            21.5818
exploration/Returns Max           -16.7036
exploration/Returns Min           -62.5595
exploration/Actions Mean            0.00749626
exploration/Actions Std             0.236603
exploration/Actions Max             0.998653
exploration/Actions Min            -0.991992
exploration/Num Paths               5
exploration/Average Returns       -35.9238
evaluation/num steps total     385500
evaluation/num paths total       3855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.23972
evaluation/Rewards Std              0.995799
evaluation/Rewards Max             -0.00731048
evaluation/Rewards Min             -9.49248
evaluation/Returns Mean           -23.972
evaluation/Returns Std             12.6507
evaluation/Returns Max             -8.9879
evaluation/Returns Min            -45.472
evaluation/Actions Mean             0.0170643
evaluation/Actions Std              0.188753
evaluation/Actions Max              0.998485
evaluation/Actions Min             -0.997319
evaluation/Num Paths               15
evaluation/Average Returns        -23.972
time/data storing (s)               0.0031916
time/evaluation sampling (s)        0.360926
time/exploration sampling (s)       0.1647
time/logging (s)                    0.00479126
time/saving (s)                     0.00199317
time/training (s)                   2.13802
time/epoch (s)                      2.67362
time/total (s)                    694.03
Epoch                             256
-----------------------------  ---------------
2019-04-22 21:49:38.066263 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 257 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0204555
trainer/QF2 Loss                    0.0188017
trainer/Policy Loss                 9.51275
trainer/Q1 Predictions Mean        -7.46709
trainer/Q1 Predictions Std          4.38854
trainer/Q1 Predictions Max         -5.84445
trainer/Q1 Predictions Min        -29.4305
trainer/Q2 Predictions Mean        -7.46909
trainer/Q2 Predictions Std          4.41106
trainer/Q2 Predictions Max         -5.89088
trainer/Q2 Predictions Min        -29.8625
trainer/Q Targets Mean             -7.55634
trainer/Q Targets Std               4.37668
trainer/Q Targets Max              -5.97358
trainer/Q Targets Min             -29.8601
trainer/Log Pis Mean                2.03648
trainer/Log Pis Std                 1.13109
trainer/Log Pis Max                 6.85789
trainer/Log Pis Min                -2.41254
trainer/Policy mu Mean              0.000358039
trainer/Policy mu Std               0.601829
trainer/Policy mu Max               3.05897
trainer/Policy mu Min              -2.90048
trainer/Policy log std Mean        -2.23781
trainer/Policy log std Std          0.385322
trainer/Policy log std Max         -0.524218
trainer/Policy log std Min         -2.45556
trainer/Alpha                       0.0617413
trainer/Alpha Loss                  0.101597
exploration/num steps total    129200
exploration/num paths total      1292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.352999
exploration/Rewards Std             1.16424
exploration/Rewards Max            -0.00560566
exploration/Rewards Min            -9.64481
exploration/Returns Mean          -35.2999
exploration/Returns Std            21.0893
exploration/Returns Max           -13.957
exploration/Returns Min           -62.6235
exploration/Actions Mean            0.020682
exploration/Actions Std             0.228494
exploration/Actions Max             0.999351
exploration/Actions Min            -0.98893
exploration/Num Paths               5
exploration/Average Returns       -35.2999
evaluation/num steps total     387000
evaluation/num paths total       3870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226861
evaluation/Rewards Std              0.968235
evaluation/Rewards Max             -0.00506539
evaluation/Rewards Min             -9.14819
evaluation/Returns Mean           -22.6861
evaluation/Returns Std             14.2399
evaluation/Returns Max             -6.35391
evaluation/Returns Min            -50.9626
evaluation/Actions Mean             0.00233143
evaluation/Actions Std              0.190629
evaluation/Actions Max              0.997984
evaluation/Actions Min             -0.998318
evaluation/Num Paths               15
evaluation/Average Returns        -22.6861
time/data storing (s)               0.00305816
time/evaluation sampling (s)        0.357773
time/exploration sampling (s)       0.165298
time/logging (s)                    0.00514798
time/saving (s)                     0.00181095
time/training (s)                   2.11448
time/epoch (s)                      2.64757
time/total (s)                    696.682
Epoch                             257
-----------------------------  ----------------
2019-04-22 21:49:40.756845 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 258 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.00744392
trainer/QF2 Loss                    0.00844588
trainer/Policy Loss                 8.48071
trainer/Q1 Predictions Mean        -6.73739
trainer/Q1 Predictions Std          1.49065
trainer/Q1 Predictions Max         -5.9619
trainer/Q1 Predictions Min        -17.6442
trainer/Q2 Predictions Mean        -6.73163
trainer/Q2 Predictions Std          1.53104
trainer/Q2 Predictions Max         -5.92922
trainer/Q2 Predictions Min        -17.9488
trainer/Q Targets Mean             -6.74516
trainer/Q Targets Std               1.5178
trainer/Q Targets Max              -5.94979
trainer/Q Targets Min             -17.9022
trainer/Log Pis Mean                1.73242
trainer/Log Pis Std                 1.15956
trainer/Log Pis Max                 6.08676
trainer/Log Pis Min                -1.21277
trainer/Policy mu Mean              0.00974602
trainer/Policy mu Std               0.440881
trainer/Policy mu Max               2.80161
trainer/Policy mu Min              -2.71866
trainer/Policy log std Mean        -2.23338
trainer/Policy log std Std          0.303083
trainer/Policy log std Max         -0.628849
trainer/Policy log std Min         -2.39654
trainer/Alpha                       0.0617322
trainer/Alpha Loss                 -0.745127
exploration/num steps total    129700
exploration/num paths total      1297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.273113
exploration/Rewards Std             0.855472
exploration/Rewards Max            -0.00572467
exploration/Rewards Min            -9.44247
exploration/Returns Mean          -27.3113
exploration/Returns Std            12.1315
exploration/Returns Max           -15.7402
exploration/Returns Min           -49.0709
exploration/Actions Mean           -0.00736008
exploration/Actions Std             0.228029
exploration/Actions Max             0.997641
exploration/Actions Min            -0.999203
exploration/Num Paths               5
exploration/Average Returns       -27.3113
evaluation/num steps total     388500
evaluation/num paths total       3885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244242
evaluation/Rewards Std              1.09829
evaluation/Rewards Max             -0.0109019
evaluation/Rewards Min            -11.4708
evaluation/Returns Mean           -24.4242
evaluation/Returns Std             16.8272
evaluation/Returns Max             -3.36886
evaluation/Returns Min            -56.1511
evaluation/Actions Mean             0.00410553
evaluation/Actions Std              0.207272
evaluation/Actions Max              0.998964
evaluation/Actions Min             -0.99901
evaluation/Num Paths               15
evaluation/Average Returns        -24.4242
time/data storing (s)               0.00308714
time/evaluation sampling (s)        0.355633
time/exploration sampling (s)       0.160382
time/logging (s)                    0.00482949
time/saving (s)                     0.00201189
time/training (s)                   2.15565
time/epoch (s)                      2.68159
time/total (s)                    699.368
Epoch                             258
-----------------------------  ---------------
2019-04-22 21:49:43.401367 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 259 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.406351
trainer/QF2 Loss                    0.402906
trainer/Policy Loss                 8.86386
trainer/Q1 Predictions Mean        -6.95269
trainer/Q1 Predictions Std          2.91471
trainer/Q1 Predictions Max         -6.02344
trainer/Q1 Predictions Min        -28.7122
trainer/Q2 Predictions Mean        -6.93926
trainer/Q2 Predictions Std          2.87092
trainer/Q2 Predictions Max         -6.06316
trainer/Q2 Predictions Min        -28.4149
trainer/Q Targets Mean             -6.86007
trainer/Q Targets Std               2.95791
trainer/Q Targets Max              -0.0608859
trainer/Q Targets Min             -28.617
trainer/Log Pis Mean                1.93441
trainer/Log Pis Std                 0.85329
trainer/Log Pis Max                 4.19428
trainer/Log Pis Min                -0.351522
trainer/Policy mu Mean              0.0137674
trainer/Policy mu Std               0.324213
trainer/Policy mu Max               3.08122
trainer/Policy mu Min              -0.356349
trainer/Policy log std Mean        -2.29281
trainer/Policy log std Std          0.223768
trainer/Policy log std Max         -0.593985
trainer/Policy log std Min         -2.48993
trainer/Alpha                       0.059072
trainer/Alpha Loss                 -0.185558
exploration/num steps total    130200
exploration/num paths total      1302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281626
exploration/Rewards Std             0.762845
exploration/Rewards Max            -0.00594353
exploration/Rewards Min            -8.5115
exploration/Returns Mean          -28.1626
exploration/Returns Std             8.34411
exploration/Returns Max           -19.6263
exploration/Returns Min           -43.1859
exploration/Actions Mean           -0.0084877
exploration/Actions Std             0.224453
exploration/Actions Max             0.999305
exploration/Actions Min            -0.997969
exploration/Num Paths               5
exploration/Average Returns       -28.1626
evaluation/num steps total     390000
evaluation/num paths total       3900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.287175
evaluation/Rewards Std              1.0463
evaluation/Rewards Max             -0.0307633
evaluation/Rewards Min             -9.69656
evaluation/Returns Mean           -28.7175
evaluation/Returns Std             15.045
evaluation/Returns Max             -3.85123
evaluation/Returns Min            -57.4563
evaluation/Actions Mean            -0.00079225
evaluation/Actions Std              0.196881
evaluation/Actions Max              0.997146
evaluation/Actions Min             -0.999062
evaluation/Num Paths               15
evaluation/Average Returns        -28.7175
time/data storing (s)               0.00299998
time/evaluation sampling (s)        0.349546
time/exploration sampling (s)       0.157626
time/logging (s)                    0.00438046
time/saving (s)                     0.0123644
time/training (s)                   2.10856
time/epoch (s)                      2.63547
time/total (s)                    702.008
Epoch                             259
-----------------------------  ---------------
2019-04-22 21:49:46.017731 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 260 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0284397
trainer/QF2 Loss                    0.0221444
trainer/Policy Loss                 9.44054
trainer/Q1 Predictions Mean        -7.39046
trainer/Q1 Predictions Std          4.45039
trainer/Q1 Predictions Max         -5.89321
trainer/Q1 Predictions Min        -36.0983
trainer/Q2 Predictions Mean        -7.37484
trainer/Q2 Predictions Std          4.38775
trainer/Q2 Predictions Max         -5.90896
trainer/Q2 Predictions Min        -35.3978
trainer/Q Targets Mean             -7.47131
trainer/Q Targets Std               4.35967
trainer/Q Targets Max              -5.96354
trainer/Q Targets Min             -35.1794
trainer/Log Pis Mean                2.08325
trainer/Log Pis Std                 1.32876
trainer/Log Pis Max                 8.4698
trainer/Log Pis Min                -1.63626
trainer/Policy mu Mean             -0.0658122
trainer/Policy mu Std               0.600064
trainer/Policy mu Max               2.99854
trainer/Policy mu Min              -3.08516
trainer/Policy log std Mean        -2.21998
trainer/Policy log std Std          0.367904
trainer/Policy log std Max         -0.615275
trainer/Policy log std Min         -2.47788
trainer/Alpha                       0.0587998
trainer/Alpha Loss                  0.235911
exploration/num steps total    130700
exploration/num paths total      1307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.465383
exploration/Rewards Std             1.3972
exploration/Rewards Max            -0.000981098
exploration/Rewards Min           -11.0378
exploration/Returns Mean          -46.5383
exploration/Returns Std            17.6042
exploration/Returns Max           -23.163
exploration/Returns Min           -70.9209
exploration/Actions Mean           -0.0053679
exploration/Actions Std             0.260755
exploration/Actions Max             0.999808
exploration/Actions Min            -0.999837
exploration/Num Paths               5
exploration/Average Returns       -46.5383
evaluation/num steps total     391500
evaluation/num paths total       3915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.267603
evaluation/Rewards Std              0.955728
evaluation/Rewards Max             -0.00288197
evaluation/Rewards Min             -9.75941
evaluation/Returns Mean           -26.7603
evaluation/Returns Std             12.2271
evaluation/Returns Max            -11.6139
evaluation/Returns Min            -58.9298
evaluation/Actions Mean            -0.0105856
evaluation/Actions Std              0.191379
evaluation/Actions Max              0.998804
evaluation/Actions Min             -0.997692
evaluation/Num Paths               15
evaluation/Average Returns        -26.7603
time/data storing (s)               0.0029892
time/evaluation sampling (s)        0.359512
time/exploration sampling (s)       0.162089
time/logging (s)                    0.00494185
time/saving (s)                     0.00249024
time/training (s)                   2.07729
time/epoch (s)                      2.60931
time/total (s)                    704.623
Epoch                             260
-----------------------------  ----------------
2019-04-22 21:49:48.681310 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 261 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.363496
trainer/QF2 Loss                    0.362524
trainer/Policy Loss                 8.53697
trainer/Q1 Predictions Mean        -6.56953
trainer/Q1 Predictions Std          1.06786
trainer/Q1 Predictions Max         -5.93119
trainer/Q1 Predictions Min        -14.8369
trainer/Q2 Predictions Mean        -6.55796
trainer/Q2 Predictions Std          1.05403
trainer/Q2 Predictions Max         -5.88909
trainer/Q2 Predictions Min        -14.6712
trainer/Q Targets Mean             -6.57492
trainer/Q Targets Std               1.23151
trainer/Q Targets Max              -0.0712425
trainer/Q Targets Min             -14.9268
trainer/Log Pis Mean                1.99203
trainer/Log Pis Std                 1.0029
trainer/Log Pis Max                 4.65764
trainer/Log Pis Min                -1.634
trainer/Policy mu Mean              0.000134063
trainer/Policy mu Std               0.413232
trainer/Policy mu Max               2.67252
trainer/Policy mu Min              -2.734
trainer/Policy log std Mean        -2.25899
trainer/Policy log std Std          0.314979
trainer/Policy log std Max         -0.604728
trainer/Policy log std Min         -2.44697
trainer/Alpha                       0.0611916
trainer/Alpha Loss                 -0.022253
exploration/num steps total    131200
exploration/num paths total      1312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.347533
exploration/Rewards Std             1.10639
exploration/Rewards Max            -0.00514072
exploration/Rewards Min            -9.21262
exploration/Returns Mean          -34.7533
exploration/Returns Std            18.3085
exploration/Returns Max           -17.4561
exploration/Returns Min           -56.9965
exploration/Actions Mean            0.0163966
exploration/Actions Std             0.235327
exploration/Actions Max             0.998531
exploration/Actions Min            -0.996075
exploration/Num Paths               5
exploration/Average Returns       -34.7533
evaluation/num steps total     393000
evaluation/num paths total       3930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260997
evaluation/Rewards Std              1.11101
evaluation/Rewards Max             -0.0168708
evaluation/Rewards Min            -10.194
evaluation/Returns Mean           -26.0997
evaluation/Returns Std             18.1011
evaluation/Returns Max             -2.89722
evaluation/Returns Min            -57.7732
evaluation/Actions Mean             0.00203826
evaluation/Actions Std              0.190002
evaluation/Actions Max              0.999008
evaluation/Actions Min             -0.997043
evaluation/Num Paths               15
evaluation/Average Returns        -26.0997
time/data storing (s)               0.00294596
time/evaluation sampling (s)        0.385902
time/exploration sampling (s)       0.15639
time/logging (s)                    0.00495327
time/saving (s)                     0.00213023
time/training (s)                   2.10255
time/epoch (s)                      2.65487
time/total (s)                    707.282
Epoch                             261
-----------------------------  ----------------
2019-04-22 21:49:51.321331 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 262 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0169221
trainer/QF2 Loss                    0.0217303
trainer/Policy Loss                 9.13319
trainer/Q1 Predictions Mean        -7.21191
trainer/Q1 Predictions Std          3.67478
trainer/Q1 Predictions Max         -5.88795
trainer/Q1 Predictions Min        -29.4074
trainer/Q2 Predictions Mean        -7.18657
trainer/Q2 Predictions Std          3.68276
trainer/Q2 Predictions Max         -5.79828
trainer/Q2 Predictions Min        -29.3445
trainer/Q Targets Mean             -7.27784
trainer/Q Targets Std               3.63891
trainer/Q Targets Max              -5.96275
trainer/Q Targets Min             -29.4293
trainer/Log Pis Mean                1.92041
trainer/Log Pis Std                 1.24668
trainer/Log Pis Max                 8.03089
trainer/Log Pis Min                -1.66568
trainer/Policy mu Mean              0.000214145
trainer/Policy mu Std               0.583399
trainer/Policy mu Max               2.92771
trainer/Policy mu Min              -2.97687
trainer/Policy log std Mean        -2.21129
trainer/Policy log std Std          0.40895
trainer/Policy log std Max         -0.543163
trainer/Policy log std Min         -2.47854
trainer/Alpha                       0.0616897
trainer/Alpha Loss                 -0.221694
exploration/num steps total    131700
exploration/num paths total      1317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.364125
exploration/Rewards Std             1.10771
exploration/Rewards Max            -0.00808657
exploration/Rewards Min            -9.67875
exploration/Returns Mean          -36.4125
exploration/Returns Std            13.5891
exploration/Returns Max           -16.3905
exploration/Returns Min           -57.6319
exploration/Actions Mean           -0.0109843
exploration/Actions Std             0.244981
exploration/Actions Max             0.998679
exploration/Actions Min            -0.999399
exploration/Num Paths               5
exploration/Average Returns       -36.4125
evaluation/num steps total     394500
evaluation/num paths total       3945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213031
evaluation/Rewards Std              0.988812
evaluation/Rewards Max             -0.00550762
evaluation/Rewards Min            -11.2297
evaluation/Returns Mean           -21.3031
evaluation/Returns Std             15.605
evaluation/Returns Max             -0.931872
evaluation/Returns Min            -54.8683
evaluation/Actions Mean             0.0138739
evaluation/Actions Std              0.191837
evaluation/Actions Max              0.998018
evaluation/Actions Min             -0.998746
evaluation/Num Paths               15
evaluation/Average Returns        -21.3031
time/data storing (s)               0.00323524
time/evaluation sampling (s)        0.359622
time/exploration sampling (s)       0.166475
time/logging (s)                    0.00492555
time/saving (s)                     0.00167538
time/training (s)                   2.095
time/epoch (s)                      2.63094
time/total (s)                    709.918
Epoch                             262
-----------------------------  ----------------
2019-04-22 21:49:54.011880 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 263 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0183018
trainer/QF2 Loss                    0.0173348
trainer/Policy Loss                 9.91384
trainer/Q1 Predictions Mean        -7.83855
trainer/Q1 Predictions Std          6.17734
trainer/Q1 Predictions Max         -5.94174
trainer/Q1 Predictions Min        -50.6971
trainer/Q2 Predictions Mean        -7.8549
trainer/Q2 Predictions Std          6.1562
trainer/Q2 Predictions Max         -6.03057
trainer/Q2 Predictions Min        -51.3236
trainer/Q Targets Mean             -7.91393
trainer/Q Targets Std               6.13746
trainer/Q Targets Max              -5.94861
trainer/Q Targets Min             -50.7679
trainer/Log Pis Mean                2.05716
trainer/Log Pis Std                 1.18003
trainer/Log Pis Max                 7.05606
trainer/Log Pis Min                -1.23302
trainer/Policy mu Mean             -0.0151953
trainer/Policy mu Std               0.631828
trainer/Policy mu Max               3.32148
trainer/Policy mu Min              -3.19488
trainer/Policy log std Mean        -2.20052
trainer/Policy log std Std          0.405028
trainer/Policy log std Max         -0.538631
trainer/Policy log std Min         -2.44341
trainer/Alpha                       0.0629325
trainer/Alpha Loss                  0.158085
exploration/num steps total    132200
exploration/num paths total      1322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.19826
exploration/Rewards Std             0.487734
exploration/Rewards Max            -0.00529102
exploration/Rewards Min            -5.70473
exploration/Returns Mean          -19.826
exploration/Returns Std             6.71387
exploration/Returns Max           -12.7767
exploration/Returns Min           -30.986
exploration/Actions Mean           -0.00833765
exploration/Actions Std             0.198392
exploration/Actions Max             0.999208
exploration/Actions Min            -0.999088
exploration/Num Paths               5
exploration/Average Returns       -19.826
evaluation/num steps total     396000
evaluation/num paths total       3960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.264424
evaluation/Rewards Std              1.08854
evaluation/Rewards Max             -0.020278
evaluation/Rewards Min            -10.7705
evaluation/Returns Mean           -26.4424
evaluation/Returns Std             15.2895
evaluation/Returns Max             -4.40993
evaluation/Returns Min            -53.2902
evaluation/Actions Mean            -0.0133925
evaluation/Actions Std              0.203856
evaluation/Actions Max              0.997894
evaluation/Actions Min             -0.998695
evaluation/Num Paths               15
evaluation/Average Returns        -26.4424
time/data storing (s)               0.00283229
time/evaluation sampling (s)        0.355606
time/exploration sampling (s)       0.164012
time/logging (s)                    0.00463016
time/saving (s)                     0.00208769
time/training (s)                   2.15226
time/epoch (s)                      2.68143
time/total (s)                    712.604
Epoch                             263
-----------------------------  ---------------
2019-04-22 21:49:56.651832 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 264 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0221109
trainer/QF2 Loss                    0.0228107
trainer/Policy Loss                 8.34158
trainer/Q1 Predictions Mean        -6.33872
trainer/Q1 Predictions Std          0.416559
trainer/Q1 Predictions Max         -5.94527
trainer/Q1 Predictions Min         -7.68361
trainer/Q2 Predictions Mean        -6.33169
trainer/Q2 Predictions Std          0.408242
trainer/Q2 Predictions Max         -5.9615
trainer/Q2 Predictions Min         -7.64898
trainer/Q Targets Mean             -6.44943
trainer/Q Targets Std               0.372014
trainer/Q Targets Max              -5.96814
trainer/Q Targets Min              -7.7069
trainer/Log Pis Mean                2.01782
trainer/Log Pis Std                 0.685281
trainer/Log Pis Max                 2.90113
trainer/Log Pis Min                 0.0258477
trainer/Policy mu Mean              0.00128689
trainer/Policy mu Std               0.337469
trainer/Policy mu Max               2.18472
trainer/Policy mu Min              -1.91245
trainer/Policy log std Mean        -2.24497
trainer/Policy log std Std          0.26298
trainer/Policy log std Max         -0.638695
trainer/Policy log std Min         -2.4161
trainer/Alpha                       0.0600053
trainer/Alpha Loss                  0.0501174
exploration/num steps total    132700
exploration/num paths total      1327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.28478
exploration/Rewards Std             0.835742
exploration/Rewards Max            -0.00701077
exploration/Rewards Min            -7.85175
exploration/Returns Mean          -28.478
exploration/Returns Std            12.4243
exploration/Returns Max           -13.45
exploration/Returns Min           -43.7809
exploration/Actions Mean           -0.00205345
exploration/Actions Std             0.221817
exploration/Actions Max             0.992865
exploration/Actions Min            -0.996371
exploration/Num Paths               5
exploration/Average Returns       -28.478
evaluation/num steps total     397500
evaluation/num paths total       3975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.265609
evaluation/Rewards Std              1.07988
evaluation/Rewards Max             -0.0234716
evaluation/Rewards Min            -10.187
evaluation/Returns Mean           -26.5609
evaluation/Returns Std             15.7886
evaluation/Returns Max             -5.44438
evaluation/Returns Min            -51.8127
evaluation/Actions Mean            -0.00856752
evaluation/Actions Std              0.201651
evaluation/Actions Max              0.997843
evaluation/Actions Min             -0.998545
evaluation/Num Paths               15
evaluation/Average Returns        -26.5609
time/data storing (s)               0.00312815
time/evaluation sampling (s)        0.359514
time/exploration sampling (s)       0.162273
time/logging (s)                    0.00477841
time/saving (s)                     0.00197842
time/training (s)                   2.09929
time/epoch (s)                      2.63097
time/total (s)                    715.239
Epoch                             264
-----------------------------  ---------------
2019-04-22 21:49:59.341849 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 265 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.398894
trainer/QF2 Loss                    0.402874
trainer/Policy Loss                 8.57287
trainer/Q1 Predictions Mean        -6.60974
trainer/Q1 Predictions Std          2.56056
trainer/Q1 Predictions Max         -5.82995
trainer/Q1 Predictions Min        -30.8441
trainer/Q2 Predictions Mean        -6.60244
trainer/Q2 Predictions Std          2.5627
trainer/Q2 Predictions Max         -5.80955
trainer/Q2 Predictions Min        -30.8344
trainer/Q Targets Mean             -6.64048
trainer/Q Targets Std               2.61908
trainer/Q Targets Max              -0.116069
trainer/Q Targets Min             -30.7892
trainer/Log Pis Mean                1.96704
trainer/Log Pis Std                 0.896161
trainer/Log Pis Max                 4.42911
trainer/Log Pis Min                -1.20994
trainer/Policy mu Mean             -0.0220427
trainer/Policy mu Std               0.364481
trainer/Policy mu Max               1.90291
trainer/Policy mu Min              -3.15012
trainer/Policy log std Mean        -2.32189
trainer/Policy log std Std          0.256167
trainer/Policy log std Max         -0.685734
trainer/Policy log std Min         -2.50058
trainer/Alpha                       0.0597329
trainer/Alpha Loss                 -0.0928757
exploration/num steps total    133200
exploration/num paths total      1332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.246526
exploration/Rewards Std             0.600022
exploration/Rewards Max            -0.00822317
exploration/Rewards Min            -6.08638
exploration/Returns Mean          -24.6526
exploration/Returns Std             4.02636
exploration/Returns Max           -20.0794
exploration/Returns Min           -31.1245
exploration/Actions Mean           -0.00614931
exploration/Actions Std             0.215098
exploration/Actions Max             0.996353
exploration/Actions Min            -0.998166
exploration/Num Paths               5
exploration/Average Returns       -24.6526
evaluation/num steps total     399000
evaluation/num paths total       3990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.235236
evaluation/Rewards Std              0.960477
evaluation/Rewards Max             -0.00713231
evaluation/Rewards Min             -8.8836
evaluation/Returns Mean           -23.5236
evaluation/Returns Std             15.4864
evaluation/Returns Max             -4.3458
evaluation/Returns Min            -51.8815
evaluation/Actions Mean             0.00579959
evaluation/Actions Std              0.190483
evaluation/Actions Max              0.998296
evaluation/Actions Min             -0.999092
evaluation/Num Paths               15
evaluation/Average Returns        -23.5236
time/data storing (s)               0.00360408
time/evaluation sampling (s)        0.355494
time/exploration sampling (s)       0.169962
time/logging (s)                    0.00386587
time/saving (s)                     0.00207384
time/training (s)                   2.14505
time/epoch (s)                      2.68005
time/total (s)                    717.924
Epoch                             265
-----------------------------  ---------------
2019-04-22 21:50:01.989654 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 266 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0250975
trainer/QF2 Loss                    0.0245553
trainer/Policy Loss                 8.81495
trainer/Q1 Predictions Mean        -6.96807
trainer/Q1 Predictions Std          3.09917
trainer/Q1 Predictions Max         -5.9853
trainer/Q1 Predictions Min        -33.3597
trainer/Q2 Predictions Mean        -6.9712
trainer/Q2 Predictions Std          3.11372
trainer/Q2 Predictions Max         -5.96873
trainer/Q2 Predictions Min        -33.5805
trainer/Q Targets Mean             -7.07176
trainer/Q Targets Std               3.10791
trainer/Q Targets Max              -6.02395
trainer/Q Targets Min             -33.5697
trainer/Log Pis Mean                1.84687
trainer/Log Pis Std                 1.26781
trainer/Log Pis Max                 7.95277
trainer/Log Pis Min                -2.61401
trainer/Policy mu Mean             -0.0545206
trainer/Policy mu Std               0.57379
trainer/Policy mu Max               2.74932
trainer/Policy mu Min              -3.17345
trainer/Policy log std Mean        -2.20974
trainer/Policy log std Std          0.391256
trainer/Policy log std Max         -0.542521
trainer/Policy log std Min         -2.43096
trainer/Alpha                       0.0623235
trainer/Alpha Loss                 -0.424992
exploration/num steps total    133700
exploration/num paths total      1337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.364586
exploration/Rewards Std             1.06185
exploration/Rewards Max            -0.00888398
exploration/Rewards Min            -8.33518
exploration/Returns Mean          -36.4586
exploration/Returns Std            10.3188
exploration/Returns Max           -19.9798
exploration/Returns Min           -52.5062
exploration/Actions Mean            0.00443744
exploration/Actions Std             0.247815
exploration/Actions Max             0.998761
exploration/Actions Min            -0.998817
exploration/Num Paths               5
exploration/Average Returns       -36.4586
evaluation/num steps total     400500
evaluation/num paths total       4005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.19219
evaluation/Rewards Std              0.829229
evaluation/Rewards Max             -0.000542117
evaluation/Rewards Min             -9.99686
evaluation/Returns Mean           -19.219
evaluation/Returns Std             13.4895
evaluation/Returns Max             -4.31886
evaluation/Returns Min            -55.204
evaluation/Actions Mean             0.0056992
evaluation/Actions Std              0.181649
evaluation/Actions Max              0.998009
evaluation/Actions Min             -0.994805
evaluation/Num Paths               15
evaluation/Average Returns        -19.219
time/data storing (s)               0.00320883
time/evaluation sampling (s)        0.350875
time/exploration sampling (s)       0.158903
time/logging (s)                    0.00490847
time/saving (s)                     0.0019952
time/training (s)                   2.12004
time/epoch (s)                      2.63993
time/total (s)                    720.569
Epoch                             266
-----------------------------  ----------------
2019-04-22 21:50:04.663672 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 267 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.385398
trainer/QF2 Loss                    0.390116
trainer/Policy Loss                 8.9438
trainer/Q1 Predictions Mean        -6.97539
trainer/Q1 Predictions Std          3.19687
trainer/Q1 Predictions Max         -6.06698
trainer/Q1 Predictions Min        -37.0315
trainer/Q2 Predictions Mean        -6.96833
trainer/Q2 Predictions Std          3.24116
trainer/Q2 Predictions Max         -6.09398
trainer/Q2 Predictions Min        -37.517
trainer/Q Targets Mean             -6.93646
trainer/Q Targets Std               3.26432
trainer/Q Targets Max              -0.075376
trainer/Q Targets Min             -36.9687
trainer/Log Pis Mean                1.97727
trainer/Log Pis Std                 1.08917
trainer/Log Pis Max                 6.72131
trainer/Log Pis Min                -1.8913
trainer/Policy mu Mean             -0.0212219
trainer/Policy mu Std               0.358372
trainer/Policy mu Max               2.59773
trainer/Policy mu Min              -3.46024
trainer/Policy log std Mean        -2.26082
trainer/Policy log std Std          0.209994
trainer/Policy log std Max         -0.620791
trainer/Policy log std Min         -2.40946
trainer/Alpha                       0.0587057
trainer/Alpha Loss                 -0.0644303
exploration/num steps total    134200
exploration/num paths total      1342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.340127
exploration/Rewards Std             1.0427
exploration/Rewards Max            -0.00129739
exploration/Rewards Min            -9.54623
exploration/Returns Mean          -34.0127
exploration/Returns Std            18.6164
exploration/Returns Max           -11.704
exploration/Returns Min           -65.6698
exploration/Actions Mean            0.00148568
exploration/Actions Std             0.227729
exploration/Actions Max             0.999383
exploration/Actions Min            -0.998346
exploration/Num Paths               5
exploration/Average Returns       -34.0127
evaluation/num steps total     402000
evaluation/num paths total       4020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.27269
evaluation/Rewards Std              1.0763
evaluation/Rewards Max             -0.00943261
evaluation/Rewards Min             -9.75723
evaluation/Returns Mean           -27.269
evaluation/Returns Std             16.7001
evaluation/Returns Max             -8.22547
evaluation/Returns Min            -57.8722
evaluation/Actions Mean             0.0137803
evaluation/Actions Std              0.191176
evaluation/Actions Max              0.998271
evaluation/Actions Min             -0.997377
evaluation/Num Paths               15
evaluation/Average Returns        -27.269
time/data storing (s)               0.00298944
time/evaluation sampling (s)        0.351012
time/exploration sampling (s)       0.161486
time/logging (s)                    0.00501057
time/saving (s)                     0.00205469
time/training (s)                   2.1423
time/epoch (s)                      2.66485
time/total (s)                    723.238
Epoch                             267
-----------------------------  ---------------
2019-04-22 21:50:07.298189 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 268 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.504906
trainer/QF2 Loss                    0.495055
trainer/Policy Loss                 9.54783
trainer/Q1 Predictions Mean        -7.43973
trainer/Q1 Predictions Std          5.18885
trainer/Q1 Predictions Max         -6.04218
trainer/Q1 Predictions Min        -52.0893
trainer/Q2 Predictions Mean        -7.43696
trainer/Q2 Predictions Std          5.20758
trainer/Q2 Predictions Max         -6.0681
trainer/Q2 Predictions Min        -52.3349
trainer/Q Targets Mean             -7.33616
trainer/Q Targets Std               5.25247
trainer/Q Targets Max              -0.177934
trainer/Q Targets Min             -52.4984
trainer/Log Pis Mean                2.13164
trainer/Log Pis Std                 1.20319
trainer/Log Pis Max                 6.55454
trainer/Log Pis Min                -3.15279
trainer/Policy mu Mean              0.0246285
trainer/Policy mu Std               0.481271
trainer/Policy mu Max               3.42429
trainer/Policy mu Min              -1.99474
trainer/Policy log std Mean        -2.30495
trainer/Policy log std Std          0.340251
trainer/Policy log std Max         -0.532408
trainer/Policy log std Min         -2.47553
trainer/Alpha                       0.0633818
trainer/Alpha Loss                  0.363168
exploration/num steps total    134700
exploration/num paths total      1347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.223639
exploration/Rewards Std             0.603064
exploration/Rewards Max            -0.00301879
exploration/Rewards Min            -7.12912
exploration/Returns Mean          -22.3639
exploration/Returns Std             9.20937
exploration/Returns Max           -14.9329
exploration/Returns Min           -40.505
exploration/Actions Mean            0.0226522
exploration/Actions Std             0.20467
exploration/Actions Max             0.996876
exploration/Actions Min            -0.988418
exploration/Num Paths               5
exploration/Average Returns       -22.3639
evaluation/num steps total     403500
evaluation/num paths total       4035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221736
evaluation/Rewards Std              0.907767
evaluation/Rewards Max             -0.0253534
evaluation/Rewards Min             -9.30676
evaluation/Returns Mean           -22.1736
evaluation/Returns Std             14.2555
evaluation/Returns Max             -3.62381
evaluation/Returns Min            -53.9452
evaluation/Actions Mean             0.00125662
evaluation/Actions Std              0.186729
evaluation/Actions Max              0.99794
evaluation/Actions Min             -0.997136
evaluation/Num Paths               15
evaluation/Average Returns        -22.1736
time/data storing (s)               0.00293182
time/evaluation sampling (s)        0.357086
time/exploration sampling (s)       0.161431
time/logging (s)                    0.00507666
time/saving (s)                     0.00197651
time/training (s)                   2.09729
time/epoch (s)                      2.62579
time/total (s)                    725.869
Epoch                             268
-----------------------------  ---------------
2019-04-22 21:50:09.927650 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 269 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.477069
trainer/QF2 Loss                    0.483294
trainer/Policy Loss                 8.7268
trainer/Q1 Predictions Mean        -6.78482
trainer/Q1 Predictions Std          3.39319
trainer/Q1 Predictions Max         -5.9597
trainer/Q1 Predictions Min        -39.4841
trainer/Q2 Predictions Mean        -6.76232
trainer/Q2 Predictions Std          3.37121
trainer/Q2 Predictions Max         -5.95875
trainer/Q2 Predictions Min        -39.2881
trainer/Q Targets Mean             -6.82441
trainer/Q Targets Std               3.40147
trainer/Q Targets Max              -0.101118
trainer/Q Targets Min             -39.0248
trainer/Log Pis Mean                1.94072
trainer/Log Pis Std                 1.0073
trainer/Log Pis Max                 5.96535
trainer/Log Pis Min                -1.05847
trainer/Policy mu Mean              0.0562953
trainer/Policy mu Std               0.417343
trainer/Policy mu Max               3.13692
trainer/Policy mu Min              -1.43211
trainer/Policy log std Mean        -2.27588
trainer/Policy log std Std          0.311402
trainer/Policy log std Max         -0.480163
trainer/Policy log std Min         -2.48421
trainer/Alpha                       0.064072
trainer/Alpha Loss                 -0.162894
exploration/num steps total    135200
exploration/num paths total      1352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.289297
exploration/Rewards Std             0.901481
exploration/Rewards Max            -0.0110665
exploration/Rewards Min            -8.39717
exploration/Returns Mean          -28.9297
exploration/Returns Std            15.7805
exploration/Returns Max           -14.216
exploration/Returns Min           -51.9505
exploration/Actions Mean            0.000120127
exploration/Actions Std             0.222335
exploration/Actions Max             0.99711
exploration/Actions Min            -0.999092
exploration/Num Paths               5
exploration/Average Returns       -28.9297
evaluation/num steps total     405000
evaluation/num paths total       4050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.217063
evaluation/Rewards Std              0.847424
evaluation/Rewards Max             -0.0296892
evaluation/Rewards Min             -9.89721
evaluation/Returns Mean           -21.7063
evaluation/Returns Std             13.6039
evaluation/Returns Max             -5.00894
evaluation/Returns Min            -49.318
evaluation/Actions Mean             0.00673108
evaluation/Actions Std              0.190427
evaluation/Actions Max              0.997255
evaluation/Actions Min             -0.998722
evaluation/Num Paths               15
evaluation/Average Returns        -21.7063
time/data storing (s)               0.00324722
time/evaluation sampling (s)        0.357981
time/exploration sampling (s)       0.16429
time/logging (s)                    0.00497966
time/saving (s)                     0.00196518
time/training (s)                   2.08797
time/epoch (s)                      2.62043
time/total (s)                    728.494
Epoch                             269
-----------------------------  ----------------
2019-04-22 21:50:12.681480 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 270 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.459296
trainer/QF2 Loss                    0.449564
trainer/Policy Loss                 9.12943
trainer/Q1 Predictions Mean        -7.38146
trainer/Q1 Predictions Std          4.66464
trainer/Q1 Predictions Max         -6.07743
trainer/Q1 Predictions Min        -41.6038
trainer/Q2 Predictions Mean        -7.36936
trainer/Q2 Predictions Std          4.6481
trainer/Q2 Predictions Max         -6.06198
trainer/Q2 Predictions Min        -41.4443
trainer/Q Targets Mean             -7.34663
trainer/Q Targets Std               4.70937
trainer/Q Targets Max              -0.228177
trainer/Q Targets Min             -41.4574
trainer/Log Pis Mean                1.72123
trainer/Log Pis Std                 1.75311
trainer/Log Pis Max                 8.10005
trainer/Log Pis Min                -4.64949
trainer/Policy mu Mean              0.00331284
trainer/Policy mu Std               0.613979
trainer/Policy mu Max               3.23528
trainer/Policy mu Min              -3.3479
trainer/Policy log std Mean        -2.21816
trainer/Policy log std Std          0.409173
trainer/Policy log std Max         -0.522167
trainer/Policy log std Min         -2.50595
trainer/Alpha                       0.061985
trainer/Alpha Loss                 -0.775176
exploration/num steps total    135700
exploration/num paths total      1357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.227032
exploration/Rewards Std             0.70061
exploration/Rewards Max            -0.00521914
exploration/Rewards Min            -7.80456
exploration/Returns Mean          -22.7032
exploration/Returns Std            12.3993
exploration/Returns Max           -12.676
exploration/Returns Min           -45.838
exploration/Actions Mean            0.0153638
exploration/Actions Std             0.205162
exploration/Actions Max             0.999317
exploration/Actions Min            -0.989244
exploration/Num Paths               5
exploration/Average Returns       -22.7032
evaluation/num steps total     406500
evaluation/num paths total       4065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.267182
evaluation/Rewards Std              1.15568
evaluation/Rewards Max             -0.00409696
evaluation/Rewards Min            -11.9165
evaluation/Returns Mean           -26.7182
evaluation/Returns Std             16.0472
evaluation/Returns Max             -1.96688
evaluation/Returns Min            -60.168
evaluation/Actions Mean            -0.0120662
evaluation/Actions Std              0.216957
evaluation/Actions Max              0.997914
evaluation/Actions Min             -0.999103
evaluation/Num Paths               15
evaluation/Average Returns        -26.7182
time/data storing (s)               0.00292022
time/evaluation sampling (s)        0.418816
time/exploration sampling (s)       0.165382
time/logging (s)                    0.00490974
time/saving (s)                     0.0346158
time/training (s)                   2.11739
time/epoch (s)                      2.74403
time/total (s)                    731.243
Epoch                             270
-----------------------------  ---------------
2019-04-22 21:50:15.304632 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 271 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.378261
trainer/QF2 Loss                    0.379344
trainer/Policy Loss                 8.454
trainer/Q1 Predictions Mean        -6.58664
trainer/Q1 Predictions Std          0.958366
trainer/Q1 Predictions Max         -6.14091
trainer/Q1 Predictions Min        -15.3647
trainer/Q2 Predictions Mean        -6.59111
trainer/Q2 Predictions Std          0.939544
trainer/Q2 Predictions Max         -6.16619
trainer/Q2 Predictions Min        -15.265
trainer/Q Targets Mean             -6.4827
trainer/Q Targets Std               1.16348
trainer/Q Targets Max              -0.0763094
trainer/Q Targets Min             -15.4808
trainer/Log Pis Mean                1.87863
trainer/Log Pis Std                 1.21659
trainer/Log Pis Max                 4.25426
trainer/Log Pis Min                -2.60603
trainer/Policy mu Mean             -0.00584074
trainer/Policy mu Std               0.231859
trainer/Policy mu Max               2.72771
trainer/Policy mu Min              -0.242684
trainer/Policy log std Mean        -2.3852
trainer/Policy log std Std          0.207993
trainer/Policy log std Max         -0.803785
trainer/Policy log std Min         -2.59991
trainer/Alpha                       0.0611365
trainer/Alpha Loss                 -0.339229
exploration/num steps total    136200
exploration/num paths total      1362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.417516
exploration/Rewards Std             1.25403
exploration/Rewards Max            -0.00477922
exploration/Rewards Min           -10.4971
exploration/Returns Mean          -41.7516
exploration/Returns Std             9.63666
exploration/Returns Max           -28.5187
exploration/Returns Min           -57.5003
exploration/Actions Mean           -0.0329989
exploration/Actions Std             0.253948
exploration/Actions Max             0.99553
exploration/Actions Min            -0.998518
exploration/Num Paths               5
exploration/Average Returns       -41.7516
evaluation/num steps total     408000
evaluation/num paths total       4080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.124636
evaluation/Rewards Std              0.630432
evaluation/Rewards Max             -0.00889993
evaluation/Rewards Min             -8.04247
evaluation/Returns Mean           -12.4636
evaluation/Returns Std             11.3411
evaluation/Returns Max             -1.66312
evaluation/Returns Min            -37.7992
evaluation/Actions Mean             0.00237892
evaluation/Actions Std              0.152278
evaluation/Actions Max              0.996399
evaluation/Actions Min             -0.998308
evaluation/Num Paths               15
evaluation/Average Returns        -12.4636
time/data storing (s)               0.00310167
time/evaluation sampling (s)        0.345758
time/exploration sampling (s)       0.160521
time/logging (s)                    0.00492797
time/saving (s)                     0.0019627
time/training (s)                   2.09795
time/epoch (s)                      2.61422
time/total (s)                    733.862
Epoch                             271
-----------------------------  ---------------
2019-04-22 21:50:17.983281 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 272 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.011482
trainer/QF2 Loss                    0.0117737
trainer/Policy Loss                 9.20768
trainer/Q1 Predictions Mean        -7.14527
trainer/Q1 Predictions Std          4.19429
trainer/Q1 Predictions Max         -6.15202
trainer/Q1 Predictions Min        -44.2303
trainer/Q2 Predictions Mean        -7.1252
trainer/Q2 Predictions Std          4.13714
trainer/Q2 Predictions Max         -6.10187
trainer/Q2 Predictions Min        -44.1213
trainer/Q Targets Mean             -7.14573
trainer/Q Targets Std               4.18847
trainer/Q Targets Max              -6.04438
trainer/Q Targets Min             -44.3898
trainer/Log Pis Mean                2.06327
trainer/Log Pis Std                 1.26712
trainer/Log Pis Max                 8.1749
trainer/Log Pis Min                -3.78668
trainer/Policy mu Mean              0.0494897
trainer/Policy mu Std               0.520899
trainer/Policy mu Max               3.44544
trainer/Policy mu Min              -2.32571
trainer/Policy log std Mean        -2.30956
trainer/Policy log std Std          0.341075
trainer/Policy log std Max         -0.493144
trainer/Policy log std Min         -2.52693
trainer/Alpha                       0.0615122
trainer/Alpha Loss                  0.176442
exploration/num steps total    136700
exploration/num paths total      1367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.235497
exploration/Rewards Std             0.65927
exploration/Rewards Max            -0.00503954
exploration/Rewards Min            -7.43626
exploration/Returns Mean          -23.5497
exploration/Returns Std            10.5246
exploration/Returns Max           -13.9552
exploration/Returns Min           -42.9458
exploration/Actions Mean            0.00514704
exploration/Actions Std             0.199256
exploration/Actions Max             0.999168
exploration/Actions Min            -0.996107
exploration/Num Paths               5
exploration/Average Returns       -23.5497
evaluation/num steps total     409500
evaluation/num paths total       4095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231507
evaluation/Rewards Std              0.890306
evaluation/Rewards Max             -0.0213299
evaluation/Rewards Min             -9.63864
evaluation/Returns Mean           -23.1507
evaluation/Returns Std             14.5831
evaluation/Returns Max             -4.56129
evaluation/Returns Min            -57.0474
evaluation/Actions Mean            -0.00934425
evaluation/Actions Std              0.180123
evaluation/Actions Max              0.997489
evaluation/Actions Min             -0.99936
evaluation/Num Paths               15
evaluation/Average Returns        -23.1507
time/data storing (s)               0.00283908
time/evaluation sampling (s)        0.349703
time/exploration sampling (s)       0.161684
time/logging (s)                    0.00443108
time/saving (s)                     0.00203402
time/training (s)                   2.14829
time/epoch (s)                      2.66898
time/total (s)                    736.536
Epoch                             272
-----------------------------  ---------------
2019-04-22 21:50:20.612411 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 273 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.402373
trainer/QF2 Loss                    0.403134
trainer/Policy Loss                 8.9851
trainer/Q1 Predictions Mean        -6.94317
trainer/Q1 Predictions Std          2.44825
trainer/Q1 Predictions Max         -5.9989
trainer/Q1 Predictions Min        -24.7647
trainer/Q2 Predictions Mean        -6.93588
trainer/Q2 Predictions Std          2.39292
trainer/Q2 Predictions Max         -5.99859
trainer/Q2 Predictions Min        -24.2264
trainer/Q Targets Mean             -6.88542
trainer/Q Targets Std               2.49983
trainer/Q Targets Max              -0.218464
trainer/Q Targets Min             -24.1822
trainer/Log Pis Mean                2.05791
trainer/Log Pis Std                 1.02718
trainer/Log Pis Max                 5.19411
trainer/Log Pis Min                -1.19829
trainer/Policy mu Mean              0.0597436
trainer/Policy mu Std               0.519964
trainer/Policy mu Max               3.19177
trainer/Policy mu Min              -2.20268
trainer/Policy log std Mean        -2.2341
trainer/Policy log std Std          0.380409
trainer/Policy log std Max         -0.399179
trainer/Policy log std Min         -2.44064
trainer/Alpha                       0.0621314
trainer/Alpha Loss                  0.160908
exploration/num steps total    137200
exploration/num paths total      1372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.3243
exploration/Rewards Std             0.994033
exploration/Rewards Max            -0.00226371
exploration/Rewards Min            -9.75484
exploration/Returns Mean          -32.43
exploration/Returns Std            17.8201
exploration/Returns Max           -13.8044
exploration/Returns Min           -65.6471
exploration/Actions Mean            8.47673e-05
exploration/Actions Std             0.221312
exploration/Actions Max             0.999725
exploration/Actions Min            -0.998069
exploration/Num Paths               5
exploration/Average Returns       -32.43
evaluation/num steps total     411000
evaluation/num paths total       4110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.271584
evaluation/Rewards Std              1.05475
evaluation/Rewards Max             -0.025282
evaluation/Rewards Min             -9.55542
evaluation/Returns Mean           -27.1584
evaluation/Returns Std             17.121
evaluation/Returns Max             -3.89085
evaluation/Returns Min            -54.9974
evaluation/Actions Mean             0.0219405
evaluation/Actions Std              0.191413
evaluation/Actions Max              0.998753
evaluation/Actions Min             -0.994121
evaluation/Num Paths               15
evaluation/Average Returns        -27.1584
time/data storing (s)               0.00298159
time/evaluation sampling (s)        0.35556
time/exploration sampling (s)       0.165183
time/logging (s)                    0.00515161
time/saving (s)                     0.00196631
time/training (s)                   2.09083
time/epoch (s)                      2.62167
time/total (s)                    739.162
Epoch                             273
-----------------------------  ----------------
2019-04-22 21:50:23.289791 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 274 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0156776
trainer/QF2 Loss                    0.021856
trainer/Policy Loss                 9.13906
trainer/Q1 Predictions Mean        -7.14124
trainer/Q1 Predictions Std          4.49351
trainer/Q1 Predictions Max         -6.06011
trainer/Q1 Predictions Min        -44.113
trainer/Q2 Predictions Mean        -7.11487
trainer/Q2 Predictions Std          4.49728
trainer/Q2 Predictions Max         -6.02948
trainer/Q2 Predictions Min        -44.1931
trainer/Q Targets Mean             -7.23161
trainer/Q Targets Std               4.4656
trainer/Q Targets Max              -6.07758
trainer/Q Targets Min             -44.0293
trainer/Log Pis Mean                2.02224
trainer/Log Pis Std                 1.1694
trainer/Log Pis Max                 7.05598
trainer/Log Pis Min                -1.62336
trainer/Policy mu Mean              0.00291699
trainer/Policy mu Std               0.418599
trainer/Policy mu Max               3.06628
trainer/Policy mu Min              -3.61815
trainer/Policy log std Mean        -2.31849
trainer/Policy log std Std          0.243016
trainer/Policy log std Max         -0.625817
trainer/Policy log std Min         -2.47853
trainer/Alpha                       0.0593866
trainer/Alpha Loss                  0.0628003
exploration/num steps total    137700
exploration/num paths total      1377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.259577
exploration/Rewards Std             0.731771
exploration/Rewards Max            -0.00672977
exploration/Rewards Min            -6.92016
exploration/Returns Mean          -25.9577
exploration/Returns Std            10.0319
exploration/Returns Max           -13.8956
exploration/Returns Min           -38.1482
exploration/Actions Mean           -0.00627181
exploration/Actions Std             0.218708
exploration/Actions Max             0.999172
exploration/Actions Min            -0.997129
exploration/Num Paths               5
exploration/Average Returns       -25.9577
evaluation/num steps total     412500
evaluation/num paths total       4125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.191141
evaluation/Rewards Std              0.779941
evaluation/Rewards Max             -0.0289787
evaluation/Rewards Min             -9.73983
evaluation/Returns Mean           -19.1141
evaluation/Returns Std             14.5667
evaluation/Returns Max             -4.16123
evaluation/Returns Min            -56.9338
evaluation/Actions Mean             9.73177e-05
evaluation/Actions Std              0.168756
evaluation/Actions Max              0.998127
evaluation/Actions Min             -0.99775
evaluation/Num Paths               15
evaluation/Average Returns        -19.1141
time/data storing (s)               0.00319514
time/evaluation sampling (s)        0.354008
time/exploration sampling (s)       0.166677
time/logging (s)                    0.00439154
time/saving (s)                     0.00200998
time/training (s)                   2.13711
time/epoch (s)                      2.66739
time/total (s)                    741.834
Epoch                             274
-----------------------------  ----------------
2019-04-22 21:50:25.931597 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 275 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0177421
trainer/QF2 Loss                    0.0219205
trainer/Policy Loss                 8.87953
trainer/Q1 Predictions Mean        -6.93544
trainer/Q1 Predictions Std          2.48231
trainer/Q1 Predictions Max         -6.0561
trainer/Q1 Predictions Min        -26.9874
trainer/Q2 Predictions Mean        -6.94624
trainer/Q2 Predictions Std          2.49621
trainer/Q2 Predictions Max         -6.03364
trainer/Q2 Predictions Min        -27.199
trainer/Q Targets Mean             -6.97402
trainer/Q Targets Std               2.47083
trainer/Q Targets Max              -6.09566
trainer/Q Targets Min             -26.7831
trainer/Log Pis Mean                1.92724
trainer/Log Pis Std                 1.23228
trainer/Log Pis Max                 8.18396
trainer/Log Pis Min                -1.38541
trainer/Policy mu Mean             -0.0530561
trainer/Policy mu Std               0.547333
trainer/Policy mu Max               2.35291
trainer/Policy mu Min              -2.9885
trainer/Policy log std Mean        -2.19559
trainer/Policy log std Std          0.371198
trainer/Policy log std Max         -0.478346
trainer/Policy log std Min         -2.50615
trainer/Alpha                       0.0594862
trainer/Alpha Loss                 -0.205313
exploration/num steps total    138200
exploration/num paths total      1382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.228555
exploration/Rewards Std             0.729576
exploration/Rewards Max            -0.00284506
exploration/Rewards Min            -8.29952
exploration/Returns Mean          -22.8555
exploration/Returns Std            13.2948
exploration/Returns Max           -11.1996
exploration/Returns Min           -47.5559
exploration/Actions Mean           -0.00523876
exploration/Actions Std             0.202348
exploration/Actions Max             0.998181
exploration/Actions Min            -0.996947
exploration/Num Paths               5
exploration/Average Returns       -22.8555
evaluation/num steps total     414000
evaluation/num paths total       4140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.248968
evaluation/Rewards Std              1.08755
evaluation/Rewards Max             -0.015235
evaluation/Rewards Min             -9.83675
evaluation/Returns Mean           -24.8968
evaluation/Returns Std             15.9943
evaluation/Returns Max             -2.21887
evaluation/Returns Min            -53.7509
evaluation/Actions Mean            -0.00018858
evaluation/Actions Std              0.198215
evaluation/Actions Max              0.99841
evaluation/Actions Min             -0.998928
evaluation/Num Paths               15
evaluation/Average Returns        -24.8968
time/data storing (s)               0.00343236
time/evaluation sampling (s)        0.363487
time/exploration sampling (s)       0.164564
time/logging (s)                    0.0050659
time/saving (s)                     0.00162638
time/training (s)                   2.0953
time/epoch (s)                      2.63348
time/total (s)                    744.472
Epoch                             275
-----------------------------  ---------------
2019-04-22 21:50:28.623944 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 276 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.381781
trainer/QF2 Loss                    0.377775
trainer/Policy Loss                 8.44982
trainer/Q1 Predictions Mean        -6.64164
trainer/Q1 Predictions Std          1.44955
trainer/Q1 Predictions Max         -5.93826
trainer/Q1 Predictions Min        -16.7781
trainer/Q2 Predictions Mean        -6.64363
trainer/Q2 Predictions Std          1.4438
trainer/Q2 Predictions Max         -5.94918
trainer/Q2 Predictions Min        -16.7098
trainer/Q Targets Mean             -6.69501
trainer/Q Targets Std               1.56765
trainer/Q Targets Max              -0.0635292
trainer/Q Targets Min             -16.805
trainer/Log Pis Mean                1.80173
trainer/Log Pis Std                 1.2023
trainer/Log Pis Max                 5.01308
trainer/Log Pis Min                -2.14579
trainer/Policy mu Mean             -0.0544799
trainer/Policy mu Std               0.449168
trainer/Policy mu Max               2.70531
trainer/Policy mu Min              -2.77334
trainer/Policy log std Mean        -2.25665
trainer/Policy log std Std          0.322005
trainer/Policy log std Max         -0.671265
trainer/Policy log std Min         -2.45289
trainer/Alpha                       0.0590309
trainer/Alpha Loss                 -0.561037
exploration/num steps total    138700
exploration/num paths total      1387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.251663
exploration/Rewards Std             0.732994
exploration/Rewards Max            -0.0102225
exploration/Rewards Min            -8.64818
exploration/Returns Mean          -25.1663
exploration/Returns Std            11.4171
exploration/Returns Max           -17.262
exploration/Returns Min           -47.1867
exploration/Actions Mean           -0.000914306
exploration/Actions Std             0.225109
exploration/Actions Max             0.998302
exploration/Actions Min            -0.997311
exploration/Num Paths               5
exploration/Average Returns       -25.1663
evaluation/num steps total     415500
evaluation/num paths total       4155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213766
evaluation/Rewards Std              0.970976
evaluation/Rewards Max             -0.00767655
evaluation/Rewards Min            -10.0427
evaluation/Returns Mean           -21.3766
evaluation/Returns Std             16.5884
evaluation/Returns Max             -1.58088
evaluation/Returns Min            -53.8938
evaluation/Actions Mean            -0.00927941
evaluation/Actions Std              0.183723
evaluation/Actions Max              0.997846
evaluation/Actions Min             -0.998764
evaluation/Num Paths               15
evaluation/Average Returns        -21.3766
time/data storing (s)               0.00326271
time/evaluation sampling (s)        0.359186
time/exploration sampling (s)       0.16221
time/logging (s)                    0.00477916
time/saving (s)                     0.00161345
time/training (s)                   2.15222
time/epoch (s)                      2.68327
time/total (s)                    747.16
Epoch                             276
-----------------------------  ----------------
2019-04-22 21:50:31.262018 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 277 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.454043
trainer/QF2 Loss                    0.453367
trainer/Policy Loss                 9.1211
trainer/Q1 Predictions Mean        -7.09927
trainer/Q1 Predictions Std          3.52956
trainer/Q1 Predictions Max         -6.07242
trainer/Q1 Predictions Min        -34.0514
trainer/Q2 Predictions Mean        -7.11529
trainer/Q2 Predictions Std          3.53113
trainer/Q2 Predictions Max         -6.05261
trainer/Q2 Predictions Min        -34.1862
trainer/Q Targets Mean             -7.08197
trainer/Q Targets Std               3.55806
trainer/Q Targets Max              -0.0999451
trainer/Q Targets Min             -33.8844
trainer/Log Pis Mean                2.01352
trainer/Log Pis Std                 1.22179
trainer/Log Pis Max                 7.62315
trainer/Log Pis Min                -0.901677
trainer/Policy mu Mean             -9.80306e-05
trainer/Policy mu Std               0.55143
trainer/Policy mu Max               2.87907
trainer/Policy mu Min              -3.10229
trainer/Policy log std Mean        -2.22452
trainer/Policy log std Std          0.37993
trainer/Policy log std Max         -0.588289
trainer/Policy log std Min         -2.48429
trainer/Alpha                       0.061145
trainer/Alpha Loss                  0.0377933
exploration/num steps total    139200
exploration/num paths total      1392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.324258
exploration/Rewards Std             1.02732
exploration/Rewards Max            -0.00411007
exploration/Rewards Min           -10.1827
exploration/Returns Mean          -32.4258
exploration/Returns Std            16.7775
exploration/Returns Max           -15.9964
exploration/Returns Min           -61.4933
exploration/Actions Mean            0.0384451
exploration/Actions Std             0.236931
exploration/Actions Max             0.998767
exploration/Actions Min            -0.913539
exploration/Num Paths               5
exploration/Average Returns       -32.4258
evaluation/num steps total     417000
evaluation/num paths total       4170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256208
evaluation/Rewards Std              1.07509
evaluation/Rewards Max             -0.028579
evaluation/Rewards Min            -11.2277
evaluation/Returns Mean           -25.6208
evaluation/Returns Std             16.9309
evaluation/Returns Max             -3.70741
evaluation/Returns Min            -60.9997
evaluation/Actions Mean             0.00880801
evaluation/Actions Std              0.204106
evaluation/Actions Max              0.998189
evaluation/Actions Min             -0.998375
evaluation/Num Paths               15
evaluation/Average Returns        -25.6208
time/data storing (s)               0.00295264
time/evaluation sampling (s)        0.357111
time/exploration sampling (s)       0.164376
time/logging (s)                    0.00486381
time/saving (s)                     0.00202295
time/training (s)                   2.09802
time/epoch (s)                      2.62935
time/total (s)                    749.793
Epoch                             277
-----------------------------  ----------------
2019-04-22 21:50:33.894400 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 278 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.850627
trainer/QF2 Loss                    0.856128
trainer/Policy Loss                 8.62825
trainer/Q1 Predictions Mean        -6.75521
trainer/Q1 Predictions Std          1.68215
trainer/Q1 Predictions Max         -6.10188
trainer/Q1 Predictions Min        -20.5885
trainer/Q2 Predictions Mean        -6.75552
trainer/Q2 Predictions Std          1.69323
trainer/Q2 Predictions Max         -6.08381
trainer/Q2 Predictions Min        -20.6131
trainer/Q Targets Mean             -6.61378
trainer/Q Targets Std               1.93601
trainer/Q Targets Max              -0.0397339
trainer/Q Targets Min             -20.6881
trainer/Log Pis Mean                1.86009
trainer/Log Pis Std                 1.1739
trainer/Log Pis Max                 4.42629
trainer/Log Pis Min                -4.31714
trainer/Policy mu Mean             -0.0524667
trainer/Policy mu Std               0.35618
trainer/Policy mu Max               1.50736
trainer/Policy mu Min              -2.89028
trainer/Policy log std Mean        -2.30478
trainer/Policy log std Std          0.240317
trainer/Policy log std Max         -0.745958
trainer/Policy log std Min         -2.5474
trainer/Alpha                       0.0602404
trainer/Alpha Loss                 -0.393058
exploration/num steps total    139700
exploration/num paths total      1397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281211
exploration/Rewards Std             0.812062
exploration/Rewards Max            -0.00631155
exploration/Rewards Min            -7.84902
exploration/Returns Mean          -28.1211
exploration/Returns Std             9.55674
exploration/Returns Max           -18.5274
exploration/Returns Min           -44.0896
exploration/Actions Mean            0.008728
exploration/Actions Std             0.222795
exploration/Actions Max             0.997314
exploration/Actions Min            -0.993073
exploration/Num Paths               5
exploration/Average Returns       -28.1211
evaluation/num steps total     418500
evaluation/num paths total       4185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.323055
evaluation/Rewards Std              1.03356
evaluation/Rewards Max             -0.0166029
evaluation/Rewards Min             -9.65649
evaluation/Returns Mean           -32.3055
evaluation/Returns Std             11.3857
evaluation/Returns Max            -15.0625
evaluation/Returns Min            -47.2856
evaluation/Actions Mean            -0.00170804
evaluation/Actions Std              0.201533
evaluation/Actions Max              0.997662
evaluation/Actions Min             -0.998671
evaluation/Num Paths               15
evaluation/Average Returns        -32.3055
time/data storing (s)               0.0033824
time/evaluation sampling (s)        0.354594
time/exploration sampling (s)       0.159028
time/logging (s)                    0.00517984
time/saving (s)                     0.00230322
time/training (s)                   2.09992
time/epoch (s)                      2.6244
time/total (s)                    752.422
Epoch                             278
-----------------------------  ---------------
2019-04-22 21:50:36.558399 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 279 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.815263
trainer/QF2 Loss                    0.812172
trainer/Policy Loss                 8.65027
trainer/Q1 Predictions Mean        -6.74744
trainer/Q1 Predictions Std          2.80743
trainer/Q1 Predictions Max         -6.01027
trainer/Q1 Predictions Min        -34.0354
trainer/Q2 Predictions Mean        -6.72907
trainer/Q2 Predictions Std          2.79098
trainer/Q2 Predictions Max         -6.03643
trainer/Q2 Predictions Min        -33.8725
trainer/Q Targets Mean             -6.6959
trainer/Q Targets Std               2.98013
trainer/Q Targets Max              -0.169051
trainer/Q Targets Min             -34.4173
trainer/Log Pis Mean                1.93466
trainer/Log Pis Std                 1.01053
trainer/Log Pis Max                 4.82249
trainer/Log Pis Min                -1.92499
trainer/Policy mu Mean             -0.000999191
trainer/Policy mu Std               0.407282
trainer/Policy mu Max               3.06949
trainer/Policy mu Min              -2.28544
trainer/Policy log std Mean        -2.24138
trainer/Policy log std Std          0.283694
trainer/Policy log std Max         -0.594867
trainer/Policy log std Min         -2.43101
trainer/Alpha                       0.0622681
trainer/Alpha Loss                 -0.1814
exploration/num steps total    140200
exploration/num paths total      1402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.275268
exploration/Rewards Std             0.89298
exploration/Rewards Max            -0.00865468
exploration/Rewards Min           -10.3357
exploration/Returns Mean          -27.5268
exploration/Returns Std            18.9237
exploration/Returns Max           -12.759
exploration/Returns Min           -63.8275
exploration/Actions Mean            0.0246936
exploration/Actions Std             0.215601
exploration/Actions Max             0.999752
exploration/Actions Min            -0.936603
exploration/Num Paths               5
exploration/Average Returns       -27.5268
evaluation/num steps total     420000
evaluation/num paths total       4200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.227957
evaluation/Rewards Std              0.926288
evaluation/Rewards Max             -0.0254188
evaluation/Rewards Min             -9.41111
evaluation/Returns Mean           -22.7957
evaluation/Returns Std             14.0793
evaluation/Returns Max             -2.87938
evaluation/Returns Min            -44.1461
evaluation/Actions Mean            -0.00593161
evaluation/Actions Std              0.195883
evaluation/Actions Max              0.997545
evaluation/Actions Min             -0.997821
evaluation/Num Paths               15
evaluation/Average Returns        -22.7957
time/data storing (s)               0.00284245
time/evaluation sampling (s)        0.363591
time/exploration sampling (s)       0.173139
time/logging (s)                    0.0049861
time/saving (s)                     0.00202884
time/training (s)                   2.10845
time/epoch (s)                      2.65504
time/total (s)                    755.082
Epoch                             279
-----------------------------  ----------------
2019-04-22 21:50:39.221283 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 280 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0429412
trainer/QF2 Loss                    0.0168379
trainer/Policy Loss                 9.23151
trainer/Q1 Predictions Mean        -7.1748
trainer/Q1 Predictions Std          5.42336
trainer/Q1 Predictions Max         -6.03121
trainer/Q1 Predictions Min        -56.9087
trainer/Q2 Predictions Mean        -7.19528
trainer/Q2 Predictions Std          5.56072
trainer/Q2 Predictions Max         -6.02819
trainer/Q2 Predictions Min        -58.2475
trainer/Q Targets Mean             -7.29027
trainer/Q Targets Std               5.56959
trainer/Q Targets Max              -6.0756
trainer/Q Targets Min             -58.5014
trainer/Log Pis Mean                2.04423
trainer/Log Pis Std                 1.2823
trainer/Log Pis Max                 8.29623
trainer/Log Pis Min                -2.69997
trainer/Policy mu Mean              0.00817228
trainer/Policy mu Std               0.495263
trainer/Policy mu Max               3.35093
trainer/Policy mu Min              -2.85752
trainer/Policy log std Mean        -2.25129
trainer/Policy log std Std          0.314918
trainer/Policy log std Max         -0.414079
trainer/Policy log std Min         -2.47527
trainer/Alpha                       0.0614402
trainer/Alpha Loss                  0.1234
exploration/num steps total    140700
exploration/num paths total      1407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.350092
exploration/Rewards Std             0.995471
exploration/Rewards Max            -0.00540014
exploration/Rewards Min            -7.7777
exploration/Returns Mean          -35.0092
exploration/Returns Std             8.66818
exploration/Returns Max           -23.1403
exploration/Returns Min           -48.0017
exploration/Actions Mean           -0.000192136
exploration/Actions Std             0.249408
exploration/Actions Max             0.997221
exploration/Actions Min            -0.998277
exploration/Num Paths               5
exploration/Average Returns       -35.0092
evaluation/num steps total     421500
evaluation/num paths total       4215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.24431
evaluation/Rewards Std              0.970598
evaluation/Rewards Max             -0.0174512
evaluation/Rewards Min            -10.0779
evaluation/Returns Mean           -24.431
evaluation/Returns Std             14.9986
evaluation/Returns Max             -5.43183
evaluation/Returns Min            -57.283
evaluation/Actions Mean             0.000554114
evaluation/Actions Std              0.192887
evaluation/Actions Max              0.998612
evaluation/Actions Min             -0.997928
evaluation/Num Paths               15
evaluation/Average Returns        -24.431
time/data storing (s)               0.0034957
time/evaluation sampling (s)        0.357588
time/exploration sampling (s)       0.167616
time/logging (s)                    0.00486679
time/saving (s)                     0.00228704
time/training (s)                   2.11808
time/epoch (s)                      2.65393
time/total (s)                    757.74
Epoch                             280
-----------------------------  ----------------
2019-04-22 21:50:41.952753 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 281 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0122377
trainer/QF2 Loss                    0.0212396
trainer/Policy Loss                 9.00112
trainer/Q1 Predictions Mean        -7.02928
trainer/Q1 Predictions Std          3.2992
trainer/Q1 Predictions Max         -6.06342
trainer/Q1 Predictions Min        -31.4256
trainer/Q2 Predictions Mean        -7.05019
trainer/Q2 Predictions Std          3.36222
trainer/Q2 Predictions Max         -6.08738
trainer/Q2 Predictions Min        -31.9747
trainer/Q Targets Mean             -7.03716
trainer/Q Targets Std               3.26935
trainer/Q Targets Max              -6.06312
trainer/Q Targets Min             -30.8761
trainer/Log Pis Mean                1.95834
trainer/Log Pis Std                 1.30782
trainer/Log Pis Max                 7.4356
trainer/Log Pis Min                -3.56747
trainer/Policy mu Mean              0.0011575
trainer/Policy mu Std               0.519078
trainer/Policy mu Max               2.93817
trainer/Policy mu Min              -3.41792
trainer/Policy log std Mean        -2.28473
trainer/Policy log std Std          0.334587
trainer/Policy log std Max         -0.622328
trainer/Policy log std Min         -2.48395
trainer/Alpha                       0.0618229
trainer/Alpha Loss                 -0.115955
exploration/num steps total    141200
exploration/num paths total      1412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.381758
exploration/Rewards Std             1.18261
exploration/Rewards Max            -0.00344534
exploration/Rewards Min            -9.92609
exploration/Returns Mean          -38.1758
exploration/Returns Std            17.5377
exploration/Returns Max           -12.2287
exploration/Returns Min           -65.6841
exploration/Actions Mean            0.0234289
exploration/Actions Std             0.235146
exploration/Actions Max             0.998655
exploration/Actions Min            -0.998534
exploration/Num Paths               5
exploration/Average Returns       -38.1758
evaluation/num steps total     423000
evaluation/num paths total       4230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.258983
evaluation/Rewards Std              1.07061
evaluation/Rewards Max             -0.013153
evaluation/Rewards Min             -9.61362
evaluation/Returns Mean           -25.8983
evaluation/Returns Std             13.8504
evaluation/Returns Max             -6.81868
evaluation/Returns Min            -46.6815
evaluation/Actions Mean            -0.00231623
evaluation/Actions Std              0.213724
evaluation/Actions Max              0.997889
evaluation/Actions Min             -0.996954
evaluation/Num Paths               15
evaluation/Average Returns        -25.8983
time/data storing (s)               0.00309953
time/evaluation sampling (s)        0.348437
time/exploration sampling (s)       0.158325
time/logging (s)                    0.00487581
time/saving (s)                     0.0343794
time/training (s)                   2.17338
time/epoch (s)                      2.7225
time/total (s)                    760.467
Epoch                             281
-----------------------------  ---------------
2019-04-22 21:50:44.636977 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 282 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0254271
trainer/QF2 Loss                    0.0243623
trainer/Policy Loss                 8.36421
trainer/Q1 Predictions Mean        -6.64643
trainer/Q1 Predictions Std          2.90044
trainer/Q1 Predictions Max         -5.87158
trainer/Q1 Predictions Min        -35.2482
trainer/Q2 Predictions Mean        -6.6406
trainer/Q2 Predictions Std          2.89418
trainer/Q2 Predictions Max         -5.84815
trainer/Q2 Predictions Min        -35.1992
trainer/Q Targets Mean             -6.70311
trainer/Q Targets Std               2.87154
trainer/Q Targets Max              -6.02846
trainer/Q Targets Min             -35.0817
trainer/Log Pis Mean                1.69606
trainer/Log Pis Std                 1.26668
trainer/Log Pis Max                 5.11775
trainer/Log Pis Min                -2.99699
trainer/Policy mu Mean              0.0619285
trainer/Policy mu Std               0.360929
trainer/Policy mu Max               3.09111
trainer/Policy mu Min              -0.229721
trainer/Policy log std Mean        -2.2615
trainer/Policy log std Std          0.280191
trainer/Policy log std Max         -0.463143
trainer/Policy log std Min         -2.43218
trainer/Alpha                       0.0625618
trainer/Alpha Loss                 -0.842329
exploration/num steps total    141700
exploration/num paths total      1417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.236632
exploration/Rewards Std             0.700779
exploration/Rewards Max            -0.00941581
exploration/Rewards Min            -8.34326
exploration/Returns Mean          -23.6632
exploration/Returns Std            11.697
exploration/Returns Max           -11.4813
exploration/Returns Min           -44.441
exploration/Actions Mean           -0.0178466
exploration/Actions Std             0.21366
exploration/Actions Max             0.989157
exploration/Actions Min            -0.999368
exploration/Num Paths               5
exploration/Average Returns       -23.6632
evaluation/num steps total     424500
evaluation/num paths total       4245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.19279
evaluation/Rewards Std              0.899512
evaluation/Rewards Max             -0.0117102
evaluation/Rewards Min            -10.1037
evaluation/Returns Mean           -19.279
evaluation/Returns Std             15.4605
evaluation/Returns Max             -2.45272
evaluation/Returns Min            -58.612
evaluation/Actions Mean             0.0164972
evaluation/Actions Std              0.181502
evaluation/Actions Max              0.998533
evaluation/Actions Min             -0.996456
evaluation/Num Paths               15
evaluation/Average Returns        -19.279
time/data storing (s)               0.00351049
time/evaluation sampling (s)        0.367578
time/exploration sampling (s)       0.166499
time/logging (s)                    0.00470888
time/saving (s)                     0.00260696
time/training (s)                   2.13081
time/epoch (s)                      2.67571
time/total (s)                    763.146
Epoch                             282
-----------------------------  ---------------
2019-04-22 21:50:47.351486 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 283 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.45341
trainer/QF2 Loss                    0.454061
trainer/Policy Loss                10.3765
trainer/Q1 Predictions Mean        -8.03775
trainer/Q1 Predictions Std          6.31476
trainer/Q1 Predictions Max         -5.96685
trainer/Q1 Predictions Min        -49.5012
trainer/Q2 Predictions Mean        -8.04258
trainer/Q2 Predictions Std          6.31608
trainer/Q2 Predictions Max         -5.94843
trainer/Q2 Predictions Min        -49.209
trainer/Q Targets Mean             -8.03383
trainer/Q Targets Std               6.33801
trainer/Q Targets Max              -0.243514
trainer/Q Targets Min             -49.4568
trainer/Log Pis Mean                2.34072
trainer/Log Pis Std                 1.45891
trainer/Log Pis Max                 8.97293
trainer/Log Pis Min                -2.2412
trainer/Policy mu Mean             -0.0583711
trainer/Policy mu Std               0.731953
trainer/Policy mu Max               3.42363
trainer/Policy mu Min              -3.2359
trainer/Policy log std Mean        -2.23023
trainer/Policy log std Std          0.459811
trainer/Policy log std Max         -0.489389
trainer/Policy log std Min         -2.46065
trainer/Alpha                       0.0616125
trainer/Alpha Loss                  0.949561
exploration/num steps total    142200
exploration/num paths total      1422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.442926
exploration/Rewards Std             1.30285
exploration/Rewards Max            -0.00527482
exploration/Rewards Min            -9.1119
exploration/Returns Mean          -44.2926
exploration/Returns Std            10.0165
exploration/Returns Max           -29.3596
exploration/Returns Min           -58.0979
exploration/Actions Mean            0.0111872
exploration/Actions Std             0.252749
exploration/Actions Max             0.998962
exploration/Actions Min            -0.999711
exploration/Num Paths               5
exploration/Average Returns       -44.2926
evaluation/num steps total     426000
evaluation/num paths total       4260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.179384
evaluation/Rewards Std              0.865598
evaluation/Rewards Max             -0.00401458
evaluation/Rewards Min             -9.33419
evaluation/Returns Mean           -17.9384
evaluation/Returns Std             12.4559
evaluation/Returns Max             -2.04193
evaluation/Returns Min            -38.8462
evaluation/Actions Mean            -0.00739054
evaluation/Actions Std              0.185015
evaluation/Actions Max              0.997119
evaluation/Actions Min             -0.996832
evaluation/Num Paths               15
evaluation/Average Returns        -17.9384
time/data storing (s)               0.00299133
time/evaluation sampling (s)        0.35362
time/exploration sampling (s)       0.160094
time/logging (s)                    0.0052165
time/saving (s)                     0.00209005
time/training (s)                   2.18163
time/epoch (s)                      2.70564
time/total (s)                    765.857
Epoch                             283
-----------------------------  ---------------
2019-04-22 21:50:50.101935 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 284 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0203565
trainer/QF2 Loss                    0.0270034
trainer/Policy Loss                 8.71504
trainer/Q1 Predictions Mean        -6.62423
trainer/Q1 Predictions Std          1.23554
trainer/Q1 Predictions Max         -5.98856
trainer/Q1 Predictions Min        -15.2117
trainer/Q2 Predictions Mean        -6.61481
trainer/Q2 Predictions Std          1.25827
trainer/Q2 Predictions Max         -5.94773
trainer/Q2 Predictions Min        -15.368
trainer/Q Targets Mean             -6.70639
trainer/Q Targets Std               1.21326
trainer/Q Targets Max              -6.02105
trainer/Q Targets Min             -15.1205
trainer/Log Pis Mean                2.09659
trainer/Log Pis Std                 0.928556
trainer/Log Pis Max                 4.79888
trainer/Log Pis Min                -1.05743
trainer/Policy mu Mean              0.0223255
trainer/Policy mu Std               0.443084
trainer/Policy mu Max               2.74875
trainer/Policy mu Min              -2.2393
trainer/Policy log std Mean        -2.255
trainer/Policy log std Std          0.308017
trainer/Policy log std Max         -0.679056
trainer/Policy log std Min         -2.41808
trainer/Alpha                       0.0605917
trainer/Alpha Loss                  0.270796
exploration/num steps total    142700
exploration/num paths total      1427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281053
exploration/Rewards Std             0.849878
exploration/Rewards Max            -0.00298922
exploration/Rewards Min            -7.83514
exploration/Returns Mean          -28.1053
exploration/Returns Std            12.5758
exploration/Returns Max           -13.7387
exploration/Returns Min           -43.7527
exploration/Actions Mean            0.00857916
exploration/Actions Std             0.221763
exploration/Actions Max             0.998536
exploration/Actions Min            -0.998059
exploration/Num Paths               5
exploration/Average Returns       -28.1053
evaluation/num steps total     427500
evaluation/num paths total       4275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.227825
evaluation/Rewards Std              0.993594
evaluation/Rewards Max             -0.0235699
evaluation/Rewards Min             -9.81553
evaluation/Returns Mean           -22.7825
evaluation/Returns Std             14.1931
evaluation/Returns Max             -4.07779
evaluation/Returns Min            -47.5948
evaluation/Actions Mean            -0.00193541
evaluation/Actions Std              0.196005
evaluation/Actions Max              0.998339
evaluation/Actions Min             -0.998293
evaluation/Num Paths               15
evaluation/Average Returns        -22.7825
time/data storing (s)               0.00386591
time/evaluation sampling (s)        0.407092
time/exploration sampling (s)       0.165327
time/logging (s)                    0.00413649
time/saving (s)                     0.00198251
time/training (s)                   2.15782
time/epoch (s)                      2.74023
time/total (s)                    768.601
Epoch                             284
-----------------------------  ---------------
2019-04-22 21:50:52.786082 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 285 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0116686
trainer/QF2 Loss                    0.0158303
trainer/Policy Loss                 8.99778
trainer/Q1 Predictions Mean        -6.94755
trainer/Q1 Predictions Std          2.98608
trainer/Q1 Predictions Max         -6.09822
trainer/Q1 Predictions Min        -34.3899
trainer/Q2 Predictions Mean        -6.93958
trainer/Q2 Predictions Std          3.00756
trainer/Q2 Predictions Max         -6.06237
trainer/Q2 Predictions Min        -34.5613
trainer/Q Targets Mean             -6.98179
trainer/Q Targets Std               2.97996
trainer/Q Targets Max              -6.01498
trainer/Q Targets Min             -34.3416
trainer/Log Pis Mean                2.05957
trainer/Log Pis Std                 1.01193
trainer/Log Pis Max                 5.45057
trainer/Log Pis Min                -0.190045
trainer/Policy mu Mean             -0.0620571
trainer/Policy mu Std               0.528427
trainer/Policy mu Max               2.62844
trainer/Policy mu Min              -3.15736
trainer/Policy log std Mean        -2.23475
trainer/Policy log std Std          0.351666
trainer/Policy log std Max         -0.620271
trainer/Policy log std Min         -2.48911
trainer/Alpha                       0.0604217
trainer/Alpha Loss                  0.167166
exploration/num steps total    143200
exploration/num paths total      1432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.250846
exploration/Rewards Std             0.681668
exploration/Rewards Max            -0.00446098
exploration/Rewards Min            -6.30613
exploration/Returns Mean          -25.0846
exploration/Returns Std             6.95628
exploration/Returns Max           -15.8261
exploration/Returns Min           -33.6814
exploration/Actions Mean           -0.0112173
exploration/Actions Std             0.211296
exploration/Actions Max             0.999195
exploration/Actions Min            -0.998286
exploration/Num Paths               5
exploration/Average Returns       -25.0846
evaluation/num steps total     429000
evaluation/num paths total       4290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243768
evaluation/Rewards Std              0.978467
evaluation/Rewards Max             -0.0268765
evaluation/Rewards Min             -9.97576
evaluation/Returns Mean           -24.3768
evaluation/Returns Std             15.9284
evaluation/Returns Max             -4.78452
evaluation/Returns Min            -54.8804
evaluation/Actions Mean             0.00105912
evaluation/Actions Std              0.189292
evaluation/Actions Max              0.998144
evaluation/Actions Min             -0.997448
evaluation/Num Paths               15
evaluation/Average Returns        -24.3768
time/data storing (s)               0.00452092
time/evaluation sampling (s)        0.364348
time/exploration sampling (s)       0.164182
time/logging (s)                    0.0047288
time/saving (s)                     0.00234321
time/training (s)                   2.13548
time/epoch (s)                      2.6756
time/total (s)                    771.282
Epoch                             285
-----------------------------  ---------------
2019-04-22 21:50:55.429699 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 286 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.806721
trainer/QF2 Loss                    0.807089
trainer/Policy Loss                 8.54485
trainer/Q1 Predictions Mean        -6.62623
trainer/Q1 Predictions Std          0.808164
trainer/Q1 Predictions Max         -6.03816
trainer/Q1 Predictions Min        -10.7287
trainer/Q2 Predictions Mean        -6.62468
trainer/Q2 Predictions Std          0.782287
trainer/Q2 Predictions Max         -6.03739
trainer/Q2 Predictions Min        -10.4408
trainer/Q Targets Mean             -6.49107
trainer/Q Targets Std               1.19281
trainer/Q Targets Max              -0.124118
trainer/Q Targets Min             -10.6588
trainer/Log Pis Mean                1.90873
trainer/Log Pis Std                 1.0949
trainer/Log Pis Max                 6.01565
trainer/Log Pis Min                -1.80098
trainer/Policy mu Mean              0.0300651
trainer/Policy mu Std               0.437325
trainer/Policy mu Max               2.66804
trainer/Policy mu Min              -2.35824
trainer/Policy log std Mean        -2.24111
trainer/Policy log std Std          0.313073
trainer/Policy log std Max         -0.54144
trainer/Policy log std Min         -2.39972
trainer/Alpha                       0.0594784
trainer/Alpha Loss                 -0.257573
exploration/num steps total    143700
exploration/num paths total      1437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.306464
exploration/Rewards Std             0.909825
exploration/Rewards Max            -0.0082629
exploration/Rewards Min            -8.32572
exploration/Returns Mean          -30.6464
exploration/Returns Std            11.8698
exploration/Returns Max           -12.9782
exploration/Returns Min           -48.3517
exploration/Actions Mean            0.028702
exploration/Actions Std             0.227761
exploration/Actions Max             0.998948
exploration/Actions Min            -0.988461
exploration/Num Paths               5
exploration/Average Returns       -30.6464
evaluation/num steps total     430500
evaluation/num paths total       4305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.193187
evaluation/Rewards Std              0.792235
evaluation/Rewards Max             -0.0319188
evaluation/Rewards Min            -10.9062
evaluation/Returns Mean           -19.3187
evaluation/Returns Std             14.8902
evaluation/Returns Max             -6.4275
evaluation/Returns Min            -62.4443
evaluation/Actions Mean            -0.00454555
evaluation/Actions Std              0.174667
evaluation/Actions Max              0.99856
evaluation/Actions Min             -0.998823
evaluation/Num Paths               15
evaluation/Average Returns        -19.3187
time/data storing (s)               0.00309069
time/evaluation sampling (s)        0.359727
time/exploration sampling (s)       0.165046
time/logging (s)                    0.00447044
time/saving (s)                     0.00203108
time/training (s)                   2.09976
time/epoch (s)                      2.63412
time/total (s)                    773.921
Epoch                             286
-----------------------------  ---------------
2019-04-22 21:50:58.063518 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 287 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.44997
trainer/QF2 Loss                    0.444466
trainer/Policy Loss                 8.66046
trainer/Q1 Predictions Mean        -6.69387
trainer/Q1 Predictions Std          2.92145
trainer/Q1 Predictions Max         -6.07909
trainer/Q1 Predictions Min        -35.1846
trainer/Q2 Predictions Mean        -6.70536
trainer/Q2 Predictions Std          2.9505
trainer/Q2 Predictions Max         -6.0921
trainer/Q2 Predictions Min        -35.5521
trainer/Q Targets Mean             -6.63166
trainer/Q Targets Std               2.9604
trainer/Q Targets Max              -0.112857
trainer/Q Targets Min             -34.8659
trainer/Log Pis Mean                1.95063
trainer/Log Pis Std                 1.08353
trainer/Log Pis Max                 6.87287
trainer/Log Pis Min                -3.0594
trainer/Policy mu Mean             -0.00598962
trainer/Policy mu Std               0.341483
trainer/Policy mu Max               2.73944
trainer/Policy mu Min              -3.41854
trainer/Policy log std Mean        -2.30641
trainer/Policy log std Std          0.215378
trainer/Policy log std Max         -0.468029
trainer/Policy log std Min         -2.39528
trainer/Alpha                       0.0587166
trainer/Alpha Loss                 -0.139964
exploration/num steps total    144200
exploration/num paths total      1442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.209984
exploration/Rewards Std             0.489536
exploration/Rewards Max            -0.00203407
exploration/Rewards Min            -5.11545
exploration/Returns Mean          -20.9984
exploration/Returns Std             5.5212
exploration/Returns Max           -14.2738
exploration/Returns Min           -27.9242
exploration/Actions Mean            0.0256198
exploration/Actions Std             0.204988
exploration/Actions Max             0.998702
exploration/Actions Min            -0.728916
exploration/Num Paths               5
exploration/Average Returns       -20.9984
evaluation/num steps total     432000
evaluation/num paths total       4320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228076
evaluation/Rewards Std              0.892887
evaluation/Rewards Max             -0.00560233
evaluation/Rewards Min             -8.40277
evaluation/Returns Mean           -22.8076
evaluation/Returns Std             13.1764
evaluation/Returns Max             -5.37033
evaluation/Returns Min            -46.5037
evaluation/Actions Mean             0.0193285
evaluation/Actions Std              0.187273
evaluation/Actions Max              0.99813
evaluation/Actions Min             -0.998726
evaluation/Num Paths               15
evaluation/Average Returns        -22.8076
time/data storing (s)               0.00311189
time/evaluation sampling (s)        0.352864
time/exploration sampling (s)       0.160887
time/logging (s)                    0.00484718
time/saving (s)                     0.00199126
time/training (s)                   2.10277
time/epoch (s)                      2.62648
time/total (s)                    776.551
Epoch                             287
-----------------------------  ---------------
2019-04-22 21:51:00.733469 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 288 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.00624476
trainer/QF2 Loss                    0.00633809
trainer/Policy Loss                 8.95424
trainer/Q1 Predictions Mean        -6.82444
trainer/Q1 Predictions Std          2.32703
trainer/Q1 Predictions Max         -6.08962
trainer/Q1 Predictions Min        -26.3078
trainer/Q2 Predictions Mean        -6.83011
trainer/Q2 Predictions Std          2.33188
trainer/Q2 Predictions Max         -6.09972
trainer/Q2 Predictions Min        -26.265
trainer/Q Targets Mean             -6.84304
trainer/Q Targets Std               2.31559
trainer/Q Targets Max              -6.06451
trainer/Q Targets Min             -26.1765
trainer/Log Pis Mean                2.11471
trainer/Log Pis Std                 1.1463
trainer/Log Pis Max                 5.47335
trainer/Log Pis Min                -3.36349
trainer/Policy mu Mean              0.00670488
trainer/Policy mu Std               0.507427
trainer/Policy mu Max               2.75198
trainer/Policy mu Min              -3.1696
trainer/Policy log std Mean        -2.28354
trainer/Policy log std Std          0.360065
trainer/Policy log std Max         -0.636109
trainer/Policy log std Min         -2.48914
trainer/Alpha                       0.0584653
trainer/Alpha Loss                  0.325717
exploration/num steps total    144700
exploration/num paths total      1447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.259603
exploration/Rewards Std             0.809065
exploration/Rewards Max            -0.00214142
exploration/Rewards Min            -7.20455
exploration/Returns Mean          -25.9603
exploration/Returns Std            10.6308
exploration/Returns Max           -12.1563
exploration/Returns Min           -37.7781
exploration/Actions Mean            0.00472783
exploration/Actions Std             0.219328
exploration/Actions Max             0.998482
exploration/Actions Min            -0.997383
exploration/Num Paths               5
exploration/Average Returns       -25.9603
evaluation/num steps total     433500
evaluation/num paths total       4335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224396
evaluation/Rewards Std              1.09911
evaluation/Rewards Max             -0.00997932
evaluation/Rewards Min            -11.3281
evaluation/Returns Mean           -22.4396
evaluation/Returns Std             19.7096
evaluation/Returns Max             -1.91412
evaluation/Returns Min            -57.5797
evaluation/Actions Mean             0.000138338
evaluation/Actions Std              0.193741
evaluation/Actions Max              0.998687
evaluation/Actions Min             -0.999087
evaluation/Num Paths               15
evaluation/Average Returns        -22.4396
time/data storing (s)               0.00294973
time/evaluation sampling (s)        0.395919
time/exploration sampling (s)       0.159108
time/logging (s)                    0.00482753
time/saving (s)                     0.00182347
time/training (s)                   2.09719
time/epoch (s)                      2.66182
time/total (s)                    779.217
Epoch                             288
-----------------------------  ----------------
2019-04-22 21:51:03.369299 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 289 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.719854
trainer/QF2 Loss                    0.722737
trainer/Policy Loss                 8.62569
trainer/Q1 Predictions Mean        -6.74989
trainer/Q1 Predictions Std          1.63668
trainer/Q1 Predictions Max         -6.03312
trainer/Q1 Predictions Min        -17.1907
trainer/Q2 Predictions Mean        -6.75295
trainer/Q2 Predictions Std          1.63388
trainer/Q2 Predictions Max         -6.03526
trainer/Q2 Predictions Min        -17.2385
trainer/Q Targets Mean             -6.69689
trainer/Q Targets Std               1.87005
trainer/Q Targets Max              -0.140206
trainer/Q Targets Min             -17.286
trainer/Log Pis Mean                1.87676
trainer/Log Pis Std                 1.12252
trainer/Log Pis Max                 4.22036
trainer/Log Pis Min                -2.36756
trainer/Policy mu Mean             -0.0660588
trainer/Policy mu Std               0.506105
trainer/Policy mu Max               2.06098
trainer/Policy mu Min              -2.8591
trainer/Policy log std Mean        -2.21567
trainer/Policy log std Std          0.354739
trainer/Policy log std Max         -0.541219
trainer/Policy log std Min         -2.4379
trainer/Alpha                       0.0583575
trainer/Alpha Loss                 -0.350148
exploration/num steps total    145200
exploration/num paths total      1452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.23821
exploration/Rewards Std             0.738222
exploration/Rewards Max            -0.00563584
exploration/Rewards Min            -8.85336
exploration/Returns Mean          -23.821
exploration/Returns Std            16.4535
exploration/Returns Max           -14.0294
exploration/Returns Min           -56.648
exploration/Actions Mean            0.00214019
exploration/Actions Std             0.19773
exploration/Actions Max             0.997817
exploration/Actions Min            -0.999324
exploration/Num Paths               5
exploration/Average Returns       -23.821
evaluation/num steps total     435000
evaluation/num paths total       4350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237481
evaluation/Rewards Std              0.977296
evaluation/Rewards Max             -0.0281841
evaluation/Rewards Min             -9.97569
evaluation/Returns Mean           -23.7481
evaluation/Returns Std             16.1216
evaluation/Returns Max             -5.94204
evaluation/Returns Min            -55.2346
evaluation/Actions Mean             0.000347352
evaluation/Actions Std              0.191151
evaluation/Actions Max              0.998035
evaluation/Actions Min             -0.997636
evaluation/Num Paths               15
evaluation/Average Returns        -23.7481
time/data storing (s)               0.00333784
time/evaluation sampling (s)        0.35189
time/exploration sampling (s)       0.161021
time/logging (s)                    0.00403467
time/saving (s)                     0.00198571
time/training (s)                   2.10372
time/epoch (s)                      2.62599
time/total (s)                    781.848
Epoch                             289
-----------------------------  ----------------
2019-04-22 21:51:06.057147 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 290 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0205493
trainer/QF2 Loss                    0.0181241
trainer/Policy Loss                 8.85924
trainer/Q1 Predictions Mean        -6.87815
trainer/Q1 Predictions Std          3.86746
trainer/Q1 Predictions Max         -6.0419
trainer/Q1 Predictions Min        -43.7414
trainer/Q2 Predictions Mean        -6.88491
trainer/Q2 Predictions Std          3.85556
trainer/Q2 Predictions Max         -6.03989
trainer/Q2 Predictions Min        -43.6562
trainer/Q Targets Mean             -6.97312
trainer/Q Targets Std               3.81612
trainer/Q Targets Max              -6.05564
trainer/Q Targets Min             -43.3656
trainer/Log Pis Mean                1.98557
trainer/Log Pis Std                 1.189
trainer/Log Pis Max                 4.30284
trainer/Log Pis Min                -4.20046
trainer/Policy mu Mean              0.0416628
trainer/Policy mu Std               0.450888
trainer/Policy mu Max               3.34611
trainer/Policy mu Min              -2.45741
trainer/Policy log std Mean        -2.30725
trainer/Policy log std Std          0.303571
trainer/Policy log std Max         -0.545829
trainer/Policy log std Min         -2.49169
trainer/Alpha                       0.0585412
trainer/Alpha Loss                 -0.0409539
exploration/num steps total    145700
exploration/num paths total      1457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375399
exploration/Rewards Std             1.24801
exploration/Rewards Max            -0.00910857
exploration/Rewards Min           -11.0358
exploration/Returns Mean          -37.5399
exploration/Returns Std            21.2526
exploration/Returns Max           -13.7433
exploration/Returns Min           -68.8959
exploration/Actions Mean            0.0259862
exploration/Actions Std             0.240516
exploration/Actions Max             0.998489
exploration/Actions Min            -0.999374
exploration/Num Paths               5
exploration/Average Returns       -37.5399
evaluation/num steps total     436500
evaluation/num paths total       4365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.184655
evaluation/Rewards Std              0.83595
evaluation/Rewards Max             -0.01054
evaluation/Rewards Min            -11.4434
evaluation/Returns Mean           -18.4655
evaluation/Returns Std             14.9213
evaluation/Returns Max             -2.63626
evaluation/Returns Min            -60.9388
evaluation/Actions Mean            -0.00259198
evaluation/Actions Std              0.180007
evaluation/Actions Max              0.995345
evaluation/Actions Min             -0.999127
evaluation/Num Paths               15
evaluation/Average Returns        -18.4655
time/data storing (s)               0.00289851
time/evaluation sampling (s)        0.353572
time/exploration sampling (s)       0.159527
time/logging (s)                    0.0049271
time/saving (s)                     0.00209645
time/training (s)                   2.15691
time/epoch (s)                      2.67993
time/total (s)                    784.532
Epoch                             290
-----------------------------  ---------------
2019-04-22 21:51:08.717035 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 291 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0213578
trainer/QF2 Loss                    0.00904735
trainer/Policy Loss                 9.45373
trainer/Q1 Predictions Mean        -7.45599
trainer/Q1 Predictions Std          5.59336
trainer/Q1 Predictions Max         -6.02989
trainer/Q1 Predictions Min        -47.5756
trainer/Q2 Predictions Mean        -7.46292
trainer/Q2 Predictions Std          5.66573
trainer/Q2 Predictions Max         -6.04513
trainer/Q2 Predictions Min        -48.7186
trainer/Q Targets Mean             -7.46542
trainer/Q Targets Std               5.65493
trainer/Q Targets Max              -6.04009
trainer/Q Targets Min             -48.6545
trainer/Log Pis Mean                1.96948
trainer/Log Pis Std                 1.0833
trainer/Log Pis Max                 6.3975
trainer/Log Pis Min                -3.56645
trainer/Policy mu Mean              0.020736
trainer/Policy mu Std               0.592328
trainer/Policy mu Max               3.14553
trainer/Policy mu Min              -3.2885
trainer/Policy log std Mean        -2.22463
trainer/Policy log std Std          0.379573
trainer/Policy log std Max         -0.507055
trainer/Policy log std Min         -2.40324
trainer/Alpha                       0.0607831
trainer/Alpha Loss                 -0.085464
exploration/num steps total    146200
exploration/num paths total      1462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31441
exploration/Rewards Std             0.994677
exploration/Rewards Max            -0.00245042
exploration/Rewards Min            -9.44164
exploration/Returns Mean          -31.441
exploration/Returns Std            18.5836
exploration/Returns Max           -13.0216
exploration/Returns Min           -61.5579
exploration/Actions Mean           -0.0161773
exploration/Actions Std             0.223049
exploration/Actions Max             0.993656
exploration/Actions Min            -0.999475
exploration/Num Paths               5
exploration/Average Returns       -31.441
evaluation/num steps total     438000
evaluation/num paths total       4380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.219867
evaluation/Rewards Std              0.941361
evaluation/Rewards Max             -0.00589755
evaluation/Rewards Min             -9.14349
evaluation/Returns Mean           -21.9867
evaluation/Returns Std             14.7971
evaluation/Returns Max             -5.01707
evaluation/Returns Min            -44.2141
evaluation/Actions Mean            -0.000113249
evaluation/Actions Std              0.189692
evaluation/Actions Max              0.99776
evaluation/Actions Min             -0.998801
evaluation/Num Paths               15
evaluation/Average Returns        -21.9867
time/data storing (s)               0.00285411
time/evaluation sampling (s)        0.369368
time/exploration sampling (s)       0.162505
time/logging (s)                    0.00509864
time/saving (s)                     0.00198189
time/training (s)                   2.1097
time/epoch (s)                      2.65151
time/total (s)                    787.189
Epoch                             291
-----------------------------  ----------------
2019-04-22 21:51:11.402260 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 292 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.020488
trainer/QF2 Loss                    0.0218974
trainer/Policy Loss                 8.35208
trainer/Q1 Predictions Mean        -6.42706
trainer/Q1 Predictions Std          0.404065
trainer/Q1 Predictions Max         -6.0032
trainer/Q1 Predictions Min         -9.02957
trainer/Q2 Predictions Mean        -6.43509
trainer/Q2 Predictions Std          0.398714
trainer/Q2 Predictions Max         -5.98833
trainer/Q2 Predictions Min         -8.93515
trainer/Q Targets Mean             -6.47687
trainer/Q Targets Std               0.452369
trainer/Q Targets Max              -6.0037
trainer/Q Targets Min              -9.15731
trainer/Log Pis Mean                1.93553
trainer/Log Pis Std                 1.11242
trainer/Log Pis Max                 3.76598
trainer/Log Pis Min                -4.56459
trainer/Policy mu Mean             -0.00409233
trainer/Policy mu Std               0.316247
trainer/Policy mu Max               2.05585
trainer/Policy mu Min              -2.34856
trainer/Policy log std Mean        -2.31989
trainer/Policy log std Std          0.248304
trainer/Policy log std Max         -0.791882
trainer/Policy log std Min         -2.50431
trainer/Alpha                       0.0615119
trainer/Alpha Loss                 -0.179785
exploration/num steps total    146700
exploration/num paths total      1467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.44606
exploration/Rewards Std             1.39743
exploration/Rewards Max            -0.0026187
exploration/Rewards Min           -10.5792
exploration/Returns Mean          -44.606
exploration/Returns Std            18.4251
exploration/Returns Max           -13.9373
exploration/Returns Min           -67.9645
exploration/Actions Mean            0.00984936
exploration/Actions Std             0.25912
exploration/Actions Max             0.999744
exploration/Actions Min            -0.999035
exploration/Num Paths               5
exploration/Average Returns       -44.606
evaluation/num steps total     439500
evaluation/num paths total       4395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.292499
evaluation/Rewards Std              1.11735
evaluation/Rewards Max             -0.0377199
evaluation/Rewards Min            -10.1146
evaluation/Returns Mean           -29.2499
evaluation/Returns Std             13.749
evaluation/Returns Max             -6.84881
evaluation/Returns Min            -55.7605
evaluation/Actions Mean             0.00863674
evaluation/Actions Std              0.206184
evaluation/Actions Max              0.997788
evaluation/Actions Min             -0.997189
evaluation/Num Paths               15
evaluation/Average Returns        -29.2499
time/data storing (s)               0.00297427
time/evaluation sampling (s)        0.358712
time/exploration sampling (s)       0.162672
time/logging (s)                    0.00500185
time/saving (s)                     0.00201912
time/training (s)                   2.14417
time/epoch (s)                      2.67555
time/total (s)                    789.869
Epoch                             292
-----------------------------  ---------------
2019-04-22 21:51:14.074953 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 293 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.754165
trainer/QF2 Loss                    0.749953
trainer/Policy Loss                 8.44354
trainer/Q1 Predictions Mean        -6.64491
trainer/Q1 Predictions Std          2.74629
trainer/Q1 Predictions Max         -5.98769
trainer/Q1 Predictions Min        -33.8255
trainer/Q2 Predictions Mean        -6.64013
trainer/Q2 Predictions Std          2.75522
trainer/Q2 Predictions Max         -6.00655
trainer/Q2 Predictions Min        -33.9237
trainer/Q Targets Mean             -6.5489
trainer/Q Targets Std               2.91478
trainer/Q Targets Max              -0.088576
trainer/Q Targets Min             -34.0771
trainer/Log Pis Mean                1.80505
trainer/Log Pis Std                 1.07929
trainer/Log Pis Max                 6.14793
trainer/Log Pis Min                -1.70523
trainer/Policy mu Mean             -0.0266639
trainer/Policy mu Std               0.351994
trainer/Policy mu Max               1.67757
trainer/Policy mu Min              -3.11987
trainer/Policy log std Mean        -2.25154
trainer/Policy log std Std          0.242301
trainer/Policy log std Max         -0.697744
trainer/Policy log std Min         -2.43024
trainer/Alpha                       0.0594662
trainer/Alpha Loss                 -0.550182
exploration/num steps total    147200
exploration/num paths total      1472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.293198
exploration/Rewards Std             0.917503
exploration/Rewards Max            -0.00204701
exploration/Rewards Min            -8.99761
exploration/Returns Mean          -29.3198
exploration/Returns Std            15.2658
exploration/Returns Max           -13.0572
exploration/Returns Min           -55.1077
exploration/Actions Mean            0.0323249
exploration/Actions Std             0.22689
exploration/Actions Max             0.998822
exploration/Actions Min            -0.994043
exploration/Num Paths               5
exploration/Average Returns       -29.3198
evaluation/num steps total     441000
evaluation/num paths total       4410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.155832
evaluation/Rewards Std              0.746497
evaluation/Rewards Max             -0.0147972
evaluation/Rewards Min            -10.0901
evaluation/Returns Mean           -15.5832
evaluation/Returns Std             12.9471
evaluation/Returns Max             -3.92475
evaluation/Returns Min            -46.9224
evaluation/Actions Mean            -0.00910313
evaluation/Actions Std              0.165868
evaluation/Actions Max              0.996225
evaluation/Actions Min             -0.998225
evaluation/Num Paths               15
evaluation/Average Returns        -15.5832
time/data storing (s)               0.00342288
time/evaluation sampling (s)        0.387051
time/exploration sampling (s)       0.161174
time/logging (s)                    0.00418093
time/saving (s)                     0.00196034
time/training (s)                   2.10495
time/epoch (s)                      2.66274
time/total (s)                    792.537
Epoch                             293
-----------------------------  ---------------
2019-04-22 21:51:16.755267 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 294 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.884603
trainer/QF2 Loss                    0.889594
trainer/Policy Loss                 8.59857
trainer/Q1 Predictions Mean        -6.58748
trainer/Q1 Predictions Std          1.32169
trainer/Q1 Predictions Max         -6.03751
trainer/Q1 Predictions Min        -18.5286
trainer/Q2 Predictions Mean        -6.58785
trainer/Q2 Predictions Std          1.30784
trainer/Q2 Predictions Max         -6.04267
trainer/Q2 Predictions Min        -18.3213
trainer/Q Targets Mean             -6.44429
trainer/Q Targets Std               1.61234
trainer/Q Targets Max              -0.15335
trainer/Q Targets Min             -18.8012
trainer/Log Pis Mean                2.01752
trainer/Log Pis Std                 0.95971
trainer/Log Pis Max                 4.52112
trainer/Log Pis Min                -3.33144
trainer/Policy mu Mean             -0.0302957
trainer/Policy mu Std               0.319533
trainer/Policy mu Max               0.261448
trainer/Policy mu Min              -2.87457
trainer/Policy log std Mean        -2.32474
trainer/Policy log std Std          0.211448
trainer/Policy log std Max         -0.655008
trainer/Policy log std Min         -2.50773
trainer/Alpha                       0.0589963
trainer/Alpha Loss                  0.049575
exploration/num steps total    147700
exploration/num paths total      1477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.215926
exploration/Rewards Std             0.585661
exploration/Rewards Max            -0.00326292
exploration/Rewards Min            -6.61537
exploration/Returns Mean          -21.5926
exploration/Returns Std             7.70581
exploration/Returns Max           -12.8199
exploration/Returns Min           -32.7013
exploration/Actions Mean            0.00216155
exploration/Actions Std             0.205417
exploration/Actions Max             0.998
exploration/Actions Min            -0.998944
exploration/Num Paths               5
exploration/Average Returns       -21.5926
evaluation/num steps total     442500
evaluation/num paths total       4425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.227031
evaluation/Rewards Std              0.937108
evaluation/Rewards Max             -0.0133404
evaluation/Rewards Min             -9.84647
evaluation/Returns Mean           -22.7031
evaluation/Returns Std             14.134
evaluation/Returns Max             -5.33047
evaluation/Returns Min            -53.5233
evaluation/Actions Mean             0.00258549
evaluation/Actions Std              0.192016
evaluation/Actions Max              0.998558
evaluation/Actions Min             -0.997642
evaluation/Num Paths               15
evaluation/Average Returns        -22.7031
time/data storing (s)               0.00299648
time/evaluation sampling (s)        0.358312
time/exploration sampling (s)       0.16355
time/logging (s)                    0.00504297
time/saving (s)                     0.00205512
time/training (s)                   2.14033
time/epoch (s)                      2.67228
time/total (s)                    795.213
Epoch                             294
-----------------------------  ---------------
2019-04-22 21:51:19.407201 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 295 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.00673475
trainer/QF2 Loss                    0.00752946
trainer/Policy Loss                 8.95106
trainer/Q1 Predictions Mean        -6.74704
trainer/Q1 Predictions Std          1.85479
trainer/Q1 Predictions Max         -6.05549
trainer/Q1 Predictions Min        -19.4006
trainer/Q2 Predictions Mean        -6.75438
trainer/Q2 Predictions Std          1.87282
trainer/Q2 Predictions Max         -6.04231
trainer/Q2 Predictions Min        -19.6265
trainer/Q Targets Mean             -6.7787
trainer/Q Targets Std               1.83689
trainer/Q Targets Max              -6.06088
trainer/Q Targets Min             -19.4202
trainer/Log Pis Mean                2.21106
trainer/Log Pis Std                 1.0483
trainer/Log Pis Max                 7.75398
trainer/Log Pis Min                -0.452039
trainer/Policy mu Mean              0.000712293
trainer/Policy mu Std               0.535643
trainer/Policy mu Max               2.76753
trainer/Policy mu Min              -2.75014
trainer/Policy log std Mean        -2.28564
trainer/Policy log std Std          0.37644
trainer/Policy log std Max         -0.531094
trainer/Policy log std Min         -2.45993
trainer/Alpha                       0.0598201
trainer/Alpha Loss                  0.594463
exploration/num steps total    148200
exploration/num paths total      1482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.395434
exploration/Rewards Std             1.20151
exploration/Rewards Max            -0.00339216
exploration/Rewards Min            -9.21073
exploration/Returns Mean          -39.5434
exploration/Returns Std            12.2454
exploration/Returns Max           -22.9454
exploration/Returns Min           -58.7952
exploration/Actions Mean           -0.00122815
exploration/Actions Std             0.24426
exploration/Actions Max             0.999216
exploration/Actions Min            -0.999021
exploration/Num Paths               5
exploration/Average Returns       -39.5434
evaluation/num steps total     444000
evaluation/num paths total       4440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241794
evaluation/Rewards Std              1.111
evaluation/Rewards Max             -0.0147132
evaluation/Rewards Min            -11.8085
evaluation/Returns Mean           -24.1794
evaluation/Returns Std             18.4047
evaluation/Returns Max             -1.94796
evaluation/Returns Min            -60.927
evaluation/Actions Mean            -0.00475149
evaluation/Actions Std              0.201251
evaluation/Actions Max              0.999046
evaluation/Actions Min             -0.998088
evaluation/Num Paths               15
evaluation/Average Returns        -24.1794
time/data storing (s)               0.00325721
time/evaluation sampling (s)        0.36192
time/exploration sampling (s)       0.161839
time/logging (s)                    0.00523684
time/saving (s)                     0.00202407
time/training (s)                   2.10842
time/epoch (s)                      2.6427
time/total (s)                    797.861
Epoch                             295
-----------------------------  ----------------
2019-04-22 21:51:22.055985 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 296 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.805131
trainer/QF2 Loss                    0.799089
trainer/Policy Loss                 8.9028
trainer/Q1 Predictions Mean        -6.8987
trainer/Q1 Predictions Std          3.88614
trainer/Q1 Predictions Max         -6.07334
trainer/Q1 Predictions Min        -43.3655
trainer/Q2 Predictions Mean        -6.89702
trainer/Q2 Predictions Std          3.88747
trainer/Q2 Predictions Max         -6.05694
trainer/Q2 Predictions Min        -43.4111
trainer/Q Targets Mean             -6.85495
trainer/Q Targets Std               3.98081
trainer/Q Targets Max              -0.071976
trainer/Q Targets Min             -43.2103
trainer/Log Pis Mean                2.01667
trainer/Log Pis Std                 1.2735
trainer/Log Pis Max                10.3083
trainer/Log Pis Min                -1.32674
trainer/Policy mu Mean             -0.0672395
trainer/Policy mu Std               0.489031
trainer/Policy mu Max               2.38657
trainer/Policy mu Min              -3.4212
trainer/Policy log std Mean        -2.24332
trainer/Policy log std Std          0.299516
trainer/Policy log std Max         -0.517413
trainer/Policy log std Min         -2.50173
trainer/Alpha                       0.0606079
trainer/Alpha Loss                  0.046729
exploration/num steps total    148700
exploration/num paths total      1487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.23366
exploration/Rewards Std             0.632704
exploration/Rewards Max            -0.00293117
exploration/Rewards Min            -6.4153
exploration/Returns Mean          -23.366
exploration/Returns Std             7.04711
exploration/Returns Max           -11.903
exploration/Returns Min           -33.1745
exploration/Actions Mean            0.00839946
exploration/Actions Std             0.211581
exploration/Actions Max             0.999697
exploration/Actions Min            -0.998493
exploration/Num Paths               5
exploration/Average Returns       -23.366
evaluation/num steps total     445500
evaluation/num paths total       4455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.235688
evaluation/Rewards Std              1.00276
evaluation/Rewards Max             -0.0298019
evaluation/Rewards Min            -11.5011
evaluation/Returns Mean           -23.5688
evaluation/Returns Std             16.5755
evaluation/Returns Max             -5.41355
evaluation/Returns Min            -60.5411
evaluation/Actions Mean            -0.00712211
evaluation/Actions Std              0.19484
evaluation/Actions Max              0.998828
evaluation/Actions Min             -0.998953
evaluation/Num Paths               15
evaluation/Average Returns        -23.5688
time/data storing (s)               0.00355398
time/evaluation sampling (s)        0.356801
time/exploration sampling (s)       0.162373
time/logging (s)                    0.00483412
time/saving (s)                     0.00201457
time/training (s)                   2.11002
time/epoch (s)                      2.6396
time/total (s)                    800.505
Epoch                             296
-----------------------------  ---------------
2019-04-22 21:51:24.724918 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 297 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.19123
trainer/QF2 Loss                    1.18667
trainer/Policy Loss                 8.89237
trainer/Q1 Predictions Mean        -6.83595
trainer/Q1 Predictions Std          2.33263
trainer/Q1 Predictions Max         -5.99587
trainer/Q1 Predictions Min        -22.6506
trainer/Q2 Predictions Mean        -6.82932
trainer/Q2 Predictions Std          2.27304
trainer/Q2 Predictions Max         -6.00844
trainer/Q2 Predictions Min        -22.2989
trainer/Q Targets Mean             -6.6933
trainer/Q Targets Std               2.54021
trainer/Q Targets Max              -0.0453973
trainer/Q Targets Min             -22.5214
trainer/Log Pis Mean                2.07417
trainer/Log Pis Std                 1.49609
trainer/Log Pis Max                 7.43684
trainer/Log Pis Min                -3.18557
trainer/Policy mu Mean              0.076072
trainer/Policy mu Std               0.569398
trainer/Policy mu Max               3.10808
trainer/Policy mu Min              -2.85814
trainer/Policy log std Mean        -2.25297
trainer/Policy log std Std          0.385908
trainer/Policy log std Max         -0.551562
trainer/Policy log std Min         -2.51961
trainer/Alpha                       0.0638808
trainer/Alpha Loss                  0.204038
exploration/num steps total    149200
exploration/num paths total      1492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.339328
exploration/Rewards Std             1.08761
exploration/Rewards Max            -0.00290769
exploration/Rewards Min           -10.9452
exploration/Returns Mean          -33.9328
exploration/Returns Std            16.1755
exploration/Returns Max           -14.2952
exploration/Returns Min           -62.1716
exploration/Actions Mean           -0.0247199
exploration/Actions Std             0.232697
exploration/Actions Max             0.996788
exploration/Actions Min            -0.998435
exploration/Num Paths               5
exploration/Average Returns       -33.9328
evaluation/num steps total     447000
evaluation/num paths total       4470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238762
evaluation/Rewards Std              0.955931
evaluation/Rewards Max             -0.0116272
evaluation/Rewards Min             -9.38247
evaluation/Returns Mean           -23.8762
evaluation/Returns Std             14.3925
evaluation/Returns Max             -6.05146
evaluation/Returns Min            -52.8309
evaluation/Actions Mean             0.0062237
evaluation/Actions Std              0.191486
evaluation/Actions Max              0.997901
evaluation/Actions Min             -0.997455
evaluation/Num Paths               15
evaluation/Average Returns        -23.8762
time/data storing (s)               0.00297838
time/evaluation sampling (s)        0.385113
time/exploration sampling (s)       0.16167
time/logging (s)                    0.00475924
time/saving (s)                     0.00199599
time/training (s)                   2.10339
time/epoch (s)                      2.65991
time/total (s)                    803.169
Epoch                             297
-----------------------------  ---------------
2019-04-22 21:51:27.370694 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 298 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0112262
trainer/QF2 Loss                    0.0108884
trainer/Policy Loss                 8.2404
trainer/Q1 Predictions Mean        -6.35777
trainer/Q1 Predictions Std          0.236521
trainer/Q1 Predictions Max         -5.99671
trainer/Q1 Predictions Min         -6.98848
trainer/Q2 Predictions Mean        -6.35828
trainer/Q2 Predictions Std          0.2343
trainer/Q2 Predictions Max         -5.99953
trainer/Q2 Predictions Min         -7.01976
trainer/Q Targets Mean             -6.39355
trainer/Q Targets Std               0.270607
trainer/Q Targets Max              -5.96803
trainer/Q Targets Min              -7.01363
trainer/Log Pis Mean                1.88863
trainer/Log Pis Std                 1.00413
trainer/Log Pis Max                 3.12663
trainer/Log Pis Min                -2.86554
trainer/Policy mu Mean              0.00594189
trainer/Policy mu Std               0.245909
trainer/Policy mu Max               1.55588
trainer/Policy mu Min              -1.68672
trainer/Policy log std Mean        -2.32841
trainer/Policy log std Std          0.183702
trainer/Policy log std Max         -1.04654
trainer/Policy log std Min         -2.52626
trainer/Alpha                       0.0629841
trainer/Alpha Loss                 -0.307897
exploration/num steps total    149700
exploration/num paths total      1497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.321687
exploration/Rewards Std             0.951887
exploration/Rewards Max            -0.00653683
exploration/Rewards Min            -7.95281
exploration/Returns Mean          -32.1687
exploration/Returns Std            14.2282
exploration/Returns Max           -14.8915
exploration/Returns Min           -47.7761
exploration/Actions Mean           -0.0026617
exploration/Actions Std             0.220073
exploration/Actions Max             0.998385
exploration/Actions Min            -0.999413
exploration/Num Paths               5
exploration/Average Returns       -32.1687
evaluation/num steps total     448500
evaluation/num paths total       4485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243446
evaluation/Rewards Std              0.915201
evaluation/Rewards Max             -0.00720466
evaluation/Rewards Min             -8.89864
evaluation/Returns Mean           -24.3446
evaluation/Returns Std             11.8038
evaluation/Returns Max             -8.32419
evaluation/Returns Min            -44.8166
evaluation/Actions Mean            -0.0179178
evaluation/Actions Std              0.186124
evaluation/Actions Max              0.997341
evaluation/Actions Min             -0.99818
evaluation/Num Paths               15
evaluation/Average Returns        -24.3446
time/data storing (s)               0.00306437
time/evaluation sampling (s)        0.361887
time/exploration sampling (s)       0.163145
time/logging (s)                    0.00456196
time/saving (s)                     0.00198942
time/training (s)                   2.10194
time/epoch (s)                      2.63658
time/total (s)                    805.81
Epoch                             298
-----------------------------  ---------------
2019-04-22 21:51:30.044130 PDT | [sac-pointmass-multitask-3_2019_04_22_21_38_00_0000--s-0] Epoch 299 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.454229
trainer/QF2 Loss                    0.44049
trainer/Policy Loss                 9.3158
trainer/Q1 Predictions Mean        -7.23419
trainer/Q1 Predictions Std          3.53393
trainer/Q1 Predictions Max         -6.04893
trainer/Q1 Predictions Min        -27.73
trainer/Q2 Predictions Mean        -7.23409
trainer/Q2 Predictions Std          3.56257
trainer/Q2 Predictions Max         -6.05257
trainer/Q2 Predictions Min        -27.9283
trainer/Q Targets Mean             -7.16482
trainer/Q Targets Std               3.60617
trainer/Q Targets Max              -0.116031
trainer/Q Targets Min             -27.6674
trainer/Log Pis Mean                2.07327
trainer/Log Pis Std                 1.12332
trainer/Log Pis Max                 7.63846
trainer/Log Pis Min                -0.612947
trainer/Policy mu Mean              0.115485
trainer/Policy mu Std               0.610635
trainer/Policy mu Max               2.98403
trainer/Policy mu Min              -2.68371
trainer/Policy log std Mean        -2.24884
trainer/Policy log std Std          0.420167
trainer/Policy log std Max         -0.537654
trainer/Policy log std Min         -2.59143
trainer/Alpha                       0.061114
trainer/Alpha Loss                  0.204785
exploration/num steps total    150200
exploration/num paths total      1502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.472691
exploration/Rewards Std             1.4176
exploration/Rewards Max            -0.00873917
exploration/Rewards Min           -11.1266
exploration/Returns Mean          -47.2691
exploration/Returns Std            12.2076
exploration/Returns Max           -27.1732
exploration/Returns Min           -64.8428
exploration/Actions Mean           -0.030719
exploration/Actions Std             0.268052
exploration/Actions Max             0.998716
exploration/Actions Min            -0.999606
exploration/Num Paths               5
exploration/Average Returns       -47.2691
evaluation/num steps total     450000
evaluation/num paths total       4500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.305617
evaluation/Rewards Std              1.20813
evaluation/Rewards Max             -0.00926338
evaluation/Rewards Min            -11.2985
evaluation/Returns Mean           -30.5617
evaluation/Returns Std             19.7098
evaluation/Returns Max             -3.68727
evaluation/Returns Min            -62.5858
evaluation/Actions Mean             0.00701044
evaluation/Actions Std              0.200632
evaluation/Actions Max              0.998785
evaluation/Actions Min             -0.999168
evaluation/Num Paths               15
evaluation/Average Returns        -30.5617
time/data storing (s)               0.00281934
time/evaluation sampling (s)        0.354458
time/exploration sampling (s)       0.158174
time/logging (s)                    0.00487396
time/saving (s)                     0.00210743
time/training (s)                   2.14218
time/epoch (s)                      2.66461
time/total (s)                    808.479
Epoch                             299
-----------------------------  ---------------
