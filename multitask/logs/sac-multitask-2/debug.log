2019-04-22 21:21:54.501961 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  41.4005
trainer/QF2 Loss                  41.3815
trainer/Policy Loss               -1.33377
trainer/Q1 Predictions Mean        0.00120897
trainer/Q1 Predictions Std         0.000580213
trainer/Q1 Predictions Max         0.00210424
trainer/Q1 Predictions Min        -0.00112805
trainer/Q2 Predictions Mean       -0.000722455
trainer/Q2 Predictions Std         0.00120711
trainer/Q2 Predictions Max         0.000659996
trainer/Q2 Predictions Min        -0.00533823
trainer/Q Targets Mean            -5.53493
trainer/Q Targets Std              3.27904
trainer/Q Targets Max             -0.335457
trainer/Q Targets Min            -12.4474
trainer/Log Pis Mean              -1.33447
trainer/Log Pis Std                0.304457
trainer/Log Pis Max               -0.563941
trainer/Log Pis Min               -1.8268
trainer/Policy mu Mean            -7.67454e-05
trainer/Policy mu Std              0.000479013
trainer/Policy mu Max              0.000591976
trainer/Policy mu Min             -0.00134821
trainer/Policy log std Mean        0.000367369
trainer/Policy log std Std         0.000939036
trainer/Policy log std Max         0.00194823
trainer/Policy log std Min        -0.000992758
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -6.36559
exploration/Rewards Std            3.09607
exploration/Rewards Max           -0.237267
exploration/Rewards Min          -12.6027
exploration/Returns Mean        -636.559
exploration/Returns Std          269.816
exploration/Returns Max         -364.168
exploration/Returns Min        -1003.66
exploration/Actions Mean          -0.0187938
exploration/Actions Std            0.619389
exploration/Actions Max            0.996719
exploration/Actions Min           -0.993707
exploration/Num Paths              5
exploration/Average Returns     -636.559
evaluation/num steps total      1500
evaluation/num paths total        15
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -6.34222
evaluation/Rewards Std             2.86658
evaluation/Rewards Max            -2.59771
evaluation/Rewards Min           -10.7956
evaluation/Returns Mean         -634.222
evaluation/Returns Std           286.654
evaluation/Returns Max          -260.19
evaluation/Returns Min         -1078.06
evaluation/Actions Mean           -0.000317273
evaluation/Actions Std             0.000562444
evaluation/Actions Max             0.000563928
evaluation/Actions Min            -0.00155728
evaluation/Num Paths              15
evaluation/Average Returns      -634.222
time/data storing (s)              0.00331305
time/evaluation sampling (s)       0.361514
time/exploration sampling (s)      0.173838
time/logging (s)                   0.00566884
time/saving (s)                    0.00284746
time/training (s)                  2.37006
time/epoch (s)                     2.91724
time/total (s)                     3.16329
Epoch                              0
-----------------------------  ---------------
2019-04-22 21:21:57.310082 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size              1200
trainer/QF1 Loss                  19.2794
trainer/QF2 Loss                  18.7519
trainer/Policy Loss                8.18518
trainer/Q1 Predictions Mean       -9.46712
trainer/Q1 Predictions Std         4.70282
trainer/Q1 Predictions Max        -2.74399
trainer/Q1 Predictions Min       -23.63
trainer/Q2 Predictions Mean       -9.51372
trainer/Q2 Predictions Std         4.69273
trainer/Q2 Predictions Max        -2.82651
trainer/Q2 Predictions Min       -24.1097
trainer/Q Targets Mean           -11.4609
trainer/Q Targets Std              4.60394
trainer/Q Targets Max             -4.54427
trainer/Q Targets Min            -24.1058
trainer/Log Pis Mean              -1.30532
trainer/Log Pis Std                0.597259
trainer/Log Pis Max               -0.131481
trainer/Log Pis Min               -4.35331
trainer/Policy mu Mean            -0.00688347
trainer/Policy mu Std              0.309409
trainer/Policy mu Max              0.710975
trainer/Policy mu Min             -0.631747
trainer/Policy log std Mean       -0.210224
trainer/Policy log std Std         0.0486802
trainer/Policy log std Max        -0.121985
trainer/Policy log std Min        -0.320666
trainer/Alpha                      0.861522
trainer/Alpha Loss                -0.491718
exploration/num steps total     1200
exploration/num paths total       12
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -7.15251
exploration/Rewards Std            3.83561
exploration/Rewards Max           -0.187452
exploration/Rewards Min          -11.7477
exploration/Returns Mean        -715.251
exploration/Returns Std          301.741
exploration/Returns Max         -185.379
exploration/Returns Min        -1090.75
exploration/Actions Mean          -0.0856686
exploration/Actions Std            0.565216
exploration/Actions Max            0.988144
exploration/Actions Min           -0.995288
exploration/Num Paths              5
exploration/Average Returns     -715.251
evaluation/num steps total      3000
evaluation/num paths total        30
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -7.4795
evaluation/Rewards Std             4.13634
evaluation/Rewards Max            -0.330819
evaluation/Rewards Min           -11.9646
evaluation/Returns Mean         -747.95
evaluation/Returns Std           347.006
evaluation/Returns Max          -209.327
evaluation/Returns Min         -1196.46
evaluation/Actions Mean           -0.12701
evaluation/Actions Std             0.173663
evaluation/Actions Max             0.563866
evaluation/Actions Min            -0.528004
evaluation/Num Paths              15
evaluation/Average Returns      -747.95
time/data storing (s)              0.00307851
time/evaluation sampling (s)       0.478562
time/exploration sampling (s)      0.203205
time/logging (s)                   0.00530845
time/saving (s)                    0.00225922
time/training (s)                  2.10871
time/epoch (s)                     2.80113
time/total (s)                     5.97008
Epoch                              1
-----------------------------  --------------
2019-04-22 21:21:59.977210 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size             1700
trainer/QF1 Loss                  2.20686
trainer/QF2 Loss                  2.44558
trainer/Policy Loss              18.518
trainer/Q1 Predictions Mean     -20.0023
trainer/Q1 Predictions Std        8.51551
trainer/Q1 Predictions Max       -9.88537
trainer/Q1 Predictions Min      -47.3332
trainer/Q2 Predictions Mean     -19.9781
trainer/Q2 Predictions Std        8.4801
trainer/Q2 Predictions Max       -9.96281
trainer/Q2 Predictions Min      -47.4421
trainer/Q Targets Mean          -20.136
trainer/Q Targets Std             8.92338
trainer/Q Targets Max            -2.27162
trainer/Q Targets Min           -45.4752
trainer/Log Pis Mean             -0.78701
trainer/Log Pis Std               0.835234
trainer/Log Pis Max               1.78092
trainer/Log Pis Min              -3.08683
trainer/Policy mu Mean           -0.0161479
trainer/Policy mu Std             0.562567
trainer/Policy mu Max             1.25372
trainer/Policy mu Min            -1.31695
trainer/Policy log std Mean      -0.297897
trainer/Policy log std Std        0.0713276
trainer/Policy log std Max       -0.169366
trainer/Policy log std Min       -0.453482
trainer/Alpha                     0.749561
trainer/Alpha Loss               -0.80268
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.8833
exploration/Rewards Std           1.60698
exploration/Rewards Max          -0.740234
exploration/Rewards Min         -11.5721
exploration/Returns Mean       -388.33
exploration/Returns Std          28.4922
exploration/Returns Max        -352.094
exploration/Returns Min        -434.42
exploration/Actions Mean          0.0206318
exploration/Actions Std           0.570622
exploration/Actions Max           0.993805
exploration/Actions Min          -0.978551
exploration/Num Paths             5
exploration/Average Returns    -388.33
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.16271
evaluation/Rewards Std            0.874942
evaluation/Rewards Max           -1.24096
evaluation/Rewards Min          -10.492
evaluation/Returns Mean        -316.271
evaluation/Returns Std           40.9878
evaluation/Returns Max         -257.674
evaluation/Returns Min         -398.395
evaluation/Actions Mean          -0.00353931
evaluation/Actions Std            0.120223
evaluation/Actions Max            0.844833
evaluation/Actions Min           -0.789755
evaluation/Num Paths             15
evaluation/Average Returns     -316.271
time/data storing (s)             0.00319597
time/evaluation sampling (s)      0.365384
time/exploration sampling (s)     0.16284
time/logging (s)                  0.00521174
time/saving (s)                   0.00802679
time/training (s)                 2.11657
time/epoch (s)                    2.66123
time/total (s)                    8.63624
Epoch                             2
-----------------------------  -------------
2019-04-22 21:22:02.722122 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             2200
trainer/QF1 Loss                  1.51893
trainer/QF2 Loss                  1.65385
trainer/Policy Loss              24.4679
trainer/Q1 Predictions Mean     -26.5748
trainer/Q1 Predictions Std       11.0633
trainer/Q1 Predictions Max      -11.891
trainer/Q1 Predictions Min      -52.4591
trainer/Q2 Predictions Mean     -26.5572
trainer/Q2 Predictions Std       11.0432
trainer/Q2 Predictions Max      -11.8453
trainer/Q2 Predictions Min      -52.6444
trainer/Q Targets Mean          -26.7733
trainer/Q Targets Std            11.4799
trainer/Q Targets Max           -11.6235
trainer/Q Targets Min           -51.9605
trainer/Log Pis Mean             -0.0753612
trainer/Log Pis Std               1.33767
trainer/Log Pis Max               2.69986
trainer/Log Pis Min              -3.54171
trainer/Policy mu Mean            0.153475
trainer/Policy mu Std             0.870052
trainer/Policy mu Max             1.4898
trainer/Policy mu Min            -1.6157
trainer/Policy log std Mean      -0.475189
trainer/Policy log std Std        0.0473791
trainer/Policy log std Max       -0.370027
trainer/Policy log std Min       -0.615468
trainer/Alpha                     0.662525
trainer/Alpha Loss               -0.853963
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.28862
exploration/Rewards Std           0.910116
exploration/Rewards Max          -0.0378884
exploration/Rewards Min          -7.26705
exploration/Returns Mean       -128.862
exploration/Returns Std          32.3186
exploration/Returns Max         -90.7524
exploration/Returns Min        -176.196
exploration/Actions Mean          0.0151069
exploration/Actions Std           0.527523
exploration/Actions Max           0.984543
exploration/Actions Min          -0.976007
exploration/Num Paths             5
exploration/Average Returns    -128.862
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.07602
evaluation/Rewards Std            0.9012
evaluation/Rewards Max           -0.375482
evaluation/Rewards Min           -9.50813
evaluation/Returns Mean        -107.602
evaluation/Returns Std           44.5509
evaluation/Returns Max          -62.6927
evaluation/Returns Min         -181.102
evaluation/Actions Mean          -0.00307918
evaluation/Actions Std            0.148821
evaluation/Actions Max            0.869198
evaluation/Actions Min           -0.922237
evaluation/Num Paths             15
evaluation/Average Returns     -107.602
time/data storing (s)             0.00452234
time/evaluation sampling (s)      0.371655
time/exploration sampling (s)     0.219497
time/logging (s)                  0.00482657
time/saving (s)                   0.00218311
time/training (s)                 2.13672
time/epoch (s)                    2.73941
time/total (s)                   11.38
Epoch                             3
-----------------------------  -------------
2019-04-22 21:22:05.367861 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                  6.14276
trainer/QF2 Loss                  6.22592
trainer/Policy Loss              25.4136
trainer/Q1 Predictions Mean     -27.3354
trainer/Q1 Predictions Std       14.8059
trainer/Q1 Predictions Max      -12.0164
trainer/Q1 Predictions Min      -65.4132
trainer/Q2 Predictions Mean     -27.3888
trainer/Q2 Predictions Std       14.7969
trainer/Q2 Predictions Max      -11.9365
trainer/Q2 Predictions Min      -65.6231
trainer/Q Targets Mean          -27.1225
trainer/Q Targets Std            15.1554
trainer/Q Targets Max            -3.64563
trainer/Q Targets Min           -62.8424
trainer/Log Pis Mean              0.155459
trainer/Log Pis Std               1.3504
trainer/Log Pis Max               3.13872
trainer/Log Pis Min              -3.10431
trainer/Policy mu Mean            0.182981
trainer/Policy mu Std             0.890402
trainer/Policy mu Max             1.57464
trainer/Policy mu Min            -1.81995
trainer/Policy log std Mean      -0.581357
trainer/Policy log std Std        0.116867
trainer/Policy log std Max       -0.335114
trainer/Policy log std Min       -0.789
trainer/Alpha                     0.590888
trainer/Alpha Loss               -0.970073
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -0.870557
exploration/Rewards Std           0.802136
exploration/Rewards Max          -0.0455647
exploration/Rewards Min          -8.38849
exploration/Returns Mean        -87.0557
exploration/Returns Std          15.1556
exploration/Returns Max         -73.8438
exploration/Returns Min        -115.498
exploration/Actions Mean          0.0115491
exploration/Actions Std           0.473094
exploration/Actions Max           0.990005
exploration/Actions Min          -0.963673
exploration/Num Paths             5
exploration/Average Returns     -87.0557
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.663959
evaluation/Rewards Std            0.938724
evaluation/Rewards Max           -0.267649
evaluation/Rewards Min          -10.3953
evaluation/Returns Mean         -66.3959
evaluation/Returns Std           17.9349
evaluation/Returns Max          -47.941
evaluation/Returns Min         -104.021
evaluation/Actions Mean          -0.0026392
evaluation/Actions Std            0.162093
evaluation/Actions Max            0.891493
evaluation/Actions Min           -0.962876
evaluation/Num Paths             15
evaluation/Average Returns      -66.3959
time/data storing (s)             0.00310301
time/evaluation sampling (s)      0.348604
time/exploration sampling (s)     0.161364
time/logging (s)                  0.0049717
time/saving (s)                   0.00201976
time/training (s)                 2.12056
time/epoch (s)                    2.64062
time/total (s)                   14.0251
Epoch                             4
-----------------------------  -------------
2019-04-22 21:22:08.066607 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             3200
trainer/QF1 Loss                  3.73976
trainer/QF2 Loss                  4.14806
trainer/Policy Loss              22.9226
trainer/Q1 Predictions Mean     -24.8379
trainer/Q1 Predictions Std       13.8521
trainer/Q1 Predictions Max      -12.3313
trainer/Q1 Predictions Min      -70.1143
trainer/Q2 Predictions Mean     -24.9096
trainer/Q2 Predictions Std       13.8368
trainer/Q2 Predictions Max      -12.1533
trainer/Q2 Predictions Min      -70.2758
trainer/Q Targets Mean          -24.8964
trainer/Q Targets Std            14.2265
trainer/Q Targets Max            -2.7139
trainer/Q Targets Min           -72.3889
trainer/Log Pis Mean              0.326084
trainer/Log Pis Std               1.44798
trainer/Log Pis Max               3.74028
trainer/Log Pis Min              -3.92338
trainer/Policy mu Mean            0.15516
trainer/Policy mu Std             0.922547
trainer/Policy mu Max             1.87079
trainer/Policy mu Min            -1.6641
trainer/Policy log std Mean      -0.660343
trainer/Policy log std Std        0.107719
trainer/Policy log std Max       -0.380557
trainer/Policy log std Min       -0.859335
trainer/Alpha                     0.526259
trainer/Alpha Loss               -1.0742
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.11838
exploration/Rewards Std           1.55142
exploration/Rewards Max          -0.0237365
exploration/Rewards Min         -10.2168
exploration/Returns Mean       -111.838
exploration/Returns Std          16.0932
exploration/Returns Max         -86.5722
exploration/Returns Min        -133.419
exploration/Actions Mean         -0.0111749
exploration/Actions Std           0.481655
exploration/Actions Max           0.98157
exploration/Actions Min          -0.98819
exploration/Num Paths             5
exploration/Average Returns    -111.838
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -0.675977
evaluation/Rewards Std            0.803371
evaluation/Rewards Max           -0.418605
evaluation/Rewards Min          -10.1424
evaluation/Returns Mean         -67.5977
evaluation/Returns Std           17.0699
evaluation/Returns Max          -42.1755
evaluation/Returns Min         -109.206
evaluation/Actions Mean          -0.00726174
evaluation/Actions Std            0.156171
evaluation/Actions Max            0.949855
evaluation/Actions Min           -0.958658
evaluation/Num Paths             15
evaluation/Average Returns      -67.5977
time/data storing (s)             0.00307536
time/evaluation sampling (s)      0.359354
time/exploration sampling (s)     0.163532
time/logging (s)                  0.00471827
time/saving (s)                   0.00192705
time/training (s)                 2.16075
time/epoch (s)                    2.69336
time/total (s)                   16.7228
Epoch                             5
-----------------------------  -------------
2019-04-22 21:22:10.720973 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                   8.6836
trainer/QF2 Loss                   9.10727
trainer/Policy Loss               25.6339
trainer/Q1 Predictions Mean      -28.0281
trainer/Q1 Predictions Std        20.638
trainer/Q1 Predictions Max       -13.0498
trainer/Q1 Predictions Min       -89.64
trainer/Q2 Predictions Mean      -28.0727
trainer/Q2 Predictions Std        20.6491
trainer/Q2 Predictions Max       -12.7496
trainer/Q2 Predictions Min       -89.7651
trainer/Q Targets Mean           -27.8168
trainer/Q Targets Std             21.0905
trainer/Q Targets Max             -0.874673
trainer/Q Targets Min            -90.644
trainer/Log Pis Mean               0.120221
trainer/Log Pis Std                1.47902
trainer/Log Pis Max                4.18552
trainer/Log Pis Min               -3.65313
trainer/Policy mu Mean             0.144754
trainer/Policy mu Std              0.949766
trainer/Policy mu Max              1.93074
trainer/Policy mu Min             -1.95679
trainer/Policy log std Mean       -0.644688
trainer/Policy log std Std         0.0984735
trainer/Policy log std Max        -0.384983
trainer/Policy log std Min        -0.854137
trainer/Alpha                      0.463652
trainer/Alpha Loss                -1.44435
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.878305
exploration/Rewards Std            1.00227
exploration/Rewards Max           -0.0128846
exploration/Rewards Min          -10.0303
exploration/Returns Mean         -87.8305
exploration/Returns Std           16.1641
exploration/Returns Max          -72.5301
exploration/Returns Min         -118.045
exploration/Actions Mean          -0.0224818
exploration/Actions Std            0.475377
exploration/Actions Max            0.97849
exploration/Actions Min           -0.995314
exploration/Num Paths              5
exploration/Average Returns      -87.8305
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.721509
evaluation/Rewards Std             1.20331
evaluation/Rewards Max            -0.445274
evaluation/Rewards Min           -10.9189
evaluation/Returns Mean          -72.1509
evaluation/Returns Std            20.7343
evaluation/Returns Max           -45.7782
evaluation/Returns Min          -104.279
evaluation/Actions Mean           -0.00179596
evaluation/Actions Std             0.198849
evaluation/Actions Max             0.953341
evaluation/Actions Min            -0.972376
evaluation/Num Paths              15
evaluation/Average Returns       -72.1509
time/data storing (s)              0.00364736
time/evaluation sampling (s)       0.361828
time/exploration sampling (s)      0.164533
time/logging (s)                   0.0050905
time/saving (s)                    0.00195057
time/training (s)                  2.11262
time/epoch (s)                     2.64967
time/total (s)                    19.3767
Epoch                              6
-----------------------------  --------------
2019-04-22 21:22:13.430257 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   1.31046
trainer/QF2 Loss                   1.77861
trainer/Policy Loss               22.7354
trainer/Q1 Predictions Mean      -23.8686
trainer/Q1 Predictions Std        14.8463
trainer/Q1 Predictions Max       -13.9218
trainer/Q1 Predictions Min       -72.466
trainer/Q2 Predictions Mean      -23.9485
trainer/Q2 Predictions Std        14.7906
trainer/Q2 Predictions Max       -13.5737
trainer/Q2 Predictions Min       -72.1064
trainer/Q Targets Mean           -24.0062
trainer/Q Targets Std             14.8934
trainer/Q Targets Max            -13.951
trainer/Q Targets Min            -73.0376
trainer/Log Pis Mean               0.018049
trainer/Log Pis Std                1.5401
trainer/Log Pis Max                4.53974
trainer/Log Pis Min               -3.36684
trainer/Policy mu Mean             0.156076
trainer/Policy mu Std              0.890369
trainer/Policy mu Max              1.98801
trainer/Policy mu Min             -2.0523
trainer/Policy log std Mean       -0.675144
trainer/Policy log std Std         0.0786304
trainer/Policy log std Max        -0.420538
trainer/Policy log std Min        -0.828925
trainer/Alpha                      0.404855
trainer/Alpha Loss                -1.7916
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.877057
exploration/Rewards Std            1.12215
exploration/Rewards Max           -0.0277067
exploration/Rewards Min           -9.58394
exploration/Returns Mean         -87.7057
exploration/Returns Std           14.326
exploration/Returns Max          -67.4005
exploration/Returns Min         -109.813
exploration/Actions Mean          -0.00362848
exploration/Actions Std            0.494935
exploration/Actions Max            0.980537
exploration/Actions Min           -0.985394
exploration/Num Paths              5
exploration/Average Returns      -87.7057
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.631786
evaluation/Rewards Std             1.02646
evaluation/Rewards Max            -0.316269
evaluation/Rewards Min           -10.2513
evaluation/Returns Mean          -63.1786
evaluation/Returns Std            16.0116
evaluation/Returns Max           -39.2974
evaluation/Returns Min           -91.0829
evaluation/Actions Mean            0.00970952
evaluation/Actions Std             0.188632
evaluation/Actions Max             0.962721
evaluation/Actions Min            -0.974594
evaluation/Num Paths              15
evaluation/Average Returns       -63.1786
time/data storing (s)              0.00297082
time/evaluation sampling (s)       0.360688
time/exploration sampling (s)      0.158522
time/logging (s)                   0.00468518
time/saving (s)                    0.00208368
time/training (s)                  2.17432
time/epoch (s)                     2.70327
time/total (s)                    22.0845
Epoch                              7
-----------------------------  --------------
2019-04-22 21:22:16.260346 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                   0.59668
trainer/QF2 Loss                   0.758715
trainer/Policy Loss               22.7925
trainer/Q1 Predictions Mean      -24.3277
trainer/Q1 Predictions Std        15.8174
trainer/Q1 Predictions Max       -14.7198
trainer/Q1 Predictions Min       -82.4956
trainer/Q2 Predictions Mean      -24.3701
trainer/Q2 Predictions Std        15.8012
trainer/Q2 Predictions Max       -14.6001
trainer/Q2 Predictions Min       -82.7401
trainer/Q Targets Mean           -24.5171
trainer/Q Targets Std             15.9795
trainer/Q Targets Max            -14.9713
trainer/Q Targets Min            -86.0483
trainer/Log Pis Mean              -0.212416
trainer/Log Pis Std                1.3616
trainer/Log Pis Max                4.07028
trainer/Log Pis Min               -3.35648
trainer/Policy mu Mean             0.0715479
trainer/Policy mu Std              0.86437
trainer/Policy mu Max              2.07587
trainer/Policy mu Min             -2.2572
trainer/Policy log std Mean       -0.672808
trainer/Policy log std Std         0.0738929
trainer/Policy log std Max        -0.466342
trainer/Policy log std Min        -0.804153
trainer/Alpha                      0.351477
trainer/Alpha Loss                -2.31268
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.793146
exploration/Rewards Std            0.922643
exploration/Rewards Max           -0.0188418
exploration/Rewards Min          -10.1658
exploration/Returns Mean         -79.3146
exploration/Returns Std           18.7904
exploration/Returns Max          -66.2568
exploration/Returns Min         -116.658
exploration/Actions Mean          -0.00233634
exploration/Actions Std            0.483309
exploration/Actions Max            0.990452
exploration/Actions Min           -0.983925
exploration/Num Paths              5
exploration/Average Returns      -79.3146
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.589534
evaluation/Rewards Std             1.16884
evaluation/Rewards Max            -0.211331
evaluation/Rewards Min            -9.37528
evaluation/Returns Mean          -58.9534
evaluation/Returns Std            17.4475
evaluation/Returns Max           -35.5629
evaluation/Returns Min           -89.6894
evaluation/Actions Mean           -0.00350431
evaluation/Actions Std             0.211661
evaluation/Actions Max             0.968198
evaluation/Actions Min            -0.971228
evaluation/Num Paths              15
evaluation/Average Returns       -58.9534
time/data storing (s)              0.00368854
time/evaluation sampling (s)       0.439893
time/exploration sampling (s)      0.164185
time/logging (s)                   0.00468826
time/saving (s)                    0.00217665
time/training (s)                  2.2099
time/epoch (s)                     2.82454
time/total (s)                    24.9139
Epoch                              8
-----------------------------  --------------
2019-04-22 21:22:18.985670 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                  12.1457
trainer/QF2 Loss                  12.1716
trainer/Policy Loss               23.7104
trainer/Q1 Predictions Mean      -24.8128
trainer/Q1 Predictions Std        15.1926
trainer/Q1 Predictions Max       -15.9486
trainer/Q1 Predictions Min       -86.2512
trainer/Q2 Predictions Mean      -24.7982
trainer/Q2 Predictions Std        15.1781
trainer/Q2 Predictions Max       -15.8065
trainer/Q2 Predictions Min       -86.6193
trainer/Q Targets Mean           -24.2158
trainer/Q Targets Std             16.074
trainer/Q Targets Max             -1.37549
trainer/Q Targets Min            -87.2248
trainer/Log Pis Mean              -0.0812767
trainer/Log Pis Std                1.50621
trainer/Log Pis Max                4.69511
trainer/Log Pis Min               -3.94121
trainer/Policy mu Mean             0.0894038
trainer/Policy mu Std              0.855692
trainer/Policy mu Max              2.19542
trainer/Policy mu Min             -2.2421
trainer/Policy log std Mean       -0.713766
trainer/Policy log std Std         0.103833
trainer/Policy log std Max        -0.508737
trainer/Policy log std Min        -0.892301
trainer/Alpha                      0.303227
trainer/Alpha Loss                -2.48291
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.822348
exploration/Rewards Std            1.02075
exploration/Rewards Max           -0.0298198
exploration/Rewards Min          -10.5876
exploration/Returns Mean         -82.2348
exploration/Returns Std           16.4416
exploration/Returns Max          -67.8931
exploration/Returns Min         -112.82
exploration/Actions Mean           0.00489752
exploration/Actions Std            0.469344
exploration/Actions Max            0.995114
exploration/Actions Min           -0.99248
exploration/Num Paths              5
exploration/Average Returns      -82.2348
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.903999
evaluation/Rewards Std             1.50366
evaluation/Rewards Max            -0.177555
evaluation/Rewards Min           -11.4092
evaluation/Returns Mean          -90.3999
evaluation/Returns Std           117.812
evaluation/Returns Max           -31.2057
evaluation/Returns Min          -526.984
evaluation/Actions Mean           -0.0326978
evaluation/Actions Std             0.255109
evaluation/Actions Max             0.973746
evaluation/Actions Min            -0.97572
evaluation/Num Paths              15
evaluation/Average Returns       -90.3999
time/data storing (s)              0.00313638
time/evaluation sampling (s)       0.36262
time/exploration sampling (s)      0.164392
time/logging (s)                   0.00523777
time/saving (s)                    0.00200701
time/training (s)                  2.18313
time/epoch (s)                     2.72053
time/total (s)                    27.6391
Epoch                              9
-----------------------------  --------------
2019-04-22 21:22:21.652784 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                   3.25546
trainer/QF2 Loss                   3.36945
trainer/Policy Loss               25.3472
trainer/Q1 Predictions Mean      -26.5414
trainer/Q1 Predictions Std        15.7312
trainer/Q1 Predictions Max       -15.6756
trainer/Q1 Predictions Min       -78.0275
trainer/Q2 Predictions Mean      -26.5913
trainer/Q2 Predictions Std        15.7078
trainer/Q2 Predictions Max       -15.7083
trainer/Q2 Predictions Min       -77.6317
trainer/Q Targets Mean           -26.541
trainer/Q Targets Std             15.6722
trainer/Q Targets Max             -0.655053
trainer/Q Targets Min            -78.6724
trainer/Log Pis Mean               0.5361
trainer/Log Pis Std                1.77511
trainer/Log Pis Max                4.48846
trainer/Log Pis Min               -3.46811
trainer/Policy mu Mean             0.121176
trainer/Policy mu Std              0.970971
trainer/Policy mu Max              2.25396
trainer/Policy mu Min             -2.35177
trainer/Policy log std Mean       -0.78732
trainer/Policy log std Std         0.120708
trainer/Policy log std Max        -0.477556
trainer/Policy log std Min        -0.971823
trainer/Alpha                      0.262705
trainer/Alpha Loss                -1.95642
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.689176
exploration/Rewards Std            1.00734
exploration/Rewards Max           -0.0264945
exploration/Rewards Min           -9.72131
exploration/Returns Mean         -68.9176
exploration/Returns Std           22.4029
exploration/Returns Max          -49.6383
exploration/Returns Min          -97.6227
exploration/Actions Mean          -0.00937848
exploration/Actions Std            0.450837
exploration/Actions Max            0.94814
exploration/Actions Min           -0.993816
exploration/Num Paths              5
exploration/Average Returns      -68.9176
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.39762
evaluation/Rewards Std             1.16181
evaluation/Rewards Max            -0.049545
evaluation/Rewards Min           -10.485
evaluation/Returns Mean          -39.762
evaluation/Returns Std            21.3324
evaluation/Returns Max           -12.0679
evaluation/Returns Min           -75.2385
evaluation/Actions Mean           -0.00417051
evaluation/Actions Std             0.195953
evaluation/Actions Max             0.977686
evaluation/Actions Min            -0.985665
evaluation/Num Paths              15
evaluation/Average Returns       -39.762
time/data storing (s)              0.003906
time/evaluation sampling (s)       0.357785
time/exploration sampling (s)      0.164479
time/logging (s)                   0.00582451
time/saving (s)                    0.00170114
time/training (s)                  2.12854
time/epoch (s)                     2.66224
time/total (s)                    30.3059
Epoch                             10
-----------------------------  --------------
2019-04-22 21:22:24.343433 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                  12.6173
trainer/QF2 Loss                  12.5922
trainer/Policy Loss               23.0759
trainer/Q1 Predictions Mean      -24.5694
trainer/Q1 Predictions Std        13.6688
trainer/Q1 Predictions Max       -16.5901
trainer/Q1 Predictions Min       -86.0814
trainer/Q2 Predictions Mean      -24.5865
trainer/Q2 Predictions Std        13.6699
trainer/Q2 Predictions Max       -16.4849
trainer/Q2 Predictions Min       -86.5482
trainer/Q Targets Mean           -24.1003
trainer/Q Targets Std             14.1207
trainer/Q Targets Max             -0.493289
trainer/Q Targets Min            -86.4662
trainer/Log Pis Mean               0.126353
trainer/Log Pis Std                1.53461
trainer/Log Pis Max                4.39318
trainer/Log Pis Min               -3.25531
trainer/Policy mu Mean             0.106489
trainer/Policy mu Std              0.833924
trainer/Policy mu Max              2.45076
trainer/Policy mu Min             -2.36277
trainer/Policy log std Mean       -0.874853
trainer/Policy log std Std         0.141158
trainer/Policy log std Max        -0.56684
trainer/Policy log std Min        -1.12581
trainer/Alpha                      0.228294
trainer/Alpha Loss                -2.7671
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.703884
exploration/Rewards Std            1.03114
exploration/Rewards Max           -0.0205029
exploration/Rewards Min           -9.40452
exploration/Returns Mean         -70.3884
exploration/Returns Std           20.3296
exploration/Returns Max          -46.5288
exploration/Returns Min         -101.316
exploration/Actions Mean          -0.0296353
exploration/Actions Std            0.452722
exploration/Actions Max            0.946308
exploration/Actions Min           -0.992207
exploration/Num Paths              5
exploration/Average Returns      -70.3884
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.390877
evaluation/Rewards Std             0.891394
evaluation/Rewards Max            -0.0801172
evaluation/Rewards Min           -10.7037
evaluation/Returns Mean          -39.0877
evaluation/Returns Std            14.8987
evaluation/Returns Max           -21.5681
evaluation/Returns Min           -79.9387
evaluation/Actions Mean           -0.00159042
evaluation/Actions Std             0.179045
evaluation/Actions Max             0.977344
evaluation/Actions Min            -0.988188
evaluation/Num Paths              15
evaluation/Average Returns       -39.0877
time/data storing (s)              0.00304249
time/evaluation sampling (s)       0.363626
time/exploration sampling (s)      0.164457
time/logging (s)                   0.00463903
time/saving (s)                    0.0021602
time/training (s)                  2.14559
time/epoch (s)                     2.68352
time/total (s)                    32.9943
Epoch                             11
-----------------------------  --------------
2019-04-22 21:22:27.087903 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              6700
trainer/QF1 Loss                   0.799199
trainer/QF2 Loss                   0.716312
trainer/Policy Loss               25.9268
trainer/Q1 Predictions Mean      -26.6908
trainer/Q1 Predictions Std        18.1076
trainer/Q1 Predictions Max       -16.3727
trainer/Q1 Predictions Min       -93.714
trainer/Q2 Predictions Mean      -26.7595
trainer/Q2 Predictions Std        18.1128
trainer/Q2 Predictions Max       -16.4721
trainer/Q2 Predictions Min       -93.9611
trainer/Q Targets Mean           -27.1613
trainer/Q Targets Std             18.1762
trainer/Q Targets Max            -16.8783
trainer/Q Targets Min            -94.0992
trainer/Log Pis Mean               0.707656
trainer/Log Pis Std                1.68875
trainer/Log Pis Max                5.5812
trainer/Log Pis Min               -2.00913
trainer/Policy mu Mean             0.035701
trainer/Policy mu Std              1.01458
trainer/Policy mu Max              2.57042
trainer/Policy mu Min             -2.67083
trainer/Policy log std Mean       -0.9087
trainer/Policy log std Std         0.175921
trainer/Policy log std Max        -0.468701
trainer/Policy log std Min        -1.22285
trainer/Alpha                      0.199274
trainer/Alpha Loss                -2.08429
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.586592
exploration/Rewards Std            0.812292
exploration/Rewards Max           -0.0243979
exploration/Rewards Min           -8.52605
exploration/Returns Mean         -58.6592
exploration/Returns Std           14.6767
exploration/Returns Max          -40.8912
exploration/Returns Min          -82.7312
exploration/Actions Mean          -0.00407715
exploration/Actions Std            0.411924
exploration/Actions Max            0.986883
exploration/Actions Min           -0.997155
exploration/Num Paths              5
exploration/Average Returns      -58.6592
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.349589
evaluation/Rewards Std             1.19624
evaluation/Rewards Max            -0.0611302
evaluation/Rewards Min           -10.6464
evaluation/Returns Mean          -34.9589
evaluation/Returns Std            18.1912
evaluation/Returns Max            -6.90099
evaluation/Returns Min           -65.0083
evaluation/Actions Mean           -0.00179462
evaluation/Actions Std             0.19843
evaluation/Actions Max             0.979489
evaluation/Actions Min            -0.986071
evaluation/Num Paths              15
evaluation/Average Returns       -34.9589
time/data storing (s)              0.00345721
time/evaluation sampling (s)       0.415517
time/exploration sampling (s)      0.163889
time/logging (s)                   0.00538879
time/saving (s)                    0.00206946
time/training (s)                  2.14936
time/epoch (s)                     2.73968
time/total (s)                    35.7386
Epoch                             12
-----------------------------  --------------
2019-04-22 21:22:29.759679 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   0.374427
trainer/QF2 Loss                   0.406712
trainer/Policy Loss               23.1922
trainer/Q1 Predictions Mean      -23.6955
trainer/Q1 Predictions Std        12.9718
trainer/Q1 Predictions Max       -16.8812
trainer/Q1 Predictions Min       -84.1583
trainer/Q2 Predictions Mean      -23.7533
trainer/Q2 Predictions Std        12.9539
trainer/Q2 Predictions Max       -16.9803
trainer/Q2 Predictions Min       -84.9905
trainer/Q Targets Mean           -24.0116
trainer/Q Targets Std             13.1318
trainer/Q Targets Max            -16.9588
trainer/Q Targets Min            -84.9869
trainer/Log Pis Mean               0.520208
trainer/Log Pis Std                1.68424
trainer/Log Pis Max                6.29154
trainer/Log Pis Min               -4.59248
trainer/Policy mu Mean            -0.0167904
trainer/Policy mu Std              0.877248
trainer/Policy mu Max              2.58897
trainer/Policy mu Min             -2.58943
trainer/Policy log std Mean       -1.01245
trainer/Policy log std Std         0.170161
trainer/Policy log std Max        -0.56629
trainer/Policy log std Min        -1.31609
trainer/Alpha                      0.174895
trainer/Alpha Loss                -2.57977
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.581083
exploration/Rewards Std            0.879702
exploration/Rewards Max           -0.00328485
exploration/Rewards Min           -9.05313
exploration/Returns Mean         -58.1083
exploration/Returns Std           13.1436
exploration/Returns Max          -47.1003
exploration/Returns Min          -82.1171
exploration/Actions Mean           0.0171917
exploration/Actions Std            0.395914
exploration/Actions Max            0.994985
exploration/Actions Min           -0.982108
exploration/Num Paths              5
exploration/Average Returns      -58.1083
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.345696
evaluation/Rewards Std             0.955303
evaluation/Rewards Max            -0.0676823
evaluation/Rewards Min            -9.95631
evaluation/Returns Mean          -34.5696
evaluation/Returns Std            12.9342
evaluation/Returns Max           -20.0406
evaluation/Returns Min           -66.3381
evaluation/Actions Mean           -0.00857639
evaluation/Actions Std             0.200439
evaluation/Actions Max             0.986827
evaluation/Actions Min            -0.990873
evaluation/Num Paths              15
evaluation/Average Returns       -34.5696
time/data storing (s)              0.00302414
time/evaluation sampling (s)       0.356282
time/exploration sampling (s)      0.162373
time/logging (s)                   0.00473978
time/saving (s)                    0.00219018
time/training (s)                  2.13661
time/epoch (s)                     2.66521
time/total (s)                    38.4089
Epoch                             13
-----------------------------  --------------
2019-04-22 21:22:32.489568 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                   8.98783
trainer/QF2 Loss                   8.91406
trainer/Policy Loss               22.8338
trainer/Q1 Predictions Mean      -23.3325
trainer/Q1 Predictions Std        11.6552
trainer/Q1 Predictions Max       -17.2773
trainer/Q1 Predictions Min       -75.733
trainer/Q2 Predictions Mean      -23.3108
trainer/Q2 Predictions Std        11.6044
trainer/Q2 Predictions Max       -17.2526
trainer/Q2 Predictions Min       -75.4867
trainer/Q Targets Mean           -22.9801
trainer/Q Targets Std             12.1216
trainer/Q Targets Max             -0.300645
trainer/Q Targets Min            -77.3261
trainer/Log Pis Mean               0.357891
trainer/Log Pis Std                1.57821
trainer/Log Pis Max                6.45649
trainer/Log Pis Min               -2.83597
trainer/Policy mu Mean             0.109691
trainer/Policy mu Std              0.852413
trainer/Policy mu Max              2.56115
trainer/Policy mu Min             -2.53618
trainer/Policy log std Mean       -1.11013
trainer/Policy log std Std         0.20936
trainer/Policy log std Max        -0.499113
trainer/Policy log std Min        -1.46776
trainer/Alpha                      0.154153
trainer/Alpha Loss                -3.07
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.61324
exploration/Rewards Std            1.14047
exploration/Rewards Max           -0.0140003
exploration/Rewards Min           -9.58679
exploration/Returns Mean         -61.324
exploration/Returns Std           17.6445
exploration/Returns Max          -44.0068
exploration/Returns Min          -88.0288
exploration/Actions Mean          -0.00704832
exploration/Actions Std            0.393745
exploration/Actions Max            0.996052
exploration/Actions Min           -0.997139
exploration/Num Paths              5
exploration/Average Returns      -61.324
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.387855
evaluation/Rewards Std             1.13924
evaluation/Rewards Max            -0.0751561
evaluation/Rewards Min           -10.3065
evaluation/Returns Mean          -38.7855
evaluation/Returns Std            21.0102
evaluation/Returns Max            -9.61335
evaluation/Returns Min           -77.1631
evaluation/Actions Mean            0.0024711
evaluation/Actions Std             0.194812
evaluation/Actions Max             0.989807
evaluation/Actions Min            -0.993071
evaluation/Num Paths              15
evaluation/Average Returns       -38.7855
time/data storing (s)              0.0034606
time/evaluation sampling (s)       0.364631
time/exploration sampling (s)      0.160854
time/logging (s)                   0.00469271
time/saving (s)                    0.00198349
time/training (s)                  2.18825
time/epoch (s)                     2.72387
time/total (s)                    41.1374
Epoch                             14
-----------------------------  --------------
2019-04-22 21:22:35.161889 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   3.48102
trainer/QF2 Loss                   3.41158
trainer/Policy Loss               24.1133
trainer/Q1 Predictions Mean      -24.6472
trainer/Q1 Predictions Std        12.783
trainer/Q1 Predictions Max       -17.2082
trainer/Q1 Predictions Min       -81.9904
trainer/Q2 Predictions Mean      -24.6413
trainer/Q2 Predictions Std        12.8337
trainer/Q2 Predictions Max       -17.1305
trainer/Q2 Predictions Min       -82.6047
trainer/Q Targets Mean           -24.6971
trainer/Q Targets Std             12.8839
trainer/Q Targets Max             -0.826856
trainer/Q Targets Min            -83.3448
trainer/Log Pis Mean               0.737683
trainer/Log Pis Std                1.77053
trainer/Log Pis Max                6.20233
trainer/Log Pis Min               -4.55988
trainer/Policy mu Mean             0.129654
trainer/Policy mu Std              0.989511
trainer/Policy mu Max              2.7605
trainer/Policy mu Min             -2.67396
trainer/Policy log std Mean       -1.11278
trainer/Policy log std Std         0.242156
trainer/Policy log std Max        -0.554179
trainer/Policy log std Min        -1.51166
trainer/Alpha                      0.136321
trainer/Alpha Loss                -2.51515
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.518858
exploration/Rewards Std            0.835974
exploration/Rewards Max           -0.0139217
exploration/Rewards Min           -8.95379
exploration/Returns Mean         -51.8858
exploration/Returns Std           16.2621
exploration/Returns Max          -34.2799
exploration/Returns Min          -78.6437
exploration/Actions Mean          -0.00714591
exploration/Actions Std            0.400285
exploration/Actions Max            0.98414
exploration/Actions Min           -0.999119
exploration/Num Paths              5
exploration/Average Returns      -51.8858
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.272649
evaluation/Rewards Std             1.01824
evaluation/Rewards Max            -0.0146848
evaluation/Rewards Min           -11.0839
evaluation/Returns Mean          -27.2649
evaluation/Returns Std            15.8757
evaluation/Returns Max           -13.4229
evaluation/Returns Min           -60.5517
evaluation/Actions Mean            0.0131563
evaluation/Actions Std             0.179519
evaluation/Actions Max             0.990361
evaluation/Actions Min            -0.989536
evaluation/Num Paths              15
evaluation/Average Returns       -27.2649
time/data storing (s)              0.00295342
time/evaluation sampling (s)       0.359234
time/exploration sampling (s)      0.15884
time/logging (s)                   0.00583
time/saving (s)                    0.00167374
time/training (s)                  2.13892
time/epoch (s)                     2.66745
time/total (s)                    43.8099
Epoch                             15
-----------------------------  --------------
2019-04-22 21:22:37.913014 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              8700
trainer/QF1 Loss                   3.15321
trainer/QF2 Loss                   3.06872
trainer/Policy Loss               23.4912
trainer/Q1 Predictions Mean      -23.5498
trainer/Q1 Predictions Std        13.4301
trainer/Q1 Predictions Max       -17.2183
trainer/Q1 Predictions Min       -86.7235
trainer/Q2 Predictions Mean      -23.5122
trainer/Q2 Predictions Std        13.3952
trainer/Q2 Predictions Max       -17.1812
trainer/Q2 Predictions Min       -86.2807
trainer/Q Targets Mean           -23.3742
trainer/Q Targets Std             13.3779
trainer/Q Targets Max             -1.14003
trainer/Q Targets Min            -84.812
trainer/Log Pis Mean               0.834686
trainer/Log Pis Std                1.84934
trainer/Log Pis Max                6.69751
trainer/Log Pis Min               -4.28361
trainer/Policy mu Mean            -0.071864
trainer/Policy mu Std              0.90894
trainer/Policy mu Max              2.66143
trainer/Policy mu Min             -2.84247
trainer/Policy log std Mean       -1.20782
trainer/Policy log std Std         0.270925
trainer/Policy log std Max        -0.492201
trainer/Policy log std Min        -1.58644
trainer/Alpha                      0.12086
trainer/Alpha Loss                -2.46216
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.436089
exploration/Rewards Std            0.637508
exploration/Rewards Max           -0.00897823
exploration/Rewards Min           -6.64054
exploration/Returns Mean         -43.6089
exploration/Returns Std            6.30165
exploration/Returns Max          -37.6821
exploration/Returns Min          -55.1241
exploration/Actions Mean          -0.00274592
exploration/Actions Std            0.345423
exploration/Actions Max            0.994626
exploration/Actions Min           -0.996882
exploration/Num Paths              5
exploration/Average Returns      -43.6089
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.320453
evaluation/Rewards Std             0.904433
evaluation/Rewards Max            -0.100764
evaluation/Rewards Min            -8.46916
evaluation/Returns Mean          -32.0453
evaluation/Returns Std            11.9388
evaluation/Returns Max           -14.5082
evaluation/Returns Min           -53.7861
evaluation/Actions Mean            0.00803927
evaluation/Actions Std             0.187969
evaluation/Actions Max             0.98701
evaluation/Actions Min            -0.993122
evaluation/Num Paths              15
evaluation/Average Returns       -32.0453
time/data storing (s)              0.00301342
time/evaluation sampling (s)       0.357735
time/exploration sampling (s)      0.157522
time/logging (s)                   0.00515494
time/saving (s)                    0.0022172
time/training (s)                  2.21871
time/epoch (s)                     2.74435
time/total (s)                    46.5592
Epoch                             16
-----------------------------  --------------
2019-04-22 21:22:40.592098 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   0.215949
trainer/QF2 Loss                   0.140156
trainer/Policy Loss               22.1507
trainer/Q1 Predictions Mean      -21.972
trainer/Q1 Predictions Std         9.45641
trainer/Q1 Predictions Max       -16.6985
trainer/Q1 Predictions Min       -73.046
trainer/Q2 Predictions Mean      -21.9809
trainer/Q2 Predictions Std         9.43448
trainer/Q2 Predictions Max       -16.8978
trainer/Q2 Predictions Min       -73.1823
trainer/Q Targets Mean           -22.1269
trainer/Q Targets Std              9.41035
trainer/Q Targets Max            -16.9611
trainer/Q Targets Min            -73.4215
trainer/Log Pis Mean               0.857505
trainer/Log Pis Std                1.54882
trainer/Log Pis Max                5.43609
trainer/Log Pis Min               -2.96115
trainer/Policy mu Mean             0.0636815
trainer/Policy mu Std              0.870715
trainer/Policy mu Max              2.77969
trainer/Policy mu Min             -2.74983
trainer/Policy log std Mean       -1.28313
trainer/Policy log std Std         0.276363
trainer/Policy log std Max        -0.462422
trainer/Policy log std Min        -1.76939
trainer/Alpha                      0.107467
trainer/Alpha Loss                -2.54814
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.417921
exploration/Rewards Std            0.791096
exploration/Rewards Max           -0.00837588
exploration/Rewards Min           -7.65831
exploration/Returns Mean         -41.7921
exploration/Returns Std           14.1834
exploration/Returns Max          -25.2821
exploration/Returns Min          -59.0185
exploration/Actions Mean           0.0083731
exploration/Actions Std            0.322952
exploration/Actions Max            0.994356
exploration/Actions Min           -0.994526
exploration/Num Paths              5
exploration/Average Returns      -41.7921
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.33832
evaluation/Rewards Std             1.0641
evaluation/Rewards Max            -0.0364943
evaluation/Rewards Min           -10.2561
evaluation/Returns Mean          -33.832
evaluation/Returns Std            19.3255
evaluation/Returns Max            -7.96348
evaluation/Returns Min           -76.124
evaluation/Actions Mean           -0.00284484
evaluation/Actions Std             0.195134
evaluation/Actions Max             0.990614
evaluation/Actions Min            -0.994385
evaluation/Num Paths              15
evaluation/Average Returns       -33.832
time/data storing (s)              0.00331961
time/evaluation sampling (s)       0.357635
time/exploration sampling (s)      0.157097
time/logging (s)                   0.00531876
time/saving (s)                    0.00209222
time/training (s)                  2.14799
time/epoch (s)                     2.67345
time/total (s)                    49.2374
Epoch                             17
-----------------------------  --------------
2019-04-22 21:22:43.354517 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                   3.39275
trainer/QF2 Loss                   3.46454
trainer/Policy Loss               22.8341
trainer/Q1 Predictions Mean      -22.773
trainer/Q1 Predictions Std        10.6479
trainer/Q1 Predictions Max       -17.0239
trainer/Q1 Predictions Min       -64.8782
trainer/Q2 Predictions Mean      -22.7012
trainer/Q2 Predictions Std        10.6026
trainer/Q2 Predictions Max       -16.9362
trainer/Q2 Predictions Min       -64.4868
trainer/Q Targets Mean           -22.6306
trainer/Q Targets Std             10.9734
trainer/Q Targets Max             -2.27162
trainer/Q Targets Min            -66.138
trainer/Log Pis Mean               1.01566
trainer/Log Pis Std                1.88109
trainer/Log Pis Max                6.98201
trainer/Log Pis Min               -5.12559
trainer/Policy mu Mean             0.131387
trainer/Policy mu Std              0.915795
trainer/Policy mu Max              2.7656
trainer/Policy mu Min             -2.75718
trainer/Policy log std Mean       -1.35622
trainer/Policy log std Std         0.319064
trainer/Policy log std Max        -0.374431
trainer/Policy log std Min        -1.8233
trainer/Alpha                      0.0957078
trainer/Alpha Loss                -2.30947
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.517669
exploration/Rewards Std            1.25556
exploration/Rewards Max           -0.0098223
exploration/Rewards Min           -9.55924
exploration/Returns Mean         -51.7669
exploration/Returns Std           16.5625
exploration/Returns Max          -26.5286
exploration/Returns Min          -70.6177
exploration/Actions Mean           0.0481661
exploration/Actions Std            0.313255
exploration/Actions Max            0.997847
exploration/Actions Min           -0.976389
exploration/Num Paths              5
exploration/Average Returns      -51.7669
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.280811
evaluation/Rewards Std             1.04465
evaluation/Rewards Max            -0.0360531
evaluation/Rewards Min            -9.70315
evaluation/Returns Mean          -28.0811
evaluation/Returns Std            16.2295
evaluation/Returns Max            -6.91398
evaluation/Returns Min           -54.8601
evaluation/Actions Mean           -0.00231761
evaluation/Actions Std             0.195137
evaluation/Actions Max             0.992123
evaluation/Actions Min            -0.990022
evaluation/Num Paths              15
evaluation/Average Returns       -28.0811
time/data storing (s)              0.00352198
time/evaluation sampling (s)       0.373086
time/exploration sampling (s)      0.165559
time/logging (s)                   0.00522375
time/saving (s)                    0.00218295
time/training (s)                  2.2069
time/epoch (s)                     2.75648
time/total (s)                    51.9986
Epoch                             18
-----------------------------  --------------
2019-04-22 21:22:46.041772 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   4.36473
trainer/QF2 Loss                   4.26646
trainer/Policy Loss               22.1998
trainer/Q1 Predictions Mean      -21.7544
trainer/Q1 Predictions Std        10.3117
trainer/Q1 Predictions Max       -16.3221
trainer/Q1 Predictions Min       -83.6205
trainer/Q2 Predictions Mean      -21.7286
trainer/Q2 Predictions Std        10.3816
trainer/Q2 Predictions Max       -16.3764
trainer/Q2 Predictions Min       -84.1696
trainer/Q Targets Mean           -21.7734
trainer/Q Targets Std             10.6877
trainer/Q Targets Max             -1.08348
trainer/Q Targets Min            -84.1086
trainer/Log Pis Mean               1.45673
trainer/Log Pis Std                1.5987
trainer/Log Pis Max                7.90112
trainer/Log Pis Min               -2.67651
trainer/Policy mu Mean             0.0599038
trainer/Policy mu Std              0.907742
trainer/Policy mu Max              2.91378
trainer/Policy mu Min             -2.77335
trainer/Policy log std Mean       -1.44367
trainer/Policy log std Std         0.306932
trainer/Policy log std Max        -0.537009
trainer/Policy log std Min        -1.86406
trainer/Alpha                      0.0861533
trainer/Alpha Loss                -1.33179
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.511652
exploration/Rewards Std            1.20662
exploration/Rewards Max           -0.0162144
exploration/Rewards Min          -10.1513
exploration/Returns Mean         -51.1652
exploration/Returns Std           20.1888
exploration/Returns Max          -31.3944
exploration/Returns Min          -84.8948
exploration/Actions Mean           0.0181808
exploration/Actions Std            0.313178
exploration/Actions Max            0.998363
exploration/Actions Min           -0.998826
exploration/Num Paths              5
exploration/Average Returns      -51.1652
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.313978
evaluation/Rewards Std             1.05131
evaluation/Rewards Max            -0.0279967
evaluation/Rewards Min           -10.9035
evaluation/Returns Mean          -31.3978
evaluation/Returns Std            17.7622
evaluation/Returns Max           -12.6121
evaluation/Returns Min           -67.6898
evaluation/Actions Mean            0.0184935
evaluation/Actions Std             0.193292
evaluation/Actions Max             0.994883
evaluation/Actions Min            -0.99341
evaluation/Num Paths              15
evaluation/Average Returns       -31.3978
time/data storing (s)              0.00308978
time/evaluation sampling (s)       0.365321
time/exploration sampling (s)      0.161689
time/logging (s)                   0.00531116
time/saving (s)                    0.00206723
time/training (s)                  2.14383
time/epoch (s)                     2.68131
time/total (s)                    54.6849
Epoch                             19
-----------------------------  --------------
2019-04-22 21:22:48.764223 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                   5.29092
trainer/QF2 Loss                   5.31427
trainer/Policy Loss               21.7453
trainer/Q1 Predictions Mean      -21.1186
trainer/Q1 Predictions Std        10.701
trainer/Q1 Predictions Max       -15.88
trainer/Q1 Predictions Min       -80.6725
trainer/Q2 Predictions Mean      -21.1398
trainer/Q2 Predictions Std        10.693
trainer/Q2 Predictions Max       -15.9478
trainer/Q2 Predictions Min       -81.5811
trainer/Q Targets Mean           -21.1187
trainer/Q Targets Std             11.059
trainer/Q Targets Max             -0.189976
trainer/Q Targets Min            -80.6273
trainer/Log Pis Mean               1.38358
trainer/Log Pis Std                1.76808
trainer/Log Pis Max                8.17749
trainer/Log Pis Min               -6.40077
trainer/Policy mu Mean             0.127461
trainer/Policy mu Std              0.928331
trainer/Policy mu Max              2.93862
trainer/Policy mu Min             -2.73475
trainer/Policy log std Mean       -1.54275
trainer/Policy log std Std         0.310778
trainer/Policy log std Max        -0.562777
trainer/Policy log std Min        -1.98899
trainer/Alpha                      0.0782028
trainer/Alpha Loss                -1.5708
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.592182
exploration/Rewards Std            1.44392
exploration/Rewards Max           -0.0184821
exploration/Rewards Min          -11.1671
exploration/Returns Mean         -59.2182
exploration/Returns Std           19.084
exploration/Returns Max          -35.8451
exploration/Returns Min          -82.6729
exploration/Actions Mean           0.00894397
exploration/Actions Std            0.327174
exploration/Actions Max            0.997102
exploration/Actions Min           -0.99659
exploration/Num Paths              5
exploration/Average Returns      -59.2182
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.255542
evaluation/Rewards Std             0.981671
evaluation/Rewards Max            -0.00746195
evaluation/Rewards Min           -10.1414
evaluation/Returns Mean          -25.5542
evaluation/Returns Std            17.881
evaluation/Returns Max            -5.1104
evaluation/Returns Min           -70.8449
evaluation/Actions Mean           -0.011025
evaluation/Actions Std             0.187152
evaluation/Actions Max             0.994667
evaluation/Actions Min            -0.993154
evaluation/Num Paths              15
evaluation/Average Returns       -25.5542
time/data storing (s)              0.00325194
time/evaluation sampling (s)       0.354127
time/exploration sampling (s)      0.15766
time/logging (s)                   0.00562181
time/saving (s)                    0.00227827
time/training (s)                  2.19388
time/epoch (s)                     2.71682
time/total (s)                    57.4065
Epoch                             20
-----------------------------  --------------
2019-04-22 21:22:51.441803 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   0.213595
trainer/QF2 Loss                   0.244024
trainer/Policy Loss               21.3908
trainer/Q1 Predictions Mean      -20.8173
trainer/Q1 Predictions Std        11.0395
trainer/Q1 Predictions Max       -16.1785
trainer/Q1 Predictions Min       -83.5526
trainer/Q2 Predictions Mean      -20.7605
trainer/Q2 Predictions Std        11.1245
trainer/Q2 Predictions Max       -16.057
trainer/Q2 Predictions Min       -84.5654
trainer/Q Targets Mean           -20.8668
trainer/Q Targets Std             11.0651
trainer/Q Targets Max            -15.919
trainer/Q Targets Min            -81.5499
trainer/Log Pis Mean               1.41535
trainer/Log Pis Std                1.94169
trainer/Log Pis Max                7.81192
trainer/Log Pis Min               -7.62244
trainer/Policy mu Mean             0.0658681
trainer/Policy mu Std              0.898899
trainer/Policy mu Max              3.03053
trainer/Policy mu Min             -2.85033
trainer/Policy log std Mean       -1.60335
trainer/Policy log std Std         0.321004
trainer/Policy log std Max        -0.358677
trainer/Policy log std Min        -1.9131
trainer/Alpha                      0.0712252
trainer/Alpha Loss                -1.54451
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.398165
exploration/Rewards Std            0.882461
exploration/Rewards Max           -0.0155161
exploration/Rewards Min           -8.14514
exploration/Returns Mean         -39.8165
exploration/Returns Std           12.5593
exploration/Returns Max          -25.1158
exploration/Returns Min          -58.2793
exploration/Actions Mean           0.0204395
exploration/Actions Std            0.288092
exploration/Actions Max            0.997801
exploration/Actions Min           -0.985445
exploration/Num Paths              5
exploration/Average Returns      -39.8165
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.246495
evaluation/Rewards Std             0.827698
evaluation/Rewards Max            -0.0256368
evaluation/Rewards Min           -10.0073
evaluation/Returns Mean          -24.6495
evaluation/Returns Std            15.5402
evaluation/Returns Max            -4.21127
evaluation/Returns Min           -58.8532
evaluation/Actions Mean            0.00603608
evaluation/Actions Std             0.175959
evaluation/Actions Max             0.993925
evaluation/Actions Min            -0.995239
evaluation/Num Paths              15
evaluation/Average Returns       -24.6495
time/data storing (s)              0.00329218
time/evaluation sampling (s)       0.364268
time/exploration sampling (s)      0.162287
time/logging (s)                   0.00532345
time/saving (s)                    0.00237279
time/training (s)                  2.13382
time/epoch (s)                     2.67136
time/total (s)                    60.0826
Epoch                             21
-----------------------------  --------------
2019-04-22 21:22:54.125213 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                   0.25758
trainer/QF2 Loss                   0.20019
trainer/Policy Loss               22.2174
trainer/Q1 Predictions Mean      -21.3375
trainer/Q1 Predictions Std        10.5361
trainer/Q1 Predictions Max       -15.2623
trainer/Q1 Predictions Min       -82.2147
trainer/Q2 Predictions Mean      -21.3542
trainer/Q2 Predictions Std        10.5384
trainer/Q2 Predictions Max       -15.3766
trainer/Q2 Predictions Min       -83.069
trainer/Q Targets Mean           -21.4945
trainer/Q Targets Std             10.3376
trainer/Q Targets Max            -15.7249
trainer/Q Targets Min            -82.9459
trainer/Log Pis Mean               1.70689
trainer/Log Pis Std                1.73908
trainer/Log Pis Max                8.66324
trainer/Log Pis Min               -2.40949
trainer/Policy mu Mean             0.0639253
trainer/Policy mu Std              0.998848
trainer/Policy mu Max              3.12984
trainer/Policy mu Min             -2.98215
trainer/Policy log std Mean       -1.61817
trainer/Policy log std Std         0.370556
trainer/Policy log std Max        -0.5101
trainer/Policy log std Min        -2.04791
trainer/Alpha                      0.0656191
trainer/Alpha Loss                -0.798337
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.368446
exploration/Rewards Std            0.845334
exploration/Rewards Max           -0.00156886
exploration/Rewards Min           -7.83663
exploration/Returns Mean         -36.8446
exploration/Returns Std            8.59055
exploration/Returns Max          -26.7848
exploration/Returns Min          -49.0929
exploration/Actions Mean           0.017967
exploration/Actions Std            0.280956
exploration/Actions Max            0.998586
exploration/Actions Min           -0.987988
exploration/Num Paths              5
exploration/Average Returns      -36.8446
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.1906
evaluation/Rewards Std             0.661408
evaluation/Rewards Max            -0.0440349
evaluation/Rewards Min            -7.49886
evaluation/Returns Mean          -19.06
evaluation/Returns Std             6.73581
evaluation/Returns Max            -6.82017
evaluation/Returns Min           -34.7965
evaluation/Actions Mean           -0.00728013
evaluation/Actions Std             0.183252
evaluation/Actions Max             0.991051
evaluation/Actions Min            -0.993754
evaluation/Num Paths              15
evaluation/Average Returns       -19.06
time/data storing (s)              0.00314007
time/evaluation sampling (s)       0.363213
time/exploration sampling (s)      0.159916
time/logging (s)                   0.0053009
time/saving (s)                    0.00221555
time/training (s)                  2.14405
time/epoch (s)                     2.67783
time/total (s)                    62.7649
Epoch                             22
-----------------------------  --------------
2019-04-22 21:22:56.867978 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   0.394656
trainer/QF2 Loss                   0.474608
trainer/Policy Loss               23.4696
trainer/Q1 Predictions Mean      -22.6996
trainer/Q1 Predictions Std        16.0578
trainer/Q1 Predictions Max       -15.4375
trainer/Q1 Predictions Min       -90.9368
trainer/Q2 Predictions Mean      -22.7218
trainer/Q2 Predictions Std        16.1261
trainer/Q2 Predictions Max       -15.4722
trainer/Q2 Predictions Min       -91.9131
trainer/Q Targets Mean           -22.7727
trainer/Q Targets Std             16.1156
trainer/Q Targets Max            -15.4195
trainer/Q Targets Min            -90.018
trainer/Log Pis Mean               1.80594
trainer/Log Pis Std                1.88715
trainer/Log Pis Max                7.89989
trainer/Log Pis Min               -1.9075
trainer/Policy mu Mean             0.109295
trainer/Policy mu Std              1.02019
trainer/Policy mu Max              3.21992
trainer/Policy mu Min             -3.12754
trainer/Policy log std Mean       -1.66762
trainer/Policy log std Std         0.400945
trainer/Policy log std Max        -0.491516
trainer/Policy log std Min        -2.13449
trainer/Alpha                      0.0606823
trainer/Alpha Loss                -0.543748
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.382354
exploration/Rewards Std            0.852616
exploration/Rewards Max           -0.00915793
exploration/Rewards Min           -8.49035
exploration/Returns Mean         -38.2354
exploration/Returns Std           12.9378
exploration/Returns Max          -19.2853
exploration/Returns Min          -57.5998
exploration/Actions Mean          -0.00292761
exploration/Actions Std            0.266156
exploration/Actions Max            0.997552
exploration/Actions Min           -0.998646
exploration/Num Paths              5
exploration/Average Returns      -38.2354
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.341208
evaluation/Rewards Std             1.08892
evaluation/Rewards Max            -0.0851829
evaluation/Rewards Min           -11.0035
evaluation/Returns Mean          -34.1208
evaluation/Returns Std            19.6487
evaluation/Returns Max            -9.51
evaluation/Returns Min           -72.823
evaluation/Actions Mean            0.00774738
evaluation/Actions Std             0.199197
evaluation/Actions Max             0.993972
evaluation/Actions Min            -0.998099
evaluation/Num Paths              15
evaluation/Average Returns       -34.1208
time/data storing (s)              0.00421032
time/evaluation sampling (s)       0.382086
time/exploration sampling (s)      0.19818
time/logging (s)                   0.00546453
time/saving (s)                    0.00201451
time/training (s)                  2.14511
time/epoch (s)                     2.73707
time/total (s)                    65.5066
Epoch                             23
-----------------------------  --------------
2019-04-22 21:22:59.523178 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 24 finished
-----------------------------  ---------------
replay_buffer/size             12700
trainer/QF1 Loss                   8.97454
trainer/QF2 Loss                   8.96157
trainer/Policy Loss               19.966
trainer/Q1 Predictions Mean      -18.8606
trainer/Q1 Predictions Std         8.31958
trainer/Q1 Predictions Max       -15.0237
trainer/Q1 Predictions Min       -74.2146
trainer/Q2 Predictions Mean      -18.8657
trainer/Q2 Predictions Std         8.218
trainer/Q2 Predictions Max       -15.1411
trainer/Q2 Predictions Min       -73.7356
trainer/Q Targets Mean           -18.5216
trainer/Q Targets Std              9.03174
trainer/Q Targets Max             -0.32154
trainer/Q Targets Min            -77.8443
trainer/Log Pis Mean               1.78831
trainer/Log Pis Std                1.48053
trainer/Log Pis Max                8.80932
trainer/Log Pis Min               -1.63923
trainer/Policy mu Mean             0.137267
trainer/Policy mu Std              0.863294
trainer/Policy mu Max              3.16726
trainer/Policy mu Min             -2.8556
trainer/Policy log std Mean       -1.76724
trainer/Policy log std Std         0.370622
trainer/Policy log std Max        -0.555064
trainer/Policy log std Min        -2.1651
trainer/Alpha                      0.057243
trainer/Alpha Loss                -0.605522
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.436422
exploration/Rewards Std            1.04087
exploration/Rewards Max           -0.00144318
exploration/Rewards Min           -9.38363
exploration/Returns Mean         -43.6422
exploration/Returns Std           15.4536
exploration/Returns Max          -21.0109
exploration/Returns Min          -66.4091
exploration/Actions Mean           0.0220963
exploration/Actions Std            0.264312
exploration/Actions Max            0.999281
exploration/Actions Min           -0.994115
exploration/Num Paths              5
exploration/Average Returns      -43.6422
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.31052
evaluation/Rewards Std             0.847746
evaluation/Rewards Max            -0.0588967
evaluation/Rewards Min           -10.3357
evaluation/Returns Mean          -31.052
evaluation/Returns Std            15.0081
evaluation/Returns Max           -15.4642
evaluation/Returns Min           -69.949
evaluation/Actions Mean           -0.000226067
evaluation/Actions Std             0.185725
evaluation/Actions Max             0.997162
evaluation/Actions Min            -0.99496
evaluation/Num Paths              15
evaluation/Average Returns       -31.052
time/data storing (s)              0.00305767
time/evaluation sampling (s)       0.357359
time/exploration sampling (s)      0.158568
time/logging (s)                   0.00529705
time/saving (s)                    0.00195463
time/training (s)                  2.12317
time/epoch (s)                     2.6494
time/total (s)                    68.1607
Epoch                             24
-----------------------------  ---------------
2019-04-22 21:23:02.250071 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   0.110534
trainer/QF2 Loss                   0.0929136
trainer/Policy Loss               20.3117
trainer/Q1 Predictions Mean      -19.3928
trainer/Q1 Predictions Std         9.68858
trainer/Q1 Predictions Max       -14.9843
trainer/Q1 Predictions Min       -83.7294
trainer/Q2 Predictions Mean      -19.3792
trainer/Q2 Predictions Std         9.77417
trainer/Q2 Predictions Max       -14.8665
trainer/Q2 Predictions Min       -84.6006
trainer/Q Targets Mean           -19.3413
trainer/Q Targets Std              9.72383
trainer/Q Targets Max            -14.7696
trainer/Q Targets Min            -84.3559
trainer/Log Pis Mean               1.82099
trainer/Log Pis Std                1.72121
trainer/Log Pis Max                8.83471
trainer/Log Pis Min               -3.83646
trainer/Policy mu Mean             0.0467616
trainer/Policy mu Std              0.910555
trainer/Policy mu Max              2.90236
trainer/Policy mu Min             -3.0962
trainer/Policy log std Mean       -1.78669
trainer/Policy log std Std         0.419556
trainer/Policy log std Max        -0.418099
trainer/Policy log std Min        -2.23874
trainer/Alpha                      0.0543823
trainer/Alpha Loss                -0.521229
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.305957
exploration/Rewards Std            0.546859
exploration/Rewards Max           -0.0222845
exploration/Rewards Min           -7.27172
exploration/Returns Mean         -30.5957
exploration/Returns Std            7.73715
exploration/Returns Max          -16.4522
exploration/Returns Min          -39.9797
exploration/Actions Mean          -0.0028394
exploration/Actions Std            0.264138
exploration/Actions Max            0.99647
exploration/Actions Min           -0.99683
exploration/Num Paths              5
exploration/Average Returns      -30.5957
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.321978
evaluation/Rewards Std             0.952447
evaluation/Rewards Max            -0.0277623
evaluation/Rewards Min            -9.78967
evaluation/Returns Mean          -32.1978
evaluation/Returns Std            15.1726
evaluation/Returns Max           -10.6069
evaluation/Returns Min           -61.4133
evaluation/Actions Mean            0.00435198
evaluation/Actions Std             0.189172
evaluation/Actions Max             0.996798
evaluation/Actions Min            -0.996899
evaluation/Num Paths              15
evaluation/Average Returns       -32.1978
time/data storing (s)              0.00301599
time/evaluation sampling (s)       0.353663
time/exploration sampling (s)      0.162772
time/logging (s)                   0.00527016
time/saving (s)                    0.0022869
time/training (s)                  2.19383
time/epoch (s)                     2.72084
time/total (s)                    70.8861
Epoch                             25
-----------------------------  --------------
2019-04-22 21:23:04.897150 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                   5.3014
trainer/QF2 Loss                   5.24571
trainer/Policy Loss               20.5276
trainer/Q1 Predictions Mean      -19.4089
trainer/Q1 Predictions Std        10.7603
trainer/Q1 Predictions Max       -14.4925
trainer/Q1 Predictions Min       -78.5401
trainer/Q2 Predictions Mean      -19.4247
trainer/Q2 Predictions Std        10.8041
trainer/Q2 Predictions Max       -14.4609
trainer/Q2 Predictions Min       -79.5989
trainer/Q Targets Mean           -19.1964
trainer/Q Targets Std             10.9633
trainer/Q Targets Max             -0.493289
trainer/Q Targets Min            -78.8662
trainer/Log Pis Mean               1.94722
trainer/Log Pis Std                1.52416
trainer/Log Pis Max                7.69986
trainer/Log Pis Min               -1.48794
trainer/Policy mu Mean             0.0678587
trainer/Policy mu Std              0.927419
trainer/Policy mu Max              3.29361
trainer/Policy mu Min             -3.10603
trainer/Policy log std Mean       -1.79829
trainer/Policy log std Std         0.416857
trainer/Policy log std Max        -0.547722
trainer/Policy log std Min        -2.20097
trainer/Alpha                      0.0513668
trainer/Alpha Loss                -0.156676
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.253846
exploration/Rewards Std            0.485514
exploration/Rewards Max           -0.00609002
exploration/Rewards Min           -5.27912
exploration/Returns Mean         -25.3846
exploration/Returns Std            6.86197
exploration/Returns Max          -18.3212
exploration/Returns Min          -37.2648
exploration/Actions Mean          -0.00206522
exploration/Actions Std            0.233887
exploration/Actions Max            0.994156
exploration/Actions Min           -0.997946
exploration/Num Paths              5
exploration/Average Returns      -25.3846
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.225285
evaluation/Rewards Std             0.986836
evaluation/Rewards Max            -0.0216546
evaluation/Rewards Min           -10.7762
evaluation/Returns Mean          -22.5285
evaluation/Returns Std            17.9338
evaluation/Returns Max            -4.03693
evaluation/Returns Min           -60.3506
evaluation/Actions Mean            0.0122577
evaluation/Actions Std             0.185406
evaluation/Actions Max             0.996137
evaluation/Actions Min            -0.996273
evaluation/Num Paths              15
evaluation/Average Returns       -22.5285
time/data storing (s)              0.00308476
time/evaluation sampling (s)       0.357725
time/exploration sampling (s)      0.162829
time/logging (s)                   0.00545257
time/saving (s)                    0.00212567
time/training (s)                  2.11002
time/epoch (s)                     2.64124
time/total (s)                    73.5321
Epoch                             26
-----------------------------  --------------
2019-04-22 21:23:07.600749 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 27 finished
-----------------------------  ---------------
replay_buffer/size             14200
trainer/QF1 Loss                   3.05587
trainer/QF2 Loss                   2.98873
trainer/Policy Loss               19.2687
trainer/Q1 Predictions Mean      -17.8731
trainer/Q1 Predictions Std         7.43448
trainer/Q1 Predictions Max       -14.2901
trainer/Q1 Predictions Min       -72.2381
trainer/Q2 Predictions Mean      -17.8638
trainer/Q2 Predictions Std         7.40128
trainer/Q2 Predictions Max       -14.2784
trainer/Q2 Predictions Min       -71.8988
trainer/Q Targets Mean           -17.7493
trainer/Q Targets Std              7.63099
trainer/Q Targets Max             -0.375542
trainer/Q Targets Min            -71.6826
trainer/Log Pis Mean               2.0103
trainer/Log Pis Std                1.23268
trainer/Log Pis Max                7.99228
trainer/Log Pis Min               -1.70932
trainer/Policy mu Mean             0.0380168
trainer/Policy mu Std              0.825672
trainer/Policy mu Max              3.09852
trainer/Policy mu Min             -2.95696
trainer/Policy log std Mean       -1.8749
trainer/Policy log std Std         0.356361
trainer/Policy log std Max        -0.580244
trainer/Policy log std Min        -2.23627
trainer/Alpha                      0.0502295
trainer/Alpha Loss                 0.0308115
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.321643
exploration/Rewards Std            0.931338
exploration/Rewards Max           -0.00594532
exploration/Rewards Min          -10.0239
exploration/Returns Mean         -32.1643
exploration/Returns Std           20.0447
exploration/Returns Max          -16.9774
exploration/Returns Min          -71.0499
exploration/Actions Mean          -0.00645827
exploration/Actions Std            0.239227
exploration/Actions Max            0.998402
exploration/Actions Min           -0.998496
exploration/Num Paths              5
exploration/Average Returns      -32.1643
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.226406
evaluation/Rewards Std             0.888874
evaluation/Rewards Max            -0.0595057
evaluation/Rewards Min           -10.7124
evaluation/Returns Mean          -22.6406
evaluation/Returns Std            16.323
evaluation/Returns Max            -6.63058
evaluation/Returns Min           -63.8743
evaluation/Actions Mean           -0.000998983
evaluation/Actions Std             0.188588
evaluation/Actions Max             0.996738
evaluation/Actions Min            -0.998278
evaluation/Num Paths              15
evaluation/Average Returns       -22.6406
time/data storing (s)              0.00318411
time/evaluation sampling (s)       0.363584
time/exploration sampling (s)      0.157086
time/logging (s)                   0.00557338
time/saving (s)                    0.0020335
time/training (s)                  2.16654
time/epoch (s)                     2.698
time/total (s)                    76.2348
Epoch                             27
-----------------------------  ---------------
2019-04-22 21:23:10.252325 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             14700
trainer/QF1 Loss                   0.259966
trainer/QF2 Loss                   0.223496
trainer/Policy Loss               20.1323
trainer/Q1 Predictions Mean      -19.1045
trainer/Q1 Predictions Std        11.2402
trainer/Q1 Predictions Max       -13.9929
trainer/Q1 Predictions Min       -77.0603
trainer/Q2 Predictions Mean      -19.0305
trainer/Q2 Predictions Std        11.268
trainer/Q2 Predictions Max       -13.9148
trainer/Q2 Predictions Min       -77.8042
trainer/Q Targets Mean           -19.1704
trainer/Q Targets Std             11.3792
trainer/Q Targets Max            -13.9455
trainer/Q Targets Min            -78.6943
trainer/Log Pis Mean               2.00289
trainer/Log Pis Std                2.00076
trainer/Log Pis Max                8.8344
trainer/Log Pis Min               -1.90589
trainer/Policy mu Mean            -0.0663347
trainer/Policy mu Std              0.986157
trainer/Policy mu Max              3.29606
trainer/Policy mu Min             -3.28111
trainer/Policy log std Mean       -1.86494
trainer/Policy log std Std         0.435846
trainer/Policy log std Max        -0.516184
trainer/Policy log std Min        -2.28391
trainer/Alpha                      0.050313
trainer/Alpha Loss                 0.00862812
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.304418
exploration/Rewards Std            0.707585
exploration/Rewards Max           -0.00872298
exploration/Rewards Min           -6.81517
exploration/Returns Mean         -30.4418
exploration/Returns Std            9.69133
exploration/Returns Max          -17.6249
exploration/Returns Min          -43.0575
exploration/Actions Mean           0.00262364
exploration/Actions Std            0.243994
exploration/Actions Max            0.997447
exploration/Actions Min           -0.998271
exploration/Num Paths              5
exploration/Average Returns      -30.4418
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.254232
evaluation/Rewards Std             0.830201
evaluation/Rewards Max            -0.0715899
evaluation/Rewards Min           -10.2325
evaluation/Returns Mean          -25.4232
evaluation/Returns Std            13.1707
evaluation/Returns Max            -8.92763
evaluation/Returns Min           -61.6944
evaluation/Actions Mean            0.0160703
evaluation/Actions Std             0.177951
evaluation/Actions Max             0.995042
evaluation/Actions Min            -0.997936
evaluation/Num Paths              15
evaluation/Average Returns       -25.4232
time/data storing (s)              0.00330681
time/evaluation sampling (s)       0.363651
time/exploration sampling (s)      0.161678
time/logging (s)                   0.0042587
time/saving (s)                    0.00188516
time/training (s)                  2.10899
time/epoch (s)                     2.64377
time/total (s)                    78.8839
Epoch                             28
-----------------------------  --------------
2019-04-22 21:23:12.963469 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   5.27271
trainer/QF2 Loss                   5.33972
trainer/Policy Loss               17.4659
trainer/Q1 Predictions Mean      -16.2166
trainer/Q1 Predictions Std         6.13244
trainer/Q1 Predictions Max       -13.6143
trainer/Q1 Predictions Min       -71.4599
trainer/Q2 Predictions Mean      -16.2
trainer/Q2 Predictions Std         6.17186
trainer/Q2 Predictions Max       -13.6068
trainer/Q2 Predictions Min       -71.7756
trainer/Q Targets Mean           -15.9477
trainer/Q Targets Std              6.39619
trainer/Q Targets Max             -0.243455
trainer/Q Targets Min            -70.5967
trainer/Log Pis Mean               1.61952
trainer/Log Pis Std                1.4283
trainer/Log Pis Max                6.13426
trainer/Log Pis Min               -3.51539
trainer/Policy mu Mean             0.0464454
trainer/Policy mu Std              0.669239
trainer/Policy mu Max              2.4661
trainer/Policy mu Min             -3.09938
trainer/Policy log std Mean       -1.99923
trainer/Policy log std Std         0.365593
trainer/Policy log std Max        -0.454166
trainer/Policy log std Min        -2.35369
trainer/Alpha                      0.0507254
trainer/Alpha Loss                -1.13432
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.341886
exploration/Rewards Std            0.893178
exploration/Rewards Max           -0.00474974
exploration/Rewards Min           -7.30178
exploration/Returns Mean         -34.1886
exploration/Returns Std            5.83912
exploration/Returns Max          -25.8935
exploration/Returns Min          -40.538
exploration/Actions Mean           0.0308732
exploration/Actions Std            0.248614
exploration/Actions Max            0.998561
exploration/Actions Min           -0.991082
exploration/Num Paths              5
exploration/Average Returns      -34.1886
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.273339
evaluation/Rewards Std             1.02893
evaluation/Rewards Max            -0.0145532
evaluation/Rewards Min           -11.2287
evaluation/Returns Mean          -27.3339
evaluation/Returns Std            17.1814
evaluation/Returns Max            -8.58217
evaluation/Returns Min           -66.7432
evaluation/Actions Mean            0.00247404
evaluation/Actions Std             0.199449
evaluation/Actions Max             0.996949
evaluation/Actions Min            -0.997812
evaluation/Num Paths              15
evaluation/Average Returns       -27.3339
time/data storing (s)              0.00317143
time/evaluation sampling (s)       0.359634
time/exploration sampling (s)      0.157823
time/logging (s)                   0.00531064
time/saving (s)                    0.00214271
time/training (s)                  2.17841
time/epoch (s)                     2.70649
time/total (s)                    81.5949
Epoch                             29
-----------------------------  --------------
2019-04-22 21:23:15.618901 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                   2.81002
trainer/QF2 Loss                   2.70879
trainer/Policy Loss               21.3231
trainer/Q1 Predictions Mean      -20.0228
trainer/Q1 Predictions Std        14.5497
trainer/Q1 Predictions Max       -13.3127
trainer/Q1 Predictions Min       -86.3012
trainer/Q2 Predictions Mean      -20.0469
trainer/Q2 Predictions Std        14.6126
trainer/Q2 Predictions Max       -13.2555
trainer/Q2 Predictions Min       -86.948
trainer/Q Targets Mean           -20.2688
trainer/Q Targets Std             14.8843
trainer/Q Targets Max             -0.259965
trainer/Q Targets Min            -86.509
trainer/Log Pis Mean               2.34764
trainer/Log Pis Std                2.03588
trainer/Log Pis Max               10.5328
trainer/Log Pis Min               -2.87244
trainer/Policy mu Mean             0.111711
trainer/Policy mu Std              1.10012
trainer/Policy mu Max              3.39828
trainer/Policy mu Min             -3.5007
trainer/Policy log std Mean       -1.82494
trainer/Policy log std Std         0.505111
trainer/Policy log std Max        -0.410915
trainer/Policy log std Min        -2.37467
trainer/Alpha                      0.0514037
trainer/Alpha Loss                 1.03184
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.328117
exploration/Rewards Std            0.696572
exploration/Rewards Max           -0.00782314
exploration/Rewards Min           -6.01174
exploration/Returns Mean         -32.8117
exploration/Returns Std            5.87462
exploration/Returns Max          -28.0782
exploration/Returns Min          -44.0725
exploration/Actions Mean          -0.0064504
exploration/Actions Std            0.251987
exploration/Actions Max            0.999572
exploration/Actions Min           -0.997618
exploration/Num Paths              5
exploration/Average Returns      -32.8117
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.298633
evaluation/Rewards Std             0.879479
evaluation/Rewards Max            -0.0416565
evaluation/Rewards Min            -9.3526
evaluation/Returns Mean          -29.8633
evaluation/Returns Std            14.2016
evaluation/Returns Max           -12.3352
evaluation/Returns Min           -55.9687
evaluation/Actions Mean           -0.00636977
evaluation/Actions Std             0.188713
evaluation/Actions Max             0.99537
evaluation/Actions Min            -0.997228
evaluation/Num Paths              15
evaluation/Average Returns       -29.8633
time/data storing (s)              0.00387582
time/evaluation sampling (s)       0.371448
time/exploration sampling (s)      0.161426
time/logging (s)                   0.00504001
time/saving (s)                    0.00222662
time/training (s)                  2.1052
time/epoch (s)                     2.64922
time/total (s)                    84.2489
Epoch                             30
-----------------------------  --------------
2019-04-22 21:23:18.274961 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   0.144917
trainer/QF2 Loss                   0.159155
trainer/Policy Loss               18.1171
trainer/Q1 Predictions Mean      -17.1569
trainer/Q1 Predictions Std        10.018
trainer/Q1 Predictions Max       -13.0992
trainer/Q1 Predictions Min       -80.5142
trainer/Q2 Predictions Mean      -17.1735
trainer/Q2 Predictions Std        10.0785
trainer/Q2 Predictions Max       -13.1189
trainer/Q2 Predictions Min       -81.4986
trainer/Q Targets Mean           -17.2382
trainer/Q Targets Std             10.0937
trainer/Q Targets Max            -13.1208
trainer/Q Targets Min            -79.7539
trainer/Log Pis Mean               1.78181
trainer/Log Pis Std                1.47598
trainer/Log Pis Max                6.5131
trainer/Log Pis Min               -1.77043
trainer/Policy mu Mean             0.0754726
trainer/Policy mu Std              0.85103
trainer/Policy mu Max              3.37024
trainer/Policy mu Min             -3.06935
trainer/Policy log std Mean       -1.89915
trainer/Policy log std Std         0.419958
trainer/Policy log std Max        -0.265815
trainer/Policy log std Min        -2.31634
trainer/Alpha                      0.0516649
trainer/Alpha Loss                -0.646486
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.305686
exploration/Rewards Std            0.65831
exploration/Rewards Max           -0.011883
exploration/Rewards Min           -7.82144
exploration/Returns Mean         -30.5686
exploration/Returns Std           13.8387
exploration/Returns Max          -17.144
exploration/Returns Min          -56.2574
exploration/Actions Mean          -0.00566004
exploration/Actions Std            0.233088
exploration/Actions Max            0.9914
exploration/Actions Min           -0.99225
exploration/Num Paths              5
exploration/Average Returns      -30.5686
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.326359
evaluation/Rewards Std             1.07378
evaluation/Rewards Max            -0.0501305
evaluation/Rewards Min           -10.5651
evaluation/Returns Mean          -32.6359
evaluation/Returns Std            18.7017
evaluation/Returns Max            -5.90686
evaluation/Returns Min           -73.4968
evaluation/Actions Mean           -0.00398188
evaluation/Actions Std             0.200476
evaluation/Actions Max             0.996148
evaluation/Actions Min            -0.997698
evaluation/Num Paths              15
evaluation/Average Returns       -32.6359
time/data storing (s)              0.00305509
time/evaluation sampling (s)       0.362498
time/exploration sampling (s)      0.163083
time/logging (s)                   0.00510952
time/saving (s)                    0.00200176
time/training (s)                  2.114
time/epoch (s)                     2.64975
time/total (s)                    86.9038
Epoch                             31
-----------------------------  --------------
2019-04-22 21:23:20.958840 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size             16700
trainer/QF1 Loss                   2.48661
trainer/QF2 Loss                   2.50854
trainer/Policy Loss               18.1234
trainer/Q1 Predictions Mean      -16.7349
trainer/Q1 Predictions Std         7.78982
trainer/Q1 Predictions Max       -12.9022
trainer/Q1 Predictions Min       -71.3606
trainer/Q2 Predictions Mean      -16.699
trainer/Q2 Predictions Std         7.86629
trainer/Q2 Predictions Max       -12.8314
trainer/Q2 Predictions Min       -71.9284
trainer/Q Targets Mean           -16.5465
trainer/Q Targets Std              7.99372
trainer/Q Targets Max             -0.20208
trainer/Q Targets Min            -71.857
trainer/Log Pis Mean               1.97121
trainer/Log Pis Std                1.55209
trainer/Log Pis Max                8.57374
trainer/Log Pis Min               -1.47519
trainer/Policy mu Mean            -0.0510519
trainer/Policy mu Std              0.856836
trainer/Policy mu Max              2.98084
trainer/Policy mu Min             -3.19992
trainer/Policy log std Mean       -1.91679
trainer/Policy log std Std         0.439298
trainer/Policy log std Max        -0.446686
trainer/Policy log std Min        -2.33919
trainer/Alpha                      0.0514315
trainer/Alpha Loss                -0.0854422
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.374429
exploration/Rewards Std            1.02826
exploration/Rewards Max           -0.0104699
exploration/Rewards Min           -9.05052
exploration/Returns Mean         -37.4429
exploration/Returns Std           15.1653
exploration/Returns Max          -19.684
exploration/Returns Min          -58.511
exploration/Actions Mean          -0.0112741
exploration/Actions Std            0.269329
exploration/Actions Max            0.999109
exploration/Actions Min           -0.999739
exploration/Num Paths              5
exploration/Average Returns      -37.4429
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.291978
evaluation/Rewards Std             1.08082
evaluation/Rewards Max            -0.023523
evaluation/Rewards Min           -10.0208
evaluation/Returns Mean          -29.1978
evaluation/Returns Std            16.2576
evaluation/Returns Max           -10.811
evaluation/Returns Min           -58.3398
evaluation/Actions Mean           -0.0057097
evaluation/Actions Std             0.205254
evaluation/Actions Max             0.995771
evaluation/Actions Min            -0.996906
evaluation/Num Paths              15
evaluation/Average Returns       -29.1978
time/data storing (s)              0.00312533
time/evaluation sampling (s)       0.375883
time/exploration sampling (s)      0.172187
time/logging (s)                   0.00506519
time/saving (s)                    0.00176123
time/training (s)                  2.11949
time/epoch (s)                     2.67751
time/total (s)                    89.5864
Epoch                             32
-----------------------------  --------------
2019-04-22 21:23:23.602869 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   6.23186
trainer/QF2 Loss                   6.32942
trainer/Policy Loss               18.9283
trainer/Q1 Predictions Mean      -17.3684
trainer/Q1 Predictions Std        11.4153
trainer/Q1 Predictions Max       -12.3979
trainer/Q1 Predictions Min       -79.0912
trainer/Q2 Predictions Mean      -17.4061
trainer/Q2 Predictions Std        11.4407
trainer/Q2 Predictions Max       -12.4338
trainer/Q2 Predictions Min       -80.1438
trainer/Q Targets Mean           -17.1327
trainer/Q Targets Std             11.6595
trainer/Q Targets Max             -0.22026
trainer/Q Targets Min            -76.6009
trainer/Log Pis Mean               2.16922
trainer/Log Pis Std                1.77808
trainer/Log Pis Max                8.64241
trainer/Log Pis Min               -3.38523
trainer/Policy mu Mean             0.0899512
trainer/Policy mu Std              0.923035
trainer/Policy mu Max              3.27517
trainer/Policy mu Min             -3.01539
trainer/Policy log std Mean       -1.9232
trainer/Policy log std Std         0.46158
trainer/Policy log std Max        -0.405019
trainer/Policy log std Min        -2.38924
trainer/Alpha                      0.05088
trainer/Alpha Loss                 0.503989
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.311172
exploration/Rewards Std            0.885485
exploration/Rewards Max           -0.00494713
exploration/Rewards Min           -8.71717
exploration/Returns Mean         -31.1172
exploration/Returns Std           12.6664
exploration/Returns Max          -17.2232
exploration/Returns Min          -54.9208
exploration/Actions Mean           0.0325942
exploration/Actions Std            0.230819
exploration/Actions Max            0.997966
exploration/Actions Min           -0.998175
exploration/Num Paths              5
exploration/Average Returns      -31.1172
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.261402
evaluation/Rewards Std             1.07787
evaluation/Rewards Max            -0.00666969
evaluation/Rewards Min           -10.2462
evaluation/Returns Mean          -26.1402
evaluation/Returns Std            19.739
evaluation/Returns Max            -4.4285
evaluation/Returns Min           -61.4933
evaluation/Actions Mean            0.0129179
evaluation/Actions Std             0.191341
evaluation/Actions Max             0.996725
evaluation/Actions Min            -0.995637
evaluation/Num Paths              15
evaluation/Average Returns       -26.1402
time/data storing (s)              0.00336997
time/evaluation sampling (s)       0.354465
time/exploration sampling (s)      0.161205
time/logging (s)                   0.0049245
time/saving (s)                    0.00197048
time/training (s)                  2.11181
time/epoch (s)                     2.63774
time/total (s)                    92.2289
Epoch                             33
-----------------------------  --------------
2019-04-22 21:23:26.291626 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                   0.231527
trainer/QF2 Loss                   0.242286
trainer/Policy Loss               17.7387
trainer/Q1 Predictions Mean      -16.4901
trainer/Q1 Predictions Std        11.0689
trainer/Q1 Predictions Max       -11.9245
trainer/Q1 Predictions Min       -79.5249
trainer/Q2 Predictions Mean      -16.5525
trainer/Q2 Predictions Std        11.1628
trainer/Q2 Predictions Max       -12.0101
trainer/Q2 Predictions Min       -80.4642
trainer/Q Targets Mean           -16.7406
trainer/Q Targets Std             10.9414
trainer/Q Targets Max            -12.3777
trainer/Q Targets Min            -81.1878
trainer/Log Pis Mean               1.83223
trainer/Log Pis Std                1.61368
trainer/Log Pis Max                9.75331
trainer/Log Pis Min               -1.45366
trainer/Policy mu Mean             0.0353664
trainer/Policy mu Std              0.884598
trainer/Policy mu Max              3.30939
trainer/Policy mu Min             -3.21684
trainer/Policy log std Mean       -1.89895
trainer/Policy log std Std         0.435575
trainer/Policy log std Max        -0.414341
trainer/Policy log std Min        -2.33495
trainer/Alpha                      0.0500475
trainer/Alpha Loss                -0.502418
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.283137
exploration/Rewards Std            0.729568
exploration/Rewards Max           -0.00164252
exploration/Rewards Min           -7.04789
exploration/Returns Mean         -28.3137
exploration/Returns Std            9.28402
exploration/Returns Max          -17.2918
exploration/Returns Min          -43.1299
exploration/Actions Mean          -0.019295
exploration/Actions Std            0.251272
exploration/Actions Max            0.994767
exploration/Actions Min           -0.999359
exploration/Num Paths              5
exploration/Average Returns      -28.3137
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.226674
evaluation/Rewards Std             0.980954
evaluation/Rewards Max            -0.027881
evaluation/Rewards Min            -9.81011
evaluation/Returns Mean          -22.6674
evaluation/Returns Std            16.6796
evaluation/Returns Max            -3.39167
evaluation/Returns Min           -57.6809
evaluation/Actions Mean            0.0240381
evaluation/Actions Std             0.188349
evaluation/Actions Max             0.996954
evaluation/Actions Min            -0.995522
evaluation/Num Paths              15
evaluation/Average Returns       -22.6674
time/data storing (s)              0.00326886
time/evaluation sampling (s)       0.366743
time/exploration sampling (s)      0.160767
time/logging (s)                   0.005065
time/saving (s)                    0.00217284
time/training (s)                  2.14454
time/epoch (s)                     2.68255
time/total (s)                    94.9165
Epoch                             34
-----------------------------  --------------
2019-04-22 21:23:28.937033 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   2.1761
trainer/QF2 Loss                   2.20927
trainer/Policy Loss               17.2711
trainer/Q1 Predictions Mean      -16.2484
trainer/Q1 Predictions Std        10.6269
trainer/Q1 Predictions Max       -12.0985
trainer/Q1 Predictions Min       -83.1969
trainer/Q2 Predictions Mean      -16.2475
trainer/Q2 Predictions Std        10.5985
trainer/Q2 Predictions Max       -12.1202
trainer/Q2 Predictions Min       -83.3005
trainer/Q Targets Mean           -16.2473
trainer/Q Targets Std             10.9252
trainer/Q Targets Max             -0.413512
trainer/Q Targets Min            -85.8226
trainer/Log Pis Mean               1.80526
trainer/Log Pis Std                1.52464
trainer/Log Pis Max                7.16392
trainer/Log Pis Min               -2.10761
trainer/Policy mu Mean             0.0157643
trainer/Policy mu Std              0.795661
trainer/Policy mu Max              2.9393
trainer/Policy mu Min             -3.21378
trainer/Policy log std Mean       -1.99471
trainer/Policy log std Std         0.41639
trainer/Policy log std Max        -0.476003
trainer/Policy log std Min        -2.40995
trainer/Alpha                      0.0513963
trainer/Alpha Loss                -0.578031
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.301745
exploration/Rewards Std            0.748531
exploration/Rewards Max           -0.00225958
exploration/Rewards Min           -6.82471
exploration/Returns Mean         -30.1745
exploration/Returns Std            7.82311
exploration/Returns Max          -21.155
exploration/Returns Min          -39.0247
exploration/Actions Mean          -0.00184084
exploration/Actions Std            0.244748
exploration/Actions Max            0.999295
exploration/Actions Min           -0.995011
exploration/Num Paths              5
exploration/Average Returns      -30.1745
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.247515
evaluation/Rewards Std             0.968011
evaluation/Rewards Max            -0.0268684
evaluation/Rewards Min            -9.88885
evaluation/Returns Mean          -24.7515
evaluation/Returns Std            17.1707
evaluation/Returns Max            -4.46549
evaluation/Returns Min           -61.9847
evaluation/Actions Mean            0.00212576
evaluation/Actions Std             0.191482
evaluation/Actions Max             0.995528
evaluation/Actions Min            -0.996637
evaluation/Num Paths              15
evaluation/Average Returns       -24.7515
time/data storing (s)              0.0043684
time/evaluation sampling (s)       0.357663
time/exploration sampling (s)      0.161106
time/logging (s)                   0.00406671
time/saving (s)                    0.0019451
time/training (s)                  2.10914
time/epoch (s)                     2.63829
time/total (s)                    97.5597
Epoch                             35
-----------------------------  --------------
2019-04-22 21:23:31.625356 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                   2.01428
trainer/QF2 Loss                   2.06831
trainer/Policy Loss               16.1975
trainer/Q1 Predictions Mean      -14.5659
trainer/Q1 Predictions Std         6.56565
trainer/Q1 Predictions Max       -11.7035
trainer/Q1 Predictions Min       -67.3534
trainer/Q2 Predictions Mean      -14.5922
trainer/Q2 Predictions Std         6.63254
trainer/Q2 Predictions Max       -11.7047
trainer/Q2 Predictions Min       -67.7985
trainer/Q Targets Mean           -14.6073
trainer/Q Targets Std              6.58361
trainer/Q Targets Max             -0.804553
trainer/Q Targets Min            -66.1425
trainer/Log Pis Mean               2.00612
trainer/Log Pis Std                1.47587
trainer/Log Pis Max                9.65984
trainer/Log Pis Min               -2.86664
trainer/Policy mu Mean             0.103476
trainer/Policy mu Std              0.747035
trainer/Policy mu Max              2.92513
trainer/Policy mu Min             -3.33508
trainer/Policy log std Mean       -2.06892
trainer/Policy log std Std         0.416951
trainer/Policy log std Max        -0.365402
trainer/Policy log std Min        -2.40946
trainer/Alpha                      0.0541747
trainer/Alpha Loss                 0.0178488
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.288436
exploration/Rewards Std            0.735884
exploration/Rewards Max           -0.00390365
exploration/Rewards Min           -6.86901
exploration/Returns Mean         -28.8436
exploration/Returns Std            9.06338
exploration/Returns Max          -15.9454
exploration/Returns Min          -38.0314
exploration/Actions Mean           0.00890243
exploration/Actions Std            0.219636
exploration/Actions Max            0.998477
exploration/Actions Min           -0.995844
exploration/Num Paths              5
exploration/Average Returns      -28.8436
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.236949
evaluation/Rewards Std             0.808812
evaluation/Rewards Max            -0.0228746
evaluation/Rewards Min           -10.4638
evaluation/Returns Mean          -23.6949
evaluation/Returns Std            14.0326
evaluation/Returns Max            -6.96951
evaluation/Returns Min           -61.1156
evaluation/Actions Mean            0.0116652
evaluation/Actions Std             0.179814
evaluation/Actions Max             0.996512
evaluation/Actions Min            -0.995196
evaluation/Num Paths              15
evaluation/Average Returns       -23.6949
time/data storing (s)              0.00383294
time/evaluation sampling (s)       0.351761
time/exploration sampling (s)      0.15664
time/logging (s)                   0.00533474
time/saving (s)                    0.00196649
time/training (s)                  2.16407
time/epoch (s)                     2.68361
time/total (s)                   100.248
Epoch                             36
-----------------------------  --------------
2019-04-22 21:23:34.259769 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   0.108167
trainer/QF2 Loss                   0.079867
trainer/Policy Loss               16.0233
trainer/Q1 Predictions Mean      -14.7326
trainer/Q1 Predictions Std         6.77997
trainer/Q1 Predictions Max       -11.4569
trainer/Q1 Predictions Min       -65.3348
trainer/Q2 Predictions Mean      -14.7829
trainer/Q2 Predictions Std         6.73162
trainer/Q2 Predictions Max       -11.5969
trainer/Q2 Predictions Min       -64.7272
trainer/Q Targets Mean           -14.983
trainer/Q Targets Std              6.81051
trainer/Q Targets Max            -11.6216
trainer/Q Targets Min            -65.9807
trainer/Log Pis Mean               1.89076
trainer/Log Pis Std                1.41943
trainer/Log Pis Max                8.13961
trainer/Log Pis Min               -2.58195
trainer/Policy mu Mean             0.0664143
trainer/Policy mu Std              0.822956
trainer/Policy mu Max              3.08499
trainer/Policy mu Min             -3.03314
trainer/Policy log std Mean       -1.93783
trainer/Policy log std Std         0.418923
trainer/Policy log std Max        -0.388255
trainer/Policy log std Min        -2.31737
trainer/Alpha                      0.0538563
trainer/Alpha Loss                -0.319114
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.272042
exploration/Rewards Std            0.67069
exploration/Rewards Max           -0.00498845
exploration/Rewards Min           -8.3645
exploration/Returns Mean         -27.2042
exploration/Returns Std           13.491
exploration/Returns Max          -14.0108
exploration/Returns Min          -50.9555
exploration/Actions Mean          -0.0110307
exploration/Actions Std            0.231216
exploration/Actions Max            0.994262
exploration/Actions Min           -0.999347
exploration/Num Paths              5
exploration/Average Returns      -27.2042
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.40182
evaluation/Rewards Std             1.27586
evaluation/Rewards Max            -0.0347657
evaluation/Rewards Min           -10.6123
evaluation/Returns Mean          -40.182
evaluation/Returns Std            18.4529
evaluation/Returns Max            -9.82309
evaluation/Returns Min           -66.382
evaluation/Actions Mean           -0.0106415
evaluation/Actions Std             0.218363
evaluation/Actions Max             0.99637
evaluation/Actions Min            -0.996963
evaluation/Num Paths              15
evaluation/Average Returns       -40.182
time/data storing (s)              0.00393419
time/evaluation sampling (s)       0.361711
time/exploration sampling (s)      0.160411
time/logging (s)                   0.00495344
time/saving (s)                    0.00204646
time/training (s)                  2.09488
time/epoch (s)                     2.62793
time/total (s)                   102.881
Epoch                             37
-----------------------------  --------------
2019-04-22 21:23:36.951311 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                   0.116203
trainer/QF2 Loss                   0.112199
trainer/Policy Loss               14.7616
trainer/Q1 Predictions Mean      -13.2205
trainer/Q1 Predictions Std         3.32209
trainer/Q1 Predictions Max       -11.1529
trainer/Q1 Predictions Min       -31.9144
trainer/Q2 Predictions Mean      -13.2292
trainer/Q2 Predictions Std         3.31945
trainer/Q2 Predictions Max       -11.1585
trainer/Q2 Predictions Min       -31.597
trainer/Q Targets Mean           -13.5196
trainer/Q Targets Std              3.37874
trainer/Q Targets Max            -11.3982
trainer/Q Targets Min            -32.759
trainer/Log Pis Mean               1.94768
trainer/Log Pis Std                1.20367
trainer/Log Pis Max                6.11618
trainer/Log Pis Min               -1.67398
trainer/Policy mu Mean             0.0238396
trainer/Policy mu Std              0.650499
trainer/Policy mu Max              2.91934
trainer/Policy mu Min             -2.46848
trainer/Policy log std Mean       -2.03899
trainer/Policy log std Std         0.378867
trainer/Policy log std Max        -0.343981
trainer/Policy log std Min        -2.37076
trainer/Alpha                      0.0513052
trainer/Alpha Loss                -0.155379
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.301873
exploration/Rewards Std            0.880202
exploration/Rewards Max           -0.0043001
exploration/Rewards Min           -9.03362
exploration/Returns Mean         -30.1873
exploration/Returns Std           17.4571
exploration/Returns Max          -16.1215
exploration/Returns Min          -62.7328
exploration/Actions Mean           0.0129114
exploration/Actions Std            0.22955
exploration/Actions Max            0.99844
exploration/Actions Min           -0.996257
exploration/Num Paths              5
exploration/Average Returns      -30.1873
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.209355
evaluation/Rewards Std             0.709715
evaluation/Rewards Max            -0.0472728
evaluation/Rewards Min            -8.36642
evaluation/Returns Mean          -20.9355
evaluation/Returns Std             6.79873
evaluation/Returns Max            -9.55971
evaluation/Returns Min           -40.4349
evaluation/Actions Mean            0.0178709
evaluation/Actions Std             0.180809
evaluation/Actions Max             0.994571
evaluation/Actions Min            -0.996747
evaluation/Num Paths              15
evaluation/Average Returns       -20.9355
time/data storing (s)              0.00302041
time/evaluation sampling (s)       0.360629
time/exploration sampling (s)      0.16295
time/logging (s)                   0.00458859
time/saving (s)                    0.00200587
time/training (s)                  2.15209
time/epoch (s)                     2.68529
time/total (s)                   105.571
Epoch                             38
-----------------------------  --------------
2019-04-22 21:23:39.587328 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                   1.45099
trainer/QF2 Loss                   1.42803
trainer/Policy Loss               16.2422
trainer/Q1 Predictions Mean      -14.697
trainer/Q1 Predictions Std         7.78158
trainer/Q1 Predictions Max       -11.2916
trainer/Q1 Predictions Min       -72.0908
trainer/Q2 Predictions Mean      -14.698
trainer/Q2 Predictions Std         7.74265
trainer/Q2 Predictions Max       -11.3255
trainer/Q2 Predictions Min       -71.5065
trainer/Q Targets Mean           -14.8595
trainer/Q Targets Std              8.17567
trainer/Q Targets Max             -0.874673
trainer/Q Targets Min            -75.0212
trainer/Log Pis Mean               2.06995
trainer/Log Pis Std                1.72481
trainer/Log Pis Max                8.864
trainer/Log Pis Min               -1.78193
trainer/Policy mu Mean            -0.0731273
trainer/Policy mu Std              0.970207
trainer/Policy mu Max              3.2058
trainer/Policy mu Min             -3.08526
trainer/Policy log std Mean       -1.87533
trainer/Policy log std Std         0.522514
trainer/Policy log std Max        -0.395769
trainer/Policy log std Min        -2.3816
trainer/Alpha                      0.0510688
trainer/Alpha Loss                 0.208073
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.269565
exploration/Rewards Std            0.604382
exploration/Rewards Max           -0.00632116
exploration/Rewards Min           -5.78535
exploration/Returns Mean         -26.9565
exploration/Returns Std            5.32031
exploration/Returns Max          -20.556
exploration/Returns Min          -34.1076
exploration/Actions Mean          -0.00462613
exploration/Actions Std            0.233837
exploration/Actions Max            0.996177
exploration/Actions Min           -0.997626
exploration/Num Paths              5
exploration/Average Returns      -26.9565
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.25961
evaluation/Rewards Std             0.859871
evaluation/Rewards Max            -0.0560859
evaluation/Rewards Min            -9.26169
evaluation/Returns Mean          -25.961
evaluation/Returns Std            10.7304
evaluation/Returns Max            -9.07852
evaluation/Returns Min           -47.8819
evaluation/Actions Mean            0.0120904
evaluation/Actions Std             0.187791
evaluation/Actions Max             0.995424
evaluation/Actions Min            -0.996799
evaluation/Num Paths              15
evaluation/Average Returns       -25.961
time/data storing (s)              0.00302958
time/evaluation sampling (s)       0.357445
time/exploration sampling (s)      0.162506
time/logging (s)                   0.00471472
time/saving (s)                    0.00195929
time/training (s)                  2.10129
time/epoch (s)                     2.63095
time/total (s)                   108.206
Epoch                             39
-----------------------------  --------------
2019-04-22 21:23:42.262366 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size             20700
trainer/QF1 Loss                   0.115725
trainer/QF2 Loss                   0.1117
trainer/Policy Loss               15.5177
trainer/Q1 Predictions Mean      -14.2634
trainer/Q1 Predictions Std         7.26915
trainer/Q1 Predictions Max       -10.9024
trainer/Q1 Predictions Min       -55.4714
trainer/Q2 Predictions Mean      -14.2673
trainer/Q2 Predictions Std         7.13104
trainer/Q2 Predictions Max       -10.9974
trainer/Q2 Predictions Min       -53.5195
trainer/Q Targets Mean           -14.4833
trainer/Q Targets Std              7.20244
trainer/Q Targets Max            -11.0839
trainer/Q Targets Min            -54.8559
trainer/Log Pis Mean               1.86083
trainer/Log Pis Std                1.72494
trainer/Log Pis Max                8.80439
trainer/Log Pis Min               -3.19396
trainer/Policy mu Mean             0.0463983
trainer/Policy mu Std              0.786641
trainer/Policy mu Max              2.93583
trainer/Policy mu Min             -3.13241
trainer/Policy log std Mean       -1.96541
trainer/Policy log std Std         0.414307
trainer/Policy log std Max        -0.47311
trainer/Policy log std Min        -2.34955
trainer/Alpha                      0.0490099
trainer/Alpha Loss                -0.419706
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.503388
exploration/Rewards Std            1.34333
exploration/Rewards Max           -0.00257506
exploration/Rewards Min           -9.76037
exploration/Returns Mean         -50.3388
exploration/Returns Std           15.3978
exploration/Returns Max          -25.7847
exploration/Returns Min          -65.0832
exploration/Actions Mean           0.0141488
exploration/Actions Std            0.278584
exploration/Actions Max            0.999101
exploration/Actions Min           -0.999591
exploration/Num Paths              5
exploration/Average Returns      -50.3388
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.298313
evaluation/Rewards Std             1.03618
evaluation/Rewards Max            -0.0724023
evaluation/Rewards Min           -10.1489
evaluation/Returns Mean          -29.8313
evaluation/Returns Std            16.8474
evaluation/Returns Max            -7.60506
evaluation/Returns Min           -66.3263
evaluation/Actions Mean           -0.0141466
evaluation/Actions Std             0.20324
evaluation/Actions Max             0.996897
evaluation/Actions Min            -0.997247
evaluation/Num Paths              15
evaluation/Average Returns       -29.8313
time/data storing (s)              0.00310365
time/evaluation sampling (s)       0.363693
time/exploration sampling (s)      0.167227
time/logging (s)                   0.00509484
time/saving (s)                    0.0104254
time/training (s)                  2.12039
time/epoch (s)                     2.66994
time/total (s)                   110.88
Epoch                             40
-----------------------------  --------------
2019-04-22 21:23:44.948755 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                   1.17819
trainer/QF2 Loss                   1.16881
trainer/Policy Loss               14.2157
trainer/Q1 Predictions Mean      -12.7746
trainer/Q1 Predictions Std         2.70574
trainer/Q1 Predictions Max       -10.7796
trainer/Q1 Predictions Min       -31.4291
trainer/Q2 Predictions Mean      -12.7728
trainer/Q2 Predictions Std         2.71684
trainer/Q2 Predictions Max       -10.7596
trainer/Q2 Predictions Min       -31.2296
trainer/Q Targets Mean           -12.7128
trainer/Q Targets Std              2.99341
trainer/Q Targets Max             -0.369336
trainer/Q Targets Min            -32.4002
trainer/Log Pis Mean               1.66781
trainer/Log Pis Std                1.02988
trainer/Log Pis Max                4.91109
trainer/Log Pis Min               -1.24276
trainer/Policy mu Mean            -0.0549791
trainer/Policy mu Std              0.59831
trainer/Policy mu Max              2.92472
trainer/Policy mu Min             -2.82589
trainer/Policy log std Mean       -2.04087
trainer/Policy log std Std         0.342981
trainer/Policy log std Max        -0.568079
trainer/Policy log std Min        -2.50685
trainer/Alpha                      0.0491492
trainer/Alpha Loss                -1.00086
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.350333
exploration/Rewards Std            0.977247
exploration/Rewards Max           -0.00481649
exploration/Rewards Min          -10.8589
exploration/Returns Mean         -35.0333
exploration/Returns Std           19.5958
exploration/Returns Max          -19.8356
exploration/Returns Min          -73.793
exploration/Actions Mean          -0.0148112
exploration/Actions Std            0.249959
exploration/Actions Max            0.990721
exploration/Actions Min           -0.999463
exploration/Num Paths              5
exploration/Average Returns      -35.0333
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.265628
evaluation/Rewards Std             0.904544
evaluation/Rewards Max            -0.0266031
evaluation/Rewards Min           -10.8958
evaluation/Returns Mean          -26.5628
evaluation/Returns Std            16.1829
evaluation/Returns Max            -8.34645
evaluation/Returns Min           -67.3649
evaluation/Actions Mean           -0.00776342
evaluation/Actions Std             0.187077
evaluation/Actions Max             0.994647
evaluation/Actions Min            -0.997671
evaluation/Num Paths              15
evaluation/Average Returns       -26.5628
time/data storing (s)              0.00306453
time/evaluation sampling (s)       0.390844
time/exploration sampling (s)      0.177048
time/logging (s)                   0.00475387
time/saving (s)                    0.00197296
time/training (s)                  2.10178
time/epoch (s)                     2.67946
time/total (s)                   113.565
Epoch                             41
-----------------------------  --------------
2019-04-22 21:23:47.585222 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 42 finished
-----------------------------  ---------------
replay_buffer/size             21700
trainer/QF1 Loss                   0.0493427
trainer/QF2 Loss                   0.0659606
trainer/Policy Loss               14.5629
trainer/Q1 Predictions Mean      -13.0957
trainer/Q1 Predictions Std         6.43274
trainer/Q1 Predictions Max       -10.5438
trainer/Q1 Predictions Min       -63.8671
trainer/Q2 Predictions Mean      -13.1427
trainer/Q2 Predictions Std         6.34874
trainer/Q2 Predictions Max       -10.7161
trainer/Q2 Predictions Min       -63.2283
trainer/Q Targets Mean           -13.2379
trainer/Q Targets Std              6.5178
trainer/Q Targets Max            -10.6227
trainer/Q Targets Min            -64.7811
trainer/Log Pis Mean               1.89677
trainer/Log Pis Std                1.16753
trainer/Log Pis Max                6.51971
trainer/Log Pis Min               -1.93344
trainer/Policy mu Mean             0.0435933
trainer/Policy mu Std              0.656573
trainer/Policy mu Max              3.21107
trainer/Policy mu Min             -2.51335
trainer/Policy log std Mean       -2.05294
trainer/Policy log std Std         0.388863
trainer/Policy log std Max        -0.449617
trainer/Policy log std Min        -2.44789
trainer/Alpha                      0.0492214
trainer/Alpha Loss                -0.310854
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.345751
exploration/Rewards Std            1.01038
exploration/Rewards Max           -0.00780398
exploration/Rewards Min           -8.94665
exploration/Returns Mean         -34.5751
exploration/Returns Std           14.3889
exploration/Returns Max          -17.6308
exploration/Returns Min          -54.7363
exploration/Actions Mean           0.00699693
exploration/Actions Std            0.25515
exploration/Actions Max            0.999733
exploration/Actions Min           -0.999134
exploration/Num Paths              5
exploration/Average Returns      -34.5751
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.231456
evaluation/Rewards Std             0.971165
evaluation/Rewards Max            -0.0153622
evaluation/Rewards Min            -9.69812
evaluation/Returns Mean          -23.1456
evaluation/Returns Std            11.7334
evaluation/Returns Max            -2.89743
evaluation/Returns Min           -44.0424
evaluation/Actions Mean            0.000702805
evaluation/Actions Std             0.200426
evaluation/Actions Max             0.995374
evaluation/Actions Min            -0.9984
evaluation/Num Paths              15
evaluation/Average Returns       -23.1456
time/data storing (s)              0.00309252
time/evaluation sampling (s)       0.352869
time/exploration sampling (s)      0.154724
time/logging (s)                   0.00507421
time/saving (s)                    0.00210063
time/training (s)                  2.11394
time/epoch (s)                     2.6318
time/total (s)                   116.2
Epoch                             42
-----------------------------  ---------------
2019-04-22 21:23:50.295451 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size             22200
trainer/QF1 Loss                   0.106949
trainer/QF2 Loss                   0.109365
trainer/Policy Loss               15.9727
trainer/Q1 Predictions Mean      -14.4413
trainer/Q1 Predictions Std        10.187
trainer/Q1 Predictions Max       -10.4668
trainer/Q1 Predictions Min       -76.8152
trainer/Q2 Predictions Mean      -14.4187
trainer/Q2 Predictions Std        10.1991
trainer/Q2 Predictions Max       -10.5026
trainer/Q2 Predictions Min       -78.1185
trainer/Q Targets Mean           -14.6284
trainer/Q Targets Std             10.2069
trainer/Q Targets Max            -10.5442
trainer/Q Targets Min            -77.7947
trainer/Log Pis Mean               2.07714
trainer/Log Pis Std                1.55973
trainer/Log Pis Max                8.43432
trainer/Log Pis Min               -2.6953
trainer/Policy mu Mean             0.0153263
trainer/Policy mu Std              0.913697
trainer/Policy mu Max              3.32833
trainer/Policy mu Min             -3.33973
trainer/Policy log std Mean       -1.95458
trainer/Policy log std Std         0.473014
trainer/Policy log std Max        -0.360114
trainer/Policy log std Min        -2.39431
trainer/Alpha                      0.0485679
trainer/Alpha Loss                 0.233325
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.34858
exploration/Rewards Std            1.0641
exploration/Rewards Max           -0.007834
exploration/Rewards Min           -9.88728
exploration/Returns Mean         -34.858
exploration/Returns Std           16.7025
exploration/Returns Max          -14.3387
exploration/Returns Min          -58.1533
exploration/Actions Mean           0.0248501
exploration/Actions Std            0.23312
exploration/Actions Max            0.999597
exploration/Actions Min           -0.998762
exploration/Num Paths              5
exploration/Average Returns      -34.858
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.214479
evaluation/Rewards Std             0.942097
evaluation/Rewards Max            -0.00862932
evaluation/Rewards Min            -9.41737
evaluation/Returns Mean          -21.4479
evaluation/Returns Std            15.1886
evaluation/Returns Max            -1.70076
evaluation/Returns Min           -49.1991
evaluation/Actions Mean            0.0138672
evaluation/Actions Std             0.188799
evaluation/Actions Max             0.996492
evaluation/Actions Min            -0.997279
evaluation/Num Paths              15
evaluation/Average Returns       -21.4479
time/data storing (s)              0.00308161
time/evaluation sampling (s)       0.360381
time/exploration sampling (s)      0.16532
time/logging (s)                   0.00533214
time/saving (s)                    0.00216392
time/training (s)                  2.16843
time/epoch (s)                     2.70471
time/total (s)                   118.91
Epoch                             43
-----------------------------  --------------
2019-04-22 21:23:52.931582 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             22700
trainer/QF1 Loss                   1.55978
trainer/QF2 Loss                   1.61761
trainer/Policy Loss               15.4883
trainer/Q1 Predictions Mean      -14.2279
trainer/Q1 Predictions Std         9.9925
trainer/Q1 Predictions Max       -10.3881
trainer/Q1 Predictions Min       -76.1646
trainer/Q2 Predictions Mean      -14.1537
trainer/Q2 Predictions Std         9.97152
trainer/Q2 Predictions Max       -10.3367
trainer/Q2 Predictions Min       -76.9839
trainer/Q Targets Mean           -14.292
trainer/Q Targets Std             10.2712
trainer/Q Targets Max             -0.311079
trainer/Q Targets Min            -77.5934
trainer/Log Pis Mean               2.07859
trainer/Log Pis Std                1.45252
trainer/Log Pis Max                7.47353
trainer/Log Pis Min               -1.05055
trainer/Policy mu Mean             0.013846
trainer/Policy mu Std              0.848981
trainer/Policy mu Max              3.2879
trainer/Policy mu Min             -3.42866
trainer/Policy log std Mean       -2.0297
trainer/Policy log std Std         0.465326
trainer/Policy log std Max        -0.378263
trainer/Policy log std Min        -2.55789
trainer/Alpha                      0.0480305
trainer/Alpha Loss                 0.238624
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.31762
exploration/Rewards Std            0.884841
exploration/Rewards Max           -0.00996387
exploration/Rewards Min           -9.38016
exploration/Returns Mean         -31.762
exploration/Returns Std           18.4175
exploration/Returns Max          -15.4845
exploration/Returns Min          -63.5007
exploration/Actions Mean          -0.0136571
exploration/Actions Std            0.219357
exploration/Actions Max            0.983074
exploration/Actions Min           -0.998811
exploration/Num Paths              5
exploration/Average Returns      -31.762
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.287964
evaluation/Rewards Std             1.12139
evaluation/Rewards Max            -0.0221346
evaluation/Rewards Min           -11.3481
evaluation/Returns Mean          -28.7964
evaluation/Returns Std            21.1553
evaluation/Returns Max            -4.91505
evaluation/Returns Min           -71.5851
evaluation/Actions Mean           -0.0052675
evaluation/Actions Std             0.19991
evaluation/Actions Max             0.996569
evaluation/Actions Min            -0.997755
evaluation/Num Paths              15
evaluation/Average Returns       -28.7964
time/data storing (s)              0.00325043
time/evaluation sampling (s)       0.364911
time/exploration sampling (s)      0.163189
time/logging (s)                   0.00389606
time/saving (s)                    0.00205455
time/training (s)                  2.0922
time/epoch (s)                     2.6295
time/total (s)                   121.543
Epoch                             44
-----------------------------  --------------
2019-04-22 21:23:55.636952 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                   1.80862
trainer/QF2 Loss                   1.89616
trainer/Policy Loss               15.2307
trainer/Q1 Predictions Mean      -13.9151
trainer/Q1 Predictions Std         9.35183
trainer/Q1 Predictions Max       -10.2329
trainer/Q1 Predictions Min       -69.3838
trainer/Q2 Predictions Mean      -13.8208
trainer/Q2 Predictions Std         9.31765
trainer/Q2 Predictions Max       -10.0981
trainer/Q2 Predictions Min       -68.9515
trainer/Q Targets Mean           -13.8604
trainer/Q Targets Std              9.69026
trainer/Q Targets Max             -0.513017
trainer/Q Targets Min            -73.5516
trainer/Log Pis Mean               2.07939
trainer/Log Pis Std                1.62277
trainer/Log Pis Max                7.90809
trainer/Log Pis Min               -2.36276
trainer/Policy mu Mean             0.0143418
trainer/Policy mu Std              0.877443
trainer/Policy mu Max              3.39748
trainer/Policy mu Min             -2.91501
trainer/Policy log std Mean       -1.96699
trainer/Policy log std Std         0.452594
trainer/Policy log std Max        -0.537973
trainer/Policy log std Min        -2.39356
trainer/Alpha                      0.0486063
trainer/Alpha Loss                 0.240085
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.444178
exploration/Rewards Std            1.27305
exploration/Rewards Max           -0.00598332
exploration/Rewards Min           -9.66873
exploration/Returns Mean         -44.4178
exploration/Returns Std           14.2261
exploration/Returns Max          -24.6143
exploration/Returns Min          -59.1089
exploration/Actions Mean           0.0119956
exploration/Actions Std            0.267032
exploration/Actions Max            0.996637
exploration/Actions Min           -0.99753
exploration/Num Paths              5
exploration/Average Returns      -44.4178
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.266722
evaluation/Rewards Std             1.06146
evaluation/Rewards Max            -0.015073
evaluation/Rewards Min           -10.4039
evaluation/Returns Mean          -26.6722
evaluation/Returns Std            15.4817
evaluation/Returns Max            -8.73905
evaluation/Returns Min           -59.1654
evaluation/Actions Mean            0.0140412
evaluation/Actions Std             0.201626
evaluation/Actions Max             0.995272
evaluation/Actions Min            -0.998191
evaluation/Num Paths              15
evaluation/Average Returns       -26.6722
time/data storing (s)              0.00333139
time/evaluation sampling (s)       0.370168
time/exploration sampling (s)      0.174947
time/logging (s)                   0.00504523
time/saving (s)                    0.00209304
time/training (s)                  2.14602
time/epoch (s)                     2.70161
time/total (s)                   124.249
Epoch                             45
-----------------------------  --------------
2019-04-22 21:23:58.282266 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                   1.05793
trainer/QF2 Loss                   1.0788
trainer/Policy Loss               16.0848
trainer/Q1 Predictions Mean      -14.6324
trainer/Q1 Predictions Std        11.2671
trainer/Q1 Predictions Max       -10.0932
trainer/Q1 Predictions Min       -72.4749
trainer/Q2 Predictions Mean      -14.6581
trainer/Q2 Predictions Std        11.2068
trainer/Q2 Predictions Max       -10.1585
trainer/Q2 Predictions Min       -72.6806
trainer/Q Targets Mean           -14.6216
trainer/Q Targets Std             11.3735
trainer/Q Targets Max             -0.615441
trainer/Q Targets Min            -73.3965
trainer/Log Pis Mean               2.20303
trainer/Log Pis Std                1.93034
trainer/Log Pis Max                9.51201
trainer/Log Pis Min               -2.60561
trainer/Policy mu Mean             0.0283399
trainer/Policy mu Std              0.939238
trainer/Policy mu Max              3.33157
trainer/Policy mu Min             -3.11726
trainer/Policy log std Mean       -1.98654
trainer/Policy log std Std         0.497935
trainer/Policy log std Max        -0.340917
trainer/Policy log std Min        -2.41203
trainer/Alpha                      0.0486127
trainer/Alpha Loss                 0.613954
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.35755
exploration/Rewards Std            1.00587
exploration/Rewards Max           -0.00444418
exploration/Rewards Min           -8.65115
exploration/Returns Mean         -35.755
exploration/Returns Std           13.7441
exploration/Returns Max          -17.8484
exploration/Returns Min          -53.6992
exploration/Actions Mean           0.00495143
exploration/Actions Std            0.246422
exploration/Actions Max            0.998864
exploration/Actions Min           -0.998653
exploration/Num Paths              5
exploration/Average Returns      -35.755
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.320635
evaluation/Rewards Std             1.14426
evaluation/Rewards Max            -0.0379512
evaluation/Rewards Min           -11.0144
evaluation/Returns Mean          -32.0635
evaluation/Returns Std            18.0637
evaluation/Returns Max           -10.8335
evaluation/Returns Min           -66.5672
evaluation/Actions Mean           -0.00131987
evaluation/Actions Std             0.200608
evaluation/Actions Max             0.995931
evaluation/Actions Min            -0.997297
evaluation/Num Paths              15
evaluation/Average Returns       -32.0635
time/data storing (s)              0.00325036
time/evaluation sampling (s)       0.370184
time/exploration sampling (s)      0.16936
time/logging (s)                   0.00532081
time/saving (s)                    0.00207839
time/training (s)                  2.08918
time/epoch (s)                     2.63938
time/total (s)                   126.893
Epoch                             46
-----------------------------  --------------
2019-04-22 21:24:01.028539 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size             24200
trainer/QF1 Loss                   0.0494156
trainer/QF2 Loss                   0.0741611
trainer/Policy Loss               15.3076
trainer/Q1 Predictions Mean      -13.5361
trainer/Q1 Predictions Std         9.87567
trainer/Q1 Predictions Max        -9.88188
trainer/Q1 Predictions Min       -76.6495
trainer/Q2 Predictions Mean      -13.5753
trainer/Q2 Predictions Std         9.93958
trainer/Q2 Predictions Max        -9.96011
trainer/Q2 Predictions Min       -77.7975
trainer/Q Targets Mean           -13.5868
trainer/Q Targets Std              9.73544
trainer/Q Targets Max             -9.96489
trainer/Q Targets Min            -75.7645
trainer/Log Pis Mean               2.18535
trainer/Log Pis Std                1.82382
trainer/Log Pis Max                9.69553
trainer/Log Pis Min               -2.24065
trainer/Policy mu Mean             0.0959751
trainer/Policy mu Std              0.833144
trainer/Policy mu Max              3.21438
trainer/Policy mu Min             -3.23444
trainer/Policy log std Mean       -2.06957
trainer/Policy log std Std         0.472145
trainer/Policy log std Max        -0.510008
trainer/Policy log std Min        -2.55547
trainer/Alpha                      0.0483984
trainer/Alpha Loss                 0.561328
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.475709
exploration/Rewards Std            1.41312
exploration/Rewards Max           -0.00392522
exploration/Rewards Min          -10.4945
exploration/Returns Mean         -47.5709
exploration/Returns Std           24.8109
exploration/Returns Max          -17.031
exploration/Returns Min          -74.6502
exploration/Actions Mean          -0.0115619
exploration/Actions Std            0.250595
exploration/Actions Max            0.998953
exploration/Actions Min           -0.999488
exploration/Num Paths              5
exploration/Average Returns      -47.5709
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.380279
evaluation/Rewards Std             1.25717
evaluation/Rewards Max            -0.035595
evaluation/Rewards Min            -9.8701
evaluation/Returns Mean          -38.0279
evaluation/Returns Std            18.0176
evaluation/Returns Max            -9.82185
evaluation/Returns Min           -63.3037
evaluation/Actions Mean           -0.00596735
evaluation/Actions Std             0.205269
evaluation/Actions Max             0.997477
evaluation/Actions Min            -0.99672
evaluation/Num Paths              15
evaluation/Average Returns       -38.0279
time/data storing (s)              0.00324223
time/evaluation sampling (s)       0.372426
time/exploration sampling (s)      0.161238
time/logging (s)                   0.00559049
time/saving (s)                    0.00205312
time/training (s)                  2.19566
time/epoch (s)                     2.74021
time/total (s)                   129.638
Epoch                             47
-----------------------------  --------------
2019-04-22 21:24:03.696853 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                   2.43802
trainer/QF2 Loss                   2.48816
trainer/Policy Loss               15.7952
trainer/Q1 Predictions Mean      -14.6855
trainer/Q1 Predictions Std        12.8071
trainer/Q1 Predictions Max        -9.744
trainer/Q1 Predictions Min       -74.1938
trainer/Q2 Predictions Mean      -14.6852
trainer/Q2 Predictions Std        12.8072
trainer/Q2 Predictions Max        -9.68798
trainer/Q2 Predictions Min       -74.6478
trainer/Q Targets Mean           -14.6419
trainer/Q Targets Std             12.9049
trainer/Q Targets Max             -0.115198
trainer/Q Targets Min            -74.3388
trainer/Log Pis Mean               1.8681
trainer/Log Pis Std                1.8813
trainer/Log Pis Max                8.59417
trainer/Log Pis Min               -3.71542
trainer/Policy mu Mean             0.0702539
trainer/Policy mu Std              0.913667
trainer/Policy mu Max              3.34791
trainer/Policy mu Min             -3.25605
trainer/Policy log std Mean       -1.98032
trainer/Policy log std Std         0.496178
trainer/Policy log std Max        -0.392964
trainer/Policy log std Min        -2.40803
trainer/Alpha                      0.0511426
trainer/Alpha Loss                -0.392157
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.45859
exploration/Rewards Std            1.38441
exploration/Rewards Max           -0.00651821
exploration/Rewards Min          -10.469
exploration/Returns Mean         -45.859
exploration/Returns Std           23.9766
exploration/Returns Max          -16.8001
exploration/Returns Min          -69.6772
exploration/Actions Mean          -0.013986
exploration/Actions Std            0.26909
exploration/Actions Max            0.995423
exploration/Actions Min           -0.999281
exploration/Num Paths              5
exploration/Average Returns      -45.859
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.227531
evaluation/Rewards Std             0.929852
evaluation/Rewards Max            -0.0401382
evaluation/Rewards Min            -9.81877
evaluation/Returns Mean          -22.7531
evaluation/Returns Std            17.9802
evaluation/Returns Max            -7.17857
evaluation/Returns Min           -60.1014
evaluation/Actions Mean           -0.0175751
evaluation/Actions Std             0.179961
evaluation/Actions Max             0.993856
evaluation/Actions Min            -0.996884
evaluation/Num Paths              15
evaluation/Average Returns       -22.7531
time/data storing (s)              0.00387102
time/evaluation sampling (s)       0.360206
time/exploration sampling (s)      0.163389
time/logging (s)                   0.00567759
time/saving (s)                    0.00234377
time/training (s)                  2.12657
time/epoch (s)                     2.66205
time/total (s)                   132.305
Epoch                             48
-----------------------------  --------------
2019-04-22 21:24:06.356415 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                   2.31
trainer/QF2 Loss                   2.33338
trainer/Policy Loss               14.1906
trainer/Q1 Predictions Mean      -12.5952
trainer/Q1 Predictions Std         7.82431
trainer/Q1 Predictions Max        -9.71373
trainer/Q1 Predictions Min       -72.1104
trainer/Q2 Predictions Mean      -12.6523
trainer/Q2 Predictions Std         7.87092
trainer/Q2 Predictions Max        -9.839
trainer/Q2 Predictions Min       -73.3091
trainer/Q Targets Mean           -12.5179
trainer/Q Targets Std              8.06017
trainer/Q Targets Max             -0.150983
trainer/Q Targets Min            -73.2644
trainer/Log Pis Mean               1.99425
trainer/Log Pis Std                1.60821
trainer/Log Pis Max                7.73267
trainer/Log Pis Min               -2.77852
trainer/Policy mu Mean             0.113239
trainer/Policy mu Std              0.733084
trainer/Policy mu Max              3.34104
trainer/Policy mu Min             -3.09253
trainer/Policy log std Mean       -2.0555
trainer/Policy log std Std         0.408033
trainer/Policy log std Max        -0.574157
trainer/Policy log std Min        -2.49071
trainer/Alpha                      0.0479414
trainer/Alpha Loss                -0.0174553
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.431691
exploration/Rewards Std            1.24863
exploration/Rewards Max           -0.00679332
exploration/Rewards Min           -9.63927
exploration/Returns Mean         -43.1691
exploration/Returns Std           15.9859
exploration/Returns Max          -18.2027
exploration/Returns Min          -65.5033
exploration/Actions Mean           0.0153641
exploration/Actions Std            0.255404
exploration/Actions Max            0.998997
exploration/Actions Min           -0.998848
exploration/Num Paths              5
exploration/Average Returns      -43.1691
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.280887
evaluation/Rewards Std             1.06485
evaluation/Rewards Max            -0.0280121
evaluation/Rewards Min           -10.8061
evaluation/Returns Mean          -28.0887
evaluation/Returns Std            18.0153
evaluation/Returns Max            -7.18188
evaluation/Returns Min           -65.4319
evaluation/Actions Mean           -0.0124987
evaluation/Actions Std             0.205773
evaluation/Actions Max             0.995872
evaluation/Actions Min            -0.99746
evaluation/Num Paths              15
evaluation/Average Returns       -28.0887
time/data storing (s)              0.0034462
time/evaluation sampling (s)       0.361057
time/exploration sampling (s)      0.164894
time/logging (s)                   0.00499969
time/saving (s)                    0.00198581
time/training (s)                  2.11615
time/epoch (s)                     2.65253
time/total (s)                   134.962
Epoch                             49
-----------------------------  --------------
2019-04-22 21:24:09.037423 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             25700
trainer/QF1 Loss                   0.958671
trainer/QF2 Loss                   0.965694
trainer/Policy Loss               12.943
trainer/Q1 Predictions Mean      -11.3999
trainer/Q1 Predictions Std         5.28571
trainer/Q1 Predictions Max        -9.44281
trainer/Q1 Predictions Min       -57.062
trainer/Q2 Predictions Mean      -11.4314
trainer/Q2 Predictions Std         5.24922
trainer/Q2 Predictions Max        -9.48899
trainer/Q2 Predictions Min       -56.8327
trainer/Q Targets Mean           -11.5007
trainer/Q Targets Std              5.32989
trainer/Q Targets Max             -0.189976
trainer/Q Targets Min            -56.1913
trainer/Log Pis Mean               1.78441
trainer/Log Pis Std                1.09911
trainer/Log Pis Max                4.37528
trainer/Log Pis Min               -1.33384
trainer/Policy mu Mean             0.0097609
trainer/Policy mu Std              0.578844
trainer/Policy mu Max              2.56382
trainer/Policy mu Min             -3.18472
trainer/Policy log std Mean       -2.11388
trainer/Policy log std Std         0.342253
trainer/Policy log std Max        -0.511843
trainer/Policy log std Min        -2.56004
trainer/Alpha                      0.0474386
trainer/Alpha Loss                -0.657181
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.297994
exploration/Rewards Std            0.884529
exploration/Rewards Max           -0.00407833
exploration/Rewards Min           -8.23295
exploration/Returns Mean         -29.7994
exploration/Returns Std           12.5001
exploration/Returns Max          -14.6639
exploration/Returns Min          -48.8885
exploration/Actions Mean           0.00537969
exploration/Actions Std            0.231884
exploration/Actions Max            0.998431
exploration/Actions Min           -0.997826
exploration/Num Paths              5
exploration/Average Returns      -29.7994
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.169142
evaluation/Rewards Std             0.705777
evaluation/Rewards Max            -0.0122674
evaluation/Rewards Min            -7.98901
evaluation/Returns Mean          -16.9142
evaluation/Returns Std             8.90405
evaluation/Returns Max            -3.71445
evaluation/Returns Min           -32.5344
evaluation/Actions Mean            0.00642702
evaluation/Actions Std             0.175415
evaluation/Actions Max             0.99494
evaluation/Actions Min            -0.994416
evaluation/Num Paths              15
evaluation/Average Returns       -16.9142
time/data storing (s)              0.00314014
time/evaluation sampling (s)       0.408917
time/exploration sampling (s)      0.165857
time/logging (s)                   0.00498679
time/saving (s)                    0.0023032
time/training (s)                  2.08897
time/epoch (s)                     2.67417
time/total (s)                   137.642
Epoch                             50
-----------------------------  --------------
2019-04-22 21:24:11.678972 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             26200
trainer/QF1 Loss                   0.0578923
trainer/QF2 Loss                   0.0584978
trainer/Policy Loss               14.8351
trainer/Q1 Predictions Mean      -13.2493
trainer/Q1 Predictions Std         9.86715
trainer/Q1 Predictions Max        -9.31604
trainer/Q1 Predictions Min       -72.9986
trainer/Q2 Predictions Mean      -13.2047
trainer/Q2 Predictions Std         9.82419
trainer/Q2 Predictions Max        -9.28452
trainer/Q2 Predictions Min       -73.6012
trainer/Q Targets Mean           -13.363
trainer/Q Targets Std              9.78655
trainer/Q Targets Max             -9.42141
trainer/Q Targets Min            -73.4657
trainer/Log Pis Mean               2.02785
trainer/Log Pis Std                1.52267
trainer/Log Pis Max                6.65764
trainer/Log Pis Min               -2.22287
trainer/Policy mu Mean            -0.0448459
trainer/Policy mu Std              0.809824
trainer/Policy mu Max              3.29287
trainer/Policy mu Min             -3.23017
trainer/Policy log std Mean       -2.03753
trainer/Policy log std Std         0.462532
trainer/Policy log std Max        -0.5195
trainer/Policy log std Min        -2.49798
trainer/Alpha                      0.0508058
trainer/Alpha Loss                 0.082996
exploration/num steps total    26200
exploration/num paths total      262
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.487425
exploration/Rewards Std            1.45653
exploration/Rewards Max           -0.00506744
exploration/Rewards Min          -11.198
exploration/Returns Mean         -48.7425
exploration/Returns Std           17.9787
exploration/Returns Max          -22.8926
exploration/Returns Min          -71.9259
exploration/Actions Mean          -0.0241646
exploration/Actions Std            0.283687
exploration/Actions Max            0.998993
exploration/Actions Min           -0.999747
exploration/Num Paths              5
exploration/Average Returns      -48.7425
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.278435
evaluation/Rewards Std             1.20191
evaluation/Rewards Max            -0.00507111
evaluation/Rewards Min           -11.3227
evaluation/Returns Mean          -27.8435
evaluation/Returns Std            17.0404
evaluation/Returns Max            -8.76325
evaluation/Returns Min           -61.4825
evaluation/Actions Mean           -0.0231134
evaluation/Actions Std             0.205852
evaluation/Actions Max             0.996337
evaluation/Actions Min            -0.997333
evaluation/Num Paths              15
evaluation/Average Returns       -27.8435
time/data storing (s)              0.00506224
time/evaluation sampling (s)       0.354191
time/exploration sampling (s)      0.159423
time/logging (s)                   0.00525296
time/saving (s)                    0.00942028
time/training (s)                  2.10201
time/epoch (s)                     2.63535
time/total (s)                   140.282
Epoch                             51
-----------------------------  --------------
2019-04-22 21:24:14.404928 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             26700
trainer/QF1 Loss                   1.45672
trainer/QF2 Loss                   1.48058
trainer/Policy Loss               14.5088
trainer/Q1 Predictions Mean      -12.7146
trainer/Q1 Predictions Std         9.36176
trainer/Q1 Predictions Max        -9.25357
trainer/Q1 Predictions Min       -65.942
trainer/Q2 Predictions Mean      -12.7281
trainer/Q2 Predictions Std         9.40089
trainer/Q2 Predictions Max        -9.22914
trainer/Q2 Predictions Min       -66.8051
trainer/Q Targets Mean           -12.8744
trainer/Q Targets Std              9.72877
trainer/Q Targets Max             -0.0867329
trainer/Q Targets Min            -68.7135
trainer/Log Pis Mean               2.07186
trainer/Log Pis Std                1.50859
trainer/Log Pis Max                7.79638
trainer/Log Pis Min               -1.5646
trainer/Policy mu Mean             0.0889057
trainer/Policy mu Std              0.77282
trainer/Policy mu Max              3.19008
trainer/Policy mu Min             -3.14174
trainer/Policy log std Mean       -2.03048
trainer/Policy log std Std         0.452053
trainer/Policy log std Max        -0.425849
trainer/Policy log std Min        -2.45409
trainer/Alpha                      0.0532123
trainer/Alpha Loss                 0.210786
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.291249
exploration/Rewards Std            0.785484
exploration/Rewards Max           -0.00948135
exploration/Rewards Min           -7.00137
exploration/Returns Mean         -29.1249
exploration/Returns Std            8.75895
exploration/Returns Max          -16.0911
exploration/Returns Min          -40.5342
exploration/Actions Mean          -0.00913935
exploration/Actions Std            0.239425
exploration/Actions Max            0.998484
exploration/Actions Min           -0.996433
exploration/Num Paths              5
exploration/Average Returns      -29.1249
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.264877
evaluation/Rewards Std             1.08206
evaluation/Rewards Max            -0.00882039
evaluation/Rewards Min           -10.2178
evaluation/Returns Mean          -26.4877
evaluation/Returns Std            16.1759
evaluation/Returns Max            -6.38515
evaluation/Returns Min           -60.6562
evaluation/Actions Mean            0.0147617
evaluation/Actions Std             0.204075
evaluation/Actions Max             0.996484
evaluation/Actions Min            -0.997012
evaluation/Num Paths              15
evaluation/Average Returns       -26.4877
time/data storing (s)              0.00311127
time/evaluation sampling (s)       0.367887
time/exploration sampling (s)      0.163072
time/logging (s)                   0.00507904
time/saving (s)                    0.00231744
time/training (s)                  2.17795
time/epoch (s)                     2.71942
time/total (s)                   143.006
Epoch                             52
-----------------------------  --------------
2019-04-22 21:24:17.071224 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             27200
trainer/QF1 Loss                   0.0380613
trainer/QF2 Loss                   0.0265126
trainer/Policy Loss               12.5203
trainer/Q1 Predictions Mean      -10.9785
trainer/Q1 Predictions Std         2.96421
trainer/Q1 Predictions Max        -8.99294
trainer/Q1 Predictions Min       -26.9024
trainer/Q2 Predictions Mean      -10.995
trainer/Q2 Predictions Std         3.00193
trainer/Q2 Predictions Max        -8.99469
trainer/Q2 Predictions Min       -26.9954
trainer/Q Targets Mean           -11.1052
trainer/Q Targets Std              2.96283
trainer/Q Targets Max             -9.10325
trainer/Q Targets Min            -27.0495
trainer/Log Pis Mean               1.79093
trainer/Log Pis Std                1.39147
trainer/Log Pis Max                5.05397
trainer/Log Pis Min               -3.28476
trainer/Policy mu Mean             0.0579678
trainer/Policy mu Std              0.663621
trainer/Policy mu Max              2.93555
trainer/Policy mu Min             -2.892
trainer/Policy log std Mean       -2.06986
trainer/Policy log std Std         0.4251
trainer/Policy log std Max        -0.508378
trainer/Policy log std Min        -2.52559
trainer/Alpha                      0.0521622
trainer/Alpha Loss                -0.61744
exploration/num steps total    27200
exploration/num paths total      272
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.381363
exploration/Rewards Std            1.21667
exploration/Rewards Max           -0.00783383
exploration/Rewards Min          -10.1673
exploration/Returns Mean         -38.1363
exploration/Returns Std           20.0485
exploration/Returns Max          -12.7859
exploration/Returns Min          -69.2543
exploration/Actions Mean           0.0337718
exploration/Actions Std            0.237895
exploration/Actions Max            0.998689
exploration/Actions Min           -0.99146
exploration/Num Paths              5
exploration/Average Returns      -38.1363
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.314184
evaluation/Rewards Std             1.14575
evaluation/Rewards Max            -0.0248689
evaluation/Rewards Min           -10.1805
evaluation/Returns Mean          -31.4184
evaluation/Returns Std            16.4941
evaluation/Returns Max            -7.06623
evaluation/Returns Min           -62.5704
evaluation/Actions Mean            0.00408537
evaluation/Actions Std             0.207205
evaluation/Actions Max             0.995903
evaluation/Actions Min            -0.99751
evaluation/Num Paths              15
evaluation/Average Returns       -31.4184
time/data storing (s)              0.00321828
time/evaluation sampling (s)       0.360702
time/exploration sampling (s)      0.163386
time/logging (s)                   0.00515073
time/saving (s)                    0.00204869
time/training (s)                  2.12573
time/epoch (s)                     2.66024
time/total (s)                   145.671
Epoch                             53
-----------------------------  --------------
2019-04-22 21:24:19.743408 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             27700
trainer/QF1 Loss                   3.98547
trainer/QF2 Loss                   4.00396
trainer/Policy Loss               12.788
trainer/Q1 Predictions Mean      -11.1529
trainer/Q1 Predictions Std         6.69018
trainer/Q1 Predictions Max        -8.86941
trainer/Q1 Predictions Min       -72.8889
trainer/Q2 Predictions Mean      -11.1704
trainer/Q2 Predictions Std         6.71885
trainer/Q2 Predictions Max        -8.904
trainer/Q2 Predictions Min       -73.3074
trainer/Q Targets Mean           -10.9112
trainer/Q Targets Std              7.14646
trainer/Q Targets Max             -0.0153609
trainer/Q Targets Min            -74.3743
trainer/Log Pis Mean               1.92191
trainer/Log Pis Std                1.51482
trainer/Log Pis Max                8.50368
trainer/Log Pis Min               -3.56189
trainer/Policy mu Mean             0.0775485
trainer/Policy mu Std              0.602705
trainer/Policy mu Max              3.23644
trainer/Policy mu Min             -2.27348
trainer/Policy log std Mean       -2.1527
trainer/Policy log std Std         0.35772
trainer/Policy log std Max        -0.659939
trainer/Policy log std Min        -2.4866
trainer/Alpha                      0.052478
trainer/Alpha Loss                -0.230157
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.333195
exploration/Rewards Std            0.896536
exploration/Rewards Max           -0.00378657
exploration/Rewards Min           -7.257
exploration/Returns Mean         -33.3195
exploration/Returns Std            7.26952
exploration/Returns Max          -20.8243
exploration/Returns Min          -43.3715
exploration/Actions Mean          -0.00103941
exploration/Actions Std            0.259809
exploration/Actions Max            0.998417
exploration/Actions Min           -0.997821
exploration/Num Paths              5
exploration/Average Returns      -33.3195
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.286008
evaluation/Rewards Std             1.13172
evaluation/Rewards Max            -0.0438798
evaluation/Rewards Min           -11.147
evaluation/Returns Mean          -28.6008
evaluation/Returns Std            19.3579
evaluation/Returns Max            -4.60072
evaluation/Returns Min           -64.281
evaluation/Actions Mean            0.00045018
evaluation/Actions Std             0.20415
evaluation/Actions Max             0.99693
evaluation/Actions Min            -0.998157
evaluation/Num Paths              15
evaluation/Average Returns       -28.6008
time/data storing (s)              0.00331679
time/evaluation sampling (s)       0.353596
time/exploration sampling (s)      0.164055
time/logging (s)                   0.00502508
time/saving (s)                    0.00239843
time/training (s)                  2.13736
time/epoch (s)                     2.66575
time/total (s)                   148.342
Epoch                             54
-----------------------------  --------------
2019-04-22 21:24:22.366735 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             28200
trainer/QF1 Loss                   0.0539157
trainer/QF2 Loss                   0.02963
trainer/Policy Loss               13.7919
trainer/Q1 Predictions Mean      -12.0716
trainer/Q1 Predictions Std         6.42969
trainer/Q1 Predictions Max        -8.85706
trainer/Q1 Predictions Min       -56.4325
trainer/Q2 Predictions Mean      -12.0936
trainer/Q2 Predictions Std         6.35454
trainer/Q2 Predictions Max        -8.97776
trainer/Q2 Predictions Min       -55.6603
trainer/Q Targets Mean           -12.0171
trainer/Q Targets Std              6.28941
trainer/Q Targets Max             -8.84133
trainer/Q Targets Min            -55.0476
trainer/Log Pis Mean               2.19421
trainer/Log Pis Std                1.38701
trainer/Log Pis Max                6.63196
trainer/Log Pis Min               -0.993489
trainer/Policy mu Mean             0.00182186
trainer/Policy mu Std              0.769348
trainer/Policy mu Max              2.95863
trainer/Policy mu Min             -3.08159
trainer/Policy log std Mean       -2.08156
trainer/Policy log std Std         0.465891
trainer/Policy log std Max        -0.5439
trainer/Policy log std Min        -2.58561
trainer/Alpha                      0.0508664
trainer/Alpha Loss                 0.578496
exploration/num steps total    28200
exploration/num paths total      282
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.307929
exploration/Rewards Std            0.940037
exploration/Rewards Max           -0.00534764
exploration/Rewards Min           -9.92934
exploration/Returns Mean         -30.7929
exploration/Returns Std           16.4259
exploration/Returns Max          -15.7701
exploration/Returns Min          -62.4283
exploration/Actions Mean          -0.0129663
exploration/Actions Std            0.247342
exploration/Actions Max            0.989787
exploration/Actions Min           -0.99906
exploration/Num Paths              5
exploration/Average Returns      -30.7929
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.23177
evaluation/Rewards Std             0.981656
evaluation/Rewards Max            -0.02307
evaluation/Rewards Min           -10.4163
evaluation/Returns Mean          -23.177
evaluation/Returns Std            15.6881
evaluation/Returns Max            -4.40595
evaluation/Returns Min           -61.4282
evaluation/Actions Mean            0.0195642
evaluation/Actions Std             0.184721
evaluation/Actions Max             0.996894
evaluation/Actions Min            -0.99527
evaluation/Num Paths              15
evaluation/Average Returns       -23.177
time/data storing (s)              0.00312595
time/evaluation sampling (s)       0.356593
time/exploration sampling (s)      0.161165
time/logging (s)                   0.00508472
time/saving (s)                    0.00224515
time/training (s)                  2.08955
time/epoch (s)                     2.61776
time/total (s)                   150.963
Epoch                             55
-----------------------------  --------------
2019-04-22 21:24:25.058583 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             28700
trainer/QF1 Loss                   0.0366571
trainer/QF2 Loss                   0.0540111
trainer/Policy Loss               13.365
trainer/Q1 Predictions Mean      -11.5852
trainer/Q1 Predictions Std         6.07613
trainer/Q1 Predictions Max        -8.74216
trainer/Q1 Predictions Min       -47.3939
trainer/Q2 Predictions Mean      -11.5937
trainer/Q2 Predictions Std         6.0495
trainer/Q2 Predictions Max        -8.82
trainer/Q2 Predictions Min       -46.6689
trainer/Q Targets Mean           -11.5262
trainer/Q Targets Std              6.05468
trainer/Q Targets Max             -8.70319
trainer/Q Targets Min            -47.2405
trainer/Log Pis Mean               1.98473
trainer/Log Pis Std                1.24792
trainer/Log Pis Max                6.75448
trainer/Log Pis Min               -1.93385
trainer/Policy mu Mean            -0.0150318
trainer/Policy mu Std              0.703746
trainer/Policy mu Max              2.83797
trainer/Policy mu Min             -3.16092
trainer/Policy log std Mean       -2.06836
trainer/Policy log std Std         0.444237
trainer/Policy log std Max        -0.486595
trainer/Policy log std Min        -2.49262
trainer/Alpha                      0.0512144
trainer/Alpha Loss                -0.0453682
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.286789
exploration/Rewards Std            0.835072
exploration/Rewards Max           -0.00288141
exploration/Rewards Min           -8.50521
exploration/Returns Mean         -28.6789
exploration/Returns Std           13.8838
exploration/Returns Max          -12.1397
exploration/Returns Min          -50.3444
exploration/Actions Mean          -0.00669749
exploration/Actions Std            0.236501
exploration/Actions Max            0.994745
exploration/Actions Min           -0.999344
exploration/Num Paths              5
exploration/Average Returns      -28.6789
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.194821
evaluation/Rewards Std             0.848503
evaluation/Rewards Max            -0.0341419
evaluation/Rewards Min            -9.90937
evaluation/Returns Mean          -19.4821
evaluation/Returns Std            17.4636
evaluation/Returns Max            -4.65583
evaluation/Returns Min           -61.1214
evaluation/Actions Mean           -0.0027149
evaluation/Actions Std             0.163156
evaluation/Actions Max             0.995959
evaluation/Actions Min            -0.997739
evaluation/Num Paths              15
evaluation/Average Returns       -19.4821
time/data storing (s)              0.00312861
time/evaluation sampling (s)       0.35352
time/exploration sampling (s)      0.158418
time/logging (s)                   0.00497614
time/saving (s)                    0.00200456
time/training (s)                  2.16373
time/epoch (s)                     2.68578
time/total (s)                   153.654
Epoch                             56
-----------------------------  --------------
2019-04-22 21:24:27.737026 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             29200
trainer/QF1 Loss                   0.147921
trainer/QF2 Loss                   0.173981
trainer/Policy Loss               12.7294
trainer/Q1 Predictions Mean      -11.1276
trainer/Q1 Predictions Std         7.87975
trainer/Q1 Predictions Max        -8.62513
trainer/Q1 Predictions Min       -63.6072
trainer/Q2 Predictions Mean      -11.0829
trainer/Q2 Predictions Std         7.84554
trainer/Q2 Predictions Max        -8.59461
trainer/Q2 Predictions Min       -63.8019
trainer/Q Targets Mean           -11.295
trainer/Q Targets Std              8.12706
trainer/Q Targets Max             -8.68056
trainer/Q Targets Min            -65.8915
trainer/Log Pis Mean               2.08016
trainer/Log Pis Std                1.33671
trainer/Log Pis Max                8.70358
trainer/Log Pis Min               -2.2249
trainer/Policy mu Mean             0.0723612
trainer/Policy mu Std              0.664435
trainer/Policy mu Max              3.24344
trainer/Policy mu Min             -3.07706
trainer/Policy log std Mean       -2.07647
trainer/Policy log std Std         0.413486
trainer/Policy log std Max        -0.40677
trainer/Policy log std Min        -2.44091
trainer/Alpha                      0.0497289
trainer/Alpha Loss                 0.240559
exploration/num steps total    29200
exploration/num paths total      292
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.347532
exploration/Rewards Std            1.01315
exploration/Rewards Max           -0.00792543
exploration/Rewards Min           -9.96862
exploration/Returns Mean         -34.7532
exploration/Returns Std           20.095
exploration/Returns Max          -16.0411
exploration/Returns Min          -70.5476
exploration/Actions Mean          -0.00459752
exploration/Actions Std            0.226756
exploration/Actions Max            0.999118
exploration/Actions Min           -0.998796
exploration/Num Paths              5
exploration/Average Returns      -34.7532
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.332467
evaluation/Rewards Std             1.08394
evaluation/Rewards Max            -0.0643905
evaluation/Rewards Min           -10.0085
evaluation/Returns Mean          -33.2467
evaluation/Returns Std            16.0453
evaluation/Returns Max           -14.0673
evaluation/Returns Min           -66.4858
evaluation/Actions Mean            0.00269868
evaluation/Actions Std             0.20296
evaluation/Actions Max             0.997135
evaluation/Actions Min            -0.995703
evaluation/Num Paths              15
evaluation/Average Returns       -33.2467
time/data storing (s)              0.00334045
time/evaluation sampling (s)       0.359062
time/exploration sampling (s)      0.16319
time/logging (s)                   0.00486385
time/saving (s)                    0.00198505
time/training (s)                  2.1397
time/epoch (s)                     2.67215
time/total (s)                   156.331
Epoch                             57
-----------------------------  --------------
2019-04-22 21:24:30.461205 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             29700
trainer/QF1 Loss                   0.0723713
trainer/QF2 Loss                   0.0949776
trainer/Policy Loss               12.5872
trainer/Q1 Predictions Mean      -10.9136
trainer/Q1 Predictions Std         5.62483
trainer/Q1 Predictions Max        -8.41037
trainer/Q1 Predictions Min       -57.0496
trainer/Q2 Predictions Mean      -10.9945
trainer/Q2 Predictions Std         5.6997
trainer/Q2 Predictions Max        -8.54298
trainer/Q2 Predictions Min       -57.633
trainer/Q Targets Mean           -11.029
trainer/Q Targets Std              5.50586
trainer/Q Targets Max             -8.5904
trainer/Q Targets Min            -56.8797
trainer/Log Pis Mean               1.80479
trainer/Log Pis Std                1.56523
trainer/Log Pis Max                6.96235
trainer/Log Pis Min               -5.38955
trainer/Policy mu Mean            -0.0119669
trainer/Policy mu Std              0.686329
trainer/Policy mu Max              2.91093
trainer/Policy mu Min             -3.17408
trainer/Policy log std Mean       -2.0635
trainer/Policy log std Std         0.425622
trainer/Policy log std Max        -0.486209
trainer/Policy log std Min        -2.42238
trainer/Alpha                      0.0495008
trainer/Alpha Loss                -0.586772
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.322382
exploration/Rewards Std            0.858702
exploration/Rewards Max           -0.0118368
exploration/Rewards Min           -8.62824
exploration/Returns Mean         -32.2382
exploration/Returns Std           14.0596
exploration/Returns Max          -18.165
exploration/Returns Min          -58.7269
exploration/Actions Mean           0.0164682
exploration/Actions Std            0.235547
exploration/Actions Max            0.999235
exploration/Actions Min           -0.995352
exploration/Num Paths              5
exploration/Average Returns      -32.2382
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.254178
evaluation/Rewards Std             0.91758
evaluation/Rewards Max            -0.0309728
evaluation/Rewards Min           -10.119
evaluation/Returns Mean          -25.4178
evaluation/Returns Std            16.4809
evaluation/Returns Max            -5.72314
evaluation/Returns Min           -61.8255
evaluation/Actions Mean           -0.00428638
evaluation/Actions Std             0.189937
evaluation/Actions Max             0.996587
evaluation/Actions Min            -0.998395
evaluation/Num Paths              15
evaluation/Average Returns       -25.4178
time/data storing (s)              0.00336005
time/evaluation sampling (s)       0.390186
time/exploration sampling (s)      0.170152
time/logging (s)                   0.00515126
time/saving (s)                    0.00203529
time/training (s)                  2.14783
time/epoch (s)                     2.71871
time/total (s)                   159.053
Epoch                             58
-----------------------------  --------------
2019-04-22 21:24:33.220277 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             30200
trainer/QF1 Loss                   1.80083
trainer/QF2 Loss                   1.86469
trainer/Policy Loss               12.4661
trainer/Q1 Predictions Mean      -10.7583
trainer/Q1 Predictions Std         3.69758
trainer/Q1 Predictions Max        -8.44237
trainer/Q1 Predictions Min       -31.2351
trainer/Q2 Predictions Mean      -10.7774
trainer/Q2 Predictions Std         3.73933
trainer/Q2 Predictions Max        -8.52168
trainer/Q2 Predictions Min       -32.1056
trainer/Q Targets Mean           -10.6285
trainer/Q Targets Std              3.87889
trainer/Q Targets Max             -0.158238
trainer/Q Targets Min            -30.3516
trainer/Log Pis Mean               2.06362
trainer/Log Pis Std                1.07733
trainer/Log Pis Max                5.52319
trainer/Log Pis Min               -1.67517
trainer/Policy mu Mean             0.047179
trainer/Policy mu Std              0.673841
trainer/Policy mu Max              3.19652
trainer/Policy mu Min             -2.80345
trainer/Policy log std Mean       -2.14907
trainer/Policy log std Std         0.404704
trainer/Policy log std Max        -0.487314
trainer/Policy log std Min        -2.49978
trainer/Alpha                      0.0515217
trainer/Alpha Loss                 0.188701
exploration/num steps total    30200
exploration/num paths total      302
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.19183
exploration/Rewards Std            0.407322
exploration/Rewards Max           -0.0136425
exploration/Rewards Min           -4.90422
exploration/Returns Mean         -19.183
exploration/Returns Std            4.33984
exploration/Returns Max          -13.2014
exploration/Returns Min          -25.8307
exploration/Actions Mean           0.0134601
exploration/Actions Std            0.201452
exploration/Actions Max            0.99778
exploration/Actions Min           -0.960101
exploration/Num Paths              5
exploration/Average Returns      -19.183
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.271226
evaluation/Rewards Std             1.10779
evaluation/Rewards Max            -0.0173755
evaluation/Rewards Min           -10.5776
evaluation/Returns Mean          -27.1226
evaluation/Returns Std            17.3428
evaluation/Returns Max            -3.73844
evaluation/Returns Min           -56.7419
evaluation/Actions Mean            0.0103746
evaluation/Actions Std             0.201853
evaluation/Actions Max             0.99648
evaluation/Actions Min            -0.997969
evaluation/Num Paths              15
evaluation/Average Returns       -27.1226
time/data storing (s)              0.00353903
time/evaluation sampling (s)       0.388601
time/exploration sampling (s)      0.159688
time/logging (s)                   0.0052986
time/saving (s)                    0.001727
time/training (s)                  2.19507
time/epoch (s)                     2.75393
time/total (s)                   161.811
Epoch                             59
-----------------------------  --------------
2019-04-22 21:24:35.881661 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             30700
trainer/QF1 Loss                   0.0965865
trainer/QF2 Loss                   0.0646664
trainer/Policy Loss               12.3033
trainer/Q1 Predictions Mean      -10.656
trainer/Q1 Predictions Std         5.97011
trainer/Q1 Predictions Max        -8.13881
trainer/Q1 Predictions Min       -50.8121
trainer/Q2 Predictions Mean      -10.7035
trainer/Q2 Predictions Std         5.84853
trainer/Q2 Predictions Max        -8.28549
trainer/Q2 Predictions Min       -50.2348
trainer/Q Targets Mean           -10.8323
trainer/Q Targets Std              5.80342
trainer/Q Targets Max             -8.33806
trainer/Q Targets Min            -50.3953
trainer/Log Pis Mean               1.94469
trainer/Log Pis Std                1.47735
trainer/Log Pis Max                8.5415
trainer/Log Pis Min               -1.93481
trainer/Policy mu Mean            -0.0136509
trainer/Policy mu Std              0.701568
trainer/Policy mu Max              2.86185
trainer/Policy mu Min             -3.22289
trainer/Policy log std Mean       -2.09222
trainer/Policy log std Std         0.414861
trainer/Policy log std Max        -0.396947
trainer/Policy log std Min        -2.48292
trainer/Alpha                      0.0512707
trainer/Alpha Loss                -0.16431
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.358202
exploration/Rewards Std            1.1113
exploration/Rewards Max           -0.00810022
exploration/Rewards Min           -9.86671
exploration/Returns Mean         -35.8202
exploration/Returns Std           19.98
exploration/Returns Max          -18.0282
exploration/Returns Min          -63.3194
exploration/Actions Mean           0.0141482
exploration/Actions Std            0.236257
exploration/Actions Max            0.998148
exploration/Actions Min           -0.998112
exploration/Num Paths              5
exploration/Average Returns      -35.8202
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.243827
evaluation/Rewards Std             0.977126
evaluation/Rewards Max            -0.0550463
evaluation/Rewards Min           -10.6986
evaluation/Returns Mean          -24.3827
evaluation/Returns Std            18.8731
evaluation/Returns Max            -7.06787
evaluation/Returns Min           -64.4498
evaluation/Actions Mean            0.00967116
evaluation/Actions Std             0.187198
evaluation/Actions Max             0.996537
evaluation/Actions Min            -0.997466
evaluation/Num Paths              15
evaluation/Average Returns       -24.3827
time/data storing (s)              0.00329818
time/evaluation sampling (s)       0.370617
time/exploration sampling (s)      0.172114
time/logging (s)                   0.00489165
time/saving (s)                    0.0020627
time/training (s)                  2.10224
time/epoch (s)                     2.65523
time/total (s)                   164.471
Epoch                             60
-----------------------------  --------------
2019-04-22 21:24:38.596502 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 61 finished
-----------------------------  ---------------
replay_buffer/size             31200
trainer/QF1 Loss                   0.144805
trainer/QF2 Loss                   0.0929843
trainer/Policy Loss               13.1768
trainer/Q1 Predictions Mean      -11.5255
trainer/Q1 Predictions Std         8.56139
trainer/Q1 Predictions Max        -7.85592
trainer/Q1 Predictions Min       -61.4955
trainer/Q2 Predictions Mean      -11.5965
trainer/Q2 Predictions Std         8.51251
trainer/Q2 Predictions Max        -8.04069
trainer/Q2 Predictions Min       -61.167
trainer/Q Targets Mean           -11.7632
trainer/Q Targets Std              8.47791
trainer/Q Targets Max             -8.1746
trainer/Q Targets Min            -61.8316
trainer/Log Pis Mean               1.97225
trainer/Log Pis Std                1.53372
trainer/Log Pis Max                8.28608
trainer/Log Pis Min               -4.69186
trainer/Policy mu Mean             0.0199714
trainer/Policy mu Std              0.789291
trainer/Policy mu Max              3.32827
trainer/Policy mu Min             -2.95399
trainer/Policy log std Mean       -2.10722
trainer/Policy log std Std         0.446684
trainer/Policy log std Max        -0.393111
trainer/Policy log std Min        -2.46677
trainer/Alpha                      0.0531858
trainer/Alpha Loss                -0.0814197
exploration/num steps total    31200
exploration/num paths total      312
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.271449
exploration/Rewards Std            0.704218
exploration/Rewards Max           -0.00704565
exploration/Rewards Min           -6.43825
exploration/Returns Mean         -27.1449
exploration/Returns Std            7.54856
exploration/Returns Max          -16.8589
exploration/Returns Min          -36.9948
exploration/Actions Mean          -0.001625
exploration/Actions Std            0.229363
exploration/Actions Max            0.99779
exploration/Actions Min           -0.999716
exploration/Num Paths              5
exploration/Average Returns      -27.1449
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.25573
evaluation/Rewards Std             0.937559
evaluation/Rewards Max            -0.0538276
evaluation/Rewards Min           -10.6933
evaluation/Returns Mean          -25.573
evaluation/Returns Std            15.357
evaluation/Returns Max            -5.9937
evaluation/Returns Min           -60.5088
evaluation/Actions Mean            0.000834715
evaluation/Actions Std             0.193524
evaluation/Actions Max             0.995465
evaluation/Actions Min            -0.996997
evaluation/Num Paths              15
evaluation/Average Returns       -25.573
time/data storing (s)              0.00319296
time/evaluation sampling (s)       0.366778
time/exploration sampling (s)      0.170343
time/logging (s)                   0.00555059
time/saving (s)                    0.00222473
time/training (s)                  2.16081
time/epoch (s)                     2.7089
time/total (s)                   167.185
Epoch                             61
-----------------------------  ---------------
2019-04-22 21:24:41.255359 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             31700
trainer/QF1 Loss                   1.26589
trainer/QF2 Loss                   1.20803
trainer/Policy Loss               12.1272
trainer/Q1 Predictions Mean      -10.6803
trainer/Q1 Predictions Std         5.93779
trainer/Q1 Predictions Max        -8.01634
trainer/Q1 Predictions Min       -58.4196
trainer/Q2 Predictions Mean      -10.7051
trainer/Q2 Predictions Std         5.93277
trainer/Q2 Predictions Max        -8.10672
trainer/Q2 Predictions Min       -58.2553
trainer/Q Targets Mean           -10.7677
trainer/Q Targets Std              6.18374
trainer/Q Targets Max             -1.08704
trainer/Q Targets Min            -60.3375
trainer/Log Pis Mean               1.69442
trainer/Log Pis Std                1.30469
trainer/Log Pis Max                5.3359
trainer/Log Pis Min               -2.84797
trainer/Policy mu Mean            -0.0292002
trainer/Policy mu Std              0.664521
trainer/Policy mu Max              3.13131
trainer/Policy mu Min             -2.89031
trainer/Policy log std Mean       -2.02889
trainer/Policy log std Std         0.405199
trainer/Policy log std Max        -0.528971
trainer/Policy log std Min        -2.47883
trainer/Alpha                      0.0532801
trainer/Alpha Loss                -0.895993
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.374357
exploration/Rewards Std            1.09347
exploration/Rewards Max           -0.0120299
exploration/Rewards Min          -10.9677
exploration/Returns Mean         -37.4357
exploration/Returns Std           21.4688
exploration/Returns Max          -20.6214
exploration/Returns Min          -73.5073
exploration/Actions Mean          -0.0148604
exploration/Actions Std            0.250176
exploration/Actions Max            0.999374
exploration/Actions Min           -0.999364
exploration/Num Paths              5
exploration/Average Returns      -37.4357
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.301243
evaluation/Rewards Std             1.14622
evaluation/Rewards Max            -0.0177832
evaluation/Rewards Min            -9.79045
evaluation/Returns Mean          -30.1243
evaluation/Returns Std            16.1935
evaluation/Returns Max            -9.87481
evaluation/Returns Min           -61.8151
evaluation/Actions Mean            0.0197609
evaluation/Actions Std             0.204366
evaluation/Actions Max             0.99627
evaluation/Actions Min            -0.996031
evaluation/Num Paths              15
evaluation/Average Returns       -30.1243
time/data storing (s)              0.00332649
time/evaluation sampling (s)       0.360211
time/exploration sampling (s)      0.163246
time/logging (s)                   0.00359302
time/saving (s)                    0.00175633
time/training (s)                  2.11871
time/epoch (s)                     2.65085
time/total (s)                   169.84
Epoch                             62
-----------------------------  --------------
2019-04-22 21:24:43.949675 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             32200
trainer/QF1 Loss                   1.06398
trainer/QF2 Loss                   1.07276
trainer/Policy Loss               12.6955
trainer/Q1 Predictions Mean      -10.8829
trainer/Q1 Predictions Std         7.07175
trainer/Q1 Predictions Max        -7.9203
trainer/Q1 Predictions Min       -60.6814
trainer/Q2 Predictions Mean      -10.901
trainer/Q2 Predictions Std         7.05902
trainer/Q2 Predictions Max        -8.00364
trainer/Q2 Predictions Min       -60.7389
trainer/Q Targets Mean           -10.8572
trainer/Q Targets Std              7.08168
trainer/Q Targets Max             -0.5199
trainer/Q Targets Min            -60.489
trainer/Log Pis Mean               2.16821
trainer/Log Pis Std                1.29243
trainer/Log Pis Max                7.69563
trainer/Log Pis Min               -1.88795
trainer/Policy mu Mean            -0.0248179
trainer/Policy mu Std              0.708896
trainer/Policy mu Max              3.15815
trainer/Policy mu Min             -2.96286
trainer/Policy log std Mean       -2.13388
trainer/Policy log std Std         0.437101
trainer/Policy log std Max        -0.590736
trainer/Policy log std Min        -2.54782
trainer/Alpha                      0.0541943
trainer/Alpha Loss                 0.490362
exploration/num steps total    32200
exploration/num paths total      322
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.363306
exploration/Rewards Std            1.06537
exploration/Rewards Max           -0.00656737
exploration/Rewards Min           -8.78927
exploration/Returns Mean         -36.3306
exploration/Returns Std           10.7776
exploration/Returns Max          -22.6217
exploration/Returns Min          -53.201
exploration/Actions Mean           0.00228635
exploration/Actions Std            0.247879
exploration/Actions Max            0.999418
exploration/Actions Min           -0.999548
exploration/Num Paths              5
exploration/Average Returns      -36.3306
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.126475
evaluation/Rewards Std             0.544508
evaluation/Rewards Max            -0.0255988
evaluation/Rewards Min            -7.76273
evaluation/Returns Mean          -12.6475
evaluation/Returns Std             7.81841
evaluation/Returns Max            -4.7443
evaluation/Returns Min           -37.1832
evaluation/Actions Mean            0.00763078
evaluation/Actions Std             0.154932
evaluation/Actions Max             0.995548
evaluation/Actions Min            -0.992205
evaluation/Num Paths              15
evaluation/Average Returns       -12.6475
time/data storing (s)              0.00324514
time/evaluation sampling (s)       0.349647
time/exploration sampling (s)      0.194324
time/logging (s)                   0.00388538
time/saving (s)                    0.00161195
time/training (s)                  2.13605
time/epoch (s)                     2.68876
time/total (s)                   172.533
Epoch                             63
-----------------------------  --------------
2019-04-22 21:24:46.562701 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             32700
trainer/QF1 Loss                   1.33083
trainer/QF2 Loss                   1.23412
trainer/Policy Loss               13.1563
trainer/Q1 Predictions Mean      -11.8449
trainer/Q1 Predictions Std         9.04603
trainer/Q1 Predictions Max        -7.87383
trainer/Q1 Predictions Min       -77.2749
trainer/Q2 Predictions Mean      -11.8596
trainer/Q2 Predictions Std         9.14147
trainer/Q2 Predictions Max        -7.88676
trainer/Q2 Predictions Min       -78.631
trainer/Q Targets Mean           -11.8617
trainer/Q Targets Std              9.02284
trainer/Q Targets Max             -0.32154
trainer/Q Targets Min            -79.0537
trainer/Log Pis Mean               1.9582
trainer/Log Pis Std                1.34028
trainer/Log Pis Max                7.21392
trainer/Log Pis Min               -1.58785
trainer/Policy mu Mean             0.0412273
trainer/Policy mu Std              0.844083
trainer/Policy mu Max              3.2513
trainer/Policy mu Min             -3.24703
trainer/Policy log std Mean       -2.00607
trainer/Policy log std Std         0.464353
trainer/Policy log std Max        -0.527431
trainer/Policy log std Min        -2.45895
trainer/Alpha                      0.0528981
trainer/Alpha Loss                -0.122865
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.376626
exploration/Rewards Std            1.16351
exploration/Rewards Max           -0.00471406
exploration/Rewards Min           -9.46785
exploration/Returns Mean         -37.6626
exploration/Returns Std           18.7911
exploration/Returns Max          -14.7504
exploration/Returns Min          -61.9287
exploration/Actions Mean           0.00608109
exploration/Actions Std            0.248032
exploration/Actions Max            0.999435
exploration/Actions Min           -0.99725
exploration/Num Paths              5
exploration/Average Returns      -37.6626
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.235176
evaluation/Rewards Std             1.01411
evaluation/Rewards Max            -0.0425703
evaluation/Rewards Min           -10.334
evaluation/Returns Mean          -23.5176
evaluation/Returns Std            20.1263
evaluation/Returns Max            -4.41067
evaluation/Returns Min           -64.5093
evaluation/Actions Mean            0.0163448
evaluation/Actions Std             0.178551
evaluation/Actions Max             0.996254
evaluation/Actions Min            -0.996855
evaluation/Num Paths              15
evaluation/Average Returns       -23.5176
time/data storing (s)              0.00315728
time/evaluation sampling (s)       0.350104
time/exploration sampling (s)      0.154388
time/logging (s)                   0.00487786
time/saving (s)                    0.00196485
time/training (s)                  2.0935
time/epoch (s)                     2.60799
time/total (s)                   175.146
Epoch                             64
-----------------------------  --------------
2019-04-22 21:24:49.239364 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             33200
trainer/QF1 Loss                   0.0384822
trainer/QF2 Loss                   0.0342697
trainer/Policy Loss               11.7239
trainer/Q1 Predictions Mean      -10.1343
trainer/Q1 Predictions Std         4.47673
trainer/Q1 Predictions Max        -7.86845
trainer/Q1 Predictions Min       -47.4091
trainer/Q2 Predictions Mean      -10.1428
trainer/Q2 Predictions Std         4.47549
trainer/Q2 Predictions Max        -7.86303
trainer/Q2 Predictions Min       -47.3715
trainer/Q Targets Mean           -10.2409
trainer/Q Targets Std              4.45423
trainer/Q Targets Max             -7.84727
trainer/Q Targets Min            -47.5169
trainer/Log Pis Mean               1.81663
trainer/Log Pis Std                1.48283
trainer/Log Pis Max                7.29206
trainer/Log Pis Min               -2.77307
trainer/Policy mu Mean             0.0832967
trainer/Policy mu Std              0.668292
trainer/Policy mu Max              3.12927
trainer/Policy mu Min             -2.5843
trainer/Policy log std Mean       -2.04461
trainer/Policy log std Std         0.390651
trainer/Policy log std Max        -0.56008
trainer/Policy log std Min        -2.407
trainer/Alpha                      0.0528309
trainer/Alpha Loss                -0.53921
exploration/num steps total    33200
exploration/num paths total      332
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.395413
exploration/Rewards Std            1.09411
exploration/Rewards Max           -0.00696187
exploration/Rewards Min           -8.92246
exploration/Returns Mean         -39.5413
exploration/Returns Std           13.4588
exploration/Returns Max          -20.3983
exploration/Returns Min          -59.3308
exploration/Actions Mean           0.0101588
exploration/Actions Std            0.256587
exploration/Actions Max            0.999487
exploration/Actions Min           -0.996365
exploration/Num Paths              5
exploration/Average Returns      -39.5413
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.295791
evaluation/Rewards Std             1.04393
evaluation/Rewards Max            -0.0146339
evaluation/Rewards Min           -10.7593
evaluation/Returns Mean          -29.5791
evaluation/Returns Std            16.2673
evaluation/Returns Max            -5.44229
evaluation/Returns Min           -71.1687
evaluation/Actions Mean            0.00192878
evaluation/Actions Std             0.202558
evaluation/Actions Max             0.99747
evaluation/Actions Min            -0.996149
evaluation/Num Paths              15
evaluation/Average Returns       -29.5791
time/data storing (s)              0.00306902
time/evaluation sampling (s)       0.356575
time/exploration sampling (s)      0.164047
time/logging (s)                   0.00513098
time/saving (s)                    0.00212597
time/training (s)                  2.13945
time/epoch (s)                     2.6704
time/total (s)                   177.821
Epoch                             65
-----------------------------  --------------
2019-04-22 21:24:51.891384 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                    0.0275683
trainer/QF2 Loss                    0.0305771
trainer/Policy Loss                12.4678
trainer/Q1 Predictions Mean       -10.8965
trainer/Q1 Predictions Std          8.26761
trainer/Q1 Predictions Max         -7.74693
trainer/Q1 Predictions Min        -68.6527
trainer/Q2 Predictions Mean       -10.9183
trainer/Q2 Predictions Std          8.22456
trainer/Q2 Predictions Max         -7.73572
trainer/Q2 Predictions Min        -68.2631
trainer/Q Targets Mean            -10.9797
trainer/Q Targets Std               8.22326
trainer/Q Targets Max              -7.80428
trainer/Q Targets Min             -68.7675
trainer/Log Pis Mean                2.06281
trainer/Log Pis Std                 1.3346
trainer/Log Pis Max                 9.04143
trainer/Log Pis Min                -0.761628
trainer/Policy mu Mean             -0.00205975
trainer/Policy mu Std               0.796585
trainer/Policy mu Max               3.00851
trainer/Policy mu Min              -3.1647
trainer/Policy log std Mean        -2.06781
trainer/Policy log std Std          0.489306
trainer/Policy log std Max         -0.497119
trainer/Policy log std Min         -2.52004
trainer/Alpha                       0.0513679
trainer/Alpha Loss                  0.186457
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.254088
exploration/Rewards Std             0.76866
exploration/Rewards Max            -0.0104008
exploration/Rewards Min            -8.67582
exploration/Returns Mean          -25.4088
exploration/Returns Std            12.3144
exploration/Returns Max           -14.6949
exploration/Returns Min           -49.0292
exploration/Actions Mean            0.00584387
exploration/Actions Std             0.231179
exploration/Actions Max             0.998549
exploration/Actions Min            -0.998812
exploration/Num Paths               5
exploration/Average Returns       -25.4088
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.162096
evaluation/Rewards Std              0.762739
evaluation/Rewards Max             -0.0193031
evaluation/Rewards Min             -8.97906
evaluation/Returns Mean           -16.2096
evaluation/Returns Std             12.395
evaluation/Returns Max             -2.42601
evaluation/Returns Min            -48.4949
evaluation/Actions Mean            -0.0103457
evaluation/Actions Std              0.174829
evaluation/Actions Max              0.996823
evaluation/Actions Min             -0.996278
evaluation/Num Paths               15
evaluation/Average Returns        -16.2096
time/data storing (s)               0.00322467
time/evaluation sampling (s)        0.351572
time/exploration sampling (s)       0.158351
time/logging (s)                    0.00497486
time/saving (s)                     0.00200523
time/training (s)                   2.12582
time/epoch (s)                      2.64594
time/total (s)                    180.471
Epoch                              66
-----------------------------  ---------------
2019-04-22 21:24:54.547648 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 67 finished
-----------------------------  ----------------
replay_buffer/size              34200
trainer/QF1 Loss                    0.0808482
trainer/QF2 Loss                    0.151755
trainer/Policy Loss                12.765
trainer/Q1 Predictions Mean       -11.1812
trainer/Q1 Predictions Std         10.3877
trainer/Q1 Predictions Max         -7.80716
trainer/Q1 Predictions Min        -76.6761
trainer/Q2 Predictions Mean       -11.1687
trainer/Q2 Predictions Std         10.538
trainer/Q2 Predictions Max         -7.71274
trainer/Q2 Predictions Min        -78.3858
trainer/Q Targets Mean            -11.234
trainer/Q Targets Std              10.3473
trainer/Q Targets Max              -7.73394
trainer/Q Targets Min             -75.5611
trainer/Log Pis Mean                1.91777
trainer/Log Pis Std                 1.47792
trainer/Log Pis Max                 7.82714
trainer/Log Pis Min                -3.14742
trainer/Policy mu Mean             -0.0633406
trainer/Policy mu Std               0.70398
trainer/Policy mu Max               3.47013
trainer/Policy mu Min              -3.15358
trainer/Policy log std Mean        -2.07859
trainer/Policy log std Std          0.432204
trainer/Policy log std Max         -0.601569
trainer/Policy log std Min         -2.50393
trainer/Alpha                       0.0504696
trainer/Alpha Loss                 -0.245545
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.280756
exploration/Rewards Std             0.756529
exploration/Rewards Max            -0.0110478
exploration/Rewards Min            -7.23593
exploration/Returns Mean          -28.0756
exploration/Returns Std             6.88644
exploration/Returns Max           -18.8549
exploration/Returns Min           -37.2891
exploration/Actions Mean            0.000320846
exploration/Actions Std             0.254837
exploration/Actions Max             0.998548
exploration/Actions Min            -0.998206
exploration/Num Paths               5
exploration/Average Returns       -28.0756
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238485
evaluation/Rewards Std              0.950311
evaluation/Rewards Max             -0.0128826
evaluation/Rewards Min            -10.161
evaluation/Returns Mean           -23.8485
evaluation/Returns Std             14.49
evaluation/Returns Max             -5.1141
evaluation/Returns Min            -55.4878
evaluation/Actions Mean            -0.00129515
evaluation/Actions Std              0.191445
evaluation/Actions Max              0.994803
evaluation/Actions Min             -0.996357
evaluation/Num Paths               15
evaluation/Average Returns        -23.8485
time/data storing (s)               0.00312334
time/evaluation sampling (s)        0.360584
time/exploration sampling (s)       0.163999
time/logging (s)                    0.0047416
time/saving (s)                     0.00204544
time/training (s)                   2.11561
time/epoch (s)                      2.65011
time/total (s)                    183.125
Epoch                              67
-----------------------------  ----------------
2019-04-22 21:24:57.261692 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                    0.0466361
trainer/QF2 Loss                    0.0506172
trainer/Policy Loss                11.9746
trainer/Q1 Predictions Mean       -10.2372
trainer/Q1 Predictions Std          5.29989
trainer/Q1 Predictions Max         -7.71597
trainer/Q1 Predictions Min        -40.9067
trainer/Q2 Predictions Mean       -10.2083
trainer/Q2 Predictions Std          5.312
trainer/Q2 Predictions Max         -7.70149
trainer/Q2 Predictions Min        -41.0882
trainer/Q Targets Mean            -10.1528
trainer/Q Targets Std               5.15139
trainer/Q Targets Max              -7.67827
trainer/Q Targets Min             -40.1832
trainer/Log Pis Mean                2.01213
trainer/Log Pis Std                 1.19705
trainer/Log Pis Max                 6.19353
trainer/Log Pis Min                -2.76614
trainer/Policy mu Mean              0.0236084
trainer/Policy mu Std               0.630617
trainer/Policy mu Max               3.3174
trainer/Policy mu Min              -2.00652
trainer/Policy log std Mean        -2.15969
trainer/Policy log std Std          0.39281
trainer/Policy log std Max         -0.547897
trainer/Policy log std Min         -2.51017
trainer/Alpha                       0.0520412
trainer/Alpha Loss                  0.0358559
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.317433
exploration/Rewards Std             0.922519
exploration/Rewards Max            -0.00251174
exploration/Rewards Min            -8.79385
exploration/Returns Mean          -31.7433
exploration/Returns Std            11.761
exploration/Returns Max           -21.8661
exploration/Returns Min           -54.8772
exploration/Actions Mean            0.00457995
exploration/Actions Std             0.236809
exploration/Actions Max             0.999125
exploration/Actions Min            -0.999867
exploration/Num Paths               5
exploration/Average Returns       -31.7433
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.388898
evaluation/Rewards Std              1.4196
evaluation/Rewards Max             -0.0160638
evaluation/Rewards Min            -11.0097
evaluation/Returns Mean           -38.8898
evaluation/Returns Std             18.9611
evaluation/Returns Max             -5.37201
evaluation/Returns Min            -63.8106
evaluation/Actions Mean            -0.0211301
evaluation/Actions Std              0.225935
evaluation/Actions Max              0.996331
evaluation/Actions Min             -0.997035
evaluation/Num Paths               15
evaluation/Average Returns        -38.8898
time/data storing (s)               0.00325608
time/evaluation sampling (s)        0.409076
time/exploration sampling (s)       0.170177
time/logging (s)                    0.00489512
time/saving (s)                     0.00204184
time/training (s)                   2.11874
time/epoch (s)                      2.70819
time/total (s)                    185.838
Epoch                              68
-----------------------------  ---------------
2019-04-22 21:24:59.919879 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                    1.81496
trainer/QF2 Loss                    1.79968
trainer/Policy Loss                11.1052
trainer/Q1 Predictions Mean        -9.52079
trainer/Q1 Predictions Std          4.21869
trainer/Q1 Predictions Max         -7.62467
trainer/Q1 Predictions Min        -41.2397
trainer/Q2 Predictions Mean        -9.50646
trainer/Q2 Predictions Std          4.19115
trainer/Q2 Predictions Max         -7.60867
trainer/Q2 Predictions Min        -41.0872
trainer/Q Targets Mean             -9.39201
trainer/Q Targets Std               4.28008
trainer/Q Targets Max              -0.179829
trainer/Q Targets Min             -40.206
trainer/Log Pis Mean                1.91375
trainer/Log Pis Std                 1.45422
trainer/Log Pis Max                 6.22142
trainer/Log Pis Min                -4.44072
trainer/Policy mu Mean              0.0975956
trainer/Policy mu Std               0.633375
trainer/Policy mu Max               2.92708
trainer/Policy mu Min              -2.59578
trainer/Policy log std Mean        -2.13457
trainer/Policy log std Std          0.413592
trainer/Policy log std Max         -0.543551
trainer/Policy log std Min         -2.50066
trainer/Alpha                       0.0545514
trainer/Alpha Loss                 -0.250872
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.421701
exploration/Rewards Std             1.22173
exploration/Rewards Max            -0.00316672
exploration/Rewards Min            -9.98066
exploration/Returns Mean          -42.1701
exploration/Returns Std            14.4868
exploration/Returns Max           -17.7061
exploration/Returns Min           -61.9549
exploration/Actions Mean            0.0269359
exploration/Actions Std             0.247216
exploration/Actions Max             0.999052
exploration/Actions Min            -0.995992
exploration/Num Paths               5
exploration/Average Returns       -42.1701
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263583
evaluation/Rewards Std              1.01052
evaluation/Rewards Max             -0.0365166
evaluation/Rewards Min            -10.0111
evaluation/Returns Mean           -26.3583
evaluation/Returns Std             18.9681
evaluation/Returns Max             -8.27725
evaluation/Returns Min            -59.4745
evaluation/Actions Mean            -0.00548234
evaluation/Actions Std              0.186634
evaluation/Actions Max              0.996999
evaluation/Actions Min             -0.997667
evaluation/Num Paths               15
evaluation/Average Returns        -26.3583
time/data storing (s)               0.00333466
time/evaluation sampling (s)        0.360599
time/exploration sampling (s)       0.163455
time/logging (s)                    0.00488741
time/saving (s)                     0.00221387
time/training (s)                   2.11755
time/epoch (s)                      2.65203
time/total (s)                    188.494
Epoch                              69
-----------------------------  ---------------
2019-04-22 21:25:02.676597 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 70 finished
-----------------------------  ----------------
replay_buffer/size              35700
trainer/QF1 Loss                    0.0531899
trainer/QF2 Loss                    0.0492478
trainer/Policy Loss                11.5762
trainer/Q1 Predictions Mean       -10.0144
trainer/Q1 Predictions Std          5.79941
trainer/Q1 Predictions Max         -7.56699
trainer/Q1 Predictions Min        -56.0716
trainer/Q2 Predictions Mean       -10.0296
trainer/Q2 Predictions Std          5.83586
trainer/Q2 Predictions Max         -7.51545
trainer/Q2 Predictions Min        -55.8463
trainer/Q Targets Mean            -10.1543
trainer/Q Targets Std               5.89721
trainer/Q Targets Max              -7.55047
trainer/Q Targets Min             -56.9419
trainer/Log Pis Mean                1.93796
trainer/Log Pis Std                 1.22212
trainer/Log Pis Max                 5.26207
trainer/Log Pis Min                -1.55896
trainer/Policy mu Mean              0.0021616
trainer/Policy mu Std               0.725367
trainer/Policy mu Max               2.86725
trainer/Policy mu Min              -3.01462
trainer/Policy log std Mean        -2.04576
trainer/Policy log std Std          0.466722
trainer/Policy log std Max         -0.403747
trainer/Policy log std Min         -2.54863
trainer/Alpha                       0.0533782
trainer/Alpha Loss                 -0.181807
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.289724
exploration/Rewards Std             0.765987
exploration/Rewards Max            -0.00408733
exploration/Rewards Min            -6.83149
exploration/Returns Mean          -28.9724
exploration/Returns Std             8.04166
exploration/Returns Max           -14.8666
exploration/Returns Min           -39.1241
exploration/Actions Mean            0.00407166
exploration/Actions Std             0.238964
exploration/Actions Max             0.997529
exploration/Actions Min            -0.998913
exploration/Num Paths               5
exploration/Average Returns       -28.9724
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238967
evaluation/Rewards Std              0.953568
evaluation/Rewards Max             -0.0195653
evaluation/Rewards Min             -9.8103
evaluation/Returns Mean           -23.8967
evaluation/Returns Std             17.7668
evaluation/Returns Max             -3.67247
evaluation/Returns Min            -61.0359
evaluation/Actions Mean             8.40208e-05
evaluation/Actions Std              0.188283
evaluation/Actions Max              0.996788
evaluation/Actions Min             -0.995977
evaluation/Num Paths               15
evaluation/Average Returns        -23.8967
time/data storing (s)               0.00323934
time/evaluation sampling (s)        0.353489
time/exploration sampling (s)       0.15839
time/logging (s)                    0.0050509
time/saving (s)                     0.00202511
time/training (s)                   2.22771
time/epoch (s)                      2.7499
time/total (s)                    191.249
Epoch                              70
-----------------------------  ----------------
2019-04-22 21:25:05.335292 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                    0.068454
trainer/QF2 Loss                    0.101363
trainer/Policy Loss                13.4073
trainer/Q1 Predictions Mean       -11.5348
trainer/Q1 Predictions Std         10.1119
trainer/Q1 Predictions Max         -7.32015
trainer/Q1 Predictions Min        -69.6849
trainer/Q2 Predictions Mean       -11.5324
trainer/Q2 Predictions Std         10.0492
trainer/Q2 Predictions Max         -7.37438
trainer/Q2 Predictions Min        -69.3178
trainer/Q Targets Mean            -11.6966
trainer/Q Targets Std              10.1945
trainer/Q Targets Max              -7.41641
trainer/Q Targets Min             -71.1423
trainer/Log Pis Mean                2.46454
trainer/Log Pis Std                 1.62915
trainer/Log Pis Max                 8.94235
trainer/Log Pis Min                -2.74743
trainer/Policy mu Mean              0.149982
trainer/Policy mu Std               0.907529
trainer/Policy mu Max               3.33301
trainer/Policy mu Min              -2.94067
trainer/Policy log std Mean        -2.03949
trainer/Policy log std Std          0.552207
trainer/Policy log std Max         -0.430757
trainer/Policy log std Min         -2.6412
trainer/Alpha                       0.0535812
trainer/Alpha Loss                  1.35957
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.339547
exploration/Rewards Std             1.02531
exploration/Rewards Max            -0.00156832
exploration/Rewards Min            -8.78444
exploration/Returns Mean          -33.9547
exploration/Returns Std            17.908
exploration/Returns Max           -11.1974
exploration/Returns Min           -55.7965
exploration/Actions Mean           -0.0145511
exploration/Actions Std             0.227138
exploration/Actions Max             0.994352
exploration/Actions Min            -0.999297
exploration/Num Paths               5
exploration/Average Returns       -33.9547
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.240995
evaluation/Rewards Std              0.982802
evaluation/Rewards Max             -0.0144886
evaluation/Rewards Min             -9.95751
evaluation/Returns Mean           -24.0995
evaluation/Returns Std             17.9887
evaluation/Returns Max             -3.10006
evaluation/Returns Min            -58.2072
evaluation/Actions Mean             0.0119393
evaluation/Actions Std              0.188041
evaluation/Actions Max              0.996685
evaluation/Actions Min             -0.996684
evaluation/Num Paths               15
evaluation/Average Returns        -24.0995
time/data storing (s)               0.00329966
time/evaluation sampling (s)        0.360103
time/exploration sampling (s)       0.16476
time/logging (s)                    0.00385374
time/saving (s)                     0.00210726
time/training (s)                   2.11668
time/epoch (s)                      2.65081
time/total (s)                    193.905
Epoch                              71
-----------------------------  ---------------
2019-04-22 21:25:08.029523 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                    0.908024
trainer/QF2 Loss                    0.919589
trainer/Policy Loss                13.7786
trainer/Q1 Predictions Mean       -11.8812
trainer/Q1 Predictions Std         10.7961
trainer/Q1 Predictions Max         -7.31118
trainer/Q1 Predictions Min        -63.6259
trainer/Q2 Predictions Mean       -11.8461
trainer/Q2 Predictions Std         10.7197
trainer/Q2 Predictions Max         -7.26548
trainer/Q2 Predictions Min        -63.6298
trainer/Q Targets Mean            -11.9107
trainer/Q Targets Std              10.7689
trainer/Q Targets Max              -0.110365
trainer/Q Targets Min             -63.2336
trainer/Log Pis Mean                2.31313
trainer/Log Pis Std                 1.78567
trainer/Log Pis Max                 9.60266
trainer/Log Pis Min                -1.29665
trainer/Policy mu Mean             -0.0437767
trainer/Policy mu Std               0.977159
trainer/Policy mu Max               3.2738
trainer/Policy mu Min              -3.22439
trainer/Policy log std Mean        -1.96676
trainer/Policy log std Std          0.569016
trainer/Policy log std Max         -0.453403
trainer/Policy log std Min         -2.47099
trainer/Alpha                       0.0547021
trainer/Alpha Loss                  0.909955
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.320493
exploration/Rewards Std             0.937567
exploration/Rewards Max            -0.00495072
exploration/Rewards Min            -8.99674
exploration/Returns Mean          -32.0493
exploration/Returns Std            15.0705
exploration/Returns Max           -15.0429
exploration/Returns Min           -57.5405
exploration/Actions Mean            0.00780205
exploration/Actions Std             0.223944
exploration/Actions Max             0.998052
exploration/Actions Min            -0.999426
exploration/Num Paths               5
exploration/Average Returns       -32.0493
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.320235
evaluation/Rewards Std              1.17316
evaluation/Rewards Max             -0.036197
evaluation/Rewards Min            -10.7552
evaluation/Returns Mean           -32.0235
evaluation/Returns Std             17.4627
evaluation/Returns Max             -6.54871
evaluation/Returns Min            -60.9091
evaluation/Actions Mean             0.00808406
evaluation/Actions Std              0.20626
evaluation/Actions Max              0.996363
evaluation/Actions Min             -0.997174
evaluation/Num Paths               15
evaluation/Average Returns        -32.0235
time/data storing (s)               0.0034905
time/evaluation sampling (s)        0.357915
time/exploration sampling (s)       0.163339
time/logging (s)                    0.00467021
time/saving (s)                     0.00220986
time/training (s)                   2.1575
time/epoch (s)                      2.68913
time/total (s)                    196.599
Epoch                              72
-----------------------------  ---------------
2019-04-22 21:25:10.692095 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    1.12744
trainer/QF2 Loss                    1.12729
trainer/Policy Loss                12.2791
trainer/Q1 Predictions Mean       -10.8949
trainer/Q1 Predictions Std          7.9215
trainer/Q1 Predictions Max         -7.39383
trainer/Q1 Predictions Min        -62.4513
trainer/Q2 Predictions Mean       -10.8933
trainer/Q2 Predictions Std          7.82615
trainer/Q2 Predictions Max         -7.42013
trainer/Q2 Predictions Min        -61.8111
trainer/Q Targets Mean            -10.697
trainer/Q Targets Std               8.02136
trainer/Q Targets Max              -0.0915079
trainer/Q Targets Min             -62.7389
trainer/Log Pis Mean                1.92675
trainer/Log Pis Std                 1.59224
trainer/Log Pis Max                 7.30552
trainer/Log Pis Min                -2.64726
trainer/Policy mu Mean             -0.0209265
trainer/Policy mu Std               0.797197
trainer/Policy mu Max               3.07558
trainer/Policy mu Min              -3.05588
trainer/Policy log std Mean        -2.00355
trainer/Policy log std Std          0.495869
trainer/Policy log std Max         -0.447686
trainer/Policy log std Min         -2.47064
trainer/Alpha                       0.0547771
trainer/Alpha Loss                 -0.212736
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.186197
exploration/Rewards Std             0.340073
exploration/Rewards Max            -0.0112661
exploration/Rewards Min            -4.74524
exploration/Returns Mean          -18.6197
exploration/Returns Std             4.47433
exploration/Returns Max           -13.2996
exploration/Returns Min           -25.6006
exploration/Actions Mean           -0.00789378
exploration/Actions Std             0.202712
exploration/Actions Max             0.989819
exploration/Actions Min            -0.996499
exploration/Num Paths               5
exploration/Average Returns       -18.6197
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.17971
evaluation/Rewards Std              0.824415
evaluation/Rewards Max             -0.0207527
evaluation/Rewards Min            -10.5787
evaluation/Returns Mean           -17.971
evaluation/Returns Std             14.1134
evaluation/Returns Max             -3.74167
evaluation/Returns Min            -59.0756
evaluation/Actions Mean             0.0177912
evaluation/Actions Std              0.176599
evaluation/Actions Max              0.997784
evaluation/Actions Min             -0.995573
evaluation/Num Paths               15
evaluation/Average Returns        -17.971
time/data storing (s)               0.00311663
time/evaluation sampling (s)        0.360071
time/exploration sampling (s)       0.164007
time/logging (s)                    0.00509747
time/saving (s)                     0.00220131
time/training (s)                   2.12186
time/epoch (s)                      2.65636
time/total (s)                    199.26
Epoch                              73
-----------------------------  ---------------
2019-04-22 21:25:13.412947 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size              37700
trainer/QF1 Loss                    0.55317
trainer/QF2 Loss                    0.537229
trainer/Policy Loss                11.003
trainer/Q1 Predictions Mean        -9.377
trainer/Q1 Predictions Std          5.12565
trainer/Q1 Predictions Max         -7.1211
trainer/Q1 Predictions Min        -43.9669
trainer/Q2 Predictions Mean        -9.41789
trainer/Q2 Predictions Std          5.02955
trainer/Q2 Predictions Max         -7.23549
trainer/Q2 Predictions Min        -43.0709
trainer/Q Targets Mean             -9.41431
trainer/Q Targets Std               5.09467
trainer/Q Targets Max              -0.323142
trainer/Q Targets Min             -43.197
trainer/Log Pis Mean                1.81821
trainer/Log Pis Std                 1.16326
trainer/Log Pis Max                 5.93642
trainer/Log Pis Min                -2.02152
trainer/Policy mu Mean             -0.0323028
trainer/Policy mu Std               0.621352
trainer/Policy mu Max               2.87852
trainer/Policy mu Min              -3.14097
trainer/Policy log std Mean        -2.09954
trainer/Policy log std Std          0.404547
trainer/Policy log std Max         -0.458103
trainer/Policy log std Min         -2.44495
trainer/Alpha                       0.0535993
trainer/Alpha Loss                 -0.531937
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.336903
exploration/Rewards Std             0.969686
exploration/Rewards Max            -0.00711142
exploration/Rewards Min            -9.27677
exploration/Returns Mean          -33.6903
exploration/Returns Std            12.859
exploration/Returns Max           -22.7387
exploration/Returns Min           -58.6785
exploration/Actions Mean            0.00615237
exploration/Actions Std             0.25427
exploration/Actions Max             0.997866
exploration/Actions Min            -0.998635
exploration/Num Paths               5
exploration/Average Returns       -33.6903
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.333958
evaluation/Rewards Std              1.13844
evaluation/Rewards Max             -0.0501867
evaluation/Rewards Min             -9.81142
evaluation/Returns Mean           -33.3958
evaluation/Returns Std             16.2698
evaluation/Returns Max             -9.87431
evaluation/Returns Min            -55.1985
evaluation/Actions Mean            -0.0095607
evaluation/Actions Std              0.205839
evaluation/Actions Max              0.996946
evaluation/Actions Min             -0.997017
evaluation/Num Paths               15
evaluation/Average Returns        -33.3958
time/data storing (s)               0.00325511
time/evaluation sampling (s)        0.360528
time/exploration sampling (s)       0.163113
time/logging (s)                    0.00459911
time/saving (s)                     0.00193113
time/training (s)                   2.18045
time/epoch (s)                      2.71387
time/total (s)                    201.979
Epoch                              74
-----------------------------  ---------------
2019-04-22 21:25:16.088620 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    0.534415
trainer/QF2 Loss                    0.535529
trainer/Policy Loss                10.8019
trainer/Q1 Predictions Mean        -8.8928
trainer/Q1 Predictions Std          3.16119
trainer/Q1 Predictions Max         -7.27171
trainer/Q1 Predictions Min        -27.8142
trainer/Q2 Predictions Mean        -8.8493
trainer/Q2 Predictions Std          3.19606
trainer/Q2 Predictions Max         -7.20137
trainer/Q2 Predictions Min        -27.8483
trainer/Q Targets Mean             -8.86971
trainer/Q Targets Std               3.26921
trainer/Q Targets Max              -0.189976
trainer/Q Targets Min             -27.4521
trainer/Log Pis Mean                2.02047
trainer/Log Pis Std                 1.19741
trainer/Log Pis Max                 5.76456
trainer/Log Pis Min                -2.05689
trainer/Policy mu Mean             -0.00845323
trainer/Policy mu Std               0.618273
trainer/Policy mu Max               2.61038
trainer/Policy mu Min              -2.93735
trainer/Policy log std Mean        -2.17106
trainer/Policy log std Std          0.430403
trainer/Policy log std Max         -0.50562
trainer/Policy log std Min         -2.55906
trainer/Alpha                       0.0537004
trainer/Alpha Loss                  0.0598636
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.381259
exploration/Rewards Std             1.28332
exploration/Rewards Max            -0.00435606
exploration/Rewards Min           -11.2055
exploration/Returns Mean          -38.1259
exploration/Returns Std            24.3402
exploration/Returns Max           -14.3327
exploration/Returns Min           -69.7529
exploration/Actions Mean           -0.00311145
exploration/Actions Std             0.244265
exploration/Actions Max             0.997458
exploration/Actions Min            -0.999831
exploration/Num Paths               5
exploration/Average Returns       -38.1259
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.194756
evaluation/Rewards Std              0.849679
evaluation/Rewards Max             -0.0197865
evaluation/Rewards Min             -9.25341
evaluation/Returns Mean           -19.4756
evaluation/Returns Std             13.6692
evaluation/Returns Max             -4.76837
evaluation/Returns Min            -49.8676
evaluation/Actions Mean             0.00271024
evaluation/Actions Std              0.179072
evaluation/Actions Max              0.997346
evaluation/Actions Min             -0.996359
evaluation/Num Paths               15
evaluation/Average Returns        -19.4756
time/data storing (s)               0.00310563
time/evaluation sampling (s)        0.357504
time/exploration sampling (s)       0.164089
time/logging (s)                    0.00498468
time/saving (s)                     0.00201113
time/training (s)                   2.13804
time/epoch (s)                      2.66973
time/total (s)                    204.653
Epoch                              75
-----------------------------  ---------------
2019-04-22 21:25:18.771013 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size              38700
trainer/QF1 Loss                    0.9781
trainer/QF2 Loss                    0.916843
trainer/Policy Loss                13.157
trainer/Q1 Predictions Mean       -11.2447
trainer/Q1 Predictions Std         12.6318
trainer/Q1 Predictions Max         -7.06588
trainer/Q1 Predictions Min        -74.1889
trainer/Q2 Predictions Mean       -11.3111
trainer/Q2 Predictions Std         12.7113
trainer/Q2 Predictions Max         -7.13497
trainer/Q2 Predictions Min        -74.9761
trainer/Q Targets Mean            -11.2966
trainer/Q Targets Std              12.9103
trainer/Q Targets Max              -0.55343
trainer/Q Targets Min             -75.7958
trainer/Log Pis Mean                2.32933
trainer/Log Pis Std                 1.48964
trainer/Log Pis Max                 7.52494
trainer/Log Pis Min                -4.2512
trainer/Policy mu Mean             -0.0925191
trainer/Policy mu Std               0.770595
trainer/Policy mu Max               3.1617
trainer/Policy mu Min              -3.44115
trainer/Policy log std Mean        -2.19401
trainer/Policy log std Std          0.451401
trainer/Policy log std Max         -0.427538
trainer/Policy log std Min         -2.7398
trainer/Alpha                       0.0556136
trainer/Alpha Loss                  0.951628
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.342617
exploration/Rewards Std             0.995877
exploration/Rewards Max            -0.00320903
exploration/Rewards Min            -9.03378
exploration/Returns Mean          -34.2617
exploration/Returns Std            10.9059
exploration/Returns Max           -23.6356
exploration/Returns Min           -55.1323
exploration/Actions Mean            0.01166
exploration/Actions Std             0.246813
exploration/Actions Max             0.998979
exploration/Actions Min            -0.998896
exploration/Num Paths               5
exploration/Average Returns       -34.2617
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.186841
evaluation/Rewards Std              0.677024
evaluation/Rewards Max             -0.0269607
evaluation/Rewards Min             -8.46086
evaluation/Returns Mean           -18.6841
evaluation/Returns Std              9.90563
evaluation/Returns Max             -4.85478
evaluation/Returns Min            -46.1253
evaluation/Actions Mean             0.00109865
evaluation/Actions Std              0.178417
evaluation/Actions Max              0.99282
evaluation/Actions Min             -0.998085
evaluation/Num Paths               15
evaluation/Average Returns        -18.6841
time/data storing (s)               0.00311779
time/evaluation sampling (s)        0.353358
time/exploration sampling (s)       0.157137
time/logging (s)                    0.00670969
time/saving (s)                     0.00264497
time/training (s)                   2.15457
time/epoch (s)                      2.67753
time/total (s)                    207.335
Epoch                              76
-----------------------------  ---------------
2019-04-22 21:25:21.403007 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    0.0395295
trainer/QF2 Loss                    0.0439348
trainer/Policy Loss                11.2433
trainer/Q1 Predictions Mean        -9.68383
trainer/Q1 Predictions Std          6.18928
trainer/Q1 Predictions Max         -7.16279
trainer/Q1 Predictions Min        -52.4007
trainer/Q2 Predictions Mean        -9.64732
trainer/Q2 Predictions Std          6.10674
trainer/Q2 Predictions Max         -7.14442
trainer/Q2 Predictions Min        -51.7563
trainer/Q Targets Mean             -9.76503
trainer/Q Targets Std               6.14048
trainer/Q Targets Max              -7.12606
trainer/Q Targets Min             -51.4528
trainer/Log Pis Mean                1.93085
trainer/Log Pis Std                 1.39895
trainer/Log Pis Max                 9.37566
trainer/Log Pis Min                -2.66032
trainer/Policy mu Mean             -0.0278012
trainer/Policy mu Std               0.705751
trainer/Policy mu Max               2.82446
trainer/Policy mu Min              -3.38199
trainer/Policy log std Mean        -2.09566
trainer/Policy log std Std          0.421388
trainer/Policy log std Max         -0.409138
trainer/Policy log std Min         -2.4202
trainer/Alpha                       0.0572222
trainer/Alpha Loss                 -0.197811
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.29824
exploration/Rewards Std             0.822178
exploration/Rewards Max            -0.00833409
exploration/Rewards Min            -8.58452
exploration/Returns Mean          -29.824
exploration/Returns Std             8.805
exploration/Returns Max           -22.1065
exploration/Returns Min           -46.6332
exploration/Actions Mean            0.0196908
exploration/Actions Std             0.239643
exploration/Actions Max             0.999108
exploration/Actions Min            -0.998036
exploration/Num Paths               5
exploration/Average Returns       -29.824
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.16654
evaluation/Rewards Std              0.704622
evaluation/Rewards Max             -0.0149271
evaluation/Rewards Min            -10.1028
evaluation/Returns Mean           -16.654
evaluation/Returns Std             12.6587
evaluation/Returns Max             -4.42352
evaluation/Returns Min            -60.5104
evaluation/Actions Mean            -0.00359896
evaluation/Actions Std              0.171604
evaluation/Actions Max              0.996634
evaluation/Actions Min             -0.993349
evaluation/Num Paths               15
evaluation/Average Returns        -16.654
time/data storing (s)               0.00346859
time/evaluation sampling (s)        0.363762
time/exploration sampling (s)       0.164106
time/logging (s)                    0.00475307
time/saving (s)                     0.00161183
time/training (s)                   2.08596
time/epoch (s)                      2.62366
time/total (s)                    209.963
Epoch                              77
-----------------------------  ---------------
2019-04-22 21:25:24.008504 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 78 finished
-----------------------------  ----------------
replay_buffer/size              39700
trainer/QF1 Loss                    0.79886
trainer/QF2 Loss                    0.79264
trainer/Policy Loss                12.4397
trainer/Q1 Predictions Mean       -10.6492
trainer/Q1 Predictions Std          9.85427
trainer/Q1 Predictions Max         -7.29604
trainer/Q1 Predictions Min        -69.3952
trainer/Q2 Predictions Mean       -10.5907
trainer/Q2 Predictions Std          9.79846
trainer/Q2 Predictions Max         -7.22402
trainer/Q2 Predictions Min        -69.6087
trainer/Q Targets Mean            -10.7125
trainer/Q Targets Std              10.2446
trainer/Q Targets Max              -0.115198
trainer/Q Targets Min             -73.7689
trainer/Log Pis Mean                2.19519
trainer/Log Pis Std                 1.62999
trainer/Log Pis Max                 9.43418
trainer/Log Pis Min                -2.62998
trainer/Policy mu Mean              0.112222
trainer/Policy mu Std               0.835596
trainer/Policy mu Max               3.23974
trainer/Policy mu Min              -3.0036
trainer/Policy log std Mean        -2.0593
trainer/Policy log std Std          0.478998
trainer/Policy log std Max         -0.561187
trainer/Policy log std Min         -2.43789
trainer/Alpha                       0.0550148
trainer/Alpha Loss                  0.56606
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.482191
exploration/Rewards Std             1.44802
exploration/Rewards Max            -0.00703376
exploration/Rewards Min           -11.1342
exploration/Returns Mean          -48.2191
exploration/Returns Std            16.7637
exploration/Returns Max           -24.3024
exploration/Returns Min           -69.753
exploration/Actions Mean            0.00742245
exploration/Actions Std             0.279217
exploration/Actions Max             0.99846
exploration/Actions Min            -0.99958
exploration/Num Paths               5
exploration/Average Returns       -48.2191
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.248539
evaluation/Rewards Std              1.04472
evaluation/Rewards Max             -0.0158663
evaluation/Rewards Min             -9.70354
evaluation/Returns Mean           -24.8539
evaluation/Returns Std             14.7196
evaluation/Returns Max             -3.76248
evaluation/Returns Min            -54.4262
evaluation/Actions Mean            -0.000366891
evaluation/Actions Std              0.204508
evaluation/Actions Max              0.99594
evaluation/Actions Min             -0.997203
evaluation/Num Paths               15
evaluation/Average Returns        -24.8539
time/data storing (s)               0.00310444
time/evaluation sampling (s)        0.348194
time/exploration sampling (s)       0.15475
time/logging (s)                    0.00508603
time/saving (s)                     0.00212448
time/training (s)                   2.08689
time/epoch (s)                      2.60015
time/total (s)                    212.567
Epoch                              78
-----------------------------  ----------------
2019-04-22 21:25:26.737752 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    0.641688
trainer/QF2 Loss                    0.736797
trainer/Policy Loss                11.6251
trainer/Q1 Predictions Mean       -10.2064
trainer/Q1 Predictions Std          8.71308
trainer/Q1 Predictions Max         -7.20094
trainer/Q1 Predictions Min        -62.4065
trainer/Q2 Predictions Mean       -10.2184
trainer/Q2 Predictions Std          8.61128
trainer/Q2 Predictions Max         -7.25029
trainer/Q2 Predictions Min        -61.2743
trainer/Q Targets Mean            -10.2164
trainer/Q Targets Std               9.03689
trainer/Q Targets Max              -0.272349
trainer/Q Targets Min             -64.9201
trainer/Log Pis Mean                1.97075
trainer/Log Pis Std                 1.28141
trainer/Log Pis Max                 6.41202
trainer/Log Pis Min                -1.52291
trainer/Policy mu Mean              0.035137
trainer/Policy mu Std               0.804635
trainer/Policy mu Max               3.12483
trainer/Policy mu Min              -3.02447
trainer/Policy log std Mean        -1.92196
trainer/Policy log std Std          0.467172
trainer/Policy log std Max         -0.459262
trainer/Policy log std Min         -2.30248
trainer/Alpha                       0.0547917
trainer/Alpha Loss                 -0.0849399
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.432375
exploration/Rewards Std             1.26101
exploration/Rewards Max            -0.00387793
exploration/Rewards Min           -10.0307
exploration/Returns Mean          -43.2375
exploration/Returns Std            20.3181
exploration/Returns Max           -19.5204
exploration/Returns Min           -69.7686
exploration/Actions Mean           -0.00338457
exploration/Actions Std             0.269917
exploration/Actions Max             0.999221
exploration/Actions Min            -0.999275
exploration/Num Paths               5
exploration/Average Returns       -43.2375
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.236001
evaluation/Rewards Std              0.954942
evaluation/Rewards Max             -0.00732289
evaluation/Rewards Min            -10.2586
evaluation/Returns Mean           -23.6001
evaluation/Returns Std             14.1636
evaluation/Returns Max             -5.79681
evaluation/Returns Min            -59.275
evaluation/Actions Mean             0.00122331
evaluation/Actions Std              0.194899
evaluation/Actions Max              0.996908
evaluation/Actions Min             -0.997907
evaluation/Num Paths               15
evaluation/Average Returns        -23.6001
time/data storing (s)               0.0032113
time/evaluation sampling (s)        0.367787
time/exploration sampling (s)       0.166561
time/logging (s)                    0.00482018
time/saving (s)                     0.00203081
time/training (s)                   2.17744
time/epoch (s)                      2.72185
time/total (s)                    215.294
Epoch                              79
-----------------------------  ---------------
2019-04-22 21:25:29.365901 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 80 finished
-----------------------------  ----------------
replay_buffer/size              40700
trainer/QF1 Loss                    0.560242
trainer/QF2 Loss                    0.550135
trainer/Policy Loss                10.9087
trainer/Q1 Predictions Mean        -9.50355
trainer/Q1 Predictions Std          8.3828
trainer/Q1 Predictions Max         -7.03121
trainer/Q1 Predictions Min        -66.3373
trainer/Q2 Predictions Mean        -9.47392
trainer/Q2 Predictions Std          8.38248
trainer/Q2 Predictions Max         -6.95194
trainer/Q2 Predictions Min        -66.5607
trainer/Q Targets Mean             -9.61252
trainer/Q Targets Std               8.52668
trainer/Q Targets Max              -0.0693179
trainer/Q Targets Min             -67.645
trainer/Log Pis Mean                1.97587
trainer/Log Pis Std                 1.40318
trainer/Log Pis Max                 7.47525
trainer/Log Pis Min                -3.118
trainer/Policy mu Mean             -0.0549512
trainer/Policy mu Std               0.618466
trainer/Policy mu Max               2.71617
trainer/Policy mu Min              -3.19345
trainer/Policy log std Mean        -2.17083
trainer/Policy log std Std          0.412575
trainer/Policy log std Max         -0.408755
trainer/Policy log std Min         -2.47204
trainer/Alpha                       0.0540334
trainer/Alpha Loss                 -0.0704211
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.382041
exploration/Rewards Std             1.25357
exploration/Rewards Max            -0.000617118
exploration/Rewards Min            -9.91799
exploration/Returns Mean          -38.2041
exploration/Returns Std            22.9648
exploration/Returns Max           -12.1992
exploration/Returns Min           -64.189
exploration/Actions Mean            0.018502
exploration/Actions Std             0.232724
exploration/Actions Max             0.9991
exploration/Actions Min            -0.999126
exploration/Num Paths               5
exploration/Average Returns       -38.2041
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245277
evaluation/Rewards Std              1.07668
evaluation/Rewards Max             -0.0105386
evaluation/Rewards Min            -10.8836
evaluation/Returns Mean           -24.5277
evaluation/Returns Std             22.1297
evaluation/Returns Max             -5.41954
evaluation/Returns Min            -65.0921
evaluation/Actions Mean             0.00908932
evaluation/Actions Std              0.200025
evaluation/Actions Max              0.995982
evaluation/Actions Min             -0.998148
evaluation/Num Paths               15
evaluation/Average Returns        -24.5277
time/data storing (s)               0.00376923
time/evaluation sampling (s)        0.362159
time/exploration sampling (s)       0.16444
time/logging (s)                    0.00478706
time/saving (s)                     0.00153267
time/training (s)                   2.08497
time/epoch (s)                      2.62166
time/total (s)                    217.921
Epoch                              80
-----------------------------  ----------------
2019-04-22 21:25:32.047366 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                    0.0307843
trainer/QF2 Loss                    0.0334334
trainer/Policy Loss                11.9259
trainer/Q1 Predictions Mean       -10.0512
trainer/Q1 Predictions Std          7.89804
trainer/Q1 Predictions Max         -6.95249
trainer/Q1 Predictions Min        -59.5149
trainer/Q2 Predictions Mean       -10.0385
trainer/Q2 Predictions Std          7.90879
trainer/Q2 Predictions Max         -6.97082
trainer/Q2 Predictions Min        -59.7625
trainer/Q Targets Mean            -10.1466
trainer/Q Targets Std               7.8751
trainer/Q Targets Max              -7.01051
trainer/Q Targets Min             -59.8892
trainer/Log Pis Mean                2.19351
trainer/Log Pis Std                 1.58463
trainer/Log Pis Max                 7.94728
trainer/Log Pis Min                -4.61491
trainer/Policy mu Mean              0.0770285
trainer/Policy mu Std               0.807738
trainer/Policy mu Max               3.46145
trainer/Policy mu Min              -3.06764
trainer/Policy log std Mean        -2.087
trainer/Policy log std Std          0.494071
trainer/Policy log std Max         -0.512792
trainer/Policy log std Min         -2.49637
trainer/Alpha                       0.0557816
trainer/Alpha Loss                  0.558547
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.269683
exploration/Rewards Std             0.858884
exploration/Rewards Max            -0.00187487
exploration/Rewards Min            -9.44428
exploration/Returns Mean          -26.9683
exploration/Returns Std            16.8004
exploration/Returns Max           -16.68
exploration/Returns Min           -60.2646
exploration/Actions Mean           -0.00912465
exploration/Actions Std             0.218279
exploration/Actions Max             0.996035
exploration/Actions Min            -0.999432
exploration/Num Paths               5
exploration/Average Returns       -26.9683
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.197208
evaluation/Rewards Std              0.84992
evaluation/Rewards Max             -0.0176047
evaluation/Rewards Min            -10.8291
evaluation/Returns Mean           -19.7208
evaluation/Returns Std             13.7249
evaluation/Returns Max             -4.00142
evaluation/Returns Min            -58.8325
evaluation/Actions Mean             0.00199936
evaluation/Actions Std              0.182958
evaluation/Actions Max              0.996622
evaluation/Actions Min             -0.996576
evaluation/Num Paths               15
evaluation/Average Returns        -19.7208
time/data storing (s)               0.00312736
time/evaluation sampling (s)        0.354273
time/exploration sampling (s)       0.159354
time/logging (s)                    0.00499045
time/saving (s)                     0.00224653
time/training (s)                   2.15159
time/epoch (s)                      2.67558
time/total (s)                    220.6
Epoch                              81
-----------------------------  ---------------
2019-04-22 21:25:34.713216 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 82 finished
-----------------------------  ----------------
replay_buffer/size              41700
trainer/QF1 Loss                    1.03111
trainer/QF2 Loss                    1.01993
trainer/Policy Loss                10.8078
trainer/Q1 Predictions Mean        -8.95838
trainer/Q1 Predictions Std          4.69841
trainer/Q1 Predictions Max         -7.07221
trainer/Q1 Predictions Min        -47.6509
trainer/Q2 Predictions Mean        -8.92523
trainer/Q2 Predictions Std          4.67607
trainer/Q2 Predictions Max         -7.06416
trainer/Q2 Predictions Min        -47.4955
trainer/Q Targets Mean             -8.86054
trainer/Q Targets Std               4.87244
trainer/Q Targets Max              -0.105508
trainer/Q Targets Min             -47.668
trainer/Log Pis Mean                2.03876
trainer/Log Pis Std                 1.11568
trainer/Log Pis Max                 5.79956
trainer/Log Pis Min                -1.80232
trainer/Policy mu Mean              0.0175471
trainer/Policy mu Std               0.61382
trainer/Policy mu Max               2.87664
trainer/Policy mu Min              -3.15182
trainer/Policy log std Mean        -2.18909
trainer/Policy log std Std          0.389772
trainer/Policy log std Max         -0.697219
trainer/Policy log std Min         -2.5529
trainer/Alpha                       0.0556964
trainer/Alpha Loss                  0.111932
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.293819
exploration/Rewards Std             0.916371
exploration/Rewards Max            -0.00936268
exploration/Rewards Min           -10.0481
exploration/Returns Mean          -29.3819
exploration/Returns Std            19.3245
exploration/Returns Max           -18.634
exploration/Returns Min           -67.9745
exploration/Actions Mean            0.000512499
exploration/Actions Std             0.21188
exploration/Actions Max             0.998993
exploration/Actions Min            -0.999184
exploration/Num Paths               5
exploration/Average Returns       -29.3819
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.272415
evaluation/Rewards Std              1.0302
evaluation/Rewards Max             -0.0198216
evaluation/Rewards Min            -10.7239
evaluation/Returns Mean           -27.2415
evaluation/Returns Std             15.909
evaluation/Returns Max             -8.93274
evaluation/Returns Min            -59.0355
evaluation/Actions Mean             0.0118732
evaluation/Actions Std              0.207991
evaluation/Actions Max              0.997135
evaluation/Actions Min             -0.998354
evaluation/Num Paths               15
evaluation/Average Returns        -27.2415
time/data storing (s)               0.00314106
time/evaluation sampling (s)        0.36456
time/exploration sampling (s)       0.165592
time/logging (s)                    0.00501603
time/saving (s)                     0.0020667
time/training (s)                   2.11919
time/epoch (s)                      2.65957
time/total (s)                    223.264
Epoch                              82
-----------------------------  ----------------
2019-04-22 21:25:37.431445 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                    1.16343
trainer/QF2 Loss                    1.16396
trainer/Policy Loss                10.3514
trainer/Q1 Predictions Mean        -8.66119
trainer/Q1 Predictions Std          4.11267
trainer/Q1 Predictions Max         -6.99813
trainer/Q1 Predictions Min        -34.3376
trainer/Q2 Predictions Mean        -8.63009
trainer/Q2 Predictions Std          4.12988
trainer/Q2 Predictions Max         -6.98863
trainer/Q2 Predictions Min        -34.9767
trainer/Q Targets Mean             -8.55534
trainer/Q Targets Std               4.27519
trainer/Q Targets Max              -0.283799
trainer/Q Targets Min             -34.3196
trainer/Log Pis Mean                2.07902
trainer/Log Pis Std                 1.11462
trainer/Log Pis Max                 6.21505
trainer/Log Pis Min                -1.97737
trainer/Policy mu Mean              0.0317369
trainer/Policy mu Std               0.58141
trainer/Policy mu Max               2.89465
trainer/Policy mu Min              -2.06645
trainer/Policy log std Mean        -2.21156
trainer/Policy log std Std          0.411415
trainer/Policy log std Max         -0.443647
trainer/Policy log std Min         -2.5807
trainer/Alpha                       0.0553643
trainer/Alpha Loss                  0.228678
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.284054
exploration/Rewards Std             0.92704
exploration/Rewards Max            -0.00328688
exploration/Rewards Min            -9.574
exploration/Returns Mean          -28.4054
exploration/Returns Std            18.7864
exploration/Returns Max           -12.7156
exploration/Returns Min           -63.0167
exploration/Actions Mean           -0.0162002
exploration/Actions Std             0.212602
exploration/Actions Max             0.988204
exploration/Actions Min            -0.998409
exploration/Num Paths               5
exploration/Average Returns       -28.4054
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.308676
evaluation/Rewards Std              1.13197
evaluation/Rewards Max             -0.0342936
evaluation/Rewards Min            -10.4296
evaluation/Returns Mean           -30.8676
evaluation/Returns Std             15.8546
evaluation/Returns Max             -6.41327
evaluation/Returns Min            -58.722
evaluation/Actions Mean            -0.00989609
evaluation/Actions Std              0.206709
evaluation/Actions Max              0.99653
evaluation/Actions Min             -0.997669
evaluation/Num Paths               15
evaluation/Average Returns        -30.8676
time/data storing (s)               0.0032866
time/evaluation sampling (s)        0.35288
time/exploration sampling (s)       0.159554
time/logging (s)                    0.00499508
time/saving (s)                     0.00215723
time/training (s)                   2.18919
time/epoch (s)                      2.71207
time/total (s)                    225.981
Epoch                              83
-----------------------------  ---------------
2019-04-22 21:25:40.075135 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                    0.683927
trainer/QF2 Loss                    0.712167
trainer/Policy Loss                10.8587
trainer/Q1 Predictions Mean        -9.17907
trainer/Q1 Predictions Std          6.66833
trainer/Q1 Predictions Max         -6.94515
trainer/Q1 Predictions Min        -54.3913
trainer/Q2 Predictions Mean        -9.15055
trainer/Q2 Predictions Std          6.60536
trainer/Q2 Predictions Max         -6.95314
trainer/Q2 Predictions Min        -53.5172
trainer/Q Targets Mean             -9.17572
trainer/Q Targets Std               6.75666
trainer/Q Targets Max              -0.119375
trainer/Q Targets Min             -55.27
trainer/Log Pis Mean                2.06933
trainer/Log Pis Std                 1.13406
trainer/Log Pis Max                 7.36969
trainer/Log Pis Min                -1.2413
trainer/Policy mu Mean              0.0630573
trainer/Policy mu Std               0.662442
trainer/Policy mu Max               3.02197
trainer/Policy mu Min              -3.03148
trainer/Policy log std Mean        -2.1111
trainer/Policy log std Std          0.428112
trainer/Policy log std Max         -0.490618
trainer/Policy log std Min         -2.47476
trainer/Alpha                       0.0579515
trainer/Alpha Loss                  0.19746
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.350362
exploration/Rewards Std             1.07846
exploration/Rewards Max            -0.00140095
exploration/Rewards Min           -10.5803
exploration/Returns Mean          -35.0362
exploration/Returns Std            18.9335
exploration/Returns Max           -16.2488
exploration/Returns Min           -70.7716
exploration/Actions Mean           -0.00255676
exploration/Actions Std             0.235794
exploration/Actions Max             0.998855
exploration/Actions Min            -0.999146
exploration/Num Paths               5
exploration/Average Returns       -35.0362
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.29529
evaluation/Rewards Std              1.06895
evaluation/Rewards Max             -0.0481951
evaluation/Rewards Min             -9.7685
evaluation/Returns Mean           -29.529
evaluation/Returns Std             15.3795
evaluation/Returns Max             -8.69666
evaluation/Returns Min            -57.1001
evaluation/Actions Mean             0.00414599
evaluation/Actions Std              0.200862
evaluation/Actions Max              0.997181
evaluation/Actions Min             -0.995865
evaluation/Num Paths               15
evaluation/Average Returns        -29.529
time/data storing (s)               0.00350878
time/evaluation sampling (s)        0.35727
time/exploration sampling (s)       0.164634
time/logging (s)                    0.00509218
time/saving (s)                     0.00202182
time/training (s)                   2.10496
time/epoch (s)                      2.63749
time/total (s)                    228.623
Epoch                              84
-----------------------------  ---------------
2019-04-22 21:25:42.780748 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                    1.62458
trainer/QF2 Loss                    1.64895
trainer/Policy Loss                10.2129
trainer/Q1 Predictions Mean        -8.35472
trainer/Q1 Predictions Std          3.15961
trainer/Q1 Predictions Max         -6.94453
trainer/Q1 Predictions Min        -28.3665
trainer/Q2 Predictions Mean        -8.38186
trainer/Q2 Predictions Std          3.11577
trainer/Q2 Predictions Max         -7.07885
trainer/Q2 Predictions Min        -28.1886
trainer/Q Targets Mean             -8.20764
trainer/Q Targets Std               3.4219
trainer/Q Targets Max              -0.0410674
trainer/Q Targets Min             -28.4537
trainer/Log Pis Mean                1.94068
trainer/Log Pis Std                 1.17146
trainer/Log Pis Max                 6.26178
trainer/Log Pis Min                -1.86892
trainer/Policy mu Mean              0.0218625
trainer/Policy mu Std               0.544053
trainer/Policy mu Max               2.89482
trainer/Policy mu Min              -2.87491
trainer/Policy log std Mean        -2.20048
trainer/Policy log std Std          0.361312
trainer/Policy log std Max         -0.565537
trainer/Policy log std Min         -2.52456
trainer/Alpha                       0.0567505
trainer/Alpha Loss                 -0.170204
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.431409
exploration/Rewards Std             1.29554
exploration/Rewards Max            -0.00230859
exploration/Rewards Min            -9.95249
exploration/Returns Mean          -43.1409
exploration/Returns Std            15.2755
exploration/Returns Max           -20.194
exploration/Returns Min           -66.5981
exploration/Actions Mean           -0.0178955
exploration/Actions Std             0.255899
exploration/Actions Max             0.998456
exploration/Actions Min            -0.999636
exploration/Num Paths               5
exploration/Average Returns       -43.1409
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.161996
evaluation/Rewards Std              0.715795
evaluation/Rewards Max             -0.0207954
evaluation/Rewards Min             -8.73306
evaluation/Returns Mean           -16.1996
evaluation/Returns Std             11.8627
evaluation/Returns Max             -2.42615
evaluation/Returns Min            -47.3629
evaluation/Actions Mean             0.00702668
evaluation/Actions Std              0.1656
evaluation/Actions Max              0.99588
evaluation/Actions Min             -0.997367
evaluation/Num Paths               15
evaluation/Average Returns        -16.1996
time/data storing (s)               0.00319313
time/evaluation sampling (s)        0.359693
time/exploration sampling (s)       0.159998
time/logging (s)                    0.00562969
time/saving (s)                     0.00248235
time/training (s)                   2.16915
time/epoch (s)                      2.70014
time/total (s)                    231.327
Epoch                              85
-----------------------------  ---------------
2019-04-22 21:25:45.461356 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size              43700
trainer/QF1 Loss                    0.0366045
trainer/QF2 Loss                    0.0306299
trainer/Policy Loss                 9.61605
trainer/Q1 Predictions Mean        -8.1261
trainer/Q1 Predictions Std          2.03195
trainer/Q1 Predictions Max         -6.82736
trainer/Q1 Predictions Min        -20.3108
trainer/Q2 Predictions Mean        -8.14719
trainer/Q2 Predictions Std          2.01968
trainer/Q2 Predictions Max         -6.91875
trainer/Q2 Predictions Min        -20.3895
trainer/Q Targets Mean             -8.24852
trainer/Q Targets Std               2.05109
trainer/Q Targets Max              -6.95606
trainer/Q Targets Min             -20.6363
trainer/Log Pis Mean                1.6266
trainer/Log Pis Std                 1.2609
trainer/Log Pis Max                 4.86775
trainer/Log Pis Min                -5.68081
trainer/Policy mu Mean              0.0331807
trainer/Policy mu Std               0.487657
trainer/Policy mu Max               2.74506
trainer/Policy mu Min              -2.83352
trainer/Policy log std Mean        -2.12414
trainer/Policy log std Std          0.35073
trainer/Policy log std Max         -0.511772
trainer/Policy log std Min         -2.395
trainer/Alpha                       0.055504
trainer/Alpha Loss                 -1.07946
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.286113
exploration/Rewards Std             0.870714
exploration/Rewards Max            -0.00215313
exploration/Rewards Min            -9.03191
exploration/Returns Mean          -28.6113
exploration/Returns Std            15.1812
exploration/Returns Max           -13.2603
exploration/Returns Min           -57.1005
exploration/Actions Mean            0.00855706
exploration/Actions Std             0.225109
exploration/Actions Max             0.998538
exploration/Actions Min            -0.998766
exploration/Num Paths               5
exploration/Average Returns       -28.6113
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.130888
evaluation/Rewards Std              0.630105
evaluation/Rewards Max             -0.0326933
evaluation/Rewards Min             -8.55446
evaluation/Returns Mean           -13.0888
evaluation/Returns Std             12.377
evaluation/Returns Max             -3.48216
evaluation/Returns Min            -43.425
evaluation/Actions Mean             0.00432415
evaluation/Actions Std              0.146105
evaluation/Actions Max              0.99494
evaluation/Actions Min             -0.997165
evaluation/Num Paths               15
evaluation/Average Returns        -13.0888
time/data storing (s)               0.00357239
time/evaluation sampling (s)        0.372337
time/exploration sampling (s)       0.164854
time/logging (s)                    0.00478024
time/saving (s)                     0.00223633
time/training (s)                   2.12426
time/epoch (s)                      2.67204
time/total (s)                    234.004
Epoch                              86
-----------------------------  ---------------
2019-04-22 21:25:48.231912 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size              44200
trainer/QF1 Loss                    0.0264476
trainer/QF2 Loss                    0.016123
trainer/Policy Loss                10.1291
trainer/Q1 Predictions Mean        -8.31025
trainer/Q1 Predictions Std          2.83632
trainer/Q1 Predictions Max         -6.90734
trainer/Q1 Predictions Min        -31.4578
trainer/Q2 Predictions Mean        -8.31246
trainer/Q2 Predictions Std          2.77956
trainer/Q2 Predictions Max         -6.91627
trainer/Q2 Predictions Min        -31.035
trainer/Q Targets Mean             -8.38313
trainer/Q Targets Std               2.75183
trainer/Q Targets Max              -6.88335
trainer/Q Targets Min             -30.8769
trainer/Log Pis Mean                1.99573
trainer/Log Pis Std                 1.21907
trainer/Log Pis Max                 7.61831
trainer/Log Pis Min                -1.55
trainer/Policy mu Mean             -0.0597097
trainer/Policy mu Std               0.57127
trainer/Policy mu Max               2.69062
trainer/Policy mu Min              -2.9184
trainer/Policy log std Mean        -2.16928
trainer/Policy log std Std          0.37544
trainer/Policy log std Max         -0.587665
trainer/Policy log std Min         -2.47483
trainer/Alpha                       0.0572298
trainer/Alpha Loss                 -0.0122068
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.249842
exploration/Rewards Std             0.717275
exploration/Rewards Max            -0.00330817
exploration/Rewards Min            -7.22413
exploration/Returns Mean          -24.9842
exploration/Returns Std             9.10935
exploration/Returns Max           -14.4034
exploration/Returns Min           -36.9985
exploration/Actions Mean           -0.0152044
exploration/Actions Std             0.219405
exploration/Actions Max             0.997112
exploration/Actions Min            -0.999341
exploration/Num Paths               5
exploration/Average Returns       -24.9842
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.264509
evaluation/Rewards Std              1.16024
evaluation/Rewards Max             -0.00329731
evaluation/Rewards Min            -10.4092
evaluation/Returns Mean           -26.4509
evaluation/Returns Std             18.305
evaluation/Returns Max             -2.35383
evaluation/Returns Min            -60.0395
evaluation/Actions Mean             0.0220567
evaluation/Actions Std              0.19968
evaluation/Actions Max              0.996111
evaluation/Actions Min             -0.996488
evaluation/Num Paths               15
evaluation/Average Returns        -26.4509
time/data storing (s)               0.00339741
time/evaluation sampling (s)        0.358693
time/exploration sampling (s)       0.15942
time/logging (s)                    0.00591165
time/saving (s)                     0.00234837
time/training (s)                   2.23516
time/epoch (s)                      2.76493
time/total (s)                    236.774
Epoch                              87
-----------------------------  ---------------
2019-04-22 21:25:51.091200 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size              44700
trainer/QF1 Loss                    0.693615
trainer/QF2 Loss                    0.698076
trainer/Policy Loss                 9.70703
trainer/Q1 Predictions Mean        -8.18195
trainer/Q1 Predictions Std          2.87674
trainer/Q1 Predictions Max         -7.00922
trainer/Q1 Predictions Min        -32.3757
trainer/Q2 Predictions Mean        -8.14718
trainer/Q2 Predictions Std          2.89624
trainer/Q2 Predictions Max         -6.94345
trainer/Q2 Predictions Min        -32.5636
trainer/Q Targets Mean             -8.08726
trainer/Q Targets Std               2.80653
trainer/Q Targets Max              -0.204042
trainer/Q Targets Min             -30.0934
trainer/Log Pis Mean                1.69858
trainer/Log Pis Std                 1.31639
trainer/Log Pis Max                 4.77975
trainer/Log Pis Min                -4.15021
trainer/Policy mu Mean              0.0462813
trainer/Policy mu Std               0.451129
trainer/Policy mu Max               3.20937
trainer/Policy mu Min              -1.53754
trainer/Policy log std Mean        -2.20603
trainer/Policy log std Std          0.308922
trainer/Policy log std Max         -0.585047
trainer/Policy log std Min         -2.44238
trainer/Alpha                       0.0551758
trainer/Alpha Loss                 -0.873268
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.325681
exploration/Rewards Std             0.912817
exploration/Rewards Max            -0.00524221
exploration/Rewards Min            -7.68994
exploration/Returns Mean          -32.5681
exploration/Returns Std             9.34025
exploration/Returns Max           -15.6341
exploration/Returns Min           -41.386
exploration/Actions Mean           -0.0233636
exploration/Actions Std             0.245795
exploration/Actions Max             0.990096
exploration/Actions Min            -0.999379
exploration/Num Paths               5
exploration/Average Returns       -32.5681
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.18186
evaluation/Rewards Std              0.781542
evaluation/Rewards Max             -0.0101003
evaluation/Rewards Min             -8.61506
evaluation/Returns Mean           -18.186
evaluation/Returns Std             13.0423
evaluation/Returns Max             -2.33698
evaluation/Returns Min            -45.7556
evaluation/Actions Mean            -0.00843933
evaluation/Actions Std              0.175398
evaluation/Actions Max              0.994573
evaluation/Actions Min             -0.998302
evaluation/Num Paths               15
evaluation/Average Returns        -18.186
time/data storing (s)               0.00358699
time/evaluation sampling (s)        0.390519
time/exploration sampling (s)       0.206785
time/logging (s)                    0.00443381
time/saving (s)                     0.0021944
time/training (s)                   2.24238
time/epoch (s)                      2.8499
time/total (s)                    239.629
Epoch                              88
-----------------------------  ---------------
2019-04-22 21:25:53.798222 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 89 finished
-----------------------------  ---------------
replay_buffer/size              45200
trainer/QF1 Loss                   32.1844
trainer/QF2 Loss                   31.5232
trainer/Policy Loss                12.2003
trainer/Q1 Predictions Mean       -10.81
trainer/Q1 Predictions Std         12.6765
trainer/Q1 Predictions Max         -6.70223
trainer/Q1 Predictions Min        -67.2463
trainer/Q2 Predictions Mean       -10.8412
trainer/Q2 Predictions Std         12.5588
trainer/Q2 Predictions Max         -6.88366
trainer/Q2 Predictions Min        -66.619
trainer/Q Targets Mean            -10.3204
trainer/Q Targets Std              11.5315
trainer/Q Targets Max              -0.166033
trainer/Q Targets Min             -65.9168
trainer/Log Pis Mean                2.0649
trainer/Log Pis Std                 1.72605
trainer/Log Pis Max                 8.99965
trainer/Log Pis Min                -3.56933
trainer/Policy mu Mean              0.0440536
trainer/Policy mu Std               0.710743
trainer/Policy mu Max               3.27798
trainer/Policy mu Min              -3.02163
trainer/Policy log std Mean        -2.15366
trainer/Policy log std Std          0.424353
trainer/Policy log std Max         -0.613012
trainer/Policy log std Min         -2.49921
trainer/Alpha                       0.0571852
trainer/Alpha Loss                  0.185704
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.376393
exploration/Rewards Std             1.18897
exploration/Rewards Max            -0.00417927
exploration/Rewards Min           -10.2607
exploration/Returns Mean          -37.6393
exploration/Returns Std            18.7165
exploration/Returns Max           -16.9066
exploration/Returns Min           -67.8474
exploration/Actions Mean            0.0165397
exploration/Actions Std             0.250299
exploration/Actions Max             0.999534
exploration/Actions Min            -0.999533
exploration/Num Paths               5
exploration/Average Returns       -37.6393
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.200594
evaluation/Rewards Std              0.884531
evaluation/Rewards Max             -0.0299737
evaluation/Rewards Min             -9.83248
evaluation/Returns Mean           -20.0594
evaluation/Returns Std             14.4726
evaluation/Returns Max             -4.96088
evaluation/Returns Min            -50.8158
evaluation/Actions Mean             0.00997944
evaluation/Actions Std              0.18424
evaluation/Actions Max              0.996053
evaluation/Actions Min             -0.997093
evaluation/Num Paths               15
evaluation/Average Returns        -20.0594
time/data storing (s)               0.0035293
time/evaluation sampling (s)        0.382559
time/exploration sampling (s)       0.175494
time/logging (s)                    0.00559318
time/saving (s)                     0.0020615
time/training (s)                   2.13142
time/epoch (s)                      2.70066
time/total (s)                    242.336
Epoch                              89
-----------------------------  ---------------
2019-04-22 21:25:56.524346 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 90 finished
-----------------------------  ----------------
replay_buffer/size              45700
trainer/QF1 Loss                    0.551109
trainer/QF2 Loss                    0.426104
trainer/Policy Loss                10.1001
trainer/Q1 Predictions Mean        -8.42067
trainer/Q1 Predictions Std          5.21442
trainer/Q1 Predictions Max         -6.78271
trainer/Q1 Predictions Min        -54.102
trainer/Q2 Predictions Mean        -8.42491
trainer/Q2 Predictions Std          5.29147
trainer/Q2 Predictions Max         -6.77676
trainer/Q2 Predictions Min        -55.0119
trainer/Q Targets Mean             -8.53477
trainer/Q Targets Std               5.85038
trainer/Q Targets Max              -6.83262
trainer/Q Targets Min             -61.4071
trainer/Log Pis Mean                1.89956
trainer/Log Pis Std                 1.25563
trainer/Log Pis Max                 8.09954
trainer/Log Pis Min                -2.69647
trainer/Policy mu Mean             -0.0195429
trainer/Policy mu Std               0.543486
trainer/Policy mu Max               2.8192
trainer/Policy mu Min              -3.03546
trainer/Policy log std Mean        -2.1979
trainer/Policy log std Std          0.336625
trainer/Policy log std Max         -0.63836
trainer/Policy log std Min         -2.51487
trainer/Alpha                       0.0575433
trainer/Alpha Loss                 -0.286771
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.288992
exploration/Rewards Std             0.887759
exploration/Rewards Max            -0.0129469
exploration/Rewards Min            -9.54818
exploration/Returns Mean          -28.8992
exploration/Returns Std            14.835
exploration/Returns Max           -14.4002
exploration/Returns Min           -53.5143
exploration/Actions Mean           -0.000274675
exploration/Actions Std             0.226043
exploration/Actions Max             0.999585
exploration/Actions Min            -0.99935
exploration/Num Paths               5
exploration/Average Returns       -28.8992
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.157833
evaluation/Rewards Std              0.707131
evaluation/Rewards Max             -0.0053537
evaluation/Rewards Min            -10.3738
evaluation/Returns Mean           -15.7833
evaluation/Returns Std             14.3337
evaluation/Returns Max             -3.17497
evaluation/Returns Min            -64.5042
evaluation/Actions Mean            -0.00673441
evaluation/Actions Std              0.164891
evaluation/Actions Max              0.995144
evaluation/Actions Min             -0.9969
evaluation/Num Paths               15
evaluation/Average Returns        -15.7833
time/data storing (s)               0.003133
time/evaluation sampling (s)        0.365254
time/exploration sampling (s)       0.164248
time/logging (s)                    0.00504576
time/saving (s)                     0.00202074
time/training (s)                   2.17887
time/epoch (s)                      2.71857
time/total (s)                    245.059
Epoch                              90
-----------------------------  ----------------
2019-04-22 21:25:59.180851 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                    0.0260997
trainer/QF2 Loss                    0.0374174
trainer/Policy Loss                10.7287
trainer/Q1 Predictions Mean        -9.06655
trainer/Q1 Predictions Std          6.932
trainer/Q1 Predictions Max         -6.72638
trainer/Q1 Predictions Min        -57.0854
trainer/Q2 Predictions Mean        -9.0296
trainer/Q2 Predictions Std          6.92086
trainer/Q2 Predictions Max         -6.68268
trainer/Q2 Predictions Min        -56.7205
trainer/Q Targets Mean             -9.12254
trainer/Q Targets Std               6.96706
trainer/Q Targets Max              -6.77158
trainer/Q Targets Min             -57.6387
trainer/Log Pis Mean                1.83877
trainer/Log Pis Std                 1.37005
trainer/Log Pis Max                 6.04375
trainer/Log Pis Min                -2.36704
trainer/Policy mu Mean             -0.0168437
trainer/Policy mu Std               0.661507
trainer/Policy mu Max               3.04545
trainer/Policy mu Min              -2.93702
trainer/Policy log std Mean        -2.16999
trainer/Policy log std Std          0.406614
trainer/Policy log std Max         -0.623494
trainer/Policy log std Min         -2.49025
trainer/Alpha                       0.0577056
trainer/Alpha Loss                 -0.459892
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.20291
exploration/Rewards Std             0.504067
exploration/Rewards Max            -0.0028497
exploration/Rewards Min            -5.77309
exploration/Returns Mean          -20.291
exploration/Returns Std             5.64486
exploration/Returns Max           -13.8701
exploration/Returns Min           -27.5474
exploration/Actions Mean           -0.0212736
exploration/Actions Std             0.202492
exploration/Actions Max             0.980533
exploration/Actions Min            -0.997181
exploration/Num Paths               5
exploration/Average Returns       -20.291
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.252728
evaluation/Rewards Std              1.08512
evaluation/Rewards Max             -0.0129652
evaluation/Rewards Min             -9.60171
evaluation/Returns Mean           -25.2728
evaluation/Returns Std             17.3274
evaluation/Returns Max             -4.85622
evaluation/Returns Min            -53.8754
evaluation/Actions Mean            -0.00848462
evaluation/Actions Std              0.194057
evaluation/Actions Max              0.995838
evaluation/Actions Min             -0.997758
evaluation/Num Paths               15
evaluation/Average Returns        -25.2728
time/data storing (s)               0.003117
time/evaluation sampling (s)        0.35085
time/exploration sampling (s)       0.159696
time/logging (s)                    0.00506566
time/saving (s)                     0.00240426
time/training (s)                   2.12874
time/epoch (s)                      2.64987
time/total (s)                    247.713
Epoch                              91
-----------------------------  ---------------
2019-04-22 21:26:01.940375 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size              46700
trainer/QF1 Loss                    0.0298916
trainer/QF2 Loss                    0.0173767
trainer/Policy Loss                 9.75873
trainer/Q1 Predictions Mean        -8.06706
trainer/Q1 Predictions Std          2.88836
trainer/Q1 Predictions Max         -7.0077
trainer/Q1 Predictions Min        -31.9107
trainer/Q2 Predictions Mean        -7.96664
trainer/Q2 Predictions Std          2.91281
trainer/Q2 Predictions Max         -6.80142
trainer/Q2 Predictions Min        -31.8347
trainer/Q Targets Mean             -8.04112
trainer/Q Targets Std               2.87523
trainer/Q Targets Max              -6.75538
trainer/Q Targets Min             -31.4553
trainer/Log Pis Mean                1.87021
trainer/Log Pis Std                 1.27037
trainer/Log Pis Max                 7.52954
trainer/Log Pis Min                -2.92793
trainer/Policy mu Mean             -0.0238791
trainer/Policy mu Std               0.549308
trainer/Policy mu Max               2.3141
trainer/Policy mu Min              -2.9005
trainer/Policy log std Mean        -2.11967
trainer/Policy log std Std          0.391629
trainer/Policy log std Max         -0.527436
trainer/Policy log std Min         -2.46493
trainer/Alpha                       0.0575089
trainer/Alpha Loss                 -0.370667
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.191839
exploration/Rewards Std             0.383515
exploration/Rewards Max            -0.00806456
exploration/Rewards Min            -4.39716
exploration/Returns Mean          -19.1839
exploration/Returns Std             4.10421
exploration/Returns Max           -14.9894
exploration/Returns Min           -25.5893
exploration/Actions Mean            0.00162401
exploration/Actions Std             0.203485
exploration/Actions Max             0.986366
exploration/Actions Min            -0.998609
exploration/Num Paths               5
exploration/Average Returns       -19.1839
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.189734
evaluation/Rewards Std              0.839153
evaluation/Rewards Max             -0.0177017
evaluation/Rewards Min            -10.5931
evaluation/Returns Mean           -18.9734
evaluation/Returns Std             15.3307
evaluation/Returns Max             -3.45496
evaluation/Returns Min            -60.6461
evaluation/Actions Mean             0.00166006
evaluation/Actions Std              0.179362
evaluation/Actions Max              0.998046
evaluation/Actions Min             -0.99749
evaluation/Num Paths               15
evaluation/Average Returns        -18.9734
time/data storing (s)               0.00322503
time/evaluation sampling (s)        0.353411
time/exploration sampling (s)       0.158622
time/logging (s)                    0.00520832
time/saving (s)                     0.00201673
time/training (s)                   2.23022
time/epoch (s)                      2.7527
time/total (s)                    250.471
Epoch                              92
-----------------------------  ---------------
2019-04-22 21:26:04.599910 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 93 finished
-----------------------------  ----------------
replay_buffer/size              47200
trainer/QF1 Loss                    0.617718
trainer/QF2 Loss                    0.673122
trainer/Policy Loss                11.5865
trainer/Q1 Predictions Mean        -9.9863
trainer/Q1 Predictions Std          9.89832
trainer/Q1 Predictions Max         -6.83605
trainer/Q1 Predictions Min        -81.2423
trainer/Q2 Predictions Mean        -9.98878
trainer/Q2 Predictions Std         10.0007
trainer/Q2 Predictions Max         -6.77827
trainer/Q2 Predictions Min        -82.1003
trainer/Q Targets Mean             -9.89582
trainer/Q Targets Std               9.71091
trainer/Q Targets Max              -0.498273
trainer/Q Targets Min             -77.9497
trainer/Log Pis Mean                2.03118
trainer/Log Pis Std                 1.29454
trainer/Log Pis Max                 7.95803
trainer/Log Pis Min                -1.98186
trainer/Policy mu Mean              0.00227956
trainer/Policy mu Std               0.755718
trainer/Policy mu Max               3.25586
trainer/Policy mu Min              -3.31059
trainer/Policy log std Mean        -2.07588
trainer/Policy log std Std          0.472791
trainer/Policy log std Max         -0.454138
trainer/Policy log std Min         -2.40961
trainer/Alpha                       0.0575451
trainer/Alpha Loss                  0.0890113
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.379182
exploration/Rewards Std             1.17324
exploration/Rewards Max            -0.00214352
exploration/Rewards Min           -10.5523
exploration/Returns Mean          -37.9182
exploration/Returns Std            16.5551
exploration/Returns Max           -21.7114
exploration/Returns Min           -63.4715
exploration/Actions Mean            0.00741443
exploration/Actions Std             0.251636
exploration/Actions Max             0.996338
exploration/Actions Min            -0.99982
exploration/Num Paths               5
exploration/Average Returns       -37.9182
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283291
evaluation/Rewards Std              1.25749
evaluation/Rewards Max             -0.00542487
evaluation/Rewards Min            -11.3213
evaluation/Returns Mean           -28.3291
evaluation/Returns Std             20.4947
evaluation/Returns Max             -1.48485
evaluation/Returns Min            -60.7398
evaluation/Actions Mean            -0.000574331
evaluation/Actions Std              0.208242
evaluation/Actions Max              0.997192
evaluation/Actions Min             -0.997804
evaluation/Num Paths               15
evaluation/Average Returns        -28.3291
time/data storing (s)               0.00354054
time/evaluation sampling (s)        0.359034
time/exploration sampling (s)       0.165691
time/logging (s)                    0.00499107
time/saving (s)                     0.00196427
time/training (s)                   2.11716
time/epoch (s)                      2.65238
time/total (s)                    253.128
Epoch                              93
-----------------------------  ----------------
2019-04-22 21:26:07.315383 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size              47700
trainer/QF1 Loss                    0.0362998
trainer/QF2 Loss                    0.0471088
trainer/Policy Loss                10.3618
trainer/Q1 Predictions Mean        -8.56834
trainer/Q1 Predictions Std          5.75896
trainer/Q1 Predictions Max         -6.76795
trainer/Q1 Predictions Min        -43.8052
trainer/Q2 Predictions Mean        -8.48958
trainer/Q2 Predictions Std          5.79094
trainer/Q2 Predictions Max         -6.59908
trainer/Q2 Predictions Min        -43.6886
trainer/Q Targets Mean             -8.669
trainer/Q Targets Std               5.8719
trainer/Q Targets Max              -6.7088
trainer/Q Targets Min             -44.8573
trainer/Log Pis Mean                1.88062
trainer/Log Pis Std                 1.35505
trainer/Log Pis Max                 5.95412
trainer/Log Pis Min                -2.42852
trainer/Policy mu Mean              0.0497741
trainer/Policy mu Std               0.546663
trainer/Policy mu Max               2.98508
trainer/Policy mu Min              -2.95029
trainer/Policy log std Mean        -2.2369
trainer/Policy log std Std          0.341689
trainer/Policy log std Max         -0.567348
trainer/Policy log std Min         -2.46167
trainer/Alpha                       0.05658
trainer/Alpha Loss                 -0.342875
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.237275
exploration/Rewards Std             0.655146
exploration/Rewards Max            -0.00294183
exploration/Rewards Min            -7.26745
exploration/Returns Mean          -23.7275
exploration/Returns Std             9.95213
exploration/Returns Max           -13.6012
exploration/Returns Min           -42.071
exploration/Actions Mean           -0.0170647
exploration/Actions Std             0.209288
exploration/Actions Max             0.995457
exploration/Actions Min            -0.999179
exploration/Num Paths               5
exploration/Average Returns       -23.7275
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.227008
evaluation/Rewards Std              1.01516
evaluation/Rewards Max             -0.00682503
evaluation/Rewards Min             -9.8725
evaluation/Returns Mean           -22.7008
evaluation/Returns Std             15.3305
evaluation/Returns Max             -3.14914
evaluation/Returns Min            -56.2955
evaluation/Actions Mean            -0.018209
evaluation/Actions Std              0.20166
evaluation/Actions Max              0.995615
evaluation/Actions Min             -0.997826
evaluation/Num Paths               15
evaluation/Average Returns        -22.7008
time/data storing (s)               0.00317624
time/evaluation sampling (s)        0.357687
time/exploration sampling (s)       0.161666
time/logging (s)                    0.00505502
time/saving (s)                     0.0020126
time/training (s)                   2.17925
time/epoch (s)                      2.70885
time/total (s)                    255.842
Epoch                              94
-----------------------------  ---------------
2019-04-22 21:26:09.982826 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                    0.0452727
trainer/QF2 Loss                    0.0872738
trainer/Policy Loss                11.2506
trainer/Q1 Predictions Mean        -9.31173
trainer/Q1 Predictions Std          8.49368
trainer/Q1 Predictions Max         -6.73791
trainer/Q1 Predictions Min        -68.9416
trainer/Q2 Predictions Mean        -9.25539
trainer/Q2 Predictions Std          8.45314
trainer/Q2 Predictions Max         -6.65272
trainer/Q2 Predictions Min        -68.251
trainer/Q Targets Mean             -9.32518
trainer/Q Targets Std               8.65375
trainer/Q Targets Max              -6.68469
trainer/Q Targets Min             -70.7151
trainer/Log Pis Mean                2.1484
trainer/Log Pis Std                 1.22235
trainer/Log Pis Max                 8.02947
trainer/Log Pis Min                -1.23588
trainer/Policy mu Mean             -0.00999929
trainer/Policy mu Std               0.781543
trainer/Policy mu Max               3.23404
trainer/Policy mu Min              -2.89357
trainer/Policy log std Mean        -2.0726
trainer/Policy log std Std          0.474415
trainer/Policy log std Max         -0.523665
trainer/Policy log std Min         -2.36756
trainer/Alpha                       0.0561255
trainer/Alpha Loss                  0.427424
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.251472
exploration/Rewards Std             0.767389
exploration/Rewards Max            -0.00206542
exploration/Rewards Min            -9.17747
exploration/Returns Mean          -25.1472
exploration/Returns Std            13.9405
exploration/Returns Max           -13.3769
exploration/Returns Min           -51.4272
exploration/Actions Mean            0.00329191
exploration/Actions Std             0.214774
exploration/Actions Max             0.998448
exploration/Actions Min            -0.999367
exploration/Num Paths               5
exploration/Average Returns       -25.1472
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.194616
evaluation/Rewards Std              0.818713
evaluation/Rewards Max             -0.0147392
evaluation/Rewards Min             -9.62171
evaluation/Returns Mean           -19.4616
evaluation/Returns Std             11.8975
evaluation/Returns Max             -5.52726
evaluation/Returns Min            -53.7739
evaluation/Actions Mean            -0.00984642
evaluation/Actions Std              0.191526
evaluation/Actions Max              0.996354
evaluation/Actions Min             -0.998364
evaluation/Num Paths               15
evaluation/Average Returns        -19.4616
time/data storing (s)               0.0031614
time/evaluation sampling (s)        0.356102
time/exploration sampling (s)       0.160503
time/logging (s)                    0.00495162
time/saving (s)                     0.0020069
time/training (s)                   2.13405
time/epoch (s)                      2.66077
time/total (s)                    258.507
Epoch                              95
-----------------------------  ---------------
2019-04-22 21:26:12.778041 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size              48700
trainer/QF1 Loss                    0.0322057
trainer/QF2 Loss                    0.0258365
trainer/Policy Loss                10.8043
trainer/Q1 Predictions Mean        -8.84727
trainer/Q1 Predictions Std          6.98275
trainer/Q1 Predictions Max         -6.59581
trainer/Q1 Predictions Min        -62.3742
trainer/Q2 Predictions Mean        -8.88404
trainer/Q2 Predictions Std          6.95684
trainer/Q2 Predictions Max         -6.77701
trainer/Q2 Predictions Min        -62.6358
trainer/Q Targets Mean             -8.85221
trainer/Q Targets Std               6.89842
trainer/Q Targets Max              -6.66977
trainer/Q Targets Min             -61.9057
trainer/Log Pis Mean                2.05588
trainer/Log Pis Std                 1.52089
trainer/Log Pis Max                 8.45599
trainer/Log Pis Min                -2.1541
trainer/Policy mu Mean             -0.0224729
trainer/Policy mu Std               0.732976
trainer/Policy mu Max               3.23706
trainer/Policy mu Min              -3.06721
trainer/Policy log std Mean        -2.08512
trainer/Policy log std Std          0.487015
trainer/Policy log std Max         -0.407408
trainer/Policy log std Min         -2.51121
trainer/Alpha                       0.0549633
trainer/Alpha Loss                  0.162102
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.312834
exploration/Rewards Std             0.826952
exploration/Rewards Max            -0.01261
exploration/Rewards Min            -7.71894
exploration/Returns Mean          -31.2834
exploration/Returns Std            13.0209
exploration/Returns Max           -19.0473
exploration/Returns Min           -50.7298
exploration/Actions Mean           -0.0228394
exploration/Actions Std             0.240289
exploration/Actions Max             0.99932
exploration/Actions Min            -0.999441
exploration/Num Paths               5
exploration/Average Returns       -31.2834
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.196301
evaluation/Rewards Std              0.66464
evaluation/Rewards Max             -0.0297149
evaluation/Rewards Min             -8.08089
evaluation/Returns Mean           -19.6301
evaluation/Returns Std             12.1086
evaluation/Returns Max             -5.31277
evaluation/Returns Min            -48.1914
evaluation/Actions Mean            -0.00834574
evaluation/Actions Std              0.16582
evaluation/Actions Max              0.991696
evaluation/Actions Min             -0.996976
evaluation/Num Paths               15
evaluation/Average Returns        -19.6301
time/data storing (s)               0.00321859
time/evaluation sampling (s)        0.35826
time/exploration sampling (s)       0.16391
time/logging (s)                    0.00545608
time/saving (s)                     0.133522
time/training (s)                   2.12484
time/epoch (s)                      2.78921
time/total (s)                    261.301
Epoch                              96
-----------------------------  ---------------
2019-04-22 21:26:15.443603 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                    1.02742
trainer/QF2 Loss                    1.04981
trainer/Policy Loss                 9.7115
trainer/Q1 Predictions Mean        -8.13086
trainer/Q1 Predictions Std          4.13768
trainer/Q1 Predictions Max         -6.70631
trainer/Q1 Predictions Min        -37.1996
trainer/Q2 Predictions Mean        -8.10595
trainer/Q2 Predictions Std          4.0808
trainer/Q2 Predictions Max         -6.7042
trainer/Q2 Predictions Min        -36.3447
trainer/Q Targets Mean             -8.02957
trainer/Q Targets Std               4.34764
trainer/Q Targets Max              -0.0965339
trainer/Q Targets Min             -38.2053
trainer/Log Pis Mean                1.97702
trainer/Log Pis Std                 1.19386
trainer/Log Pis Max                 6.53496
trainer/Log Pis Min                -2.08369
trainer/Policy mu Mean              0.0715853
trainer/Policy mu Std               0.592816
trainer/Policy mu Max               2.85246
trainer/Policy mu Min              -2.49845
trainer/Policy log std Mean        -2.21174
trainer/Policy log std Std          0.426086
trainer/Policy log std Max         -0.513539
trainer/Policy log std Min         -2.52114
trainer/Alpha                       0.0579526
trainer/Alpha Loss                 -0.0654416
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.330754
exploration/Rewards Std             0.98745
exploration/Rewards Max            -0.00240661
exploration/Rewards Min            -8.50513
exploration/Returns Mean          -33.0754
exploration/Returns Std            12.0996
exploration/Returns Max           -21.3674
exploration/Returns Min           -51.585
exploration/Actions Mean            0.00480935
exploration/Actions Std             0.241096
exploration/Actions Max             0.999252
exploration/Actions Min            -0.997982
exploration/Num Paths               5
exploration/Average Returns       -33.0754
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274187
evaluation/Rewards Std              1.13207
evaluation/Rewards Max             -0.0128025
evaluation/Rewards Min            -10.3992
evaluation/Returns Mean           -27.4187
evaluation/Returns Std             17.2782
evaluation/Returns Max             -3.61775
evaluation/Returns Min            -62.0429
evaluation/Actions Mean            -0.00676872
evaluation/Actions Std              0.1987
evaluation/Actions Max              0.995481
evaluation/Actions Min             -0.998359
evaluation/Num Paths               15
evaluation/Average Returns        -27.4187
time/data storing (s)               0.00334952
time/evaluation sampling (s)        0.377455
time/exploration sampling (s)       0.159686
time/logging (s)                    0.00394973
time/saving (s)                     0.00208521
time/training (s)                   2.10812
time/epoch (s)                      2.65464
time/total (s)                    263.962
Epoch                              97
-----------------------------  ---------------
2019-04-22 21:26:18.112026 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                    0.48364
trainer/QF2 Loss                    0.503618
trainer/Policy Loss                 9.46255
trainer/Q1 Predictions Mean        -7.63454
trainer/Q1 Predictions Std          1.81393
trainer/Q1 Predictions Max         -6.64483
trainer/Q1 Predictions Min        -19.2353
trainer/Q2 Predictions Mean        -7.64829
trainer/Q2 Predictions Std          1.80916
trainer/Q2 Predictions Max         -6.66315
trainer/Q2 Predictions Min        -19.5381
trainer/Q Targets Mean             -7.54747
trainer/Q Targets Std               1.81526
trainer/Q Targets Max              -0.0957051
trainer/Q Targets Min             -17.3665
trainer/Log Pis Mean                1.95125
trainer/Log Pis Std                 1.02354
trainer/Log Pis Max                 3.69025
trainer/Log Pis Min                -1.57978
trainer/Policy mu Mean              0.0433231
trainer/Policy mu Std               0.455426
trainer/Policy mu Max               2.763
trainer/Policy mu Min              -1.1431
trainer/Policy log std Mean        -2.20617
trainer/Policy log std Std          0.329689
trainer/Policy log std Max         -0.528573
trainer/Policy log std Min         -2.44607
trainer/Alpha                       0.0557497
trainer/Alpha Loss                 -0.140743
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.18501
exploration/Rewards Std             0.351535
exploration/Rewards Max            -0.00681115
exploration/Rewards Min            -4.0706
exploration/Returns Mean          -18.501
exploration/Returns Std             2.68674
exploration/Returns Max           -15.4213
exploration/Returns Min           -22.2641
exploration/Actions Mean            0.00212887
exploration/Actions Std             0.201675
exploration/Actions Max             0.99828
exploration/Actions Min            -0.992372
exploration/Num Paths               5
exploration/Average Returns       -18.501
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241201
evaluation/Rewards Std              0.944332
evaluation/Rewards Max             -0.0199539
evaluation/Rewards Min            -11.3112
evaluation/Returns Mean           -24.1201
evaluation/Returns Std             16.7819
evaluation/Returns Max             -8.124
evaluation/Returns Min            -67.5287
evaluation/Actions Mean            -0.0085953
evaluation/Actions Std              0.184137
evaluation/Actions Max              0.994679
evaluation/Actions Min             -0.997981
evaluation/Num Paths               15
evaluation/Average Returns        -24.1201
time/data storing (s)               0.003178
time/evaluation sampling (s)        0.3568
time/exploration sampling (s)       0.166163
time/logging (s)                    0.00507784
time/saving (s)                     0.00216252
time/training (s)                   2.1304
time/epoch (s)                      2.66378
time/total (s)                    266.63
Epoch                              98
-----------------------------  ---------------
2019-04-22 21:26:20.823549 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                    0.492983
trainer/QF2 Loss                    0.485779
trainer/Policy Loss                 9.66882
trainer/Q1 Predictions Mean        -8.07046
trainer/Q1 Predictions Std          4.99222
trainer/Q1 Predictions Max         -6.68137
trainer/Q1 Predictions Min        -51.8287
trainer/Q2 Predictions Mean        -8.08072
trainer/Q2 Predictions Std          4.98911
trainer/Q2 Predictions Max         -6.67435
trainer/Q2 Predictions Min        -51.747
trainer/Q Targets Mean             -8.12482
trainer/Q Targets Std               5.17938
trainer/Q Targets Max              -0.119185
trainer/Q Targets Min             -52.7386
trainer/Log Pis Mean                1.78341
trainer/Log Pis Std                 1.24768
trainer/Log Pis Max                 7.85908
trainer/Log Pis Min                -2.04298
trainer/Policy mu Mean             -0.0599124
trainer/Policy mu Std               0.572677
trainer/Policy mu Max               3.11938
trainer/Policy mu Min              -2.71658
trainer/Policy log std Mean        -2.12026
trainer/Policy log std Std          0.362477
trainer/Policy log std Max         -0.525158
trainer/Policy log std Min         -2.39999
trainer/Alpha                       0.0556428
trainer/Alpha Loss                 -0.625666
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.320401
exploration/Rewards Std             1.03111
exploration/Rewards Max            -0.00513858
exploration/Rewards Min           -10.8944
exploration/Returns Mean          -32.0401
exploration/Returns Std            20.2005
exploration/Returns Max           -16.0303
exploration/Returns Min           -68.1659
exploration/Actions Mean           -0.0123415
exploration/Actions Std             0.234855
exploration/Actions Max             0.997496
exploration/Actions Min            -0.999311
exploration/Num Paths               5
exploration/Average Returns       -32.0401
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.186867
evaluation/Rewards Std              0.821266
evaluation/Rewards Max             -0.0195946
evaluation/Rewards Min            -10.432
evaluation/Returns Mean           -18.6867
evaluation/Returns Std             14.5781
evaluation/Returns Max             -5.10742
evaluation/Returns Min            -62.4782
evaluation/Actions Mean            -0.0124685
evaluation/Actions Std              0.181814
evaluation/Actions Max              0.993062
evaluation/Actions Min             -0.997119
evaluation/Num Paths               15
evaluation/Average Returns        -18.6867
time/data storing (s)               0.00316417
time/evaluation sampling (s)        0.360951
time/exploration sampling (s)       0.163325
time/logging (s)                    0.0049337
time/saving (s)                     0.00201498
time/training (s)                   2.17017
time/epoch (s)                      2.70456
time/total (s)                    269.339
Epoch                              99
-----------------------------  ---------------
2019-04-22 21:26:23.480650 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              50700
trainer/QF1 Loss                    0.942136
trainer/QF2 Loss                    0.93361
trainer/Policy Loss                10.5617
trainer/Q1 Predictions Mean        -8.6847
trainer/Q1 Predictions Std          6.93595
trainer/Q1 Predictions Max         -6.76187
trainer/Q1 Predictions Min        -58.9694
trainer/Q2 Predictions Mean        -8.64546
trainer/Q2 Predictions Std          6.99038
trainer/Q2 Predictions Max         -6.73538
trainer/Q2 Predictions Min        -59.1124
trainer/Q Targets Mean             -8.55763
trainer/Q Targets Std               6.99583
trainer/Q Targets Max              -0.0829681
trainer/Q Targets Min             -58.2863
trainer/Log Pis Mean                2.04667
trainer/Log Pis Std                 1.45077
trainer/Log Pis Max                 8.99412
trainer/Log Pis Min                -3.7225
trainer/Policy mu Mean             -0.022736
trainer/Policy mu Std               0.680367
trainer/Policy mu Max               3.19357
trainer/Policy mu Min              -3.02683
trainer/Policy log std Mean        -2.13646
trainer/Policy log std Std          0.440409
trainer/Policy log std Max         -0.553232
trainer/Policy log std Min         -2.47662
trainer/Alpha                       0.0545612
trainer/Alpha Loss                  0.13574
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.282025
exploration/Rewards Std             0.932547
exploration/Rewards Max            -0.00835902
exploration/Rewards Min           -10.0389
exploration/Returns Mean          -28.2025
exploration/Returns Std            18.5939
exploration/Returns Max           -13.4676
exploration/Returns Min           -64.9305
exploration/Actions Mean            0.00950021
exploration/Actions Std             0.225193
exploration/Actions Max             0.999166
exploration/Actions Min            -0.992592
exploration/Num Paths               5
exploration/Average Returns       -28.2025
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.338408
evaluation/Rewards Std              1.36703
evaluation/Rewards Max             -0.0118505
evaluation/Rewards Min            -10.9271
evaluation/Returns Mean           -33.8408
evaluation/Returns Std             20.6315
evaluation/Returns Max             -5.01291
evaluation/Returns Min            -61.5605
evaluation/Actions Mean             0.00477471
evaluation/Actions Std              0.217322
evaluation/Actions Max              0.997646
evaluation/Actions Min             -0.997729
evaluation/Num Paths               15
evaluation/Average Returns        -33.8408
time/data storing (s)               0.00316685
time/evaluation sampling (s)        0.357694
time/exploration sampling (s)       0.159274
time/logging (s)                    0.00504405
time/saving (s)                     0.00199357
time/training (s)                   2.12296
time/epoch (s)                      2.65013
time/total (s)                    271.994
Epoch                             100
-----------------------------  ---------------
2019-04-22 21:26:26.153262 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 101 finished
-----------------------------  ----------------
replay_buffer/size              51200
trainer/QF1 Loss                    1.00452
trainer/QF2 Loss                    0.985763
trainer/Policy Loss                 9.36289
trainer/Q1 Predictions Mean        -7.89679
trainer/Q1 Predictions Std          4.58845
trainer/Q1 Predictions Max         -6.47255
trainer/Q1 Predictions Min        -48.5573
trainer/Q2 Predictions Mean        -7.91015
trainer/Q2 Predictions Std          4.57781
trainer/Q2 Predictions Max         -6.52162
trainer/Q2 Predictions Min        -48.1889
trainer/Q Targets Mean             -7.94707
trainer/Q Targets Std               4.6972
trainer/Q Targets Max              -0.0153609
trainer/Q Targets Min             -48.1675
trainer/Log Pis Mean                1.66043
trainer/Log Pis Std                 1.26923
trainer/Log Pis Max                 5.63714
trainer/Log Pis Min                -2.67819
trainer/Policy mu Mean              0.00249743
trainer/Policy mu Std               0.485214
trainer/Policy mu Max               2.8221
trainer/Policy mu Min              -3.14981
trainer/Policy log std Mean        -2.10839
trainer/Policy log std Std          0.34899
trainer/Policy log std Max         -0.407014
trainer/Policy log std Min         -2.35364
trainer/Alpha                       0.0559907
trainer/Alpha Loss                 -0.978736
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.244839
exploration/Rewards Std             0.55158
exploration/Rewards Max            -0.00792047
exploration/Rewards Min            -5.6469
exploration/Returns Mean          -24.4839
exploration/Returns Std             6.67653
exploration/Returns Max           -14.8759
exploration/Returns Min           -32.8072
exploration/Actions Mean           -0.0118805
exploration/Actions Std             0.221047
exploration/Actions Max             0.992624
exploration/Actions Min            -0.99703
exploration/Num Paths               5
exploration/Average Returns       -24.4839
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.286658
evaluation/Rewards Std              1.08555
evaluation/Rewards Max             -0.0400096
evaluation/Rewards Min            -10.8033
evaluation/Returns Mean           -28.6658
evaluation/Returns Std             18.2191
evaluation/Returns Max             -5.3987
evaluation/Returns Min            -63.536
evaluation/Actions Mean            -0.000672737
evaluation/Actions Std              0.206422
evaluation/Actions Max              0.996737
evaluation/Actions Min             -0.997925
evaluation/Num Paths               15
evaluation/Average Returns        -28.6658
time/data storing (s)               0.00314774
time/evaluation sampling (s)        0.352422
time/exploration sampling (s)       0.165282
time/logging (s)                    0.00475955
time/saving (s)                     0.00206004
time/training (s)                   2.13779
time/epoch (s)                      2.66546
time/total (s)                    274.665
Epoch                             101
-----------------------------  ----------------
2019-04-22 21:26:28.802816 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              51700
trainer/QF1 Loss                    0.932004
trainer/QF2 Loss                    0.929503
trainer/Policy Loss                10.192
trainer/Q1 Predictions Mean        -8.52004
trainer/Q1 Predictions Std          6.3107
trainer/Q1 Predictions Max         -6.65139
trainer/Q1 Predictions Min        -60.6413
trainer/Q2 Predictions Mean        -8.53373
trainer/Q2 Predictions Std          6.31675
trainer/Q2 Predictions Max         -6.65168
trainer/Q2 Predictions Min        -60.6606
trainer/Q Targets Mean             -8.4248
trainer/Q Targets Std               6.47572
trainer/Q Targets Max              -0.201775
trainer/Q Targets Min             -60.9523
trainer/Log Pis Mean                2.00964
trainer/Log Pis Std                 1.15662
trainer/Log Pis Max                 5.08986
trainer/Log Pis Min                -2.7972
trainer/Policy mu Mean             -0.0646404
trainer/Policy mu Std               0.663011
trainer/Policy mu Max               2.98234
trainer/Policy mu Min              -2.95851
trainer/Policy log std Mean        -2.13459
trainer/Policy log std Std          0.457506
trainer/Policy log std Max         -0.545566
trainer/Policy log std Min         -2.46719
trainer/Alpha                       0.0557633
trainer/Alpha Loss                  0.027841
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.355035
exploration/Rewards Std             1.11667
exploration/Rewards Max            -0.00432212
exploration/Rewards Min            -9.83389
exploration/Returns Mean          -35.5035
exploration/Returns Std            18.1366
exploration/Returns Max           -12.9185
exploration/Returns Min           -61.3734
exploration/Actions Mean           -0.00272849
exploration/Actions Std             0.243951
exploration/Actions Max             0.999128
exploration/Actions Min            -0.998416
exploration/Num Paths               5
exploration/Average Returns       -35.5035
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.163331
evaluation/Rewards Std              0.685922
evaluation/Rewards Max             -0.0121314
evaluation/Rewards Min             -7.33918
evaluation/Returns Mean           -16.3331
evaluation/Returns Std              7.80704
evaluation/Returns Max             -6.10344
evaluation/Returns Min            -32.2152
evaluation/Actions Mean             0.0107459
evaluation/Actions Std              0.177103
evaluation/Actions Max              0.998383
evaluation/Actions Min             -0.994744
evaluation/Num Paths               15
evaluation/Average Returns        -16.3331
time/data storing (s)               0.00323805
time/evaluation sampling (s)        0.358201
time/exploration sampling (s)       0.165286
time/logging (s)                    0.005225
time/saving (s)                     0.00212257
time/training (s)                   2.10916
time/epoch (s)                      2.64323
time/total (s)                    277.313
Epoch                             102
-----------------------------  ---------------
2019-04-22 21:26:31.516474 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                    1.18024
trainer/QF2 Loss                    1.16224
trainer/Policy Loss                10.0605
trainer/Q1 Predictions Mean        -8.30429
trainer/Q1 Predictions Std          7.0746
trainer/Q1 Predictions Max         -6.59304
trainer/Q1 Predictions Min        -72.2087
trainer/Q2 Predictions Mean        -8.30865
trainer/Q2 Predictions Std          7.08627
trainer/Q2 Predictions Max         -6.58036
trainer/Q2 Predictions Min        -72.4663
trainer/Q Targets Mean             -8.26788
trainer/Q Targets Std               7.31334
trainer/Q Targets Max              -0.126657
trainer/Q Targets Min             -74.8605
trainer/Log Pis Mean                2.03987
trainer/Log Pis Std                 1.34611
trainer/Log Pis Max                 9.27112
trainer/Log Pis Min                -1.01728
trainer/Policy mu Mean              0.072549
trainer/Policy mu Std               0.616681
trainer/Policy mu Max               3.35691
trainer/Policy mu Min              -2.78373
trainer/Policy log std Mean        -2.19865
trainer/Policy log std Std          0.405617
trainer/Policy log std Max         -0.522593
trainer/Policy log std Min         -2.46289
trainer/Alpha                       0.0559743
trainer/Alpha Loss                  0.114936
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.164153
exploration/Rewards Std             0.305461
exploration/Rewards Max            -0.00539494
exploration/Rewards Min            -4.58381
exploration/Returns Mean          -16.4153
exploration/Returns Std             3.55553
exploration/Returns Max           -12.5104
exploration/Returns Min           -23.0163
exploration/Actions Mean           -0.00488827
exploration/Actions Std             0.196271
exploration/Actions Max             0.990195
exploration/Actions Min            -0.996954
exploration/Num Paths               5
exploration/Average Returns       -16.4153
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.204479
evaluation/Rewards Std              0.873718
evaluation/Rewards Max             -0.035707
evaluation/Rewards Min             -9.92753
evaluation/Returns Mean           -20.4479
evaluation/Returns Std             13.1221
evaluation/Returns Max             -5.22523
evaluation/Returns Min            -55.5214
evaluation/Actions Mean            -0.00883168
evaluation/Actions Std              0.191198
evaluation/Actions Max              0.992399
evaluation/Actions Min             -0.998011
evaluation/Num Paths               15
evaluation/Average Returns        -20.4479
time/data storing (s)               0.00363218
time/evaluation sampling (s)        0.364424
time/exploration sampling (s)       0.161085
time/logging (s)                    0.00498354
time/saving (s)                     0.00213373
time/training (s)                   2.17026
time/epoch (s)                      2.70652
time/total (s)                    280.024
Epoch                             103
-----------------------------  ---------------
2019-04-22 21:26:34.198732 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              52700
trainer/QF1 Loss                    0.0135351
trainer/QF2 Loss                    0.00795135
trainer/Policy Loss                 9.20228
trainer/Q1 Predictions Mean        -7.45054
trainer/Q1 Predictions Std          2.53599
trainer/Q1 Predictions Max         -6.60759
trainer/Q1 Predictions Min        -26.9156
trainer/Q2 Predictions Mean        -7.47226
trainer/Q2 Predictions Std          2.50357
trainer/Q2 Predictions Max         -6.66799
trainer/Q2 Predictions Min        -26.6007
trainer/Q Targets Mean             -7.47759
trainer/Q Targets Std               2.51074
trainer/Q Targets Max              -6.6244
trainer/Q Targets Min             -26.9369
trainer/Log Pis Mean                1.77113
trainer/Log Pis Std                 1.32562
trainer/Log Pis Max                 8.45702
trainer/Log Pis Min                -3.10397
trainer/Policy mu Mean             -0.0345481
trainer/Policy mu Std               0.514725
trainer/Policy mu Max               2.11629
trainer/Policy mu Min              -3.4418
trainer/Policy log std Mean        -2.20453
trainer/Policy log std Std          0.356135
trainer/Policy log std Max         -0.295414
trainer/Policy log std Min         -2.44267
trainer/Alpha                       0.0573091
trainer/Alpha Loss                 -0.65441
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.352237
exploration/Rewards Std             1.15014
exploration/Rewards Max            -0.00573619
exploration/Rewards Min           -10.0956
exploration/Returns Mean          -35.2237
exploration/Returns Std            21.8816
exploration/Returns Max           -11.828
exploration/Returns Min           -62.4892
exploration/Actions Mean            0.00625182
exploration/Actions Std             0.237226
exploration/Actions Max             0.999266
exploration/Actions Min            -0.998324
exploration/Num Paths               5
exploration/Average Returns       -35.2237
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238054
evaluation/Rewards Std              0.890888
evaluation/Rewards Max             -0.00221975
evaluation/Rewards Min             -9.11156
evaluation/Returns Mean           -23.8054
evaluation/Returns Std             12.4168
evaluation/Returns Max             -8.19995
evaluation/Returns Min            -46.5993
evaluation/Actions Mean            -0.0123633
evaluation/Actions Std              0.198107
evaluation/Actions Max              0.997643
evaluation/Actions Min             -0.996605
evaluation/Num Paths               15
evaluation/Average Returns        -23.8054
time/data storing (s)               0.00308412
time/evaluation sampling (s)        0.356131
time/exploration sampling (s)       0.164683
time/logging (s)                    0.00411465
time/saving (s)                     0.00200545
time/training (s)                   2.14465
time/epoch (s)                      2.67467
time/total (s)                    282.703
Epoch                             104
-----------------------------  ---------------
2019-04-22 21:26:36.908027 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                    1.40092
trainer/QF2 Loss                    1.41157
trainer/Policy Loss                11.0135
trainer/Q1 Predictions Mean        -9.38127
trainer/Q1 Predictions Std          9.55358
trainer/Q1 Predictions Max         -6.64764
trainer/Q1 Predictions Min        -64.6722
trainer/Q2 Predictions Mean        -9.30663
trainer/Q2 Predictions Std          9.43339
trainer/Q2 Predictions Max         -6.61246
trainer/Q2 Predictions Min        -63.7962
trainer/Q Targets Mean             -9.30926
trainer/Q Targets Std               9.77922
trainer/Q Targets Max              -1.05117
trainer/Q Targets Min             -66.2752
trainer/Log Pis Mean                2.08656
trainer/Log Pis Std                 1.36973
trainer/Log Pis Max                 7.24844
trainer/Log Pis Min                -1.45842
trainer/Policy mu Mean              0.147132
trainer/Policy mu Std               0.734313
trainer/Policy mu Max               3.17225
trainer/Policy mu Min              -2.14448
trainer/Policy log std Mean        -2.06765
trainer/Policy log std Std          0.449576
trainer/Policy log std Max         -0.430601
trainer/Policy log std Min         -2.40673
trainer/Alpha                       0.0562377
trainer/Alpha Loss                  0.24912
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.338833
exploration/Rewards Std             0.932997
exploration/Rewards Max            -0.00151253
exploration/Rewards Min            -8.50344
exploration/Returns Mean          -33.8833
exploration/Returns Std            12.2621
exploration/Returns Max           -21.9426
exploration/Returns Min           -54.6468
exploration/Actions Mean            0.00342217
exploration/Actions Std             0.238388
exploration/Actions Max             0.998849
exploration/Actions Min            -0.997774
exploration/Num Paths               5
exploration/Average Returns       -33.8833
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.232982
evaluation/Rewards Std              0.914496
evaluation/Rewards Max             -0.0433011
evaluation/Rewards Min            -10.297
evaluation/Returns Mean           -23.2982
evaluation/Returns Std             15.0763
evaluation/Returns Max             -6.13312
evaluation/Returns Min            -63.2483
evaluation/Actions Mean            -0.0111872
evaluation/Actions Std              0.18584
evaluation/Actions Max              0.997328
evaluation/Actions Min             -0.998117
evaluation/Num Paths               15
evaluation/Average Returns        -23.2982
time/data storing (s)               0.00307619
time/evaluation sampling (s)        0.362742
time/exploration sampling (s)       0.164547
time/logging (s)                    0.00603964
time/saving (s)                     0.00196993
time/training (s)                   2.16609
time/epoch (s)                      2.70446
time/total (s)                    285.412
Epoch                             105
-----------------------------  ---------------
2019-04-22 21:26:39.564092 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 106 finished
-----------------------------  ----------------
replay_buffer/size              53700
trainer/QF1 Loss                    0.453029
trainer/QF2 Loss                    0.466901
trainer/Policy Loss                 9.67137
trainer/Q1 Predictions Mean        -7.71709
trainer/Q1 Predictions Std          4.18144
trainer/Q1 Predictions Max         -6.69378
trainer/Q1 Predictions Min        -47.3833
trainer/Q2 Predictions Mean        -7.74545
trainer/Q2 Predictions Std          4.22993
trainer/Q2 Predictions Max         -6.70628
trainer/Q2 Predictions Min        -47.9106
trainer/Q Targets Mean             -7.64236
trainer/Q Targets Std               4.24018
trainer/Q Targets Max              -0.0758658
trainer/Q Targets Min             -47.2351
trainer/Log Pis Mean                2.1358
trainer/Log Pis Std                 0.92581
trainer/Log Pis Max                 4.2978
trainer/Log Pis Min                -1.6216
trainer/Policy mu Mean              0.0454443
trainer/Policy mu Std               0.452844
trainer/Policy mu Max               3.02184
trainer/Policy mu Min              -2.58264
trainer/Policy log std Mean        -2.27614
trainer/Policy log std Std          0.309291
trainer/Policy log std Max         -0.612682
trainer/Policy log std Min         -2.5492
trainer/Alpha                       0.0559799
trainer/Alpha Loss                  0.391493
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.32388
exploration/Rewards Std             0.986865
exploration/Rewards Max            -0.000188331
exploration/Rewards Min            -9.56922
exploration/Returns Mean          -32.388
exploration/Returns Std            12.3991
exploration/Returns Max           -19.021
exploration/Returns Min           -55.5008
exploration/Actions Mean           -0.00649867
exploration/Actions Std             0.244458
exploration/Actions Max             0.998704
exploration/Actions Min            -0.999734
exploration/Num Paths               5
exploration/Average Returns       -32.388
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.332615
evaluation/Rewards Std              1.27403
evaluation/Rewards Max             -0.00115918
evaluation/Rewards Min            -10.5605
evaluation/Returns Mean           -33.2615
evaluation/Returns Std             18.3886
evaluation/Returns Max             -5.38657
evaluation/Returns Min            -62.322
evaluation/Actions Mean             0.0215141
evaluation/Actions Std              0.21535
evaluation/Actions Max              0.996698
evaluation/Actions Min             -0.997751
evaluation/Num Paths               15
evaluation/Average Returns        -33.2615
time/data storing (s)               0.0030947
time/evaluation sampling (s)        0.38409
time/exploration sampling (s)       0.164108
time/logging (s)                    0.00475776
time/saving (s)                     0.00203599
time/training (s)                   2.0889
time/epoch (s)                      2.64699
time/total (s)                    288.064
Epoch                             106
-----------------------------  ----------------
2019-04-22 21:26:42.251411 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              54200
trainer/QF1 Loss                    0.0142025
trainer/QF2 Loss                    0.0150757
trainer/Policy Loss                 9.94986
trainer/Q1 Predictions Mean        -8.08945
trainer/Q1 Predictions Std          6.309
trainer/Q1 Predictions Max         -6.49978
trainer/Q1 Predictions Min        -54.5461
trainer/Q2 Predictions Mean        -8.07594
trainer/Q2 Predictions Std          6.30414
trainer/Q2 Predictions Max         -6.49408
trainer/Q2 Predictions Min        -54.8092
trainer/Q Targets Mean             -8.1302
trainer/Q Targets Std               6.25883
trainer/Q Targets Max              -6.54099
trainer/Q Targets Min             -54.364
trainer/Log Pis Mean                1.93781
trainer/Log Pis Std                 1.05714
trainer/Log Pis Max                 5.24915
trainer/Log Pis Min                -1.67674
trainer/Policy mu Mean             -0.0716995
trainer/Policy mu Std               0.422345
trainer/Policy mu Max               0.784867
trainer/Policy mu Min              -3.0704
trainer/Policy log std Mean        -2.27158
trainer/Policy log std Std          0.297993
trainer/Policy log std Max         -0.434637
trainer/Policy log std Min         -2.50959
trainer/Alpha                       0.0562558
trainer/Alpha Loss                 -0.178983
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407502
exploration/Rewards Std             1.31005
exploration/Rewards Max            -0.00622141
exploration/Rewards Min           -10.7934
exploration/Returns Mean          -40.7502
exploration/Returns Std            20.1958
exploration/Returns Max           -12.794
exploration/Returns Min           -69.4598
exploration/Actions Mean            0.018083
exploration/Actions Std             0.256122
exploration/Actions Max             0.999446
exploration/Actions Min            -0.998664
exploration/Num Paths               5
exploration/Average Returns       -40.7502
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.220595
evaluation/Rewards Std              1.03136
evaluation/Rewards Max             -0.013547
evaluation/Rewards Min            -11.247
evaluation/Returns Mean           -22.0595
evaluation/Returns Std             16.3551
evaluation/Returns Max             -1.7686
evaluation/Returns Min            -60.352
evaluation/Actions Mean             0.00982439
evaluation/Actions Std              0.19954
evaluation/Actions Max              0.997219
evaluation/Actions Min             -0.997741
evaluation/Num Paths               15
evaluation/Average Returns        -22.0595
time/data storing (s)               0.00328957
time/evaluation sampling (s)        0.358725
time/exploration sampling (s)       0.171419
time/logging (s)                    0.00507311
time/saving (s)                     0.00394392
time/training (s)                   2.13836
time/epoch (s)                      2.68081
time/total (s)                    290.75
Epoch                             107
-----------------------------  ---------------
2019-04-22 21:26:44.971618 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              54700
trainer/QF1 Loss                    0.531943
trainer/QF2 Loss                    0.519691
trainer/Policy Loss                10.3359
trainer/Q1 Predictions Mean        -8.62261
trainer/Q1 Predictions Std          6.18258
trainer/Q1 Predictions Max         -6.57614
trainer/Q1 Predictions Min        -57.2519
trainer/Q2 Predictions Mean        -8.60537
trainer/Q2 Predictions Std          6.12501
trainer/Q2 Predictions Max         -6.55057
trainer/Q2 Predictions Min        -56.4861
trainer/Q Targets Mean             -8.56469
trainer/Q Targets Std               6.12965
trainer/Q Targets Max              -0.166199
trainer/Q Targets Min             -56.4482
trainer/Log Pis Mean                1.93611
trainer/Log Pis Std                 1.50833
trainer/Log Pis Max                 7.80669
trainer/Log Pis Min                -3.23954
trainer/Policy mu Mean             -0.016491
trainer/Policy mu Std               0.715254
trainer/Policy mu Max               2.89077
trainer/Policy mu Min              -3.19104
trainer/Policy log std Mean        -2.10911
trainer/Policy log std Std          0.479859
trainer/Policy log std Max         -0.423058
trainer/Policy log std Min         -2.4189
trainer/Alpha                       0.0543399
trainer/Alpha Loss                 -0.18608
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.306148
exploration/Rewards Std             0.895158
exploration/Rewards Max            -0.0064234
exploration/Rewards Min            -8.68783
exploration/Returns Mean          -30.6148
exploration/Returns Std            11.596
exploration/Returns Max           -13.5349
exploration/Returns Min           -45.6096
exploration/Actions Mean            0.00988437
exploration/Actions Std             0.235663
exploration/Actions Max             0.997261
exploration/Actions Min            -0.998565
exploration/Num Paths               5
exploration/Average Returns       -30.6148
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.289526
evaluation/Rewards Std              1.12281
evaluation/Rewards Max             -0.0183028
evaluation/Rewards Min            -10.1809
evaluation/Returns Mean           -28.9526
evaluation/Returns Std             14.5296
evaluation/Returns Max             -7.07852
evaluation/Returns Min            -55.1266
evaluation/Actions Mean             0.00576693
evaluation/Actions Std              0.213777
evaluation/Actions Max              0.995913
evaluation/Actions Min             -0.996834
evaluation/Num Paths               15
evaluation/Average Returns        -28.9526
time/data storing (s)               0.0032137
time/evaluation sampling (s)        0.35676
time/exploration sampling (s)       0.160149
time/logging (s)                    0.00490981
time/saving (s)                     0.00206623
time/training (s)                   2.18619
time/epoch (s)                      2.71328
time/total (s)                    293.468
Epoch                             108
-----------------------------  ---------------
2019-04-22 21:26:47.723787 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                    0.550442
trainer/QF2 Loss                    0.584873
trainer/Policy Loss                 9.88548
trainer/Q1 Predictions Mean        -7.97948
trainer/Q1 Predictions Std          6.69711
trainer/Q1 Predictions Max         -6.44695
trainer/Q1 Predictions Min        -65.2339
trainer/Q2 Predictions Mean        -8.04022
trainer/Q2 Predictions Std          6.57533
trainer/Q2 Predictions Max         -6.57861
trainer/Q2 Predictions Min        -63.8132
trainer/Q Targets Mean             -8.0302
trainer/Q Targets Std               6.82022
trainer/Q Targets Max              -0.237935
trainer/Q Targets Min             -66.3002
trainer/Log Pis Mean                2.02669
trainer/Log Pis Std                 1.15848
trainer/Log Pis Max                 6.1082
trainer/Log Pis Min                -2.32391
trainer/Policy mu Mean              0.0297069
trainer/Policy mu Std               0.537506
trainer/Policy mu Max               3.13727
trainer/Policy mu Min              -2.96631
trainer/Policy log std Mean        -2.18421
trainer/Policy log std Std          0.369646
trainer/Policy log std Max         -0.510718
trainer/Policy log std Min         -2.50636
trainer/Alpha                       0.0560634
trainer/Alpha Loss                  0.0768927
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.288879
exploration/Rewards Std             0.861511
exploration/Rewards Max            -0.00257705
exploration/Rewards Min            -8.3209
exploration/Returns Mean          -28.8879
exploration/Returns Std            11.2053
exploration/Returns Max           -16.7128
exploration/Returns Min           -46.4119
exploration/Actions Mean            0.0177906
exploration/Actions Std             0.240016
exploration/Actions Max             0.999047
exploration/Actions Min            -0.995781
exploration/Num Paths               5
exploration/Average Returns       -28.8879
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.339919
evaluation/Rewards Std              1.31836
evaluation/Rewards Max             -0.00412171
evaluation/Rewards Min            -10.9525
evaluation/Returns Mean           -33.9919
evaluation/Returns Std             20.3689
evaluation/Returns Max             -6.47776
evaluation/Returns Min            -61.5011
evaluation/Actions Mean            -0.00938504
evaluation/Actions Std              0.213795
evaluation/Actions Max              0.998118
evaluation/Actions Min             -0.997928
evaluation/Num Paths               15
evaluation/Average Returns        -33.9919
time/data storing (s)               0.00320442
time/evaluation sampling (s)        0.365216
time/exploration sampling (s)       0.166237
time/logging (s)                    0.00524062
time/saving (s)                     0.00200619
time/training (s)                   2.20351
time/epoch (s)                      2.74541
time/total (s)                    296.218
Epoch                             109
-----------------------------  ---------------
2019-04-22 21:26:50.379434 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              55700
trainer/QF1 Loss                    0.442792
trainer/QF2 Loss                    0.447144
trainer/Policy Loss                 9.31162
trainer/Q1 Predictions Mean        -7.36381
trainer/Q1 Predictions Std          1.63668
trainer/Q1 Predictions Max         -6.60898
trainer/Q1 Predictions Min        -21.471
trainer/Q2 Predictions Mean        -7.34162
trainer/Q2 Predictions Std          1.69741
trainer/Q2 Predictions Max         -6.56874
trainer/Q2 Predictions Min        -22.06
trainer/Q Targets Mean             -7.27285
trainer/Q Targets Std               1.79884
trainer/Q Targets Max              -0.238445
trainer/Q Targets Min             -21.4177
trainer/Log Pis Mean                2.10545
trainer/Log Pis Std                 0.835042
trainer/Log Pis Max                 5.02502
trainer/Log Pis Min                -0.216087
trainer/Policy mu Mean              0.0187308
trainer/Policy mu Std               0.449314
trainer/Policy mu Max               3.23565
trainer/Policy mu Min              -2.02009
trainer/Policy log std Mean        -2.25108
trainer/Policy log std Std          0.340018
trainer/Policy log std Max         -0.56909
trainer/Policy log std Min         -2.52949
trainer/Alpha                       0.0572127
trainer/Alpha Loss                  0.301702
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.359574
exploration/Rewards Std             1.15696
exploration/Rewards Max            -0.00907017
exploration/Rewards Min           -10.4731
exploration/Returns Mean          -35.9574
exploration/Returns Std            21.0569
exploration/Returns Max           -13.2558
exploration/Returns Min           -70.4388
exploration/Actions Mean            0.00318263
exploration/Actions Std             0.232586
exploration/Actions Max             0.99827
exploration/Actions Min            -0.997307
exploration/Num Paths               5
exploration/Average Returns       -35.9574
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.184666
evaluation/Rewards Std              0.827141
evaluation/Rewards Max             -0.0252724
evaluation/Rewards Min             -8.80442
evaluation/Returns Mean           -18.4666
evaluation/Returns Std             11.8571
evaluation/Returns Max             -2.84319
evaluation/Returns Min            -41.5514
evaluation/Actions Mean             0.0131588
evaluation/Actions Std              0.190738
evaluation/Actions Max              0.996991
evaluation/Actions Min             -0.99717
evaluation/Num Paths               15
evaluation/Average Returns        -18.4666
time/data storing (s)               0.00314827
time/evaluation sampling (s)        0.367789
time/exploration sampling (s)       0.163953
time/logging (s)                    0.00504534
time/saving (s)                     0.00201962
time/training (s)                   2.10649
time/epoch (s)                      2.64844
time/total (s)                    298.871
Epoch                             110
-----------------------------  ---------------
2019-04-22 21:26:53.073203 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                    1.03766
trainer/QF2 Loss                    1.0401
trainer/Policy Loss                10.2855
trainer/Q1 Predictions Mean        -8.32398
trainer/Q1 Predictions Std          6.83313
trainer/Q1 Predictions Max         -6.34929
trainer/Q1 Predictions Min        -60.6088
trainer/Q2 Predictions Mean        -8.35085
trainer/Q2 Predictions Std          6.89773
trainer/Q2 Predictions Max         -6.36187
trainer/Q2 Predictions Min        -60.6783
trainer/Q Targets Mean             -8.33983
trainer/Q Targets Std               6.94298
trainer/Q Targets Max              -0.140324
trainer/Q Targets Min             -60.6587
trainer/Log Pis Mean                2.12697
trainer/Log Pis Std                 1.46969
trainer/Log Pis Max                 9.05975
trainer/Log Pis Min                -1.44481
trainer/Policy mu Mean              0.0587199
trainer/Policy mu Std               0.679118
trainer/Policy mu Max               3.33217
trainer/Policy mu Min              -2.95834
trainer/Policy log std Mean        -2.17232
trainer/Policy log std Std          0.441491
trainer/Policy log std Max         -0.588354
trainer/Policy log std Min         -2.46795
trainer/Alpha                       0.0585441
trainer/Alpha Loss                  0.360351
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.316346
exploration/Rewards Std             0.94128
exploration/Rewards Max            -0.00253093
exploration/Rewards Min            -7.62861
exploration/Returns Mean          -31.6346
exploration/Returns Std             8.86363
exploration/Returns Max           -16.0328
exploration/Returns Min           -42.9134
exploration/Actions Mean            0.0253438
exploration/Actions Std             0.246934
exploration/Actions Max             0.998795
exploration/Actions Min            -0.996913
exploration/Num Paths               5
exploration/Average Returns       -31.6346
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.173112
evaluation/Rewards Std              0.771736
evaluation/Rewards Max             -0.0235886
evaluation/Rewards Min             -8.11701
evaluation/Returns Mean           -17.3112
evaluation/Returns Std             10.4822
evaluation/Returns Max             -3.34033
evaluation/Returns Min            -37.2335
evaluation/Actions Mean             0.016599
evaluation/Actions Std              0.176353
evaluation/Actions Max              0.99515
evaluation/Actions Min             -0.994514
evaluation/Num Paths               15
evaluation/Average Returns        -17.3112
time/data storing (s)               0.00335779
time/evaluation sampling (s)        0.361867
time/exploration sampling (s)       0.160194
time/logging (s)                    0.00477054
time/saving (s)                     0.00194802
time/training (s)                   2.1551
time/epoch (s)                      2.68724
time/total (s)                    301.563
Epoch                             111
-----------------------------  ---------------
2019-04-22 21:26:55.722093 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              56700
trainer/QF1 Loss                    0.863475
trainer/QF2 Loss                    0.857086
trainer/Policy Loss                11.0345
trainer/Q1 Predictions Mean        -9.22711
trainer/Q1 Predictions Std          9.33161
trainer/Q1 Predictions Max         -6.47789
trainer/Q1 Predictions Min        -67.2597
trainer/Q2 Predictions Mean        -9.19107
trainer/Q2 Predictions Std          9.31359
trainer/Q2 Predictions Max         -6.41222
trainer/Q2 Predictions Min        -66.311
trainer/Q Targets Mean             -9.15519
trainer/Q Targets Std               9.43592
trainer/Q Targets Max              -0.103519
trainer/Q Targets Min             -67.3819
trainer/Log Pis Mean                2.18901
trainer/Log Pis Std                 1.36233
trainer/Log Pis Max                 9.23599
trainer/Log Pis Min                -0.921163
trainer/Policy mu Mean             -0.0197388
trainer/Policy mu Std               0.749253
trainer/Policy mu Max               2.90717
trainer/Policy mu Min              -3.30752
trainer/Policy log std Mean        -2.18087
trainer/Policy log std Std          0.488608
trainer/Policy log std Max         -0.238575
trainer/Policy log std Min         -2.52726
trainer/Alpha                       0.056308
trainer/Alpha Loss                  0.543787
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.290711
exploration/Rewards Std             0.868359
exploration/Rewards Max            -0.00790493
exploration/Rewards Min            -8.2905
exploration/Returns Mean          -29.0711
exploration/Returns Std            12.1759
exploration/Returns Max           -14.8519
exploration/Returns Min           -48.0075
exploration/Actions Mean           -0.00475621
exploration/Actions Std             0.231863
exploration/Actions Max             0.998666
exploration/Actions Min            -0.998926
exploration/Num Paths               5
exploration/Average Returns       -29.0711
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274494
evaluation/Rewards Std              1.13978
evaluation/Rewards Max             -0.0374765
evaluation/Rewards Min            -10.6378
evaluation/Returns Mean           -27.4494
evaluation/Returns Std             19.8843
evaluation/Returns Max             -5.22846
evaluation/Returns Min            -60.6959
evaluation/Actions Mean            -0.00616882
evaluation/Actions Std              0.204514
evaluation/Actions Max              0.997768
evaluation/Actions Min             -0.99806
evaluation/Num Paths               15
evaluation/Average Returns        -27.4494
time/data storing (s)               0.00302622
time/evaluation sampling (s)        0.356555
time/exploration sampling (s)       0.163515
time/logging (s)                    0.00499419
time/saving (s)                     0.00217337
time/training (s)                   2.11208
time/epoch (s)                      2.64234
time/total (s)                    304.209
Epoch                             112
-----------------------------  ---------------
2019-04-22 21:26:58.378089 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              57200
trainer/QF1 Loss                    0.440664
trainer/QF2 Loss                    0.433747
trainer/Policy Loss                 9.58866
trainer/Q1 Predictions Mean        -7.77916
trainer/Q1 Predictions Std          3.82925
trainer/Q1 Predictions Max         -6.48515
trainer/Q1 Predictions Min        -35.3243
trainer/Q2 Predictions Mean        -7.79143
trainer/Q2 Predictions Std          3.79798
trainer/Q2 Predictions Max         -6.51616
trainer/Q2 Predictions Min        -35.5162
trainer/Q Targets Mean             -7.69479
trainer/Q Targets Std               3.85419
trainer/Q Targets Max              -0.0953374
trainer/Q Targets Min             -35.3124
trainer/Log Pis Mean                1.88179
trainer/Log Pis Std                 1.06071
trainer/Log Pis Max                 6.00537
trainer/Log Pis Min                -1.9445
trainer/Policy mu Mean              0.0184295
trainer/Policy mu Std               0.550417
trainer/Policy mu Max               2.9532
trainer/Policy mu Min              -2.848
trainer/Policy log std Mean        -2.14737
trainer/Policy log std Std          0.383369
trainer/Policy log std Max         -0.46438
trainer/Policy log std Min         -2.44309
trainer/Alpha                       0.0589654
trainer/Alpha Loss                 -0.334625
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.209317
exploration/Rewards Std             0.459602
exploration/Rewards Max            -0.0109426
exploration/Rewards Min            -5.42814
exploration/Returns Mean          -20.9317
exploration/Returns Std             6.26403
exploration/Returns Max           -15.5955
exploration/Returns Min           -30.0784
exploration/Actions Mean            0.0062758
exploration/Actions Std             0.207577
exploration/Actions Max             0.994385
exploration/Actions Min            -0.997502
exploration/Num Paths               5
exploration/Average Returns       -20.9317
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.189235
evaluation/Rewards Std              0.81345
evaluation/Rewards Max             -0.00802367
evaluation/Rewards Min             -8.78107
evaluation/Returns Mean           -18.9235
evaluation/Returns Std             11.9384
evaluation/Returns Max             -1.85645
evaluation/Returns Min            -49.2592
evaluation/Actions Mean            -0.00372303
evaluation/Actions Std              0.185252
evaluation/Actions Max              0.995302
evaluation/Actions Min             -0.998634
evaluation/Num Paths               15
evaluation/Average Returns        -18.9235
time/data storing (s)               0.00326917
time/evaluation sampling (s)        0.359725
time/exploration sampling (s)       0.161851
time/logging (s)                    0.0050303
time/saving (s)                     0.0021408
time/training (s)                   2.11704
time/epoch (s)                      2.64905
time/total (s)                    306.863
Epoch                             113
-----------------------------  ---------------
2019-04-22 21:27:01.066442 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              57700
trainer/QF1 Loss                    0.0187649
trainer/QF2 Loss                    0.0152593
trainer/Policy Loss                 8.65434
trainer/Q1 Predictions Mean        -7.07119
trainer/Q1 Predictions Std          1.24101
trainer/Q1 Predictions Max         -6.5279
trainer/Q1 Predictions Min        -18.0671
trainer/Q2 Predictions Mean        -7.04945
trainer/Q2 Predictions Std          1.24156
trainer/Q2 Predictions Max         -6.47935
trainer/Q2 Predictions Min        -17.7969
trainer/Q Targets Mean             -7.12646
trainer/Q Targets Std               1.22727
trainer/Q Targets Max              -6.45241
trainer/Q Targets Min             -17.6804
trainer/Log Pis Mean                1.70672
trainer/Log Pis Std                 1.04456
trainer/Log Pis Max                 3.36836
trainer/Log Pis Min                -1.86402
trainer/Policy mu Mean              0.0183425
trainer/Policy mu Std               0.388431
trainer/Policy mu Max               2.55435
trainer/Policy mu Min              -1.98155
trainer/Policy log std Mean        -2.2077
trainer/Policy log std Std          0.291989
trainer/Policy log std Max         -0.619871
trainer/Policy log std Min         -2.4005
trainer/Alpha                       0.0576431
trainer/Alpha Loss                 -0.836849
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.421637
exploration/Rewards Std             1.3171
exploration/Rewards Max            -0.0112241
exploration/Rewards Min           -11.1315
exploration/Returns Mean          -42.1637
exploration/Returns Std            19.7151
exploration/Returns Max           -16.0098
exploration/Returns Min           -70.2164
exploration/Actions Mean            0.0187992
exploration/Actions Std             0.262182
exploration/Actions Max             0.996988
exploration/Actions Min            -0.999259
exploration/Num Paths               5
exploration/Average Returns       -42.1637
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.217454
evaluation/Rewards Std              1.03995
evaluation/Rewards Max             -0.00812412
evaluation/Rewards Min            -10.4322
evaluation/Returns Mean           -21.7454
evaluation/Returns Std             16.5581
evaluation/Returns Max             -1.02205
evaluation/Returns Min            -54.5281
evaluation/Actions Mean            -0.00752681
evaluation/Actions Std              0.198328
evaluation/Actions Max              0.996076
evaluation/Actions Min             -0.998676
evaluation/Num Paths               15
evaluation/Average Returns        -21.7454
time/data storing (s)               0.00342011
time/evaluation sampling (s)        0.35336
time/exploration sampling (s)       0.180611
time/logging (s)                    0.00368965
time/saving (s)                     0.00206511
time/training (s)                   2.13695
time/epoch (s)                      2.68009
time/total (s)                    309.548
Epoch                             114
-----------------------------  ---------------
2019-04-22 21:27:03.739324 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                    0.501305
trainer/QF2 Loss                    0.525431
trainer/Policy Loss                11.0063
trainer/Q1 Predictions Mean        -9.28319
trainer/Q1 Predictions Std          9.74393
trainer/Q1 Predictions Max         -6.37953
trainer/Q1 Predictions Min        -65.9167
trainer/Q2 Predictions Mean        -9.31518
trainer/Q2 Predictions Std          9.78465
trainer/Q2 Predictions Max         -6.42929
trainer/Q2 Predictions Min        -66.8788
trainer/Q Targets Mean             -9.30431
trainer/Q Targets Std               9.88065
trainer/Q Targets Max              -0.238683
trainer/Q Targets Min             -66.2917
trainer/Log Pis Mean                2.17002
trainer/Log Pis Std                 1.1127
trainer/Log Pis Max                 6.55888
trainer/Log Pis Min                -0.433151
trainer/Policy mu Mean             -0.00737252
trainer/Policy mu Std               0.714271
trainer/Policy mu Max               3.18622
trainer/Policy mu Min              -3.07337
trainer/Policy log std Mean        -2.17579
trainer/Policy log std Std          0.493553
trainer/Policy log std Max         -0.423726
trainer/Policy log std Min         -2.54724
trainer/Alpha                       0.0558341
trainer/Alpha Loss                  0.490578
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.330572
exploration/Rewards Std             0.979418
exploration/Rewards Max            -0.00466273
exploration/Rewards Min            -8.65876
exploration/Returns Mean          -33.0572
exploration/Returns Std            11.5289
exploration/Returns Max           -20.1816
exploration/Returns Min           -54.1416
exploration/Actions Mean            0.00587958
exploration/Actions Std             0.241922
exploration/Actions Max             0.999049
exploration/Actions Min            -0.996748
exploration/Num Paths               5
exploration/Average Returns       -33.0572
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.285289
evaluation/Rewards Std              1.18858
evaluation/Rewards Max             -0.01628
evaluation/Rewards Min            -10.8213
evaluation/Returns Mean           -28.5289
evaluation/Returns Std             17.3359
evaluation/Returns Max             -4.73732
evaluation/Returns Min            -57.9971
evaluation/Actions Mean            -0.0202254
evaluation/Actions Std              0.199809
evaluation/Actions Max              0.997259
evaluation/Actions Min             -0.997883
evaluation/Num Paths               15
evaluation/Average Returns        -28.5289
time/data storing (s)               0.00329287
time/evaluation sampling (s)        0.360387
time/exploration sampling (s)       0.163981
time/logging (s)                    0.00549169
time/saving (s)                     0.0020084
time/training (s)                   2.13263
time/epoch (s)                      2.66779
time/total (s)                    312.22
Epoch                             115
-----------------------------  ---------------
2019-04-22 21:27:06.515264 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              58700
trainer/QF1 Loss                    0.0159964
trainer/QF2 Loss                    0.0154099
trainer/Policy Loss                 9.77507
trainer/Q1 Predictions Mean        -7.76323
trainer/Q1 Predictions Std          4.2961
trainer/Q1 Predictions Max         -6.49585
trainer/Q1 Predictions Min        -42.1404
trainer/Q2 Predictions Mean        -7.80936
trainer/Q2 Predictions Std          4.32099
trainer/Q2 Predictions Max         -6.53834
trainer/Q2 Predictions Min        -42.3551
trainer/Q Targets Mean             -7.77802
trainer/Q Targets Std               4.28644
trainer/Q Targets Max              -6.43873
trainer/Q Targets Min             -42.0337
trainer/Log Pis Mean                2.19401
trainer/Log Pis Std                 1.22854
trainer/Log Pis Max                 8.56369
trainer/Log Pis Min                -0.671008
trainer/Policy mu Mean              0.027128
trainer/Policy mu Std               0.601589
trainer/Policy mu Max               2.90769
trainer/Policy mu Min              -2.96852
trainer/Policy log std Mean        -2.18107
trainer/Policy log std Std          0.406342
trainer/Policy log std Max         -0.290302
trainer/Policy log std Min         -2.43259
trainer/Alpha                       0.0556143
trainer/Alpha Loss                  0.560553
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.310855
exploration/Rewards Std             0.982266
exploration/Rewards Max            -0.00266657
exploration/Rewards Min            -9.35897
exploration/Returns Mean          -31.0855
exploration/Returns Std            17.9776
exploration/Returns Max           -13.865
exploration/Returns Min           -60.1739
exploration/Actions Mean           -0.017339
exploration/Actions Std             0.234099
exploration/Actions Max             0.998385
exploration/Actions Min            -0.999285
exploration/Num Paths               5
exploration/Average Returns       -31.0855
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.197505
evaluation/Rewards Std              0.95985
evaluation/Rewards Max             -0.00422847
evaluation/Rewards Min            -10.5616
evaluation/Returns Mean           -19.7505
evaluation/Returns Std             16.808
evaluation/Returns Max             -0.829249
evaluation/Returns Min            -60.6521
evaluation/Actions Mean            -0.0200207
evaluation/Actions Std              0.188091
evaluation/Actions Max              0.988767
evaluation/Actions Min             -0.997562
evaluation/Num Paths               15
evaluation/Average Returns        -19.7505
time/data storing (s)               0.00341414
time/evaluation sampling (s)        0.371925
time/exploration sampling (s)       0.169857
time/logging (s)                    0.00497289
time/saving (s)                     0.00203594
time/training (s)                   2.21615
time/epoch (s)                      2.76836
time/total (s)                    314.993
Epoch                             116
-----------------------------  ---------------
2019-04-22 21:27:09.182809 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 117 finished
-----------------------------  ----------------
replay_buffer/size              59200
trainer/QF1 Loss                    0.43741
trainer/QF2 Loss                    0.423966
trainer/Policy Loss                10.0783
trainer/Q1 Predictions Mean        -8.08924
trainer/Q1 Predictions Std          6.56629
trainer/Q1 Predictions Max         -6.45035
trainer/Q1 Predictions Min        -63.5783
trainer/Q2 Predictions Mean        -8.08525
trainer/Q2 Predictions Std          6.66024
trainer/Q2 Predictions Max         -6.41371
trainer/Q2 Predictions Min        -64.5605
trainer/Q Targets Mean             -8.07042
trainer/Q Targets Std               6.65922
trainer/Q Targets Max              -0.142837
trainer/Q Targets Min             -64.2072
trainer/Log Pis Mean                2.10157
trainer/Log Pis Std                 1.1299
trainer/Log Pis Max                 5.72715
trainer/Log Pis Min                -2.11828
trainer/Policy mu Mean             -0.0383532
trainer/Policy mu Std               0.603791
trainer/Policy mu Max               2.96278
trainer/Policy mu Min              -3.17388
trainer/Policy log std Mean        -2.20417
trainer/Policy log std Std          0.426472
trainer/Policy log std Max         -0.462476
trainer/Policy log std Min         -2.49182
trainer/Alpha                       0.0546197
trainer/Alpha Loss                  0.295309
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.309869
exploration/Rewards Std             0.990544
exploration/Rewards Max            -0.0091673
exploration/Rewards Min            -9.38768
exploration/Returns Mean          -30.9869
exploration/Returns Std            17.7043
exploration/Returns Max           -13.199
exploration/Returns Min           -59.5918
exploration/Actions Mean            0.0206552
exploration/Actions Std             0.227804
exploration/Actions Max             0.997826
exploration/Actions Min            -0.998472
exploration/Num Paths               5
exploration/Average Returns       -30.9869
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222267
evaluation/Rewards Std              0.954735
evaluation/Rewards Max             -0.0211295
evaluation/Rewards Min            -10.3594
evaluation/Returns Mean           -22.2267
evaluation/Returns Std             14.9548
evaluation/Returns Max             -5.0276
evaluation/Returns Min            -61.8538
evaluation/Actions Mean            -0.000534975
evaluation/Actions Std              0.195942
evaluation/Actions Max              0.997946
evaluation/Actions Min             -0.998332
evaluation/Num Paths               15
evaluation/Average Returns        -22.2267
time/data storing (s)               0.00314289
time/evaluation sampling (s)        0.357922
time/exploration sampling (s)       0.163978
time/logging (s)                    0.00503187
time/saving (s)                     0.00207297
time/training (s)                   2.12852
time/epoch (s)                      2.66066
time/total (s)                    317.658
Epoch                             117
-----------------------------  ----------------
2019-04-22 21:27:11.908578 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              59700
trainer/QF1 Loss                    0.942662
trainer/QF2 Loss                    0.959791
trainer/Policy Loss                 9.51164
trainer/Q1 Predictions Mean        -7.65928
trainer/Q1 Predictions Std          4.06629
trainer/Q1 Predictions Max         -6.51094
trainer/Q1 Predictions Min        -42.7793
trainer/Q2 Predictions Mean        -7.6308
trainer/Q2 Predictions Std          4.09825
trainer/Q2 Predictions Max         -6.4461
trainer/Q2 Predictions Min        -43.0352
trainer/Q Targets Mean             -7.51863
trainer/Q Targets Std               4.06719
trainer/Q Targets Max              -0.141041
trainer/Q Targets Min             -41.285
trainer/Log Pis Mean                2.01477
trainer/Log Pis Std                 1.17979
trainer/Log Pis Max                 8.00262
trainer/Log Pis Min                -2.45182
trainer/Policy mu Mean              0.0387787
trainer/Policy mu Std               0.501101
trainer/Policy mu Max               3.02833
trainer/Policy mu Min              -2.53581
trainer/Policy log std Mean        -2.20236
trainer/Policy log std Std          0.358923
trainer/Policy log std Max         -0.543608
trainer/Policy log std Min         -2.50981
trainer/Alpha                       0.05566
trainer/Alpha Loss                  0.0426582
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.412967
exploration/Rewards Std             1.30373
exploration/Rewards Max            -0.0056791
exploration/Rewards Min            -9.60244
exploration/Returns Mean          -41.2967
exploration/Returns Std            19.9232
exploration/Returns Max           -15.4505
exploration/Returns Min           -62.2692
exploration/Actions Mean            0.0166059
exploration/Actions Std             0.252724
exploration/Actions Max             0.99951
exploration/Actions Min            -0.998511
exploration/Num Paths               5
exploration/Average Returns       -41.2967
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.150484
evaluation/Rewards Std              0.732344
evaluation/Rewards Max             -0.0133259
evaluation/Rewards Min             -7.61451
evaluation/Returns Mean           -15.0484
evaluation/Returns Std              9.00896
evaluation/Returns Max             -2.72781
evaluation/Returns Min            -29.5721
evaluation/Actions Mean            -0.00395069
evaluation/Actions Std              0.185045
evaluation/Actions Max              0.994064
evaluation/Actions Min             -0.996998
evaluation/Num Paths               15
evaluation/Average Returns        -15.0484
time/data storing (s)               0.00329475
time/evaluation sampling (s)        0.356158
time/exploration sampling (s)       0.160746
time/logging (s)                    0.00506005
time/saving (s)                     0.00792093
time/training (s)                   2.18575
time/epoch (s)                      2.71893
time/total (s)                    320.381
Epoch                             118
-----------------------------  ---------------
2019-04-22 21:27:14.567207 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 119 finished
-----------------------------  ----------------
replay_buffer/size              60200
trainer/QF1 Loss                    0.442257
trainer/QF2 Loss                    0.453324
trainer/Policy Loss                 9.63833
trainer/Q1 Predictions Mean        -7.91798
trainer/Q1 Predictions Std          5.75552
trainer/Q1 Predictions Max         -6.38901
trainer/Q1 Predictions Min        -59.3765
trainer/Q2 Predictions Mean        -7.95113
trainer/Q2 Predictions Std          5.7912
trainer/Q2 Predictions Max         -6.40003
trainer/Q2 Predictions Min        -59.765
trainer/Q Targets Mean             -7.93522
trainer/Q Targets Std               5.67274
trainer/Q Targets Max              -0.08326
trainer/Q Targets Min             -58.3747
trainer/Log Pis Mean                1.91012
trainer/Log Pis Std                 1.17949
trainer/Log Pis Max                 5.41589
trainer/Log Pis Min                -3.11878
trainer/Policy mu Mean             -0.000680133
trainer/Policy mu Std               0.559911
trainer/Policy mu Max               2.70464
trainer/Policy mu Min              -2.96186
trainer/Policy log std Mean        -2.18288
trainer/Policy log std Std          0.390771
trainer/Policy log std Max         -0.574535
trainer/Policy log std Min         -2.45938
trainer/Alpha                       0.0541953
trainer/Alpha Loss                 -0.262
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.408103
exploration/Rewards Std             1.25516
exploration/Rewards Max            -0.00341322
exploration/Rewards Min            -9.18791
exploration/Returns Mean          -40.8103
exploration/Returns Std            15.6095
exploration/Returns Max           -15.1
exploration/Returns Min           -55.4279
exploration/Actions Mean            0.0116747
exploration/Actions Std             0.25577
exploration/Actions Max             0.99968
exploration/Actions Min            -0.998144
exploration/Num Paths               5
exploration/Average Returns       -40.8103
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.242011
evaluation/Rewards Std              1.07301
evaluation/Rewards Max             -0.0148546
evaluation/Rewards Min            -10.0012
evaluation/Returns Mean           -24.2011
evaluation/Returns Std             15.9133
evaluation/Returns Max             -6.60232
evaluation/Returns Min            -49.2664
evaluation/Actions Mean             0.00614378
evaluation/Actions Std              0.209422
evaluation/Actions Max              0.996601
evaluation/Actions Min             -0.997785
evaluation/Num Paths               15
evaluation/Average Returns        -24.2011
time/data storing (s)               0.0032426
time/evaluation sampling (s)        0.357209
time/exploration sampling (s)       0.163354
time/logging (s)                    0.00510416
time/saving (s)                     0.00200612
time/training (s)                   2.12064
time/epoch (s)                      2.65155
time/total (s)                    323.037
Epoch                             119
-----------------------------  ----------------
2019-04-22 21:27:17.232849 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              60700
trainer/QF1 Loss                    0.935955
trainer/QF2 Loss                    0.937756
trainer/Policy Loss                10.7474
trainer/Q1 Predictions Mean        -8.51239
trainer/Q1 Predictions Std          6.70423
trainer/Q1 Predictions Max         -6.28944
trainer/Q1 Predictions Min        -61.5843
trainer/Q2 Predictions Mean        -8.53699
trainer/Q2 Predictions Std          6.72177
trainer/Q2 Predictions Max         -6.35844
trainer/Q2 Predictions Min        -61.9372
trainer/Q Targets Mean             -8.47464
trainer/Q Targets Std               6.72584
trainer/Q Targets Max              -0.0758658
trainer/Q Targets Min             -61.0941
trainer/Log Pis Mean                2.46709
trainer/Log Pis Std                 1.06787
trainer/Log Pis Max                 6.8299
trainer/Log Pis Min                -0.230623
trainer/Policy mu Mean              0.0189845
trainer/Policy mu Std               0.778598
trainer/Policy mu Max               3.04497
trainer/Policy mu Min              -3.11496
trainer/Policy log std Mean        -2.12236
trainer/Policy log std Std          0.518073
trainer/Policy log std Max         -0.455259
trainer/Policy log std Min         -2.4459
trainer/Alpha                       0.0550701
trainer/Alpha Loss                  1.35419
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.328813
exploration/Rewards Std             0.97324
exploration/Rewards Max            -0.00599366
exploration/Rewards Min            -8.73752
exploration/Returns Mean          -32.8813
exploration/Returns Std            10.0101
exploration/Returns Max           -21.5272
exploration/Returns Min           -51.2236
exploration/Actions Mean            0.0150887
exploration/Actions Std             0.244227
exploration/Actions Max             0.998703
exploration/Actions Min            -0.997657
exploration/Num Paths               5
exploration/Average Returns       -32.8813
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274627
evaluation/Rewards Std              1.09845
evaluation/Rewards Max             -0.0422231
evaluation/Rewards Min            -11.1811
evaluation/Returns Mean           -27.4627
evaluation/Returns Std             17.0104
evaluation/Returns Max             -5.46106
evaluation/Returns Min            -63.1301
evaluation/Actions Mean            -0.0294039
evaluation/Actions Std              0.203532
evaluation/Actions Max              0.994208
evaluation/Actions Min             -0.997574
evaluation/Num Paths               15
evaluation/Average Returns        -27.4627
time/data storing (s)               0.00321362
time/evaluation sampling (s)        0.363348
time/exploration sampling (s)       0.165255
time/logging (s)                    0.004966
time/saving (s)                     0.00196656
time/training (s)                   2.11998
time/epoch (s)                      2.65873
time/total (s)                    325.701
Epoch                             120
-----------------------------  ---------------
2019-04-22 21:27:19.861356 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 121 finished
-----------------------------  ----------------
replay_buffer/size              61200
trainer/QF1 Loss                    0.0172214
trainer/QF2 Loss                    0.0148615
trainer/Policy Loss                10.2993
trainer/Q1 Predictions Mean        -8.63572
trainer/Q1 Predictions Std          6.70858
trainer/Q1 Predictions Max         -6.50483
trainer/Q1 Predictions Min        -56.8553
trainer/Q2 Predictions Mean        -8.62718
trainer/Q2 Predictions Std          6.67576
trainer/Q2 Predictions Max         -6.51026
trainer/Q2 Predictions Min        -56.3911
trainer/Q Targets Mean             -8.6672
trainer/Q Targets Std               6.70619
trainer/Q Targets Max              -6.42886
trainer/Q Targets Min             -56.9689
trainer/Log Pis Mean                1.93186
trainer/Log Pis Std                 1.29198
trainer/Log Pis Max                 5.95788
trainer/Log Pis Min                -2.07112
trainer/Policy mu Mean              0.0271955
trainer/Policy mu Std               0.703113
trainer/Policy mu Max               3.10219
trainer/Policy mu Min              -3.06389
trainer/Policy log std Mean        -2.16903
trainer/Policy log std Std          0.482124
trainer/Policy log std Max         -0.47305
trainer/Policy log std Min         -2.50385
trainer/Alpha                       0.0554111
trainer/Alpha Loss                 -0.197122
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.518033
exploration/Rewards Std             1.49812
exploration/Rewards Max            -0.00690828
exploration/Rewards Min           -10.1033
exploration/Returns Mean          -51.8033
exploration/Returns Std            13.0301
exploration/Returns Max           -31.0532
exploration/Returns Min           -67.2813
exploration/Actions Mean            0.0140373
exploration/Actions Std             0.273952
exploration/Actions Max             0.998601
exploration/Actions Min            -0.99911
exploration/Num Paths               5
exploration/Average Returns       -51.8033
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.248764
evaluation/Rewards Std              0.945834
evaluation/Rewards Max             -0.0439632
evaluation/Rewards Min             -8.72686
evaluation/Returns Mean           -24.8764
evaluation/Returns Std             11.2396
evaluation/Returns Max            -12.2387
evaluation/Returns Min            -46.924
evaluation/Actions Mean             0.000601633
evaluation/Actions Std              0.200544
evaluation/Actions Max              0.996949
evaluation/Actions Min             -0.995926
evaluation/Num Paths               15
evaluation/Average Returns        -24.8764
time/data storing (s)               0.00356187
time/evaluation sampling (s)        0.352187
time/exploration sampling (s)       0.158077
time/logging (s)                    0.00493598
time/saving (s)                     0.00209065
time/training (s)                   2.10057
time/epoch (s)                      2.62142
time/total (s)                    328.327
Epoch                             121
-----------------------------  ----------------
2019-04-22 21:27:22.500942 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              61700
trainer/QF1 Loss                   33.2241
trainer/QF2 Loss                   33.5341
trainer/Policy Loss                10.8134
trainer/Q1 Predictions Mean        -9.00719
trainer/Q1 Predictions Std          9.2323
trainer/Q1 Predictions Max         -6.5456
trainer/Q1 Predictions Min        -68.0438
trainer/Q2 Predictions Mean        -8.98492
trainer/Q2 Predictions Std          9.27839
trainer/Q2 Predictions Max         -6.47055
trainer/Q2 Predictions Min        -68.3433
trainer/Q Targets Mean             -8.30208
trainer/Q Targets Std               7.3274
trainer/Q Targets Max              -0.0726114
trainer/Q Targets Min             -57.2043
trainer/Log Pis Mean                2.22065
trainer/Log Pis Std                 1.26549
trainer/Log Pis Max                 7.26721
trainer/Log Pis Min                -1.7087
trainer/Policy mu Mean              0.106907
trainer/Policy mu Std               0.709923
trainer/Policy mu Max               3.2929
trainer/Policy mu Min              -3.06173
trainer/Policy log std Mean        -2.20634
trainer/Policy log std Std          0.477285
trainer/Policy log std Max         -0.387507
trainer/Policy log std Min         -2.53415
trainer/Alpha                       0.0536932
trainer/Alpha Loss                  0.645305
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.344873
exploration/Rewards Std             1.05084
exploration/Rewards Max            -0.00147044
exploration/Rewards Min           -10.1302
exploration/Returns Mean          -34.4873
exploration/Returns Std            17.8561
exploration/Returns Max           -19.5829
exploration/Returns Min           -68.7935
exploration/Actions Mean           -0.0261453
exploration/Actions Std             0.238879
exploration/Actions Max             0.975562
exploration/Actions Min            -0.999568
exploration/Num Paths               5
exploration/Average Returns       -34.4873
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245098
evaluation/Rewards Std              0.982027
evaluation/Rewards Max             -0.013542
evaluation/Rewards Min             -9.90637
evaluation/Returns Mean           -24.5098
evaluation/Returns Std             14.2775
evaluation/Returns Max             -8.05382
evaluation/Returns Min            -56.8707
evaluation/Actions Mean            -0.00554324
evaluation/Actions Std              0.203404
evaluation/Actions Max              0.996738
evaluation/Actions Min             -0.997701
evaluation/Num Paths               15
evaluation/Average Returns        -24.5098
time/data storing (s)               0.00319532
time/evaluation sampling (s)        0.348011
time/exploration sampling (s)       0.160462
time/logging (s)                    0.00494206
time/saving (s)                     0.00213305
time/training (s)                   2.11395
time/epoch (s)                      2.63269
time/total (s)                    330.964
Epoch                             122
-----------------------------  ---------------
2019-04-22 21:27:25.196350 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                    0.480927
trainer/QF2 Loss                    0.48593
trainer/Policy Loss                10.2779
trainer/Q1 Predictions Mean        -8.45627
trainer/Q1 Predictions Std          7.7172
trainer/Q1 Predictions Max         -6.44746
trainer/Q1 Predictions Min        -61.9259
trainer/Q2 Predictions Mean        -8.45615
trainer/Q2 Predictions Std          7.63594
trainer/Q2 Predictions Max         -6.48659
trainer/Q2 Predictions Min        -62.1151
trainer/Q Targets Mean             -8.43642
trainer/Q Targets Std               7.74252
trainer/Q Targets Max              -0.178758
trainer/Q Targets Min             -62.5215
trainer/Log Pis Mean                2.26364
trainer/Log Pis Std                 1.25007
trainer/Log Pis Max                 7.56735
trainer/Log Pis Min                -0.909563
trainer/Policy mu Mean             -0.0111156
trainer/Policy mu Std               0.702934
trainer/Policy mu Max               3.33859
trainer/Policy mu Min              -2.94043
trainer/Policy log std Mean        -2.19037
trainer/Policy log std Std          0.487775
trainer/Policy log std Max         -0.483692
trainer/Policy log std Min         -2.47876
trainer/Alpha                       0.0560564
trainer/Alpha Loss                  0.759721
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.339851
exploration/Rewards Std             0.989259
exploration/Rewards Max            -0.00995984
exploration/Rewards Min            -7.91527
exploration/Returns Mean          -33.9851
exploration/Returns Std             8.12843
exploration/Returns Max           -24.992
exploration/Returns Min           -46.0441
exploration/Actions Mean            0.0114023
exploration/Actions Std             0.250418
exploration/Actions Max             0.999156
exploration/Actions Min            -0.998069
exploration/Num Paths               5
exploration/Average Returns       -33.9851
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274347
evaluation/Rewards Std              1.09863
evaluation/Rewards Max             -0.00455268
evaluation/Rewards Min             -9.54609
evaluation/Returns Mean           -27.4347
evaluation/Returns Std             15.8846
evaluation/Returns Max             -2.43004
evaluation/Returns Min            -56.6148
evaluation/Actions Mean            -0.00968924
evaluation/Actions Std              0.205309
evaluation/Actions Max              0.996212
evaluation/Actions Min             -0.996483
evaluation/Num Paths               15
evaluation/Average Returns        -27.4347
time/data storing (s)               0.0033747
time/evaluation sampling (s)        0.372857
time/exploration sampling (s)       0.171834
time/logging (s)                    0.00516512
time/saving (s)                     0.00216395
time/training (s)                   2.13383
time/epoch (s)                      2.68923
time/total (s)                    333.658
Epoch                             123
-----------------------------  ---------------
2019-04-22 21:27:27.852342 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 124 finished
-----------------------------  ----------------
replay_buffer/size              62700
trainer/QF1 Loss                    0.494378
trainer/QF2 Loss                    0.492006
trainer/Policy Loss                 9.36951
trainer/Q1 Predictions Mean        -7.74188
trainer/Q1 Predictions Std          4.64231
trainer/Q1 Predictions Max         -6.37059
trainer/Q1 Predictions Min        -48.1397
trainer/Q2 Predictions Mean        -7.77361
trainer/Q2 Predictions Std          4.62689
trainer/Q2 Predictions Max         -6.43388
trainer/Q2 Predictions Min        -47.9578
trainer/Q Targets Mean             -7.76736
trainer/Q Targets Std               4.71756
trainer/Q Targets Max              -0.253804
trainer/Q Targets Min             -48.2827
trainer/Log Pis Mean                1.84265
trainer/Log Pis Std                 0.996155
trainer/Log Pis Max                 3.79394
trainer/Log Pis Min                -2.09532
trainer/Policy mu Mean              0.0184543
trainer/Policy mu Std               0.566111
trainer/Policy mu Max               2.84169
trainer/Policy mu Min              -2.98783
trainer/Policy log std Mean        -2.21073
trainer/Policy log std Std          0.41237
trainer/Policy log std Max         -0.528026
trainer/Policy log std Min         -2.43152
trainer/Alpha                       0.0558601
trainer/Alpha Loss                 -0.453942
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.349659
exploration/Rewards Std             0.995122
exploration/Rewards Max            -0.00239187
exploration/Rewards Min            -8.43608
exploration/Returns Mean          -34.9659
exploration/Returns Std             6.39821
exploration/Returns Max           -28.9903
exploration/Returns Min           -44.4612
exploration/Actions Mean            0.000172325
exploration/Actions Std             0.252671
exploration/Actions Max             0.997554
exploration/Actions Min            -0.998625
exploration/Num Paths               5
exploration/Average Returns       -34.9659
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.183937
evaluation/Rewards Std              0.782984
evaluation/Rewards Max             -0.0166367
evaluation/Rewards Min            -10.1422
evaluation/Returns Mean           -18.3937
evaluation/Returns Std             14.9051
evaluation/Returns Max             -3.89731
evaluation/Returns Min            -63.1511
evaluation/Actions Mean            -0.0125058
evaluation/Actions Std              0.176651
evaluation/Actions Max              0.996903
evaluation/Actions Min             -0.995722
evaluation/Num Paths               15
evaluation/Average Returns        -18.3937
time/data storing (s)               0.00352651
time/evaluation sampling (s)        0.359492
time/exploration sampling (s)       0.164372
time/logging (s)                    0.0050248
time/saving (s)                     0.00203294
time/training (s)                   2.11407
time/epoch (s)                      2.64851
time/total (s)                    336.311
Epoch                             124
-----------------------------  ----------------
2019-04-22 21:27:30.544947 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              63200
trainer/QF1 Loss                    0.451895
trainer/QF2 Loss                    0.450181
trainer/Policy Loss                10.0955
trainer/Q1 Predictions Mean        -8.14029
trainer/Q1 Predictions Std          6.30595
trainer/Q1 Predictions Max         -6.30143
trainer/Q1 Predictions Min        -48.5306
trainer/Q2 Predictions Mean        -8.21939
trainer/Q2 Predictions Std          6.25109
trainer/Q2 Predictions Max         -6.43764
trainer/Q2 Predictions Min        -48.0452
trainer/Q Targets Mean             -8.28217
trainer/Q Targets Std               6.32635
trainer/Q Targets Max              -0.141319
trainer/Q Targets Min             -48.8492
trainer/Log Pis Mean                2.07229
trainer/Log Pis Std                 1.27359
trainer/Log Pis Max                 8.35014
trainer/Log Pis Min                -1.57366
trainer/Policy mu Mean              0.0751424
trainer/Policy mu Std               0.676746
trainer/Policy mu Max               3.1868
trainer/Policy mu Min              -2.99692
trainer/Policy log std Mean        -2.11151
trainer/Policy log std Std          0.419504
trainer/Policy log std Max         -0.525546
trainer/Policy log std Min         -2.45605
trainer/Alpha                       0.0562297
trainer/Alpha Loss                  0.208062
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.371637
exploration/Rewards Std             1.11389
exploration/Rewards Max            -0.00379135
exploration/Rewards Min            -9.37977
exploration/Returns Mean          -37.1637
exploration/Returns Std            15.5507
exploration/Returns Max           -15.7289
exploration/Returns Min           -55.3064
exploration/Actions Mean           -0.0113096
exploration/Actions Std             0.254217
exploration/Actions Max             0.996766
exploration/Actions Min            -0.999021
exploration/Num Paths               5
exploration/Average Returns       -37.1637
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.242468
evaluation/Rewards Std              0.919341
evaluation/Rewards Max             -0.0426369
evaluation/Rewards Min            -10.9565
evaluation/Returns Mean           -24.2468
evaluation/Returns Std             14.2169
evaluation/Returns Max             -4.48844
evaluation/Returns Min            -63.6354
evaluation/Actions Mean             0.0094357
evaluation/Actions Std              0.197319
evaluation/Actions Max              0.998172
evaluation/Actions Min             -0.998788
evaluation/Num Paths               15
evaluation/Average Returns        -24.2468
time/data storing (s)               0.00316709
time/evaluation sampling (s)        0.357179
time/exploration sampling (s)       0.158802
time/logging (s)                    0.00511109
time/saving (s)                     0.00200689
time/training (s)                   2.15933
time/epoch (s)                      2.68559
time/total (s)                    339.001
Epoch                             125
-----------------------------  ---------------
2019-04-22 21:27:33.208396 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              63700
trainer/QF1 Loss                    0.518411
trainer/QF2 Loss                    0.517081
trainer/Policy Loss                 9.54712
trainer/Q1 Predictions Mean        -7.81979
trainer/Q1 Predictions Std          4.71636
trainer/Q1 Predictions Max         -6.44659
trainer/Q1 Predictions Min        -46.9928
trainer/Q2 Predictions Mean        -7.82445
trainer/Q2 Predictions Std          4.66732
trainer/Q2 Predictions Max         -6.51907
trainer/Q2 Predictions Min        -46.6406
trainer/Q Targets Mean             -7.71941
trainer/Q Targets Std               4.76208
trainer/Q Targets Max              -0.0691279
trainer/Q Targets Min             -47.4408
trainer/Log Pis Mean                1.9357
trainer/Log Pis Std                 1.18634
trainer/Log Pis Max                 7.7655
trainer/Log Pis Min                -1.20846
trainer/Policy mu Mean              0.088339
trainer/Policy mu Std               0.62092
trainer/Policy mu Max               2.60009
trainer/Policy mu Min              -2.91542
trainer/Policy log std Mean        -2.09162
trainer/Policy log std Std          0.418406
trainer/Policy log std Max         -0.553068
trainer/Policy log std Min         -2.39799
trainer/Alpha                       0.0561081
trainer/Alpha Loss                 -0.185192
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.484902
exploration/Rewards Std             1.45948
exploration/Rewards Max            -0.0136325
exploration/Rewards Min           -11.2183
exploration/Returns Mean          -48.4902
exploration/Returns Std            17.6497
exploration/Returns Max           -22.1591
exploration/Returns Min           -70.2455
exploration/Actions Mean            0.0192507
exploration/Actions Std             0.276818
exploration/Actions Max             0.999269
exploration/Actions Min            -0.999526
exploration/Num Paths               5
exploration/Average Returns       -48.4902
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247927
evaluation/Rewards Std              0.981109
evaluation/Rewards Max             -0.013246
evaluation/Rewards Min             -9.77014
evaluation/Returns Mean           -24.7927
evaluation/Returns Std             15.3947
evaluation/Returns Max             -3.65042
evaluation/Returns Min            -45.3514
evaluation/Actions Mean             0.0027384
evaluation/Actions Std              0.18732
evaluation/Actions Max              0.997469
evaluation/Actions Min             -0.995593
evaluation/Num Paths               15
evaluation/Average Returns        -24.7927
time/data storing (s)               0.00321808
time/evaluation sampling (s)        0.356913
time/exploration sampling (s)       0.159613
time/logging (s)                    0.00460365
time/saving (s)                     0.00220735
time/training (s)                   2.12954
time/epoch (s)                      2.65609
time/total (s)                    341.662
Epoch                             126
-----------------------------  ---------------
2019-04-22 21:27:35.887513 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    0.0116845
trainer/QF2 Loss                    0.00938074
trainer/Policy Loss                 9.97546
trainer/Q1 Predictions Mean        -8.24608
trainer/Q1 Predictions Std          7.80485
trainer/Q1 Predictions Max         -6.51065
trainer/Q1 Predictions Min        -61.6054
trainer/Q2 Predictions Mean        -8.25724
trainer/Q2 Predictions Std          7.85497
trainer/Q2 Predictions Max         -6.44256
trainer/Q2 Predictions Min        -61.978
trainer/Q Targets Mean             -8.26201
trainer/Q Targets Std               7.82537
trainer/Q Targets Max              -6.39027
trainer/Q Targets Min             -61.7751
trainer/Log Pis Mean                2.03029
trainer/Log Pis Std                 1.21184
trainer/Log Pis Max                 6.16759
trainer/Log Pis Min                -2.0291
trainer/Policy mu Mean             -0.024949
trainer/Policy mu Std               0.602439
trainer/Policy mu Max               2.72171
trainer/Policy mu Min              -2.90682
trainer/Policy log std Mean        -2.15033
trainer/Policy log std Std          0.434354
trainer/Policy log std Max         -0.480772
trainer/Policy log std Min         -2.48647
trainer/Alpha                       0.0570991
trainer/Alpha Loss                  0.0867166
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.238967
exploration/Rewards Std             0.592444
exploration/Rewards Max            -0.00198632
exploration/Rewards Min            -5.9874
exploration/Returns Mean          -23.8967
exploration/Returns Std             4.73695
exploration/Returns Max           -15.1886
exploration/Returns Min           -29.6503
exploration/Actions Mean            5.792e-05
exploration/Actions Std             0.226356
exploration/Actions Max             0.994964
exploration/Actions Min            -0.997237
exploration/Num Paths               5
exploration/Average Returns       -23.8967
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.212503
evaluation/Rewards Std              0.917328
evaluation/Rewards Max             -0.0171714
evaluation/Rewards Min            -10.1324
evaluation/Returns Mean           -21.2503
evaluation/Returns Std             15.6319
evaluation/Returns Max             -5.947
evaluation/Returns Min            -60.8332
evaluation/Actions Mean             0.00573599
evaluation/Actions Std              0.188175
evaluation/Actions Max              0.997092
evaluation/Actions Min             -0.997221
evaluation/Num Paths               15
evaluation/Average Returns        -21.2503
time/data storing (s)               0.00334737
time/evaluation sampling (s)        0.359566
time/exploration sampling (s)       0.162414
time/logging (s)                    0.00477493
time/saving (s)                     0.00226359
time/training (s)                   2.13966
time/epoch (s)                      2.67202
time/total (s)                    344.338
Epoch                             127
-----------------------------  ---------------
2019-04-22 21:27:38.529062 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              64700
trainer/QF1 Loss                    0.908037
trainer/QF2 Loss                    0.920148
trainer/Policy Loss                 9.81352
trainer/Q1 Predictions Mean        -8.04313
trainer/Q1 Predictions Std          7.08184
trainer/Q1 Predictions Max         -6.43581
trainer/Q1 Predictions Min        -56.4146
trainer/Q2 Predictions Mean        -8.06622
trainer/Q2 Predictions Std          7.13005
trainer/Q2 Predictions Max         -6.44656
trainer/Q2 Predictions Min        -56.889
trainer/Q Targets Mean             -7.94048
trainer/Q Targets Std               7.13885
trainer/Q Targets Max              -0.140986
trainer/Q Targets Min             -56.3787
trainer/Log Pis Mean                1.89051
trainer/Log Pis Std                 1.50746
trainer/Log Pis Max                 9.32077
trainer/Log Pis Min                -6.28581
trainer/Policy mu Mean             -0.011761
trainer/Policy mu Std               0.511882
trainer/Policy mu Max               3.24559
trainer/Policy mu Min              -3.095
trainer/Policy log std Mean        -2.20609
trainer/Policy log std Std          0.335719
trainer/Policy log std Max         -0.505633
trainer/Policy log std Min         -2.42699
trainer/Alpha                       0.0565928
trainer/Alpha Loss                 -0.314444
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.390388
exploration/Rewards Std             1.19561
exploration/Rewards Max            -0.00375666
exploration/Rewards Min            -9.49779
exploration/Returns Mean          -39.0388
exploration/Returns Std            18.584
exploration/Returns Max           -17.1437
exploration/Returns Min           -63.9411
exploration/Actions Mean           -0.0142134
exploration/Actions Std             0.244626
exploration/Actions Max             0.999035
exploration/Actions Min            -0.998536
exploration/Num Paths               5
exploration/Average Returns       -39.0388
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.290572
evaluation/Rewards Std              1.19352
evaluation/Rewards Max             -0.0242743
evaluation/Rewards Min            -10.2384
evaluation/Returns Mean           -29.0572
evaluation/Returns Std             17.57
evaluation/Returns Max             -6.72731
evaluation/Returns Min            -60.5181
evaluation/Actions Mean             0.00396352
evaluation/Actions Std              0.205701
evaluation/Actions Max              0.996046
evaluation/Actions Min             -0.997665
evaluation/Num Paths               15
evaluation/Average Returns        -29.0572
time/data storing (s)               0.00309205
time/evaluation sampling (s)        0.353368
time/exploration sampling (s)       0.161704
time/logging (s)                    0.00512008
time/saving (s)                     0.00202685
time/training (s)                   2.10955
time/epoch (s)                      2.63487
time/total (s)                    346.978
Epoch                             128
-----------------------------  ---------------
2019-04-22 21:27:41.222558 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              65200
trainer/QF1 Loss                    0.851367
trainer/QF2 Loss                    0.875013
trainer/Policy Loss                10.5244
trainer/Q1 Predictions Mean        -8.7484
trainer/Q1 Predictions Std          7.61699
trainer/Q1 Predictions Max         -6.411
trainer/Q1 Predictions Min        -58.1957
trainer/Q2 Predictions Mean        -8.84084
trainer/Q2 Predictions Std          7.63584
trainer/Q2 Predictions Max         -6.53426
trainer/Q2 Predictions Min        -58.7636
trainer/Q Targets Mean             -8.68333
trainer/Q Targets Std               7.71644
trainer/Q Targets Max              -0.0376697
trainer/Q Targets Min             -58.8952
trainer/Log Pis Mean                2.12371
trainer/Log Pis Std                 1.22071
trainer/Log Pis Max                 7.23645
trainer/Log Pis Min                -1.08814
trainer/Policy mu Mean              0.0970309
trainer/Policy mu Std               0.720012
trainer/Policy mu Max               3.06303
trainer/Policy mu Min              -3.23046
trainer/Policy log std Mean        -2.10973
trainer/Policy log std Std          0.480722
trainer/Policy log std Max         -0.443269
trainer/Policy log std Min         -2.43419
trainer/Alpha                       0.0555247
trainer/Alpha Loss                  0.357627
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.275158
exploration/Rewards Std             0.797187
exploration/Rewards Max            -0.00199317
exploration/Rewards Min            -8.43903
exploration/Returns Mean          -27.5158
exploration/Returns Std            12.6217
exploration/Returns Max           -14.632
exploration/Returns Min           -50.2428
exploration/Actions Mean            0.0143394
exploration/Actions Std             0.234525
exploration/Actions Max             0.998406
exploration/Actions Min            -0.987796
exploration/Num Paths               5
exploration/Average Returns       -27.5158
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.277247
evaluation/Rewards Std              1.05515
evaluation/Rewards Max             -0.0157437
evaluation/Rewards Min            -10.1064
evaluation/Returns Mean           -27.7247
evaluation/Returns Std             17.2059
evaluation/Returns Max             -9.73194
evaluation/Returns Min            -63.824
evaluation/Actions Mean             0.0102187
evaluation/Actions Std              0.200869
evaluation/Actions Max              0.996797
evaluation/Actions Min             -0.996942
evaluation/Num Paths               15
evaluation/Average Returns        -27.7247
time/data storing (s)               0.00327302
time/evaluation sampling (s)        0.354424
time/exploration sampling (s)       0.165727
time/logging (s)                    0.00490505
time/saving (s)                     0.00201247
time/training (s)                   2.1551
time/epoch (s)                      2.68544
time/total (s)                    349.669
Epoch                             129
-----------------------------  ---------------
2019-04-22 21:27:43.891326 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 130 finished
-----------------------------  ----------------
replay_buffer/size              65700
trainer/QF1 Loss                    0.0297996
trainer/QF2 Loss                    0.0456643
trainer/Policy Loss                 9.83308
trainer/Q1 Predictions Mean        -7.94067
trainer/Q1 Predictions Std          5.49576
trainer/Q1 Predictions Max         -6.46277
trainer/Q1 Predictions Min        -42.8238
trainer/Q2 Predictions Mean        -7.89115
trainer/Q2 Predictions Std          5.44432
trainer/Q2 Predictions Max         -6.34004
trainer/Q2 Predictions Min        -41.6714
trainer/Q Targets Mean             -8.02945
trainer/Q Targets Std               5.44343
trainer/Q Targets Max              -6.37898
trainer/Q Targets Min             -42.8077
trainer/Log Pis Mean                1.93571
trainer/Log Pis Std                 1.47488
trainer/Log Pis Max                 7.08545
trainer/Log Pis Min                -5.53459
trainer/Policy mu Mean              0.0167275
trainer/Policy mu Std               0.582905
trainer/Policy mu Max               2.98948
trainer/Policy mu Min              -3.11781
trainer/Policy log std Mean        -2.21969
trainer/Policy log std Std          0.371418
trainer/Policy log std Max         -0.558914
trainer/Policy log std Min         -2.46183
trainer/Alpha                       0.0564962
trainer/Alpha Loss                 -0.184764
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.205013
exploration/Rewards Std             0.517217
exploration/Rewards Max            -0.00481787
exploration/Rewards Min            -5.04884
exploration/Returns Mean          -20.5013
exploration/Returns Std             6.26536
exploration/Returns Max           -12.1536
exploration/Returns Min           -27.588
exploration/Actions Mean            0.00183362
exploration/Actions Std             0.204078
exploration/Actions Max             0.996262
exploration/Actions Min            -0.997889
exploration/Num Paths               5
exploration/Average Returns       -20.5013
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.186249
evaluation/Rewards Std              0.810057
evaluation/Rewards Max             -0.0154193
evaluation/Rewards Min            -10.0983
evaluation/Returns Mean           -18.6249
evaluation/Returns Std             13.3108
evaluation/Returns Max             -4.98899
evaluation/Returns Min            -58.999
evaluation/Actions Mean             0.000805585
evaluation/Actions Std              0.183827
evaluation/Actions Max              0.996835
evaluation/Actions Min             -0.997809
evaluation/Num Paths               15
evaluation/Average Returns        -18.6249
time/data storing (s)               0.00314677
time/evaluation sampling (s)        0.357378
time/exploration sampling (s)       0.167472
time/logging (s)                    0.00492229
time/saving (s)                     0.00165138
time/training (s)                   2.1268
time/epoch (s)                      2.66137
time/total (s)                    352.335
Epoch                             130
-----------------------------  ----------------
2019-04-22 21:27:46.545357 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    0.594309
trainer/QF2 Loss                    0.59388
trainer/Policy Loss                10.1539
trainer/Q1 Predictions Mean        -8.50027
trainer/Q1 Predictions Std          9.21611
trainer/Q1 Predictions Max         -6.32696
trainer/Q1 Predictions Min        -71.2934
trainer/Q2 Predictions Mean        -8.46824
trainer/Q2 Predictions Std          9.27194
trainer/Q2 Predictions Max         -6.23731
trainer/Q2 Predictions Min        -71.9226
trainer/Q Targets Mean             -8.55458
trainer/Q Targets Std               9.49505
trainer/Q Targets Max              -0.159032
trainer/Q Targets Min             -73.5457
trainer/Log Pis Mean                2.00492
trainer/Log Pis Std                 1.06514
trainer/Log Pis Max                 6.89094
trainer/Log Pis Min                -0.699614
trainer/Policy mu Mean             -0.00067201
trainer/Policy mu Std               0.635161
trainer/Policy mu Max               3.3203
trainer/Policy mu Min              -2.29383
trainer/Policy log std Mean        -2.12712
trainer/Policy log std Std          0.412522
trainer/Policy log std Max         -0.412175
trainer/Policy log std Min         -2.39605
trainer/Alpha                       0.0560948
trainer/Alpha Loss                  0.014171
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378738
exploration/Rewards Std             1.14378
exploration/Rewards Max            -0.00780628
exploration/Rewards Min           -10.7894
exploration/Returns Mean          -37.8738
exploration/Returns Std            17.9538
exploration/Returns Max           -14.9004
exploration/Returns Min           -68.9891
exploration/Actions Mean           -0.0234758
exploration/Actions Std             0.262269
exploration/Actions Max             0.997687
exploration/Actions Min            -0.999697
exploration/Num Paths               5
exploration/Average Returns       -37.8738
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.34916
evaluation/Rewards Std              1.29016
evaluation/Rewards Max             -0.0328372
evaluation/Rewards Min            -10.0134
evaluation/Returns Mean           -34.916
evaluation/Returns Std             18.1519
evaluation/Returns Max             -6.2561
evaluation/Returns Min            -60.5871
evaluation/Actions Mean            -0.00425024
evaluation/Actions Std              0.211426
evaluation/Actions Max              0.997306
evaluation/Actions Min             -0.997732
evaluation/Num Paths               15
evaluation/Average Returns        -34.916
time/data storing (s)               0.00316537
time/evaluation sampling (s)        0.355648
time/exploration sampling (s)       0.160367
time/logging (s)                    0.004818
time/saving (s)                     0.00200989
time/training (s)                   2.12065
time/epoch (s)                      2.64666
time/total (s)                    354.986
Epoch                             131
-----------------------------  ---------------
2019-04-22 21:27:49.222859 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              66700
trainer/QF1 Loss                    0.412052
trainer/QF2 Loss                    0.419657
trainer/Policy Loss                 9.5884
trainer/Q1 Predictions Mean        -7.62459
trainer/Q1 Predictions Std          5.6535
trainer/Q1 Predictions Max         -6.3582
trainer/Q1 Predictions Min        -58.3209
trainer/Q2 Predictions Mean        -7.65071
trainer/Q2 Predictions Std          5.62796
trainer/Q2 Predictions Max         -6.38342
trainer/Q2 Predictions Min        -58.0728
trainer/Q Targets Mean             -7.64048
trainer/Q Targets Std               5.72374
trainer/Q Targets Max              -0.240301
trainer/Q Targets Min             -58.5725
trainer/Log Pis Mean                2.20443
trainer/Log Pis Std                 1.0058
trainer/Log Pis Max                 5.5574
trainer/Log Pis Min                -1.92741
trainer/Policy mu Mean              0.0562372
trainer/Policy mu Std               0.49715
trainer/Policy mu Max               3.03036
trainer/Policy mu Min              -1.46065
trainer/Policy log std Mean        -2.26412
trainer/Policy log std Std          0.36335
trainer/Policy log std Max         -0.595323
trainer/Policy log std Min         -2.56595
trainer/Alpha                       0.0558427
trainer/Alpha Loss                  0.589859
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.263438
exploration/Rewards Std             0.853442
exploration/Rewards Max            -0.00478987
exploration/Rewards Min            -9.2795
exploration/Returns Mean          -26.3438
exploration/Returns Std            16.8034
exploration/Returns Max           -16.0485
exploration/Returns Min           -59.8454
exploration/Actions Mean           -0.0144196
exploration/Actions Std             0.223479
exploration/Actions Max             0.989547
exploration/Actions Min            -0.998572
exploration/Num Paths               5
exploration/Average Returns       -26.3438
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261015
evaluation/Rewards Std              1.0887
evaluation/Rewards Max             -0.00565475
evaluation/Rewards Min            -11.019
evaluation/Returns Mean           -26.1015
evaluation/Returns Std             17.1267
evaluation/Returns Max             -5.54489
evaluation/Returns Min            -61.4395
evaluation/Actions Mean            -0.0104073
evaluation/Actions Std              0.204819
evaluation/Actions Max              0.997417
evaluation/Actions Min             -0.998686
evaluation/Num Paths               15
evaluation/Average Returns        -26.1015
time/data storing (s)               0.00385741
time/evaluation sampling (s)        0.366765
time/exploration sampling (s)       0.167936
time/logging (s)                    0.00493302
time/saving (s)                     0.00203922
time/training (s)                   2.12517
time/epoch (s)                      2.6707
time/total (s)                    357.662
Epoch                             132
-----------------------------  ---------------
2019-04-22 21:27:51.877691 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              67200
trainer/QF1 Loss                    0.886659
trainer/QF2 Loss                    0.912189
trainer/Policy Loss                 9.63284
trainer/Q1 Predictions Mean        -7.75297
trainer/Q1 Predictions Std          4.83645
trainer/Q1 Predictions Max         -6.31691
trainer/Q1 Predictions Min        -39.0519
trainer/Q2 Predictions Mean        -7.76024
trainer/Q2 Predictions Std          4.79733
trainer/Q2 Predictions Max         -6.34355
trainer/Q2 Predictions Min        -39.0563
trainer/Q Targets Mean             -7.67085
trainer/Q Targets Std               4.93553
trainer/Q Targets Max              -0.0903156
trainer/Q Targets Min             -39.1108
trainer/Log Pis Mean                2.01595
trainer/Log Pis Std                 1.12251
trainer/Log Pis Max                 6.40696
trainer/Log Pis Min                -1.22087
trainer/Policy mu Mean              0.0301554
trainer/Policy mu Std               0.565567
trainer/Policy mu Max               2.88782
trainer/Policy mu Min              -3.18095
trainer/Policy log std Mean        -2.17456
trainer/Policy log std Std          0.406911
trainer/Policy log std Max         -0.546167
trainer/Policy log std Min         -2.4476
trainer/Alpha                       0.0558152
trainer/Alpha Loss                  0.0460296
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.279705
exploration/Rewards Std             0.928796
exploration/Rewards Max            -0.00243583
exploration/Rewards Min           -10.4553
exploration/Returns Mean          -27.9705
exploration/Returns Std            20.6876
exploration/Returns Max           -13.2964
exploration/Returns Min           -68.7218
exploration/Actions Mean            0.0220761
exploration/Actions Std             0.220552
exploration/Actions Max             0.998035
exploration/Actions Min            -0.995132
exploration/Num Paths               5
exploration/Average Returns       -27.9705
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213131
evaluation/Rewards Std              0.976989
evaluation/Rewards Max             -0.00273746
evaluation/Rewards Min            -10.9699
evaluation/Returns Mean           -21.3131
evaluation/Returns Std             14.9242
evaluation/Returns Max             -1.37261
evaluation/Returns Min            -59.2692
evaluation/Actions Mean             0.00137196
evaluation/Actions Std              0.19776
evaluation/Actions Max              0.99456
evaluation/Actions Min             -0.99814
evaluation/Num Paths               15
evaluation/Average Returns        -21.3131
time/data storing (s)               0.00322699
time/evaluation sampling (s)        0.356204
time/exploration sampling (s)       0.157751
time/logging (s)                    0.00504465
time/saving (s)                     0.00191619
time/training (s)                   2.12357
time/epoch (s)                      2.64772
time/total (s)                    360.314
Epoch                             133
-----------------------------  ---------------
2019-04-22 21:27:54.572706 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              67700
trainer/QF1 Loss                    0.521629
trainer/QF2 Loss                    0.51563
trainer/Policy Loss                10.1764
trainer/Q1 Predictions Mean        -8.34925
trainer/Q1 Predictions Std          6.56365
trainer/Q1 Predictions Max         -6.49015
trainer/Q1 Predictions Min        -56.1069
trainer/Q2 Predictions Mean        -8.32316
trainer/Q2 Predictions Std          6.58507
trainer/Q2 Predictions Max         -6.40805
trainer/Q2 Predictions Min        -55.9804
trainer/Q Targets Mean             -8.28547
trainer/Q Targets Std               6.73193
trainer/Q Targets Max              -0.170897
trainer/Q Targets Min             -57.6084
trainer/Log Pis Mean                1.99174
trainer/Log Pis Std                 1.16082
trainer/Log Pis Max                 7.51775
trainer/Log Pis Min                -1.47267
trainer/Policy mu Mean              0.0684696
trainer/Policy mu Std               0.674416
trainer/Policy mu Max               3.10787
trainer/Policy mu Min              -3.25346
trainer/Policy log std Mean        -2.10879
trainer/Policy log std Std          0.452974
trainer/Policy log std Max         -0.491975
trainer/Policy log std Min         -2.43678
trainer/Alpha                       0.0574727
trainer/Alpha Loss                 -0.0235812
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.325233
exploration/Rewards Std             1.02097
exploration/Rewards Max            -0.00424996
exploration/Rewards Min           -10.1965
exploration/Returns Mean          -32.5233
exploration/Returns Std            18.0344
exploration/Returns Max           -14.745
exploration/Returns Min           -64.5365
exploration/Actions Mean           -0.00721349
exploration/Actions Std             0.236821
exploration/Actions Max             0.998394
exploration/Actions Min            -0.999516
exploration/Num Paths               5
exploration/Average Returns       -32.5233
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.190099
evaluation/Rewards Std              0.751507
evaluation/Rewards Max             -0.0313658
evaluation/Rewards Min             -8.95071
evaluation/Returns Mean           -19.0099
evaluation/Returns Std             11.6505
evaluation/Returns Max             -5.02506
evaluation/Returns Min            -42.6679
evaluation/Actions Mean            -0.00590086
evaluation/Actions Std              0.178116
evaluation/Actions Max              0.993414
evaluation/Actions Min             -0.997607
evaluation/Num Paths               15
evaluation/Average Returns        -19.0099
time/data storing (s)               0.00338462
time/evaluation sampling (s)        0.353677
time/exploration sampling (s)       0.163446
time/logging (s)                    0.00485182
time/saving (s)                     0.00168077
time/training (s)                   2.16082
time/epoch (s)                      2.68786
time/total (s)                    363.006
Epoch                             134
-----------------------------  ---------------
2019-04-22 21:27:57.226934 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                    0.0310046
trainer/QF2 Loss                    0.0325164
trainer/Policy Loss                 8.97147
trainer/Q1 Predictions Mean        -7.24801
trainer/Q1 Predictions Std          2.70802
trainer/Q1 Predictions Max         -6.27964
trainer/Q1 Predictions Min        -25.0881
trainer/Q2 Predictions Mean        -7.24351
trainer/Q2 Predictions Std          2.74639
trainer/Q2 Predictions Max         -6.26269
trainer/Q2 Predictions Min        -25.5939
trainer/Q Targets Mean             -7.38437
trainer/Q Targets Std               2.71773
trainer/Q Targets Max              -6.30457
trainer/Q Targets Min             -25.364
trainer/Log Pis Mean                1.82072
trainer/Log Pis Std                 1.29866
trainer/Log Pis Max                 5.77325
trainer/Log Pis Min                -3.29113
trainer/Policy mu Mean             -0.0269315
trainer/Policy mu Std               0.575009
trainer/Policy mu Max               2.80125
trainer/Policy mu Min              -2.93352
trainer/Policy log std Mean        -2.14941
trainer/Policy log std Std          0.431038
trainer/Policy log std Max         -0.470927
trainer/Policy log std Min         -2.49511
trainer/Alpha                       0.0570891
trainer/Alpha Loss                 -0.513314
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.287323
exploration/Rewards Std             0.94795
exploration/Rewards Max            -0.00427447
exploration/Rewards Min           -10.1763
exploration/Returns Mean          -28.7323
exploration/Returns Std            19.7434
exploration/Returns Max           -13.3009
exploration/Returns Min           -65.6172
exploration/Actions Mean           -0.0208457
exploration/Actions Std             0.217982
exploration/Actions Max             0.903954
exploration/Actions Min            -0.998028
exploration/Num Paths               5
exploration/Average Returns       -28.7323
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.206129
evaluation/Rewards Std              0.951952
evaluation/Rewards Max             -0.0136283
evaluation/Rewards Min            -10.0025
evaluation/Returns Mean           -20.6129
evaluation/Returns Std             16.0975
evaluation/Returns Max             -2.49918
evaluation/Returns Min            -50.2026
evaluation/Actions Mean            -0.00058456
evaluation/Actions Std              0.182515
evaluation/Actions Max              0.996491
evaluation/Actions Min             -0.998385
evaluation/Num Paths               15
evaluation/Average Returns        -20.6129
time/data storing (s)               0.00321303
time/evaluation sampling (s)        0.354319
time/exploration sampling (s)       0.164944
time/logging (s)                    0.00529863
time/saving (s)                     0.00207478
time/training (s)                   2.11854
time/epoch (s)                      2.64839
time/total (s)                    365.659
Epoch                             135
-----------------------------  ---------------
2019-04-22 21:27:59.944364 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              68700
trainer/QF1 Loss                    0.0539567
trainer/QF2 Loss                    0.0474663
trainer/Policy Loss                 9.87404
trainer/Q1 Predictions Mean        -8.12703
trainer/Q1 Predictions Std          7.64358
trainer/Q1 Predictions Max         -6.13985
trainer/Q1 Predictions Min        -68.8591
trainer/Q2 Predictions Mean        -8.17652
trainer/Q2 Predictions Std          7.57949
trainer/Q2 Predictions Max         -6.22704
trainer/Q2 Predictions Min        -68.3192
trainer/Q Targets Mean             -8.24174
trainer/Q Targets Std               7.6767
trainer/Q Targets Max              -6.30313
trainer/Q Targets Min             -69.9549
trainer/Log Pis Mean                1.90752
trainer/Log Pis Std                 1.28089
trainer/Log Pis Max                 6.55224
trainer/Log Pis Min                -5.31824
trainer/Policy mu Mean              0.0234509
trainer/Policy mu Std               0.613581
trainer/Policy mu Max               3.19019
trainer/Policy mu Min              -2.93525
trainer/Policy log std Mean        -2.11846
trainer/Policy log std Std          0.414526
trainer/Policy log std Max         -0.371956
trainer/Policy log std Min         -2.42531
trainer/Alpha                       0.0573145
trainer/Alpha Loss                 -0.264428
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.454669
exploration/Rewards Std             1.32191
exploration/Rewards Max            -0.00683282
exploration/Rewards Min            -9.62461
exploration/Returns Mean          -45.4669
exploration/Returns Std            16.075
exploration/Returns Max           -20.678
exploration/Returns Min           -65.6432
exploration/Actions Mean            0.00538969
exploration/Actions Std             0.267012
exploration/Actions Max             0.998632
exploration/Actions Min            -0.998988
exploration/Num Paths               5
exploration/Average Returns       -45.4669
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.278783
evaluation/Rewards Std              1.09628
evaluation/Rewards Max             -0.046993
evaluation/Rewards Min            -10.5963
evaluation/Returns Mean           -27.8783
evaluation/Returns Std             19.2427
evaluation/Returns Max             -5.6554
evaluation/Returns Min            -62.4754
evaluation/Actions Mean            -0.0139834
evaluation/Actions Std              0.195066
evaluation/Actions Max              0.996927
evaluation/Actions Min             -0.997368
evaluation/Num Paths               15
evaluation/Average Returns        -27.8783
time/data storing (s)               0.00328491
time/evaluation sampling (s)        0.376977
time/exploration sampling (s)       0.164122
time/logging (s)                    0.00490781
time/saving (s)                     0.00206854
time/training (s)                   2.15806
time/epoch (s)                      2.70942
time/total (s)                    368.373
Epoch                             136
-----------------------------  ---------------
2019-04-22 21:28:02.571299 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                    0.00888099
trainer/QF2 Loss                    0.0203367
trainer/Policy Loss                 9.2739
trainer/Q1 Predictions Mean        -7.44361
trainer/Q1 Predictions Std          2.5007
trainer/Q1 Predictions Max         -6.31719
trainer/Q1 Predictions Min        -25.3746
trainer/Q2 Predictions Mean        -7.38413
trainer/Q2 Predictions Std          2.47208
trainer/Q2 Predictions Max         -6.20144
trainer/Q2 Predictions Min        -25.1843
trainer/Q Targets Mean             -7.43077
trainer/Q Targets Std               2.48057
trainer/Q Targets Max              -6.3131
trainer/Q Targets Min             -25.2512
trainer/Log Pis Mean                1.94189
trainer/Log Pis Std                 1.36204
trainer/Log Pis Max                 5.86028
trainer/Log Pis Min                -7.34939
trainer/Policy mu Mean              0.066074
trainer/Policy mu Std               0.574512
trainer/Policy mu Max               2.97826
trainer/Policy mu Min              -3.12872
trainer/Policy log std Mean        -2.13021
trainer/Policy log std Std          0.402459
trainer/Policy log std Max         -0.439951
trainer/Policy log std Min         -2.44134
trainer/Alpha                       0.0540635
trainer/Alpha Loss                 -0.169517
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.361397
exploration/Rewards Std             1.16929
exploration/Rewards Max            -0.00280294
exploration/Rewards Min            -9.60887
exploration/Returns Mean          -36.1397
exploration/Returns Std            20.3549
exploration/Returns Max           -11.1453
exploration/Returns Min           -59.4011
exploration/Actions Mean            0.0162188
exploration/Actions Std             0.235338
exploration/Actions Max             0.998756
exploration/Actions Min            -0.998857
exploration/Num Paths               5
exploration/Average Returns       -36.1397
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.204597
evaluation/Rewards Std              0.807218
evaluation/Rewards Max             -0.0229725
evaluation/Rewards Min             -9.30428
evaluation/Returns Mean           -20.4597
evaluation/Returns Std              9.12339
evaluation/Returns Max             -6.19105
evaluation/Returns Min            -45.1751
evaluation/Actions Mean            -0.00835742
evaluation/Actions Std              0.197962
evaluation/Actions Max              0.994189
evaluation/Actions Min             -0.998479
evaluation/Num Paths               15
evaluation/Average Returns        -20.4597
time/data storing (s)               0.00350241
time/evaluation sampling (s)        0.352942
time/exploration sampling (s)       0.157718
time/logging (s)                    0.004861
time/saving (s)                     0.00229273
time/training (s)                   2.0996
time/epoch (s)                      2.62091
time/total (s)                    370.997
Epoch                             137
-----------------------------  ---------------
2019-04-22 21:28:05.293077 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              69700
trainer/QF1 Loss                    1.36971
trainer/QF2 Loss                    1.39534
trainer/Policy Loss                10.4302
trainer/Q1 Predictions Mean        -8.61833
trainer/Q1 Predictions Std          8.74988
trainer/Q1 Predictions Max         -6.21593
trainer/Q1 Predictions Min        -68.1792
trainer/Q2 Predictions Mean        -8.62733
trainer/Q2 Predictions Std          8.69512
trainer/Q2 Predictions Max         -6.22984
trainer/Q2 Predictions Min        -67.2346
trainer/Q Targets Mean             -8.52997
trainer/Q Targets Std               9.02203
trainer/Q Targets Max              -0.0233912
trainer/Q Targets Min             -69.9232
trainer/Log Pis Mean                2.06122
trainer/Log Pis Std                 1.34722
trainer/Log Pis Max                 9.21666
trainer/Log Pis Min                -1.21249
trainer/Policy mu Mean              0.0865655
trainer/Policy mu Std               0.663265
trainer/Policy mu Max               3.25862
trainer/Policy mu Min              -3.1441
trainer/Policy log std Mean        -2.15068
trainer/Policy log std Std          0.441282
trainer/Policy log std Max         -0.48646
trainer/Policy log std Min         -2.43556
trainer/Alpha                       0.0550335
trainer/Alpha Loss                  0.177516
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.427832
exploration/Rewards Std             1.29322
exploration/Rewards Max            -0.00126779
exploration/Rewards Min            -9.98037
exploration/Returns Mean          -42.7832
exploration/Returns Std            15.0332
exploration/Returns Max           -25.4819
exploration/Returns Min           -65.9714
exploration/Actions Mean            0.0275876
exploration/Actions Std             0.265078
exploration/Actions Max             0.999393
exploration/Actions Min            -0.998977
exploration/Num Paths               5
exploration/Average Returns       -42.7832
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228409
evaluation/Rewards Std              0.994156
evaluation/Rewards Max             -0.0207509
evaluation/Rewards Min            -10.1638
evaluation/Returns Mean           -22.8409
evaluation/Returns Std             16.9245
evaluation/Returns Max             -2.82533
evaluation/Returns Min            -60.9003
evaluation/Actions Mean             0.00428975
evaluation/Actions Std              0.186894
evaluation/Actions Max              0.996887
evaluation/Actions Min             -0.997337
evaluation/Num Paths               15
evaluation/Average Returns        -22.8409
time/data storing (s)               0.00371154
time/evaluation sampling (s)        0.359644
time/exploration sampling (s)       0.15727
time/logging (s)                    0.00441921
time/saving (s)                     0.00201673
time/training (s)                   2.18734
time/epoch (s)                      2.7144
time/total (s)                    373.716
Epoch                             138
-----------------------------  ---------------
2019-04-22 21:28:07.949345 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 139 finished
-----------------------------  ----------------
replay_buffer/size              70200
trainer/QF1 Loss                    0.0161023
trainer/QF2 Loss                    0.0218631
trainer/Policy Loss                 8.66417
trainer/Q1 Predictions Mean        -6.98552
trainer/Q1 Predictions Std          1.66341
trainer/Q1 Predictions Max         -6.4235
trainer/Q1 Predictions Min        -19.7246
trainer/Q2 Predictions Mean        -6.95353
trainer/Q2 Predictions Std          1.71225
trainer/Q2 Predictions Max         -6.34261
trainer/Q2 Predictions Min        -20.3058
trainer/Q Targets Mean             -7.03061
trainer/Q Targets Std               1.66683
trainer/Q Targets Max              -6.30134
trainer/Q Targets Min             -19.7309
trainer/Log Pis Mean                1.8261
trainer/Log Pis Std                 1.07299
trainer/Log Pis Max                 4.1066
trainer/Log Pis Min                -2.23773
trainer/Policy mu Mean              0.00293774
trainer/Policy mu Std               0.434429
trainer/Policy mu Max               2.67465
trainer/Policy mu Min              -2.61804
trainer/Policy log std Mean        -2.28375
trainer/Policy log std Std          0.307472
trainer/Policy log std Max         -0.5955
trainer/Policy log std Min         -2.49844
trainer/Alpha                       0.0549056
trainer/Alpha Loss                 -0.5047
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.289746
exploration/Rewards Std             0.858793
exploration/Rewards Max            -0.0065116
exploration/Rewards Min            -8.63437
exploration/Returns Mean          -28.9746
exploration/Returns Std            10.6172
exploration/Returns Max           -16.0546
exploration/Returns Min           -46.0672
exploration/Actions Mean           -0.0148515
exploration/Actions Std             0.23325
exploration/Actions Max             0.999267
exploration/Actions Min            -0.999106
exploration/Num Paths               5
exploration/Average Returns       -28.9746
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.278679
evaluation/Rewards Std              1.05275
evaluation/Rewards Max             -0.0397689
evaluation/Rewards Min            -10.2306
evaluation/Returns Mean           -27.8679
evaluation/Returns Std             16.1994
evaluation/Returns Max             -7.18326
evaluation/Returns Min            -54.0771
evaluation/Actions Mean             0.000656312
evaluation/Actions Std              0.199384
evaluation/Actions Max              0.997371
evaluation/Actions Min             -0.996301
evaluation/Num Paths               15
evaluation/Average Returns        -27.8679
time/data storing (s)               0.00318787
time/evaluation sampling (s)        0.354348
time/exploration sampling (s)       0.159008
time/logging (s)                    0.00507864
time/saving (s)                     0.00201878
time/training (s)                   2.12577
time/epoch (s)                      2.64942
time/total (s)                    376.37
Epoch                             139
-----------------------------  ----------------
2019-04-22 21:28:10.623893 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              70700
trainer/QF1 Loss                    0.0159748
trainer/QF2 Loss                    0.0208869
trainer/Policy Loss                 8.87593
trainer/Q1 Predictions Mean        -7.11393
trainer/Q1 Predictions Std          2.16096
trainer/Q1 Predictions Max         -6.3086
trainer/Q1 Predictions Min        -22.9162
trainer/Q2 Predictions Mean        -7.10391
trainer/Q2 Predictions Std          2.18922
trainer/Q2 Predictions Max         -6.30459
trainer/Q2 Predictions Min        -23.1857
trainer/Q Targets Mean             -7.16467
trainer/Q Targets Std               2.11273
trainer/Q Targets Max              -6.30365
trainer/Q Targets Min             -22.5183
trainer/Log Pis Mean                1.83141
trainer/Log Pis Std                 1.14336
trainer/Log Pis Max                 4.5304
trainer/Log Pis Min                -2.92608
trainer/Policy mu Mean             -0.0429943
trainer/Policy mu Std               0.485106
trainer/Policy mu Max               3.14262
trainer/Policy mu Min              -2.90582
trainer/Policy log std Mean        -2.1763
trainer/Policy log std Std          0.347968
trainer/Policy log std Max         -0.420857
trainer/Policy log std Min         -2.51738
trainer/Alpha                       0.0558344
trainer/Alpha Loss                 -0.486433
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.36831
exploration/Rewards Std             0.970193
exploration/Rewards Max            -0.0134348
exploration/Rewards Min            -7.87858
exploration/Returns Mean          -36.831
exploration/Returns Std             6.00182
exploration/Returns Max           -30.0801
exploration/Returns Min           -46.6398
exploration/Actions Mean            0.00375651
exploration/Actions Std             0.254764
exploration/Actions Max             0.998245
exploration/Actions Min            -0.999466
exploration/Num Paths               5
exploration/Average Returns       -36.831
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.277501
evaluation/Rewards Std              0.954002
evaluation/Rewards Max             -0.0123699
evaluation/Rewards Min             -9.93765
evaluation/Returns Mean           -27.7501
evaluation/Returns Std             14.3228
evaluation/Returns Max             -8.49897
evaluation/Returns Min            -52.5212
evaluation/Actions Mean             0.00701063
evaluation/Actions Std              0.197529
evaluation/Actions Max              0.997203
evaluation/Actions Min             -0.998541
evaluation/Num Paths               15
evaluation/Average Returns        -27.7501
time/data storing (s)               0.00334912
time/evaluation sampling (s)        0.362593
time/exploration sampling (s)       0.16667
time/logging (s)                    0.00453587
time/saving (s)                     0.00205119
time/training (s)                   2.1279
time/epoch (s)                      2.66709
time/total (s)                    379.042
Epoch                             140
-----------------------------  ---------------
2019-04-22 21:28:13.373903 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                    0.467468
trainer/QF2 Loss                    0.459384
trainer/Policy Loss                 9.03699
trainer/Q1 Predictions Mean        -7.28009
trainer/Q1 Predictions Std          3.95338
trainer/Q1 Predictions Max         -6.18865
trainer/Q1 Predictions Min        -42.1107
trainer/Q2 Predictions Mean        -7.34319
trainer/Q2 Predictions Std          3.93144
trainer/Q2 Predictions Max         -6.31539
trainer/Q2 Predictions Min        -41.8966
trainer/Q Targets Mean             -7.36384
trainer/Q Targets Std               4.0424
trainer/Q Targets Max              -0.135692
trainer/Q Targets Min             -42.7356
trainer/Log Pis Mean                1.7958
trainer/Log Pis Std                 1.1246
trainer/Log Pis Max                 7.38489
trainer/Log Pis Min                -2.27379
trainer/Policy mu Mean             -0.0474384
trainer/Policy mu Std               0.533082
trainer/Policy mu Max               3.13443
trainer/Policy mu Min              -2.92878
trainer/Policy log std Mean        -2.15877
trainer/Policy log std Std          0.372188
trainer/Policy log std Max         -0.468541
trainer/Policy log std Min         -2.42124
trainer/Alpha                       0.0552035
trainer/Alpha Loss                 -0.591507
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.32081
exploration/Rewards Std             0.978372
exploration/Rewards Max            -0.00829529
exploration/Rewards Min            -8.17098
exploration/Returns Mean          -32.081
exploration/Returns Std            15.2043
exploration/Returns Max           -13.7613
exploration/Returns Min           -49.3919
exploration/Actions Mean           -0.00433058
exploration/Actions Std             0.232135
exploration/Actions Max             0.999713
exploration/Actions Min            -0.999807
exploration/Num Paths               5
exploration/Average Returns       -32.081
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.197014
evaluation/Rewards Std              0.947412
evaluation/Rewards Max             -0.0127273
evaluation/Rewards Min            -10.0082
evaluation/Returns Mean           -19.7014
evaluation/Returns Std             13.8447
evaluation/Returns Max             -1.35226
evaluation/Returns Min            -52.8676
evaluation/Actions Mean            -0.00373629
evaluation/Actions Std              0.19358
evaluation/Actions Max              0.997403
evaluation/Actions Min             -0.997985
evaluation/Num Paths               15
evaluation/Average Returns        -19.7014
time/data storing (s)               0.00326431
time/evaluation sampling (s)        0.38938
time/exploration sampling (s)       0.15945
time/logging (s)                    0.00519771
time/saving (s)                     0.0102052
time/training (s)                   2.17596
time/epoch (s)                      2.74346
time/total (s)                    381.79
Epoch                             141
-----------------------------  ---------------
2019-04-22 21:28:16.016147 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              71700
trainer/QF1 Loss                    0.463343
trainer/QF2 Loss                    0.458692
trainer/Policy Loss                 9.94429
trainer/Q1 Predictions Mean        -8.38088
trainer/Q1 Predictions Std          8.62881
trainer/Q1 Predictions Max         -6.27914
trainer/Q1 Predictions Min        -69.1295
trainer/Q2 Predictions Mean        -8.36692
trainer/Q2 Predictions Std          8.58189
trainer/Q2 Predictions Max         -6.33409
trainer/Q2 Predictions Min        -68.2555
trainer/Q Targets Mean             -8.38017
trainer/Q Targets Std               8.59896
trainer/Q Targets Max              -0.0794341
trainer/Q Targets Min             -68.7171
trainer/Log Pis Mean                1.82682
trainer/Log Pis Std                 1.32111
trainer/Log Pis Max                 6.40583
trainer/Log Pis Min                -2.90672
trainer/Policy mu Mean              0.0166214
trainer/Policy mu Std               0.616066
trainer/Policy mu Max               3.24858
trainer/Policy mu Min              -2.99911
trainer/Policy log std Mean        -2.16333
trainer/Policy log std Std          0.408653
trainer/Policy log std Max         -0.44214
trainer/Policy log std Min         -2.42578
trainer/Alpha                       0.055146
trainer/Alpha Loss                 -0.501797
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.228932
exploration/Rewards Std             0.569027
exploration/Rewards Max            -0.0105307
exploration/Rewards Min            -6.9211
exploration/Returns Mean          -22.8932
exploration/Returns Std             6.47686
exploration/Returns Max           -17.8011
exploration/Returns Min           -34.729
exploration/Actions Mean            0.00972212
exploration/Actions Std             0.219114
exploration/Actions Max             0.999858
exploration/Actions Min            -0.986213
exploration/Num Paths               5
exploration/Average Returns       -22.8932
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238616
evaluation/Rewards Std              0.984892
evaluation/Rewards Max             -0.0220748
evaluation/Rewards Min            -10.5781
evaluation/Returns Mean           -23.8616
evaluation/Returns Std             16.4808
evaluation/Returns Max             -5.00474
evaluation/Returns Min            -60.471
evaluation/Actions Mean            -0.0107738
evaluation/Actions Std              0.191499
evaluation/Actions Max              0.997941
evaluation/Actions Min             -0.998138
evaluation/Num Paths               15
evaluation/Average Returns        -23.8616
time/data storing (s)               0.00349918
time/evaluation sampling (s)        0.358228
time/exploration sampling (s)       0.163757
time/logging (s)                    0.00508488
time/saving (s)                     0.00213925
time/training (s)                   2.10151
time/epoch (s)                      2.63422
time/total (s)                    384.429
Epoch                             142
-----------------------------  ---------------
2019-04-22 21:28:18.739817 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              72200
trainer/QF1 Loss                    0.025583
trainer/QF2 Loss                    0.0202892
trainer/Policy Loss                 9.92869
trainer/Q1 Predictions Mean        -8.30771
trainer/Q1 Predictions Std          6.85317
trainer/Q1 Predictions Max         -6.23224
trainer/Q1 Predictions Min        -49.4442
trainer/Q2 Predictions Mean        -8.30334
trainer/Q2 Predictions Std          6.84655
trainer/Q2 Predictions Max         -6.26306
trainer/Q2 Predictions Min        -49.3535
trainer/Q Targets Mean             -8.36777
trainer/Q Targets Std               6.77365
trainer/Q Targets Max              -6.31984
trainer/Q Targets Min             -48.5235
trainer/Log Pis Mean                1.85422
trainer/Log Pis Std                 1.38108
trainer/Log Pis Max                 4.72833
trainer/Log Pis Min                -5.98544
trainer/Policy mu Mean              0.0944517
trainer/Policy mu Std               0.68133
trainer/Policy mu Max               3.15915
trainer/Policy mu Min              -2.96821
trainer/Policy log std Mean        -2.14783
trainer/Policy log std Std          0.449308
trainer/Policy log std Max         -0.544074
trainer/Policy log std Min         -2.43934
trainer/Alpha                       0.0551498
trainer/Alpha Loss                 -0.422427
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.327036
exploration/Rewards Std             0.974203
exploration/Rewards Max            -0.00552764
exploration/Rewards Min            -9.31077
exploration/Returns Mean          -32.7036
exploration/Returns Std            10.9422
exploration/Returns Max           -16.6327
exploration/Returns Min           -50.5744
exploration/Actions Mean           -0.0354147
exploration/Actions Std             0.242979
exploration/Actions Max             0.983727
exploration/Actions Min            -0.999894
exploration/Num Paths               5
exploration/Average Returns       -32.7036
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222012
evaluation/Rewards Std              0.989377
evaluation/Rewards Max             -0.0289758
evaluation/Rewards Min            -10.3539
evaluation/Returns Mean           -22.2012
evaluation/Returns Std             18.1002
evaluation/Returns Max             -4.54505
evaluation/Returns Min            -59.0613
evaluation/Actions Mean            -0.00338101
evaluation/Actions Std              0.180909
evaluation/Actions Max              0.997487
evaluation/Actions Min             -0.99744
evaluation/Num Paths               15
evaluation/Average Returns        -22.2012
time/data storing (s)               0.00366346
time/evaluation sampling (s)        0.358775
time/exploration sampling (s)       0.164602
time/logging (s)                    0.00495504
time/saving (s)                     0.00204108
time/training (s)                   2.18191
time/epoch (s)                      2.71595
time/total (s)                    387.15
Epoch                             143
-----------------------------  ---------------
2019-04-22 21:28:21.413949 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              72700
trainer/QF1 Loss                    0.859436
trainer/QF2 Loss                    0.853491
trainer/Policy Loss                 9.22331
trainer/Q1 Predictions Mean        -7.60561
trainer/Q1 Predictions Std          4.05498
trainer/Q1 Predictions Max         -6.18121
trainer/Q1 Predictions Min        -29.24
trainer/Q2 Predictions Mean        -7.62743
trainer/Q2 Predictions Std          4.0789
trainer/Q2 Predictions Max         -6.30617
trainer/Q2 Predictions Min        -29.4239
trainer/Q Targets Mean             -7.56289
trainer/Q Targets Std               4.17397
trainer/Q Targets Max              -0.164028
trainer/Q Targets Min             -29.2135
trainer/Log Pis Mean                1.6938
trainer/Log Pis Std                 1.39556
trainer/Log Pis Max                 7.28148
trainer/Log Pis Min                -3.41681
trainer/Policy mu Mean              0.0279618
trainer/Policy mu Std               0.560715
trainer/Policy mu Max               2.96091
trainer/Policy mu Min              -2.90139
trainer/Policy log std Mean        -2.16069
trainer/Policy log std Std          0.365548
trainer/Policy log std Max         -0.57974
trainer/Policy log std Min         -2.40221
trainer/Alpha                       0.0526454
trainer/Alpha Loss                 -0.901467
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.315041
exploration/Rewards Std             0.952562
exploration/Rewards Max            -0.0139545
exploration/Rewards Min           -10.4855
exploration/Returns Mean          -31.5041
exploration/Returns Std            17.88
exploration/Returns Max           -16.2187
exploration/Returns Min           -64.97
exploration/Actions Mean           -0.00427054
exploration/Actions Std             0.234018
exploration/Actions Max             0.994363
exploration/Actions Min            -0.999816
exploration/Num Paths               5
exploration/Average Returns       -31.5041
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.295055
evaluation/Rewards Std              1.00705
evaluation/Rewards Max             -0.0590551
evaluation/Rewards Min            -10.7925
evaluation/Returns Mean           -29.5055
evaluation/Returns Std             15.0355
evaluation/Returns Max            -13.2805
evaluation/Returns Min            -62.1484
evaluation/Actions Mean            -0.00870387
evaluation/Actions Std              0.204335
evaluation/Actions Max              0.997274
evaluation/Actions Min             -0.998253
evaluation/Num Paths               15
evaluation/Average Returns        -29.5055
time/data storing (s)               0.00317408
time/evaluation sampling (s)        0.367169
time/exploration sampling (s)       0.165154
time/logging (s)                    0.00368904
time/saving (s)                     0.00185164
time/training (s)                   2.1241
time/epoch (s)                      2.66514
time/total (s)                    389.82
Epoch                             144
-----------------------------  ---------------
2019-04-22 21:28:24.096948 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                    0.461542
trainer/QF2 Loss                    0.470798
trainer/Policy Loss                 9.47828
trainer/Q1 Predictions Mean        -7.65041
trainer/Q1 Predictions Std          3.8923
trainer/Q1 Predictions Max         -6.32757
trainer/Q1 Predictions Min        -30.863
trainer/Q2 Predictions Mean        -7.68196
trainer/Q2 Predictions Std          3.9488
trainer/Q2 Predictions Max         -6.34947
trainer/Q2 Predictions Min        -31.0745
trainer/Q Targets Mean             -7.61743
trainer/Q Targets Std               3.99564
trainer/Q Targets Max              -0.282642
trainer/Q Targets Min             -31.002
trainer/Log Pis Mean                1.99935
trainer/Log Pis Std                 1.32821
trainer/Log Pis Max                 7.15527
trainer/Log Pis Min                -2.05799
trainer/Policy mu Mean              0.0271414
trainer/Policy mu Std               0.604115
trainer/Policy mu Max               2.78566
trainer/Policy mu Min              -2.96243
trainer/Policy log std Mean        -2.18179
trainer/Policy log std Std          0.421622
trainer/Policy log std Max         -0.428372
trainer/Policy log std Min         -2.45376
trainer/Alpha                       0.0535245
trainer/Alpha Loss                 -0.00188821
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351788
exploration/Rewards Std             1.13765
exploration/Rewards Max            -0.00772436
exploration/Rewards Min           -10.655
exploration/Returns Mean          -35.1788
exploration/Returns Std            20.3022
exploration/Returns Max           -12.9722
exploration/Returns Min           -69.7739
exploration/Actions Mean            0.0095579
exploration/Actions Std             0.24077
exploration/Actions Max             0.995396
exploration/Actions Min            -0.998719
exploration/Num Paths               5
exploration/Average Returns       -35.1788
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.278755
evaluation/Rewards Std              1.1759
evaluation/Rewards Max             -0.0140605
evaluation/Rewards Min            -10.4867
evaluation/Returns Mean           -27.8755
evaluation/Returns Std             17.5714
evaluation/Returns Max             -5.20525
evaluation/Returns Min            -61.0898
evaluation/Actions Mean             0.0111978
evaluation/Actions Std              0.211683
evaluation/Actions Max              0.997601
evaluation/Actions Min             -0.998483
evaluation/Num Paths               15
evaluation/Average Returns        -27.8755
time/data storing (s)               0.00377215
time/evaluation sampling (s)        0.358171
time/exploration sampling (s)       0.167209
time/logging (s)                    0.00492338
time/saving (s)                     0.00204929
time/training (s)                   2.14027
time/epoch (s)                      2.6764
time/total (s)                    392.501
Epoch                             145
-----------------------------  ---------------
2019-04-22 21:28:26.708272 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              73700
trainer/QF1 Loss                    0.408492
trainer/QF2 Loss                    0.413178
trainer/Policy Loss                 8.75108
trainer/Q1 Predictions Mean        -7.1652
trainer/Q1 Predictions Std          2.7901
trainer/Q1 Predictions Max         -6.32926
trainer/Q1 Predictions Min        -31.9712
trainer/Q2 Predictions Mean        -7.17237
trainer/Q2 Predictions Std          2.80806
trainer/Q2 Predictions Max         -6.34762
trainer/Q2 Predictions Min        -32.2146
trainer/Q Targets Mean             -7.12143
trainer/Q Targets Std               2.86747
trainer/Q Targets Max              -0.255592
trainer/Q Targets Min             -32.0573
trainer/Log Pis Mean                1.66746
trainer/Log Pis Std                 1.3329
trainer/Log Pis Max                 4.84782
trainer/Log Pis Min                -5.1149
trainer/Policy mu Mean              0.0321153
trainer/Policy mu Std               0.461541
trainer/Policy mu Max               3.01651
trainer/Policy mu Min              -2.33681
trainer/Policy log std Mean        -2.20537
trainer/Policy log std Std          0.331219
trainer/Policy log std Max         -0.564158
trainer/Policy log std Min         -2.38979
trainer/Alpha                       0.0540514
trainer/Alpha Loss                 -0.970303
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396395
exploration/Rewards Std             1.16647
exploration/Rewards Max            -0.00535995
exploration/Rewards Min            -9.09743
exploration/Returns Mean          -39.6395
exploration/Returns Std            15.2904
exploration/Returns Max           -14.1823
exploration/Returns Min           -56.2771
exploration/Actions Mean           -0.0121959
exploration/Actions Std             0.250821
exploration/Actions Max             0.998906
exploration/Actions Min            -0.999579
exploration/Num Paths               5
exploration/Average Returns       -39.6395
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.201406
evaluation/Rewards Std              0.967519
evaluation/Rewards Max             -0.0151466
evaluation/Rewards Min             -9.44481
evaluation/Returns Mean           -20.1406
evaluation/Returns Std             18.2088
evaluation/Returns Max             -1.99952
evaluation/Returns Min            -50.6606
evaluation/Actions Mean            -0.00309151
evaluation/Actions Std              0.176259
evaluation/Actions Max              0.997376
evaluation/Actions Min             -0.998221
evaluation/Num Paths               15
evaluation/Average Returns        -20.1406
time/data storing (s)               0.00310132
time/evaluation sampling (s)        0.344577
time/exploration sampling (s)       0.157692
time/logging (s)                    0.00492894
time/saving (s)                     0.00213214
time/training (s)                   2.09144
time/epoch (s)                      2.60387
time/total (s)                    395.11
Epoch                             146
-----------------------------  ---------------
2019-04-22 21:28:29.388239 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              74200
trainer/QF1 Loss                    0.0241679
trainer/QF2 Loss                    0.0211931
trainer/Policy Loss                 9.69172
trainer/Q1 Predictions Mean        -7.85744
trainer/Q1 Predictions Std          5.80515
trainer/Q1 Predictions Max         -6.35821
trainer/Q1 Predictions Min        -54.3839
trainer/Q2 Predictions Mean        -7.83151
trainer/Q2 Predictions Std          5.83548
trainer/Q2 Predictions Max         -6.31118
trainer/Q2 Predictions Min        -54.4977
trainer/Q Targets Mean             -7.84038
trainer/Q Targets Std               5.7304
trainer/Q Targets Max              -6.32666
trainer/Q Targets Min             -53.5947
trainer/Log Pis Mean                1.9211
trainer/Log Pis Std                 1.11166
trainer/Log Pis Max                 5.6844
trainer/Log Pis Min                -1.56712
trainer/Policy mu Mean             -0.0353218
trainer/Policy mu Std               0.56033
trainer/Policy mu Max               2.96915
trainer/Policy mu Min              -2.9261
trainer/Policy log std Mean        -2.18668
trainer/Policy log std Std          0.385946
trainer/Policy log std Max         -0.51669
trainer/Policy log std Min         -2.42608
trainer/Alpha                       0.054044
trainer/Alpha Loss                 -0.230206
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.361513
exploration/Rewards Std             1.06057
exploration/Rewards Max            -0.00473297
exploration/Rewards Min            -9.22017
exploration/Returns Mean          -36.1513
exploration/Returns Std            16.4635
exploration/Returns Max           -15.3632
exploration/Returns Min           -59.8972
exploration/Actions Mean            0.00430742
exploration/Actions Std             0.231817
exploration/Actions Max             0.998427
exploration/Actions Min            -0.998309
exploration/Num Paths               5
exploration/Average Returns       -36.1513
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.317726
evaluation/Rewards Std              1.20108
evaluation/Rewards Max             -0.0264029
evaluation/Rewards Min            -10.6874
evaluation/Returns Mean           -31.7726
evaluation/Returns Std             20.4614
evaluation/Returns Max             -6.55339
evaluation/Returns Min            -63.8757
evaluation/Actions Mean             0.0120388
evaluation/Actions Std              0.199807
evaluation/Actions Max              0.997771
evaluation/Actions Min             -0.997801
evaluation/Num Paths               15
evaluation/Average Returns        -31.7726
time/data storing (s)               0.00332861
time/evaluation sampling (s)        0.349141
time/exploration sampling (s)       0.156871
time/logging (s)                    0.00498012
time/saving (s)                     0.0020084
time/training (s)                   2.15671
time/epoch (s)                      2.67304
time/total (s)                    397.788
Epoch                             147
-----------------------------  ---------------
2019-04-22 21:28:32.069844 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              74700
trainer/QF1 Loss                    0.849275
trainer/QF2 Loss                    0.859509
trainer/Policy Loss                 9.78469
trainer/Q1 Predictions Mean        -7.76142
trainer/Q1 Predictions Std          4.5427
trainer/Q1 Predictions Max         -6.2703
trainer/Q1 Predictions Min        -32.2059
trainer/Q2 Predictions Mean        -7.77844
trainer/Q2 Predictions Std          4.5557
trainer/Q2 Predictions Max         -6.32635
trainer/Q2 Predictions Min        -32.1713
trainer/Q Targets Mean             -7.66537
trainer/Q Targets Std               4.69312
trainer/Q Targets Max              -0.124343
trainer/Q Targets Min             -32.9452
trainer/Log Pis Mean                2.16831
trainer/Log Pis Std                 0.991051
trainer/Log Pis Max                 6.30766
trainer/Log Pis Min                -0.314057
trainer/Policy mu Mean             -0.0239155
trainer/Policy mu Std               0.601883
trainer/Policy mu Max               2.87206
trainer/Policy mu Min              -2.90977
trainer/Policy log std Mean        -2.18295
trainer/Policy log std Std          0.420936
trainer/Policy log std Max         -0.475606
trainer/Policy log std Min         -2.39273
trainer/Alpha                       0.0538388
trainer/Alpha Loss                  0.491791
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.382238
exploration/Rewards Std             1.19679
exploration/Rewards Max            -0.00767466
exploration/Rewards Min           -10.3221
exploration/Returns Mean          -38.2238
exploration/Returns Std            20.0952
exploration/Returns Max           -17.7655
exploration/Returns Min           -62.6135
exploration/Actions Mean            0.0152023
exploration/Actions Std             0.249888
exploration/Actions Max             0.999257
exploration/Actions Min            -0.998123
exploration/Num Paths               5
exploration/Average Returns       -38.2238
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224167
evaluation/Rewards Std              0.923942
evaluation/Rewards Max             -0.0157555
evaluation/Rewards Min             -8.50031
evaluation/Returns Mean           -22.4167
evaluation/Returns Std             12.6107
evaluation/Returns Max             -4.76813
evaluation/Returns Min            -45.3178
evaluation/Actions Mean            -0.00361648
evaluation/Actions Std              0.192384
evaluation/Actions Max              0.996394
evaluation/Actions Min             -0.99844
evaluation/Num Paths               15
evaluation/Average Returns        -22.4167
time/data storing (s)               0.00333034
time/evaluation sampling (s)        0.361717
time/exploration sampling (s)       0.16413
time/logging (s)                    0.0045882
time/saving (s)                     0.00207591
time/training (s)                   2.13747
time/epoch (s)                      2.67331
time/total (s)                    400.466
Epoch                             148
-----------------------------  ---------------
2019-04-22 21:28:34.699181 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                    0.589426
trainer/QF2 Loss                    0.604866
trainer/Policy Loss                 9.35513
trainer/Q1 Predictions Mean        -7.62936
trainer/Q1 Predictions Std          4.322
trainer/Q1 Predictions Max         -6.29991
trainer/Q1 Predictions Min        -40.1496
trainer/Q2 Predictions Mean        -7.60529
trainer/Q2 Predictions Std          4.3425
trainer/Q2 Predictions Max         -6.26473
trainer/Q2 Predictions Min        -40.3658
trainer/Q Targets Mean             -7.52028
trainer/Q Targets Std               4.11486
trainer/Q Targets Max              -0.118154
trainer/Q Targets Min             -36.5246
trainer/Log Pis Mean                2.00352
trainer/Log Pis Std                 1.13301
trainer/Log Pis Max                 6.24838
trainer/Log Pis Min                -0.752488
trainer/Policy mu Mean              0.0242726
trainer/Policy mu Std               0.589207
trainer/Policy mu Max               3.0471
trainer/Policy mu Min              -2.43758
trainer/Policy log std Mean        -2.16768
trainer/Policy log std Std          0.434449
trainer/Policy log std Max         -0.505956
trainer/Policy log std Min         -2.50891
trainer/Alpha                       0.0525715
trainer/Alpha Loss                  0.0103779
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.296947
exploration/Rewards Std             0.873892
exploration/Rewards Max            -0.00624715
exploration/Rewards Min            -9.22727
exploration/Returns Mean          -29.6947
exploration/Returns Std            13.7741
exploration/Returns Max           -17.0771
exploration/Returns Min           -55.2593
exploration/Actions Mean            0.0140907
exploration/Actions Std             0.225315
exploration/Actions Max             0.998941
exploration/Actions Min            -0.999351
exploration/Num Paths               5
exploration/Average Returns       -29.6947
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241856
evaluation/Rewards Std              1.01864
evaluation/Rewards Max             -0.0298008
evaluation/Rewards Min            -10.6583
evaluation/Returns Mean           -24.1856
evaluation/Returns Std             17.3625
evaluation/Returns Max             -5.47483
evaluation/Returns Min            -58.6307
evaluation/Actions Mean            -0.00469278
evaluation/Actions Std              0.193036
evaluation/Actions Max              0.995911
evaluation/Actions Min             -0.996906
evaluation/Num Paths               15
evaluation/Average Returns        -24.1856
time/data storing (s)               0.00345626
time/evaluation sampling (s)        0.355054
time/exploration sampling (s)       0.157976
time/logging (s)                    0.00509346
time/saving (s)                     0.00208352
time/training (s)                   2.09865
time/epoch (s)                      2.62231
time/total (s)                    403.093
Epoch                             149
-----------------------------  ---------------
2019-04-22 21:28:37.417957 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              75700
trainer/QF1 Loss                    1.25738
trainer/QF2 Loss                    1.23063
trainer/Policy Loss                10.0303
trainer/Q1 Predictions Mean        -7.85306
trainer/Q1 Predictions Std          4.96093
trainer/Q1 Predictions Max         -6.10324
trainer/Q1 Predictions Min        -41.7179
trainer/Q2 Predictions Mean        -7.87614
trainer/Q2 Predictions Std          4.98013
trainer/Q2 Predictions Max         -6.19918
trainer/Q2 Predictions Min        -41.942
trainer/Q Targets Mean             -7.81792
trainer/Q Targets Std               5.0456
trainer/Q Targets Max              -0.200696
trainer/Q Targets Min             -41.3808
trainer/Log Pis Mean                2.30339
trainer/Log Pis Std                 1.11107
trainer/Log Pis Max                 7.70256
trainer/Log Pis Min                -1.19738
trainer/Policy mu Mean              0.0833987
trainer/Policy mu Std               0.697219
trainer/Policy mu Max               2.99027
trainer/Policy mu Min              -2.63788
trainer/Policy log std Mean        -2.17505
trainer/Policy log std Std          0.489415
trainer/Policy log std Max         -0.468033
trainer/Policy log std Min         -2.54295
trainer/Alpha                       0.0527348
trainer/Alpha Loss                  0.892739
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.303992
exploration/Rewards Std             0.856696
exploration/Rewards Max            -0.00777225
exploration/Rewards Min            -7.76027
exploration/Returns Mean          -30.3992
exploration/Returns Std             9.25277
exploration/Returns Max           -17.8059
exploration/Returns Min           -43.6478
exploration/Actions Mean           -0.00594223
exploration/Actions Std             0.231559
exploration/Actions Max             0.998162
exploration/Actions Min            -0.99829
exploration/Num Paths               5
exploration/Average Returns       -30.3992
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.278896
evaluation/Rewards Std              1.11514
evaluation/Rewards Max             -0.00957909
evaluation/Rewards Min            -11.5226
evaluation/Returns Mean           -27.8896
evaluation/Returns Std             16.6599
evaluation/Returns Max             -2.80502
evaluation/Returns Min            -69.821
evaluation/Actions Mean             0.00131244
evaluation/Actions Std              0.205718
evaluation/Actions Max              0.99848
evaluation/Actions Min             -0.996955
evaluation/Num Paths               15
evaluation/Average Returns        -27.8896
time/data storing (s)               0.00323198
time/evaluation sampling (s)        0.411839
time/exploration sampling (s)       0.164582
time/logging (s)                    0.00504372
time/saving (s)                     0.0020071
time/training (s)                   2.12526
time/epoch (s)                      2.71196
time/total (s)                    405.809
Epoch                             150
-----------------------------  ---------------
2019-04-22 21:28:40.094300 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 151 finished
-----------------------------  ----------------
replay_buffer/size              76200
trainer/QF1 Loss                    0.462957
trainer/QF2 Loss                    0.455839
trainer/Policy Loss                 9.30377
trainer/Q1 Predictions Mean        -7.41785
trainer/Q1 Predictions Std          5.83725
trainer/Q1 Predictions Max         -6.22195
trainer/Q1 Predictions Min        -61.9339
trainer/Q2 Predictions Mean        -7.43833
trainer/Q2 Predictions Std          5.88538
trainer/Q2 Predictions Max         -6.24411
trainer/Q2 Predictions Min        -62.3007
trainer/Q Targets Mean             -7.48234
trainer/Q Targets Std               5.99283
trainer/Q Targets Max              -0.118154
trainer/Q Targets Min             -63.1623
trainer/Log Pis Mean                1.89879
trainer/Log Pis Std                 1.52602
trainer/Log Pis Max                10.7325
trainer/Log Pis Min                -1.36779
trainer/Policy mu Mean             -0.0409198
trainer/Policy mu Std               0.577797
trainer/Policy mu Max               3.4505
trainer/Policy mu Min              -3.32564
trainer/Policy log std Mean        -2.17252
trainer/Policy log std Std          0.352939
trainer/Policy log std Max         -0.399934
trainer/Policy log std Min         -2.51905
trainer/Alpha                       0.0539181
trainer/Alpha Loss                 -0.295553
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.305961
exploration/Rewards Std             0.850845
exploration/Rewards Max            -0.0135301
exploration/Rewards Min            -7.68063
exploration/Returns Mean          -30.5961
exploration/Returns Std            10.9127
exploration/Returns Max           -18.8286
exploration/Returns Min           -48.6517
exploration/Actions Mean            0.000897164
exploration/Actions Std             0.245303
exploration/Actions Max             0.998759
exploration/Actions Min            -0.99623
exploration/Num Paths               5
exploration/Average Returns       -30.5961
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231723
evaluation/Rewards Std              0.901452
evaluation/Rewards Max             -0.0154511
evaluation/Rewards Min            -10.6716
evaluation/Returns Mean           -23.1723
evaluation/Returns Std             15.8491
evaluation/Returns Max             -8.00153
evaluation/Returns Min            -63.4886
evaluation/Actions Mean            -0.00680338
evaluation/Actions Std              0.187849
evaluation/Actions Max              0.998037
evaluation/Actions Min             -0.998825
evaluation/Num Paths               15
evaluation/Average Returns        -23.1723
time/data storing (s)               0.00317789
time/evaluation sampling (s)        0.366565
time/exploration sampling (s)       0.163897
time/logging (s)                    0.0049149
time/saving (s)                     0.00202243
time/training (s)                   2.12843
time/epoch (s)                      2.66901
time/total (s)                    408.482
Epoch                             151
-----------------------------  ----------------
2019-04-22 21:28:42.824895 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              76700
trainer/QF1 Loss                    0.833687
trainer/QF2 Loss                    0.832706
trainer/Policy Loss                 8.79048
trainer/Q1 Predictions Mean        -7.04066
trainer/Q1 Predictions Std          3.10005
trainer/Q1 Predictions Max         -6.24812
trainer/Q1 Predictions Min        -35.6026
trainer/Q2 Predictions Mean        -7.00646
trainer/Q2 Predictions Std          3.08609
trainer/Q2 Predictions Max         -6.21479
trainer/Q2 Predictions Min        -35.3444
trainer/Q Targets Mean             -6.97701
trainer/Q Targets Std               3.25911
trainer/Q Targets Max              -0.12921
trainer/Q Targets Min             -35.6103
trainer/Log Pis Mean                1.85094
trainer/Log Pis Std                 1.1389
trainer/Log Pis Max                 7.19321
trainer/Log Pis Min                -1.92925
trainer/Policy mu Mean              0.0413689
trainer/Policy mu Std               0.458446
trainer/Policy mu Max               2.9128
trainer/Policy mu Min              -2.81312
trainer/Policy log std Mean        -2.2103
trainer/Policy log std Std          0.310516
trainer/Policy log std Max         -0.473034
trainer/Policy log std Min         -2.43762
trainer/Alpha                       0.0534611
trainer/Alpha Loss                 -0.436543
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.414902
exploration/Rewards Std             1.22667
exploration/Rewards Max            -0.00107528
exploration/Rewards Min           -10.8484
exploration/Returns Mean          -41.4902
exploration/Returns Std            14.0136
exploration/Returns Max           -29.3143
exploration/Returns Min           -68.6667
exploration/Actions Mean           -0.0231833
exploration/Actions Std             0.274034
exploration/Actions Max             0.997407
exploration/Actions Min            -0.99919
exploration/Num Paths               5
exploration/Average Returns       -41.4902
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.2912
evaluation/Rewards Std              1.17323
evaluation/Rewards Max             -0.00441649
evaluation/Rewards Min            -10.4362
evaluation/Returns Mean           -29.12
evaluation/Returns Std             16.223
evaluation/Returns Max             -9.51391
evaluation/Returns Min            -56.7528
evaluation/Actions Mean             0.00796335
evaluation/Actions Std              0.211664
evaluation/Actions Max              0.997148
evaluation/Actions Min             -0.99676
evaluation/Num Paths               15
evaluation/Average Returns        -29.12
time/data storing (s)               0.00313262
time/evaluation sampling (s)        0.358557
time/exploration sampling (s)       0.163573
time/logging (s)                    0.00492692
time/saving (s)                     0.00215301
time/training (s)                   2.19091
time/epoch (s)                      2.72325
time/total (s)                    411.21
Epoch                             152
-----------------------------  ---------------
2019-04-22 21:28:45.512325 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              77200
trainer/QF1 Loss                    0.0410893
trainer/QF2 Loss                    0.0168452
trainer/Policy Loss                10.6131
trainer/Q1 Predictions Mean        -8.77431
trainer/Q1 Predictions Std          9.15837
trainer/Q1 Predictions Max         -6.2457
trainer/Q1 Predictions Min        -66.4291
trainer/Q2 Predictions Mean        -8.74738
trainer/Q2 Predictions Std          9.14089
trainer/Q2 Predictions Max         -6.21757
trainer/Q2 Predictions Min        -66.9379
trainer/Q Targets Mean             -8.79042
trainer/Q Targets Std               9.12337
trainer/Q Targets Max              -6.20959
trainer/Q Targets Min             -67.3972
trainer/Log Pis Mean                2.17247
trainer/Log Pis Std                 1.31077
trainer/Log Pis Max                 8.12138
trainer/Log Pis Min                -1.7069
trainer/Policy mu Mean              0.0568942
trainer/Policy mu Std               0.691289
trainer/Policy mu Max               3.22101
trainer/Policy mu Min              -3.23401
trainer/Policy log std Mean        -2.17917
trainer/Policy log std Std          0.482603
trainer/Policy log std Max         -0.554149
trainer/Policy log std Min         -2.5099
trainer/Alpha                       0.0545745
trainer/Alpha Loss                  0.501602
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.322433
exploration/Rewards Std             1.03741
exploration/Rewards Max            -0.00338869
exploration/Rewards Min           -10.3261
exploration/Returns Mean          -32.2433
exploration/Returns Std            20.458
exploration/Returns Max           -13.7129
exploration/Returns Min           -69.7145
exploration/Actions Mean            0.0120474
exploration/Actions Std             0.231058
exploration/Actions Max             0.998881
exploration/Actions Min            -0.990674
exploration/Num Paths               5
exploration/Average Returns       -32.2433
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.309936
evaluation/Rewards Std              1.0872
evaluation/Rewards Max             -0.0507299
evaluation/Rewards Min             -9.50876
evaluation/Returns Mean           -30.9936
evaluation/Returns Std             10.4188
evaluation/Returns Max            -13.0337
evaluation/Returns Min            -49.0243
evaluation/Actions Mean             0.012627
evaluation/Actions Std              0.213186
evaluation/Actions Max              0.997266
evaluation/Actions Min             -0.997153
evaluation/Num Paths               15
evaluation/Average Returns        -30.9936
time/data storing (s)               0.00381516
time/evaluation sampling (s)        0.362985
time/exploration sampling (s)       0.171197
time/logging (s)                    0.00455619
time/saving (s)                     0.00207217
time/training (s)                   2.13482
time/epoch (s)                      2.67945
time/total (s)                    413.894
Epoch                             153
-----------------------------  ---------------
2019-04-22 21:28:48.244054 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 154 finished
-----------------------------  ----------------
replay_buffer/size              77700
trainer/QF1 Loss                    0.43186
trainer/QF2 Loss                    0.417962
trainer/Policy Loss                 9.96914
trainer/Q1 Predictions Mean        -8.01383
trainer/Q1 Predictions Std          6.53619
trainer/Q1 Predictions Max         -6.28051
trainer/Q1 Predictions Min        -52.613
trainer/Q2 Predictions Mean        -7.99324
trainer/Q2 Predictions Std          6.51728
trainer/Q2 Predictions Max         -6.24503
trainer/Q2 Predictions Min        -52.4104
trainer/Q Targets Mean             -7.97319
trainer/Q Targets Std               6.45757
trainer/Q Targets Max              -0.0293843
trainer/Q Targets Min             -51.5993
trainer/Log Pis Mean                2.11191
trainer/Log Pis Std                 1.42514
trainer/Log Pis Max                 6.37696
trainer/Log Pis Min                -3.6242
trainer/Policy mu Mean             -0.00334524
trainer/Policy mu Std               0.725707
trainer/Policy mu Max               3.16768
trainer/Policy mu Min              -3.1993
trainer/Policy log std Mean        -2.1628
trainer/Policy log std Std          0.493715
trainer/Policy log std Max         -0.463169
trainer/Policy log std Min         -2.47823
trainer/Alpha                       0.0547731
trainer/Alpha Loss                  0.325043
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.263616
exploration/Rewards Std             0.79096
exploration/Rewards Max            -0.00509361
exploration/Rewards Min            -9.26207
exploration/Returns Mean          -26.3616
exploration/Returns Std            14.7077
exploration/Returns Max           -14.4173
exploration/Returns Min           -53.9967
exploration/Actions Mean           -0.00449436
exploration/Actions Std             0.211579
exploration/Actions Max             0.98735
exploration/Actions Min            -0.997567
exploration/Num Paths               5
exploration/Average Returns       -26.3616
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.255955
evaluation/Rewards Std              0.972671
evaluation/Rewards Max             -0.0257117
evaluation/Rewards Min             -9.37331
evaluation/Returns Mean           -25.5955
evaluation/Returns Std             15.887
evaluation/Returns Max             -5.62129
evaluation/Returns Min            -53.4004
evaluation/Actions Mean            -0.000451864
evaluation/Actions Std              0.184894
evaluation/Actions Max              0.997275
evaluation/Actions Min             -0.998445
evaluation/Num Paths               15
evaluation/Average Returns        -25.5955
time/data storing (s)               0.00325067
time/evaluation sampling (s)        0.363264
time/exploration sampling (s)       0.165072
time/logging (s)                    0.00509809
time/saving (s)                     0.00217771
time/training (s)                   2.18575
time/epoch (s)                      2.72461
time/total (s)                    416.624
Epoch                             154
-----------------------------  ----------------
2019-04-22 21:28:50.937897 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 155 finished
-----------------------------  ---------------
replay_buffer/size              78200
trainer/QF1 Loss                    0.414129
trainer/QF2 Loss                    0.40414
trainer/Policy Loss                 9.59792
trainer/Q1 Predictions Mean        -7.56998
trainer/Q1 Predictions Std          4.08817
trainer/Q1 Predictions Max         -6.1026
trainer/Q1 Predictions Min        -33.9311
trainer/Q2 Predictions Mean        -7.60937
trainer/Q2 Predictions Std          4.11644
trainer/Q2 Predictions Max         -6.14405
trainer/Q2 Predictions Min        -34.143
trainer/Q Targets Mean             -7.60989
trainer/Q Targets Std               4.12727
trainer/Q Targets Max              -0.0670399
trainer/Q Targets Min             -33.4853
trainer/Log Pis Mean                2.11389
trainer/Log Pis Std                 1.16496
trainer/Log Pis Max                 7.34312
trainer/Log Pis Min                -1.34855
trainer/Policy mu Mean              0.0116593
trainer/Policy mu Std               0.66481
trainer/Policy mu Max               2.83337
trainer/Policy mu Min              -3.05142
trainer/Policy log std Mean        -2.12183
trainer/Policy log std Std          0.449268
trainer/Policy log std Max         -0.294205
trainer/Policy log std Min         -2.40758
trainer/Alpha                       0.0548626
trainer/Alpha Loss                  0.330598
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.279823
exploration/Rewards Std             0.850852
exploration/Rewards Max            -0.00481664
exploration/Rewards Min            -8.71578
exploration/Returns Mean          -27.9823
exploration/Returns Std            12.2984
exploration/Returns Max           -13.2531
exploration/Returns Min           -45.4897
exploration/Actions Mean           -0.00024525
exploration/Actions Std             0.228454
exploration/Actions Max             0.999366
exploration/Actions Min            -0.997891
exploration/Num Paths               5
exploration/Average Returns       -27.9823
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.227128
evaluation/Rewards Std              0.943827
evaluation/Rewards Max             -0.0245649
evaluation/Rewards Min            -10.4356
evaluation/Returns Mean           -22.7128
evaluation/Returns Std             15.0734
evaluation/Returns Max             -4.83878
evaluation/Returns Min            -62.6245
evaluation/Actions Mean            -0.00794231
evaluation/Actions Std              0.197423
evaluation/Actions Max              0.997425
evaluation/Actions Min             -0.998678
evaluation/Num Paths               15
evaluation/Average Returns        -22.7128
time/data storing (s)               0.00319876
time/evaluation sampling (s)        0.359427
time/exploration sampling (s)       0.158548
time/logging (s)                    0.00501435
time/saving (s)                     0.00747517
time/training (s)                   2.15249
time/epoch (s)                      2.68615
time/total (s)                    419.314
Epoch                             155
-----------------------------  ---------------
2019-04-22 21:28:53.629570 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              78700
trainer/QF1 Loss                    0.0612237
trainer/QF2 Loss                    0.0720286
trainer/Policy Loss                 9.0872
trainer/Q1 Predictions Mean        -7.10477
trainer/Q1 Predictions Std          2.72685
trainer/Q1 Predictions Max         -6.20567
trainer/Q1 Predictions Min        -27.2656
trainer/Q2 Predictions Mean        -7.09347
trainer/Q2 Predictions Std          2.72722
trainer/Q2 Predictions Max         -6.19976
trainer/Q2 Predictions Min        -27.0109
trainer/Q Targets Mean             -7.20181
trainer/Q Targets Std               2.91139
trainer/Q Targets Max              -6.25514
trainer/Q Targets Min             -29.3434
trainer/Log Pis Mean                2.16328
trainer/Log Pis Std                 0.928291
trainer/Log Pis Max                 4.85495
trainer/Log Pis Min                -0.882903
trainer/Policy mu Mean             -0.0191026
trainer/Policy mu Std               0.526424
trainer/Policy mu Max               2.97944
trainer/Policy mu Min              -2.50887
trainer/Policy log std Mean        -2.2573
trainer/Policy log std Std          0.385759
trainer/Policy log std Max         -0.511803
trainer/Policy log std Min         -2.47083
trainer/Alpha                       0.0524847
trainer/Alpha Loss                  0.481301
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.252893
exploration/Rewards Std             0.718165
exploration/Rewards Max            -0.0068406
exploration/Rewards Min            -7.46578
exploration/Returns Mean          -25.2893
exploration/Returns Std             8.0408
exploration/Returns Max           -14.6842
exploration/Returns Min           -39.5263
exploration/Actions Mean            0.0182449
exploration/Actions Std             0.215222
exploration/Actions Max             0.998737
exploration/Actions Min            -0.998802
exploration/Num Paths               5
exploration/Average Returns       -25.2893
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282974
evaluation/Rewards Std              1.10805
evaluation/Rewards Max             -0.0116449
evaluation/Rewards Min            -10.6921
evaluation/Returns Mean           -28.2974
evaluation/Returns Std             17.0588
evaluation/Returns Max             -6.64341
evaluation/Returns Min            -56.5921
evaluation/Actions Mean             0.00154971
evaluation/Actions Std              0.205449
evaluation/Actions Max              0.998086
evaluation/Actions Min             -0.99844
evaluation/Num Paths               15
evaluation/Average Returns        -28.2974
time/data storing (s)               0.00318194
time/evaluation sampling (s)        0.357904
time/exploration sampling (s)       0.161527
time/logging (s)                    0.00493388
time/saving (s)                     0.0019483
time/training (s)                   2.154
time/epoch (s)                      2.6835
time/total (s)                    422.003
Epoch                             156
-----------------------------  ---------------
2019-04-22 21:28:56.293550 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 157 finished
-----------------------------  ----------------
replay_buffer/size              79200
trainer/QF1 Loss                    1.37865
trainer/QF2 Loss                    1.38626
trainer/Policy Loss                 8.73495
trainer/Q1 Predictions Mean        -6.91219
trainer/Q1 Predictions Std          2.09811
trainer/Q1 Predictions Max         -6.07698
trainer/Q1 Predictions Min        -21.772
trainer/Q2 Predictions Mean        -6.9043
trainer/Q2 Predictions Std          2.12219
trainer/Q2 Predictions Max         -6.05431
trainer/Q2 Predictions Min        -21.7508
trainer/Q Targets Mean             -6.78406
trainer/Q Targets Std               2.37063
trainer/Q Targets Max              -0.0292206
trainer/Q Targets Min             -21.6998
trainer/Log Pis Mean                1.9784
trainer/Log Pis Std                 0.994238
trainer/Log Pis Max                 5.3206
trainer/Log Pis Min                -1.3911
trainer/Policy mu Mean              0.0188452
trainer/Policy mu Std               0.420803
trainer/Policy mu Max               2.81458
trainer/Policy mu Min              -2.51817
trainer/Policy log std Mean        -2.28458
trainer/Policy log std Std          0.315712
trainer/Policy log std Max         -0.615244
trainer/Policy log std Min         -2.51878
trainer/Alpha                       0.055942
trainer/Alpha Loss                 -0.0622864
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.391019
exploration/Rewards Std             1.30868
exploration/Rewards Max            -0.00384799
exploration/Rewards Min           -10.9755
exploration/Returns Mean          -39.1019
exploration/Returns Std            24.4111
exploration/Returns Max           -11.6529
exploration/Returns Min           -70.2876
exploration/Actions Mean           -0.00739962
exploration/Actions Std             0.246528
exploration/Actions Max             0.99897
exploration/Actions Min            -0.999646
exploration/Num Paths               5
exploration/Average Returns       -39.1019
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.206619
evaluation/Rewards Std              0.97518
evaluation/Rewards Max             -0.00504875
evaluation/Rewards Min             -9.90384
evaluation/Returns Mean           -20.6619
evaluation/Returns Std             18.6115
evaluation/Returns Max             -2.88371
evaluation/Returns Min            -57.1721
evaluation/Actions Mean             7.71074e-05
evaluation/Actions Std              0.182897
evaluation/Actions Max              0.997275
evaluation/Actions Min             -0.995208
evaluation/Num Paths               15
evaluation/Average Returns        -20.6619
time/data storing (s)               0.00305203
time/evaluation sampling (s)        0.367627
time/exploration sampling (s)       0.161521
time/logging (s)                    0.00483654
time/saving (s)                     0.00199764
time/training (s)                   2.11818
time/epoch (s)                      2.65722
time/total (s)                    424.664
Epoch                             157
-----------------------------  ----------------
2019-04-22 21:28:58.979052 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              79700
trainer/QF1 Loss                    0.856799
trainer/QF2 Loss                    0.935817
trainer/Policy Loss                 9.68786
trainer/Q1 Predictions Mean        -7.86027
trainer/Q1 Predictions Std          6.9002
trainer/Q1 Predictions Max         -6.21436
trainer/Q1 Predictions Min        -69.9849
trainer/Q2 Predictions Mean        -7.79619
trainer/Q2 Predictions Std          6.73546
trainer/Q2 Predictions Max         -6.11709
trainer/Q2 Predictions Min        -68.136
trainer/Q Targets Mean             -7.76419
trainer/Q Targets Std               7.07644
trainer/Q Targets Max              -0.0632296
trainer/Q Targets Min             -71.3974
trainer/Log Pis Mean                2.0578
trainer/Log Pis Std                 1.24001
trainer/Log Pis Max                 6.39854
trainer/Log Pis Min                -2.32362
trainer/Policy mu Mean              0.0656689
trainer/Policy mu Std               0.660763
trainer/Policy mu Max               3.52923
trainer/Policy mu Min              -2.75266
trainer/Policy log std Mean        -2.16126
trainer/Policy log std Std          0.454205
trainer/Policy log std Max         -0.524485
trainer/Policy log std Min         -2.53704
trainer/Alpha                       0.0563079
trainer/Alpha Loss                  0.166293
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.255055
exploration/Rewards Std             0.780661
exploration/Rewards Max            -0.00293393
exploration/Rewards Min            -8.07858
exploration/Returns Mean          -25.5055
exploration/Returns Std            12.4887
exploration/Returns Max           -12.7
exploration/Returns Min           -46.497
exploration/Actions Mean           -0.0229989
exploration/Actions Std             0.217716
exploration/Actions Max             0.960017
exploration/Actions Min            -0.999816
exploration/Num Paths               5
exploration/Average Returns       -25.5055
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.242499
evaluation/Rewards Std              1.02996
evaluation/Rewards Max             -0.0178485
evaluation/Rewards Min            -10.3234
evaluation/Returns Mean           -24.2499
evaluation/Returns Std             14.8367
evaluation/Returns Max             -2.721
evaluation/Returns Min            -55.7513
evaluation/Actions Mean             0.0135767
evaluation/Actions Std              0.202116
evaluation/Actions Max              0.997504
evaluation/Actions Min             -0.996604
evaluation/Num Paths               15
evaluation/Average Returns        -24.2499
time/data storing (s)               0.00312501
time/evaluation sampling (s)        0.350844
time/exploration sampling (s)       0.158237
time/logging (s)                    0.00606643
time/saving (s)                     0.00215012
time/training (s)                   2.15996
time/epoch (s)                      2.68038
time/total (s)                    427.349
Epoch                             158
-----------------------------  ---------------
2019-04-22 21:29:01.647991 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    0.435428
trainer/QF2 Loss                    0.431235
trainer/Policy Loss                 9.19603
trainer/Q1 Predictions Mean        -7.4172
trainer/Q1 Predictions Std          4.33994
trainer/Q1 Predictions Max         -6.38171
trainer/Q1 Predictions Min        -41.6819
trainer/Q2 Predictions Mean        -7.40036
trainer/Q2 Predictions Std          4.3695
trainer/Q2 Predictions Max         -6.36519
trainer/Q2 Predictions Min        -42.0277
trainer/Q Targets Mean             -7.37901
trainer/Q Targets Std               4.4455
trainer/Q Targets Max              -0.127968
trainer/Q Targets Min             -42.095
trainer/Log Pis Mean                1.88184
trainer/Log Pis Std                 1.30807
trainer/Log Pis Max                 5.95488
trainer/Log Pis Min                -3.83063
trainer/Policy mu Mean              0.00261918
trainer/Policy mu Std               0.562104
trainer/Policy mu Max               3.10727
trainer/Policy mu Min              -3.21446
trainer/Policy log std Mean        -2.14647
trainer/Policy log std Std          0.390148
trainer/Policy log std Max         -0.500946
trainer/Policy log std Min         -2.41975
trainer/Alpha                       0.056242
trainer/Alpha Loss                 -0.340053
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.267153
exploration/Rewards Std             0.740017
exploration/Rewards Max            -0.00648608
exploration/Rewards Min            -7.44241
exploration/Returns Mean          -26.7153
exploration/Returns Std             9.98973
exploration/Returns Max           -14.7273
exploration/Returns Min           -44.5029
exploration/Actions Mean            0.0130976
exploration/Actions Std             0.230471
exploration/Actions Max             0.999524
exploration/Actions Min            -0.999588
exploration/Num Paths               5
exploration/Average Returns       -26.7153
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.149902
evaluation/Rewards Std              0.796844
evaluation/Rewards Max             -0.00640262
evaluation/Rewards Min             -9.77144
evaluation/Returns Mean           -14.9902
evaluation/Returns Std             13.5454
evaluation/Returns Max             -1.59839
evaluation/Returns Min            -49.6789
evaluation/Actions Mean            -0.00153526
evaluation/Actions Std              0.177698
evaluation/Actions Max              0.997081
evaluation/Actions Min             -0.995934
evaluation/Num Paths               15
evaluation/Average Returns        -14.9902
time/data storing (s)               0.0039324
time/evaluation sampling (s)        0.364823
time/exploration sampling (s)       0.163252
time/logging (s)                    0.00486488
time/saving (s)                     0.00205989
time/training (s)                   2.11764
time/epoch (s)                      2.65657
time/total (s)                    430.013
Epoch                             159
-----------------------------  ---------------
2019-04-22 21:29:04.315666 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              80700
trainer/QF1 Loss                    0.838784
trainer/QF2 Loss                    0.832733
trainer/Policy Loss                 9.80176
trainer/Q1 Predictions Mean        -7.81302
trainer/Q1 Predictions Std          6.73537
trainer/Q1 Predictions Max         -6.35572
trainer/Q1 Predictions Min        -57.9556
trainer/Q2 Predictions Mean        -7.7945
trainer/Q2 Predictions Std          6.682
trainer/Q2 Predictions Max         -6.32984
trainer/Q2 Predictions Min        -57.4726
trainer/Q Targets Mean             -7.71388
trainer/Q Targets Std               6.70845
trainer/Q Targets Max              -0.0935939
trainer/Q Targets Min             -56.8961
trainer/Log Pis Mean                2.04618
trainer/Log Pis Std                 1.37402
trainer/Log Pis Max                 8.9092
trainer/Log Pis Min                -0.52819
trainer/Policy mu Mean              8.6168e-05
trainer/Policy mu Std               0.575341
trainer/Policy mu Max               3.14378
trainer/Policy mu Min              -3.47252
trainer/Policy log std Mean        -2.2422
trainer/Policy log std Std          0.355656
trainer/Policy log std Max         -0.587749
trainer/Policy log std Min         -2.4723
trainer/Alpha                       0.0538367
trainer/Alpha Loss                  0.13493
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.292044
exploration/Rewards Std             0.952212
exploration/Rewards Max            -0.00624927
exploration/Rewards Min           -10.4296
exploration/Returns Mean          -29.2044
exploration/Returns Std            17.4556
exploration/Returns Max           -16.7833
exploration/Returns Min           -63.3565
exploration/Actions Mean            0.0188176
exploration/Actions Std             0.222887
exploration/Actions Max             0.999619
exploration/Actions Min            -0.999077
exploration/Num Paths               5
exploration/Average Returns       -29.2044
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.280947
evaluation/Rewards Std              1.17841
evaluation/Rewards Max             -0.0232551
evaluation/Rewards Min            -10.5762
evaluation/Returns Mean           -28.0947
evaluation/Returns Std             18.4876
evaluation/Returns Max             -3.37208
evaluation/Returns Min            -61.866
evaluation/Actions Mean            -0.00601302
evaluation/Actions Std              0.205546
evaluation/Actions Max              0.998125
evaluation/Actions Min             -0.997303
evaluation/Num Paths               15
evaluation/Average Returns        -28.0947
time/data storing (s)               0.00319474
time/evaluation sampling (s)        0.361498
time/exploration sampling (s)       0.165118
time/logging (s)                    0.00493387
time/saving (s)                     0.00210286
time/training (s)                   2.12331
time/epoch (s)                      2.66016
time/total (s)                    432.678
Epoch                             160
-----------------------------  ---------------
2019-04-22 21:29:06.987571 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              81200
trainer/QF1 Loss                    0.0450715
trainer/QF2 Loss                    0.0422394
trainer/Policy Loss                 9.98019
trainer/Q1 Predictions Mean        -8.16157
trainer/Q1 Predictions Std          7.50975
trainer/Q1 Predictions Max         -6.38291
trainer/Q1 Predictions Min        -64.8421
trainer/Q2 Predictions Mean        -8.12666
trainer/Q2 Predictions Std          7.5256
trainer/Q2 Predictions Max         -6.29172
trainer/Q2 Predictions Min        -65.0091
trainer/Q Targets Mean             -8.23604
trainer/Q Targets Std               7.63878
trainer/Q Targets Max              -6.33074
trainer/Q Targets Min             -66.082
trainer/Log Pis Mean                2.08854
trainer/Log Pis Std                 1.176
trainer/Log Pis Max                 8.07974
trainer/Log Pis Min                -0.56911
trainer/Policy mu Mean              0.00184862
trainer/Policy mu Std               0.648441
trainer/Policy mu Max               3.24491
trainer/Policy mu Min              -3.1281
trainer/Policy log std Mean        -2.18148
trainer/Policy log std Std          0.46575
trainer/Policy log std Max         -0.331096
trainer/Policy log std Min         -2.44491
trainer/Alpha                       0.05314
trainer/Alpha Loss                  0.259871
exploration/num steps total     81200
exploration/num paths total       812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.402542
exploration/Rewards Std             1.19357
exploration/Rewards Max            -0.00421855
exploration/Rewards Min            -9.27442
exploration/Returns Mean          -40.2542
exploration/Returns Std            12.3467
exploration/Returns Max           -18.471
exploration/Returns Min           -53.4543
exploration/Actions Mean           -0.025493
exploration/Actions Std             0.257251
exploration/Actions Max             0.995652
exploration/Actions Min            -0.99967
exploration/Num Paths               5
exploration/Average Returns       -40.2542
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.235995
evaluation/Rewards Std              0.864988
evaluation/Rewards Max             -0.0266611
evaluation/Rewards Min             -9.99945
evaluation/Returns Mean           -23.5995
evaluation/Returns Std             16.6076
evaluation/Returns Max             -8.01964
evaluation/Returns Min            -65.9747
evaluation/Actions Mean             0.00590303
evaluation/Actions Std              0.180287
evaluation/Actions Max              0.996953
evaluation/Actions Min             -0.99506
evaluation/Num Paths               15
evaluation/Average Returns        -23.5995
time/data storing (s)               0.00330059
time/evaluation sampling (s)        0.351959
time/exploration sampling (s)       0.154535
time/logging (s)                    0.00488268
time/saving (s)                     0.00200557
time/training (s)                   2.14754
time/epoch (s)                      2.66422
time/total (s)                    435.347
Epoch                             161
-----------------------------  ---------------
2019-04-22 21:29:09.599784 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              81700
trainer/QF1 Loss                    0.0637925
trainer/QF2 Loss                    0.07239
trainer/Policy Loss                 8.96035
trainer/Q1 Predictions Mean        -7.14389
trainer/Q1 Predictions Std          2.73702
trainer/Q1 Predictions Max         -6.2489
trainer/Q1 Predictions Min        -28.8175
trainer/Q2 Predictions Mean        -7.11815
trainer/Q2 Predictions Std          2.74652
trainer/Q2 Predictions Max         -6.18135
trainer/Q2 Predictions Min        -28.8424
trainer/Q Targets Mean             -7.24641
trainer/Q Targets Std               2.87534
trainer/Q Targets Max              -6.29195
trainer/Q Targets Min             -30.944
trainer/Log Pis Mean                1.99636
trainer/Log Pis Std                 1.20125
trainer/Log Pis Max                 7.32064
trainer/Log Pis Min                -2.91202
trainer/Policy mu Mean              0.00487091
trainer/Policy mu Std               0.610277
trainer/Policy mu Max               2.81706
trainer/Policy mu Min              -3.57975
trainer/Policy log std Mean        -2.14236
trainer/Policy log std Std          0.421062
trainer/Policy log std Max         -0.478031
trainer/Policy log std Min         -2.46071
trainer/Alpha                       0.0542189
trainer/Alpha Loss                 -0.0106233
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.348791
exploration/Rewards Std             1.0862
exploration/Rewards Max            -0.00598399
exploration/Rewards Min            -9.39777
exploration/Returns Mean          -34.8791
exploration/Returns Std            16.8571
exploration/Returns Max           -14.8016
exploration/Returns Min           -55.9049
exploration/Actions Mean            0.00227047
exploration/Actions Std             0.243875
exploration/Actions Max             0.999499
exploration/Actions Min            -0.998485
exploration/Num Paths               5
exploration/Average Returns       -34.8791
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.222969
evaluation/Rewards Std              0.9851
evaluation/Rewards Max             -0.0104037
evaluation/Rewards Min            -10.0606
evaluation/Returns Mean           -22.2969
evaluation/Returns Std             14.2063
evaluation/Returns Max             -2.32961
evaluation/Returns Min            -51.1578
evaluation/Actions Mean             0.00693684
evaluation/Actions Std              0.195484
evaluation/Actions Max              0.998153
evaluation/Actions Min             -0.998773
evaluation/Num Paths               15
evaluation/Average Returns        -22.2969
time/data storing (s)               0.00316476
time/evaluation sampling (s)        0.349416
time/exploration sampling (s)       0.158038
time/logging (s)                    0.00518599
time/saving (s)                     0.0019972
time/training (s)                   2.08712
time/epoch (s)                      2.60492
time/total (s)                    437.957
Epoch                             162
-----------------------------  ---------------
2019-04-22 21:29:12.325869 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              82200
trainer/QF1 Loss                    1.17282
trainer/QF2 Loss                    1.20841
trainer/Policy Loss                 8.35798
trainer/Q1 Predictions Mean        -6.71282
trainer/Q1 Predictions Std          0.962676
trainer/Q1 Predictions Max         -6.23129
trainer/Q1 Predictions Min        -13.9156
trainer/Q2 Predictions Mean        -6.745
trainer/Q2 Predictions Std          0.944248
trainer/Q2 Predictions Max         -6.33284
trainer/Q2 Predictions Min        -13.9448
trainer/Q Targets Mean             -6.56294
trainer/Q Targets Std               1.46583
trainer/Q Targets Max              -0.0489725
trainer/Q Targets Min             -13.8304
trainer/Log Pis Mean                1.76051
trainer/Log Pis Std                 1.25464
trainer/Log Pis Max                 3.02455
trainer/Log Pis Min                -3.3683
trainer/Policy mu Mean              0.00714651
trainer/Policy mu Std               0.312789
trainer/Policy mu Max               2.38852
trainer/Policy mu Min              -1.04868
trainer/Policy log std Mean        -2.33187
trainer/Policy log std Std          0.223802
trainer/Policy log std Max         -0.782248
trainer/Policy log std Min         -2.53509
trainer/Alpha                       0.0562338
trainer/Alpha Loss                 -0.689303
exploration/num steps total     82200
exploration/num paths total       822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.291229
exploration/Rewards Std             0.894408
exploration/Rewards Max            -0.00561308
exploration/Rewards Min            -8.30528
exploration/Returns Mean          -29.1229
exploration/Returns Std            12.0455
exploration/Returns Max           -13.5287
exploration/Returns Min           -49.978
exploration/Actions Mean            0.00859545
exploration/Actions Std             0.229648
exploration/Actions Max             0.995115
exploration/Actions Min            -0.999306
exploration/Num Paths               5
exploration/Average Returns       -29.1229
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.235908
evaluation/Rewards Std              1.05485
evaluation/Rewards Max             -0.00353015
evaluation/Rewards Min            -10.4298
evaluation/Returns Mean           -23.5908
evaluation/Returns Std             18.9045
evaluation/Returns Max             -3.97659
evaluation/Returns Min            -63.184
evaluation/Actions Mean             0.00563803
evaluation/Actions Std              0.199793
evaluation/Actions Max              0.998195
evaluation/Actions Min             -0.995864
evaluation/Num Paths               15
evaluation/Average Returns        -23.5908
time/data storing (s)               0.00318715
time/evaluation sampling (s)        0.351116
time/exploration sampling (s)       0.166814
time/logging (s)                    0.00485216
time/saving (s)                     0.0107372
time/training (s)                   2.18162
time/epoch (s)                      2.71832
time/total (s)                    440.68
Epoch                             163
-----------------------------  ---------------
2019-04-22 21:29:14.995310 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 164 finished
-----------------------------  ----------------
replay_buffer/size              82700
trainer/QF1 Loss                    0.0233061
trainer/QF2 Loss                    0.0208981
trainer/Policy Loss                 8.55228
trainer/Q1 Predictions Mean        -6.63359
trainer/Q1 Predictions Std          1.03374
trainer/Q1 Predictions Max         -6.25493
trainer/Q1 Predictions Min        -15.9102
trainer/Q2 Predictions Mean        -6.64685
trainer/Q2 Predictions Std          1.04523
trainer/Q2 Predictions Max         -6.27376
trainer/Q2 Predictions Min        -16.02
trainer/Q Targets Mean             -6.73433
trainer/Q Targets Std               1.11171
trainer/Q Targets Max              -6.31853
trainer/Q Targets Min             -16.8338
trainer/Log Pis Mean                1.95648
trainer/Log Pis Std                 0.862289
trainer/Log Pis Max                 3.44776
trainer/Log Pis Min                -1.58431
trainer/Policy mu Mean              0.0126171
trainer/Policy mu Std               0.368607
trainer/Policy mu Max               2.68087
trainer/Policy mu Min              -2.61868
trainer/Policy log std Mean        -2.28243
trainer/Policy log std Std          0.315099
trainer/Policy log std Max         -0.525319
trainer/Policy log std Min         -2.57222
trainer/Alpha                       0.0553449
trainer/Alpha Loss                 -0.12596
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.209407
exploration/Rewards Std             0.620609
exploration/Rewards Max            -0.000826486
exploration/Rewards Min            -7.705
exploration/Returns Mean          -20.9407
exploration/Returns Std            12.5363
exploration/Returns Max           -12.5402
exploration/Returns Min           -45.7188
exploration/Actions Mean           -0.00429405
exploration/Actions Std             0.184114
exploration/Actions Max             0.987516
exploration/Actions Min            -0.997506
exploration/Num Paths               5
exploration/Average Returns       -20.9407
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274519
evaluation/Rewards Std              1.07343
evaluation/Rewards Max             -0.0311003
evaluation/Rewards Min            -10.5437
evaluation/Returns Mean           -27.4519
evaluation/Returns Std             17.1912
evaluation/Returns Max             -8.3534
evaluation/Returns Min            -59.537
evaluation/Actions Mean             0.00115753
evaluation/Actions Std              0.19932
evaluation/Actions Max              0.996854
evaluation/Actions Min             -0.998312
evaluation/Num Paths               15
evaluation/Average Returns        -27.4519
time/data storing (s)               0.00330182
time/evaluation sampling (s)        0.357569
time/exploration sampling (s)       0.157435
time/logging (s)                    0.00510221
time/saving (s)                     0.00199733
time/training (s)                   2.13648
time/epoch (s)                      2.66189
time/total (s)                    443.346
Epoch                             164
-----------------------------  ----------------
2019-04-22 21:29:17.661519 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              83200
trainer/QF1 Loss                    0.0239073
trainer/QF2 Loss                    0.0167649
trainer/Policy Loss                 9.00026
trainer/Q1 Predictions Mean        -7.03023
trainer/Q1 Predictions Std          3.58943
trainer/Q1 Predictions Max         -6.25352
trainer/Q1 Predictions Min        -41.7935
trainer/Q2 Predictions Mean        -7.06885
trainer/Q2 Predictions Std          3.57474
trainer/Q2 Predictions Max         -6.35721
trainer/Q2 Predictions Min        -41.6516
trainer/Q Targets Mean             -7.09515
trainer/Q Targets Std               3.57186
trainer/Q Targets Max              -6.29361
trainer/Q Targets Min             -41.5658
trainer/Log Pis Mean                2.04575
trainer/Log Pis Std                 1.06394
trainer/Log Pis Max                 5.59652
trainer/Log Pis Min                -2.27643
trainer/Policy mu Mean             -0.015978
trainer/Policy mu Std               0.442756
trainer/Policy mu Max               3.02411
trainer/Policy mu Min              -2.83568
trainer/Policy log std Mean        -2.25141
trainer/Policy log std Std          0.316658
trainer/Policy log std Max         -0.443395
trainer/Policy log std Min         -2.45195
trainer/Alpha                       0.0533057
trainer/Alpha Loss                  0.134118
exploration/num steps total     83200
exploration/num paths total       832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.379332
exploration/Rewards Std             1.13704
exploration/Rewards Max            -0.00735248
exploration/Rewards Min           -10.0627
exploration/Returns Mean          -37.9332
exploration/Returns Std            16.2858
exploration/Returns Max           -16.666
exploration/Returns Min           -66.4608
exploration/Actions Mean           -0.0200906
exploration/Actions Std             0.249842
exploration/Actions Max             0.998841
exploration/Actions Min            -0.998794
exploration/Num Paths               5
exploration/Average Returns       -37.9332
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.259437
evaluation/Rewards Std              1.00648
evaluation/Rewards Max             -0.0208649
evaluation/Rewards Min            -10.2444
evaluation/Returns Mean           -25.9437
evaluation/Returns Std             18.3976
evaluation/Returns Max             -7.20407
evaluation/Returns Min            -60.0998
evaluation/Actions Mean             0.0141332
evaluation/Actions Std              0.190497
evaluation/Actions Max              0.997558
evaluation/Actions Min             -0.995584
evaluation/Num Paths               15
evaluation/Average Returns        -25.9437
time/data storing (s)               0.00331918
time/evaluation sampling (s)        0.346909
time/exploration sampling (s)       0.159552
time/logging (s)                    0.00485745
time/saving (s)                     0.00757634
time/training (s)                   2.136
time/epoch (s)                      2.65821
time/total (s)                    446.009
Epoch                             165
-----------------------------  ---------------
2019-04-22 21:29:20.278248 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 166 finished
-----------------------------  ----------------
replay_buffer/size              83700
trainer/QF1 Loss                    0.434466
trainer/QF2 Loss                    0.41554
trainer/Policy Loss                 9.20274
trainer/Q1 Predictions Mean        -7.40909
trainer/Q1 Predictions Std          4.21993
trainer/Q1 Predictions Max         -6.34722
trainer/Q1 Predictions Min        -44.4249
trainer/Q2 Predictions Mean        -7.39096
trainer/Q2 Predictions Std          4.20852
trainer/Q2 Predictions Max         -6.30878
trainer/Q2 Predictions Min        -44.3505
trainer/Q Targets Mean             -7.37266
trainer/Q Targets Std               4.19079
trainer/Q Targets Max              -0.249189
trainer/Q Targets Min             -43.7972
trainer/Log Pis Mean                1.86085
trainer/Log Pis Std                 1.12329
trainer/Log Pis Max                 6.3599
trainer/Log Pis Min                -1.7864
trainer/Policy mu Mean             -0.0428116
trainer/Policy mu Std               0.607156
trainer/Policy mu Max               2.72073
trainer/Policy mu Min              -3.19446
trainer/Policy log std Mean        -2.11937
trainer/Policy log std Std          0.432279
trainer/Policy log std Max         -0.450877
trainer/Policy log std Min         -2.41504
trainer/Alpha                       0.0524149
trainer/Alpha Loss                 -0.410269
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.539632
exploration/Rewards Std             1.62511
exploration/Rewards Max            -0.00904373
exploration/Rewards Min           -10.9347
exploration/Returns Mean          -53.9632
exploration/Returns Std            21.3688
exploration/Returns Max           -14.568
exploration/Returns Min           -71.4196
exploration/Actions Mean           -0.016141
exploration/Actions Std             0.283972
exploration/Actions Max             0.999549
exploration/Actions Min            -0.9996
exploration/Num Paths               5
exploration/Average Returns       -53.9632
evaluation/num steps total     250500
evaluation/num paths total       2505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.186789
evaluation/Rewards Std              0.834074
evaluation/Rewards Max             -0.00338566
evaluation/Rewards Min            -10.1937
evaluation/Returns Mean           -18.6789
evaluation/Returns Std             12.4309
evaluation/Returns Max             -6.27434
evaluation/Returns Min            -58.4969
evaluation/Actions Mean             0.000629412
evaluation/Actions Std              0.192161
evaluation/Actions Max              0.997052
evaluation/Actions Min             -0.998846
evaluation/Num Paths               15
evaluation/Average Returns        -18.6789
time/data storing (s)               0.00351404
time/evaluation sampling (s)        0.353112
time/exploration sampling (s)       0.159772
time/logging (s)                    0.00522096
time/saving (s)                     0.00191536
time/training (s)                   2.08619
time/epoch (s)                      2.60972
time/total (s)                    448.623
Epoch                             166
-----------------------------  ----------------
2019-04-22 21:29:22.959561 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              84200
trainer/QF1 Loss                    0.817286
trainer/QF2 Loss                    0.818817
trainer/Policy Loss                 9.8291
trainer/Q1 Predictions Mean        -7.72549
trainer/Q1 Predictions Std          5.07667
trainer/Q1 Predictions Max         -6.34955
trainer/Q1 Predictions Min        -42.4195
trainer/Q2 Predictions Mean        -7.71395
trainer/Q2 Predictions Std          5.03817
trainer/Q2 Predictions Max         -6.3465
trainer/Q2 Predictions Min        -42.2702
trainer/Q Targets Mean             -7.63207
trainer/Q Targets Std               5.13643
trainer/Q Targets Max              -0.0270793
trainer/Q Targets Min             -42.0408
trainer/Log Pis Mean                2.23689
trainer/Log Pis Std                 1.32303
trainer/Log Pis Max                 7.16411
trainer/Log Pis Min                -3.1408
trainer/Policy mu Mean              0.0406681
trainer/Policy mu Std               0.653257
trainer/Policy mu Max               2.84745
trainer/Policy mu Min              -3.04909
trainer/Policy log std Mean        -2.22437
trainer/Policy log std Std          0.470058
trainer/Policy log std Max         -0.377452
trainer/Policy log std Min         -2.55769
trainer/Alpha                       0.0543402
trainer/Alpha Loss                  0.689995
exploration/num steps total     84200
exploration/num paths total       842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.278717
exploration/Rewards Std             0.812632
exploration/Rewards Max            -0.00144336
exploration/Rewards Min            -6.86574
exploration/Returns Mean          -27.8717
exploration/Returns Std             8.60043
exploration/Returns Max           -13.0112
exploration/Returns Min           -35.931
exploration/Actions Mean            0.0113429
exploration/Actions Std             0.23066
exploration/Actions Max             0.998733
exploration/Actions Min            -0.999101
exploration/Num Paths               5
exploration/Average Returns       -27.8717
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241134
evaluation/Rewards Std              0.982902
evaluation/Rewards Max             -0.0291354
evaluation/Rewards Min            -10.8022
evaluation/Returns Mean           -24.1134
evaluation/Returns Std             14.554
evaluation/Returns Max             -5.07494
evaluation/Returns Min            -59.1694
evaluation/Actions Mean            -0.0185104
evaluation/Actions Std              0.207378
evaluation/Actions Max              0.994643
evaluation/Actions Min             -0.997022
evaluation/Num Paths               15
evaluation/Average Returns        -24.1134
time/data storing (s)               0.00329817
time/evaluation sampling (s)        0.352812
time/exploration sampling (s)       0.160191
time/logging (s)                    0.0058015
time/saving (s)                     0.00219807
time/training (s)                   2.15003
time/epoch (s)                      2.67433
time/total (s)                    451.302
Epoch                             167
-----------------------------  ---------------
2019-04-22 21:29:25.634555 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 168 finished
-----------------------------  ----------------
replay_buffer/size              84700
trainer/QF1 Loss                    0.140568
trainer/QF2 Loss                    0.188148
trainer/Policy Loss                 9.71313
trainer/Q1 Predictions Mean        -7.87908
trainer/Q1 Predictions Std          7.97019
trainer/Q1 Predictions Max         -6.26623
trainer/Q1 Predictions Min        -78.7789
trainer/Q2 Predictions Mean        -7.91256
trainer/Q2 Predictions Std          8.01472
trainer/Q2 Predictions Max         -6.27032
trainer/Q2 Predictions Min        -79.5614
trainer/Q Targets Mean             -7.95754
trainer/Q Targets Std               7.63013
trainer/Q Targets Max              -6.33234
trainer/Q Targets Min             -75.4589
trainer/Log Pis Mean                2.00828
trainer/Log Pis Std                 1.17504
trainer/Log Pis Max                 6.79116
trainer/Log Pis Min                -2.79393
trainer/Policy mu Mean             -0.00944647
trainer/Policy mu Std               0.576825
trainer/Policy mu Max               2.97817
trainer/Policy mu Min              -3.12612
trainer/Policy log std Mean        -2.25118
trainer/Policy log std Std          0.375681
trainer/Policy log std Max         -0.619287
trainer/Policy log std Min         -2.51484
trainer/Alpha                       0.0554417
trainer/Alpha Loss                  0.0239492
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.410644
exploration/Rewards Std             1.23667
exploration/Rewards Max            -0.0069147
exploration/Rewards Min           -10.4122
exploration/Returns Mean          -41.0644
exploration/Returns Std            14.243
exploration/Returns Max           -24.3661
exploration/Returns Min           -61.0865
exploration/Actions Mean           -0.029228
exploration/Actions Std             0.253556
exploration/Actions Max             0.994446
exploration/Actions Min            -0.99982
exploration/Num Paths               5
exploration/Average Returns       -41.0644
evaluation/num steps total     253500
evaluation/num paths total       2535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225762
evaluation/Rewards Std              0.922382
evaluation/Rewards Max             -0.030568
evaluation/Rewards Min            -10.0504
evaluation/Returns Mean           -22.5762
evaluation/Returns Std             14.7675
evaluation/Returns Max             -8.72861
evaluation/Returns Min            -59.8084
evaluation/Actions Mean            -0.000430668
evaluation/Actions Std              0.195119
evaluation/Actions Max              0.997747
evaluation/Actions Min             -0.998388
evaluation/Num Paths               15
evaluation/Average Returns        -22.5762
time/data storing (s)               0.00351123
time/evaluation sampling (s)        0.3686
time/exploration sampling (s)       0.172717
time/logging (s)                    0.00513751
time/saving (s)                     0.0020089
time/training (s)                   2.11475
time/epoch (s)                      2.66672
time/total (s)                    453.974
Epoch                             168
-----------------------------  ----------------
2019-04-22 21:29:28.293988 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              85200
trainer/QF1 Loss                    0.0109258
trainer/QF2 Loss                    0.0164558
trainer/Policy Loss                 9.4744
trainer/Q1 Predictions Mean        -7.66596
trainer/Q1 Predictions Std          5.84425
trainer/Q1 Predictions Max         -6.3582
trainer/Q1 Predictions Min        -50.9056
trainer/Q2 Predictions Mean        -7.6059
trainer/Q2 Predictions Std          5.86218
trainer/Q2 Predictions Max         -6.36089
trainer/Q2 Predictions Min        -51.3802
trainer/Q Targets Mean             -7.67297
trainer/Q Targets Std               5.82191
trainer/Q Targets Max              -6.36348
trainer/Q Targets Min             -50.7397
trainer/Log Pis Mean                1.90647
trainer/Log Pis Std                 1.07131
trainer/Log Pis Max                 5.08502
trainer/Log Pis Min                -2.60232
trainer/Policy mu Mean             -0.0270367
trainer/Policy mu Std               0.56422
trainer/Policy mu Max               3.19389
trainer/Policy mu Min              -3.1631
trainer/Policy log std Mean        -2.17221
trainer/Policy log std Std          0.407849
trainer/Policy log std Max         -0.402069
trainer/Policy log std Min         -2.52384
trainer/Alpha                       0.0545814
trainer/Alpha Loss                 -0.271967
exploration/num steps total     85200
exploration/num paths total       852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.301784
exploration/Rewards Std             0.948569
exploration/Rewards Max            -0.00319472
exploration/Rewards Min            -9.74891
exploration/Returns Mean          -30.1784
exploration/Returns Std            14.3132
exploration/Returns Max           -13.6533
exploration/Returns Min           -54.078
exploration/Actions Mean           -0.0230074
exploration/Actions Std             0.243272
exploration/Actions Max             0.995861
exploration/Actions Min            -0.99981
exploration/Num Paths               5
exploration/Average Returns       -30.1784
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.237605
evaluation/Rewards Std              1.0393
evaluation/Rewards Max             -0.0137053
evaluation/Rewards Min             -9.65632
evaluation/Returns Mean           -23.7605
evaluation/Returns Std             15.0917
evaluation/Returns Max             -3.26912
evaluation/Returns Min            -52.6531
evaluation/Actions Mean             0.0021599
evaluation/Actions Std              0.198448
evaluation/Actions Max              0.996272
evaluation/Actions Min             -0.998427
evaluation/Num Paths               15
evaluation/Average Returns        -23.7605
time/data storing (s)               0.00312182
time/evaluation sampling (s)        0.359363
time/exploration sampling (s)       0.163879
time/logging (s)                    0.00433169
time/saving (s)                     0.00204016
time/training (s)                   2.11899
time/epoch (s)                      2.65172
time/total (s)                    456.629
Epoch                             169
-----------------------------  ---------------
2019-04-22 21:29:31.003435 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              85700
trainer/QF1 Loss                    0.813504
trainer/QF2 Loss                    0.812373
trainer/Policy Loss                 9.44282
trainer/Q1 Predictions Mean        -7.91211
trainer/Q1 Predictions Std          6.80403
trainer/Q1 Predictions Max         -6.28134
trainer/Q1 Predictions Min        -65.6062
trainer/Q2 Predictions Mean        -7.90663
trainer/Q2 Predictions Std          6.77635
trainer/Q2 Predictions Max         -6.31072
trainer/Q2 Predictions Min        -65.5005
trainer/Q Targets Mean             -7.92407
trainer/Q Targets Std               6.92575
trainer/Q Targets Max              -0.202943
trainer/Q Targets Min             -66.07
trainer/Log Pis Mean                1.81297
trainer/Log Pis Std                 1.56865
trainer/Log Pis Max                 8.01354
trainer/Log Pis Min                -5.07683
trainer/Policy mu Mean             -0.0256265
trainer/Policy mu Std               0.700501
trainer/Policy mu Max               2.71032
trainer/Policy mu Min              -3.30795
trainer/Policy log std Mean        -2.16764
trainer/Policy log std Std          0.492247
trainer/Policy log std Max         -0.586687
trainer/Policy log std Min         -2.61141
trainer/Alpha                       0.0531837
trainer/Alpha Loss                 -0.548752
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.224944
exploration/Rewards Std             0.616959
exploration/Rewards Max            -0.0084679
exploration/Rewards Min            -6.48306
exploration/Returns Mean          -22.4944
exploration/Returns Std             8.4057
exploration/Returns Max           -13.4684
exploration/Returns Min           -36.186
exploration/Actions Mean            0.0164733
exploration/Actions Std             0.218223
exploration/Actions Max             0.998881
exploration/Actions Min            -0.995771
exploration/Num Paths               5
exploration/Average Returns       -22.4944
evaluation/num steps total     256500
evaluation/num paths total       2565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22534
evaluation/Rewards Std              1.06754
evaluation/Rewards Max             -0.00378973
evaluation/Rewards Min            -10.8465
evaluation/Returns Mean           -22.534
evaluation/Returns Std             18.9521
evaluation/Returns Max             -0.784876
evaluation/Returns Min            -61.3119
evaluation/Actions Mean             0.00835225
evaluation/Actions Std              0.195164
evaluation/Actions Max              0.997368
evaluation/Actions Min             -0.998036
evaluation/Num Paths               15
evaluation/Average Returns        -22.534
time/data storing (s)               0.00398572
time/evaluation sampling (s)        0.355306
time/exploration sampling (s)       0.167469
time/logging (s)                    0.00490695
time/saving (s)                     0.00203517
time/training (s)                   2.16946
time/epoch (s)                      2.70316
time/total (s)                    459.337
Epoch                             170
-----------------------------  ---------------
2019-04-22 21:29:33.629568 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              86200
trainer/QF1 Loss                    0.00976764
trainer/QF2 Loss                    0.00945717
trainer/Policy Loss                 9.64082
trainer/Q1 Predictions Mean        -7.76278
trainer/Q1 Predictions Std          5.36149
trainer/Q1 Predictions Max         -6.33533
trainer/Q1 Predictions Min        -40.1549
trainer/Q2 Predictions Mean        -7.802
trainer/Q2 Predictions Std          5.38511
trainer/Q2 Predictions Max         -6.39717
trainer/Q2 Predictions Min        -40.7072
trainer/Q Targets Mean             -7.81186
trainer/Q Targets Std               5.36191
trainer/Q Targets Max              -6.36052
trainer/Q Targets Min             -40.2832
trainer/Log Pis Mean                1.86683
trainer/Log Pis Std                 1.46311
trainer/Log Pis Max                 6.71321
trainer/Log Pis Min                -5.00609
trainer/Policy mu Mean             -0.034728
trainer/Policy mu Std               0.640702
trainer/Policy mu Max               2.99827
trainer/Policy mu Min              -2.93846
trainer/Policy log std Mean        -2.16013
trainer/Policy log std Std          0.447053
trainer/Policy log std Max         -0.527366
trainer/Policy log std Min         -2.46304
trainer/Alpha                       0.0539821
trainer/Alpha Loss                 -0.388721
exploration/num steps total     86200
exploration/num paths total       862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.462554
exploration/Rewards Std             1.37901
exploration/Rewards Max            -0.00407809
exploration/Rewards Min           -10.8113
exploration/Returns Mean          -46.2554
exploration/Returns Std            20.6868
exploration/Returns Max           -20.2018
exploration/Returns Min           -72.0332
exploration/Actions Mean           -0.0113563
exploration/Actions Std             0.269489
exploration/Actions Max             0.999639
exploration/Actions Min            -0.998382
exploration/Num Paths               5
exploration/Average Returns       -46.2554
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.230233
evaluation/Rewards Std              0.863457
evaluation/Rewards Max             -0.0278648
evaluation/Rewards Min            -11.0109
evaluation/Returns Mean           -23.0233
evaluation/Returns Std             14.3782
evaluation/Returns Max             -4.56249
evaluation/Returns Min            -67.0001
evaluation/Actions Mean            -0.00406704
evaluation/Actions Std              0.186869
evaluation/Actions Max              0.998191
evaluation/Actions Min             -0.998412
evaluation/Num Paths               15
evaluation/Average Returns        -23.0233
time/data storing (s)               0.003048
time/evaluation sampling (s)        0.355296
time/exploration sampling (s)       0.155715
time/logging (s)                    0.00513293
time/saving (s)                     0.00210486
time/training (s)                   2.09829
time/epoch (s)                      2.61959
time/total (s)                    461.96
Epoch                             171
-----------------------------  ---------------
2019-04-22 21:29:36.303732 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                    0.0387932
trainer/QF2 Loss                    0.1053
trainer/Policy Loss                10.4712
trainer/Q1 Predictions Mean        -8.5812
trainer/Q1 Predictions Std          9.36862
trainer/Q1 Predictions Max         -6.43864
trainer/Q1 Predictions Min        -74.8716
trainer/Q2 Predictions Mean        -8.5329
trainer/Q2 Predictions Std          9.45352
trainer/Q2 Predictions Max         -6.33136
trainer/Q2 Predictions Min        -76.2695
trainer/Q Targets Mean             -8.54996
trainer/Q Targets Std               9.20115
trainer/Q Targets Max              -6.36543
trainer/Q Targets Min             -73.205
trainer/Log Pis Mean                2.10773
trainer/Log Pis Std                 1.31974
trainer/Log Pis Max                 8.56422
trainer/Log Pis Min                -0.993716
trainer/Policy mu Mean             -0.0343628
trainer/Policy mu Std               0.711121
trainer/Policy mu Max               3.37166
trainer/Policy mu Min              -3.26973
trainer/Policy log std Mean        -2.18407
trainer/Policy log std Std          0.462133
trainer/Policy log std Max         -0.380456
trainer/Policy log std Min         -2.54089
trainer/Alpha                       0.0537528
trainer/Alpha Loss                  0.31494
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.274885
exploration/Rewards Std             0.835949
exploration/Rewards Max            -0.00914761
exploration/Rewards Min            -8.59915
exploration/Returns Mean          -27.4885
exploration/Returns Std            11.8667
exploration/Returns Max           -13.0545
exploration/Returns Min           -47.9714
exploration/Actions Mean           -0.036696
exploration/Actions Std             0.231461
exploration/Actions Max             0.981728
exploration/Actions Min            -0.999079
exploration/Num Paths               5
exploration/Average Returns       -27.4885
evaluation/num steps total     259500
evaluation/num paths total       2595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.2382
evaluation/Rewards Std              0.994874
evaluation/Rewards Max             -0.0169595
evaluation/Rewards Min            -10.0565
evaluation/Returns Mean           -23.82
evaluation/Returns Std             12.4426
evaluation/Returns Max             -9.59713
evaluation/Returns Min            -54.1994
evaluation/Actions Mean             0.00892768
evaluation/Actions Std              0.206445
evaluation/Actions Max              0.997695
evaluation/Actions Min             -0.995044
evaluation/Num Paths               15
evaluation/Average Returns        -23.82
time/data storing (s)               0.00309752
time/evaluation sampling (s)        0.34311
time/exploration sampling (s)       0.157422
time/logging (s)                    0.00511328
time/saving (s)                     0.00235044
time/training (s)                   2.15569
time/epoch (s)                      2.66678
time/total (s)                    464.631
Epoch                             172
-----------------------------  ---------------
2019-04-22 21:29:38.964962 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              87200
trainer/QF1 Loss                    0.477653
trainer/QF2 Loss                    0.463941
trainer/Policy Loss                10.1703
trainer/Q1 Predictions Mean        -8.22159
trainer/Q1 Predictions Std          6.72656
trainer/Q1 Predictions Max         -6.20752
trainer/Q1 Predictions Min        -43.5842
trainer/Q2 Predictions Mean        -8.25058
trainer/Q2 Predictions Std          6.70454
trainer/Q2 Predictions Max         -6.27128
trainer/Q2 Predictions Min        -42.8867
trainer/Q Targets Mean             -8.33085
trainer/Q Targets Std               6.86511
trainer/Q Targets Max              -0.205413
trainer/Q Targets Min             -43.7535
trainer/Log Pis Mean                1.9632
trainer/Log Pis Std                 1.28645
trainer/Log Pis Max                 6.25691
trainer/Log Pis Min                -2.25134
trainer/Policy mu Mean              0.00475554
trainer/Policy mu Std               0.725064
trainer/Policy mu Max               2.95877
trainer/Policy mu Min              -3.13919
trainer/Policy log std Mean        -2.0969
trainer/Policy log std Std          0.441897
trainer/Policy log std Max         -0.457113
trainer/Policy log std Min         -2.44623
trainer/Alpha                       0.0542943
trainer/Alpha Loss                 -0.107217
exploration/num steps total     87200
exploration/num paths total       872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.450593
exploration/Rewards Std             1.32396
exploration/Rewards Max            -0.00486821
exploration/Rewards Min            -9.4111
exploration/Returns Mean          -45.0593
exploration/Returns Std            16.1173
exploration/Returns Max           -15.424
exploration/Returns Min           -63.8758
exploration/Actions Mean           -0.0181975
exploration/Actions Std             0.2637
exploration/Actions Max             0.997876
exploration/Actions Min            -0.998297
exploration/Num Paths               5
exploration/Average Returns       -45.0593
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.230956
evaluation/Rewards Std              1.00845
evaluation/Rewards Max             -0.0310169
evaluation/Rewards Min            -11.0742
evaluation/Returns Mean           -23.0956
evaluation/Returns Std             17.921
evaluation/Returns Max             -4.50872
evaluation/Returns Min            -62.4467
evaluation/Actions Mean             0.00077059
evaluation/Actions Std              0.200684
evaluation/Actions Max              0.997702
evaluation/Actions Min             -0.998068
evaluation/Num Paths               15
evaluation/Average Returns        -23.0956
time/data storing (s)               0.00312473
time/evaluation sampling (s)        0.355113
time/exploration sampling (s)       0.157081
time/logging (s)                    0.00464322
time/saving (s)                     0.00213249
time/training (s)                   2.13092
time/epoch (s)                      2.65301
time/total (s)                    467.289
Epoch                             173
-----------------------------  ---------------
2019-04-22 21:29:41.662284 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              87700
trainer/QF1 Loss                    0.424691
trainer/QF2 Loss                    0.427114
trainer/Policy Loss                 8.71603
trainer/Q1 Predictions Mean        -7.05987
trainer/Q1 Predictions Std          2.33907
trainer/Q1 Predictions Max         -6.40264
trainer/Q1 Predictions Min        -24.4617
trainer/Q2 Predictions Mean        -7.05382
trainer/Q2 Predictions Std          2.35877
trainer/Q2 Predictions Max         -6.40655
trainer/Q2 Predictions Min        -24.6837
trainer/Q Targets Mean             -6.99254
trainer/Q Targets Std               2.4167
trainer/Q Targets Max              -0.0431479
trainer/Q Targets Min             -24.2599
trainer/Log Pis Mean                1.6651
trainer/Log Pis Std                 1.24722
trainer/Log Pis Max                 3.90566
trainer/Log Pis Min                -3.65856
trainer/Policy mu Mean             -0.0126151
trainer/Policy mu Std               0.480199
trainer/Policy mu Max               2.83488
trainer/Policy mu Min              -2.92777
trainer/Policy log std Mean        -2.23933
trainer/Policy log std Std          0.359478
trainer/Policy log std Max         -0.598979
trainer/Policy log std Min         -2.44973
trainer/Alpha                       0.0549309
trainer/Alpha Loss                 -0.971755
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.29728
exploration/Rewards Std             0.875036
exploration/Rewards Max            -0.00667687
exploration/Rewards Min            -8.2321
exploration/Returns Mean          -29.728
exploration/Returns Std            12.0254
exploration/Returns Max           -11.8743
exploration/Returns Min           -49.6237
exploration/Actions Mean            0.012154
exploration/Actions Std             0.228127
exploration/Actions Max             0.998954
exploration/Actions Min            -0.998141
exploration/Num Paths               5
exploration/Average Returns       -29.728
evaluation/num steps total     262500
evaluation/num paths total       2625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.196904
evaluation/Rewards Std              0.864324
evaluation/Rewards Max             -0.019855
evaluation/Rewards Min             -9.09347
evaluation/Returns Mean           -19.6904
evaluation/Returns Std             11.7688
evaluation/Returns Max             -4.98113
evaluation/Returns Min            -44.0959
evaluation/Actions Mean             0.0200139
evaluation/Actions Std              0.192331
evaluation/Actions Max              0.9971
evaluation/Actions Min             -0.998568
evaluation/Num Paths               15
evaluation/Average Returns        -19.6904
time/data storing (s)               0.0031422
time/evaluation sampling (s)        0.345806
time/exploration sampling (s)       0.159473
time/logging (s)                    0.00577112
time/saving (s)                     0.00208243
time/training (s)                   2.17495
time/epoch (s)                      2.69122
time/total (s)                    469.984
Epoch                             174
-----------------------------  ---------------
2019-04-22 21:29:44.338108 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              88200
trainer/QF1 Loss                    0.431613
trainer/QF2 Loss                    0.433189
trainer/Policy Loss                 8.64472
trainer/Q1 Predictions Mean        -6.87927
trainer/Q1 Predictions Std          1.64543
trainer/Q1 Predictions Max         -6.34857
trainer/Q1 Predictions Min        -17.4595
trainer/Q2 Predictions Mean        -6.86271
trainer/Q2 Predictions Std          1.65263
trainer/Q2 Predictions Max         -6.33502
trainer/Q2 Predictions Min        -17.5016
trainer/Q Targets Mean             -6.84694
trainer/Q Targets Std               1.85589
trainer/Q Targets Max              -0.154523
trainer/Q Targets Min             -18.0775
trainer/Log Pis Mean                1.81517
trainer/Log Pis Std                 1.27985
trainer/Log Pis Max                 5.89624
trainer/Log Pis Min                -5.63323
trainer/Policy mu Mean              0.031558
trainer/Policy mu Std               0.435752
trainer/Policy mu Max               2.82988
trainer/Policy mu Min              -2.80362
trainer/Policy log std Mean        -2.1934
trainer/Policy log std Std          0.316702
trainer/Policy log std Max         -0.493996
trainer/Policy log std Min         -2.42375
trainer/Alpha                       0.0544965
trainer/Alpha Loss                 -0.537751
exploration/num steps total     88200
exploration/num paths total       882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.295247
exploration/Rewards Std             0.860347
exploration/Rewards Max            -0.00466667
exploration/Rewards Min            -8.2077
exploration/Returns Mean          -29.5247
exploration/Returns Std            10.4391
exploration/Returns Max           -17.8114
exploration/Returns Min           -48.3466
exploration/Actions Mean            0.010206
exploration/Actions Std             0.236938
exploration/Actions Max             0.998979
exploration/Actions Min            -0.997684
exploration/Num Paths               5
exploration/Average Returns       -29.5247
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.28523
evaluation/Rewards Std              1.13142
evaluation/Rewards Max             -0.0095843
evaluation/Rewards Min             -9.99602
evaluation/Returns Mean           -28.523
evaluation/Returns Std             17.3813
evaluation/Returns Max             -6.57678
evaluation/Returns Min            -60.4401
evaluation/Actions Mean             0.0105985
evaluation/Actions Std              0.200733
evaluation/Actions Max              0.997536
evaluation/Actions Min             -0.994902
evaluation/Num Paths               15
evaluation/Average Returns        -28.523
time/data storing (s)               0.00313785
time/evaluation sampling (s)        0.370375
time/exploration sampling (s)       0.161753
time/logging (s)                    0.00496999
time/saving (s)                     0.00211456
time/training (s)                   2.12464
time/epoch (s)                      2.66699
time/total (s)                    472.656
Epoch                             175
-----------------------------  ---------------
2019-04-22 21:29:47.007903 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              88700
trainer/QF1 Loss                    0.447283
trainer/QF2 Loss                    0.430309
trainer/Policy Loss                 9.25277
trainer/Q1 Predictions Mean        -7.25335
trainer/Q1 Predictions Std          3.97621
trainer/Q1 Predictions Max         -6.32417
trainer/Q1 Predictions Min        -35.7545
trainer/Q2 Predictions Mean        -7.21938
trainer/Q2 Predictions Std          3.95389
trainer/Q2 Predictions Max         -6.35902
trainer/Q2 Predictions Min        -35.8548
trainer/Q Targets Mean             -7.17823
trainer/Q Targets Std               4.07629
trainer/Q Targets Max              -0.143039
trainer/Q Targets Min             -36.1832
trainer/Log Pis Mean                2.03894
trainer/Log Pis Std                 1.15597
trainer/Log Pis Max                 7.79552
trainer/Log Pis Min                -1.70059
trainer/Policy mu Mean              0.0971596
trainer/Policy mu Std               0.527347
trainer/Policy mu Max               2.93573
trainer/Policy mu Min              -2.87142
trainer/Policy log std Mean        -2.20053
trainer/Policy log std Std          0.357796
trainer/Policy log std Max         -0.492678
trainer/Policy log std Min         -2.45158
trainer/Alpha                       0.0540624
trainer/Alpha Loss                  0.113608
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.300419
exploration/Rewards Std             0.7772
exploration/Rewards Max            -0.00167822
exploration/Rewards Min            -7.57377
exploration/Returns Mean          -30.0419
exploration/Returns Std             8.77225
exploration/Returns Max           -21.3227
exploration/Returns Min           -45.5562
exploration/Actions Mean           -0.0134486
exploration/Actions Std             0.230887
exploration/Actions Max             0.996587
exploration/Actions Min            -0.998314
exploration/Num Paths               5
exploration/Average Returns       -30.0419
evaluation/num steps total     265500
evaluation/num paths total       2655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288142
evaluation/Rewards Std              1.04268
evaluation/Rewards Max             -0.0247029
evaluation/Rewards Min            -10.7397
evaluation/Returns Mean           -28.8142
evaluation/Returns Std             17.7265
evaluation/Returns Max             -6.3182
evaluation/Returns Min            -61.019
evaluation/Actions Mean            -0.00490791
evaluation/Actions Std              0.197327
evaluation/Actions Max              0.998061
evaluation/Actions Min             -0.99662
evaluation/Num Paths               15
evaluation/Average Returns        -28.8142
time/data storing (s)               0.00314876
time/evaluation sampling (s)        0.35827
time/exploration sampling (s)       0.161171
time/logging (s)                    0.0051499
time/saving (s)                     0.00205199
time/training (s)                   2.13214
time/epoch (s)                      2.66193
time/total (s)                    475.323
Epoch                             176
-----------------------------  ---------------
2019-04-22 21:29:49.636704 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 177 finished
-----------------------------  ----------------
replay_buffer/size              89200
trainer/QF1 Loss                    0.419112
trainer/QF2 Loss                    0.415126
trainer/Policy Loss                 8.70904
trainer/Q1 Predictions Mean        -6.97243
trainer/Q1 Predictions Std          2.11637
trainer/Q1 Predictions Max         -6.44067
trainer/Q1 Predictions Min        -25.2784
trainer/Q2 Predictions Mean        -6.9405
trainer/Q2 Predictions Std          2.137
trainer/Q2 Predictions Max         -6.36379
trainer/Q2 Predictions Min        -25.4901
trainer/Q Targets Mean             -6.91933
trainer/Q Targets Std               2.20709
trainer/Q Targets Max              -0.112005
trainer/Q Targets Min             -25.2496
trainer/Log Pis Mean                1.76527
trainer/Log Pis Std                 1.10846
trainer/Log Pis Max                 4.30964
trainer/Log Pis Min                -1.70355
trainer/Policy mu Mean              0.0294055
trainer/Policy mu Std               0.517002
trainer/Policy mu Max               2.7113
trainer/Policy mu Min              -3.02666
trainer/Policy log std Mean        -2.13326
trainer/Policy log std Std          0.392383
trainer/Policy log std Max         -0.495502
trainer/Policy log std Min         -2.42755
trainer/Alpha                       0.0529768
trainer/Alpha Loss                 -0.689568
exploration/num steps total     89200
exploration/num paths total       892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332414
exploration/Rewards Std             1.04462
exploration/Rewards Max            -0.00851178
exploration/Rewards Min            -9.55943
exploration/Returns Mean          -33.2414
exploration/Returns Std            17.8065
exploration/Returns Max           -13.3961
exploration/Returns Min           -57.1911
exploration/Actions Mean           -0.00803264
exploration/Actions Std             0.243038
exploration/Actions Max             0.992668
exploration/Actions Min            -0.99982
exploration/Num Paths               5
exploration/Average Returns       -33.2414
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.191532
evaluation/Rewards Std              0.928368
evaluation/Rewards Max             -0.000734767
evaluation/Rewards Min             -9.76798
evaluation/Returns Mean           -19.1532
evaluation/Returns Std             15.9335
evaluation/Returns Max             -1.95709
evaluation/Returns Min            -48.4292
evaluation/Actions Mean            -0.00453503
evaluation/Actions Std              0.194362
evaluation/Actions Max              0.995702
evaluation/Actions Min             -0.998694
evaluation/Num Paths               15
evaluation/Average Returns        -19.1532
time/data storing (s)               0.00319232
time/evaluation sampling (s)        0.362006
time/exploration sampling (s)       0.159101
time/logging (s)                    0.00491479
time/saving (s)                     0.00168799
time/training (s)                   2.08979
time/epoch (s)                      2.62069
time/total (s)                    477.948
Epoch                             177
-----------------------------  ----------------
2019-04-22 21:29:52.286128 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 178 finished
-----------------------------  ----------------
replay_buffer/size              89700
trainer/QF1 Loss                    0.0298331
trainer/QF2 Loss                    0.0311949
trainer/Policy Loss                10.49
trainer/Q1 Predictions Mean        -8.60694
trainer/Q1 Predictions Std          9.1349
trainer/Q1 Predictions Max         -6.30397
trainer/Q1 Predictions Min        -68.949
trainer/Q2 Predictions Mean        -8.6148
trainer/Q2 Predictions Std          9.09798
trainer/Q2 Predictions Max         -6.31487
trainer/Q2 Predictions Min        -68.3863
trainer/Q Targets Mean             -8.7322
trainer/Q Targets Std               9.09411
trainer/Q Targets Max              -6.32335
trainer/Q Targets Min             -68.4981
trainer/Log Pis Mean                2.0878
trainer/Log Pis Std                 1.37161
trainer/Log Pis Max                 7.57727
trainer/Log Pis Min                -3.10197
trainer/Policy mu Mean             -0.0173915
trainer/Policy mu Std               0.788421
trainer/Policy mu Max               3.3757
trainer/Policy mu Min              -2.96478
trainer/Policy log std Mean        -2.09557
trainer/Policy log std Std          0.518548
trainer/Policy log std Max         -0.445322
trainer/Policy log std Min         -2.45341
trainer/Alpha                       0.0543749
trainer/Alpha Loss                  0.255641
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.459687
exploration/Rewards Std             1.37029
exploration/Rewards Max            -0.000948798
exploration/Rewards Min           -10.689
exploration/Returns Mean          -45.9687
exploration/Returns Std            18.8054
exploration/Returns Max           -21.1538
exploration/Returns Min           -70.9849
exploration/Actions Mean           -0.0284779
exploration/Actions Std             0.269125
exploration/Actions Max             0.998054
exploration/Actions Min            -0.999393
exploration/Num Paths               5
exploration/Average Returns       -45.9687
evaluation/num steps total     268500
evaluation/num paths total       2685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.151394
evaluation/Rewards Std              0.581454
evaluation/Rewards Max             -0.037267
evaluation/Rewards Min             -6.49377
evaluation/Returns Mean           -15.1394
evaluation/Returns Std              8.61659
evaluation/Returns Max             -4.98885
evaluation/Returns Min            -27.9086
evaluation/Actions Mean            -0.0011439
evaluation/Actions Std              0.16056
evaluation/Actions Max              0.997051
evaluation/Actions Min             -0.997374
evaluation/Num Paths               15
evaluation/Average Returns        -15.1394
time/data storing (s)               0.00314403
time/evaluation sampling (s)        0.347333
time/exploration sampling (s)       0.15865
time/logging (s)                    0.00504136
time/saving (s)                     0.00208543
time/training (s)                   2.12571
time/epoch (s)                      2.64196
time/total (s)                    480.594
Epoch                             178
-----------------------------  ----------------
2019-04-22 21:29:54.986007 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              90200
trainer/QF1 Loss                    0.0322256
trainer/QF2 Loss                    0.0336447
trainer/Policy Loss                 8.93449
trainer/Q1 Predictions Mean        -7.14443
trainer/Q1 Predictions Std          2.89833
trainer/Q1 Predictions Max         -6.30812
trainer/Q1 Predictions Min        -27.8402
trainer/Q2 Predictions Mean        -7.12174
trainer/Q2 Predictions Std          2.91059
trainer/Q2 Predictions Max         -6.2785
trainer/Q2 Predictions Min        -27.8892
trainer/Q Targets Mean             -7.25632
trainer/Q Targets Std               2.93313
trainer/Q Targets Max              -6.34837
trainer/Q Targets Min             -28.4609
trainer/Log Pis Mean                1.83193
trainer/Log Pis Std                 1.08144
trainer/Log Pis Max                 5.26093
trainer/Log Pis Min                -1.98229
trainer/Policy mu Mean             -0.0808863
trainer/Policy mu Std               0.61195
trainer/Policy mu Max               2.95069
trainer/Policy mu Min              -2.88121
trainer/Policy log std Mean        -2.08277
trainer/Policy log std Std          0.429008
trainer/Policy log std Max         -0.558527
trainer/Policy log std Min         -2.46727
trainer/Alpha                       0.0541343
trainer/Alpha Loss                 -0.490064
exploration/num steps total     90200
exploration/num paths total       902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.256821
exploration/Rewards Std             0.679402
exploration/Rewards Max            -0.00788344
exploration/Rewards Min            -7.01988
exploration/Returns Mean          -25.6821
exploration/Returns Std             7.02526
exploration/Returns Max           -17.7004
exploration/Returns Min           -38.7685
exploration/Actions Mean           -0.0113645
exploration/Actions Std             0.224631
exploration/Actions Max             0.998828
exploration/Actions Min            -0.998929
exploration/Num Paths               5
exploration/Average Returns       -25.6821
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.290812
evaluation/Rewards Std              1.06081
evaluation/Rewards Max             -0.0440031
evaluation/Rewards Min             -9.76528
evaluation/Returns Mean           -29.0812
evaluation/Returns Std             13.9695
evaluation/Returns Max             -6.99239
evaluation/Returns Min            -51.1567
evaluation/Actions Mean            -0.00130018
evaluation/Actions Std              0.206332
evaluation/Actions Max              0.997957
evaluation/Actions Min             -0.99665
evaluation/Num Paths               15
evaluation/Average Returns        -29.0812
time/data storing (s)               0.00318397
time/evaluation sampling (s)        0.358166
time/exploration sampling (s)       0.159596
time/logging (s)                    0.00498748
time/saving (s)                     0.00204632
time/training (s)                   2.16392
time/epoch (s)                      2.6919
time/total (s)                    483.291
Epoch                             179
-----------------------------  ---------------
2019-04-22 21:29:57.609261 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              90700
trainer/QF1 Loss                    0.515384
trainer/QF2 Loss                    0.479559
trainer/Policy Loss                10.2474
trainer/Q1 Predictions Mean        -8.40563
trainer/Q1 Predictions Std          8.5218
trainer/Q1 Predictions Max         -6.32402
trainer/Q1 Predictions Min        -60.8798
trainer/Q2 Predictions Mean        -8.37533
trainer/Q2 Predictions Std          8.57485
trainer/Q2 Predictions Max         -6.29317
trainer/Q2 Predictions Min        -61.3983
trainer/Q Targets Mean             -8.44051
trainer/Q Targets Std               8.78082
trainer/Q Targets Max              -0.192553
trainer/Q Targets Min             -63.8946
trainer/Log Pis Mean                2.11368
trainer/Log Pis Std                 1.13952
trainer/Log Pis Max                 8.59006
trainer/Log Pis Min                -1.7629
trainer/Policy mu Mean             -0.00484643
trainer/Policy mu Std               0.719421
trainer/Policy mu Max               3.12697
trainer/Policy mu Min              -3.29424
trainer/Policy log std Mean        -2.19229
trainer/Policy log std Std          0.472351
trainer/Policy log std Max         -0.565198
trainer/Policy log std Min         -2.6435
trainer/Alpha                       0.0544718
trainer/Alpha Loss                  0.330826
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.413601
exploration/Rewards Std             1.25656
exploration/Rewards Max            -0.0056027
exploration/Rewards Min            -9.06896
exploration/Returns Mean          -41.3601
exploration/Returns Std            12.6968
exploration/Returns Max           -22.9512
exploration/Returns Min           -55.2986
exploration/Actions Mean           -0.0115822
exploration/Actions Std             0.26334
exploration/Actions Max             0.999365
exploration/Actions Min            -0.999543
exploration/Num Paths               5
exploration/Average Returns       -41.3601
evaluation/num steps total     271500
evaluation/num paths total       2715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.197555
evaluation/Rewards Std              0.875519
evaluation/Rewards Max             -0.0092581
evaluation/Rewards Min             -9.02985
evaluation/Returns Mean           -19.7555
evaluation/Returns Std             13.9803
evaluation/Returns Max             -2.38292
evaluation/Returns Min            -49.9324
evaluation/Actions Mean            -0.00369335
evaluation/Actions Std              0.183477
evaluation/Actions Max              0.997219
evaluation/Actions Min             -0.998485
evaluation/Num Paths               15
evaluation/Average Returns        -19.7555
time/data storing (s)               0.00327391
time/evaluation sampling (s)        0.352769
time/exploration sampling (s)       0.160529
time/logging (s)                    0.00479694
time/saving (s)                     0.00196164
time/training (s)                   2.09258
time/epoch (s)                      2.61591
time/total (s)                    485.911
Epoch                             180
-----------------------------  ---------------
2019-04-22 21:30:00.311478 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              91200
trainer/QF1 Loss                    0.0456626
trainer/QF2 Loss                    0.0494509
trainer/Policy Loss                 9.66566
trainer/Q1 Predictions Mean        -7.77955
trainer/Q1 Predictions Std          6.82618
trainer/Q1 Predictions Max         -6.22441
trainer/Q1 Predictions Min        -51.1531
trainer/Q2 Predictions Mean        -7.79201
trainer/Q2 Predictions Std          6.82992
trainer/Q2 Predictions Max         -6.22371
trainer/Q2 Predictions Min        -51.5763
trainer/Q Targets Mean             -7.84904
trainer/Q Targets Std               6.893
trainer/Q Targets Max              -6.29727
trainer/Q Targets Min             -52.3226
trainer/Log Pis Mean                1.90194
trainer/Log Pis Std                 1.31878
trainer/Log Pis Max                 6.33669
trainer/Log Pis Min                -2.53391
trainer/Policy mu Mean             -0.0385941
trainer/Policy mu Std               0.542949
trainer/Policy mu Max               3.16792
trainer/Policy mu Min              -3.22717
trainer/Policy log std Mean        -2.23148
trainer/Policy log std Std          0.34918
trainer/Policy log std Max         -0.492764
trainer/Policy log std Min         -2.50558
trainer/Alpha                       0.0543878
trainer/Alpha Loss                 -0.285486
exploration/num steps total     91200
exploration/num paths total       912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.313459
exploration/Rewards Std             1.01042
exploration/Rewards Max            -0.0078642
exploration/Rewards Min            -9.751
exploration/Returns Mean          -31.3459
exploration/Returns Std            18.2061
exploration/Returns Max           -15.6543
exploration/Returns Min           -56.0408
exploration/Actions Mean           -0.0159828
exploration/Actions Std             0.235403
exploration/Actions Max             0.997671
exploration/Actions Min            -0.998785
exploration/Num Paths               5
exploration/Average Returns       -31.3459
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.269097
evaluation/Rewards Std              0.994233
evaluation/Rewards Max             -0.0540037
evaluation/Rewards Min             -9.15137
evaluation/Returns Mean           -26.9097
evaluation/Returns Std             13.4716
evaluation/Returns Max             -6.22286
evaluation/Returns Min            -53.6484
evaluation/Actions Mean             0.0072406
evaluation/Actions Std              0.208319
evaluation/Actions Max              0.996456
evaluation/Actions Min             -0.996827
evaluation/Num Paths               15
evaluation/Average Returns        -26.9097
time/data storing (s)               0.00321878
time/evaluation sampling (s)        0.351004
time/exploration sampling (s)       0.161622
time/logging (s)                    0.00512985
time/saving (s)                     0.00200528
time/training (s)                   2.17099
time/epoch (s)                      2.69397
time/total (s)                    488.61
Epoch                             181
-----------------------------  ---------------
2019-04-22 21:30:02.984271 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              91700
trainer/QF1 Loss                    0.40211
trainer/QF2 Loss                    0.394289
trainer/Policy Loss                 9.21575
trainer/Q1 Predictions Mean        -7.23771
trainer/Q1 Predictions Std          4.40154
trainer/Q1 Predictions Max         -6.22511
trainer/Q1 Predictions Min        -43.9265
trainer/Q2 Predictions Mean        -7.19764
trainer/Q2 Predictions Std          4.41054
trainer/Q2 Predictions Max         -6.16449
trainer/Q2 Predictions Min        -44.0511
trainer/Q Targets Mean             -7.24338
trainer/Q Targets Std               4.41568
trainer/Q Targets Max              -0.189283
trainer/Q Targets Min             -43.716
trainer/Log Pis Mean                2.0644
trainer/Log Pis Std                 1.25231
trainer/Log Pis Max                 6.23632
trainer/Log Pis Min                -4.37898
trainer/Policy mu Mean             -0.0172718
trainer/Policy mu Std               0.509823
trainer/Policy mu Max               2.92469
trainer/Policy mu Min              -2.99213
trainer/Policy log std Mean        -2.26424
trainer/Policy log std Std          0.37598
trainer/Policy log std Max         -0.551658
trainer/Policy log std Min         -2.49565
trainer/Alpha                       0.0560809
trainer/Alpha Loss                  0.185553
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.204776
exploration/Rewards Std             0.490992
exploration/Rewards Max            -0.00637148
exploration/Rewards Min            -5.39842
exploration/Returns Mean          -20.4776
exploration/Returns Std             4.75878
exploration/Returns Max           -13.456
exploration/Returns Min           -27.1372
exploration/Actions Mean           -0.00344808
exploration/Actions Std             0.210397
exploration/Actions Max             0.998946
exploration/Actions Min            -0.996933
exploration/Num Paths               5
exploration/Average Returns       -20.4776
evaluation/num steps total     274500
evaluation/num paths total       2745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.233841
evaluation/Rewards Std              1.03836
evaluation/Rewards Max             -0.00101202
evaluation/Rewards Min             -9.53074
evaluation/Returns Mean           -23.3841
evaluation/Returns Std             15.6686
evaluation/Returns Max             -0.982934
evaluation/Returns Min            -49.5777
evaluation/Actions Mean            -0.0143442
evaluation/Actions Std              0.193399
evaluation/Actions Max              0.996273
evaluation/Actions Min             -0.995434
evaluation/Num Paths               15
evaluation/Average Returns        -23.3841
time/data storing (s)               0.00324689
time/evaluation sampling (s)        0.367218
time/exploration sampling (s)       0.165963
time/logging (s)                    0.00514034
time/saving (s)                     0.00207944
time/training (s)                   2.12173
time/epoch (s)                      2.66537
time/total (s)                    491.28
Epoch                             182
-----------------------------  ---------------
2019-04-22 21:30:05.697758 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              92200
trainer/QF1 Loss                    0.409073
trainer/QF2 Loss                    0.404184
trainer/Policy Loss                 8.6057
trainer/Q1 Predictions Mean        -6.71568
trainer/Q1 Predictions Std          1.25771
trainer/Q1 Predictions Max         -6.3372
trainer/Q1 Predictions Min        -14.9935
trainer/Q2 Predictions Mean        -6.71286
trainer/Q2 Predictions Std          1.23568
trainer/Q2 Predictions Max         -6.32702
trainer/Q2 Predictions Min        -14.6997
trainer/Q Targets Mean             -6.66559
trainer/Q Targets Std               1.40584
trainer/Q Targets Max              -0.0875729
trainer/Q Targets Min             -14.5574
trainer/Log Pis Mean                1.96196
trainer/Log Pis Std                 1.0451
trainer/Log Pis Max                 6.42542
trainer/Log Pis Min                -2.42884
trainer/Policy mu Mean              0.0221978
trainer/Policy mu Std               0.424263
trainer/Policy mu Max               2.69435
trainer/Policy mu Min              -2.69866
trainer/Policy log std Mean        -2.28618
trainer/Policy log std Std          0.327179
trainer/Policy log std Max         -0.446798
trainer/Policy log std Min         -2.56185
trainer/Alpha                       0.0572186
trainer/Alpha Loss                 -0.10884
exploration/num steps total     92200
exploration/num paths total       922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.363291
exploration/Rewards Std             1.09925
exploration/Rewards Max            -0.00910022
exploration/Rewards Min           -10.6082
exploration/Returns Mean          -36.3291
exploration/Returns Std            15.4882
exploration/Returns Max           -23.3194
exploration/Returns Min           -65.9577
exploration/Actions Mean           -0.0377391
exploration/Actions Std             0.235954
exploration/Actions Max             0.959882
exploration/Actions Min            -0.99876
exploration/Num Paths               5
exploration/Average Returns       -36.3291
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.181022
evaluation/Rewards Std              0.813547
evaluation/Rewards Max             -0.0114644
evaluation/Rewards Min            -10.4541
evaluation/Returns Mean           -18.1022
evaluation/Returns Std             16.288
evaluation/Returns Max             -2.78126
evaluation/Returns Min            -64.5885
evaluation/Actions Mean            -0.00878432
evaluation/Actions Std              0.17816
evaluation/Actions Max              0.997593
evaluation/Actions Min             -0.996271
evaluation/Num Paths               15
evaluation/Average Returns        -18.1022
time/data storing (s)               0.00324546
time/evaluation sampling (s)        0.358204
time/exploration sampling (s)       0.158948
time/logging (s)                    0.00506301
time/saving (s)                     0.00199788
time/training (s)                   2.17819
time/epoch (s)                      2.70565
time/total (s)                    493.99
Epoch                             183
-----------------------------  ---------------
2019-04-22 21:30:08.328050 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              92700
trainer/QF1 Loss                    0.433078
trainer/QF2 Loss                    0.410029
trainer/Policy Loss                 9.10157
trainer/Q1 Predictions Mean        -7.23313
trainer/Q1 Predictions Std          3.97499
trainer/Q1 Predictions Max         -6.31705
trainer/Q1 Predictions Min        -44.5464
trainer/Q2 Predictions Mean        -7.19671
trainer/Q2 Predictions Std          3.95694
trainer/Q2 Predictions Max         -6.33349
trainer/Q2 Predictions Min        -44.3848
trainer/Q Targets Mean             -7.17092
trainer/Q Targets Std               4.01089
trainer/Q Targets Max              -0.36374
trainer/Q Targets Min             -44.4068
trainer/Log Pis Mean                2.01977
trainer/Log Pis Std                 1.35514
trainer/Log Pis Max                 7.54387
trainer/Log Pis Min                -2.49473
trainer/Policy mu Mean              0.00361196
trainer/Policy mu Std               0.571489
trainer/Policy mu Max               2.57417
trainer/Policy mu Min              -3.0159
trainer/Policy log std Mean        -2.20617
trainer/Policy log std Std          0.413594
trainer/Policy log std Max         -0.532637
trainer/Policy log std Min         -2.53145
trainer/Alpha                       0.057601
trainer/Alpha Loss                  0.0564301
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.261556
exploration/Rewards Std             0.736091
exploration/Rewards Max            -0.00526562
exploration/Rewards Min            -7.11967
exploration/Returns Mean          -26.1556
exploration/Returns Std             9.24758
exploration/Returns Max           -13.7393
exploration/Returns Min           -40.4552
exploration/Actions Mean           -0.0142099
exploration/Actions Std             0.218922
exploration/Actions Max             0.98989
exploration/Actions Min            -0.998277
exploration/Num Paths               5
exploration/Average Returns       -26.1556
evaluation/num steps total     277500
evaluation/num paths total       2775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241542
evaluation/Rewards Std              1.01883
evaluation/Rewards Max             -0.0239322
evaluation/Rewards Min             -9.64051
evaluation/Returns Mean           -24.1542
evaluation/Returns Std             15.6088
evaluation/Returns Max             -4.66351
evaluation/Returns Min            -53.7387
evaluation/Actions Mean             0.015791
evaluation/Actions Std              0.193648
evaluation/Actions Max              0.99672
evaluation/Actions Min             -0.996931
evaluation/Num Paths               15
evaluation/Average Returns        -24.1542
time/data storing (s)               0.00335404
time/evaluation sampling (s)        0.35945
time/exploration sampling (s)       0.158898
time/logging (s)                    0.00524883
time/saving (s)                     0.00237982
time/training (s)                   2.09314
time/epoch (s)                      2.62247
time/total (s)                    496.617
Epoch                             184
-----------------------------  ---------------
2019-04-22 21:30:10.956824 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              93200
trainer/QF1 Loss                    0.389274
trainer/QF2 Loss                    0.385912
trainer/Policy Loss                 9.44267
trainer/Q1 Predictions Mean        -7.35179
trainer/Q1 Predictions Std          4.5993
trainer/Q1 Predictions Max         -6.12846
trainer/Q1 Predictions Min        -38.1708
trainer/Q2 Predictions Mean        -7.38593
trainer/Q2 Predictions Std          4.59314
trainer/Q2 Predictions Max         -6.23435
trainer/Q2 Predictions Min        -38.4339
trainer/Q Targets Mean             -7.37961
trainer/Q Targets Std               4.63154
trainer/Q Targets Max              -0.192553
trainer/Q Targets Min             -38.3586
trainer/Log Pis Mean                2.08653
trainer/Log Pis Std                 0.924731
trainer/Log Pis Max                 3.82166
trainer/Log Pis Min                -0.853151
trainer/Policy mu Mean              0.0188496
trainer/Policy mu Std               0.558815
trainer/Policy mu Max               2.77572
trainer/Policy mu Min              -3.12058
trainer/Policy log std Mean        -2.29443
trainer/Policy log std Std          0.392206
trainer/Policy log std Max         -0.669894
trainer/Policy log std Min         -2.62992
trainer/Alpha                       0.056609
trainer/Alpha Loss                  0.248506
exploration/num steps total     93200
exploration/num paths total       932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.320051
exploration/Rewards Std             1.00873
exploration/Rewards Max            -0.00106305
exploration/Rewards Min            -7.7516
exploration/Returns Mean          -32.0051
exploration/Returns Std            12.124
exploration/Returns Max           -11.9195
exploration/Returns Min           -44.9646
exploration/Actions Mean           -0.0163407
exploration/Actions Std             0.23157
exploration/Actions Max             0.999417
exploration/Actions Min            -0.999005
exploration/Num Paths               5
exploration/Average Returns       -32.0051
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282074
evaluation/Rewards Std              1.21229
evaluation/Rewards Max             -0.00790883
evaluation/Rewards Min            -11.087
evaluation/Returns Mean           -28.2074
evaluation/Returns Std             17.3411
evaluation/Returns Max             -5.49635
evaluation/Returns Min            -59.7178
evaluation/Actions Mean             0.00132625
evaluation/Actions Std              0.214716
evaluation/Actions Max              0.996813
evaluation/Actions Min             -0.997994
evaluation/Num Paths               15
evaluation/Average Returns        -28.2074
time/data storing (s)               0.00314018
time/evaluation sampling (s)        0.345242
time/exploration sampling (s)       0.155628
time/logging (s)                    0.00491393
time/saving (s)                     0.00204307
time/training (s)                   2.11025
time/epoch (s)                      2.62121
time/total (s)                    499.244
Epoch                             185
-----------------------------  ---------------
2019-04-22 21:30:13.667786 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 186 finished
-----------------------------  ----------------
replay_buffer/size              93700
trainer/QF1 Loss                    0.0682948
trainer/QF2 Loss                    0.0410888
trainer/Policy Loss                 8.98435
trainer/Q1 Predictions Mean        -7.19267
trainer/Q1 Predictions Std          4.8752
trainer/Q1 Predictions Max         -6.08723
trainer/Q1 Predictions Min        -44.7723
trainer/Q2 Predictions Mean        -7.24257
trainer/Q2 Predictions Std          4.86229
trainer/Q2 Predictions Max         -6.16725
trainer/Q2 Predictions Min        -44.364
trainer/Q Targets Mean             -7.40412
trainer/Q Targets Std               4.85644
trainer/Q Targets Max              -6.27162
trainer/Q Targets Min             -44.2816
trainer/Log Pis Mean                1.84646
trainer/Log Pis Std                 1.24439
trainer/Log Pis Max                 4.57403
trainer/Log Pis Min                -4.18626
trainer/Policy mu Mean              0.00244298
trainer/Policy mu Std               0.566786
trainer/Policy mu Max               2.68923
trainer/Policy mu Min              -3.1551
trainer/Policy log std Mean        -2.18098
trainer/Policy log std Std          0.409913
trainer/Policy log std Max         -0.4918
trainer/Policy log std Min         -2.45164
trainer/Alpha                       0.055773
trainer/Alpha Loss                 -0.443144
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.496834
exploration/Rewards Std             1.44108
exploration/Rewards Max            -0.00771082
exploration/Rewards Min           -10.1141
exploration/Returns Mean          -49.6834
exploration/Returns Std            15.2055
exploration/Returns Max           -25.2722
exploration/Returns Min           -62.192
exploration/Actions Mean           -0.000285436
exploration/Actions Std             0.279335
exploration/Actions Max             0.999775
exploration/Actions Min            -0.998819
exploration/Num Paths               5
exploration/Average Returns       -49.6834
evaluation/num steps total     280500
evaluation/num paths total       2805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288023
evaluation/Rewards Std              1.14611
evaluation/Rewards Max             -0.015394
evaluation/Rewards Min            -10.2656
evaluation/Returns Mean           -28.8023
evaluation/Returns Std             19.5703
evaluation/Returns Max             -4.73384
evaluation/Returns Min            -61.2981
evaluation/Actions Mean             0.00704128
evaluation/Actions Std              0.19345
evaluation/Actions Max              0.997649
evaluation/Actions Min             -0.996931
evaluation/Num Paths               15
evaluation/Average Returns        -28.8023
time/data storing (s)               0.00316464
time/evaluation sampling (s)        0.389512
time/exploration sampling (s)       0.157756
time/logging (s)                    0.00503661
time/saving (s)                     0.0023805
time/training (s)                   2.14419
time/epoch (s)                      2.70204
time/total (s)                    501.95
Epoch                             186
-----------------------------  ----------------
2019-04-22 21:30:16.330528 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              94200
trainer/QF1 Loss                    0.0164232
trainer/QF2 Loss                    0.0152458
trainer/Policy Loss                 9.55782
trainer/Q1 Predictions Mean        -7.591
trainer/Q1 Predictions Std          6.16826
trainer/Q1 Predictions Max         -6.33312
trainer/Q1 Predictions Min        -62.7895
trainer/Q2 Predictions Mean        -7.56906
trainer/Q2 Predictions Std          6.16716
trainer/Q2 Predictions Max         -6.28735
trainer/Q2 Predictions Min        -62.827
trainer/Q Targets Mean             -7.63763
trainer/Q Targets Std               6.12114
trainer/Q Targets Max              -6.30374
trainer/Q Targets Min             -62.5384
trainer/Log Pis Mean                2.17877
trainer/Log Pis Std                 1.18567
trainer/Log Pis Max                 9.02178
trainer/Log Pis Min                -1.73613
trainer/Policy mu Mean             -0.00795872
trainer/Policy mu Std               0.606242
trainer/Policy mu Max               2.92267
trainer/Policy mu Min              -3.24261
trainer/Policy log std Mean        -2.19516
trainer/Policy log std Std          0.413352
trainer/Policy log std Max         -0.513495
trainer/Policy log std Min         -2.48846
trainer/Alpha                       0.0539259
trainer/Alpha Loss                  0.522043
exploration/num steps total     94200
exploration/num paths total       942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.329949
exploration/Rewards Std             1.04763
exploration/Rewards Max            -0.00237736
exploration/Rewards Min            -9.8787
exploration/Returns Mean          -32.9949
exploration/Returns Std            17.0717
exploration/Returns Max           -15.0861
exploration/Returns Min           -58.9377
exploration/Actions Mean           -0.0107289
exploration/Actions Std             0.236253
exploration/Actions Max             0.99793
exploration/Actions Min            -0.998999
exploration/Num Paths               5
exploration/Average Returns       -32.9949
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.214563
evaluation/Rewards Std              0.998847
evaluation/Rewards Max             -0.00494379
evaluation/Rewards Min            -10.0386
evaluation/Returns Mean           -21.4563
evaluation/Returns Std             16.1703
evaluation/Returns Max             -1.88917
evaluation/Returns Min            -56.9149
evaluation/Actions Mean            -0.0225191
evaluation/Actions Std              0.192874
evaluation/Actions Max              0.992875
evaluation/Actions Min             -0.996747
evaluation/Num Paths               15
evaluation/Average Returns        -21.4563
time/data storing (s)               0.00400922
time/evaluation sampling (s)        0.357063
time/exploration sampling (s)       0.16278
time/logging (s)                    0.0053029
time/saving (s)                     0.00207872
time/training (s)                   2.12375
time/epoch (s)                      2.65499
time/total (s)                    504.61
Epoch                             187
-----------------------------  ---------------
2019-04-22 21:30:19.074061 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              94700
trainer/QF1 Loss                    0.0892753
trainer/QF2 Loss                    0.078797
trainer/Policy Loss                 9.27141
trainer/Q1 Predictions Mean        -7.43898
trainer/Q1 Predictions Std          3.96323
trainer/Q1 Predictions Max         -6.22099
trainer/Q1 Predictions Min        -30.835
trainer/Q2 Predictions Mean        -7.43918
trainer/Q2 Predictions Std          3.94369
trainer/Q2 Predictions Max         -6.25698
trainer/Q2 Predictions Min        -30.647
trainer/Q Targets Mean             -7.53062
trainer/Q Targets Std               3.82576
trainer/Q Targets Max              -6.31097
trainer/Q Targets Min             -30.4296
trainer/Log Pis Mean                2.0515
trainer/Log Pis Std                 1.00291
trainer/Log Pis Max                 6.4492
trainer/Log Pis Min                -1.37132
trainer/Policy mu Mean             -0.0117321
trainer/Policy mu Std               0.624566
trainer/Policy mu Max               2.90447
trainer/Policy mu Min              -2.96149
trainer/Policy log std Mean        -2.18834
trainer/Policy log std Std          0.43004
trainer/Policy log std Max         -0.545378
trainer/Policy log std Min         -2.42222
trainer/Alpha                       0.0526315
trainer/Alpha Loss                  0.151641
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.278915
exploration/Rewards Std             0.817686
exploration/Rewards Max            -0.00444293
exploration/Rewards Min            -9.23218
exploration/Returns Mean          -27.8915
exploration/Returns Std            11.7456
exploration/Returns Max           -18.5495
exploration/Returns Min           -50.4072
exploration/Actions Mean           -0.0276638
exploration/Actions Std             0.227741
exploration/Actions Max             0.996441
exploration/Actions Min            -0.999011
exploration/Num Paths               5
exploration/Average Returns       -27.8915
evaluation/num steps total     283500
evaluation/num paths total       2835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.285134
evaluation/Rewards Std              1.13194
evaluation/Rewards Max             -0.0301728
evaluation/Rewards Min            -10.5189
evaluation/Returns Mean           -28.5134
evaluation/Returns Std             19.9003
evaluation/Returns Max             -3.85531
evaluation/Returns Min            -62.8472
evaluation/Actions Mean            -0.00836258
evaluation/Actions Std              0.193125
evaluation/Actions Max              0.997811
evaluation/Actions Min             -0.99765
evaluation/Num Paths               15
evaluation/Average Returns        -28.5134
time/data storing (s)               0.00320698
time/evaluation sampling (s)        0.358921
time/exploration sampling (s)       0.160922
time/logging (s)                    0.00500728
time/saving (s)                     0.00212008
time/training (s)                   2.20482
time/epoch (s)                      2.73499
time/total (s)                    507.349
Epoch                             188
-----------------------------  ---------------
2019-04-22 21:30:21.697351 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              95200
trainer/QF1 Loss                    0.018081
trainer/QF2 Loss                    0.0234732
trainer/Policy Loss                10.1646
trainer/Q1 Predictions Mean        -8.10525
trainer/Q1 Predictions Std          6.81858
trainer/Q1 Predictions Max         -6.39312
trainer/Q1 Predictions Min        -60.8925
trainer/Q2 Predictions Mean        -8.09191
trainer/Q2 Predictions Std          6.86029
trainer/Q2 Predictions Max         -6.38737
trainer/Q2 Predictions Min        -61.4613
trainer/Q Targets Mean             -8.06503
trainer/Q Targets Std               6.76728
trainer/Q Targets Max              -6.3087
trainer/Q Targets Min             -60.4875
trainer/Log Pis Mean                2.19383
trainer/Log Pis Std                 1.19238
trainer/Log Pis Max                 6.61102
trainer/Log Pis Min                -1.94857
trainer/Policy mu Mean              0.0351231
trainer/Policy mu Std               0.72166
trainer/Policy mu Max               3.14292
trainer/Policy mu Min              -2.9993
trainer/Policy log std Mean        -2.14512
trainer/Policy log std Std          0.465462
trainer/Policy log std Max         -0.450179
trainer/Policy log std Min         -2.44962
trainer/Alpha                       0.0533009
trainer/Alpha Loss                  0.568302
exploration/num steps total     95200
exploration/num paths total       952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.274811
exploration/Rewards Std             0.744646
exploration/Rewards Max            -0.00703483
exploration/Rewards Min            -7.19548
exploration/Returns Mean          -27.4811
exploration/Returns Std             7.14172
exploration/Returns Max           -20.0544
exploration/Returns Min           -37.2393
exploration/Actions Mean            0.0207537
exploration/Actions Std             0.225172
exploration/Actions Max             0.998723
exploration/Actions Min            -0.99166
exploration/Num Paths               5
exploration/Average Returns       -27.4811
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.23912
evaluation/Rewards Std              0.981392
evaluation/Rewards Max             -0.00334038
evaluation/Rewards Min             -9.13907
evaluation/Returns Mean           -23.912
evaluation/Returns Std             14.3586
evaluation/Returns Max             -6.80112
evaluation/Returns Min            -49.0189
evaluation/Actions Mean             0.0134191
evaluation/Actions Std              0.196717
evaluation/Actions Max              0.997158
evaluation/Actions Min             -0.997398
evaluation/Num Paths               15
evaluation/Average Returns        -23.912
time/data storing (s)               0.00333938
time/evaluation sampling (s)        0.35819
time/exploration sampling (s)       0.159631
time/logging (s)                    0.00475528
time/saving (s)                     0.00197918
time/training (s)                   2.08704
time/epoch (s)                      2.61494
time/total (s)                    509.969
Epoch                             189
-----------------------------  ---------------
2019-04-22 21:30:24.409117 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              95700
trainer/QF1 Loss                    0.0113168
trainer/QF2 Loss                    0.015957
trainer/Policy Loss                 8.91809
trainer/Q1 Predictions Mean        -6.97645
trainer/Q1 Predictions Std          2.32333
trainer/Q1 Predictions Max         -6.26471
trainer/Q1 Predictions Min        -22.1552
trainer/Q2 Predictions Mean        -6.94811
trainer/Q2 Predictions Std          2.298
trainer/Q2 Predictions Max         -6.19792
trainer/Q2 Predictions Min        -22.1069
trainer/Q Targets Mean             -7.01542
trainer/Q Targets Std               2.3113
trainer/Q Targets Max              -6.26416
trainer/Q Targets Min             -21.9775
trainer/Log Pis Mean                1.97467
trainer/Log Pis Std                 0.974334
trainer/Log Pis Max                 5.80839
trainer/Log Pis Min                -0.692535
trainer/Policy mu Mean              0.0413965
trainer/Policy mu Std               0.556124
trainer/Policy mu Max               2.90869
trainer/Policy mu Min              -2.78419
trainer/Policy log std Mean        -2.12566
trainer/Policy log std Std          0.405218
trainer/Policy log std Max         -0.378059
trainer/Policy log std Min         -2.37933
trainer/Alpha                       0.052926
trainer/Alpha Loss                 -0.074438
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.258991
exploration/Rewards Std             0.761172
exploration/Rewards Max            -0.0103905
exploration/Rewards Min            -8.71741
exploration/Returns Mean          -25.8991
exploration/Returns Std            14.2091
exploration/Returns Max           -15.1649
exploration/Returns Min           -53.4125
exploration/Actions Mean            0.00567914
exploration/Actions Std             0.22072
exploration/Actions Max             0.998203
exploration/Actions Min            -0.994822
exploration/Num Paths               5
exploration/Average Returns       -25.8991
evaluation/num steps total     286500
evaluation/num paths total       2865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.344884
evaluation/Rewards Std              1.27145
evaluation/Rewards Max             -0.0142602
evaluation/Rewards Min            -10.517
evaluation/Returns Mean           -34.4884
evaluation/Returns Std             16.0749
evaluation/Returns Max             -4.9113
evaluation/Returns Min            -62.1158
evaluation/Actions Mean            -0.0134242
evaluation/Actions Std              0.218133
evaluation/Actions Max              0.996703
evaluation/Actions Min             -0.998427
evaluation/Num Paths               15
evaluation/Average Returns        -34.4884
time/data storing (s)               0.00315193
time/evaluation sampling (s)        0.349015
time/exploration sampling (s)       0.161266
time/logging (s)                    0.00491436
time/saving (s)                     0.00199125
time/training (s)                   2.18392
time/epoch (s)                      2.70426
time/total (s)                    512.678
Epoch                             190
-----------------------------  ---------------
2019-04-22 21:30:27.067215 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              96200
trainer/QF1 Loss                    1.61031
trainer/QF2 Loss                    1.60335
trainer/Policy Loss                 8.7529
trainer/Q1 Predictions Mean        -6.85966
trainer/Q1 Predictions Std          1.63364
trainer/Q1 Predictions Max         -6.30785
trainer/Q1 Predictions Min        -16.2781
trainer/Q2 Predictions Mean        -6.8495
trainer/Q2 Predictions Std          1.65299
trainer/Q2 Predictions Max         -6.28572
trainer/Q2 Predictions Min        -16.3221
trainer/Q Targets Mean             -6.64007
trainer/Q Targets Std               2.07625
trainer/Q Targets Max              -0.016373
trainer/Q Targets Min             -16.1909
trainer/Log Pis Mean                1.9557
trainer/Log Pis Std                 1.21248
trainer/Log Pis Max                 6.09487
trainer/Log Pis Min                -2.77727
trainer/Policy mu Mean              0.00467687
trainer/Policy mu Std               0.520336
trainer/Policy mu Max               2.51864
trainer/Policy mu Min              -2.7692
trainer/Policy log std Mean        -2.19897
trainer/Policy log std Std          0.374699
trainer/Policy log std Max         -0.512387
trainer/Policy log std Min         -2.40956
trainer/Alpha                       0.0547803
trainer/Alpha Loss                 -0.128675
exploration/num steps total     96200
exploration/num paths total       962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.286719
exploration/Rewards Std             0.83523
exploration/Rewards Max            -0.00267384
exploration/Rewards Min            -8.16183
exploration/Returns Mean          -28.6719
exploration/Returns Std            11.8307
exploration/Returns Max           -17.8862
exploration/Returns Min           -49.9051
exploration/Actions Mean            0.00908523
exploration/Actions Std             0.234575
exploration/Actions Max             0.997781
exploration/Actions Min            -0.997572
exploration/Num Paths               5
exploration/Average Returns       -28.6719
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229637
evaluation/Rewards Std              0.922774
evaluation/Rewards Max             -0.0415555
evaluation/Rewards Min             -9.75706
evaluation/Returns Mean           -22.9637
evaluation/Returns Std             14.1041
evaluation/Returns Max             -6.1546
evaluation/Returns Min            -48.8922
evaluation/Actions Mean             0.00814245
evaluation/Actions Std              0.187443
evaluation/Actions Max              0.997215
evaluation/Actions Min             -0.998689
evaluation/Num Paths               15
evaluation/Average Returns        -22.9637
time/data storing (s)               0.0031831
time/evaluation sampling (s)        0.356547
time/exploration sampling (s)       0.157626
time/logging (s)                    0.0049216
time/saving (s)                     0.00198573
time/training (s)                   2.12551
time/epoch (s)                      2.64978
time/total (s)                    515.332
Epoch                             191
-----------------------------  ---------------
2019-04-22 21:30:29.755950 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              96700
trainer/QF1 Loss                    1.20715
trainer/QF2 Loss                    1.23803
trainer/Policy Loss                10.1411
trainer/Q1 Predictions Mean        -8.02861
trainer/Q1 Predictions Std          7.6807
trainer/Q1 Predictions Max         -6.11734
trainer/Q1 Predictions Min        -60.1762
trainer/Q2 Predictions Mean        -8.07486
trainer/Q2 Predictions Std          7.69412
trainer/Q2 Predictions Max         -6.21993
trainer/Q2 Predictions Min        -60.2674
trainer/Q Targets Mean             -8.0024
trainer/Q Targets Std               7.74939
trainer/Q Targets Max              -0.205315
trainer/Q Targets Min             -60.8932
trainer/Log Pis Mean                2.10282
trainer/Log Pis Std                 1.5077
trainer/Log Pis Max                 9.48694
trainer/Log Pis Min                -4.75848
trainer/Policy mu Mean             -0.0369031
trainer/Policy mu Std               0.722977
trainer/Policy mu Max               3.42535
trainer/Policy mu Min              -3.26121
trainer/Policy log std Mean        -2.17253
trainer/Policy log std Std          0.457826
trainer/Policy log std Max         -0.546673
trainer/Policy log std Min         -2.44529
trainer/Alpha                       0.0559822
trainer/Alpha Loss                  0.296415
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281891
exploration/Rewards Std             0.832403
exploration/Rewards Max            -0.00269419
exploration/Rewards Min            -7.90097
exploration/Returns Mean          -28.1891
exploration/Returns Std            11.5832
exploration/Returns Max           -15.7809
exploration/Returns Min           -46.5784
exploration/Actions Mean            0.00854582
exploration/Actions Std             0.233336
exploration/Actions Max             0.997218
exploration/Actions Min            -0.999701
exploration/Num Paths               5
exploration/Average Returns       -28.1891
evaluation/num steps total     289500
evaluation/num paths total       2895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.190252
evaluation/Rewards Std              0.960181
evaluation/Rewards Max             -0.00464759
evaluation/Rewards Min            -10.1423
evaluation/Returns Mean           -19.0252
evaluation/Returns Std             15.9241
evaluation/Returns Max             -2.09244
evaluation/Returns Min            -48.9716
evaluation/Actions Mean             0.010497
evaluation/Actions Std              0.19185
evaluation/Actions Max              0.997965
evaluation/Actions Min             -0.995269
evaluation/Num Paths               15
evaluation/Average Returns        -19.0252
time/data storing (s)               0.00326967
time/evaluation sampling (s)        0.350373
time/exploration sampling (s)       0.159106
time/logging (s)                    0.00368755
time/saving (s)                     0.00185244
time/training (s)                   2.16096
time/epoch (s)                      2.67925
time/total (s)                    518.016
Epoch                             192
-----------------------------  ---------------
2019-04-22 21:30:32.406930 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              97200
trainer/QF1 Loss                    0.0397419
trainer/QF2 Loss                    0.0377485
trainer/Policy Loss                10.052
trainer/Q1 Predictions Mean        -7.76099
trainer/Q1 Predictions Std          6.72886
trainer/Q1 Predictions Max         -6.11757
trainer/Q1 Predictions Min        -67.7399
trainer/Q2 Predictions Mean        -7.83017
trainer/Q2 Predictions Std          6.70495
trainer/Q2 Predictions Max         -6.27779
trainer/Q2 Predictions Min        -67.4055
trainer/Q Targets Mean             -7.89275
trainer/Q Targets Std               6.75873
trainer/Q Targets Max              -6.23228
trainer/Q Targets Min             -68.4635
trainer/Log Pis Mean                2.30362
trainer/Log Pis Std                 1.1738
trainer/Log Pis Max                 7.56256
trainer/Log Pis Min                -0.497258
trainer/Policy mu Mean             -0.00148575
trainer/Policy mu Std               0.736508
trainer/Policy mu Max               3.23584
trainer/Policy mu Min              -3.00836
trainer/Policy log std Mean        -2.17865
trainer/Policy log std Std          0.51726
trainer/Policy log std Max         -0.555602
trainer/Policy log std Min         -2.48985
trainer/Alpha                       0.0537085
trainer/Alpha Loss                  0.887884
exploration/num steps total     97200
exploration/num paths total       972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.392066
exploration/Rewards Std             1.22881
exploration/Rewards Max            -0.00436234
exploration/Rewards Min           -10.3832
exploration/Returns Mean          -39.2066
exploration/Returns Std            19.0844
exploration/Returns Max           -20.2751
exploration/Returns Min           -70.0914
exploration/Actions Mean           -0.00434712
exploration/Actions Std             0.253461
exploration/Actions Max             0.999215
exploration/Actions Min            -0.999544
exploration/Num Paths               5
exploration/Average Returns       -39.2066
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.201703
evaluation/Rewards Std              0.873
evaluation/Rewards Max             -0.0344689
evaluation/Rewards Min             -9.72951
evaluation/Returns Mean           -20.1703
evaluation/Returns Std             13.8451
evaluation/Returns Max             -4.53153
evaluation/Returns Min            -50.5662
evaluation/Actions Mean            -0.00418423
evaluation/Actions Std              0.178518
evaluation/Actions Max              0.996202
evaluation/Actions Min             -0.995811
evaluation/Num Paths               15
evaluation/Average Returns        -20.1703
time/data storing (s)               0.00328876
time/evaluation sampling (s)        0.354419
time/exploration sampling (s)       0.157375
time/logging (s)                    0.00472018
time/saving (s)                     0.00209977
time/training (s)                   2.12261
time/epoch (s)                      2.64451
time/total (s)                    520.666
Epoch                             193
-----------------------------  ---------------
2019-04-22 21:30:35.082731 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              97700
trainer/QF1 Loss                    0.470555
trainer/QF2 Loss                    0.4523
trainer/Policy Loss                 9.35057
trainer/Q1 Predictions Mean        -7.25966
trainer/Q1 Predictions Std          4.39256
trainer/Q1 Predictions Max         -6.00522
trainer/Q1 Predictions Min        -43.9379
trainer/Q2 Predictions Mean        -7.29767
trainer/Q2 Predictions Std          4.38162
trainer/Q2 Predictions Max         -6.07449
trainer/Q2 Predictions Min        -43.8578
trainer/Q Targets Mean             -7.33056
trainer/Q Targets Std               4.41936
trainer/Q Targets Max              -0.205413
trainer/Q Targets Min             -43.9026
trainer/Log Pis Mean                2.10317
trainer/Log Pis Std                 1.18096
trainer/Log Pis Max                 6.10302
trainer/Log Pis Min                -2.47346
trainer/Policy mu Mean             -0.0148524
trainer/Policy mu Std               0.624499
trainer/Policy mu Max               2.56526
trainer/Policy mu Min              -2.9625
trainer/Policy log std Mean        -2.21686
trainer/Policy log std Std          0.444789
trainer/Policy log std Max         -0.47428
trainer/Policy log std Min         -2.46675
trainer/Alpha                       0.0527262
trainer/Alpha Loss                  0.30361
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.376319
exploration/Rewards Std             1.09698
exploration/Rewards Max            -0.00759373
exploration/Rewards Min            -8.98874
exploration/Returns Mean          -37.6319
exploration/Returns Std             9.47369
exploration/Returns Max           -27.686
exploration/Returns Min           -55.1183
exploration/Actions Mean            0.0200722
exploration/Actions Std             0.249675
exploration/Actions Max             0.998463
exploration/Actions Min            -0.998762
exploration/Num Paths               5
exploration/Average Returns       -37.6319
evaluation/num steps total     292500
evaluation/num paths total       2925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.312451
evaluation/Rewards Std              1.16506
evaluation/Rewards Max             -0.00799544
evaluation/Rewards Min            -10.1044
evaluation/Returns Mean           -31.2451
evaluation/Returns Std             17.3777
evaluation/Returns Max             -9.70987
evaluation/Returns Min            -59.8353
evaluation/Actions Mean            -0.00379302
evaluation/Actions Std              0.2085
evaluation/Actions Max              0.996987
evaluation/Actions Min             -0.997067
evaluation/Num Paths               15
evaluation/Average Returns        -31.2451
time/data storing (s)               0.00321943
time/evaluation sampling (s)        0.352647
time/exploration sampling (s)       0.158495
time/logging (s)                    0.0057213
time/saving (s)                     0.00198226
time/training (s)                   2.14658
time/epoch (s)                      2.66865
time/total (s)                    523.339
Epoch                             194
-----------------------------  ---------------
2019-04-22 21:30:37.717182 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 195 finished
-----------------------------  ----------------
replay_buffer/size              98200
trainer/QF1 Loss                    0.389887
trainer/QF2 Loss                    0.39895
trainer/Policy Loss                 8.78864
trainer/Q1 Predictions Mean        -7.03066
trainer/Q1 Predictions Std          3.38049
trainer/Q1 Predictions Max         -6.17073
trainer/Q1 Predictions Min        -34.7142
trainer/Q2 Predictions Mean        -7.04373
trainer/Q2 Predictions Std          3.35597
trainer/Q2 Predictions Max         -6.24213
trainer/Q2 Predictions Min        -34.44
trainer/Q Targets Mean             -6.98692
trainer/Q Targets Std               3.45364
trainer/Q Targets Max              -0.0550412
trainer/Q Targets Min             -34.9306
trainer/Log Pis Mean                1.8164
trainer/Log Pis Std                 1.18472
trainer/Log Pis Max                 5.4315
trainer/Log Pis Min                -2.57636
trainer/Policy mu Mean             -0.0256897
trainer/Policy mu Std               0.467436
trainer/Policy mu Max               2.88289
trainer/Policy mu Min              -3.11505
trainer/Policy log std Mean        -2.22595
trainer/Policy log std Std          0.327697
trainer/Policy log std Max         -0.680552
trainer/Policy log std Min         -2.45017
trainer/Alpha                       0.0544857
trainer/Alpha Loss                 -0.534229
exploration/num steps total     98200
exploration/num paths total       982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.324692
exploration/Rewards Std             1.005
exploration/Rewards Max            -0.00832281
exploration/Rewards Min            -9.69849
exploration/Returns Mean          -32.4692
exploration/Returns Std            15.0879
exploration/Returns Max           -12.4138
exploration/Returns Min           -59.1298
exploration/Actions Mean           -0.0241631
exploration/Actions Std             0.248697
exploration/Actions Max             0.998069
exploration/Actions Min            -0.997949
exploration/Num Paths               5
exploration/Average Returns       -32.4692
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.199241
evaluation/Rewards Std              0.886203
evaluation/Rewards Max             -0.000744538
evaluation/Rewards Min             -9.15349
evaluation/Returns Mean           -19.9241
evaluation/Returns Std             12.6354
evaluation/Returns Max             -5.12498
evaluation/Returns Min            -44.5663
evaluation/Actions Mean            -0.00103764
evaluation/Actions Std              0.188748
evaluation/Actions Max              0.997269
evaluation/Actions Min             -0.99671
evaluation/Num Paths               15
evaluation/Average Returns        -19.9241
time/data storing (s)               0.00301606
time/evaluation sampling (s)        0.366628
time/exploration sampling (s)       0.156637
time/logging (s)                    0.0048583
time/saving (s)                     0.00159456
time/training (s)                   2.09154
time/epoch (s)                      2.62427
time/total (s)                    525.968
Epoch                             195
-----------------------------  ----------------
2019-04-22 21:30:40.329749 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              98700
trainer/QF1 Loss                    0.0278495
trainer/QF2 Loss                    0.0296608
trainer/Policy Loss                 9.09193
trainer/Q1 Predictions Mean        -7.25748
trainer/Q1 Predictions Std          5.11998
trainer/Q1 Predictions Max         -6.25773
trainer/Q1 Predictions Min        -52.2261
trainer/Q2 Predictions Mean        -7.24872
trainer/Q2 Predictions Std          5.15466
trainer/Q2 Predictions Max         -6.274
trainer/Q2 Predictions Min        -52.5815
trainer/Q Targets Mean             -7.33476
trainer/Q Targets Std               5.07149
trainer/Q Targets Max              -6.22508
trainer/Q Targets Min             -51.7297
trainer/Log Pis Mean                1.86312
trainer/Log Pis Std                 0.974332
trainer/Log Pis Max                 4.80169
trainer/Log Pis Min                -0.767687
trainer/Policy mu Mean              0.0060066
trainer/Policy mu Std               0.487118
trainer/Policy mu Max               3.01891
trainer/Policy mu Min              -3.06399
trainer/Policy log std Mean        -2.23065
trainer/Policy log std Std          0.352267
trainer/Policy log std Max         -0.563971
trainer/Policy log std Min         -2.47534
trainer/Alpha                       0.0519572
trainer/Alpha Loss                 -0.404784
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.328418
exploration/Rewards Std             1.00323
exploration/Rewards Max            -0.00198111
exploration/Rewards Min            -8.36116
exploration/Returns Mean          -32.8418
exploration/Returns Std            14.3805
exploration/Returns Max           -11.2375
exploration/Returns Min           -50.6665
exploration/Actions Mean            0.0158617
exploration/Actions Std             0.243696
exploration/Actions Max             0.999763
exploration/Actions Min            -0.999243
exploration/Num Paths               5
exploration/Average Returns       -32.8418
evaluation/num steps total     295500
evaluation/num paths total       2955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.25676
evaluation/Rewards Std              1.06088
evaluation/Rewards Max             -0.00819675
evaluation/Rewards Min             -9.86517
evaluation/Returns Mean           -25.676
evaluation/Returns Std             17.9449
evaluation/Returns Max             -1.79581
evaluation/Returns Min            -54.7751
evaluation/Actions Mean            -0.00544559
evaluation/Actions Std              0.200274
evaluation/Actions Max              0.997656
evaluation/Actions Min             -0.998271
evaluation/Num Paths               15
evaluation/Average Returns        -25.676
time/data storing (s)               0.00299298
time/evaluation sampling (s)        0.346924
time/exploration sampling (s)       0.154778
time/logging (s)                    0.0049428
time/saving (s)                     0.00256254
time/training (s)                   2.09227
time/epoch (s)                      2.60447
time/total (s)                    528.578
Epoch                             196
-----------------------------  ---------------
2019-04-22 21:30:43.025589 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 197 finished
-----------------------------  ----------------
replay_buffer/size              99200
trainer/QF1 Loss                    0.394105
trainer/QF2 Loss                    0.390911
trainer/Policy Loss                 9.63405
trainer/Q1 Predictions Mean        -7.66114
trainer/Q1 Predictions Std          5.08185
trainer/Q1 Predictions Max         -6.12088
trainer/Q1 Predictions Min        -43.5356
trainer/Q2 Predictions Mean        -7.68724
trainer/Q2 Predictions Std          5.05623
trainer/Q2 Predictions Max         -6.18947
trainer/Q2 Predictions Min        -43.5186
trainer/Q Targets Mean             -7.67397
trainer/Q Targets Std               5.11125
trainer/Q Targets Max              -0.084847
trainer/Q Targets Min             -43.7029
trainer/Log Pis Mean                2.0736
trainer/Log Pis Std                 1.30553
trainer/Log Pis Max                 6.47132
trainer/Log Pis Min                -2.59699
trainer/Policy mu Mean             -0.000657735
trainer/Policy mu Std               0.66752
trainer/Policy mu Max               3.02308
trainer/Policy mu Min              -2.87013
trainer/Policy log std Mean        -2.18482
trainer/Policy log std Std          0.467798
trainer/Policy log std Max         -0.492843
trainer/Policy log std Min         -2.46024
trainer/Alpha                       0.0553341
trainer/Alpha Loss                  0.213046
exploration/num steps total     99200
exploration/num paths total       992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354734
exploration/Rewards Std             1.11753
exploration/Rewards Max            -0.00848584
exploration/Rewards Min           -10.1474
exploration/Returns Mean          -35.4734
exploration/Returns Std            16.9761
exploration/Returns Max           -17.9417
exploration/Returns Min           -60.3171
exploration/Actions Mean           -0.026906
exploration/Actions Std             0.249019
exploration/Actions Max             0.998629
exploration/Actions Min            -0.998681
exploration/Num Paths               5
exploration/Average Returns       -35.4734
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247717
evaluation/Rewards Std              1.10437
evaluation/Rewards Max             -0.0141303
evaluation/Rewards Min             -9.91886
evaluation/Returns Mean           -24.7717
evaluation/Returns Std             16.2135
evaluation/Returns Max             -5.25785
evaluation/Returns Min            -51.1104
evaluation/Actions Mean            -0.00374526
evaluation/Actions Std              0.207008
evaluation/Actions Max              0.997312
evaluation/Actions Min             -0.996613
evaluation/Num Paths               15
evaluation/Average Returns        -24.7717
time/data storing (s)               0.00316785
time/evaluation sampling (s)        0.339628
time/exploration sampling (s)       0.155536
time/logging (s)                    0.00515771
time/saving (s)                     0.00182914
time/training (s)                   2.18365
time/epoch (s)                      2.68897
time/total (s)                    531.271
Epoch                             197
-----------------------------  ----------------
2019-04-22 21:30:45.707289 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              99700
trainer/QF1 Loss                    0.839273
trainer/QF2 Loss                    0.856274
trainer/Policy Loss                 9.47434
trainer/Q1 Predictions Mean        -7.64415
trainer/Q1 Predictions Std          5.68686
trainer/Q1 Predictions Max         -6.19487
trainer/Q1 Predictions Min        -46.8483
trainer/Q2 Predictions Mean        -7.61385
trainer/Q2 Predictions Std          5.66573
trainer/Q2 Predictions Max         -6.22474
trainer/Q2 Predictions Min        -47.0854
trainer/Q Targets Mean             -7.56153
trainer/Q Targets Std               5.82049
trainer/Q Targets Max              -0.218425
trainer/Q Targets Min             -46.108
trainer/Log Pis Mean                2.03276
trainer/Log Pis Std                 1.48774
trainer/Log Pis Max                 8.49375
trainer/Log Pis Min                -2.44776
trainer/Policy mu Mean              0.0136483
trainer/Policy mu Std               0.617348
trainer/Policy mu Max               3.04007
trainer/Policy mu Min              -3.09549
trainer/Policy log std Mean        -2.22343
trainer/Policy log std Std          0.422037
trainer/Policy log std Max         -0.485006
trainer/Policy log std Min         -2.4865
trainer/Alpha                       0.0556843
trainer/Alpha Loss                  0.0946274
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.374928
exploration/Rewards Std             1.10747
exploration/Rewards Max            -0.00288049
exploration/Rewards Min            -9.36702
exploration/Returns Mean          -37.4928
exploration/Returns Std            11.3699
exploration/Returns Max           -26.315
exploration/Returns Min           -58.0929
exploration/Actions Mean            0.0298567
exploration/Actions Std             0.245676
exploration/Actions Max             0.996228
exploration/Actions Min            -0.992276
exploration/Num Paths               5
exploration/Average Returns       -37.4928
evaluation/num steps total     298500
evaluation/num paths total       2985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.161916
evaluation/Rewards Std              0.721441
evaluation/Rewards Max             -0.0061384
evaluation/Rewards Min            -10.7937
evaluation/Returns Mean           -16.1916
evaluation/Returns Std             14.6369
evaluation/Returns Max             -5.57575
evaluation/Returns Min            -62.0857
evaluation/Actions Mean            -0.00875778
evaluation/Actions Std              0.159313
evaluation/Actions Max              0.991855
evaluation/Actions Min             -0.996769
evaluation/Num Paths               15
evaluation/Average Returns        -16.1916
time/data storing (s)               0.00322662
time/evaluation sampling (s)        0.366474
time/exploration sampling (s)       0.165457
time/logging (s)                    0.00458348
time/saving (s)                     0.00208221
time/training (s)                   2.13079
time/epoch (s)                      2.67262
time/total (s)                    533.948
Epoch                             198
-----------------------------  ---------------
2019-04-22 21:30:48.510588 PDT | [sac-pointmass-multitask-2_2019_04_22_21_21_51_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.812553
trainer/QF2 Loss                    0.801711
trainer/Policy Loss                 8.83009
trainer/Q1 Predictions Mean        -7.05632
trainer/Q1 Predictions Std          3.05398
trainer/Q1 Predictions Max         -6.31857
trainer/Q1 Predictions Min        -28.4839
trainer/Q2 Predictions Mean        -7.05096
trainer/Q2 Predictions Std          3.06313
trainer/Q2 Predictions Max         -6.29296
trainer/Q2 Predictions Min        -28.4421
trainer/Q Targets Mean             -6.95834
trainer/Q Targets Std               3.18521
trainer/Q Targets Max              -0.0305302
trainer/Q Targets Min             -28.351
trainer/Log Pis Mean                1.77401
trainer/Log Pis Std                 1.23545
trainer/Log Pis Max                 4.85109
trainer/Log Pis Min                -2.77973
trainer/Policy mu Mean             -0.0243653
trainer/Policy mu Std               0.519909
trainer/Policy mu Max               2.95512
trainer/Policy mu Min              -2.92463
trainer/Policy log std Mean        -2.20914
trainer/Policy log std Std          0.385525
trainer/Policy log std Max         -0.381425
trainer/Policy log std Min         -2.46853
trainer/Alpha                       0.0541897
trainer/Alpha Loss                 -0.658815
exploration/num steps total    100200
exploration/num paths total      1002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.212602
exploration/Rewards Std             0.553973
exploration/Rewards Max            -0.00544009
exploration/Rewards Min            -5.62574
exploration/Returns Mean          -21.2602
exploration/Returns Std             6.84317
exploration/Returns Max           -14.0887
exploration/Returns Min           -31.4453
exploration/Actions Mean           -0.002631
exploration/Actions Std             0.211445
exploration/Actions Max             0.99933
exploration/Actions Min            -0.998216
exploration/Num Paths               5
exploration/Average Returns       -21.2602
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.21125
evaluation/Rewards Std              0.988764
evaluation/Rewards Max             -0.00322123
evaluation/Rewards Min            -10.1431
evaluation/Returns Mean           -21.125
evaluation/Returns Std             17.7266
evaluation/Returns Max             -0.987327
evaluation/Returns Min            -57.5669
evaluation/Actions Mean             0.002669
evaluation/Actions Std              0.183928
evaluation/Actions Max              0.997523
evaluation/Actions Min             -0.997979
evaluation/Num Paths               15
evaluation/Average Returns        -21.125
time/data storing (s)               0.00322957
time/evaluation sampling (s)        0.362825
time/exploration sampling (s)       0.166037
time/logging (s)                    0.00479783
time/saving (s)                     0.00208414
time/training (s)                   2.25686
time/epoch (s)                      2.79583
time/total (s)                    536.749
Epoch                             199
-----------------------------  ---------------
