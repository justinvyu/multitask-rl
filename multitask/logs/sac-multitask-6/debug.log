2019-04-22 22:36:36.767703 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  51.5913
trainer/QF2 Loss                  51.5783
trainer/Policy Loss               -1.36926
trainer/Q1 Predictions Mean        0.00139074
trainer/Q1 Predictions Std         0.00120055
trainer/Q1 Predictions Max         0.00414445
trainer/Q1 Predictions Min        -0.000377617
trainer/Q2 Predictions Mean        0.000561892
trainer/Q2 Predictions Std         0.000793453
trainer/Q2 Predictions Max         0.00248173
trainer/Q2 Predictions Min        -0.00134328
trainer/Q Targets Mean            -6.45738
trainer/Q Targets Std              3.14206
trainer/Q Targets Max             -0.249267
trainer/Q Targets Min            -12.3335
trainer/Log Pis Mean              -1.36875
trainer/Log Pis Std                0.381086
trainer/Log Pis Max               -0.691127
trainer/Log Pis Min               -2.92248
trainer/Policy mu Mean             0.000723987
trainer/Policy mu Std              0.00112759
trainer/Policy mu Max              0.00284849
trainer/Policy mu Min             -0.00126428
trainer/Policy log std Mean       -0.000119787
trainer/Policy log std Std         0.00151343
trainer/Policy log std Max         0.0023029
trainer/Policy log std Min        -0.00306191
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -6.19161
exploration/Rewards Std            3.32114
exploration/Rewards Max           -0.224885
exploration/Rewards Min          -13.3099
exploration/Returns Mean        -619.161
exploration/Returns Std          276.713
exploration/Returns Max         -215.693
exploration/Returns Min         -959.855
exploration/Actions Mean           0.0286801
exploration/Actions Std            0.629467
exploration/Actions Max            0.998129
exploration/Actions Min           -0.996603
exploration/Num Paths              5
exploration/Average Returns     -619.161
evaluation/num steps total      1500
evaluation/num paths total        15
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -5.49944
evaluation/Rewards Std             3.02255
evaluation/Rewards Max            -1.52215
evaluation/Rewards Min           -10.1132
evaluation/Returns Mean         -549.944
evaluation/Returns Std           302.236
evaluation/Returns Max          -152.296
evaluation/Returns Min         -1008.14
evaluation/Actions Mean            0.000761983
evaluation/Actions Std             0.0010428
evaluation/Actions Max             0.00272713
evaluation/Actions Min            -0.00118957
evaluation/Num Paths              15
evaluation/Average Returns      -549.944
time/data storing (s)              0.00276869
time/evaluation sampling (s)       0.286358
time/exploration sampling (s)      0.139536
time/logging (s)                   0.00500436
time/saving (s)                    0.0026305
time/training (s)                  2.00034
time/epoch (s)                     2.43663
time/total (s)                     2.64535
Epoch                              0
-----------------------------  ---------------
2019-04-22 22:36:39.277496 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size              1200
trainer/QF1 Loss                   4.70454
trainer/QF2 Loss                   5.30892
trainer/Policy Loss               10.9475
trainer/Q1 Predictions Mean      -12.4546
trainer/Q1 Predictions Std         3.40425
trainer/Q1 Predictions Max        -6.23231
trainer/Q1 Predictions Min       -21.0544
trainer/Q2 Predictions Mean      -12.378
trainer/Q2 Predictions Std         3.44415
trainer/Q2 Predictions Max        -5.8742
trainer/Q2 Predictions Min       -21.0309
trainer/Q Targets Mean           -12.9304
trainer/Q Targets Std              4.18919
trainer/Q Targets Max             -5.65753
trainer/Q Targets Min            -22.3799
trainer/Log Pis Mean              -1.10789
trainer/Log Pis Std                0.615425
trainer/Log Pis Max                0.621338
trainer/Log Pis Min               -3.07181
trainer/Policy mu Mean            -0.0711962
trainer/Policy mu Std              0.357335
trainer/Policy mu Max              0.744653
trainer/Policy mu Min             -0.532096
trainer/Policy log std Mean       -0.228072
trainer/Policy log std Std         0.0271585
trainer/Policy log std Max        -0.157293
trainer/Policy log std Min        -0.30752
trainer/Alpha                      0.862379
trainer/Alpha Loss                -0.459274
exploration/num steps total     1200
exploration/num paths total       12
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -6.53649
exploration/Rewards Std            2.51353
exploration/Rewards Max           -0.118857
exploration/Rewards Min          -11.2703
exploration/Returns Mean        -653.649
exploration/Returns Std          184.346
exploration/Returns Max         -319.159
exploration/Returns Min         -876.613
exploration/Actions Mean          -0.0527699
exploration/Actions Std            0.571737
exploration/Actions Max            0.993466
exploration/Actions Min           -0.992058
exploration/Num Paths              5
exploration/Average Returns     -653.649
evaluation/num steps total      3000
evaluation/num paths total        30
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -7.31096
evaluation/Rewards Std             3.02584
evaluation/Rewards Max            -1.09596
evaluation/Rewards Min           -11.335
evaluation/Returns Mean         -731.096
evaluation/Returns Std           273.166
evaluation/Returns Max          -173.419
evaluation/Returns Min         -1126.19
evaluation/Actions Mean           -0.0854903
evaluation/Actions Std             0.153269
evaluation/Actions Max             0.617161
evaluation/Actions Min            -0.471472
evaluation/Num Paths              15
evaluation/Average Returns      -731.096
time/data storing (s)              0.0029555
time/evaluation sampling (s)       0.356633
time/exploration sampling (s)      0.145718
time/logging (s)                   0.00483248
time/saving (s)                    0.00159842
time/training (s)                  1.99209
time/epoch (s)                     2.50383
time/total (s)                     5.15414
Epoch                              1
-----------------------------  --------------
2019-04-22 22:36:41.706282 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size             1700
trainer/QF1 Loss                  5.7272
trainer/QF2 Loss                  6.35716
trainer/Policy Loss              18.389
trainer/Q1 Predictions Mean     -19.9456
trainer/Q1 Predictions Std        8.46277
trainer/Q1 Predictions Max      -10.9576
trainer/Q1 Predictions Min      -41.5824
trainer/Q2 Predictions Mean     -19.8062
trainer/Q2 Predictions Std        8.60749
trainer/Q2 Predictions Max      -10.6266
trainer/Q2 Predictions Min      -42.2328
trainer/Q Targets Mean          -20.24
trainer/Q Targets Std             8.57184
trainer/Q Targets Max            -5.08338
trainer/Q Targets Min           -43.8495
trainer/Log Pis Mean             -0.69491
trainer/Log Pis Std               1.04233
trainer/Log Pis Max               1.88706
trainer/Log Pis Min              -3.6623
trainer/Policy mu Mean            0.0153067
trainer/Policy mu Std             0.619515
trainer/Policy mu Max             1.52498
trainer/Policy mu Min            -1.28682
trainer/Policy log std Mean      -0.33195
trainer/Policy log std Std        0.0673468
trainer/Policy log std Max       -0.19205
trainer/Policy log std Min       -0.527914
trainer/Alpha                     0.751796
trainer/Alpha Loss               -0.768143
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.10114
exploration/Rewards Std           1.17659
exploration/Rewards Max          -1.25487
exploration/Rewards Min          -8.56728
exploration/Returns Mean       -410.114
exploration/Returns Std          59.6185
exploration/Returns Max        -309.758
exploration/Returns Min        -497.114
exploration/Actions Mean          0.0144808
exploration/Actions Std           0.558501
exploration/Actions Max           0.989376
exploration/Actions Min          -0.981412
exploration/Num Paths             5
exploration/Average Returns    -410.114
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.3534
evaluation/Rewards Std            1.08787
evaluation/Rewards Max           -2.22875
evaluation/Rewards Min          -11.5435
evaluation/Returns Mean        -435.34
evaluation/Returns Std           97.9203
evaluation/Returns Max         -268.432
evaluation/Returns Min         -553.35
evaluation/Actions Mean          -0.00331087
evaluation/Actions Std            0.11117
evaluation/Actions Max            0.772885
evaluation/Actions Min           -0.853329
evaluation/Num Paths             15
evaluation/Average Returns     -435.34
time/data storing (s)             0.00284581
time/evaluation sampling (s)      0.329703
time/exploration sampling (s)     0.138981
time/logging (s)                  0.00549538
time/saving (s)                   0.00201034
time/training (s)                 1.94543
time/epoch (s)                    2.42447
time/total (s)                    7.58285
Epoch                             2
-----------------------------  -------------
2019-04-22 22:36:44.218177 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             2200
trainer/QF1 Loss                  0.994863
trainer/QF2 Loss                  1.14216
trainer/Policy Loss              27.2122
trainer/Q1 Predictions Mean     -28.821
trainer/Q1 Predictions Std       10.4425
trainer/Q1 Predictions Max      -16.2691
trainer/Q1 Predictions Min      -53.3745
trainer/Q2 Predictions Mean     -28.85
trainer/Q2 Predictions Std       10.5879
trainer/Q2 Predictions Max      -15.8311
trainer/Q2 Predictions Min      -53.6225
trainer/Q Targets Mean          -28.7453
trainer/Q Targets Std            10.6022
trainer/Q Targets Max           -16.3039
trainer/Q Targets Min           -54.3165
trainer/Log Pis Mean             -0.561789
trainer/Log Pis Std               1.13399
trainer/Log Pis Max               2.08833
trainer/Log Pis Min              -3.60938
trainer/Policy mu Mean            0.20993
trainer/Policy mu Std             0.723327
trainer/Policy mu Max             1.72587
trainer/Policy mu Min            -1.42167
trainer/Policy log std Mean      -0.40797
trainer/Policy log std Std        0.075797
trainer/Policy log std Max       -0.213718
trainer/Policy log std Min       -0.544977
trainer/Alpha                     0.660284
trainer/Alpha Loss               -1.06272
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.47233
exploration/Rewards Std           1.15826
exploration/Rewards Max          -0.127496
exploration/Rewards Min          -7.01487
exploration/Returns Mean       -247.233
exploration/Returns Std          72.1381
exploration/Returns Max        -195.236
exploration/Returns Min        -390.214
exploration/Actions Mean          0.0084677
exploration/Actions Std           0.545452
exploration/Actions Max           0.966427
exploration/Actions Min          -0.983613
exploration/Num Paths             5
exploration/Average Returns    -247.233
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.10267
evaluation/Rewards Std            1.52234
evaluation/Rewards Max           -0.887299
evaluation/Rewards Min          -11.6177
evaluation/Returns Mean        -310.267
evaluation/Returns Std          133.015
evaluation/Returns Max         -123.657
evaluation/Returns Min         -470.979
evaluation/Actions Mean          -0.00395166
evaluation/Actions Std            0.14329
evaluation/Actions Max            0.898657
evaluation/Actions Min           -0.909807
evaluation/Num Paths             15
evaluation/Average Returns     -310.267
time/data storing (s)             0.0027883
time/evaluation sampling (s)      0.332945
time/exploration sampling (s)     0.139234
time/logging (s)                  0.00484577
time/saving (s)                   0.00158227
time/training (s)                 2.02465
time/epoch (s)                    2.50604
time/total (s)                   10.0933
Epoch                             3
-----------------------------  -------------
2019-04-22 22:36:46.634603 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                 22.5745
trainer/QF2 Loss                 22.5488
trainer/Policy Loss              31.4507
trainer/Q1 Predictions Mean     -33.5103
trainer/Q1 Predictions Std       12.5176
trainer/Q1 Predictions Max      -18.7195
trainer/Q1 Predictions Min      -65.4489
trainer/Q2 Predictions Mean     -33.5708
trainer/Q2 Predictions Std       12.536
trainer/Q2 Predictions Max      -19.0084
trainer/Q2 Predictions Min      -65.4643
trainer/Q Targets Mean          -33.6196
trainer/Q Targets Std            12.9782
trainer/Q Targets Max            -8.13337
trainer/Q Targets Min           -69.1418
trainer/Log Pis Mean             -0.352502
trainer/Log Pis Std               1.22151
trainer/Log Pis Max               2.44029
trainer/Log Pis Min              -3.18225
trainer/Policy mu Mean            0.121567
trainer/Policy mu Std             0.781499
trainer/Policy mu Max             1.71813
trainer/Policy mu Min            -1.59665
trainer/Policy log std Mean      -0.471392
trainer/Policy log std Std        0.0791537
trainer/Policy log std Max       -0.259239
trainer/Policy log std Min       -0.658615
trainer/Alpha                     0.580834
trainer/Alpha Loss               -1.27751
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.26123
exploration/Rewards Std           1.45262
exploration/Rewards Max          -0.102926
exploration/Rewards Min          -9.3338
exploration/Returns Mean       -226.123
exploration/Returns Std         111.293
exploration/Returns Max        -126.841
exploration/Returns Min        -413.036
exploration/Actions Mean          0.018853
exploration/Actions Std           0.528183
exploration/Actions Max           0.985382
exploration/Actions Min          -0.985046
exploration/Num Paths             5
exploration/Average Returns    -226.123
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -2.07044
evaluation/Rewards Std            1.2037
evaluation/Rewards Max           -0.45714
evaluation/Rewards Min          -10.4143
evaluation/Returns Mean        -207.044
evaluation/Returns Std           92.299
evaluation/Returns Max         -107.363
evaluation/Returns Min         -396.587
evaluation/Actions Mean           0.00147908
evaluation/Actions Std            0.151219
evaluation/Actions Max            0.953349
evaluation/Actions Min           -0.943602
evaluation/Num Paths             15
evaluation/Average Returns     -207.044
time/data storing (s)             0.00293397
time/evaluation sampling (s)      0.3307
time/exploration sampling (s)     0.138707
time/logging (s)                  0.00487567
time/saving (s)                   0.00190858
time/training (s)                 1.93242
time/epoch (s)                    2.41155
time/total (s)                   12.5091
Epoch                             4
-----------------------------  -------------
2019-04-22 22:36:49.070023 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             3200
trainer/QF1 Loss                 48.2969
trainer/QF2 Loss                 48.2242
trainer/Policy Loss              34.1732
trainer/Q1 Predictions Mean     -36.1349
trainer/Q1 Predictions Std       16.3986
trainer/Q1 Predictions Max      -20.148
trainer/Q1 Predictions Min      -78.58
trainer/Q2 Predictions Mean     -36.1862
trainer/Q2 Predictions Std       16.3663
trainer/Q2 Predictions Max      -20.2815
trainer/Q2 Predictions Min      -78.7153
trainer/Q Targets Mean          -35.9138
trainer/Q Targets Std            16.6654
trainer/Q Targets Max            -1.18396
trainer/Q Targets Min           -77.9219
trainer/Log Pis Mean              0.121953
trainer/Log Pis Std               1.36261
trainer/Log Pis Max               3.16992
trainer/Log Pis Min              -4.82908
trainer/Policy mu Mean            0.118025
trainer/Policy mu Std             0.87858
trainer/Policy mu Max             1.7408
trainer/Policy mu Min            -1.88262
trainer/Policy log std Mean      -0.573997
trainer/Policy log std Std        0.0874791
trainer/Policy log std Max       -0.324538
trainer/Policy log std Min       -0.737664
trainer/Alpha                     0.510586
trainer/Alpha Loss               -1.26195
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.03134
exploration/Rewards Std           0.830631
exploration/Rewards Max          -0.0417661
exploration/Rewards Min          -8.91416
exploration/Returns Mean       -103.134
exploration/Returns Std          10.1677
exploration/Returns Max         -90.9097
exploration/Returns Min        -117.695
exploration/Actions Mean         -0.00910705
exploration/Actions Std           0.488142
exploration/Actions Max           0.981891
exploration/Actions Min          -0.994818
exploration/Num Paths             5
exploration/Average Returns    -103.134
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.36703
evaluation/Rewards Std            1.19129
evaluation/Rewards Max           -0.268914
evaluation/Rewards Min          -10.3608
evaluation/Returns Mean        -136.703
evaluation/Returns Std           78.6555
evaluation/Returns Max          -61.8287
evaluation/Returns Min         -288.442
evaluation/Actions Mean           0.0106919
evaluation/Actions Std            0.165305
evaluation/Actions Max            0.950339
evaluation/Actions Min           -0.96019
evaluation/Num Paths             15
evaluation/Average Returns     -136.703
time/data storing (s)             0.00303211
time/evaluation sampling (s)      0.324279
time/exploration sampling (s)     0.146513
time/logging (s)                  0.00478475
time/saving (s)                   0.00195069
time/training (s)                 1.94981
time/epoch (s)                    2.43037
time/total (s)                   14.9436
Epoch                             5
-----------------------------  -------------
2019-04-22 22:36:51.506031 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                  38.6859
trainer/QF2 Loss                  38.9741
trainer/Policy Loss               34.6126
trainer/Q1 Predictions Mean      -36.1265
trainer/Q1 Predictions Std        15.9214
trainer/Q1 Predictions Max       -21.7083
trainer/Q1 Predictions Min       -80.5538
trainer/Q2 Predictions Mean      -36.139
trainer/Q2 Predictions Std        15.9709
trainer/Q2 Predictions Max       -21.8073
trainer/Q2 Predictions Min       -80.6195
trainer/Q Targets Mean           -35.7732
trainer/Q Targets Std             15.6458
trainer/Q Targets Max             -8.13337
trainer/Q Targets Min            -80.2991
trainer/Log Pis Mean               0.190969
trainer/Log Pis Std                1.48387
trainer/Log Pis Max                3.57247
trainer/Log Pis Min               -3.5508
trainer/Policy mu Mean             0.122633
trainer/Policy mu Std              0.865298
trainer/Policy mu Max              2.17829
trainer/Policy mu Min             -1.79371
trainer/Policy log std Mean       -0.654123
trainer/Policy log std Std         0.106983
trainer/Policy log std Max        -0.318515
trainer/Policy log std Min        -0.819235
trainer/Alpha                      0.448595
trainer/Alpha Loss                -1.44973
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.61837
exploration/Rewards Std            1.41094
exploration/Rewards Max           -0.0389405
exploration/Rewards Min           -9.29293
exploration/Returns Mean        -161.837
exploration/Returns Std           99.0117
exploration/Returns Max         -107.68
exploration/Returns Min         -359.611
exploration/Actions Mean           0.00882357
exploration/Actions Std            0.49542
exploration/Actions Max            0.990005
exploration/Actions Min           -0.963571
exploration/Num Paths              5
exploration/Average Returns     -161.837
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.55734
evaluation/Rewards Std             1.41808
evaluation/Rewards Max            -0.176543
evaluation/Rewards Min           -10.3971
evaluation/Returns Mean         -155.734
evaluation/Returns Std           116.186
evaluation/Returns Max           -27.0926
evaluation/Returns Min          -376.267
evaluation/Actions Mean           -0.00535075
evaluation/Actions Std             0.160654
evaluation/Actions Max             0.948303
evaluation/Actions Min            -0.966876
evaluation/Num Paths              15
evaluation/Average Returns      -155.734
time/data storing (s)              0.00288662
time/evaluation sampling (s)       0.333066
time/exploration sampling (s)      0.142842
time/logging (s)                   0.00491807
time/saving (s)                    0.00195798
time/training (s)                  1.94497
time/epoch (s)                     2.43064
time/total (s)                    17.379
Epoch                              6
-----------------------------  --------------
2019-04-22 22:36:53.937941 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   1.11356
trainer/QF2 Loss                   1.09101
trainer/Policy Loss               41.4245
trainer/Q1 Predictions Mean      -43.0101
trainer/Q1 Predictions Std        19.5355
trainer/Q1 Predictions Max       -22.5488
trainer/Q1 Predictions Min       -86.5755
trainer/Q2 Predictions Mean      -43.0459
trainer/Q2 Predictions Std        19.5372
trainer/Q2 Predictions Max       -22.4164
trainer/Q2 Predictions Min       -86.5049
trainer/Q Targets Mean           -43.2465
trainer/Q Targets Std             19.7813
trainer/Q Targets Max            -22.3327
trainer/Q Targets Min            -90.4353
trainer/Log Pis Mean               0.163418
trainer/Log Pis Std                1.7196
trainer/Log Pis Max                4.4028
trainer/Log Pis Min               -4.27115
trainer/Policy mu Mean             0.110572
trainer/Policy mu Std              0.876761
trainer/Policy mu Max              2.25545
trainer/Policy mu Min             -1.88834
trainer/Policy log std Mean       -0.67
trainer/Policy log std Std         0.14457
trainer/Policy log std Max        -0.412071
trainer/Policy log std Min        -0.900089
trainer/Alpha                      0.393913
trainer/Alpha Loss                -1.71053
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.55282
exploration/Rewards Std            1.53662
exploration/Rewards Max           -0.0703267
exploration/Rewards Min           -6.90381
exploration/Returns Mean        -255.282
exploration/Returns Std          130.576
exploration/Returns Max          -84.3479
exploration/Returns Min         -393.362
exploration/Actions Mean           0.0113198
exploration/Actions Std            0.473247
exploration/Actions Max            0.98667
exploration/Actions Min           -0.979085
exploration/Num Paths              5
exploration/Average Returns     -255.282
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.338
evaluation/Rewards Std             1.53807
evaluation/Rewards Max            -0.237688
evaluation/Rewards Min           -10.3713
evaluation/Returns Mean         -133.8
evaluation/Returns Std           119.288
evaluation/Returns Max           -42.133
evaluation/Returns Min          -374.908
evaluation/Actions Mean            0.0067575
evaluation/Actions Std             0.182492
evaluation/Actions Max             0.981324
evaluation/Actions Min            -0.970933
evaluation/Num Paths              15
evaluation/Average Returns      -133.8
time/data storing (s)              0.00294414
time/evaluation sampling (s)       0.33031
time/exploration sampling (s)      0.144133
time/logging (s)                   0.00482876
time/saving (s)                    0.00194176
time/training (s)                  1.94266
time/epoch (s)                     2.42682
time/total (s)                    19.81
Epoch                              7
-----------------------------  --------------
2019-04-22 22:36:56.383476 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                  78.7694
trainer/QF2 Loss                  79.9527
trainer/Policy Loss               39.9698
trainer/Q1 Predictions Mean      -41.7118
trainer/Q1 Predictions Std        19.6489
trainer/Q1 Predictions Max       -22.5601
trainer/Q1 Predictions Min       -96.6314
trainer/Q2 Predictions Mean      -41.7215
trainer/Q2 Predictions Std        19.6781
trainer/Q2 Predictions Max       -22.3272
trainer/Q2 Predictions Min       -96.256
trainer/Q Targets Mean           -40.352
trainer/Q Targets Std             20.6799
trainer/Q Targets Max             -1.48723
trainer/Q Targets Min            -99.0838
trainer/Log Pis Mean               0.132575
trainer/Log Pis Std                1.42432
trainer/Log Pis Max                3.63572
trainer/Log Pis Min               -5.15167
trainer/Policy mu Mean             0.0751102
trainer/Policy mu Std              0.83325
trainer/Policy mu Max              1.99789
trainer/Policy mu Min             -2.17759
trainer/Policy log std Mean       -0.734945
trainer/Policy log std Std         0.151946
trainer/Policy log std Max        -0.384803
trainer/Policy log std Min        -0.929615
trainer/Alpha                      0.345423
trainer/Alpha Loss                -1.98454
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.21478
exploration/Rewards Std            1.27847
exploration/Rewards Max           -0.0829328
exploration/Rewards Min           -7.63856
exploration/Returns Mean        -221.478
exploration/Returns Std          105.036
exploration/Returns Max          -76.9929
exploration/Returns Min         -315.096
exploration/Actions Mean           0.00227966
exploration/Actions Std            0.479746
exploration/Actions Max            0.986894
exploration/Actions Min           -0.982848
exploration/Num Paths              5
exploration/Average Returns     -221.478
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.71189
evaluation/Rewards Std             1.31718
evaluation/Rewards Max            -0.430488
evaluation/Rewards Min            -9.90666
evaluation/Returns Mean         -171.189
evaluation/Returns Std           103.26
evaluation/Returns Max           -43.8835
evaluation/Returns Min          -309.566
evaluation/Actions Mean            0.0197939
evaluation/Actions Std             0.168051
evaluation/Actions Max             0.973315
evaluation/Actions Min            -0.952107
evaluation/Num Paths              15
evaluation/Average Returns      -171.189
time/data storing (s)              0.00299053
time/evaluation sampling (s)       0.328269
time/exploration sampling (s)      0.143588
time/logging (s)                   0.00482688
time/saving (s)                    0.0019327
time/training (s)                  1.95886
time/epoch (s)                     2.44047
time/total (s)                    22.2547
Epoch                              8
-----------------------------  --------------
2019-04-22 22:36:58.872276 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                  37.8544
trainer/QF2 Loss                  37.8876
trainer/Policy Loss               39.4674
trainer/Q1 Predictions Mean      -41.0932
trainer/Q1 Predictions Std        20.2485
trainer/Q1 Predictions Max       -22.9337
trainer/Q1 Predictions Min      -104.804
trainer/Q2 Predictions Mean      -41.0547
trainer/Q2 Predictions Std        20.2318
trainer/Q2 Predictions Max       -22.8139
trainer/Q2 Predictions Min      -104.622
trainer/Q Targets Mean           -39.9678
trainer/Q Targets Std             22.1561
trainer/Q Targets Max             -0.581778
trainer/Q Targets Min           -105.792
trainer/Log Pis Mean               0.0511193
trainer/Log Pis Std                1.48393
trainer/Log Pis Max                4.89276
trainer/Log Pis Min               -3.36889
trainer/Policy mu Mean             0.0886089
trainer/Policy mu Std              0.827902
trainer/Policy mu Max              2.20905
trainer/Policy mu Min             -2.31636
trainer/Policy log std Mean       -0.812441
trainer/Policy log std Std         0.190252
trainer/Policy log std Max        -0.378039
trainer/Policy log std Min        -1.10609
trainer/Alpha                      0.302099
trainer/Alpha Loss                -2.33231
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.47604
exploration/Rewards Std            1.25032
exploration/Rewards Max           -0.0266251
exploration/Rewards Min           -7.66814
exploration/Returns Mean        -147.604
exploration/Returns Std          108.889
exploration/Returns Max          -57.5775
exploration/Returns Min         -307.546
exploration/Actions Mean          -0.00948273
exploration/Actions Std            0.461144
exploration/Actions Max            0.994712
exploration/Actions Min           -0.97916
exploration/Num Paths              5
exploration/Average Returns     -147.604
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.64372
evaluation/Rewards Std             1.38759
evaluation/Rewards Max            -0.0603707
evaluation/Rewards Min           -10.0444
evaluation/Returns Mean         -164.372
evaluation/Returns Std           111.443
evaluation/Returns Max           -16.999
evaluation/Returns Min          -300.692
evaluation/Actions Mean            0.00462175
evaluation/Actions Std             0.170357
evaluation/Actions Max             0.986395
evaluation/Actions Min            -0.974148
evaluation/Num Paths              15
evaluation/Average Returns      -164.372
time/data storing (s)              0.00273789
time/evaluation sampling (s)       0.332959
time/exploration sampling (s)      0.146141
time/logging (s)                   0.0048314
time/saving (s)                    0.00194747
time/training (s)                  1.99517
time/epoch (s)                     2.48378
time/total (s)                    24.7427
Epoch                              9
-----------------------------  --------------
2019-04-22 22:37:01.297787 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                  48.1161
trainer/QF2 Loss                  47.6835
trainer/Policy Loss               42.9608
trainer/Q1 Predictions Mean      -44.0495
trainer/Q1 Predictions Std        21.3025
trainer/Q1 Predictions Max       -23.4301
trainer/Q1 Predictions Min       -87.2885
trainer/Q2 Predictions Mean      -44.0042
trainer/Q2 Predictions Std        21.2677
trainer/Q2 Predictions Max       -23.3599
trainer/Q2 Predictions Min       -87.351
trainer/Q Targets Mean           -43.7563
trainer/Q Targets Std             21.9638
trainer/Q Targets Max             -2.10637
trainer/Q Targets Min            -89.3695
trainer/Log Pis Mean               0.0323263
trainer/Log Pis Std                1.56954
trainer/Log Pis Max                4.47424
trainer/Log Pis Min               -4.86778
trainer/Policy mu Mean            -0.0315033
trainer/Policy mu Std              0.909013
trainer/Policy mu Max              2.37445
trainer/Policy mu Min             -2.14474
trainer/Policy log std Mean       -0.815648
trainer/Policy log std Std         0.219794
trainer/Policy log std Max        -0.368812
trainer/Policy log std Min        -1.16281
trainer/Alpha                      0.264433
trainer/Alpha Loss                -2.61681
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.14101
exploration/Rewards Std            1.22545
exploration/Rewards Max           -0.050579
exploration/Rewards Min           -9.63924
exploration/Returns Mean        -114.101
exploration/Returns Std           64.6422
exploration/Returns Max          -57.5351
exploration/Returns Min         -232.422
exploration/Actions Mean          -0.033335
exploration/Actions Std            0.439844
exploration/Actions Max            0.968238
exploration/Actions Min           -0.98702
exploration/Num Paths              5
exploration/Average Returns     -114.101
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.974805
evaluation/Rewards Std             0.9708
evaluation/Rewards Max            -0.17907
evaluation/Rewards Min           -10.0839
evaluation/Returns Mean          -97.4805
evaluation/Returns Std            50.5696
evaluation/Returns Max           -37.1652
evaluation/Returns Min          -222.686
evaluation/Actions Mean            0.0134629
evaluation/Actions Std             0.176643
evaluation/Actions Max             0.988252
evaluation/Actions Min            -0.98053
evaluation/Num Paths              15
evaluation/Average Returns       -97.4805
time/data storing (s)              0.0029549
time/evaluation sampling (s)       0.335232
time/exploration sampling (s)      0.14375
time/logging (s)                   0.00483925
time/saving (s)                    0.00197
time/training (s)                  1.9316
time/epoch (s)                     2.42035
time/total (s)                    27.1674
Epoch                             10
-----------------------------  --------------
2019-04-22 22:37:03.717920 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   7.37625
trainer/QF2 Loss                   7.77554
trainer/Policy Loss               48.0501
trainer/Q1 Predictions Mean      -49.0829
trainer/Q1 Predictions Std        25.3355
trainer/Q1 Predictions Max       -23.3472
trainer/Q1 Predictions Min      -102.184
trainer/Q2 Predictions Mean      -49.0922
trainer/Q2 Predictions Std        25.3538
trainer/Q2 Predictions Max       -23.5243
trainer/Q2 Predictions Min      -102.363
trainer/Q Targets Mean           -49.4032
trainer/Q Targets Std             26.1459
trainer/Q Targets Max             -2.79063
trainer/Q Targets Min           -103.228
trainer/Log Pis Mean               0.424113
trainer/Log Pis Std                1.72355
trainer/Log Pis Max                5.4429
trainer/Log Pis Min               -5.15319
trainer/Policy mu Mean            -0.144865
trainer/Policy mu Std              0.948432
trainer/Policy mu Max              2.05307
trainer/Policy mu Min             -2.38009
trainer/Policy log std Mean       -0.832938
trainer/Policy log std Std         0.229703
trainer/Policy log std Max        -0.381548
trainer/Policy log std Min        -1.20364
trainer/Alpha                      0.231368
trainer/Alpha Loss                -2.30631
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.52288
exploration/Rewards Std            1.4058
exploration/Rewards Max           -0.0927016
exploration/Rewards Min          -11.9609
exploration/Returns Mean        -152.288
exploration/Returns Std           58.2811
exploration/Returns Max          -90.8568
exploration/Returns Min         -262.052
exploration/Actions Mean          -0.0203897
exploration/Actions Std            0.489642
exploration/Actions Max            0.989983
exploration/Actions Min           -0.987862
exploration/Num Paths              5
exploration/Average Returns     -152.288
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.956726
evaluation/Rewards Std             1.11658
evaluation/Rewards Max            -0.0358637
evaluation/Rewards Min           -10.8452
evaluation/Returns Mean          -95.6726
evaluation/Returns Std            64.6158
evaluation/Returns Max           -42.6985
evaluation/Returns Min          -254.569
evaluation/Actions Mean           -0.00326901
evaluation/Actions Std             0.172552
evaluation/Actions Max             0.991816
evaluation/Actions Min            -0.983954
evaluation/Num Paths              15
evaluation/Average Returns       -95.6726
time/data storing (s)              0.00292322
time/evaluation sampling (s)       0.330879
time/exploration sampling (s)      0.144534
time/logging (s)                   0.00479635
time/saving (s)                    0.00194234
time/training (s)                  1.92992
time/epoch (s)                     2.41499
time/total (s)                    29.5866
Epoch                             11
-----------------------------  --------------
2019-04-22 22:37:06.131574 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 12 finished
-----------------------------  ---------------
replay_buffer/size              6700
trainer/QF1 Loss                   1.65452
trainer/QF2 Loss                   1.52053
trainer/Policy Loss               44.1387
trainer/Q1 Predictions Mean      -45.1364
trainer/Q1 Predictions Std        24.2521
trainer/Q1 Predictions Max       -23.0186
trainer/Q1 Predictions Min      -117.837
trainer/Q2 Predictions Mean      -45.1644
trainer/Q2 Predictions Std        24.2501
trainer/Q2 Predictions Max       -22.9077
trainer/Q2 Predictions Min      -117.442
trainer/Q Targets Mean           -46.0053
trainer/Q Targets Std             24.4775
trainer/Q Targets Max            -23.3327
trainer/Q Targets Min           -115.27
trainer/Log Pis Mean               0.614368
trainer/Log Pis Std                1.76931
trainer/Log Pis Max                5.32975
trainer/Log Pis Min               -4.00893
trainer/Policy mu Mean            -0.0245401
trainer/Policy mu Std              1.0141
trainer/Policy mu Max              2.7819
trainer/Policy mu Min             -2.61809
trainer/Policy log std Mean       -0.925587
trainer/Policy log std Std         0.236395
trainer/Policy log std Max        -0.550902
trainer/Policy log std Min        -1.31956
trainer/Alpha                      0.203615
trainer/Alpha Loss                -2.20494
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.18773
exploration/Rewards Std            1.45024
exploration/Rewards Max           -0.0243033
exploration/Rewards Min           -9.15336
exploration/Returns Mean        -118.773
exploration/Returns Std          112.061
exploration/Returns Max          -39.0424
exploration/Returns Min         -341.373
exploration/Actions Mean           0.009896
exploration/Actions Std            0.371325
exploration/Actions Max            0.99
exploration/Actions Min           -0.989495
exploration/Num Paths              5
exploration/Average Returns     -118.773
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.954254
evaluation/Rewards Std             1.208
evaluation/Rewards Max            -0.196176
evaluation/Rewards Min           -10.722
evaluation/Returns Mean          -95.4254
evaluation/Returns Std            64.2454
evaluation/Returns Max           -21.5325
evaluation/Returns Min          -312.085
evaluation/Actions Mean           -0.000216943
evaluation/Actions Std             0.198284
evaluation/Actions Max             0.995467
evaluation/Actions Min            -0.995346
evaluation/Num Paths              15
evaluation/Average Returns       -95.4254
time/data storing (s)              0.00310349
time/evaluation sampling (s)       0.331448
time/exploration sampling (s)      0.144755
time/logging (s)                   0.00482996
time/saving (s)                    0.00217692
time/training (s)                  1.92228
time/epoch (s)                     2.4086
time/total (s)                    31.9994
Epoch                             12
-----------------------------  ---------------
2019-04-22 22:37:08.557937 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                  84.5394
trainer/QF2 Loss                  85.6798
trainer/Policy Loss               44.2881
trainer/Q1 Predictions Mean      -45.1912
trainer/Q1 Predictions Std        24.7819
trainer/Q1 Predictions Max       -23.255
trainer/Q1 Predictions Min       -97.919
trainer/Q2 Predictions Mean      -45.1824
trainer/Q2 Predictions Std        24.8325
trainer/Q2 Predictions Max       -23.1654
trainer/Q2 Predictions Min       -98.0045
trainer/Q Targets Mean           -44.1714
trainer/Q Targets Std             25.2862
trainer/Q Targets Max             -1.03055
trainer/Q Targets Min            -99.5212
trainer/Log Pis Mean               0.427773
trainer/Log Pis Std                1.68387
trainer/Log Pis Max                4.98228
trainer/Log Pis Min               -3.99428
trainer/Policy mu Mean             0.0998054
trainer/Policy mu Std              0.969503
trainer/Policy mu Max              2.74474
trainer/Policy mu Min             -2.39161
trainer/Policy log std Mean       -0.991161
trainer/Policy log std Std         0.25624
trainer/Policy log std Max        -0.503723
trainer/Policy log std Min        -1.41212
trainer/Alpha                      0.180183
trainer/Alpha Loss                -2.69407
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.21806
exploration/Rewards Std            1.45984
exploration/Rewards Max           -0.0311551
exploration/Rewards Min           -9.85771
exploration/Returns Mean        -121.806
exploration/Returns Std           88.8938
exploration/Returns Max          -62.2758
exploration/Returns Min         -298.877
exploration/Actions Mean           0.0259249
exploration/Actions Std            0.388324
exploration/Actions Max            0.994671
exploration/Actions Min           -0.993798
exploration/Num Paths              5
exploration/Average Returns     -121.806
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.981723
evaluation/Rewards Std             1.08069
evaluation/Rewards Max            -0.224262
evaluation/Rewards Min            -8.24259
evaluation/Returns Mean          -98.1723
evaluation/Returns Std            80.3416
evaluation/Returns Max           -28.5009
evaluation/Returns Min          -298.945
evaluation/Actions Mean           -0.00734661
evaluation/Actions Std             0.172794
evaluation/Actions Max             0.975473
evaluation/Actions Min            -0.987434
evaluation/Num Paths              15
evaluation/Average Returns       -98.1723
time/data storing (s)              0.00293085
time/evaluation sampling (s)       0.331076
time/exploration sampling (s)      0.141207
time/logging (s)                   0.00398176
time/saving (s)                    0.00155751
time/training (s)                  1.94006
time/epoch (s)                     2.42082
time/total (s)                    34.4241
Epoch                             13
-----------------------------  --------------
2019-04-22 22:37:10.969782 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                   1.38758
trainer/QF2 Loss                   1.56694
trainer/Policy Loss               46.1008
trainer/Q1 Predictions Mean      -46.3775
trainer/Q1 Predictions Std        25.1785
trainer/Q1 Predictions Max       -22.6405
trainer/Q1 Predictions Min       -98.3602
trainer/Q2 Predictions Mean      -46.3465
trainer/Q2 Predictions Std        25.2133
trainer/Q2 Predictions Max       -22.3532
trainer/Q2 Predictions Min       -98.4809
trainer/Q Targets Mean           -47.1006
trainer/Q Targets Std             25.3674
trainer/Q Targets Max            -23.1847
trainer/Q Targets Min           -100.427
trainer/Log Pis Mean               0.84172
trainer/Log Pis Std                1.45415
trainer/Log Pis Max                5.65889
trainer/Log Pis Min               -3.85143
trainer/Policy mu Mean             0.0703132
trainer/Policy mu Std              0.901817
trainer/Policy mu Max              2.62588
trainer/Policy mu Min             -2.28036
trainer/Policy log std Mean       -1.1127
trainer/Policy log std Std         0.239952
trainer/Policy log std Max        -0.607924
trainer/Policy log std Min        -1.61476
trainer/Alpha                      0.159842
trainer/Alpha Loss                -2.12353
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.935823
exploration/Rewards Std            1.03694
exploration/Rewards Max           -0.0361083
exploration/Rewards Min           -9.73499
exploration/Returns Mean         -93.5823
exploration/Returns Std           26.0555
exploration/Returns Max          -69.2279
exploration/Returns Min         -144.182
exploration/Actions Mean           0.0295139
exploration/Actions Std            0.357569
exploration/Actions Max            0.99889
exploration/Actions Min           -0.924201
exploration/Num Paths              5
exploration/Average Returns      -93.5823
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.02546
evaluation/Rewards Std             0.935059
evaluation/Rewards Max            -0.145924
evaluation/Rewards Min            -8.75194
evaluation/Returns Mean         -102.546
evaluation/Returns Std            65.7902
evaluation/Returns Max           -20.1571
evaluation/Returns Min          -226.585
evaluation/Actions Mean           -0.00204713
evaluation/Actions Std             0.170904
evaluation/Actions Max             0.988876
evaluation/Actions Min            -0.979948
evaluation/Num Paths              15
evaluation/Average Returns      -102.546
time/data storing (s)              0.0029241
time/evaluation sampling (s)       0.330226
time/exploration sampling (s)      0.143927
time/logging (s)                   0.00482777
time/saving (s)                    0.0019448
time/training (s)                  1.92374
time/epoch (s)                     2.40759
time/total (s)                    36.8359
Epoch                             14
-----------------------------  --------------
2019-04-22 22:37:13.411963 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                  68.9795
trainer/QF2 Loss                  69.7808
trainer/Policy Loss               49.531
trainer/Q1 Predictions Mean      -50.0107
trainer/Q1 Predictions Std        27.7209
trainer/Q1 Predictions Max       -22.4956
trainer/Q1 Predictions Min      -116.199
trainer/Q2 Predictions Mean      -50.0049
trainer/Q2 Predictions Std        27.7782
trainer/Q2 Predictions Max       -22.4919
trainer/Q2 Predictions Min      -116.498
trainer/Q Targets Mean           -49.5285
trainer/Q Targets Std             28.6401
trainer/Q Targets Max             -0.327209
trainer/Q Targets Min           -117.539
trainer/Log Pis Mean               0.861056
trainer/Log Pis Std                1.56297
trainer/Log Pis Max                6.62873
trainer/Log Pis Min               -3.5379
trainer/Policy mu Mean            -0.0579807
trainer/Policy mu Std              0.970749
trainer/Policy mu Max              2.70645
trainer/Policy mu Min             -2.86952
trainer/Policy log std Mean       -1.13496
trainer/Policy log std Std         0.290404
trainer/Policy log std Max        -0.493574
trainer/Policy log std Min        -1.71791
trainer/Alpha                      0.142052
trainer/Alpha Loss                -2.22246
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.29545
exploration/Rewards Std            1.28996
exploration/Rewards Max           -0.0362635
exploration/Rewards Min           -7.86786
exploration/Returns Mean        -129.545
exploration/Returns Std           96.9011
exploration/Returns Max          -63.8805
exploration/Returns Min         -322.474
exploration/Actions Mean          -0.0153174
exploration/Actions Std            0.362296
exploration/Actions Max            0.989641
exploration/Actions Min           -0.994507
exploration/Num Paths              5
exploration/Average Returns     -129.545
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.85231
evaluation/Rewards Std             1.42137
evaluation/Rewards Max            -0.259194
evaluation/Rewards Min            -9.85291
evaluation/Returns Mean         -185.231
evaluation/Returns Std           117.821
evaluation/Returns Max           -45.9865
evaluation/Returns Min          -325.834
evaluation/Actions Mean           -0.012405
evaluation/Actions Std             0.185225
evaluation/Actions Max             0.991075
evaluation/Actions Min            -0.996258
evaluation/Num Paths              15
evaluation/Average Returns      -185.231
time/data storing (s)              0.00306972
time/evaluation sampling (s)       0.331809
time/exploration sampling (s)      0.145811
time/logging (s)                   0.0048595
time/saving (s)                    0.00992566
time/training (s)                  1.94148
time/epoch (s)                     2.43695
time/total (s)                    39.2772
Epoch                             15
-----------------------------  --------------
2019-04-22 22:37:15.847456 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 16 finished
-----------------------------  ---------------
replay_buffer/size              8700
trainer/QF1 Loss                  11.0995
trainer/QF2 Loss                  11.2246
trainer/Policy Loss               47.9865
trainer/Q1 Predictions Mean      -48.4698
trainer/Q1 Predictions Std        25.3139
trainer/Q1 Predictions Max       -22.1642
trainer/Q1 Predictions Min      -102.499
trainer/Q2 Predictions Mean      -48.4525
trainer/Q2 Predictions Std        25.2986
trainer/Q2 Predictions Max       -22.0751
trainer/Q2 Predictions Min      -102.517
trainer/Q Targets Mean           -48.1838
trainer/Q Targets Std             26.2405
trainer/Q Targets Max             -0.190576
trainer/Q Targets Min           -104.318
trainer/Log Pis Mean               0.846751
trainer/Log Pis Std                1.64163
trainer/Log Pis Max                5.63139
trainer/Log Pis Min               -4.45436
trainer/Policy mu Mean            -0.139097
trainer/Policy mu Std              0.975911
trainer/Policy mu Max              2.62237
trainer/Policy mu Min             -2.87177
trainer/Policy log std Mean       -1.18862
trainer/Policy log std Std         0.303314
trainer/Policy log std Max        -0.520246
trainer/Policy log std Min        -1.83577
trainer/Alpha                      0.127002
trainer/Alpha Loss                -2.37953
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.906736
exploration/Rewards Std            1.00462
exploration/Rewards Max           -0.0142703
exploration/Rewards Min           -4.83286
exploration/Returns Mean         -90.6736
exploration/Returns Std           90.1447
exploration/Returns Max          -33.5039
exploration/Returns Min         -269.958
exploration/Actions Mean          -7.63645e-05
exploration/Actions Std            0.30713
exploration/Actions Max            0.988648
exploration/Actions Min           -0.989847
exploration/Num Paths              5
exploration/Average Returns      -90.6736
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.0181
evaluation/Rewards Std             1.4222
evaluation/Rewards Max            -0.0191962
evaluation/Rewards Min           -11.5041
evaluation/Returns Mean         -101.81
evaluation/Returns Std            99.1123
evaluation/Returns Max           -13.217
evaluation/Returns Min          -304.319
evaluation/Actions Mean           -0.000472652
evaluation/Actions Std             0.202912
evaluation/Actions Max             0.998556
evaluation/Actions Min            -0.996277
evaluation/Num Paths              15
evaluation/Average Returns      -101.81
time/data storing (s)              0.00309254
time/evaluation sampling (s)       0.326189
time/exploration sampling (s)      0.14612
time/logging (s)                   0.00450751
time/saving (s)                    0.00194607
time/training (s)                  1.94803
time/epoch (s)                     2.42989
time/total (s)                    41.7113
Epoch                             16
-----------------------------  ---------------
2019-04-22 22:37:18.302478 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                 139.86
trainer/QF2 Loss                 138.509
trainer/Policy Loss               49.3411
trainer/Q1 Predictions Mean      -49.7333
trainer/Q1 Predictions Std        26.5439
trainer/Q1 Predictions Max       -21.6376
trainer/Q1 Predictions Min      -109.003
trainer/Q2 Predictions Mean      -49.7156
trainer/Q2 Predictions Std        26.5312
trainer/Q2 Predictions Max       -21.6977
trainer/Q2 Predictions Min      -109.096
trainer/Q Targets Mean           -48.3923
trainer/Q Targets Std             27.1418
trainer/Q Targets Max             -0.688728
trainer/Q Targets Min           -109.943
trainer/Log Pis Mean               1.19806
trainer/Log Pis Std                1.80366
trainer/Log Pis Max                7.23292
trainer/Log Pis Min               -4.30966
trainer/Policy mu Mean             0.0769091
trainer/Policy mu Std              1.03027
trainer/Policy mu Max              3.01701
trainer/Policy mu Min             -2.95394
trainer/Policy log std Mean       -1.29797
trainer/Policy log std Std         0.327834
trainer/Policy log std Max        -0.475148
trainer/Policy log std Min        -1.94027
trainer/Alpha                      0.114023
trainer/Alpha Loss                -1.74112
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.81349
exploration/Rewards Std            0.98897
exploration/Rewards Max           -0.46127
exploration/Rewards Min           -8.95047
exploration/Returns Mean        -181.349
exploration/Returns Std           62.4947
exploration/Returns Max         -102.789
exploration/Returns Min         -241.8
exploration/Actions Mean          -0.0211257
exploration/Actions Std            0.327652
exploration/Actions Max            0.870318
exploration/Actions Min           -0.996984
exploration/Num Paths              5
exploration/Average Returns     -181.349
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.973916
evaluation/Rewards Std             1.24387
evaluation/Rewards Max            -0.0281929
evaluation/Rewards Min           -10.8674
evaluation/Returns Mean          -97.3916
evaluation/Returns Std            84.7906
evaluation/Returns Max           -11.2979
evaluation/Returns Min          -242.988
evaluation/Actions Mean            0.00530211
evaluation/Actions Std             0.182668
evaluation/Actions Max             0.996916
evaluation/Actions Min            -0.995431
evaluation/Num Paths              15
evaluation/Average Returns       -97.3916
time/data storing (s)              0.0027369
time/evaluation sampling (s)       0.343982
time/exploration sampling (s)      0.142769
time/logging (s)                   0.00485772
time/saving (s)                    0.00206272
time/training (s)                  1.95495
time/epoch (s)                     2.45136
time/total (s)                    44.1661
Epoch                             17
-----------------------------  --------------
2019-04-22 22:37:20.720439 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                   0.516152
trainer/QF2 Loss                   0.582317
trainer/Policy Loss               48.4965
trainer/Q1 Predictions Mean      -48.5834
trainer/Q1 Predictions Std        27.2717
trainer/Q1 Predictions Max       -21.4471
trainer/Q1 Predictions Min      -110.453
trainer/Q2 Predictions Mean      -48.5983
trainer/Q2 Predictions Std        27.2783
trainer/Q2 Predictions Max       -21.4834
trainer/Q2 Predictions Min      -110.105
trainer/Q Targets Mean           -48.7024
trainer/Q Targets Std             27.1867
trainer/Q Targets Max            -21.6002
trainer/Q Targets Min           -113.17
trainer/Log Pis Mean               1.11931
trainer/Log Pis Std                1.84197
trainer/Log Pis Max                8.01849
trainer/Log Pis Min               -4.05796
trainer/Policy mu Mean            -0.00899467
trainer/Policy mu Std              1.06916
trainer/Policy mu Max              2.83247
trainer/Policy mu Min             -3.14224
trainer/Policy log std Mean       -1.20395
trainer/Policy log std Std         0.392711
trainer/Policy log std Max        -0.290588
trainer/Policy log std Min        -1.84485
trainer/Alpha                      0.102223
trainer/Alpha Loss                -2.00831
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.3419
exploration/Rewards Std            1.12996
exploration/Rewards Max           -0.23637
exploration/Rewards Min          -10.4746
exploration/Returns Mean        -134.19
exploration/Returns Std           39.3356
exploration/Returns Max          -75.8003
exploration/Returns Min         -174.269
exploration/Actions Mean          -0.0283038
exploration/Actions Std            0.377264
exploration/Actions Max            0.994686
exploration/Actions Min           -0.998471
exploration/Num Paths              5
exploration/Average Returns     -134.19
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.718335
evaluation/Rewards Std             0.862303
evaluation/Rewards Max            -0.172874
evaluation/Rewards Min            -9.17225
evaluation/Returns Mean          -71.8335
evaluation/Returns Std            38.8858
evaluation/Returns Max           -26.6009
evaluation/Returns Min          -149.784
evaluation/Actions Mean            0.00148592
evaluation/Actions Std             0.161348
evaluation/Actions Max             0.997448
evaluation/Actions Min            -0.994829
evaluation/Num Paths              15
evaluation/Average Returns       -71.8335
time/data storing (s)              0.00298174
time/evaluation sampling (s)       0.330277
time/exploration sampling (s)      0.145256
time/logging (s)                   0.00481013
time/saving (s)                    0.00190916
time/training (s)                  1.92742
time/epoch (s)                     2.41265
time/total (s)                    46.583
Epoch                             18
-----------------------------  --------------
2019-04-22 22:37:23.152109 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 19 finished
-----------------------------  ---------------
replay_buffer/size             10200
trainer/QF1 Loss                   8.09557
trainer/QF2 Loss                   7.99677
trainer/Policy Loss               45.5208
trainer/Q1 Predictions Mean      -45.3952
trainer/Q1 Predictions Std        25.9165
trainer/Q1 Predictions Max       -21.2343
trainer/Q1 Predictions Min      -112.947
trainer/Q2 Predictions Mean      -45.3783
trainer/Q2 Predictions Std        25.995
trainer/Q2 Predictions Max       -21.4471
trainer/Q2 Predictions Min      -112.962
trainer/Q Targets Mean           -45.793
trainer/Q Targets Std             26.8606
trainer/Q Targets Max             -0.0606619
trainer/Q Targets Min           -115.088
trainer/Log Pis Mean               1.46667
trainer/Log Pis Std                1.52949
trainer/Log Pis Max                7.26451
trainer/Log Pis Min               -1.52363
trainer/Policy mu Mean            -0.0884957
trainer/Policy mu Std              1.00569
trainer/Policy mu Max              2.91733
trainer/Policy mu Min             -2.87337
trainer/Policy log std Mean       -1.36448
trainer/Policy log std Std         0.401548
trainer/Policy log std Max        -0.31223
trainer/Policy log std Min        -2.04086
trainer/Alpha                      0.0913967
trainer/Alpha Loss                -1.2759
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.15896
exploration/Rewards Std            0.869674
exploration/Rewards Max           -0.0315673
exploration/Rewards Min           -7.78626
exploration/Returns Mean        -115.896
exploration/Returns Std           44.2302
exploration/Returns Max          -38.4709
exploration/Returns Min         -169.222
exploration/Actions Mean          -0.0173761
exploration/Actions Std            0.326897
exploration/Actions Max            0.923812
exploration/Actions Min           -0.997722
exploration/Num Paths              5
exploration/Average Returns     -115.896
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.645182
evaluation/Rewards Std             0.925372
evaluation/Rewards Max            -0.0387812
evaluation/Rewards Min           -10.8295
evaluation/Returns Mean          -64.5182
evaluation/Returns Std            39.3529
evaluation/Returns Max           -14.2861
evaluation/Returns Min          -158.944
evaluation/Actions Mean           -0.000376291
evaluation/Actions Std             0.178026
evaluation/Actions Max             0.99251
evaluation/Actions Min            -0.997177
evaluation/Num Paths              15
evaluation/Average Returns       -64.5182
time/data storing (s)              0.00292934
time/evaluation sampling (s)       0.332077
time/exploration sampling (s)      0.145056
time/logging (s)                   0.00490827
time/saving (s)                    0.00195762
time/training (s)                  1.93965
time/epoch (s)                     2.42658
time/total (s)                    49.0138
Epoch                             19
-----------------------------  ---------------
2019-04-22 22:37:25.593791 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                   7.756
trainer/QF2 Loss                   7.53771
trainer/Policy Loss               45.4397
trainer/Q1 Predictions Mean      -44.9741
trainer/Q1 Predictions Std        26.2545
trainer/Q1 Predictions Max       -21.088
trainer/Q1 Predictions Min       -94.2711
trainer/Q2 Predictions Mean      -44.9594
trainer/Q2 Predictions Std        26.2588
trainer/Q2 Predictions Max       -21.074
trainer/Q2 Predictions Min       -94.6646
trainer/Q Targets Mean           -45.1906
trainer/Q Targets Std             27.0389
trainer/Q Targets Max             -1.06586
trainer/Q Targets Min            -97.0185
trainer/Log Pis Mean               1.74609
trainer/Log Pis Std                1.58177
trainer/Log Pis Max                7.34709
trainer/Log Pis Min               -1.43399
trainer/Policy mu Mean             0.0262237
trainer/Policy mu Std              1.12025
trainer/Policy mu Max              2.98452
trainer/Policy mu Min             -2.87309
trainer/Policy log std Mean       -1.33735
trainer/Policy log std Std         0.410712
trainer/Policy log std Max        -0.39114
trainer/Policy log std Min        -2.05494
trainer/Alpha                      0.0827982
trainer/Alpha Loss                -0.632529
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.509156
exploration/Rewards Std            1.00063
exploration/Rewards Max           -0.0190004
exploration/Rewards Min          -10.9603
exploration/Returns Mean         -50.9156
exploration/Returns Std           16.2027
exploration/Returns Max          -35.468
exploration/Returns Min          -80.5721
exploration/Actions Mean           0.0311314
exploration/Actions Std            0.282138
exploration/Actions Max            0.997923
exploration/Actions Min           -0.972155
exploration/Num Paths              5
exploration/Average Returns      -50.9156
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.879793
evaluation/Rewards Std             1.2736
evaluation/Rewards Max            -0.178557
evaluation/Rewards Min           -10.339
evaluation/Returns Mean          -87.9793
evaluation/Returns Std            47.2484
evaluation/Returns Max           -18.8907
evaluation/Returns Min          -178.813
evaluation/Actions Mean            0.00253575
evaluation/Actions Std             0.205742
evaluation/Actions Max             0.997495
evaluation/Actions Min            -0.998834
evaluation/Num Paths              15
evaluation/Average Returns       -87.9793
time/data storing (s)              0.00315647
time/evaluation sampling (s)       0.334464
time/exploration sampling (s)      0.145221
time/logging (s)                   0.00483028
time/saving (s)                    0.0019183
time/training (s)                  1.94705
time/epoch (s)                     2.43664
time/total (s)                    51.4545
Epoch                             20
-----------------------------  --------------
2019-04-22 22:37:28.034656 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   0.798495
trainer/QF2 Loss                   0.813191
trainer/Policy Loss               44.2791
trainer/Q1 Predictions Mean      -44.2805
trainer/Q1 Predictions Std        26.0389
trainer/Q1 Predictions Max       -20.7523
trainer/Q1 Predictions Min      -111.036
trainer/Q2 Predictions Mean      -44.2547
trainer/Q2 Predictions Std        26.0494
trainer/Q2 Predictions Max       -20.8931
trainer/Q2 Predictions Min      -110.994
trainer/Q Targets Mean           -44.5853
trainer/Q Targets Std             26.3516
trainer/Q Targets Max            -21.0351
trainer/Q Targets Min           -113.654
trainer/Log Pis Mean               1.53206
trainer/Log Pis Std                2.23511
trainer/Log Pis Max                9.26141
trainer/Log Pis Min               -4.58096
trainer/Policy mu Mean             0.0118458
trainer/Policy mu Std              1.169
trainer/Policy mu Max              3.3483
trainer/Policy mu Min             -3.26232
trainer/Policy log std Mean       -1.33087
trainer/Policy log std Std         0.436965
trainer/Policy log std Max        -0.37474
trainer/Policy log std Min        -2.01069
trainer/Alpha                      0.0749421
trainer/Alpha Loss                -1.21233
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.791547
exploration/Rewards Std            1.22234
exploration/Rewards Max           -0.0385732
exploration/Rewards Min          -11.2926
exploration/Returns Mean         -79.1547
exploration/Returns Std           19.0659
exploration/Returns Max          -60.2962
exploration/Returns Min         -113.613
exploration/Actions Mean           0.0266992
exploration/Actions Std            0.301545
exploration/Actions Max            0.99884
exploration/Actions Min           -0.999025
exploration/Num Paths              5
exploration/Average Returns      -79.1547
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.761798
evaluation/Rewards Std             1.00327
evaluation/Rewards Max            -0.0124442
evaluation/Rewards Min           -10.6464
evaluation/Returns Mean          -76.1798
evaluation/Returns Std            23.895
evaluation/Returns Max           -28.4404
evaluation/Returns Min          -135.125
evaluation/Actions Mean            0.00357418
evaluation/Actions Std             0.201535
evaluation/Actions Max             0.99883
evaluation/Actions Min            -0.997166
evaluation/Num Paths              15
evaluation/Average Returns       -76.1798
time/data storing (s)              0.00291527
time/evaluation sampling (s)       0.332987
time/exploration sampling (s)      0.14856
time/logging (s)                   0.00489339
time/saving (s)                    0.0019528
time/training (s)                  1.94448
time/epoch (s)                     2.43579
time/total (s)                    53.8944
Epoch                             21
-----------------------------  --------------
2019-04-22 22:37:30.442238 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                  72.7489
trainer/QF2 Loss                  72.273
trainer/Policy Loss               43.1853
trainer/Q1 Predictions Mean      -42.5614
trainer/Q1 Predictions Std        26.2576
trainer/Q1 Predictions Max       -20.7356
trainer/Q1 Predictions Min      -104.434
trainer/Q2 Predictions Mean      -42.5469
trainer/Q2 Predictions Std        26.2844
trainer/Q2 Predictions Max       -20.9218
trainer/Q2 Predictions Min      -104.558
trainer/Q Targets Mean           -41.9791
trainer/Q Targets Std             26.998
trainer/Q Targets Max             -0.429207
trainer/Q Targets Min           -107.011
trainer/Log Pis Mean               1.52567
trainer/Log Pis Std                1.69981
trainer/Log Pis Max                7.85261
trainer/Log Pis Min               -2.39549
trainer/Policy mu Mean            -0.086914
trainer/Policy mu Std              0.963054
trainer/Policy mu Max              2.78496
trainer/Policy mu Min             -3.18689
trainer/Policy log std Mean       -1.50092
trainer/Policy log std Std         0.39656
trainer/Policy log std Max        -0.481468
trainer/Policy log std Min        -2.09543
trainer/Alpha                      0.0689323
trainer/Alpha Loss                -1.26859
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.05704
exploration/Rewards Std            1.20252
exploration/Rewards Max           -0.0355338
exploration/Rewards Min          -10.8475
exploration/Returns Mean        -105.704
exploration/Returns Std           43.5803
exploration/Returns Max          -25.9241
exploration/Returns Min         -154.93
exploration/Actions Mean          -0.0156791
exploration/Actions Std            0.308906
exploration/Actions Max            0.996119
exploration/Actions Min           -0.999599
exploration/Num Paths              5
exploration/Average Returns     -105.704
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.75513
evaluation/Rewards Std             1.07485
evaluation/Rewards Max            -0.024661
evaluation/Rewards Min           -10.962
evaluation/Returns Mean          -75.513
evaluation/Returns Std            29.0843
evaluation/Returns Max           -43.9445
evaluation/Returns Min          -129.493
evaluation/Actions Mean            0.00047498
evaluation/Actions Std             0.195253
evaluation/Actions Max             0.99857
evaluation/Actions Min            -0.997885
evaluation/Num Paths              15
evaluation/Average Returns       -75.513
time/data storing (s)              0.00310796
time/evaluation sampling (s)       0.330718
time/exploration sampling (s)      0.145883
time/logging (s)                   0.0046477
time/saving (s)                    0.0016048
time/training (s)                  1.91609
time/epoch (s)                     2.40206
time/total (s)                    56.3008
Epoch                             22
-----------------------------  --------------
2019-04-22 22:37:32.861966 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                  73.0456
trainer/QF2 Loss                  73.4587
trainer/Policy Loss               47.7677
trainer/Q1 Predictions Mean      -47.2777
trainer/Q1 Predictions Std        26.507
trainer/Q1 Predictions Max       -20.299
trainer/Q1 Predictions Min      -111.916
trainer/Q2 Predictions Mean      -47.2893
trainer/Q2 Predictions Std        26.5149
trainer/Q2 Predictions Max       -20.4788
trainer/Q2 Predictions Min      -111.933
trainer/Q Targets Mean           -46.3338
trainer/Q Targets Std             26.9188
trainer/Q Targets Max             -0.780066
trainer/Q Targets Min           -112.923
trainer/Log Pis Mean               1.83943
trainer/Log Pis Std                1.96148
trainer/Log Pis Max                8.59876
trainer/Log Pis Min               -5.09814
trainer/Policy mu Mean            -0.0309837
trainer/Policy mu Std              1.11125
trainer/Policy mu Max              2.953
trainer/Policy mu Min             -3.5348
trainer/Policy log std Mean       -1.5102
trainer/Policy log std Std         0.440312
trainer/Policy log std Max        -0.315015
trainer/Policy log std Min        -2.17316
trainer/Alpha                      0.0640179
trainer/Alpha Loss                -0.441325
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.802486
exploration/Rewards Std            1.18061
exploration/Rewards Max           -0.0420909
exploration/Rewards Min           -9.46766
exploration/Returns Mean         -80.2486
exploration/Returns Std           39.9747
exploration/Returns Max          -41.5081
exploration/Returns Min         -154.298
exploration/Actions Mean          -0.00140281
exploration/Actions Std            0.282732
exploration/Actions Max            0.997818
exploration/Actions Min           -0.9994
exploration/Num Paths              5
exploration/Average Returns      -80.2486
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.869537
evaluation/Rewards Std             1.10137
evaluation/Rewards Max            -0.0221965
evaluation/Rewards Min            -9.32879
evaluation/Returns Mean          -86.9537
evaluation/Returns Std            48.5198
evaluation/Returns Max           -27.1832
evaluation/Returns Min          -154.854
evaluation/Actions Mean           -0.00323769
evaluation/Actions Std             0.206177
evaluation/Actions Max             0.996351
evaluation/Actions Min            -0.996928
evaluation/Num Paths              15
evaluation/Average Returns       -86.9537
time/data storing (s)              0.00321232
time/evaluation sampling (s)       0.330843
time/exploration sampling (s)      0.148393
time/logging (s)                   0.0042515
time/saving (s)                    0.00185813
time/training (s)                  1.92509
time/epoch (s)                     2.41364
time/total (s)                    58.719
Epoch                             23
-----------------------------  --------------
2019-04-22 22:37:35.288188 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size             12700
trainer/QF1 Loss                   0.792418
trainer/QF2 Loss                   0.736749
trainer/Policy Loss               46.0902
trainer/Q1 Predictions Mean      -45.2143
trainer/Q1 Predictions Std        24.9731
trainer/Q1 Predictions Max       -19.9778
trainer/Q1 Predictions Min      -106.016
trainer/Q2 Predictions Mean      -45.2271
trainer/Q2 Predictions Std        24.9956
trainer/Q2 Predictions Max       -20.0343
trainer/Q2 Predictions Min      -105.942
trainer/Q Targets Mean           -45.7311
trainer/Q Targets Std             25.3396
trainer/Q Targets Max            -20.1621
trainer/Q Targets Min           -106.836
trainer/Log Pis Mean               2.17323
trainer/Log Pis Std                2.14421
trainer/Log Pis Max                9.52096
trainer/Log Pis Min               -2.48243
trainer/Policy mu Mean             0.0113763
trainer/Policy mu Std              1.20611
trainer/Policy mu Max              3.05058
trainer/Policy mu Min             -3.26219
trainer/Policy log std Mean       -1.52751
trainer/Policy log std Std         0.46911
trainer/Policy log std Max        -0.410224
trainer/Policy log std Min        -2.25566
trainer/Alpha                      0.0609186
trainer/Alpha Loss                 0.484728
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.00743
exploration/Rewards Std            1.10793
exploration/Rewards Max           -0.0127551
exploration/Rewards Min           -9.35729
exploration/Returns Mean        -100.743
exploration/Returns Std           57.9698
exploration/Returns Max          -47.873
exploration/Returns Min         -179.074
exploration/Actions Mean           0.00328589
exploration/Actions Std            0.287719
exploration/Actions Max            0.999483
exploration/Actions Min           -0.99847
exploration/Num Paths              5
exploration/Average Returns     -100.743
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.767006
evaluation/Rewards Std             1.06121
evaluation/Rewards Max            -0.194966
evaluation/Rewards Min           -11.2646
evaluation/Returns Mean          -76.7006
evaluation/Returns Std            54.3675
evaluation/Returns Max           -23.7653
evaluation/Returns Min          -204.91
evaluation/Actions Mean           -0.00884823
evaluation/Actions Std             0.195471
evaluation/Actions Max             0.99651
evaluation/Actions Min            -0.999346
evaluation/Num Paths              15
evaluation/Average Returns       -76.7006
time/data storing (s)              0.00292539
time/evaluation sampling (s)       0.332268
time/exploration sampling (s)      0.143388
time/logging (s)                   0.00482612
time/saving (s)                    0.0019557
time/training (s)                  1.93728
time/epoch (s)                     2.42264
time/total (s)                    61.1451
Epoch                             24
-----------------------------  --------------
2019-04-22 22:37:37.725943 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   0.521493
trainer/QF2 Loss                   0.526226
trainer/Policy Loss               41.8087
trainer/Q1 Predictions Mean      -40.9219
trainer/Q1 Predictions Std        22.2528
trainer/Q1 Predictions Max       -19.7408
trainer/Q1 Predictions Min       -89.3378
trainer/Q2 Predictions Mean      -40.9404
trainer/Q2 Predictions Std        22.2748
trainer/Q2 Predictions Max       -19.8453
trainer/Q2 Predictions Min       -89.1003
trainer/Q Targets Mean           -41.3767
trainer/Q Targets Std             22.3802
trainer/Q Targets Max            -19.9285
trainer/Q Targets Min            -88.975
trainer/Log Pis Mean               1.9107
trainer/Log Pis Std                1.34578
trainer/Log Pis Max                6.73811
trainer/Log Pis Min               -1.65388
trainer/Policy mu Mean            -0.0590405
trainer/Policy mu Std              0.924646
trainer/Policy mu Max              2.90616
trainer/Policy mu Min             -2.56585
trainer/Policy log std Mean       -1.65754
trainer/Policy log std Std         0.405547
trainer/Policy log std Max        -0.387646
trainer/Policy log std Min        -2.43038
trainer/Alpha                      0.0582203
trainer/Alpha Loss                -0.253931
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.68654
exploration/Rewards Std            1.16896
exploration/Rewards Max           -0.019399
exploration/Rewards Min           -9.90508
exploration/Returns Mean         -68.654
exploration/Returns Std           46.4411
exploration/Returns Max          -33.3296
exploration/Returns Min         -156.477
exploration/Actions Mean          -0.00555813
exploration/Actions Std            0.262594
exploration/Actions Max            0.997977
exploration/Actions Min           -0.999762
exploration/Num Paths              5
exploration/Average Returns      -68.654
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.889052
evaluation/Rewards Std             0.94106
evaluation/Rewards Max            -0.0216298
evaluation/Rewards Min            -9.07414
evaluation/Returns Mean          -88.9052
evaluation/Returns Std            45.4501
evaluation/Returns Max           -10.9472
evaluation/Returns Min          -149.403
evaluation/Actions Mean           -0.00419882
evaluation/Actions Std             0.181447
evaluation/Actions Max             0.997047
evaluation/Actions Min            -0.997778
evaluation/Num Paths              15
evaluation/Average Returns       -88.9052
time/data storing (s)              0.00289845
time/evaluation sampling (s)       0.329424
time/exploration sampling (s)      0.148447
time/logging (s)                   0.00482658
time/saving (s)                    0.00197718
time/training (s)                  1.94478
time/epoch (s)                     2.43235
time/total (s)                    63.5818
Epoch                             25
-----------------------------  --------------
2019-04-22 22:37:40.167742 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                  10.5169
trainer/QF2 Loss                  10.3983
trainer/Policy Loss               44.9095
trainer/Q1 Predictions Mean      -44.106
trainer/Q1 Predictions Std        23.6729
trainer/Q1 Predictions Max       -19.5498
trainer/Q1 Predictions Min       -86.5734
trainer/Q2 Predictions Mean      -44.1117
trainer/Q2 Predictions Std        23.7342
trainer/Q2 Predictions Max       -19.712
trainer/Q2 Predictions Min       -86.7351
trainer/Q Targets Mean           -44.3132
trainer/Q Targets Std             24.6796
trainer/Q Targets Max             -0.297136
trainer/Q Targets Min            -87.8327
trainer/Log Pis Mean               1.95389
trainer/Log Pis Std                1.9255
trainer/Log Pis Max                6.67769
trainer/Log Pis Min               -5.95132
trainer/Policy mu Mean            -0.0778284
trainer/Policy mu Std              1.14674
trainer/Policy mu Max              2.96509
trainer/Policy mu Min             -3.26284
trainer/Policy log std Mean       -1.55566
trainer/Policy log std Std         0.508731
trainer/Policy log std Max        -0.358223
trainer/Policy log std Min        -2.39677
trainer/Alpha                      0.0555887
trainer/Alpha Loss                -0.133262
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.532952
exploration/Rewards Std            1.02628
exploration/Rewards Max           -0.0242655
exploration/Rewards Min           -9.72467
exploration/Returns Mean         -53.2952
exploration/Returns Std           18.3369
exploration/Returns Max          -35.6668
exploration/Returns Min          -78.8963
exploration/Actions Mean           0.0197147
exploration/Actions Std            0.257688
exploration/Actions Max            0.996841
exploration/Actions Min           -0.999001
exploration/Num Paths              5
exploration/Average Returns      -53.2952
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.680639
evaluation/Rewards Std             0.983201
evaluation/Rewards Max            -0.0856847
evaluation/Rewards Min            -9.34285
evaluation/Returns Mean          -68.0639
evaluation/Returns Std            41.4967
evaluation/Returns Max           -23.8762
evaluation/Returns Min          -137.303
evaluation/Actions Mean            0.00265537
evaluation/Actions Std             0.181349
evaluation/Actions Max             0.997886
evaluation/Actions Min            -0.998534
evaluation/Num Paths              15
evaluation/Average Returns       -68.0639
time/data storing (s)              0.00292033
time/evaluation sampling (s)       0.333031
time/exploration sampling (s)      0.145781
time/logging (s)                   0.00484756
time/saving (s)                    0.00197076
time/training (s)                  1.94782
time/epoch (s)                     2.43637
time/total (s)                    66.0225
Epoch                             26
-----------------------------  --------------
2019-04-22 22:37:42.619926 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   0.380086
trainer/QF2 Loss                   0.322305
trainer/Policy Loss               44.4755
trainer/Q1 Predictions Mean      -43.2269
trainer/Q1 Predictions Std        24.5199
trainer/Q1 Predictions Max       -18.9647
trainer/Q1 Predictions Min      -108.318
trainer/Q2 Predictions Mean      -43.2071
trainer/Q2 Predictions Std        24.5116
trainer/Q2 Predictions Max       -19.0808
trainer/Q2 Predictions Min      -109.036
trainer/Q Targets Mean           -43.1421
trainer/Q Targets Std             24.4504
trainer/Q Targets Max            -19.1907
trainer/Q Targets Min           -110.304
trainer/Log Pis Mean               2.052
trainer/Log Pis Std                1.60912
trainer/Log Pis Max                6.42469
trainer/Log Pis Min               -4.29059
trainer/Policy mu Mean            -0.083829
trainer/Policy mu Std              1.09019
trainer/Policy mu Max              3.18194
trainer/Policy mu Min             -3.62075
trainer/Policy log std Mean       -1.62519
trainer/Policy log std Std         0.513193
trainer/Policy log std Max        -0.363233
trainer/Policy log std Min        -2.39443
trainer/Alpha                      0.0556991
trainer/Alpha Loss                 0.150175
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.789905
exploration/Rewards Std            0.725734
exploration/Rewards Max           -0.0232604
exploration/Rewards Min           -6.24177
exploration/Returns Mean         -78.9905
exploration/Returns Std           46.1815
exploration/Returns Max          -29.9224
exploration/Returns Min         -142.647
exploration/Actions Mean          -0.0144435
exploration/Actions Std            0.246246
exploration/Actions Max            0.975588
exploration/Actions Min           -0.99755
exploration/Num Paths              5
exploration/Average Returns      -78.9905
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.572018
evaluation/Rewards Std             0.850948
evaluation/Rewards Max            -0.0947526
evaluation/Rewards Min            -9.26079
evaluation/Returns Mean          -57.2018
evaluation/Returns Std            50.8535
evaluation/Returns Max           -20.297
evaluation/Returns Min          -167.577
evaluation/Actions Mean            0.0170106
evaluation/Actions Std             0.157367
evaluation/Actions Max             0.998148
evaluation/Actions Min            -0.99274
evaluation/Num Paths              15
evaluation/Average Returns       -57.2018
time/data storing (s)              0.00299012
time/evaluation sampling (s)       0.334388
time/exploration sampling (s)      0.148785
time/logging (s)                   0.00494514
time/saving (s)                    0.0212538
time/training (s)                  1.93453
time/epoch (s)                     2.44689
time/total (s)                    68.4737
Epoch                             27
-----------------------------  --------------
2019-04-22 22:37:45.048607 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             14700
trainer/QF1 Loss                  62.6768
trainer/QF2 Loss                  62.8153
trainer/Policy Loss               48.4374
trainer/Q1 Predictions Mean      -47.2831
trainer/Q1 Predictions Std        25.669
trainer/Q1 Predictions Max       -18.7764
trainer/Q1 Predictions Min      -113.32
trainer/Q2 Predictions Mean      -47.2716
trainer/Q2 Predictions Std        25.528
trainer/Q2 Predictions Max       -19.007
trainer/Q2 Predictions Min      -110.093
trainer/Q Targets Mean           -47.2299
trainer/Q Targets Std             26.2985
trainer/Q Targets Max             -2.05818
trainer/Q Targets Min           -115.528
trainer/Log Pis Mean               1.99715
trainer/Log Pis Std                2.19952
trainer/Log Pis Max                8.0767
trainer/Log Pis Min               -3.34929
trainer/Policy mu Mean            -0.106859
trainer/Policy mu Std              1.17161
trainer/Policy mu Max              3.32212
trainer/Policy mu Min             -3.65987
trainer/Policy log std Mean       -1.56013
trainer/Policy log std Std         0.507775
trainer/Policy log std Max        -0.261268
trainer/Policy log std Min        -2.41932
trainer/Alpha                      0.0542008
trainer/Alpha Loss                -0.00829789
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.885982
exploration/Rewards Std            0.943237
exploration/Rewards Max           -0.0260341
exploration/Rewards Min           -9.47701
exploration/Returns Mean         -88.5982
exploration/Returns Std           32.7578
exploration/Returns Max          -37.3693
exploration/Returns Min         -135.081
exploration/Actions Mean          -0.0100093
exploration/Actions Std            0.265048
exploration/Actions Max            0.992737
exploration/Actions Min           -0.999939
exploration/Num Paths              5
exploration/Average Returns      -88.5982
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.809308
evaluation/Rewards Std             0.948656
evaluation/Rewards Max            -0.0392705
evaluation/Rewards Min           -10.2543
evaluation/Returns Mean          -80.9308
evaluation/Returns Std            41.7083
evaluation/Returns Max           -19.0232
evaluation/Returns Min          -138.866
evaluation/Actions Mean           -0.0051086
evaluation/Actions Std             0.17647
evaluation/Actions Max             0.995857
evaluation/Actions Min            -0.997985
evaluation/Num Paths              15
evaluation/Average Returns       -80.9308
time/data storing (s)              0.00290431
time/evaluation sampling (s)       0.327941
time/exploration sampling (s)      0.144596
time/logging (s)                   0.00484554
time/saving (s)                    0.00195469
time/training (s)                  1.94072
time/epoch (s)                     2.42297
time/total (s)                    70.9012
Epoch                             28
-----------------------------  --------------
2019-04-22 22:37:47.500370 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                  21.2424
trainer/QF2 Loss                  21.441
trainer/Policy Loss               38.3297
trainer/Q1 Predictions Mean      -37.1408
trainer/Q1 Predictions Std        21.4999
trainer/Q1 Predictions Max       -18.0606
trainer/Q1 Predictions Min       -92.4982
trainer/Q2 Predictions Mean      -37.1363
trainer/Q2 Predictions Std        21.4915
trainer/Q2 Predictions Max       -18.3164
trainer/Q2 Predictions Min       -92.6525
trainer/Q Targets Mean           -37.0204
trainer/Q Targets Std             22.2038
trainer/Q Targets Max             -0.219677
trainer/Q Targets Min            -92.6139
trainer/Log Pis Mean               1.99953
trainer/Log Pis Std                1.63122
trainer/Log Pis Max                9.36181
trainer/Log Pis Min               -2.82547
trainer/Policy mu Mean            -0.0424211
trainer/Policy mu Std              0.90811
trainer/Policy mu Max              3.41653
trainer/Policy mu Min             -3.11154
trainer/Policy log std Mean       -1.80207
trainer/Policy log std Std         0.45002
trainer/Policy log std Max        -0.385635
trainer/Policy log std Min        -2.41143
trainer/Alpha                      0.0530104
trainer/Alpha Loss                -0.00138661
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.860285
exploration/Rewards Std            0.905493
exploration/Rewards Max           -0.014862
exploration/Rewards Min           -7.0272
exploration/Returns Mean         -86.0285
exploration/Returns Std           43.6469
exploration/Returns Max          -48.8173
exploration/Returns Min         -146.062
exploration/Actions Mean           0.0223584
exploration/Actions Std            0.248234
exploration/Actions Max            0.999551
exploration/Actions Min           -0.960224
exploration/Num Paths              5
exploration/Average Returns      -86.0285
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.81037
evaluation/Rewards Std             0.984356
evaluation/Rewards Max            -0.0548737
evaluation/Rewards Min            -9.55671
evaluation/Returns Mean          -81.037
evaluation/Returns Std            39.3502
evaluation/Returns Max           -20.9211
evaluation/Returns Min          -149.642
evaluation/Actions Mean           -0.0102778
evaluation/Actions Std             0.193634
evaluation/Actions Max             0.997539
evaluation/Actions Min            -0.999287
evaluation/Num Paths              15
evaluation/Average Returns       -81.037
time/data storing (s)              0.00304854
time/evaluation sampling (s)       0.332303
time/exploration sampling (s)      0.145174
time/logging (s)                   0.00485066
time/saving (s)                    0.0019681
time/training (s)                  1.95878
time/epoch (s)                     2.44612
time/total (s)                    73.3519
Epoch                             29
-----------------------------  --------------
2019-04-22 22:37:49.947509 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                  61.5947
trainer/QF2 Loss                  61.7173
trainer/Policy Loss               41.696
trainer/Q1 Predictions Mean      -40.7179
trainer/Q1 Predictions Std        23.3813
trainer/Q1 Predictions Max       -17.8052
trainer/Q1 Predictions Min      -104.128
trainer/Q2 Predictions Mean      -40.7049
trainer/Q2 Predictions Std        23.3474
trainer/Q2 Predictions Max       -17.975
trainer/Q2 Predictions Min      -104.091
trainer/Q Targets Mean           -40.1061
trainer/Q Targets Std             23.7571
trainer/Q Targets Max             -0.780066
trainer/Q Targets Min           -103.917
trainer/Log Pis Mean               2.07091
trainer/Log Pis Std                1.67889
trainer/Log Pis Max                7.08323
trainer/Log Pis Min               -0.998121
trainer/Policy mu Mean            -0.0827034
trainer/Policy mu Std              1.12826
trainer/Policy mu Max              3.65711
trainer/Policy mu Min             -3.57566
trainer/Policy log std Mean       -1.62849
trainer/Policy log std Std         0.529303
trainer/Policy log std Max        -0.110014
trainer/Policy log std Min        -2.3528
trainer/Alpha                      0.0513449
trainer/Alpha Loss                 0.210546
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.992963
exploration/Rewards Std            0.886302
exploration/Rewards Max           -0.0305635
exploration/Rewards Min           -8.84159
exploration/Returns Mean         -99.2963
exploration/Returns Std           49.6262
exploration/Returns Max          -30.2603
exploration/Returns Min         -156.923
exploration/Actions Mean          -0.00670534
exploration/Actions Std            0.298101
exploration/Actions Max            0.998457
exploration/Actions Min           -0.99826
exploration/Num Paths              5
exploration/Average Returns      -99.2963
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.647259
evaluation/Rewards Std             1.01449
evaluation/Rewards Max            -0.0637884
evaluation/Rewards Min           -10.5892
evaluation/Returns Mean          -64.7259
evaluation/Returns Std            43.6933
evaluation/Returns Max            -7.5064
evaluation/Returns Min          -141.371
evaluation/Actions Mean            0.00759987
evaluation/Actions Std             0.179851
evaluation/Actions Max             0.999528
evaluation/Actions Min            -0.995961
evaluation/Num Paths              15
evaluation/Average Returns       -64.7259
time/data storing (s)              0.00289712
time/evaluation sampling (s)       0.330458
time/exploration sampling (s)      0.149465
time/logging (s)                   0.00485236
time/saving (s)                    0.0019608
time/training (s)                  1.95187
time/epoch (s)                     2.4415
time/total (s)                    75.798
Epoch                             30
-----------------------------  --------------
2019-04-22 22:37:52.383682 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   0.461748
trainer/QF2 Loss                   0.49292
trainer/Policy Loss               39.9697
trainer/Q1 Predictions Mean      -38.939
trainer/Q1 Predictions Std        21.2212
trainer/Q1 Predictions Max       -17.4865
trainer/Q1 Predictions Min       -91.0279
trainer/Q2 Predictions Mean      -38.9131
trainer/Q2 Predictions Std        21.21
trainer/Q2 Predictions Max       -17.7115
trainer/Q2 Predictions Min       -91.2163
trainer/Q Targets Mean           -39.3468
trainer/Q Targets Std             21.4625
trainer/Q Targets Max            -17.6713
trainer/Q Targets Min            -92.6091
trainer/Log Pis Mean               2.08715
trainer/Log Pis Std                1.92562
trainer/Log Pis Max                7.54808
trainer/Log Pis Min               -2.37606
trainer/Policy mu Mean            -0.12259
trainer/Policy mu Std              1.08127
trainer/Policy mu Max              3.00704
trainer/Policy mu Min             -3.60273
trainer/Policy log std Mean       -1.64351
trainer/Policy log std Std         0.483513
trainer/Policy log std Max        -0.329075
trainer/Policy log std Min        -2.31398
trainer/Alpha                      0.0489918
trainer/Alpha Loss                 0.262853
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.673304
exploration/Rewards Std            1.08963
exploration/Rewards Max           -0.0195666
exploration/Rewards Min          -10.898
exploration/Returns Mean         -67.3304
exploration/Returns Std           35.1209
exploration/Returns Max          -27.341
exploration/Returns Min         -125.623
exploration/Actions Mean           0.00944734
exploration/Actions Std            0.2534
exploration/Actions Max            0.999186
exploration/Actions Min           -0.996862
exploration/Num Paths              5
exploration/Average Returns      -67.3304
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.80571
evaluation/Rewards Std             0.838369
evaluation/Rewards Max            -0.126686
evaluation/Rewards Min           -10.4124
evaluation/Returns Mean          -80.571
evaluation/Returns Std            40.4643
evaluation/Returns Max           -27.7632
evaluation/Returns Min          -137.942
evaluation/Actions Mean           -0.00857017
evaluation/Actions Std             0.176705
evaluation/Actions Max             0.996622
evaluation/Actions Min            -0.999369
evaluation/Num Paths              15
evaluation/Average Returns       -80.571
time/data storing (s)              0.00298544
time/evaluation sampling (s)       0.329582
time/exploration sampling (s)      0.141229
time/logging (s)                   0.0045165
time/saving (s)                    0.00194345
time/training (s)                  1.9499
time/epoch (s)                     2.43015
time/total (s)                    78.2326
Epoch                             31
-----------------------------  --------------
2019-04-22 22:37:54.804315 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size             16700
trainer/QF1 Loss                   0.361305
trainer/QF2 Loss                   0.448841
trainer/Policy Loss               36.3482
trainer/Q1 Predictions Mean      -35.2916
trainer/Q1 Predictions Std        18.8423
trainer/Q1 Predictions Max       -17.0823
trainer/Q1 Predictions Min       -84.3847
trainer/Q2 Predictions Mean      -35.3353
trainer/Q2 Predictions Std        18.8187
trainer/Q2 Predictions Max       -17.2516
trainer/Q2 Predictions Min       -84.9579
trainer/Q Targets Mean           -35.4009
trainer/Q Targets Std             18.7264
trainer/Q Targets Max            -17.4544
trainer/Q Targets Min            -80.1833
trainer/Log Pis Mean               1.73662
trainer/Log Pis Std                1.48807
trainer/Log Pis Max                7.42164
trainer/Log Pis Min               -2.4004
trainer/Policy mu Mean            -0.0783531
trainer/Policy mu Std              0.897729
trainer/Policy mu Max              3.19154
trainer/Policy mu Min             -2.90462
trainer/Policy log std Mean       -1.75332
trainer/Policy log std Std         0.44958
trainer/Policy log std Max        -0.461078
trainer/Policy log std Min        -2.46197
trainer/Alpha                      0.0463778
trainer/Alpha Loss                -0.808803
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.652876
exploration/Rewards Std            0.785251
exploration/Rewards Max           -0.0230563
exploration/Rewards Min           -8.06191
exploration/Returns Mean         -65.2876
exploration/Returns Std           30.5712
exploration/Returns Max          -22.6066
exploration/Returns Min         -104.881
exploration/Actions Mean          -0.00950992
exploration/Actions Std            0.228459
exploration/Actions Max            0.957472
exploration/Actions Min           -0.998701
exploration/Num Paths              5
exploration/Average Returns      -65.2876
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.762833
evaluation/Rewards Std             0.884171
evaluation/Rewards Max            -0.0973968
evaluation/Rewards Min            -9.76136
evaluation/Returns Mean          -76.2833
evaluation/Returns Std            24.9511
evaluation/Returns Max           -13.9044
evaluation/Returns Min          -115.224
evaluation/Actions Mean            0.00610067
evaluation/Actions Std             0.180922
evaluation/Actions Max             0.999054
evaluation/Actions Min            -0.999222
evaluation/Num Paths              15
evaluation/Average Returns       -76.2833
time/data storing (s)              0.00303621
time/evaluation sampling (s)       0.334792
time/exploration sampling (s)      0.14717
time/logging (s)                   0.0036479
time/saving (s)                    0.00195012
time/training (s)                  1.92484
time/epoch (s)                     2.41543
time/total (s)                    80.6515
Epoch                             32
-----------------------------  --------------
2019-04-22 22:37:57.254369 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   3.81171
trainer/QF2 Loss                   3.85894
trainer/Policy Loss               38.051
trainer/Q1 Predictions Mean      -36.8013
trainer/Q1 Predictions Std        20.758
trainer/Q1 Predictions Max       -16.5663
trainer/Q1 Predictions Min      -103.445
trainer/Q2 Predictions Mean      -36.7831
trainer/Q2 Predictions Std        20.7868
trainer/Q2 Predictions Max       -16.6702
trainer/Q2 Predictions Min      -103.91
trainer/Q Targets Mean           -36.8524
trainer/Q Targets Std             21.0871
trainer/Q Targets Max             -0.670168
trainer/Q Targets Min           -105.935
trainer/Log Pis Mean               2.00113
trainer/Log Pis Std                1.51032
trainer/Log Pis Max                7.11112
trainer/Log Pis Min               -2.47492
trainer/Policy mu Mean             0.0752065
trainer/Policy mu Std              0.864779
trainer/Policy mu Max              2.93802
trainer/Policy mu Min             -3.6746
trainer/Policy log std Mean       -1.84645
trainer/Policy log std Std         0.441209
trainer/Policy log std Max        -0.481006
trainer/Policy log std Min        -2.4853
trainer/Alpha                      0.0456326
trainer/Alpha Loss                 0.00350258
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.877444
exploration/Rewards Std            0.697534
exploration/Rewards Max           -0.0408192
exploration/Rewards Min           -6.57919
exploration/Returns Mean         -87.7444
exploration/Returns Std           46.4094
exploration/Returns Max          -26.3576
exploration/Returns Min         -132.643
exploration/Actions Mean           0.0131322
exploration/Actions Std            0.234749
exploration/Actions Max            0.999246
exploration/Actions Min           -0.999219
exploration/Num Paths              5
exploration/Average Returns      -87.7444
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.783369
evaluation/Rewards Std             0.964465
evaluation/Rewards Max            -0.105774
evaluation/Rewards Min           -10.5655
evaluation/Returns Mean          -78.3369
evaluation/Returns Std            44.6298
evaluation/Returns Max           -22.2992
evaluation/Returns Min          -145.249
evaluation/Actions Mean            0.00241263
evaluation/Actions Std             0.181359
evaluation/Actions Max             0.999577
evaluation/Actions Min            -0.998674
evaluation/Num Paths              15
evaluation/Average Returns       -78.3369
time/data storing (s)              0.00315612
time/evaluation sampling (s)       0.325433
time/exploration sampling (s)      0.147129
time/logging (s)                   0.00486572
time/saving (s)                    0.00157117
time/training (s)                  1.96438
time/epoch (s)                     2.44654
time/total (s)                    83.1019
Epoch                             33
-----------------------------  --------------
2019-04-22 22:37:59.734933 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                  26.1745
trainer/QF2 Loss                  25.9433
trainer/Policy Loss               39.4787
trainer/Q1 Predictions Mean      -38.5235
trainer/Q1 Predictions Std        21.0028
trainer/Q1 Predictions Max       -16.6038
trainer/Q1 Predictions Min       -94.7609
trainer/Q2 Predictions Mean      -38.5102
trainer/Q2 Predictions Std        21.0325
trainer/Q2 Predictions Max       -16.6484
trainer/Q2 Predictions Min       -94.6101
trainer/Q Targets Mean           -38.2011
trainer/Q Targets Std             21.8996
trainer/Q Targets Max             -0.359977
trainer/Q Targets Min            -95.8966
trainer/Log Pis Mean               2.16964
trainer/Log Pis Std                1.80409
trainer/Log Pis Max                7.82977
trainer/Log Pis Min               -1.63004
trainer/Policy mu Mean            -0.164021
trainer/Policy mu Std              1.08184
trainer/Policy mu Max              3.08425
trainer/Policy mu Min             -3.46375
trainer/Policy log std Mean       -1.72734
trainer/Policy log std Std         0.55242
trainer/Policy log std Max        -0.194523
trainer/Policy log std Min        -2.71232
trainer/Alpha                      0.0452541
trainer/Alpha Loss                 0.525128
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.496445
exploration/Rewards Std            0.885407
exploration/Rewards Max           -0.0165471
exploration/Rewards Min           -6.94088
exploration/Returns Mean         -49.6445
exploration/Returns Std            9.62629
exploration/Returns Max          -33.668
exploration/Returns Min          -59.9663
exploration/Actions Mean          -0.022226
exploration/Actions Std            0.230478
exploration/Actions Max            0.999546
exploration/Actions Min           -0.999444
exploration/Num Paths              5
exploration/Average Returns      -49.6445
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.703482
evaluation/Rewards Std             0.883855
evaluation/Rewards Max            -0.158021
evaluation/Rewards Min            -8.9679
evaluation/Returns Mean          -70.3482
evaluation/Returns Std            36.2561
evaluation/Returns Max           -28.1423
evaluation/Returns Min          -125.221
evaluation/Actions Mean            0.00478037
evaluation/Actions Std             0.177044
evaluation/Actions Max             0.998794
evaluation/Actions Min            -0.995861
evaluation/Num Paths              15
evaluation/Average Returns       -70.3482
time/data storing (s)              0.00304924
time/evaluation sampling (s)       0.333479
time/exploration sampling (s)      0.146625
time/logging (s)                   0.00484936
time/saving (s)                    0.0019852
time/training (s)                  1.98489
time/epoch (s)                     2.47488
time/total (s)                    85.5813
Epoch                             34
-----------------------------  --------------
2019-04-22 22:38:02.185257 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 35 finished
-----------------------------  ---------------
replay_buffer/size             18200
trainer/QF1 Loss                  13.6413
trainer/QF2 Loss                  13.5431
trainer/Policy Loss               40.842
trainer/Q1 Predictions Mean      -39.6677
trainer/Q1 Predictions Std        21.6236
trainer/Q1 Predictions Max       -16.0997
trainer/Q1 Predictions Min       -90.1766
trainer/Q2 Predictions Mean      -39.6658
trainer/Q2 Predictions Std        21.6122
trainer/Q2 Predictions Max       -16.1795
trainer/Q2 Predictions Min       -89.8517
trainer/Q Targets Mean           -39.5555
trainer/Q Targets Std             22.2146
trainer/Q Targets Max             -0.394126
trainer/Q Targets Min            -91.9616
trainer/Log Pis Mean               2.25711
trainer/Log Pis Std                1.96308
trainer/Log Pis Max                9.54564
trainer/Log Pis Min               -3.19513
trainer/Policy mu Mean            -0.134348
trainer/Policy mu Std              1.17226
trainer/Policy mu Max              3.54513
trainer/Policy mu Min             -3.30885
trainer/Policy log std Mean       -1.67648
trainer/Policy log std Std         0.524972
trainer/Policy log std Max        -0.295619
trainer/Policy log std Min        -2.48994
trainer/Alpha                      0.0440802
trainer/Alpha Loss                 0.802594
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.497948
exploration/Rewards Std            0.871848
exploration/Rewards Max           -0.00401592
exploration/Rewards Min           -8.76501
exploration/Returns Mean         -49.7948
exploration/Returns Std           25.4608
exploration/Returns Max          -18.3451
exploration/Returns Min          -89.3219
exploration/Actions Mean           0.00841818
exploration/Actions Std            0.244743
exploration/Actions Max            0.997337
exploration/Actions Min           -0.996915
exploration/Num Paths              5
exploration/Average Returns      -49.7948
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.500614
evaluation/Rewards Std             1.06305
evaluation/Rewards Max            -0.0159511
evaluation/Rewards Min           -10.2033
evaluation/Returns Mean          -50.0614
evaluation/Returns Std            33.6661
evaluation/Returns Max            -6.18627
evaluation/Returns Min          -118.518
evaluation/Actions Mean            0.000645952
evaluation/Actions Std             0.17816
evaluation/Actions Max             0.998961
evaluation/Actions Min            -0.999619
evaluation/Num Paths              15
evaluation/Average Returns       -50.0614
time/data storing (s)              0.00296736
time/evaluation sampling (s)       0.339561
time/exploration sampling (s)      0.143753
time/logging (s)                   0.00487272
time/saving (s)                    0.00195663
time/training (s)                  1.95238
time/epoch (s)                     2.44549
time/total (s)                    88.0307
Epoch                             35
-----------------------------  ---------------
2019-04-22 22:38:04.625453 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                   3.26785
trainer/QF2 Loss                   3.19827
trainer/Policy Loss               35.0787
trainer/Q1 Predictions Mean      -33.6836
trainer/Q1 Predictions Std        20.4607
trainer/Q1 Predictions Max       -16.0756
trainer/Q1 Predictions Min       -80.6145
trainer/Q2 Predictions Mean      -33.6971
trainer/Q2 Predictions Std        20.4397
trainer/Q2 Predictions Max       -16.1262
trainer/Q2 Predictions Min       -81.4068
trainer/Q Targets Mean           -34.1017
trainer/Q Targets Std             21.1225
trainer/Q Targets Max             -0.581778
trainer/Q Targets Min            -82.4447
trainer/Log Pis Mean               1.92342
trainer/Log Pis Std                1.44081
trainer/Log Pis Max                7.25319
trainer/Log Pis Min               -2.06963
trainer/Policy mu Mean            -0.0210772
trainer/Policy mu Std              0.900762
trainer/Policy mu Max              2.96042
trainer/Policy mu Min             -3.94833
trainer/Policy log std Mean       -1.80177
trainer/Policy log std Std         0.460017
trainer/Policy log std Max        -0.287222
trainer/Policy log std Min        -2.46317
trainer/Alpha                      0.0419848
trainer/Alpha Loss                -0.242796
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.638613
exploration/Rewards Std            1.07598
exploration/Rewards Max           -0.0123258
exploration/Rewards Min           -9.17088
exploration/Returns Mean         -63.8613
exploration/Returns Std           47.5045
exploration/Returns Max          -27.0675
exploration/Returns Min         -156.351
exploration/Actions Mean           0.010211
exploration/Actions Std            0.25684
exploration/Actions Max            0.99979
exploration/Actions Min           -0.998125
exploration/Num Paths              5
exploration/Average Returns      -63.8613
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.730156
evaluation/Rewards Std             0.798574
evaluation/Rewards Max            -0.00625281
evaluation/Rewards Min            -8.8383
evaluation/Returns Mean          -73.0156
evaluation/Returns Std            45.2928
evaluation/Returns Max           -17.7427
evaluation/Returns Min          -130.992
evaluation/Actions Mean           -0.0036228
evaluation/Actions Std             0.166106
evaluation/Actions Max             0.998011
evaluation/Actions Min            -0.998516
evaluation/Num Paths              15
evaluation/Average Returns       -73.0156
time/data storing (s)              0.0030606
time/evaluation sampling (s)       0.325865
time/exploration sampling (s)      0.14743
time/logging (s)                   0.00486937
time/saving (s)                    0.0019494
time/training (s)                  1.9513
time/epoch (s)                     2.43448
time/total (s)                    90.4697
Epoch                             36
-----------------------------  --------------
2019-04-22 22:38:07.069856 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 37 finished
-----------------------------  ---------------
replay_buffer/size             19200
trainer/QF1 Loss                  60.2596
trainer/QF2 Loss                  59.7362
trainer/Policy Loss               34.1765
trainer/Q1 Predictions Mean      -32.8529
trainer/Q1 Predictions Std        19.3836
trainer/Q1 Predictions Max       -15.7485
trainer/Q1 Predictions Min       -93.5943
trainer/Q2 Predictions Mean      -32.8611
trainer/Q2 Predictions Std        19.3858
trainer/Q2 Predictions Max       -15.8389
trainer/Q2 Predictions Min       -93.644
trainer/Q Targets Mean           -32.0626
trainer/Q Targets Std             19.6032
trainer/Q Targets Max             -0.464302
trainer/Q Targets Min            -93.8603
trainer/Log Pis Mean               2.10123
trainer/Log Pis Std                1.34931
trainer/Log Pis Max                7.53015
trainer/Log Pis Min               -1.21296
trainer/Policy mu Mean            -0.16424
trainer/Policy mu Std              0.962122
trainer/Policy mu Max              3.08123
trainer/Policy mu Min             -3.5957
trainer/Policy log std Mean       -1.80638
trainer/Policy log std Std         0.496022
trainer/Policy log std Max        -0.374064
trainer/Policy log std Min        -2.54524
trainer/Alpha                      0.0417107
trainer/Alpha Loss                 0.321623
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.56334
exploration/Rewards Std            0.847774
exploration/Rewards Max           -0.00468031
exploration/Rewards Min           -9.57702
exploration/Returns Mean         -56.334
exploration/Returns Std           30.623
exploration/Returns Max          -28.2608
exploration/Returns Min         -106.467
exploration/Actions Mean          -0.0182385
exploration/Actions Std            0.221865
exploration/Actions Max            0.996706
exploration/Actions Min           -0.998205
exploration/Num Paths              5
exploration/Average Returns      -56.334
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.570035
evaluation/Rewards Std             0.937291
evaluation/Rewards Max            -0.0408645
evaluation/Rewards Min           -10.0513
evaluation/Returns Mean          -57.0035
evaluation/Returns Std            39.1959
evaluation/Returns Max           -10.1757
evaluation/Returns Min          -140.405
evaluation/Actions Mean           -0.000246625
evaluation/Actions Std             0.187598
evaluation/Actions Max             0.998049
evaluation/Actions Min            -0.999193
evaluation/Num Paths              15
evaluation/Average Returns       -57.0035
time/data storing (s)              0.00308995
time/evaluation sampling (s)       0.332208
time/exploration sampling (s)      0.147165
time/logging (s)                   0.00485122
time/saving (s)                    0.00196168
time/training (s)                  1.94945
time/epoch (s)                     2.43873
time/total (s)                    92.9129
Epoch                             37
-----------------------------  ---------------
2019-04-22 22:38:09.494767 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 38 finished
-----------------------------  ---------------
replay_buffer/size             19700
trainer/QF1 Loss                   0.381749
trainer/QF2 Loss                   0.357606
trainer/Policy Loss               36.1517
trainer/Q1 Predictions Mean      -35.237
trainer/Q1 Predictions Std        20.9858
trainer/Q1 Predictions Max       -15.6743
trainer/Q1 Predictions Min       -84.6248
trainer/Q2 Predictions Mean      -35.264
trainer/Q2 Predictions Std        20.9605
trainer/Q2 Predictions Max       -15.6638
trainer/Q2 Predictions Min       -84.4886
trainer/Q Targets Mean           -35.5953
trainer/Q Targets Std             21.1897
trainer/Q Targets Max            -15.5702
trainer/Q Targets Min            -86.4135
trainer/Log Pis Mean               2.10625
trainer/Log Pis Std                1.42899
trainer/Log Pis Max                6.18632
trainer/Log Pis Min               -1.40319
trainer/Policy mu Mean            -0.0271179
trainer/Policy mu Std              0.951621
trainer/Policy mu Max              3.83651
trainer/Policy mu Min             -2.93261
trainer/Policy log std Mean       -1.85516
trainer/Policy log std Std         0.489897
trainer/Policy log std Max        -0.290919
trainer/Policy log std Min        -2.61483
trainer/Alpha                      0.0417738
trainer/Alpha Loss                 0.337413
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.523823
exploration/Rewards Std            0.975933
exploration/Rewards Max           -0.0129335
exploration/Rewards Min           -8.74105
exploration/Returns Mean         -52.3823
exploration/Returns Std           39.2705
exploration/Returns Max          -23.4451
exploration/Returns Min         -124.698
exploration/Actions Mean          -0.0279554
exploration/Actions Std            0.211754
exploration/Actions Max            0.98889
exploration/Actions Min           -0.999889
exploration/Num Paths              5
exploration/Average Returns      -52.3823
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.557459
evaluation/Rewards Std             0.73332
evaluation/Rewards Max            -0.0481162
evaluation/Rewards Min           -10.0871
evaluation/Returns Mean          -55.7459
evaluation/Returns Std            30.872
evaluation/Returns Max           -14.5196
evaluation/Returns Min          -129.541
evaluation/Actions Mean           -0.000203204
evaluation/Actions Std             0.16937
evaluation/Actions Max             0.998108
evaluation/Actions Min            -0.998768
evaluation/Num Paths              15
evaluation/Average Returns       -55.7459
time/data storing (s)              0.00295684
time/evaluation sampling (s)       0.328849
time/exploration sampling (s)      0.144098
time/logging (s)                   0.00491556
time/saving (s)                    0.00194549
time/training (s)                  1.93642
time/epoch (s)                     2.41919
time/total (s)                    95.3367
Epoch                             38
-----------------------------  ---------------
2019-04-22 22:38:11.921510 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                   8.599
trainer/QF2 Loss                   8.39699
trainer/Policy Loss               38.4075
trainer/Q1 Predictions Mean      -37.1847
trainer/Q1 Predictions Std        22.7506
trainer/Q1 Predictions Max       -15.3145
trainer/Q1 Predictions Min       -98.6244
trainer/Q2 Predictions Mean      -37.1719
trainer/Q2 Predictions Std        22.7356
trainer/Q2 Predictions Max       -15.2892
trainer/Q2 Predictions Min       -99.0711
trainer/Q Targets Mean           -36.8352
trainer/Q Targets Std             23.5074
trainer/Q Targets Max             -0.201764
trainer/Q Targets Min           -101.396
trainer/Log Pis Mean               2.24085
trainer/Log Pis Std                1.84885
trainer/Log Pis Max                8.69974
trainer/Log Pis Min               -3.10301
trainer/Policy mu Mean            -0.204395
trainer/Policy mu Std              1.06141
trainer/Policy mu Max              2.93648
trainer/Policy mu Min             -3.82491
trainer/Policy log std Mean       -1.7676
trainer/Policy log std Std         0.539373
trainer/Policy log std Max        -0.121126
trainer/Policy log std Min        -2.46184
trainer/Alpha                      0.0423623
trainer/Alpha Loss                 0.761426
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.524372
exploration/Rewards Std            0.329991
exploration/Rewards Max           -0.0314236
exploration/Rewards Min           -3.75499
exploration/Returns Mean         -52.4372
exploration/Returns Std           19.4977
exploration/Returns Max          -23.5149
exploration/Returns Min          -76.1355
exploration/Actions Mean          -0.00125906
exploration/Actions Std            0.18351
exploration/Actions Max            0.983214
exploration/Actions Min           -0.979995
exploration/Num Paths              5
exploration/Average Returns      -52.4372
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.589352
evaluation/Rewards Std             1.03302
evaluation/Rewards Max            -0.0325729
evaluation/Rewards Min           -10.1436
evaluation/Returns Mean          -58.9352
evaluation/Returns Std            23.0305
evaluation/Returns Max           -21.2395
evaluation/Returns Min          -103.026
evaluation/Actions Mean            0.00203745
evaluation/Actions Std             0.203982
evaluation/Actions Max             0.999019
evaluation/Actions Min            -0.997253
evaluation/Num Paths              15
evaluation/Average Returns       -58.9352
time/data storing (s)              0.00314265
time/evaluation sampling (s)       0.331603
time/exploration sampling (s)      0.144793
time/logging (s)                   0.00484235
time/saving (s)                    0.00721867
time/training (s)                  1.9294
time/epoch (s)                     2.421
time/total (s)                    97.7622
Epoch                             39
-----------------------------  --------------
2019-04-22 22:38:14.346483 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size             20700
trainer/QF1 Loss                  74.8988
trainer/QF2 Loss                  72.8049
trainer/Policy Loss               37.9065
trainer/Q1 Predictions Mean      -36.7611
trainer/Q1 Predictions Std        21.7528
trainer/Q1 Predictions Max       -14.8322
trainer/Q1 Predictions Min       -97.3174
trainer/Q2 Predictions Mean      -36.7358
trainer/Q2 Predictions Std        21.6887
trainer/Q2 Predictions Max       -14.7894
trainer/Q2 Predictions Min       -96.0113
trainer/Q Targets Mean           -36.4448
trainer/Q Targets Std             21.7537
trainer/Q Targets Max             -0.0606619
trainer/Q Targets Min            -90.2333
trainer/Log Pis Mean               1.94311
trainer/Log Pis Std                1.96008
trainer/Log Pis Max                9.53008
trainer/Log Pis Min               -4.13848
trainer/Policy mu Mean             0.0318773
trainer/Policy mu Std              1.01508
trainer/Policy mu Max              3.67221
trainer/Policy mu Min             -3.19967
trainer/Policy log std Mean       -1.80396
trainer/Policy log std Std         0.543278
trainer/Policy log std Max        -0.156542
trainer/Policy log std Min        -2.53396
trainer/Alpha                      0.0422185
trainer/Alpha Loss                -0.180045
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.727956
exploration/Rewards Std            1.16024
exploration/Rewards Max           -0.0138652
exploration/Rewards Min          -10.0446
exploration/Returns Mean         -72.7956
exploration/Returns Std           39.8962
exploration/Returns Max          -19.3022
exploration/Returns Min         -121.543
exploration/Actions Mean          -0.0128663
exploration/Actions Std            0.260966
exploration/Actions Max            0.999745
exploration/Actions Min           -0.998253
exploration/Num Paths              5
exploration/Average Returns      -72.7956
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.645046
evaluation/Rewards Std             1.07087
evaluation/Rewards Max            -0.115448
evaluation/Rewards Min           -10.6719
evaluation/Returns Mean          -64.5046
evaluation/Returns Std            31.2741
evaluation/Returns Max           -21.8787
evaluation/Returns Min          -113.119
evaluation/Actions Mean           -0.00286993
evaluation/Actions Std             0.192975
evaluation/Actions Max             0.999551
evaluation/Actions Min            -0.999404
evaluation/Num Paths              15
evaluation/Average Returns       -64.5046
time/data storing (s)              0.00304825
time/evaluation sampling (s)       0.327077
time/exploration sampling (s)      0.143506
time/logging (s)                   0.0047656
time/saving (s)                    0.00193972
time/training (s)                  1.9389
time/epoch (s)                     2.41924
time/total (s)                   100.186
Epoch                             40
-----------------------------  --------------
2019-04-22 22:38:16.794188 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                   0.367575
trainer/QF2 Loss                   0.295149
trainer/Policy Loss               37.4144
trainer/Q1 Predictions Mean      -36.1295
trainer/Q1 Predictions Std        18.8104
trainer/Q1 Predictions Max       -14.8606
trainer/Q1 Predictions Min       -81.8755
trainer/Q2 Predictions Mean      -36.1305
trainer/Q2 Predictions Std        18.8629
trainer/Q2 Predictions Max       -14.8422
trainer/Q2 Predictions Min       -81.9288
trainer/Q Targets Mean           -36.4093
trainer/Q Targets Std             19.0049
trainer/Q Targets Max            -14.9921
trainer/Q Targets Min            -82.7375
trainer/Log Pis Mean               1.95429
trainer/Log Pis Std                1.81671
trainer/Log Pis Max                6.79835
trainer/Log Pis Min               -4.60295
trainer/Policy mu Mean            -0.0338942
trainer/Policy mu Std              1.03349
trainer/Policy mu Max              3.50028
trainer/Policy mu Min             -2.78839
trainer/Policy log std Mean       -1.76231
trainer/Policy log std Std         0.48675
trainer/Policy log std Max        -0.320582
trainer/Policy log std Min        -2.41466
trainer/Alpha                      0.0425286
trainer/Alpha Loss                -0.144333
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.883144
exploration/Rewards Std            1.02098
exploration/Rewards Max           -0.0865304
exploration/Rewards Min           -8.86264
exploration/Returns Mean         -88.3144
exploration/Returns Std           26.32
exploration/Returns Max          -42.9973
exploration/Returns Min         -119.86
exploration/Actions Mean          -0.0268973
exploration/Actions Std            0.238715
exploration/Actions Max            0.971763
exploration/Actions Min           -0.999238
exploration/Num Paths              5
exploration/Average Returns      -88.3144
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.496616
evaluation/Rewards Std             0.872062
evaluation/Rewards Max            -0.1126
evaluation/Rewards Min            -9.06116
evaluation/Returns Mean          -49.6616
evaluation/Returns Std            24.0352
evaluation/Returns Max           -20.6897
evaluation/Returns Min          -116.78
evaluation/Actions Mean           -0.00438727
evaluation/Actions Std             0.192576
evaluation/Actions Max             0.99744
evaluation/Actions Min            -0.999425
evaluation/Num Paths              15
evaluation/Average Returns       -49.6616
time/data storing (s)              0.00293267
time/evaluation sampling (s)       0.327857
time/exploration sampling (s)      0.149092
time/logging (s)                   0.00487439
time/saving (s)                    0.00155131
time/training (s)                  1.95592
time/epoch (s)                     2.44222
time/total (s)                   102.632
Epoch                             41
-----------------------------  --------------
2019-04-22 22:38:19.224149 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size             21700
trainer/QF1 Loss                   0.306081
trainer/QF2 Loss                   0.244571
trainer/Policy Loss               37.2262
trainer/Q1 Predictions Mean      -35.8721
trainer/Q1 Predictions Std        21.3549
trainer/Q1 Predictions Max       -14.3942
trainer/Q1 Predictions Min       -74.2548
trainer/Q2 Predictions Mean      -35.942
trainer/Q2 Predictions Std        21.4007
trainer/Q2 Predictions Max       -14.4121
trainer/Q2 Predictions Min       -75.1695
trainer/Q Targets Mean           -36.1827
trainer/Q Targets Std             21.3769
trainer/Q Targets Max            -14.5512
trainer/Q Targets Min            -74.034
trainer/Log Pis Mean               1.98502
trainer/Log Pis Std                1.64338
trainer/Log Pis Max                6.79817
trainer/Log Pis Min               -3.4698
trainer/Policy mu Mean             0.00670093
trainer/Policy mu Std              0.897847
trainer/Policy mu Max              3.52977
trainer/Policy mu Min             -3.14767
trainer/Policy log std Mean       -1.94147
trainer/Policy log std Std         0.486878
trainer/Policy log std Max        -0.293555
trainer/Policy log std Min        -2.50127
trainer/Alpha                      0.0432587
trainer/Alpha Loss                -0.0470546
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.771524
exploration/Rewards Std            1.27302
exploration/Rewards Max           -0.0111297
exploration/Rewards Min          -11.2743
exploration/Returns Mean         -77.1524
exploration/Returns Std           30.0153
exploration/Returns Max          -27.2486
exploration/Returns Min         -108.784
exploration/Actions Mean          -0.0272243
exploration/Actions Std            0.246845
exploration/Actions Max            0.999813
exploration/Actions Min           -0.999705
exploration/Num Paths              5
exploration/Average Returns      -77.1524
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.658595
evaluation/Rewards Std             1.17637
evaluation/Rewards Max            -0.0376728
evaluation/Rewards Min           -10.8557
evaluation/Returns Mean          -65.8595
evaluation/Returns Std            37.3714
evaluation/Returns Max           -15.1544
evaluation/Returns Min          -129.9
evaluation/Actions Mean           -0.00792195
evaluation/Actions Std             0.209926
evaluation/Actions Max             0.999128
evaluation/Actions Min            -0.999861
evaluation/Num Paths              15
evaluation/Average Returns       -65.8595
time/data storing (s)              0.00307472
time/evaluation sampling (s)       0.330635
time/exploration sampling (s)      0.143813
time/logging (s)                   0.00425621
time/saving (s)                    0.00198555
time/training (s)                  1.93978
time/epoch (s)                     2.42355
time/total (s)                   105.06
Epoch                             42
-----------------------------  --------------
2019-04-22 22:38:21.664363 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size             22200
trainer/QF1 Loss                   0.297752
trainer/QF2 Loss                   0.333723
trainer/Policy Loss               35.1407
trainer/Q1 Predictions Mean      -33.6163
trainer/Q1 Predictions Std        20.9416
trainer/Q1 Predictions Max       -14.6639
trainer/Q1 Predictions Min       -97.5651
trainer/Q2 Predictions Mean      -33.61
trainer/Q2 Predictions Std        20.8998
trainer/Q2 Predictions Max       -14.6569
trainer/Q2 Predictions Min       -96.3414
trainer/Q Targets Mean           -33.723
trainer/Q Targets Std             21.1499
trainer/Q Targets Max            -14.3773
trainer/Q Targets Min            -98.7456
trainer/Log Pis Mean               2.14732
trainer/Log Pis Std                1.62319
trainer/Log Pis Max                8.4275
trainer/Log Pis Min               -2.39589
trainer/Policy mu Mean             0.0286243
trainer/Policy mu Std              0.978099
trainer/Policy mu Max              3.9163
trainer/Policy mu Min             -4.02458
trainer/Policy log std Mean       -1.89048
trainer/Policy log std Std         0.498431
trainer/Policy log std Max        -0.172827
trainer/Policy log std Min        -2.35959
trainer/Alpha                      0.0458458
trainer/Alpha Loss                 0.454136
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.37359
exploration/Rewards Std            0.827718
exploration/Rewards Max           -0.00412733
exploration/Rewards Min           -7.78297
exploration/Returns Mean         -37.359
exploration/Returns Std           16.8212
exploration/Returns Max          -16.4272
exploration/Returns Min          -65.2985
exploration/Actions Mean           0.0121536
exploration/Actions Std            0.228039
exploration/Actions Max            0.999838
exploration/Actions Min           -0.996873
exploration/Num Paths              5
exploration/Average Returns      -37.359
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.566058
evaluation/Rewards Std             0.867734
evaluation/Rewards Max            -0.0285244
evaluation/Rewards Min            -9.71166
evaluation/Returns Mean          -56.6058
evaluation/Returns Std            28.3476
evaluation/Returns Max           -16.9307
evaluation/Returns Min          -101.289
evaluation/Actions Mean            0.00666854
evaluation/Actions Std             0.176046
evaluation/Actions Max             0.999477
evaluation/Actions Min            -0.997378
evaluation/Num Paths              15
evaluation/Average Returns       -56.6058
time/data storing (s)              0.00295841
time/evaluation sampling (s)       0.327285
time/exploration sampling (s)      0.144213
time/logging (s)                   0.00486716
time/saving (s)                    0.00195187
time/training (s)                  1.95431
time/epoch (s)                     2.43559
time/total (s)                   107.5
Epoch                             43
-----------------------------  --------------
2019-04-22 22:38:24.086514 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 44 finished
-----------------------------  ---------------
replay_buffer/size             22700
trainer/QF1 Loss                   0.515981
trainer/QF2 Loss                   0.416812
trainer/Policy Loss               36.2486
trainer/Q1 Predictions Mean      -34.7959
trainer/Q1 Predictions Std        20.9496
trainer/Q1 Predictions Max       -13.7094
trainer/Q1 Predictions Min       -94.7095
trainer/Q2 Predictions Mean      -34.7938
trainer/Q2 Predictions Std        20.9807
trainer/Q2 Predictions Max       -13.6752
trainer/Q2 Predictions Min       -95.9283
trainer/Q Targets Mean           -35.199
trainer/Q Targets Std             21.0404
trainer/Q Targets Max            -14.1448
trainer/Q Targets Min            -97.4008
trainer/Log Pis Mean               1.8025
trainer/Log Pis Std                1.21831
trainer/Log Pis Max                6.16257
trainer/Log Pis Min               -1.82459
trainer/Policy mu Mean            -0.0431431
trainer/Policy mu Std              0.856874
trainer/Policy mu Max              3.15951
trainer/Policy mu Min             -3.7346
trainer/Policy log std Mean       -1.8584
trainer/Policy log std Std         0.472615
trainer/Policy log std Max        -0.313818
trainer/Policy log std Min        -2.35402
trainer/Alpha                      0.0464651
trainer/Alpha Loss                -0.606134
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.404358
exploration/Rewards Std            0.939313
exploration/Rewards Max           -0.00956283
exploration/Rewards Min           -9.05919
exploration/Returns Mean         -40.4358
exploration/Returns Std           21.8822
exploration/Returns Max          -19.9615
exploration/Returns Min          -77.4606
exploration/Actions Mean           0.000969134
exploration/Actions Std            0.224582
exploration/Actions Max            0.999918
exploration/Actions Min           -0.999202
exploration/Num Paths              5
exploration/Average Returns      -40.4358
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.408948
evaluation/Rewards Std             0.769752
evaluation/Rewards Max            -0.0261127
evaluation/Rewards Min           -10.0787
evaluation/Returns Mean          -40.8948
evaluation/Returns Std            34.1001
evaluation/Returns Max            -4.25371
evaluation/Returns Min          -105.21
evaluation/Actions Mean            0.00488947
evaluation/Actions Std             0.156674
evaluation/Actions Max             0.997427
evaluation/Actions Min            -0.998481
evaluation/Num Paths              15
evaluation/Average Returns       -40.8948
time/data storing (s)              0.00282091
time/evaluation sampling (s)       0.329654
time/exploration sampling (s)      0.139588
time/logging (s)                   0.0042407
time/saving (s)                    0.00194979
time/training (s)                  1.9374
time/epoch (s)                     2.41566
time/total (s)                   109.921
Epoch                             44
-----------------------------  ---------------
2019-04-22 22:38:26.519313 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                  19.2468
trainer/QF2 Loss                  19.2328
trainer/Policy Loss               36.6258
trainer/Q1 Predictions Mean      -35.6319
trainer/Q1 Predictions Std        21.3991
trainer/Q1 Predictions Max       -13.566
trainer/Q1 Predictions Min       -94.0858
trainer/Q2 Predictions Mean      -35.6264
trainer/Q2 Predictions Std        21.3543
trainer/Q2 Predictions Max       -13.6195
trainer/Q2 Predictions Min       -94.1683
trainer/Q Targets Mean           -35.7715
trainer/Q Targets Std             22.0161
trainer/Q Targets Max             -0.103869
trainer/Q Targets Min            -94.9992
trainer/Log Pis Mean               1.65041
trainer/Log Pis Std                1.39436
trainer/Log Pis Max                8.26283
trainer/Log Pis Min               -3.67908
trainer/Policy mu Mean            -0.0847111
trainer/Policy mu Std              0.890617
trainer/Policy mu Max              2.87229
trainer/Policy mu Min             -3.86182
trainer/Policy log std Mean       -1.85737
trainer/Policy log std Std         0.499924
trainer/Policy log std Max        -0.307887
trainer/Policy log std Min        -2.49892
trainer/Alpha                      0.0469479
trainer/Alpha Loss                -1.06924
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.728758
exploration/Rewards Std            1.20152
exploration/Rewards Max           -0.0187301
exploration/Rewards Min          -10.1265
exploration/Returns Mean         -72.8758
exploration/Returns Std           32.3941
exploration/Returns Max          -29.0767
exploration/Returns Min         -125.148
exploration/Actions Mean          -0.0184808
exploration/Actions Std            0.256608
exploration/Actions Max            0.998336
exploration/Actions Min           -0.999901
exploration/Num Paths              5
exploration/Average Returns      -72.8758
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.715612
evaluation/Rewards Std             0.957385
evaluation/Rewards Max            -0.171648
evaluation/Rewards Min           -10.1575
evaluation/Returns Mean          -71.5612
evaluation/Returns Std            28.1334
evaluation/Returns Max           -34.7163
evaluation/Returns Min          -126.324
evaluation/Actions Mean           -0.0129751
evaluation/Actions Std             0.185294
evaluation/Actions Max             0.998605
evaluation/Actions Min            -0.999779
evaluation/Num Paths              15
evaluation/Average Returns       -71.5612
time/data storing (s)              0.00286429
time/evaluation sampling (s)       0.32743
time/exploration sampling (s)      0.13947
time/logging (s)                   0.00484961
time/saving (s)                    0.0019624
time/training (s)                  1.95107
time/epoch (s)                     2.42765
time/total (s)                   112.353
Epoch                             45
-----------------------------  --------------
2019-04-22 22:38:28.949959 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                  36.7697
trainer/QF2 Loss                  36.8291
trainer/Policy Loss               34.4446
trainer/Q1 Predictions Mean      -33.2237
trainer/Q1 Predictions Std        21.1977
trainer/Q1 Predictions Max       -13.5366
trainer/Q1 Predictions Min       -85.7253
trainer/Q2 Predictions Mean      -33.2235
trainer/Q2 Predictions Std        21.2046
trainer/Q2 Predictions Max       -13.5792
trainer/Q2 Predictions Min       -85.821
trainer/Q Targets Mean           -33.0514
trainer/Q Targets Std             21.538
trainer/Q Targets Max             -1.01925
trainer/Q Targets Min            -88.3026
trainer/Log Pis Mean               1.93075
trainer/Log Pis Std                1.66681
trainer/Log Pis Max                8.48181
trainer/Log Pis Min               -3.32802
trainer/Policy mu Mean            -0.0974669
trainer/Policy mu Std              0.837312
trainer/Policy mu Max              2.99582
trainer/Policy mu Min             -3.40314
trainer/Policy log std Mean       -1.95485
trainer/Policy log std Std         0.481493
trainer/Policy log std Max        -0.339424
trainer/Policy log std Min        -2.5229
trainer/Alpha                      0.0466095
trainer/Alpha Loss                -0.212303
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.8562
exploration/Rewards Std            1.06609
exploration/Rewards Max           -0.0311977
exploration/Rewards Min           -9.54537
exploration/Returns Mean         -85.62
exploration/Returns Std           31.8978
exploration/Returns Max          -49.2982
exploration/Returns Min         -134.351
exploration/Actions Mean          -0.018322
exploration/Actions Std            0.256545
exploration/Actions Max            0.99828
exploration/Actions Min           -0.999963
exploration/Num Paths              5
exploration/Average Returns      -85.62
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.536315
evaluation/Rewards Std             1.03874
evaluation/Rewards Max            -0.0726729
evaluation/Rewards Min            -9.33833
evaluation/Returns Mean          -53.6315
evaluation/Returns Std            32.1723
evaluation/Returns Max           -14.3291
evaluation/Returns Min          -120.323
evaluation/Actions Mean            0.011451
evaluation/Actions Std             0.195508
evaluation/Actions Max             0.999022
evaluation/Actions Min            -0.998662
evaluation/Num Paths              15
evaluation/Average Returns       -53.6315
time/data storing (s)              0.00324243
time/evaluation sampling (s)       0.321582
time/exploration sampling (s)      0.142077
time/logging (s)                   0.00485557
time/saving (s)                    0.00172127
time/training (s)                  1.95128
time/epoch (s)                     2.42476
time/total (s)                   114.782
Epoch                             46
-----------------------------  --------------
2019-04-22 22:38:31.388946 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size             24200
trainer/QF1 Loss                  18.0313
trainer/QF2 Loss                  17.7529
trainer/Policy Loss               34.1328
trainer/Q1 Predictions Mean      -33.1507
trainer/Q1 Predictions Std        18.8847
trainer/Q1 Predictions Max       -13.4716
trainer/Q1 Predictions Min       -75.0273
trainer/Q2 Predictions Mean      -33.1413
trainer/Q2 Predictions Std        18.9305
trainer/Q2 Predictions Max       -13.3943
trainer/Q2 Predictions Min       -75.2622
trainer/Q Targets Mean           -32.9262
trainer/Q Targets Std             19.2426
trainer/Q Targets Max             -1.62139
trainer/Q Targets Min            -75.6116
trainer/Log Pis Mean               1.62882
trainer/Log Pis Std                1.67335
trainer/Log Pis Max                7.19152
trainer/Log Pis Min               -3.39242
trainer/Policy mu Mean            -0.0720131
trainer/Policy mu Std              0.830002
trainer/Policy mu Max              3.51519
trainer/Policy mu Min             -3.24863
trainer/Policy log std Mean       -1.90629
trainer/Policy log std Std         0.515172
trainer/Policy log std Max        -0.508646
trainer/Policy log std Min        -2.59563
trainer/Alpha                      0.0467509
trainer/Alpha Loss                -1.13691
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.681641
exploration/Rewards Std            0.7871
exploration/Rewards Max           -0.00948087
exploration/Rewards Min           -8.29301
exploration/Returns Mean         -68.1641
exploration/Returns Std           30.095
exploration/Returns Max          -25.0601
exploration/Returns Min         -109.121
exploration/Actions Mean           0.00951392
exploration/Actions Std            0.221727
exploration/Actions Max            0.999108
exploration/Actions Min           -0.997166
exploration/Num Paths              5
exploration/Average Returns      -68.1641
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.541549
evaluation/Rewards Std             1.04876
evaluation/Rewards Max            -0.00761831
evaluation/Rewards Min            -9.94898
evaluation/Returns Mean          -54.1549
evaluation/Returns Std            27.9271
evaluation/Returns Max           -14.4425
evaluation/Returns Min          -104.128
evaluation/Actions Mean           -0.00058997
evaluation/Actions Std             0.19007
evaluation/Actions Max             0.999108
evaluation/Actions Min            -0.999714
evaluation/Num Paths              15
evaluation/Average Returns       -54.1549
time/data storing (s)              0.00304448
time/evaluation sampling (s)       0.330346
time/exploration sampling (s)      0.144056
time/logging (s)                   0.00491363
time/saving (s)                    0.00192278
time/training (s)                  1.94891
time/epoch (s)                     2.43319
time/total (s)                   117.22
Epoch                             47
-----------------------------  --------------
2019-04-22 22:38:33.819453 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                   4.26887
trainer/QF2 Loss                   4.12948
trainer/Policy Loss               32.3994
trainer/Q1 Predictions Mean      -31.0088
trainer/Q1 Predictions Std        18.7628
trainer/Q1 Predictions Max       -13.3076
trainer/Q1 Predictions Min       -80.001
trainer/Q2 Predictions Mean      -31.0003
trainer/Q2 Predictions Std        18.7349
trainer/Q2 Predictions Max       -13.3268
trainer/Q2 Predictions Min       -79.7227
trainer/Q Targets Mean           -31.2174
trainer/Q Targets Std             19.1193
trainer/Q Targets Max             -4.36212
trainer/Q Targets Min            -82
trainer/Log Pis Mean               1.9422
trainer/Log Pis Std                1.31514
trainer/Log Pis Max                6.97969
trainer/Log Pis Min               -0.785178
trainer/Policy mu Mean            -0.107566
trainer/Policy mu Std              0.748628
trainer/Policy mu Max              2.74225
trainer/Policy mu Min             -3.77901
trainer/Policy log std Mean       -1.9367
trainer/Policy log std Std         0.474979
trainer/Policy log std Max        -0.455119
trainer/Policy log std Min        -2.47518
trainer/Alpha                      0.0463163
trainer/Alpha Loss                -0.177566
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.531886
exploration/Rewards Std            0.55271
exploration/Rewards Max           -0.0110405
exploration/Rewards Min           -5.18184
exploration/Returns Mean         -53.1886
exploration/Returns Std           28.612
exploration/Returns Max          -26.2792
exploration/Returns Min          -88.3748
exploration/Actions Mean           0.0162037
exploration/Actions Std            0.179102
exploration/Actions Max            0.99722
exploration/Actions Min           -0.808476
exploration/Num Paths              5
exploration/Average Returns      -53.1886
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.584577
evaluation/Rewards Std             1.05006
evaluation/Rewards Max            -0.0484858
evaluation/Rewards Min            -9.83544
evaluation/Returns Mean          -58.4577
evaluation/Returns Std            33.8909
evaluation/Returns Max            -9.11968
evaluation/Returns Min          -130.147
evaluation/Actions Mean            0.00977556
evaluation/Actions Std             0.18886
evaluation/Actions Max             0.99912
evaluation/Actions Min            -0.999502
evaluation/Num Paths              15
evaluation/Average Returns       -58.4577
time/data storing (s)              0.00286293
time/evaluation sampling (s)       0.326313
time/exploration sampling (s)      0.14224
time/logging (s)                   0.00490266
time/saving (s)                    0.00202619
time/training (s)                  1.94627
time/epoch (s)                     2.42461
time/total (s)                   119.649
Epoch                             48
-----------------------------  --------------
2019-04-22 22:38:36.242707 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                  35.0731
trainer/QF2 Loss                  34.9358
trainer/Policy Loss               32.7886
trainer/Q1 Predictions Mean      -31.657
trainer/Q1 Predictions Std        19.4997
trainer/Q1 Predictions Max       -12.9575
trainer/Q1 Predictions Min       -78.2725
trainer/Q2 Predictions Mean      -31.6627
trainer/Q2 Predictions Std        19.4723
trainer/Q2 Predictions Max       -13.0199
trainer/Q2 Predictions Min       -78.1626
trainer/Q Targets Mean           -31.3302
trainer/Q Targets Std             19.4194
trainer/Q Targets Max             -1.25292
trainer/Q Targets Min            -79.7772
trainer/Log Pis Mean               1.98155
trainer/Log Pis Std                1.38329
trainer/Log Pis Max                8.10789
trainer/Log Pis Min               -3.17774
trainer/Policy mu Mean            -0.0938007
trainer/Policy mu Std              0.765139
trainer/Policy mu Max              3.11153
trainer/Policy mu Min             -2.93964
trainer/Policy log std Mean       -1.94001
trainer/Policy log std Std         0.465853
trainer/Policy log std Max        -0.478896
trainer/Policy log std Min        -2.50152
trainer/Alpha                      0.0469201
trainer/Alpha Loss                -0.0564472
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.589441
exploration/Rewards Std            1.09423
exploration/Rewards Max           -0.0130977
exploration/Rewards Min          -10.7026
exploration/Returns Mean         -58.9441
exploration/Returns Std           26.8337
exploration/Returns Max          -33.4633
exploration/Returns Min         -107.221
exploration/Actions Mean           0.0131893
exploration/Actions Std            0.241238
exploration/Actions Max            0.99987
exploration/Actions Min           -0.991964
exploration/Num Paths              5
exploration/Average Returns      -58.9441
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.615021
evaluation/Rewards Std             1.03258
evaluation/Rewards Max            -0.00226507
evaluation/Rewards Min           -10.2484
evaluation/Returns Mean          -61.5021
evaluation/Returns Std            41.1106
evaluation/Returns Max            -4.77996
evaluation/Returns Min          -133.944
evaluation/Actions Mean           -0.0108488
evaluation/Actions Std             0.183468
evaluation/Actions Max             0.99909
evaluation/Actions Min            -0.999335
evaluation/Num Paths              15
evaluation/Average Returns       -61.5021
time/data storing (s)              0.00291525
time/evaluation sampling (s)       0.32419
time/exploration sampling (s)      0.140091
time/logging (s)                   0.00482748
time/saving (s)                    0.00195459
time/training (s)                  1.94356
time/epoch (s)                     2.41754
time/total (s)                   122.071
Epoch                             49
-----------------------------  --------------
2019-04-22 22:38:38.679738 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             25700
trainer/QF1 Loss                   2.71609
trainer/QF2 Loss                   2.74389
trainer/Policy Loss               31.4998
trainer/Q1 Predictions Mean      -30.1323
trainer/Q1 Predictions Std        18.1728
trainer/Q1 Predictions Max       -13.0706
trainer/Q1 Predictions Min       -84.3664
trainer/Q2 Predictions Mean      -30.1201
trainer/Q2 Predictions Std        18.1513
trainer/Q2 Predictions Max       -13.0742
trainer/Q2 Predictions Min       -84.7623
trainer/Q Targets Mean           -30.3457
trainer/Q Targets Std             18.5087
trainer/Q Targets Max             -1.02213
trainer/Q Targets Min            -86.2391
trainer/Log Pis Mean               2.19103
trainer/Log Pis Std                1.74199
trainer/Log Pis Max                8.22437
trainer/Log Pis Min               -4.51913
trainer/Policy mu Mean             0.0333854
trainer/Policy mu Std              0.971713
trainer/Policy mu Max              3.10022
trainer/Policy mu Min             -3.53633
trainer/Policy log std Mean       -1.84188
trainer/Policy log std Std         0.51254
trainer/Policy log std Max        -0.359758
trainer/Policy log std Min        -2.48256
trainer/Alpha                      0.0462292
trainer/Alpha Loss                 0.587262
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.496474
exploration/Rewards Std            0.570148
exploration/Rewards Max           -0.0288913
exploration/Rewards Min           -7.83035
exploration/Returns Mean         -49.6474
exploration/Returns Std           19.7875
exploration/Returns Max          -17.4423
exploration/Returns Min          -71.8413
exploration/Actions Mean          -0.00204036
exploration/Actions Std            0.215858
exploration/Actions Max            0.983337
exploration/Actions Min           -0.996214
exploration/Num Paths              5
exploration/Average Returns      -49.6474
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.538532
evaluation/Rewards Std             0.846508
evaluation/Rewards Max            -0.0273828
evaluation/Rewards Min           -10.0799
evaluation/Returns Mean          -53.8532
evaluation/Returns Std            31.4245
evaluation/Returns Max           -18.2055
evaluation/Returns Min          -131.738
evaluation/Actions Mean            0.0140706
evaluation/Actions Std             0.174089
evaluation/Actions Max             0.999437
evaluation/Actions Min            -0.99922
evaluation/Num Paths              15
evaluation/Average Returns       -53.8532
time/data storing (s)              0.00302846
time/evaluation sampling (s)       0.33066
time/exploration sampling (s)      0.146035
time/logging (s)                   0.00360479
time/saving (s)                    0.00195658
time/training (s)                  1.94446
time/epoch (s)                     2.42975
time/total (s)                   124.505
Epoch                             50
-----------------------------  --------------
2019-04-22 22:38:41.127689 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             26200
trainer/QF1 Loss                   0.254913
trainer/QF2 Loss                   0.279482
trainer/Policy Loss               31.1779
trainer/Q1 Predictions Mean      -30.3048
trainer/Q1 Predictions Std        17.8191
trainer/Q1 Predictions Max       -12.9894
trainer/Q1 Predictions Min       -67.264
trainer/Q2 Predictions Mean      -30.2607
trainer/Q2 Predictions Std        17.7825
trainer/Q2 Predictions Max       -13.0086
trainer/Q2 Predictions Min       -67.1387
trainer/Q Targets Mean           -30.5625
trainer/Q Targets Std             17.9935
trainer/Q Targets Max            -13.0652
trainer/Q Targets Min            -67.7609
trainer/Log Pis Mean               1.73596
trainer/Log Pis Std                1.4965
trainer/Log Pis Max                6.01982
trainer/Log Pis Min               -5.36501
trainer/Policy mu Mean            -0.0330983
trainer/Policy mu Std              0.84748
trainer/Policy mu Max              3.45142
trainer/Policy mu Min             -3.15215
trainer/Policy log std Mean       -1.90824
trainer/Policy log std Std         0.474826
trainer/Policy log std Max        -0.509558
trainer/Policy log std Min        -2.48712
trainer/Alpha                      0.0469877
trainer/Alpha Loss                -0.807378
exploration/num steps total    26200
exploration/num paths total      262
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.472863
exploration/Rewards Std            0.988204
exploration/Rewards Max           -0.00759394
exploration/Rewards Min           -8.98577
exploration/Returns Mean         -47.2863
exploration/Returns Std           18.408
exploration/Returns Max          -24.2152
exploration/Returns Min          -79.0258
exploration/Actions Mean          -0.00919448
exploration/Actions Std            0.226718
exploration/Actions Max            0.99978
exploration/Actions Min           -0.999889
exploration/Num Paths              5
exploration/Average Returns      -47.2863
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.497084
evaluation/Rewards Std             0.969652
evaluation/Rewards Max            -0.0564997
evaluation/Rewards Min            -9.5374
evaluation/Returns Mean          -49.7084
evaluation/Returns Std            25.6288
evaluation/Returns Max           -18.803
evaluation/Returns Min          -114.016
evaluation/Actions Mean            0.00843202
evaluation/Actions Std             0.187376
evaluation/Actions Max             0.999192
evaluation/Actions Min            -0.998416
evaluation/Num Paths              15
evaluation/Average Returns       -49.7084
time/data storing (s)              0.00309336
time/evaluation sampling (s)       0.330351
time/exploration sampling (s)      0.142274
time/logging (s)                   0.00486301
time/saving (s)                    0.00194084
time/training (s)                  1.96082
time/epoch (s)                     2.44335
time/total (s)                   126.953
Epoch                             51
-----------------------------  --------------
2019-04-22 22:38:43.561935 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 52 finished
-----------------------------  ---------------
replay_buffer/size             26700
trainer/QF1 Loss                  27.5606
trainer/QF2 Loss                  27.8899
trainer/Policy Loss               32.7422
trainer/Q1 Predictions Mean      -31.3679
trainer/Q1 Predictions Std        20.0435
trainer/Q1 Predictions Max       -12.6688
trainer/Q1 Predictions Min       -76.4011
trainer/Q2 Predictions Mean      -31.3842
trainer/Q2 Predictions Std        20.0428
trainer/Q2 Predictions Max       -12.6789
trainer/Q2 Predictions Min       -76.6713
trainer/Q Targets Mean           -30.9682
trainer/Q Targets Std             20.2198
trainer/Q Targets Max             -0.123408
trainer/Q Targets Min            -76.4925
trainer/Log Pis Mean               2.35645
trainer/Log Pis Std                1.86473
trainer/Log Pis Max                7.77343
trainer/Log Pis Min               -0.928839
trainer/Policy mu Mean             0.00570943
trainer/Policy mu Std              1.03666
trainer/Policy mu Max              3.78426
trainer/Policy mu Min             -3.09546
trainer/Policy log std Mean       -1.86329
trainer/Policy log std Std         0.551975
trainer/Policy log std Max        -0.251259
trainer/Policy log std Min        -2.59934
trainer/Alpha                      0.0471756
trainer/Alpha Loss                 1.0886
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.528486
exploration/Rewards Std            0.859847
exploration/Rewards Max           -0.0110839
exploration/Rewards Min           -7.05672
exploration/Returns Mean         -52.8486
exploration/Returns Std           25.8926
exploration/Returns Max          -32.3489
exploration/Returns Min         -103.64
exploration/Actions Mean           0.00500555
exploration/Actions Std            0.229913
exploration/Actions Max            0.999372
exploration/Actions Min           -0.999152
exploration/Num Paths              5
exploration/Average Returns      -52.8486
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.387557
evaluation/Rewards Std             0.755818
evaluation/Rewards Max            -0.026591
evaluation/Rewards Min            -9.5386
evaluation/Returns Mean          -38.7557
evaluation/Returns Std            25.4763
evaluation/Returns Max            -5.98541
evaluation/Returns Min           -96.0734
evaluation/Actions Mean            0.000688426
evaluation/Actions Std             0.160423
evaluation/Actions Max             0.99678
evaluation/Actions Min            -0.999191
evaluation/Num Paths              15
evaluation/Average Returns       -38.7557
time/data storing (s)              0.00297305
time/evaluation sampling (s)       0.3231
time/exploration sampling (s)      0.139767
time/logging (s)                   0.00366333
time/saving (s)                    0.0108987
time/training (s)                  1.94668
time/epoch (s)                     2.42708
time/total (s)                   129.384
Epoch                             52
-----------------------------  ---------------
2019-04-22 22:38:46.002273 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             27200
trainer/QF1 Loss                  46.791
trainer/QF2 Loss                  46.8912
trainer/Policy Loss               28.6263
trainer/Q1 Predictions Mean      -27.2853
trainer/Q1 Predictions Std        17.8451
trainer/Q1 Predictions Max       -12.432
trainer/Q1 Predictions Min       -70.6942
trainer/Q2 Predictions Mean      -27.2703
trainer/Q2 Predictions Std        17.7922
trainer/Q2 Predictions Max       -12.5295
trainer/Q2 Predictions Min       -71.3709
trainer/Q Targets Mean           -26.7358
trainer/Q Targets Std             18.2429
trainer/Q Targets Max             -0.965071
trainer/Q Targets Min            -71.425
trainer/Log Pis Mean               1.86972
trainer/Log Pis Std                1.48835
trainer/Log Pis Max                6.34906
trainer/Log Pis Min               -3.43185
trainer/Policy mu Mean            -0.0220264
trainer/Policy mu Std              0.8528
trainer/Policy mu Max              3.70787
trainer/Policy mu Min             -3.12975
trainer/Policy log std Mean       -1.93114
trainer/Policy log std Std         0.495592
trainer/Policy log std Max        -0.292898
trainer/Policy log std Min        -2.56068
trainer/Alpha                      0.0484175
trainer/Alpha Loss                -0.394469
exploration/num steps total    27200
exploration/num paths total      272
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.644899
exploration/Rewards Std            0.927131
exploration/Rewards Max           -0.0238262
exploration/Rewards Min           -7.28907
exploration/Returns Mean         -64.4899
exploration/Returns Std           24.5384
exploration/Returns Max          -39.3965
exploration/Returns Min         -106.214
exploration/Actions Mean          -0.0106258
exploration/Actions Std            0.252367
exploration/Actions Max            0.998905
exploration/Actions Min           -0.999926
exploration/Num Paths              5
exploration/Average Returns      -64.4899
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.434827
evaluation/Rewards Std             0.638851
evaluation/Rewards Max            -0.0353456
evaluation/Rewards Min            -8.60515
evaluation/Returns Mean          -43.4827
evaluation/Returns Std            28.8792
evaluation/Returns Max            -8.81886
evaluation/Returns Min           -87.9487
evaluation/Actions Mean            0.00427474
evaluation/Actions Std             0.155681
evaluation/Actions Max             0.996332
evaluation/Actions Min            -0.996474
evaluation/Num Paths              15
evaluation/Average Returns       -43.4827
time/data storing (s)              0.00289768
time/evaluation sampling (s)       0.324946
time/exploration sampling (s)      0.144935
time/logging (s)                   0.00485758
time/saving (s)                    0.00195406
time/training (s)                  1.95624
time/epoch (s)                     2.43583
time/total (s)                   131.825
Epoch                             53
-----------------------------  --------------
2019-04-22 22:38:48.409200 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             27700
trainer/QF1 Loss                  35.5011
trainer/QF2 Loss                  35.0562
trainer/Policy Loss               35.569
trainer/Q1 Predictions Mean      -34.0887
trainer/Q1 Predictions Std        18.9948
trainer/Q1 Predictions Max       -12.4123
trainer/Q1 Predictions Min       -76.6464
trainer/Q2 Predictions Mean      -34.0975
trainer/Q2 Predictions Std        18.9546
trainer/Q2 Predictions Max       -12.4178
trainer/Q2 Predictions Min       -76.0786
trainer/Q Targets Mean           -33.7204
trainer/Q Targets Std             19.6925
trainer/Q Targets Max             -0.133021
trainer/Q Targets Min            -78.4593
trainer/Log Pis Mean               2.11819
trainer/Log Pis Std                1.77595
trainer/Log Pis Max                9.14205
trainer/Log Pis Min               -3.07542
trainer/Policy mu Mean             0.0191199
trainer/Policy mu Std              1.04712
trainer/Policy mu Max              3.14716
trainer/Policy mu Min             -3.45233
trainer/Policy log std Mean       -1.76327
trainer/Policy log std Std         0.586842
trainer/Policy log std Max        -0.189921
trainer/Policy log std Min        -2.62498
trainer/Alpha                      0.0472651
trainer/Alpha Loss                 0.360691
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.592207
exploration/Rewards Std            0.522816
exploration/Rewards Max           -0.0105321
exploration/Rewards Min           -4.09976
exploration/Returns Mean         -59.2207
exploration/Returns Std           40.1493
exploration/Returns Max          -19.3001
exploration/Returns Min         -108.502
exploration/Actions Mean          -0.0108347
exploration/Actions Std            0.210023
exploration/Actions Max            0.98432
exploration/Actions Min           -0.998121
exploration/Num Paths              5
exploration/Average Returns      -59.2207
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.447753
evaluation/Rewards Std             1.09148
evaluation/Rewards Max            -0.0495507
evaluation/Rewards Min            -9.54663
evaluation/Returns Mean          -44.7753
evaluation/Returns Std            28.6502
evaluation/Returns Max           -15.9656
evaluation/Returns Min          -110.414
evaluation/Actions Mean            0.00262386
evaluation/Actions Std             0.206423
evaluation/Actions Max             0.999166
evaluation/Actions Min            -0.998163
evaluation/Num Paths              15
evaluation/Average Returns       -44.7753
time/data storing (s)              0.00291042
time/evaluation sampling (s)       0.327688
time/exploration sampling (s)      0.138876
time/logging (s)                   0.00489927
time/saving (s)                    0.00178308
time/training (s)                  1.9249
time/epoch (s)                     2.40106
time/total (s)                   134.23
Epoch                             54
-----------------------------  --------------
2019-04-22 22:38:50.846940 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             28200
trainer/QF1 Loss                   0.491164
trainer/QF2 Loss                   0.690098
trainer/Policy Loss               31.2673
trainer/Q1 Predictions Mean      -29.9564
trainer/Q1 Predictions Std        19.6536
trainer/Q1 Predictions Max       -12.341
trainer/Q1 Predictions Min       -99.8959
trainer/Q2 Predictions Mean      -29.8926
trainer/Q2 Predictions Std        19.5114
trainer/Q2 Predictions Max       -12.3673
trainer/Q2 Predictions Min       -96.8991
trainer/Q Targets Mean           -30.3362
trainer/Q Targets Std             20.0291
trainer/Q Targets Max            -12.5306
trainer/Q Targets Min           -101.035
trainer/Log Pis Mean               1.87191
trainer/Log Pis Std                1.65056
trainer/Log Pis Max                9.96465
trainer/Log Pis Min               -2.82831
trainer/Policy mu Mean             0.0253283
trainer/Policy mu Std              0.935849
trainer/Policy mu Max              3.61793
trainer/Policy mu Min             -4.3466
trainer/Policy log std Mean       -1.91409
trainer/Policy log std Std         0.561054
trainer/Policy log std Max         0.0858582
trainer/Policy log std Min        -2.67512
trainer/Alpha                      0.0484691
trainer/Alpha Loss                -0.387692
exploration/num steps total    28200
exploration/num paths total      282
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.421892
exploration/Rewards Std            0.646399
exploration/Rewards Max           -0.00168089
exploration/Rewards Min           -7.4339
exploration/Returns Mean         -42.1892
exploration/Returns Std           28.568
exploration/Returns Max          -14.3947
exploration/Returns Min          -95.2045
exploration/Actions Mean           0.0038883
exploration/Actions Std            0.200757
exploration/Actions Max            0.998007
exploration/Actions Min           -0.997645
exploration/Num Paths              5
exploration/Average Returns      -42.1892
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.526069
evaluation/Rewards Std             1.07964
evaluation/Rewards Max            -0.0183714
evaluation/Rewards Min            -9.44959
evaluation/Returns Mean          -52.6069
evaluation/Returns Std            31.8016
evaluation/Returns Max            -6.38154
evaluation/Returns Min          -107.512
evaluation/Actions Mean           -0.00132453
evaluation/Actions Std             0.192609
evaluation/Actions Max             0.998873
evaluation/Actions Min            -0.99949
evaluation/Num Paths              15
evaluation/Average Returns       -52.6069
time/data storing (s)              0.00290203
time/evaluation sampling (s)       0.324748
time/exploration sampling (s)      0.144176
time/logging (s)                   0.00451353
time/saving (s)                    0.00196924
time/training (s)                  1.95298
time/epoch (s)                     2.43129
time/total (s)                   136.666
Epoch                             55
-----------------------------  --------------
2019-04-22 22:38:53.274808 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             28700
trainer/QF1 Loss                  31.7097
trainer/QF2 Loss                  31.7141
trainer/Policy Loss               32.6585
trainer/Q1 Predictions Mean      -31.4615
trainer/Q1 Predictions Std        19.297
trainer/Q1 Predictions Max       -11.988
trainer/Q1 Predictions Min       -91.5635
trainer/Q2 Predictions Mean      -31.4929
trainer/Q2 Predictions Std        19.3142
trainer/Q2 Predictions Max       -12.0534
trainer/Q2 Predictions Min       -91.0005
trainer/Q Targets Mean           -31.0508
trainer/Q Targets Std             19.5394
trainer/Q Targets Max             -0.378948
trainer/Q Targets Min            -93.758
trainer/Log Pis Mean               2.05188
trainer/Log Pis Std                1.79265
trainer/Log Pis Max                8.60893
trainer/Log Pis Min               -4.29334
trainer/Policy mu Mean            -0.0245079
trainer/Policy mu Std              0.952087
trainer/Policy mu Max              3.15603
trainer/Policy mu Min             -3.24366
trainer/Policy log std Mean       -1.91362
trainer/Policy log std Std         0.585041
trainer/Policy log std Max        -0.374553
trainer/Policy log std Min        -2.67318
trainer/Alpha                      0.0493686
trainer/Alpha Loss                 0.156092
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.565582
exploration/Rewards Std            0.722517
exploration/Rewards Max           -0.0106898
exploration/Rewards Min           -7.11853
exploration/Returns Mean         -56.5582
exploration/Returns Std           40.6868
exploration/Returns Max          -20.9378
exploration/Returns Min         -109.78
exploration/Actions Mean          -0.00222851
exploration/Actions Std            0.19953
exploration/Actions Max            0.995839
exploration/Actions Min           -0.998981
exploration/Num Paths              5
exploration/Average Returns      -56.5582
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.826538
evaluation/Rewards Std             1.11603
evaluation/Rewards Max            -0.0447408
evaluation/Rewards Min           -10.0698
evaluation/Returns Mean          -82.6538
evaluation/Returns Std            34.2355
evaluation/Returns Max           -17.1191
evaluation/Returns Min          -127.043
evaluation/Actions Mean           -0.0161133
evaluation/Actions Std             0.211801
evaluation/Actions Max             0.998176
evaluation/Actions Min            -0.999405
evaluation/Num Paths              15
evaluation/Average Returns       -82.6538
time/data storing (s)              0.00281229
time/evaluation sampling (s)       0.326543
time/exploration sampling (s)      0.141298
time/logging (s)                   0.00481463
time/saving (s)                    0.0019718
time/training (s)                  1.94491
time/epoch (s)                     2.42235
time/total (s)                   139.093
Epoch                             56
-----------------------------  --------------
2019-04-22 22:38:55.723978 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             29200
trainer/QF1 Loss                   2.0104
trainer/QF2 Loss                   2.06351
trainer/Policy Loss               31.2572
trainer/Q1 Predictions Mean      -29.8239
trainer/Q1 Predictions Std        18.0775
trainer/Q1 Predictions Max       -12.0753
trainer/Q1 Predictions Min       -81.8234
trainer/Q2 Predictions Mean      -29.8229
trainer/Q2 Predictions Std        18.0328
trainer/Q2 Predictions Max       -12.1427
trainer/Q2 Predictions Min       -80.5003
trainer/Q Targets Mean           -29.8807
trainer/Q Targets Std             18.4139
trainer/Q Targets Max             -0.0844827
trainer/Q Targets Min            -81.3187
trainer/Log Pis Mean               1.92114
trainer/Log Pis Std                1.29478
trainer/Log Pis Max                7.4932
trainer/Log Pis Min               -1.97014
trainer/Policy mu Mean            -0.05234
trainer/Policy mu Std              0.753907
trainer/Policy mu Max              3.18072
trainer/Policy mu Min             -3.66562
trainer/Policy log std Mean       -1.96309
trainer/Policy log std Std         0.501574
trainer/Policy log std Max        -0.238712
trainer/Policy log std Min        -2.60559
trainer/Alpha                      0.0491949
trainer/Alpha Loss                -0.237517
exploration/num steps total    29200
exploration/num paths total      292
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.684632
exploration/Rewards Std            1.04355
exploration/Rewards Max           -0.0466298
exploration/Rewards Min          -10.3016
exploration/Returns Mean         -68.4632
exploration/Returns Std           17.6961
exploration/Returns Max          -40.1614
exploration/Returns Min          -88.1517
exploration/Actions Mean           0.00334592
exploration/Actions Std            0.277665
exploration/Actions Max            0.997498
exploration/Actions Min           -0.999486
exploration/Num Paths              5
exploration/Average Returns      -68.4632
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.418867
evaluation/Rewards Std             0.872044
evaluation/Rewards Max            -0.0298371
evaluation/Rewards Min            -9.18947
evaluation/Returns Mean          -41.8867
evaluation/Returns Std            26.4104
evaluation/Returns Max           -13.8988
evaluation/Returns Min          -106.304
evaluation/Actions Mean            0.00404843
evaluation/Actions Std             0.183856
evaluation/Actions Max             0.998425
evaluation/Actions Min            -0.998374
evaluation/Num Paths              15
evaluation/Average Returns       -41.8867
time/data storing (s)              0.00299167
time/evaluation sampling (s)       0.325678
time/exploration sampling (s)      0.144497
time/logging (s)                   0.00482116
time/saving (s)                    0.00194546
time/training (s)                  1.96332
time/epoch (s)                     2.44325
time/total (s)                   141.541
Epoch                             57
-----------------------------  --------------
2019-04-22 22:38:58.151368 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             29700
trainer/QF1 Loss                  30.2334
trainer/QF2 Loss                  30.1995
trainer/Policy Loss               32.013
trainer/Q1 Predictions Mean      -30.5871
trainer/Q1 Predictions Std        17.3713
trainer/Q1 Predictions Max       -11.7176
trainer/Q1 Predictions Min       -71.3739
trainer/Q2 Predictions Mean      -30.6008
trainer/Q2 Predictions Std        17.3802
trainer/Q2 Predictions Max       -11.8258
trainer/Q2 Predictions Min       -71.4205
trainer/Q Targets Mean           -30.2673
trainer/Q Targets Std             18.1091
trainer/Q Targets Max             -0.411553
trainer/Q Targets Min            -70.7844
trainer/Log Pis Mean               1.89326
trainer/Log Pis Std                1.52198
trainer/Log Pis Max                9.04564
trainer/Log Pis Min               -1.05944
trainer/Policy mu Mean             0.0132211
trainer/Policy mu Std              0.828381
trainer/Policy mu Max              3.3494
trainer/Policy mu Min             -2.95269
trainer/Policy log std Mean       -1.89337
trainer/Policy log std Std         0.545556
trainer/Policy log std Max        -0.376004
trainer/Policy log std Min        -2.62088
trainer/Alpha                      0.0491263
trainer/Alpha Loss                -0.32164
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.621947
exploration/Rewards Std            1.20126
exploration/Rewards Max           -0.00631292
exploration/Rewards Min          -11.2641
exploration/Returns Mean         -62.1947
exploration/Returns Std           28.7412
exploration/Returns Max          -26.3038
exploration/Returns Min         -110.012
exploration/Actions Mean           0.024873
exploration/Actions Std            0.250219
exploration/Actions Max            0.99998
exploration/Actions Min           -0.997256
exploration/Num Paths              5
exploration/Average Returns      -62.1947
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.548233
evaluation/Rewards Std             1.05512
evaluation/Rewards Max            -0.055419
evaluation/Rewards Min           -10.4465
evaluation/Returns Mean          -54.8233
evaluation/Returns Std            24.6102
evaluation/Returns Max           -21.9524
evaluation/Returns Min          -102.985
evaluation/Actions Mean            0.0013744
evaluation/Actions Std             0.191462
evaluation/Actions Max             0.999263
evaluation/Actions Min            -0.999676
evaluation/Num Paths              15
evaluation/Average Returns       -54.8233
time/data storing (s)              0.00303543
time/evaluation sampling (s)       0.328061
time/exploration sampling (s)      0.142876
time/logging (s)                   0.00481734
time/saving (s)                    0.00192825
time/training (s)                  1.94084
time/epoch (s)                     2.42156
time/total (s)                   143.967
Epoch                             58
-----------------------------  --------------
2019-04-22 22:39:00.570714 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             30200
trainer/QF1 Loss                   1.52547
trainer/QF2 Loss                   1.51436
trainer/Policy Loss               27.3767
trainer/Q1 Predictions Mean      -25.7641
trainer/Q1 Predictions Std        17.2351
trainer/Q1 Predictions Max       -11.9521
trainer/Q1 Predictions Min       -69.551
trainer/Q2 Predictions Mean      -25.7676
trainer/Q2 Predictions Std        17.2338
trainer/Q2 Predictions Max       -12.0198
trainer/Q2 Predictions Min       -68.8791
trainer/Q Targets Mean           -25.7502
trainer/Q Targets Std             17.3955
trainer/Q Targets Max             -0.265272
trainer/Q Targets Min            -68.4016
trainer/Log Pis Mean               2.13246
trainer/Log Pis Std                1.38103
trainer/Log Pis Max                9.08305
trainer/Log Pis Min               -1.98993
trainer/Policy mu Mean            -0.0653832
trainer/Policy mu Std              0.765532
trainer/Policy mu Max              3.40921
trainer/Policy mu Min             -2.92142
trainer/Policy log std Mean       -1.95135
trainer/Policy log std Std         0.492594
trainer/Policy log std Max        -0.25581
trainer/Policy log std Min        -2.63742
trainer/Alpha                      0.0496729
trainer/Alpha Loss                 0.397671
exploration/num steps total    30200
exploration/num paths total      302
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.566569
exploration/Rewards Std            1.09657
exploration/Rewards Max           -0.0189448
exploration/Rewards Min           -9.04201
exploration/Returns Mean         -56.6569
exploration/Returns Std           14.1319
exploration/Returns Max          -32.4775
exploration/Returns Min          -75.5786
exploration/Actions Mean           0.0123337
exploration/Actions Std            0.270188
exploration/Actions Max            0.999409
exploration/Actions Min           -0.999439
exploration/Num Paths              5
exploration/Average Returns      -56.6569
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.735449
evaluation/Rewards Std             0.983029
evaluation/Rewards Max            -0.102533
evaluation/Rewards Min            -9.7777
evaluation/Returns Mean          -73.5449
evaluation/Returns Std            32.6935
evaluation/Returns Max           -27.2157
evaluation/Returns Min          -125.694
evaluation/Actions Mean           -0.00362414
evaluation/Actions Std             0.19061
evaluation/Actions Max             0.998164
evaluation/Actions Min            -0.999468
evaluation/Num Paths              15
evaluation/Average Returns       -73.5449
time/data storing (s)              0.00279104
time/evaluation sampling (s)       0.324999
time/exploration sampling (s)      0.139837
time/logging (s)                   0.00491917
time/saving (s)                    0.0019423
time/training (s)                  1.93921
time/epoch (s)                     2.4137
time/total (s)                   146.385
Epoch                             59
-----------------------------  --------------
2019-04-22 22:39:03.004355 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             30700
trainer/QF1 Loss                   1.83061
trainer/QF2 Loss                   1.82638
trainer/Policy Loss               32.9712
trainer/Q1 Predictions Mean      -31.3717
trainer/Q1 Predictions Std        18.9732
trainer/Q1 Predictions Max       -11.8196
trainer/Q1 Predictions Min       -86.0778
trainer/Q2 Predictions Mean      -31.3815
trainer/Q2 Predictions Std        19
trainer/Q2 Predictions Max       -11.8735
trainer/Q2 Predictions Min       -86.8949
trainer/Q Targets Mean           -31.4867
trainer/Q Targets Std             19.235
trainer/Q Targets Max             -0.317059
trainer/Q Targets Min            -88.4497
trainer/Log Pis Mean               2.31764
trainer/Log Pis Std                1.59905
trainer/Log Pis Max                8.3264
trainer/Log Pis Min               -3.41456
trainer/Policy mu Mean            -0.107019
trainer/Policy mu Std              1.05999
trainer/Policy mu Max              3.29494
trainer/Policy mu Min             -3.51362
trainer/Policy log std Mean       -1.85802
trainer/Policy log std Std         0.624672
trainer/Policy log std Max        -0.151287
trainer/Policy log std Min        -2.74074
trainer/Alpha                      0.0511352
trainer/Alpha Loss                 0.944469
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.545929
exploration/Rewards Std            0.965545
exploration/Rewards Max           -0.0149576
exploration/Rewards Min           -9.70351
exploration/Returns Mean         -54.5929
exploration/Returns Std           28.4638
exploration/Returns Max          -23.8667
exploration/Returns Min         -105.464
exploration/Actions Mean          -0.00282006
exploration/Actions Std            0.249722
exploration/Actions Max            0.998016
exploration/Actions Min           -0.998611
exploration/Num Paths              5
exploration/Average Returns      -54.5929
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.453258
evaluation/Rewards Std             0.971901
evaluation/Rewards Max            -0.0733413
evaluation/Rewards Min            -9.59586
evaluation/Returns Mean          -45.3258
evaluation/Returns Std            27.5213
evaluation/Returns Max           -19.5024
evaluation/Returns Min          -130.408
evaluation/Actions Mean            0.00294716
evaluation/Actions Std             0.19508
evaluation/Actions Max             0.999652
evaluation/Actions Min            -0.999324
evaluation/Num Paths              15
evaluation/Average Returns       -45.3258
time/data storing (s)              0.0029333
time/evaluation sampling (s)       0.323449
time/exploration sampling (s)      0.144882
time/logging (s)                   0.00379511
time/saving (s)                    0.00194681
time/training (s)                  1.94995
time/epoch (s)                     2.42695
time/total (s)                   148.816
Epoch                             60
-----------------------------  --------------
2019-04-22 22:39:05.428897 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 61 finished
-----------------------------  ---------------
replay_buffer/size             31200
trainer/QF1 Loss                  51.8827
trainer/QF2 Loss                  51.8328
trainer/Policy Loss               30.869
trainer/Q1 Predictions Mean      -29.532
trainer/Q1 Predictions Std        18.2849
trainer/Q1 Predictions Max       -11.5807
trainer/Q1 Predictions Min       -82.975
trainer/Q2 Predictions Mean      -29.5232
trainer/Q2 Predictions Std        18.325
trainer/Q2 Predictions Max       -11.5787
trainer/Q2 Predictions Min       -83.4772
trainer/Q Targets Mean           -28.8648
trainer/Q Targets Std             18.5666
trainer/Q Targets Max             -0.93363
trainer/Q Targets Min            -84.7488
trainer/Log Pis Mean               1.88648
trainer/Log Pis Std                1.75151
trainer/Log Pis Max                9.57202
trainer/Log Pis Min               -5.26266
trainer/Policy mu Mean            -0.00581306
trainer/Policy mu Std              0.879189
trainer/Policy mu Max              3.64543
trainer/Policy mu Min             -3.41109
trainer/Policy log std Mean       -1.90869
trainer/Policy log std Std         0.569167
trainer/Policy log std Max        -0.288393
trainer/Policy log std Min        -2.7
trainer/Alpha                      0.0527245
trainer/Alpha Loss                -0.334047
exploration/num steps total    31200
exploration/num paths total      312
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.317674
exploration/Rewards Std            0.750326
exploration/Rewards Max           -0.0153373
exploration/Rewards Min           -7.64009
exploration/Returns Mean         -31.7674
exploration/Returns Std           15.0203
exploration/Returns Max          -18.4997
exploration/Returns Min          -56.0943
exploration/Actions Mean           0.0137385
exploration/Actions Std            0.229766
exploration/Actions Max            0.999474
exploration/Actions Min           -0.990982
exploration/Num Paths              5
exploration/Average Returns      -31.7674
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.320424
evaluation/Rewards Std             0.946699
evaluation/Rewards Max            -0.030285
evaluation/Rewards Min            -9.99596
evaluation/Returns Mean          -32.0424
evaluation/Returns Std            26.537
evaluation/Returns Max           -11.9377
evaluation/Returns Min          -106.851
evaluation/Actions Mean           -0.000657792
evaluation/Actions Std             0.175228
evaluation/Actions Max             0.998702
evaluation/Actions Min            -0.999453
evaluation/Num Paths              15
evaluation/Average Returns       -32.0424
time/data storing (s)              0.00293663
time/evaluation sampling (s)       0.327962
time/exploration sampling (s)      0.142972
time/logging (s)                   0.0035995
time/saving (s)                    0.00188504
time/training (s)                  1.93924
time/epoch (s)                     2.4186
time/total (s)                   151.238
Epoch                             61
-----------------------------  ---------------
2019-04-22 22:39:07.887276 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             31700
trainer/QF1 Loss                  32.4572
trainer/QF2 Loss                  32.5771
trainer/Policy Loss               26.9906
trainer/Q1 Predictions Mean      -25.595
trainer/Q1 Predictions Std        17.4519
trainer/Q1 Predictions Max       -11.7102
trainer/Q1 Predictions Min       -66.9871
trainer/Q2 Predictions Mean      -25.62
trainer/Q2 Predictions Std        17.4503
trainer/Q2 Predictions Max       -11.7842
trainer/Q2 Predictions Min       -66.5829
trainer/Q Targets Mean           -24.7514
trainer/Q Targets Std             17.5792
trainer/Q Targets Max             -0.225628
trainer/Q Targets Min            -66.3519
trainer/Log Pis Mean               1.86377
trainer/Log Pis Std                1.45665
trainer/Log Pis Max                7.00809
trainer/Log Pis Min               -2.18142
trainer/Policy mu Mean            -0.0120567
trainer/Policy mu Std              0.845715
trainer/Policy mu Max              3.45337
trainer/Policy mu Min             -2.74377
trainer/Policy log std Mean       -1.91045
trainer/Policy log std Std         0.532662
trainer/Policy log std Max        -0.183698
trainer/Policy log std Min        -2.58762
trainer/Alpha                      0.0532484
trainer/Alpha Loss                -0.399534
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.558961
exploration/Rewards Std            0.970784
exploration/Rewards Max           -0.0128432
exploration/Rewards Min           -8.37241
exploration/Returns Mean         -55.8961
exploration/Returns Std           28.9842
exploration/Returns Max          -24.7825
exploration/Returns Min         -107.514
exploration/Actions Mean          -0.0148931
exploration/Actions Std            0.278894
exploration/Actions Max            0.997676
exploration/Actions Min           -0.999647
exploration/Num Paths              5
exploration/Average Returns      -55.8961
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.369942
evaluation/Rewards Std             1.01988
evaluation/Rewards Max            -0.0420457
evaluation/Rewards Min            -9.93775
evaluation/Returns Mean          -36.9942
evaluation/Returns Std            28.0938
evaluation/Returns Max           -10.2687
evaluation/Returns Min          -122.174
evaluation/Actions Mean           -0.00229246
evaluation/Actions Std             0.189309
evaluation/Actions Max             0.997776
evaluation/Actions Min            -0.999649
evaluation/Num Paths              15
evaluation/Average Returns       -36.9942
time/data storing (s)              0.00290802
time/evaluation sampling (s)       0.326239
time/exploration sampling (s)      0.142147
time/logging (s)                   0.00482097
time/saving (s)                    0.00192568
time/training (s)                  1.97623
time/epoch (s)                     2.45427
time/total (s)                   153.697
Epoch                             62
-----------------------------  --------------
2019-04-22 22:39:10.334056 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size             32200
trainer/QF1 Loss                   0.227387
trainer/QF2 Loss                   0.168045
trainer/Policy Loss               30.8643
trainer/Q1 Predictions Mean      -29.6724
trainer/Q1 Predictions Std        16.3201
trainer/Q1 Predictions Max       -11.5009
trainer/Q1 Predictions Min       -68.7696
trainer/Q2 Predictions Mean      -29.6913
trainer/Q2 Predictions Std        16.3317
trainer/Q2 Predictions Max       -11.5531
trainer/Q2 Predictions Min       -69.6678
trainer/Q Targets Mean           -29.9251
trainer/Q Targets Std             16.3955
trainer/Q Targets Max            -11.6633
trainer/Q Targets Min            -69.8585
trainer/Log Pis Mean               1.85267
trainer/Log Pis Std                1.49852
trainer/Log Pis Max                6.8956
trainer/Log Pis Min               -1.84853
trainer/Policy mu Mean            -0.018831
trainer/Policy mu Std              0.865605
trainer/Policy mu Max              3.33414
trainer/Policy mu Min             -3.49221
trainer/Policy log std Mean       -1.90573
trainer/Policy log std Std         0.596001
trainer/Policy log std Max        -0.347254
trainer/Policy log std Min        -2.64672
trainer/Alpha                      0.0537461
trainer/Alpha Loss                -0.430727
exploration/num steps total    32200
exploration/num paths total      322
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.511305
exploration/Rewards Std            1.01694
exploration/Rewards Max           -0.0142899
exploration/Rewards Min           -9.29282
exploration/Returns Mean         -51.1305
exploration/Returns Std           23.753
exploration/Returns Max          -19.2954
exploration/Returns Min          -83.2525
exploration/Actions Mean          -9.07785e-05
exploration/Actions Std            0.22141
exploration/Actions Max            0.999149
exploration/Actions Min           -0.998419
exploration/Num Paths              5
exploration/Average Returns      -51.1305
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.533607
evaluation/Rewards Std             0.977444
evaluation/Rewards Max            -0.071232
evaluation/Rewards Min            -9.51245
evaluation/Returns Mean          -53.3607
evaluation/Returns Std            35.4944
evaluation/Returns Max           -11.9355
evaluation/Returns Min          -114.569
evaluation/Actions Mean           -0.0137972
evaluation/Actions Std             0.184378
evaluation/Actions Max             0.997992
evaluation/Actions Min            -0.999326
evaluation/Num Paths              15
evaluation/Average Returns       -53.3607
time/data storing (s)              0.0028614
time/evaluation sampling (s)       0.326349
time/exploration sampling (s)      0.140604
time/logging (s)                   0.00481993
time/saving (s)                    0.00195228
time/training (s)                  1.96468
time/epoch (s)                     2.44127
time/total (s)                   156.142
Epoch                             63
-----------------------------  ---------------
2019-04-22 22:39:12.777729 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 64 finished
-----------------------------  ---------------
replay_buffer/size             32700
trainer/QF1 Loss                   0.300092
trainer/QF2 Loss                   0.221113
trainer/Policy Loss               26.6795
trainer/Q1 Predictions Mean      -25.3108
trainer/Q1 Predictions Std        15.9823
trainer/Q1 Predictions Max       -11.0797
trainer/Q1 Predictions Min       -71.5498
trainer/Q2 Predictions Mean      -25.3312
trainer/Q2 Predictions Std        16.0284
trainer/Q2 Predictions Max       -11.1427
trainer/Q2 Predictions Min       -71.7324
trainer/Q Targets Mean           -25.6235
trainer/Q Targets Std             16.1162
trainer/Q Targets Max            -11.6009
trainer/Q Targets Min            -73.6703
trainer/Log Pis Mean               2.13323
trainer/Log Pis Std                1.49745
trainer/Log Pis Max                7.52865
trainer/Log Pis Min               -1.67221
trainer/Policy mu Mean             0.00402497
trainer/Policy mu Std              0.897279
trainer/Policy mu Max              3.66607
trainer/Policy mu Min             -3.57006
trainer/Policy log std Mean       -1.91838
trainer/Policy log std Std         0.564376
trainer/Policy log std Max        -0.3619
trainer/Policy log std Min        -2.59024
trainer/Alpha                      0.0531379
trainer/Alpha Loss                 0.39101
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.526225
exploration/Rewards Std            0.875398
exploration/Rewards Max           -0.01144
exploration/Rewards Min           -8.98995
exploration/Returns Mean         -52.6225
exploration/Returns Std           30.0113
exploration/Returns Max          -26.7548
exploration/Returns Min          -93.7616
exploration/Actions Mean          -0.000406433
exploration/Actions Std            0.255099
exploration/Actions Max            0.999755
exploration/Actions Min           -0.998774
exploration/Num Paths              5
exploration/Average Returns      -52.6225
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.395302
evaluation/Rewards Std             0.945732
evaluation/Rewards Max            -0.040386
evaluation/Rewards Min            -8.8781
evaluation/Returns Mean          -39.5302
evaluation/Returns Std            27.786
evaluation/Returns Max            -8.38057
evaluation/Returns Min          -100.031
evaluation/Actions Mean            0.0179005
evaluation/Actions Std             0.192681
evaluation/Actions Max             0.998796
evaluation/Actions Min            -0.997525
evaluation/Num Paths              15
evaluation/Average Returns       -39.5302
time/data storing (s)              0.00296402
time/evaluation sampling (s)       0.328297
time/exploration sampling (s)      0.139267
time/logging (s)                   0.0036326
time/saving (s)                    0.0101635
time/training (s)                  1.95238
time/epoch (s)                     2.4367
time/total (s)                   158.583
Epoch                             64
-----------------------------  ---------------
2019-04-22 22:39:15.214590 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             33200
trainer/QF1 Loss                   2.81526
trainer/QF2 Loss                   2.83102
trainer/Policy Loss               28.3744
trainer/Q1 Predictions Mean      -26.9881
trainer/Q1 Predictions Std        16.7348
trainer/Q1 Predictions Max       -11.3012
trainer/Q1 Predictions Min       -75.8863
trainer/Q2 Predictions Mean      -26.9865
trainer/Q2 Predictions Std        16.7266
trainer/Q2 Predictions Max       -11.4237
trainer/Q2 Predictions Min       -75.9645
trainer/Q Targets Mean           -27.0982
trainer/Q Targets Std             17.0807
trainer/Q Targets Max             -0.178653
trainer/Q Targets Min            -77.5269
trainer/Log Pis Mean               1.98306
trainer/Log Pis Std                1.58331
trainer/Log Pis Max                9.09128
trainer/Log Pis Min               -1.83056
trainer/Policy mu Mean            -0.0328302
trainer/Policy mu Std              0.89012
trainer/Policy mu Max              3.73452
trainer/Policy mu Min             -2.92916
trainer/Policy log std Mean       -1.92887
trainer/Policy log std Std         0.556663
trainer/Policy log std Max        -0.224619
trainer/Policy log std Min        -2.63169
trainer/Alpha                      0.0525294
trainer/Alpha Loss                -0.0499221
exploration/num steps total    33200
exploration/num paths total      332
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.282826
exploration/Rewards Std            0.513696
exploration/Rewards Max           -0.00937845
exploration/Rewards Min           -5.59657
exploration/Returns Mean         -28.2826
exploration/Returns Std            5.55057
exploration/Returns Max          -17.4283
exploration/Returns Min          -32.4993
exploration/Actions Mean          -0.00524127
exploration/Actions Std            0.228432
exploration/Actions Max            0.998146
exploration/Actions Min           -0.997634
exploration/Num Paths              5
exploration/Average Returns      -28.2826
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.411546
evaluation/Rewards Std             0.892148
evaluation/Rewards Max            -0.0252108
evaluation/Rewards Min           -10.0511
evaluation/Returns Mean          -41.1546
evaluation/Returns Std            33.8436
evaluation/Returns Max            -4.2689
evaluation/Returns Min          -123.508
evaluation/Actions Mean            0.0049139
evaluation/Actions Std             0.184762
evaluation/Actions Max             0.998846
evaluation/Actions Min            -0.999342
evaluation/Num Paths              15
evaluation/Average Returns       -41.1546
time/data storing (s)              0.00296018
time/evaluation sampling (s)       0.327049
time/exploration sampling (s)      0.138032
time/logging (s)                   0.0048138
time/saving (s)                    0.00198405
time/training (s)                  1.95741
time/epoch (s)                     2.43225
time/total (s)                   161.02
Epoch                             65
-----------------------------  --------------
2019-04-22 22:39:17.656927 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                    0.101226
trainer/QF2 Loss                    0.0848072
trainer/Policy Loss                24.0623
trainer/Q1 Predictions Mean       -22.8323
trainer/Q1 Predictions Std         14.6736
trainer/Q1 Predictions Max        -11.3752
trainer/Q1 Predictions Min        -69.1558
trainer/Q2 Predictions Mean       -22.8623
trainer/Q2 Predictions Std         14.6879
trainer/Q2 Predictions Max        -11.4677
trainer/Q2 Predictions Min        -69.4226
trainer/Q Targets Mean            -22.9985
trainer/Q Targets Std              14.8262
trainer/Q Targets Max             -11.3943
trainer/Q Targets Min             -69.4004
trainer/Log Pis Mean                1.92349
trainer/Log Pis Std                 1.31749
trainer/Log Pis Max                 7.29891
trainer/Log Pis Min                -2.05712
trainer/Policy mu Mean             -0.0588318
trainer/Policy mu Std               0.811277
trainer/Policy mu Max               2.73331
trainer/Policy mu Min              -3.08871
trainer/Policy log std Mean        -2.00381
trainer/Policy log std Std          0.519485
trainer/Policy log std Max         -0.395905
trainer/Policy log std Min         -2.66393
trainer/Alpha                       0.0514935
trainer/Alpha Loss                 -0.226951
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.491018
exploration/Rewards Std             1.03098
exploration/Rewards Max            -0.0090599
exploration/Rewards Min            -9.89942
exploration/Returns Mean          -49.1018
exploration/Returns Std            36.4666
exploration/Returns Max           -17.6045
exploration/Returns Min          -117.763
exploration/Actions Mean            0.0135906
exploration/Actions Std             0.237761
exploration/Actions Max             0.999433
exploration/Actions Min            -0.999559
exploration/Num Paths               5
exploration/Average Returns       -49.1018
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.388571
evaluation/Rewards Std              1.08383
evaluation/Rewards Max             -0.00464223
evaluation/Rewards Min            -10.6825
evaluation/Returns Mean           -38.8571
evaluation/Returns Std             28.28
evaluation/Returns Max            -10.1466
evaluation/Returns Min           -106.798
evaluation/Actions Mean            -0.015959
evaluation/Actions Std              0.198595
evaluation/Actions Max              0.997019
evaluation/Actions Min             -0.999528
evaluation/Num Paths               15
evaluation/Average Returns        -38.8571
time/data storing (s)               0.00301434
time/evaluation sampling (s)        0.327382
time/exploration sampling (s)       0.142825
time/logging (s)                    0.00484834
time/saving (s)                     0.00157146
time/training (s)                   1.95668
time/epoch (s)                      2.43633
time/total (s)                    163.46
Epoch                              66
-----------------------------  ---------------
2019-04-22 22:39:20.080415 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                   12.3589
trainer/QF2 Loss                   12.2668
trainer/Policy Loss                24.2149
trainer/Q1 Predictions Mean       -22.9956
trainer/Q1 Predictions Std         15.2859
trainer/Q1 Predictions Max        -11.3895
trainer/Q1 Predictions Min        -81.3876
trainer/Q2 Predictions Mean       -22.9991
trainer/Q2 Predictions Std         15.3306
trainer/Q2 Predictions Max        -11.3536
trainer/Q2 Predictions Min        -82.2733
trainer/Q Targets Mean            -22.7329
trainer/Q Targets Std              15.3707
trainer/Q Targets Max              -0.829416
trainer/Q Targets Min             -83.4955
trainer/Log Pis Mean                1.62355
trainer/Log Pis Std                 1.62213
trainer/Log Pis Max                 6.56293
trainer/Log Pis Min                -6.31535
trainer/Policy mu Mean              0.0564284
trainer/Policy mu Std               0.762278
trainer/Policy mu Max               3.11065
trainer/Policy mu Min              -3.71606
trainer/Policy log std Mean        -2.00039
trainer/Policy log std Std          0.480541
trainer/Policy log std Max         -0.406008
trainer/Policy log std Min         -2.65123
trainer/Alpha                       0.0516772
trainer/Alpha Loss                 -1.11529
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.706793
exploration/Rewards Std             1.16363
exploration/Rewards Max            -0.00567661
exploration/Rewards Min            -9.44036
exploration/Returns Mean          -70.6793
exploration/Returns Std            36.1075
exploration/Returns Max           -24.2296
exploration/Returns Min          -107.659
exploration/Actions Mean            0.0203672
exploration/Actions Std             0.290233
exploration/Actions Max             0.999694
exploration/Actions Min            -0.997641
exploration/Num Paths               5
exploration/Average Returns       -70.6793
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.483371
evaluation/Rewards Std              0.956612
evaluation/Rewards Max             -0.00719782
evaluation/Rewards Min             -9.82722
evaluation/Returns Mean           -48.3371
evaluation/Returns Std             38.4469
evaluation/Returns Max            -12.3603
evaluation/Returns Min           -126.839
evaluation/Actions Mean             0.00506457
evaluation/Actions Std              0.185448
evaluation/Actions Max              0.998282
evaluation/Actions Min             -0.999449
evaluation/Num Paths               15
evaluation/Average Returns        -48.3371
time/data storing (s)               0.00289361
time/evaluation sampling (s)        0.320758
time/exploration sampling (s)       0.139021
time/logging (s)                    0.00483985
time/saving (s)                     0.00157342
time/training (s)                   1.94854
time/epoch (s)                      2.41762
time/total (s)                    165.882
Epoch                              67
-----------------------------  ---------------
2019-04-22 22:39:22.526509 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                    3.78863
trainer/QF2 Loss                    3.83327
trainer/Policy Loss                29.2755
trainer/Q1 Predictions Mean       -27.414
trainer/Q1 Predictions Std         17.6363
trainer/Q1 Predictions Max        -11.0368
trainer/Q1 Predictions Min        -80.3017
trainer/Q2 Predictions Mean       -27.4092
trainer/Q2 Predictions Std         17.6875
trainer/Q2 Predictions Max        -11.1109
trainer/Q2 Predictions Min        -80.3332
trainer/Q Targets Mean            -27.2689
trainer/Q Targets Std              17.857
trainer/Q Targets Max              -0.368708
trainer/Q Targets Min             -82.7679
trainer/Log Pis Mean                2.41545
trainer/Log Pis Std                 1.52344
trainer/Log Pis Max                 9.1516
trainer/Log Pis Min                -1.36866
trainer/Policy mu Mean             -0.00493825
trainer/Policy mu Std               1.0659
trainer/Policy mu Max               3.49529
trainer/Policy mu Min              -3.64974
trainer/Policy log std Mean        -1.89699
trainer/Policy log std Std          0.642203
trainer/Policy log std Max         -0.237235
trainer/Policy log std Min         -2.64119
trainer/Alpha                       0.0522728
trainer/Alpha Loss                  1.22618
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.589284
exploration/Rewards Std             1.14939
exploration/Rewards Max            -0.00776661
exploration/Rewards Min           -11.5598
exploration/Returns Mean          -58.9284
exploration/Returns Std            30.2125
exploration/Returns Max           -28.4094
exploration/Returns Min          -105.292
exploration/Actions Mean           -0.0138909
exploration/Actions Std             0.259311
exploration/Actions Max             0.998832
exploration/Actions Min            -0.999851
exploration/Num Paths               5
exploration/Average Returns       -58.9284
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.497935
evaluation/Rewards Std              0.947007
evaluation/Rewards Max             -0.0876436
evaluation/Rewards Min             -8.32334
evaluation/Returns Mean           -49.7935
evaluation/Returns Std             33.9874
evaluation/Returns Max            -14.8215
evaluation/Returns Min           -122.467
evaluation/Actions Mean             0.00296666
evaluation/Actions Std              0.189053
evaluation/Actions Max              0.998314
evaluation/Actions Min             -0.998691
evaluation/Num Paths               15
evaluation/Average Returns        -49.7935
time/data storing (s)               0.00291023
time/evaluation sampling (s)        0.329247
time/exploration sampling (s)       0.142391
time/logging (s)                    0.00487703
time/saving (s)                     0.00196091
time/training (s)                   1.95862
time/epoch (s)                      2.44001
time/total (s)                    168.327
Epoch                              68
-----------------------------  ---------------
2019-04-22 22:39:24.952341 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                   12.766
trainer/QF2 Loss                   12.9415
trainer/Policy Loss                27.1602
trainer/Q1 Predictions Mean       -25.9886
trainer/Q1 Predictions Std         17.5473
trainer/Q1 Predictions Max        -10.9881
trainer/Q1 Predictions Min        -95.7791
trainer/Q2 Predictions Mean       -25.9974
trainer/Q2 Predictions Std         17.5107
trainer/Q2 Predictions Max        -11.026
trainer/Q2 Predictions Min        -95.4595
trainer/Q Targets Mean            -25.8332
trainer/Q Targets Std              18.0948
trainer/Q Targets Max              -0.195025
trainer/Q Targets Min             -99.3299
trainer/Log Pis Mean                1.97571
trainer/Log Pis Std                 1.5888
trainer/Log Pis Max                 6.8963
trainer/Log Pis Min                -2.77239
trainer/Policy mu Mean              0.0386492
trainer/Policy mu Std               0.926117
trainer/Policy mu Max               3.69568
trainer/Policy mu Min              -3.56829
trainer/Policy log std Mean        -1.89055
trainer/Policy log std Std          0.537716
trainer/Policy log std Max         -0.123196
trainer/Policy log std Min         -2.47856
trainer/Alpha                       0.0525244
trainer/Alpha Loss                 -0.0715582
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.736021
exploration/Rewards Std             1.28199
exploration/Rewards Max            -0.0145971
exploration/Rewards Min            -9.56116
exploration/Returns Mean          -73.6021
exploration/Returns Std            34.901
exploration/Returns Max           -38.7542
exploration/Returns Min          -127.722
exploration/Actions Mean            0.00839702
exploration/Actions Std             0.248476
exploration/Actions Max             0.999033
exploration/Actions Min            -0.999968
exploration/Num Paths               5
exploration/Average Returns       -73.6021
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.469601
evaluation/Rewards Std              1.17104
evaluation/Rewards Max             -0.0385413
evaluation/Rewards Min             -9.78642
evaluation/Returns Mean           -46.9601
evaluation/Returns Std             25.9901
evaluation/Returns Max             -9.57978
evaluation/Returns Min           -105.848
evaluation/Actions Mean            -0.00640442
evaluation/Actions Std              0.194193
evaluation/Actions Max              0.998985
evaluation/Actions Min             -0.999555
evaluation/Num Paths               15
evaluation/Average Returns        -46.9601
time/data storing (s)               0.00298674
time/evaluation sampling (s)        0.322721
time/exploration sampling (s)       0.14132
time/logging (s)                    0.00483355
time/saving (s)                     0.0020242
time/training (s)                   1.94632
time/epoch (s)                      2.42021
time/total (s)                    170.751
Epoch                              69
-----------------------------  ---------------
2019-04-22 22:39:27.385054 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 70 finished
-----------------------------  ---------------
replay_buffer/size              35700
trainer/QF1 Loss                    0.0986633
trainer/QF2 Loss                    0.120178
trainer/Policy Loss                27.0702
trainer/Q1 Predictions Mean       -25.7949
trainer/Q1 Predictions Std         15.6285
trainer/Q1 Predictions Max        -10.7567
trainer/Q1 Predictions Min        -57.2223
trainer/Q2 Predictions Mean       -25.7721
trainer/Q2 Predictions Std         15.654
trainer/Q2 Predictions Max        -10.7722
trainer/Q2 Predictions Min        -57.7667
trainer/Q Targets Mean            -25.8079
trainer/Q Targets Std              15.4357
trainer/Q Targets Max             -11.0311
trainer/Q Targets Min             -56.679
trainer/Log Pis Mean                1.93965
trainer/Log Pis Std                 1.40451
trainer/Log Pis Max                 6.9945
trainer/Log Pis Min                -2.41751
trainer/Policy mu Mean             -0.01755
trainer/Policy mu Std               0.845295
trainer/Policy mu Max               2.5598
trainer/Policy mu Min              -3.06662
trainer/Policy log std Mean        -1.93511
trainer/Policy log std Std          0.551622
trainer/Policy log std Max         -0.491835
trainer/Policy log std Min         -2.4393
trainer/Alpha                       0.0535891
trainer/Alpha Loss                 -0.176599
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.732815
exploration/Rewards Std             1.07862
exploration/Rewards Max            -0.0245365
exploration/Rewards Min            -8.89288
exploration/Returns Mean          -73.2815
exploration/Returns Std            33.4099
exploration/Returns Max           -34.5922
exploration/Returns Min          -127.217
exploration/Actions Mean           -0.0398659
exploration/Actions Std             0.240339
exploration/Actions Max             0.853719
exploration/Actions Min            -0.99998
exploration/Num Paths               5
exploration/Average Returns       -73.2815
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.422749
evaluation/Rewards Std              0.983981
evaluation/Rewards Max             -0.0484568
evaluation/Rewards Min            -10.0617
evaluation/Returns Mean           -42.2749
evaluation/Returns Std             32.7075
evaluation/Returns Max             -9.20295
evaluation/Returns Min           -118.002
evaluation/Actions Mean             0.00139592
evaluation/Actions Std              0.179201
evaluation/Actions Max              0.998906
evaluation/Actions Min             -0.999236
evaluation/Num Paths               15
evaluation/Average Returns        -42.2749
time/data storing (s)               0.00297378
time/evaluation sampling (s)        0.325835
time/exploration sampling (s)       0.142568
time/logging (s)                    0.00486804
time/saving (s)                     0.00195864
time/training (s)                   1.9482
time/epoch (s)                      2.4264
time/total (s)                    173.182
Epoch                              70
-----------------------------  ---------------
2019-04-22 22:39:29.887570 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                    0.193024
trainer/QF2 Loss                    0.252282
trainer/Policy Loss                25.3321
trainer/Q1 Predictions Mean       -24.1611
trainer/Q1 Predictions Std         17.221
trainer/Q1 Predictions Max        -11.0741
trainer/Q1 Predictions Min        -89.296
trainer/Q2 Predictions Mean       -24.1092
trainer/Q2 Predictions Std         17.1657
trainer/Q2 Predictions Max        -11.0302
trainer/Q2 Predictions Min        -89.9066
trainer/Q Targets Mean            -24.2889
trainer/Q Targets Std              17.4092
trainer/Q Targets Max             -10.9243
trainer/Q Targets Min             -91.1599
trainer/Log Pis Mean                1.75471
trainer/Log Pis Std                 1.57395
trainer/Log Pis Max                 7.43197
trainer/Log Pis Min                -3.41577
trainer/Policy mu Mean              0.0717306
trainer/Policy mu Std               0.834403
trainer/Policy mu Max               3.6922
trainer/Policy mu Min              -3.51376
trainer/Policy log std Mean        -1.96696
trainer/Policy log std Std          0.493572
trainer/Policy log std Max         -0.370275
trainer/Policy log std Min         -2.3999
trainer/Alpha                       0.051771
trainer/Alpha Loss                 -0.72625
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396765
exploration/Rewards Std             0.940835
exploration/Rewards Max            -0.00842813
exploration/Rewards Min            -8.14676
exploration/Returns Mean          -39.6765
exploration/Returns Std            16.0897
exploration/Returns Max           -19.0702
exploration/Returns Min           -58.3406
exploration/Actions Mean            0.00971525
exploration/Actions Std             0.273857
exploration/Actions Max             0.999296
exploration/Actions Min            -0.998343
exploration/Num Paths               5
exploration/Average Returns       -39.6765
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.328842
evaluation/Rewards Std              0.971739
evaluation/Rewards Max             -0.00301341
evaluation/Rewards Min             -9.31325
evaluation/Returns Mean           -32.8842
evaluation/Returns Std             22.6577
evaluation/Returns Max             -7.79242
evaluation/Returns Min            -97.2143
evaluation/Actions Mean             0.0179683
evaluation/Actions Std              0.190671
evaluation/Actions Max              0.998955
evaluation/Actions Min             -0.994877
evaluation/Num Paths               15
evaluation/Average Returns        -32.8842
time/data storing (s)               0.00291325
time/evaluation sampling (s)        0.325024
time/exploration sampling (s)       0.146533
time/logging (s)                    0.00484352
time/saving (s)                     0.00197032
time/training (s)                   2.01499
time/epoch (s)                      2.49628
time/total (s)                    175.683
Epoch                              71
-----------------------------  ---------------
2019-04-22 22:39:32.314125 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                    0.0690298
trainer/QF2 Loss                    0.0765257
trainer/Policy Loss                24.949
trainer/Q1 Predictions Mean       -23.6879
trainer/Q1 Predictions Std         14.4422
trainer/Q1 Predictions Max        -10.8349
trainer/Q1 Predictions Min        -72.0299
trainer/Q2 Predictions Mean       -23.676
trainer/Q2 Predictions Std         14.411
trainer/Q2 Predictions Max        -10.8661
trainer/Q2 Predictions Min        -71.927
trainer/Q Targets Mean            -23.7787
trainer/Q Targets Std              14.5582
trainer/Q Targets Max             -10.8334
trainer/Q Targets Min             -73.5582
trainer/Log Pis Mean                1.77246
trainer/Log Pis Std                 1.55033
trainer/Log Pis Max                 8.23279
trainer/Log Pis Min                -2.69666
trainer/Policy mu Mean              0.0699498
trainer/Policy mu Std               0.717294
trainer/Policy mu Max               2.8785
trainer/Policy mu Min              -3.90085
trainer/Policy log std Mean        -1.9755
trainer/Policy log std Std          0.491116
trainer/Policy log std Max         -0.441085
trainer/Policy log std Min         -2.46698
trainer/Alpha                       0.0527464
trainer/Alpha Loss                 -0.669482
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.573474
exploration/Rewards Std             0.849125
exploration/Rewards Max            -0.0100435
exploration/Rewards Min            -7.94917
exploration/Returns Mean          -57.3474
exploration/Returns Std            25.1505
exploration/Returns Max           -20.5418
exploration/Returns Min           -87.4136
exploration/Actions Mean            0.00909168
exploration/Actions Std             0.213682
exploration/Actions Max             0.999628
exploration/Actions Min            -0.993396
exploration/Num Paths               5
exploration/Average Returns       -57.3474
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.382867
evaluation/Rewards Std              1.13466
evaluation/Rewards Max             -0.0133004
evaluation/Rewards Min            -11.4462
evaluation/Returns Mean           -38.2867
evaluation/Returns Std             28.5234
evaluation/Returns Max            -10.1558
evaluation/Returns Min           -121.601
evaluation/Actions Mean             0.00352901
evaluation/Actions Std              0.198624
evaluation/Actions Max              0.999689
evaluation/Actions Min             -0.99957
evaluation/Num Paths               15
evaluation/Average Returns        -38.2867
time/data storing (s)               0.00288938
time/evaluation sampling (s)        0.328667
time/exploration sampling (s)       0.140565
time/logging (s)                    0.00486299
time/saving (s)                     0.0019508
time/training (s)                   1.94145
time/epoch (s)                      2.42039
time/total (s)                    178.108
Epoch                              72
-----------------------------  ---------------
2019-04-22 22:39:34.796085 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    9.64916
trainer/QF2 Loss                    9.68698
trainer/Policy Loss                24.7843
trainer/Q1 Predictions Mean       -23.2084
trainer/Q1 Predictions Std         14.0052
trainer/Q1 Predictions Max        -10.6137
trainer/Q1 Predictions Min        -53.1579
trainer/Q2 Predictions Mean       -23.1916
trainer/Q2 Predictions Std         14.0132
trainer/Q2 Predictions Max        -10.6167
trainer/Q2 Predictions Min        -52.9815
trainer/Q Targets Mean            -23.0786
trainer/Q Targets Std              14.2799
trainer/Q Targets Max              -0.965071
trainer/Q Targets Min             -53.8296
trainer/Log Pis Mean                1.91048
trainer/Log Pis Std                 1.32642
trainer/Log Pis Max                 7.07119
trainer/Log Pis Min                -2.74246
trainer/Policy mu Mean              0.0681882
trainer/Policy mu Std               0.808307
trainer/Policy mu Max               3.19768
trainer/Policy mu Min              -2.89627
trainer/Policy log std Mean        -1.85823
trainer/Policy log std Std          0.512411
trainer/Policy log std Max         -0.393089
trainer/Policy log std Min         -2.46154
trainer/Alpha                       0.0529514
trainer/Alpha Loss                 -0.263045
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.4916
exploration/Rewards Std             0.52349
exploration/Rewards Max            -0.00100094
exploration/Rewards Min            -5.28961
exploration/Returns Mean          -49.16
exploration/Returns Std            39.9958
exploration/Returns Max           -16.5104
exploration/Returns Min          -104.608
exploration/Actions Mean            0.00438044
exploration/Actions Std             0.189825
exploration/Actions Max             0.99379
exploration/Actions Min            -0.99165
exploration/Num Paths               5
exploration/Average Returns       -49.16
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228797
evaluation/Rewards Std              0.660529
evaluation/Rewards Max             -0.00497569
evaluation/Rewards Min            -10.0219
evaluation/Returns Mean           -22.8797
evaluation/Returns Std             13.8282
evaluation/Returns Max             -5.76356
evaluation/Returns Min            -54.5035
evaluation/Actions Mean             0.00796876
evaluation/Actions Std              0.155028
evaluation/Actions Max              0.997309
evaluation/Actions Min             -0.998234
evaluation/Num Paths               15
evaluation/Average Returns        -22.8797
time/data storing (s)               0.00303994
time/evaluation sampling (s)        0.3357
time/exploration sampling (s)       0.149426
time/logging (s)                    0.00485767
time/saving (s)                     0.00195916
time/training (s)                   1.9807
time/epoch (s)                      2.47568
time/total (s)                    180.588
Epoch                              73
-----------------------------  ---------------
2019-04-22 22:39:37.240877 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 74 finished
-----------------------------  ----------------
replay_buffer/size              37700
trainer/QF1 Loss                   10.3103
trainer/QF2 Loss                   10.3861
trainer/Policy Loss                26.05
trainer/Q1 Predictions Mean       -24.9496
trainer/Q1 Predictions Std         15.7152
trainer/Q1 Predictions Max        -10.8205
trainer/Q1 Predictions Min        -88.9931
trainer/Q2 Predictions Mean       -24.9276
trainer/Q2 Predictions Std         15.6936
trainer/Q2 Predictions Max        -10.7603
trainer/Q2 Predictions Min        -88.6534
trainer/Q Targets Mean            -25.0311
trainer/Q Targets Std              16.373
trainer/Q Targets Max              -1.28261
trainer/Q Targets Min             -93.8592
trainer/Log Pis Mean                1.97662
trainer/Log Pis Std                 1.73772
trainer/Log Pis Max                11.6145
trainer/Log Pis Min                -3.09892
trainer/Policy mu Mean             -0.0107919
trainer/Policy mu Std               0.936875
trainer/Policy mu Max               3.4979
trainer/Policy mu Min              -3.5218
trainer/Policy log std Mean        -1.84362
trainer/Policy log std Std          0.555662
trainer/Policy log std Max         -0.315095
trainer/Policy log std Min         -2.42229
trainer/Alpha                       0.0515838
trainer/Alpha Loss                 -0.0693127
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.432702
exploration/Rewards Std             0.869651
exploration/Rewards Max            -0.0042819
exploration/Rewards Min            -9.22121
exploration/Returns Mean          -43.2702
exploration/Returns Std            27.4905
exploration/Returns Max           -16.2033
exploration/Returns Min           -87.5824
exploration/Actions Mean            0.000229024
exploration/Actions Std             0.209665
exploration/Actions Max             0.999607
exploration/Actions Min            -0.998849
exploration/Num Paths               5
exploration/Average Returns       -43.2702
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.492939
evaluation/Rewards Std              0.931793
evaluation/Rewards Max             -0.0283406
evaluation/Rewards Min             -9.46193
evaluation/Returns Mean           -49.2939
evaluation/Returns Std             43.8658
evaluation/Returns Max             -5.68319
evaluation/Returns Min           -121.926
evaluation/Actions Mean            -0.00431032
evaluation/Actions Std              0.180531
evaluation/Actions Max              0.997782
evaluation/Actions Min             -0.999078
evaluation/Num Paths               15
evaluation/Average Returns        -49.2939
time/data storing (s)               0.00296008
time/evaluation sampling (s)        0.335193
time/exploration sampling (s)       0.141882
time/logging (s)                    0.00484183
time/saving (s)                     0.00196949
time/training (s)                   1.95199
time/epoch (s)                      2.43884
time/total (s)                    183.031
Epoch                              74
-----------------------------  ----------------
2019-04-22 22:39:39.676676 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                   29.41
trainer/QF2 Loss                   29.4631
trainer/Policy Loss                25.3669
trainer/Q1 Predictions Mean       -23.9234
trainer/Q1 Predictions Std         14.7873
trainer/Q1 Predictions Max        -10.5342
trainer/Q1 Predictions Min        -50.1409
trainer/Q2 Predictions Mean       -23.8952
trainer/Q2 Predictions Std         14.7735
trainer/Q2 Predictions Max        -10.4768
trainer/Q2 Predictions Min        -49.9348
trainer/Q Targets Mean            -23.2944
trainer/Q Targets Std              14.9368
trainer/Q Targets Max              -0.261145
trainer/Q Targets Min             -50.4532
trainer/Log Pis Mean                1.78876
trainer/Log Pis Std                 1.42631
trainer/Log Pis Max                 8.13979
trainer/Log Pis Min                -2.0945
trainer/Policy mu Mean             -0.034416
trainer/Policy mu Std               0.724863
trainer/Policy mu Max               3.1013
trainer/Policy mu Min              -3.09727
trainer/Policy log std Mean        -2.02488
trainer/Policy log std Std          0.463151
trainer/Policy log std Max         -0.421026
trainer/Policy log std Min         -2.49192
trainer/Alpha                       0.0521935
trainer/Alpha Loss                 -0.623727
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.406326
exploration/Rewards Std             1.10955
exploration/Rewards Max            -0.00425408
exploration/Rewards Min            -9.37547
exploration/Returns Mean          -40.6326
exploration/Returns Std            12.8322
exploration/Returns Max           -21.6889
exploration/Returns Min           -58.6632
exploration/Actions Mean            0.0274069
exploration/Actions Std             0.238543
exploration/Actions Max             0.99971
exploration/Actions Min            -0.999683
exploration/Num Paths               5
exploration/Average Returns       -40.6326
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.416996
evaluation/Rewards Std              1.11574
evaluation/Rewards Max             -0.0515835
evaluation/Rewards Min            -10.6035
evaluation/Returns Mean           -41.6996
evaluation/Returns Std             21.0269
evaluation/Returns Max            -10.8819
evaluation/Returns Min            -78.4177
evaluation/Actions Mean            -0.0002612
evaluation/Actions Std              0.206727
evaluation/Actions Max              0.999011
evaluation/Actions Min             -0.999578
evaluation/Num Paths               15
evaluation/Average Returns        -41.6996
time/data storing (s)               0.00299546
time/evaluation sampling (s)        0.326122
time/exploration sampling (s)       0.14295
time/logging (s)                    0.00491251
time/saving (s)                     0.00195262
time/training (s)                   1.95085
time/epoch (s)                      2.42978
time/total (s)                    185.466
Epoch                              75
-----------------------------  ---------------
2019-04-22 22:39:42.147315 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size              38700
trainer/QF1 Loss                    8.82154
trainer/QF2 Loss                    8.63038
trainer/Policy Loss                26.7008
trainer/Q1 Predictions Mean       -25.4066
trainer/Q1 Predictions Std         14.5384
trainer/Q1 Predictions Max        -10.4543
trainer/Q1 Predictions Min        -53.5159
trainer/Q2 Predictions Mean       -25.3922
trainer/Q2 Predictions Std         14.5625
trainer/Q2 Predictions Max        -10.3542
trainer/Q2 Predictions Min        -53.1068
trainer/Q Targets Mean            -25.5016
trainer/Q Targets Std              15.0983
trainer/Q Targets Max              -1.21283
trainer/Q Targets Min             -53.6268
trainer/Log Pis Mean                1.85324
trainer/Log Pis Std                 1.25216
trainer/Log Pis Max                 6.39229
trainer/Log Pis Min                -2.10404
trainer/Policy mu Mean             -0.0195861
trainer/Policy mu Std               0.807709
trainer/Policy mu Max               3.00484
trainer/Policy mu Min              -4.15333
trainer/Policy log std Mean        -1.8959
trainer/Policy log std Std          0.529645
trainer/Policy log std Max         -0.228313
trainer/Policy log std Min         -2.41114
trainer/Alpha                       0.0534347
trainer/Alpha Loss                 -0.429907
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.455394
exploration/Rewards Std             1.12576
exploration/Rewards Max            -0.0141441
exploration/Rewards Min           -10.6921
exploration/Returns Mean          -45.5394
exploration/Returns Std            15.9516
exploration/Returns Max           -21.465
exploration/Returns Min           -65.8709
exploration/Actions Mean            0.00104823
exploration/Actions Std             0.267787
exploration/Actions Max             0.999481
exploration/Actions Min            -0.999439
exploration/Num Paths               5
exploration/Average Returns       -45.5394
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.487107
evaluation/Rewards Std              1.17191
evaluation/Rewards Max             -0.0187194
evaluation/Rewards Min            -11.215
evaluation/Returns Mean           -48.7107
evaluation/Returns Std             38.0642
evaluation/Returns Max             -4.39972
evaluation/Returns Min           -130.293
evaluation/Actions Mean             0.00110106
evaluation/Actions Std              0.202084
evaluation/Actions Max              0.999116
evaluation/Actions Min             -0.999166
evaluation/Num Paths               15
evaluation/Average Returns        -48.7107
time/data storing (s)               0.0030525
time/evaluation sampling (s)        0.330978
time/exploration sampling (s)       0.142342
time/logging (s)                    0.00484827
time/saving (s)                     0.0103384
time/training (s)                   1.97306
time/epoch (s)                      2.46462
time/total (s)                    187.935
Epoch                              76
-----------------------------  ---------------
2019-04-22 22:39:44.592187 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    0.111867
trainer/QF2 Loss                    0.104198
trainer/Policy Loss                23.1991
trainer/Q1 Predictions Mean       -21.5937
trainer/Q1 Predictions Std         13.22
trainer/Q1 Predictions Max        -10.3376
trainer/Q1 Predictions Min        -66.0517
trainer/Q2 Predictions Mean       -21.6332
trainer/Q2 Predictions Std         13.2305
trainer/Q2 Predictions Max        -10.3873
trainer/Q2 Predictions Min        -66.5187
trainer/Q Targets Mean            -21.7614
trainer/Q Targets Std              13.3531
trainer/Q Targets Max             -10.2157
trainer/Q Targets Min             -66.5991
trainer/Log Pis Mean                2.0842
trainer/Log Pis Std                 1.59322
trainer/Log Pis Max                 7.73452
trainer/Log Pis Min                -4.49269
trainer/Policy mu Mean              0.108329
trainer/Policy mu Std               0.853779
trainer/Policy mu Max               3.17858
trainer/Policy mu Min              -2.69476
trainer/Policy log std Mean        -1.95452
trainer/Policy log std Std          0.533716
trainer/Policy log std Max         -0.304456
trainer/Policy log std Min         -2.56782
trainer/Alpha                       0.0536763
trainer/Alpha Loss                  0.246263
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387849
exploration/Rewards Std             1.13521
exploration/Rewards Max            -0.0142392
exploration/Rewards Min           -10.6217
exploration/Returns Mean          -38.7849
exploration/Returns Std            14.9077
exploration/Returns Max           -17.3715
exploration/Returns Min           -61.5489
exploration/Actions Mean            0.0388279
exploration/Actions Std             0.251658
exploration/Actions Max             0.999778
exploration/Actions Min            -0.992128
exploration/Num Paths               5
exploration/Average Returns       -38.7849
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.502849
evaluation/Rewards Std              0.996524
evaluation/Rewards Max             -0.0483209
evaluation/Rewards Min             -8.64472
evaluation/Returns Mean           -50.2849
evaluation/Returns Std             28.9247
evaluation/Returns Max            -22.0994
evaluation/Returns Min           -113.372
evaluation/Actions Mean             0.00311941
evaluation/Actions Std              0.202726
evaluation/Actions Max              0.997671
evaluation/Actions Min             -0.999213
evaluation/Num Paths               15
evaluation/Average Returns        -50.2849
time/data storing (s)               0.00295795
time/evaluation sampling (s)        0.329308
time/exploration sampling (s)       0.141634
time/logging (s)                    0.00488395
time/saving (s)                     0.00195421
time/training (s)                   1.95797
time/epoch (s)                      2.43871
time/total (s)                    190.378
Epoch                              77
-----------------------------  ---------------
2019-04-22 22:39:47.035104 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size              39700
trainer/QF1 Loss                    2.77304
trainer/QF2 Loss                    2.77166
trainer/Policy Loss                21.9801
trainer/Q1 Predictions Mean       -20.3248
trainer/Q1 Predictions Std         13.4327
trainer/Q1 Predictions Max        -10.1641
trainer/Q1 Predictions Min        -62.9306
trainer/Q2 Predictions Mean       -20.3102
trainer/Q2 Predictions Std         13.4001
trainer/Q2 Predictions Max        -10.1818
trainer/Q2 Predictions Min        -62.4851
trainer/Q Targets Mean            -20.3551
trainer/Q Targets Std              13.601
trainer/Q Targets Max              -0.108744
trainer/Q Targets Min             -61.2946
trainer/Log Pis Mean                1.98145
trainer/Log Pis Std                 1.38366
trainer/Log Pis Max                 8.61934
trainer/Log Pis Min                -0.904767
trainer/Policy mu Mean             -0.0220083
trainer/Policy mu Std               0.680164
trainer/Policy mu Max               2.93027
trainer/Policy mu Min              -2.90155
trainer/Policy log std Mean        -2.00984
trainer/Policy log std Std          0.43928
trainer/Policy log std Max         -0.292331
trainer/Policy log std Min         -2.56303
trainer/Alpha                       0.0522687
trainer/Alpha Loss                 -0.0547384
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.458696
exploration/Rewards Std             1.07204
exploration/Rewards Max            -0.00506489
exploration/Rewards Min            -8.456
exploration/Returns Mean          -45.8696
exploration/Returns Std            11.3673
exploration/Returns Max           -31.3214
exploration/Returns Min           -60.7897
exploration/Actions Mean           -0.0108555
exploration/Actions Std             0.274664
exploration/Actions Max             0.999379
exploration/Actions Min            -0.999768
exploration/Num Paths               5
exploration/Average Returns       -45.8696
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.346862
evaluation/Rewards Std              0.874054
evaluation/Rewards Max             -0.0260349
evaluation/Rewards Min             -9.56938
evaluation/Returns Mean           -34.6862
evaluation/Returns Std             23.8707
evaluation/Returns Max             -9.50407
evaluation/Returns Min            -84.5398
evaluation/Actions Mean             0.0115675
evaluation/Actions Std              0.175563
evaluation/Actions Max              0.998447
evaluation/Actions Min             -0.994888
evaluation/Num Paths               15
evaluation/Average Returns        -34.6862
time/data storing (s)               0.00286465
time/evaluation sampling (s)        0.33206
time/exploration sampling (s)       0.145207
time/logging (s)                    0.00485518
time/saving (s)                     0.00194742
time/training (s)                   1.9499
time/epoch (s)                      2.43684
time/total (s)                    192.819
Epoch                              78
-----------------------------  ---------------
2019-04-22 22:39:49.482726 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    7.51698
trainer/QF2 Loss                    7.58924
trainer/Policy Loss                23.3355
trainer/Q1 Predictions Mean       -21.7741
trainer/Q1 Predictions Std         14.495
trainer/Q1 Predictions Max         -9.89728
trainer/Q1 Predictions Min        -70.3467
trainer/Q2 Predictions Mean       -21.7713
trainer/Q2 Predictions Std         14.455
trainer/Q2 Predictions Max         -9.90197
trainer/Q2 Predictions Min        -69.3778
trainer/Q Targets Mean            -21.9309
trainer/Q Targets Std              14.9033
trainer/Q Targets Max              -0.839481
trainer/Q Targets Min             -71.6665
trainer/Log Pis Mean                1.92803
trainer/Log Pis Std                 1.47185
trainer/Log Pis Max                 8.65094
trainer/Log Pis Min                -1.41809
trainer/Policy mu Mean              0.0313549
trainer/Policy mu Std               0.833014
trainer/Policy mu Max               2.9509
trainer/Policy mu Min              -4.0886
trainer/Policy log std Mean        -1.97792
trainer/Policy log std Std          0.502702
trainer/Policy log std Max          0.0639933
trainer/Policy log std Min         -2.50811
trainer/Alpha                       0.0515724
trainer/Alpha Loss                 -0.213358
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.303727
exploration/Rewards Std             0.687782
exploration/Rewards Max            -0.00463805
exploration/Rewards Min            -7.59675
exploration/Returns Mean          -30.3727
exploration/Returns Std            11.2305
exploration/Returns Max           -16.8693
exploration/Returns Min           -50.1203
exploration/Actions Mean           -7.8361e-05
exploration/Actions Std             0.228434
exploration/Actions Max             0.999558
exploration/Actions Min            -0.997303
exploration/Num Paths               5
exploration/Average Returns       -30.3727
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.362076
evaluation/Rewards Std              0.797117
evaluation/Rewards Max             -0.019867
evaluation/Rewards Min            -10.6292
evaluation/Returns Mean           -36.2076
evaluation/Returns Std             27.289
evaluation/Returns Max             -7.55786
evaluation/Returns Min            -87.2872
evaluation/Actions Mean            -0.00370743
evaluation/Actions Std              0.179843
evaluation/Actions Max              0.997668
evaluation/Actions Min             -0.999494
evaluation/Num Paths               15
evaluation/Average Returns        -36.2076
time/data storing (s)               0.00300161
time/evaluation sampling (s)        0.328451
time/exploration sampling (s)       0.141362
time/logging (s)                    0.00424807
time/saving (s)                     0.00194288
time/training (s)                   1.96175
time/epoch (s)                      2.44075
time/total (s)                    195.264
Epoch                              79
-----------------------------  ---------------
2019-04-22 22:39:51.894706 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size              40700
trainer/QF1 Loss                    0.268428
trainer/QF2 Loss                    0.293197
trainer/Policy Loss                24.5353
trainer/Q1 Predictions Mean       -22.7085
trainer/Q1 Predictions Std         14.687
trainer/Q1 Predictions Max         -9.91806
trainer/Q1 Predictions Min        -73.9374
trainer/Q2 Predictions Mean       -22.7324
trainer/Q2 Predictions Std         14.7155
trainer/Q2 Predictions Max         -9.89622
trainer/Q2 Predictions Min        -74.1642
trainer/Q Targets Mean            -23.0744
trainer/Q Targets Std              14.8559
trainer/Q Targets Max             -10.031
trainer/Q Targets Min             -75.2284
trainer/Log Pis Mean                2.17331
trainer/Log Pis Std                 1.49747
trainer/Log Pis Max                 8.00767
trainer/Log Pis Min                -3.30284
trainer/Policy mu Mean              0.00167806
trainer/Policy mu Std               0.895858
trainer/Policy mu Max               3.34135
trainer/Policy mu Min              -3.1792
trainer/Policy log std Mean        -1.9088
trainer/Policy log std Std          0.518318
trainer/Policy log std Max         -0.315908
trainer/Policy log std Min         -2.59023
trainer/Alpha                       0.0513202
trainer/Alpha Loss                  0.514704
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.352931
exploration/Rewards Std             0.5589
exploration/Rewards Max            -0.00329554
exploration/Rewards Min            -7.40209
exploration/Returns Mean          -35.2931
exploration/Returns Std            24.835
exploration/Returns Max           -14.038
exploration/Returns Min           -80.3675
exploration/Actions Mean           -0.00601495
exploration/Actions Std             0.227566
exploration/Actions Max             0.99603
exploration/Actions Min            -0.996144
exploration/Num Paths               5
exploration/Average Returns       -35.2931
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.33491
evaluation/Rewards Std              0.769843
evaluation/Rewards Max             -0.022075
evaluation/Rewards Min             -8.64115
evaluation/Returns Mean           -33.491
evaluation/Returns Std             27.9146
evaluation/Returns Max             -9.35554
evaluation/Returns Min           -101.482
evaluation/Actions Mean             0.00937519
evaluation/Actions Std              0.175638
evaluation/Actions Max              0.99906
evaluation/Actions Min             -0.998791
evaluation/Num Paths               15
evaluation/Average Returns        -33.491
time/data storing (s)               0.002889
time/evaluation sampling (s)        0.322709
time/exploration sampling (s)       0.143139
time/logging (s)                    0.0048899
time/saving (s)                     0.0019664
time/training (s)                   1.93078
time/epoch (s)                      2.40637
time/total (s)                    197.675
Epoch                              80
-----------------------------  ---------------
2019-04-22 22:39:54.340390 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                    1.10816
trainer/QF2 Loss                    1.09473
trainer/Policy Loss                20.4918
trainer/Q1 Predictions Mean       -19.2043
trainer/Q1 Predictions Std         12.1509
trainer/Q1 Predictions Max         -9.75792
trainer/Q1 Predictions Min        -48.5571
trainer/Q2 Predictions Mean       -19.19
trainer/Q2 Predictions Std         12.1578
trainer/Q2 Predictions Max         -9.70845
trainer/Q2 Predictions Min        -48.832
trainer/Q Targets Mean            -19.2279
trainer/Q Targets Std              12.3025
trainer/Q Targets Max              -0.108217
trainer/Q Targets Min             -49.184
trainer/Log Pis Mean                1.97151
trainer/Log Pis Std                 1.35525
trainer/Log Pis Max                 6.6447
trainer/Log Pis Min                -1.9422
trainer/Policy mu Mean              0.0500912
trainer/Policy mu Std               0.782694
trainer/Policy mu Max               2.92216
trainer/Policy mu Min              -2.40993
trainer/Policy log std Mean        -1.99923
trainer/Policy log std Std          0.505377
trainer/Policy log std Max         -0.54708
trainer/Policy log std Min         -2.59101
trainer/Alpha                       0.051453
trainer/Alpha Loss                 -0.0845165
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.246132
exploration/Rewards Std             0.639899
exploration/Rewards Max            -0.00961788
exploration/Rewards Min            -7.38563
exploration/Returns Mean          -24.6132
exploration/Returns Std            10.6795
exploration/Returns Max           -14.1631
exploration/Returns Min           -44.6234
exploration/Actions Mean           -0.0105822
exploration/Actions Std             0.210822
exploration/Actions Max             0.998741
exploration/Actions Min            -0.999368
exploration/Num Paths               5
exploration/Average Returns       -24.6132
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.385373
evaluation/Rewards Std              0.923434
evaluation/Rewards Max             -0.00628309
evaluation/Rewards Min             -9.74406
evaluation/Returns Mean           -38.5373
evaluation/Returns Std             36.9785
evaluation/Returns Max             -5.56905
evaluation/Returns Min           -113.872
evaluation/Actions Mean            -0.00540708
evaluation/Actions Std              0.174025
evaluation/Actions Max              0.997654
evaluation/Actions Min             -0.999345
evaluation/Num Paths               15
evaluation/Average Returns        -38.5373
time/data storing (s)               0.0029793
time/evaluation sampling (s)        0.328594
time/exploration sampling (s)       0.145394
time/logging (s)                    0.00486816
time/saving (s)                     0.00195172
time/training (s)                   1.95526
time/epoch (s)                      2.43905
time/total (s)                    200.119
Epoch                              81
-----------------------------  ---------------
2019-04-22 22:39:56.765028 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size              41700
trainer/QF1 Loss                    2.5188
trainer/QF2 Loss                    2.52908
trainer/Policy Loss                22.6992
trainer/Q1 Predictions Mean       -21.6135
trainer/Q1 Predictions Std         13.3861
trainer/Q1 Predictions Max         -9.63839
trainer/Q1 Predictions Min        -52.4854
trainer/Q2 Predictions Mean       -21.6364
trainer/Q2 Predictions Std         13.4117
trainer/Q2 Predictions Max         -9.60254
trainer/Q2 Predictions Min        -52.6502
trainer/Q Targets Mean            -21.4339
trainer/Q Targets Std              13.5462
trainer/Q Targets Max              -0.216349
trainer/Q Targets Min             -53.0118
trainer/Log Pis Mean                1.79555
trainer/Log Pis Std                 1.57322
trainer/Log Pis Max                 7.10521
trainer/Log Pis Min                -6.08013
trainer/Policy mu Mean             -0.128441
trainer/Policy mu Std               0.892462
trainer/Policy mu Max               2.90395
trainer/Policy mu Min              -2.72232
trainer/Policy log std Mean        -1.91563
trainer/Policy log std Std          0.568693
trainer/Policy log std Max         -0.374252
trainer/Policy log std Min         -2.52915
trainer/Alpha                       0.0515345
trainer/Alpha Loss                 -0.606273
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.429794
exploration/Rewards Std             0.762837
exploration/Rewards Max            -0.00913088
exploration/Rewards Min            -8.56873
exploration/Returns Mean          -42.9794
exploration/Returns Std            28.8432
exploration/Returns Max           -20.5486
exploration/Returns Min           -96.6266
exploration/Actions Mean           -0.00115372
exploration/Actions Std             0.223526
exploration/Actions Max             0.99722
exploration/Actions Min            -0.998011
exploration/Num Paths               5
exploration/Average Returns       -42.9794
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.553366
evaluation/Rewards Std              1.04602
evaluation/Rewards Max             -0.0156328
evaluation/Rewards Min            -10.4923
evaluation/Returns Mean           -55.3366
evaluation/Returns Std             37.6439
evaluation/Returns Max            -10.8581
evaluation/Returns Min           -125.674
evaluation/Actions Mean            -0.00243328
evaluation/Actions Std              0.19178
evaluation/Actions Max              0.997846
evaluation/Actions Min             -0.999516
evaluation/Num Paths               15
evaluation/Average Returns        -55.3366
time/data storing (s)               0.00304705
time/evaluation sampling (s)        0.325712
time/exploration sampling (s)       0.139793
time/logging (s)                    0.0048529
time/saving (s)                     0.00195002
time/training (s)                   1.9434
time/epoch (s)                      2.41876
time/total (s)                    202.542
Epoch                              82
-----------------------------  ---------------
2019-04-22 22:39:59.175882 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                   21.2769
trainer/QF2 Loss                   21.2741
trainer/Policy Loss                22.4053
trainer/Q1 Predictions Mean       -20.8063
trainer/Q1 Predictions Std         14.9393
trainer/Q1 Predictions Max         -9.5966
trainer/Q1 Predictions Min        -82.5385
trainer/Q2 Predictions Mean       -20.8024
trainer/Q2 Predictions Std         14.9333
trainer/Q2 Predictions Max         -9.60679
trainer/Q2 Predictions Min        -83.0147
trainer/Q Targets Mean            -20.5683
trainer/Q Targets Std              14.9558
trainer/Q Targets Max              -3.16982
trainer/Q Targets Min             -83.045
trainer/Log Pis Mean                2.21357
trainer/Log Pis Std                 1.51664
trainer/Log Pis Max                 6.75624
trainer/Log Pis Min                -2.72692
trainer/Policy mu Mean              0.0709326
trainer/Policy mu Std               0.939028
trainer/Policy mu Max               3.2765
trainer/Policy mu Min              -3.31608
trainer/Policy log std Mean        -1.96085
trainer/Policy log std Std          0.548585
trainer/Policy log std Max         -0.337691
trainer/Policy log std Min         -2.56624
trainer/Alpha                       0.0522894
trainer/Alpha Loss                  0.630291
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.314524
exploration/Rewards Std             0.913645
exploration/Rewards Max            -0.00650409
exploration/Rewards Min            -9.29424
exploration/Returns Mean          -31.4524
exploration/Returns Std            16.0894
exploration/Returns Max           -15.9865
exploration/Returns Min           -60.3713
exploration/Actions Mean            0.0257746
exploration/Actions Std             0.203767
exploration/Actions Max             0.999724
exploration/Actions Min            -0.517751
exploration/Num Paths               5
exploration/Average Returns       -31.4524
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.491458
evaluation/Rewards Std              0.928898
evaluation/Rewards Max             -0.0582614
evaluation/Rewards Min            -10.2261
evaluation/Returns Mean           -49.1458
evaluation/Returns Std             44.7918
evaluation/Returns Max            -10.1765
evaluation/Returns Min           -134.366
evaluation/Actions Mean             0.00441596
evaluation/Actions Std              0.17466
evaluation/Actions Max              0.999521
evaluation/Actions Min             -0.998394
evaluation/Num Paths               15
evaluation/Average Returns        -49.1458
time/data storing (s)               0.0028175
time/evaluation sampling (s)        0.329977
time/exploration sampling (s)       0.137594
time/logging (s)                    0.00483016
time/saving (s)                     0.00195589
time/training (s)                   1.92761
time/epoch (s)                      2.40478
time/total (s)                    204.951
Epoch                              83
-----------------------------  ---------------
2019-04-22 22:40:01.600793 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                    0.193588
trainer/QF2 Loss                    0.199928
trainer/Policy Loss                23.1204
trainer/Q1 Predictions Mean       -21.6625
trainer/Q1 Predictions Std         13.2915
trainer/Q1 Predictions Max         -9.56037
trainer/Q1 Predictions Min        -49.1264
trainer/Q2 Predictions Mean       -21.6505
trainer/Q2 Predictions Std         13.2544
trainer/Q2 Predictions Max         -9.53414
trainer/Q2 Predictions Min        -48.8328
trainer/Q Targets Mean            -21.9093
trainer/Q Targets Std              13.4897
trainer/Q Targets Max              -9.4954
trainer/Q Targets Min             -49.2194
trainer/Log Pis Mean                1.7384
trainer/Log Pis Std                 1.19085
trainer/Log Pis Max                 5.71874
trainer/Log Pis Min                -2.63444
trainer/Policy mu Mean              0.0817194
trainer/Policy mu Std               0.748852
trainer/Policy mu Max               3.25479
trainer/Policy mu Min              -2.98792
trainer/Policy log std Mean        -1.96651
trainer/Policy log std Std          0.495312
trainer/Policy log std Max         -0.337652
trainer/Policy log std Min         -2.44897
trainer/Alpha                       0.0533812
trainer/Alpha Loss                 -0.766568
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.399547
exploration/Rewards Std             1.12092
exploration/Rewards Max            -0.00822852
exploration/Rewards Min            -9.52943
exploration/Returns Mean          -39.9547
exploration/Returns Std            14.8127
exploration/Returns Max           -19.6288
exploration/Returns Min           -61.8368
exploration/Actions Mean            0.0215277
exploration/Actions Std             0.255728
exploration/Actions Max             0.999457
exploration/Actions Min            -0.998667
exploration/Num Paths               5
exploration/Average Returns       -39.9547
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.311406
evaluation/Rewards Std              0.971961
evaluation/Rewards Max             -0.0105223
evaluation/Rewards Min             -9.76072
evaluation/Returns Mean           -31.1406
evaluation/Returns Std             27.2855
evaluation/Returns Max             -4.11868
evaluation/Returns Min           -121.778
evaluation/Actions Mean             0.00643425
evaluation/Actions Std              0.197373
evaluation/Actions Max              0.998242
evaluation/Actions Min             -0.997825
evaluation/Num Paths               15
evaluation/Average Returns        -31.1406
time/data storing (s)               0.00301147
time/evaluation sampling (s)        0.327782
time/exploration sampling (s)       0.141199
time/logging (s)                    0.00442004
time/saving (s)                     0.00195037
time/training (s)                   1.93979
time/epoch (s)                      2.41815
time/total (s)                    207.373
Epoch                              84
-----------------------------  ---------------
2019-04-22 22:40:04.017106 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                   20.2599
trainer/QF2 Loss                   20.2216
trainer/Policy Loss                22.5144
trainer/Q1 Predictions Mean       -20.7968
trainer/Q1 Predictions Std         14.2902
trainer/Q1 Predictions Max         -9.36706
trainer/Q1 Predictions Min        -55.5001
trainer/Q2 Predictions Mean       -20.8112
trainer/Q2 Predictions Std         14.3137
trainer/Q2 Predictions Max         -9.39566
trainer/Q2 Predictions Min        -55.4225
trainer/Q Targets Mean            -20.4462
trainer/Q Targets Std              14.55
trainer/Q Targets Max              -0.0654368
trainer/Q Targets Min             -55.8116
trainer/Log Pis Mean                2.09009
trainer/Log Pis Std                 1.42289
trainer/Log Pis Max                 8.56941
trainer/Log Pis Min                -2.93396
trainer/Policy mu Mean              0.0950315
trainer/Policy mu Std               0.800402
trainer/Policy mu Max               3.26642
trainer/Policy mu Min              -2.80154
trainer/Policy log std Mean        -1.99998
trainer/Policy log std Std          0.505441
trainer/Policy log std Max         -0.187057
trainer/Policy log std Min         -2.5013
trainer/Alpha                       0.0531931
trainer/Alpha Loss                  0.264291
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.513295
exploration/Rewards Std             0.959773
exploration/Rewards Max            -0.00604188
exploration/Rewards Min            -7.52797
exploration/Returns Mean          -51.3295
exploration/Returns Std            32.6119
exploration/Returns Max           -12.5688
exploration/Returns Min          -111.661
exploration/Actions Mean            0.0061896
exploration/Actions Std             0.231575
exploration/Actions Max             0.999526
exploration/Actions Min            -0.997991
exploration/Num Paths               5
exploration/Average Returns       -51.3295
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.374094
evaluation/Rewards Std              0.955341
evaluation/Rewards Max             -0.0121502
evaluation/Rewards Min            -10.571
evaluation/Returns Mean           -37.4094
evaluation/Returns Std             36.1454
evaluation/Returns Max            -10.7233
evaluation/Returns Min           -140.109
evaluation/Actions Mean             0.00231694
evaluation/Actions Std              0.181962
evaluation/Actions Max              0.997894
evaluation/Actions Min             -0.999216
evaluation/Num Paths               15
evaluation/Average Returns        -37.4094
time/data storing (s)               0.00292906
time/evaluation sampling (s)        0.331332
time/exploration sampling (s)       0.142356
time/logging (s)                    0.00483928
time/saving (s)                     0.00175022
time/training (s)                   1.92783
time/epoch (s)                      2.41104
time/total (s)                    209.788
Epoch                              85
-----------------------------  ---------------
2019-04-22 22:40:06.461256 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size              43700
trainer/QF1 Loss                    1.599
trainer/QF2 Loss                    1.57191
trainer/Policy Loss                21.4854
trainer/Q1 Predictions Mean       -19.8359
trainer/Q1 Predictions Std         15.1838
trainer/Q1 Predictions Max         -9.25423
trainer/Q1 Predictions Min        -85.5165
trainer/Q2 Predictions Mean       -19.8543
trainer/Q2 Predictions Std         15.21
trainer/Q2 Predictions Max         -9.28863
trainer/Q2 Predictions Min        -86.1427
trainer/Q Targets Mean            -20.151
trainer/Q Targets Std              15.7421
trainer/Q Targets Max              -0.655359
trainer/Q Targets Min             -87.1926
trainer/Log Pis Mean                1.93701
trainer/Log Pis Std                 1.70109
trainer/Log Pis Max                10.4186
trainer/Log Pis Min                -3.51913
trainer/Policy mu Mean             -0.0654001
trainer/Policy mu Std               0.809609
trainer/Policy mu Max               3.20292
trainer/Policy mu Min              -4.01675
trainer/Policy log std Mean        -2.03848
trainer/Policy log std Std          0.501955
trainer/Policy log std Max         -0.220799
trainer/Policy log std Min         -2.60979
trainer/Alpha                       0.0518685
trainer/Alpha Loss                 -0.18639
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.461879
exploration/Rewards Std             1.30195
exploration/Rewards Max            -0.0130613
exploration/Rewards Min           -10.9582
exploration/Returns Mean          -46.1879
exploration/Returns Std            17.477
exploration/Returns Max           -25.9992
exploration/Returns Min           -75.6857
exploration/Actions Mean           -0.00157791
exploration/Actions Std             0.275355
exploration/Actions Max             0.998859
exploration/Actions Min            -0.99937
exploration/Num Paths               5
exploration/Average Returns       -46.1879
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.368846
evaluation/Rewards Std              1.13544
evaluation/Rewards Max             -0.0271022
evaluation/Rewards Min             -9.84074
evaluation/Returns Mean           -36.8846
evaluation/Returns Std             31.8734
evaluation/Returns Max             -4.30743
evaluation/Returns Min           -139.17
evaluation/Actions Mean            -0.0103211
evaluation/Actions Std              0.201453
evaluation/Actions Max              0.998319
evaluation/Actions Min             -0.999666
evaluation/Num Paths               15
evaluation/Average Returns        -36.8846
time/data storing (s)               0.00291181
time/evaluation sampling (s)        0.325932
time/exploration sampling (s)       0.139754
time/logging (s)                    0.00467294
time/saving (s)                     0.00158806
time/training (s)                   1.96279
time/epoch (s)                      2.43765
time/total (s)                    212.231
Epoch                              86
-----------------------------  ---------------
2019-04-22 22:40:08.907219 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 87 finished
-----------------------------  ----------------
replay_buffer/size              44200
trainer/QF1 Loss                    2.12335
trainer/QF2 Loss                    2.16404
trainer/Policy Loss                23.1608
trainer/Q1 Predictions Mean       -21.4605
trainer/Q1 Predictions Std         15.4594
trainer/Q1 Predictions Max         -9.12993
trainer/Q1 Predictions Min        -64.7406
trainer/Q2 Predictions Mean       -21.4217
trainer/Q2 Predictions Std         15.4388
trainer/Q2 Predictions Max         -9.12434
trainer/Q2 Predictions Min        -64.278
trainer/Q Targets Mean            -21.3731
trainer/Q Targets Std              15.6777
trainer/Q Targets Max              -0.293054
trainer/Q Targets Min             -65.3729
trainer/Log Pis Mean                2.08033
trainer/Log Pis Std                 1.32688
trainer/Log Pis Max                 6.51755
trainer/Log Pis Min                -2.8519
trainer/Policy mu Mean             -0.0337012
trainer/Policy mu Std               0.799247
trainer/Policy mu Max               3.11499
trainer/Policy mu Min              -3.77733
trainer/Policy log std Mean        -2.04382
trainer/Policy log std Std          0.525816
trainer/Policy log std Max         -0.246209
trainer/Policy log std Min         -2.56316
trainer/Alpha                       0.0521334
trainer/Alpha Loss                  0.237297
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.684471
exploration/Rewards Std             1.19385
exploration/Rewards Max            -0.00967626
exploration/Rewards Min           -10.5303
exploration/Returns Mean          -68.4471
exploration/Returns Std            34.6509
exploration/Returns Max           -30.8094
exploration/Returns Min          -126.526
exploration/Actions Mean           -0.0163474
exploration/Actions Std             0.257321
exploration/Actions Max             0.999117
exploration/Actions Min            -0.999754
exploration/Num Paths               5
exploration/Average Returns       -68.4471
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.334808
evaluation/Rewards Std              0.75033
evaluation/Rewards Max             -0.000934856
evaluation/Rewards Min             -9.84958
evaluation/Returns Mean           -33.4808
evaluation/Returns Std             32.4527
evaluation/Returns Max             -4.84813
evaluation/Returns Min           -105.647
evaluation/Actions Mean            -3.03003e-05
evaluation/Actions Std              0.148865
evaluation/Actions Max              0.998172
evaluation/Actions Min             -0.998713
evaluation/Num Paths               15
evaluation/Average Returns        -33.4808
time/data storing (s)               0.00288337
time/evaluation sampling (s)        0.32319
time/exploration sampling (s)       0.141035
time/logging (s)                    0.00490778
time/saving (s)                     0.00203243
time/training (s)                   1.96571
time/epoch (s)                      2.43976
time/total (s)                    214.675
Epoch                              87
-----------------------------  ----------------
2019-04-22 22:40:11.328856 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size              44700
trainer/QF1 Loss                   20.5283
trainer/QF2 Loss                   20.6222
trainer/Policy Loss                23.6543
trainer/Q1 Predictions Mean       -22.0211
trainer/Q1 Predictions Std         17.0813
trainer/Q1 Predictions Max         -9.15109
trainer/Q1 Predictions Min        -79.3954
trainer/Q2 Predictions Mean       -22.0299
trainer/Q2 Predictions Std         17.122
trainer/Q2 Predictions Max         -9.10386
trainer/Q2 Predictions Min        -80.076
trainer/Q Targets Mean            -21.5788
trainer/Q Targets Std              17.2837
trainer/Q Targets Max              -0.236004
trainer/Q Targets Min             -80.898
trainer/Log Pis Mean                2.12111
trainer/Log Pis Std                 1.52385
trainer/Log Pis Max                 7.81831
trainer/Log Pis Min                -2.43531
trainer/Policy mu Mean             -0.0623367
trainer/Policy mu Std               0.844088
trainer/Policy mu Max               3.15378
trainer/Policy mu Min              -3.60504
trainer/Policy log std Mean        -2.01208
trainer/Policy log std Std          0.526153
trainer/Policy log std Max         -0.327189
trainer/Policy log std Min         -2.49814
trainer/Alpha                       0.0529573
trainer/Alpha Loss                  0.355846
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.333693
exploration/Rewards Std             0.88984
exploration/Rewards Max            -0.00718202
exploration/Rewards Min            -9.9112
exploration/Returns Mean          -33.3693
exploration/Returns Std            16.7567
exploration/Returns Max           -19.5506
exploration/Returns Min           -66.2001
exploration/Actions Mean            0.0147285
exploration/Actions Std             0.229687
exploration/Actions Max             0.999747
exploration/Actions Min            -0.982766
exploration/Num Paths               5
exploration/Average Returns       -33.3693
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.403444
evaluation/Rewards Std              1.0757
evaluation/Rewards Max             -0.0104766
evaluation/Rewards Min            -10.1898
evaluation/Returns Mean           -40.3444
evaluation/Returns Std             25.0747
evaluation/Returns Max            -15.0822
evaluation/Returns Min            -92.3031
evaluation/Actions Mean             0.00298521
evaluation/Actions Std              0.19965
evaluation/Actions Max              0.998021
evaluation/Actions Min             -0.999046
evaluation/Num Paths               15
evaluation/Average Returns        -40.3444
time/data storing (s)               0.00285054
time/evaluation sampling (s)        0.326725
time/exploration sampling (s)       0.138197
time/logging (s)                    0.00389859
time/saving (s)                     0.00195774
time/training (s)                   1.94054
time/epoch (s)                      2.41417
time/total (s)                    217.093
Epoch                              88
-----------------------------  ---------------
2019-04-22 22:40:13.802784 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 89 finished
-----------------------------  ---------------
replay_buffer/size              45200
trainer/QF1 Loss                    0.320801
trainer/QF2 Loss                    0.339827
trainer/Policy Loss                24.8053
trainer/Q1 Predictions Mean       -23.2071
trainer/Q1 Predictions Std         15.04
trainer/Q1 Predictions Max         -9.06625
trainer/Q1 Predictions Min        -51.0624
trainer/Q2 Predictions Mean       -23.2226
trainer/Q2 Predictions Std         15.0268
trainer/Q2 Predictions Max         -9.05561
trainer/Q2 Predictions Min        -51.3776
trainer/Q Targets Mean            -23.4915
trainer/Q Targets Std              15.4155
trainer/Q Targets Max              -8.94199
trainer/Q Targets Min             -53.457
trainer/Log Pis Mean                2.04021
trainer/Log Pis Std                 1.31305
trainer/Log Pis Max                 6.89342
trainer/Log Pis Min                -1.55562
trainer/Policy mu Mean              0.0858772
trainer/Policy mu Std               0.855259
trainer/Policy mu Max               3.25336
trainer/Policy mu Min              -3.13437
trainer/Policy log std Mean        -1.9392
trainer/Policy log std Std          0.498539
trainer/Policy log std Max         -0.48695
trainer/Policy log std Min         -2.61378
trainer/Alpha                       0.0521211
trainer/Alpha Loss                  0.118789
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.511356
exploration/Rewards Std             0.982594
exploration/Rewards Max            -0.00479408
exploration/Rewards Min            -9.39433
exploration/Returns Mean          -51.1356
exploration/Returns Std            25.3184
exploration/Returns Max           -20.7002
exploration/Returns Min           -93.6449
exploration/Actions Mean           -0.0246198
exploration/Actions Std             0.252756
exploration/Actions Max             0.982929
exploration/Actions Min            -0.999463
exploration/Num Paths               5
exploration/Average Returns       -51.1356
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.380867
evaluation/Rewards Std              1.05278
evaluation/Rewards Max             -0.0451687
evaluation/Rewards Min            -10.9119
evaluation/Returns Mean           -38.0867
evaluation/Returns Std             34.3448
evaluation/Returns Max             -9.04635
evaluation/Returns Min           -118.782
evaluation/Actions Mean             0.0164682
evaluation/Actions Std              0.192997
evaluation/Actions Max              0.998775
evaluation/Actions Min             -0.998732
evaluation/Num Paths               15
evaluation/Average Returns        -38.0867
time/data storing (s)               0.00370499
time/evaluation sampling (s)        0.329533
time/exploration sampling (s)       0.179459
time/logging (s)                    0.0044049
time/saving (s)                     0.00983353
time/training (s)                   1.94224
time/epoch (s)                      2.46917
time/total (s)                    219.566
Epoch                              89
-----------------------------  ---------------
2019-04-22 22:40:16.245908 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size              45700
trainer/QF1 Loss                    0.316276
trainer/QF2 Loss                    0.308571
trainer/Policy Loss                21.6345
trainer/Q1 Predictions Mean       -19.9323
trainer/Q1 Predictions Std         13.7837
trainer/Q1 Predictions Max         -8.98353
trainer/Q1 Predictions Min        -67.8469
trainer/Q2 Predictions Mean       -19.9636
trainer/Q2 Predictions Std         13.7701
trainer/Q2 Predictions Max         -8.97319
trainer/Q2 Predictions Min        -67.3373
trainer/Q Targets Mean            -20.2511
trainer/Q Targets Std              14.1611
trainer/Q Targets Max              -8.92253
trainer/Q Targets Min             -68.9666
trainer/Log Pis Mean                2.05532
trainer/Log Pis Std                 1.48882
trainer/Log Pis Max                 8.16383
trainer/Log Pis Min                -2.44268
trainer/Policy mu Mean             -0.0265136
trainer/Policy mu Std               0.748115
trainer/Policy mu Max               2.33493
trainer/Policy mu Min              -3.57405
trainer/Policy log std Mean        -2.06091
trainer/Policy log std Std          0.47461
trainer/Policy log std Max         -0.366813
trainer/Policy log std Min         -2.57847
trainer/Alpha                       0.0525323
trainer/Alpha Loss                  0.162993
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.562597
exploration/Rewards Std             1.19063
exploration/Rewards Max            -0.00372953
exploration/Rewards Min            -9.8303
exploration/Returns Mean          -56.2597
exploration/Returns Std            25.7625
exploration/Returns Max           -28.4395
exploration/Returns Min           -99.6646
exploration/Actions Mean           -0.024068
exploration/Actions Std             0.250163
exploration/Actions Max             0.996877
exploration/Actions Min            -0.999855
exploration/Num Paths               5
exploration/Average Returns       -56.2597
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.384632
evaluation/Rewards Std              0.87124
evaluation/Rewards Max             -0.0150933
evaluation/Rewards Min            -10.5214
evaluation/Returns Mean           -38.4632
evaluation/Returns Std             27.8604
evaluation/Returns Max             -9.70373
evaluation/Returns Min           -109.792
evaluation/Actions Mean            -0.00253618
evaluation/Actions Std              0.188223
evaluation/Actions Max              0.995927
evaluation/Actions Min             -0.999871
evaluation/Num Paths               15
evaluation/Average Returns        -38.4632
time/data storing (s)               0.00280874
time/evaluation sampling (s)        0.325713
time/exploration sampling (s)       0.144036
time/logging (s)                    0.00440349
time/saving (s)                     0.00199236
time/training (s)                   1.95906
time/epoch (s)                      2.43801
time/total (s)                    222.008
Epoch                              90
-----------------------------  ---------------
2019-04-22 22:40:18.679135 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 91 finished
-----------------------------  ----------------
replay_buffer/size              46200
trainer/QF1 Loss                    0.256505
trainer/QF2 Loss                    0.249404
trainer/Policy Loss                21.3099
trainer/Q1 Predictions Mean       -19.8828
trainer/Q1 Predictions Std         14.7004
trainer/Q1 Predictions Max         -8.94307
trainer/Q1 Predictions Min        -66.0794
trainer/Q2 Predictions Mean       -19.8779
trainer/Q2 Predictions Std         14.7059
trainer/Q2 Predictions Max         -8.95719
trainer/Q2 Predictions Min        -66.0823
trainer/Q Targets Mean            -20.0554
trainer/Q Targets Std              15.0178
trainer/Q Targets Max              -8.82166
trainer/Q Targets Min             -69.6818
trainer/Log Pis Mean                1.88648
trainer/Log Pis Std                 1.42182
trainer/Log Pis Max                 8.33098
trainer/Log Pis Min                -1.76067
trainer/Policy mu Mean              0.0276736
trainer/Policy mu Std               0.78664
trainer/Policy mu Max               2.94083
trainer/Policy mu Min              -3.33021
trainer/Policy log std Mean        -1.98964
trainer/Policy log std Std          0.471833
trainer/Policy log std Max         -0.237133
trainer/Policy log std Min         -2.45269
trainer/Alpha                       0.0523061
trainer/Alpha Loss                 -0.33494
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.47388
exploration/Rewards Std             1.00955
exploration/Rewards Max            -0.0125039
exploration/Rewards Min            -8.52562
exploration/Returns Mean          -47.388
exploration/Returns Std            24.3434
exploration/Returns Max           -16.9006
exploration/Returns Min           -90.3461
exploration/Actions Mean            0.000551934
exploration/Actions Std             0.242825
exploration/Actions Max             0.999974
exploration/Actions Min            -0.999301
exploration/Num Paths               5
exploration/Average Returns       -47.388
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.492748
evaluation/Rewards Std              0.889868
evaluation/Rewards Max             -0.0108462
evaluation/Rewards Min             -9.29028
evaluation/Returns Mean           -49.2748
evaluation/Returns Std             36.0868
evaluation/Returns Max             -4.54629
evaluation/Returns Min           -117.566
evaluation/Actions Mean            -0.0059841
evaluation/Actions Std              0.177512
evaluation/Actions Max              0.997822
evaluation/Actions Min             -0.999413
evaluation/Num Paths               15
evaluation/Average Returns        -49.2748
time/data storing (s)               0.00299394
time/evaluation sampling (s)        0.328244
time/exploration sampling (s)       0.140749
time/logging (s)                    0.00474658
time/saving (s)                     0.00195492
time/training (s)                   1.94946
time/epoch (s)                      2.42815
time/total (s)                    224.44
Epoch                              91
-----------------------------  ----------------
2019-04-22 22:40:21.135090 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 92 finished
-----------------------------  ----------------
replay_buffer/size              46700
trainer/QF1 Loss                    0.209086
trainer/QF2 Loss                    0.214183
trainer/Policy Loss                21.4896
trainer/Q1 Predictions Mean       -19.7152
trainer/Q1 Predictions Std         14.777
trainer/Q1 Predictions Max         -8.60822
trainer/Q1 Predictions Min        -59.8224
trainer/Q2 Predictions Mean       -19.738
trainer/Q2 Predictions Std         14.7413
trainer/Q2 Predictions Max         -8.64583
trainer/Q2 Predictions Min        -59.9619
trainer/Q Targets Mean            -20.0081
trainer/Q Targets Std              14.8762
trainer/Q Targets Max              -8.72528
trainer/Q Targets Min             -59.3996
trainer/Log Pis Mean                2.37521
trainer/Log Pis Std                 1.50623
trainer/Log Pis Max                 8.39791
trainer/Log Pis Min                -1.39414
trainer/Policy mu Mean              0.0611772
trainer/Policy mu Std               0.963221
trainer/Policy mu Max               3.33427
trainer/Policy mu Min              -3.34605
trainer/Policy log std Mean        -1.96929
trainer/Policy log std Std          0.557038
trainer/Policy log std Max         -0.230213
trainer/Policy log std Min         -2.48914
trainer/Alpha                       0.0524649
trainer/Alpha Loss                  1.10602
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.384866
exploration/Rewards Std             1.18469
exploration/Rewards Max            -0.00843725
exploration/Rewards Min           -10.3305
exploration/Returns Mean          -38.4866
exploration/Returns Std            22.3727
exploration/Returns Max           -16.4146
exploration/Returns Min           -72.5147
exploration/Actions Mean            0.0182619
exploration/Actions Std             0.237742
exploration/Actions Max             0.999092
exploration/Actions Min            -0.999257
exploration/Num Paths               5
exploration/Average Returns       -38.4866
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.374046
evaluation/Rewards Std              1.03321
evaluation/Rewards Max             -0.0311201
evaluation/Rewards Min             -9.83293
evaluation/Returns Mean           -37.4046
evaluation/Returns Std             29.7662
evaluation/Returns Max             -6.68574
evaluation/Returns Min           -104.25
evaluation/Actions Mean             0.000553387
evaluation/Actions Std              0.188241
evaluation/Actions Max              0.99894
evaluation/Actions Min             -0.999764
evaluation/Num Paths               15
evaluation/Average Returns        -37.4046
time/data storing (s)               0.00307899
time/evaluation sampling (s)        0.329252
time/exploration sampling (s)       0.140107
time/logging (s)                    0.00485857
time/saving (s)                     0.00194924
time/training (s)                   1.97094
time/epoch (s)                      2.45019
time/total (s)                    226.895
Epoch                              92
-----------------------------  ----------------
2019-04-22 22:40:23.564827 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size              47200
trainer/QF1 Loss                    0.887539
trainer/QF2 Loss                    0.9781
trainer/Policy Loss                19.066
trainer/Q1 Predictions Mean       -17.4464
trainer/Q1 Predictions Std         12.2069
trainer/Q1 Predictions Max         -8.7253
trainer/Q1 Predictions Min        -52.3478
trainer/Q2 Predictions Mean       -17.4639
trainer/Q2 Predictions Std         12.2345
trainer/Q2 Predictions Max         -8.71283
trainer/Q2 Predictions Min        -52.35
trainer/Q Targets Mean            -17.4804
trainer/Q Targets Std              12.4735
trainer/Q Targets Max              -0.201764
trainer/Q Targets Min             -52.0536
trainer/Log Pis Mean                1.9977
trainer/Log Pis Std                 1.26228
trainer/Log Pis Max                 7.19882
trainer/Log Pis Min                -1.75278
trainer/Policy mu Mean              0.0547804
trainer/Policy mu Std               0.759765
trainer/Policy mu Max               2.79016
trainer/Policy mu Min              -2.81264
trainer/Policy log std Mean        -2.00583
trainer/Policy log std Std          0.482239
trainer/Policy log std Max         -0.586035
trainer/Policy log std Min         -2.48964
trainer/Alpha                       0.0523714
trainer/Alpha Loss                 -0.00679485
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.596535
exploration/Rewards Std             0.928707
exploration/Rewards Max            -0.00731637
exploration/Rewards Min            -9.06693
exploration/Returns Mean          -59.6535
exploration/Returns Std            40.9216
exploration/Returns Max           -12.3128
exploration/Returns Min          -118.909
exploration/Actions Mean            0.0121251
exploration/Actions Std             0.226308
exploration/Actions Max             0.999363
exploration/Actions Min            -0.997702
exploration/Num Paths               5
exploration/Average Returns       -59.6535
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.581592
evaluation/Rewards Std              0.913954
evaluation/Rewards Max             -0.0224932
evaluation/Rewards Min             -8.40011
evaluation/Returns Mean           -58.1592
evaluation/Returns Std             42.7975
evaluation/Returns Max            -10.0506
evaluation/Returns Min           -123.377
evaluation/Actions Mean            -0.0169744
evaluation/Actions Std              0.180456
evaluation/Actions Max              0.99866
evaluation/Actions Min             -0.999376
evaluation/Num Paths               15
evaluation/Average Returns        -58.1592
time/data storing (s)               0.00304684
time/evaluation sampling (s)        0.321797
time/exploration sampling (s)       0.140533
time/logging (s)                    0.00486885
time/saving (s)                     0.00196448
time/training (s)                   1.95109
time/epoch (s)                      2.4233
time/total (s)                    229.322
Epoch                              93
-----------------------------  ---------------
2019-04-22 22:40:26.007022 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size              47700
trainer/QF1 Loss                    0.871446
trainer/QF2 Loss                    0.861187
trainer/Policy Loss                21.7442
trainer/Q1 Predictions Mean       -20.2806
trainer/Q1 Predictions Std         15.4461
trainer/Q1 Predictions Max         -8.5316
trainer/Q1 Predictions Min        -68.7031
trainer/Q2 Predictions Mean       -20.2916
trainer/Q2 Predictions Std         15.4564
trainer/Q2 Predictions Max         -8.50011
trainer/Q2 Predictions Min        -68.6936
trainer/Q Targets Mean            -20.3818
trainer/Q Targets Std              15.612
trainer/Q Targets Max              -0.504044
trainer/Q Targets Min             -68.0118
trainer/Log Pis Mean                1.83682
trainer/Log Pis Std                 1.44459
trainer/Log Pis Max                 6.46216
trainer/Log Pis Min                -1.48089
trainer/Policy mu Mean             -0.0589052
trainer/Policy mu Std               0.823138
trainer/Policy mu Max               3.14503
trainer/Policy mu Min              -3.45738
trainer/Policy log std Mean        -1.99829
trainer/Policy log std Std          0.527096
trainer/Policy log std Max         -0.147714
trainer/Policy log std Min         -2.50274
trainer/Alpha                       0.053053
trainer/Alpha Loss                 -0.47916
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.397482
exploration/Rewards Std             1.04956
exploration/Rewards Max            -0.00113432
exploration/Rewards Min            -8.3042
exploration/Returns Mean          -39.7482
exploration/Returns Std             6.6312
exploration/Returns Max           -29.3226
exploration/Returns Min           -47.2251
exploration/Actions Mean            0.00979595
exploration/Actions Std             0.274159
exploration/Actions Max             0.998185
exploration/Actions Min            -0.998976
exploration/Num Paths               5
exploration/Average Returns       -39.7482
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.489557
evaluation/Rewards Std              1.24569
evaluation/Rewards Max             -0.00704874
evaluation/Rewards Min            -10.125
evaluation/Returns Mean           -48.9557
evaluation/Returns Std             32.5615
evaluation/Returns Max             -9.96447
evaluation/Returns Min           -126.564
evaluation/Actions Mean             0.00707865
evaluation/Actions Std              0.213063
evaluation/Actions Max              0.99819
evaluation/Actions Min             -0.999624
evaluation/Num Paths               15
evaluation/Average Returns        -48.9557
time/data storing (s)               0.00288625
time/evaluation sampling (s)        0.319859
time/exploration sampling (s)       0.144546
time/logging (s)                    0.00495421
time/saving (s)                     0.00202536
time/training (s)                   1.96157
time/epoch (s)                      2.43584
time/total (s)                    231.763
Epoch                              94
-----------------------------  ---------------
2019-04-22 22:40:28.452455 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                    1.55039
trainer/QF2 Loss                    1.56275
trainer/Policy Loss                22.2673
trainer/Q1 Predictions Mean       -20.7344
trainer/Q1 Predictions Std         14.999
trainer/Q1 Predictions Max         -8.52064
trainer/Q1 Predictions Min        -68.1775
trainer/Q2 Predictions Mean       -20.7557
trainer/Q2 Predictions Std         15.0067
trainer/Q2 Predictions Max         -8.54079
trainer/Q2 Predictions Min        -68.2263
trainer/Q Targets Mean            -20.7151
trainer/Q Targets Std              15.2815
trainer/Q Targets Max              -0.611926
trainer/Q Targets Min             -67.433
trainer/Log Pis Mean                2.02361
trainer/Log Pis Std                 1.35783
trainer/Log Pis Max                 6.68318
trainer/Log Pis Min                -1.07894
trainer/Policy mu Mean             -0.00546371
trainer/Policy mu Std               0.832386
trainer/Policy mu Max               2.99405
trainer/Policy mu Min              -3.63111
trainer/Policy log std Mean        -1.97525
trainer/Policy log std Std          0.479031
trainer/Policy log std Max         -0.330161
trainer/Policy log std Min         -2.49549
trainer/Alpha                       0.0527195
trainer/Alpha Loss                  0.0694725
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.347742
exploration/Rewards Std             1.0174
exploration/Rewards Max            -0.00814704
exploration/Rewards Min            -8.93791
exploration/Returns Mean          -34.7742
exploration/Returns Std            14.601
exploration/Returns Max           -15.9273
exploration/Returns Min           -55.6073
exploration/Actions Mean            0.014115
exploration/Actions Std             0.241538
exploration/Actions Max             0.99906
exploration/Actions Min            -0.999919
exploration/Num Paths               5
exploration/Average Returns       -34.7742
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.32503
evaluation/Rewards Std              0.72702
evaluation/Rewards Max             -0.042728
evaluation/Rewards Min             -7.60797
evaluation/Returns Mean           -32.503
evaluation/Returns Std             31.4008
evaluation/Returns Max             -5.43193
evaluation/Returns Min           -107.741
evaluation/Actions Mean            -0.00245422
evaluation/Actions Std              0.163864
evaluation/Actions Max              0.997771
evaluation/Actions Min             -0.998619
evaluation/Num Paths               15
evaluation/Average Returns        -32.503
time/data storing (s)               0.00282501
time/evaluation sampling (s)        0.328475
time/exploration sampling (s)       0.138921
time/logging (s)                    0.00486632
time/saving (s)                     0.00196137
time/training (s)                   1.96194
time/epoch (s)                      2.43899
time/total (s)                    234.206
Epoch                              95
-----------------------------  ---------------
2019-04-22 22:40:30.887278 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 96 finished
-----------------------------  ----------------
replay_buffer/size              48700
trainer/QF1 Loss                    0.296466
trainer/QF2 Loss                    0.375677
trainer/Policy Loss                21.0352
trainer/Q1 Predictions Mean       -19.3663
trainer/Q1 Predictions Std         14.6132
trainer/Q1 Predictions Max         -8.6145
trainer/Q1 Predictions Min        -58.2082
trainer/Q2 Predictions Mean       -19.3616
trainer/Q2 Predictions Std         14.6172
trainer/Q2 Predictions Max         -8.61417
trainer/Q2 Predictions Min        -58.2409
trainer/Q Targets Mean            -19.5321
trainer/Q Targets Std              14.9804
trainer/Q Targets Max              -8.42708
trainer/Q Targets Min             -59.1409
trainer/Log Pis Mean                2.28182
trainer/Log Pis Std                 1.32099
trainer/Log Pis Max                 7.36085
trainer/Log Pis Min                -0.989354
trainer/Policy mu Mean              0.0743765
trainer/Policy mu Std               0.847697
trainer/Policy mu Max               3.52755
trainer/Policy mu Min              -3.01874
trainer/Policy log std Mean        -1.97603
trainer/Policy log std Std          0.533787
trainer/Policy log std Max         -0.265261
trainer/Policy log std Min         -2.50726
trainer/Alpha                       0.0527206
trainer/Alpha Loss                  0.829313
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.439531
exploration/Rewards Std             1.25642
exploration/Rewards Max            -0.00815583
exploration/Rewards Min           -11.1888
exploration/Returns Mean          -43.9531
exploration/Returns Std            19.3817
exploration/Returns Max           -18.8343
exploration/Returns Min           -71.6999
exploration/Actions Mean            0.0342727
exploration/Actions Std             0.249326
exploration/Actions Max             0.999037
exploration/Actions Min            -0.990479
exploration/Num Paths               5
exploration/Average Returns       -43.9531
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.371995
evaluation/Rewards Std              1.16644
evaluation/Rewards Max             -0.0409733
evaluation/Rewards Min            -10.1135
evaluation/Returns Mean           -37.1995
evaluation/Returns Std             17.5471
evaluation/Returns Max            -12.1216
evaluation/Returns Min            -69.482
evaluation/Actions Mean            -0.000531008
evaluation/Actions Std              0.208592
evaluation/Actions Max              0.99956
evaluation/Actions Min             -0.999533
evaluation/Num Paths               15
evaluation/Average Returns        -37.1995
time/data storing (s)               0.00299354
time/evaluation sampling (s)        0.325354
time/exploration sampling (s)       0.141932
time/logging (s)                    0.00484956
time/saving (s)                     0.0019602
time/training (s)                   1.95163
time/epoch (s)                      2.42872
time/total (s)                    236.639
Epoch                              96
-----------------------------  ----------------
2019-04-22 22:40:33.309606 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                    0.212736
trainer/QF2 Loss                    0.331548
trainer/Policy Loss                22.3366
trainer/Q1 Predictions Mean       -20.9129
trainer/Q1 Predictions Std         15.9351
trainer/Q1 Predictions Max         -8.47874
trainer/Q1 Predictions Min        -76.1044
trainer/Q2 Predictions Mean       -20.896
trainer/Q2 Predictions Std         15.9014
trainer/Q2 Predictions Max         -8.46991
trainer/Q2 Predictions Min        -74.5299
trainer/Q Targets Mean            -21.0665
trainer/Q Targets Std              15.9975
trainer/Q Targets Max              -8.3296
trainer/Q Targets Min             -77.3995
trainer/Log Pis Mean                2.01694
trainer/Log Pis Std                 1.48798
trainer/Log Pis Max                 9.93581
trainer/Log Pis Min                -1.42485
trainer/Policy mu Mean             -0.0303481
trainer/Policy mu Std               0.891976
trainer/Policy mu Max               3.29843
trainer/Policy mu Min              -4.08956
trainer/Policy log std Mean        -1.97457
trainer/Policy log std Std          0.505399
trainer/Policy log std Max         -0.0486941
trainer/Policy log std Min         -2.54633
trainer/Alpha                       0.0520375
trainer/Alpha Loss                  0.0500649
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.770431
exploration/Rewards Std             1.04181
exploration/Rewards Max            -0.0105841
exploration/Rewards Min            -9.27378
exploration/Returns Mean          -77.0431
exploration/Returns Std            34.968
exploration/Returns Max           -10.494
exploration/Returns Min          -106.46
exploration/Actions Mean           -0.0425586
exploration/Actions Std             0.246488
exploration/Actions Max             0.523103
exploration/Actions Min            -0.999983
exploration/Num Paths               5
exploration/Average Returns       -77.0431
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.259071
evaluation/Rewards Std              0.965253
evaluation/Rewards Max             -0.0142318
evaluation/Rewards Min             -9.33374
evaluation/Returns Mean           -25.9071
evaluation/Returns Std             26.4237
evaluation/Returns Max             -3.03682
evaluation/Returns Min           -108.536
evaluation/Actions Mean             0.00509667
evaluation/Actions Std              0.181373
evaluation/Actions Max              0.998374
evaluation/Actions Min             -0.999547
evaluation/Num Paths               15
evaluation/Average Returns        -25.9071
time/data storing (s)               0.00305007
time/evaluation sampling (s)        0.323628
time/exploration sampling (s)       0.140641
time/logging (s)                    0.00491586
time/saving (s)                     0.00158671
time/training (s)                   1.94233
time/epoch (s)                      2.41615
time/total (s)                    239.059
Epoch                              97
-----------------------------  ---------------
2019-04-22 22:40:35.754600 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                   26.9695
trainer/QF2 Loss                   26.2277
trainer/Policy Loss                20.8022
trainer/Q1 Predictions Mean       -18.9852
trainer/Q1 Predictions Std         14.6407
trainer/Q1 Predictions Max         -8.09689
trainer/Q1 Predictions Min        -60.1451
trainer/Q2 Predictions Mean       -18.9701
trainer/Q2 Predictions Std         14.6195
trainer/Q2 Predictions Max         -8.09396
trainer/Q2 Predictions Min        -59.4082
trainer/Q Targets Mean            -18.7446
trainer/Q Targets Std              14.6808
trainer/Q Targets Max              -0.111979
trainer/Q Targets Min             -48.1002
trainer/Log Pis Mean                1.99271
trainer/Log Pis Std                 1.10366
trainer/Log Pis Max                 5.19047
trainer/Log Pis Min                -0.867789
trainer/Policy mu Mean              0.0170078
trainer/Policy mu Std               0.605141
trainer/Policy mu Max               3.5781
trainer/Policy mu Min              -3.07046
trainer/Policy log std Mean        -2.14542
trainer/Policy log std Std          0.396026
trainer/Policy log std Max         -0.519732
trainer/Policy log std Min         -2.53547
trainer/Alpha                       0.051703
trainer/Alpha Loss                 -0.021585
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.450696
exploration/Rewards Std             1.28567
exploration/Rewards Max            -0.0058416
exploration/Rewards Min            -8.83143
exploration/Returns Mean          -45.0696
exploration/Returns Std             9.69396
exploration/Returns Max           -29.1296
exploration/Returns Min           -56.676
exploration/Actions Mean            0.00920954
exploration/Actions Std             0.249934
exploration/Actions Max             0.998983
exploration/Actions Min            -0.9998
exploration/Num Paths               5
exploration/Average Returns       -45.0696
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.344839
evaluation/Rewards Std              1.03971
evaluation/Rewards Max             -0.011376
evaluation/Rewards Min            -11.0528
evaluation/Returns Mean           -34.4839
evaluation/Returns Std             27.8768
evaluation/Returns Max             -5.27071
evaluation/Returns Min           -100.906
evaluation/Actions Mean             0.00135073
evaluation/Actions Std              0.191998
evaluation/Actions Max              0.998118
evaluation/Actions Min             -0.999438
evaluation/Num Paths               15
evaluation/Average Returns        -34.4839
time/data storing (s)               0.00291997
time/evaluation sampling (s)        0.325216
time/exploration sampling (s)       0.140961
time/logging (s)                    0.00485658
time/saving (s)                     0.0019457
time/training (s)                   1.96284
time/epoch (s)                      2.43874
time/total (s)                    241.502
Epoch                              98
-----------------------------  ---------------
2019-04-22 22:40:38.185777 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                   19.0126
trainer/QF2 Loss                   19.0063
trainer/Policy Loss                20.8632
trainer/Q1 Predictions Mean       -18.9858
trainer/Q1 Predictions Std         14.003
trainer/Q1 Predictions Max         -8.29266
trainer/Q1 Predictions Min        -48.8677
trainer/Q2 Predictions Mean       -19.0112
trainer/Q2 Predictions Std         14.0285
trainer/Q2 Predictions Max         -8.28367
trainer/Q2 Predictions Min        -49.033
trainer/Q Targets Mean            -18.6889
trainer/Q Targets Std              13.9362
trainer/Q Targets Max              -2.10637
trainer/Q Targets Min             -49.9019
trainer/Log Pis Mean                2.34233
trainer/Log Pis Std                 1.21401
trainer/Log Pis Max                 7.8077
trainer/Log Pis Min                -0.385815
trainer/Policy mu Mean             -0.059446
trainer/Policy mu Std               0.870785
trainer/Policy mu Max               3.09276
trainer/Policy mu Min              -3.67346
trainer/Policy log std Mean        -1.94832
trainer/Policy log std Std          0.525848
trainer/Policy log std Max         -0.131876
trainer/Policy log std Min         -2.46469
trainer/Alpha                       0.0541851
trainer/Alpha Loss                  0.998015
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.471494
exploration/Rewards Std             0.766442
exploration/Rewards Max            -0.0135592
exploration/Rewards Min            -7.31844
exploration/Returns Mean          -47.1494
exploration/Returns Std            19.4555
exploration/Returns Max           -19.531
exploration/Returns Min           -73.9471
exploration/Actions Mean           -0.00306264
exploration/Actions Std             0.227243
exploration/Actions Max             0.998991
exploration/Actions Min            -0.99663
exploration/Num Paths               5
exploration/Average Returns       -47.1494
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.300421
evaluation/Rewards Std              1.10987
evaluation/Rewards Max             -0.00330909
evaluation/Rewards Min            -10.5333
evaluation/Returns Mean           -30.0421
evaluation/Returns Std             20.4026
evaluation/Returns Max             -4.11765
evaluation/Returns Min            -61.7503
evaluation/Actions Mean             0.0237849
evaluation/Actions Std              0.192135
evaluation/Actions Max              0.998796
evaluation/Actions Min             -0.996669
evaluation/Num Paths               15
evaluation/Average Returns        -30.0421
time/data storing (s)               0.00289054
time/evaluation sampling (s)        0.327099
time/exploration sampling (s)       0.139885
time/logging (s)                    0.00485871
time/saving (s)                     0.00195733
time/training (s)                   1.94826
time/epoch (s)                      2.42495
time/total (s)                    243.932
Epoch                              99
-----------------------------  ---------------
2019-04-22 22:40:40.645463 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              50700
trainer/QF1 Loss                    4.47908
trainer/QF2 Loss                    4.45052
trainer/Policy Loss                18.6744
trainer/Q1 Predictions Mean       -17.3659
trainer/Q1 Predictions Std         13.0181
trainer/Q1 Predictions Max         -8.12674
trainer/Q1 Predictions Min        -66.0345
trainer/Q2 Predictions Mean       -17.3686
trainer/Q2 Predictions Std         13.0329
trainer/Q2 Predictions Max         -8.12282
trainer/Q2 Predictions Min        -66.1399
trainer/Q Targets Mean            -17.1619
trainer/Q Targets Std              13.1598
trainer/Q Targets Max              -0.25292
trainer/Q Targets Min             -65.9158
trainer/Log Pis Mean                1.89727
trainer/Log Pis Std                 1.41252
trainer/Log Pis Max                 6.64024
trainer/Log Pis Min                -3.60198
trainer/Policy mu Mean             -0.0376205
trainer/Policy mu Std               0.717007
trainer/Policy mu Max               2.70696
trainer/Policy mu Min              -3.27746
trainer/Policy log std Mean        -2.00961
trainer/Policy log std Std          0.454014
trainer/Policy log std Max         -0.335052
trainer/Policy log std Min         -2.41134
trainer/Alpha                       0.0533886
trainer/Alpha Loss                 -0.301023
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.253371
exploration/Rewards Std             0.678743
exploration/Rewards Max            -0.00861145
exploration/Rewards Min            -6.81439
exploration/Returns Mean          -25.3371
exploration/Returns Std             7.61527
exploration/Returns Max           -15.2316
exploration/Returns Min           -35.0796
exploration/Actions Mean            0.0154721
exploration/Actions Std             0.218927
exploration/Actions Max             0.998994
exploration/Actions Min            -0.992487
exploration/Num Paths               5
exploration/Average Returns       -25.3371
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.337586
evaluation/Rewards Std              0.993825
evaluation/Rewards Max             -0.00757297
evaluation/Rewards Min            -10.6257
evaluation/Returns Mean           -33.7586
evaluation/Returns Std             29.0681
evaluation/Returns Max             -1.88912
evaluation/Returns Min            -92.207
evaluation/Actions Mean            -0.0108884
evaluation/Actions Std              0.19178
evaluation/Actions Max              0.99611
evaluation/Actions Min             -0.999762
evaluation/Num Paths               15
evaluation/Average Returns        -33.7586
time/data storing (s)               0.00305356
time/evaluation sampling (s)        0.329461
time/exploration sampling (s)       0.142163
time/logging (s)                    0.00497242
time/saving (s)                     0.00193897
time/training (s)                   1.97193
time/epoch (s)                      2.45352
time/total (s)                    246.389
Epoch                             100
-----------------------------  ---------------
2019-04-22 22:40:43.077144 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              51200
trainer/QF1 Loss                    3.27381
trainer/QF2 Loss                    3.26994
trainer/Policy Loss                20.871
trainer/Q1 Predictions Mean       -19.4969
trainer/Q1 Predictions Std         15.2465
trainer/Q1 Predictions Max         -8.20904
trainer/Q1 Predictions Min        -61.1194
trainer/Q2 Predictions Mean       -19.4892
trainer/Q2 Predictions Std         15.2477
trainer/Q2 Predictions Max         -8.19425
trainer/Q2 Predictions Min        -61.1711
trainer/Q Targets Mean            -19.266
trainer/Q Targets Std              15.1696
trainer/Q Targets Max              -0.872656
trainer/Q Targets Min             -58.6131
trainer/Log Pis Mean                1.9212
trainer/Log Pis Std                 1.21995
trainer/Log Pis Max                 6.326
trainer/Log Pis Min                -1.61275
trainer/Policy mu Mean              0.00494102
trainer/Policy mu Std               0.709729
trainer/Policy mu Max               3.43406
trainer/Policy mu Min              -3.00829
trainer/Policy log std Mean        -2.01729
trainer/Policy log std Std          0.469105
trainer/Policy log std Max         -0.509188
trainer/Policy log std Min         -2.42857
trainer/Alpha                       0.0540447
trainer/Alpha Loss                 -0.229924
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.38615
exploration/Rewards Std             1.02795
exploration/Rewards Max            -0.00272598
exploration/Rewards Min            -9.41153
exploration/Returns Mean          -38.615
exploration/Returns Std            13.055
exploration/Returns Max           -23.3883
exploration/Returns Min           -60.8174
exploration/Actions Mean            0.0069203
exploration/Actions Std             0.248246
exploration/Actions Max             0.999092
exploration/Actions Min            -0.999462
exploration/Num Paths               5
exploration/Average Returns       -38.615
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.366714
evaluation/Rewards Std              1.04559
evaluation/Rewards Max             -0.0172273
evaluation/Rewards Min            -10.6203
evaluation/Returns Mean           -36.6714
evaluation/Returns Std             22.6308
evaluation/Returns Max             -9.27281
evaluation/Returns Min            -75.5573
evaluation/Actions Mean            -0.0095374
evaluation/Actions Std              0.196765
evaluation/Actions Max              0.997864
evaluation/Actions Min             -0.999638
evaluation/Num Paths               15
evaluation/Average Returns        -36.6714
time/data storing (s)               0.00297322
time/evaluation sampling (s)        0.328987
time/exploration sampling (s)       0.143656
time/logging (s)                    0.00489976
time/saving (s)                     0.0100162
time/training (s)                   1.93471
time/epoch (s)                      2.42524
time/total (s)                    248.819
Epoch                             101
-----------------------------  ---------------
2019-04-22 22:40:45.520565 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              51700
trainer/QF1 Loss                    0.296771
trainer/QF2 Loss                    0.261052
trainer/Policy Loss                19.5556
trainer/Q1 Predictions Mean       -17.9605
trainer/Q1 Predictions Std         13.8534
trainer/Q1 Predictions Max         -8.247
trainer/Q1 Predictions Min        -47.1378
trainer/Q2 Predictions Mean       -17.962
trainer/Q2 Predictions Std         13.8665
trainer/Q2 Predictions Max         -8.27524
trainer/Q2 Predictions Min        -47.1113
trainer/Q Targets Mean            -18.2359
trainer/Q Targets Std              14.1572
trainer/Q Targets Max              -8.02142
trainer/Q Targets Min             -47.7829
trainer/Log Pis Mean                2.20728
trainer/Log Pis Std                 1.4669
trainer/Log Pis Max                 8.81255
trainer/Log Pis Min                -1.29869
trainer/Policy mu Mean              0.0363501
trainer/Policy mu Std               0.895957
trainer/Policy mu Max               2.96845
trainer/Policy mu Min              -3.01371
trainer/Policy log std Mean        -1.96196
trainer/Policy log std Std          0.528768
trainer/Policy log std Max         -0.497329
trainer/Policy log std Min         -2.41411
trainer/Alpha                       0.0540908
trainer/Alpha Loss                  0.604675
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.466059
exploration/Rewards Std             0.740663
exploration/Rewards Max            -0.0178225
exploration/Rewards Min            -7.95879
exploration/Returns Mean          -46.6059
exploration/Returns Std            33.8823
exploration/Returns Max           -15.9265
exploration/Returns Min           -91.6244
exploration/Actions Mean           -0.01833
exploration/Actions Std             0.215706
exploration/Actions Max             0.994891
exploration/Actions Min            -0.999413
exploration/Num Paths               5
exploration/Average Returns       -46.6059
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.351673
evaluation/Rewards Std              1.19475
evaluation/Rewards Max             -0.0217385
evaluation/Rewards Min            -11.3943
evaluation/Returns Mean           -35.1673
evaluation/Returns Std             15.9309
evaluation/Returns Max            -12.6326
evaluation/Returns Min            -65.6026
evaluation/Actions Mean             0.0110969
evaluation/Actions Std              0.215185
evaluation/Actions Max              0.999214
evaluation/Actions Min             -0.999467
evaluation/Num Paths               15
evaluation/Average Returns        -35.1673
time/data storing (s)               0.00305389
time/evaluation sampling (s)        0.323063
time/exploration sampling (s)       0.14282
time/logging (s)                    0.00484958
time/saving (s)                     0.00193055
time/training (s)                   1.9611
time/epoch (s)                      2.43682
time/total (s)                    251.26
Epoch                             102
-----------------------------  ---------------
2019-04-22 22:40:48.037013 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                    0.44936
trainer/QF2 Loss                    0.383104
trainer/Policy Loss                18.9579
trainer/Q1 Predictions Mean       -17.2128
trainer/Q1 Predictions Std         13.3246
trainer/Q1 Predictions Max         -8.17533
trainer/Q1 Predictions Min        -53.4862
trainer/Q2 Predictions Mean       -17.2551
trainer/Q2 Predictions Std         13.3615
trainer/Q2 Predictions Max         -8.15853
trainer/Q2 Predictions Min        -53.5743
trainer/Q Targets Mean            -17.5971
trainer/Q Targets Std              13.7469
trainer/Q Targets Max              -8.02321
trainer/Q Targets Min             -53.35
trainer/Log Pis Mean                2.24555
trainer/Log Pis Std                 1.46201
trainer/Log Pis Max                 9.10473
trainer/Log Pis Min                -2.31729
trainer/Policy mu Mean             -0.0195827
trainer/Policy mu Std               0.774846
trainer/Policy mu Max               3.03221
trainer/Policy mu Min              -2.89991
trainer/Policy log std Mean        -2.00663
trainer/Policy log std Std          0.511455
trainer/Policy log std Max         -0.490376
trainer/Policy log std Min         -2.4961
trainer/Alpha                       0.0540765
trainer/Alpha Loss                  0.716322
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.383471
exploration/Rewards Std             0.780181
exploration/Rewards Max            -0.00237059
exploration/Rewards Min            -6.56014
exploration/Returns Mean          -38.3471
exploration/Returns Std            23.7118
exploration/Returns Max           -20.6095
exploration/Returns Min           -84.7098
exploration/Actions Mean            0.00278858
exploration/Actions Std             0.2359
exploration/Actions Max             0.999101
exploration/Actions Min            -0.999786
exploration/Num Paths               5
exploration/Average Returns       -38.3471
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.370289
evaluation/Rewards Std              0.871138
evaluation/Rewards Max             -0.011582
evaluation/Rewards Min             -9.06523
evaluation/Returns Mean           -37.0289
evaluation/Returns Std             24.7628
evaluation/Returns Max             -1.89067
evaluation/Returns Min            -76.1968
evaluation/Actions Mean             0.00284899
evaluation/Actions Std              0.186446
evaluation/Actions Max              0.998539
evaluation/Actions Min             -0.998763
evaluation/Num Paths               15
evaluation/Average Returns        -37.0289
time/data storing (s)               0.00275255
time/evaluation sampling (s)        0.32934
time/exploration sampling (s)       0.143296
time/logging (s)                    0.00491159
time/saving (s)                     0.00196282
time/training (s)                   2.028
time/epoch (s)                      2.51026
time/total (s)                    253.775
Epoch                             103
-----------------------------  ---------------
2019-04-22 22:40:50.474456 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              52700
trainer/QF1 Loss                    0.0771427
trainer/QF2 Loss                    0.0613362
trainer/Policy Loss                19.1618
trainer/Q1 Predictions Mean       -17.6322
trainer/Q1 Predictions Std         13.4753
trainer/Q1 Predictions Max         -7.86185
trainer/Q1 Predictions Min        -48.9851
trainer/Q2 Predictions Mean       -17.6488
trainer/Q2 Predictions Std         13.488
trainer/Q2 Predictions Max         -7.84574
trainer/Q2 Predictions Min        -49.7619
trainer/Q Targets Mean            -17.7905
trainer/Q Targets Std              13.552
trainer/Q Targets Max              -7.8749
trainer/Q Targets Min             -49.6076
trainer/Log Pis Mean                1.81088
trainer/Log Pis Std                 1.13496
trainer/Log Pis Max                 5.15941
trainer/Log Pis Min                -3.42367
trainer/Policy mu Mean              0.00292582
trainer/Policy mu Std               0.610394
trainer/Policy mu Max               2.84692
trainer/Policy mu Min              -2.46095
trainer/Policy log std Mean        -2.00373
trainer/Policy log std Std          0.411731
trainer/Policy log std Max         -0.463917
trainer/Policy log std Min         -2.41451
trainer/Alpha                       0.0537164
trainer/Alpha Loss                 -0.552983
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.431756
exploration/Rewards Std             0.918381
exploration/Rewards Max            -0.00682883
exploration/Rewards Min            -9.19692
exploration/Returns Mean          -43.1756
exploration/Returns Std            20.2759
exploration/Returns Max           -18.0481
exploration/Returns Min           -70.933
exploration/Actions Mean            0.00531068
exploration/Actions Std             0.249949
exploration/Actions Max             0.999656
exploration/Actions Min            -0.996114
exploration/Num Paths               5
exploration/Average Returns       -43.1756
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.345664
evaluation/Rewards Std              1.14304
evaluation/Rewards Max             -0.0151931
evaluation/Rewards Min            -10.1016
evaluation/Returns Mean           -34.5664
evaluation/Returns Std             20.8955
evaluation/Returns Max             -5.61557
evaluation/Returns Min            -97.9626
evaluation/Actions Mean             0.00534251
evaluation/Actions Std              0.20992
evaluation/Actions Max              0.998813
evaluation/Actions Min             -0.999147
evaluation/Num Paths               15
evaluation/Average Returns        -34.5664
time/data storing (s)               0.00288655
time/evaluation sampling (s)        0.329177
time/exploration sampling (s)       0.140684
time/logging (s)                    0.00488699
time/saving (s)                     0.00194788
time/training (s)                   1.95124
time/epoch (s)                      2.43082
time/total (s)                    256.21
Epoch                             104
-----------------------------  ---------------
2019-04-22 22:40:52.917490 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                    1.71318
trainer/QF2 Loss                    1.68991
trainer/Policy Loss                18.2371
trainer/Q1 Predictions Mean       -16.8749
trainer/Q1 Predictions Std         13.0611
trainer/Q1 Predictions Max         -8.08544
trainer/Q1 Predictions Min        -51.9583
trainer/Q2 Predictions Mean       -16.8927
trainer/Q2 Predictions Std         13.101
trainer/Q2 Predictions Max         -8.04507
trainer/Q2 Predictions Min        -52.235
trainer/Q Targets Mean            -16.8287
trainer/Q Targets Std              13.3567
trainer/Q Targets Max              -0.0745188
trainer/Q Targets Min             -52.2349
trainer/Log Pis Mean                1.61274
trainer/Log Pis Std                 1.55931
trainer/Log Pis Max                 8.41852
trainer/Log Pis Min                -4.16279
trainer/Policy mu Mean             -0.0382546
trainer/Policy mu Std               0.667365
trainer/Policy mu Max               3.10449
trainer/Policy mu Min              -2.73125
trainer/Policy log std Mean        -2.01498
trainer/Policy log std Std          0.444927
trainer/Policy log std Max         -0.274027
trainer/Policy log std Min         -2.44749
trainer/Alpha                       0.0524837
trainer/Alpha Loss                 -1.14125
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.416356
exploration/Rewards Std             1.13987
exploration/Rewards Max            -0.00957482
exploration/Rewards Min            -9.22179
exploration/Returns Mean          -41.6356
exploration/Returns Std            12.776
exploration/Returns Max           -26.8629
exploration/Returns Min           -58.6491
exploration/Actions Mean           -0.00916227
exploration/Actions Std             0.259293
exploration/Actions Max             0.999036
exploration/Actions Min            -0.999677
exploration/Num Paths               5
exploration/Average Returns       -41.6356
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.451069
evaluation/Rewards Std              1.18787
evaluation/Rewards Max             -0.0309599
evaluation/Rewards Min            -10.0044
evaluation/Returns Mean           -45.1069
evaluation/Returns Std             34.9951
evaluation/Returns Max             -5.8125
evaluation/Returns Min           -115.64
evaluation/Actions Mean            -0.00783986
evaluation/Actions Std              0.209559
evaluation/Actions Max              0.998066
evaluation/Actions Min             -0.999639
evaluation/Num Paths               15
evaluation/Average Returns        -45.1069
time/data storing (s)               0.00281494
time/evaluation sampling (s)        0.328295
time/exploration sampling (s)       0.136664
time/logging (s)                    0.00487312
time/saving (s)                     0.00196722
time/training (s)                   1.96173
time/epoch (s)                      2.43635
time/total (s)                    258.651
Epoch                             105
-----------------------------  ---------------
2019-04-22 22:40:55.361882 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 106 finished
-----------------------------  ----------------
replay_buffer/size              53700
trainer/QF1 Loss                    1.12833
trainer/QF2 Loss                    1.10996
trainer/Policy Loss                21.3856
trainer/Q1 Predictions Mean       -19.9167
trainer/Q1 Predictions Std         15.5177
trainer/Q1 Predictions Max         -7.85727
trainer/Q1 Predictions Min        -69.2585
trainer/Q2 Predictions Mean       -19.8785
trainer/Q2 Predictions Std         15.4274
trainer/Q2 Predictions Max         -7.87957
trainer/Q2 Predictions Min        -68.4972
trainer/Q Targets Mean            -19.9806
trainer/Q Targets Std              15.6811
trainer/Q Targets Max              -0.137697
trainer/Q Targets Min             -68.4769
trainer/Log Pis Mean                2.24349
trainer/Log Pis Std                 1.52682
trainer/Log Pis Max                 7.46432
trainer/Log Pis Min                -2.9997
trainer/Policy mu Mean              0.0886789
trainer/Policy mu Std               0.904714
trainer/Policy mu Max               3.3543
trainer/Policy mu Min              -3.13524
trainer/Policy log std Mean        -1.95978
trainer/Policy log std Std          0.530087
trainer/Policy log std Max         -0.406271
trainer/Policy log std Min         -2.48092
trainer/Alpha                       0.0528917
trainer/Alpha Loss                  0.715762
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.562521
exploration/Rewards Std             1.19235
exploration/Rewards Max            -0.00588631
exploration/Rewards Min            -9.87469
exploration/Returns Mean          -56.2521
exploration/Returns Std            38.9769
exploration/Returns Max           -13.6544
exploration/Returns Min          -108.6
exploration/Actions Mean           -0.0205673
exploration/Actions Std             0.239227
exploration/Actions Max             0.999263
exploration/Actions Min            -0.999911
exploration/Num Paths               5
exploration/Average Returns       -56.2521
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.3577
evaluation/Rewards Std              1.04179
evaluation/Rewards Max             -0.011765
evaluation/Rewards Min             -9.17824
evaluation/Returns Mean           -35.77
evaluation/Returns Std             25.3252
evaluation/Returns Max             -3.32201
evaluation/Returns Min            -94.1976
evaluation/Actions Mean            -0.000584005
evaluation/Actions Std              0.18906
evaluation/Actions Max              0.998956
evaluation/Actions Min             -0.999628
evaluation/Num Paths               15
evaluation/Average Returns        -35.77
time/data storing (s)               0.00301988
time/evaluation sampling (s)        0.322211
time/exploration sampling (s)       0.140313
time/logging (s)                    0.00487526
time/saving (s)                     0.00193381
time/training (s)                   1.96548
time/epoch (s)                      2.43783
time/total (s)                    261.093
Epoch                             106
-----------------------------  ----------------
2019-04-22 22:40:57.807493 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              54200
trainer/QF1 Loss                    0.127621
trainer/QF2 Loss                    0.127072
trainer/Policy Loss                19.5422
trainer/Q1 Predictions Mean       -17.7108
trainer/Q1 Predictions Std         13.4978
trainer/Q1 Predictions Max         -7.63688
trainer/Q1 Predictions Min        -48.9585
trainer/Q2 Predictions Mean       -17.7006
trainer/Q2 Predictions Std         13.5051
trainer/Q2 Predictions Max         -7.66155
trainer/Q2 Predictions Min        -48.9047
trainer/Q Targets Mean            -17.8058
trainer/Q Targets Std              13.4306
trainer/Q Targets Max              -7.8055
trainer/Q Targets Min             -49.783
trainer/Log Pis Mean                2.2747
trainer/Log Pis Std                 1.36582
trainer/Log Pis Max                 6.47719
trainer/Log Pis Min                -2.60652
trainer/Policy mu Mean             -0.06995
trainer/Policy mu Std               0.939688
trainer/Policy mu Max               3.11174
trainer/Policy mu Min              -3.06116
trainer/Policy log std Mean        -1.98508
trainer/Policy log std Std          0.581793
trainer/Policy log std Max         -0.304757
trainer/Policy log std Min         -2.48328
trainer/Alpha                       0.055066
trainer/Alpha Loss                  0.796453
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.350093
exploration/Rewards Std             0.708452
exploration/Rewards Max            -0.00808319
exploration/Rewards Min            -7.34858
exploration/Returns Mean          -35.0093
exploration/Returns Std            29.1607
exploration/Returns Max           -16.6416
exploration/Returns Min           -92.9269
exploration/Actions Mean            0.0122059
exploration/Actions Std             0.203103
exploration/Actions Max             0.998248
exploration/Actions Min            -0.999542
exploration/Num Paths               5
exploration/Average Returns       -35.0093
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.182873
evaluation/Rewards Std              0.773908
evaluation/Rewards Max             -0.0179666
evaluation/Rewards Min             -9.85942
evaluation/Returns Mean           -18.2873
evaluation/Returns Std             14.0391
evaluation/Returns Max             -4.8769
evaluation/Returns Min            -51.141
evaluation/Actions Mean             0.00686458
evaluation/Actions Std              0.171038
evaluation/Actions Max              0.997502
evaluation/Actions Min             -0.998765
evaluation/Num Paths               15
evaluation/Average Returns        -18.2873
time/data storing (s)               0.00291536
time/evaluation sampling (s)        0.325429
time/exploration sampling (s)       0.138898
time/logging (s)                    0.00488194
time/saving (s)                     0.00197243
time/training (s)                   1.96477
time/epoch (s)                      2.43887
time/total (s)                    263.537
Epoch                             107
-----------------------------  ---------------
2019-04-22 22:41:00.263241 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              54700
trainer/QF1 Loss                   20.7256
trainer/QF2 Loss                   20.7685
trainer/Policy Loss                20.3766
trainer/Q1 Predictions Mean       -18.7721
trainer/Q1 Predictions Std         15.5894
trainer/Q1 Predictions Max         -7.67633
trainer/Q1 Predictions Min        -77.5403
trainer/Q2 Predictions Mean       -18.7872
trainer/Q2 Predictions Std         15.5952
trainer/Q2 Predictions Max         -7.69412
trainer/Q2 Predictions Min        -77.5568
trainer/Q Targets Mean            -18.1841
trainer/Q Targets Std              15.7669
trainer/Q Targets Max              -0.310715
trainer/Q Targets Min             -77.8212
trainer/Log Pis Mean                2.08345
trainer/Log Pis Std                 1.41871
trainer/Log Pis Max                 8.17545
trainer/Log Pis Min                -1.34776
trainer/Policy mu Mean             -0.0604371
trainer/Policy mu Std               0.824009
trainer/Policy mu Max               3.43789
trainer/Policy mu Min              -3.93383
trainer/Policy log std Mean        -2.04936
trainer/Policy log std Std          0.516223
trainer/Policy log std Max         -0.0784577
trainer/Policy log std Min         -2.48708
trainer/Alpha                       0.0551966
trainer/Alpha Loss                  0.241745
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.271124
exploration/Rewards Std             0.73988
exploration/Rewards Max            -0.00228735
exploration/Rewards Min            -7.52933
exploration/Returns Mean          -27.1124
exploration/Returns Std            10.9016
exploration/Returns Max           -12.0007
exploration/Returns Min           -41.6955
exploration/Actions Mean           -0.00237013
exploration/Actions Std             0.228773
exploration/Actions Max             0.997144
exploration/Actions Min            -0.999513
exploration/Num Paths               5
exploration/Average Returns       -27.1124
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.281708
evaluation/Rewards Std              0.982728
evaluation/Rewards Max             -0.00234062
evaluation/Rewards Min             -9.20479
evaluation/Returns Mean           -28.1708
evaluation/Returns Std             16.6371
evaluation/Returns Max             -2.4995
evaluation/Returns Min            -64.7855
evaluation/Actions Mean            -0.00618943
evaluation/Actions Std              0.193444
evaluation/Actions Max              0.998931
evaluation/Actions Min             -0.99958
evaluation/Num Paths               15
evaluation/Average Returns        -28.1708
time/data storing (s)               0.00295416
time/evaluation sampling (s)        0.325044
time/exploration sampling (s)       0.143784
time/logging (s)                    0.00492217
time/saving (s)                     0.00198028
time/training (s)                   1.97052
time/epoch (s)                      2.4492
time/total (s)                    265.991
Epoch                             108
-----------------------------  ---------------
2019-04-22 22:41:02.711109 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                    0.0912503
trainer/QF2 Loss                    0.0841153
trainer/Policy Loss                18.9021
trainer/Q1 Predictions Mean       -17.3056
trainer/Q1 Predictions Std         13.7664
trainer/Q1 Predictions Max         -7.61859
trainer/Q1 Predictions Min        -60.9732
trainer/Q2 Predictions Mean       -17.3071
trainer/Q2 Predictions Std         13.7625
trainer/Q2 Predictions Max         -7.62708
trainer/Q2 Predictions Min        -60.8149
trainer/Q Targets Mean            -17.4659
trainer/Q Targets Std              13.7673
trainer/Q Targets Max              -7.78946
trainer/Q Targets Min             -60.1062
trainer/Log Pis Mean                1.90839
trainer/Log Pis Std                 1.28854
trainer/Log Pis Max                 5.83548
trainer/Log Pis Min                -1.68075
trainer/Policy mu Mean             -0.00824636
trainer/Policy mu Std               0.715152
trainer/Policy mu Max               3.02397
trainer/Policy mu Min              -3.6948
trainer/Policy log std Mean        -2.02369
trainer/Policy log std Std          0.457747
trainer/Policy log std Max         -0.217904
trainer/Policy log std Min         -2.4272
trainer/Alpha                       0.0550006
trainer/Alpha Loss                 -0.26573
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.47143
exploration/Rewards Std             0.792794
exploration/Rewards Max            -0.00962033
exploration/Rewards Min            -7.51733
exploration/Returns Mean          -47.143
exploration/Returns Std            12.2188
exploration/Returns Max           -30.0565
exploration/Returns Min           -62.0391
exploration/Actions Mean            0.00131633
exploration/Actions Std             0.236833
exploration/Actions Max             0.998255
exploration/Actions Min            -0.999977
exploration/Num Paths               5
exploration/Average Returns       -47.143
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.370789
evaluation/Rewards Std              1.15603
evaluation/Rewards Max             -0.0108586
evaluation/Rewards Min            -10.0488
evaluation/Returns Mean           -37.0789
evaluation/Returns Std             19.051
evaluation/Returns Max             -9.34113
evaluation/Returns Min            -70.49
evaluation/Actions Mean             0.0100825
evaluation/Actions Std              0.208105
evaluation/Actions Max              0.998816
evaluation/Actions Min             -0.998874
evaluation/Num Paths               15
evaluation/Average Returns        -37.0789
time/data storing (s)               0.00296761
time/evaluation sampling (s)        0.331478
time/exploration sampling (s)       0.140993
time/logging (s)                    0.00476642
time/saving (s)                     0.00191922
time/training (s)                   1.95907
time/epoch (s)                      2.44119
time/total (s)                    268.436
Epoch                             109
-----------------------------  ---------------
2019-04-22 22:41:05.148290 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              55700
trainer/QF1 Loss                    0.0588736
trainer/QF2 Loss                    0.0482164
trainer/Policy Loss                19.2595
trainer/Q1 Predictions Mean       -17.7836
trainer/Q1 Predictions Std         13.9378
trainer/Q1 Predictions Max         -7.57034
trainer/Q1 Predictions Min        -70.3326
trainer/Q2 Predictions Mean       -17.8123
trainer/Q2 Predictions Std         13.9497
trainer/Q2 Predictions Max         -7.6052
trainer/Q2 Predictions Min        -70.1327
trainer/Q Targets Mean            -17.8777
trainer/Q Targets Std              13.9277
trainer/Q Targets Max              -7.619
trainer/Q Targets Min             -69.5611
trainer/Log Pis Mean                1.94464
trainer/Log Pis Std                 1.21355
trainer/Log Pis Max                 7.33529
trainer/Log Pis Min                -0.844764
trainer/Policy mu Mean             -0.136584
trainer/Policy mu Std               0.701675
trainer/Policy mu Max               1.76964
trainer/Policy mu Min              -3.46075
trainer/Policy log std Mean        -2.05351
trainer/Policy log std Std          0.455877
trainer/Policy log std Max         -0.227989
trainer/Policy log std Min         -2.50779
trainer/Alpha                       0.0542497
trainer/Alpha Loss                 -0.161329
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.608145
exploration/Rewards Std             1.18386
exploration/Rewards Max            -0.00167169
exploration/Rewards Min           -10.4728
exploration/Returns Mean          -60.8145
exploration/Returns Std            19.5795
exploration/Returns Max           -28.636
exploration/Returns Min           -88.6354
exploration/Actions Mean            0.016997
exploration/Actions Std             0.243485
exploration/Actions Max             0.999194
exploration/Actions Min            -0.998788
exploration/Num Paths               5
exploration/Average Returns       -60.8145
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.3554
evaluation/Rewards Std              0.97526
evaluation/Rewards Max             -0.0200476
evaluation/Rewards Min             -9.96153
evaluation/Returns Mean           -35.54
evaluation/Returns Std             24.696
evaluation/Returns Max             -3.0305
evaluation/Returns Min            -81.5065
evaluation/Actions Mean             0.00776341
evaluation/Actions Std              0.185115
evaluation/Actions Max              0.998927
evaluation/Actions Min             -0.999007
evaluation/Num Paths               15
evaluation/Average Returns        -35.54
time/data storing (s)               0.00298659
time/evaluation sampling (s)        0.323171
time/exploration sampling (s)       0.14155
time/logging (s)                    0.00487288
time/saving (s)                     0.001955
time/training (s)                   1.95622
time/epoch (s)                      2.43076
time/total (s)                    270.872
Epoch                             110
-----------------------------  ---------------
2019-04-22 22:41:07.605924 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                    0.072615
trainer/QF2 Loss                    0.0725855
trainer/Policy Loss                16.2478
trainer/Q1 Predictions Mean       -14.725
trainer/Q1 Predictions Std         11.3151
trainer/Q1 Predictions Max         -7.54962
trainer/Q1 Predictions Min        -51.4968
trainer/Q2 Predictions Mean       -14.7271
trainer/Q2 Predictions Std         11.3224
trainer/Q2 Predictions Max         -7.56755
trainer/Q2 Predictions Min        -51.6487
trainer/Q Targets Mean            -14.7777
trainer/Q Targets Std              11.394
trainer/Q Targets Max              -7.58517
trainer/Q Targets Min             -51.4079
trainer/Log Pis Mean                1.79627
trainer/Log Pis Std                 1.13365
trainer/Log Pis Max                 5.75401
trainer/Log Pis Min                -2.42528
trainer/Policy mu Mean              0.0507593
trainer/Policy mu Std               0.693568
trainer/Policy mu Max               3.22861
trainer/Policy mu Min              -3.14553
trainer/Policy log std Mean        -2.07456
trainer/Policy log std Std          0.410369
trainer/Policy log std Max         -0.449514
trainer/Policy log std Min         -2.45736
trainer/Alpha                       0.0534648
trainer/Alpha Loss                 -0.596669
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.158922
exploration/Rewards Std             0.18956
exploration/Rewards Max            -0.00651148
exploration/Rewards Min            -2.62298
exploration/Returns Mean          -15.8922
exploration/Returns Std             1.47264
exploration/Returns Max           -14.5219
exploration/Returns Min           -18.5695
exploration/Actions Mean            0.00303764
exploration/Actions Std             0.16844
exploration/Actions Max             0.987079
exploration/Actions Min            -0.961196
exploration/Num Paths               5
exploration/Average Returns       -15.8922
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.407709
evaluation/Rewards Std              1.00537
evaluation/Rewards Max             -0.00834826
evaluation/Rewards Min            -11.1953
evaluation/Returns Mean           -40.7709
evaluation/Returns Std             32.6867
evaluation/Returns Max             -4.07305
evaluation/Returns Min           -112.169
evaluation/Actions Mean            -0.0090617
evaluation/Actions Std              0.188849
evaluation/Actions Max              0.998936
evaluation/Actions Min             -0.999803
evaluation/Num Paths               15
evaluation/Average Returns        -40.7709
time/data storing (s)               0.00295286
time/evaluation sampling (s)        0.322051
time/exploration sampling (s)       0.143337
time/logging (s)                    0.00492873
time/saving (s)                     0.00186983
time/training (s)                   1.97591
time/epoch (s)                      2.45105
time/total (s)                    273.327
Epoch                             111
-----------------------------  ---------------
2019-04-22 22:41:10.063096 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              56700
trainer/QF1 Loss                    0.117681
trainer/QF2 Loss                    0.107933
trainer/Policy Loss                19.2231
trainer/Q1 Predictions Mean       -17.4332
trainer/Q1 Predictions Std         13.6683
trainer/Q1 Predictions Max         -7.59096
trainer/Q1 Predictions Min        -50.3469
trainer/Q2 Predictions Mean       -17.4511
trainer/Q2 Predictions Std         13.6897
trainer/Q2 Predictions Max         -7.60443
trainer/Q2 Predictions Min        -50.3118
trainer/Q Targets Mean            -17.574
trainer/Q Targets Std              13.852
trainer/Q Targets Max              -7.57145
trainer/Q Targets Min             -50.5889
trainer/Log Pis Mean                2.12496
trainer/Log Pis Std                 1.45583
trainer/Log Pis Max                 7.69503
trainer/Log Pis Min                -2.41881
trainer/Policy mu Mean              0.0290711
trainer/Policy mu Std               0.79113
trainer/Policy mu Max               3.26681
trainer/Policy mu Min              -3.77642
trainer/Policy log std Mean        -2.07556
trainer/Policy log std Std          0.471028
trainer/Policy log std Max         -0.319049
trainer/Policy log std Min         -2.54438
trainer/Alpha                       0.0540543
trainer/Alpha Loss                  0.364601
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.237201
exploration/Rewards Std             0.549713
exploration/Rewards Max            -0.005475
exploration/Rewards Min            -5.38031
exploration/Returns Mean          -23.7201
exploration/Returns Std             6.04593
exploration/Returns Max           -15.7507
exploration/Returns Min           -29.7836
exploration/Actions Mean           -0.00608761
exploration/Actions Std             0.224016
exploration/Actions Max             0.997871
exploration/Actions Min            -0.999272
exploration/Num Paths               5
exploration/Average Returns       -23.7201
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.365901
evaluation/Rewards Std              0.947707
evaluation/Rewards Max             -0.0106735
evaluation/Rewards Min            -10.0724
evaluation/Returns Mean           -36.5901
evaluation/Returns Std             33.4955
evaluation/Returns Max             -3.87153
evaluation/Returns Min           -113.466
evaluation/Actions Mean            -0.00710668
evaluation/Actions Std              0.181563
evaluation/Actions Max              0.998309
evaluation/Actions Min             -0.999799
evaluation/Num Paths               15
evaluation/Average Returns        -36.5901
time/data storing (s)               0.00290273
time/evaluation sampling (s)        0.322914
time/exploration sampling (s)       0.149248
time/logging (s)                    0.00489118
time/saving (s)                     0.00194992
time/training (s)                   1.96856
time/epoch (s)                      2.45047
time/total (s)                    275.782
Epoch                             112
-----------------------------  ---------------
2019-04-22 22:41:12.516435 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              57200
trainer/QF1 Loss                    2.00682
trainer/QF2 Loss                    2.01139
trainer/Policy Loss                17.8103
trainer/Q1 Predictions Mean       -16.3437
trainer/Q1 Predictions Std         13.1196
trainer/Q1 Predictions Max         -7.29519
trainer/Q1 Predictions Min        -67.2734
trainer/Q2 Predictions Mean       -16.3539
trainer/Q2 Predictions Std         13.1038
trainer/Q2 Predictions Max         -7.32125
trainer/Q2 Predictions Min        -66.7567
trainer/Q Targets Mean            -16.2481
trainer/Q Targets Std              13.2738
trainer/Q Targets Max              -0.345775
trainer/Q Targets Min             -65.0632
trainer/Log Pis Mean                1.92311
trainer/Log Pis Std                 1.73108
trainer/Log Pis Max                 8.79117
trainer/Log Pis Min                -2.15184
trainer/Policy mu Mean              0.0355737
trainer/Policy mu Std               0.802013
trainer/Policy mu Max               3.48352
trainer/Policy mu Min              -3.87147
trainer/Policy log std Mean        -2.03975
trainer/Policy log std Std          0.477101
trainer/Policy log std Max         -0.359561
trainer/Policy log std Min         -2.5237
trainer/Alpha                       0.0531717
trainer/Alpha Loss                 -0.225606
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.349813
exploration/Rewards Std             0.965037
exploration/Rewards Max            -0.00582311
exploration/Rewards Min            -8.63778
exploration/Returns Mean          -34.9813
exploration/Returns Std            11.0551
exploration/Returns Max           -23.5114
exploration/Returns Min           -52.6589
exploration/Actions Mean           -0.00066152
exploration/Actions Std             0.229602
exploration/Actions Max             0.999757
exploration/Actions Min            -0.999818
exploration/Num Paths               5
exploration/Average Returns       -34.9813
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.31637
evaluation/Rewards Std              1.02048
evaluation/Rewards Max             -0.0194544
evaluation/Rewards Min             -9.96429
evaluation/Returns Mean           -31.637
evaluation/Returns Std             25.5244
evaluation/Returns Max             -4.87046
evaluation/Returns Min           -104.123
evaluation/Actions Mean            -0.00509162
evaluation/Actions Std              0.196817
evaluation/Actions Max              0.997325
evaluation/Actions Min             -0.999206
evaluation/Num Paths               15
evaluation/Average Returns        -31.637
time/data storing (s)               0.00299514
time/evaluation sampling (s)        0.324706
time/exploration sampling (s)       0.142816
time/logging (s)                    0.00489921
time/saving (s)                     0.0110103
time/training (s)                   1.96036
time/epoch (s)                      2.44679
time/total (s)                    278.233
Epoch                             113
-----------------------------  ---------------
2019-04-22 22:41:14.970369 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              57700
trainer/QF1 Loss                    1.12666
trainer/QF2 Loss                    1.11449
trainer/Policy Loss                17.5901
trainer/Q1 Predictions Mean       -16.0302
trainer/Q1 Predictions Std         12.8745
trainer/Q1 Predictions Max         -7.41289
trainer/Q1 Predictions Min        -52.289
trainer/Q2 Predictions Mean       -16.0288
trainer/Q2 Predictions Std         12.8785
trainer/Q2 Predictions Max         -7.3918
trainer/Q2 Predictions Min        -52.4397
trainer/Q Targets Mean            -16.0688
trainer/Q Targets Std              13.1188
trainer/Q Targets Max              -0.164324
trainer/Q Targets Min             -53.9656
trainer/Log Pis Mean                2.01219
trainer/Log Pis Std                 1.30855
trainer/Log Pis Max                 7.84671
trainer/Log Pis Min                -2.17901
trainer/Policy mu Mean             -0.0646574
trainer/Policy mu Std               0.710773
trainer/Policy mu Max               3.20578
trainer/Policy mu Min              -2.99785
trainer/Policy log std Mean        -2.04326
trainer/Policy log std Std          0.444426
trainer/Policy log std Max         -0.328218
trainer/Policy log std Min         -2.45817
trainer/Alpha                       0.0517382
trainer/Alpha Loss                  0.0360873
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.581766
exploration/Rewards Std             1.08565
exploration/Rewards Max            -0.0185882
exploration/Rewards Min            -8.7232
exploration/Returns Mean          -58.1766
exploration/Returns Std            25.1458
exploration/Returns Max           -18.8087
exploration/Returns Min           -95.5386
exploration/Actions Mean           -0.0105839
exploration/Actions Std             0.239222
exploration/Actions Max             0.999762
exploration/Actions Min            -0.999882
exploration/Num Paths               5
exploration/Average Returns       -58.1766
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.278457
evaluation/Rewards Std              1.00863
evaluation/Rewards Max             -0.0344011
evaluation/Rewards Min            -10.3463
evaluation/Returns Mean           -27.8457
evaluation/Returns Std             26.8411
evaluation/Returns Max             -3.94115
evaluation/Returns Min           -107.495
evaluation/Actions Mean             0.00204299
evaluation/Actions Std              0.179203
evaluation/Actions Max              0.998015
evaluation/Actions Min             -0.999784
evaluation/Num Paths               15
evaluation/Average Returns        -27.8457
time/data storing (s)               0.00292947
time/evaluation sampling (s)        0.323941
time/exploration sampling (s)       0.142799
time/logging (s)                    0.00465871
time/saving (s)                     0.00194897
time/training (s)                   1.97193
time/epoch (s)                      2.44821
time/total (s)                    280.685
Epoch                             114
-----------------------------  ---------------
2019-04-22 22:41:17.678822 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                    1.63583
trainer/QF2 Loss                    1.66326
trainer/Policy Loss                16.8095
trainer/Q1 Predictions Mean       -15.1533
trainer/Q1 Predictions Std         12.0606
trainer/Q1 Predictions Max         -7.39299
trainer/Q1 Predictions Min        -49.1405
trainer/Q2 Predictions Mean       -15.1463
trainer/Q2 Predictions Std         12.039
trainer/Q2 Predictions Max         -7.37879
trainer/Q2 Predictions Min        -48.8019
trainer/Q Targets Mean            -15.1243
trainer/Q Targets Std              12.3356
trainer/Q Targets Max              -0.176213
trainer/Q Targets Min             -50.3499
trainer/Log Pis Mean                2.00904
trainer/Log Pis Std                 1.31057
trainer/Log Pis Max                 9.83572
trainer/Log Pis Min                -2.3345
trainer/Policy mu Mean              0.0364625
trainer/Policy mu Std               0.717535
trainer/Policy mu Max               3.10241
trainer/Policy mu Min              -3.09917
trainer/Policy log std Mean        -2.06293
trainer/Policy log std Std          0.446336
trainer/Policy log std Max         -0.346785
trainer/Policy log std Min         -2.45136
trainer/Alpha                       0.0521853
trainer/Alpha Loss                  0.0266916
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.44377
exploration/Rewards Std             1.30036
exploration/Rewards Max            -0.00396303
exploration/Rewards Min            -9.80724
exploration/Returns Mean          -44.377
exploration/Returns Std            15.0351
exploration/Returns Max           -19.6862
exploration/Returns Min           -60.7863
exploration/Actions Mean           -0.00470445
exploration/Actions Std             0.264999
exploration/Actions Max             0.999428
exploration/Actions Min            -0.9998
exploration/Num Paths               5
exploration/Average Returns       -44.377
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.334999
evaluation/Rewards Std              1.01519
evaluation/Rewards Max             -0.0158969
evaluation/Rewards Min            -11.3556
evaluation/Returns Mean           -33.4999
evaluation/Returns Std             25.0185
evaluation/Returns Max             -5.22399
evaluation/Returns Min            -88.1077
evaluation/Actions Mean             0.0151032
evaluation/Actions Std              0.193105
evaluation/Actions Max              0.999514
evaluation/Actions Min             -0.998996
evaluation/Num Paths               15
evaluation/Average Returns        -33.4999
time/data storing (s)               0.00288735
time/evaluation sampling (s)        0.323194
time/exploration sampling (s)       0.137024
time/logging (s)                    0.00491797
time/saving (s)                     0.00193847
time/training (s)                   2.23332
time/epoch (s)                      2.70328
time/total (s)                    283.392
Epoch                             115
-----------------------------  ---------------
2019-04-22 22:41:20.264842 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              58700
trainer/QF1 Loss                    0.247878
trainer/QF2 Loss                    0.278449
trainer/Policy Loss                18.304
trainer/Q1 Predictions Mean       -16.7539
trainer/Q1 Predictions Std         13.5308
trainer/Q1 Predictions Max         -7.38445
trainer/Q1 Predictions Min        -54.9256
trainer/Q2 Predictions Mean       -16.7356
trainer/Q2 Predictions Std         13.5132
trainer/Q2 Predictions Max         -7.41454
trainer/Q2 Predictions Min        -54.8836
trainer/Q Targets Mean            -17.0641
trainer/Q Targets Std              13.7848
trainer/Q Targets Max              -7.35918
trainer/Q Targets Min             -56.2313
trainer/Log Pis Mean                1.95755
trainer/Log Pis Std                 1.45997
trainer/Log Pis Max                 8.53752
trainer/Log Pis Min                -1.74607
trainer/Policy mu Mean             -0.0314283
trainer/Policy mu Std               0.780625
trainer/Policy mu Max               2.71437
trainer/Policy mu Min              -3.72467
trainer/Policy log std Mean        -2.0431
trainer/Policy log std Std          0.457886
trainer/Policy log std Max         -0.392223
trainer/Policy log std Min         -2.48306
trainer/Alpha                       0.0528208
trainer/Alpha Loss                 -0.124848
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.644282
exploration/Rewards Std             1.34093
exploration/Rewards Max            -0.00331027
exploration/Rewards Min           -11.0729
exploration/Returns Mean          -64.4282
exploration/Returns Std            28.9678
exploration/Returns Max           -27.0327
exploration/Returns Min           -99.2819
exploration/Actions Mean           -0.0052368
exploration/Actions Std             0.272246
exploration/Actions Max             0.999801
exploration/Actions Min            -0.999851
exploration/Num Paths               5
exploration/Average Returns       -64.4282
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282813
evaluation/Rewards Std              0.836803
evaluation/Rewards Max             -0.0586681
evaluation/Rewards Min             -9.45982
evaluation/Returns Mean           -28.2813
evaluation/Returns Std             28.7143
evaluation/Returns Max             -7.43035
evaluation/Returns Min            -95.7229
evaluation/Actions Mean            -0.00197138
evaluation/Actions Std              0.166434
evaluation/Actions Max              0.998344
evaluation/Actions Min             -0.999528
evaluation/Num Paths               15
evaluation/Average Returns        -28.2813
time/data storing (s)               0.00305616
time/evaluation sampling (s)        0.346328
time/exploration sampling (s)       0.157388
time/logging (s)                    0.00492732
time/saving (s)                     0.00195268
time/training (s)                   2.06566
time/epoch (s)                      2.57931
time/total (s)                    285.976
Epoch                             116
-----------------------------  ---------------
2019-04-22 22:41:22.700245 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              59200
trainer/QF1 Loss                    0.107053
trainer/QF2 Loss                    0.114496
trainer/Policy Loss                17.6485
trainer/Q1 Predictions Mean       -16.0028
trainer/Q1 Predictions Std         12.4015
trainer/Q1 Predictions Max         -7.14708
trainer/Q1 Predictions Min        -51.1931
trainer/Q2 Predictions Mean       -16.0044
trainer/Q2 Predictions Std         12.4088
trainer/Q2 Predictions Max         -7.16773
trainer/Q2 Predictions Min        -51.29
trainer/Q Targets Mean            -16.0296
trainer/Q Targets Std              12.3908
trainer/Q Targets Max              -7.36001
trainer/Q Targets Min             -51.1119
trainer/Log Pis Mean                2.09217
trainer/Log Pis Std                 1.48497
trainer/Log Pis Max                 7.64503
trainer/Log Pis Min                -2.7552
trainer/Policy mu Mean             -0.117794
trainer/Policy mu Std               0.777783
trainer/Policy mu Max               2.75218
trainer/Policy mu Min              -3.26274
trainer/Policy log std Mean        -2.03988
trainer/Policy log std Std          0.481312
trainer/Policy log std Max         -0.466676
trainer/Policy log std Min         -2.4679
trainer/Alpha                       0.0536852
trainer/Alpha Loss                  0.269573
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.509279
exploration/Rewards Std             1.28548
exploration/Rewards Max            -0.0121791
exploration/Rewards Min           -10.7075
exploration/Returns Mean          -50.9279
exploration/Returns Std            17.8669
exploration/Returns Max           -16.8779
exploration/Returns Min           -69.1488
exploration/Actions Mean            0.00954878
exploration/Actions Std             0.247021
exploration/Actions Max             0.999649
exploration/Actions Min            -0.998317
exploration/Num Paths               5
exploration/Average Returns       -50.9279
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.316202
evaluation/Rewards Std              0.842892
evaluation/Rewards Max             -0.00324508
evaluation/Rewards Min             -9.19406
evaluation/Returns Mean           -31.6202
evaluation/Returns Std             21.0079
evaluation/Returns Max             -9.142
evaluation/Returns Min            -78.8183
evaluation/Actions Mean            -0.00734586
evaluation/Actions Std              0.180201
evaluation/Actions Max              0.996247
evaluation/Actions Min             -0.998361
evaluation/Num Paths               15
evaluation/Average Returns        -31.6202
time/data storing (s)               0.00286768
time/evaluation sampling (s)        0.329125
time/exploration sampling (s)       0.144694
time/logging (s)                    0.00485064
time/saving (s)                     0.00198118
time/training (s)                   1.94503
time/epoch (s)                      2.42855
time/total (s)                    288.409
Epoch                             117
-----------------------------  ---------------
2019-04-22 22:41:25.148142 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              59700
trainer/QF1 Loss                    0.139292
trainer/QF2 Loss                    0.156617
trainer/Policy Loss                18.2267
trainer/Q1 Predictions Mean       -16.7964
trainer/Q1 Predictions Std         13.0124
trainer/Q1 Predictions Max         -7.173
trainer/Q1 Predictions Min        -50.2717
trainer/Q2 Predictions Mean       -16.7785
trainer/Q2 Predictions Std         12.9828
trainer/Q2 Predictions Max         -7.21444
trainer/Q2 Predictions Min        -49.8268
trainer/Q Targets Mean            -16.7124
trainer/Q Targets Std              12.9913
trainer/Q Targets Max              -7.32375
trainer/Q Targets Min             -52.6763
trainer/Log Pis Mean                1.85472
trainer/Log Pis Std                 1.27716
trainer/Log Pis Max                 6.44803
trainer/Log Pis Min                -2.38602
trainer/Policy mu Mean             -0.0571876
trainer/Policy mu Std               0.673333
trainer/Policy mu Max               3.29046
trainer/Policy mu Min              -3.35868
trainer/Policy log std Mean        -2.01626
trainer/Policy log std Std          0.43351
trainer/Policy log std Max         -0.376825
trainer/Policy log std Min         -2.45389
trainer/Alpha                       0.0524468
trainer/Alpha Loss                 -0.428284
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.487597
exploration/Rewards Std             0.889885
exploration/Rewards Max            -0.0152254
exploration/Rewards Min            -8.08221
exploration/Returns Mean          -48.7597
exploration/Returns Std            18.1235
exploration/Returns Max           -25.2131
exploration/Returns Min           -74.2949
exploration/Actions Mean           -0.0211301
exploration/Actions Std             0.236438
exploration/Actions Max             0.998027
exploration/Actions Min            -0.999783
exploration/Num Paths               5
exploration/Average Returns       -48.7597
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.337161
evaluation/Rewards Std              1.03448
evaluation/Rewards Max             -0.0474416
evaluation/Rewards Min            -10.7124
evaluation/Returns Mean           -33.7161
evaluation/Returns Std             16.6326
evaluation/Returns Max             -9.66658
evaluation/Returns Min            -61.5403
evaluation/Actions Mean             0.0125055
evaluation/Actions Std              0.195247
evaluation/Actions Max              0.99904
evaluation/Actions Min             -0.997079
evaluation/Num Paths               15
evaluation/Average Returns        -33.7161
time/data storing (s)               0.00289803
time/evaluation sampling (s)        0.328132
time/exploration sampling (s)       0.141642
time/logging (s)                    0.00483858
time/saving (s)                     0.00195832
time/training (s)                   1.9617
time/epoch (s)                      2.44117
time/total (s)                    290.855
Epoch                             118
-----------------------------  ---------------
2019-04-22 22:41:27.602538 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 119 finished
-----------------------------  ----------------
replay_buffer/size              60200
trainer/QF1 Loss                    0.957923
trainer/QF2 Loss                    0.970503
trainer/Policy Loss                15.6745
trainer/Q1 Predictions Mean       -14.0111
trainer/Q1 Predictions Std         10.8041
trainer/Q1 Predictions Max         -7.32726
trainer/Q1 Predictions Min        -49.9711
trainer/Q2 Predictions Mean       -14.008
trainer/Q2 Predictions Std         10.8329
trainer/Q2 Predictions Max         -7.34962
trainer/Q2 Predictions Min        -49.9695
trainer/Q Targets Mean            -14.1288
trainer/Q Targets Std              11.1095
trainer/Q Targets Max              -0.611926
trainer/Q Targets Min             -50.5194
trainer/Log Pis Mean                2.08727
trainer/Log Pis Std                 1.42682
trainer/Log Pis Max                 9.24115
trainer/Log Pis Min                -1.54774
trainer/Policy mu Mean             -0.0509168
trainer/Policy mu Std               0.714836
trainer/Policy mu Max               2.93768
trainer/Policy mu Min              -3.51946
trainer/Policy log std Mean        -2.10779
trainer/Policy log std Std          0.433999
trainer/Policy log std Max         -0.436391
trainer/Policy log std Min         -2.50674
trainer/Alpha                       0.0515782
trainer/Alpha Loss                  0.25873
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.411323
exploration/Rewards Std             1.12486
exploration/Rewards Max            -0.00404258
exploration/Rewards Min           -10.6275
exploration/Returns Mean          -41.1323
exploration/Returns Std            13.8224
exploration/Returns Max           -25.5543
exploration/Returns Min           -66.626
exploration/Actions Mean           -0.000358495
exploration/Actions Std             0.257532
exploration/Actions Max             0.999306
exploration/Actions Min            -0.998527
exploration/Num Paths               5
exploration/Average Returns       -41.1323
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.389606
evaluation/Rewards Std              1.21673
evaluation/Rewards Max             -0.00390996
evaluation/Rewards Min            -11.5074
evaluation/Returns Mean           -38.9606
evaluation/Returns Std             28.5613
evaluation/Returns Max             -5.22753
evaluation/Returns Min            -96.6016
evaluation/Actions Mean             0.00877678
evaluation/Actions Std              0.21251
evaluation/Actions Max              0.99944
evaluation/Actions Min             -0.99914
evaluation/Num Paths               15
evaluation/Average Returns        -38.9606
time/data storing (s)               0.00302035
time/evaluation sampling (s)        0.329419
time/exploration sampling (s)       0.139671
time/logging (s)                    0.00486329
time/saving (s)                     0.00196657
time/training (s)                   1.96904
time/epoch (s)                      2.44798
time/total (s)                    293.307
Epoch                             119
-----------------------------  ----------------
2019-04-22 22:41:30.059234 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 120 finished
-----------------------------  ----------------
replay_buffer/size              60700
trainer/QF1 Loss                   15.1521
trainer/QF2 Loss                   15.1228
trainer/Policy Loss                16.2329
trainer/Q1 Predictions Mean       -14.5213
trainer/Q1 Predictions Std         11.259
trainer/Q1 Predictions Max         -7.1677
trainer/Q1 Predictions Min        -41.7836
trainer/Q2 Predictions Mean       -14.5281
trainer/Q2 Predictions Std         11.2553
trainer/Q2 Predictions Max         -7.15844
trainer/Q2 Predictions Min        -41.4466
trainer/Q Targets Mean            -14.2292
trainer/Q Targets Std              11.026
trainer/Q Targets Max              -0.932314
trainer/Q Targets Min             -41.4553
trainer/Log Pis Mean                1.92028
trainer/Log Pis Std                 1.05975
trainer/Log Pis Max                 5.78701
trainer/Log Pis Min                -2.47461
trainer/Policy mu Mean             -0.0271964
trainer/Policy mu Std               0.523671
trainer/Policy mu Max               2.62793
trainer/Policy mu Min              -2.28654
trainer/Policy log std Mean        -2.17414
trainer/Policy log std Std          0.368186
trainer/Policy log std Max         -0.487772
trainer/Policy log std Min         -2.55527
trainer/Alpha                       0.0514428
trainer/Alpha Loss                 -0.236531
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.39501
exploration/Rewards Std             0.940998
exploration/Rewards Max            -0.000284969
exploration/Rewards Min            -7.65133
exploration/Returns Mean          -39.501
exploration/Returns Std            20.2235
exploration/Returns Max           -23.135
exploration/Returns Min           -78.5157
exploration/Actions Mean            0.0152849
exploration/Actions Std             0.240688
exploration/Actions Max             0.99932
exploration/Actions Min            -0.999857
exploration/Num Paths               5
exploration/Average Returns       -39.501
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.461522
evaluation/Rewards Std              1.1618
evaluation/Rewards Max             -0.0302971
evaluation/Rewards Min            -10.8777
evaluation/Returns Mean           -46.1522
evaluation/Returns Std             13.5028
evaluation/Returns Max            -18.2208
evaluation/Returns Min            -61.1505
evaluation/Actions Mean             0.00175791
evaluation/Actions Std              0.204799
evaluation/Actions Max              0.999023
evaluation/Actions Min             -0.998979
evaluation/Num Paths               15
evaluation/Average Returns        -46.1522
time/data storing (s)               0.00293384
time/evaluation sampling (s)        0.332296
time/exploration sampling (s)       0.141423
time/logging (s)                    0.00498532
time/saving (s)                     0.00193164
time/training (s)                   1.96512
time/epoch (s)                      2.44869
time/total (s)                    295.761
Epoch                             120
-----------------------------  ----------------
2019-04-22 22:41:32.504475 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              61200
trainer/QF1 Loss                    0.586687
trainer/QF2 Loss                    0.570791
trainer/Policy Loss                18.3793
trainer/Q1 Predictions Mean       -16.5572
trainer/Q1 Predictions Std         13.4211
trainer/Q1 Predictions Max         -7.12328
trainer/Q1 Predictions Min        -57.3615
trainer/Q2 Predictions Mean       -16.559
trainer/Q2 Predictions Std         13.4569
trainer/Q2 Predictions Max         -7.08446
trainer/Q2 Predictions Min        -57.8733
trainer/Q Targets Mean            -16.593
trainer/Q Targets Std              13.5549
trainer/Q Targets Max              -0.140162
trainer/Q Targets Min             -57.5006
trainer/Log Pis Mean                2.14952
trainer/Log Pis Std                 1.14824
trainer/Log Pis Max                 6.31858
trainer/Log Pis Min                -1.8357
trainer/Policy mu Mean              0.0127835
trainer/Policy mu Std               0.79059
trainer/Policy mu Max               3.32308
trainer/Policy mu Min              -3.42639
trainer/Policy log std Mean        -2.04687
trainer/Policy log std Std          0.492831
trainer/Policy log std Max         -0.291015
trainer/Policy log std Min         -2.49675
trainer/Alpha                       0.0536677
trainer/Alpha Loss                  0.437346
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.291888
exploration/Rewards Std             0.677277
exploration/Rewards Max            -0.00489773
exploration/Rewards Min            -6.34469
exploration/Returns Mean          -29.1888
exploration/Returns Std             6.78479
exploration/Returns Max           -15.992
exploration/Returns Min           -35.0995
exploration/Actions Mean           -0.0143067
exploration/Actions Std             0.233589
exploration/Actions Max             0.998684
exploration/Actions Min            -0.992796
exploration/Num Paths               5
exploration/Average Returns       -29.1888
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.309296
evaluation/Rewards Std              0.96536
evaluation/Rewards Max             -0.0253829
evaluation/Rewards Min             -9.63233
evaluation/Returns Mean           -30.9296
evaluation/Returns Std             25.7932
evaluation/Returns Max             -3.87012
evaluation/Returns Min            -93.49
evaluation/Actions Mean             0.00600633
evaluation/Actions Std              0.184903
evaluation/Actions Max              0.999125
evaluation/Actions Min             -0.999729
evaluation/Num Paths               15
evaluation/Average Returns        -30.9296
time/data storing (s)               0.00304096
time/evaluation sampling (s)        0.325832
time/exploration sampling (s)       0.143633
time/logging (s)                    0.00365673
time/saving (s)                     0.00194105
time/training (s)                   1.95937
time/epoch (s)                      2.43748
time/total (s)                    298.202
Epoch                             121
-----------------------------  ---------------
2019-04-22 22:41:34.944885 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 122 finished
-----------------------------  ----------------
replay_buffer/size              61700
trainer/QF1 Loss                   14.9888
trainer/QF2 Loss                   14.6874
trainer/Policy Loss                18.0817
trainer/Q1 Predictions Mean       -16.7078
trainer/Q1 Predictions Std         13.2461
trainer/Q1 Predictions Max         -6.96765
trainer/Q1 Predictions Min        -53.301
trainer/Q2 Predictions Mean       -16.6748
trainer/Q2 Predictions Std         13.2339
trainer/Q2 Predictions Max         -7.01326
trainer/Q2 Predictions Min        -53.7672
trainer/Q Targets Mean            -16.5643
trainer/Q Targets Std              13.229
trainer/Q Targets Max              -0.589473
trainer/Q Targets Min             -54.5252
trainer/Log Pis Mean                2.02512
trainer/Log Pis Std                 1.44483
trainer/Log Pis Max                 7.66534
trainer/Log Pis Min                -2.01467
trainer/Policy mu Mean              0.0194131
trainer/Policy mu Std               0.853046
trainer/Policy mu Max               3.20297
trainer/Policy mu Min              -2.95549
trainer/Policy log std Mean        -2.00678
trainer/Policy log std Std          0.51663
trainer/Policy log std Max         -0.432187
trainer/Policy log std Min         -2.48656
trainer/Alpha                       0.0531649
trainer/Alpha Loss                  0.0737167
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.289884
exploration/Rewards Std             0.745274
exploration/Rewards Max            -0.0204487
exploration/Rewards Min            -8.71549
exploration/Returns Mean          -28.9884
exploration/Returns Std            14.9806
exploration/Returns Max           -16.6152
exploration/Returns Min           -55.5426
exploration/Actions Mean           -0.00422618
exploration/Actions Std             0.231412
exploration/Actions Max             0.990166
exploration/Actions Min            -0.998482
exploration/Num Paths               5
exploration/Average Returns       -28.9884
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.28739
evaluation/Rewards Std              1.04198
evaluation/Rewards Max             -0.0174645
evaluation/Rewards Min            -11.1201
evaluation/Returns Mean           -28.739
evaluation/Returns Std             20.3271
evaluation/Returns Max             -3.02965
evaluation/Returns Min            -75.0626
evaluation/Actions Mean             0.000411284
evaluation/Actions Std              0.1995
evaluation/Actions Max              0.997959
evaluation/Actions Min             -0.999448
evaluation/Num Paths               15
evaluation/Average Returns        -28.739
time/data storing (s)               0.00292671
time/evaluation sampling (s)        0.329525
time/exploration sampling (s)       0.140155
time/logging (s)                    0.00488576
time/saving (s)                     0.00191984
time/training (s)                   1.95612
time/epoch (s)                      2.43553
time/total (s)                    300.642
Epoch                             122
-----------------------------  ----------------
2019-04-22 22:41:37.378340 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                   15.4653
trainer/QF2 Loss                   15.2409
trainer/Policy Loss                16.3194
trainer/Q1 Predictions Mean       -14.5128
trainer/Q1 Predictions Std         11.3473
trainer/Q1 Predictions Max         -7.21603
trainer/Q1 Predictions Min        -43.3095
trainer/Q2 Predictions Mean       -14.5132
trainer/Q2 Predictions Std         11.3614
trainer/Q2 Predictions Max         -7.22558
trainer/Q2 Predictions Min        -43.5192
trainer/Q Targets Mean            -14.1499
trainer/Q Targets Std              11.4272
trainer/Q Targets Max              -0.114077
trainer/Q Targets Min             -44.1238
trainer/Log Pis Mean                2.14911
trainer/Log Pis Std                 1.12118
trainer/Log Pis Max                 5.79226
trainer/Log Pis Min                -0.851074
trainer/Policy mu Mean              0.0306602
trainer/Policy mu Std               0.695377
trainer/Policy mu Max               3.31501
trainer/Policy mu Min              -2.74157
trainer/Policy log std Mean        -2.11085
trainer/Policy log std Std          0.454138
trainer/Policy log std Max         -0.369698
trainer/Policy log std Min         -2.57656
trainer/Alpha                       0.0538362
trainer/Alpha Loss                  0.43571
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.464281
exploration/Rewards Std             1.09335
exploration/Rewards Max            -0.0112319
exploration/Rewards Min            -9.55175
exploration/Returns Mean          -46.4281
exploration/Returns Std            30.2965
exploration/Returns Max           -19.9856
exploration/Returns Min           -98.1335
exploration/Actions Mean           -0.00838024
exploration/Actions Std             0.235338
exploration/Actions Max             0.997466
exploration/Actions Min            -0.999793
exploration/Num Paths               5
exploration/Average Returns       -46.4281
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.331121
evaluation/Rewards Std              0.83117
evaluation/Rewards Max             -0.0107094
evaluation/Rewards Min             -8.92648
evaluation/Returns Mean           -33.1121
evaluation/Returns Std             20.3103
evaluation/Returns Max             -5.28486
evaluation/Returns Min            -70.8322
evaluation/Actions Mean             0.00810859
evaluation/Actions Std              0.17898
evaluation/Actions Max              0.998645
evaluation/Actions Min             -0.996217
evaluation/Num Paths               15
evaluation/Average Returns        -33.1121
time/data storing (s)               0.00294591
time/evaluation sampling (s)        0.336649
time/exploration sampling (s)       0.142651
time/logging (s)                    0.0048939
time/saving (s)                     0.001935
time/training (s)                   1.93789
time/epoch (s)                      2.42697
time/total (s)                    303.074
Epoch                             123
-----------------------------  ---------------
2019-04-22 22:41:39.815782 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              62700
trainer/QF1 Loss                    1.81595
trainer/QF2 Loss                    1.80458
trainer/Policy Loss                16.4196
trainer/Q1 Predictions Mean       -14.764
trainer/Q1 Predictions Std         12.0556
trainer/Q1 Predictions Max         -6.7864
trainer/Q1 Predictions Min        -62.8267
trainer/Q2 Predictions Mean       -14.7387
trainer/Q2 Predictions Std         12.0159
trainer/Q2 Predictions Max         -6.83859
trainer/Q2 Predictions Min        -62.6488
trainer/Q Targets Mean            -14.5876
trainer/Q Targets Std              12.1165
trainer/Q Targets Max              -0.129038
trainer/Q Targets Min             -62.2389
trainer/Log Pis Mean                1.84429
trainer/Log Pis Std                 1.56592
trainer/Log Pis Max                 6.12097
trainer/Log Pis Min                -6.47796
trainer/Policy mu Mean             -0.0610117
trainer/Policy mu Std               0.640073
trainer/Policy mu Max               3.24666
trainer/Policy mu Min              -3.81706
trainer/Policy log std Mean        -2.10392
trainer/Policy log std Std          0.398914
trainer/Policy log std Max         -0.196845
trainer/Policy log std Min         -2.53365
trainer/Alpha                       0.0549981
trainer/Alpha Loss                 -0.451638
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.383031
exploration/Rewards Std             1.06096
exploration/Rewards Max            -0.00651551
exploration/Rewards Min            -8.18487
exploration/Returns Mean          -38.3031
exploration/Returns Std            13.241
exploration/Returns Max           -17.0098
exploration/Returns Min           -52.0129
exploration/Actions Mean           -0.018427
exploration/Actions Std             0.247283
exploration/Actions Max             0.999488
exploration/Actions Min            -0.999473
exploration/Num Paths               5
exploration/Average Returns       -38.3031
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.381399
evaluation/Rewards Std              1.16909
evaluation/Rewards Max             -0.0152913
evaluation/Rewards Min            -11.5759
evaluation/Returns Mean           -38.1399
evaluation/Returns Std             19.8216
evaluation/Returns Max            -13.1615
evaluation/Returns Min            -82.8742
evaluation/Actions Mean            -0.00465787
evaluation/Actions Std              0.222463
evaluation/Actions Max              0.997858
evaluation/Actions Min             -0.999181
evaluation/Num Paths               15
evaluation/Average Returns        -38.1399
time/data storing (s)               0.00283569
time/evaluation sampling (s)        0.332305
time/exploration sampling (s)       0.137796
time/logging (s)                    0.00484032
time/saving (s)                     0.00192843
time/training (s)                   1.9508
time/epoch (s)                      2.43051
time/total (s)                    305.509
Epoch                             124
-----------------------------  ---------------
2019-04-22 22:41:42.287877 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              63200
trainer/QF1 Loss                    0.717433
trainer/QF2 Loss                    0.692018
trainer/Policy Loss                16.318
trainer/Q1 Predictions Mean       -15.0075
trainer/Q1 Predictions Std         12.0849
trainer/Q1 Predictions Max         -7.19051
trainer/Q1 Predictions Min        -50.7326
trainer/Q2 Predictions Mean       -15.0125
trainer/Q2 Predictions Std         12.0784
trainer/Q2 Predictions Max         -7.17514
trainer/Q2 Predictions Min        -51.0524
trainer/Q Targets Mean            -15.1868
trainer/Q Targets Std              12.3164
trainer/Q Targets Max              -0.207055
trainer/Q Targets Min             -51.9839
trainer/Log Pis Mean                1.83967
trainer/Log Pis Std                 1.37094
trainer/Log Pis Max                 8.71378
trainer/Log Pis Min                -1.81405
trainer/Policy mu Mean             -0.0300863
trainer/Policy mu Std               0.744917
trainer/Policy mu Max               2.85964
trainer/Policy mu Min              -3.07664
trainer/Policy log std Mean        -2.00553
trainer/Policy log std Std          0.443125
trainer/Policy log std Max         -0.405918
trainer/Policy log std Min         -2.40338
trainer/Alpha                       0.0549474
trainer/Alpha Loss                 -0.465156
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.411745
exploration/Rewards Std             1.1467
exploration/Rewards Max            -0.00953002
exploration/Rewards Min            -8.34902
exploration/Returns Mean          -41.1745
exploration/Returns Std             8.80603
exploration/Returns Max           -24.9588
exploration/Returns Min           -49.8296
exploration/Actions Mean            0.0160693
exploration/Actions Std             0.252564
exploration/Actions Max             0.999774
exploration/Actions Min            -0.997575
exploration/Num Paths               5
exploration/Average Returns       -41.1745
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268034
evaluation/Rewards Std              0.903667
evaluation/Rewards Max             -0.0208597
evaluation/Rewards Min             -9.10664
evaluation/Returns Mean           -26.8034
evaluation/Returns Std             23.9987
evaluation/Returns Max             -4.7278
evaluation/Returns Min            -90.9377
evaluation/Actions Mean            -0.00276101
evaluation/Actions Std              0.169722
evaluation/Actions Max              0.998501
evaluation/Actions Min             -0.99975
evaluation/Num Paths               15
evaluation/Average Returns        -26.8034
time/data storing (s)               0.00298732
time/evaluation sampling (s)        0.330457
time/exploration sampling (s)       0.142571
time/logging (s)                    0.0048453
time/saving (s)                     0.00948986
time/training (s)                   1.97488
time/epoch (s)                      2.46523
time/total (s)                    307.979
Epoch                             125
-----------------------------  ---------------
2019-04-22 22:41:44.726325 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 126 finished
-----------------------------  ----------------
replay_buffer/size              63700
trainer/QF1 Loss                   13.2933
trainer/QF2 Loss                   13.5596
trainer/Policy Loss                15.5029
trainer/Q1 Predictions Mean       -13.9924
trainer/Q1 Predictions Std         11.5169
trainer/Q1 Predictions Max         -7.1678
trainer/Q1 Predictions Min        -54.5917
trainer/Q2 Predictions Mean       -13.9732
trainer/Q2 Predictions Std         11.5
trainer/Q2 Predictions Max         -7.15027
trainer/Q2 Predictions Min        -53.9491
trainer/Q Targets Mean            -13.8136
trainer/Q Targets Std              11.5716
trainer/Q Targets Max              -1.57133
trainer/Q Targets Min             -54.1005
trainer/Log Pis Mean                1.75256
trainer/Log Pis Std                 0.991157
trainer/Log Pis Max                 5.3201
trainer/Log Pis Min                -1.88555
trainer/Policy mu Mean             -0.0491924
trainer/Policy mu Std               0.516416
trainer/Policy mu Max               2.14705
trainer/Policy mu Min              -3.04143
trainer/Policy log std Mean        -2.05029
trainer/Policy log std Std          0.364697
trainer/Policy log std Max         -0.201645
trainer/Policy log std Min         -2.43342
trainer/Alpha                       0.053169
trainer/Alpha Loss                 -0.725948
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.698528
exploration/Rewards Std             1.31708
exploration/Rewards Max            -0.00394207
exploration/Rewards Min           -10.89
exploration/Returns Mean          -69.8528
exploration/Returns Std            25.6269
exploration/Returns Max           -40.2749
exploration/Returns Min          -111.44
exploration/Actions Mean           -0.0327659
exploration/Actions Std             0.291671
exploration/Actions Max             0.998167
exploration/Actions Min            -0.999822
exploration/Num Paths               5
exploration/Average Returns       -69.8528
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.435626
evaluation/Rewards Std              1.16221
evaluation/Rewards Max             -0.0153826
evaluation/Rewards Min             -9.55022
evaluation/Returns Mean           -43.5626
evaluation/Returns Std             28.4434
evaluation/Returns Max            -10.5233
evaluation/Returns Min           -103.237
evaluation/Actions Mean             0.000636027
evaluation/Actions Std              0.203076
evaluation/Actions Max              0.997218
evaluation/Actions Min             -0.999451
evaluation/Num Paths               15
evaluation/Average Returns        -43.5626
time/data storing (s)               0.00308706
time/evaluation sampling (s)        0.32127
time/exploration sampling (s)       0.141931
time/logging (s)                    0.00392279
time/saving (s)                     0.00196
time/training (s)                   1.9584
time/epoch (s)                      2.43057
time/total (s)                    310.414
Epoch                             126
-----------------------------  ----------------
2019-04-22 22:41:47.169841 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    0.929369
trainer/QF2 Loss                    0.947809
trainer/Policy Loss                17.138
trainer/Q1 Predictions Mean       -15.6961
trainer/Q1 Predictions Std         13.7035
trainer/Q1 Predictions Max         -7.1274
trainer/Q1 Predictions Min        -73.504
trainer/Q2 Predictions Mean       -15.6874
trainer/Q2 Predictions Std         13.6981
trainer/Q2 Predictions Max         -7.17138
trainer/Q2 Predictions Min        -73.6986
trainer/Q Targets Mean            -15.8984
trainer/Q Targets Std              14.1748
trainer/Q Targets Max              -0.0606619
trainer/Q Targets Min             -75.396
trainer/Log Pis Mean                1.88624
trainer/Log Pis Std                 1.44684
trainer/Log Pis Max                 8.13108
trainer/Log Pis Min                -2.21118
trainer/Policy mu Mean             -0.0592873
trainer/Policy mu Std               0.722989
trainer/Policy mu Max               3.2984
trainer/Policy mu Min              -4.0701
trainer/Policy log std Mean        -2.09252
trainer/Policy log std Std          0.436573
trainer/Policy log std Max         -0.220912
trainer/Policy log std Min         -2.48028
trainer/Alpha                       0.0514492
trainer/Alpha Loss                 -0.337546
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.42911
exploration/Rewards Std             0.991568
exploration/Rewards Max            -0.01314
exploration/Rewards Min            -7.68353
exploration/Returns Mean          -42.911
exploration/Returns Std            10.2621
exploration/Returns Max           -23.4625
exploration/Returns Min           -53.5675
exploration/Actions Mean           -0.00706896
exploration/Actions Std             0.2333
exploration/Actions Max             0.999479
exploration/Actions Min            -0.999622
exploration/Num Paths               5
exploration/Average Returns       -42.911
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.24044
evaluation/Rewards Std              0.84988
evaluation/Rewards Max             -0.0233887
evaluation/Rewards Min            -10.3599
evaluation/Returns Mean           -24.044
evaluation/Returns Std             19.9778
evaluation/Returns Max             -9.42906
evaluation/Returns Min            -81.8777
evaluation/Actions Mean             0.00307209
evaluation/Actions Std              0.178428
evaluation/Actions Max              0.999089
evaluation/Actions Min             -0.998744
evaluation/Num Paths               15
evaluation/Average Returns        -24.044
time/data storing (s)               0.00298385
time/evaluation sampling (s)        0.318741
time/exploration sampling (s)       0.141672
time/logging (s)                    0.00479531
time/saving (s)                     0.00193817
time/training (s)                   1.96855
time/epoch (s)                      2.43868
time/total (s)                    312.856
Epoch                             127
-----------------------------  ---------------
2019-04-22 22:41:49.592368 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              64700
trainer/QF1 Loss                    0.558304
trainer/QF2 Loss                    0.555812
trainer/Policy Loss                15.3353
trainer/Q1 Predictions Mean       -13.5863
trainer/Q1 Predictions Std         10.4002
trainer/Q1 Predictions Max         -7.05588
trainer/Q1 Predictions Min        -39.4356
trainer/Q2 Predictions Mean       -13.6034
trainer/Q2 Predictions Std         10.3984
trainer/Q2 Predictions Max         -7.02058
trainer/Q2 Predictions Min        -39.3259
trainer/Q Targets Mean            -13.6699
trainer/Q Targets Std              10.5414
trainer/Q Targets Max              -0.0890897
trainer/Q Targets Min             -39.7948
trainer/Log Pis Mean                1.95939
trainer/Log Pis Std                 1.15327
trainer/Log Pis Max                 7.46793
trainer/Log Pis Min                -2.99414
trainer/Policy mu Mean              0.0253157
trainer/Policy mu Std               0.615581
trainer/Policy mu Max               2.98451
trainer/Policy mu Min              -2.65871
trainer/Policy log std Mean        -2.08772
trainer/Policy log std Std          0.404478
trainer/Policy log std Max         -0.395736
trainer/Policy log std Min         -2.46194
trainer/Alpha                       0.0529532
trainer/Alpha Loss                 -0.119315
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.382774
exploration/Rewards Std             1.2599
exploration/Rewards Max            -0.0107339
exploration/Rewards Min           -11.7817
exploration/Returns Mean          -38.2774
exploration/Returns Std            22.6783
exploration/Returns Max           -15.0352
exploration/Returns Min           -70.0348
exploration/Actions Mean            0.0300072
exploration/Actions Std             0.244617
exploration/Actions Max             0.999954
exploration/Actions Min            -0.995895
exploration/Num Paths               5
exploration/Average Returns       -38.2774
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.299719
evaluation/Rewards Std              0.987003
evaluation/Rewards Max             -0.0252377
evaluation/Rewards Min             -8.62799
evaluation/Returns Mean           -29.9719
evaluation/Returns Std             15.1931
evaluation/Returns Max             -8.26067
evaluation/Returns Min            -62.776
evaluation/Actions Mean             0.0142395
evaluation/Actions Std              0.189833
evaluation/Actions Max              0.998951
evaluation/Actions Min             -0.996409
evaluation/Num Paths               15
evaluation/Average Returns        -29.9719
time/data storing (s)               0.0029357
time/evaluation sampling (s)        0.33109
time/exploration sampling (s)       0.140666
time/logging (s)                    0.00479849
time/saving (s)                     0.00192824
time/training (s)                   1.93431
time/epoch (s)                      2.41573
time/total (s)                    315.276
Epoch                             128
-----------------------------  ---------------
2019-04-22 22:41:52.017544 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 129 finished
-----------------------------  ----------------
replay_buffer/size              65200
trainer/QF1 Loss                    1.70343
trainer/QF2 Loss                    1.73333
trainer/Policy Loss                16.8238
trainer/Q1 Predictions Mean       -15.3075
trainer/Q1 Predictions Std         12.8641
trainer/Q1 Predictions Max         -6.93279
trainer/Q1 Predictions Min        -56.629
trainer/Q2 Predictions Mean       -15.3044
trainer/Q2 Predictions Std         12.8542
trainer/Q2 Predictions Max         -6.90931
trainer/Q2 Predictions Min        -56.5602
trainer/Q Targets Mean            -15.177
trainer/Q Targets Std              12.9671
trainer/Q Targets Max              -0.163455
trainer/Q Targets Min             -55.2442
trainer/Log Pis Mean                1.77772
trainer/Log Pis Std                 1.49532
trainer/Log Pis Max                 7.84774
trainer/Log Pis Min                -2.43723
trainer/Policy mu Mean             -0.0295056
trainer/Policy mu Std               0.678659
trainer/Policy mu Max               3.22872
trainer/Policy mu Min              -3.49491
trainer/Policy log std Mean        -2.10183
trainer/Policy log std Std          0.426597
trainer/Policy log std Max         -0.388883
trainer/Policy log std Min         -2.55307
trainer/Alpha                       0.0549015
trainer/Alpha Loss                 -0.645122
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387673
exploration/Rewards Std             1.1039
exploration/Rewards Max            -0.00510967
exploration/Rewards Min           -10.9172
exploration/Returns Mean          -38.7673
exploration/Returns Std            18.7115
exploration/Returns Max           -21.9149
exploration/Returns Min           -73.2203
exploration/Actions Mean           -0.0268639
exploration/Actions Std             0.250275
exploration/Actions Max             0.997712
exploration/Actions Min            -0.999986
exploration/Num Paths               5
exploration/Average Returns       -38.7673
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.409627
evaluation/Rewards Std              1.10987
evaluation/Rewards Max             -0.0109653
evaluation/Rewards Min             -9.91608
evaluation/Returns Mean           -40.9627
evaluation/Returns Std             27.0405
evaluation/Returns Max             -8.46918
evaluation/Returns Min            -89.2465
evaluation/Actions Mean             6.22431e-07
evaluation/Actions Std              0.209026
evaluation/Actions Max              0.999464
evaluation/Actions Min             -0.998496
evaluation/Num Paths               15
evaluation/Average Returns        -40.9627
time/data storing (s)               0.00330127
time/evaluation sampling (s)        0.320894
time/exploration sampling (s)       0.138446
time/logging (s)                    0.00357903
time/saving (s)                     0.00156178
time/training (s)                   1.95052
time/epoch (s)                      2.4183
time/total (s)                    317.698
Epoch                             129
-----------------------------  ----------------
2019-04-22 22:41:54.446995 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              65700
trainer/QF1 Loss                   13.6926
trainer/QF2 Loss                   14.0198
trainer/Policy Loss                17.9269
trainer/Q1 Predictions Mean       -16.4865
trainer/Q1 Predictions Std         14.8608
trainer/Q1 Predictions Max         -7.00429
trainer/Q1 Predictions Min        -74.6716
trainer/Q2 Predictions Mean       -16.4909
trainer/Q2 Predictions Std         14.916
trainer/Q2 Predictions Max         -6.97619
trainer/Q2 Predictions Min        -75.5901
trainer/Q Targets Mean            -16.0882
trainer/Q Targets Std              14.4694
trainer/Q Targets Max              -0.959706
trainer/Q Targets Min             -69.5959
trainer/Log Pis Mean                2.17122
trainer/Log Pis Std                 1.09908
trainer/Log Pis Max                 5.20742
trainer/Log Pis Min                -2.60531
trainer/Policy mu Mean             -0.0885104
trainer/Policy mu Std               0.779453
trainer/Policy mu Max               3.34075
trainer/Policy mu Min              -3.5232
trainer/Policy log std Mean        -2.09169
trainer/Policy log std Std          0.474745
trainer/Policy log std Max         -0.489144
trainer/Policy log std Min         -2.5507
trainer/Alpha                       0.055333
trainer/Alpha Loss                  0.495583
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.207523
exploration/Rewards Std             0.531454
exploration/Rewards Max            -0.0010131
exploration/Rewards Min            -6.21626
exploration/Returns Mean          -20.7523
exploration/Returns Std             6.12629
exploration/Returns Max           -12.92
exploration/Returns Min           -28.7575
exploration/Actions Mean            0.00211568
exploration/Actions Std             0.202687
exploration/Actions Max             0.997419
exploration/Actions Min            -0.98918
exploration/Num Paths               5
exploration/Average Returns       -20.7523
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.344498
evaluation/Rewards Std              1.02765
evaluation/Rewards Max             -0.0167478
evaluation/Rewards Min            -10.3014
evaluation/Returns Mean           -34.4498
evaluation/Returns Std             20.4056
evaluation/Returns Max             -4.99535
evaluation/Returns Min            -74.7689
evaluation/Actions Mean            -0.00365882
evaluation/Actions Std              0.200842
evaluation/Actions Max              0.999074
evaluation/Actions Min             -0.99876
evaluation/Num Paths               15
evaluation/Average Returns        -34.4498
time/data storing (s)               0.0030715
time/evaluation sampling (s)        0.324333
time/exploration sampling (s)       0.14065
time/logging (s)                    0.00479999
time/saving (s)                     0.00192374
time/training (s)                   1.94912
time/epoch (s)                      2.4239
time/total (s)                    320.127
Epoch                             130
-----------------------------  ---------------
2019-04-22 22:41:56.882852 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    0.237352
trainer/QF2 Loss                    0.26766
trainer/Policy Loss                17.9592
trainer/Q1 Predictions Mean       -16.4567
trainer/Q1 Predictions Std         13.6815
trainer/Q1 Predictions Max         -7.11444
trainer/Q1 Predictions Min        -62.8644
trainer/Q2 Predictions Mean       -16.4351
trainer/Q2 Predictions Std         13.6788
trainer/Q2 Predictions Max         -7.13071
trainer/Q2 Predictions Min        -63.0802
trainer/Q Targets Mean            -16.716
trainer/Q Targets Std              13.9753
trainer/Q Targets Max              -7.04151
trainer/Q Targets Min             -63.4019
trainer/Log Pis Mean                1.94611
trainer/Log Pis Std                 1.68387
trainer/Log Pis Max                 8.88045
trainer/Log Pis Min                -2.30409
trainer/Policy mu Mean             -0.0291723
trainer/Policy mu Std               0.839087
trainer/Policy mu Max               3.6106
trainer/Policy mu Min              -3.38531
trainer/Policy log std Mean        -2.00156
trainer/Policy log std Std          0.509955
trainer/Policy log std Max         -0.194748
trainer/Policy log std Min         -2.60456
trainer/Alpha                       0.0560132
trainer/Alpha Loss                 -0.155303
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.221523
exploration/Rewards Std             0.437028
exploration/Rewards Max            -0.00676952
exploration/Rewards Min            -4.70519
exploration/Returns Mean          -22.1523
exploration/Returns Std             5.501
exploration/Returns Max           -16.9247
exploration/Returns Min           -30.329
exploration/Actions Mean           -0.01249
exploration/Actions Std             0.216405
exploration/Actions Max             0.997464
exploration/Actions Min            -0.999674
exploration/Num Paths               5
exploration/Average Returns       -22.1523
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.343504
evaluation/Rewards Std              0.814664
evaluation/Rewards Max             -0.0130112
evaluation/Rewards Min             -9.65252
evaluation/Returns Mean           -34.3504
evaluation/Returns Std             27.3675
evaluation/Returns Max             -7.15154
evaluation/Returns Min            -78.3086
evaluation/Actions Mean            -0.0100226
evaluation/Actions Std              0.175923
evaluation/Actions Max              0.996999
evaluation/Actions Min             -0.99897
evaluation/Num Paths               15
evaluation/Average Returns        -34.3504
time/data storing (s)               0.00291817
time/evaluation sampling (s)        0.320829
time/exploration sampling (s)       0.153135
time/logging (s)                    0.00482259
time/saving (s)                     0.00196189
time/training (s)                   1.94544
time/epoch (s)                      2.4291
time/total (s)                    322.56
Epoch                             131
-----------------------------  ---------------
2019-04-22 22:41:59.318948 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              66700
trainer/QF1 Loss                    0.0475002
trainer/QF2 Loss                    0.0434116
trainer/Policy Loss                15.7872
trainer/Q1 Predictions Mean       -13.8903
trainer/Q1 Predictions Std         11.0647
trainer/Q1 Predictions Max         -7.04612
trainer/Q1 Predictions Min        -43.1461
trainer/Q2 Predictions Mean       -13.8967
trainer/Q2 Predictions Std         11.0799
trainer/Q2 Predictions Max         -7.03074
trainer/Q2 Predictions Min        -43.2944
trainer/Q Targets Mean            -14.0298
trainer/Q Targets Std              11.1445
trainer/Q Targets Max              -6.96622
trainer/Q Targets Min             -43.36
trainer/Log Pis Mean                2.0915
trainer/Log Pis Std                 1.00342
trainer/Log Pis Max                 5.32243
trainer/Log Pis Min                -1.26944
trainer/Policy mu Mean             -0.0415765
trainer/Policy mu Std               0.610884
trainer/Policy mu Max               3.03929
trainer/Policy mu Min              -2.53044
trainer/Policy log std Mean        -2.12943
trainer/Policy log std Std          0.418275
trainer/Policy log std Max         -0.501113
trainer/Policy log std Min         -2.59062
trainer/Alpha                       0.0556681
trainer/Alpha Loss                  0.264299
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.424647
exploration/Rewards Std             1.23627
exploration/Rewards Max            -0.0103476
exploration/Rewards Min           -10.5794
exploration/Returns Mean          -42.4647
exploration/Returns Std            19.4279
exploration/Returns Max           -20.151
exploration/Returns Min           -72.6362
exploration/Actions Mean           -0.00683008
exploration/Actions Std             0.256383
exploration/Actions Max             0.998601
exploration/Actions Min            -0.999448
exploration/Num Paths               5
exploration/Average Returns       -42.4647
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.297722
evaluation/Rewards Std              0.907269
evaluation/Rewards Max             -0.0132396
evaluation/Rewards Min            -11.0023
evaluation/Returns Mean           -29.7722
evaluation/Returns Std             25.257
evaluation/Returns Max             -3.95205
evaluation/Returns Min            -85.3077
evaluation/Actions Mean            -0.0126893
evaluation/Actions Std              0.178901
evaluation/Actions Max              0.997519
evaluation/Actions Min             -0.999704
evaluation/Num Paths               15
evaluation/Average Returns        -29.7722
time/data storing (s)               0.00274264
time/evaluation sampling (s)        0.322307
time/exploration sampling (s)       0.142369
time/logging (s)                    0.00483563
time/saving (s)                     0.00196122
time/training (s)                   1.9567
time/epoch (s)                      2.43091
time/total (s)                    324.995
Epoch                             132
-----------------------------  ---------------
2019-04-22 22:42:01.781520 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 133 finished
-----------------------------  ---------------
replay_buffer/size              67200
trainer/QF1 Loss                    1.05868
trainer/QF2 Loss                    1.05886
trainer/Policy Loss                14.4242
trainer/Q1 Predictions Mean       -12.889
trainer/Q1 Predictions Std          9.86948
trainer/Q1 Predictions Max         -6.99924
trainer/Q1 Predictions Min        -37.1716
trainer/Q2 Predictions Mean       -12.8973
trainer/Q2 Predictions Std          9.86594
trainer/Q2 Predictions Max         -7.01211
trainer/Q2 Predictions Min        -37.0275
trainer/Q Targets Mean            -12.7477
trainer/Q Targets Std              10.0302
trainer/Q Targets Max              -0.0813575
trainer/Q Targets Min             -37.2299
trainer/Log Pis Mean                1.81235
trainer/Log Pis Std                 1.00258
trainer/Log Pis Max                 5.09397
trainer/Log Pis Min                -1.02146
trainer/Policy mu Mean              0.042345
trainer/Policy mu Std               0.415578
trainer/Policy mu Max               1.43071
trainer/Policy mu Min              -2.2438
trainer/Policy log std Mean        -2.15306
trainer/Policy log std Std          0.285314
trainer/Policy log std Max         -0.612505
trainer/Policy log std Min         -2.44503
trainer/Alpha                       0.0561354
trainer/Alpha Loss                 -0.540418
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.456518
exploration/Rewards Std             1.01306
exploration/Rewards Max            -0.00882097
exploration/Rewards Min            -8.9348
exploration/Returns Mean          -45.6518
exploration/Returns Std            20.0657
exploration/Returns Max           -27.8643
exploration/Returns Min           -80.1785
exploration/Actions Mean           -0.0172356
exploration/Actions Std             0.242469
exploration/Actions Max             0.997394
exploration/Actions Min            -0.9994
exploration/Num Paths               5
exploration/Average Returns       -45.6518
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.394121
evaluation/Rewards Std              0.846706
evaluation/Rewards Max             -0.0179387
evaluation/Rewards Min             -8.97254
evaluation/Returns Mean           -39.4121
evaluation/Returns Std             26.2336
evaluation/Returns Max             -8.06917
evaluation/Returns Min            -88.0794
evaluation/Actions Mean            -0.00680906
evaluation/Actions Std              0.187586
evaluation/Actions Max              0.997758
evaluation/Actions Min             -0.998183
evaluation/Num Paths               15
evaluation/Average Returns        -39.4121
time/data storing (s)               0.00277428
time/evaluation sampling (s)        0.322624
time/exploration sampling (s)       0.141178
time/logging (s)                    0.00502534
time/saving (s)                     0.00209581
time/training (s)                   1.98235
time/epoch (s)                      2.45604
time/total (s)                    327.455
Epoch                             133
-----------------------------  ---------------
2019-04-22 22:42:04.214802 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              67700
trainer/QF1 Loss                    0.711134
trainer/QF2 Loss                    0.679704
trainer/Policy Loss                15.2114
trainer/Q1 Predictions Mean       -13.3213
trainer/Q1 Predictions Std         10.9323
trainer/Q1 Predictions Max         -6.9096
trainer/Q1 Predictions Min        -65.9448
trainer/Q2 Predictions Mean       -13.2934
trainer/Q2 Predictions Std         10.9091
trainer/Q2 Predictions Max         -6.89432
trainer/Q2 Predictions Min        -65.8502
trainer/Q Targets Mean            -13.302
trainer/Q Targets Std              11.0666
trainer/Q Targets Max              -0.323924
trainer/Q Targets Min             -65.931
trainer/Log Pis Mean                2.13347
trainer/Log Pis Std                 1.28096
trainer/Log Pis Max                 8.33912
trainer/Log Pis Min                -0.807414
trainer/Policy mu Mean             -0.0927031
trainer/Policy mu Std               0.787468
trainer/Policy mu Max               3.11825
trainer/Policy mu Min              -3.85146
trainer/Policy log std Mean        -2.04977
trainer/Policy log std Std          0.518999
trainer/Policy log std Max         -0.235891
trainer/Policy log std Min         -2.53386
trainer/Alpha                       0.0558221
trainer/Alpha Loss                  0.385164
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.242515
exploration/Rewards Std             0.585468
exploration/Rewards Max            -0.00859275
exploration/Rewards Min            -5.14578
exploration/Returns Mean          -24.2515
exploration/Returns Std             5.51271
exploration/Returns Max           -14.8216
exploration/Returns Min           -30.9486
exploration/Actions Mean            0.0134661
exploration/Actions Std             0.21124
exploration/Actions Max             0.998955
exploration/Actions Min            -0.994905
exploration/Num Paths               5
exploration/Average Returns       -24.2515
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.296819
evaluation/Rewards Std              0.994239
evaluation/Rewards Max             -0.0399797
evaluation/Rewards Min             -9.84726
evaluation/Returns Mean           -29.6819
evaluation/Returns Std             21.6189
evaluation/Returns Max             -6.84276
evaluation/Returns Min            -92.8683
evaluation/Actions Mean             0.0104202
evaluation/Actions Std              0.196077
evaluation/Actions Max              0.997706
evaluation/Actions Min             -0.999774
evaluation/Num Paths               15
evaluation/Average Returns        -29.6819
time/data storing (s)               0.00295767
time/evaluation sampling (s)        0.32437
time/exploration sampling (s)       0.142061
time/logging (s)                    0.00484775
time/saving (s)                     0.00198008
time/training (s)                   1.95016
time/epoch (s)                      2.42637
time/total (s)                    329.886
Epoch                             134
-----------------------------  ---------------
2019-04-22 22:42:06.657848 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                    1.05014
trainer/QF2 Loss                    1.03719
trainer/Policy Loss                14.1161
trainer/Q1 Predictions Mean       -12.3605
trainer/Q1 Predictions Std          8.8154
trainer/Q1 Predictions Max         -7.05242
trainer/Q1 Predictions Min        -36.9729
trainer/Q2 Predictions Mean       -12.3623
trainer/Q2 Predictions Std          8.81638
trainer/Q2 Predictions Max         -7.04982
trainer/Q2 Predictions Min        -37.1043
trainer/Q Targets Mean            -12.4323
trainer/Q Targets Std               9.03709
trainer/Q Targets Max              -0.0712692
trainer/Q Targets Min             -38.0051
trainer/Log Pis Mean                2.07409
trainer/Log Pis Std                 1.2192
trainer/Log Pis Max                 6.14333
trainer/Log Pis Min                -4.02372
trainer/Policy mu Mean              0.0261675
trainer/Policy mu Std               0.674027
trainer/Policy mu Max               2.82817
trainer/Policy mu Min              -3.04445
trainer/Policy log std Mean        -2.1236
trainer/Policy log std Std          0.44637
trainer/Policy log std Max         -0.279
trainer/Policy log std Min         -2.4987
trainer/Alpha                       0.0561622
trainer/Alpha Loss                  0.213337
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.335439
exploration/Rewards Std             1.03084
exploration/Rewards Max            -0.00650757
exploration/Rewards Min            -9.50515
exploration/Returns Mean          -33.5439
exploration/Returns Std            16.0208
exploration/Returns Max           -14.7419
exploration/Returns Min           -62.9448
exploration/Actions Mean            0.0198575
exploration/Actions Std             0.232405
exploration/Actions Max             0.999283
exploration/Actions Min            -0.999103
exploration/Num Paths               5
exploration/Average Returns       -33.5439
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.382604
evaluation/Rewards Std              1.07153
evaluation/Rewards Max             -0.00886132
evaluation/Rewards Min            -10.5634
evaluation/Returns Mean           -38.2604
evaluation/Returns Std             20.9622
evaluation/Returns Max             -9.76648
evaluation/Returns Min            -87.6134
evaluation/Actions Mean            -0.00200222
evaluation/Actions Std              0.205395
evaluation/Actions Max              0.997657
evaluation/Actions Min             -0.998703
evaluation/Num Paths               15
evaluation/Average Returns        -38.2604
time/data storing (s)               0.00292923
time/evaluation sampling (s)        0.324787
time/exploration sampling (s)       0.142492
time/logging (s)                    0.00482298
time/saving (s)                     0.00155892
time/training (s)                   1.96047
time/epoch (s)                      2.43706
time/total (s)                    332.326
Epoch                             135
-----------------------------  ---------------
2019-04-22 22:42:09.118103 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              68700
trainer/QF1 Loss                    1.41562
trainer/QF2 Loss                    1.4278
trainer/Policy Loss                17.2784
trainer/Q1 Predictions Mean       -15.6883
trainer/Q1 Predictions Std         12.1604
trainer/Q1 Predictions Max         -7.25893
trainer/Q1 Predictions Min        -56.1442
trainer/Q2 Predictions Mean       -15.6683
trainer/Q2 Predictions Std         12.1439
trainer/Q2 Predictions Max         -7.20678
trainer/Q2 Predictions Min        -55.7029
trainer/Q Targets Mean            -15.9903
trainer/Q Targets Std              12.6577
trainer/Q Targets Max              -0.408033
trainer/Q Targets Min             -55.0082
trainer/Log Pis Mean                2.1618
trainer/Log Pis Std                 1.49024
trainer/Log Pis Max                 8.64098
trainer/Log Pis Min                -2.88916
trainer/Policy mu Mean             -0.0759624
trainer/Policy mu Std               0.829136
trainer/Policy mu Max               3.13778
trainer/Policy mu Min              -3.5043
trainer/Policy log std Mean        -2.03795
trainer/Policy log std Std          0.50109
trainer/Policy log std Max         -0.390984
trainer/Policy log std Min         -2.58589
trainer/Alpha                       0.05681
trainer/Alpha Loss                  0.464068
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.477987
exploration/Rewards Std             1.08277
exploration/Rewards Max            -0.00755473
exploration/Rewards Min            -8.23508
exploration/Returns Mean          -47.7987
exploration/Returns Std            12.7582
exploration/Returns Max           -28.4597
exploration/Returns Min           -68.6905
exploration/Actions Mean           -0.0227616
exploration/Actions Std             0.246638
exploration/Actions Max             0.999267
exploration/Actions Min            -0.999875
exploration/Num Paths               5
exploration/Average Returns       -47.7987
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.333577
evaluation/Rewards Std              1.00379
evaluation/Rewards Max             -0.0104332
evaluation/Rewards Min             -9.31058
evaluation/Returns Mean           -33.3577
evaluation/Returns Std             19.5578
evaluation/Returns Max             -4.52827
evaluation/Returns Min            -72.2533
evaluation/Actions Mean             0.0105848
evaluation/Actions Std              0.196331
evaluation/Actions Max              0.999129
evaluation/Actions Min             -0.997189
evaluation/Num Paths               15
evaluation/Average Returns        -33.3577
time/data storing (s)               0.00277232
time/evaluation sampling (s)        0.327476
time/exploration sampling (s)       0.151934
time/logging (s)                    0.00407053
time/saving (s)                     0.0019601
time/training (s)                   1.96468
time/epoch (s)                      2.4529
time/total (s)                    334.783
Epoch                             136
-----------------------------  ---------------
2019-04-22 22:42:11.555169 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                   13.3901
trainer/QF2 Loss                   13.0412
trainer/Policy Loss                16.2831
trainer/Q1 Predictions Mean       -14.6929
trainer/Q1 Predictions Std         11.4772
trainer/Q1 Predictions Max         -6.73433
trainer/Q1 Predictions Min        -40.3289
trainer/Q2 Predictions Mean       -14.6964
trainer/Q2 Predictions Std         11.4514
trainer/Q2 Predictions Max         -6.74977
trainer/Q2 Predictions Min        -40.403
trainer/Q Targets Mean            -14.2998
trainer/Q Targets Std              11.2655
trainer/Q Targets Max              -0.354383
trainer/Q Targets Min             -40.4266
trainer/Log Pis Mean                1.92334
trainer/Log Pis Std                 1.0508
trainer/Log Pis Max                 7.36462
trainer/Log Pis Min                -1.67679
trainer/Policy mu Mean              0.00212077
trainer/Policy mu Std               0.583058
trainer/Policy mu Max               2.84228
trainer/Policy mu Min              -2.48445
trainer/Policy log std Mean        -2.10984
trainer/Policy log std Std          0.38173
trainer/Policy log std Max         -0.50378
trainer/Policy log std Min         -2.47736
trainer/Alpha                       0.0546696
trainer/Alpha Loss                 -0.222808
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.342194
exploration/Rewards Std             0.841665
exploration/Rewards Max            -0.00520224
exploration/Rewards Min            -9.36827
exploration/Returns Mean          -34.2194
exploration/Returns Std            19.5755
exploration/Returns Max           -15.5099
exploration/Returns Min           -61.0162
exploration/Actions Mean           -0.0141627
exploration/Actions Std             0.210911
exploration/Actions Max             0.999401
exploration/Actions Min            -0.999381
exploration/Num Paths               5
exploration/Average Returns       -34.2194
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.284659
evaluation/Rewards Std              0.879628
evaluation/Rewards Max             -0.0181155
evaluation/Rewards Min             -9.60201
evaluation/Returns Mean           -28.4659
evaluation/Returns Std             22.2781
evaluation/Returns Max             -2.91654
evaluation/Returns Min            -71.6603
evaluation/Actions Mean            -0.00234555
evaluation/Actions Std              0.176852
evaluation/Actions Max              0.996558
evaluation/Actions Min             -0.998475
evaluation/Num Paths               15
evaluation/Average Returns        -28.4659
time/data storing (s)               0.0028222
time/evaluation sampling (s)        0.320701
time/exploration sampling (s)       0.139752
time/logging (s)                    0.00485131
time/saving (s)                     0.00192501
time/training (s)                   1.96255
time/epoch (s)                      2.4326
time/total (s)                    337.219
Epoch                             137
-----------------------------  ---------------
2019-04-22 22:42:14.000726 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              69700
trainer/QF1 Loss                    0.71498
trainer/QF2 Loss                    0.698206
trainer/Policy Loss                15.6551
trainer/Q1 Predictions Mean       -14.1084
trainer/Q1 Predictions Std         10.486
trainer/Q1 Predictions Max         -6.96769
trainer/Q1 Predictions Min        -37.9643
trainer/Q2 Predictions Mean       -14.1014
trainer/Q2 Predictions Std         10.5091
trainer/Q2 Predictions Max         -6.9731
trainer/Q2 Predictions Min        -37.7421
trainer/Q Targets Mean            -14.1381
trainer/Q Targets Std              10.7421
trainer/Q Targets Max              -0.282189
trainer/Q Targets Min             -38.2463
trainer/Log Pis Mean                1.87778
trainer/Log Pis Std                 1.06179
trainer/Log Pis Max                 4.18721
trainer/Log Pis Min                -2.28919
trainer/Policy mu Mean              0.0490759
trainer/Policy mu Std               0.596492
trainer/Policy mu Max               2.99722
trainer/Policy mu Min              -2.64312
trainer/Policy log std Mean        -2.12861
trainer/Policy log std Std          0.378403
trainer/Policy log std Max         -0.523198
trainer/Policy log std Min         -2.50149
trainer/Alpha                       0.0540921
trainer/Alpha Loss                 -0.356521
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.254127
exploration/Rewards Std             0.830872
exploration/Rewards Max            -0.00220884
exploration/Rewards Min            -9.63777
exploration/Returns Mean          -25.4127
exploration/Returns Std            19.9449
exploration/Returns Max           -12.6237
exploration/Returns Min           -65.108
exploration/Actions Mean           -0.00253792
exploration/Actions Std             0.196736
exploration/Actions Max             0.98933
exploration/Actions Min            -0.999026
exploration/Num Paths               5
exploration/Average Returns       -25.4127
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.367629
evaluation/Rewards Std              1.09619
evaluation/Rewards Max             -0.00553814
evaluation/Rewards Min            -10.1082
evaluation/Returns Mean           -36.7629
evaluation/Returns Std             25.6252
evaluation/Returns Max             -2.46059
evaluation/Returns Min            -93.1689
evaluation/Actions Mean             0.00524437
evaluation/Actions Std              0.196139
evaluation/Actions Max              0.999085
evaluation/Actions Min             -0.999473
evaluation/Num Paths               15
evaluation/Average Returns        -36.7629
time/data storing (s)               0.00305464
time/evaluation sampling (s)        0.353603
time/exploration sampling (s)       0.141686
time/logging (s)                    0.00440202
time/saving (s)                     0.00163039
time/training (s)                   1.93398
time/epoch (s)                      2.43836
time/total (s)                    339.662
Epoch                             138
-----------------------------  ---------------
2019-04-22 22:42:16.443331 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              70200
trainer/QF1 Loss                    1.0602
trainer/QF2 Loss                    1.07958
trainer/Policy Loss                14.3315
trainer/Q1 Predictions Mean       -12.6087
trainer/Q1 Predictions Std         10.1455
trainer/Q1 Predictions Max         -6.89182
trainer/Q1 Predictions Min        -44.7975
trainer/Q2 Predictions Mean       -12.5962
trainer/Q2 Predictions Std         10.1276
trainer/Q2 Predictions Max         -6.88671
trainer/Q2 Predictions Min        -44.5485
trainer/Q Targets Mean            -12.5117
trainer/Q Targets Std              10.309
trainer/Q Targets Max              -0.212949
trainer/Q Targets Min             -45.7914
trainer/Log Pis Mean                1.96271
trainer/Log Pis Std                 1.39429
trainer/Log Pis Max                 8.47512
trainer/Log Pis Min                -1.49598
trainer/Policy mu Mean              0.0368887
trainer/Policy mu Std               0.694223
trainer/Policy mu Max               3.13034
trainer/Policy mu Min              -2.88768
trainer/Policy log std Mean        -2.124
trainer/Policy log std Std          0.42312
trainer/Policy log std Max         -0.552397
trainer/Policy log std Min         -2.50667
trainer/Alpha                       0.0531069
trainer/Alpha Loss                 -0.10946
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.336145
exploration/Rewards Std             1.02248
exploration/Rewards Max            -0.00470607
exploration/Rewards Min            -8.77958
exploration/Returns Mean          -33.6145
exploration/Returns Std            15.2621
exploration/Returns Max           -16.2839
exploration/Returns Min           -53.5761
exploration/Actions Mean           -0.00380924
exploration/Actions Std             0.223679
exploration/Actions Max             0.999134
exploration/Actions Min            -0.999566
exploration/Num Paths               5
exploration/Average Returns       -33.6145
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.341617
evaluation/Rewards Std              1.09065
evaluation/Rewards Max             -0.00403469
evaluation/Rewards Min            -10.3899
evaluation/Returns Mean           -34.1617
evaluation/Returns Std             18.3217
evaluation/Returns Max             -4.77521
evaluation/Returns Min            -72.4503
evaluation/Actions Mean             0.0129693
evaluation/Actions Std              0.214687
evaluation/Actions Max              0.999124
evaluation/Actions Min             -0.997161
evaluation/Num Paths               15
evaluation/Average Returns        -34.1617
time/data storing (s)               0.00286168
time/evaluation sampling (s)        0.32658
time/exploration sampling (s)       0.138778
time/logging (s)                    0.00483865
time/saving (s)                     0.00158523
time/training (s)                   1.96172
time/epoch (s)                      2.43637
time/total (s)                    342.102
Epoch                             139
-----------------------------  ---------------
2019-04-22 22:42:18.882402 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              70700
trainer/QF1 Loss                   13.01
trainer/QF2 Loss                   13.0166
trainer/Policy Loss                15.1877
trainer/Q1 Predictions Mean       -13.3464
trainer/Q1 Predictions Std         10.7921
trainer/Q1 Predictions Max         -6.88646
trainer/Q1 Predictions Min        -47.7237
trainer/Q2 Predictions Mean       -13.3505
trainer/Q2 Predictions Std         10.8034
trainer/Q2 Predictions Max         -6.91087
trainer/Q2 Predictions Min        -48.3482
trainer/Q Targets Mean            -13.0418
trainer/Q Targets Std              10.8124
trainer/Q Targets Max              -0.0699807
trainer/Q Targets Min             -50.035
trainer/Log Pis Mean                1.98881
trainer/Log Pis Std                 1.30422
trainer/Log Pis Max                 8.1978
trainer/Log Pis Min                -2.07331
trainer/Policy mu Mean             -0.0457668
trainer/Policy mu Std               0.673856
trainer/Policy mu Max               3.42824
trainer/Policy mu Min              -2.75438
trainer/Policy log std Mean        -2.1212
trainer/Policy log std Std          0.445251
trainer/Policy log std Max         -0.411273
trainer/Policy log std Min         -2.54968
trainer/Alpha                       0.052482
trainer/Alpha Loss                 -0.032983
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.360117
exploration/Rewards Std             1.10577
exploration/Rewards Max            -0.00514382
exploration/Rewards Min           -10.7052
exploration/Returns Mean          -36.0117
exploration/Returns Std            16.0534
exploration/Returns Max           -15.5231
exploration/Returns Min           -63.5466
exploration/Actions Mean           -0.00175925
exploration/Actions Std             0.242422
exploration/Actions Max             0.99971
exploration/Actions Min            -0.999874
exploration/Num Paths               5
exploration/Average Returns       -36.0117
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.363535
evaluation/Rewards Std              1.1017
evaluation/Rewards Max             -0.0186304
evaluation/Rewards Min            -10.1482
evaluation/Returns Mean           -36.3535
evaluation/Returns Std             23.5926
evaluation/Returns Max             -6.80497
evaluation/Returns Min            -88.6129
evaluation/Actions Mean             0.00732752
evaluation/Actions Std              0.209786
evaluation/Actions Max              0.9992
evaluation/Actions Min             -0.999685
evaluation/Num Paths               15
evaluation/Average Returns        -36.3535
time/data storing (s)               0.00307288
time/evaluation sampling (s)        0.326603
time/exploration sampling (s)       0.141637
time/logging (s)                    0.00485168
time/saving (s)                     0.00194107
time/training (s)                   1.95391
time/epoch (s)                      2.43202
time/total (s)                    344.539
Epoch                             140
-----------------------------  ---------------
2019-04-22 22:42:21.327377 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                    0.168978
trainer/QF2 Loss                    0.144043
trainer/Policy Loss                14.4255
trainer/Q1 Predictions Mean       -12.9056
trainer/Q1 Predictions Std         11.2648
trainer/Q1 Predictions Max         -6.88196
trainer/Q1 Predictions Min        -68.5737
trainer/Q2 Predictions Mean       -12.9104
trainer/Q2 Predictions Std         11.2583
trainer/Q2 Predictions Max         -6.87524
trainer/Q2 Predictions Min        -68.9174
trainer/Q Targets Mean            -13.0228
trainer/Q Targets Std              11.4598
trainer/Q Targets Max              -6.84284
trainer/Q Targets Min             -71.9939
trainer/Log Pis Mean                1.91754
trainer/Log Pis Std                 1.52095
trainer/Log Pis Max                10.1397
trainer/Log Pis Min                -3.97073
trainer/Policy mu Mean             -0.0182991
trainer/Policy mu Std               0.767378
trainer/Policy mu Max               3.61919
trainer/Policy mu Min              -3.58062
trainer/Policy log std Mean        -2.06383
trainer/Policy log std Std          0.478654
trainer/Policy log std Max         -0.333103
trainer/Policy log std Min         -2.47627
trainer/Alpha                       0.0532679
trainer/Alpha Loss                 -0.241808
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.449348
exploration/Rewards Std             1.13268
exploration/Rewards Max            -0.0124503
exploration/Rewards Min            -9.19503
exploration/Returns Mean          -44.9348
exploration/Returns Std            14.3928
exploration/Returns Max           -18.4477
exploration/Returns Min           -59.865
exploration/Actions Mean           -0.00175928
exploration/Actions Std             0.251329
exploration/Actions Max             0.999181
exploration/Actions Min            -0.99962
exploration/Num Paths               5
exploration/Average Returns       -44.9348
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.286219
evaluation/Rewards Std              0.836566
evaluation/Rewards Max             -0.0151592
evaluation/Rewards Min             -8.27439
evaluation/Returns Mean           -28.6219
evaluation/Returns Std             11.733
evaluation/Returns Max            -12.0446
evaluation/Returns Min            -48.6384
evaluation/Actions Mean             0.00591013
evaluation/Actions Std              0.190411
evaluation/Actions Max              0.999323
evaluation/Actions Min             -0.995743
evaluation/Num Paths               15
evaluation/Average Returns        -28.6219
time/data storing (s)               0.00293752
time/evaluation sampling (s)        0.326645
time/exploration sampling (s)       0.140264
time/logging (s)                    0.00488562
time/saving (s)                     0.00196187
time/training (s)                   1.96128
time/epoch (s)                      2.43798
time/total (s)                    346.981
Epoch                             141
-----------------------------  ---------------
2019-04-22 22:42:23.771129 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              71700
trainer/QF1 Loss                    0.0605796
trainer/QF2 Loss                    0.0620855
trainer/Policy Loss                14.4516
trainer/Q1 Predictions Mean       -12.6611
trainer/Q1 Predictions Std         10.5424
trainer/Q1 Predictions Max         -6.81808
trainer/Q1 Predictions Min        -43.1821
trainer/Q2 Predictions Mean       -12.6577
trainer/Q2 Predictions Std         10.5287
trainer/Q2 Predictions Max         -6.79639
trainer/Q2 Predictions Min        -42.806
trainer/Q Targets Mean            -12.8401
trainer/Q Targets Std              10.5703
trainer/Q Targets Max              -6.88335
trainer/Q Targets Min             -43.2146
trainer/Log Pis Mean                2.06764
trainer/Log Pis Std                 1.1018
trainer/Log Pis Max                 5.03824
trainer/Log Pis Min                -3.15758
trainer/Policy mu Mean             -0.0250147
trainer/Policy mu Std               0.647099
trainer/Policy mu Max               2.97131
trainer/Policy mu Min              -2.76176
trainer/Policy log std Mean        -2.0838
trainer/Policy log std Std          0.435463
trainer/Policy log std Max         -0.500862
trainer/Policy log std Min         -2.57217
trainer/Alpha                       0.0543575
trainer/Alpha Loss                  0.196994
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.398901
exploration/Rewards Std             0.843914
exploration/Rewards Max            -0.0196346
exploration/Rewards Min            -9.55191
exploration/Returns Mean          -39.8901
exploration/Returns Std            23.4219
exploration/Returns Max           -17.0346
exploration/Returns Min           -78.6244
exploration/Actions Mean           -0.015206
exploration/Actions Std             0.218083
exploration/Actions Max             0.999109
exploration/Actions Min            -0.99833
exploration/Num Paths               5
exploration/Average Returns       -39.8901
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.300523
evaluation/Rewards Std              1.07067
evaluation/Rewards Max             -0.00497175
evaluation/Rewards Min            -10.5478
evaluation/Returns Mean           -30.0523
evaluation/Returns Std             22.618
evaluation/Returns Max             -1.22304
evaluation/Returns Min            -71.6888
evaluation/Actions Mean            -0.00765375
evaluation/Actions Std              0.196517
evaluation/Actions Max              0.997988
evaluation/Actions Min             -0.999406
evaluation/Num Paths               15
evaluation/Average Returns        -30.0523
time/data storing (s)               0.00295123
time/evaluation sampling (s)        0.325909
time/exploration sampling (s)       0.136175
time/logging (s)                    0.00483924
time/saving (s)                     0.00193887
time/training (s)                   1.96485
time/epoch (s)                      2.43666
time/total (s)                    349.422
Epoch                             142
-----------------------------  ---------------
2019-04-22 22:42:26.188066 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              72200
trainer/QF1 Loss                   12.1328
trainer/QF2 Loss                   12.2222
trainer/Policy Loss                18.123
trainer/Q1 Predictions Mean       -16.641
trainer/Q1 Predictions Std         13.6867
trainer/Q1 Predictions Max         -6.77394
trainer/Q1 Predictions Min        -66.0069
trainer/Q2 Predictions Mean       -16.6715
trainer/Q2 Predictions Std         13.6865
trainer/Q2 Predictions Max         -6.79944
trainer/Q2 Predictions Min        -65.6206
trainer/Q Targets Mean            -16.4761
trainer/Q Targets Std              13.7078
trainer/Q Targets Max              -0.940844
trainer/Q Targets Min             -67.5826
trainer/Log Pis Mean                1.93713
trainer/Log Pis Std                 1.23303
trainer/Log Pis Max                 6.31393
trainer/Log Pis Min                -1.33321
trainer/Policy mu Mean              0.025254
trainer/Policy mu Std               0.758402
trainer/Policy mu Max               3.37086
trainer/Policy mu Min              -3.47151
trainer/Policy log std Mean        -2.03336
trainer/Policy log std Std          0.482211
trainer/Policy log std Max         -0.436587
trainer/Policy log std Min         -2.44812
trainer/Alpha                       0.0539271
trainer/Alpha Loss                 -0.183568
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.283004
exploration/Rewards Std             0.68101
exploration/Rewards Max            -0.00639778
exploration/Rewards Min            -6.81337
exploration/Returns Mean          -28.3004
exploration/Returns Std             4.70069
exploration/Returns Max           -19.9386
exploration/Returns Min           -33.8057
exploration/Actions Mean            0.00128498
exploration/Actions Std             0.236623
exploration/Actions Max             0.999727
exploration/Actions Min            -0.997305
exploration/Num Paths               5
exploration/Average Returns       -28.3004
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.285421
evaluation/Rewards Std              0.988156
evaluation/Rewards Max             -0.0205953
evaluation/Rewards Min            -11.2384
evaluation/Returns Mean           -28.5421
evaluation/Returns Std             22.3649
evaluation/Returns Max             -5.87142
evaluation/Returns Min            -86.0937
evaluation/Actions Mean             0.00604588
evaluation/Actions Std              0.194051
evaluation/Actions Max              0.998783
evaluation/Actions Min             -0.998521
evaluation/Num Paths               15
evaluation/Average Returns        -28.5421
time/data storing (s)               0.00294303
time/evaluation sampling (s)        0.32249
time/exploration sampling (s)       0.142352
time/logging (s)                    0.00486802
time/saving (s)                     0.00195322
time/training (s)                   1.9361
time/epoch (s)                      2.4107
time/total (s)                    351.837
Epoch                             143
-----------------------------  ---------------
2019-04-22 22:42:28.603542 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              72700
trainer/QF1 Loss                   12.8032
trainer/QF2 Loss                   12.5343
trainer/Policy Loss                14.3219
trainer/Q1 Predictions Mean       -12.607
trainer/Q1 Predictions Std         10.1445
trainer/Q1 Predictions Max         -6.62718
trainer/Q1 Predictions Min        -41.1726
trainer/Q2 Predictions Mean       -12.6192
trainer/Q2 Predictions Std         10.124
trainer/Q2 Predictions Max         -6.61712
trainer/Q2 Predictions Min        -41.0298
trainer/Q Targets Mean            -12.2263
trainer/Q Targets Std               9.74127
trainer/Q Targets Max              -2.24929
trainer/Q Targets Min             -40.3078
trainer/Log Pis Mean                1.88258
trainer/Log Pis Std                 1.03849
trainer/Log Pis Max                 4.57595
trainer/Log Pis Min                -1.62761
trainer/Policy mu Mean             -0.0372112
trainer/Policy mu Std               0.634358
trainer/Policy mu Max               2.80093
trainer/Policy mu Min              -2.78703
trainer/Policy log std Mean        -2.07199
trainer/Policy log std Std          0.450638
trainer/Policy log std Max         -0.558
trainer/Policy log std Min         -2.54467
trainer/Alpha                       0.0533145
trainer/Alpha Loss                 -0.344226
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.660371
exploration/Rewards Std             1.11568
exploration/Rewards Max            -0.00339232
exploration/Rewards Min            -9.44772
exploration/Returns Mean          -66.0371
exploration/Returns Std            27.7226
exploration/Returns Max           -28.5099
exploration/Returns Min           -94.8857
exploration/Actions Mean           -0.0194993
exploration/Actions Std             0.249084
exploration/Actions Max             0.9997
exploration/Actions Min            -0.999837
exploration/Num Paths               5
exploration/Average Returns       -66.0371
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.384334
evaluation/Rewards Std              1.10892
evaluation/Rewards Max             -0.0155481
evaluation/Rewards Min             -9.23615
evaluation/Returns Mean           -38.4334
evaluation/Returns Std             22.7762
evaluation/Returns Max             -5.54169
evaluation/Returns Min            -92.0478
evaluation/Actions Mean            -0.00745277
evaluation/Actions Std              0.207198
evaluation/Actions Max              0.997808
evaluation/Actions Min             -0.999402
evaluation/Num Paths               15
evaluation/Average Returns        -38.4334
time/data storing (s)               0.00298136
time/evaluation sampling (s)        0.325228
time/exploration sampling (s)       0.138174
time/logging (s)                    0.00484758
time/saving (s)                     0.00191982
time/training (s)                   1.93523
time/epoch (s)                      2.40838
time/total (s)                    354.25
Epoch                             144
-----------------------------  ---------------
2019-04-22 22:42:31.040864 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                    1.59922
trainer/QF2 Loss                    1.6299
trainer/Policy Loss                15.9032
trainer/Q1 Predictions Mean       -14.106
trainer/Q1 Predictions Std         10.6927
trainer/Q1 Predictions Max         -6.74502
trainer/Q1 Predictions Min        -40.6407
trainer/Q2 Predictions Mean       -14.104
trainer/Q2 Predictions Std         10.699
trainer/Q2 Predictions Max         -6.74676
trainer/Q2 Predictions Min        -40.8524
trainer/Q Targets Mean            -14.0529
trainer/Q Targets Std              10.9544
trainer/Q Targets Max              -0.193391
trainer/Q Targets Min             -40.5355
trainer/Log Pis Mean                2.128
trainer/Log Pis Std                 1.32226
trainer/Log Pis Max                 6.85299
trainer/Log Pis Min                -0.749368
trainer/Policy mu Mean             -0.0626879
trainer/Policy mu Std               0.778413
trainer/Policy mu Max               3.24052
trainer/Policy mu Min              -3.07518
trainer/Policy log std Mean        -2.03407
trainer/Policy log std Std          0.501899
trainer/Policy log std Max         -0.464697
trainer/Policy log std Min         -2.55883
trainer/Alpha                       0.0527586
trainer/Alpha Loss                  0.376607
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.564908
exploration/Rewards Std             1.44597
exploration/Rewards Max            -0.0108341
exploration/Rewards Min           -10.4766
exploration/Returns Mean          -56.4908
exploration/Returns Std            18.6798
exploration/Returns Max           -24.2159
exploration/Returns Min           -76.4227
exploration/Actions Mean            0.0281669
exploration/Actions Std             0.26049
exploration/Actions Max             0.999642
exploration/Actions Min            -0.998923
exploration/Num Paths               5
exploration/Average Returns       -56.4908
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.330904
evaluation/Rewards Std              0.843139
evaluation/Rewards Max             -0.00681272
evaluation/Rewards Min             -9.62617
evaluation/Returns Mean           -33.0904
evaluation/Returns Std             26.9259
evaluation/Returns Max             -1.63813
evaluation/Returns Min            -94.4299
evaluation/Actions Mean            -0.00299028
evaluation/Actions Std              0.168928
evaluation/Actions Max              0.997982
evaluation/Actions Min             -0.999579
evaluation/Num Paths               15
evaluation/Average Returns        -33.0904
time/data storing (s)               0.00271095
time/evaluation sampling (s)        0.326793
time/exploration sampling (s)       0.14096
time/logging (s)                    0.00484524
time/saving (s)                     0.00171611
time/training (s)                   1.95318
time/epoch (s)                      2.43021
time/total (s)                    356.685
Epoch                             145
-----------------------------  ---------------
2019-04-22 22:42:33.460107 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              73700
trainer/QF1 Loss                    0.684716
trainer/QF2 Loss                    0.70873
trainer/Policy Loss                15.9455
trainer/Q1 Predictions Mean       -14.2399
trainer/Q1 Predictions Std         11.1141
trainer/Q1 Predictions Max         -6.80424
trainer/Q1 Predictions Min        -44.7196
trainer/Q2 Predictions Mean       -14.2526
trainer/Q2 Predictions Std         11.118
trainer/Q2 Predictions Max         -6.80004
trainer/Q2 Predictions Min        -44.3527
trainer/Q Targets Mean            -14.2447
trainer/Q Targets Std              11.2453
trainer/Q Targets Max              -0.464302
trainer/Q Targets Min             -45.361
trainer/Log Pis Mean                2.09729
trainer/Log Pis Std                 1.41729
trainer/Log Pis Max                 8.31393
trainer/Log Pis Min                -2.26196
trainer/Policy mu Mean             -0.0163116
trainer/Policy mu Std               0.76087
trainer/Policy mu Max               3.16839
trainer/Policy mu Min              -3.03125
trainer/Policy log std Mean        -2.04041
trainer/Policy log std Std          0.481727
trainer/Policy log std Max         -0.326402
trainer/Policy log std Min         -2.53742
trainer/Alpha                       0.0520298
trainer/Alpha Loss                  0.287577
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.294536
exploration/Rewards Std             0.811948
exploration/Rewards Max            -0.012988
exploration/Rewards Min            -7.03439
exploration/Returns Mean          -29.4536
exploration/Returns Std             8.46394
exploration/Returns Max           -16.7911
exploration/Returns Min           -36.9446
exploration/Actions Mean           -0.00439625
exploration/Actions Std             0.233738
exploration/Actions Max             0.999108
exploration/Actions Min            -0.997588
exploration/Num Paths               5
exploration/Average Returns       -29.4536
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.377487
evaluation/Rewards Std              1.16546
evaluation/Rewards Max             -0.0181042
evaluation/Rewards Min            -10.6423
evaluation/Returns Mean           -37.7487
evaluation/Returns Std             21.3917
evaluation/Returns Max             -5.40204
evaluation/Returns Min            -96.9539
evaluation/Actions Mean             0.00880913
evaluation/Actions Std              0.212696
evaluation/Actions Max              0.999221
evaluation/Actions Min             -0.999535
evaluation/Num Paths               15
evaluation/Average Returns        -37.7487
time/data storing (s)               0.00294015
time/evaluation sampling (s)        0.32309
time/exploration sampling (s)       0.140104
time/logging (s)                    0.00486594
time/saving (s)                     0.00197527
time/training (s)                   1.93918
time/epoch (s)                      2.41216
time/total (s)                    359.101
Epoch                             146
-----------------------------  ---------------
2019-04-22 22:42:35.904740 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 147 finished
-----------------------------  ----------------
replay_buffer/size              74200
trainer/QF1 Loss                    0.574734
trainer/QF2 Loss                    0.565803
trainer/Policy Loss                14.7493
trainer/Q1 Predictions Mean       -12.9984
trainer/Q1 Predictions Std         10.2748
trainer/Q1 Predictions Max         -6.70767
trainer/Q1 Predictions Min        -53.18
trainer/Q2 Predictions Mean       -13.0174
trainer/Q2 Predictions Std         10.2957
trainer/Q2 Predictions Max         -6.74462
trainer/Q2 Predictions Min        -53.1525
trainer/Q Targets Mean            -13.0669
trainer/Q Targets Std              10.4565
trainer/Q Targets Max              -0.0893957
trainer/Q Targets Min             -53.6312
trainer/Log Pis Mean                2.07943
trainer/Log Pis Std                 1.34774
trainer/Log Pis Max                 6.34839
trainer/Log Pis Min                -3.58145
trainer/Policy mu Mean              0.0399989
trainer/Policy mu Std               0.706134
trainer/Policy mu Max               3.30881
trainer/Policy mu Min              -2.58462
trainer/Policy log std Mean        -2.08452
trainer/Policy log std Std          0.450774
trainer/Policy log std Max         -0.489082
trainer/Policy log std Min         -2.56611
trainer/Alpha                       0.0521057
trainer/Alpha Loss                  0.234673
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.416833
exploration/Rewards Std             1.07562
exploration/Rewards Max            -0.000894559
exploration/Rewards Min           -10.1034
exploration/Returns Mean          -41.6833
exploration/Returns Std            19.8428
exploration/Returns Max           -18.7277
exploration/Returns Min           -68.9075
exploration/Actions Mean            0.0141295
exploration/Actions Std             0.232251
exploration/Actions Max             0.999585
exploration/Actions Min            -0.999574
exploration/Num Paths               5
exploration/Average Returns       -41.6833
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.284745
evaluation/Rewards Std              1.04211
evaluation/Rewards Max             -0.00953404
evaluation/Rewards Min            -10.4264
evaluation/Returns Mean           -28.4745
evaluation/Returns Std             14.9939
evaluation/Returns Max             -5.20511
evaluation/Returns Min            -59.7685
evaluation/Actions Mean             0.00787421
evaluation/Actions Std              0.202197
evaluation/Actions Max              0.997977
evaluation/Actions Min             -0.999167
evaluation/Num Paths               15
evaluation/Average Returns        -28.4745
time/data storing (s)               0.00290109
time/evaluation sampling (s)        0.325991
time/exploration sampling (s)       0.142213
time/logging (s)                    0.00359702
time/saving (s)                     0.00154817
time/training (s)                   1.96022
time/epoch (s)                      2.43647
time/total (s)                    361.542
Epoch                             147
-----------------------------  ----------------
2019-04-22 22:42:38.336694 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              74700
trainer/QF1 Loss                    0.10969
trainer/QF2 Loss                    0.0927033
trainer/Policy Loss                15.2569
trainer/Q1 Predictions Mean       -13.6808
trainer/Q1 Predictions Std         10.9029
trainer/Q1 Predictions Max         -6.8146
trainer/Q1 Predictions Min        -48.7342
trainer/Q2 Predictions Mean       -13.6742
trainer/Q2 Predictions Std         10.9286
trainer/Q2 Predictions Max         -6.77449
trainer/Q2 Predictions Min        -49.0135
trainer/Q Targets Mean            -13.8304
trainer/Q Targets Std              11.0347
trainer/Q Targets Max              -6.86786
trainer/Q Targets Min             -51.0391
trainer/Log Pis Mean                1.88254
trainer/Log Pis Std                 1.31796
trainer/Log Pis Max                 5.97798
trainer/Log Pis Min                -1.72609
trainer/Policy mu Mean             -0.0472797
trainer/Policy mu Std               0.65161
trainer/Policy mu Max               3.15647
trainer/Policy mu Min              -3.0817
trainer/Policy log std Mean        -2.10591
trainer/Policy log std Std          0.420052
trainer/Policy log std Max         -0.467734
trainer/Policy log std Min         -2.56114
trainer/Alpha                       0.0529221
trainer/Alpha Loss                 -0.345223
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.267504
exploration/Rewards Std             0.896664
exploration/Rewards Max            -0.00432996
exploration/Rewards Min           -10.2768
exploration/Returns Mean          -26.7504
exploration/Returns Std            16.3207
exploration/Returns Max           -12.8102
exploration/Returns Min           -56.9077
exploration/Actions Mean            0.0241958
exploration/Actions Std             0.217155
exploration/Actions Max             0.998928
exploration/Actions Min            -0.994595
exploration/Num Paths               5
exploration/Average Returns       -26.7504
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.331209
evaluation/Rewards Std              0.810841
evaluation/Rewards Max             -0.0194643
evaluation/Rewards Min             -9.41389
evaluation/Returns Mean           -33.1209
evaluation/Returns Std             22.7481
evaluation/Returns Max             -3.57095
evaluation/Returns Min            -70.2971
evaluation/Actions Mean            -0.00585086
evaluation/Actions Std              0.170164
evaluation/Actions Max              0.996067
evaluation/Actions Min             -0.998589
evaluation/Num Paths               15
evaluation/Average Returns        -33.1209
time/data storing (s)               0.00295041
time/evaluation sampling (s)        0.327254
time/exploration sampling (s)       0.137905
time/logging (s)                    0.00427275
time/saving (s)                     0.00192883
time/training (s)                   1.9527
time/epoch (s)                      2.42701
time/total (s)                    363.973
Epoch                             148
-----------------------------  ---------------
2019-04-22 22:42:40.772414 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                    1.03237
trainer/QF2 Loss                    1.02989
trainer/Policy Loss                16.5565
trainer/Q1 Predictions Mean       -14.6883
trainer/Q1 Predictions Std         11.5116
trainer/Q1 Predictions Max         -6.77546
trainer/Q1 Predictions Min        -50.1723
trainer/Q2 Predictions Mean       -14.6717
trainer/Q2 Predictions Std         11.4996
trainer/Q2 Predictions Max         -6.80515
trainer/Q2 Predictions Min        -50.0485
trainer/Q Targets Mean            -14.4763
trainer/Q Targets Std              11.5326
trainer/Q Targets Max              -0.0698773
trainer/Q Targets Min             -50.6387
trainer/Log Pis Mean                2.03285
trainer/Log Pis Std                 1.30073
trainer/Log Pis Max                 7.67304
trainer/Log Pis Min                -2.22141
trainer/Policy mu Mean              0.0444121
trainer/Policy mu Std               0.731222
trainer/Policy mu Max               3.31127
trainer/Policy mu Min              -2.60045
trainer/Policy log std Mean        -2.0412
trainer/Policy log std Std          0.45701
trainer/Policy log std Max         -0.509169
trainer/Policy log std Min         -2.52692
trainer/Alpha                       0.0521964
trainer/Alpha Loss                  0.0970035
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.341035
exploration/Rewards Std             1.01561
exploration/Rewards Max            -0.00707694
exploration/Rewards Min            -8.61205
exploration/Returns Mean          -34.1035
exploration/Returns Std            15.4968
exploration/Returns Max           -14.0386
exploration/Returns Min           -52.942
exploration/Actions Mean            0.0194538
exploration/Actions Std             0.242923
exploration/Actions Max             0.999294
exploration/Actions Min            -0.999523
exploration/Num Paths               5
exploration/Average Returns       -34.1035
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.34819
evaluation/Rewards Std              0.952862
evaluation/Rewards Max             -0.0307341
evaluation/Rewards Min            -10.339
evaluation/Returns Mean           -34.819
evaluation/Returns Std             22.3733
evaluation/Returns Max             -6.73226
evaluation/Returns Min            -83.6425
evaluation/Actions Mean            -0.0120445
evaluation/Actions Std              0.197009
evaluation/Actions Max              0.997251
evaluation/Actions Min             -0.997965
evaluation/Num Paths               15
evaluation/Average Returns        -34.819
time/data storing (s)               0.00298026
time/evaluation sampling (s)        0.329126
time/exploration sampling (s)       0.138326
time/logging (s)                    0.00488579
time/saving (s)                     0.00196161
time/training (s)                   1.95189
time/epoch (s)                      2.42917
time/total (s)                    366.406
Epoch                             149
-----------------------------  ---------------
2019-04-22 22:42:43.226426 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              75700
trainer/QF1 Loss                    0.80301
trainer/QF2 Loss                    0.806068
trainer/Policy Loss                15.7361
trainer/Q1 Predictions Mean       -14.1375
trainer/Q1 Predictions Std         11.1312
trainer/Q1 Predictions Max         -6.72443
trainer/Q1 Predictions Min        -41.662
trainer/Q2 Predictions Mean       -14.1373
trainer/Q2 Predictions Std         11.121
trainer/Q2 Predictions Max         -6.68581
trainer/Q2 Predictions Min        -41.8629
trainer/Q Targets Mean            -14.3009
trainer/Q Targets Std              11.3621
trainer/Q Targets Max              -0.679254
trainer/Q Targets Min             -42.2282
trainer/Log Pis Mean                1.8621
trainer/Log Pis Std                 1.18417
trainer/Log Pis Max                 5.02956
trainer/Log Pis Min                -2.22642
trainer/Policy mu Mean             -0.0013263
trainer/Policy mu Std               0.47658
trainer/Policy mu Max               3.11572
trainer/Policy mu Min              -2.54657
trainer/Policy log std Mean        -2.1602
trainer/Policy log std Std          0.328259
trainer/Policy log std Max         -0.610322
trainer/Policy log std Min         -2.49275
trainer/Alpha                       0.051665
trainer/Alpha Loss                 -0.408577
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.198167
exploration/Rewards Std             0.342824
exploration/Rewards Max            -0.0106675
exploration/Rewards Min            -4.21474
exploration/Returns Mean          -19.8167
exploration/Returns Std             3.69824
exploration/Returns Max           -14.5359
exploration/Returns Min           -23.8478
exploration/Actions Mean           -0.00507942
exploration/Actions Std             0.186898
exploration/Actions Max             0.999895
exploration/Actions Min            -0.995563
exploration/Num Paths               5
exploration/Average Returns       -19.8167
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.371225
evaluation/Rewards Std              1.06046
evaluation/Rewards Max             -0.0151043
evaluation/Rewards Min            -10.1395
evaluation/Returns Mean           -37.1225
evaluation/Returns Std             19.9681
evaluation/Returns Max             -9.44341
evaluation/Returns Min            -75.7461
evaluation/Actions Mean            -0.00115276
evaluation/Actions Std              0.195926
evaluation/Actions Max              0.999406
evaluation/Actions Min             -0.99897
evaluation/Num Paths               15
evaluation/Average Returns        -37.1225
time/data storing (s)               0.00288998
time/evaluation sampling (s)        0.328003
time/exploration sampling (s)       0.141049
time/logging (s)                    0.00488596
time/saving (s)                     0.00198136
time/training (s)                   1.96853
time/epoch (s)                      2.44733
time/total (s)                    368.858
Epoch                             150
-----------------------------  ---------------
2019-04-22 22:42:45.653630 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              76200
trainer/QF1 Loss                    0.223424
trainer/QF2 Loss                    0.207693
trainer/Policy Loss                16.0911
trainer/Q1 Predictions Mean       -14.2564
trainer/Q1 Predictions Std         12.4486
trainer/Q1 Predictions Max         -6.73131
trainer/Q1 Predictions Min        -62.7141
trainer/Q2 Predictions Mean       -14.2742
trainer/Q2 Predictions Std         12.4711
trainer/Q2 Predictions Max         -6.7771
trainer/Q2 Predictions Min        -63.154
trainer/Q Targets Mean            -14.4689
trainer/Q Targets Std              12.6474
trainer/Q Targets Max              -6.74374
trainer/Q Targets Min             -66.0799
trainer/Log Pis Mean                2.22505
trainer/Log Pis Std                 1.41081
trainer/Log Pis Max                 7.97565
trainer/Log Pis Min                -1.20875
trainer/Policy mu Mean             -0.0982021
trainer/Policy mu Std               0.745964
trainer/Policy mu Max               3.41843
trainer/Policy mu Min              -3.55603
trainer/Policy log std Mean        -2.12314
trainer/Policy log std Std          0.465266
trainer/Policy log std Max         -0.43991
trainer/Policy log std Min         -2.60844
trainer/Alpha                       0.0515044
trainer/Alpha Loss                  0.667556
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.289921
exploration/Rewards Std             0.547992
exploration/Rewards Max            -0.00949671
exploration/Rewards Min            -5.79308
exploration/Returns Mean          -28.9921
exploration/Returns Std            19.5935
exploration/Returns Max           -13.9575
exploration/Returns Min           -67.2628
exploration/Actions Mean           -0.0088188
exploration/Actions Std             0.208917
exploration/Actions Max             0.998705
exploration/Actions Min            -0.997445
exploration/Num Paths               5
exploration/Average Returns       -28.9921
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.249596
evaluation/Rewards Std              0.839155
evaluation/Rewards Max             -0.0296031
evaluation/Rewards Min             -9.51507
evaluation/Returns Mean           -24.9596
evaluation/Returns Std             19.1283
evaluation/Returns Max             -3.18289
evaluation/Returns Min            -57.2065
evaluation/Actions Mean            -0.00924702
evaluation/Actions Std              0.17698
evaluation/Actions Max              0.997086
evaluation/Actions Min             -0.999591
evaluation/Num Paths               15
evaluation/Average Returns        -24.9596
time/data storing (s)               0.00272036
time/evaluation sampling (s)        0.326748
time/exploration sampling (s)       0.142651
time/logging (s)                    0.0048356
time/saving (s)                     0.00167757
time/training (s)                   1.94131
time/epoch (s)                      2.41994
time/total (s)                    371.282
Epoch                             151
-----------------------------  ---------------
2019-04-22 22:42:48.096855 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              76700
trainer/QF1 Loss                    0.930535
trainer/QF2 Loss                    0.949077
trainer/Policy Loss                12.6889
trainer/Q1 Predictions Mean       -10.9752
trainer/Q1 Predictions Std          8.33345
trainer/Q1 Predictions Max         -6.7197
trainer/Q1 Predictions Min        -47.1841
trainer/Q2 Predictions Mean       -10.9827
trainer/Q2 Predictions Std          8.33938
trainer/Q2 Predictions Max         -6.73745
trainer/Q2 Predictions Min        -47.1562
trainer/Q Targets Mean            -10.9608
trainer/Q Targets Std               8.52255
trainer/Q Targets Max              -0.129126
trainer/Q Targets Min             -47.8864
trainer/Log Pis Mean                2.13606
trainer/Log Pis Std                 1.36316
trainer/Log Pis Max                 7.70575
trainer/Log Pis Min                -0.700932
trainer/Policy mu Mean             -0.0537986
trainer/Policy mu Std               0.731048
trainer/Policy mu Max               3.06904
trainer/Policy mu Min              -2.98095
trainer/Policy log std Mean        -2.10385
trainer/Policy log std Std          0.472749
trainer/Policy log std Max         -0.404543
trainer/Policy log std Min         -2.52014
trainer/Alpha                       0.0516379
trainer/Alpha Loss                  0.403209
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.40559
exploration/Rewards Std             1.11308
exploration/Rewards Max            -0.00575856
exploration/Rewards Min            -9.85501
exploration/Returns Mean          -40.559
exploration/Returns Std            14.0641
exploration/Returns Max           -27.1296
exploration/Returns Min           -67.0663
exploration/Actions Mean           -0.00869957
exploration/Actions Std             0.25684
exploration/Actions Max             0.999245
exploration/Actions Min            -0.998841
exploration/Num Paths               5
exploration/Average Returns       -40.559
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.354784
evaluation/Rewards Std              0.92928
evaluation/Rewards Max             -0.00127988
evaluation/Rewards Min             -9.26007
evaluation/Returns Mean           -35.4784
evaluation/Returns Std             23.6315
evaluation/Returns Max             -5.50798
evaluation/Returns Min            -80.7486
evaluation/Actions Mean            -0.00800723
evaluation/Actions Std              0.191384
evaluation/Actions Max              0.998103
evaluation/Actions Min             -0.997703
evaluation/Num Paths               15
evaluation/Average Returns        -35.4784
time/data storing (s)               0.00297442
time/evaluation sampling (s)        0.327914
time/exploration sampling (s)       0.143165
time/logging (s)                    0.00484334
time/saving (s)                     0.00194834
time/training (s)                   1.95518
time/epoch (s)                      2.43603
time/total (s)                    373.723
Epoch                             152
-----------------------------  ---------------
2019-04-22 22:42:50.535703 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              77200
trainer/QF1 Loss                    0.125375
trainer/QF2 Loss                    0.126632
trainer/Policy Loss                15.0565
trainer/Q1 Predictions Mean       -13.28
trainer/Q1 Predictions Std         10.9527
trainer/Q1 Predictions Max         -6.62078
trainer/Q1 Predictions Min        -44.8302
trainer/Q2 Predictions Mean       -13.2564
trainer/Q2 Predictions Std         10.8862
trainer/Q2 Predictions Max         -6.63343
trainer/Q2 Predictions Min        -44.267
trainer/Q Targets Mean            -13.4577
trainer/Q Targets Std              11.0693
trainer/Q Targets Max              -6.64797
trainer/Q Targets Min             -45.6059
trainer/Log Pis Mean                1.9379
trainer/Log Pis Std                 1.13532
trainer/Log Pis Max                 5.91706
trainer/Log Pis Min                -2.31859
trainer/Policy mu Mean              0.0144171
trainer/Policy mu Std               0.656275
trainer/Policy mu Max               3.11138
trainer/Policy mu Min              -3.23316
trainer/Policy log std Mean        -2.09892
trainer/Policy log std Std          0.414231
trainer/Policy log std Max         -0.466476
trainer/Policy log std Min         -2.55427
trainer/Alpha                       0.0531031
trainer/Alpha Loss                 -0.182295
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.357868
exploration/Rewards Std             0.768616
exploration/Rewards Max            -0.0119306
exploration/Rewards Min            -7.45398
exploration/Returns Mean          -35.7868
exploration/Returns Std            21.2974
exploration/Returns Max           -18.5158
exploration/Returns Min           -75.4397
exploration/Actions Mean           -0.00445977
exploration/Actions Std             0.226369
exploration/Actions Max             0.998559
exploration/Actions Min            -0.99883
exploration/Num Paths               5
exploration/Average Returns       -35.7868
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.289879
evaluation/Rewards Std              0.735333
evaluation/Rewards Max             -0.0260129
evaluation/Rewards Min             -7.64923
evaluation/Returns Mean           -28.9879
evaluation/Returns Std             15.4916
evaluation/Returns Max             -5.29414
evaluation/Returns Min            -63.1006
evaluation/Actions Mean            -0.00228346
evaluation/Actions Std              0.178241
evaluation/Actions Max              0.996327
evaluation/Actions Min             -0.997242
evaluation/Num Paths               15
evaluation/Average Returns        -28.9879
time/data storing (s)               0.00289381
time/evaluation sampling (s)        0.32788
time/exploration sampling (s)       0.138185
time/logging (s)                    0.00482775
time/saving (s)                     0.00194432
time/training (s)                   1.95695
time/epoch (s)                      2.43268
time/total (s)                    376.159
Epoch                             153
-----------------------------  ---------------
2019-04-22 22:42:52.982527 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              77700
trainer/QF1 Loss                    0.245085
trainer/QF2 Loss                    0.328214
trainer/Policy Loss                15.6247
trainer/Q1 Predictions Mean       -14.0054
trainer/Q1 Predictions Std         12.8519
trainer/Q1 Predictions Max         -6.42023
trainer/Q1 Predictions Min        -62.7653
trainer/Q2 Predictions Mean       -14.002
trainer/Q2 Predictions Std         12.7796
trainer/Q2 Predictions Max         -6.44022
trainer/Q2 Predictions Min        -61.5118
trainer/Q Targets Mean            -14.2595
trainer/Q Targets Std              13.1325
trainer/Q Targets Max              -6.5792
trainer/Q Targets Min             -63.5724
trainer/Log Pis Mean                2.08313
trainer/Log Pis Std                 1.45769
trainer/Log Pis Max                 8.66347
trainer/Log Pis Min                -1.36502
trainer/Policy mu Mean             -0.0551631
trainer/Policy mu Std               0.745552
trainer/Policy mu Max               3.29544
trainer/Policy mu Min              -3.6235
trainer/Policy log std Mean        -2.10646
trainer/Policy log std Std          0.505451
trainer/Policy log std Max         -0.107242
trainer/Policy log std Min         -2.54411
trainer/Alpha                       0.053131
trainer/Alpha Loss                  0.24397
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.384129
exploration/Rewards Std             0.8039
exploration/Rewards Max            -0.00337568
exploration/Rewards Min            -7.41139
exploration/Returns Mean          -38.4129
exploration/Returns Std            17.9152
exploration/Returns Max           -22.2216
exploration/Returns Min           -71.3014
exploration/Actions Mean            0.0046954
exploration/Actions Std             0.228177
exploration/Actions Max             0.999121
exploration/Actions Min            -0.997723
exploration/Num Paths               5
exploration/Average Returns       -38.4129
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.342889
evaluation/Rewards Std              0.775453
evaluation/Rewards Max             -0.00876535
evaluation/Rewards Min             -8.35259
evaluation/Returns Mean           -34.2889
evaluation/Returns Std             25.9489
evaluation/Returns Max             -5.51944
evaluation/Returns Min            -78.2855
evaluation/Actions Mean            -0.00990121
evaluation/Actions Std              0.178146
evaluation/Actions Max              0.996883
evaluation/Actions Min             -0.997787
evaluation/Num Paths               15
evaluation/Average Returns        -34.2889
time/data storing (s)               0.00288052
time/evaluation sampling (s)        0.321346
time/exploration sampling (s)       0.141578
time/logging (s)                    0.00365816
time/saving (s)                     0.00238639
time/training (s)                   1.96633
time/epoch (s)                      2.43818
time/total (s)                    378.602
Epoch                             154
-----------------------------  ---------------
2019-04-22 22:42:55.426191 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 155 finished
-----------------------------  ----------------
replay_buffer/size              78200
trainer/QF1 Loss                    0.510431
trainer/QF2 Loss                    0.567041
trainer/Policy Loss                16.7467
trainer/Q1 Predictions Mean       -14.942
trainer/Q1 Predictions Std         11.8289
trainer/Q1 Predictions Max         -6.58129
trainer/Q1 Predictions Min        -51.5064
trainer/Q2 Predictions Mean       -14.9037
trainer/Q2 Predictions Std         11.7596
trainer/Q2 Predictions Max         -6.58398
trainer/Q2 Predictions Min        -50.3663
trainer/Q Targets Mean            -15.0324
trainer/Q Targets Std              11.9919
trainer/Q Targets Max              -0.220091
trainer/Q Targets Min             -53.3471
trainer/Log Pis Mean                2.06445
trainer/Log Pis Std                 1.2386
trainer/Log Pis Max                 5.76115
trainer/Log Pis Min                -1.54531
trainer/Policy mu Mean              0.0184909
trainer/Policy mu Std               0.762447
trainer/Policy mu Max               3.04161
trainer/Policy mu Min              -3.22663
trainer/Policy log std Mean        -2.04799
trainer/Policy log std Std          0.483581
trainer/Policy log std Max         -0.37848
trainer/Policy log std Min         -2.61545
trainer/Alpha                       0.0532048
trainer/Alpha Loss                  0.189062
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.436141
exploration/Rewards Std             1.04629
exploration/Rewards Max            -0.00929631
exploration/Rewards Min            -9.29904
exploration/Returns Mean          -43.6141
exploration/Returns Std            12.8875
exploration/Returns Max           -29.3697
exploration/Returns Min           -64.8134
exploration/Actions Mean            0.000506497
exploration/Actions Std             0.237275
exploration/Actions Max             0.999178
exploration/Actions Min            -0.999363
exploration/Num Paths               5
exploration/Average Returns       -43.6141
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.321441
evaluation/Rewards Std              1.12266
evaluation/Rewards Max             -0.0146422
evaluation/Rewards Min            -10.3621
evaluation/Returns Mean           -32.1441
evaluation/Returns Std             15.587
evaluation/Returns Max             -9.15144
evaluation/Returns Min            -59.2994
evaluation/Actions Mean             0.0130462
evaluation/Actions Std              0.200046
evaluation/Actions Max              0.997735
evaluation/Actions Min             -0.997635
evaluation/Num Paths               15
evaluation/Average Returns        -32.1441
time/data storing (s)               0.00284296
time/evaluation sampling (s)        0.327348
time/exploration sampling (s)       0.14
time/logging (s)                    0.00487688
time/saving (s)                     0.00193172
time/training (s)                   1.96101
time/epoch (s)                      2.43801
time/total (s)                    381.044
Epoch                             155
-----------------------------  ----------------
2019-04-22 22:42:57.856349 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 156 finished
-----------------------------  ----------------
replay_buffer/size              78700
trainer/QF1 Loss                    0.0769214
trainer/QF2 Loss                    0.0838496
trainer/Policy Loss                15.1251
trainer/Q1 Predictions Mean       -13.1745
trainer/Q1 Predictions Std         10.7425
trainer/Q1 Predictions Max         -6.50501
trainer/Q1 Predictions Min        -39.1751
trainer/Q2 Predictions Mean       -13.2091
trainer/Q2 Predictions Std         10.8002
trainer/Q2 Predictions Max         -6.51998
trainer/Q2 Predictions Min        -39.4023
trainer/Q Targets Mean            -13.2906
trainer/Q Targets Std              10.7844
trainer/Q Targets Max              -6.58594
trainer/Q Targets Min             -39.2649
trainer/Log Pis Mean                2.16879
trainer/Log Pis Std                 1.05938
trainer/Log Pis Max                 6.71219
trainer/Log Pis Min                -1.38501
trainer/Policy mu Mean             -0.0750313
trainer/Policy mu Std               0.589965
trainer/Policy mu Max               3.06494
trainer/Policy mu Min              -2.78767
trainer/Policy log std Mean        -2.1722
trainer/Policy log std Std          0.406448
trainer/Policy log std Max         -0.460016
trainer/Policy log std Min         -2.5762
trainer/Alpha                       0.0545178
trainer/Alpha Loss                  0.491057
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.409692
exploration/Rewards Std             0.998976
exploration/Rewards Max            -0.0115673
exploration/Rewards Min            -8.74867
exploration/Returns Mean          -40.9692
exploration/Returns Std            21.3289
exploration/Returns Max           -14.5023
exploration/Returns Min           -77.557
exploration/Actions Mean           -0.00659363
exploration/Actions Std             0.236544
exploration/Actions Max             0.999517
exploration/Actions Min            -0.999596
exploration/Num Paths               5
exploration/Average Returns       -40.9692
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.320657
evaluation/Rewards Std              1.06397
evaluation/Rewards Max             -0.00926
evaluation/Rewards Min            -10.9354
evaluation/Returns Mean           -32.0657
evaluation/Returns Std             26.6779
evaluation/Returns Max             -6.28343
evaluation/Returns Min            -87.6365
evaluation/Actions Mean             5.23753e-05
evaluation/Actions Std              0.204422
evaluation/Actions Max              0.998436
evaluation/Actions Min             -0.998174
evaluation/Num Paths               15
evaluation/Average Returns        -32.0657
time/data storing (s)               0.0026905
time/evaluation sampling (s)        0.323437
time/exploration sampling (s)       0.138255
time/logging (s)                    0.00483005
time/saving (s)                     0.00157824
time/training (s)                   1.95212
time/epoch (s)                      2.42291
time/total (s)                    383.472
Epoch                             156
-----------------------------  ----------------
2019-04-22 22:43:00.311134 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              79200
trainer/QF1 Loss                    0.272082
trainer/QF2 Loss                    0.261994
trainer/Policy Loss                15.8147
trainer/Q1 Predictions Mean       -14.0983
trainer/Q1 Predictions Std         11.0424
trainer/Q1 Predictions Max         -6.59383
trainer/Q1 Predictions Min        -47.3955
trainer/Q2 Predictions Mean       -14.0805
trainer/Q2 Predictions Std         11.0596
trainer/Q2 Predictions Max         -6.5765
trainer/Q2 Predictions Min        -47.4943
trainer/Q Targets Mean            -14.3317
trainer/Q Targets Std              11.3935
trainer/Q Targets Max              -6.57218
trainer/Q Targets Min             -47.2594
trainer/Log Pis Mean                2.01906
trainer/Log Pis Std                 1.53162
trainer/Log Pis Max                10.189
trainer/Log Pis Min                -1.48042
trainer/Policy mu Mean              0.0757499
trainer/Policy mu Std               0.767361
trainer/Policy mu Max               3.55046
trainer/Policy mu Min              -2.93484
trainer/Policy log std Mean        -2.08629
trainer/Policy log std Std          0.484081
trainer/Policy log std Max         -0.318023
trainer/Policy log std Min         -2.552
trainer/Alpha                       0.0546011
trainer/Alpha Loss                  0.0554155
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.452354
exploration/Rewards Std             1.11964
exploration/Rewards Max            -0.00683904
exploration/Rewards Min            -9.80585
exploration/Returns Mean          -45.2354
exploration/Returns Std            23.4019
exploration/Returns Max           -21.2189
exploration/Returns Min           -83.2347
exploration/Actions Mean            0.0179468
exploration/Actions Std             0.244451
exploration/Actions Max             0.999457
exploration/Actions Min            -0.999043
exploration/Num Paths               5
exploration/Average Returns       -45.2354
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.253325
evaluation/Rewards Std              0.943428
evaluation/Rewards Max             -0.00807912
evaluation/Rewards Min            -10.5442
evaluation/Returns Mean           -25.3325
evaluation/Returns Std             17.0444
evaluation/Returns Max             -4.90732
evaluation/Returns Min            -58.2317
evaluation/Actions Mean             0.0170265
evaluation/Actions Std              0.188495
evaluation/Actions Max              0.997952
evaluation/Actions Min             -0.994912
evaluation/Num Paths               15
evaluation/Average Returns        -25.3325
time/data storing (s)               0.0027164
time/evaluation sampling (s)        0.330978
time/exploration sampling (s)       0.139142
time/logging (s)                    0.00484234
time/saving (s)                     0.00192114
time/training (s)                   1.96788
time/epoch (s)                      2.44748
time/total (s)                    385.924
Epoch                             157
-----------------------------  ---------------
2019-04-22 22:43:02.808737 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              79700
trainer/QF1 Loss                    0.662598
trainer/QF2 Loss                    0.669233
trainer/Policy Loss                14.4662
trainer/Q1 Predictions Mean       -12.9013
trainer/Q1 Predictions Std         10.3001
trainer/Q1 Predictions Max         -6.50173
trainer/Q1 Predictions Min        -56.4188
trainer/Q2 Predictions Mean       -12.9288
trainer/Q2 Predictions Std         10.3095
trainer/Q2 Predictions Max         -6.49725
trainer/Q2 Predictions Min        -56.2727
trainer/Q Targets Mean            -12.8887
trainer/Q Targets Std              10.3348
trainer/Q Targets Max              -0.129841
trainer/Q Targets Min             -56.9986
trainer/Log Pis Mean                1.99834
trainer/Log Pis Std                 1.14564
trainer/Log Pis Max                 5.9585
trainer/Log Pis Min                -2.0357
trainer/Policy mu Mean             -0.0249896
trainer/Policy mu Std               0.779254
trainer/Policy mu Max               3.09025
trainer/Policy mu Min              -2.68354
trainer/Policy log std Mean        -2.03708
trainer/Policy log std Std          0.518577
trainer/Policy log std Max         -0.482645
trainer/Policy log std Min         -2.54491
trainer/Alpha                       0.05452
trainer/Alpha Loss                 -0.00484149
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.525498
exploration/Rewards Std             1.18778
exploration/Rewards Max            -0.00973271
exploration/Rewards Min           -10.6935
exploration/Returns Mean          -52.5498
exploration/Returns Std            12.4375
exploration/Returns Max           -30.1408
exploration/Returns Min           -67.1226
exploration/Actions Mean           -0.0166989
exploration/Actions Std             0.251794
exploration/Actions Max             0.998742
exploration/Actions Min            -0.999164
exploration/Num Paths               5
exploration/Average Returns       -52.5498
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.322579
evaluation/Rewards Std              0.86293
evaluation/Rewards Max             -0.00148874
evaluation/Rewards Min             -8.84163
evaluation/Returns Mean           -32.2579
evaluation/Returns Std             19.6903
evaluation/Returns Max             -3.34687
evaluation/Returns Min            -77.8734
evaluation/Actions Mean            -0.00162782
evaluation/Actions Std              0.188432
evaluation/Actions Max              0.997716
evaluation/Actions Min             -0.999187
evaluation/Num Paths               15
evaluation/Average Returns        -32.2579
time/data storing (s)               0.00291492
time/evaluation sampling (s)        0.32803
time/exploration sampling (s)       0.146823
time/logging (s)                    0.0048508
time/saving (s)                     0.00168806
time/training (s)                   2.00602
time/epoch (s)                      2.49033
time/total (s)                    388.419
Epoch                             158
-----------------------------  ---------------
2019-04-22 22:43:05.262677 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    0.0523473
trainer/QF2 Loss                    0.0857654
trainer/Policy Loss                14.9966
trainer/Q1 Predictions Mean       -13.211
trainer/Q1 Predictions Std         12.3574
trainer/Q1 Predictions Max         -6.40486
trainer/Q1 Predictions Min        -71.1521
trainer/Q2 Predictions Mean       -13.1832
trainer/Q2 Predictions Std         12.2932
trainer/Q2 Predictions Max         -6.40205
trainer/Q2 Predictions Min        -71.2416
trainer/Q Targets Mean            -13.2559
trainer/Q Targets Std              12.3477
trainer/Q Targets Max              -6.62978
trainer/Q Targets Min             -71.9444
trainer/Log Pis Mean                2.07069
trainer/Log Pis Std                 1.64833
trainer/Log Pis Max                 8.47778
trainer/Log Pis Min                -2.18321
trainer/Policy mu Mean             -0.0605249
trainer/Policy mu Std               0.808842
trainer/Policy mu Max               3.15414
trainer/Policy mu Min              -4.32281
trainer/Policy log std Mean        -2.03347
trainer/Policy log std Std          0.488507
trainer/Policy log std Max         -0.477665
trainer/Policy log std Min         -2.5084
trainer/Alpha                       0.0534707
trainer/Alpha Loss                  0.207014
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.439722
exploration/Rewards Std             1.17721
exploration/Rewards Max            -0.0112827
exploration/Rewards Min            -9.72424
exploration/Returns Mean          -43.9722
exploration/Returns Std            27.6746
exploration/Returns Max           -13.3721
exploration/Returns Min           -87.7854
exploration/Actions Mean           -0.00164235
exploration/Actions Std             0.231228
exploration/Actions Max             0.999059
exploration/Actions Min            -0.999731
exploration/Num Paths               5
exploration/Average Returns       -43.9722
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298379
evaluation/Rewards Std              0.927072
evaluation/Rewards Max             -0.0192241
evaluation/Rewards Min             -9.6366
evaluation/Returns Mean           -29.8379
evaluation/Returns Std             16.8647
evaluation/Returns Max             -4.79352
evaluation/Returns Min            -63.0961
evaluation/Actions Mean             0.0100598
evaluation/Actions Std              0.198413
evaluation/Actions Max              0.998165
evaluation/Actions Min             -0.996334
evaluation/Num Paths               15
evaluation/Average Returns        -29.8379
time/data storing (s)               0.0028218
time/evaluation sampling (s)        0.331337
time/exploration sampling (s)       0.143547
time/logging (s)                    0.00387932
time/saving (s)                     0.00158558
time/training (s)                   1.96251
time/epoch (s)                      2.44568
time/total (s)                    390.869
Epoch                             159
-----------------------------  ---------------
2019-04-22 22:43:07.702931 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              80700
trainer/QF1 Loss                    0.917283
trainer/QF2 Loss                    0.898197
trainer/Policy Loss                13.9428
trainer/Q1 Predictions Mean       -12.2249
trainer/Q1 Predictions Std          9.58646
trainer/Q1 Predictions Max         -6.59897
trainer/Q1 Predictions Min        -38.1759
trainer/Q2 Predictions Mean       -12.2247
trainer/Q2 Predictions Std          9.58022
trainer/Q2 Predictions Max         -6.58628
trainer/Q2 Predictions Min        -37.1455
trainer/Q Targets Mean            -12.3378
trainer/Q Targets Std               9.86904
trainer/Q Targets Max              -0.305663
trainer/Q Targets Min             -37.9522
trainer/Log Pis Mean                2.06332
trainer/Log Pis Std                 1.66335
trainer/Log Pis Max                 8.30737
trainer/Log Pis Min                -3.47291
trainer/Policy mu Mean              0.0200606
trainer/Policy mu Std               0.762269
trainer/Policy mu Max               3.00504
trainer/Policy mu Min              -3.27087
trainer/Policy log std Mean        -2.10074
trainer/Policy log std Std          0.518312
trainer/Policy log std Max         -0.514592
trainer/Policy log std Min         -2.5906
trainer/Alpha                       0.054378
trainer/Alpha Loss                  0.184399
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.34862
exploration/Rewards Std             0.972252
exploration/Rewards Max            -0.00407433
exploration/Rewards Min            -8.07659
exploration/Returns Mean          -34.862
exploration/Returns Std            11.5417
exploration/Returns Max           -21.4766
exploration/Returns Min           -49.4626
exploration/Actions Mean           -0.00121034
exploration/Actions Std             0.24521
exploration/Actions Max             0.998358
exploration/Actions Min            -0.999176
exploration/Num Paths               5
exploration/Average Returns       -34.862
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.344822
evaluation/Rewards Std              1.1374
evaluation/Rewards Max             -0.0153285
evaluation/Rewards Min            -12.154
evaluation/Returns Mean           -34.4822
evaluation/Returns Std             20.7408
evaluation/Returns Max             -9.022
evaluation/Returns Min            -73.5726
evaluation/Actions Mean             0.0176212
evaluation/Actions Std              0.213105
evaluation/Actions Max              0.999332
evaluation/Actions Min             -0.997789
evaluation/Num Paths               15
evaluation/Average Returns        -34.4822
time/data storing (s)               0.00287465
time/evaluation sampling (s)        0.326219
time/exploration sampling (s)       0.140259
time/logging (s)                    0.00483256
time/saving (s)                     0.00196359
time/training (s)                   1.95825
time/epoch (s)                      2.4344
time/total (s)                    393.308
Epoch                             160
-----------------------------  ---------------
2019-04-22 22:43:10.156911 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              81200
trainer/QF1 Loss                    0.0533105
trainer/QF2 Loss                    0.129937
trainer/Policy Loss                14.0788
trainer/Q1 Predictions Mean       -12.4887
trainer/Q1 Predictions Std         10.2624
trainer/Q1 Predictions Max         -6.4492
trainer/Q1 Predictions Min        -54.0934
trainer/Q2 Predictions Mean       -12.4502
trainer/Q2 Predictions Std         10.2141
trainer/Q2 Predictions Max         -6.42163
trainer/Q2 Predictions Min        -52.4105
trainer/Q Targets Mean            -12.4984
trainer/Q Targets Std              10.2095
trainer/Q Targets Max              -6.51092
trainer/Q Targets Min             -55.1575
trainer/Log Pis Mean                1.87204
trainer/Log Pis Std                 1.19935
trainer/Log Pis Max                 5.69161
trainer/Log Pis Min                -2.3525
trainer/Policy mu Mean             -0.0332518
trainer/Policy mu Std               0.64157
trainer/Policy mu Max               3.19999
trainer/Policy mu Min              -3.30229
trainer/Policy log std Mean        -2.07767
trainer/Policy log std Std          0.42538
trainer/Policy log std Max         -0.442038
trainer/Policy log std Min         -2.48666
trainer/Alpha                       0.0535138
trainer/Alpha Loss                 -0.374618
exploration/num steps total     81200
exploration/num paths total       812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.523436
exploration/Rewards Std             1.26027
exploration/Rewards Max            -0.0226045
exploration/Rewards Min           -10.7586
exploration/Returns Mean          -52.3436
exploration/Returns Std            12.9612
exploration/Returns Max           -29.9762
exploration/Returns Min           -69.3534
exploration/Actions Mean           -0.0208767
exploration/Actions Std             0.262876
exploration/Actions Max             0.999387
exploration/Actions Min            -0.999716
exploration/Num Paths               5
exploration/Average Returns       -52.3436
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.330044
evaluation/Rewards Std              0.895026
evaluation/Rewards Max             -0.00512489
evaluation/Rewards Min             -9.22764
evaluation/Returns Mean           -33.0044
evaluation/Returns Std             21.2981
evaluation/Returns Max             -1.22207
evaluation/Returns Min            -70.2873
evaluation/Actions Mean            -0.0066602
evaluation/Actions Std              0.199054
evaluation/Actions Max              0.996558
evaluation/Actions Min             -0.998602
evaluation/Num Paths               15
evaluation/Average Returns        -33.0044
time/data storing (s)               0.00291452
time/evaluation sampling (s)        0.330059
time/exploration sampling (s)       0.144751
time/logging (s)                    0.00481598
time/saving (s)                     0.00194734
time/training (s)                   1.96215
time/epoch (s)                      2.44664
time/total (s)                    395.759
Epoch                             161
-----------------------------  ---------------
2019-04-22 22:43:12.618548 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              81700
trainer/QF1 Loss                    1.60575
trainer/QF2 Loss                    1.63394
trainer/Policy Loss                15.8324
trainer/Q1 Predictions Mean       -14.1244
trainer/Q1 Predictions Std         11.6711
trainer/Q1 Predictions Max         -6.34567
trainer/Q1 Predictions Min        -50.6445
trainer/Q2 Predictions Mean       -14.106
trainer/Q2 Predictions Std         11.6299
trainer/Q2 Predictions Max         -6.37047
trainer/Q2 Predictions Min        -50.5016
trainer/Q Targets Mean            -14.0861
trainer/Q Targets Std              12.0002
trainer/Q Targets Max              -0.0814272
trainer/Q Targets Min             -52.5015
trainer/Log Pis Mean                1.9563
trainer/Log Pis Std                 1.42678
trainer/Log Pis Max                 7.6272
trainer/Log Pis Min                -2.7701
trainer/Policy mu Mean              0.0273616
trainer/Policy mu Std               0.782603
trainer/Policy mu Max               3.38448
trainer/Policy mu Min              -3.11592
trainer/Policy log std Mean        -2.06578
trainer/Policy log std Std          0.527965
trainer/Policy log std Max         -0.42018
trainer/Policy log std Min         -2.54102
trainer/Alpha                       0.0541477
trainer/Alpha Loss                 -0.127441
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.422816
exploration/Rewards Std             0.72072
exploration/Rewards Max            -0.00146288
exploration/Rewards Min            -6.7325
exploration/Returns Mean          -42.2816
exploration/Returns Std            20.8916
exploration/Returns Max           -21.041
exploration/Returns Min           -74.2309
exploration/Actions Mean            0.0104266
exploration/Actions Std             0.211019
exploration/Actions Max             0.998509
exploration/Actions Min            -0.999276
exploration/Num Paths               5
exploration/Average Returns       -42.2816
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.306209
evaluation/Rewards Std              0.887139
evaluation/Rewards Max             -0.0318689
evaluation/Rewards Min             -8.89379
evaluation/Returns Mean           -30.6209
evaluation/Returns Std             24.2855
evaluation/Returns Max             -3.60039
evaluation/Returns Min            -78.2936
evaluation/Actions Mean             0.00110002
evaluation/Actions Std              0.181235
evaluation/Actions Max              0.99861
evaluation/Actions Min             -0.998352
evaluation/Num Paths               15
evaluation/Average Returns        -30.6209
time/data storing (s)               0.00299647
time/evaluation sampling (s)        0.326298
time/exploration sampling (s)       0.140524
time/logging (s)                    0.00486812
time/saving (s)                     0.010506
time/training (s)                   1.96974
time/epoch (s)                      2.45493
time/total (s)                    398.218
Epoch                             162
-----------------------------  ---------------
2019-04-22 22:43:15.058416 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              82200
trainer/QF1 Loss                   10.2084
trainer/QF2 Loss                   10.1776
trainer/Policy Loss                15.0965
trainer/Q1 Predictions Mean       -13.6049
trainer/Q1 Predictions Std         11.2799
trainer/Q1 Predictions Max         -6.39363
trainer/Q1 Predictions Min        -61.6171
trainer/Q2 Predictions Mean       -13.6152
trainer/Q2 Predictions Std         11.3006
trainer/Q2 Predictions Max         -6.45004
trainer/Q2 Predictions Min        -62.0798
trainer/Q Targets Mean            -13.4195
trainer/Q Targets Std              11.1766
trainer/Q Targets Max              -0.63983
trainer/Q Targets Min             -62.0727
trainer/Log Pis Mean                1.93133
trainer/Log Pis Std                 1.45332
trainer/Log Pis Max                 6.33043
trainer/Log Pis Min                -2.35168
trainer/Policy mu Mean             -0.023333
trainer/Policy mu Std               0.682524
trainer/Policy mu Max               2.73729
trainer/Policy mu Min              -3.37675
trainer/Policy log std Mean        -2.1084
trainer/Policy log std Std          0.483943
trainer/Policy log std Max         -0.404631
trainer/Policy log std Min         -2.58188
trainer/Alpha                       0.0540246
trainer/Alpha Loss                 -0.200411
exploration/num steps total     82200
exploration/num paths total       822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.447557
exploration/Rewards Std             1.17555
exploration/Rewards Max            -0.00867941
exploration/Rewards Min            -9.91294
exploration/Returns Mean          -44.7557
exploration/Returns Std            28.5116
exploration/Returns Max           -17.7945
exploration/Returns Min           -94.816
exploration/Actions Mean           -0.0126072
exploration/Actions Std             0.255586
exploration/Actions Max             0.998854
exploration/Actions Min            -0.999637
exploration/Num Paths               5
exploration/Average Returns       -44.7557
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.401347
evaluation/Rewards Std              1.0396
evaluation/Rewards Max             -0.0104323
evaluation/Rewards Min            -10.9209
evaluation/Returns Mean           -40.1347
evaluation/Returns Std             28.0801
evaluation/Returns Max             -1.51256
evaluation/Returns Min            -94.1545
evaluation/Actions Mean            -0.0117371
evaluation/Actions Std              0.196501
evaluation/Actions Max              0.998087
evaluation/Actions Min             -0.999553
evaluation/Num Paths               15
evaluation/Average Returns        -40.1347
time/data storing (s)               0.00278682
time/evaluation sampling (s)        0.324874
time/exploration sampling (s)       0.13973
time/logging (s)                    0.00488395
time/saving (s)                     0.00194753
time/training (s)                   1.95832
time/epoch (s)                      2.43254
time/total (s)                    400.655
Epoch                             163
-----------------------------  ---------------
2019-04-22 22:43:17.495573 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              82700
trainer/QF1 Loss                   11.8537
trainer/QF2 Loss                   11.7901
trainer/Policy Loss                16.48
trainer/Q1 Predictions Mean       -14.7221
trainer/Q1 Predictions Std         10.9494
trainer/Q1 Predictions Max         -6.32578
trainer/Q1 Predictions Min        -39.305
trainer/Q2 Predictions Mean       -14.7025
trainer/Q2 Predictions Std         10.9327
trainer/Q2 Predictions Max         -6.31255
trainer/Q2 Predictions Min        -38.7639
trainer/Q Targets Mean            -14.356
trainer/Q Targets Std              10.9031
trainer/Q Targets Max              -0.702486
trainer/Q Targets Min             -39.1515
trainer/Log Pis Mean                2.03422
trainer/Log Pis Std                 1.02435
trainer/Log Pis Max                 5.05391
trainer/Log Pis Min                -1.87672
trainer/Policy mu Mean             -0.0510087
trainer/Policy mu Std               0.733408
trainer/Policy mu Max               2.88657
trainer/Policy mu Min              -3.00176
trainer/Policy log std Mean        -2.05962
trainer/Policy log std Std          0.488049
trainer/Policy log std Max         -0.407554
trainer/Policy log std Min         -2.54546
trainer/Alpha                       0.0534091
trainer/Alpha Loss                  0.10026
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.39444
exploration/Rewards Std             1.02609
exploration/Rewards Max            -0.00390802
exploration/Rewards Min           -10.1577
exploration/Returns Mean          -39.444
exploration/Returns Std            12.4468
exploration/Returns Max           -18.8363
exploration/Returns Min           -54.0433
exploration/Actions Mean            0.00643215
exploration/Actions Std             0.248488
exploration/Actions Max             0.998831
exploration/Actions Min            -0.997828
exploration/Num Paths               5
exploration/Average Returns       -39.444
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.367685
evaluation/Rewards Std              1.18091
evaluation/Rewards Max             -0.0105721
evaluation/Rewards Min            -10.4039
evaluation/Returns Mean           -36.7685
evaluation/Returns Std             20.4271
evaluation/Returns Max             -8.16596
evaluation/Returns Min            -70.1743
evaluation/Actions Mean            -0.0121064
evaluation/Actions Std              0.207023
evaluation/Actions Max              0.999135
evaluation/Actions Min             -0.999507
evaluation/Num Paths               15
evaluation/Average Returns        -36.7685
time/data storing (s)               0.00293795
time/evaluation sampling (s)        0.321425
time/exploration sampling (s)       0.145866
time/logging (s)                    0.00484821
time/saving (s)                     0.00193737
time/training (s)                   1.95268
time/epoch (s)                      2.4297
time/total (s)                    403.089
Epoch                             164
-----------------------------  ---------------
2019-04-22 22:43:19.907420 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              83200
trainer/QF1 Loss                    0.0630882
trainer/QF2 Loss                    0.0679171
trainer/Policy Loss                15.7924
trainer/Q1 Predictions Mean       -13.9953
trainer/Q1 Predictions Std         11.1979
trainer/Q1 Predictions Max         -6.31523
trainer/Q1 Predictions Min        -49.398
trainer/Q2 Predictions Mean       -14.03
trainer/Q2 Predictions Std         11.1652
trainer/Q2 Predictions Max         -6.28755
trainer/Q2 Predictions Min        -49.3164
trainer/Q Targets Mean            -14.1834
trainer/Q Targets Std              11.1345
trainer/Q Targets Max              -6.43796
trainer/Q Targets Min             -49.7281
trainer/Log Pis Mean                1.97629
trainer/Log Pis Std                 1.16561
trainer/Log Pis Max                 6.0843
trainer/Log Pis Min                -1.11225
trainer/Policy mu Mean             -0.0742014
trainer/Policy mu Std               0.624006
trainer/Policy mu Max               3.0229
trainer/Policy mu Min              -3.41861
trainer/Policy log std Mean        -2.14339
trainer/Policy log std Std          0.411974
trainer/Policy log std Max         -0.522237
trainer/Policy log std Min         -2.52851
trainer/Alpha                       0.0552542
trainer/Alpha Loss                 -0.0686672
exploration/num steps total     83200
exploration/num paths total       832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.235932
exploration/Rewards Std             0.580096
exploration/Rewards Max            -0.00347641
exploration/Rewards Min            -6.20591
exploration/Returns Mean          -23.5932
exploration/Returns Std             7.25415
exploration/Returns Max           -13.3276
exploration/Returns Min           -34.2905
exploration/Actions Mean            0.00135581
exploration/Actions Std             0.215564
exploration/Actions Max             0.990648
exploration/Actions Min            -0.998817
exploration/Num Paths               5
exploration/Average Returns       -23.5932
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30964
evaluation/Rewards Std              0.8216
evaluation/Rewards Max             -0.0374195
evaluation/Rewards Min            -10.3768
evaluation/Returns Mean           -30.964
evaluation/Returns Std             20.9117
evaluation/Returns Max             -6.77049
evaluation/Returns Min            -76.2249
evaluation/Actions Mean            -0.00758085
evaluation/Actions Std              0.171756
evaluation/Actions Max              0.997259
evaluation/Actions Min             -0.999082
evaluation/Num Paths               15
evaluation/Average Returns        -30.964
time/data storing (s)               0.00275699
time/evaluation sampling (s)        0.3249
time/exploration sampling (s)       0.138273
time/logging (s)                    0.00484245
time/saving (s)                     0.00196834
time/training (s)                   1.93225
time/epoch (s)                      2.40499
time/total (s)                    405.499
Epoch                             165
-----------------------------  ---------------
2019-04-22 22:43:22.354058 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              83700
trainer/QF1 Loss                    0.0632115
trainer/QF2 Loss                    0.0788618
trainer/Policy Loss                14.6419
trainer/Q1 Predictions Mean       -12.9253
trainer/Q1 Predictions Std          9.99596
trainer/Q1 Predictions Max         -6.46695
trainer/Q1 Predictions Min        -38.3211
trainer/Q2 Predictions Mean       -12.928
trainer/Q2 Predictions Std         10.0026
trainer/Q2 Predictions Max         -6.43951
trainer/Q2 Predictions Min        -38.1834
trainer/Q Targets Mean            -12.9903
trainer/Q Targets Std               9.99066
trainer/Q Targets Max              -6.40096
trainer/Q Targets Min             -37.3583
trainer/Log Pis Mean                2.0426
trainer/Log Pis Std                 1.36278
trainer/Log Pis Max                 8.39658
trainer/Log Pis Min                -2.49421
trainer/Policy mu Mean             -0.0793861
trainer/Policy mu Std               0.624271
trainer/Policy mu Max               2.80206
trainer/Policy mu Min              -2.97738
trainer/Policy log std Mean        -2.13316
trainer/Policy log std Std          0.44752
trainer/Policy log std Max         -0.390788
trainer/Policy log std Min         -2.58848
trainer/Alpha                       0.0542285
trainer/Alpha Loss                  0.124155
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.456054
exploration/Rewards Std             1.13246
exploration/Rewards Max            -0.0053549
exploration/Rewards Min            -9.80235
exploration/Returns Mean          -45.6054
exploration/Returns Std            26.2669
exploration/Returns Max           -18.0021
exploration/Returns Min           -87.9478
exploration/Actions Mean           -0.0124565
exploration/Actions Std             0.235285
exploration/Actions Max             0.99574
exploration/Actions Min            -0.999789
exploration/Num Paths               5
exploration/Average Returns       -45.6054
evaluation/num steps total     250500
evaluation/num paths total       2505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.212541
evaluation/Rewards Std              0.921426
evaluation/Rewards Max             -0.0108013
evaluation/Rewards Min            -10.1045
evaluation/Returns Mean           -21.2541
evaluation/Returns Std             13.9238
evaluation/Returns Max             -3.36084
evaluation/Returns Min            -54.7271
evaluation/Actions Mean             0.00247248
evaluation/Actions Std              0.19043
evaluation/Actions Max              0.997659
evaluation/Actions Min             -0.997531
evaluation/Num Paths               15
evaluation/Average Returns        -21.2541
time/data storing (s)               0.00288827
time/evaluation sampling (s)        0.325387
time/exploration sampling (s)       0.139751
time/logging (s)                    0.004867
time/saving (s)                     0.00192912
time/training (s)                   1.96446
time/epoch (s)                      2.43928
time/total (s)                    407.943
Epoch                             166
-----------------------------  ---------------
2019-04-22 22:43:24.766190 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              84200
trainer/QF1 Loss                    0.847773
trainer/QF2 Loss                    0.815054
trainer/Policy Loss                14.5311
trainer/Q1 Predictions Mean       -12.698
trainer/Q1 Predictions Std          9.51696
trainer/Q1 Predictions Max         -6.42492
trainer/Q1 Predictions Min        -38.4984
trainer/Q2 Predictions Mean       -12.7329
trainer/Q2 Predictions Std          9.53491
trainer/Q2 Predictions Max         -6.46237
trainer/Q2 Predictions Min        -38.6093
trainer/Q Targets Mean            -13.0304
trainer/Q Targets Std               9.89087
trainer/Q Targets Max              -1.28261
trainer/Q Targets Min             -39.7802
trainer/Log Pis Mean                2.01805
trainer/Log Pis Std                 1.30986
trainer/Log Pis Max                 6.11462
trainer/Log Pis Min                -3.65155
trainer/Policy mu Mean              0.0375621
trainer/Policy mu Std               0.716207
trainer/Policy mu Max               3.23866
trainer/Policy mu Min              -2.91841
trainer/Policy log std Mean        -2.12961
trainer/Policy log std Std          0.486566
trainer/Policy log std Max         -0.525243
trainer/Policy log std Min         -2.58382
trainer/Alpha                       0.0535604
trainer/Alpha Loss                  0.0528399
exploration/num steps total     84200
exploration/num paths total       842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.264681
exploration/Rewards Std             0.830443
exploration/Rewards Max            -0.00753073
exploration/Rewards Min            -8.4897
exploration/Returns Mean          -26.4681
exploration/Returns Std            15.0107
exploration/Returns Max           -13.0217
exploration/Returns Min           -51.8993
exploration/Actions Mean            0.0197755
exploration/Actions Std             0.203614
exploration/Actions Max             0.999348
exploration/Actions Min            -0.977406
exploration/Num Paths               5
exploration/Average Returns       -26.4681
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.329547
evaluation/Rewards Std              0.879044
evaluation/Rewards Max             -0.0120146
evaluation/Rewards Min            -10.7482
evaluation/Returns Mean           -32.9547
evaluation/Returns Std             26.5784
evaluation/Returns Max             -6.84374
evaluation/Returns Min            -99.2938
evaluation/Actions Mean            -0.00579633
evaluation/Actions Std              0.182019
evaluation/Actions Max              0.997595
evaluation/Actions Min             -0.999372
evaluation/Num Paths               15
evaluation/Average Returns        -32.9547
time/data storing (s)               0.00291384
time/evaluation sampling (s)        0.323695
time/exploration sampling (s)       0.139951
time/logging (s)                    0.00487279
time/saving (s)                     0.00195386
time/training (s)                   1.93159
time/epoch (s)                      2.40497
time/total (s)                    410.352
Epoch                             167
-----------------------------  ---------------
2019-04-22 22:43:27.192423 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              84700
trainer/QF1 Loss                    2.14991
trainer/QF2 Loss                    2.16011
trainer/Policy Loss                15.149
trainer/Q1 Predictions Mean       -13.3835
trainer/Q1 Predictions Std         10.4669
trainer/Q1 Predictions Max         -6.30342
trainer/Q1 Predictions Min        -37.909
trainer/Q2 Predictions Mean       -13.3649
trainer/Q2 Predictions Std         10.4416
trainer/Q2 Predictions Max         -6.2789
trainer/Q2 Predictions Min        -36.7203
trainer/Q Targets Mean            -13.1274
trainer/Q Targets Std              10.5696
trainer/Q Targets Max              -0.0274734
trainer/Q Targets Min             -37.8369
trainer/Log Pis Mean                2.01912
trainer/Log Pis Std                 1.13644
trainer/Log Pis Max                 6.66138
trainer/Log Pis Min                -1.41833
trainer/Policy mu Mean             -0.0667999
trainer/Policy mu Std               0.593961
trainer/Policy mu Max               3.07234
trainer/Policy mu Min              -3.52339
trainer/Policy log std Mean        -2.20554
trainer/Policy log std Std          0.403687
trainer/Policy log std Max         -0.544583
trainer/Policy log std Min         -2.58648
trainer/Alpha                       0.0532962
trainer/Alpha Loss                  0.0560691
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387601
exploration/Rewards Std             0.967124
exploration/Rewards Max            -0.0073089
exploration/Rewards Min            -8.88432
exploration/Returns Mean          -38.7601
exploration/Returns Std             8.37932
exploration/Returns Max           -26.7712
exploration/Returns Min           -49.6635
exploration/Actions Mean            0.0264854
exploration/Actions Std             0.2386
exploration/Actions Max             0.999372
exploration/Actions Min            -0.995366
exploration/Num Paths               5
exploration/Average Returns       -38.7601
evaluation/num steps total     253500
evaluation/num paths total       2535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.323884
evaluation/Rewards Std              0.993007
evaluation/Rewards Max             -0.0163187
evaluation/Rewards Min             -9.67311
evaluation/Returns Mean           -32.3884
evaluation/Returns Std             21.0422
evaluation/Returns Max             -2.20907
evaluation/Returns Min            -84.3442
evaluation/Actions Mean             0.00275399
evaluation/Actions Std              0.189272
evaluation/Actions Max              0.999105
evaluation/Actions Min             -0.999401
evaluation/Num Paths               15
evaluation/Average Returns        -32.3884
time/data storing (s)               0.0029353
time/evaluation sampling (s)        0.329823
time/exploration sampling (s)       0.144251
time/logging (s)                    0.00476552
time/saving (s)                     0.00154313
time/training (s)                   1.93563
time/epoch (s)                      2.41895
time/total (s)                    412.776
Epoch                             168
-----------------------------  ---------------
2019-04-22 22:43:29.624736 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              85200
trainer/QF1 Loss                    9.83864
trainer/QF2 Loss                    9.82366
trainer/Policy Loss                14.0234
trainer/Q1 Predictions Mean       -12.3451
trainer/Q1 Predictions Std          9.42103
trainer/Q1 Predictions Max         -6.33475
trainer/Q1 Predictions Min        -37.8119
trainer/Q2 Predictions Mean       -12.3353
trainer/Q2 Predictions Std          9.4187
trainer/Q2 Predictions Max         -6.33222
trainer/Q2 Predictions Min        -37.7259
trainer/Q Targets Mean            -12.0356
trainer/Q Targets Std               9.29097
trainer/Q Targets Max              -0.622145
trainer/Q Targets Min             -38.1765
trainer/Log Pis Mean                1.86177
trainer/Log Pis Std                 0.974641
trainer/Log Pis Max                 6.49518
trainer/Log Pis Min                -0.789081
trainer/Policy mu Mean             -0.00623307
trainer/Policy mu Std               0.582794
trainer/Policy mu Max               2.74955
trainer/Policy mu Min              -3.23438
trainer/Policy log std Mean        -2.09232
trainer/Policy log std Std          0.406069
trainer/Policy log std Max         -0.526403
trainer/Policy log std Min         -2.4793
trainer/Alpha                       0.0540084
trainer/Alpha Loss                 -0.403421
exploration/num steps total     85200
exploration/num paths total       852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.487346
exploration/Rewards Std             1.2128
exploration/Rewards Max            -0.00992297
exploration/Rewards Min            -9.39892
exploration/Returns Mean          -48.7346
exploration/Returns Std            21.225
exploration/Returns Max           -25.1394
exploration/Returns Min           -87.529
exploration/Actions Mean            0.0057775
exploration/Actions Std             0.258562
exploration/Actions Max             0.999196
exploration/Actions Min            -0.999977
exploration/Num Paths               5
exploration/Average Returns       -48.7346
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.307675
evaluation/Rewards Std              0.89935
evaluation/Rewards Max             -0.0332686
evaluation/Rewards Min             -9.5191
evaluation/Returns Mean           -30.7675
evaluation/Returns Std             18.515
evaluation/Returns Max             -4.04266
evaluation/Returns Min            -62.3103
evaluation/Actions Mean             0.00514468
evaluation/Actions Std              0.17549
evaluation/Actions Max              0.999509
evaluation/Actions Min             -0.995673
evaluation/Num Paths               15
evaluation/Average Returns        -30.7675
time/data storing (s)               0.00285419
time/evaluation sampling (s)        0.32478
time/exploration sampling (s)       0.136856
time/logging (s)                    0.00483371
time/saving (s)                     0.00194844
time/training (s)                   1.95399
time/epoch (s)                      2.42526
time/total (s)                    415.205
Epoch                             169
-----------------------------  ---------------
2019-04-22 22:43:32.053913 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 170 finished
-----------------------------  ----------------
replay_buffer/size              85700
trainer/QF1 Loss                    0.128536
trainer/QF2 Loss                    0.15427
trainer/Policy Loss                14.2574
trainer/Q1 Predictions Mean       -12.4534
trainer/Q1 Predictions Std          9.3032
trainer/Q1 Predictions Max         -6.36456
trainer/Q1 Predictions Min        -37.5085
trainer/Q2 Predictions Mean       -12.4469
trainer/Q2 Predictions Std          9.26771
trainer/Q2 Predictions Max         -6.39769
trainer/Q2 Predictions Min        -36.9979
trainer/Q Targets Mean            -12.6976
trainer/Q Targets Std               9.51099
trainer/Q Targets Max              -6.45062
trainer/Q Targets Min             -37.4969
trainer/Log Pis Mean                2.08175
trainer/Log Pis Std                 1.17595
trainer/Log Pis Max                 6.81327
trainer/Log Pis Min                -1.18423
trainer/Policy mu Mean             -0.0441321
trainer/Policy mu Std               0.604511
trainer/Policy mu Max               2.94392
trainer/Policy mu Min              -2.71731
trainer/Policy log std Mean        -2.18038
trainer/Policy log std Std          0.427358
trainer/Policy log std Max         -0.593361
trainer/Policy log std Min         -2.64731
trainer/Alpha                       0.0543946
trainer/Alpha Loss                  0.238039
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.224982
exploration/Rewards Std             0.609385
exploration/Rewards Max            -0.00550056
exploration/Rewards Min            -6.51926
exploration/Returns Mean          -22.4982
exploration/Returns Std             6.79677
exploration/Returns Max           -16.6952
exploration/Returns Min           -32.6192
exploration/Actions Mean           -0.00193917
exploration/Actions Std             0.212381
exploration/Actions Max             0.996526
exploration/Actions Min            -0.994003
exploration/Num Paths               5
exploration/Average Returns       -22.4982
evaluation/num steps total     256500
evaluation/num paths total       2565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.341047
evaluation/Rewards Std              1.03401
evaluation/Rewards Max             -0.0185149
evaluation/Rewards Min            -11.8452
evaluation/Returns Mean           -34.1047
evaluation/Returns Std             21.0739
evaluation/Returns Max            -10.6432
evaluation/Returns Min            -72.3519
evaluation/Actions Mean            -0.000742358
evaluation/Actions Std              0.20061
evaluation/Actions Max              0.998768
evaluation/Actions Min             -0.999294
evaluation/Num Paths               15
evaluation/Average Returns        -34.1047
time/data storing (s)               0.00283761
time/evaluation sampling (s)        0.327629
time/exploration sampling (s)       0.144547
time/logging (s)                    0.00484917
time/saving (s)                     0.0019315
time/training (s)                   1.94024
time/epoch (s)                      2.42203
time/total (s)                    417.631
Epoch                             170
-----------------------------  ----------------
2019-04-22 22:43:34.489683 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              86200
trainer/QF1 Loss                    0.518154
trainer/QF2 Loss                    0.601849
trainer/Policy Loss                13.3307
trainer/Q1 Predictions Mean       -11.5831
trainer/Q1 Predictions Std          9.72401
trainer/Q1 Predictions Max         -6.53859
trainer/Q1 Predictions Min        -53.9545
trainer/Q2 Predictions Mean       -11.5273
trainer/Q2 Predictions Std          9.67294
trainer/Q2 Predictions Max         -6.50452
trainer/Q2 Predictions Min        -52.3655
trainer/Q Targets Mean            -11.6237
trainer/Q Targets Std               9.93788
trainer/Q Targets Max              -0.0915859
trainer/Q Targets Min             -55.0134
trainer/Log Pis Mean                2.02512
trainer/Log Pis Std                 1.26785
trainer/Log Pis Max                 6.90067
trainer/Log Pis Min                -2.12806
trainer/Policy mu Mean             -0.0651758
trainer/Policy mu Std               0.696733
trainer/Policy mu Max               2.9044
trainer/Policy mu Min              -3.30347
trainer/Policy log std Mean        -2.1116
trainer/Policy log std Std          0.479041
trainer/Policy log std Max         -0.316613
trainer/Policy log std Min         -2.56216
trainer/Alpha                       0.0535363
trainer/Alpha Loss                  0.0735298
exploration/num steps total     86200
exploration/num paths total       862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.517569
exploration/Rewards Std             0.999169
exploration/Rewards Max            -0.00574711
exploration/Rewards Min            -9.09241
exploration/Returns Mean          -51.7569
exploration/Returns Std            28.1738
exploration/Returns Max           -22.7953
exploration/Returns Min          -100.748
exploration/Actions Mean           -0.0110803
exploration/Actions Std             0.234242
exploration/Actions Max             0.999805
exploration/Actions Min            -0.99976
exploration/Num Paths               5
exploration/Average Returns       -51.7569
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.311417
evaluation/Rewards Std              1.03104
evaluation/Rewards Max             -0.0162145
evaluation/Rewards Min             -9.73841
evaluation/Returns Mean           -31.1417
evaluation/Returns Std             20.721
evaluation/Returns Max             -3.82944
evaluation/Returns Min            -66.1966
evaluation/Actions Mean             0.0088823
evaluation/Actions Std              0.192501
evaluation/Actions Max              0.997012
evaluation/Actions Min             -0.999308
evaluation/Num Paths               15
evaluation/Average Returns        -31.1417
time/data storing (s)               0.00273708
time/evaluation sampling (s)        0.323264
time/exploration sampling (s)       0.137054
time/logging (s)                    0.00485058
time/saving (s)                     0.00194197
time/training (s)                   1.95875
time/epoch (s)                      2.4286
time/total (s)                    420.064
Epoch                             171
-----------------------------  ---------------
2019-04-22 22:43:36.938696 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                    0.566489
trainer/QF2 Loss                    0.562876
trainer/Policy Loss                15.3121
trainer/Q1 Predictions Mean       -13.6523
trainer/Q1 Predictions Std         10.7992
trainer/Q1 Predictions Max         -6.23076
trainer/Q1 Predictions Min        -48.393
trainer/Q2 Predictions Mean       -13.6643
trainer/Q2 Predictions Std         10.7899
trainer/Q2 Predictions Max         -6.30059
trainer/Q2 Predictions Min        -48.1944
trainer/Q Targets Mean            -13.7144
trainer/Q Targets Std              10.9051
trainer/Q Targets Max              -0.0746768
trainer/Q Targets Min             -49.6236
trainer/Log Pis Mean                2.07274
trainer/Log Pis Std                 1.39727
trainer/Log Pis Max                 6.1645
trainer/Log Pis Min                -5.95299
trainer/Policy mu Mean             -0.078767
trainer/Policy mu Std               0.657154
trainer/Policy mu Max               2.84976
trainer/Policy mu Min              -3.03436
trainer/Policy log std Mean        -2.15184
trainer/Policy log std Std          0.459337
trainer/Policy log std Max         -0.492484
trainer/Policy log std Min         -2.63991
trainer/Alpha                       0.0553639
trainer/Alpha Loss                  0.210502
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.337252
exploration/Rewards Std             0.814058
exploration/Rewards Max            -0.00836654
exploration/Rewards Min            -9.52613
exploration/Returns Mean          -33.7252
exploration/Returns Std            16.0018
exploration/Returns Max           -12.8688
exploration/Returns Min           -56.5893
exploration/Actions Mean            0.00209622
exploration/Actions Std             0.214312
exploration/Actions Max             0.999745
exploration/Actions Min            -0.999306
exploration/Num Paths               5
exploration/Average Returns       -33.7252
evaluation/num steps total     259500
evaluation/num paths total       2595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283055
evaluation/Rewards Std              1.01887
evaluation/Rewards Max             -0.00283897
evaluation/Rewards Min            -11.7825
evaluation/Returns Mean           -28.3055
evaluation/Returns Std             23.6406
evaluation/Returns Max             -0.96101
evaluation/Returns Min            -77.1748
evaluation/Actions Mean             0.002767
evaluation/Actions Std              0.199388
evaluation/Actions Max              0.999174
evaluation/Actions Min             -0.999046
evaluation/Num Paths               15
evaluation/Average Returns        -28.3055
time/data storing (s)               0.00316935
time/evaluation sampling (s)        0.324598
time/exploration sampling (s)       0.141315
time/logging (s)                    0.00485422
time/saving (s)                     0.0015665
time/training (s)                   1.96638
time/epoch (s)                      2.44189
time/total (s)                    422.51
Epoch                             172
-----------------------------  ---------------
2019-04-22 22:43:39.424643 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              87200
trainer/QF1 Loss                    0.0333108
trainer/QF2 Loss                    0.0240997
trainer/Policy Loss                13.3176
trainer/Q1 Predictions Mean       -11.5697
trainer/Q1 Predictions Std          8.57139
trainer/Q1 Predictions Max         -6.33169
trainer/Q1 Predictions Min        -35.2353
trainer/Q2 Predictions Mean       -11.5706
trainer/Q2 Predictions Std          8.59004
trainer/Q2 Predictions Max         -6.32143
trainer/Q2 Predictions Min        -35.2801
trainer/Q Targets Mean            -11.6247
trainer/Q Targets Std               8.58919
trainer/Q Targets Max              -6.41071
trainer/Q Targets Min             -35.3594
trainer/Log Pis Mean                1.99653
trainer/Log Pis Std                 1.42128
trainer/Log Pis Max                 9.26389
trainer/Log Pis Min                -2.3759
trainer/Policy mu Mean              0.0315813
trainer/Policy mu Std               0.691685
trainer/Policy mu Max               2.97464
trainer/Policy mu Min              -2.94399
trainer/Policy log std Mean        -2.09337
trainer/Policy log std Std          0.446229
trainer/Policy log std Max         -0.383921
trainer/Policy log std Min         -2.57435
trainer/Alpha                       0.0568659
trainer/Alpha Loss                 -0.00993842
exploration/num steps total     87200
exploration/num paths total       872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.492028
exploration/Rewards Std             1.03386
exploration/Rewards Max            -0.00400674
exploration/Rewards Min            -8.17964
exploration/Returns Mean          -49.2028
exploration/Returns Std            10.889
exploration/Returns Max           -35.129
exploration/Returns Min           -63.3653
exploration/Actions Mean           -0.00758577
exploration/Actions Std             0.251834
exploration/Actions Max             0.999682
exploration/Actions Min            -0.99929
exploration/Num Paths               5
exploration/Average Returns       -49.2028
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282092
evaluation/Rewards Std              0.878796
evaluation/Rewards Max             -0.0117794
evaluation/Rewards Min             -9.46861
evaluation/Returns Mean           -28.2092
evaluation/Returns Std             19.1486
evaluation/Returns Max             -7.098
evaluation/Returns Min            -76.3632
evaluation/Actions Mean            -0.00219097
evaluation/Actions Std              0.182484
evaluation/Actions Max              0.997823
evaluation/Actions Min             -0.999208
evaluation/Num Paths               15
evaluation/Average Returns        -28.2092
time/data storing (s)               0.00301518
time/evaluation sampling (s)        0.327976
time/exploration sampling (s)       0.140588
time/logging (s)                    0.00481888
time/saving (s)                     0.00194038
time/training (s)                   2.00035
time/epoch (s)                      2.47869
time/total (s)                    424.993
Epoch                             173
-----------------------------  ---------------
2019-04-22 22:43:41.873804 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              87700
trainer/QF1 Loss                    0.0525524
trainer/QF2 Loss                    0.0417535
trainer/Policy Loss                13.6281
trainer/Q1 Predictions Mean       -12.2563
trainer/Q1 Predictions Std          9.25932
trainer/Q1 Predictions Max         -6.44802
trainer/Q1 Predictions Min        -35.8387
trainer/Q2 Predictions Mean       -12.2769
trainer/Q2 Predictions Std          9.23949
trainer/Q2 Predictions Max         -6.52236
trainer/Q2 Predictions Min        -35.8155
trainer/Q Targets Mean            -12.3959
trainer/Q Targets Std               9.31113
trainer/Q Targets Max              -6.51403
trainer/Q Targets Min             -35.9
trainer/Log Pis Mean                1.5759
trainer/Log Pis Std                 1.11599
trainer/Log Pis Max                 3.42918
trainer/Log Pis Min                -1.79192
trainer/Policy mu Mean             -0.0327163
trainer/Policy mu Std               0.554375
trainer/Policy mu Max               3.12856
trainer/Policy mu Min              -2.94637
trainer/Policy log std Mean        -2.11586
trainer/Policy log std Std          0.389884
trainer/Policy log std Max         -0.220861
trainer/Policy log std Min         -2.52424
trainer/Alpha                       0.0559069
trainer/Alpha Loss                 -1.22299
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.366679
exploration/Rewards Std             0.529169
exploration/Rewards Max            -0.0153028
exploration/Rewards Min            -5.94837
exploration/Returns Mean          -36.6679
exploration/Returns Std            17.8371
exploration/Returns Max           -19.6277
exploration/Returns Min           -65.9743
exploration/Actions Mean            0.00182739
exploration/Actions Std             0.203247
exploration/Actions Max             0.970638
exploration/Actions Min            -0.998629
exploration/Num Paths               5
exploration/Average Returns       -36.6679
evaluation/num steps total     262500
evaluation/num paths total       2625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.446763
evaluation/Rewards Std              1.09629
evaluation/Rewards Max             -0.0307448
evaluation/Rewards Min             -9.43073
evaluation/Returns Mean           -44.6763
evaluation/Returns Std             25.2123
evaluation/Returns Max            -12.9105
evaluation/Returns Min            -90.9077
evaluation/Actions Mean            -0.0171272
evaluation/Actions Std              0.209062
evaluation/Actions Max              0.998666
evaluation/Actions Min             -0.999587
evaluation/Num Paths               15
evaluation/Average Returns        -44.6763
time/data storing (s)               0.00283741
time/evaluation sampling (s)        0.327512
time/exploration sampling (s)       0.14007
time/logging (s)                    0.00432579
time/saving (s)                     0.00640076
time/training (s)                   1.96078
time/epoch (s)                      2.44193
time/total (s)                    427.439
Epoch                             174
-----------------------------  ---------------
2019-04-22 22:43:44.314717 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              88200
trainer/QF1 Loss                   20.695
trainer/QF2 Loss                   20.7826
trainer/Policy Loss                15.3219
trainer/Q1 Predictions Mean       -13.5926
trainer/Q1 Predictions Std         10.6189
trainer/Q1 Predictions Max         -6.53774
trainer/Q1 Predictions Min        -49.9941
trainer/Q2 Predictions Mean       -13.6135
trainer/Q2 Predictions Std         10.6451
trainer/Q2 Predictions Max         -6.48713
trainer/Q2 Predictions Min        -49.9902
trainer/Q Targets Mean            -12.7283
trainer/Q Targets Std              10.6359
trainer/Q Targets Max              -0.12814
trainer/Q Targets Min             -51.2401
trainer/Log Pis Mean                2.11971
trainer/Log Pis Std                 1.25055
trainer/Log Pis Max                 7.13141
trainer/Log Pis Min                -1.03704
trainer/Policy mu Mean             -0.00556108
trainer/Policy mu Std               0.765512
trainer/Policy mu Max               3.25932
trainer/Policy mu Min              -3.15937
trainer/Policy log std Mean        -2.03469
trainer/Policy log std Std          0.508607
trainer/Policy log std Max         -0.356148
trainer/Policy log std Min         -2.49415
trainer/Alpha                       0.0545676
trainer/Alpha Loss                  0.348133
exploration/num steps total     88200
exploration/num paths total       882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.418225
exploration/Rewards Std             0.97249
exploration/Rewards Max            -0.00376128
exploration/Rewards Min            -8.26966
exploration/Returns Mean          -41.8225
exploration/Returns Std            12.8142
exploration/Returns Max           -20.6213
exploration/Returns Min           -59.7077
exploration/Actions Mean            0.00795703
exploration/Actions Std             0.242841
exploration/Actions Max             0.999776
exploration/Actions Min            -0.999737
exploration/Num Paths               5
exploration/Average Returns       -41.8225
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274435
evaluation/Rewards Std              0.828238
evaluation/Rewards Max             -0.0364314
evaluation/Rewards Min            -10.5121
evaluation/Returns Mean           -27.4435
evaluation/Returns Std             23.5686
evaluation/Returns Max             -4.20219
evaluation/Returns Min            -88.7891
evaluation/Actions Mean            -0.00684849
evaluation/Actions Std              0.185509
evaluation/Actions Max              0.998451
evaluation/Actions Min             -0.998996
evaluation/Num Paths               15
evaluation/Average Returns        -27.4435
time/data storing (s)               0.00299634
time/evaluation sampling (s)        0.322046
time/exploration sampling (s)       0.141787
time/logging (s)                    0.00371981
time/saving (s)                     0.00193804
time/training (s)                   1.96026
time/epoch (s)                      2.43274
time/total (s)                    429.877
Epoch                             175
-----------------------------  ---------------
2019-04-22 22:43:46.728239 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              88700
trainer/QF1 Loss                    0.70761
trainer/QF2 Loss                    0.707818
trainer/Policy Loss                14.0219
trainer/Q1 Predictions Mean       -12.4128
trainer/Q1 Predictions Std          9.39607
trainer/Q1 Predictions Max         -6.48702
trainer/Q1 Predictions Min        -37.9858
trainer/Q2 Predictions Mean       -12.4057
trainer/Q2 Predictions Std          9.38294
trainer/Q2 Predictions Max         -6.47833
trainer/Q2 Predictions Min        -37.928
trainer/Q Targets Mean            -12.3333
trainer/Q Targets Std               9.378
trainer/Q Targets Max              -0.217326
trainer/Q Targets Min             -37.7342
trainer/Log Pis Mean                2.09789
trainer/Log Pis Std                 1.3826
trainer/Log Pis Max                 6.77024
trainer/Log Pis Min                -2.31229
trainer/Policy mu Mean             -0.0307522
trainer/Policy mu Std               0.810716
trainer/Policy mu Max               3.39205
trainer/Policy mu Min              -2.98964
trainer/Policy log std Mean        -2.03588
trainer/Policy log std Std          0.520021
trainer/Policy log std Max         -0.480112
trainer/Policy log std Min         -2.53705
trainer/Alpha                       0.0549447
trainer/Alpha Loss                  0.284004
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.294864
exploration/Rewards Std             0.480185
exploration/Rewards Max            -0.00990772
exploration/Rewards Min            -4.94022
exploration/Returns Mean          -29.4864
exploration/Returns Std            14.4898
exploration/Returns Max           -13.312
exploration/Returns Min           -55.8447
exploration/Actions Mean           -0.00993594
exploration/Actions Std             0.204051
exploration/Actions Max             0.993575
exploration/Actions Min            -0.994298
exploration/Num Paths               5
exploration/Average Returns       -29.4864
evaluation/num steps total     265500
evaluation/num paths total       2655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.394144
evaluation/Rewards Std              1.08669
evaluation/Rewards Max             -0.0223995
evaluation/Rewards Min            -11.8986
evaluation/Returns Mean           -39.4144
evaluation/Returns Std             24.792
evaluation/Returns Max             -4.20729
evaluation/Returns Min            -77.7846
evaluation/Actions Mean            -0.0165809
evaluation/Actions Std              0.210202
evaluation/Actions Max              0.999292
evaluation/Actions Min             -0.998631
evaluation/Num Paths               15
evaluation/Average Returns        -39.4144
time/data storing (s)               0.00295112
time/evaluation sampling (s)        0.326165
time/exploration sampling (s)       0.141662
time/logging (s)                    0.00484431
time/saving (s)                     0.00192376
time/training (s)                   1.92946
time/epoch (s)                      2.40701
time/total (s)                    432.288
Epoch                             176
-----------------------------  ---------------
2019-04-22 22:43:49.161664 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size              89200
trainer/QF1 Loss                    0.117248
trainer/QF2 Loss                    0.164205
trainer/Policy Loss                13.8119
trainer/Q1 Predictions Mean       -12.2294
trainer/Q1 Predictions Std          9.46816
trainer/Q1 Predictions Max         -6.48424
trainer/Q1 Predictions Min        -39.2846
trainer/Q2 Predictions Mean       -12.2324
trainer/Q2 Predictions Std          9.51618
trainer/Q2 Predictions Max         -6.47513
trainer/Q2 Predictions Min        -39.444
trainer/Q Targets Mean            -12.4205
trainer/Q Targets Std               9.60469
trainer/Q Targets Max              -6.46206
trainer/Q Targets Min             -39.5139
trainer/Log Pis Mean                1.87283
trainer/Log Pis Std                 1.4271
trainer/Log Pis Max                 5.80476
trainer/Log Pis Min                -5.74408
trainer/Policy mu Mean             -0.00243498
trainer/Policy mu Std               0.66775
trainer/Policy mu Max               3.04699
trainer/Policy mu Min              -3.0937
trainer/Policy log std Mean        -2.10524
trainer/Policy log std Std          0.43048
trainer/Policy log std Max         -0.57948
trainer/Policy log std Min         -2.53287
trainer/Alpha                       0.0548883
trainer/Alpha Loss                 -0.369118
exploration/num steps total     89200
exploration/num paths total       892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.403338
exploration/Rewards Std             1.23262
exploration/Rewards Max            -0.00449959
exploration/Rewards Min            -9.3056
exploration/Returns Mean          -40.3338
exploration/Returns Std            16.2243
exploration/Returns Max           -18.8168
exploration/Returns Min           -56.7468
exploration/Actions Mean            0.0126062
exploration/Actions Std             0.251895
exploration/Actions Max             0.99932
exploration/Actions Min            -0.990617
exploration/Num Paths               5
exploration/Average Returns       -40.3338
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.284174
evaluation/Rewards Std              0.669163
evaluation/Rewards Max             -0.0245148
evaluation/Rewards Min             -7.22992
evaluation/Returns Mean           -28.4174
evaluation/Returns Std             22.2315
evaluation/Returns Max             -7.24396
evaluation/Returns Min            -71.4031
evaluation/Actions Mean            -0.0130411
evaluation/Actions Std              0.177472
evaluation/Actions Max              0.994144
evaluation/Actions Min             -0.996699
evaluation/Num Paths               15
evaluation/Average Returns        -28.4174
time/data storing (s)               0.00291914
time/evaluation sampling (s)        0.328804
time/exploration sampling (s)       0.141112
time/logging (s)                    0.00483198
time/saving (s)                     0.00194886
time/training (s)                   1.94631
time/epoch (s)                      2.42593
time/total (s)                    434.719
Epoch                             177
-----------------------------  ---------------
2019-04-22 22:43:51.593725 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              89700
trainer/QF1 Loss                    0.463864
trainer/QF2 Loss                    0.469282
trainer/Policy Loss                13.6108
trainer/Q1 Predictions Mean       -12.1
trainer/Q1 Predictions Std          9.07948
trainer/Q1 Predictions Max         -6.23169
trainer/Q1 Predictions Min        -34.9335
trainer/Q2 Predictions Mean       -12.0972
trainer/Q2 Predictions Std          9.06067
trainer/Q2 Predictions Max         -6.21263
trainer/Q2 Predictions Min        -34.6732
trainer/Q Targets Mean            -12.2253
trainer/Q Targets Std               9.14826
trainer/Q Targets Max              -0.0747678
trainer/Q Targets Min             -34.3886
trainer/Log Pis Mean                1.70989
trainer/Log Pis Std                 1.46036
trainer/Log Pis Max                 6.02395
trainer/Log Pis Min                -6.79762
trainer/Policy mu Mean             -0.0172001
trainer/Policy mu Std               0.566673
trainer/Policy mu Max               2.8668
trainer/Policy mu Min              -2.90136
trainer/Policy log std Mean        -2.10308
trainer/Policy log std Std          0.37416
trainer/Policy log std Max         -0.496766
trainer/Policy log std Min         -2.48499
trainer/Alpha                       0.0548817
trainer/Alpha Loss                 -0.842006
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.450953
exploration/Rewards Std             1.36502
exploration/Rewards Max            -0.00686515
exploration/Rewards Min           -10.3138
exploration/Returns Mean          -45.0953
exploration/Returns Std            21.1573
exploration/Returns Max           -16.965
exploration/Returns Min           -73.0905
exploration/Actions Mean           -0.0055273
exploration/Actions Std             0.266267
exploration/Actions Max             0.998701
exploration/Actions Min            -0.99971
exploration/Num Paths               5
exploration/Average Returns       -45.0953
evaluation/num steps total     268500
evaluation/num paths total       2685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.369351
evaluation/Rewards Std              1.02576
evaluation/Rewards Max             -0.0114525
evaluation/Rewards Min             -9.25756
evaluation/Returns Mean           -36.9351
evaluation/Returns Std             23.9952
evaluation/Returns Max             -4.2425
evaluation/Returns Min            -91.8204
evaluation/Actions Mean            -0.0101976
evaluation/Actions Std              0.203185
evaluation/Actions Max              0.997619
evaluation/Actions Min             -0.999316
evaluation/Num Paths               15
evaluation/Average Returns        -36.9351
time/data storing (s)               0.00279856
time/evaluation sampling (s)        0.320628
time/exploration sampling (s)       0.138223
time/logging (s)                    0.00492486
time/saving (s)                     0.00193583
time/training (s)                   1.95617
time/epoch (s)                      2.42468
time/total (s)                    437.148
Epoch                             178
-----------------------------  ---------------
2019-04-22 22:43:54.023691 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              90200
trainer/QF1 Loss                    8.97141
trainer/QF2 Loss                    9.07256
trainer/Policy Loss                15.9306
trainer/Q1 Predictions Mean       -14.1119
trainer/Q1 Predictions Std         11.7816
trainer/Q1 Predictions Max         -6.52958
trainer/Q1 Predictions Min        -54.863
trainer/Q2 Predictions Mean       -14.104
trainer/Q2 Predictions Std         11.7768
trainer/Q2 Predictions Max         -6.52514
trainer/Q2 Predictions Min        -53.3835
trainer/Q Targets Mean            -14.0251
trainer/Q Targets Std              12.1247
trainer/Q Targets Max              -0.396899
trainer/Q Targets Min             -56.0614
trainer/Log Pis Mean                2.06376
trainer/Log Pis Std                 1.42076
trainer/Log Pis Max                 6.77611
trainer/Log Pis Min                -1.68841
trainer/Policy mu Mean             -0.0639479
trainer/Policy mu Std               0.824947
trainer/Policy mu Max               3.39724
trainer/Policy mu Min              -3.3406
trainer/Policy log std Mean        -2.04855
trainer/Policy log std Std          0.541619
trainer/Policy log std Max         -0.387184
trainer/Policy log std Min         -2.68703
trainer/Alpha                       0.0549943
trainer/Alpha Loss                  0.184938
exploration/num steps total     90200
exploration/num paths total       902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.312367
exploration/Rewards Std             0.951182
exploration/Rewards Max            -0.00675914
exploration/Rewards Min            -8.54178
exploration/Returns Mean          -31.2367
exploration/Returns Std            13.5148
exploration/Returns Max           -15.7753
exploration/Returns Min           -51.5115
exploration/Actions Mean            0.0180946
exploration/Actions Std             0.226608
exploration/Actions Max             0.999705
exploration/Actions Min            -0.978765
exploration/Num Paths               5
exploration/Average Returns       -31.2367
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.274955
evaluation/Rewards Std              0.772971
evaluation/Rewards Max             -0.00300661
evaluation/Rewards Min             -9.42275
evaluation/Returns Mean           -27.4955
evaluation/Returns Std             19.097
evaluation/Returns Max             -3.34361
evaluation/Returns Min            -56.2675
evaluation/Actions Mean            -0.0122735
evaluation/Actions Std              0.172544
evaluation/Actions Max              0.996778
evaluation/Actions Min             -0.997962
evaluation/Num Paths               15
evaluation/Average Returns        -27.4955
time/data storing (s)               0.00287978
time/evaluation sampling (s)        0.323729
time/exploration sampling (s)       0.140421
time/logging (s)                    0.00482511
time/saving (s)                     0.00188042
time/training (s)                   1.94855
time/epoch (s)                      2.42229
time/total (s)                    439.575
Epoch                             179
-----------------------------  ---------------
2019-04-22 22:43:56.441262 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              90700
trainer/QF1 Loss                    0.0376025
trainer/QF2 Loss                    0.0618067
trainer/Policy Loss                13.4779
trainer/Q1 Predictions Mean       -11.6677
trainer/Q1 Predictions Std          8.42764
trainer/Q1 Predictions Max         -6.37483
trainer/Q1 Predictions Min        -37.2555
trainer/Q2 Predictions Mean       -11.6661
trainer/Q2 Predictions Std          8.42201
trainer/Q2 Predictions Max         -6.37409
trainer/Q2 Predictions Min        -37.3001
trainer/Q Targets Mean            -11.7391
trainer/Q Targets Std               8.44789
trainer/Q Targets Max              -6.42436
trainer/Q Targets Min             -37.6855
trainer/Log Pis Mean                2.14598
trainer/Log Pis Std                 1.12602
trainer/Log Pis Max                 5.82572
trainer/Log Pis Min                -1.80683
trainer/Policy mu Mean             -0.0656461
trainer/Policy mu Std               0.672208
trainer/Policy mu Max               3.03401
trainer/Policy mu Min              -2.99635
trainer/Policy log std Mean        -2.13947
trainer/Policy log std Std          0.468631
trainer/Policy log std Max         -0.512718
trainer/Policy log std Min         -2.66838
trainer/Alpha                       0.0559855
trainer/Alpha Loss                  0.42083
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.412512
exploration/Rewards Std             0.758745
exploration/Rewards Max            -0.0121631
exploration/Rewards Min            -7.79199
exploration/Returns Mean          -41.2512
exploration/Returns Std            23.8549
exploration/Returns Max           -18.8197
exploration/Returns Min           -75.3006
exploration/Actions Mean           -0.0169063
exploration/Actions Std             0.225873
exploration/Actions Max             0.99117
exploration/Actions Min            -0.999159
exploration/Num Paths               5
exploration/Average Returns       -41.2512
evaluation/num steps total     271500
evaluation/num paths total       2715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270684
evaluation/Rewards Std              0.850813
evaluation/Rewards Max             -0.0050046
evaluation/Rewards Min             -8.96078
evaluation/Returns Mean           -27.0684
evaluation/Returns Std             21.046
evaluation/Returns Max             -3.89476
evaluation/Returns Min            -67.816
evaluation/Actions Mean             0.0106052
evaluation/Actions Std              0.180375
evaluation/Actions Max              0.999256
evaluation/Actions Min             -0.997667
evaluation/Num Paths               15
evaluation/Average Returns        -27.0684
time/data storing (s)               0.00299472
time/evaluation sampling (s)        0.326996
time/exploration sampling (s)       0.141463
time/logging (s)                    0.00487167
time/saving (s)                     0.00156214
time/training (s)                   1.93214
time/epoch (s)                      2.41003
time/total (s)                    441.989
Epoch                             180
-----------------------------  ---------------
2019-04-22 22:43:58.867867 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              91200
trainer/QF1 Loss                    0.754741
trainer/QF2 Loss                    0.752542
trainer/Policy Loss                14.5197
trainer/Q1 Predictions Mean       -12.8875
trainer/Q1 Predictions Std          9.6169
trainer/Q1 Predictions Max         -6.24569
trainer/Q1 Predictions Min        -44.5619
trainer/Q2 Predictions Mean       -12.8713
trainer/Q2 Predictions Std          9.6575
trainer/Q2 Predictions Max         -6.23359
trainer/Q2 Predictions Min        -44.6683
trainer/Q Targets Mean            -12.9245
trainer/Q Targets Std               9.80063
trainer/Q Targets Max              -0.508295
trainer/Q Targets Min             -43.8068
trainer/Log Pis Mean                1.82431
trainer/Log Pis Std                 1.29671
trainer/Log Pis Max                 5.27676
trainer/Log Pis Min                -2.73856
trainer/Policy mu Mean              0.00162404
trainer/Policy mu Std               0.672547
trainer/Policy mu Max               2.9731
trainer/Policy mu Min              -3.03385
trainer/Policy log std Mean        -2.08732
trainer/Policy log std Std          0.47199
trainer/Policy log std Max         -0.226182
trainer/Policy log std Min         -2.60917
trainer/Alpha                       0.0561581
trainer/Alpha Loss                 -0.505907
exploration/num steps total     91200
exploration/num paths total       912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.262457
exploration/Rewards Std             0.692154
exploration/Rewards Max            -0.00662188
exploration/Rewards Min            -6.30232
exploration/Returns Mean          -26.2457
exploration/Returns Std             9.57294
exploration/Returns Max           -13.3268
exploration/Returns Min           -37.969
exploration/Actions Mean            0.0308158
exploration/Actions Std             0.22587
exploration/Actions Max             0.999498
exploration/Actions Min            -0.762424
exploration/Num Paths               5
exploration/Average Returns       -26.2457
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245285
evaluation/Rewards Std              1.02807
evaluation/Rewards Max             -0.0220703
evaluation/Rewards Min            -10.4995
evaluation/Returns Mean           -24.5285
evaluation/Returns Std             14.2628
evaluation/Returns Max             -6.18318
evaluation/Returns Min            -52.0684
evaluation/Actions Mean             0.0129456
evaluation/Actions Std              0.206868
evaluation/Actions Max              0.996378
evaluation/Actions Min             -0.997663
evaluation/Num Paths               15
evaluation/Average Returns        -24.5285
time/data storing (s)               0.00281111
time/evaluation sampling (s)        0.322048
time/exploration sampling (s)       0.140748
time/logging (s)                    0.00494887
time/saving (s)                     0.0019798
time/training (s)                   1.94621
time/epoch (s)                      2.41874
time/total (s)                    444.413
Epoch                             181
-----------------------------  ---------------
2019-04-22 22:44:01.316454 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              91700
trainer/QF1 Loss                    1.49277
trainer/QF2 Loss                    1.47823
trainer/Policy Loss                13.7175
trainer/Q1 Predictions Mean       -12.2309
trainer/Q1 Predictions Std          9.37492
trainer/Q1 Predictions Max         -6.1333
trainer/Q1 Predictions Min        -45.2234
trainer/Q2 Predictions Mean       -12.2208
trainer/Q2 Predictions Std          9.32869
trainer/Q2 Predictions Max         -6.11053
trainer/Q2 Predictions Min        -44.7509
trainer/Q Targets Mean            -12.3883
trainer/Q Targets Std               9.80471
trainer/Q Targets Max              -0.0828906
trainer/Q Targets Min             -47.2825
trainer/Log Pis Mean                1.66703
trainer/Log Pis Std                 1.37656
trainer/Log Pis Max                 7.01944
trainer/Log Pis Min                -2.19288
trainer/Policy mu Mean             -0.084109
trainer/Policy mu Std               0.619185
trainer/Policy mu Max               3.23309
trainer/Policy mu Min              -2.81532
trainer/Policy log std Mean        -2.04808
trainer/Policy log std Std          0.441142
trainer/Policy log std Max         -0.530754
trainer/Policy log std Min         -2.58236
trainer/Alpha                       0.0564351
trainer/Alpha Loss                 -0.957099
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.2483
exploration/Rewards Std             0.563879
exploration/Rewards Max            -0.0071467
exploration/Rewards Min            -6.12727
exploration/Returns Mean          -24.83
exploration/Returns Std             5.7339
exploration/Returns Max           -19.5248
exploration/Returns Min           -32.842
exploration/Actions Mean            0.0158628
exploration/Actions Std             0.231742
exploration/Actions Max             0.999852
exploration/Actions Min            -0.99256
exploration/Num Paths               5
exploration/Average Returns       -24.83
evaluation/num steps total     274500
evaluation/num paths total       2745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.306308
evaluation/Rewards Std              0.949713
evaluation/Rewards Max             -0.0152192
evaluation/Rewards Min            -12.0405
evaluation/Returns Mean           -30.6308
evaluation/Returns Std             21.952
evaluation/Returns Max            -10.0215
evaluation/Returns Min            -81.5631
evaluation/Actions Mean             0.00158878
evaluation/Actions Std              0.184223
evaluation/Actions Max              0.99833
evaluation/Actions Min             -0.998645
evaluation/Num Paths               15
evaluation/Average Returns        -30.6308
time/data storing (s)               0.00292248
time/evaluation sampling (s)        0.325881
time/exploration sampling (s)       0.14046
time/logging (s)                    0.00483601
time/saving (s)                     0.00193433
time/training (s)                   1.96563
time/epoch (s)                      2.44167
time/total (s)                    446.858
Epoch                             182
-----------------------------  ---------------
2019-04-22 22:44:03.758633 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              92200
trainer/QF1 Loss                    0.116098
trainer/QF2 Loss                    0.166387
trainer/Policy Loss                14.3847
trainer/Q1 Predictions Mean       -12.7298
trainer/Q1 Predictions Std         10.0311
trainer/Q1 Predictions Max         -6.19517
trainer/Q1 Predictions Min        -49.0859
trainer/Q2 Predictions Mean       -12.7273
trainer/Q2 Predictions Std          9.96959
trainer/Q2 Predictions Max         -6.17883
trainer/Q2 Predictions Min        -48.2171
trainer/Q Targets Mean            -12.9346
trainer/Q Targets Std              10.2115
trainer/Q Targets Max              -6.30589
trainer/Q Targets Min             -51.2241
trainer/Log Pis Mean                1.81789
trainer/Log Pis Std                 1.36766
trainer/Log Pis Max                 5.63044
trainer/Log Pis Min                -1.90343
trainer/Policy mu Mean              0.00993689
trainer/Policy mu Std               0.649651
trainer/Policy mu Max               3.19384
trainer/Policy mu Min              -2.91375
trainer/Policy log std Mean        -2.14599
trainer/Policy log std Std          0.465129
trainer/Policy log std Max         -0.450667
trainer/Policy log std Min         -2.63806
trainer/Alpha                       0.0556841
trainer/Alpha Loss                 -0.525962
exploration/num steps total     92200
exploration/num paths total       922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.3367
exploration/Rewards Std             0.82375
exploration/Rewards Max            -0.00426878
exploration/Rewards Min            -8.00052
exploration/Returns Mean          -33.67
exploration/Returns Std            16.6049
exploration/Returns Max           -13.9869
exploration/Returns Min           -54.9186
exploration/Actions Mean            0.0318804
exploration/Actions Std             0.211055
exploration/Actions Max             0.999527
exploration/Actions Min            -0.749604
exploration/Num Paths               5
exploration/Average Returns       -33.67
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.29258
evaluation/Rewards Std              0.922473
evaluation/Rewards Max             -0.00371647
evaluation/Rewards Min             -9.43199
evaluation/Returns Mean           -29.258
evaluation/Returns Std             26.4048
evaluation/Returns Max             -4.21144
evaluation/Returns Min            -84.7807
evaluation/Actions Mean            -0.0138565
evaluation/Actions Std              0.19045
evaluation/Actions Max              0.99798
evaluation/Actions Min             -0.997965
evaluation/Num Paths               15
evaluation/Average Returns        -29.258
time/data storing (s)               0.00292525
time/evaluation sampling (s)        0.325177
time/exploration sampling (s)       0.142605
time/logging (s)                    0.00485089
time/saving (s)                     0.00197688
time/training (s)                   1.95703
time/epoch (s)                      2.43456
time/total (s)                    449.297
Epoch                             183
-----------------------------  ---------------
2019-04-22 22:44:06.199615 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 184 finished
-----------------------------  ----------------
replay_buffer/size              92700
trainer/QF1 Loss                    0.0738089
trainer/QF2 Loss                    0.0602482
trainer/Policy Loss                13.0215
trainer/Q1 Predictions Mean       -11.5314
trainer/Q1 Predictions Std          9.03974
trainer/Q1 Predictions Max         -6.27328
trainer/Q1 Predictions Min        -54.7635
trainer/Q2 Predictions Mean       -11.5098
trainer/Q2 Predictions Std          9.05867
trainer/Q2 Predictions Max         -6.23525
trainer/Q2 Predictions Min        -54.9906
trainer/Q Targets Mean            -11.5332
trainer/Q Targets Std               9.1135
trainer/Q Targets Max              -6.23206
trainer/Q Targets Min             -55.5942
trainer/Log Pis Mean                1.86261
trainer/Log Pis Std                 1.30998
trainer/Log Pis Max                 7.10443
trainer/Log Pis Min                -1.9435
trainer/Policy mu Mean              0.00356684
trainer/Policy mu Std               0.586511
trainer/Policy mu Max               3.05757
trainer/Policy mu Min              -3.24942
trainer/Policy log std Mean        -2.20261
trainer/Policy log std Std          0.419047
trainer/Policy log std Max         -0.424543
trainer/Policy log std Min         -2.73257
trainer/Alpha                       0.0572607
trainer/Alpha Loss                 -0.392965
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.496427
exploration/Rewards Std             1.20895
exploration/Rewards Max            -0.00394885
exploration/Rewards Min           -11.2654
exploration/Returns Mean          -49.6427
exploration/Returns Std            22.3571
exploration/Returns Max           -16.686
exploration/Returns Min           -75.6878
exploration/Actions Mean           -5.96843e-05
exploration/Actions Std             0.245216
exploration/Actions Max             0.998753
exploration/Actions Min            -0.996458
exploration/Num Paths               5
exploration/Average Returns       -49.6427
evaluation/num steps total     277500
evaluation/num paths total       2775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228588
evaluation/Rewards Std              0.925503
evaluation/Rewards Max             -0.0169156
evaluation/Rewards Min            -11.5103
evaluation/Returns Mean           -22.8588
evaluation/Returns Std             19.8379
evaluation/Returns Max             -5.19988
evaluation/Returns Min            -58.5881
evaluation/Actions Mean             0.00365237
evaluation/Actions Std              0.173693
evaluation/Actions Max              0.998812
evaluation/Actions Min             -0.997965
evaluation/Num Paths               15
evaluation/Average Returns        -22.8588
time/data storing (s)               0.00286551
time/evaluation sampling (s)        0.326661
time/exploration sampling (s)       0.139367
time/logging (s)                    0.00487235
time/saving (s)                     0.00193438
time/training (s)                   1.95758
time/epoch (s)                      2.43328
time/total (s)                    451.735
Epoch                             184
-----------------------------  ----------------
2019-04-22 22:44:08.645714 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              93200
trainer/QF1 Loss                    0.159449
trainer/QF2 Loss                    0.189642
trainer/Policy Loss                13.818
trainer/Q1 Predictions Mean       -12.0866
trainer/Q1 Predictions Std          9.78609
trainer/Q1 Predictions Max         -6.26144
trainer/Q1 Predictions Min        -60.5067
trainer/Q2 Predictions Mean       -12.069
trainer/Q2 Predictions Std          9.76123
trainer/Q2 Predictions Max         -6.24095
trainer/Q2 Predictions Min        -60.0783
trainer/Q Targets Mean            -12.3016
trainer/Q Targets Std              10.0401
trainer/Q Targets Max              -6.25962
trainer/Q Targets Min             -63.2141
trainer/Log Pis Mean                2.19417
trainer/Log Pis Std                 1.37156
trainer/Log Pis Max                 8.16514
trainer/Log Pis Min                -2.38754
trainer/Policy mu Mean             -0.0667453
trainer/Policy mu Std               0.669583
trainer/Policy mu Max               2.38246
trainer/Policy mu Min              -3.3722
trainer/Policy log std Mean        -2.15543
trainer/Policy log std Std          0.46336
trainer/Policy log std Max         -0.522884
trainer/Policy log std Min         -2.65117
trainer/Alpha                       0.0567996
trainer/Alpha Loss                  0.556946
exploration/num steps total     93200
exploration/num paths total       932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.223838
exploration/Rewards Std             0.503801
exploration/Rewards Max            -0.0074574
exploration/Rewards Min            -5.48604
exploration/Returns Mean          -22.3838
exploration/Returns Std             5.9695
exploration/Returns Max           -13.2286
exploration/Returns Min           -31.5732
exploration/Actions Mean           -0.0110243
exploration/Actions Std             0.20433
exploration/Actions Max             0.990025
exploration/Actions Min            -0.998283
exploration/Num Paths               5
exploration/Average Returns       -22.3838
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268161
evaluation/Rewards Std              0.71133
evaluation/Rewards Max             -0.0523065
evaluation/Rewards Min             -8.49162
evaluation/Returns Mean           -26.8161
evaluation/Returns Std             17.4338
evaluation/Returns Max             -7.38784
evaluation/Returns Min            -68.0011
evaluation/Actions Mean            -0.00394525
evaluation/Actions Std              0.174502
evaluation/Actions Max              0.994187
evaluation/Actions Min             -0.998336
evaluation/Num Paths               15
evaluation/Average Returns        -26.8161
time/data storing (s)               0.00303943
time/evaluation sampling (s)        0.320882
time/exploration sampling (s)       0.141853
time/logging (s)                    0.00489694
time/saving (s)                     0.00195843
time/training (s)                   1.96582
time/epoch (s)                      2.43845
time/total (s)                    454.178
Epoch                             185
-----------------------------  ---------------
2019-04-22 22:44:11.078952 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              93700
trainer/QF1 Loss                    0.858718
trainer/QF2 Loss                    0.850308
trainer/Policy Loss                12.0065
trainer/Q1 Predictions Mean       -10.2428
trainer/Q1 Predictions Std          7.57464
trainer/Q1 Predictions Max         -6.19696
trainer/Q1 Predictions Min        -52.6054
trainer/Q2 Predictions Mean       -10.2821
trainer/Q2 Predictions Std          7.60673
trainer/Q2 Predictions Max         -6.2177
trainer/Q2 Predictions Min        -52.8419
trainer/Q Targets Mean            -10.2571
trainer/Q Targets Std               7.82571
trainer/Q Targets Max              -0.04497
trainer/Q Targets Min             -54.1362
trainer/Log Pis Mean                1.98973
trainer/Log Pis Std                 1.41216
trainer/Log Pis Max                 8.76377
trainer/Log Pis Min                -2.12245
trainer/Policy mu Mean              0.0893236
trainer/Policy mu Std               0.650739
trainer/Policy mu Max               3.42057
trainer/Policy mu Min              -2.8486
trainer/Policy log std Mean        -2.11308
trainer/Policy log std Std          0.459988
trainer/Policy log std Max         -0.461606
trainer/Policy log std Min         -2.62595
trainer/Alpha                       0.0558
trainer/Alpha Loss                 -0.0296503
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.304485
exploration/Rewards Std             0.906416
exploration/Rewards Max            -0.00707144
exploration/Rewards Min            -9.20903
exploration/Returns Mean          -30.4485
exploration/Returns Std            14.6411
exploration/Returns Max           -14.1347
exploration/Returns Min           -57.2274
exploration/Actions Mean           -0.0117978
exploration/Actions Std             0.235861
exploration/Actions Max             0.999481
exploration/Actions Min            -0.996814
exploration/Num Paths               5
exploration/Average Returns       -30.4485
evaluation/num steps total     280500
evaluation/num paths total       2805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.346965
evaluation/Rewards Std              1.06717
evaluation/Rewards Max             -0.00198207
evaluation/Rewards Min            -10.4808
evaluation/Returns Mean           -34.6965
evaluation/Returns Std             18.4838
evaluation/Returns Max             -2.50531
evaluation/Returns Min            -70.3755
evaluation/Actions Mean            -0.00989147
evaluation/Actions Std              0.20916
evaluation/Actions Max              0.996365
evaluation/Actions Min             -0.998112
evaluation/Num Paths               15
evaluation/Average Returns        -34.6965
time/data storing (s)               0.0029196
time/evaluation sampling (s)        0.324875
time/exploration sampling (s)       0.141437
time/logging (s)                    0.00489658
time/saving (s)                     0.00194772
time/training (s)                   1.94971
time/epoch (s)                      2.42578
time/total (s)                    456.608
Epoch                             186
-----------------------------  ---------------
2019-04-22 22:44:13.506472 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 187 finished
-----------------------------  ----------------
replay_buffer/size              94200
trainer/QF1 Loss                    0.825703
trainer/QF2 Loss                    0.835374
trainer/Policy Loss                14.1801
trainer/Q1 Predictions Mean       -12.2973
trainer/Q1 Predictions Std          8.73712
trainer/Q1 Predictions Max         -6.32754
trainer/Q1 Predictions Min        -32.9405
trainer/Q2 Predictions Mean       -12.2959
trainer/Q2 Predictions Std          8.73377
trainer/Q2 Predictions Max         -6.31254
trainer/Q2 Predictions Min        -32.6474
trainer/Q Targets Mean            -12.2469
trainer/Q Targets Std               8.90193
trainer/Q Targets Max              -0.312908
trainer/Q Targets Min             -32.6361
trainer/Log Pis Mean                2.06195
trainer/Log Pis Std                 1.10261
trainer/Log Pis Max                 5.9633
trainer/Log Pis Min                -1.70629
trainer/Policy mu Mean              0.000491803
trainer/Policy mu Std               0.662982
trainer/Policy mu Max               3.0396
trainer/Policy mu Min              -3.17374
trainer/Policy log std Mean        -2.11712
trainer/Policy log std Std          0.46093
trainer/Policy log std Max         -0.556793
trainer/Policy log std Min         -2.6562
trainer/Alpha                       0.0571277
trainer/Alpha Loss                  0.177326
exploration/num steps total     94200
exploration/num paths total       942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.365394
exploration/Rewards Std             0.869942
exploration/Rewards Max            -0.00374134
exploration/Rewards Min            -8.21085
exploration/Returns Mean          -36.5394
exploration/Returns Std            15.3681
exploration/Returns Max           -14.5944
exploration/Returns Min           -61.8491
exploration/Actions Mean           -0.00852372
exploration/Actions Std             0.226738
exploration/Actions Max             0.997503
exploration/Actions Min            -0.997186
exploration/Num Paths               5
exploration/Average Returns       -36.5394
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.299953
evaluation/Rewards Std              0.970609
evaluation/Rewards Max             -0.0189301
evaluation/Rewards Min             -9.83474
evaluation/Returns Mean           -29.9953
evaluation/Returns Std             20.32
evaluation/Returns Max             -2.43089
evaluation/Returns Min            -60.6574
evaluation/Actions Mean             0.00393534
evaluation/Actions Std              0.180734
evaluation/Actions Max              0.998649
evaluation/Actions Min             -0.996941
evaluation/Num Paths               15
evaluation/Average Returns        -29.9953
time/data storing (s)               0.0029759
time/evaluation sampling (s)        0.322819
time/exploration sampling (s)       0.14175
time/logging (s)                    0.00374776
time/saving (s)                     0.0106173
time/training (s)                   1.93811
time/epoch (s)                      2.42002
time/total (s)                    459.032
Epoch                             187
-----------------------------  ----------------
2019-04-22 22:44:15.935294 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              94700
trainer/QF1 Loss                    0.0319477
trainer/QF2 Loss                    0.023258
trainer/Policy Loss                13.023
trainer/Q1 Predictions Mean       -11.1786
trainer/Q1 Predictions Std          7.58119
trainer/Q1 Predictions Max         -6.34046
trainer/Q1 Predictions Min        -34.8756
trainer/Q2 Predictions Mean       -11.1895
trainer/Q2 Predictions Std          7.59442
trainer/Q2 Predictions Max         -6.33903
trainer/Q2 Predictions Min        -34.8253
trainer/Q Targets Mean            -11.2205
trainer/Q Targets Std               7.54271
trainer/Q Targets Max              -6.2665
trainer/Q Targets Min             -33.9418
trainer/Log Pis Mean                2.00599
trainer/Log Pis Std                 1.05427
trainer/Log Pis Max                 5.58254
trainer/Log Pis Min                -0.923393
trainer/Policy mu Mean             -0.0568739
trainer/Policy mu Std               0.66576
trainer/Policy mu Max               2.98422
trainer/Policy mu Min              -2.98058
trainer/Policy log std Mean        -2.11543
trainer/Policy log std Std          0.444247
trainer/Policy log std Max         -0.569164
trainer/Policy log std Min         -2.72161
trainer/Alpha                       0.0554741
trainer/Alpha Loss                  0.0173218
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.471772
exploration/Rewards Std             1.10714
exploration/Rewards Max            -0.00727603
exploration/Rewards Min            -9.80461
exploration/Returns Mean          -47.1772
exploration/Returns Std            25.9032
exploration/Returns Max           -16.8711
exploration/Returns Min           -79.6024
exploration/Actions Mean           -0.0151663
exploration/Actions Std             0.231754
exploration/Actions Max             0.99373
exploration/Actions Min            -0.99968
exploration/Num Paths               5
exploration/Average Returns       -47.1772
evaluation/num steps total     283500
evaluation/num paths total       2835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273605
evaluation/Rewards Std              0.880559
evaluation/Rewards Max             -0.033938
evaluation/Rewards Min             -9.36381
evaluation/Returns Mean           -27.3605
evaluation/Returns Std             14.7996
evaluation/Returns Max             -7.31982
evaluation/Returns Min            -55.1056
evaluation/Actions Mean             0.00056567
evaluation/Actions Std              0.189491
evaluation/Actions Max              0.999305
evaluation/Actions Min             -0.99795
evaluation/Num Paths               15
evaluation/Average Returns        -27.3605
time/data storing (s)               0.00289101
time/evaluation sampling (s)        0.322768
time/exploration sampling (s)       0.143019
time/logging (s)                    0.00474104
time/saving (s)                     0.00194109
time/training (s)                   1.9468
time/epoch (s)                      2.42216
time/total (s)                    461.459
Epoch                             188
-----------------------------  ---------------
2019-04-22 22:44:18.368855 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              95200
trainer/QF1 Loss                    0.0864861
trainer/QF2 Loss                    0.0651572
trainer/Policy Loss                13.7186
trainer/Q1 Predictions Mean       -11.8761
trainer/Q1 Predictions Std          8.91737
trainer/Q1 Predictions Max         -6.28251
trainer/Q1 Predictions Min        -46.1502
trainer/Q2 Predictions Mean       -11.9205
trainer/Q2 Predictions Std          9.00143
trainer/Q2 Predictions Max         -6.28488
trainer/Q2 Predictions Min        -46.7634
trainer/Q Targets Mean            -12.0166
trainer/Q Targets Std               9.04053
trainer/Q Targets Max              -6.27144
trainer/Q Targets Min             -45.9293
trainer/Log Pis Mean                2.026
trainer/Log Pis Std                 1.22763
trainer/Log Pis Max                 5.50874
trainer/Log Pis Min                -2.03358
trainer/Policy mu Mean              0.0806559
trainer/Policy mu Std               0.67089
trainer/Policy mu Max               3.28884
trainer/Policy mu Min              -3.14061
trainer/Policy log std Mean        -2.10421
trainer/Policy log std Std          0.454426
trainer/Policy log std Max         -0.439077
trainer/Policy log std Min         -2.75032
trainer/Alpha                       0.0551534
trainer/Alpha Loss                  0.0753375
exploration/num steps total     95200
exploration/num paths total       952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.365952
exploration/Rewards Std             0.724395
exploration/Rewards Max            -0.00464377
exploration/Rewards Min            -7.76729
exploration/Returns Mean          -36.5952
exploration/Returns Std            12.4627
exploration/Returns Max           -18.5792
exploration/Returns Min           -52.4345
exploration/Actions Mean           -0.00354989
exploration/Actions Std             0.211563
exploration/Actions Max             0.999326
exploration/Actions Min            -0.995844
exploration/Num Paths               5
exploration/Average Returns       -36.5952
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.339209
evaluation/Rewards Std              1.16713
evaluation/Rewards Max             -0.0293031
evaluation/Rewards Min            -11.4718
evaluation/Returns Mean           -33.9209
evaluation/Returns Std             22.0949
evaluation/Returns Max             -7.56894
evaluation/Returns Min            -87.0266
evaluation/Actions Mean            -0.0111463
evaluation/Actions Std              0.207374
evaluation/Actions Max              0.997919
evaluation/Actions Min             -0.999434
evaluation/Num Paths               15
evaluation/Average Returns        -33.9209
time/data storing (s)               0.00294769
time/evaluation sampling (s)        0.325831
time/exploration sampling (s)       0.139523
time/logging (s)                    0.00487195
time/saving (s)                     0.00196345
time/training (s)                   1.95087
time/epoch (s)                      2.426
time/total (s)                    463.889
Epoch                             189
-----------------------------  ---------------
2019-04-22 22:44:20.813581 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 190 finished
-----------------------------  ----------------
replay_buffer/size              95700
trainer/QF1 Loss                    1.39708
trainer/QF2 Loss                    1.43332
trainer/Policy Loss                13.5578
trainer/Q1 Predictions Mean       -11.8023
trainer/Q1 Predictions Std          8.36818
trainer/Q1 Predictions Max         -6.17531
trainer/Q1 Predictions Min        -36.0465
trainer/Q2 Predictions Mean       -11.78
trainer/Q2 Predictions Std          8.35489
trainer/Q2 Predictions Max         -6.18313
trainer/Q2 Predictions Min        -36.0047
trainer/Q Targets Mean            -11.9209
trainer/Q Targets Std               8.79068
trainer/Q Targets Max              -0.261145
trainer/Q Targets Min             -36.8507
trainer/Log Pis Mean                2.0518
trainer/Log Pis Std                 1.15679
trainer/Log Pis Max                 5.92108
trainer/Log Pis Min                -4.51655
trainer/Policy mu Mean             -0.0727633
trainer/Policy mu Std               0.684848
trainer/Policy mu Max               3.07643
trainer/Policy mu Min              -2.69671
trainer/Policy log std Mean        -2.06209
trainer/Policy log std Std          0.472158
trainer/Policy log std Max         -0.446742
trainer/Policy log std Min         -2.66931
trainer/Alpha                       0.05497
trainer/Alpha Loss                  0.150257
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.42252
exploration/Rewards Std             0.809526
exploration/Rewards Max            -0.00817463
exploration/Rewards Min            -8.18054
exploration/Returns Mean          -42.252
exploration/Returns Std            18.3876
exploration/Returns Max           -23.8562
exploration/Returns Min           -72.6131
exploration/Actions Mean           -0.000595459
exploration/Actions Std             0.23585
exploration/Actions Max             0.998882
exploration/Actions Min            -0.999467
exploration/Num Paths               5
exploration/Average Returns       -42.252
evaluation/num steps total     286500
evaluation/num paths total       2865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.334533
evaluation/Rewards Std              0.860817
evaluation/Rewards Max             -0.0584804
evaluation/Rewards Min            -10.4708
evaluation/Returns Mean           -33.4533
evaluation/Returns Std             23.7138
evaluation/Returns Max             -9.45375
evaluation/Returns Min            -87.0863
evaluation/Actions Mean            -0.00996074
evaluation/Actions Std              0.191543
evaluation/Actions Max              0.996629
evaluation/Actions Min             -0.999439
evaluation/Num Paths               15
evaluation/Average Returns        -33.4533
time/data storing (s)               0.00297977
time/evaluation sampling (s)        0.322613
time/exploration sampling (s)       0.140427
time/logging (s)                    0.00491099
time/saving (s)                     0.00194819
time/training (s)                   1.96422
time/epoch (s)                      2.4371
time/total (s)                    466.331
Epoch                             190
-----------------------------  ----------------
2019-04-22 22:44:23.224467 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              96200
trainer/QF1 Loss                    7.6671
trainer/QF2 Loss                    7.81542
trainer/Policy Loss                14.0155
trainer/Q1 Predictions Mean       -12.1341
trainer/Q1 Predictions Std          9.91618
trainer/Q1 Predictions Max         -6.28653
trainer/Q1 Predictions Min        -55.8465
trainer/Q2 Predictions Mean       -12.1778
trainer/Q2 Predictions Std         10.0004
trainer/Q2 Predictions Max         -6.31396
trainer/Q2 Predictions Min        -56.846
trainer/Q Targets Mean            -11.9775
trainer/Q Targets Std               9.81176
trainer/Q Targets Max              -1.05067
trainer/Q Targets Min             -55.8576
trainer/Log Pis Mean                2.09263
trainer/Log Pis Std                 1.25458
trainer/Log Pis Max                 5.66141
trainer/Log Pis Min                -3.55812
trainer/Policy mu Mean             -0.0819531
trainer/Policy mu Std               0.69234
trainer/Policy mu Max               2.36257
trainer/Policy mu Min              -3.61346
trainer/Policy log std Mean        -2.13542
trainer/Policy log std Std          0.456985
trainer/Policy log std Max         -0.453707
trainer/Policy log std Min         -2.70207
trainer/Alpha                       0.0550175
trainer/Alpha Loss                  0.268655
exploration/num steps total     96200
exploration/num paths total       962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.318558
exploration/Rewards Std             0.9909
exploration/Rewards Max            -0.00584937
exploration/Rewards Min           -10.7603
exploration/Returns Mean          -31.8558
exploration/Returns Std            19.5386
exploration/Returns Max           -15.0844
exploration/Returns Min           -69.5591
exploration/Actions Mean           -0.0188577
exploration/Actions Std             0.23164
exploration/Actions Max             0.992896
exploration/Actions Min            -0.999822
exploration/Num Paths               5
exploration/Average Returns       -31.8558
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.265442
evaluation/Rewards Std              0.972065
evaluation/Rewards Max             -0.0206149
evaluation/Rewards Min            -10.6137
evaluation/Returns Mean           -26.5442
evaluation/Returns Std             18.4554
evaluation/Returns Max             -5.83269
evaluation/Returns Min            -54.9595
evaluation/Actions Mean             0.0044594
evaluation/Actions Std              0.190038
evaluation/Actions Max              0.998815
evaluation/Actions Min             -0.997189
evaluation/Num Paths               15
evaluation/Average Returns        -26.5442
time/data storing (s)               0.00304357
time/evaluation sampling (s)        0.326607
time/exploration sampling (s)       0.142341
time/logging (s)                    0.00458633
time/saving (s)                     0.00203016
time/training (s)                   1.92423
time/epoch (s)                      2.40284
time/total (s)                    468.738
Epoch                             191
-----------------------------  ---------------
2019-04-22 22:44:25.654380 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              96700
trainer/QF1 Loss                    0.447035
trainer/QF2 Loss                    0.445561
trainer/Policy Loss                13.8491
trainer/Q1 Predictions Mean       -12.1827
trainer/Q1 Predictions Std          8.5768
trainer/Q1 Predictions Max         -6.14269
trainer/Q1 Predictions Min        -35.0971
trainer/Q2 Predictions Mean       -12.2221
trainer/Q2 Predictions Std          8.5902
trainer/Q2 Predictions Max         -6.14213
trainer/Q2 Predictions Min        -34.6226
trainer/Q Targets Mean            -12.2757
trainer/Q Targets Std               8.69106
trainer/Q Targets Max              -0.168192
trainer/Q Targets Min             -35.8429
trainer/Log Pis Mean                1.96655
trainer/Log Pis Std                 1.11647
trainer/Log Pis Max                 6.03275
trainer/Log Pis Min                -1.48459
trainer/Policy mu Mean             -0.0492992
trainer/Policy mu Std               0.59282
trainer/Policy mu Max               2.93999
trainer/Policy mu Min              -2.90363
trainer/Policy log std Mean        -2.14575
trainer/Policy log std Std          0.439212
trainer/Policy log std Max         -0.506114
trainer/Policy log std Min         -2.58139
trainer/Alpha                       0.0555408
trainer/Alpha Loss                 -0.0966836
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.37094
exploration/Rewards Std             0.863958
exploration/Rewards Max            -0.00482186
exploration/Rewards Min            -8.5326
exploration/Returns Mean          -37.094
exploration/Returns Std            15.0114
exploration/Returns Max           -16.4403
exploration/Returns Min           -57.3755
exploration/Actions Mean            0.0106843
exploration/Actions Std             0.227062
exploration/Actions Max             0.999115
exploration/Actions Min            -0.981152
exploration/Num Paths               5
exploration/Average Returns       -37.094
evaluation/num steps total     289500
evaluation/num paths total       2895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.38601
evaluation/Rewards Std              0.91367
evaluation/Rewards Max             -0.0156
evaluation/Rewards Min             -9.45563
evaluation/Returns Mean           -38.601
evaluation/Returns Std             20.6046
evaluation/Returns Max             -8.65225
evaluation/Returns Min            -67.4203
evaluation/Actions Mean            -0.0108798
evaluation/Actions Std              0.184242
evaluation/Actions Max              0.99849
evaluation/Actions Min             -0.99744
evaluation/Num Paths               15
evaluation/Average Returns        -38.601
time/data storing (s)               0.00297001
time/evaluation sampling (s)        0.329749
time/exploration sampling (s)       0.140842
time/logging (s)                    0.00364793
time/saving (s)                     0.00155852
time/training (s)                   1.94238
time/epoch (s)                      2.42115
time/total (s)                    471.164
Epoch                             192
-----------------------------  ---------------
2019-04-22 22:44:28.059358 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              97200
trainer/QF1 Loss                    0.378987
trainer/QF2 Loss                    0.479626
trainer/Policy Loss                13.895
trainer/Q1 Predictions Mean       -12.0685
trainer/Q1 Predictions Std         10.5697
trainer/Q1 Predictions Max         -6.3499
trainer/Q1 Predictions Min        -61.8538
trainer/Q2 Predictions Mean       -12.0692
trainer/Q2 Predictions Std         10.5992
trainer/Q2 Predictions Max         -6.33208
trainer/Q2 Predictions Min        -61.9535
trainer/Q Targets Mean            -12.3307
trainer/Q Targets Std              10.8778
trainer/Q Targets Max              -6.26575
trainer/Q Targets Min             -65.526
trainer/Log Pis Mean                2.21109
trainer/Log Pis Std                 1.53292
trainer/Log Pis Max                11.6531
trainer/Log Pis Min                -0.884115
trainer/Policy mu Mean              0.0270859
trainer/Policy mu Std               0.819618
trainer/Policy mu Max               3.64106
trainer/Policy mu Min              -2.96477
trainer/Policy log std Mean        -2.02082
trainer/Policy log std Std          0.506159
trainer/Policy log std Max         -0.273345
trainer/Policy log std Min         -2.659
trainer/Alpha                       0.0563443
trainer/Alpha Loss                  0.607157
exploration/num steps total     97200
exploration/num paths total       972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.425279
exploration/Rewards Std             1.03444
exploration/Rewards Max            -0.00468606
exploration/Rewards Min            -9.29353
exploration/Returns Mean          -42.5279
exploration/Returns Std            17.7305
exploration/Returns Max           -14.1507
exploration/Returns Min           -62.2674
exploration/Actions Mean           -0.00560216
exploration/Actions Std             0.228579
exploration/Actions Max             0.9991
exploration/Actions Min            -0.998497
exploration/Num Paths               5
exploration/Average Returns       -42.5279
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.354119
evaluation/Rewards Std              1.04453
evaluation/Rewards Max             -0.0111376
evaluation/Rewards Min            -10.2872
evaluation/Returns Mean           -35.4119
evaluation/Returns Std             21.0874
evaluation/Returns Max             -4.50467
evaluation/Returns Min            -83.0434
evaluation/Actions Mean             0.00121649
evaluation/Actions Std              0.203989
evaluation/Actions Max              0.997795
evaluation/Actions Min             -0.998254
evaluation/Num Paths               15
evaluation/Average Returns        -35.4119
time/data storing (s)               0.002922
time/evaluation sampling (s)        0.325274
time/exploration sampling (s)       0.142449
time/logging (s)                    0.00483586
time/saving (s)                     0.00160495
time/training (s)                   1.92134
time/epoch (s)                      2.39842
time/total (s)                    473.567
Epoch                             193
-----------------------------  ---------------
2019-04-22 22:44:30.495419 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              97700
trainer/QF1 Loss                    1.19946
trainer/QF2 Loss                    1.21736
trainer/Policy Loss                11.6763
trainer/Q1 Predictions Mean       -10.222
trainer/Q1 Predictions Std          6.55654
trainer/Q1 Predictions Max         -6.2768
trainer/Q1 Predictions Min        -30.0441
trainer/Q2 Predictions Mean       -10.2312
trainer/Q2 Predictions Std          6.55851
trainer/Q2 Predictions Max         -6.30161
trainer/Q2 Predictions Min        -29.8884
trainer/Q Targets Mean            -10.1061
trainer/Q Targets Std               6.64104
trainer/Q Targets Max              -0.0600755
trainer/Q Targets Min             -30.0558
trainer/Log Pis Mean                1.5362
trainer/Log Pis Std                 1.544
trainer/Log Pis Max                 6.57724
trainer/Log Pis Min                -4.89783
trainer/Policy mu Mean             -0.0537473
trainer/Policy mu Std               0.532341
trainer/Policy mu Max               2.95295
trainer/Policy mu Min              -2.78003
trainer/Policy log std Mean        -2.13243
trainer/Policy log std Std          0.352346
trainer/Policy log std Max         -0.600638
trainer/Policy log std Min         -2.63516
trainer/Alpha                       0.0563361
trainer/Alpha Loss                 -1.33406
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.379562
exploration/Rewards Std             1.17278
exploration/Rewards Max            -0.00226056
exploration/Rewards Min           -11.3095
exploration/Returns Mean          -37.9562
exploration/Returns Std            16.1626
exploration/Returns Max           -14.7652
exploration/Returns Min           -64.7848
exploration/Actions Mean           -0.00683874
exploration/Actions Std             0.259988
exploration/Actions Max             0.998083
exploration/Actions Min            -0.997644
exploration/Num Paths               5
exploration/Average Returns       -37.9562
evaluation/num steps total     292500
evaluation/num paths total       2925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.34477
evaluation/Rewards Std              1.10602
evaluation/Rewards Max             -0.00772923
evaluation/Rewards Min            -10.4782
evaluation/Returns Mean           -34.477
evaluation/Returns Std             21.6757
evaluation/Returns Max             -2.87786
evaluation/Returns Min            -81.1276
evaluation/Actions Mean             0.00991721
evaluation/Actions Std              0.19555
evaluation/Actions Max              0.999375
evaluation/Actions Min             -0.999301
evaluation/Num Paths               15
evaluation/Average Returns        -34.477
time/data storing (s)               0.00294837
time/evaluation sampling (s)        0.329724
time/exploration sampling (s)       0.140572
time/logging (s)                    0.00483999
time/saving (s)                     0.00168219
time/training (s)                   1.94857
time/epoch (s)                      2.42834
time/total (s)                    476
Epoch                             194
-----------------------------  ---------------
2019-04-22 22:44:32.924503 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              98200
trainer/QF1 Loss                    0.0293028
trainer/QF2 Loss                    0.0369586
trainer/Policy Loss                13.9994
trainer/Q1 Predictions Mean       -12.4218
trainer/Q1 Predictions Std          9.49146
trainer/Q1 Predictions Max         -6.15959
trainer/Q1 Predictions Min        -43.0929
trainer/Q2 Predictions Mean       -12.4458
trainer/Q2 Predictions Std          9.51245
trainer/Q2 Predictions Max         -6.23453
trainer/Q2 Predictions Min        -43.1204
trainer/Q Targets Mean            -12.4843
trainer/Q Targets Std               9.46458
trainer/Q Targets Max              -6.3508
trainer/Q Targets Min             -43.402
trainer/Log Pis Mean                1.9322
trainer/Log Pis Std                 1.57479
trainer/Log Pis Max                 6.947
trainer/Log Pis Min                -9.34484
trainer/Policy mu Mean             -0.0220609
trainer/Policy mu Std               0.70379
trainer/Policy mu Max               2.77792
trainer/Policy mu Min              -2.93044
trainer/Policy log std Mean        -2.07595
trainer/Policy log std Std          0.506683
trainer/Policy log std Max         -0.306845
trainer/Policy log std Min         -2.60248
trainer/Alpha                       0.0561081
trainer/Alpha Loss                 -0.195284
exploration/num steps total     98200
exploration/num paths total       982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.462918
exploration/Rewards Std             1.17456
exploration/Rewards Max            -0.00323676
exploration/Rewards Min            -9.52839
exploration/Returns Mean          -46.2918
exploration/Returns Std            17.0904
exploration/Returns Max           -18.5397
exploration/Returns Min           -62.4768
exploration/Actions Mean            0.0173913
exploration/Actions Std             0.248129
exploration/Actions Max             0.999687
exploration/Actions Min            -0.999463
exploration/Num Paths               5
exploration/Average Returns       -46.2918
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.294784
evaluation/Rewards Std              0.993978
evaluation/Rewards Max             -0.0105657
evaluation/Rewards Min             -8.77152
evaluation/Returns Mean           -29.4784
evaluation/Returns Std             18.7896
evaluation/Returns Max             -3.66022
evaluation/Returns Min            -71.7502
evaluation/Actions Mean             0.00919482
evaluation/Actions Std              0.188979
evaluation/Actions Max              0.997775
evaluation/Actions Min             -0.998852
evaluation/Num Paths               15
evaluation/Average Returns        -29.4784
time/data storing (s)               0.00294265
time/evaluation sampling (s)        0.322674
time/exploration sampling (s)       0.140492
time/logging (s)                    0.00488896
time/saving (s)                     0.00195115
time/training (s)                   1.94821
time/epoch (s)                      2.42116
time/total (s)                    478.425
Epoch                             195
-----------------------------  ---------------
2019-04-22 22:44:35.368339 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              98700
trainer/QF1 Loss                    2.5077
trainer/QF2 Loss                    2.68372
trainer/Policy Loss                13.4682
trainer/Q1 Predictions Mean       -11.7919
trainer/Q1 Predictions Std          9.47013
trainer/Q1 Predictions Max         -6.07916
trainer/Q1 Predictions Min        -58.8031
trainer/Q2 Predictions Mean       -11.8361
trainer/Q2 Predictions Std          9.48387
trainer/Q2 Predictions Max         -6.05044
trainer/Q2 Predictions Min        -59.3866
trainer/Q Targets Mean            -11.8568
trainer/Q Targets Std               9.59328
trainer/Q Targets Max              -0.328699
trainer/Q Targets Min             -54.7248
trainer/Log Pis Mean                1.95925
trainer/Log Pis Std                 1.44712
trainer/Log Pis Max                 8.3171
trainer/Log Pis Min                -3.62202
trainer/Policy mu Mean             -0.100769
trainer/Policy mu Std               0.738329
trainer/Policy mu Max               3.20783
trainer/Policy mu Min              -3.18545
trainer/Policy log std Mean        -2.10171
trainer/Policy log std Std          0.483252
trainer/Policy log std Max         -0.540263
trainer/Policy log std Min         -2.6007
trainer/Alpha                       0.0571811
trainer/Alpha Loss                 -0.116598
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.376979
exploration/Rewards Std             1.10327
exploration/Rewards Max            -0.00995032
exploration/Rewards Min            -9.47714
exploration/Returns Mean          -37.6979
exploration/Returns Std            14.3781
exploration/Returns Max           -16.8208
exploration/Returns Min           -61.9122
exploration/Actions Mean            0.00741654
exploration/Actions Std             0.247304
exploration/Actions Max             0.999982
exploration/Actions Min            -0.999169
exploration/Num Paths               5
exploration/Average Returns       -37.6979
evaluation/num steps total     295500
evaluation/num paths total       2955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.250726
evaluation/Rewards Std              0.798299
evaluation/Rewards Max             -0.0341962
evaluation/Rewards Min             -9.49533
evaluation/Returns Mean           -25.0726
evaluation/Returns Std             17.3747
evaluation/Returns Max             -3.69232
evaluation/Returns Min            -56.7059
evaluation/Actions Mean             0.00904393
evaluation/Actions Std              0.173428
evaluation/Actions Max              0.997571
evaluation/Actions Min             -0.998513
evaluation/Num Paths               15
evaluation/Average Returns        -25.0726
time/data storing (s)               0.00283577
time/evaluation sampling (s)        0.325429
time/exploration sampling (s)       0.140617
time/logging (s)                    0.00486606
time/saving (s)                     0.00194972
time/training (s)                   1.96077
time/epoch (s)                      2.43646
time/total (s)                    480.866
Epoch                             196
-----------------------------  ---------------
2019-04-22 22:44:37.809262 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              99200
trainer/QF1 Loss                    0.444751
trainer/QF2 Loss                    0.455458
trainer/Policy Loss                14.566
trainer/Q1 Predictions Mean       -12.453
trainer/Q1 Predictions Std          9.55892
trainer/Q1 Predictions Max         -6.21876
trainer/Q1 Predictions Min        -48.2244
trainer/Q2 Predictions Mean       -12.4717
trainer/Q2 Predictions Std          9.50408
trainer/Q2 Predictions Max         -6.25061
trainer/Q2 Predictions Min        -46.4511
trainer/Q Targets Mean            -12.5209
trainer/Q Targets Std               9.70576
trainer/Q Targets Max              -0.0628967
trainer/Q Targets Min             -47.6883
trainer/Log Pis Mean                2.22842
trainer/Log Pis Std                 1.44418
trainer/Log Pis Max                 9.66681
trainer/Log Pis Min                -2.14893
trainer/Policy mu Mean             -0.0135504
trainer/Policy mu Std               0.747653
trainer/Policy mu Max               3.09658
trainer/Policy mu Min              -3.41881
trainer/Policy log std Mean        -2.12515
trainer/Policy log std Std          0.474249
trainer/Policy log std Max         -0.460712
trainer/Policy log std Min         -2.7206
trainer/Alpha                       0.0569546
trainer/Alpha Loss                  0.654578
exploration/num steps total     99200
exploration/num paths total       992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.419295
exploration/Rewards Std             1.01769
exploration/Rewards Max            -0.012767
exploration/Rewards Min            -9.71445
exploration/Returns Mean          -41.9295
exploration/Returns Std            20.8473
exploration/Returns Max           -20.3336
exploration/Returns Min           -69.8754
exploration/Actions Mean            0.0136928
exploration/Actions Std             0.239928
exploration/Actions Max             0.998919
exploration/Actions Min            -0.999831
exploration/Num Paths               5
exploration/Average Returns       -41.9295
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.317144
evaluation/Rewards Std              1.03932
evaluation/Rewards Max             -0.00798963
evaluation/Rewards Min            -11.4337
evaluation/Returns Mean           -31.7144
evaluation/Returns Std             21.9159
evaluation/Returns Max             -2.59928
evaluation/Returns Min            -61.8647
evaluation/Actions Mean             0.00734628
evaluation/Actions Std              0.201709
evaluation/Actions Max              0.998786
evaluation/Actions Min             -0.996703
evaluation/Num Paths               15
evaluation/Average Returns        -31.7144
time/data storing (s)               0.0029376
time/evaluation sampling (s)        0.322974
time/exploration sampling (s)       0.139301
time/logging (s)                    0.00486904
time/saving (s)                     0.00194804
time/training (s)                   1.96119
time/epoch (s)                      2.43322
time/total (s)                    483.304
Epoch                             197
-----------------------------  ---------------
2019-04-22 22:44:40.249569 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              99700
trainer/QF1 Loss                    0.197066
trainer/QF2 Loss                    0.296278
trainer/Policy Loss                13.8978
trainer/Q1 Predictions Mean       -12.4218
trainer/Q1 Predictions Std          9.61954
trainer/Q1 Predictions Max         -6.29313
trainer/Q1 Predictions Min        -67.8293
trainer/Q2 Predictions Mean       -12.4508
trainer/Q2 Predictions Std          9.69296
trainer/Q2 Predictions Max         -6.32455
trainer/Q2 Predictions Min        -69.039
trainer/Q Targets Mean            -12.5383
trainer/Q Targets Std               9.52756
trainer/Q Targets Max              -6.23735
trainer/Q Targets Min             -64.2595
trainer/Log Pis Mean                1.78466
trainer/Log Pis Std                 1.3878
trainer/Log Pis Max                 6.15708
trainer/Log Pis Min                -3.74432
trainer/Policy mu Mean              0.0462397
trainer/Policy mu Std               0.652187
trainer/Policy mu Max               3.32838
trainer/Policy mu Min              -3.06078
trainer/Policy log std Mean        -2.08411
trainer/Policy log std Std          0.444119
trainer/Policy log std Max         -0.347616
trainer/Policy log std Min         -2.60034
trainer/Alpha                       0.0570378
trainer/Alpha Loss                 -0.61671
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.374409
exploration/Rewards Std             1.02844
exploration/Rewards Max            -0.0047198
exploration/Rewards Min            -8.92952
exploration/Returns Mean          -37.4409
exploration/Returns Std            12.929
exploration/Returns Max           -26.3684
exploration/Returns Min           -57.8379
exploration/Actions Mean           -0.00270794
exploration/Actions Std             0.252343
exploration/Actions Max             0.999429
exploration/Actions Min            -0.99979
exploration/Num Paths               5
exploration/Average Returns       -37.4409
evaluation/num steps total     298500
evaluation/num paths total       2985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.275918
evaluation/Rewards Std              0.955837
evaluation/Rewards Max             -0.023724
evaluation/Rewards Min            -10.8835
evaluation/Returns Mean           -27.5918
evaluation/Returns Std             26.2573
evaluation/Returns Max             -5.78695
evaluation/Returns Min            -93.1464
evaluation/Actions Mean            -0.0151693
evaluation/Actions Std              0.188952
evaluation/Actions Max              0.992892
evaluation/Actions Min             -0.999317
evaluation/Num Paths               15
evaluation/Average Returns        -27.5918
time/data storing (s)               0.00306031
time/evaluation sampling (s)        0.322775
time/exploration sampling (s)       0.144479
time/logging (s)                    0.00441999
time/saving (s)                     0.00195993
time/training (s)                   1.95532
time/epoch (s)                      2.43202
time/total (s)                    485.74
Epoch                             198
-----------------------------  ---------------
2019-04-22 22:44:42.682808 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.00773
trainer/QF2 Loss                    2.00004
trainer/Policy Loss                12.8998
trainer/Q1 Predictions Mean       -11.2369
trainer/Q1 Predictions Std          7.91863
trainer/Q1 Predictions Max         -6.27317
trainer/Q1 Predictions Min        -44.8836
trainer/Q2 Predictions Mean       -11.254
trainer/Q2 Predictions Std          7.9611
trainer/Q2 Predictions Max         -6.24384
trainer/Q2 Predictions Min        -45.1278
trainer/Q Targets Mean            -11.1178
trainer/Q Targets Std               8.25975
trainer/Q Targets Max              -0.188973
trainer/Q Targets Min             -45.9141
trainer/Log Pis Mean                1.96049
trainer/Log Pis Std                 1.13201
trainer/Log Pis Max                 5.55711
trainer/Log Pis Min                -1.14466
trainer/Policy mu Mean             -0.00053475
trainer/Policy mu Std               0.712488
trainer/Policy mu Max               2.63653
trainer/Policy mu Min              -3.1256
trainer/Policy log std Mean        -2.07255
trainer/Policy log std Std          0.487553
trainer/Policy log std Max         -0.494449
trainer/Policy log std Min         -2.61764
trainer/Alpha                       0.0554383
trainer/Alpha Loss                 -0.114273
exploration/num steps total    100200
exploration/num paths total      1002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.338792
exploration/Rewards Std             0.749537
exploration/Rewards Max            -0.0170043
exploration/Rewards Min            -7.05734
exploration/Returns Mean          -33.8792
exploration/Returns Std            19.8231
exploration/Returns Max           -18.4427
exploration/Returns Min           -72.8646
exploration/Actions Mean            0.0198
exploration/Actions Std             0.220562
exploration/Actions Max             0.997645
exploration/Actions Min            -0.999888
exploration/Num Paths               5
exploration/Average Returns       -33.8792
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.3101
evaluation/Rewards Std              0.982135
evaluation/Rewards Max             -0.0459245
evaluation/Rewards Min            -11.5171
evaluation/Returns Mean           -31.01
evaluation/Returns Std             23.0061
evaluation/Returns Max             -9.10678
evaluation/Returns Min            -90.8927
evaluation/Actions Mean             0.00135873
evaluation/Actions Std              0.189126
evaluation/Actions Max              0.998189
evaluation/Actions Min             -0.998905
evaluation/Num Paths               15
evaluation/Average Returns        -31.01
time/data storing (s)               0.00267932
time/evaluation sampling (s)        0.336408
time/exploration sampling (s)       0.1383
time/logging (s)                    0.00488911
time/saving (s)                     0.00998461
time/training (s)                   1.93465
time/epoch (s)                      2.42691
time/total (s)                    488.171
Epoch                             199
-----------------------------  ---------------
2019-04-22 22:44:45.112295 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 200 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.87023
trainer/QF2 Loss                    6.94327
trainer/Policy Loss                12.7149
trainer/Q1 Predictions Mean       -10.9452
trainer/Q1 Predictions Std          7.55076
trainer/Q1 Predictions Max         -6.20028
trainer/Q1 Predictions Min        -30.4838
trainer/Q2 Predictions Mean       -10.9621
trainer/Q2 Predictions Std          7.56824
trainer/Q2 Predictions Max         -6.19698
trainer/Q2 Predictions Min        -30.6671
trainer/Q Targets Mean            -10.7859
trainer/Q Targets Std               7.46847
trainer/Q Targets Max              -1.00331
trainer/Q Targets Min             -31.0663
trainer/Log Pis Mean                1.85712
trainer/Log Pis Std                 1.15797
trainer/Log Pis Max                 5.41621
trainer/Log Pis Min                -2.84676
trainer/Policy mu Mean             -0.0197788
trainer/Policy mu Std               0.598256
trainer/Policy mu Max               3.08315
trainer/Policy mu Min              -2.88821
trainer/Policy log std Mean        -2.08983
trainer/Policy log std Std          0.422112
trainer/Policy log std Max         -0.567522
trainer/Policy log std Min         -2.51492
trainer/Alpha                       0.0550343
trainer/Alpha Loss                 -0.414287
exploration/num steps total    100700
exploration/num paths total      1007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.34303
exploration/Rewards Std             0.861294
exploration/Rewards Max            -0.0104337
exploration/Rewards Min            -6.69402
exploration/Returns Mean          -34.303
exploration/Returns Std             4.48573
exploration/Returns Max           -28.9724
exploration/Returns Min           -40.3647
exploration/Actions Mean            0.0361459
exploration/Actions Std             0.249306
exploration/Actions Max             0.998959
exploration/Actions Min            -0.915819
exploration/Num Paths               5
exploration/Average Returns       -34.303
evaluation/num steps total     301500
evaluation/num paths total       3015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.356825
evaluation/Rewards Std              0.863466
evaluation/Rewards Max             -0.0308612
evaluation/Rewards Min             -9.52941
evaluation/Returns Mean           -35.6825
evaluation/Returns Std             23.8358
evaluation/Returns Max             -6.62695
evaluation/Returns Min            -77.6537
evaluation/Actions Mean             0.00576313
evaluation/Actions Std              0.186542
evaluation/Actions Max              0.999544
evaluation/Actions Min             -0.996705
evaluation/Num Paths               15
evaluation/Average Returns        -35.6825
time/data storing (s)               0.00275887
time/evaluation sampling (s)        0.32329
time/exploration sampling (s)       0.140992
time/logging (s)                    0.00472242
time/saving (s)                     0.00200885
time/training (s)                   1.94774
time/epoch (s)                      2.42152
time/total (s)                    490.598
Epoch                             200
-----------------------------  ---------------
2019-04-22 22:44:47.535207 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 201 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.755092
trainer/QF2 Loss                    0.796256
trainer/Policy Loss                13.5782
trainer/Q1 Predictions Mean       -11.653
trainer/Q1 Predictions Std          9.20039
trainer/Q1 Predictions Max         -6.16378
trainer/Q1 Predictions Min        -52.6873
trainer/Q2 Predictions Mean       -11.6463
trainer/Q2 Predictions Std          9.21013
trainer/Q2 Predictions Max         -6.13223
trainer/Q2 Predictions Min        -53.3442
trainer/Q Targets Mean            -11.7347
trainer/Q Targets Std               9.42729
trainer/Q Targets Max              -0.15418
trainer/Q Targets Min             -52.7848
trainer/Log Pis Mean                2.1217
trainer/Log Pis Std                 1.06707
trainer/Log Pis Max                 7.69338
trainer/Log Pis Min                -0.984912
trainer/Policy mu Mean             -0.0161057
trainer/Policy mu Std               0.660636
trainer/Policy mu Max               3.37956
trainer/Policy mu Min              -3.36844
trainer/Policy log std Mean        -2.17687
trainer/Policy log std Std          0.469368
trainer/Policy log std Max         -0.303851
trainer/Policy log std Min         -2.75364
trainer/Alpha                       0.0566136
trainer/Alpha Loss                  0.349488
exploration/num steps total    101200
exploration/num paths total      1012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375413
exploration/Rewards Std             1.23183
exploration/Rewards Max            -0.00469895
exploration/Rewards Min           -11.2812
exploration/Returns Mean          -37.5413
exploration/Returns Std            20.252
exploration/Returns Max           -12.5304
exploration/Returns Min           -67.7784
exploration/Actions Mean            0.0317586
exploration/Actions Std             0.249623
exploration/Actions Max             0.999235
exploration/Actions Min            -0.999147
exploration/Num Paths               5
exploration/Average Returns       -37.5413
evaluation/num steps total     303000
evaluation/num paths total       3030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.352042
evaluation/Rewards Std              1.15445
evaluation/Rewards Max             -0.00182266
evaluation/Rewards Min            -11.6503
evaluation/Returns Mean           -35.2042
evaluation/Returns Std             19.3589
evaluation/Returns Max             -2.07356
evaluation/Returns Min            -62.672
evaluation/Actions Mean            -0.00470983
evaluation/Actions Std              0.201261
evaluation/Actions Max              0.997855
evaluation/Actions Min             -0.999427
evaluation/Num Paths               15
evaluation/Average Returns        -35.2042
time/data storing (s)               0.00287353
time/evaluation sampling (s)        0.32901
time/exploration sampling (s)       0.138082
time/logging (s)                    0.00483461
time/saving (s)                     0.00154847
time/training (s)                   1.9385
time/epoch (s)                      2.41485
time/total (s)                    493.017
Epoch                             201
-----------------------------  ---------------
2019-04-22 22:44:49.982222 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 202 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   14.1468
trainer/QF2 Loss                   14.2599
trainer/Policy Loss                15.7615
trainer/Q1 Predictions Mean       -13.6097
trainer/Q1 Predictions Std          9.04668
trainer/Q1 Predictions Max         -6.08459
trainer/Q1 Predictions Min        -34.7851
trainer/Q2 Predictions Mean       -13.6313
trainer/Q2 Predictions Std          9.02635
trainer/Q2 Predictions Max         -6.13173
trainer/Q2 Predictions Min        -34.4097
trainer/Q Targets Mean            -13.1166
trainer/Q Targets Std               9.21937
trainer/Q Targets Max              -0.222642
trainer/Q Targets Min             -34.1307
trainer/Log Pis Mean                2.33338
trainer/Log Pis Std                 0.992763
trainer/Log Pis Max                 5.29229
trainer/Log Pis Min                -0.23356
trainer/Policy mu Mean             -0.0596037
trainer/Policy mu Std               0.581109
trainer/Policy mu Max               3.2284
trainer/Policy mu Min              -2.96379
trainer/Policy log std Mean        -2.24818
trainer/Policy log std Std          0.464202
trainer/Policy log std Max         -0.40438
trainer/Policy log std Min         -2.77655
trainer/Alpha                       0.0576193
trainer/Alpha Loss                  0.951438
exploration/num steps total    101700
exploration/num paths total      1017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.308387
exploration/Rewards Std             0.858
exploration/Rewards Max            -0.00265681
exploration/Rewards Min            -7.80113
exploration/Returns Mean          -30.8387
exploration/Returns Std            10.6727
exploration/Returns Max           -17.69
exploration/Returns Min           -46.7981
exploration/Actions Mean           -0.00271031
exploration/Actions Std             0.223467
exploration/Actions Max             0.997398
exploration/Actions Min            -0.998281
exploration/Num Paths               5
exploration/Average Returns       -30.8387
evaluation/num steps total     304500
evaluation/num paths total       3045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298459
evaluation/Rewards Std              1.03274
evaluation/Rewards Max             -0.0163614
evaluation/Rewards Min            -10.8695
evaluation/Returns Mean           -29.8459
evaluation/Returns Std             24.622
evaluation/Returns Max             -6.2153
evaluation/Returns Min            -86.8365
evaluation/Actions Mean            -0.011121
evaluation/Actions Std              0.191259
evaluation/Actions Max              0.998602
evaluation/Actions Min             -0.999251
evaluation/Num Paths               15
evaluation/Average Returns        -29.8459
time/data storing (s)               0.0026877
time/evaluation sampling (s)        0.326382
time/exploration sampling (s)       0.138467
time/logging (s)                    0.0048721
time/saving (s)                     0.00154794
time/training (s)                   1.96648
time/epoch (s)                      2.44044
time/total (s)                    495.462
Epoch                             202
-----------------------------  ---------------
2019-04-22 22:44:52.426182 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 203 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.919705
trainer/QF2 Loss                    0.912499
trainer/Policy Loss                13.7344
trainer/Q1 Predictions Mean       -11.8742
trainer/Q1 Predictions Std          8.96175
trainer/Q1 Predictions Max         -6.01211
trainer/Q1 Predictions Min        -48.5589
trainer/Q2 Predictions Mean       -11.8823
trainer/Q2 Predictions Std          8.97243
trainer/Q2 Predictions Max         -5.99446
trainer/Q2 Predictions Min        -49.0316
trainer/Q Targets Mean            -11.9228
trainer/Q Targets Std               9.15668
trainer/Q Targets Max              -0.118753
trainer/Q Targets Min             -50.4061
trainer/Log Pis Mean                1.97687
trainer/Log Pis Std                 1.19222
trainer/Log Pis Max                 5.58393
trainer/Log Pis Min                -3.3082
trainer/Policy mu Mean             -0.03952
trainer/Policy mu Std               0.47772
trainer/Policy mu Max               3.34484
trainer/Policy mu Min              -3.11045
trainer/Policy log std Mean        -2.23167
trainer/Policy log std Std          0.324749
trainer/Policy log std Max         -0.559485
trainer/Policy log std Min         -2.74762
trainer/Alpha                       0.0571797
trainer/Alpha Loss                 -0.0661791
exploration/num steps total    102200
exploration/num paths total      1022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.377173
exploration/Rewards Std             0.701715
exploration/Rewards Max            -0.00527077
exploration/Rewards Min            -7.95552
exploration/Returns Mean          -37.7173
exploration/Returns Std            18.5373
exploration/Returns Max           -14.416
exploration/Returns Min           -54.4897
exploration/Actions Mean           -0.00449262
exploration/Actions Std             0.205516
exploration/Actions Max             0.9883
exploration/Actions Min            -0.999651
exploration/Num Paths               5
exploration/Average Returns       -37.7173
evaluation/num steps total     306000
evaluation/num paths total       3060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.326928
evaluation/Rewards Std              0.885759
evaluation/Rewards Max             -0.00623054
evaluation/Rewards Min             -9.6627
evaluation/Returns Mean           -32.6928
evaluation/Returns Std             25.0729
evaluation/Returns Max             -3.42315
evaluation/Returns Min            -85.9439
evaluation/Actions Mean            -7.56054e-05
evaluation/Actions Std              0.176478
evaluation/Actions Max              0.997464
evaluation/Actions Min             -0.999174
evaluation/Num Paths               15
evaluation/Average Returns        -32.6928
time/data storing (s)               0.00277939
time/evaluation sampling (s)        0.32949
time/exploration sampling (s)       0.140002
time/logging (s)                    0.00485379
time/saving (s)                     0.00192332
time/training (s)                   1.95674
time/epoch (s)                      2.43579
time/total (s)                    497.902
Epoch                             203
-----------------------------  ----------------
2019-04-22 22:44:54.851389 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 204 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.86772
trainer/QF2 Loss                    0.907153
trainer/Policy Loss                14.1641
trainer/Q1 Predictions Mean       -12.0611
trainer/Q1 Predictions Std          9.21778
trainer/Q1 Predictions Max         -6.08392
trainer/Q1 Predictions Min        -49.1936
trainer/Q2 Predictions Mean       -12.088
trainer/Q2 Predictions Std          9.24978
trainer/Q2 Predictions Max         -6.12005
trainer/Q2 Predictions Min        -50.1688
trainer/Q Targets Mean            -11.9043
trainer/Q Targets Std               9.08433
trainer/Q Targets Max              -0.240402
trainer/Q Targets Min             -47.8234
trainer/Log Pis Mean                2.2645
trainer/Log Pis Std                 1.1824
trainer/Log Pis Max                 7.25407
trainer/Log Pis Min                -0.553859
trainer/Policy mu Mean             -0.0421611
trainer/Policy mu Std               0.783565
trainer/Policy mu Max               3.30365
trainer/Policy mu Min              -3.39346
trainer/Policy log std Mean        -2.09051
trainer/Policy log std Std          0.531675
trainer/Policy log std Max         -0.501401
trainer/Policy log std Min         -2.78829
trainer/Alpha                       0.0567854
trainer/Alpha Loss                  0.758723
exploration/num steps total    102700
exploration/num paths total      1027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.397155
exploration/Rewards Std             1.14562
exploration/Rewards Max            -0.00311845
exploration/Rewards Min           -10.2634
exploration/Returns Mean          -39.7155
exploration/Returns Std            15.5132
exploration/Returns Max           -20.4879
exploration/Returns Min           -62.2045
exploration/Actions Mean           -0.00166292
exploration/Actions Std             0.257886
exploration/Actions Max             0.9997
exploration/Actions Min            -0.999405
exploration/Num Paths               5
exploration/Average Returns       -39.7155
evaluation/num steps total     307500
evaluation/num paths total       3075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.246668
evaluation/Rewards Std              0.84236
evaluation/Rewards Max             -0.0112391
evaluation/Rewards Min            -10.5112
evaluation/Returns Mean           -24.6668
evaluation/Returns Std             19.0735
evaluation/Returns Max             -4.96013
evaluation/Returns Min            -60.6584
evaluation/Actions Mean            -0.00475579
evaluation/Actions Std              0.173614
evaluation/Actions Max              0.996034
evaluation/Actions Min             -0.998455
evaluation/Num Paths               15
evaluation/Average Returns        -24.6668
time/data storing (s)               0.00282163
time/evaluation sampling (s)        0.322952
time/exploration sampling (s)       0.138055
time/logging (s)                    0.00384947
time/saving (s)                     0.00197044
time/training (s)                   1.94691
time/epoch (s)                      2.41656
time/total (s)                    500.323
Epoch                             204
-----------------------------  ---------------
2019-04-22 22:44:57.264596 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 205 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0289709
trainer/QF2 Loss                    0.0363282
trainer/Policy Loss                13.4282
trainer/Q1 Predictions Mean       -11.232
trainer/Q1 Predictions Std          7.97984
trainer/Q1 Predictions Max         -6.12089
trainer/Q1 Predictions Min        -39.4905
trainer/Q2 Predictions Mean       -11.2421
trainer/Q2 Predictions Std          7.97038
trainer/Q2 Predictions Max         -6.16683
trainer/Q2 Predictions Min        -39.538
trainer/Q Targets Mean            -11.316
trainer/Q Targets Std               7.95513
trainer/Q Targets Max              -6.23374
trainer/Q Targets Min             -38.9944
trainer/Log Pis Mean                2.2732
trainer/Log Pis Std                 1.16425
trainer/Log Pis Max                 8.61766
trainer/Log Pis Min                -0.987599
trainer/Policy mu Mean              0.00448237
trainer/Policy mu Std               0.655383
trainer/Policy mu Max               3.05266
trainer/Policy mu Min              -2.77936
trainer/Policy log std Mean        -2.15372
trainer/Policy log std Std          0.444519
trainer/Policy log std Max         -0.454899
trainer/Policy log std Min         -2.61966
trainer/Alpha                       0.0562802
trainer/Alpha Loss                  0.786132
exploration/num steps total    103200
exploration/num paths total      1032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.413775
exploration/Rewards Std             0.988751
exploration/Rewards Max            -0.0079833
exploration/Rewards Min            -9.10786
exploration/Returns Mean          -41.3775
exploration/Returns Std            17.3617
exploration/Returns Max           -19.0372
exploration/Returns Min           -62.4315
exploration/Actions Mean            0.00696339
exploration/Actions Std             0.234875
exploration/Actions Max             0.99908
exploration/Actions Min            -0.999098
exploration/Num Paths               5
exploration/Average Returns       -41.3775
evaluation/num steps total     309000
evaluation/num paths total       3090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.276442
evaluation/Rewards Std              0.925571
evaluation/Rewards Max             -0.0150803
evaluation/Rewards Min            -10.1677
evaluation/Returns Mean           -27.6442
evaluation/Returns Std             22.1061
evaluation/Returns Max             -2.3035
evaluation/Returns Min            -75.626
evaluation/Actions Mean             0.0165739
evaluation/Actions Std              0.187301
evaluation/Actions Max              0.99766
evaluation/Actions Min             -0.998287
evaluation/Num Paths               15
evaluation/Average Returns        -27.6442
time/data storing (s)               0.00276738
time/evaluation sampling (s)        0.337484
time/exploration sampling (s)       0.138225
time/logging (s)                    0.00407264
time/saving (s)                     0.00155721
time/training (s)                   1.92171
time/epoch (s)                      2.40581
time/total (s)                    502.733
Epoch                             205
-----------------------------  ---------------
2019-04-22 22:44:59.700830 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 206 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.533
trainer/QF2 Loss                    0.548346
trainer/Policy Loss                13.2053
trainer/Q1 Predictions Mean       -11.3864
trainer/Q1 Predictions Std          7.84973
trainer/Q1 Predictions Max         -6.10687
trainer/Q1 Predictions Min        -29.6277
trainer/Q2 Predictions Mean       -11.3845
trainer/Q2 Predictions Std          7.85334
trainer/Q2 Predictions Max         -6.14082
trainer/Q2 Predictions Min        -30.2791
trainer/Q Targets Mean            -11.3749
trainer/Q Targets Std               7.94825
trainer/Q Targets Max              -0.268265
trainer/Q Targets Min             -29.2585
trainer/Log Pis Mean                1.99814
trainer/Log Pis Std                 1.01138
trainer/Log Pis Max                 5.83109
trainer/Log Pis Min                -2.34333
trainer/Policy mu Mean             -0.016187
trainer/Policy mu Std               0.561259
trainer/Policy mu Max               3.07852
trainer/Policy mu Min              -2.06844
trainer/Policy log std Mean        -2.16472
trainer/Policy log std Std          0.421699
trainer/Policy log std Max         -0.40538
trainer/Policy log std Min         -2.57806
trainer/Alpha                       0.0558188
trainer/Alpha Loss                 -0.00535331
exploration/num steps total    103700
exploration/num paths total      1037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.519122
exploration/Rewards Std             1.13123
exploration/Rewards Max            -0.0137568
exploration/Rewards Min            -8.5511
exploration/Returns Mean          -51.9122
exploration/Returns Std            13.6301
exploration/Returns Max           -34.3582
exploration/Returns Min           -71.1816
exploration/Actions Mean           -0.021038
exploration/Actions Std             0.254042
exploration/Actions Max             0.999021
exploration/Actions Min            -0.99912
exploration/Num Paths               5
exploration/Average Returns       -51.9122
evaluation/num steps total     310500
evaluation/num paths total       3105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.280816
evaluation/Rewards Std              0.667749
evaluation/Rewards Max             -0.00920785
evaluation/Rewards Min             -9.24404
evaluation/Returns Mean           -28.0816
evaluation/Returns Std             19.4053
evaluation/Returns Max             -2.50896
evaluation/Returns Min            -60.148
evaluation/Actions Mean             0.00558244
evaluation/Actions Std              0.167797
evaluation/Actions Max              0.997738
evaluation/Actions Min             -0.995801
evaluation/Num Paths               15
evaluation/Average Returns        -28.0816
time/data storing (s)               0.00266269
time/evaluation sampling (s)        0.32455
time/exploration sampling (s)       0.139685
time/logging (s)                    0.00485845
time/saving (s)                     0.00193885
time/training (s)                   1.95603
time/epoch (s)                      2.42972
time/total (s)                    505.167
Epoch                             206
-----------------------------  ---------------
2019-04-22 22:45:02.150857 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 207 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.42785
trainer/QF2 Loss                    6.46111
trainer/Policy Loss                13.003
trainer/Q1 Predictions Mean       -11.1016
trainer/Q1 Predictions Std          8.50695
trainer/Q1 Predictions Max         -6.26957
trainer/Q1 Predictions Min        -51.9762
trainer/Q2 Predictions Mean       -11.0903
trainer/Q2 Predictions Std          8.50853
trainer/Q2 Predictions Max         -6.24622
trainer/Q2 Predictions Min        -51.946
trainer/Q Targets Mean            -10.9707
trainer/Q Targets Std               8.52125
trainer/Q Targets Max              -0.93363
trainer/Q Targets Min             -51.8038
trainer/Log Pis Mean                2.00842
trainer/Log Pis Std                 1.1383
trainer/Log Pis Max                 5.91412
trainer/Log Pis Min                -1.12196
trainer/Policy mu Mean              0.0379883
trainer/Policy mu Std               0.552705
trainer/Policy mu Max               3.06565
trainer/Policy mu Min              -3.45786
trainer/Policy log std Mean        -2.17152
trainer/Policy log std Std          0.333444
trainer/Policy log std Max         -0.550732
trainer/Policy log std Min         -2.55235
trainer/Alpha                       0.0544211
trainer/Alpha Loss                  0.0245224
exploration/num steps total    104200
exploration/num paths total      1042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.28838
exploration/Rewards Std             0.63724
exploration/Rewards Max            -0.00423616
exploration/Rewards Min            -8.37976
exploration/Returns Mean          -28.838
exploration/Returns Std            14.006
exploration/Returns Max           -16.1187
exploration/Returns Min           -47.7812
exploration/Actions Mean           -0.00182419
exploration/Actions Std             0.200698
exploration/Actions Max             0.995468
exploration/Actions Min            -0.997911
exploration/Num Paths               5
exploration/Average Returns       -28.838
evaluation/num steps total     312000
evaluation/num paths total       3120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261145
evaluation/Rewards Std              1.14513
evaluation/Rewards Max             -0.0018316
evaluation/Rewards Min            -12.0385
evaluation/Returns Mean           -26.1145
evaluation/Returns Std             21.9086
evaluation/Returns Max             -2.85797
evaluation/Returns Min            -64.6789
evaluation/Actions Mean             0.000364687
evaluation/Actions Std              0.189369
evaluation/Actions Max              0.998641
evaluation/Actions Min             -0.998713
evaluation/Num Paths               15
evaluation/Average Returns        -26.1145
time/data storing (s)               0.00284577
time/evaluation sampling (s)        0.324448
time/exploration sampling (s)       0.142536
time/logging (s)                    0.00493436
time/saving (s)                     0.00196361
time/training (s)                   1.96564
time/epoch (s)                      2.44236
time/total (s)                    507.614
Epoch                             207
-----------------------------  ----------------
2019-04-22 22:45:04.570808 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 208 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.483196
trainer/QF2 Loss                    0.472593
trainer/Policy Loss                13.2207
trainer/Q1 Predictions Mean       -11.2022
trainer/Q1 Predictions Std          7.9245
trainer/Q1 Predictions Max         -6.11565
trainer/Q1 Predictions Min        -35.112
trainer/Q2 Predictions Mean       -11.2214
trainer/Q2 Predictions Std          8.02371
trainer/Q2 Predictions Max         -6.14385
trainer/Q2 Predictions Min        -37.0656
trainer/Q Targets Mean            -11.2714
trainer/Q Targets Std               8.13003
trainer/Q Targets Max              -0.123687
trainer/Q Targets Min             -36.6377
trainer/Log Pis Mean                2.12472
trainer/Log Pis Std                 1.06492
trainer/Log Pis Max                 7.29854
trainer/Log Pis Min                -0.926162
trainer/Policy mu Mean             -0.0167162
trainer/Policy mu Std               0.614823
trainer/Policy mu Max               3.03112
trainer/Policy mu Min              -3.34026
trainer/Policy log std Mean        -2.24101
trainer/Policy log std Std          0.408937
trainer/Policy log std Max         -0.559921
trainer/Policy log std Min         -2.55954
trainer/Alpha                       0.0545796
trainer/Alpha Loss                  0.362696
exploration/num steps total    104700
exploration/num paths total      1047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.283287
exploration/Rewards Std             0.801492
exploration/Rewards Max            -0.00397276
exploration/Rewards Min            -8.06218
exploration/Returns Mean          -28.3287
exploration/Returns Std            11.5308
exploration/Returns Max           -18.3833
exploration/Returns Min           -49.6875
exploration/Actions Mean           -0.0120482
exploration/Actions Std             0.225339
exploration/Actions Max             0.999525
exploration/Actions Min            -0.997528
exploration/Num Paths               5
exploration/Average Returns       -28.3287
evaluation/num steps total     313500
evaluation/num paths total       3135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.318086
evaluation/Rewards Std              1.08218
evaluation/Rewards Max             -0.0154789
evaluation/Rewards Min            -10.5554
evaluation/Returns Mean           -31.8086
evaluation/Returns Std             21.9011
evaluation/Returns Max             -4.11296
evaluation/Returns Min            -66.4805
evaluation/Actions Mean             0.00497608
evaluation/Actions Std              0.191633
evaluation/Actions Max              0.998191
evaluation/Actions Min             -0.996885
evaluation/Num Paths               15
evaluation/Average Returns        -31.8086
time/data storing (s)               0.00268744
time/evaluation sampling (s)        0.325728
time/exploration sampling (s)       0.138179
time/logging (s)                    0.00485632
time/saving (s)                     0.00194057
time/training (s)                   1.93885
time/epoch (s)                      2.41224
time/total (s)                    510.03
Epoch                             208
-----------------------------  ---------------
2019-04-22 22:45:06.985452 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 209 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.75564
trainer/QF2 Loss                    7.77592
trainer/Policy Loss                12.7706
trainer/Q1 Predictions Mean       -10.7206
trainer/Q1 Predictions Std          8.3534
trainer/Q1 Predictions Max         -6.30896
trainer/Q1 Predictions Min        -44.4127
trainer/Q2 Predictions Mean       -10.7481
trainer/Q2 Predictions Std          8.34296
trainer/Q2 Predictions Max         -6.33699
trainer/Q2 Predictions Min        -43.993
trainer/Q Targets Mean            -10.4055
trainer/Q Targets Std               8.40012
trainer/Q Targets Max              -0.19183
trainer/Q Targets Min             -45.2945
trainer/Log Pis Mean                2.09229
trainer/Log Pis Std                 1.32279
trainer/Log Pis Max                 7.29485
trainer/Log Pis Min                -2.8619
trainer/Policy mu Mean             -0.0491769
trainer/Policy mu Std               0.731491
trainer/Policy mu Max               2.94665
trainer/Policy mu Min              -3.33287
trainer/Policy log std Mean        -2.14253
trainer/Policy log std Std          0.461323
trainer/Policy log std Max         -0.479744
trainer/Policy log std Min         -2.59323
trainer/Alpha                       0.0545803
trainer/Alpha Loss                  0.268399
exploration/num steps total    105200
exploration/num paths total      1052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.38941
exploration/Rewards Std             0.957007
exploration/Rewards Max            -0.00600918
exploration/Rewards Min            -7.3401
exploration/Returns Mean          -38.941
exploration/Returns Std            17.6151
exploration/Returns Max           -15.0105
exploration/Returns Min           -67.0614
exploration/Actions Mean            0.011949
exploration/Actions Std             0.228012
exploration/Actions Max             0.999551
exploration/Actions Min            -0.998568
exploration/Num Paths               5
exploration/Average Returns       -38.941
evaluation/num steps total     315000
evaluation/num paths total       3150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.320683
evaluation/Rewards Std              0.7827
evaluation/Rewards Max             -0.0199414
evaluation/Rewards Min             -9.16817
evaluation/Returns Mean           -32.0683
evaluation/Returns Std             20.1432
evaluation/Returns Max             -6.51866
evaluation/Returns Min            -77.6371
evaluation/Actions Mean            -0.0127189
evaluation/Actions Std              0.190149
evaluation/Actions Max              0.996724
evaluation/Actions Min             -0.998843
evaluation/Num Paths               15
evaluation/Average Returns        -32.0683
time/data storing (s)               0.00284388
time/evaluation sampling (s)        0.323496
time/exploration sampling (s)       0.140616
time/logging (s)                    0.00482824
time/saving (s)                     0.00193931
time/training (s)                   1.93352
time/epoch (s)                      2.40724
time/total (s)                    512.441
Epoch                             209
-----------------------------  ---------------
2019-04-22 22:45:09.418261 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 210 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.575912
trainer/QF2 Loss                    0.585067
trainer/Policy Loss                13.3886
trainer/Q1 Predictions Mean       -11.5073
trainer/Q1 Predictions Std          7.86006
trainer/Q1 Predictions Max         -6.14501
trainer/Q1 Predictions Min        -30.791
trainer/Q2 Predictions Mean       -11.517
trainer/Q2 Predictions Std          7.84818
trainer/Q2 Predictions Max         -6.16179
trainer/Q2 Predictions Min        -30.9456
trainer/Q Targets Mean            -11.4631
trainer/Q Targets Std               7.87386
trainer/Q Targets Max              -0.0236494
trainer/Q Targets Min             -30.2902
trainer/Log Pis Mean                1.96076
trainer/Log Pis Std                 1.30861
trainer/Log Pis Max                 8.40684
trainer/Log Pis Min                -2.18496
trainer/Policy mu Mean              0.0220124
trainer/Policy mu Std               0.591255
trainer/Policy mu Max               3.21056
trainer/Policy mu Min              -2.74615
trainer/Policy log std Mean        -2.15318
trainer/Policy log std Std          0.408893
trainer/Policy log std Max         -0.426704
trainer/Policy log std Min         -2.631
trainer/Alpha                       0.0564006
trainer/Alpha Loss                 -0.112811
exploration/num steps total    105700
exploration/num paths total      1057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.298678
exploration/Rewards Std             0.791688
exploration/Rewards Max            -0.0120674
exploration/Rewards Min            -6.72967
exploration/Returns Mean          -29.8678
exploration/Returns Std             3.47934
exploration/Returns Max           -25.4464
exploration/Returns Min           -35.7155
exploration/Actions Mean            0.0300731
exploration/Actions Std             0.232586
exploration/Actions Max             0.99806
exploration/Actions Min            -0.978831
exploration/Num Paths               5
exploration/Average Returns       -29.8678
evaluation/num steps total     316500
evaluation/num paths total       3165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.19919
evaluation/Rewards Std              0.844821
evaluation/Rewards Max             -0.00688977
evaluation/Rewards Min             -9.66455
evaluation/Returns Mean           -19.919
evaluation/Returns Std             13.2583
evaluation/Returns Max             -2.57161
evaluation/Returns Min            -46.5221
evaluation/Actions Mean             0.0222001
evaluation/Actions Std              0.183147
evaluation/Actions Max              0.997731
evaluation/Actions Min             -0.994411
evaluation/Num Paths               15
evaluation/Average Returns        -19.919
time/data storing (s)               0.00274039
time/evaluation sampling (s)        0.324381
time/exploration sampling (s)       0.139323
time/logging (s)                    0.00487976
time/saving (s)                     0.00193853
time/training (s)                   1.95233
time/epoch (s)                      2.42559
time/total (s)                    514.871
Epoch                             210
-----------------------------  ---------------
2019-04-22 22:45:11.842748 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 211 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0514256
trainer/QF2 Loss                    0.0537734
trainer/Policy Loss                13.6154
trainer/Q1 Predictions Mean       -11.642
trainer/Q1 Predictions Std          7.85477
trainer/Q1 Predictions Max         -6.1874
trainer/Q1 Predictions Min        -29.2174
trainer/Q2 Predictions Mean       -11.6555
trainer/Q2 Predictions Std          7.86268
trainer/Q2 Predictions Max         -6.19042
trainer/Q2 Predictions Min        -29.2719
trainer/Q Targets Mean            -11.6796
trainer/Q Targets Std               7.78778
trainer/Q Targets Max              -6.18347
trainer/Q Targets Min             -28.0671
trainer/Log Pis Mean                2.01756
trainer/Log Pis Std                 1.16069
trainer/Log Pis Max                 8.11534
trainer/Log Pis Min                -1.64905
trainer/Policy mu Mean              0.0352164
trainer/Policy mu Std               0.493206
trainer/Policy mu Max               2.94077
trainer/Policy mu Min              -2.18012
trainer/Policy log std Mean        -2.27474
trainer/Policy log std Std          0.332634
trainer/Policy log std Max         -0.660273
trainer/Policy log std Min         -2.66688
trainer/Alpha                       0.056951
trainer/Alpha Loss                  0.0503118
exploration/num steps total    106200
exploration/num paths total      1062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.445975
exploration/Rewards Std             1.10361
exploration/Rewards Max            -0.0156778
exploration/Rewards Min            -8.64027
exploration/Returns Mean          -44.5975
exploration/Returns Std            20.3499
exploration/Returns Max           -14.8071
exploration/Returns Min           -77.107
exploration/Actions Mean            0.0117575
exploration/Actions Std             0.247957
exploration/Actions Max             0.999013
exploration/Actions Min            -0.999662
exploration/Num Paths               5
exploration/Average Returns       -44.5975
evaluation/num steps total     318000
evaluation/num paths total       3180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.338228
evaluation/Rewards Std              1.09518
evaluation/Rewards Max             -0.00254172
evaluation/Rewards Min            -10.9012
evaluation/Returns Mean           -33.8228
evaluation/Returns Std             24.033
evaluation/Returns Max             -1.16748
evaluation/Returns Min            -95.4289
evaluation/Actions Mean            -0.00592197
evaluation/Actions Std              0.193677
evaluation/Actions Max              0.998396
evaluation/Actions Min             -0.999467
evaluation/Num Paths               15
evaluation/Average Returns        -33.8228
time/data storing (s)               0.00278335
time/evaluation sampling (s)        0.324733
time/exploration sampling (s)       0.143212
time/logging (s)                    0.00495151
time/saving (s)                     0.00199542
time/training (s)                   1.93908
time/epoch (s)                      2.41675
time/total (s)                    517.292
Epoch                             211
-----------------------------  ---------------
2019-04-22 22:45:14.282638 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.630538
trainer/QF2 Loss                    0.679997
trainer/Policy Loss                13.5441
trainer/Q1 Predictions Mean       -11.6993
trainer/Q1 Predictions Std          8.35477
trainer/Q1 Predictions Max         -6.03662
trainer/Q1 Predictions Min        -50.3646
trainer/Q2 Predictions Mean       -11.697
trainer/Q2 Predictions Std          8.27858
trainer/Q2 Predictions Max         -6.03671
trainer/Q2 Predictions Min        -48.8651
trainer/Q Targets Mean            -11.8234
trainer/Q Targets Std               8.59305
trainer/Q Targets Max              -0.0625659
trainer/Q Targets Min             -51.1586
trainer/Log Pis Mean                1.92289
trainer/Log Pis Std                 1.35789
trainer/Log Pis Max                10.1559
trainer/Log Pis Min                -2.9516
trainer/Policy mu Mean              0.011932
trainer/Policy mu Std               0.522333
trainer/Policy mu Max               3.04461
trainer/Policy mu Min              -3.13393
trainer/Policy log std Mean        -2.22281
trainer/Policy log std Std          0.374101
trainer/Policy log std Max         -0.363402
trainer/Policy log std Min         -2.681
trainer/Alpha                       0.0569561
trainer/Alpha Loss                 -0.220939
exploration/num steps total    106700
exploration/num paths total      1067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.40235
exploration/Rewards Std             0.980247
exploration/Rewards Max            -0.00124734
exploration/Rewards Min            -8.66816
exploration/Returns Mean          -40.235
exploration/Returns Std            21.4961
exploration/Returns Max           -15.8035
exploration/Returns Min           -76.8092
exploration/Actions Mean            0.025393
exploration/Actions Std             0.230042
exploration/Actions Max             0.997532
exploration/Actions Min            -0.999632
exploration/Num Paths               5
exploration/Average Returns       -40.235
evaluation/num steps total     319500
evaluation/num paths total       3195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221
evaluation/Rewards Std              0.760105
evaluation/Rewards Max             -0.0119644
evaluation/Rewards Min             -9.01219
evaluation/Returns Mean           -22.1
evaluation/Returns Std             21.555
evaluation/Returns Max             -3.29266
evaluation/Returns Min            -85.1154
evaluation/Actions Mean             0.00651136
evaluation/Actions Std              0.169248
evaluation/Actions Max              0.997112
evaluation/Actions Min             -0.99887
evaluation/Num Paths               15
evaluation/Average Returns        -22.1
time/data storing (s)               0.00287743
time/evaluation sampling (s)        0.325037
time/exploration sampling (s)       0.141765
time/logging (s)                    0.00506937
time/saving (s)                     0.00197327
time/training (s)                   1.9524
time/epoch (s)                      2.42912
time/total (s)                    519.729
Epoch                             212
-----------------------------  ---------------
2019-04-22 22:45:16.725574 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 213 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.678473
trainer/QF2 Loss                    0.677456
trainer/Policy Loss                13.1212
trainer/Q1 Predictions Mean       -11.2759
trainer/Q1 Predictions Std          7.44637
trainer/Q1 Predictions Max         -6.05589
trainer/Q1 Predictions Min        -28.2974
trainer/Q2 Predictions Mean       -11.3014
trainer/Q2 Predictions Std          7.46634
trainer/Q2 Predictions Max         -6.05882
trainer/Q2 Predictions Min        -28.8526
trainer/Q Targets Mean            -11.3646
trainer/Q Targets Std               7.63535
trainer/Q Targets Max              -0.181988
trainer/Q Targets Min             -28.4143
trainer/Log Pis Mean                1.93683
trainer/Log Pis Std                 1.1483
trainer/Log Pis Max                 5.78397
trainer/Log Pis Min                -2.12969
trainer/Policy mu Mean             -0.0282822
trainer/Policy mu Std               0.498633
trainer/Policy mu Max               2.64627
trainer/Policy mu Min              -2.82925
trainer/Policy log std Mean        -2.24235
trainer/Policy log std Std          0.331901
trainer/Policy log std Max         -0.425746
trainer/Policy log std Min         -2.64255
trainer/Alpha                       0.0574585
trainer/Alpha Loss                 -0.180463
exploration/num steps total    107200
exploration/num paths total      1072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.365355
exploration/Rewards Std             1.08728
exploration/Rewards Max            -0.0094355
exploration/Rewards Min           -10.0305
exploration/Returns Mean          -36.5355
exploration/Returns Std            15.8206
exploration/Returns Max           -15.1525
exploration/Returns Min           -64.2732
exploration/Actions Mean            0.00146109
exploration/Actions Std             0.234081
exploration/Actions Max             0.997722
exploration/Actions Min            -0.998785
exploration/Num Paths               5
exploration/Average Returns       -36.5355
evaluation/num steps total     321000
evaluation/num paths total       3210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.301778
evaluation/Rewards Std              1.03614
evaluation/Rewards Max             -0.0130146
evaluation/Rewards Min            -11.0755
evaluation/Returns Mean           -30.1778
evaluation/Returns Std             23.2546
evaluation/Returns Max             -4.30106
evaluation/Returns Min            -80.5224
evaluation/Actions Mean            -0.00193861
evaluation/Actions Std              0.20246
evaluation/Actions Max              0.998322
evaluation/Actions Min             -0.999056
evaluation/Num Paths               15
evaluation/Average Returns        -30.1778
time/data storing (s)               0.00261889
time/evaluation sampling (s)        0.328378
time/exploration sampling (s)       0.138525
time/logging (s)                    0.00411134
time/saving (s)                     0.00195926
time/training (s)                   1.95831
time/epoch (s)                      2.4339
time/total (s)                    522.167
Epoch                             213
-----------------------------  ---------------
2019-04-22 22:45:19.170776 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 214 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.767714
trainer/QF2 Loss                    0.702987
trainer/Policy Loss                12.6854
trainer/Q1 Predictions Mean       -10.8987
trainer/Q1 Predictions Std          7.50891
trainer/Q1 Predictions Max         -6.12132
trainer/Q1 Predictions Min        -37.0736
trainer/Q2 Predictions Mean       -10.9089
trainer/Q2 Predictions Std          7.5403
trainer/Q2 Predictions Max         -6.09571
trainer/Q2 Predictions Min        -38.6704
trainer/Q Targets Mean            -11.0955
trainer/Q Targets Std               7.79954
trainer/Q Targets Max              -0.262178
trainer/Q Targets Min             -38.486
trainer/Log Pis Mean                1.86255
trainer/Log Pis Std                 1.39899
trainer/Log Pis Max                 8.62934
trainer/Log Pis Min                -4.26349
trainer/Policy mu Mean              0.0385944
trainer/Policy mu Std               0.623568
trainer/Policy mu Max               3.86877
trainer/Policy mu Min              -2.95162
trainer/Policy log std Mean        -2.17074
trainer/Policy log std Std          0.400455
trainer/Policy log std Max         -0.178961
trainer/Policy log std Min         -2.54478
trainer/Alpha                       0.05914
trainer/Alpha Loss                 -0.388646
exploration/num steps total    107700
exploration/num paths total      1077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.434039
exploration/Rewards Std             1.1548
exploration/Rewards Max            -0.00591325
exploration/Rewards Min           -10.162
exploration/Returns Mean          -43.4039
exploration/Returns Std            33.5378
exploration/Returns Max           -16.066
exploration/Returns Min          -104.161
exploration/Actions Mean            0.0191748
exploration/Actions Std             0.237939
exploration/Actions Max             0.999941
exploration/Actions Min            -0.999331
exploration/Num Paths               5
exploration/Average Returns       -43.4039
evaluation/num steps total     322500
evaluation/num paths total       3225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.387672
evaluation/Rewards Std              1.16845
evaluation/Rewards Max             -0.0126788
evaluation/Rewards Min            -10.9593
evaluation/Returns Mean           -38.7672
evaluation/Returns Std             23.9022
evaluation/Returns Max            -15.9747
evaluation/Returns Min           -103.353
evaluation/Actions Mean             0.00666789
evaluation/Actions Std              0.207591
evaluation/Actions Max              0.999316
evaluation/Actions Min             -0.999349
evaluation/Num Paths               15
evaluation/Average Returns        -38.7672
time/data storing (s)               0.00279522
time/evaluation sampling (s)        0.327006
time/exploration sampling (s)       0.14167
time/logging (s)                    0.0040082
time/saving (s)                     0.00197128
time/training (s)                   1.95966
time/epoch (s)                      2.43712
time/total (s)                    524.609
Epoch                             214
-----------------------------  ---------------
2019-04-22 22:45:21.587139 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 215 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.74845
trainer/QF2 Loss                    6.95903
trainer/Policy Loss                13.152
trainer/Q1 Predictions Mean       -11.2594
trainer/Q1 Predictions Std          7.86697
trainer/Q1 Predictions Max         -6.03176
trainer/Q1 Predictions Min        -33.4316
trainer/Q2 Predictions Mean       -11.271
trainer/Q2 Predictions Std          7.88375
trainer/Q2 Predictions Max         -6.02689
trainer/Q2 Predictions Min        -33.9573
trainer/Q Targets Mean            -11.1712
trainer/Q Targets Std               7.83414
trainer/Q Targets Max              -1.69301
trainer/Q Targets Min             -33.0274
trainer/Log Pis Mean                1.97928
trainer/Log Pis Std                 1.07002
trainer/Log Pis Max                 4.87123
trainer/Log Pis Min                -1.18814
trainer/Policy mu Mean             -0.0156505
trainer/Policy mu Std               0.462317
trainer/Policy mu Max               2.87355
trainer/Policy mu Min              -2.78671
trainer/Policy log std Mean        -2.26912
trainer/Policy log std Std          0.354311
trainer/Policy log std Max         -0.414827
trainer/Policy log std Min         -2.84585
trainer/Alpha                       0.0601234
trainer/Alpha Loss                 -0.0582433
exploration/num steps total    108200
exploration/num paths total      1082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.296362
exploration/Rewards Std             0.770137
exploration/Rewards Max            -0.0077698
exploration/Rewards Min            -8.3917
exploration/Returns Mean          -29.6362
exploration/Returns Std             7.17368
exploration/Returns Max           -22.149
exploration/Returns Min           -43.2202
exploration/Actions Mean            0.00136313
exploration/Actions Std             0.236452
exploration/Actions Max             0.996698
exploration/Actions Min            -0.999439
exploration/Num Paths               5
exploration/Average Returns       -29.6362
evaluation/num steps total     324000
evaluation/num paths total       3240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.331006
evaluation/Rewards Std              0.953861
evaluation/Rewards Max             -0.0190369
evaluation/Rewards Min             -8.26029
evaluation/Returns Mean           -33.1006
evaluation/Returns Std             19.165
evaluation/Returns Max             -4.44964
evaluation/Returns Min            -66.2581
evaluation/Actions Mean            -0.0073877
evaluation/Actions Std              0.187757
evaluation/Actions Max              0.995948
evaluation/Actions Min             -0.99725
evaluation/Num Paths               15
evaluation/Average Returns        -33.1006
time/data storing (s)               0.00270118
time/evaluation sampling (s)        0.327694
time/exploration sampling (s)       0.137627
time/logging (s)                    0.00486124
time/saving (s)                     0.00194561
time/training (s)                   1.93443
time/epoch (s)                      2.40926
time/total (s)                    527.022
Epoch                             215
-----------------------------  ---------------
2019-04-22 22:45:24.027352 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 216 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.541261
trainer/QF2 Loss                    0.538851
trainer/Policy Loss                14.6606
trainer/Q1 Predictions Mean       -12.7099
trainer/Q1 Predictions Std          8.50074
trainer/Q1 Predictions Max         -6.25947
trainer/Q1 Predictions Min        -38.3971
trainer/Q2 Predictions Mean       -12.7182
trainer/Q2 Predictions Std          8.5204
trainer/Q2 Predictions Max         -6.21905
trainer/Q2 Predictions Min        -39.1054
trainer/Q Targets Mean            -12.8726
trainer/Q Targets Std               8.77054
trainer/Q Targets Max              -0.0542492
trainer/Q Targets Min             -38.6665
trainer/Log Pis Mean                2.08679
trainer/Log Pis Std                 1.53234
trainer/Log Pis Max                 7.89003
trainer/Log Pis Min                -5.45665
trainer/Policy mu Mean             -0.0633874
trainer/Policy mu Std               0.559004
trainer/Policy mu Max               2.66893
trainer/Policy mu Min              -3.10831
trainer/Policy log std Mean        -2.27458
trainer/Policy log std Std          0.429508
trainer/Policy log std Max         -0.626261
trainer/Policy log std Min         -2.77408
trainer/Alpha                       0.063329
trainer/Alpha Loss                  0.239482
exploration/num steps total    108700
exploration/num paths total      1087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.372915
exploration/Rewards Std             1.06073
exploration/Rewards Max            -0.00622389
exploration/Rewards Min            -7.87456
exploration/Returns Mean          -37.2915
exploration/Returns Std             9.47252
exploration/Returns Max           -24.0701
exploration/Returns Min           -47.6125
exploration/Actions Mean           -0.00338939
exploration/Actions Std             0.247529
exploration/Actions Max             0.999427
exploration/Actions Min            -0.999287
exploration/Num Paths               5
exploration/Average Returns       -37.2915
evaluation/num steps total     325500
evaluation/num paths total       3255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.295132
evaluation/Rewards Std              0.924864
evaluation/Rewards Max             -0.0330928
evaluation/Rewards Min             -9.68148
evaluation/Returns Mean           -29.5132
evaluation/Returns Std             20.7988
evaluation/Returns Max             -5.13142
evaluation/Returns Min            -75.4821
evaluation/Actions Mean             0.00087814
evaluation/Actions Std              0.180141
evaluation/Actions Max              0.995545
evaluation/Actions Min             -0.999045
evaluation/Num Paths               15
evaluation/Average Returns        -29.5132
time/data storing (s)               0.00289091
time/evaluation sampling (s)        0.320766
time/exploration sampling (s)       0.142818
time/logging (s)                    0.00371005
time/saving (s)                     0.00157372
time/training (s)                   1.95908
time/epoch (s)                      2.43084
time/total (s)                    529.458
Epoch                             216
-----------------------------  ---------------
2019-04-22 22:45:26.460917 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 217 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.591634
trainer/QF2 Loss                    0.606636
trainer/Policy Loss                12.8648
trainer/Q1 Predictions Mean       -10.9759
trainer/Q1 Predictions Std          8.89284
trainer/Q1 Predictions Max         -6.13514
trainer/Q1 Predictions Min        -55.294
trainer/Q2 Predictions Mean       -10.9991
trainer/Q2 Predictions Std          8.90902
trainer/Q2 Predictions Max         -6.16757
trainer/Q2 Predictions Min        -56.3059
trainer/Q Targets Mean            -10.9323
trainer/Q Targets Std               8.89047
trainer/Q Targets Max              -0.0863119
trainer/Q Targets Min             -54.8656
trainer/Log Pis Mean                1.93356
trainer/Log Pis Std                 1.19173
trainer/Log Pis Max                 5.89127
trainer/Log Pis Min                -3.21495
trainer/Policy mu Mean             -0.00193764
trainer/Policy mu Std               0.548537
trainer/Policy mu Max               3.1929
trainer/Policy mu Min              -3.29595
trainer/Policy log std Mean        -2.20198
trainer/Policy log std Std          0.386472
trainer/Policy log std Max         -0.616665
trainer/Policy log std Min         -2.83043
trainer/Alpha                       0.0626364
trainer/Alpha Loss                 -0.184061
exploration/num steps total    109200
exploration/num paths total      1092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.388105
exploration/Rewards Std             0.890018
exploration/Rewards Max            -0.0126251
exploration/Rewards Min            -8.60973
exploration/Returns Mean          -38.8105
exploration/Returns Std            14.0815
exploration/Returns Max           -22.0942
exploration/Returns Min           -56.5589
exploration/Actions Mean           -0.00183182
exploration/Actions Std             0.238054
exploration/Actions Max             0.998313
exploration/Actions Min            -0.999141
exploration/Num Paths               5
exploration/Average Returns       -38.8105
evaluation/num steps total     327000
evaluation/num paths total       3270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.211497
evaluation/Rewards Std              0.727486
evaluation/Rewards Max             -0.0119721
evaluation/Rewards Min             -9.14311
evaluation/Returns Mean           -21.1497
evaluation/Returns Std             14.5456
evaluation/Returns Max             -5.65845
evaluation/Returns Min            -46.5211
evaluation/Actions Mean             0.00701528
evaluation/Actions Std              0.165241
evaluation/Actions Max              0.997372
evaluation/Actions Min             -0.9953
evaluation/Num Paths               15
evaluation/Average Returns        -21.1497
time/data storing (s)               0.0027633
time/evaluation sampling (s)        0.321878
time/exploration sampling (s)       0.141265
time/logging (s)                    0.00480765
time/saving (s)                     0.00168796
time/training (s)                   1.95428
time/epoch (s)                      2.42668
time/total (s)                    531.889
Epoch                             217
-----------------------------  ---------------
2019-04-22 22:45:28.902191 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 218 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0706188
trainer/QF2 Loss                    0.0455968
trainer/Policy Loss                12.8105
trainer/Q1 Predictions Mean       -10.924
trainer/Q1 Predictions Std          7.59629
trainer/Q1 Predictions Max         -6.13136
trainer/Q1 Predictions Min        -31.5227
trainer/Q2 Predictions Mean       -10.9822
trainer/Q2 Predictions Std          7.6159
trainer/Q2 Predictions Max         -6.17137
trainer/Q2 Predictions Min        -32.8107
trainer/Q Targets Mean            -11.1092
trainer/Q Targets Std               7.65867
trainer/Q Targets Max              -6.19097
trainer/Q Targets Min             -32.6362
trainer/Log Pis Mean                1.917
trainer/Log Pis Std                 1.0263
trainer/Log Pis Max                 6.28879
trainer/Log Pis Min                -0.893108
trainer/Policy mu Mean              0.0129231
trainer/Policy mu Std               0.435704
trainer/Policy mu Max               3.14173
trainer/Policy mu Min              -2.95883
trainer/Policy log std Mean        -2.24543
trainer/Policy log std Std          0.303655
trainer/Policy log std Max         -0.571811
trainer/Policy log std Min         -2.68281
trainer/Alpha                       0.0601707
trainer/Alpha Loss                 -0.233283
exploration/num steps total    109700
exploration/num paths total      1097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.45264
exploration/Rewards Std             1.34338
exploration/Rewards Max            -0.00220971
exploration/Rewards Min            -9.7067
exploration/Returns Mean          -45.264
exploration/Returns Std            19.8257
exploration/Returns Max           -16.4062
exploration/Returns Min           -64.0512
exploration/Actions Mean           -0.0188716
exploration/Actions Std             0.240853
exploration/Actions Max             0.997106
exploration/Actions Min            -0.998827
exploration/Num Paths               5
exploration/Average Returns       -45.264
evaluation/num steps total     328500
evaluation/num paths total       3285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.29616
evaluation/Rewards Std              1.08453
evaluation/Rewards Max             -0.00471442
evaluation/Rewards Min            -10.6443
evaluation/Returns Mean           -29.616
evaluation/Returns Std             19.1659
evaluation/Returns Max             -4.55005
evaluation/Returns Min            -70.2011
evaluation/Actions Mean             0.00595024
evaluation/Actions Std              0.197036
evaluation/Actions Max              0.997981
evaluation/Actions Min             -0.997691
evaluation/Num Paths               15
evaluation/Average Returns        -29.616
time/data storing (s)               0.00283937
time/evaluation sampling (s)        0.325814
time/exploration sampling (s)       0.141996
time/logging (s)                    0.00355973
time/saving (s)                     0.00170708
time/training (s)                   1.95644
time/epoch (s)                      2.43236
time/total (s)                    534.325
Epoch                             218
-----------------------------  ---------------
2019-04-22 22:45:31.347493 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 219 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.671474
trainer/QF2 Loss                    0.669393
trainer/Policy Loss                11.6903
trainer/Q1 Predictions Mean        -9.85408
trainer/Q1 Predictions Std          6.43112
trainer/Q1 Predictions Max         -6.24064
trainer/Q1 Predictions Min        -26.4982
trainer/Q2 Predictions Mean        -9.8246
trainer/Q2 Predictions Std          6.4556
trainer/Q2 Predictions Max         -6.19974
trainer/Q2 Predictions Min        -26.5386
trainer/Q Targets Mean             -9.94125
trainer/Q Targets Std               6.67931
trainer/Q Targets Max              -0.112631
trainer/Q Targets Min             -27.2124
trainer/Log Pis Mean                1.93141
trainer/Log Pis Std                 0.989755
trainer/Log Pis Max                 4.28278
trainer/Log Pis Min                -1.77639
trainer/Policy mu Mean              0.0218144
trainer/Policy mu Std               0.298869
trainer/Policy mu Max               2.00999
trainer/Policy mu Min              -1.03304
trainer/Policy log std Mean        -2.30034
trainer/Policy log std Std          0.249663
trainer/Policy log std Max         -0.856723
trainer/Policy log std Min         -2.71789
trainer/Alpha                       0.0597648
trainer/Alpha Loss                 -0.193243
exploration/num steps total    110200
exploration/num paths total      1102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.369405
exploration/Rewards Std             1.17602
exploration/Rewards Max            -0.00210237
exploration/Rewards Min           -10.0215
exploration/Returns Mean          -36.9405
exploration/Returns Std            14.8627
exploration/Returns Max           -11.5074
exploration/Returns Min           -54.5259
exploration/Actions Mean            0.00654302
exploration/Actions Std             0.252867
exploration/Actions Max             0.999492
exploration/Actions Min            -0.998512
exploration/Num Paths               5
exploration/Average Returns       -36.9405
evaluation/num steps total     330000
evaluation/num paths total       3300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.293568
evaluation/Rewards Std              1.0886
evaluation/Rewards Max             -0.00862129
evaluation/Rewards Min            -10.7067
evaluation/Returns Mean           -29.3568
evaluation/Returns Std             23.666
evaluation/Returns Max             -2.41279
evaluation/Returns Min            -95.2549
evaluation/Actions Mean            -0.0122575
evaluation/Actions Std              0.197768
evaluation/Actions Max              0.995656
evaluation/Actions Min             -0.998621
evaluation/Num Paths               15
evaluation/Average Returns        -29.3568
time/data storing (s)               0.00258795
time/evaluation sampling (s)        0.333289
time/exploration sampling (s)       0.138784
time/logging (s)                    0.00483213
time/saving (s)                     0.00195517
time/training (s)                   1.95782
time/epoch (s)                      2.43927
time/total (s)                    536.769
Epoch                             219
-----------------------------  ---------------
2019-04-22 22:45:33.784512 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 220 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.10459
trainer/QF2 Loss                    1.09628
trainer/Policy Loss                13.8708
trainer/Q1 Predictions Mean       -11.8205
trainer/Q1 Predictions Std          8.40557
trainer/Q1 Predictions Max         -6.15322
trainer/Q1 Predictions Min        -45.8992
trainer/Q2 Predictions Mean       -11.8355
trainer/Q2 Predictions Std          8.40369
trainer/Q2 Predictions Max         -6.12602
trainer/Q2 Predictions Min        -45.4744
trainer/Q Targets Mean            -11.8351
trainer/Q Targets Std               8.68886
trainer/Q Targets Max              -0.101735
trainer/Q Targets Min             -46.2727
trainer/Log Pis Mean                2.10406
trainer/Log Pis Std                 1.13267
trainer/Log Pis Max                 7.72928
trainer/Log Pis Min                -0.849685
trainer/Policy mu Mean             -0.0201966
trainer/Policy mu Std               0.558393
trainer/Policy mu Max               3.53414
trainer/Policy mu Min              -3.12886
trainer/Policy log std Mean        -2.31207
trainer/Policy log std Std          0.37884
trainer/Policy log std Max         -0.44034
trainer/Policy log std Min         -2.7115
trainer/Alpha                       0.0610704
trainer/Alpha Loss                  0.290952
exploration/num steps total    110700
exploration/num paths total      1107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.358899
exploration/Rewards Std             0.677498
exploration/Rewards Max            -0.00414176
exploration/Rewards Min            -6.43416
exploration/Returns Mean          -35.8899
exploration/Returns Std            22.3074
exploration/Returns Max           -13.4844
exploration/Returns Min           -65.9192
exploration/Actions Mean           -0.00919949
exploration/Actions Std             0.20762
exploration/Actions Max             0.996416
exploration/Actions Min            -0.998657
exploration/Num Paths               5
exploration/Average Returns       -35.8899
evaluation/num steps total     331500
evaluation/num paths total       3315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.344756
evaluation/Rewards Std              1.1095
evaluation/Rewards Max             -0.00646903
evaluation/Rewards Min            -10.2663
evaluation/Returns Mean           -34.4756
evaluation/Returns Std             22.4921
evaluation/Returns Max             -2.8707
evaluation/Returns Min            -79.1981
evaluation/Actions Mean            -0.00684466
evaluation/Actions Std              0.190276
evaluation/Actions Max              0.998116
evaluation/Actions Min             -0.998013
evaluation/Num Paths               15
evaluation/Average Returns        -34.4756
time/data storing (s)               0.00283638
time/evaluation sampling (s)        0.324784
time/exploration sampling (s)       0.140649
time/logging (s)                    0.00483633
time/saving (s)                     0.00195624
time/training (s)                   1.95365
time/epoch (s)                      2.42871
time/total (s)                    539.203
Epoch                             220
-----------------------------  ---------------
2019-04-22 22:45:36.215000 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 221 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.09361
trainer/QF2 Loss                    0.10219
trainer/Policy Loss                13.7735
trainer/Q1 Predictions Mean       -11.7882
trainer/Q1 Predictions Std          7.93441
trainer/Q1 Predictions Max         -6.23579
trainer/Q1 Predictions Min        -30.1709
trainer/Q2 Predictions Mean       -11.7751
trainer/Q2 Predictions Std          7.93592
trainer/Q2 Predictions Max         -6.18753
trainer/Q2 Predictions Min        -30.506
trainer/Q Targets Mean            -11.9791
trainer/Q Targets Std               8.0769
trainer/Q Targets Max              -6.19314
trainer/Q Targets Min             -29.6423
trainer/Log Pis Mean                2.04586
trainer/Log Pis Std                 1.12004
trainer/Log Pis Max                 8.08559
trainer/Log Pis Min                -0.794637
trainer/Policy mu Mean              0.0248059
trainer/Policy mu Std               0.509664
trainer/Policy mu Max               2.82009
trainer/Policy mu Min              -2.82346
trainer/Policy log std Mean        -2.24892
trainer/Policy log std Std          0.351306
trainer/Policy log std Max         -0.679175
trainer/Policy log std Min         -2.7074
trainer/Alpha                       0.0613377
trainer/Alpha Loss                  0.12801
exploration/num steps total    111200
exploration/num paths total      1112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.454653
exploration/Rewards Std             0.958764
exploration/Rewards Max            -0.011675
exploration/Rewards Min            -8.49439
exploration/Returns Mean          -45.4653
exploration/Returns Std            17.7348
exploration/Returns Max           -17.8754
exploration/Returns Min           -73.3651
exploration/Actions Mean            0.00288294
exploration/Actions Std             0.226348
exploration/Actions Max             0.998406
exploration/Actions Min            -0.998449
exploration/Num Paths               5
exploration/Average Returns       -45.4653
evaluation/num steps total     333000
evaluation/num paths total       3330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.294131
evaluation/Rewards Std              1.03125
evaluation/Rewards Max             -0.00236887
evaluation/Rewards Min            -10.0371
evaluation/Returns Mean           -29.4131
evaluation/Returns Std             20.9707
evaluation/Returns Max             -0.910841
evaluation/Returns Min            -62.9609
evaluation/Actions Mean            -0.00373673
evaluation/Actions Std              0.194213
evaluation/Actions Max              0.99788
evaluation/Actions Min             -0.998798
evaluation/Num Paths               15
evaluation/Average Returns        -29.4131
time/data storing (s)               0.0026899
time/evaluation sampling (s)        0.32353
time/exploration sampling (s)       0.144164
time/logging (s)                    0.00482996
time/saving (s)                     0.00197376
time/training (s)                   1.94516
time/epoch (s)                      2.42234
time/total (s)                    541.63
Epoch                             221
-----------------------------  ---------------
2019-04-22 22:45:38.640021 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 222 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0790267
trainer/QF2 Loss                    0.0993118
trainer/Policy Loss                15.3309
trainer/Q1 Predictions Mean       -13.0475
trainer/Q1 Predictions Std         10.453
trainer/Q1 Predictions Max         -6.1837
trainer/Q1 Predictions Min        -70.4218
trainer/Q2 Predictions Mean       -13.0569
trainer/Q2 Predictions Std         10.4404
trainer/Q2 Predictions Max         -6.15459
trainer/Q2 Predictions Min        -69.9846
trainer/Q Targets Mean            -13.0488
trainer/Q Targets Std              10.498
trainer/Q Targets Max              -6.27446
trainer/Q Targets Min             -71.9038
trainer/Log Pis Mean                2.36024
trainer/Log Pis Std                 1.22906
trainer/Log Pis Max                 6.84022
trainer/Log Pis Min                -0.717338
trainer/Policy mu Mean             -0.0223056
trainer/Policy mu Std               0.641482
trainer/Policy mu Max               2.91244
trainer/Policy mu Min              -3.82556
trainer/Policy log std Mean        -2.29448
trainer/Policy log std Std          0.434953
trainer/Policy log std Max         -0.570764
trainer/Policy log std Min         -2.93324
trainer/Alpha                       0.0624052
trainer/Alpha Loss                  0.999444
exploration/num steps total    111700
exploration/num paths total      1117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.299112
exploration/Rewards Std             0.682154
exploration/Rewards Max            -0.00965867
exploration/Rewards Min            -7.09804
exploration/Returns Mean          -29.9112
exploration/Returns Std            14.5384
exploration/Returns Max           -16.4171
exploration/Returns Min           -52.7401
exploration/Actions Mean           -0.0134614
exploration/Actions Std             0.204311
exploration/Actions Max             0.998086
exploration/Actions Min            -0.999199
exploration/Num Paths               5
exploration/Average Returns       -29.9112
evaluation/num steps total     334500
evaluation/num paths total       3345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.317959
evaluation/Rewards Std              1.04194
evaluation/Rewards Max             -0.016755
evaluation/Rewards Min            -10.0399
evaluation/Returns Mean           -31.7959
evaluation/Returns Std             14.9967
evaluation/Returns Max             -3.59301
evaluation/Returns Min            -49.0956
evaluation/Actions Mean            -0.00206031
evaluation/Actions Std              0.200773
evaluation/Actions Max              0.997912
evaluation/Actions Min             -0.996632
evaluation/Num Paths               15
evaluation/Average Returns        -31.7959
time/data storing (s)               0.0025879
time/evaluation sampling (s)        0.319104
time/exploration sampling (s)       0.138433
time/logging (s)                    0.00352671
time/saving (s)                     0.00195862
time/training (s)                   1.95018
time/epoch (s)                      2.41579
time/total (s)                    544.049
Epoch                             222
-----------------------------  ---------------
2019-04-22 22:45:41.082592 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 223 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.401559
trainer/QF2 Loss                    0.410074
trainer/Policy Loss                12.3818
trainer/Q1 Predictions Mean       -10.57
trainer/Q1 Predictions Std          6.95642
trainer/Q1 Predictions Max         -6.19484
trainer/Q1 Predictions Min        -26.3787
trainer/Q2 Predictions Mean       -10.5689
trainer/Q2 Predictions Std          6.97248
trainer/Q2 Predictions Max         -6.25451
trainer/Q2 Predictions Min        -26.4212
trainer/Q Targets Mean            -10.5763
trainer/Q Targets Std               7.08798
trainer/Q Targets Max              -0.174002
trainer/Q Targets Min             -26.659
trainer/Log Pis Mean                1.85208
trainer/Log Pis Std                 1.0539
trainer/Log Pis Max                 3.50482
trainer/Log Pis Min                -1.92797
trainer/Policy mu Mean             -0.0381935
trainer/Policy mu Std               0.295142
trainer/Policy mu Max               2.20771
trainer/Policy mu Min              -2.60869
trainer/Policy log std Mean        -2.34379
trainer/Policy log std Std          0.275244
trainer/Policy log std Max         -0.668975
trainer/Policy log std Min         -2.83173
trainer/Alpha                       0.0638945
trainer/Alpha Loss                 -0.406831
exploration/num steps total    112200
exploration/num paths total      1122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.349749
exploration/Rewards Std             0.845612
exploration/Rewards Max            -0.00788508
exploration/Rewards Min            -7.44005
exploration/Returns Mean          -34.9749
exploration/Returns Std             9.03545
exploration/Returns Max           -20.2785
exploration/Returns Min           -43.4716
exploration/Actions Mean           -0.0110326
exploration/Actions Std             0.211369
exploration/Actions Max             0.998659
exploration/Actions Min            -0.999257
exploration/Num Paths               5
exploration/Average Returns       -34.9749
evaluation/num steps total     336000
evaluation/num paths total       3360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.285821
evaluation/Rewards Std              1.01628
evaluation/Rewards Max             -0.0096508
evaluation/Rewards Min             -9.31231
evaluation/Returns Mean           -28.5821
evaluation/Returns Std             15.7004
evaluation/Returns Max             -5.61728
evaluation/Returns Min            -51.0858
evaluation/Actions Mean            -0.00404813
evaluation/Actions Std              0.188963
evaluation/Actions Max              0.996885
evaluation/Actions Min             -0.998057
evaluation/Num Paths               15
evaluation/Average Returns        -28.5821
time/data storing (s)               0.00273524
time/evaluation sampling (s)        0.320426
time/exploration sampling (s)       0.140849
time/logging (s)                    0.00480627
time/saving (s)                     0.00199638
time/training (s)                   1.96667
time/epoch (s)                      2.43748
time/total (s)                    546.491
Epoch                             223
-----------------------------  ---------------
2019-04-22 22:45:43.533759 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 224 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0821945
trainer/QF2 Loss                    0.0791691
trainer/Policy Loss                11.7737
trainer/Q1 Predictions Mean        -9.9047
trainer/Q1 Predictions Std          6.48861
trainer/Q1 Predictions Max         -6.14087
trainer/Q1 Predictions Min        -26.0623
trainer/Q2 Predictions Mean        -9.90223
trainer/Q2 Predictions Std          6.49894
trainer/Q2 Predictions Max         -6.15359
trainer/Q2 Predictions Min        -25.9641
trainer/Q Targets Mean            -10.1045
trainer/Q Targets Std               6.65277
trainer/Q Targets Max              -6.29195
trainer/Q Targets Min             -26.624
trainer/Log Pis Mean                1.9352
trainer/Log Pis Std                 0.999814
trainer/Log Pis Max                 3.61483
trainer/Log Pis Min                -2.41957
trainer/Policy mu Mean             -0.0385272
trainer/Policy mu Std               0.288161
trainer/Policy mu Max               0.785274
trainer/Policy mu Min              -2.34792
trainer/Policy log std Mean        -2.29592
trainer/Policy log std Std          0.26572
trainer/Policy log std Max         -0.772509
trainer/Policy log std Min         -2.7463
trainer/Alpha                       0.064093
trainer/Alpha Loss                 -0.178043
exploration/num steps total    112700
exploration/num paths total      1127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.37401
exploration/Rewards Std             0.938929
exploration/Rewards Max            -0.00797485
exploration/Rewards Min           -10.1533
exploration/Returns Mean          -37.401
exploration/Returns Std            18.5677
exploration/Returns Max           -20.4105
exploration/Returns Min           -68.6619
exploration/Actions Mean           -0.00639086
exploration/Actions Std             0.215114
exploration/Actions Max             0.993699
exploration/Actions Min            -0.998778
exploration/Num Paths               5
exploration/Average Returns       -37.401
evaluation/num steps total     337500
evaluation/num paths total       3375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234735
evaluation/Rewards Std              0.876538
evaluation/Rewards Max             -0.0146332
evaluation/Rewards Min             -9.00253
evaluation/Returns Mean           -23.4735
evaluation/Returns Std             18.5689
evaluation/Returns Max             -2.82495
evaluation/Returns Min            -77.1816
evaluation/Actions Mean             0.00196808
evaluation/Actions Std              0.188746
evaluation/Actions Max              0.997275
evaluation/Actions Min             -0.998636
evaluation/Num Paths               15
evaluation/Average Returns        -23.4735
time/data storing (s)               0.00271874
time/evaluation sampling (s)        0.333487
time/exploration sampling (s)       0.139526
time/logging (s)                    0.00472336
time/saving (s)                     0.0101955
time/training (s)                   1.95397
time/epoch (s)                      2.44462
time/total (s)                    548.939
Epoch                             224
-----------------------------  ---------------
2019-04-22 22:45:45.955871 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 225 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.84412
trainer/QF2 Loss                    0.845944
trainer/Policy Loss                11.8473
trainer/Q1 Predictions Mean        -9.83297
trainer/Q1 Predictions Std          6.21762
trainer/Q1 Predictions Max         -6.21705
trainer/Q1 Predictions Min        -27.9678
trainer/Q2 Predictions Mean        -9.83986
trainer/Q2 Predictions Std          6.24265
trainer/Q2 Predictions Max         -6.22534
trainer/Q2 Predictions Min        -28.1507
trainer/Q Targets Mean             -9.73535
trainer/Q Targets Std               6.3221
trainer/Q Targets Max              -0.157238
trainer/Q Targets Min             -27.7516
trainer/Log Pis Mean                2.04807
trainer/Log Pis Std                 1.07341
trainer/Log Pis Max                 5.93045
trainer/Log Pis Min                -3.20126
trainer/Policy mu Mean             -0.0138514
trainer/Policy mu Std               0.456063
trainer/Policy mu Max               3.18422
trainer/Policy mu Min              -2.24376
trainer/Policy log std Mean        -2.2523
trainer/Policy log std Std          0.361078
trainer/Policy log std Max         -0.336106
trainer/Policy log std Min         -2.81306
trainer/Alpha                       0.0650238
trainer/Alpha Loss                  0.131376
exploration/num steps total    113200
exploration/num paths total      1132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378601
exploration/Rewards Std             0.926218
exploration/Rewards Max            -0.0108302
exploration/Rewards Min            -8.71161
exploration/Returns Mean          -37.8601
exploration/Returns Std            20.8918
exploration/Returns Max           -13.7157
exploration/Returns Min           -70.91
exploration/Actions Mean           -0.0102594
exploration/Actions Std             0.223272
exploration/Actions Max             0.999275
exploration/Actions Min            -0.999243
exploration/Num Paths               5
exploration/Average Returns       -37.8601
evaluation/num steps total     339000
evaluation/num paths total       3390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22684
evaluation/Rewards Std              0.758654
evaluation/Rewards Max             -0.00625481
evaluation/Rewards Min             -9.03927
evaluation/Returns Mean           -22.684
evaluation/Returns Std             20.0063
evaluation/Returns Max             -3.78506
evaluation/Returns Min            -77.3
evaluation/Actions Mean            -0.0153113
evaluation/Actions Std              0.168415
evaluation/Actions Max              0.995607
evaluation/Actions Min             -0.998399
evaluation/Num Paths               15
evaluation/Average Returns        -22.684
time/data storing (s)               0.00261984
time/evaluation sampling (s)        0.326373
time/exploration sampling (s)       0.140165
time/logging (s)                    0.00483628
time/saving (s)                     0.00193011
time/training (s)                   1.93885
time/epoch (s)                      2.41478
time/total (s)                    551.358
Epoch                             225
-----------------------------  ---------------
2019-04-22 22:45:48.596673 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 226 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.399279
trainer/QF2 Loss                    0.406985
trainer/Policy Loss                13.5522
trainer/Q1 Predictions Mean       -11.7684
trainer/Q1 Predictions Std          7.99936
trainer/Q1 Predictions Max         -6.1801
trainer/Q1 Predictions Min        -34.6431
trainer/Q2 Predictions Mean       -11.7587
trainer/Q2 Predictions Std          7.98789
trainer/Q2 Predictions Max         -6.20475
trainer/Q2 Predictions Min        -34.5962
trainer/Q Targets Mean            -11.7235
trainer/Q Targets Std               8.02706
trainer/Q Targets Max              -0.31801
trainer/Q Targets Min             -35.1892
trainer/Log Pis Mean                1.84866
trainer/Log Pis Std                 1.29228
trainer/Log Pis Max                 5.29359
trainer/Log Pis Min                -2.07909
trainer/Policy mu Mean             -0.00914202
trainer/Policy mu Std               0.418656
trainer/Policy mu Max               3.00702
trainer/Policy mu Min              -2.52569
trainer/Policy log std Mean        -2.29237
trainer/Policy log std Std          0.337365
trainer/Policy log std Max         -0.5743
trainer/Policy log std Min         -2.80188
trainer/Alpha                       0.0647725
trainer/Alpha Loss                 -0.414189
exploration/num steps total    113700
exploration/num paths total      1137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332704
exploration/Rewards Std             1.07688
exploration/Rewards Max            -0.00525071
exploration/Rewards Min           -11.5156
exploration/Returns Mean          -33.2704
exploration/Returns Std            18.7871
exploration/Returns Max           -16.292
exploration/Returns Min           -69.4054
exploration/Actions Mean            0.0118208
exploration/Actions Std             0.244608
exploration/Actions Max             0.999151
exploration/Actions Min            -0.997586
exploration/Num Paths               5
exploration/Average Returns       -33.2704
evaluation/num steps total     340500
evaluation/num paths total       3405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244714
evaluation/Rewards Std              0.968566
evaluation/Rewards Max             -0.0136741
evaluation/Rewards Min            -10.1854
evaluation/Returns Mean           -24.4714
evaluation/Returns Std             24.4833
evaluation/Returns Max             -2.60231
evaluation/Returns Min            -84.0932
evaluation/Actions Mean             0.00521506
evaluation/Actions Std              0.171859
evaluation/Actions Max              0.997458
evaluation/Actions Min             -0.999276
evaluation/Num Paths               15
evaluation/Average Returns        -24.4714
time/data storing (s)               0.00301613
time/evaluation sampling (s)        0.326952
time/exploration sampling (s)       0.139308
time/logging (s)                    0.00557328
time/saving (s)                     0.0019515
time/training (s)                   2.15623
time/epoch (s)                      2.63303
time/total (s)                    553.996
Epoch                             226
-----------------------------  ---------------
2019-04-22 22:45:51.138196 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 227 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0270709
trainer/QF2 Loss                    0.0250221
trainer/Policy Loss                12.5322
trainer/Q1 Predictions Mean       -10.6384
trainer/Q1 Predictions Std          8.06052
trainer/Q1 Predictions Max         -6.27536
trainer/Q1 Predictions Min        -56.3818
trainer/Q2 Predictions Mean       -10.6228
trainer/Q2 Predictions Std          8.04864
trainer/Q2 Predictions Max         -6.26724
trainer/Q2 Predictions Min        -56.3383
trainer/Q Targets Mean            -10.6864
trainer/Q Targets Std               8.03272
trainer/Q Targets Max              -6.29577
trainer/Q Targets Min             -56.2463
trainer/Log Pis Mean                1.93501
trainer/Log Pis Std                 1.41226
trainer/Log Pis Max                 6.02146
trainer/Log Pis Min                -3.58119
trainer/Policy mu Mean             -0.118995
trainer/Policy mu Std               0.609356
trainer/Policy mu Max               2.62627
trainer/Policy mu Min              -3.43563
trainer/Policy log std Mean        -2.13457
trainer/Policy log std Std          0.407631
trainer/Policy log std Max         -0.503909
trainer/Policy log std Min         -2.63246
trainer/Alpha                       0.0644166
trainer/Alpha Loss                 -0.178206
exploration/num steps total    114200
exploration/num paths total      1142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.380057
exploration/Rewards Std             1.16847
exploration/Rewards Max            -0.00349953
exploration/Rewards Min           -10.8107
exploration/Returns Mean          -38.0057
exploration/Returns Std            19.3101
exploration/Returns Max           -15.0579
exploration/Returns Min           -71.3572
exploration/Actions Mean           -0.0151346
exploration/Actions Std             0.242
exploration/Actions Max             0.990287
exploration/Actions Min            -0.999941
exploration/Num Paths               5
exploration/Average Returns       -38.0057
evaluation/num steps total     342000
evaluation/num paths total       3420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.374192
evaluation/Rewards Std              1.24416
evaluation/Rewards Max             -0.000793055
evaluation/Rewards Min            -10.5904
evaluation/Returns Mean           -37.4192
evaluation/Returns Std             22.9804
evaluation/Returns Max             -6.66208
evaluation/Returns Min            -82.1877
evaluation/Actions Mean             0.00144894
evaluation/Actions Std              0.213364
evaluation/Actions Max              0.997426
evaluation/Actions Min             -0.998967
evaluation/Num Paths               15
evaluation/Average Returns        -37.4192
time/data storing (s)               0.00277249
time/evaluation sampling (s)        0.342719
time/exploration sampling (s)       0.141907
time/logging (s)                    0.00485795
time/saving (s)                     0.00198942
time/training (s)                   2.03787
time/epoch (s)                      2.53212
time/total (s)                    556.533
Epoch                             227
-----------------------------  ----------------
2019-04-22 22:45:53.577505 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 228 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.458731
trainer/QF2 Loss                    0.467048
trainer/Policy Loss                12.1329
trainer/Q1 Predictions Mean       -10.3498
trainer/Q1 Predictions Std          7.0616
trainer/Q1 Predictions Max         -6.31212
trainer/Q1 Predictions Min        -39.8676
trainer/Q2 Predictions Mean       -10.328
trainer/Q2 Predictions Std          7.02495
trainer/Q2 Predictions Max         -6.28637
trainer/Q2 Predictions Min        -39.155
trainer/Q Targets Mean            -10.2515
trainer/Q Targets Std               7.01307
trainer/Q Targets Max              -0.199276
trainer/Q Targets Min             -39.4353
trainer/Log Pis Mean                1.81211
trainer/Log Pis Std                 1.30926
trainer/Log Pis Max                 7.09547
trainer/Log Pis Min                -3.04716
trainer/Policy mu Mean             -0.00913959
trainer/Policy mu Std               0.433785
trainer/Policy mu Max               2.97998
trainer/Policy mu Min              -3.20545
trainer/Policy log std Mean        -2.26174
trainer/Policy log std Std          0.311574
trainer/Policy log std Max         -0.583396
trainer/Policy log std Min         -2.687
trainer/Alpha                       0.0625683
trainer/Alpha Loss                 -0.520726
exploration/num steps total    114700
exploration/num paths total      1147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.282537
exploration/Rewards Std             0.766999
exploration/Rewards Max            -0.00646312
exploration/Rewards Min            -7.34665
exploration/Returns Mean          -28.2537
exploration/Returns Std             8.27818
exploration/Returns Max           -14.1218
exploration/Returns Min           -40.1234
exploration/Actions Mean           -0.00569915
exploration/Actions Std             0.219123
exploration/Actions Max             0.999565
exploration/Actions Min            -0.996974
exploration/Num Paths               5
exploration/Average Returns       -28.2537
evaluation/num steps total     343500
evaluation/num paths total       3435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.360934
evaluation/Rewards Std              1.02534
evaluation/Rewards Max             -0.00775538
evaluation/Rewards Min             -9.57274
evaluation/Returns Mean           -36.0934
evaluation/Returns Std             25.2055
evaluation/Returns Max             -1.4585
evaluation/Returns Min            -89.6004
evaluation/Actions Mean             0.00392938
evaluation/Actions Std              0.192744
evaluation/Actions Max              0.996822
evaluation/Actions Min             -0.998955
evaluation/Num Paths               15
evaluation/Average Returns        -36.0934
time/data storing (s)               0.00260276
time/evaluation sampling (s)        0.32973
time/exploration sampling (s)       0.140372
time/logging (s)                    0.0048166
time/saving (s)                     0.00195255
time/training (s)                   1.95147
time/epoch (s)                      2.43095
time/total (s)                    558.968
Epoch                             228
-----------------------------  ---------------
2019-04-22 22:45:56.005063 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 229 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0199405
trainer/QF2 Loss                    0.0204035
trainer/Policy Loss                11.5586
trainer/Q1 Predictions Mean        -9.77184
trainer/Q1 Predictions Std          5.91504
trainer/Q1 Predictions Max         -6.28082
trainer/Q1 Predictions Min        -26.5827
trainer/Q2 Predictions Mean        -9.7727
trainer/Q2 Predictions Std          5.8994
trainer/Q2 Predictions Max         -6.32731
trainer/Q2 Predictions Min        -26.3592
trainer/Q Targets Mean             -9.83041
trainer/Q Targets Std               5.89851
trainer/Q Targets Max              -6.33719
trainer/Q Targets Min             -26.506
trainer/Log Pis Mean                1.85298
trainer/Log Pis Std                 1.32593
trainer/Log Pis Max                 6.35247
trainer/Log Pis Min                -2.48436
trainer/Policy mu Mean              0.0165991
trainer/Policy mu Std               0.51439
trainer/Policy mu Max               2.80397
trainer/Policy mu Min              -2.65841
trainer/Policy log std Mean        -2.16044
trainer/Policy log std Std          0.382054
trainer/Policy log std Max         -0.560237
trainer/Policy log std Min         -2.69609
trainer/Alpha                       0.0618922
trainer/Alpha Loss                 -0.409015
exploration/num steps total    115200
exploration/num paths total      1152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.445496
exploration/Rewards Std             1.08994
exploration/Rewards Max            -0.0128952
exploration/Rewards Min            -9.41752
exploration/Returns Mean          -44.5496
exploration/Returns Std            16.45
exploration/Returns Max           -16.6578
exploration/Returns Min           -61.6556
exploration/Actions Mean            0.0200631
exploration/Actions Std             0.22974
exploration/Actions Max             0.998552
exploration/Actions Min            -0.999729
exploration/Num Paths               5
exploration/Average Returns       -44.5496
evaluation/num steps total     345000
evaluation/num paths total       3450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.33462
evaluation/Rewards Std              1.1468
evaluation/Rewards Max             -0.00880215
evaluation/Rewards Min            -10.158
evaluation/Returns Mean           -33.462
evaluation/Returns Std             17.5537
evaluation/Returns Max             -7.63462
evaluation/Returns Min            -77.4819
evaluation/Actions Mean             0.000663547
evaluation/Actions Std              0.216248
evaluation/Actions Max              0.997857
evaluation/Actions Min             -0.998997
evaluation/Num Paths               15
evaluation/Average Returns        -33.462
time/data storing (s)               0.0027918
time/evaluation sampling (s)        0.326588
time/exploration sampling (s)       0.142548
time/logging (s)                    0.00453872
time/saving (s)                     0.00196064
time/training (s)                   1.94181
time/epoch (s)                      2.42024
time/total (s)                    561.392
Epoch                             229
-----------------------------  ----------------
2019-04-22 22:45:58.431421 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 230 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   12.0618
trainer/QF2 Loss                   12.0384
trainer/Policy Loss                12.6434
trainer/Q1 Predictions Mean       -10.4863
trainer/Q1 Predictions Std          6.58181
trainer/Q1 Predictions Max         -6.3012
trainer/Q1 Predictions Min        -27.864
trainer/Q2 Predictions Mean       -10.4881
trainer/Q2 Predictions Std          6.57886
trainer/Q2 Predictions Max         -6.31459
trainer/Q2 Predictions Min        -27.3061
trainer/Q Targets Mean            -10.0378
trainer/Q Targets Std               6.4309
trainer/Q Targets Max              -0.648502
trainer/Q Targets Min             -27.7822
trainer/Log Pis Mean                2.19648
trainer/Log Pis Std                 1.18887
trainer/Log Pis Max                 8.26731
trainer/Log Pis Min                -2.50676
trainer/Policy mu Mean              0.0484586
trainer/Policy mu Std               0.500129
trainer/Policy mu Max               2.82882
trainer/Policy mu Min              -2.93104
trainer/Policy log std Mean        -2.26192
trainer/Policy log std Std          0.399433
trainer/Policy log std Max         -0.571246
trainer/Policy log std Min         -2.91596
trainer/Alpha                       0.062682
trainer/Alpha Loss                  0.544232
exploration/num steps total    115700
exploration/num paths total      1157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.452394
exploration/Rewards Std             1.14259
exploration/Rewards Max            -0.00219462
exploration/Rewards Min            -8.70125
exploration/Returns Mean          -45.2394
exploration/Returns Std            17.6871
exploration/Returns Max           -15.5789
exploration/Returns Min           -69.0916
exploration/Actions Mean           -0.00825614
exploration/Actions Std             0.235509
exploration/Actions Max             0.997788
exploration/Actions Min            -0.998113
exploration/Num Paths               5
exploration/Average Returns       -45.2394
evaluation/num steps total     346500
evaluation/num paths total       3465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.306608
evaluation/Rewards Std              0.871367
evaluation/Rewards Max             -0.0142504
evaluation/Rewards Min             -9.43462
evaluation/Returns Mean           -30.6608
evaluation/Returns Std             22.4609
evaluation/Returns Max             -4.50322
evaluation/Returns Min            -80.1125
evaluation/Actions Mean            -0.0207203
evaluation/Actions Std              0.172874
evaluation/Actions Max              0.994915
evaluation/Actions Min             -0.998486
evaluation/Num Paths               15
evaluation/Average Returns        -30.6608
time/data storing (s)               0.00287071
time/evaluation sampling (s)        0.320157
time/exploration sampling (s)       0.143628
time/logging (s)                    0.00485233
time/saving (s)                     0.00194318
time/training (s)                   1.94618
time/epoch (s)                      2.41963
time/total (s)                    563.816
Epoch                             230
-----------------------------  ---------------
2019-04-22 22:46:00.860215 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 231 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.18847
trainer/QF2 Loss                    1.19579
trainer/Policy Loss                12.248
trainer/Q1 Predictions Mean       -10.2713
trainer/Q1 Predictions Std          6.68127
trainer/Q1 Predictions Max         -6.23572
trainer/Q1 Predictions Min        -31.5518
trainer/Q2 Predictions Mean       -10.2759
trainer/Q2 Predictions Std          6.68528
trainer/Q2 Predictions Max         -6.25016
trainer/Q2 Predictions Min        -31.3108
trainer/Q Targets Mean            -10.2455
trainer/Q Targets Std               6.95468
trainer/Q Targets Max              -0.132613
trainer/Q Targets Min             -31.1258
trainer/Log Pis Mean                2.01085
trainer/Log Pis Std                 1.11752
trainer/Log Pis Max                 6.07234
trainer/Log Pis Min                -1.21915
trainer/Policy mu Mean              0.0141475
trainer/Policy mu Std               0.605282
trainer/Policy mu Max               2.6133
trainer/Policy mu Min              -3.00573
trainer/Policy log std Mean        -2.19218
trainer/Policy log std Std          0.42874
trainer/Policy log std Max         -0.632186
trainer/Policy log std Min         -2.8914
trainer/Alpha                       0.0634763
trainer/Alpha Loss                  0.0299137
exploration/num steps total    116200
exploration/num paths total      1162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.231816
exploration/Rewards Std             0.549243
exploration/Rewards Max            -0.00592423
exploration/Rewards Min            -5.96926
exploration/Returns Mean          -23.1816
exploration/Returns Std             6.27001
exploration/Returns Max           -15.4293
exploration/Returns Min           -34.3969
exploration/Actions Mean            0.00743
exploration/Actions Std             0.205316
exploration/Actions Max             0.998912
exploration/Actions Min            -0.992516
exploration/Num Paths               5
exploration/Average Returns       -23.1816
evaluation/num steps total     348000
evaluation/num paths total       3480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.345198
evaluation/Rewards Std              0.928828
evaluation/Rewards Max             -0.00873069
evaluation/Rewards Min            -10.111
evaluation/Returns Mean           -34.5198
evaluation/Returns Std             25.3517
evaluation/Returns Max             -3.25057
evaluation/Returns Min            -84.9116
evaluation/Actions Mean            -0.0146623
evaluation/Actions Std              0.199014
evaluation/Actions Max              0.995836
evaluation/Actions Min             -0.998119
evaluation/Num Paths               15
evaluation/Average Returns        -34.5198
time/data storing (s)               0.00269668
time/evaluation sampling (s)        0.330118
time/exploration sampling (s)       0.137493
time/logging (s)                    0.00487386
time/saving (s)                     0.00156772
time/training (s)                   1.94386
time/epoch (s)                      2.42061
time/total (s)                    566.241
Epoch                             231
-----------------------------  ---------------
2019-04-22 22:46:03.301864 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 232 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.458155
trainer/QF2 Loss                    0.472548
trainer/Policy Loss                13.1301
trainer/Q1 Predictions Mean       -10.9494
trainer/Q1 Predictions Std          7.71448
trainer/Q1 Predictions Max         -6.18076
trainer/Q1 Predictions Min        -44.1117
trainer/Q2 Predictions Mean       -10.9448
trainer/Q2 Predictions Std          7.72507
trainer/Q2 Predictions Max         -6.17159
trainer/Q2 Predictions Min        -44.0161
trainer/Q Targets Mean            -11.0075
trainer/Q Targets Std               7.79124
trainer/Q Targets Max              -0.114442
trainer/Q Targets Min             -44.3353
trainer/Log Pis Mean                2.23549
trainer/Log Pis Std                 1.51524
trainer/Log Pis Max                 8.22337
trainer/Log Pis Min                -6.3849
trainer/Policy mu Mean              0.0189701
trainer/Policy mu Std               0.658138
trainer/Policy mu Max               3.34794
trainer/Policy mu Min              -3.31925
trainer/Policy log std Mean        -2.20865
trainer/Policy log std Std          0.449071
trainer/Policy log std Max         -0.417373
trainer/Policy log std Min         -2.87994
trainer/Alpha                       0.0616998
trainer/Alpha Loss                  0.655974
exploration/num steps total    116700
exploration/num paths total      1167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.401079
exploration/Rewards Std             0.727383
exploration/Rewards Max            -0.0139656
exploration/Rewards Min            -7.65615
exploration/Returns Mean          -40.1079
exploration/Returns Std            21.7348
exploration/Returns Max           -14.8439
exploration/Returns Min           -71.4102
exploration/Actions Mean           -0.0184536
exploration/Actions Std             0.188975
exploration/Actions Max             0.992656
exploration/Actions Min            -0.999181
exploration/Num Paths               5
exploration/Average Returns       -40.1079
evaluation/num steps total     349500
evaluation/num paths total       3495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.245785
evaluation/Rewards Std              0.993246
evaluation/Rewards Max             -0.00905063
evaluation/Rewards Min            -10.2141
evaluation/Returns Mean           -24.5785
evaluation/Returns Std             19.2925
evaluation/Returns Max             -3.26753
evaluation/Returns Min            -77.0993
evaluation/Actions Mean             0.00486851
evaluation/Actions Std              0.199068
evaluation/Actions Max              0.998087
evaluation/Actions Min             -0.998053
evaluation/Num Paths               15
evaluation/Average Returns        -24.5785
time/data storing (s)               0.00288984
time/evaluation sampling (s)        0.3283
time/exploration sampling (s)       0.141005
time/logging (s)                    0.00493093
time/saving (s)                     0.00196114
time/training (s)                   1.95445
time/epoch (s)                      2.43353
time/total (s)                    568.679
Epoch                             232
-----------------------------  ---------------
2019-04-22 22:46:05.731124 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 233 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0314443
trainer/QF2 Loss                    0.0305349
trainer/Policy Loss                12.7641
trainer/Q1 Predictions Mean       -10.7271
trainer/Q1 Predictions Std          6.66992
trainer/Q1 Predictions Max         -6.26747
trainer/Q1 Predictions Min        -27.0588
trainer/Q2 Predictions Mean       -10.7396
trainer/Q2 Predictions Std          6.65628
trainer/Q2 Predictions Max         -6.27053
trainer/Q2 Predictions Min        -27.2189
trainer/Q Targets Mean            -10.8284
trainer/Q Targets Std               6.71982
trainer/Q Targets Max              -6.23071
trainer/Q Targets Min             -27.271
trainer/Log Pis Mean                2.07328
trainer/Log Pis Std                 1.18436
trainer/Log Pis Max                 4.65588
trainer/Log Pis Min                -4.18816
trainer/Policy mu Mean             -0.00551105
trainer/Policy mu Std               0.558599
trainer/Policy mu Max               3.08913
trainer/Policy mu Min              -2.66989
trainer/Policy log std Mean        -2.22302
trainer/Policy log std Std          0.413616
trainer/Policy log std Max         -0.515361
trainer/Policy log std Min         -2.84545
trainer/Alpha                       0.0612735
trainer/Alpha Loss                  0.204613
exploration/num steps total    117200
exploration/num paths total      1172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.506097
exploration/Rewards Std             1.39785
exploration/Rewards Max            -0.00214212
exploration/Rewards Min           -10.0458
exploration/Returns Mean          -50.6097
exploration/Returns Std            21.0425
exploration/Returns Max           -15.7411
exploration/Returns Min           -78.1391
exploration/Actions Mean           -0.025533
exploration/Actions Std             0.260484
exploration/Actions Max             0.99902
exploration/Actions Min            -0.999608
exploration/Num Paths               5
exploration/Average Returns       -50.6097
evaluation/num steps total     351000
evaluation/num paths total       3510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.338462
evaluation/Rewards Std              1.15108
evaluation/Rewards Max             -0.00128735
evaluation/Rewards Min            -11.7761
evaluation/Returns Mean           -33.8462
evaluation/Returns Std             21.2794
evaluation/Returns Max             -1.67623
evaluation/Returns Min            -72.2795
evaluation/Actions Mean             0.0039406
evaluation/Actions Std              0.205078
evaluation/Actions Max              0.99867
evaluation/Actions Min             -0.998291
evaluation/Num Paths               15
evaluation/Average Returns        -33.8462
time/data storing (s)               0.00300542
time/evaluation sampling (s)        0.312738
time/exploration sampling (s)       0.142309
time/logging (s)                    0.00486942
time/saving (s)                     0.00196209
time/training (s)                   1.9561
time/epoch (s)                      2.42098
time/total (s)                    571.105
Epoch                             233
-----------------------------  ---------------
2019-04-22 22:46:08.175798 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 234 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0191873
trainer/QF2 Loss                    0.0171459
trainer/Policy Loss                11.772
trainer/Q1 Predictions Mean        -9.7886
trainer/Q1 Predictions Std          6.11926
trainer/Q1 Predictions Max         -6.28736
trainer/Q1 Predictions Min        -27.7646
trainer/Q2 Predictions Mean        -9.79849
trainer/Q2 Predictions Std          6.12333
trainer/Q2 Predictions Max         -6.26862
trainer/Q2 Predictions Min        -28.1555
trainer/Q Targets Mean             -9.79784
trainer/Q Targets Std               6.11745
trainer/Q Targets Max              -6.20799
trainer/Q Targets Min             -27.9867
trainer/Log Pis Mean                2.01999
trainer/Log Pis Std                 0.983922
trainer/Log Pis Max                 5.30302
trainer/Log Pis Min                -0.668457
trainer/Policy mu Mean              0.00166243
trainer/Policy mu Std               0.467165
trainer/Policy mu Max               2.72784
trainer/Policy mu Min              -2.92947
trainer/Policy log std Mean        -2.29823
trainer/Policy log std Std          0.33948
trainer/Policy log std Max         -0.454093
trainer/Policy log std Min         -2.85821
trainer/Alpha                       0.0617508
trainer/Alpha Loss                  0.0556604
exploration/num steps total    117700
exploration/num paths total      1177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.299912
exploration/Rewards Std             0.911168
exploration/Rewards Max            -0.00529043
exploration/Rewards Min            -8.52851
exploration/Returns Mean          -29.9912
exploration/Returns Std            16.8236
exploration/Returns Max           -15.2889
exploration/Returns Min           -52.7119
exploration/Actions Mean            0.00879949
exploration/Actions Std             0.213292
exploration/Actions Max             0.999279
exploration/Actions Min            -0.992632
exploration/Num Paths               5
exploration/Average Returns       -29.9912
evaluation/num steps total     352500
evaluation/num paths total       3525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.216728
evaluation/Rewards Std              0.850249
evaluation/Rewards Max             -0.0225095
evaluation/Rewards Min            -10.1517
evaluation/Returns Mean           -21.6728
evaluation/Returns Std             15.3955
evaluation/Returns Max             -3.2328
evaluation/Returns Min            -62.1377
evaluation/Actions Mean             0.00336542
evaluation/Actions Std              0.172608
evaluation/Actions Max              0.997691
evaluation/Actions Min             -0.998226
evaluation/Num Paths               15
evaluation/Average Returns        -21.6728
time/data storing (s)               0.00280743
time/evaluation sampling (s)        0.328029
time/exploration sampling (s)       0.139096
time/logging (s)                    0.00486233
time/saving (s)                     0.0019571
time/training (s)                   1.95977
time/epoch (s)                      2.43652
time/total (s)                    573.546
Epoch                             234
-----------------------------  ---------------
2019-04-22 22:46:10.606663 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 235 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0476864
trainer/QF2 Loss                    0.0503765
trainer/Policy Loss                14.3038
trainer/Q1 Predictions Mean       -12.1417
trainer/Q1 Predictions Std          8.40133
trainer/Q1 Predictions Max         -6.27194
trainer/Q1 Predictions Min        -36.0511
trainer/Q2 Predictions Mean       -12.1711
trainer/Q2 Predictions Std          8.42682
trainer/Q2 Predictions Max         -6.29727
trainer/Q2 Predictions Min        -36.1928
trainer/Q Targets Mean            -12.2314
trainer/Q Targets Std               8.34224
trainer/Q Targets Max              -6.2639
trainer/Q Targets Min             -36.5839
trainer/Log Pis Mean                2.21462
trainer/Log Pis Std                 1.25317
trainer/Log Pis Max                 8.44282
trainer/Log Pis Min                -1.21552
trainer/Policy mu Mean             -0.0193279
trainer/Policy mu Std               0.511515
trainer/Policy mu Max               2.82943
trainer/Policy mu Min              -2.93794
trainer/Policy log std Mean        -2.2864
trainer/Policy log std Std          0.355821
trainer/Policy log std Max         -0.666155
trainer/Policy log std Min         -2.78517
trainer/Alpha                       0.0607741
trainer/Alpha Loss                  0.601068
exploration/num steps total    118200
exploration/num paths total      1182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.2351
exploration/Rewards Std             0.682389
exploration/Rewards Max            -0.00705709
exploration/Rewards Min            -7.95964
exploration/Returns Mean          -23.51
exploration/Returns Std            12.8293
exploration/Returns Max           -13.5467
exploration/Returns Min           -47.6388
exploration/Actions Mean            0.00512686
exploration/Actions Std             0.204132
exploration/Actions Max             0.997744
exploration/Actions Min            -0.998643
exploration/Num Paths               5
exploration/Average Returns       -23.51
evaluation/num steps total     354000
evaluation/num paths total       3540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.279503
evaluation/Rewards Std              0.871356
evaluation/Rewards Max             -0.00605532
evaluation/Rewards Min            -10.0664
evaluation/Returns Mean           -27.9503
evaluation/Returns Std             19.7094
evaluation/Returns Max             -3.94726
evaluation/Returns Min            -59.8208
evaluation/Actions Mean             0.000358088
evaluation/Actions Std              0.176112
evaluation/Actions Max              0.997857
evaluation/Actions Min             -0.997815
evaluation/Num Paths               15
evaluation/Average Returns        -27.9503
time/data storing (s)               0.00268195
time/evaluation sampling (s)        0.32882
time/exploration sampling (s)       0.14116
time/logging (s)                    0.00488819
time/saving (s)                     0.0019404
time/training (s)                   1.94317
time/epoch (s)                      2.42266
time/total (s)                    575.973
Epoch                             235
-----------------------------  ----------------
2019-04-22 22:46:13.062339 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 236 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0152435
trainer/QF2 Loss                    0.0166515
trainer/Policy Loss                11.6634
trainer/Q1 Predictions Mean        -9.61599
trainer/Q1 Predictions Std          5.60487
trainer/Q1 Predictions Max         -6.37288
trainer/Q1 Predictions Min        -24.9538
trainer/Q2 Predictions Mean        -9.59395
trainer/Q2 Predictions Std          5.57817
trainer/Q2 Predictions Max         -6.39754
trainer/Q2 Predictions Min        -24.8894
trainer/Q Targets Mean             -9.65309
trainer/Q Targets Std               5.61699
trainer/Q Targets Max              -6.33565
trainer/Q Targets Min             -25.0732
trainer/Log Pis Mean                2.08852
trainer/Log Pis Std                 0.89875
trainer/Log Pis Max                 4.8377
trainer/Log Pis Min                -0.789766
trainer/Policy mu Mean              0.0171824
trainer/Policy mu Std               0.480259
trainer/Policy mu Max               3.00626
trainer/Policy mu Min              -2.88847
trainer/Policy log std Mean        -2.24584
trainer/Policy log std Std          0.339756
trainer/Policy log std Max         -0.73032
trainer/Policy log std Min         -2.80298
trainer/Alpha                       0.0604444
trainer/Alpha Loss                  0.248385
exploration/num steps total    118700
exploration/num paths total      1187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.34408
exploration/Rewards Std             0.554485
exploration/Rewards Max            -0.0162672
exploration/Rewards Min            -6.57943
exploration/Returns Mean          -34.408
exploration/Returns Std            15.8386
exploration/Returns Max           -15.5498
exploration/Returns Min           -53.7312
exploration/Actions Mean           -0.00861148
exploration/Actions Std             0.186677
exploration/Actions Max             0.98844
exploration/Actions Min            -0.994079
exploration/Num Paths               5
exploration/Average Returns       -34.408
evaluation/num steps total     355500
evaluation/num paths total       3555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.316749
evaluation/Rewards Std              0.94828
evaluation/Rewards Max             -0.0248101
evaluation/Rewards Min             -8.97151
evaluation/Returns Mean           -31.6749
evaluation/Returns Std             15.4604
evaluation/Returns Max            -13.1517
evaluation/Returns Min            -67.9125
evaluation/Actions Mean             0.0114377
evaluation/Actions Std              0.194379
evaluation/Actions Max              0.998185
evaluation/Actions Min             -0.998248
evaluation/Num Paths               15
evaluation/Average Returns        -31.6749
time/data storing (s)               0.00275114
time/evaluation sampling (s)        0.319075
time/exploration sampling (s)       0.142887
time/logging (s)                    0.00495576
time/saving (s)                     0.0104441
time/training (s)                   1.96733
time/epoch (s)                      2.44745
time/total (s)                    578.425
Epoch                             236
-----------------------------  ---------------
2019-04-22 22:46:15.505026 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 237 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0455406
trainer/QF2 Loss                    0.0435143
trainer/Policy Loss                12.7604
trainer/Q1 Predictions Mean       -10.6159
trainer/Q1 Predictions Std          7.09032
trainer/Q1 Predictions Max         -6.29822
trainer/Q1 Predictions Min        -42.8317
trainer/Q2 Predictions Mean       -10.6214
trainer/Q2 Predictions Std          7.08712
trainer/Q2 Predictions Max         -6.22786
trainer/Q2 Predictions Min        -42.89
trainer/Q Targets Mean            -10.5996
trainer/Q Targets Std               6.97597
trainer/Q Targets Max              -6.2865
trainer/Q Targets Min             -42.1722
trainer/Log Pis Mean                2.18082
trainer/Log Pis Std                 1.31911
trainer/Log Pis Max                 6.89983
trainer/Log Pis Min                -2.44005
trainer/Policy mu Mean             -0.0117101
trainer/Policy mu Std               0.610521
trainer/Policy mu Max               2.80435
trainer/Policy mu Min              -3.10489
trainer/Policy log std Mean        -2.17794
trainer/Policy log std Std          0.423134
trainer/Policy log std Max         -0.519104
trainer/Policy log std Min         -2.79201
trainer/Alpha                       0.0624914
trainer/Alpha Loss                  0.501361
exploration/num steps total    119200
exploration/num paths total      1192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.406814
exploration/Rewards Std             1.03088
exploration/Rewards Max            -0.0102247
exploration/Rewards Min            -9.84305
exploration/Returns Mean          -40.6814
exploration/Returns Std            19.1232
exploration/Returns Max           -20.2919
exploration/Returns Min           -67.7407
exploration/Actions Mean           -0.0264126
exploration/Actions Std             0.226216
exploration/Actions Max             0.989675
exploration/Actions Min            -0.999763
exploration/Num Paths               5
exploration/Average Returns       -40.6814
evaluation/num steps total     357000
evaluation/num paths total       3570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.418192
evaluation/Rewards Std              1.22159
evaluation/Rewards Max             -0.0120832
evaluation/Rewards Min            -10.6202
evaluation/Returns Mean           -41.8192
evaluation/Returns Std             27.2199
evaluation/Returns Max             -1.53489
evaluation/Returns Min            -83.1053
evaluation/Actions Mean            -0.0131516
evaluation/Actions Std              0.2082
evaluation/Actions Max              0.998472
evaluation/Actions Min             -0.999116
evaluation/Num Paths               15
evaluation/Average Returns        -41.8192
time/data storing (s)               0.00278833
time/evaluation sampling (s)        0.323329
time/exploration sampling (s)       0.138616
time/logging (s)                    0.00487159
time/saving (s)                     0.00191795
time/training (s)                   1.96399
time/epoch (s)                      2.43552
time/total (s)                    580.864
Epoch                             237
-----------------------------  ---------------
2019-04-22 22:46:17.941840 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 238 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.57613
trainer/QF2 Loss                    5.67072
trainer/Policy Loss                13.2541
trainer/Q1 Predictions Mean       -11.3277
trainer/Q1 Predictions Std          7.39038
trainer/Q1 Predictions Max         -6.30091
trainer/Q1 Predictions Min        -31.5034
trainer/Q2 Predictions Mean       -11.3359
trainer/Q2 Predictions Std          7.3807
trainer/Q2 Predictions Max         -6.35958
trainer/Q2 Predictions Min        -31.7188
trainer/Q Targets Mean            -11.1115
trainer/Q Targets Std               7.31665
trainer/Q Targets Max              -0.398802
trainer/Q Targets Min             -31.3552
trainer/Log Pis Mean                1.96145
trainer/Log Pis Std                 1.19195
trainer/Log Pis Max                 5.33175
trainer/Log Pis Min                -1.1546
trainer/Policy mu Mean             -0.00750762
trainer/Policy mu Std               0.4789
trainer/Policy mu Max               3.10742
trainer/Policy mu Min              -3.28178
trainer/Policy log std Mean        -2.30959
trainer/Policy log std Std          0.371264
trainer/Policy log std Max         -0.572925
trainer/Policy log std Min         -2.90067
trainer/Alpha                       0.0613197
trainer/Alpha Loss                 -0.107631
exploration/num steps total    119700
exploration/num paths total      1197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.421158
exploration/Rewards Std             1.04147
exploration/Rewards Max            -0.00142858
exploration/Rewards Min            -8.31494
exploration/Returns Mean          -42.1158
exploration/Returns Std            17.5382
exploration/Returns Max           -17.6406
exploration/Returns Min           -68.8819
exploration/Actions Mean            0.00855428
exploration/Actions Std             0.241941
exploration/Actions Max             0.999064
exploration/Actions Min            -0.996828
exploration/Num Paths               5
exploration/Average Returns       -42.1158
evaluation/num steps total     358500
evaluation/num paths total       3585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262483
evaluation/Rewards Std              0.964954
evaluation/Rewards Max             -0.0087713
evaluation/Rewards Min             -9.4392
evaluation/Returns Mean           -26.2483
evaluation/Returns Std             15.9799
evaluation/Returns Max             -8.0241
evaluation/Returns Min            -53.1417
evaluation/Actions Mean             0.00486443
evaluation/Actions Std              0.183206
evaluation/Actions Max              0.997655
evaluation/Actions Min             -0.997825
evaluation/Num Paths               15
evaluation/Average Returns        -26.2483
time/data storing (s)               0.00273956
time/evaluation sampling (s)        0.325401
time/exploration sampling (s)       0.138721
time/logging (s)                    0.0048708
time/saving (s)                     0.00153597
time/training (s)                   1.9553
time/epoch (s)                      2.42857
time/total (s)                    583.297
Epoch                             238
-----------------------------  ---------------
2019-04-22 22:46:20.373385 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 239 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.75376
trainer/QF2 Loss                    6.79548
trainer/Policy Loss                13.0656
trainer/Q1 Predictions Mean       -11.1044
trainer/Q1 Predictions Std          7.33079
trainer/Q1 Predictions Max         -6.3434
trainer/Q1 Predictions Min        -38.0811
trainer/Q2 Predictions Mean       -11.1224
trainer/Q2 Predictions Std          7.32955
trainer/Q2 Predictions Max         -6.35932
trainer/Q2 Predictions Min        -37.8899
trainer/Q Targets Mean            -10.7682
trainer/Q Targets Std               7.42479
trainer/Q Targets Max              -0.122335
trainer/Q Targets Min             -37.7481
trainer/Log Pis Mean                2.01186
trainer/Log Pis Std                 1.28194
trainer/Log Pis Max                 5.77982
trainer/Log Pis Min                -3.14808
trainer/Policy mu Mean              0.0652265
trainer/Policy mu Std               0.497028
trainer/Policy mu Max               3.07598
trainer/Policy mu Min              -1.92132
trainer/Policy log std Mean        -2.26209
trainer/Policy log std Std          0.357449
trainer/Policy log std Max         -0.61479
trainer/Policy log std Min         -2.82277
trainer/Alpha                       0.0602859
trainer/Alpha Loss                  0.0333052
exploration/num steps total    120200
exploration/num paths total      1202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.431566
exploration/Rewards Std             1.06387
exploration/Rewards Max            -0.0150959
exploration/Rewards Min            -8.38599
exploration/Returns Mean          -43.1566
exploration/Returns Std            13.9376
exploration/Returns Max           -26.1433
exploration/Returns Min           -66.8951
exploration/Actions Mean            0.00900022
exploration/Actions Std             0.249926
exploration/Actions Max             0.99991
exploration/Actions Min            -0.998855
exploration/Num Paths               5
exploration/Average Returns       -43.1566
evaluation/num steps total     360000
evaluation/num paths total       3600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244443
evaluation/Rewards Std              0.782107
evaluation/Rewards Max             -0.00643345
evaluation/Rewards Min             -8.76955
evaluation/Returns Mean           -24.4443
evaluation/Returns Std             15.7277
evaluation/Returns Max             -1.21051
evaluation/Returns Min            -52.0594
evaluation/Actions Mean             0.00372853
evaluation/Actions Std              0.172873
evaluation/Actions Max              0.998452
evaluation/Actions Min             -0.998169
evaluation/Num Paths               15
evaluation/Average Returns        -24.4443
time/data storing (s)               0.00277564
time/evaluation sampling (s)        0.32353
time/exploration sampling (s)       0.137068
time/logging (s)                    0.00495351
time/saving (s)                     0.00195739
time/training (s)                   1.95303
time/epoch (s)                      2.42331
time/total (s)                    585.725
Epoch                             239
-----------------------------  ---------------
2019-04-22 22:46:22.788831 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 240 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0191507
trainer/QF2 Loss                    0.0154891
trainer/Policy Loss                12.3369
trainer/Q1 Predictions Mean       -10.4355
trainer/Q1 Predictions Std          6.64157
trainer/Q1 Predictions Max         -6.26257
trainer/Q1 Predictions Min        -24.9971
trainer/Q2 Predictions Mean       -10.4581
trainer/Q2 Predictions Std          6.63761
trainer/Q2 Predictions Max         -6.2373
trainer/Q2 Predictions Min        -24.7786
trainer/Q Targets Mean            -10.5032
trainer/Q Targets Std               6.62852
trainer/Q Targets Max              -6.21726
trainer/Q Targets Min             -24.9324
trainer/Log Pis Mean                1.91388
trainer/Log Pis Std                 0.96449
trainer/Log Pis Max                 6.82802
trainer/Log Pis Min                -1.22165
trainer/Policy mu Mean              0.0205428
trainer/Policy mu Std               0.262329
trainer/Policy mu Max               2.3961
trainer/Policy mu Min              -0.388619
trainer/Policy log std Mean        -2.27739
trainer/Policy log std Std          0.221861
trainer/Policy log std Max         -0.661264
trainer/Policy log std Min         -2.6562
trainer/Alpha                       0.0597911
trainer/Alpha Loss                 -0.24258
exploration/num steps total    120700
exploration/num paths total      1207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.48593
exploration/Rewards Std             1.41467
exploration/Rewards Max            -0.00603338
exploration/Rewards Min           -10.5616
exploration/Returns Mean          -48.593
exploration/Returns Std            13.3601
exploration/Returns Max           -30.0027
exploration/Returns Min           -64.8635
exploration/Actions Mean            0.0412724
exploration/Actions Std             0.261657
exploration/Actions Max             0.999692
exploration/Actions Min            -0.998542
exploration/Num Paths               5
exploration/Average Returns       -48.593
evaluation/num steps total     361500
evaluation/num paths total       3615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.299896
evaluation/Rewards Std              0.91553
evaluation/Rewards Max             -0.0141328
evaluation/Rewards Min            -10.6298
evaluation/Returns Mean           -29.9896
evaluation/Returns Std             17.1386
evaluation/Returns Max             -5.91161
evaluation/Returns Min            -54.1579
evaluation/Actions Mean            -3.64796e-05
evaluation/Actions Std              0.187796
evaluation/Actions Max              0.999145
evaluation/Actions Min             -0.99806
evaluation/Num Paths               15
evaluation/Average Returns        -29.9896
time/data storing (s)               0.00262354
time/evaluation sampling (s)        0.324142
time/exploration sampling (s)       0.135404
time/logging (s)                    0.00363756
time/saving (s)                     0.00191357
time/training (s)                   1.9386
time/epoch (s)                      2.40632
time/total (s)                    588.136
Epoch                             240
-----------------------------  ----------------
2019-04-22 22:46:25.240861 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 241 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0354561
trainer/QF2 Loss                    0.0336322
trainer/Policy Loss                13.3431
trainer/Q1 Predictions Mean       -11.2422
trainer/Q1 Predictions Std          7.7416
trainer/Q1 Predictions Max         -6.3037
trainer/Q1 Predictions Min        -49.6493
trainer/Q2 Predictions Mean       -11.2289
trainer/Q2 Predictions Std          7.74844
trainer/Q2 Predictions Max         -6.23647
trainer/Q2 Predictions Min        -49.5947
trainer/Q Targets Mean            -11.3754
trainer/Q Targets Std               7.75026
trainer/Q Targets Max              -6.20583
trainer/Q Targets Min             -49.2969
trainer/Log Pis Mean                2.13778
trainer/Log Pis Std                 1.01571
trainer/Log Pis Max                 6.74907
trainer/Log Pis Min                -0.713388
trainer/Policy mu Mean             -0.0250917
trainer/Policy mu Std               0.420322
trainer/Policy mu Max               2.71942
trainer/Policy mu Min              -3.36401
trainer/Policy log std Mean        -2.34049
trainer/Policy log std Std          0.328588
trainer/Policy log std Max         -0.52199
trainer/Policy log std Min         -2.71907
trainer/Alpha                       0.0584115
trainer/Alpha Loss                  0.391318
exploration/num steps total    121200
exploration/num paths total      1212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.310087
exploration/Rewards Std             0.985759
exploration/Rewards Max            -0.00477769
exploration/Rewards Min           -10.9325
exploration/Returns Mean          -31.0087
exploration/Returns Std            19.1593
exploration/Returns Max           -15.3747
exploration/Returns Min           -67.0836
exploration/Actions Mean            0.00717194
exploration/Actions Std             0.213598
exploration/Actions Max             0.999613
exploration/Actions Min            -0.999494
exploration/Num Paths               5
exploration/Average Returns       -31.0087
evaluation/num steps total     363000
evaluation/num paths total       3630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.267584
evaluation/Rewards Std              0.861625
evaluation/Rewards Max             -0.016514
evaluation/Rewards Min            -10.051
evaluation/Returns Mean           -26.7584
evaluation/Returns Std             17.9298
evaluation/Returns Max             -7.81221
evaluation/Returns Min            -62.8494
evaluation/Actions Mean            -0.00181326
evaluation/Actions Std              0.17648
evaluation/Actions Max              0.997449
evaluation/Actions Min             -0.999101
evaluation/Num Paths               15
evaluation/Average Returns        -26.7584
time/data storing (s)               0.00266777
time/evaluation sampling (s)        0.332685
time/exploration sampling (s)       0.1399
time/logging (s)                    0.00403368
time/saving (s)                     0.00156282
time/training (s)                   1.9635
time/epoch (s)                      2.44435
time/total (s)                    590.584
Epoch                             241
-----------------------------  ---------------
2019-04-22 22:46:27.660840 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 242 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.519816
trainer/QF2 Loss                    0.506882
trainer/Policy Loss                11.7541
trainer/Q1 Predictions Mean        -9.97743
trainer/Q1 Predictions Std          5.91066
trainer/Q1 Predictions Max         -6.10518
trainer/Q1 Predictions Min        -24.2484
trainer/Q2 Predictions Mean        -9.99647
trainer/Q2 Predictions Std          5.91331
trainer/Q2 Predictions Max         -6.14993
trainer/Q2 Predictions Min        -24.1364
trainer/Q Targets Mean            -10.0547
trainer/Q Targets Std               6.14902
trainer/Q Targets Max              -0.184012
trainer/Q Targets Min             -25.2626
trainer/Log Pis Mean                1.81467
trainer/Log Pis Std                 1.16959
trainer/Log Pis Max                 5.69637
trainer/Log Pis Min                -2.75238
trainer/Policy mu Mean              0.0101406
trainer/Policy mu Std               0.356881
trainer/Policy mu Max               2.69488
trainer/Policy mu Min              -2.82474
trainer/Policy log std Mean        -2.28257
trainer/Policy log std Std          0.282082
trainer/Policy log std Max         -0.500682
trainer/Policy log std Min         -2.66022
trainer/Alpha                       0.0602296
trainer/Alpha Loss                 -0.520689
exploration/num steps total    121700
exploration/num paths total      1217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.429981
exploration/Rewards Std             1.05751
exploration/Rewards Max            -0.0105739
exploration/Rewards Min            -8.33789
exploration/Returns Mean          -42.9981
exploration/Returns Std            13.3992
exploration/Returns Max           -22.369
exploration/Returns Min           -61.6955
exploration/Actions Mean            0.010221
exploration/Actions Std             0.237692
exploration/Actions Max             0.998323
exploration/Actions Min            -0.997244
exploration/Num Paths               5
exploration/Average Returns       -42.9981
evaluation/num steps total     364500
evaluation/num paths total       3645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.370057
evaluation/Rewards Std              0.773483
evaluation/Rewards Max             -0.0386659
evaluation/Rewards Min             -8.54019
evaluation/Returns Mean           -37.0057
evaluation/Returns Std             22.3097
evaluation/Returns Max            -11.6531
evaluation/Returns Min            -80.2289
evaluation/Actions Mean            -0.00677448
evaluation/Actions Std              0.175737
evaluation/Actions Max              0.996582
evaluation/Actions Min             -0.999099
evaluation/Num Paths               15
evaluation/Average Returns        -37.0057
time/data storing (s)               0.00264814
time/evaluation sampling (s)        0.331537
time/exploration sampling (s)       0.140635
time/logging (s)                    0.00488557
time/saving (s)                     0.00196274
time/training (s)                   1.93239
time/epoch (s)                      2.41406
time/total (s)                    593.002
Epoch                             242
-----------------------------  ---------------
2019-04-22 22:46:30.085720 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 243 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.141682
trainer/QF2 Loss                    0.132282
trainer/Policy Loss                11.8946
trainer/Q1 Predictions Mean        -9.88238
trainer/Q1 Predictions Std          6.26739
trainer/Q1 Predictions Max         -6.20846
trainer/Q1 Predictions Min        -40.8927
trainer/Q2 Predictions Mean        -9.87446
trainer/Q2 Predictions Std          6.25121
trainer/Q2 Predictions Max         -6.17949
trainer/Q2 Predictions Min        -39.9871
trainer/Q Targets Mean            -10.0929
trainer/Q Targets Std               6.47241
trainer/Q Targets Max              -6.13933
trainer/Q Targets Min             -40.6286
trainer/Log Pis Mean                2.05536
trainer/Log Pis Std                 1.06263
trainer/Log Pis Max                 7.62803
trainer/Log Pis Min                -0.830802
trainer/Policy mu Mean              0.00833955
trainer/Policy mu Std               0.535535
trainer/Policy mu Max               3.22448
trainer/Policy mu Min              -2.62563
trainer/Policy log std Mean        -2.26577
trainer/Policy log std Std          0.385015
trainer/Policy log std Max         -0.535494
trainer/Policy log std Min         -2.79746
trainer/Alpha                       0.0606232
trainer/Alpha Loss                  0.155165
exploration/num steps total    122200
exploration/num paths total      1222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.359073
exploration/Rewards Std             0.84854
exploration/Rewards Max            -0.00457156
exploration/Rewards Min            -8.18822
exploration/Returns Mean          -35.9073
exploration/Returns Std            14.6532
exploration/Returns Max           -17.7787
exploration/Returns Min           -60.6684
exploration/Actions Mean            0.00296246
exploration/Actions Std             0.223248
exploration/Actions Max             0.999162
exploration/Actions Min            -0.998157
exploration/Num Paths               5
exploration/Average Returns       -35.9073
evaluation/num steps total     366000
evaluation/num paths total       3660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.21575
evaluation/Rewards Std              0.897307
evaluation/Rewards Max             -0.00140727
evaluation/Rewards Min            -10.2567
evaluation/Returns Mean           -21.575
evaluation/Returns Std             18.3348
evaluation/Returns Max             -1.60199
evaluation/Returns Min            -53.6348
evaluation/Actions Mean             0.00308535
evaluation/Actions Std              0.177809
evaluation/Actions Max              0.997929
evaluation/Actions Min             -0.997855
evaluation/Num Paths               15
evaluation/Average Returns        -21.575
time/data storing (s)               0.00295515
time/evaluation sampling (s)        0.329834
time/exploration sampling (s)       0.140015
time/logging (s)                    0.00488805
time/saving (s)                     0.00190571
time/training (s)                   1.93723
time/epoch (s)                      2.41683
time/total (s)                    595.423
Epoch                             243
-----------------------------  ---------------
2019-04-22 22:46:32.525316 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 244 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0198951
trainer/QF2 Loss                    0.022435
trainer/Policy Loss                12.2622
trainer/Q1 Predictions Mean       -10.3523
trainer/Q1 Predictions Std          7.26526
trainer/Q1 Predictions Max         -6.19004
trainer/Q1 Predictions Min        -42.5557
trainer/Q2 Predictions Mean       -10.374
trainer/Q2 Predictions Std          7.27015
trainer/Q2 Predictions Max         -6.18204
trainer/Q2 Predictions Min        -43.0759
trainer/Q Targets Mean            -10.4507
trainer/Q Targets Std               7.26137
trainer/Q Targets Max              -6.18031
trainer/Q Targets Min             -42.6718
trainer/Log Pis Mean                1.94073
trainer/Log Pis Std                 1.08963
trainer/Log Pis Max                 5.58984
trainer/Log Pis Min                -1.99974
trainer/Policy mu Mean             -0.0103342
trainer/Policy mu Std               0.457298
trainer/Policy mu Max               2.99906
trainer/Policy mu Min              -3.33984
trainer/Policy log std Mean        -2.27692
trainer/Policy log std Std          0.305819
trainer/Policy log std Max         -0.529517
trainer/Policy log std Min         -2.82267
trainer/Alpha                       0.0593078
trainer/Alpha Loss                 -0.167433
exploration/num steps total    122700
exploration/num paths total      1227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.302248
exploration/Rewards Std             0.633903
exploration/Rewards Max            -0.00275414
exploration/Rewards Min            -5.74996
exploration/Returns Mean          -30.2248
exploration/Returns Std             9.67388
exploration/Returns Max           -19.5219
exploration/Returns Min           -48.0365
exploration/Actions Mean           -0.0178225
exploration/Actions Std             0.209247
exploration/Actions Max             0.997698
exploration/Actions Min            -0.998193
exploration/Num Paths               5
exploration/Average Returns       -30.2248
evaluation/num steps total     367500
evaluation/num paths total       3675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.292889
evaluation/Rewards Std              0.881834
evaluation/Rewards Max             -0.0270895
evaluation/Rewards Min             -9.37419
evaluation/Returns Mean           -29.2889
evaluation/Returns Std             18.7403
evaluation/Returns Max             -5.36882
evaluation/Returns Min            -75.3529
evaluation/Actions Mean            -0.000422954
evaluation/Actions Std              0.185265
evaluation/Actions Max              0.998435
evaluation/Actions Min             -0.99905
evaluation/Num Paths               15
evaluation/Average Returns        -29.2889
time/data storing (s)               0.00274857
time/evaluation sampling (s)        0.324522
time/exploration sampling (s)       0.141607
time/logging (s)                    0.00357649
time/saving (s)                     0.0019484
time/training (s)                   1.95574
time/epoch (s)                      2.43014
time/total (s)                    597.857
Epoch                             244
-----------------------------  ----------------
2019-04-22 22:46:34.937620 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 245 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0292371
trainer/QF2 Loss                    0.0333509
trainer/Policy Loss                12.1799
trainer/Q1 Predictions Mean       -10.0857
trainer/Q1 Predictions Std          6.76597
trainer/Q1 Predictions Max         -6.05486
trainer/Q1 Predictions Min        -40.2038
trainer/Q2 Predictions Mean       -10.0992
trainer/Q2 Predictions Std          6.72644
trainer/Q2 Predictions Max         -6.05878
trainer/Q2 Predictions Min        -40.2128
trainer/Q Targets Mean            -10.1301
trainer/Q Targets Std               6.68527
trainer/Q Targets Max              -6.2229
trainer/Q Targets Min             -40.107
trainer/Log Pis Mean                2.15919
trainer/Log Pis Std                 0.973326
trainer/Log Pis Max                 4.57913
trainer/Log Pis Min                -1.96683
trainer/Policy mu Mean             -0.0563584
trainer/Policy mu Std               0.445533
trainer/Policy mu Max               2.00264
trainer/Policy mu Min              -2.95288
trainer/Policy log std Mean        -2.29809
trainer/Policy log std Std          0.325125
trainer/Policy log std Max         -0.571373
trainer/Policy log std Min         -2.63522
trainer/Alpha                       0.0576211
trainer/Alpha Loss                  0.45432
exploration/num steps total    123200
exploration/num paths total      1232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.411458
exploration/Rewards Std             0.803229
exploration/Rewards Max            -0.00432928
exploration/Rewards Min            -8.11515
exploration/Returns Mean          -41.1458
exploration/Returns Std            23.1415
exploration/Returns Max           -12.495
exploration/Returns Min           -75.6373
exploration/Actions Mean           -0.00589568
exploration/Actions Std             0.220743
exploration/Actions Max             0.995263
exploration/Actions Min            -0.999344
exploration/Num Paths               5
exploration/Average Returns       -41.1458
evaluation/num steps total     369000
evaluation/num paths total       3690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263273
evaluation/Rewards Std              0.826125
evaluation/Rewards Max             -0.0147286
evaluation/Rewards Min             -9.68512
evaluation/Returns Mean           -26.3273
evaluation/Returns Std             19.095
evaluation/Returns Max             -5.07994
evaluation/Returns Min            -64.2713
evaluation/Actions Mean            -0.00576473
evaluation/Actions Std              0.177927
evaluation/Actions Max              0.998734
evaluation/Actions Min             -0.998623
evaluation/Num Paths               15
evaluation/Average Returns        -26.3273
time/data storing (s)               0.00274534
time/evaluation sampling (s)        0.324615
time/exploration sampling (s)       0.141589
time/logging (s)                    0.00484253
time/saving (s)                     0.00154396
time/training (s)                   1.93151
time/epoch (s)                      2.40685
time/total (s)                    600.268
Epoch                             245
-----------------------------  ---------------
2019-04-22 22:46:37.448167 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 246 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0305294
trainer/QF2 Loss                    0.0279961
trainer/Policy Loss                11.4375
trainer/Q1 Predictions Mean        -9.66943
trainer/Q1 Predictions Std          5.74278
trainer/Q1 Predictions Max         -6.13186
trainer/Q1 Predictions Min        -29.5364
trainer/Q2 Predictions Mean        -9.68675
trainer/Q2 Predictions Std          5.75497
trainer/Q2 Predictions Max         -6.1309
trainer/Q2 Predictions Min        -29.49
trainer/Q Targets Mean             -9.77455
trainer/Q Targets Std               5.72127
trainer/Q Targets Max              -6.27658
trainer/Q Targets Min             -29.6785
trainer/Log Pis Mean                1.77469
trainer/Log Pis Std                 1.35589
trainer/Log Pis Max                 5.72262
trainer/Log Pis Min                -2.37404
trainer/Policy mu Mean             -0.0561748
trainer/Policy mu Std               0.538202
trainer/Policy mu Max               2.84334
trainer/Policy mu Min              -3.09294
trainer/Policy log std Mean        -2.21227
trainer/Policy log std Std          0.368195
trainer/Policy log std Max         -0.629329
trainer/Policy log std Min         -2.54016
trainer/Alpha                       0.0580065
trainer/Alpha Loss                 -0.641493
exploration/num steps total    123700
exploration/num paths total      1237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.309869
exploration/Rewards Std             0.995652
exploration/Rewards Max            -0.00282653
exploration/Rewards Min            -9.24026
exploration/Returns Mean          -30.9869
exploration/Returns Std            18.2361
exploration/Returns Max           -12.5915
exploration/Returns Min           -59.4961
exploration/Actions Mean            0.00627732
exploration/Actions Std             0.225708
exploration/Actions Max             0.998653
exploration/Actions Min            -0.998015
exploration/Num Paths               5
exploration/Average Returns       -30.9869
evaluation/num steps total     370500
evaluation/num paths total       3705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.313586
evaluation/Rewards Std              1.04038
evaluation/Rewards Max             -0.000403761
evaluation/Rewards Min            -10.0598
evaluation/Returns Mean           -31.3586
evaluation/Returns Std             24.1817
evaluation/Returns Max             -4.80861
evaluation/Returns Min            -83.7157
evaluation/Actions Mean            -0.00227313
evaluation/Actions Std              0.194133
evaluation/Actions Max              0.997882
evaluation/Actions Min             -0.9988
evaluation/Num Paths               15
evaluation/Average Returns        -31.3586
time/data storing (s)               0.00278674
time/evaluation sampling (s)        0.330376
time/exploration sampling (s)       0.140604
time/logging (s)                    0.0048716
time/saving (s)                     0.00193401
time/training (s)                   2.02187
time/epoch (s)                      2.50244
time/total (s)                    602.775
Epoch                             246
-----------------------------  ----------------
2019-04-22 22:46:39.937009 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 247 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.902329
trainer/QF2 Loss                    0.914017
trainer/Policy Loss                12.3466
trainer/Q1 Predictions Mean       -10.402
trainer/Q1 Predictions Std          7.01481
trainer/Q1 Predictions Max         -6.23654
trainer/Q1 Predictions Min        -40.5644
trainer/Q2 Predictions Mean       -10.4163
trainer/Q2 Predictions Std          7.0507
trainer/Q2 Predictions Max         -6.2368
trainer/Q2 Predictions Min        -41.533
trainer/Q Targets Mean            -10.4204
trainer/Q Targets Std               7.23778
trainer/Q Targets Max              -0.0876053
trainer/Q Targets Min             -40.3737
trainer/Log Pis Mean                1.93842
trainer/Log Pis Std                 1.47119
trainer/Log Pis Max                 7.32522
trainer/Log Pis Min                -5.29376
trainer/Policy mu Mean             -0.0404979
trainer/Policy mu Std               0.511229
trainer/Policy mu Max               2.40809
trainer/Policy mu Min              -3.35002
trainer/Policy log std Mean        -2.25298
trainer/Policy log std Std          0.346865
trainer/Policy log std Max         -0.197637
trainer/Policy log std Min         -2.56458
trainer/Alpha                       0.0585811
trainer/Alpha Loss                 -0.174725
exploration/num steps total    124200
exploration/num paths total      1242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.193263
exploration/Rewards Std             0.438763
exploration/Rewards Max            -0.00711336
exploration/Rewards Min            -5.43427
exploration/Returns Mean          -19.3263
exploration/Returns Std             5.94735
exploration/Returns Max           -13.4274
exploration/Returns Min           -29.9669
exploration/Actions Mean           -0.00597146
exploration/Actions Std             0.185724
exploration/Actions Max             0.979964
exploration/Actions Min            -0.997125
exploration/Num Paths               5
exploration/Average Returns       -19.3263
evaluation/num steps total     372000
evaluation/num paths total       3720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.265948
evaluation/Rewards Std              0.853695
evaluation/Rewards Max             -0.00247823
evaluation/Rewards Min             -8.35235
evaluation/Returns Mean           -26.5948
evaluation/Returns Std             17.9145
evaluation/Returns Max             -1.01702
evaluation/Returns Min            -75.209
evaluation/Actions Mean             2.86325e-05
evaluation/Actions Std              0.183084
evaluation/Actions Max              0.997898
evaluation/Actions Min             -0.998455
evaluation/Num Paths               15
evaluation/Average Returns        -26.5948
time/data storing (s)               0.00274211
time/evaluation sampling (s)        0.329049
time/exploration sampling (s)       0.145015
time/logging (s)                    0.00485187
time/saving (s)                     0.00194256
time/training (s)                   1.9973
time/epoch (s)                      2.4809
time/total (s)                    605.26
Epoch                             247
-----------------------------  ----------------
2019-04-22 22:46:42.391403 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 248 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.6323
trainer/QF2 Loss                    5.59878
trainer/Policy Loss                11.6544
trainer/Q1 Predictions Mean        -9.8293
trainer/Q1 Predictions Std          7.11016
trainer/Q1 Predictions Max         -6.12364
trainer/Q1 Predictions Min        -54.5813
trainer/Q2 Predictions Mean        -9.8146
trainer/Q2 Predictions Std          6.99586
trainer/Q2 Predictions Max         -6.12523
trainer/Q2 Predictions Min        -53.0231
trainer/Q Targets Mean             -9.77273
trainer/Q Targets Std               7.28798
trainer/Q Targets Max              -0.104668
trainer/Q Targets Min             -55.2307
trainer/Log Pis Mean                1.85171
trainer/Log Pis Std                 1.22281
trainer/Log Pis Max                 9.26534
trainer/Log Pis Min                -1.63021
trainer/Policy mu Mean              0.0090827
trainer/Policy mu Std               0.389983
trainer/Policy mu Max               3.59506
trainer/Policy mu Min              -2.1899
trainer/Policy log std Mean        -2.2682
trainer/Policy log std Std          0.266629
trainer/Policy log std Max         -0.61035
trainer/Policy log std Min         -2.66466
trainer/Alpha                       0.0589025
trainer/Alpha Loss                 -0.419944
exploration/num steps total    124700
exploration/num paths total      1247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.399054
exploration/Rewards Std             0.842621
exploration/Rewards Max            -0.00958369
exploration/Rewards Min            -9.51545
exploration/Returns Mean          -39.9054
exploration/Returns Std            17.8592
exploration/Returns Max           -17.353
exploration/Returns Min           -55.8341
exploration/Actions Mean            0.00632502
exploration/Actions Std             0.21398
exploration/Actions Max             0.999227
exploration/Actions Min            -0.998797
exploration/Num Paths               5
exploration/Average Returns       -39.9054
evaluation/num steps total     373500
evaluation/num paths total       3735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288453
evaluation/Rewards Std              0.779216
evaluation/Rewards Max             -0.00595515
evaluation/Rewards Min             -9.33912
evaluation/Returns Mean           -28.8453
evaluation/Returns Std             18.7742
evaluation/Returns Max             -7.88501
evaluation/Returns Min            -79.9949
evaluation/Actions Mean             0.00739996
evaluation/Actions Std              0.186022
evaluation/Actions Max              0.997599
evaluation/Actions Min             -0.998763
evaluation/Num Paths               15
evaluation/Average Returns        -28.8453
time/data storing (s)               0.00284923
time/evaluation sampling (s)        0.33735
time/exploration sampling (s)       0.139574
time/logging (s)                    0.00491739
time/saving (s)                     0.0108081
time/training (s)                   1.95223
time/epoch (s)                      2.44773
time/total (s)                    607.711
Epoch                             248
-----------------------------  ---------------
2019-04-22 22:46:44.816519 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 249 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.229728
trainer/QF2 Loss                    0.215261
trainer/Policy Loss                11.9468
trainer/Q1 Predictions Mean       -10.117
trainer/Q1 Predictions Std          7.09656
trainer/Q1 Predictions Max         -6.31598
trainer/Q1 Predictions Min        -55.3876
trainer/Q2 Predictions Mean       -10.1296
trainer/Q2 Predictions Std          7.10498
trainer/Q2 Predictions Max         -6.23829
trainer/Q2 Predictions Min        -55.1948
trainer/Q Targets Mean            -10.387
trainer/Q Targets Std               7.37438
trainer/Q Targets Max              -6.19681
trainer/Q Targets Min             -55.6141
trainer/Log Pis Mean                1.82887
trainer/Log Pis Std                 1.47837
trainer/Log Pis Max                 8.4619
trainer/Log Pis Min                -4.05841
trainer/Policy mu Mean             -0.0259671
trainer/Policy mu Std               0.553088
trainer/Policy mu Max               2.77531
trainer/Policy mu Min              -3.31174
trainer/Policy log std Mean        -2.26198
trainer/Policy log std Std          0.373095
trainer/Policy log std Max         -0.505564
trainer/Policy log std Min         -2.64304
trainer/Alpha                       0.0583972
trainer/Alpha Loss                 -0.486093
exploration/num steps total    125200
exploration/num paths total      1252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.298748
exploration/Rewards Std             0.854092
exploration/Rewards Max            -0.00278109
exploration/Rewards Min            -7.04151
exploration/Returns Mean          -29.8748
exploration/Returns Std             8.91351
exploration/Returns Max           -14.4013
exploration/Returns Min           -38.0045
exploration/Actions Mean           -0.00749014
exploration/Actions Std             0.228767
exploration/Actions Max             0.999829
exploration/Actions Min            -0.999005
exploration/Num Paths               5
exploration/Average Returns       -29.8748
evaluation/num steps total     375000
evaluation/num paths total       3750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.322162
evaluation/Rewards Std              0.8717
evaluation/Rewards Max             -0.0380979
evaluation/Rewards Min            -10.3729
evaluation/Returns Mean           -32.2162
evaluation/Returns Std             22.2118
evaluation/Returns Max             -5.08197
evaluation/Returns Min            -71.9034
evaluation/Actions Mean            -0.00736098
evaluation/Actions Std              0.179528
evaluation/Actions Max              0.997289
evaluation/Actions Min             -0.999162
evaluation/Num Paths               15
evaluation/Average Returns        -32.2162
time/data storing (s)               0.00261929
time/evaluation sampling (s)        0.324184
time/exploration sampling (s)       0.139481
time/logging (s)                    0.00484401
time/saving (s)                     0.00167972
time/training (s)                   1.94372
time/epoch (s)                      2.41653
time/total (s)                    610.132
Epoch                             249
-----------------------------  ---------------
2019-04-22 22:46:47.251288 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 250 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.568117
trainer/QF2 Loss                    0.569428
trainer/Policy Loss                12.2849
trainer/Q1 Predictions Mean       -10.5076
trainer/Q1 Predictions Std          7.50846
trainer/Q1 Predictions Max         -6.18912
trainer/Q1 Predictions Min        -53.5746
trainer/Q2 Predictions Mean       -10.4999
trainer/Q2 Predictions Std          7.50328
trainer/Q2 Predictions Max         -6.17
trainer/Q2 Predictions Min        -53.5421
trainer/Q Targets Mean            -10.4753
trainer/Q Targets Std               7.55352
trainer/Q Targets Max              -0.187954
trainer/Q Targets Min             -52.986
trainer/Log Pis Mean                1.774
trainer/Log Pis Std                 1.20892
trainer/Log Pis Max                 7.70911
trainer/Log Pis Min                -2.98226
trainer/Policy mu Mean             -0.00874343
trainer/Policy mu Std               0.495967
trainer/Policy mu Max               2.61077
trainer/Policy mu Min              -3.61125
trainer/Policy log std Mean        -2.25293
trainer/Policy log std Std          0.342198
trainer/Policy log std Max         -0.345942
trainer/Policy log std Min         -2.58049
trainer/Alpha                       0.0580195
trainer/Alpha Loss                 -0.643393
exploration/num steps total    125700
exploration/num paths total      1257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.452416
exploration/Rewards Std             1.19125
exploration/Rewards Max            -0.00563876
exploration/Rewards Min            -9.81669
exploration/Returns Mean          -45.2416
exploration/Returns Std            20.4019
exploration/Returns Max           -18.2247
exploration/Returns Min           -68.6902
exploration/Actions Mean            0.00716489
exploration/Actions Std             0.235786
exploration/Actions Max             0.999129
exploration/Actions Min            -0.999602
exploration/Num Paths               5
exploration/Average Returns       -45.2416
evaluation/num steps total     376500
evaluation/num paths total       3765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.318339
evaluation/Rewards Std              0.925742
evaluation/Rewards Max             -0.00225981
evaluation/Rewards Min             -8.35648
evaluation/Returns Mean           -31.8339
evaluation/Returns Std             12.5388
evaluation/Returns Max             -8.49842
evaluation/Returns Min            -54.3694
evaluation/Actions Mean             0.0180031
evaluation/Actions Std              0.196236
evaluation/Actions Max              0.999059
evaluation/Actions Min             -0.997577
evaluation/Num Paths               15
evaluation/Average Returns        -31.8339
time/data storing (s)               0.00267783
time/evaluation sampling (s)        0.327687
time/exploration sampling (s)       0.139286
time/logging (s)                    0.00496021
time/saving (s)                     0.00194936
time/training (s)                   1.94986
time/epoch (s)                      2.42642
time/total (s)                    612.563
Epoch                             250
-----------------------------  ---------------
2019-04-22 22:46:49.689797 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 251 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.16508
trainer/QF2 Loss                    1.15753
trainer/Policy Loss                11.669
trainer/Q1 Predictions Mean        -9.58644
trainer/Q1 Predictions Std          5.70598
trainer/Q1 Predictions Max         -6.10998
trainer/Q1 Predictions Min        -23.9959
trainer/Q2 Predictions Mean        -9.5856
trainer/Q2 Predictions Std          5.69796
trainer/Q2 Predictions Max         -6.07566
trainer/Q2 Predictions Min        -23.8439
trainer/Q Targets Mean             -9.51159
trainer/Q Targets Std               5.93311
trainer/Q Targets Max              -0.100388
trainer/Q Targets Min             -24.2159
trainer/Log Pis Mean                2.13718
trainer/Log Pis Std                 0.805467
trainer/Log Pis Max                 5.75445
trainer/Log Pis Min                -0.908792
trainer/Policy mu Mean             -5.24765e-05
trainer/Policy mu Std               0.34683
trainer/Policy mu Max               2.40569
trainer/Policy mu Min              -2.96387
trainer/Policy log std Mean        -2.31869
trainer/Policy log std Std          0.26614
trainer/Policy log std Max         -0.586509
trainer/Policy log std Min         -2.57088
trainer/Alpha                       0.0582045
trainer/Alpha Loss                  0.390141
exploration/num steps total    126200
exploration/num paths total      1262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31451
exploration/Rewards Std             0.960686
exploration/Rewards Max            -0.00220587
exploration/Rewards Min            -8.97801
exploration/Returns Mean          -31.451
exploration/Returns Std            19.3419
exploration/Returns Max           -10.5892
exploration/Returns Min           -55.8356
exploration/Actions Mean            0.0183883
exploration/Actions Std             0.20203
exploration/Actions Max             0.999195
exploration/Actions Min            -0.925694
exploration/Num Paths               5
exploration/Average Returns       -31.451
evaluation/num steps total     378000
evaluation/num paths total       3780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.311617
evaluation/Rewards Std              1.07328
evaluation/Rewards Max             -0.0322378
evaluation/Rewards Min            -10.1016
evaluation/Returns Mean           -31.1617
evaluation/Returns Std             15.3766
evaluation/Returns Max             -8.53915
evaluation/Returns Min            -65.0266
evaluation/Actions Mean             0.0288025
evaluation/Actions Std              0.199081
evaluation/Actions Max              0.998731
evaluation/Actions Min             -0.997158
evaluation/Num Paths               15
evaluation/Average Returns        -31.1617
time/data storing (s)               0.00278729
time/evaluation sampling (s)        0.318599
time/exploration sampling (s)       0.139749
time/logging (s)                    0.00484059
time/saving (s)                     0.00155765
time/training (s)                   1.96246
time/epoch (s)                      2.42999
time/total (s)                    614.998
Epoch                             251
-----------------------------  ----------------
2019-04-22 22:46:52.119199 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 252 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0176779
trainer/QF2 Loss                    0.0173954
trainer/Policy Loss                11.8083
trainer/Q1 Predictions Mean        -9.92138
trainer/Q1 Predictions Std          5.97838
trainer/Q1 Predictions Max         -6.11902
trainer/Q1 Predictions Min        -24.5286
trainer/Q2 Predictions Mean        -9.93001
trainer/Q2 Predictions Std          5.96395
trainer/Q2 Predictions Max         -6.12036
trainer/Q2 Predictions Min        -24.2729
trainer/Q Targets Mean             -9.93427
trainer/Q Targets Std               6.00282
trainer/Q Targets Max              -6.13538
trainer/Q Targets Min             -24.4507
trainer/Log Pis Mean                1.91763
trainer/Log Pis Std                 0.96074
trainer/Log Pis Max                 4.27886
trainer/Log Pis Min                -1.19391
trainer/Policy mu Mean             -0.0301548
trainer/Policy mu Std               0.421482
trainer/Policy mu Max               3.18116
trainer/Policy mu Min              -2.55751
trainer/Policy log std Mean        -2.27361
trainer/Policy log std Std          0.297645
trainer/Policy log std Max         -0.57479
trainer/Policy log std Min         -2.54454
trainer/Alpha                       0.0594616
trainer/Alpha Loss                 -0.232489
exploration/num steps total    126700
exploration/num paths total      1267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.359495
exploration/Rewards Std             1.07224
exploration/Rewards Max            -0.0036724
exploration/Rewards Min            -9.17632
exploration/Returns Mean          -35.9495
exploration/Returns Std            15.1962
exploration/Returns Max           -14.1436
exploration/Returns Min           -56.4208
exploration/Actions Mean            0.00669568
exploration/Actions Std             0.240937
exploration/Actions Max             0.998574
exploration/Actions Min            -0.99913
exploration/Num Paths               5
exploration/Average Returns       -35.9495
evaluation/num steps total     379500
evaluation/num paths total       3795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.265211
evaluation/Rewards Std              0.892875
evaluation/Rewards Max             -0.0265545
evaluation/Rewards Min             -8.80763
evaluation/Returns Mean           -26.5211
evaluation/Returns Std             16.7768
evaluation/Returns Max             -4.22923
evaluation/Returns Min            -56.7972
evaluation/Actions Mean             0.00478805
evaluation/Actions Std              0.186218
evaluation/Actions Max              0.99875
evaluation/Actions Min             -0.995995
evaluation/Num Paths               15
evaluation/Average Returns        -26.5211
time/data storing (s)               0.00272183
time/evaluation sampling (s)        0.326026
time/exploration sampling (s)       0.138785
time/logging (s)                    0.00481758
time/saving (s)                     0.00195434
time/training (s)                   1.9466
time/epoch (s)                      2.42091
time/total (s)                    617.423
Epoch                             252
-----------------------------  ---------------
2019-04-22 22:46:54.531200 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 253 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.379873
trainer/QF2 Loss                    0.378982
trainer/Policy Loss                11.3382
trainer/Q1 Predictions Mean        -9.33346
trainer/Q1 Predictions Std          6.37296
trainer/Q1 Predictions Max         -6.13802
trainer/Q1 Predictions Min        -45.865
trainer/Q2 Predictions Mean        -9.3526
trainer/Q2 Predictions Std          6.36867
trainer/Q2 Predictions Max         -6.1563
trainer/Q2 Predictions Min        -45.7741
trainer/Q Targets Mean             -9.32382
trainer/Q Targets Std               6.41181
trainer/Q Targets Max              -0.180325
trainer/Q Targets Min             -45.6143
trainer/Log Pis Mean                2.0297
trainer/Log Pis Std                 0.743168
trainer/Log Pis Max                 4.15622
trainer/Log Pis Min                -0.941985
trainer/Policy mu Mean             -0.0660462
trainer/Policy mu Std               0.30216
trainer/Policy mu Max               0.341029
trainer/Policy mu Min              -3.14288
trainer/Policy log std Mean        -2.29074
trainer/Policy log std Std          0.234249
trainer/Policy log std Max         -0.54632
trainer/Policy log std Min         -2.59907
trainer/Alpha                       0.0603724
trainer/Alpha Loss                  0.0833797
exploration/num steps total    127200
exploration/num paths total      1272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.275531
exploration/Rewards Std             0.742161
exploration/Rewards Max            -0.00154243
exploration/Rewards Min            -6.35185
exploration/Returns Mean          -27.5531
exploration/Returns Std             7.53259
exploration/Returns Max           -18.3944
exploration/Returns Min           -34.9682
exploration/Actions Mean            0.00732377
exploration/Actions Std             0.221741
exploration/Actions Max             0.999358
exploration/Actions Min            -0.989457
exploration/Num Paths               5
exploration/Average Returns       -27.5531
evaluation/num steps total     381000
evaluation/num paths total       3810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.297636
evaluation/Rewards Std              1.08529
evaluation/Rewards Max             -0.00882492
evaluation/Rewards Min             -9.11912
evaluation/Returns Mean           -29.7636
evaluation/Returns Std             14.7331
evaluation/Returns Max             -4.36872
evaluation/Returns Min            -54.4755
evaluation/Actions Mean             0.00571231
evaluation/Actions Std              0.200508
evaluation/Actions Max              0.998317
evaluation/Actions Min             -0.997751
evaluation/Num Paths               15
evaluation/Average Returns        -29.7636
time/data storing (s)               0.00270553
time/evaluation sampling (s)        0.32456
time/exploration sampling (s)       0.139503
time/logging (s)                    0.00482791
time/saving (s)                     0.00193773
time/training (s)                   1.93
time/epoch (s)                      2.40353
time/total (s)                    619.831
Epoch                             253
-----------------------------  ---------------
2019-04-22 22:46:56.976162 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 254 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.564944
trainer/QF2 Loss                    0.576149
trainer/Policy Loss                12.3405
trainer/Q1 Predictions Mean       -10.4101
trainer/Q1 Predictions Std          7.00652
trainer/Q1 Predictions Max         -6.07469
trainer/Q1 Predictions Min        -38.5226
trainer/Q2 Predictions Mean       -10.4183
trainer/Q2 Predictions Std          7.02203
trainer/Q2 Predictions Max         -6.06265
trainer/Q2 Predictions Min        -39.1986
trainer/Q Targets Mean            -10.4426
trainer/Q Targets Std               7.13263
trainer/Q Targets Max              -0.166739
trainer/Q Targets Min             -38.215
trainer/Log Pis Mean                1.94659
trainer/Log Pis Std                 1.37554
trainer/Log Pis Max                 4.95956
trainer/Log Pis Min                -3.81711
trainer/Policy mu Mean             -0.05502
trainer/Policy mu Std               0.460049
trainer/Policy mu Max               2.23781
trainer/Policy mu Min              -3.03765
trainer/Policy log std Mean        -2.30531
trainer/Policy log std Std          0.320086
trainer/Policy log std Max         -0.637656
trainer/Policy log std Min         -2.71507
trainer/Alpha                       0.0598569
trainer/Alpha Loss                 -0.150391
exploration/num steps total    127700
exploration/num paths total      1277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.438694
exploration/Rewards Std             1.10136
exploration/Rewards Max            -0.00189487
exploration/Rewards Min            -9.44195
exploration/Returns Mean          -43.8694
exploration/Returns Std            15.9625
exploration/Returns Max           -29.7753
exploration/Returns Min           -74.6981
exploration/Actions Mean           -0.0142343
exploration/Actions Std             0.243026
exploration/Actions Max             0.999546
exploration/Actions Min            -0.999318
exploration/Num Paths               5
exploration/Average Returns       -43.8694
evaluation/num steps total     382500
evaluation/num paths total       3825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.294621
evaluation/Rewards Std              0.944082
evaluation/Rewards Max             -0.0242675
evaluation/Rewards Min            -10.2803
evaluation/Returns Mean           -29.4621
evaluation/Returns Std             19.6359
evaluation/Returns Max             -3.41081
evaluation/Returns Min            -75.9167
evaluation/Actions Mean             0.0014139
evaluation/Actions Std              0.18772
evaluation/Actions Max              0.998367
evaluation/Actions Min             -0.999065
evaluation/Num Paths               15
evaluation/Average Returns        -29.4621
time/data storing (s)               0.0028844
time/evaluation sampling (s)        0.325021
time/exploration sampling (s)       0.151581
time/logging (s)                    0.00359359
time/saving (s)                     0.00155257
time/training (s)                   1.95089
time/epoch (s)                      2.43552
time/total (s)                    622.271
Epoch                             254
-----------------------------  ---------------
2019-04-22 22:46:59.487302 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 255 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0154979
trainer/QF2 Loss                    0.0130139
trainer/Policy Loss                11.7357
trainer/Q1 Predictions Mean        -9.74886
trainer/Q1 Predictions Std          5.95371
trainer/Q1 Predictions Max         -6.03693
trainer/Q1 Predictions Min        -26.6007
trainer/Q2 Predictions Mean        -9.73652
trainer/Q2 Predictions Std          5.94128
trainer/Q2 Predictions Max         -6.02438
trainer/Q2 Predictions Min        -26.2216
trainer/Q Targets Mean             -9.79912
trainer/Q Targets Std               5.90091
trainer/Q Targets Max              -6.13747
trainer/Q Targets Min             -26.1096
trainer/Log Pis Mean                1.99197
trainer/Log Pis Std                 1.03936
trainer/Log Pis Max                 5.17534
trainer/Log Pis Min                -1.63369
trainer/Policy mu Mean              0.00275069
trainer/Policy mu Std               0.386829
trainer/Policy mu Max               3.04923
trainer/Policy mu Min              -2.40977
trainer/Policy log std Mean        -2.28959
trainer/Policy log std Std          0.2981
trainer/Policy log std Max         -0.708307
trainer/Policy log std Min         -2.80978
trainer/Alpha                       0.0597005
trainer/Alpha Loss                 -0.0226417
exploration/num steps total    128200
exploration/num paths total      1282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.412141
exploration/Rewards Std             1.10191
exploration/Rewards Max            -0.00527613
exploration/Rewards Min            -9.29351
exploration/Returns Mean          -41.2141
exploration/Returns Std            21.4183
exploration/Returns Max           -13.1021
exploration/Returns Min           -74.2021
exploration/Actions Mean           -0.00142759
exploration/Actions Std             0.237681
exploration/Actions Max             0.999114
exploration/Actions Min            -0.999743
exploration/Num Paths               5
exploration/Average Returns       -41.2141
evaluation/num steps total     384000
evaluation/num paths total       3840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.285208
evaluation/Rewards Std              1.02298
evaluation/Rewards Max             -0.00195922
evaluation/Rewards Min            -10.2404
evaluation/Returns Mean           -28.5208
evaluation/Returns Std             19.1065
evaluation/Returns Max             -4.86574
evaluation/Returns Min            -72.4785
evaluation/Actions Mean             0.00113552
evaluation/Actions Std              0.19989
evaluation/Actions Max              0.998137
evaluation/Actions Min             -0.997861
evaluation/Num Paths               15
evaluation/Average Returns        -28.5208
time/data storing (s)               0.00267225
time/evaluation sampling (s)        0.328349
time/exploration sampling (s)       0.141703
time/logging (s)                    0.00487976
time/saving (s)                     0.00189796
time/training (s)                   2.02502
time/epoch (s)                      2.50452
time/total (s)                    624.78
Epoch                             255
-----------------------------  ---------------
2019-04-22 22:47:01.930914 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 256 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0522735
trainer/QF2 Loss                    0.0629266
trainer/Policy Loss                10.5332
trainer/Q1 Predictions Mean        -8.47511
trainer/Q1 Predictions Std          4.80346
trainer/Q1 Predictions Max         -6.17186
trainer/Q1 Predictions Min        -38.0216
trainer/Q2 Predictions Mean        -8.45763
trainer/Q2 Predictions Std          4.82301
trainer/Q2 Predictions Max         -6.14947
trainer/Q2 Predictions Min        -38.4159
trainer/Q Targets Mean             -8.56197
trainer/Q Targets Std               4.85093
trainer/Q Targets Max              -6.10833
trainer/Q Targets Min             -37.1056
trainer/Log Pis Mean                2.06713
trainer/Log Pis Std                 1.36711
trainer/Log Pis Max                 8.07189
trainer/Log Pis Min                -2.70148
trainer/Policy mu Mean             -0.020291
trainer/Policy mu Std               0.487937
trainer/Policy mu Max               2.73827
trainer/Policy mu Min              -3.616
trainer/Policy log std Mean        -2.3118
trainer/Policy log std Std          0.350333
trainer/Policy log std Max         -0.410883
trainer/Policy log std Min         -2.83148
trainer/Alpha                       0.0619102
trainer/Alpha Loss                  0.186759
exploration/num steps total    128700
exploration/num paths total      1287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.443376
exploration/Rewards Std             1.28971
exploration/Rewards Max            -0.0100356
exploration/Rewards Min            -9.59356
exploration/Returns Mean          -44.3376
exploration/Returns Std            13.2839
exploration/Returns Max           -18.8232
exploration/Returns Min           -56.3078
exploration/Actions Mean            0.0289169
exploration/Actions Std             0.250454
exploration/Actions Max             0.999835
exploration/Actions Min            -0.99983
exploration/Num Paths               5
exploration/Average Returns       -44.3376
evaluation/num steps total     385500
evaluation/num paths total       3855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.337051
evaluation/Rewards Std              1.09204
evaluation/Rewards Max             -0.020384
evaluation/Rewards Min             -9.84403
evaluation/Returns Mean           -33.7051
evaluation/Returns Std             17.0667
evaluation/Returns Max             -6.78858
evaluation/Returns Min            -62.4089
evaluation/Actions Mean            -0.00971949
evaluation/Actions Std              0.198103
evaluation/Actions Max              0.99917
evaluation/Actions Min             -0.999218
evaluation/Num Paths               15
evaluation/Average Returns        -33.7051
time/data storing (s)               0.00277473
time/evaluation sampling (s)        0.32621
time/exploration sampling (s)       0.146936
time/logging (s)                    0.0048499
time/saving (s)                     0.00153809
time/training (s)                   1.95363
time/epoch (s)                      2.43594
time/total (s)                    627.22
Epoch                             256
-----------------------------  ---------------
2019-04-22 22:47:04.390366 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 257 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.574198
trainer/QF2 Loss                    0.592256
trainer/Policy Loss                13.9968
trainer/Q1 Predictions Mean       -11.798
trainer/Q1 Predictions Std          8.82593
trainer/Q1 Predictions Max         -6.07107
trainer/Q1 Predictions Min        -50.7885
trainer/Q2 Predictions Mean       -11.8237
trainer/Q2 Predictions Std          8.85825
trainer/Q2 Predictions Max         -6.09436
trainer/Q2 Predictions Min        -51.4732
trainer/Q Targets Mean            -11.6676
trainer/Q Targets Std               8.65636
trainer/Q Targets Max              -0.0834836
trainer/Q Targets Min             -49.2269
trainer/Log Pis Mean                2.20994
trainer/Log Pis Std                 1.40042
trainer/Log Pis Max                 7.2791
trainer/Log Pis Min                -1.33457
trainer/Policy mu Mean             -0.022661
trainer/Policy mu Std               0.710948
trainer/Policy mu Max               2.95066
trainer/Policy mu Min              -3.57962
trainer/Policy log std Mean        -2.17394
trainer/Policy log std Std          0.457458
trainer/Policy log std Max         -0.443851
trainer/Policy log std Min         -2.7002
trainer/Alpha                       0.0606908
trainer/Alpha Loss                  0.58824
exploration/num steps total    129200
exploration/num paths total      1292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.381833
exploration/Rewards Std             1.00491
exploration/Rewards Max            -0.00325836
exploration/Rewards Min            -8.10467
exploration/Returns Mean          -38.1833
exploration/Returns Std             8.59748
exploration/Returns Max           -30.497
exploration/Returns Min           -53.3599
exploration/Actions Mean           -0.00840074
exploration/Actions Std             0.236565
exploration/Actions Max             0.998615
exploration/Actions Min            -0.99958
exploration/Num Paths               5
exploration/Average Returns       -38.1833
evaluation/num steps total     387000
evaluation/num paths total       3870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.340874
evaluation/Rewards Std              1.04262
evaluation/Rewards Max             -0.00262596
evaluation/Rewards Min            -10.7621
evaluation/Returns Mean           -34.0874
evaluation/Returns Std             17.6003
evaluation/Returns Max            -10.2541
evaluation/Returns Min            -60.5637
evaluation/Actions Mean            -0.00279112
evaluation/Actions Std              0.202401
evaluation/Actions Max              0.998805
evaluation/Actions Min             -0.997854
evaluation/Num Paths               15
evaluation/Average Returns        -34.0874
time/data storing (s)               0.00267643
time/evaluation sampling (s)        0.329517
time/exploration sampling (s)       0.142505
time/logging (s)                    0.0048399
time/saving (s)                     0.00155571
time/training (s)                   1.96984
time/epoch (s)                      2.45093
time/total (s)                    629.675
Epoch                             257
-----------------------------  ---------------
2019-04-22 22:47:06.837510 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 258 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.552822
trainer/QF2 Loss                    0.554265
trainer/Policy Loss                12.2062
trainer/Q1 Predictions Mean       -10.2627
trainer/Q1 Predictions Std          6.39765
trainer/Q1 Predictions Max         -6.17969
trainer/Q1 Predictions Min        -28.7668
trainer/Q2 Predictions Mean       -10.2577
trainer/Q2 Predictions Std          6.37996
trainer/Q2 Predictions Max         -6.15017
trainer/Q2 Predictions Min        -28.5301
trainer/Q Targets Mean            -10.2313
trainer/Q Targets Std               6.40188
trainer/Q Targets Max              -0.113768
trainer/Q Targets Min             -28.2215
trainer/Log Pis Mean                1.95179
trainer/Log Pis Std                 1.28837
trainer/Log Pis Max                 5.67749
trainer/Log Pis Min                -1.77474
trainer/Policy mu Mean              0.0866268
trainer/Policy mu Std               0.561768
trainer/Policy mu Max               3.16059
trainer/Policy mu Min              -2.47034
trainer/Policy log std Mean        -2.19969
trainer/Policy log std Std          0.351445
trainer/Policy log std Max         -0.570177
trainer/Policy log std Min         -2.53347
trainer/Alpha                       0.0588363
trainer/Alpha Loss                 -0.136586
exploration/num steps total    129700
exploration/num paths total      1297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.498627
exploration/Rewards Std             1.1357
exploration/Rewards Max            -0.00932275
exploration/Rewards Min            -9.73853
exploration/Returns Mean          -49.8627
exploration/Returns Std             9.11819
exploration/Returns Max           -36.9381
exploration/Returns Min           -63.2936
exploration/Actions Mean            0.0142636
exploration/Actions Std             0.250222
exploration/Actions Max             0.999721
exploration/Actions Min            -0.997565
exploration/Num Paths               5
exploration/Average Returns       -49.8627
evaluation/num steps total     388500
evaluation/num paths total       3885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270922
evaluation/Rewards Std              0.996724
evaluation/Rewards Max             -0.0113188
evaluation/Rewards Min             -9.99666
evaluation/Returns Mean           -27.0922
evaluation/Returns Std             16.2881
evaluation/Returns Max             -2.72423
evaluation/Returns Min            -59.5284
evaluation/Actions Mean             0.00932793
evaluation/Actions Std              0.185626
evaluation/Actions Max              0.998013
evaluation/Actions Min             -0.999106
evaluation/Num Paths               15
evaluation/Average Returns        -27.0922
time/data storing (s)               0.00259731
time/evaluation sampling (s)        0.326002
time/exploration sampling (s)       0.138592
time/logging (s)                    0.0048539
time/saving (s)                     0.0019502
time/training (s)                   1.96531
time/epoch (s)                      2.4393
time/total (s)                    632.119
Epoch                             258
-----------------------------  ---------------
2019-04-22 22:47:09.274558 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 259 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.58463
trainer/QF2 Loss                    0.586108
trainer/Policy Loss                11.3115
trainer/Q1 Predictions Mean        -9.4835
trainer/Q1 Predictions Std          5.95611
trainer/Q1 Predictions Max         -6.22829
trainer/Q1 Predictions Min        -37.9788
trainer/Q2 Predictions Mean        -9.45213
trainer/Q2 Predictions Std          5.94956
trainer/Q2 Predictions Max         -6.17196
trainer/Q2 Predictions Min        -37.6888
trainer/Q Targets Mean             -9.39644
trainer/Q Targets Std               6.03283
trainer/Q Targets Max              -0.202553
trainer/Q Targets Min             -37.5975
trainer/Log Pis Mean                1.83332
trainer/Log Pis Std                 1.29713
trainer/Log Pis Max                 6.76688
trainer/Log Pis Min                -1.2152
trainer/Policy mu Mean              0.0347593
trainer/Policy mu Std               0.537377
trainer/Policy mu Max               3.19626
trainer/Policy mu Min              -2.65256
trainer/Policy log std Mean        -2.24245
trainer/Policy log std Std          0.334664
trainer/Policy log std Max         -0.364227
trainer/Policy log std Min         -2.47957
trainer/Alpha                       0.0577198
trainer/Alpha Loss                 -0.475373
exploration/num steps total    130200
exploration/num paths total      1302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.349969
exploration/Rewards Std             0.828338
exploration/Rewards Max            -0.00723781
exploration/Rewards Min            -7.41606
exploration/Returns Mean          -34.9969
exploration/Returns Std            14.9356
exploration/Returns Max           -13.3458
exploration/Returns Min           -57.7128
exploration/Actions Mean           -0.0207124
exploration/Actions Std             0.220745
exploration/Actions Max             0.997887
exploration/Actions Min            -0.998764
exploration/Num Paths               5
exploration/Average Returns       -34.9969
evaluation/num steps total     390000
evaluation/num paths total       3900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.246612
evaluation/Rewards Std              0.682363
evaluation/Rewards Max             -0.0173812
evaluation/Rewards Min             -8.40692
evaluation/Returns Mean           -24.6612
evaluation/Returns Std             17.2603
evaluation/Returns Max             -5.19134
evaluation/Returns Min            -57.4573
evaluation/Actions Mean            -0.00609763
evaluation/Actions Std              0.169168
evaluation/Actions Max              0.997719
evaluation/Actions Min             -0.998113
evaluation/Num Paths               15
evaluation/Average Returns        -24.6612
time/data storing (s)               0.00282421
time/evaluation sampling (s)        0.334388
time/exploration sampling (s)       0.139276
time/logging (s)                    0.00481442
time/saving (s)                     0.0019381
time/training (s)                   1.94597
time/epoch (s)                      2.42921
time/total (s)                    634.552
Epoch                             259
-----------------------------  ---------------
2019-04-22 22:47:11.725060 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 260 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0207297
trainer/QF2 Loss                    0.0616195
trainer/Policy Loss                11.7832
trainer/Q1 Predictions Mean       -10.0648
trainer/Q1 Predictions Std          6.72913
trainer/Q1 Predictions Max         -6.18287
trainer/Q1 Predictions Min        -43.7097
trainer/Q2 Predictions Mean       -10.0869
trainer/Q2 Predictions Std          6.81088
trainer/Q2 Predictions Max         -6.13405
trainer/Q2 Predictions Min        -45.2198
trainer/Q Targets Mean            -10.0605
trainer/Q Targets Std               6.63575
trainer/Q Targets Max              -6.10938
trainer/Q Targets Min             -43.2514
trainer/Log Pis Mean                1.71836
trainer/Log Pis Std                 1.17182
trainer/Log Pis Max                 5.58724
trainer/Log Pis Min                -1.06578
trainer/Policy mu Mean             -0.040381
trainer/Policy mu Std               0.469552
trainer/Policy mu Max               3.15565
trainer/Policy mu Min              -3.44453
trainer/Policy log std Mean        -2.22902
trainer/Policy log std Std          0.285533
trainer/Policy log std Max         -0.512522
trainer/Policy log std Min         -2.48019
trainer/Alpha                       0.0565674
trainer/Alpha Loss                 -0.808966
exploration/num steps total    130700
exploration/num paths total      1307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.360331
exploration/Rewards Std             0.856417
exploration/Rewards Max            -0.0027955
exploration/Rewards Min            -7.8524
exploration/Returns Mean          -36.0331
exploration/Returns Std            11.9528
exploration/Returns Max           -19.4657
exploration/Returns Min           -46.9065
exploration/Actions Mean            0.00892355
exploration/Actions Std             0.223317
exploration/Actions Max             0.999384
exploration/Actions Min            -0.997802
exploration/Num Paths               5
exploration/Average Returns       -36.0331
evaluation/num steps total     391500
evaluation/num paths total       3915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.30573
evaluation/Rewards Std              1.01388
evaluation/Rewards Max             -0.0371561
evaluation/Rewards Min            -10.3169
evaluation/Returns Mean           -30.573
evaluation/Returns Std             19.0434
evaluation/Returns Max             -5.62582
evaluation/Returns Min            -59.4705
evaluation/Actions Mean            -0.00165273
evaluation/Actions Std              0.19846
evaluation/Actions Max              0.999482
evaluation/Actions Min             -0.998587
evaluation/Num Paths               15
evaluation/Average Returns        -30.573
time/data storing (s)               0.00284777
time/evaluation sampling (s)        0.326869
time/exploration sampling (s)       0.141243
time/logging (s)                    0.00560588
time/saving (s)                     0.00218486
time/training (s)                   1.96423
time/epoch (s)                      2.44297
time/total (s)                    636.999
Epoch                             260
-----------------------------  ---------------
2019-04-22 22:47:14.139573 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 261 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.14106
trainer/QF2 Loss                    1.13121
trainer/Policy Loss                11.4646
trainer/Q1 Predictions Mean        -9.56741
trainer/Q1 Predictions Std          5.77091
trainer/Q1 Predictions Max         -6.16029
trainer/Q1 Predictions Min        -31.264
trainer/Q2 Predictions Mean        -9.58318
trainer/Q2 Predictions Std          5.78693
trainer/Q2 Predictions Max         -6.1507
trainer/Q2 Predictions Min        -31.4305
trainer/Q Targets Mean             -9.59008
trainer/Q Targets Std               6.0332
trainer/Q Targets Max              -0.0454126
trainer/Q Targets Min             -31.6819
trainer/Log Pis Mean                1.91278
trainer/Log Pis Std                 1.02838
trainer/Log Pis Max                 4.57174
trainer/Log Pis Min                -2.23824
trainer/Policy mu Mean             -0.0135734
trainer/Policy mu Std               0.43257
trainer/Policy mu Max               2.82026
trainer/Policy mu Min              -2.74859
trainer/Policy log std Mean        -2.29564
trainer/Policy log std Std          0.293029
trainer/Policy log std Max         -0.653578
trainer/Policy log std Min         -2.55059
trainer/Alpha                       0.0572686
trainer/Alpha Loss                 -0.249438
exploration/num steps total    131200
exploration/num paths total      1312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.435205
exploration/Rewards Std             1.30424
exploration/Rewards Max            -0.01529
exploration/Rewards Min           -10.505
exploration/Returns Mean          -43.5205
exploration/Returns Std            20.7147
exploration/Returns Max           -18.9702
exploration/Returns Min           -73.7057
exploration/Actions Mean           -0.00965931
exploration/Actions Std             0.242628
exploration/Actions Max             0.998589
exploration/Actions Min            -0.999459
exploration/Num Paths               5
exploration/Average Returns       -43.5205
evaluation/num steps total     393000
evaluation/num paths total       3930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.24066
evaluation/Rewards Std              0.781793
evaluation/Rewards Max             -0.0255655
evaluation/Rewards Min             -9.77593
evaluation/Returns Mean           -24.066
evaluation/Returns Std             15.1586
evaluation/Returns Max             -4.26545
evaluation/Returns Min            -57.185
evaluation/Actions Mean             0.0113531
evaluation/Actions Std              0.165327
evaluation/Actions Max              0.998297
evaluation/Actions Min             -0.995357
evaluation/Num Paths               15
evaluation/Average Returns        -24.066
time/data storing (s)               0.00274533
time/evaluation sampling (s)        0.329506
time/exploration sampling (s)       0.137456
time/logging (s)                    0.00482446
time/saving (s)                     0.00197768
time/training (s)                   1.92734
time/epoch (s)                      2.40385
time/total (s)                    639.408
Epoch                             261
-----------------------------  ---------------
2019-04-22 22:47:16.591850 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 262 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0434189
trainer/QF2 Loss                    0.0383093
trainer/Policy Loss                12.5839
trainer/Q1 Predictions Mean       -10.6877
trainer/Q1 Predictions Std          6.56099
trainer/Q1 Predictions Max         -6.34661
trainer/Q1 Predictions Min        -24.2686
trainer/Q2 Predictions Mean       -10.6669
trainer/Q2 Predictions Std          6.58207
trainer/Q2 Predictions Max         -6.29826
trainer/Q2 Predictions Min        -24.3588
trainer/Q Targets Mean            -10.7634
trainer/Q Targets Std               6.64281
trainer/Q Targets Max              -6.14029
trainer/Q Targets Min             -24.5178
trainer/Log Pis Mean                1.92001
trainer/Log Pis Std                 1.12874
trainer/Log Pis Max                 6.1948
trainer/Log Pis Min                -2.12061
trainer/Policy mu Mean              0.000107403
trainer/Policy mu Std               0.52867
trainer/Policy mu Max               3.21895
trainer/Policy mu Min              -3.26979
trainer/Policy log std Mean        -2.20509
trainer/Policy log std Std          0.317421
trainer/Policy log std Max         -0.609133
trainer/Policy log std Min         -2.52841
trainer/Alpha                       0.0564768
trainer/Alpha Loss                 -0.229865
exploration/num steps total    131700
exploration/num paths total      1317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.214686
exploration/Rewards Std             0.484706
exploration/Rewards Max            -0.00916962
exploration/Rewards Min            -5.15837
exploration/Returns Mean          -21.4686
exploration/Returns Std             5.70216
exploration/Returns Max           -14.738
exploration/Returns Min           -29.651
exploration/Actions Mean            0.00733158
exploration/Actions Std             0.191808
exploration/Actions Max             0.997928
exploration/Actions Min            -0.99655
exploration/Num Paths               5
exploration/Average Returns       -21.4686
evaluation/num steps total     394500
evaluation/num paths total       3945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.340988
evaluation/Rewards Std              1.12173
evaluation/Rewards Max             -0.0203664
evaluation/Rewards Min            -10.7417
evaluation/Returns Mean           -34.0988
evaluation/Returns Std             18.2986
evaluation/Returns Max             -4.66145
evaluation/Returns Min            -72.1282
evaluation/Actions Mean            -0.0103509
evaluation/Actions Std              0.20889
evaluation/Actions Max              0.997463
evaluation/Actions Min             -0.999213
evaluation/Num Paths               15
evaluation/Average Returns        -34.0988
time/data storing (s)               0.00260399
time/evaluation sampling (s)        0.326106
time/exploration sampling (s)       0.138733
time/logging (s)                    0.00481691
time/saving (s)                     0.00191349
time/training (s)                   1.9695
time/epoch (s)                      2.44367
time/total (s)                    641.856
Epoch                             262
-----------------------------  ----------------
2019-04-22 22:47:19.033477 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 263 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.02836
trainer/QF2 Loss                    1.03226
trainer/Policy Loss                12.4259
trainer/Q1 Predictions Mean       -10.5545
trainer/Q1 Predictions Std          7.14778
trainer/Q1 Predictions Max         -6.24727
trainer/Q1 Predictions Min        -42.9055
trainer/Q2 Predictions Mean       -10.5541
trainer/Q2 Predictions Std          7.14891
trainer/Q2 Predictions Max         -6.21444
trainer/Q2 Predictions Min        -42.7609
trainer/Q Targets Mean            -10.5629
trainer/Q Targets Std               7.41807
trainer/Q Targets Max              -0.0819654
trainer/Q Targets Min             -43.3024
trainer/Log Pis Mean                1.87079
trainer/Log Pis Std                 1.07387
trainer/Log Pis Max                 6.64117
trainer/Log Pis Min                -0.762646
trainer/Policy mu Mean              0.072924
trainer/Policy mu Std               0.504851
trainer/Policy mu Max               3.33045
trainer/Policy mu Min              -1.06269
trainer/Policy log std Mean        -2.26231
trainer/Policy log std Std          0.316237
trainer/Policy log std Max         -0.618882
trainer/Policy log std Min         -2.56996
trainer/Alpha                       0.0583307
trainer/Alpha Loss                 -0.367167
exploration/num steps total    132200
exploration/num paths total      1322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.519971
exploration/Rewards Std             1.2338
exploration/Rewards Max            -0.00367931
exploration/Rewards Min           -11.1136
exploration/Returns Mean          -51.9971
exploration/Returns Std            22.1606
exploration/Returns Max           -31.7957
exploration/Returns Min           -94.8699
exploration/Actions Mean           -0.007689
exploration/Actions Std             0.250416
exploration/Actions Max             0.997475
exploration/Actions Min            -0.999713
exploration/Num Paths               5
exploration/Average Returns       -51.9971
evaluation/num steps total     396000
evaluation/num paths total       3960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268388
evaluation/Rewards Std              0.788952
evaluation/Rewards Max             -0.00252858
evaluation/Rewards Min             -9.35409
evaluation/Returns Mean           -26.8388
evaluation/Returns Std             20.9052
evaluation/Returns Max             -2.02709
evaluation/Returns Min            -61.2396
evaluation/Actions Mean             0.00597831
evaluation/Actions Std              0.167648
evaluation/Actions Max              0.999314
evaluation/Actions Min             -0.996786
evaluation/Num Paths               15
evaluation/Average Returns        -26.8388
time/data storing (s)               0.00282336
time/evaluation sampling (s)        0.324431
time/exploration sampling (s)       0.142527
time/logging (s)                    0.00490612
time/saving (s)                     0.0019607
time/training (s)                   1.95648
time/epoch (s)                      2.43313
time/total (s)                    644.294
Epoch                             263
-----------------------------  ---------------
2019-04-22 22:47:21.443778 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 264 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0327947
trainer/QF2 Loss                    0.0379311
trainer/Policy Loss                12.6931
trainer/Q1 Predictions Mean       -10.5077
trainer/Q1 Predictions Std          7.38788
trainer/Q1 Predictions Max         -6.08743
trainer/Q1 Predictions Min        -42.6867
trainer/Q2 Predictions Mean       -10.5072
trainer/Q2 Predictions Std          7.38783
trainer/Q2 Predictions Max         -6.03729
trainer/Q2 Predictions Min        -42.8191
trainer/Q Targets Mean            -10.6466
trainer/Q Targets Std               7.37457
trainer/Q Targets Max              -6.15047
trainer/Q Targets Min             -42.9713
trainer/Log Pis Mean                2.21289
trainer/Log Pis Std                 1.42769
trainer/Log Pis Max                 8.74155
trainer/Log Pis Min                -2.66722
trainer/Policy mu Mean             -0.0152655
trainer/Policy mu Std               0.556483
trainer/Policy mu Max               3.80775
trainer/Policy mu Min              -3.00499
trainer/Policy log std Mean        -2.29976
trainer/Policy log std Std          0.364391
trainer/Policy log std Max         -0.360102
trainer/Policy log std Min         -2.57745
trainer/Alpha                       0.0579591
trainer/Alpha Loss                  0.606323
exploration/num steps total    132700
exploration/num paths total      1327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.418388
exploration/Rewards Std             1.21932
exploration/Rewards Max            -0.00529154
exploration/Rewards Min           -10.7548
exploration/Returns Mean          -41.8388
exploration/Returns Std            11.4985
exploration/Returns Max           -26.6297
exploration/Returns Min           -60.9924
exploration/Actions Mean            0.0153314
exploration/Actions Std             0.244354
exploration/Actions Max             0.999652
exploration/Actions Min            -0.998844
exploration/Num Paths               5
exploration/Average Returns       -41.8388
evaluation/num steps total     397500
evaluation/num paths total       3975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.275293
evaluation/Rewards Std              0.920863
evaluation/Rewards Max             -0.0182472
evaluation/Rewards Min             -8.75671
evaluation/Returns Mean           -27.5293
evaluation/Returns Std             12.9636
evaluation/Returns Max             -8.55726
evaluation/Returns Min            -45.4858
evaluation/Actions Mean             0.0160553
evaluation/Actions Std              0.178168
evaluation/Actions Max              0.999055
evaluation/Actions Min             -0.996421
evaluation/Num Paths               15
evaluation/Average Returns        -27.5293
time/data storing (s)               0.00261399
time/evaluation sampling (s)        0.318458
time/exploration sampling (s)       0.14162
time/logging (s)                    0.00490577
time/saving (s)                     0.00194841
time/training (s)                   1.93215
time/epoch (s)                      2.40169
time/total (s)                    646.7
Epoch                             264
-----------------------------  ---------------
2019-04-22 22:47:23.890131 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 265 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.13524
trainer/QF2 Loss                    5.13896
trainer/Policy Loss                11.1402
trainer/Q1 Predictions Mean        -9.49696
trainer/Q1 Predictions Std          5.70026
trainer/Q1 Predictions Max         -6.07862
trainer/Q1 Predictions Min        -23.3833
trainer/Q2 Predictions Mean        -9.45698
trainer/Q2 Predictions Std          5.716
trainer/Q2 Predictions Max         -5.99054
trainer/Q2 Predictions Min        -23.3357
trainer/Q Targets Mean             -9.37403
trainer/Q Targets Std               5.63361
trainer/Q Targets Max              -0.46034
trainer/Q Targets Min             -23.6815
trainer/Log Pis Mean                1.65841
trainer/Log Pis Std                 0.998323
trainer/Log Pis Max                 3.02534
trainer/Log Pis Min                -2.10022
trainer/Policy mu Mean             -0.0222439
trainer/Policy mu Std               0.329193
trainer/Policy mu Max               2.7886
trainer/Policy mu Min              -2.67314
trainer/Policy log std Mean        -2.24204
trainer/Policy log std Std          0.231953
trainer/Policy log std Max         -0.60988
trainer/Policy log std Min         -2.47301
trainer/Alpha                       0.058096
trainer/Alpha Loss                 -0.972036
exploration/num steps total    133200
exploration/num paths total      1332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.428723
exploration/Rewards Std             1.12934
exploration/Rewards Max            -0.004315
exploration/Rewards Min            -8.98104
exploration/Returns Mean          -42.8723
exploration/Returns Std            21.0571
exploration/Returns Max           -15.4762
exploration/Returns Min           -71.6909
exploration/Actions Mean           -0.0055715
exploration/Actions Std             0.235636
exploration/Actions Max             0.998562
exploration/Actions Min            -0.99831
exploration/Num Paths               5
exploration/Average Returns       -42.8723
evaluation/num steps total     399000
evaluation/num paths total       3990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.325826
evaluation/Rewards Std              1.13706
evaluation/Rewards Max             -0.0192376
evaluation/Rewards Min            -10.308
evaluation/Returns Mean           -32.5826
evaluation/Returns Std             22.591
evaluation/Returns Max             -4.26089
evaluation/Returns Min            -81.7177
evaluation/Actions Mean            -0.00348817
evaluation/Actions Std              0.204765
evaluation/Actions Max              0.997981
evaluation/Actions Min             -0.998907
evaluation/Num Paths               15
evaluation/Average Returns        -32.5826
time/data storing (s)               0.00273586
time/evaluation sampling (s)        0.32624
time/exploration sampling (s)       0.140167
time/logging (s)                    0.00483124
time/saving (s)                     0.0019388
time/training (s)                   1.96254
time/epoch (s)                      2.43845
time/total (s)                    649.142
Epoch                             265
-----------------------------  ---------------
2019-04-22 22:47:26.310071 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 266 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.51883
trainer/QF2 Loss                    5.65087
trainer/Policy Loss                10.5469
trainer/Q1 Predictions Mean        -8.85782
trainer/Q1 Predictions Std          4.88989
trainer/Q1 Predictions Max         -6.2355
trainer/Q1 Predictions Min        -23.5909
trainer/Q2 Predictions Mean        -8.85304
trainer/Q2 Predictions Std          4.89785
trainer/Q2 Predictions Max         -6.14857
trainer/Q2 Predictions Min        -23.5115
trainer/Q Targets Mean             -8.67179
trainer/Q Targets Std               4.94821
trainer/Q Targets Max              -0.204079
trainer/Q Targets Min             -24.0444
trainer/Log Pis Mean                1.68174
trainer/Log Pis Std                 1.4208
trainer/Log Pis Max                 7.18109
trainer/Log Pis Min                -3.20975
trainer/Policy mu Mean              0.0379369
trainer/Policy mu Std               0.420877
trainer/Policy mu Max               2.85263
trainer/Policy mu Min              -2.41295
trainer/Policy log std Mean        -2.24875
trainer/Policy log std Std          0.293417
trainer/Policy log std Max         -0.627841
trainer/Policy log std Min         -2.49704
trainer/Alpha                       0.0582223
trainer/Alpha Loss                 -0.904918
exploration/num steps total    133700
exploration/num paths total      1337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.358087
exploration/Rewards Std             0.846515
exploration/Rewards Max            -0.00340588
exploration/Rewards Min            -7.75367
exploration/Returns Mean          -35.8087
exploration/Returns Std             8.38734
exploration/Returns Max           -24.4934
exploration/Returns Min           -46.2438
exploration/Actions Mean            0.0214954
exploration/Actions Std             0.215926
exploration/Actions Max             0.999201
exploration/Actions Min            -0.99542
exploration/Num Paths               5
exploration/Average Returns       -35.8087
evaluation/num steps total     400500
evaluation/num paths total       4005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224605
evaluation/Rewards Std              0.783645
evaluation/Rewards Max             -0.0243749
evaluation/Rewards Min            -10.0244
evaluation/Returns Mean           -22.4605
evaluation/Returns Std             20.2636
evaluation/Returns Max             -2.83857
evaluation/Returns Min            -80.1144
evaluation/Actions Mean             0.00275874
evaluation/Actions Std              0.17162
evaluation/Actions Max              0.998535
evaluation/Actions Min             -0.998656
evaluation/Num Paths               15
evaluation/Average Returns        -22.4605
time/data storing (s)               0.0028117
time/evaluation sampling (s)        0.320632
time/exploration sampling (s)       0.140177
time/logging (s)                    0.00485163
time/saving (s)                     0.0019524
time/training (s)                   1.94112
time/epoch (s)                      2.41154
time/total (s)                    651.558
Epoch                             266
-----------------------------  ---------------
2019-04-22 22:47:28.757505 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 267 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.16287
trainer/QF2 Loss                    5.17402
trainer/Policy Loss                11.1512
trainer/Q1 Predictions Mean        -9.29298
trainer/Q1 Predictions Std          5.59379
trainer/Q1 Predictions Max         -6.09239
trainer/Q1 Predictions Min        -23.6746
trainer/Q2 Predictions Mean        -9.30499
trainer/Q2 Predictions Std          5.60142
trainer/Q2 Predictions Max         -6.06348
trainer/Q2 Predictions Min        -23.6976
trainer/Q Targets Mean             -9.12759
trainer/Q Targets Std               5.45263
trainer/Q Targets Max              -0.987248
trainer/Q Targets Min             -24.0581
trainer/Log Pis Mean                1.86169
trainer/Log Pis Std                 0.930298
trainer/Log Pis Max                 3.05078
trainer/Log Pis Min                -1.9226
trainer/Policy mu Mean             -0.0099591
trainer/Policy mu Std               0.1137
trainer/Policy mu Max               0.319664
trainer/Policy mu Min              -0.482125
trainer/Policy log std Mean        -2.31566
trainer/Policy log std Std          0.121154
trainer/Policy log std Max         -1.93634
trainer/Policy log std Min         -2.53612
trainer/Alpha                       0.0581817
trainer/Alpha Loss                 -0.393383
exploration/num steps total    134200
exploration/num paths total      1342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378474
exploration/Rewards Std             1.18899
exploration/Rewards Max            -0.00572646
exploration/Rewards Min           -10.5462
exploration/Returns Mean          -37.8474
exploration/Returns Std            16.7815
exploration/Returns Max           -17.996
exploration/Returns Min           -58.105
exploration/Actions Mean           -0.00067845
exploration/Actions Std             0.253105
exploration/Actions Max             0.999375
exploration/Actions Min            -0.999472
exploration/Num Paths               5
exploration/Average Returns       -37.8474
evaluation/num steps total     402000
evaluation/num paths total       4020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.28557
evaluation/Rewards Std              0.857552
evaluation/Rewards Max             -0.00426153
evaluation/Rewards Min             -8.58613
evaluation/Returns Mean           -28.557
evaluation/Returns Std             21.0477
evaluation/Returns Max             -5.43018
evaluation/Returns Min            -72.9331
evaluation/Actions Mean            -0.00526165
evaluation/Actions Std              0.191009
evaluation/Actions Max              0.997418
evaluation/Actions Min             -0.99851
evaluation/Num Paths               15
evaluation/Average Returns        -28.557
time/data storing (s)               0.00283807
time/evaluation sampling (s)        0.326195
time/exploration sampling (s)       0.139183
time/logging (s)                    0.00493637
time/saving (s)                     0.00190518
time/training (s)                   1.96432
time/epoch (s)                      2.43937
time/total (s)                    654.001
Epoch                             267
-----------------------------  ---------------
2019-04-22 22:47:31.207982 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 268 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0548498
trainer/QF2 Loss                    0.0501656
trainer/Policy Loss                12.2341
trainer/Q1 Predictions Mean       -10.4741
trainer/Q1 Predictions Std          6.58559
trainer/Q1 Predictions Max         -5.89518
trainer/Q1 Predictions Min        -30.6685
trainer/Q2 Predictions Mean       -10.5055
trainer/Q2 Predictions Std          6.59285
trainer/Q2 Predictions Max         -5.91622
trainer/Q2 Predictions Min        -30.6758
trainer/Q Targets Mean            -10.666
trainer/Q Targets Std               6.62071
trainer/Q Targets Max              -6.12227
trainer/Q Targets Min             -30.8164
trainer/Log Pis Mean                1.73509
trainer/Log Pis Std                 1.41186
trainer/Log Pis Max                 6.75503
trainer/Log Pis Min                -3.58309
trainer/Policy mu Mean             -0.0318897
trainer/Policy mu Std               0.520171
trainer/Policy mu Max               2.66341
trainer/Policy mu Min              -2.98421
trainer/Policy log std Mean        -2.20558
trainer/Policy log std Std          0.353353
trainer/Policy log std Max         -0.523892
trainer/Policy log std Min         -2.50401
trainer/Alpha                       0.0587846
trainer/Alpha Loss                 -0.750701
exploration/num steps total    134700
exploration/num paths total      1347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.365708
exploration/Rewards Std             1.0816
exploration/Rewards Max            -0.0159665
exploration/Rewards Min            -9.25466
exploration/Returns Mean          -36.5708
exploration/Returns Std            14.1658
exploration/Returns Max           -20.7496
exploration/Returns Min           -57.7122
exploration/Actions Mean            0.00941656
exploration/Actions Std             0.252906
exploration/Actions Max             0.99941
exploration/Actions Min            -0.999535
exploration/Num Paths               5
exploration/Average Returns       -36.5708
evaluation/num steps total     403500
evaluation/num paths total       4035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.28973
evaluation/Rewards Std              0.942066
evaluation/Rewards Max             -0.0120442
evaluation/Rewards Min            -10.9966
evaluation/Returns Mean           -28.973
evaluation/Returns Std             18.5649
evaluation/Returns Max             -3.01738
evaluation/Returns Min            -54.1177
evaluation/Actions Mean             0.0104945
evaluation/Actions Std              0.180404
evaluation/Actions Max              0.998558
evaluation/Actions Min             -0.998065
evaluation/Num Paths               15
evaluation/Average Returns        -28.973
time/data storing (s)               0.00282588
time/evaluation sampling (s)        0.324624
time/exploration sampling (s)       0.142079
time/logging (s)                    0.00488449
time/saving (s)                     0.00176153
time/training (s)                   1.96552
time/epoch (s)                      2.4417
time/total (s)                    656.447
Epoch                             268
-----------------------------  ---------------
2019-04-22 22:47:33.656105 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 269 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.385026
trainer/QF2 Loss                    0.382586
trainer/Policy Loss                14.0087
trainer/Q1 Predictions Mean       -11.8383
trainer/Q1 Predictions Std          8.08244
trainer/Q1 Predictions Max         -6.11856
trainer/Q1 Predictions Min        -44.8295
trainer/Q2 Predictions Mean       -11.835
trainer/Q2 Predictions Std          8.09822
trainer/Q2 Predictions Max         -6.09884
trainer/Q2 Predictions Min        -45.7098
trainer/Q Targets Mean            -11.7566
trainer/Q Targets Std               8.09486
trainer/Q Targets Max              -0.0666442
trainer/Q Targets Min             -44.9793
trainer/Log Pis Mean                2.1799
trainer/Log Pis Std                 1.27121
trainer/Log Pis Max                 7.5969
trainer/Log Pis Min                -0.420902
trainer/Policy mu Mean             -0.0818538
trainer/Policy mu Std               0.660699
trainer/Policy mu Max               2.91179
trainer/Policy mu Min              -3.77687
trainer/Policy log std Mean        -2.23777
trainer/Policy log std Std          0.38849
trainer/Policy log std Max         -0.475837
trainer/Policy log std Min         -2.50972
trainer/Alpha                       0.0583074
trainer/Alpha Loss                  0.511266
exploration/num steps total    135200
exploration/num paths total      1352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.405965
exploration/Rewards Std             0.689983
exploration/Rewards Max            -0.00817945
exploration/Rewards Min            -7.51351
exploration/Returns Mean          -40.5965
exploration/Returns Std            19.1795
exploration/Returns Max           -19.2062
exploration/Returns Min           -66.2059
exploration/Actions Mean           -0.0301486
exploration/Actions Std             0.205661
exploration/Actions Max             0.995621
exploration/Actions Min            -0.997971
exploration/Num Paths               5
exploration/Average Returns       -40.5965
evaluation/num steps total     405000
evaluation/num paths total       4050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.261377
evaluation/Rewards Std              0.936312
evaluation/Rewards Max             -0.0214454
evaluation/Rewards Min             -9.58955
evaluation/Returns Mean           -26.1377
evaluation/Returns Std             17.6665
evaluation/Returns Max             -6.17493
evaluation/Returns Min            -59.163
evaluation/Actions Mean            -0.00973071
evaluation/Actions Std              0.188116
evaluation/Actions Max              0.997809
evaluation/Actions Min             -0.999031
evaluation/Num Paths               15
evaluation/Average Returns        -26.1377
time/data storing (s)               0.00266965
time/evaluation sampling (s)        0.330916
time/exploration sampling (s)       0.140785
time/logging (s)                    0.00427228
time/saving (s)                     0.0016807
time/training (s)                   1.95927
time/epoch (s)                      2.43959
time/total (s)                    658.891
Epoch                             269
-----------------------------  ---------------
2019-04-22 22:47:36.098790 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 270 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.00703
trainer/QF2 Loss                    1.01149
trainer/Policy Loss                11.8333
trainer/Q1 Predictions Mean        -9.80435
trainer/Q1 Predictions Std          6.83121
trainer/Q1 Predictions Max         -6.10292
trainer/Q1 Predictions Min        -44.3
trainer/Q2 Predictions Mean        -9.80936
trainer/Q2 Predictions Std          6.82457
trainer/Q2 Predictions Max         -6.13103
trainer/Q2 Predictions Min        -44.2506
trainer/Q Targets Mean             -9.74046
trainer/Q Targets Std               6.99206
trainer/Q Targets Max              -0.0970217
trainer/Q Targets Min             -43.9193
trainer/Log Pis Mean                2.04756
trainer/Log Pis Std                 1.18967
trainer/Log Pis Max                 5.8141
trainer/Log Pis Min                -1.80939
trainer/Policy mu Mean             -0.0464115
trainer/Policy mu Std               0.564861
trainer/Policy mu Max               2.68697
trainer/Policy mu Min              -3.42883
trainer/Policy log std Mean        -2.25311
trainer/Policy log std Std          0.386094
trainer/Policy log std Max         -0.605419
trainer/Policy log std Min         -2.7061
trainer/Alpha                       0.0582355
trainer/Alpha Loss                  0.135237
exploration/num steps total    135700
exploration/num paths total      1357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.319104
exploration/Rewards Std             0.69655
exploration/Rewards Max            -0.00740825
exploration/Rewards Min            -7.33242
exploration/Returns Mean          -31.9104
exploration/Returns Std            11.8187
exploration/Returns Max           -14.5466
exploration/Returns Min           -46.5759
exploration/Actions Mean           -0.00631062
exploration/Actions Std             0.204788
exploration/Actions Max             0.998106
exploration/Actions Min            -0.998841
exploration/Num Paths               5
exploration/Average Returns       -31.9104
evaluation/num steps total     406500
evaluation/num paths total       4065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.295021
evaluation/Rewards Std              1.13966
evaluation/Rewards Max             -0.0158249
evaluation/Rewards Min            -10.4264
evaluation/Returns Mean           -29.5021
evaluation/Returns Std             17.9039
evaluation/Returns Max             -3.37809
evaluation/Returns Min            -54.4257
evaluation/Actions Mean             0.00251806
evaluation/Actions Std              0.204886
evaluation/Actions Max              0.998345
evaluation/Actions Min             -0.998563
evaluation/Num Paths               15
evaluation/Average Returns        -29.5021
time/data storing (s)               0.00272652
time/evaluation sampling (s)        0.325558
time/exploration sampling (s)       0.140208
time/logging (s)                    0.0043032
time/saving (s)                     0.00194587
time/training (s)                   1.95938
time/epoch (s)                      2.43412
time/total (s)                    661.329
Epoch                             270
-----------------------------  ---------------
2019-04-22 22:47:38.532611 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 271 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.93949
trainer/QF2 Loss                    4.94156
trainer/Policy Loss                12.625
trainer/Q1 Predictions Mean       -10.5776
trainer/Q1 Predictions Std          7.94244
trainer/Q1 Predictions Max         -5.93651
trainer/Q1 Predictions Min        -55.4644
trainer/Q2 Predictions Mean       -10.5508
trainer/Q2 Predictions Std          7.91064
trainer/Q2 Predictions Max         -5.91662
trainer/Q2 Predictions Min        -54.9845
trainer/Q Targets Mean            -10.4318
trainer/Q Targets Std               7.89347
trainer/Q Targets Max              -0.479123
trainer/Q Targets Min             -54.761
trainer/Log Pis Mean                2.07441
trainer/Log Pis Std                 1.31854
trainer/Log Pis Max                 6.64025
trainer/Log Pis Min                -2.55491
trainer/Policy mu Mean             -0.0335237
trainer/Policy mu Std               0.525563
trainer/Policy mu Max               2.97771
trainer/Policy mu Min              -3.80571
trainer/Policy log std Mean        -2.27207
trainer/Policy log std Std          0.339162
trainer/Policy log std Max         -0.497553
trainer/Policy log std Min         -2.65025
trainer/Alpha                       0.0583011
trainer/Alpha Loss                  0.2115
exploration/num steps total    136200
exploration/num paths total      1362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.267486
exploration/Rewards Std             0.734569
exploration/Rewards Max            -0.00335342
exploration/Rewards Min            -8.52691
exploration/Returns Mean          -26.7486
exploration/Returns Std            11.7658
exploration/Returns Max           -15.6403
exploration/Returns Min           -47.8359
exploration/Actions Mean           -0.000583512
exploration/Actions Std             0.222681
exploration/Actions Max             0.997828
exploration/Actions Min            -0.998186
exploration/Num Paths               5
exploration/Average Returns       -26.7486
evaluation/num steps total     408000
evaluation/num paths total       4080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.252258
evaluation/Rewards Std              0.899687
evaluation/Rewards Max             -0.0226722
evaluation/Rewards Min            -10.4668
evaluation/Returns Mean           -25.2258
evaluation/Returns Std             17.656
evaluation/Returns Max             -4.8833
evaluation/Returns Min            -63.3186
evaluation/Actions Mean             0.0058934
evaluation/Actions Std              0.181234
evaluation/Actions Max              0.997322
evaluation/Actions Min             -0.999163
evaluation/Num Paths               15
evaluation/Average Returns        -25.2258
time/data storing (s)               0.00283717
time/evaluation sampling (s)        0.319734
time/exploration sampling (s)       0.142899
time/logging (s)                    0.00483138
time/saving (s)                     0.0019243
time/training (s)                   1.95345
time/epoch (s)                      2.42567
time/total (s)                    663.76
Epoch                             271
-----------------------------  ----------------
2019-04-22 22:47:40.972922 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 272 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.546304
trainer/QF2 Loss                    0.554718
trainer/Policy Loss                12.2508
trainer/Q1 Predictions Mean       -10.3416
trainer/Q1 Predictions Std          7.4307
trainer/Q1 Predictions Max         -6.04679
trainer/Q1 Predictions Min        -42.3432
trainer/Q2 Predictions Mean       -10.315
trainer/Q2 Predictions Std          7.40071
trainer/Q2 Predictions Max         -5.99008
trainer/Q2 Predictions Min        -42.3171
trainer/Q Targets Mean            -10.2728
trainer/Q Targets Std               7.47625
trainer/Q Targets Max              -0.242961
trainer/Q Targets Min             -42.3175
trainer/Log Pis Mean                1.92767
trainer/Log Pis Std                 1.22838
trainer/Log Pis Max                 5.79222
trainer/Log Pis Min                -2.04993
trainer/Policy mu Mean             -0.0422689
trainer/Policy mu Std               0.586886
trainer/Policy mu Max               3.64201
trainer/Policy mu Min              -3.00326
trainer/Policy log std Mean        -2.20359
trainer/Policy log std Std          0.379154
trainer/Policy log std Max         -0.0899631
trainer/Policy log std Min         -2.51564
trainer/Alpha                       0.0599083
trainer/Alpha Loss                 -0.203583
exploration/num steps total    136700
exploration/num paths total      1367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.421615
exploration/Rewards Std             1.23517
exploration/Rewards Max            -0.00378289
exploration/Rewards Min            -9.75383
exploration/Returns Mean          -42.1615
exploration/Returns Std            17.9318
exploration/Returns Max           -19.2647
exploration/Returns Min           -66.9622
exploration/Actions Mean           -0.0109298
exploration/Actions Std             0.251174
exploration/Actions Max             0.998967
exploration/Actions Min            -0.999743
exploration/Num Paths               5
exploration/Average Returns       -42.1615
evaluation/num steps total     409500
evaluation/num paths total       4095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.276399
evaluation/Rewards Std              1.01078
evaluation/Rewards Max             -0.00173346
evaluation/Rewards Min            -10.8923
evaluation/Returns Mean           -27.6399
evaluation/Returns Std             17.8974
evaluation/Returns Max             -3.01302
evaluation/Returns Min            -60.8869
evaluation/Actions Mean            -0.0017816
evaluation/Actions Std              0.177993
evaluation/Actions Max              0.998545
evaluation/Actions Min             -0.999196
evaluation/Num Paths               15
evaluation/Average Returns        -27.6399
time/data storing (s)               0.00266191
time/evaluation sampling (s)        0.327059
time/exploration sampling (s)       0.139648
time/logging (s)                    0.00439142
time/saving (s)                     0.00195761
time/training (s)                   1.95545
time/epoch (s)                      2.43117
time/total (s)                    666.195
Epoch                             272
-----------------------------  ---------------
2019-04-22 22:47:43.434252 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 273 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.10784
trainer/QF2 Loss                    1.13796
trainer/Policy Loss                11.6023
trainer/Q1 Predictions Mean        -9.70673
trainer/Q1 Predictions Std          6.16583
trainer/Q1 Predictions Max         -5.86119
trainer/Q1 Predictions Min        -28.7164
trainer/Q2 Predictions Mean        -9.73248
trainer/Q2 Predictions Std          6.16949
trainer/Q2 Predictions Max         -5.89366
trainer/Q2 Predictions Min        -28.6727
trainer/Q Targets Mean             -9.68749
trainer/Q Targets Std               6.3779
trainer/Q Targets Max              -0.093369
trainer/Q Targets Min             -28.7368
trainer/Log Pis Mean                1.88467
trainer/Log Pis Std                 1.30015
trainer/Log Pis Max                 6.9532
trainer/Log Pis Min                -2.02886
trainer/Policy mu Mean             -0.0223512
trainer/Policy mu Std               0.343681
trainer/Policy mu Max               3.16495
trainer/Policy mu Min              -3.01538
trainer/Policy log std Mean        -2.35981
trainer/Policy log std Std          0.249785
trainer/Policy log std Max         -0.581666
trainer/Policy log std Min         -2.68283
trainer/Alpha                       0.0591637
trainer/Alpha Loss                 -0.326091
exploration/num steps total    137200
exploration/num paths total      1372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.434792
exploration/Rewards Std             1.27249
exploration/Rewards Max            -0.00807909
exploration/Rewards Min            -9.75919
exploration/Returns Mean          -43.4792
exploration/Returns Std             7.94321
exploration/Returns Max           -34.1507
exploration/Returns Min           -57.6227
exploration/Actions Mean           -0.0274336
exploration/Actions Std             0.253627
exploration/Actions Max             0.993887
exploration/Actions Min            -0.998978
exploration/Num Paths               5
exploration/Average Returns       -43.4792
evaluation/num steps total     411000
evaluation/num paths total       4110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.303175
evaluation/Rewards Std              1.07206
evaluation/Rewards Max             -0.00633826
evaluation/Rewards Min            -10.2705
evaluation/Returns Mean           -30.3175
evaluation/Returns Std             18.6031
evaluation/Returns Max             -2.85549
evaluation/Returns Min            -69.6775
evaluation/Actions Mean             0.0158906
evaluation/Actions Std              0.19968
evaluation/Actions Max              0.998496
evaluation/Actions Min             -0.998377
evaluation/Num Paths               15
evaluation/Average Returns        -30.3175
time/data storing (s)               0.0027678
time/evaluation sampling (s)        0.321979
time/exploration sampling (s)       0.139316
time/logging (s)                    0.00359815
time/saving (s)                     0.00198177
time/training (s)                   1.98203
time/epoch (s)                      2.45168
time/total (s)                    668.651
Epoch                             273
-----------------------------  ---------------
2019-04-22 22:47:45.877295 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 274 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.104317
trainer/QF2 Loss                    0.0992833
trainer/Policy Loss                12.9984
trainer/Q1 Predictions Mean       -10.9238
trainer/Q1 Predictions Std          6.94907
trainer/Q1 Predictions Max         -5.93018
trainer/Q1 Predictions Min        -30.8746
trainer/Q2 Predictions Mean       -10.9445
trainer/Q2 Predictions Std          6.95561
trainer/Q2 Predictions Max         -5.92461
trainer/Q2 Predictions Min        -31.2715
trainer/Q Targets Mean            -11.1697
trainer/Q Targets Std               7.12217
trainer/Q Targets Max              -5.95021
trainer/Q Targets Min             -31.3648
trainer/Log Pis Mean                2.06409
trainer/Log Pis Std                 1.12107
trainer/Log Pis Max                 5.39821
trainer/Log Pis Min                -3.27388
trainer/Policy mu Mean             -0.0108042
trainer/Policy mu Std               0.483947
trainer/Policy mu Max               3.00725
trainer/Policy mu Min              -2.74194
trainer/Policy log std Mean        -2.22979
trainer/Policy log std Std          0.323709
trainer/Policy log std Max         -0.537999
trainer/Policy log std Min         -2.52077
trainer/Alpha                       0.0595087
trainer/Alpha Loss                  0.180849
exploration/num steps total    137700
exploration/num paths total      1377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.418034
exploration/Rewards Std             1.02489
exploration/Rewards Max            -0.0104474
exploration/Rewards Min            -9.81252
exploration/Returns Mean          -41.8034
exploration/Returns Std            24.7356
exploration/Returns Max           -12.5027
exploration/Returns Min           -78.3954
exploration/Actions Mean           -0.0198989
exploration/Actions Std             0.223917
exploration/Actions Max             0.993387
exploration/Actions Min            -0.999738
exploration/Num Paths               5
exploration/Average Returns       -41.8034
evaluation/num steps total     412500
evaluation/num paths total       4125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.239276
evaluation/Rewards Std              0.936317
evaluation/Rewards Max             -0.00368354
evaluation/Rewards Min             -9.65098
evaluation/Returns Mean           -23.9276
evaluation/Returns Std             14.8365
evaluation/Returns Max             -3.41092
evaluation/Returns Min            -57.1456
evaluation/Actions Mean             0.0137048
evaluation/Actions Std              0.190674
evaluation/Actions Max              0.998188
evaluation/Actions Min             -0.997635
evaluation/Num Paths               15
evaluation/Average Returns        -23.9276
time/data storing (s)               0.00280112
time/evaluation sampling (s)        0.331248
time/exploration sampling (s)       0.137839
time/logging (s)                    0.00486073
time/saving (s)                     0.00195862
time/training (s)                   1.95891
time/epoch (s)                      2.43762
time/total (s)                    671.092
Epoch                             274
-----------------------------  ---------------
2019-04-22 22:47:48.294821 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 275 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.545729
trainer/QF2 Loss                    0.56174
trainer/Policy Loss                12.0546
trainer/Q1 Predictions Mean        -9.94379
trainer/Q1 Predictions Std          7.54455
trainer/Q1 Predictions Max         -6.00036
trainer/Q1 Predictions Min        -50.7802
trainer/Q2 Predictions Mean        -9.9476
trainer/Q2 Predictions Std          7.50504
trainer/Q2 Predictions Max         -5.9432
trainer/Q2 Predictions Min        -50.2089
trainer/Q Targets Mean             -9.98169
trainer/Q Targets Std               7.67579
trainer/Q Targets Max              -0.0968184
trainer/Q Targets Min             -51.1644
trainer/Log Pis Mean                2.09619
trainer/Log Pis Std                 1.40876
trainer/Log Pis Max                 9.02049
trainer/Log Pis Min                -3.06283
trainer/Policy mu Mean              0.00026938
trainer/Policy mu Std               0.646175
trainer/Policy mu Max               3.40539
trainer/Policy mu Min              -3.08267
trainer/Policy log std Mean        -2.22675
trainer/Policy log std Std          0.381379
trainer/Policy log std Max         -0.64126
trainer/Policy log std Min         -2.56197
trainer/Alpha                       0.0584114
trainer/Alpha Loss                  0.273209
exploration/num steps total    138200
exploration/num paths total      1382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.321967
exploration/Rewards Std             0.906899
exploration/Rewards Max            -0.0123193
exploration/Rewards Min            -7.75741
exploration/Returns Mean          -32.1967
exploration/Returns Std            11.5142
exploration/Returns Max           -21.5531
exploration/Returns Min           -47.9594
exploration/Actions Mean           -0.0166252
exploration/Actions Std             0.223613
exploration/Actions Max             0.996005
exploration/Actions Min            -0.999413
exploration/Num Paths               5
exploration/Average Returns       -32.1967
evaluation/num steps total     414000
evaluation/num paths total       4140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.334531
evaluation/Rewards Std              1.13162
evaluation/Rewards Max             -0.0253383
evaluation/Rewards Min            -10.2504
evaluation/Returns Mean           -33.4531
evaluation/Returns Std             21.9563
evaluation/Returns Max             -8.32871
evaluation/Returns Min            -87.2001
evaluation/Actions Mean            -0.018786
evaluation/Actions Std              0.205256
evaluation/Actions Max              0.997796
evaluation/Actions Min             -0.99944
evaluation/Num Paths               15
evaluation/Average Returns        -33.4531
time/data storing (s)               0.00263446
time/evaluation sampling (s)        0.326233
time/exploration sampling (s)       0.135526
time/logging (s)                    0.00487009
time/saving (s)                     0.00193795
time/training (s)                   1.938
time/epoch (s)                      2.4092
time/total (s)                    673.506
Epoch                             275
-----------------------------  ---------------
2019-04-22 22:47:50.729772 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 276 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.72747
trainer/QF2 Loss                    6.76569
trainer/Policy Loss                12.106
trainer/Q1 Predictions Mean       -10.1951
trainer/Q1 Predictions Std          6.46355
trainer/Q1 Predictions Max         -5.99641
trainer/Q1 Predictions Min        -33.1388
trainer/Q2 Predictions Mean       -10.2056
trainer/Q2 Predictions Std          6.4917
trainer/Q2 Predictions Max         -5.94273
trainer/Q2 Predictions Min        -33.4308
trainer/Q Targets Mean             -9.78117
trainer/Q Targets Std               6.73529
trainer/Q Targets Max              -0.0971726
trainer/Q Targets Min             -32.7918
trainer/Log Pis Mean                1.90648
trainer/Log Pis Std                 1.19794
trainer/Log Pis Max                 6.0586
trainer/Log Pis Min                -2.88337
trainer/Policy mu Mean              0.0609246
trainer/Policy mu Std               0.483526
trainer/Policy mu Max               2.98317
trainer/Policy mu Min              -2.04141
trainer/Policy log std Mean        -2.22104
trainer/Policy log std Std          0.302671
trainer/Policy log std Max         -0.468091
trainer/Policy log std Min         -2.52751
trainer/Alpha                       0.0583455
trainer/Alpha Loss                 -0.26571
exploration/num steps total    138700
exploration/num paths total      1387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.300082
exploration/Rewards Std             0.636299
exploration/Rewards Max            -0.00382892
exploration/Rewards Min            -7.31249
exploration/Returns Mean          -30.0082
exploration/Returns Std            17.1991
exploration/Returns Max           -15.1896
exploration/Returns Min           -62.7027
exploration/Actions Mean           -0.00375418
exploration/Actions Std             0.212626
exploration/Actions Max             0.994095
exploration/Actions Min            -0.991502
exploration/Num Paths               5
exploration/Average Returns       -30.0082
evaluation/num steps total     415500
evaluation/num paths total       4155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282996
evaluation/Rewards Std              0.820229
evaluation/Rewards Max             -0.013677
evaluation/Rewards Min            -10.3012
evaluation/Returns Mean           -28.2996
evaluation/Returns Std             18.7609
evaluation/Returns Max             -5.01689
evaluation/Returns Min            -55.4051
evaluation/Actions Mean            -0.00511977
evaluation/Actions Std              0.178332
evaluation/Actions Max              0.996767
evaluation/Actions Min             -0.998273
evaluation/Num Paths               15
evaluation/Average Returns        -28.2996
time/data storing (s)               0.00273829
time/evaluation sampling (s)        0.320059
time/exploration sampling (s)       0.139433
time/logging (s)                    0.00487682
time/saving (s)                     0.0019772
time/training (s)                   1.9577
time/epoch (s)                      2.42678
time/total (s)                    675.937
Epoch                             276
-----------------------------  ---------------
2019-04-22 22:47:53.158999 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 277 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0241286
trainer/QF2 Loss                    0.0602059
trainer/Policy Loss                13.4222
trainer/Q1 Predictions Mean       -11.051
trainer/Q1 Predictions Std          7.95515
trainer/Q1 Predictions Max         -5.9672
trainer/Q1 Predictions Min        -54.974
trainer/Q2 Predictions Mean       -11.0399
trainer/Q2 Predictions Std          7.97284
trainer/Q2 Predictions Max         -5.92954
trainer/Q2 Predictions Min        -54.6301
trainer/Q Targets Mean            -11.0311
trainer/Q Targets Std               7.99132
trainer/Q Targets Max              -5.89625
trainer/Q Targets Min             -54.7769
trainer/Log Pis Mean                2.394
trainer/Log Pis Std                 1.44485
trainer/Log Pis Max                 9.55145
trainer/Log Pis Min                -0.844586
trainer/Policy mu Mean              0.0166755
trainer/Policy mu Std               0.672243
trainer/Policy mu Max               3.19766
trainer/Policy mu Min              -3.38403
trainer/Policy log std Mean        -2.2571
trainer/Policy log std Std          0.394108
trainer/Policy log std Max         -0.420419
trainer/Policy log std Min         -2.61841
trainer/Alpha                       0.0567951
trainer/Alpha Loss                  1.13015
exploration/num steps total    139200
exploration/num paths total      1392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.482376
exploration/Rewards Std             1.44908
exploration/Rewards Max            -0.00372077
exploration/Rewards Min           -10.5136
exploration/Returns Mean          -48.2376
exploration/Returns Std            19.2833
exploration/Returns Max           -12.4029
exploration/Returns Min           -68.2239
exploration/Actions Mean            0.0075637
exploration/Actions Std             0.252642
exploration/Actions Max             0.998804
exploration/Actions Min            -0.999509
exploration/Num Paths               5
exploration/Average Returns       -48.2376
evaluation/num steps total     417000
evaluation/num paths total       4170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.348995
evaluation/Rewards Std              1.10878
evaluation/Rewards Max             -0.0182022
evaluation/Rewards Min            -10.1834
evaluation/Returns Mean           -34.8995
evaluation/Returns Std             17.4845
evaluation/Returns Max            -11.2809
evaluation/Returns Min            -75.0745
evaluation/Actions Mean            -0.011594
evaluation/Actions Std              0.204754
evaluation/Actions Max              0.998824
evaluation/Actions Min             -0.999159
evaluation/Num Paths               15
evaluation/Average Returns        -34.8995
time/data storing (s)               0.0027642
time/evaluation sampling (s)        0.327079
time/exploration sampling (s)       0.14162
time/logging (s)                    0.00416083
time/saving (s)                     0.00192064
time/training (s)                   1.94275
time/epoch (s)                      2.42029
time/total (s)                    678.361
Epoch                             277
-----------------------------  ---------------
2019-04-22 22:47:55.585707 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 278 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0331616
trainer/QF2 Loss                    0.0334599
trainer/Policy Loss                11.4763
trainer/Q1 Predictions Mean        -9.76946
trainer/Q1 Predictions Std          5.9276
trainer/Q1 Predictions Max         -5.94478
trainer/Q1 Predictions Min        -22.6296
trainer/Q2 Predictions Mean        -9.76493
trainer/Q2 Predictions Std          5.93822
trainer/Q2 Predictions Max         -5.93474
trainer/Q2 Predictions Min        -22.7049
trainer/Q Targets Mean             -9.85006
trainer/Q Targets Std               6.04229
trainer/Q Targets Max              -5.88633
trainer/Q Targets Min             -23.0974
trainer/Log Pis Mean                1.69964
trainer/Log Pis Std                 1.20138
trainer/Log Pis Max                 3.21984
trainer/Log Pis Min                -3.1503
trainer/Policy mu Mean              0.00792684
trainer/Policy mu Std               0.15219
trainer/Policy mu Max               0.427499
trainer/Policy mu Min              -1.14851
trainer/Policy log std Mean        -2.31163
trainer/Policy log std Std          0.127441
trainer/Policy log std Max         -1.75575
trainer/Policy log std Min         -2.58333
trainer/Alpha                       0.0587632
trainer/Alpha Loss                 -0.851271
exploration/num steps total    139700
exploration/num paths total      1397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.394167
exploration/Rewards Std             1.22903
exploration/Rewards Max            -0.00799095
exploration/Rewards Min           -11.7665
exploration/Returns Mean          -39.4167
exploration/Returns Std            20.5908
exploration/Returns Max           -13.2806
exploration/Returns Min           -71.9996
exploration/Actions Mean            0.021634
exploration/Actions Std             0.240685
exploration/Actions Max             0.998897
exploration/Actions Min            -0.998259
exploration/Num Paths               5
exploration/Average Returns       -39.4167
evaluation/num steps total     418500
evaluation/num paths total       4185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260333
evaluation/Rewards Std              0.760218
evaluation/Rewards Max             -0.0109044
evaluation/Rewards Min             -8.37088
evaluation/Returns Mean           -26.0333
evaluation/Returns Std             14.9867
evaluation/Returns Max             -8.61734
evaluation/Returns Min            -54.913
evaluation/Actions Mean             0.0111775
evaluation/Actions Std              0.176738
evaluation/Actions Max              0.996966
evaluation/Actions Min             -0.998124
evaluation/Num Paths               15
evaluation/Average Returns        -26.0333
time/data storing (s)               0.00278007
time/evaluation sampling (s)        0.326637
time/exploration sampling (s)       0.141998
time/logging (s)                    0.00482608
time/saving (s)                     0.00164161
time/training (s)                   1.94097
time/epoch (s)                      2.41885
time/total (s)                    680.784
Epoch                             278
-----------------------------  ---------------
2019-04-22 22:47:57.994056 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 279 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0332412
trainer/QF2 Loss                    0.040396
trainer/Policy Loss                11.6945
trainer/Q1 Predictions Mean        -9.77057
trainer/Q1 Predictions Std          6.37546
trainer/Q1 Predictions Max         -5.95442
trainer/Q1 Predictions Min        -38.3444
trainer/Q2 Predictions Mean        -9.79725
trainer/Q2 Predictions Std          6.38585
trainer/Q2 Predictions Max         -5.96071
trainer/Q2 Predictions Min        -38.4732
trainer/Q Targets Mean             -9.81956
trainer/Q Targets Std               6.37663
trainer/Q Targets Max              -5.8929
trainer/Q Targets Min             -37.7947
trainer/Log Pis Mean                1.91574
trainer/Log Pis Std                 1.14425
trainer/Log Pis Max                 5.42642
trainer/Log Pis Min                -1.67885
trainer/Policy mu Mean              0.057289
trainer/Policy mu Std               0.527068
trainer/Policy mu Max               3.29338
trainer/Policy mu Min              -2.58155
trainer/Policy log std Mean        -2.27479
trainer/Policy log std Std          0.316397
trainer/Policy log std Max         -0.582902
trainer/Policy log std Min         -2.52714
trainer/Alpha                       0.0587867
trainer/Alpha Loss                 -0.238786
exploration/num steps total    140200
exploration/num paths total      1402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.227768
exploration/Rewards Std             0.294376
exploration/Rewards Max            -0.00256319
exploration/Rewards Min            -3.53469
exploration/Returns Mean          -22.7768
exploration/Returns Std            12.2643
exploration/Returns Max           -13.4241
exploration/Returns Min           -46.1707
exploration/Actions Mean           -0.00956009
exploration/Actions Std             0.169804
exploration/Actions Max             0.948486
exploration/Actions Min            -0.996995
exploration/Num Paths               5
exploration/Average Returns       -22.7768
evaluation/num steps total     420000
evaluation/num paths total       4200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.340585
evaluation/Rewards Std              1.07784
evaluation/Rewards Max             -0.0256599
evaluation/Rewards Min            -10.57
evaluation/Returns Mean           -34.0585
evaluation/Returns Std             20.7121
evaluation/Returns Max             -8.25501
evaluation/Returns Min            -82.2807
evaluation/Actions Mean            -0.0118814
evaluation/Actions Std              0.206186
evaluation/Actions Max              0.997853
evaluation/Actions Min             -0.999456
evaluation/Num Paths               15
evaluation/Average Returns        -34.0585
time/data storing (s)               0.00273454
time/evaluation sampling (s)        0.326162
time/exploration sampling (s)       0.144447
time/logging (s)                    0.00491858
time/saving (s)                     0.0019572
time/training (s)                   1.91967
time/epoch (s)                      2.39989
time/total (s)                    683.188
Epoch                             279
-----------------------------  ---------------
2019-04-22 22:48:00.416285 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 280 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0367738
trainer/QF2 Loss                    0.0465903
trainer/Policy Loss                11.88
trainer/Q1 Predictions Mean        -9.89328
trainer/Q1 Predictions Std          6.2368
trainer/Q1 Predictions Max         -5.925
trainer/Q1 Predictions Min        -30.9665
trainer/Q2 Predictions Mean        -9.92377
trainer/Q2 Predictions Std          6.29974
trainer/Q2 Predictions Max         -5.86127
trainer/Q2 Predictions Min        -32.5312
trainer/Q Targets Mean            -10.0115
trainer/Q Targets Std               6.33768
trainer/Q Targets Max              -5.90745
trainer/Q Targets Min             -31.2826
trainer/Log Pis Mean                1.98498
trainer/Log Pis Std                 1.14814
trainer/Log Pis Max                 4.608
trainer/Log Pis Min                -3.37919
trainer/Policy mu Mean             -0.016943
trainer/Policy mu Std               0.444326
trainer/Policy mu Max               3.14775
trainer/Policy mu Min              -3.11048
trainer/Policy log std Mean        -2.28189
trainer/Policy log std Std          0.30468
trainer/Policy log std Max         -0.512413
trainer/Policy log std Min         -2.60485
trainer/Alpha                       0.0590221
trainer/Alpha Loss                 -0.042504
exploration/num steps total    140700
exploration/num paths total      1407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.358444
exploration/Rewards Std             0.994908
exploration/Rewards Max            -0.00541086
exploration/Rewards Min            -8.04586
exploration/Returns Mean          -35.8444
exploration/Returns Std            20.3442
exploration/Returns Max           -11.9629
exploration/Returns Min           -63.0981
exploration/Actions Mean            0.00320365
exploration/Actions Std             0.218068
exploration/Actions Max             0.99864
exploration/Actions Min            -0.999917
exploration/Num Paths               5
exploration/Average Returns       -35.8444
evaluation/num steps total     421500
evaluation/num paths total       4215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.201856
evaluation/Rewards Std              0.834673
evaluation/Rewards Max             -0.00434274
evaluation/Rewards Min             -9.70164
evaluation/Returns Mean           -20.1856
evaluation/Returns Std             14.3318
evaluation/Returns Max             -1.73165
evaluation/Returns Min            -51.6072
evaluation/Actions Mean            -0.00737555
evaluation/Actions Std              0.179961
evaluation/Actions Max              0.998047
evaluation/Actions Min             -0.998635
evaluation/Num Paths               15
evaluation/Average Returns        -20.1856
time/data storing (s)               0.0027497
time/evaluation sampling (s)        0.318208
time/exploration sampling (s)       0.135448
time/logging (s)                    0.0048187
time/saving (s)                     0.0015526
time/training (s)                   1.95078
time/epoch (s)                      2.41355
time/total (s)                    685.606
Epoch                             280
-----------------------------  ---------------
2019-04-22 22:48:02.850867 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 281 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0198344
trainer/QF2 Loss                    0.0145565
trainer/Policy Loss                12.7783
trainer/Q1 Predictions Mean       -10.6995
trainer/Q1 Predictions Std          6.5945
trainer/Q1 Predictions Max         -5.87747
trainer/Q1 Predictions Min        -23.578
trainer/Q2 Predictions Mean       -10.7088
trainer/Q2 Predictions Std          6.577
trainer/Q2 Predictions Max         -5.87745
trainer/Q2 Predictions Min        -23.27
trainer/Q Targets Mean            -10.7686
trainer/Q Targets Std               6.56208
trainer/Q Targets Max              -5.89343
trainer/Q Targets Min             -23.4824
trainer/Log Pis Mean                2.09931
trainer/Log Pis Std                 1.01757
trainer/Log Pis Max                 5.60083
trainer/Log Pis Min                -1.55256
trainer/Policy mu Mean              0.00654531
trainer/Policy mu Std               0.532164
trainer/Policy mu Max               2.72805
trainer/Policy mu Min              -2.91303
trainer/Policy log std Mean        -2.23468
trainer/Policy log std Std          0.382744
trainer/Policy log std Max         -0.434177
trainer/Policy log std Min         -2.54446
trainer/Alpha                       0.0601845
trainer/Alpha Loss                  0.279098
exploration/num steps total    141200
exploration/num paths total      1412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.341371
exploration/Rewards Std             0.954752
exploration/Rewards Max            -0.00575084
exploration/Rewards Min           -10.1158
exploration/Returns Mean          -34.1371
exploration/Returns Std            19.3128
exploration/Returns Max           -13.3261
exploration/Returns Min           -58.8703
exploration/Actions Mean            0.0233366
exploration/Actions Std             0.220899
exploration/Actions Max             0.998151
exploration/Actions Min            -0.996274
exploration/Num Paths               5
exploration/Average Returns       -34.1371
evaluation/num steps total     423000
evaluation/num paths total       4230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282282
evaluation/Rewards Std              0.917649
evaluation/Rewards Max             -0.00893151
evaluation/Rewards Min            -10.0821
evaluation/Returns Mean           -28.2282
evaluation/Returns Std             15.9328
evaluation/Returns Max             -1.86789
evaluation/Returns Min            -56.7545
evaluation/Actions Mean             0.0111235
evaluation/Actions Std              0.187474
evaluation/Actions Max              0.997242
evaluation/Actions Min             -0.998096
evaluation/Num Paths               15
evaluation/Average Returns        -28.2282
time/data storing (s)               0.00274967
time/evaluation sampling (s)        0.323298
time/exploration sampling (s)       0.141388
time/logging (s)                    0.00482639
time/saving (s)                     0.00161083
time/training (s)                   1.95224
time/epoch (s)                      2.42612
time/total (s)                    688.036
Epoch                             281
-----------------------------  ---------------
2019-04-22 22:48:05.316169 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 282 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0165842
trainer/QF2 Loss                    0.0145213
trainer/Policy Loss                12.3342
trainer/Q1 Predictions Mean       -10.47
trainer/Q1 Predictions Std          7.87083
trainer/Q1 Predictions Max         -5.94822
trainer/Q1 Predictions Min        -59.377
trainer/Q2 Predictions Mean       -10.4671
trainer/Q2 Predictions Std          7.93316
trainer/Q2 Predictions Max         -6.00438
trainer/Q2 Predictions Min        -60.1239
trainer/Q Targets Mean            -10.4568
trainer/Q Targets Std               7.90097
trainer/Q Targets Max              -5.94104
trainer/Q Targets Min             -59.751
trainer/Log Pis Mean                1.86298
trainer/Log Pis Std                 1.20577
trainer/Log Pis Max                 5.61525
trainer/Log Pis Min                -2.59115
trainer/Policy mu Mean             -0.107805
trainer/Policy mu Std               0.578284
trainer/Policy mu Max               1.86721
trainer/Policy mu Min              -3.6253
trainer/Policy log std Mean        -2.23897
trainer/Policy log std Std          0.369973
trainer/Policy log std Max         -0.427676
trainer/Policy log std Min         -2.56867
trainer/Alpha                       0.0586555
trainer/Alpha Loss                 -0.388588
exploration/num steps total    141700
exploration/num paths total      1417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.369101
exploration/Rewards Std             0.926356
exploration/Rewards Max            -0.000624653
exploration/Rewards Min            -9.16775
exploration/Returns Mean          -36.9101
exploration/Returns Std            18.9444
exploration/Returns Max           -14.7061
exploration/Returns Min           -58.5096
exploration/Actions Mean            0.00372045
exploration/Actions Std             0.209796
exploration/Actions Max             0.998486
exploration/Actions Min            -0.999333
exploration/Num Paths               5
exploration/Average Returns       -36.9101
evaluation/num steps total     424500
evaluation/num paths total       4245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283081
evaluation/Rewards Std              0.993657
evaluation/Rewards Max             -0.0326239
evaluation/Rewards Min            -10.8647
evaluation/Returns Mean           -28.3081
evaluation/Returns Std             19.3157
evaluation/Returns Max             -7.77296
evaluation/Returns Min            -65.4834
evaluation/Actions Mean            -0.00245385
evaluation/Actions Std              0.188728
evaluation/Actions Max              0.996904
evaluation/Actions Min             -0.998665
evaluation/Num Paths               15
evaluation/Average Returns        -28.3081
time/data storing (s)               0.0028794
time/evaluation sampling (s)        0.327105
time/exploration sampling (s)       0.142889
time/logging (s)                    0.00481999
time/saving (s)                     0.0019562
time/training (s)                   1.97709
time/epoch (s)                      2.45674
time/total (s)                    690.497
Epoch                             282
-----------------------------  ----------------
2019-04-22 22:48:07.787100 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 283 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0551896
trainer/QF2 Loss                    0.0538682
trainer/Policy Loss                11.5128
trainer/Q1 Predictions Mean        -9.66971
trainer/Q1 Predictions Std          5.71853
trainer/Q1 Predictions Max         -5.97904
trainer/Q1 Predictions Min        -22.511
trainer/Q2 Predictions Mean        -9.64663
trainer/Q2 Predictions Std          5.73396
trainer/Q2 Predictions Max         -5.90263
trainer/Q2 Predictions Min        -22.4182
trainer/Q Targets Mean             -9.72642
trainer/Q Targets Std               5.91878
trainer/Q Targets Max              -5.80372
trainer/Q Targets Min             -23.0649
trainer/Log Pis Mean                1.8561
trainer/Log Pis Std                 1.03176
trainer/Log Pis Max                 3.60697
trainer/Log Pis Min                -2.87634
trainer/Policy mu Mean              0.0386322
trainer/Policy mu Std               0.222243
trainer/Policy mu Max               2.65134
trainer/Policy mu Min              -0.459857
trainer/Policy log std Mean        -2.29136
trainer/Policy log std Std          0.181109
trainer/Policy log std Max         -0.774266
trainer/Policy log std Min         -2.63834
trainer/Alpha                       0.057538
trainer/Alpha Loss                 -0.410866
exploration/num steps total    142200
exploration/num paths total      1422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.385547
exploration/Rewards Std             0.936009
exploration/Rewards Max            -0.00107902
exploration/Rewards Min            -9.25792
exploration/Returns Mean          -38.5547
exploration/Returns Std            24.0459
exploration/Returns Max           -15.0593
exploration/Returns Min           -76.1658
exploration/Actions Mean           -0.00731122
exploration/Actions Std             0.214816
exploration/Actions Max             0.999681
exploration/Actions Min            -0.998123
exploration/Num Paths               5
exploration/Average Returns       -38.5547
evaluation/num steps total     426000
evaluation/num paths total       4260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.218327
evaluation/Rewards Std              0.919071
evaluation/Rewards Max             -0.00578331
evaluation/Rewards Min             -9.50291
evaluation/Returns Mean           -21.8327
evaluation/Returns Std             14.6025
evaluation/Returns Max             -2.04862
evaluation/Returns Min            -44.5286
evaluation/Actions Mean             0.0124991
evaluation/Actions Std              0.188465
evaluation/Actions Max              0.998343
evaluation/Actions Min             -0.997755
evaluation/Num Paths               15
evaluation/Average Returns        -21.8327
time/data storing (s)               0.00281065
time/evaluation sampling (s)        0.327407
time/exploration sampling (s)       0.145411
time/logging (s)                    0.00481229
time/saving (s)                     0.00195893
time/training (s)                   1.97995
time/epoch (s)                      2.46235
time/total (s)                    692.964
Epoch                             283
-----------------------------  ---------------
2019-04-22 22:48:10.239613 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 284 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0298009
trainer/QF2 Loss                    0.0157738
trainer/Policy Loss                10.2909
trainer/Q1 Predictions Mean        -8.37279
trainer/Q1 Predictions Std          4.92054
trainer/Q1 Predictions Max         -5.99412
trainer/Q1 Predictions Min        -38.105
trainer/Q2 Predictions Mean        -8.40731
trainer/Q2 Predictions Std          4.9056
trainer/Q2 Predictions Max         -5.91438
trainer/Q2 Predictions Min        -37.7904
trainer/Q Targets Mean             -8.4286
trainer/Q Targets Std               4.92332
trainer/Q Targets Max              -5.89144
trainer/Q Targets Min             -37.8877
trainer/Log Pis Mean                1.90286
trainer/Log Pis Std                 1.25923
trainer/Log Pis Max                 6.50876
trainer/Log Pis Min                -2.71691
trainer/Policy mu Mean             -0.0508628
trainer/Policy mu Std               0.490838
trainer/Policy mu Max               3.71947
trainer/Policy mu Min              -2.8694
trainer/Policy log std Mean        -2.26275
trainer/Policy log std Std          0.315736
trainer/Policy log std Max         -0.517907
trainer/Policy log std Min         -2.53369
trainer/Alpha                       0.0565703
trainer/Alpha Loss                 -0.279009
exploration/num steps total    142700
exploration/num paths total      1427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.339937
exploration/Rewards Std             0.946574
exploration/Rewards Max            -0.00574538
exploration/Rewards Min           -10.1508
exploration/Returns Mean          -33.9937
exploration/Returns Std            16.0139
exploration/Returns Max           -14.7026
exploration/Returns Min           -62.4256
exploration/Actions Mean            0.00188745
exploration/Actions Std             0.221112
exploration/Actions Max             0.999077
exploration/Actions Min            -0.999381
exploration/Num Paths               5
exploration/Average Returns       -33.9937
evaluation/num steps total     427500
evaluation/num paths total       4275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.224571
evaluation/Rewards Std              0.861051
evaluation/Rewards Max             -0.00639245
evaluation/Rewards Min            -10.0826
evaluation/Returns Mean           -22.4571
evaluation/Returns Std             18.5479
evaluation/Returns Max             -2.47511
evaluation/Returns Min            -57.5921
evaluation/Actions Mean            -0.00873047
evaluation/Actions Std              0.176551
evaluation/Actions Max              0.997359
evaluation/Actions Min             -0.999071
evaluation/Num Paths               15
evaluation/Average Returns        -22.4571
time/data storing (s)               0.00272537
time/evaluation sampling (s)        0.327878
time/exploration sampling (s)       0.139448
time/logging (s)                    0.00484639
time/saving (s)                     0.00190685
time/training (s)                   1.96744
time/epoch (s)                      2.44424
time/total (s)                    695.412
Epoch                             284
-----------------------------  ---------------
2019-04-22 22:48:12.686964 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 285 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0377669
trainer/QF2 Loss                    0.0493193
trainer/Policy Loss                11.7721
trainer/Q1 Predictions Mean        -9.99453
trainer/Q1 Predictions Std          6.64743
trainer/Q1 Predictions Max         -5.82282
trainer/Q1 Predictions Min        -31.3657
trainer/Q2 Predictions Mean        -9.9876
trainer/Q2 Predictions Std          6.64376
trainer/Q2 Predictions Max         -5.9026
trainer/Q2 Predictions Min        -31.432
trainer/Q Targets Mean            -10.1181
trainer/Q Targets Std               6.57866
trainer/Q Targets Max              -5.90206
trainer/Q Targets Min             -30.6216
trainer/Log Pis Mean                1.75833
trainer/Log Pis Std                 1.14532
trainer/Log Pis Max                 6.62126
trainer/Log Pis Min                -2.30661
trainer/Policy mu Mean              0.0146513
trainer/Policy mu Std               0.297488
trainer/Policy mu Max               3.00108
trainer/Policy mu Min              -1.49515
trainer/Policy log std Mean        -2.2993
trainer/Policy log std Std          0.178269
trainer/Policy log std Max         -0.889754
trainer/Policy log std Min         -2.51651
trainer/Alpha                       0.0564458
trainer/Alpha Loss                 -0.69466
exploration/num steps total    143200
exploration/num paths total      1432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.373903
exploration/Rewards Std             1.12137
exploration/Rewards Max            -0.00944007
exploration/Rewards Min            -8.88926
exploration/Returns Mean          -37.3903
exploration/Returns Std            14.3567
exploration/Returns Max           -14.8686
exploration/Returns Min           -52.7089
exploration/Actions Mean           -0.00629549
exploration/Actions Std             0.240033
exploration/Actions Max             0.999246
exploration/Actions Min            -0.999528
exploration/Num Paths               5
exploration/Average Returns       -37.3903
evaluation/num steps total     429000
evaluation/num paths total       4290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.323737
evaluation/Rewards Std              1.279
evaluation/Rewards Max             -0.011155
evaluation/Rewards Min            -11.3085
evaluation/Returns Mean           -32.3737
evaluation/Returns Std             15.3739
evaluation/Returns Max             -7.29501
evaluation/Returns Min            -56.737
evaluation/Actions Mean             0.00711934
evaluation/Actions Std              0.22297
evaluation/Actions Max              0.999253
evaluation/Actions Min             -0.999165
evaluation/Num Paths               15
evaluation/Average Returns        -32.3737
time/data storing (s)               0.00258882
time/evaluation sampling (s)        0.323511
time/exploration sampling (s)       0.141339
time/logging (s)                    0.00488032
time/saving (s)                     0.0111112
time/training (s)                   1.95668
time/epoch (s)                      2.44011
time/total (s)                    697.856
Epoch                             285
-----------------------------  ---------------
2019-04-22 22:48:15.118206 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 286 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.101797
trainer/QF2 Loss                    0.090863
trainer/Policy Loss                11.4413
trainer/Q1 Predictions Mean        -9.39349
trainer/Q1 Predictions Std          6.1477
trainer/Q1 Predictions Max         -5.84921
trainer/Q1 Predictions Min        -38.2542
trainer/Q2 Predictions Mean        -9.38819
trainer/Q2 Predictions Std          6.14536
trainer/Q2 Predictions Max         -5.79906
trainer/Q2 Predictions Min        -37.9407
trainer/Q Targets Mean             -9.60192
trainer/Q Targets Std               6.19685
trainer/Q Targets Max              -5.887
trainer/Q Targets Min             -36.8251
trainer/Log Pis Mean                2.03857
trainer/Log Pis Std                 1.31579
trainer/Log Pis Max                 9.25856
trainer/Log Pis Min                -0.73681
trainer/Policy mu Mean              0.0175737
trainer/Policy mu Std               0.486878
trainer/Policy mu Max               3.17341
trainer/Policy mu Min              -2.75603
trainer/Policy log std Mean        -2.26834
trainer/Policy log std Std          0.331829
trainer/Policy log std Max         -0.429726
trainer/Policy log std Min         -2.62612
trainer/Alpha                       0.0583107
trainer/Alpha Loss                  0.10961
exploration/num steps total    143700
exploration/num paths total      1437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.456738
exploration/Rewards Std             1.1583
exploration/Rewards Max            -0.00258448
exploration/Rewards Min            -8.95016
exploration/Returns Mean          -45.6738
exploration/Returns Std            13.1924
exploration/Returns Max           -24.4611
exploration/Returns Min           -57.7029
exploration/Actions Mean           -0.00240939
exploration/Actions Std             0.246279
exploration/Actions Max             0.99891
exploration/Actions Min            -0.999605
exploration/Num Paths               5
exploration/Average Returns       -45.6738
evaluation/num steps total     430500
evaluation/num paths total       4305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247505
evaluation/Rewards Std              1.05568
evaluation/Rewards Max             -0.0211969
evaluation/Rewards Min            -11.5052
evaluation/Returns Mean           -24.7505
evaluation/Returns Std             17.5721
evaluation/Returns Max             -5.34317
evaluation/Returns Min            -60.1999
evaluation/Actions Mean             0.00571383
evaluation/Actions Std              0.198189
evaluation/Actions Max              0.997914
evaluation/Actions Min             -0.998576
evaluation/Num Paths               15
evaluation/Average Returns        -24.7505
time/data storing (s)               0.00281986
time/evaluation sampling (s)        0.32066
time/exploration sampling (s)       0.140953
time/logging (s)                    0.00402766
time/saving (s)                     0.0019576
time/training (s)                   1.95203
time/epoch (s)                      2.42245
time/total (s)                    700.282
Epoch                             286
-----------------------------  ---------------
2019-04-22 22:48:17.549036 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 287 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0148111
trainer/QF2 Loss                    0.0142302
trainer/Policy Loss                12.4493
trainer/Q1 Predictions Mean       -10.384
trainer/Q1 Predictions Std          7.02316
trainer/Q1 Predictions Max         -5.78557
trainer/Q1 Predictions Min        -41.2163
trainer/Q2 Predictions Mean       -10.3934
trainer/Q2 Predictions Std          7.01974
trainer/Q2 Predictions Max         -5.74074
trainer/Q2 Predictions Min        -40.9667
trainer/Q Targets Mean            -10.4479
trainer/Q Targets Std               7.02572
trainer/Q Targets Max              -5.82316
trainer/Q Targets Min             -40.9336
trainer/Log Pis Mean                2.06566
trainer/Log Pis Std                 1.11597
trainer/Log Pis Max                 7.41131
trainer/Log Pis Min                -0.760674
trainer/Policy mu Mean             -0.0169511
trainer/Policy mu Std               0.492123
trainer/Policy mu Max               2.79377
trainer/Policy mu Min              -3.38582
trainer/Policy log std Mean        -2.27231
trainer/Policy log std Std          0.34101
trainer/Policy log std Max         -0.478081
trainer/Policy log std Min         -2.58703
trainer/Alpha                       0.0585814
trainer/Alpha Loss                  0.186314
exploration/num steps total    144200
exploration/num paths total      1442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.293917
exploration/Rewards Std             0.789198
exploration/Rewards Max            -0.00517875
exploration/Rewards Min            -6.72333
exploration/Returns Mean          -29.3917
exploration/Returns Std             6.55265
exploration/Returns Max           -21.5699
exploration/Returns Min           -40.3739
exploration/Actions Mean            0.00228154
exploration/Actions Std             0.223233
exploration/Actions Max             0.999571
exploration/Actions Min            -0.999496
exploration/Num Paths               5
exploration/Average Returns       -29.3917
evaluation/num steps total     432000
evaluation/num paths total       4320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.2436
evaluation/Rewards Std              0.95085
evaluation/Rewards Max             -0.00915504
evaluation/Rewards Min            -11.4692
evaluation/Returns Mean           -24.36
evaluation/Returns Std             17.6777
evaluation/Returns Max             -4.13583
evaluation/Returns Min            -63.3597
evaluation/Actions Mean             0.0143171
evaluation/Actions Std              0.185654
evaluation/Actions Max              0.998816
evaluation/Actions Min             -0.99652
evaluation/Num Paths               15
evaluation/Average Returns        -24.36
time/data storing (s)               0.00279671
time/evaluation sampling (s)        0.319927
time/exploration sampling (s)       0.136039
time/logging (s)                    0.00483836
time/saving (s)                     0.0019358
time/training (s)                   1.9576
time/epoch (s)                      2.42313
time/total (s)                    702.71
Epoch                             287
-----------------------------  ---------------
2019-04-22 22:48:19.989542 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 288 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0213738
trainer/QF2 Loss                    0.0213308
trainer/Policy Loss                11.652
trainer/Q1 Predictions Mean        -9.5119
trainer/Q1 Predictions Std          5.8932
trainer/Q1 Predictions Max         -5.68928
trainer/Q1 Predictions Min        -22.7542
trainer/Q2 Predictions Mean        -9.51478
trainer/Q2 Predictions Std          5.89891
trainer/Q2 Predictions Max         -5.71158
trainer/Q2 Predictions Min        -22.8075
trainer/Q Targets Mean             -9.57385
trainer/Q Targets Std               5.83911
trainer/Q Targets Max              -5.86232
trainer/Q Targets Min             -22.9252
trainer/Log Pis Mean                2.13838
trainer/Log Pis Std                 1.28936
trainer/Log Pis Max                 5.56414
trainer/Log Pis Min                -2.79345
trainer/Policy mu Mean              0.0491279
trainer/Policy mu Std               0.500746
trainer/Policy mu Max               2.97388
trainer/Policy mu Min              -2.26069
trainer/Policy log std Mean        -2.28505
trainer/Policy log std Std          0.369015
trainer/Policy log std Max         -0.605421
trainer/Policy log std Min         -2.71719
trainer/Alpha                       0.0585806
trainer/Alpha Loss                  0.392656
exploration/num steps total    144700
exploration/num paths total      1447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.38134
exploration/Rewards Std             0.97629
exploration/Rewards Max            -0.000152763
exploration/Rewards Min           -10.7984
exploration/Returns Mean          -38.134
exploration/Returns Std            23.3262
exploration/Returns Max           -14.1757
exploration/Returns Min           -79.3394
exploration/Actions Mean           -0.0162302
exploration/Actions Std             0.220652
exploration/Actions Max             0.998105
exploration/Actions Min            -0.999474
exploration/Num Paths               5
exploration/Average Returns       -38.134
evaluation/num steps total     433500
evaluation/num paths total       4335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.379458
evaluation/Rewards Std              1.20138
evaluation/Rewards Max             -0.00854449
evaluation/Rewards Min            -11.488
evaluation/Returns Mean           -37.9458
evaluation/Returns Std             18.6471
evaluation/Returns Max             -8.67164
evaluation/Returns Min            -85.6092
evaluation/Actions Mean            -0.00288208
evaluation/Actions Std              0.208942
evaluation/Actions Max              0.998577
evaluation/Actions Min             -0.999325
evaluation/Num Paths               15
evaluation/Average Returns        -37.9458
time/data storing (s)               0.00256412
time/evaluation sampling (s)        0.324254
time/exploration sampling (s)       0.139053
time/logging (s)                    0.00509515
time/saving (s)                     0.00195744
time/training (s)                   1.95884
time/epoch (s)                      2.43176
time/total (s)                    705.146
Epoch                             288
-----------------------------  ----------------
2019-04-22 22:48:22.419931 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 289 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.56605
trainer/QF2 Loss                    5.5773
trainer/Policy Loss                12.0501
trainer/Q1 Predictions Mean       -10.1249
trainer/Q1 Predictions Std          7.26368
trainer/Q1 Predictions Max         -5.81631
trainer/Q1 Predictions Min        -43.4723
trainer/Q2 Predictions Mean       -10.1282
trainer/Q2 Predictions Std          7.26054
trainer/Q2 Predictions Max         -5.79664
trainer/Q2 Predictions Min        -43.4769
trainer/Q Targets Mean             -9.92154
trainer/Q Targets Std               7.39322
trainer/Q Targets Max              -0.0999983
trainer/Q Targets Min             -43.8732
trainer/Log Pis Mean                1.92338
trainer/Log Pis Std                 1.44219
trainer/Log Pis Max                 9.63049
trainer/Log Pis Min                -2.30098
trainer/Policy mu Mean              0.0432021
trainer/Policy mu Std               0.540264
trainer/Policy mu Max               3.19917
trainer/Policy mu Min              -2.9951
trainer/Policy log std Mean        -2.24402
trainer/Policy log std Std          0.316066
trainer/Policy log std Max         -0.626763
trainer/Policy log std Min         -2.60242
trainer/Alpha                       0.0568473
trainer/Alpha Loss                 -0.219696
exploration/num steps total    145200
exploration/num paths total      1452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354293
exploration/Rewards Std             0.888098
exploration/Rewards Max            -0.00473069
exploration/Rewards Min            -8.90761
exploration/Returns Mean          -35.4293
exploration/Returns Std            13.577
exploration/Returns Max           -14.2838
exploration/Returns Min           -49.7852
exploration/Actions Mean            0.00606146
exploration/Actions Std             0.228519
exploration/Actions Max             0.999192
exploration/Actions Min            -0.996447
exploration/Num Paths               5
exploration/Average Returns       -35.4293
evaluation/num steps total     435000
evaluation/num paths total       4350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.298168
evaluation/Rewards Std              1.00679
evaluation/Rewards Max             -0.0200199
evaluation/Rewards Min            -10.5104
evaluation/Returns Mean           -29.8168
evaluation/Returns Std             20.7381
evaluation/Returns Max             -5.02828
evaluation/Returns Min            -86.102
evaluation/Actions Mean             0.0151948
evaluation/Actions Std              0.179412
evaluation/Actions Max              0.998482
evaluation/Actions Min             -0.999242
evaluation/Num Paths               15
evaluation/Average Returns        -29.8168
time/data storing (s)               0.00283062
time/evaluation sampling (s)        0.318782
time/exploration sampling (s)       0.145726
time/logging (s)                    0.00485238
time/saving (s)                     0.00197131
time/training (s)                   1.94694
time/epoch (s)                      2.4211
time/total (s)                    707.572
Epoch                             289
-----------------------------  ---------------
2019-04-22 22:48:24.846123 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 290 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0791165
trainer/QF2 Loss                    0.0683546
trainer/Policy Loss                12.5879
trainer/Q1 Predictions Mean       -10.419
trainer/Q1 Predictions Std          9.05561
trainer/Q1 Predictions Max         -5.76926
trainer/Q1 Predictions Min        -72.8689
trainer/Q2 Predictions Mean       -10.4434
trainer/Q2 Predictions Std          9.06536
trainer/Q2 Predictions Max         -5.73387
trainer/Q2 Predictions Min        -72.9626
trainer/Q Targets Mean            -10.5338
trainer/Q Targets Std               9.1182
trainer/Q Targets Max              -5.82218
trainer/Q Targets Min             -74.8724
trainer/Log Pis Mean                2.16661
trainer/Log Pis Std                 1.67231
trainer/Log Pis Max                10.7211
trainer/Log Pis Min                -1.47027
trainer/Policy mu Mean             -0.0815365
trainer/Policy mu Std               0.626066
trainer/Policy mu Max               2.7903
trainer/Policy mu Min              -4.12154
trainer/Policy log std Mean        -2.26918
trainer/Policy log std Std          0.350791
trainer/Policy log std Max         -0.55028
trainer/Policy log std Min         -2.69027
trainer/Alpha                       0.0563497
trainer/Alpha Loss                  0.479213
exploration/num steps total    145700
exploration/num paths total      1457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.457983
exploration/Rewards Std             1.0464
exploration/Rewards Max            -0.00375491
exploration/Rewards Min            -8.43526
exploration/Returns Mean          -45.7983
exploration/Returns Std            14.5225
exploration/Returns Max           -26.6164
exploration/Returns Min           -69.5373
exploration/Actions Mean            0.000604385
exploration/Actions Std             0.234799
exploration/Actions Max             0.99864
exploration/Actions Min            -0.998936
exploration/Num Paths               5
exploration/Average Returns       -45.7983
evaluation/num steps total     436500
evaluation/num paths total       4365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.310054
evaluation/Rewards Std              0.90171
evaluation/Rewards Max             -0.0192246
evaluation/Rewards Min             -8.75261
evaluation/Returns Mean           -31.0054
evaluation/Returns Std             21.0782
evaluation/Returns Max             -4.93855
evaluation/Returns Min            -67.1615
evaluation/Actions Mean            -0.00177591
evaluation/Actions Std              0.17872
evaluation/Actions Max              0.99815
evaluation/Actions Min             -0.999258
evaluation/Num Paths               15
evaluation/Average Returns        -31.0054
time/data storing (s)               0.00268976
time/evaluation sampling (s)        0.328631
time/exploration sampling (s)       0.14086
time/logging (s)                    0.00491453
time/saving (s)                     0.00196832
time/training (s)                   1.93823
time/epoch (s)                      2.41729
time/total (s)                    709.994
Epoch                             290
-----------------------------  ----------------
2019-04-22 22:48:27.281519 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 291 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.359917
trainer/QF2 Loss                    0.376212
trainer/Policy Loss                12.4524
trainer/Q1 Predictions Mean       -10.2834
trainer/Q1 Predictions Std          7.59545
trainer/Q1 Predictions Max         -5.82439
trainer/Q1 Predictions Min        -40.098
trainer/Q2 Predictions Mean       -10.2787
trainer/Q2 Predictions Std          7.62747
trainer/Q2 Predictions Max         -5.83613
trainer/Q2 Predictions Min        -40.3176
trainer/Q Targets Mean            -10.2907
trainer/Q Targets Std               7.67955
trainer/Q Targets Max              -0.0893957
trainer/Q Targets Min             -39.8708
trainer/Log Pis Mean                2.17789
trainer/Log Pis Std                 1.30406
trainer/Log Pis Max                 8.44609
trainer/Log Pis Min                -1.56041
trainer/Policy mu Mean              0.00709595
trainer/Policy mu Std               0.560007
trainer/Policy mu Max               3.11656
trainer/Policy mu Min              -3.33189
trainer/Policy log std Mean        -2.28674
trainer/Policy log std Std          0.336636
trainer/Policy log std Max         -0.700495
trainer/Policy log std Min         -2.73869
trainer/Alpha                       0.0566298
trainer/Alpha Loss                  0.510795
exploration/num steps total    146200
exploration/num paths total      1462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.399197
exploration/Rewards Std             1.24928
exploration/Rewards Max            -0.0137507
exploration/Rewards Min           -10.4746
exploration/Returns Mean          -39.9197
exploration/Returns Std            21.9527
exploration/Returns Max           -18.3916
exploration/Returns Min           -69.8444
exploration/Actions Mean           -0.0036295
exploration/Actions Std             0.242834
exploration/Actions Max             0.997981
exploration/Actions Min            -0.999325
exploration/Num Paths               5
exploration/Average Returns       -39.9197
evaluation/num steps total     438000
evaluation/num paths total       4380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.316947
evaluation/Rewards Std              1.1896
evaluation/Rewards Max             -0.0154116
evaluation/Rewards Min            -10.7903
evaluation/Returns Mean           -31.6947
evaluation/Returns Std             19.4138
evaluation/Returns Max             -2.33627
evaluation/Returns Min            -60.6704
evaluation/Actions Mean            -0.0196339
evaluation/Actions Std              0.198767
evaluation/Actions Max              0.999085
evaluation/Actions Min             -0.999225
evaluation/Num Paths               15
evaluation/Average Returns        -31.6947
time/data storing (s)               0.00274257
time/evaluation sampling (s)        0.323927
time/exploration sampling (s)       0.137791
time/logging (s)                    0.00378067
time/saving (s)                     0.00157831
time/training (s)                   1.95546
time/epoch (s)                      2.42528
time/total (s)                    712.423
Epoch                             291
-----------------------------  ---------------
2019-04-22 22:48:29.727646 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 292 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0480258
trainer/QF2 Loss                    0.0621984
trainer/Policy Loss                11.6401
trainer/Q1 Predictions Mean        -9.59177
trainer/Q1 Predictions Std          5.7329
trainer/Q1 Predictions Max         -5.79544
trainer/Q1 Predictions Min        -28.8111
trainer/Q2 Predictions Mean        -9.60655
trainer/Q2 Predictions Std          5.77256
trainer/Q2 Predictions Max         -5.74087
trainer/Q2 Predictions Min        -29.7771
trainer/Q Targets Mean             -9.71182
trainer/Q Targets Std               5.85746
trainer/Q Targets Max              -5.84916
trainer/Q Targets Min             -28.4906
trainer/Log Pis Mean                2.05262
trainer/Log Pis Std                 1.34446
trainer/Log Pis Max                 8.60341
trainer/Log Pis Min                -2.20364
trainer/Policy mu Mean             -0.022318
trainer/Policy mu Std               0.466631
trainer/Policy mu Max               3.07743
trainer/Policy mu Min              -3.03367
trainer/Policy log std Mean        -2.32072
trainer/Policy log std Std          0.342917
trainer/Policy log std Max         -0.494273
trainer/Policy log std Min         -2.82462
trainer/Alpha                       0.0591086
trainer/Alpha Loss                  0.148834
exploration/num steps total    146700
exploration/num paths total      1467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43407
exploration/Rewards Std             1.25118
exploration/Rewards Max            -0.00703703
exploration/Rewards Min           -11.1011
exploration/Returns Mean          -43.407
exploration/Returns Std            19.5587
exploration/Returns Max           -16.8246
exploration/Returns Min           -65.3983
exploration/Actions Mean           -0.0145498
exploration/Actions Std             0.241922
exploration/Actions Max             0.999649
exploration/Actions Min            -0.999578
exploration/Num Paths               5
exploration/Average Returns       -43.407
evaluation/num steps total     439500
evaluation/num paths total       4395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288318
evaluation/Rewards Std              1.02012
evaluation/Rewards Max             -0.0213285
evaluation/Rewards Min             -9.88968
evaluation/Returns Mean           -28.8318
evaluation/Returns Std             14.6462
evaluation/Returns Max             -5.35126
evaluation/Returns Min            -53.3925
evaluation/Actions Mean             0.00469225
evaluation/Actions Std              0.205796
evaluation/Actions Max              0.999028
evaluation/Actions Min             -0.998648
evaluation/Num Paths               15
evaluation/Average Returns        -28.8318
time/data storing (s)               0.00281078
time/evaluation sampling (s)        0.3281
time/exploration sampling (s)       0.142604
time/logging (s)                    0.00475522
time/saving (s)                     0.00193615
time/training (s)                   1.95936
time/epoch (s)                      2.43957
time/total (s)                    714.867
Epoch                             292
-----------------------------  ---------------
2019-04-22 22:48:32.176019 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 293 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.76649
trainer/QF2 Loss                    0.777999
trainer/Policy Loss                11.0835
trainer/Q1 Predictions Mean        -9.05222
trainer/Q1 Predictions Std          5.22815
trainer/Q1 Predictions Max         -5.783
trainer/Q1 Predictions Min        -26.0774
trainer/Q2 Predictions Mean        -9.0425
trainer/Q2 Predictions Std          5.2111
trainer/Q2 Predictions Max         -5.77925
trainer/Q2 Predictions Min        -25.8297
trainer/Q Targets Mean             -9.02515
trainer/Q Targets Std               5.37468
trainer/Q Targets Max              -0.0947252
trainer/Q Targets Min             -25.826
trainer/Log Pis Mean                2.05508
trainer/Log Pis Std                 1.05341
trainer/Log Pis Max                 4.56619
trainer/Log Pis Min                -1.77212
trainer/Policy mu Mean             -0.0150403
trainer/Policy mu Std               0.463359
trainer/Policy mu Max               2.54469
trainer/Policy mu Min              -2.54979
trainer/Policy log std Mean        -2.28936
trainer/Policy log std Std          0.358074
trainer/Policy log std Max         -0.743784
trainer/Policy log std Min         -2.85183
trainer/Alpha                       0.0608252
trainer/Alpha Loss                  0.154211
exploration/num steps total    147200
exploration/num paths total      1472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.443437
exploration/Rewards Std             1.37124
exploration/Rewards Max            -0.00579248
exploration/Rewards Min           -11.3994
exploration/Returns Mean          -44.3437
exploration/Returns Std            15.4464
exploration/Returns Max           -17.9537
exploration/Returns Min           -65.877
exploration/Actions Mean           -0.0169598
exploration/Actions Std             0.255167
exploration/Actions Max             0.999096
exploration/Actions Min            -0.99956
exploration/Num Paths               5
exploration/Average Returns       -44.3437
evaluation/num steps total     441000
evaluation/num paths total       4410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.307432
evaluation/Rewards Std              1.00121
evaluation/Rewards Max             -0.00399748
evaluation/Rewards Min             -9.77336
evaluation/Returns Mean           -30.7432
evaluation/Returns Std             17.5486
evaluation/Returns Max             -5.04788
evaluation/Returns Min            -76.4634
evaluation/Actions Mean            -0.00929217
evaluation/Actions Std              0.195411
evaluation/Actions Max              0.997765
evaluation/Actions Min             -0.999408
evaluation/Num Paths               15
evaluation/Average Returns        -30.7432
time/data storing (s)               0.00307895
time/evaluation sampling (s)        0.326301
time/exploration sampling (s)       0.142299
time/logging (s)                    0.00484589
time/saving (s)                     0.00194039
time/training (s)                   1.96123
time/epoch (s)                      2.4397
time/total (s)                    717.311
Epoch                             293
-----------------------------  ---------------
2019-04-22 22:48:34.609402 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 294 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.55497
trainer/QF2 Loss                    4.56527
trainer/Policy Loss                11.7028
trainer/Q1 Predictions Mean        -9.84492
trainer/Q1 Predictions Std          6.0365
trainer/Q1 Predictions Max         -5.70303
trainer/Q1 Predictions Min        -34.6113
trainer/Q2 Predictions Mean        -9.81007
trainer/Q2 Predictions Std          6.05326
trainer/Q2 Predictions Max         -5.68034
trainer/Q2 Predictions Min        -34.9197
trainer/Q Targets Mean             -9.77251
trainer/Q Targets Std               6.19688
trainer/Q Targets Max              -0.0871079
trainer/Q Targets Min             -33.9595
trainer/Log Pis Mean                1.86345
trainer/Log Pis Std                 1.2872
trainer/Log Pis Max                 6.16422
trainer/Log Pis Min                -3.34472
trainer/Policy mu Mean             -0.0423918
trainer/Policy mu Std               0.443795
trainer/Policy mu Max               3.02623
trainer/Policy mu Min              -3.64127
trainer/Policy log std Mean        -2.30274
trainer/Policy log std Std          0.327851
trainer/Policy log std Max         -0.481166
trainer/Policy log std Min         -2.73003
trainer/Alpha                       0.0598509
trainer/Alpha Loss                 -0.384501
exploration/num steps total    147700
exploration/num paths total      1477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.432907
exploration/Rewards Std             1.12706
exploration/Rewards Max            -0.0125245
exploration/Rewards Min            -9.54954
exploration/Returns Mean          -43.2907
exploration/Returns Std            18.5257
exploration/Returns Max           -22.1816
exploration/Returns Min           -72.1733
exploration/Actions Mean           -0.00561415
exploration/Actions Std             0.256605
exploration/Actions Max             0.999473
exploration/Actions Min            -0.999462
exploration/Num Paths               5
exploration/Average Returns       -43.2907
evaluation/num steps total     442500
evaluation/num paths total       4425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.334515
evaluation/Rewards Std              1.05297
evaluation/Rewards Max             -0.00557145
evaluation/Rewards Min            -10.8999
evaluation/Returns Mean           -33.4515
evaluation/Returns Std             15.5438
evaluation/Returns Max            -13.3963
evaluation/Returns Min            -66.0841
evaluation/Actions Mean             0.0139492
evaluation/Actions Std              0.207146
evaluation/Actions Max              0.998825
evaluation/Actions Min             -0.998872
evaluation/Num Paths               15
evaluation/Average Returns        -33.4515
time/data storing (s)               0.00265406
time/evaluation sampling (s)        0.320877
time/exploration sampling (s)       0.140302
time/logging (s)                    0.00485456
time/saving (s)                     0.00194597
time/training (s)                   1.9543
time/epoch (s)                      2.42494
time/total (s)                    719.74
Epoch                             294
-----------------------------  ---------------
2019-04-22 22:48:37.048353 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 295 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.78157
trainer/QF2 Loss                    4.78649
trainer/Policy Loss                12.0579
trainer/Q1 Predictions Mean       -10.0297
trainer/Q1 Predictions Std          6.11595
trainer/Q1 Predictions Max         -5.77214
trainer/Q1 Predictions Min        -31.2824
trainer/Q2 Predictions Mean       -10.0024
trainer/Q2 Predictions Std          6.10305
trainer/Q2 Predictions Max         -5.69736
trainer/Q2 Predictions Min        -31.0112
trainer/Q Targets Mean             -9.79852
trainer/Q Targets Std               6.17222
trainer/Q Targets Max              -0.297003
trainer/Q Targets Min             -31.2922
trainer/Log Pis Mean                2.05106
trainer/Log Pis Std                 1.27947
trainer/Log Pis Max                 7.47271
trainer/Log Pis Min                -3.65776
trainer/Policy mu Mean             -0.00813576
trainer/Policy mu Std               0.58198
trainer/Policy mu Max               2.91641
trainer/Policy mu Min              -3.11763
trainer/Policy log std Mean        -2.20066
trainer/Policy log std Std          0.385024
trainer/Policy log std Max         -0.538246
trainer/Policy log std Min         -2.5919
trainer/Alpha                       0.0582231
trainer/Alpha Loss                  0.145168
exploration/num steps total    148200
exploration/num paths total      1482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.221699
exploration/Rewards Std             0.660376
exploration/Rewards Max            -0.000665373
exploration/Rewards Min            -8.66164
exploration/Returns Mean          -22.1699
exploration/Returns Std            12.9212
exploration/Returns Max           -13.1708
exploration/Returns Min           -47.7633
exploration/Actions Mean            0.00136011
exploration/Actions Std             0.197547
exploration/Actions Max             0.994731
exploration/Actions Min            -0.999401
exploration/Num Paths               5
exploration/Average Returns       -22.1699
evaluation/num steps total     444000
evaluation/num paths total       4440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283368
evaluation/Rewards Std              0.907698
evaluation/Rewards Max             -0.018376
evaluation/Rewards Min             -9.37695
evaluation/Returns Mean           -28.3368
evaluation/Returns Std             18.0441
evaluation/Returns Max             -3.61757
evaluation/Returns Min            -67.589
evaluation/Actions Mean            -0.00498624
evaluation/Actions Std              0.179853
evaluation/Actions Max              0.997717
evaluation/Actions Min             -0.999407
evaluation/Num Paths               15
evaluation/Average Returns        -28.3368
time/data storing (s)               0.002724
time/evaluation sampling (s)        0.324602
time/exploration sampling (s)       0.139983
time/logging (s)                    0.00489597
time/saving (s)                     0.00195853
time/training (s)                   1.956
time/epoch (s)                      2.43016
time/total (s)                    722.175
Epoch                             295
-----------------------------  ----------------
2019-04-22 22:48:39.443901 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 296 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0399254
trainer/QF2 Loss                    0.060831
trainer/Policy Loss                11.6671
trainer/Q1 Predictions Mean        -9.59339
trainer/Q1 Predictions Std          6.5749
trainer/Q1 Predictions Max         -5.73232
trainer/Q1 Predictions Min        -47.703
trainer/Q2 Predictions Mean        -9.58694
trainer/Q2 Predictions Std          6.52524
trainer/Q2 Predictions Max         -5.72621
trainer/Q2 Predictions Min        -47.3802
trainer/Q Targets Mean             -9.71105
trainer/Q Targets Std               6.60536
trainer/Q Targets Max              -5.70363
trainer/Q Targets Min             -47.1797
trainer/Log Pis Mean                2.0842
trainer/Log Pis Std                 1.22995
trainer/Log Pis Max                 6.54025
trainer/Log Pis Min                -4.50082
trainer/Policy mu Mean              0.0264934
trainer/Policy mu Std               0.590004
trainer/Policy mu Max               3.14009
trainer/Policy mu Min              -3.68243
trainer/Policy log std Mean        -2.24773
trainer/Policy log std Std          0.392987
trainer/Policy log std Max         -0.367309
trainer/Policy log std Min         -2.63837
trainer/Alpha                       0.0575689
trainer/Alpha Loss                  0.240394
exploration/num steps total    148700
exploration/num paths total      1487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407216
exploration/Rewards Std             1.16424
exploration/Rewards Max            -0.00953684
exploration/Rewards Min           -10.9897
exploration/Returns Mean          -40.7216
exploration/Returns Std            25.2877
exploration/Returns Max           -13.9434
exploration/Returns Min           -83.6065
exploration/Actions Mean           -0.0138254
exploration/Actions Std             0.228867
exploration/Actions Max             0.99927
exploration/Actions Min            -0.999803
exploration/Num Paths               5
exploration/Average Returns       -40.7216
evaluation/num steps total     445500
evaluation/num paths total       4455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.336324
evaluation/Rewards Std              1.05522
evaluation/Rewards Max             -0.0156802
evaluation/Rewards Min            -11.2538
evaluation/Returns Mean           -33.6324
evaluation/Returns Std             16.3042
evaluation/Returns Max             -5.71936
evaluation/Returns Min            -60.0898
evaluation/Actions Mean             0.0042901
evaluation/Actions Std              0.194729
evaluation/Actions Max              0.999456
evaluation/Actions Min             -0.999352
evaluation/Num Paths               15
evaluation/Average Returns        -33.6324
time/data storing (s)               0.00261721
time/evaluation sampling (s)        0.325318
time/exploration sampling (s)       0.138905
time/logging (s)                    0.0048473
time/saving (s)                     0.00194986
time/training (s)                   1.91313
time/epoch (s)                      2.38677
time/total (s)                    724.566
Epoch                             296
-----------------------------  ---------------
2019-04-22 22:48:41.889263 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 297 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0307233
trainer/QF2 Loss                    0.0374193
trainer/Policy Loss                12.3507
trainer/Q1 Predictions Mean       -10.386
trainer/Q1 Predictions Std          6.54975
trainer/Q1 Predictions Max         -5.72298
trainer/Q1 Predictions Min        -26.11
trainer/Q2 Predictions Mean       -10.371
trainer/Q2 Predictions Std          6.55114
trainer/Q2 Predictions Max         -5.66963
trainer/Q2 Predictions Min        -26.3383
trainer/Q Targets Mean            -10.485
trainer/Q Targets Std               6.57775
trainer/Q Targets Max              -5.7416
trainer/Q Targets Min             -26.1977
trainer/Log Pis Mean                1.98428
trainer/Log Pis Std                 1.0668
trainer/Log Pis Max                 5.53158
trainer/Log Pis Min                -2.28146
trainer/Policy mu Mean              0.00985846
trainer/Policy mu Std               0.440597
trainer/Policy mu Max               3.13687
trainer/Policy mu Min              -3.04038
trainer/Policy log std Mean        -2.27845
trainer/Policy log std Std          0.273287
trainer/Policy log std Max         -0.594631
trainer/Policy log std Min         -2.56162
trainer/Alpha                       0.0577835
trainer/Alpha Loss                 -0.0448172
exploration/num steps total    149200
exploration/num paths total      1492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.40319
exploration/Rewards Std             0.969278
exploration/Rewards Max            -0.00442803
exploration/Rewards Min            -8.29565
exploration/Returns Mean          -40.319
exploration/Returns Std            21.2773
exploration/Returns Max           -14.624
exploration/Returns Min           -77.1441
exploration/Actions Mean           -0.024869
exploration/Actions Std             0.221061
exploration/Actions Max             0.997142
exploration/Actions Min            -0.999427
exploration/Num Paths               5
exploration/Average Returns       -40.319
evaluation/num steps total     447000
evaluation/num paths total       4470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256778
evaluation/Rewards Std              0.873792
evaluation/Rewards Max             -0.0395591
evaluation/Rewards Min             -9.86974
evaluation/Returns Mean           -25.6778
evaluation/Returns Std             14.6632
evaluation/Returns Max             -6.31536
evaluation/Returns Min            -59.6446
evaluation/Actions Mean             0.00132313
evaluation/Actions Std              0.188056
evaluation/Actions Max              0.997332
evaluation/Actions Min             -0.998297
evaluation/Num Paths               15
evaluation/Average Returns        -25.6778
time/data storing (s)               0.00277297
time/evaluation sampling (s)        0.33267
time/exploration sampling (s)       0.139813
time/logging (s)                    0.00500829
time/saving (s)                     0.00198595
time/training (s)                   1.95421
time/epoch (s)                      2.43646
time/total (s)                    727.007
Epoch                             297
-----------------------------  ---------------
2019-04-22 22:48:44.357848 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 298 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.73581
trainer/QF2 Loss                    4.72359
trainer/Policy Loss                12.4732
trainer/Q1 Predictions Mean       -10.1201
trainer/Q1 Predictions Std          8.20811
trainer/Q1 Predictions Max         -5.82296
trainer/Q1 Predictions Min        -56.3096
trainer/Q2 Predictions Mean       -10.1192
trainer/Q2 Predictions Std          8.24482
trainer/Q2 Predictions Max         -5.78207
trainer/Q2 Predictions Min        -56.6683
trainer/Q Targets Mean             -9.90046
trainer/Q Targets Std               8.22968
trainer/Q Targets Max              -0.151485
trainer/Q Targets Min             -56.1691
trainer/Log Pis Mean                2.37208
trainer/Log Pis Std                 1.19381
trainer/Log Pis Max                 7.47164
trainer/Log Pis Min                -0.03012
trainer/Policy mu Mean             -0.0416906
trainer/Policy mu Std               0.60852
trainer/Policy mu Max               3.34714
trainer/Policy mu Min              -3.72452
trainer/Policy log std Mean        -2.29275
trainer/Policy log std Std          0.385221
trainer/Policy log std Max         -0.43331
trainer/Policy log std Min         -2.75183
trainer/Alpha                       0.057336
trainer/Alpha Loss                  1.06379
exploration/num steps total    149700
exploration/num paths total      1497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370935
exploration/Rewards Std             1.15303
exploration/Rewards Max            -0.00446787
exploration/Rewards Min            -9.59238
exploration/Returns Mean          -37.0935
exploration/Returns Std            20.0353
exploration/Returns Max           -15.4121
exploration/Returns Min           -62.8723
exploration/Actions Mean           -0.0126653
exploration/Actions Std             0.227476
exploration/Actions Max             0.997821
exploration/Actions Min            -0.998054
exploration/Num Paths               5
exploration/Average Returns       -37.0935
evaluation/num steps total     448500
evaluation/num paths total       4485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.436162
evaluation/Rewards Std              1.33837
evaluation/Rewards Max             -0.00544109
evaluation/Rewards Min            -10.6068
evaluation/Returns Mean           -43.6162
evaluation/Returns Std             19.9377
evaluation/Returns Max             -6.47463
evaluation/Returns Min            -85.1444
evaluation/Actions Mean            -0.0263158
evaluation/Actions Std              0.226792
evaluation/Actions Max              0.997143
evaluation/Actions Min             -0.999453
evaluation/Num Paths               15
evaluation/Average Returns        -43.6162
time/data storing (s)               0.00286285
time/evaluation sampling (s)        0.329446
time/exploration sampling (s)       0.14018
time/logging (s)                    0.00484715
time/saving (s)                     0.0112544
time/training (s)                   1.97027
time/epoch (s)                      2.45886
time/total (s)                    729.471
Epoch                             298
-----------------------------  ---------------
2019-04-22 22:48:46.798755 PDT | [sac-pointmass-multitask-6_2019_04_22_22_36_34_0000--s-0] Epoch 299 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.465306
trainer/QF2 Loss                    0.465138
trainer/Policy Loss                12.3423
trainer/Q1 Predictions Mean       -10.1991
trainer/Q1 Predictions Std          7.94717
trainer/Q1 Predictions Max         -5.84028
trainer/Q1 Predictions Min        -49.1654
trainer/Q2 Predictions Mean       -10.203
trainer/Q2 Predictions Std          7.96778
trainer/Q2 Predictions Max         -5.81891
trainer/Q2 Predictions Min        -48.524
trainer/Q Targets Mean            -10.1795
trainer/Q Targets Std               7.98886
trainer/Q Targets Max              -0.151048
trainer/Q Targets Min             -48.6487
trainer/Log Pis Mean                2.15884
trainer/Log Pis Std                 1.4172
trainer/Log Pis Max                 8.49905
trainer/Log Pis Min                -2.60072
trainer/Policy mu Mean             -0.00180102
trainer/Policy mu Std               0.658012
trainer/Policy mu Max               3.27272
trainer/Policy mu Min              -3.47699
trainer/Policy log std Mean        -2.21447
trainer/Policy log std Std          0.416032
trainer/Policy log std Max         -0.53161
trainer/Policy log std Min         -2.62697
trainer/Alpha                       0.058468
trainer/Alpha Loss                  0.450995
exploration/num steps total    150200
exploration/num paths total      1502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.47873
exploration/Rewards Std             0.928872
exploration/Rewards Max            -0.0101446
exploration/Rewards Min            -7.74215
exploration/Returns Mean          -47.873
exploration/Returns Std            14.3376
exploration/Returns Max           -33.134
exploration/Returns Min           -68.4521
exploration/Actions Mean           -0.0100619
exploration/Actions Std             0.222451
exploration/Actions Max             0.999627
exploration/Actions Min            -0.999972
exploration/Num Paths               5
exploration/Average Returns       -47.873
evaluation/num steps total     450000
evaluation/num paths total       4500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226596
evaluation/Rewards Std              0.757829
evaluation/Rewards Max             -0.00569569
evaluation/Rewards Min             -7.62794
evaluation/Returns Mean           -22.6596
evaluation/Returns Std             15.9334
evaluation/Returns Max             -2.54626
evaluation/Returns Min            -51.213
evaluation/Actions Mean             0.00402484
evaluation/Actions Std              0.174405
evaluation/Actions Max              0.998258
evaluation/Actions Min             -0.995386
evaluation/Num Paths               15
evaluation/Average Returns        -22.6596
time/data storing (s)               0.00281731
time/evaluation sampling (s)        0.319803
time/exploration sampling (s)       0.141001
time/logging (s)                    0.00486558
time/saving (s)                     0.00171304
time/training (s)                   1.96164
time/epoch (s)                      2.43184
time/total (s)                    731.907
Epoch                             299
-----------------------------  ---------------
