2019-04-22 21:56:00.456418 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  51.3407
trainer/QF2 Loss                  51.322
trainer/Policy Loss               -1.33425
trainer/Q1 Predictions Mean       -0.0017144
trainer/Q1 Predictions Std         0.000795498
trainer/Q1 Predictions Max         0.000245063
trainer/Q1 Predictions Min        -0.0031074
trainer/Q2 Predictions Mean       -0.0034291
trainer/Q2 Predictions Std         0.00108268
trainer/Q2 Predictions Max        -0.00162792
trainer/Q2 Predictions Min        -0.0056797
trainer/Q Targets Mean            -6.25751
trainer/Q Targets Std              3.49379
trainer/Q Targets Max             -0.516345
trainer/Q Targets Min            -11.9897
trainer/Log Pis Mean              -1.33779
trainer/Log Pis Std                0.265321
trainer/Log Pis Max               -0.674471
trainer/Log Pis Min               -1.82971
trainer/Policy mu Mean            -7.28954e-05
trainer/Policy mu Std              0.000969457
trainer/Policy mu Max              0.00182739
trainer/Policy mu Min             -0.00146565
trainer/Policy log std Mean       -0.00011338
trainer/Policy log std Std         0.000489713
trainer/Policy log std Max         0.00101766
trainer/Policy log std Min        -0.000956817
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -6.48837
exploration/Rewards Std            3.61646
exploration/Rewards Max           -0.364242
exploration/Rewards Min          -12.4214
exploration/Returns Mean        -648.837
exploration/Returns Std          295.211
exploration/Returns Max         -264.656
exploration/Returns Min        -1104.54
exploration/Actions Mean           0.0184486
exploration/Actions Std            0.633915
exploration/Actions Max            0.998288
exploration/Actions Min           -0.995857
exploration/Num Paths              5
exploration/Average Returns     -648.837
evaluation/num steps total      1500
evaluation/num paths total        15
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -6.32262
evaluation/Rewards Std             3.11519
evaluation/Rewards Max            -0.109718
evaluation/Rewards Min           -10.6453
evaluation/Returns Mean         -632.262
evaluation/Returns Std           311.509
evaluation/Returns Max           -14.1704
evaluation/Returns Min         -1059.66
evaluation/Actions Mean            7.62302e-05
evaluation/Actions Std             0.000925066
evaluation/Actions Max             0.0016483
evaluation/Actions Min            -0.00122391
evaluation/Num Paths              15
evaluation/Average Returns      -632.262
time/data storing (s)              0.00312879
time/evaluation sampling (s)       0.324403
time/exploration sampling (s)      0.162348
time/logging (s)                   0.00490348
time/saving (s)                    0.00251
time/training (s)                  2.16976
time/epoch (s)                     2.66705
time/total (s)                     2.90746
Epoch                              0
-----------------------------  ---------------
2019-04-22 21:56:03.110825 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 1 finished
-----------------------------  --------------
replay_buffer/size              1200
trainer/QF1 Loss                   7.55337
trainer/QF2 Loss                   7.43917
trainer/Policy Loss               10.5613
trainer/Q1 Predictions Mean      -11.9087
trainer/Q1 Predictions Std         4.53273
trainer/Q1 Predictions Max        -4.67088
trainer/Q1 Predictions Min       -22.264
trainer/Q2 Predictions Mean      -11.9688
trainer/Q2 Predictions Std         4.5036
trainer/Q2 Predictions Max        -4.41475
trainer/Q2 Predictions Min       -22.5144
trainer/Q Targets Mean           -12.1798
trainer/Q Targets Std              4.94303
trainer/Q Targets Max             -4.07614
trainer/Q Targets Min            -22.1029
trainer/Log Pis Mean              -1.18232
trainer/Log Pis Std                0.607921
trainer/Log Pis Max                0.485423
trainer/Log Pis Min               -2.83765
trainer/Policy mu Mean            -0.261296
trainer/Policy mu Std              0.248666
trainer/Policy mu Max              0.134658
trainer/Policy mu Min             -0.737144
trainer/Policy log std Mean       -0.161262
trainer/Policy log std Std         0.0342603
trainer/Policy log std Max        -0.109976
trainer/Policy log std Min        -0.252632
trainer/Alpha                      0.862611
trainer/Alpha Loss                -0.469409
exploration/num steps total     1200
exploration/num paths total       12
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -6.73721
exploration/Rewards Std            3.23919
exploration/Rewards Max           -0.256073
exploration/Rewards Min          -12.8472
exploration/Returns Mean        -673.721
exploration/Returns Std          241.863
exploration/Returns Max         -439.939
exploration/Returns Min         -973.379
exploration/Actions Mean          -0.106869
exploration/Actions Std            0.597659
exploration/Actions Max            0.988414
exploration/Actions Min           -0.995316
exploration/Num Paths              5
exploration/Average Returns     -673.721
evaluation/num steps total      3000
evaluation/num paths total        30
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -7.09581
evaluation/Rewards Std             3.25963
evaluation/Rewards Max            -0.564737
evaluation/Rewards Min           -11.7742
evaluation/Returns Mean         -709.581
evaluation/Returns Std           298.195
evaluation/Returns Max          -293.476
evaluation/Returns Min         -1122.68
evaluation/Actions Mean           -0.183532
evaluation/Actions Std             0.114038
evaluation/Actions Max             0.0931905
evaluation/Actions Min            -0.634715
evaluation/Num Paths              15
evaluation/Average Returns      -709.581
time/data storing (s)              0.00323305
time/evaluation sampling (s)       0.374605
time/exploration sampling (s)      0.164784
time/logging (s)                   0.00508235
time/saving (s)                    0.00195632
time/training (s)                  2.09897
time/epoch (s)                     2.64864
time/total (s)                     5.56124
Epoch                              1
-----------------------------  --------------
2019-04-22 21:56:05.827272 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size             1700
trainer/QF1 Loss                  9.0465
trainer/QF2 Loss                  8.69557
trainer/Policy Loss              20.8154
trainer/Q1 Predictions Mean     -22.7214
trainer/Q1 Predictions Std        8.89504
trainer/Q1 Predictions Max       -8.59913
trainer/Q1 Predictions Min      -42.7197
trainer/Q2 Predictions Mean     -22.7176
trainer/Q2 Predictions Std        8.94484
trainer/Q2 Predictions Max       -8.58105
trainer/Q2 Predictions Min      -42.6581
trainer/Q Targets Mean          -22.4358
trainer/Q Targets Std             9.38155
trainer/Q Targets Max            -8.62376
trainer/Q Targets Min           -42.7031
trainer/Log Pis Mean             -0.837212
trainer/Log Pis Std               1.04829
trainer/Log Pis Max               1.77518
trainer/Log Pis Min              -5.48154
trainer/Policy mu Mean           -0.130055
trainer/Policy mu Std             0.615293
trainer/Policy mu Max             0.931837
trainer/Policy mu Min            -1.21376
trainer/Policy log std Mean      -0.312564
trainer/Policy log std Std        0.0691026
trainer/Policy log std Max       -0.195618
trainer/Policy log std Min       -0.477323
trainer/Alpha                     0.750658
trainer/Alpha Loss               -0.81299
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -5.09816
exploration/Rewards Std           1.63498
exploration/Rewards Max          -0.30383
exploration/Rewards Min          -9.95636
exploration/Returns Mean       -509.816
exploration/Returns Std         128.621
exploration/Returns Max        -255.181
exploration/Returns Min        -596.98
exploration/Actions Mean         -0.00647792
exploration/Actions Std           0.562653
exploration/Actions Max           0.99465
exploration/Actions Min          -0.98067
exploration/Num Paths             5
exploration/Average Returns    -509.816
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.27882
evaluation/Rewards Std            1.54891
evaluation/Rewards Max           -0.783803
evaluation/Rewards Min          -10.794
evaluation/Returns Mean        -427.882
evaluation/Returns Std          145.83
evaluation/Returns Max         -220.819
evaluation/Returns Min         -601.018
evaluation/Actions Mean          -0.0186533
evaluation/Actions Std            0.122811
evaluation/Actions Max            0.659739
evaluation/Actions Min           -0.842053
evaluation/Num Paths             15
evaluation/Average Returns     -427.882
time/data storing (s)             0.00321056
time/evaluation sampling (s)      0.36153
time/exploration sampling (s)     0.164491
time/logging (s)                  0.00490442
time/saving (s)                   0.00228885
time/training (s)                 2.17531
time/epoch (s)                    2.71174
time/total (s)                    8.27682
Epoch                             2
-----------------------------  -------------
2019-04-22 21:56:08.477343 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             2200
trainer/QF1 Loss                 18.321
trainer/QF2 Loss                 18.4807
trainer/Policy Loss              28.1277
trainer/Q1 Predictions Mean     -30.1418
trainer/Q1 Predictions Std       11.7786
trainer/Q1 Predictions Max       -9.85831
trainer/Q1 Predictions Min      -54.0138
trainer/Q2 Predictions Mean     -30.092
trainer/Q2 Predictions Std       11.8171
trainer/Q2 Predictions Max      -10.1665
trainer/Q2 Predictions Min      -54.1039
trainer/Q Targets Mean          -29.8318
trainer/Q Targets Std            11.9949
trainer/Q Targets Max           -10.0415
trainer/Q Targets Min           -54.0935
trainer/Log Pis Mean             -0.362536
trainer/Log Pis Std               1.22956
trainer/Log Pis Max               3.09221
trainer/Log Pis Min              -3.37337
trainer/Policy mu Mean           -0.0221635
trainer/Policy mu Std             0.816152
trainer/Policy mu Max             1.46866
trainer/Policy mu Min            -1.57856
trainer/Policy log std Mean      -0.445473
trainer/Policy log std Std        0.0776631
trainer/Policy log std Max       -0.279648
trainer/Policy log std Min       -0.662125
trainer/Alpha                     0.66167
trainer/Alpha Loss               -0.975144
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.3677
exploration/Rewards Std           1.35801
exploration/Rewards Max          -0.154855
exploration/Rewards Min          -9.29111
exploration/Returns Mean       -336.77
exploration/Returns Std         110.241
exploration/Returns Max        -145.208
exploration/Returns Min        -430.703
exploration/Actions Mean         -0.00161107
exploration/Actions Std           0.526088
exploration/Actions Max           0.979152
exploration/Actions Min          -0.981185
exploration/Num Paths             5
exploration/Average Returns    -336.77
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.08929
evaluation/Rewards Std            1.07002
evaluation/Rewards Max           -1.28944
evaluation/Rewards Min           -9.65163
evaluation/Returns Mean        -308.929
evaluation/Returns Std           88.5103
evaluation/Returns Max         -131.864
evaluation/Returns Min         -438.99
evaluation/Actions Mean          -0.0100232
evaluation/Actions Std            0.139102
evaluation/Actions Max            0.875024
evaluation/Actions Min           -0.920125
evaluation/Num Paths             15
evaluation/Average Returns     -308.929
time/data storing (s)             0.00367796
time/evaluation sampling (s)      0.358531
time/exploration sampling (s)     0.161468
time/logging (s)                  0.00481285
time/saving (s)                   0.00160727
time/training (s)                 2.11471
time/epoch (s)                    2.64481
time/total (s)                   10.9258
Epoch                             3
-----------------------------  -------------
2019-04-22 21:56:11.182374 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                 55.9036
trainer/QF2 Loss                 55.7699
trainer/Policy Loss              29.7766
trainer/Q1 Predictions Mean     -31.6443
trainer/Q1 Predictions Std       14.2687
trainer/Q1 Predictions Max      -10.3356
trainer/Q1 Predictions Min      -70.1502
trainer/Q2 Predictions Mean     -31.6077
trainer/Q2 Predictions Std       14.2638
trainer/Q2 Predictions Max      -10.3592
trainer/Q2 Predictions Min      -69.7927
trainer/Q Targets Mean          -30.3801
trainer/Q Targets Std            15.0892
trainer/Q Targets Max            -0.687669
trainer/Q Targets Min           -70.0898
trainer/Log Pis Mean             -0.195998
trainer/Log Pis Std               1.13371
trainer/Log Pis Max               2.53579
trainer/Log Pis Min              -2.69266
trainer/Policy mu Mean            0.134596
trainer/Policy mu Std             0.796552
trainer/Policy mu Max             1.68879
trainer/Policy mu Min            -1.56868
trainer/Policy log std Mean      -0.526717
trainer/Policy log std Std        0.0926591
trainer/Policy log std Max       -0.281915
trainer/Policy log std Min       -0.739193
trainer/Alpha                     0.585011
trainer/Alpha Loss               -1.1768
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.19148
exploration/Rewards Std           0.997243
exploration/Rewards Max          -0.0168272
exploration/Rewards Min          -7.54674
exploration/Returns Mean       -219.148
exploration/Returns Std          70.5691
exploration/Returns Max         -81.678
exploration/Returns Min        -283.264
exploration/Actions Mean         -0.0206396
exploration/Actions Std           0.505513
exploration/Actions Max           0.952583
exploration/Actions Min          -0.977735
exploration/Num Paths             5
exploration/Average Returns    -219.148
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -2.36867
evaluation/Rewards Std            1.13664
evaluation/Rewards Max           -0.498748
evaluation/Rewards Min          -10.4044
evaluation/Returns Mean        -236.867
evaluation/Returns Std           96.1512
evaluation/Returns Max          -56.7033
evaluation/Returns Min         -362.263
evaluation/Actions Mean          -0.0135309
evaluation/Actions Std            0.140631
evaluation/Actions Max            0.861145
evaluation/Actions Min           -0.917218
evaluation/Num Paths             15
evaluation/Average Returns     -236.867
time/data storing (s)             0.00333466
time/evaluation sampling (s)      0.353961
time/exploration sampling (s)     0.156071
time/logging (s)                  0.00432174
time/saving (s)                   0.0022929
time/training (s)                 2.17994
time/epoch (s)                    2.69992
time/total (s)                   13.6295
Epoch                             4
-----------------------------  -------------
2019-04-22 21:56:13.866911 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 5 finished
-----------------------------  --------------
replay_buffer/size             3200
trainer/QF1 Loss                  1.35139
trainer/QF2 Loss                  1.42259
trainer/Policy Loss              34.1406
trainer/Q1 Predictions Mean     -35.9523
trainer/Q1 Predictions Std       19.3596
trainer/Q1 Predictions Max      -11.0772
trainer/Q1 Predictions Min      -83.7046
trainer/Q2 Predictions Mean     -35.897
trainer/Q2 Predictions Std       19.3596
trainer/Q2 Predictions Max      -11.2916
trainer/Q2 Predictions Min      -84.2556
trainer/Q Targets Mean          -36.1855
trainer/Q Targets Std            19.5206
trainer/Q Targets Max           -11.3373
trainer/Q Targets Min           -83.6535
trainer/Log Pis Mean             -0.172963
trainer/Log Pis Std               1.4521
trainer/Log Pis Max               3.89442
trainer/Log Pis Min              -3.62042
trainer/Policy mu Mean            0.0810915
trainer/Policy mu Std             0.836074
trainer/Policy mu Max             1.74157
trainer/Policy mu Min            -1.70337
trainer/Policy log std Mean      -0.583138
trainer/Policy log std Std        0.101222
trainer/Policy log std Max       -0.375408
trainer/Policy log std Min       -0.771324
trainer/Alpha                     0.516504
trainer/Alpha Loss               -1.43508
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.73384
exploration/Rewards Std           1.30017
exploration/Rewards Max          -0.0652409
exploration/Rewards Min         -10.3714
exploration/Returns Mean       -173.384
exploration/Returns Std          92.747
exploration/Returns Max         -80.2275
exploration/Returns Min        -334.363
exploration/Actions Mean         -0.0243794
exploration/Actions Std           0.501699
exploration/Actions Max           0.976555
exploration/Actions Min          -0.990052
exploration/Num Paths             5
exploration/Average Returns    -173.384
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -2.54358
evaluation/Rewards Std            1.20543
evaluation/Rewards Max           -0.47364
evaluation/Rewards Min          -10.397
evaluation/Returns Mean        -254.358
evaluation/Returns Std          101.38
evaluation/Returns Max          -54.272
evaluation/Returns Min         -359.265
evaluation/Actions Mean           9.81127e-05
evaluation/Actions Std            0.158914
evaluation/Actions Max            0.926271
evaluation/Actions Min           -0.926401
evaluation/Num Paths             15
evaluation/Average Returns     -254.358
time/data storing (s)             0.00418757
time/evaluation sampling (s)      0.35563
time/exploration sampling (s)     0.173444
time/logging (s)                  0.00512514
time/saving (s)                   0.00191251
time/training (s)                 2.13992
time/epoch (s)                    2.68022
time/total (s)                   16.3143
Epoch                             5
-----------------------------  --------------
2019-04-22 21:56:16.523560 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                   7.99064
trainer/QF2 Loss                   7.62233
trainer/Policy Loss               38.1833
trainer/Q1 Predictions Mean      -39.9246
trainer/Q1 Predictions Std        21.1468
trainer/Q1 Predictions Max       -11.7561
trainer/Q1 Predictions Min       -94.5293
trainer/Q2 Predictions Mean      -39.8939
trainer/Q2 Predictions Std        21.1905
trainer/Q2 Predictions Max       -11.6495
trainer/Q2 Predictions Min       -95.1404
trainer/Q Targets Mean           -39.8361
trainer/Q Targets Std             21.8317
trainer/Q Targets Max             -1.12602
trainer/Q Targets Min            -92.0806
trainer/Log Pis Mean               0.022333
trainer/Log Pis Std                1.36337
trainer/Log Pis Max                3.79555
trainer/Log Pis Min               -4.06273
trainer/Policy mu Mean             0.0757272
trainer/Policy mu Std              0.824634
trainer/Policy mu Max              1.99603
trainer/Policy mu Min             -1.85913
trainer/Policy log std Mean       -0.621839
trainer/Policy log std Std         0.0986865
trainer/Policy log std Max        -0.39613
trainer/Policy log std Min        -0.816704
trainer/Alpha                      0.454661
trainer/Alpha Loss                -1.55831
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.35402
exploration/Rewards Std            1.48495
exploration/Rewards Max           -0.1733
exploration/Rewards Min          -11.0793
exploration/Returns Mean        -235.402
exploration/Returns Std           72.6895
exploration/Returns Max         -143.639
exploration/Returns Min         -306.482
exploration/Actions Mean          -0.00960798
exploration/Actions Std            0.510628
exploration/Actions Max            0.983356
exploration/Actions Min           -0.986383
exploration/Num Paths              5
exploration/Average Returns     -235.402
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.5041
evaluation/Rewards Std             1.26943
evaluation/Rewards Max            -0.331968
evaluation/Rewards Min            -9.12768
evaluation/Returns Mean         -150.41
evaluation/Returns Std           100.171
evaluation/Returns Max           -50.4379
evaluation/Returns Min          -317.245
evaluation/Actions Mean           -0.0109635
evaluation/Actions Std             0.165448
evaluation/Actions Max             0.940911
evaluation/Actions Min            -0.955941
evaluation/Num Paths              15
evaluation/Average Returns      -150.41
time/data storing (s)              0.00311757
time/evaluation sampling (s)       0.350768
time/exploration sampling (s)      0.159704
time/logging (s)                   0.00580097
time/saving (s)                    0.00244086
time/training (s)                  2.13003
time/epoch (s)                     2.65186
time/total (s)                    18.9708
Epoch                              6
-----------------------------  --------------
2019-04-22 21:56:19.238898 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   1.19047
trainer/QF2 Loss                   1.06106
trainer/Policy Loss               37.9658
trainer/Q1 Predictions Mean      -39.6833
trainer/Q1 Predictions Std        18.0582
trainer/Q1 Predictions Max       -11.7842
trainer/Q1 Predictions Min       -89.3642
trainer/Q2 Predictions Mean      -39.6993
trainer/Q2 Predictions Std        18.1429
trainer/Q2 Predictions Max       -11.8002
trainer/Q2 Predictions Min       -90.1754
trainer/Q Targets Mean           -39.8459
trainer/Q Targets Std             18.2009
trainer/Q Targets Max            -12.3043
trainer/Q Targets Min            -91.3973
trainer/Log Pis Mean               0.26786
trainer/Log Pis Std                1.40575
trainer/Log Pis Max                4.25728
trainer/Log Pis Min               -3.0812
trainer/Policy mu Mean            -0.0959271
trainer/Policy mu Std              0.847075
trainer/Policy mu Max              1.97755
trainer/Policy mu Min             -2.01216
trainer/Policy log std Mean       -0.704803
trainer/Policy log std Std         0.111793
trainer/Policy log std Max        -0.479696
trainer/Policy log std Min        -0.909695
trainer/Alpha                      0.399599
trainer/Alpha Loss                -1.58844
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.4609
exploration/Rewards Std            1.0041
exploration/Rewards Max           -0.168125
exploration/Rewards Min           -8.72285
exploration/Returns Mean        -246.09
exploration/Returns Std           58.8426
exploration/Returns Max         -131.424
exploration/Returns Min         -294.067
exploration/Actions Mean          -0.00654803
exploration/Actions Std            0.502972
exploration/Actions Max            0.981571
exploration/Actions Min           -0.985624
exploration/Num Paths              5
exploration/Average Returns     -246.09
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.71358
evaluation/Rewards Std             1.26071
evaluation/Rewards Max            -0.205931
evaluation/Rewards Min           -10.0148
evaluation/Returns Mean         -171.358
evaluation/Returns Std           106.694
evaluation/Returns Max           -35.0443
evaluation/Returns Min          -302.999
evaluation/Actions Mean           -0.00440151
evaluation/Actions Std             0.161311
evaluation/Actions Max             0.955834
evaluation/Actions Min            -0.973022
evaluation/Num Paths              15
evaluation/Average Returns      -171.358
time/data storing (s)              0.00340676
time/evaluation sampling (s)       0.383171
time/exploration sampling (s)      0.164667
time/logging (s)                   0.00477076
time/saving (s)                    0.00162402
time/training (s)                  2.15101
time/epoch (s)                     2.70865
time/total (s)                    21.6844
Epoch                              7
-----------------------------  --------------
2019-04-22 21:56:21.946282 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                   3.11607
trainer/QF2 Loss                   2.78086
trainer/Policy Loss               42.4342
trainer/Q1 Predictions Mean      -44.1079
trainer/Q1 Predictions Std        21.1824
trainer/Q1 Predictions Max       -11.8689
trainer/Q1 Predictions Min      -101.343
trainer/Q2 Predictions Mean      -44.1253
trainer/Q2 Predictions Std        21.2141
trainer/Q2 Predictions Max       -11.9334
trainer/Q2 Predictions Min      -102.325
trainer/Q Targets Mean           -44.1498
trainer/Q Targets Std             21.3763
trainer/Q Targets Max             -0.690601
trainer/Q Targets Min           -101.6
trainer/Log Pis Mean               0.304637
trainer/Log Pis Std                1.66252
trainer/Log Pis Max                4.70658
trainer/Log Pis Min               -4.97182
trainer/Policy mu Mean             0.0245063
trainer/Policy mu Std              0.930205
trainer/Policy mu Max              2.31732
trainer/Policy mu Min             -1.83977
trainer/Policy log std Mean       -0.724358
trainer/Policy log std Std         0.120687
trainer/Policy log std Max        -0.5059
trainer/Policy log std Min        -0.940512
trainer/Alpha                      0.349892
trainer/Alpha Loss                -1.77991
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.57486
exploration/Rewards Std            0.901124
exploration/Rewards Max           -0.0134263
exploration/Rewards Min           -6.23122
exploration/Returns Mean        -157.486
exploration/Returns Std           60.9434
exploration/Returns Max          -78.8607
exploration/Returns Min         -226.991
exploration/Actions Mean          -0.00983427
exploration/Actions Std            0.471785
exploration/Actions Max            0.986063
exploration/Actions Min           -0.978232
exploration/Num Paths              5
exploration/Average Returns     -157.486
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.45088
evaluation/Rewards Std             1.11417
evaluation/Rewards Max            -0.326975
evaluation/Rewards Min            -9.8238
evaluation/Returns Mean         -145.088
evaluation/Returns Std            80.1146
evaluation/Returns Max           -42.0242
evaluation/Returns Min          -244.306
evaluation/Actions Mean           -0.00701873
evaluation/Actions Std             0.163538
evaluation/Actions Max             0.97851
evaluation/Actions Min            -0.983352
evaluation/Num Paths              15
evaluation/Average Returns      -145.088
time/data storing (s)              0.0035607
time/evaluation sampling (s)       0.357679
time/exploration sampling (s)      0.166341
time/logging (s)                   0.00427815
time/saving (s)                    0.00202316
time/training (s)                  2.16775
time/epoch (s)                     2.70163
time/total (s)                    24.3903
Epoch                              8
-----------------------------  --------------
2019-04-22 21:56:24.639944 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 9 finished
-----------------------------  ---------------
replay_buffer/size              5200
trainer/QF1 Loss                  12.0076
trainer/QF2 Loss                  12.1759
trainer/Policy Loss               45.7069
trainer/Q1 Predictions Mean      -47.2384
trainer/Q1 Predictions Std        23.4671
trainer/Q1 Predictions Max       -12.0634
trainer/Q1 Predictions Min      -106.647
trainer/Q2 Predictions Mean      -47.2231
trainer/Q2 Predictions Std        23.4936
trainer/Q2 Predictions Max       -11.954
trainer/Q2 Predictions Min      -106.962
trainer/Q Targets Mean           -47.1927
trainer/Q Targets Std             24.2864
trainer/Q Targets Max             -0.841561
trainer/Q Targets Min           -109.177
trainer/Log Pis Mean               0.264469
trainer/Log Pis Std                1.65389
trainer/Log Pis Max                5.48358
trainer/Log Pis Min               -6.3975
trainer/Policy mu Mean             0.0601554
trainer/Policy mu Std              0.897193
trainer/Policy mu Max              2.27226
trainer/Policy mu Min             -2.08081
trainer/Policy log std Mean       -0.736126
trainer/Policy log std Std         0.148583
trainer/Policy log std Max        -0.484687
trainer/Policy log std Min        -1.01124
trainer/Alpha                      0.304958
trainer/Alpha Loss                -2.06061
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.36943
exploration/Rewards Std            0.809125
exploration/Rewards Max           -0.029723
exploration/Rewards Min           -3.75367
exploration/Returns Mean        -136.943
exploration/Returns Std           64.492
exploration/Returns Max          -63.5863
exploration/Returns Min         -234.35
exploration/Actions Mean          -0.0100872
exploration/Actions Std            0.456625
exploration/Actions Max            0.955237
exploration/Actions Min           -0.98474
exploration/Num Paths              5
exploration/Average Returns     -136.943
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.6741
evaluation/Rewards Std             1.32265
evaluation/Rewards Max            -0.275628
evaluation/Rewards Min           -10.9287
evaluation/Returns Mean         -167.41
evaluation/Returns Std            89.6365
evaluation/Returns Max           -38.6846
evaluation/Returns Min          -274.164
evaluation/Actions Mean            0.000199224
evaluation/Actions Std             0.186418
evaluation/Actions Max             0.98209
evaluation/Actions Min            -0.985884
evaluation/Num Paths              15
evaluation/Average Returns      -167.41
time/data storing (s)              0.00333637
time/evaluation sampling (s)       0.3609
time/exploration sampling (s)      0.166186
time/logging (s)                   0.00427677
time/saving (s)                    0.00210686
time/training (s)                  2.15139
time/epoch (s)                     2.68819
time/total (s)                    27.0831
Epoch                              9
-----------------------------  ---------------
2019-04-22 21:56:27.297504 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                  88.825
trainer/QF2 Loss                  88.6055
trainer/Policy Loss               43.6248
trainer/Q1 Predictions Mean      -44.9509
trainer/Q1 Predictions Std        23.0193
trainer/Q1 Predictions Max       -12.4602
trainer/Q1 Predictions Min       -97.3911
trainer/Q2 Predictions Mean      -44.9242
trainer/Q2 Predictions Std        22.9675
trainer/Q2 Predictions Max       -12.4653
trainer/Q2 Predictions Min       -95.8807
trainer/Q Targets Mean           -43.9253
trainer/Q Targets Std             23.6757
trainer/Q Targets Max             -0.690601
trainer/Q Targets Min            -99.7509
trainer/Log Pis Mean               0.0304863
trainer/Log Pis Std                1.26831
trainer/Log Pis Max                4.81593
trainer/Log Pis Min               -1.86172
trainer/Policy mu Mean             0.131166
trainer/Policy mu Std              0.887046
trainer/Policy mu Max              2.23727
trainer/Policy mu Min             -2.03014
trainer/Policy log std Mean       -0.78418
trainer/Policy log std Std         0.175194
trainer/Policy log std Max        -0.476685
trainer/Policy log std Min        -1.14224
trainer/Alpha                      0.266652
trainer/Alpha Loss                -2.60279
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.13139
exploration/Rewards Std            1.1472
exploration/Rewards Max           -0.0404784
exploration/Rewards Min          -10.0628
exploration/Returns Mean        -113.139
exploration/Returns Std           60.5799
exploration/Returns Max          -72.3909
exploration/Returns Min         -231.616
exploration/Actions Mean          -0.0143008
exploration/Actions Std            0.416265
exploration/Actions Max            0.994407
exploration/Actions Min           -0.994244
exploration/Num Paths              5
exploration/Average Returns     -113.139
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.35057
evaluation/Rewards Std             1.22703
evaluation/Rewards Max            -0.40234
evaluation/Rewards Min           -10.4219
evaluation/Returns Mean         -135.057
evaluation/Returns Std            78.3961
evaluation/Returns Max           -48.3997
evaluation/Returns Min          -235.013
evaluation/Actions Mean           -0.00439527
evaluation/Actions Std             0.179246
evaluation/Actions Max             0.978251
evaluation/Actions Min            -0.986701
evaluation/Num Paths              15
evaluation/Average Returns      -135.057
time/data storing (s)              0.00322522
time/evaluation sampling (s)       0.358549
time/exploration sampling (s)      0.164398
time/logging (s)                   0.00523908
time/saving (s)                    0.00217675
time/training (s)                  2.11905
time/epoch (s)                     2.65263
time/total (s)                    29.7407
Epoch                             10
-----------------------------  --------------
2019-04-22 21:56:30.028722 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                  50.3582
trainer/QF2 Loss                  50.8206
trainer/Policy Loss               49.5416
trainer/Q1 Predictions Mean      -50.7467
trainer/Q1 Predictions Std        25.9546
trainer/Q1 Predictions Max       -13.4178
trainer/Q1 Predictions Min      -115.79
trainer/Q2 Predictions Mean      -50.7468
trainer/Q2 Predictions Std        25.9086
trainer/Q2 Predictions Max       -13.3779
trainer/Q2 Predictions Min      -116.255
trainer/Q Targets Mean           -50.357
trainer/Q Targets Std             26.9809
trainer/Q Targets Max             -2.29795
trainer/Q Targets Min           -118.169
trainer/Log Pis Mean               0.418083
trainer/Log Pis Std                1.48108
trainer/Log Pis Max                5.35806
trainer/Log Pis Min               -2.29561
trainer/Policy mu Mean             0.258663
trainer/Policy mu Std              0.950015
trainer/Policy mu Max              2.37326
trainer/Policy mu Min             -2.19552
trainer/Policy log std Mean       -0.842513
trainer/Policy log std Std         0.231747
trainer/Policy log std Max        -0.445175
trainer/Policy log std Min        -1.30192
trainer/Alpha                      0.233758
trainer/Alpha Loss                -2.29885
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.07287
exploration/Rewards Std            0.822355
exploration/Rewards Max           -0.0617161
exploration/Rewards Min           -5.30936
exploration/Returns Mean        -107.287
exploration/Returns Std           59.0547
exploration/Returns Max          -55.6167
exploration/Returns Min         -221.372
exploration/Actions Mean           0.00147424
exploration/Actions Std            0.446944
exploration/Actions Max            0.977127
exploration/Actions Min           -0.988589
exploration/Num Paths              5
exploration/Average Returns     -107.287
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.14859
evaluation/Rewards Std             1.13644
evaluation/Rewards Max            -0.233549
evaluation/Rewards Min            -9.65118
evaluation/Returns Mean         -114.859
evaluation/Returns Std            62.8489
evaluation/Returns Max           -26.4696
evaluation/Returns Min          -234.687
evaluation/Actions Mean           -0.00117932
evaluation/Actions Std             0.187407
evaluation/Actions Max             0.975
evaluation/Actions Min            -0.98913
evaluation/Num Paths              15
evaluation/Average Returns      -114.859
time/data storing (s)              0.00312198
time/evaluation sampling (s)       0.367957
time/exploration sampling (s)      0.165896
time/logging (s)                   0.00484169
time/saving (s)                    0.00195981
time/training (s)                  2.18149
time/epoch (s)                     2.72526
time/total (s)                    32.4705
Epoch                             11
-----------------------------  --------------
2019-04-22 21:56:32.702440 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              6700
trainer/QF1 Loss                   8.37153
trainer/QF2 Loss                   8.34276
trainer/Policy Loss               49.0469
trainer/Q1 Predictions Mean      -49.7867
trainer/Q1 Predictions Std        25.9102
trainer/Q1 Predictions Max       -13.8066
trainer/Q1 Predictions Min      -117.021
trainer/Q2 Predictions Mean      -49.8402
trainer/Q2 Predictions Std        25.8799
trainer/Q2 Predictions Max       -13.9508
trainer/Q2 Predictions Min      -117.443
trainer/Q Targets Mean           -49.7441
trainer/Q Targets Std             26.3245
trainer/Q Targets Max             -2.14533
trainer/Q Targets Min           -116.699
trainer/Log Pis Mean               0.618526
trainer/Log Pis Std                1.63083
trainer/Log Pis Max                6.33263
trainer/Log Pis Min               -3.88708
trainer/Policy mu Mean             0.20527
trainer/Policy mu Std              0.956191
trainer/Policy mu Max              2.40271
trainer/Policy mu Min             -2.39881
trainer/Policy log std Mean       -0.904413
trainer/Policy log std Std         0.211815
trainer/Policy log std Max        -0.527186
trainer/Policy log std Min        -1.37089
trainer/Alpha                      0.205698
trainer/Alpha Loss                -2.18424
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.06027
exploration/Rewards Std            1.30268
exploration/Rewards Max           -0.00332018
exploration/Rewards Min           -9.55097
exploration/Returns Mean        -106.027
exploration/Returns Std           45.9268
exploration/Returns Max          -65.739
exploration/Returns Min         -192.459
exploration/Actions Mean           0.00270679
exploration/Actions Std            0.444599
exploration/Actions Max            0.997961
exploration/Actions Min           -0.996424
exploration/Num Paths              5
exploration/Average Returns     -106.027
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.578847
evaluation/Rewards Std             0.782987
evaluation/Rewards Max            -0.158604
evaluation/Rewards Min            -8.34851
evaluation/Returns Mean          -57.8847
evaluation/Returns Std            30.8517
evaluation/Returns Max           -26.771
evaluation/Returns Min          -161.566
evaluation/Actions Mean           -0.012025
evaluation/Actions Std             0.166964
evaluation/Actions Max             0.961668
evaluation/Actions Min            -0.992764
evaluation/Num Paths              15
evaluation/Average Returns       -57.8847
time/data storing (s)              0.00315488
time/evaluation sampling (s)       0.361178
time/exploration sampling (s)      0.158596
time/logging (s)                   0.00476298
time/saving (s)                    0.00195368
time/training (s)                  2.13814
time/epoch (s)                     2.66778
time/total (s)                    35.1431
Epoch                             12
-----------------------------  --------------
2019-04-22 21:56:35.437837 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   7.86308
trainer/QF2 Loss                   8.00329
trainer/Policy Loss               47.3396
trainer/Q1 Predictions Mean      -48.1706
trainer/Q1 Predictions Std        23.4449
trainer/Q1 Predictions Max       -14.6679
trainer/Q1 Predictions Min      -103.347
trainer/Q2 Predictions Mean      -48.1477
trainer/Q2 Predictions Std        23.4223
trainer/Q2 Predictions Max       -14.8106
trainer/Q2 Predictions Min      -103.586
trainer/Q Targets Mean           -48.3591
trainer/Q Targets Std             23.9694
trainer/Q Targets Max             -0.160983
trainer/Q Targets Min           -106.903
trainer/Log Pis Mean               0.581767
trainer/Log Pis Std                1.60358
trainer/Log Pis Max                5.54792
trainer/Log Pis Min               -3.42068
trainer/Policy mu Mean             0.31378
trainer/Policy mu Std              0.928015
trainer/Policy mu Max              2.60081
trainer/Policy mu Min             -2.16901
trainer/Policy log std Mean       -0.988555
trainer/Policy log std Std         0.214335
trainer/Policy log std Max        -0.592476
trainer/Policy log std Min        -1.4147
trainer/Alpha                      0.182197
trainer/Alpha Loss                -2.41445
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.919012
exploration/Rewards Std            0.829225
exploration/Rewards Max           -0.0253412
exploration/Rewards Min           -7.1919
exploration/Returns Mean         -91.9012
exploration/Returns Std           49.9129
exploration/Returns Max          -56.356
exploration/Returns Min         -189.572
exploration/Actions Mean           0.0139874
exploration/Actions Std            0.406013
exploration/Actions Max            0.988278
exploration/Actions Min           -0.978507
exploration/Num Paths              5
exploration/Average Returns      -91.9012
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.27234
evaluation/Rewards Std             1.19966
evaluation/Rewards Max            -0.114701
evaluation/Rewards Min           -10.8875
evaluation/Returns Mean         -127.234
evaluation/Returns Std            61.2107
evaluation/Returns Max           -42.2057
evaluation/Returns Min          -206.938
evaluation/Actions Mean            0.0138352
evaluation/Actions Std             0.195463
evaluation/Actions Max             0.991036
evaluation/Actions Min            -0.995999
evaluation/Num Paths              15
evaluation/Average Returns      -127.234
time/data storing (s)              0.00354822
time/evaluation sampling (s)       0.357104
time/exploration sampling (s)      0.159421
time/logging (s)                   0.00372058
time/saving (s)                    0.00186745
time/training (s)                  2.20337
time/epoch (s)                     2.72903
time/total (s)                    37.8765
Epoch                             13
-----------------------------  --------------
2019-04-22 21:56:38.099199 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                  86.1971
trainer/QF2 Loss                  85.8945
trainer/Policy Loss               45.5274
trainer/Q1 Predictions Mean      -45.6584
trainer/Q1 Predictions Std        23.3652
trainer/Q1 Predictions Max       -15.5145
trainer/Q1 Predictions Min      -109.12
trainer/Q2 Predictions Mean      -45.6403
trainer/Q2 Predictions Std        23.3858
trainer/Q2 Predictions Max       -15.5413
trainer/Q2 Predictions Min      -108.958
trainer/Q Targets Mean           -45.0365
trainer/Q Targets Std             24.3042
trainer/Q Targets Max             -2.47674
trainer/Q Targets Min           -111.33
trainer/Log Pis Mean               0.884129
trainer/Log Pis Std                1.36957
trainer/Log Pis Max                4.43132
trainer/Log Pis Min               -2.82586
trainer/Policy mu Mean             0.327754
trainer/Policy mu Std              0.967515
trainer/Policy mu Max              2.49949
trainer/Policy mu Min             -2.36262
trainer/Policy log std Mean       -1.04033
trainer/Policy log std Std         0.227852
trainer/Policy log std Max        -0.499026
trainer/Policy log std Min        -1.45133
trainer/Alpha                      0.16226
trainer/Alpha Loss                -2.02903
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.905174
exploration/Rewards Std            0.960192
exploration/Rewards Max           -0.0289697
exploration/Rewards Min           -8.71061
exploration/Returns Mean         -90.5174
exploration/Returns Std           27.3517
exploration/Returns Max          -57.81
exploration/Returns Min         -128.234
exploration/Actions Mean           0.020517
exploration/Actions Std            0.37249
exploration/Actions Max            0.995002
exploration/Actions Min           -0.996635
exploration/Num Paths              5
exploration/Average Returns      -90.5174
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.08265
evaluation/Rewards Std             1.02602
evaluation/Rewards Max            -0.290967
evaluation/Rewards Min           -10.7765
evaluation/Returns Mean         -108.265
evaluation/Returns Std            60.442
evaluation/Returns Max           -32.3215
evaluation/Returns Min          -188.619
evaluation/Actions Mean           -0.015274
evaluation/Actions Std             0.165619
evaluation/Actions Max             0.974932
evaluation/Actions Min            -0.992324
evaluation/Num Paths              15
evaluation/Average Returns      -108.265
time/data storing (s)              0.00329131
time/evaluation sampling (s)       0.355172
time/exploration sampling (s)      0.159165
time/logging (s)                   0.00550706
time/saving (s)                    0.00203919
time/training (s)                  2.1333
time/epoch (s)                     2.65848
time/total (s)                    40.539
Epoch                             14
-----------------------------  --------------
2019-04-22 21:56:40.850124 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   1.95908
trainer/QF2 Loss                   1.90612
trainer/Policy Loss               48.5178
trainer/Q1 Predictions Mean      -48.9701
trainer/Q1 Predictions Std        26.4301
trainer/Q1 Predictions Max       -16.461
trainer/Q1 Predictions Min      -122.347
trainer/Q2 Predictions Mean      -48.9724
trainer/Q2 Predictions Std        26.4716
trainer/Q2 Predictions Max       -16.6631
trainer/Q2 Predictions Min      -123.118
trainer/Q Targets Mean           -49.8231
trainer/Q Targets Std             26.9818
trainer/Q Targets Max            -16.3524
trainer/Q Targets Min           -126.042
trainer/Log Pis Mean               1.28773
trainer/Log Pis Std                2.02491
trainer/Log Pis Max                6.81698
trainer/Log Pis Min               -5.78843
trainer/Policy mu Mean             0.265537
trainer/Policy mu Std              1.14986
trainer/Policy mu Max              2.80017
trainer/Policy mu Min             -2.68126
trainer/Policy log std Mean       -1.0588
trainer/Policy log std Std         0.277528
trainer/Policy log std Max        -0.457576
trainer/Policy log std Min        -1.48152
trainer/Alpha                      0.144871
trainer/Alpha Loss                -1.37589
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.970852
exploration/Rewards Std            1.05019
exploration/Rewards Max           -0.017898
exploration/Rewards Min           -8.61628
exploration/Returns Mean         -97.0852
exploration/Returns Std           50.523
exploration/Returns Max          -49.2778
exploration/Returns Min         -189.266
exploration/Actions Mean           0.00308716
exploration/Actions Std            0.339648
exploration/Actions Max            0.99664
exploration/Actions Min           -0.993819
exploration/Num Paths              5
exploration/Average Returns      -97.0852
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.15458
evaluation/Rewards Std             1.01755
evaluation/Rewards Max            -0.287558
evaluation/Rewards Min           -10.7621
evaluation/Returns Mean         -115.458
evaluation/Returns Std            57.6474
evaluation/Returns Max           -37.398
evaluation/Returns Min          -193.783
evaluation/Actions Mean            0.0185836
evaluation/Actions Std             0.187532
evaluation/Actions Max             0.990438
evaluation/Actions Min            -0.993834
evaluation/Num Paths              15
evaluation/Average Returns      -115.458
time/data storing (s)              0.00309151
time/evaluation sampling (s)       0.365717
time/exploration sampling (s)      0.161764
time/logging (s)                   0.00532101
time/saving (s)                    0.00208032
time/training (s)                  2.20709
time/epoch (s)                     2.74506
time/total (s)                    43.2887
Epoch                             15
-----------------------------  --------------
2019-04-22 21:56:43.582329 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              8700
trainer/QF1 Loss                   7.25824
trainer/QF2 Loss                   7.25569
trainer/Policy Loss               43.0618
trainer/Q1 Predictions Mean      -43.4173
trainer/Q1 Predictions Std        22.5207
trainer/Q1 Predictions Max       -16.6712
trainer/Q1 Predictions Min       -99.0119
trainer/Q2 Predictions Mean      -43.4301
trainer/Q2 Predictions Std        22.5584
trainer/Q2 Predictions Max       -16.69
trainer/Q2 Predictions Min       -99.0404
trainer/Q Targets Mean           -43.1556
trainer/Q Targets Std             22.8291
trainer/Q Targets Max             -1.39974
trainer/Q Targets Min           -100.114
trainer/Log Pis Mean               1.05888
trainer/Log Pis Std                1.87939
trainer/Log Pis Max                6.52016
trainer/Log Pis Min               -6.09851
trainer/Policy mu Mean             0.24371
trainer/Policy mu Std              0.969062
trainer/Policy mu Max              2.52231
trainer/Policy mu Min             -2.34645
trainer/Policy log std Mean       -1.21052
trainer/Policy log std Std         0.258847
trainer/Policy log std Max        -0.544291
trainer/Policy log std Min        -1.69583
trainer/Alpha                      0.129296
trainer/Alpha Loss                -1.92501
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.50714
exploration/Rewards Std            1.02638
exploration/Rewards Max           -0.0878448
exploration/Rewards Min          -10.3706
exploration/Returns Mean        -150.714
exploration/Returns Std           28.0806
exploration/Returns Max          -96.0715
exploration/Returns Min         -175.662
exploration/Actions Mean           0.00151491
exploration/Actions Std            0.352438
exploration/Actions Max            0.988265
exploration/Actions Min           -0.99384
exploration/Num Paths              5
exploration/Average Returns     -150.714
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.07082
evaluation/Rewards Std             1.08959
evaluation/Rewards Max            -0.329574
evaluation/Rewards Min           -10.6224
evaluation/Returns Mean         -107.082
evaluation/Returns Std            50.9757
evaluation/Returns Max           -41.3332
evaluation/Returns Min          -180.669
evaluation/Actions Mean            0.0164886
evaluation/Actions Std             0.249237
evaluation/Actions Max             0.987465
evaluation/Actions Min            -0.996479
evaluation/Num Paths              15
evaluation/Average Returns      -107.082
time/data storing (s)              0.00307597
time/evaluation sampling (s)       0.372183
time/exploration sampling (s)      0.164446
time/logging (s)                   0.00462616
time/saving (s)                    0.0115028
time/training (s)                  2.1702
time/epoch (s)                     2.72604
time/total (s)                    46.0193
Epoch                             16
-----------------------------  --------------
2019-04-22 21:56:46.277010 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   0.762955
trainer/QF2 Loss                   0.815761
trainer/Policy Loss               49.0388
trainer/Q1 Predictions Mean      -49.2866
trainer/Q1 Predictions Std        24.7119
trainer/Q1 Predictions Max       -17.5557
trainer/Q1 Predictions Min      -121.646
trainer/Q2 Predictions Mean      -49.2756
trainer/Q2 Predictions Std        24.7214
trainer/Q2 Predictions Max       -17.7597
trainer/Q2 Predictions Min      -122.231
trainer/Q Targets Mean           -49.6719
trainer/Q Targets Std             25.1126
trainer/Q Targets Max            -17.25
trainer/Q Targets Min           -123.857
trainer/Log Pis Mean               1.32677
trainer/Log Pis Std                2.00003
trainer/Log Pis Max                6.57141
trainer/Log Pis Min               -7.1537
trainer/Policy mu Mean             0.266596
trainer/Policy mu Std              1.10772
trainer/Policy mu Max              2.75419
trainer/Policy mu Min             -2.71997
trainer/Policy log std Mean       -1.16123
trainer/Policy log std Std         0.325443
trainer/Policy log std Max        -0.452015
trainer/Policy log std Min        -1.67963
trainer/Alpha                      0.116467
trainer/Alpha Loss                -1.44741
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.32352
exploration/Rewards Std            0.958649
exploration/Rewards Max           -0.0220336
exploration/Rewards Min           -8.33331
exploration/Returns Mean        -132.352
exploration/Returns Std           63.9758
exploration/Returns Max          -51.7267
exploration/Returns Min         -207.037
exploration/Actions Mean           0.00817868
exploration/Actions Std            0.328575
exploration/Actions Max            0.995935
exploration/Actions Min           -0.995354
exploration/Num Paths              5
exploration/Average Returns     -132.352
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.0658
evaluation/Rewards Std             1.1844
evaluation/Rewards Max            -0.234504
evaluation/Rewards Min            -9.77565
evaluation/Returns Mean         -106.58
evaluation/Returns Std            69.8127
evaluation/Returns Max           -26.2673
evaluation/Returns Min          -219.286
evaluation/Actions Mean            0.00162869
evaluation/Actions Std             0.184801
evaluation/Actions Max             0.990249
evaluation/Actions Min            -0.996991
evaluation/Num Paths              15
evaluation/Average Returns      -106.58
time/data storing (s)              0.00332007
time/evaluation sampling (s)       0.359703
time/exploration sampling (s)      0.160159
time/logging (s)                   0.00514045
time/saving (s)                    0.00211115
time/training (s)                  2.15915
time/epoch (s)                     2.68959
time/total (s)                    48.7135
Epoch                             17
-----------------------------  --------------
2019-04-22 21:56:49.070369 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                   0.803122
trainer/QF2 Loss                   0.956238
trainer/Policy Loss               46.8059
trainer/Q1 Predictions Mean      -46.9821
trainer/Q1 Predictions Std        24.77
trainer/Q1 Predictions Max       -17.7094
trainer/Q1 Predictions Min      -102.705
trainer/Q2 Predictions Mean      -46.9416
trainer/Q2 Predictions Std        24.7856
trainer/Q2 Predictions Max       -17.7893
trainer/Q2 Predictions Min      -102.506
trainer/Q Targets Mean           -47.4918
trainer/Q Targets Std             24.9128
trainer/Q Targets Max            -17.7611
trainer/Q Targets Min           -104.187
trainer/Log Pis Mean               1.35024
trainer/Log Pis Std                1.81079
trainer/Log Pis Max                7.41208
trainer/Log Pis Min               -4.45695
trainer/Policy mu Mean             0.295743
trainer/Policy mu Std              1.06543
trainer/Policy mu Max              2.77679
trainer/Policy mu Min             -2.58777
trainer/Policy log std Mean       -1.23743
trainer/Policy log std Std         0.357455
trainer/Policy log std Max        -0.40791
trainer/Policy log std Min        -1.88796
trainer/Alpha                      0.105558
trainer/Alpha Loss                -1.46087
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.15588
exploration/Rewards Std            0.681597
exploration/Rewards Max           -0.0302543
exploration/Rewards Min           -6.02587
exploration/Returns Mean        -115.588
exploration/Returns Std           45.974
exploration/Returns Max          -40.5336
exploration/Returns Min         -184.906
exploration/Actions Mean           0.0198639
exploration/Actions Std            0.279711
exploration/Actions Max            0.995273
exploration/Actions Min           -0.856695
exploration/Num Paths              5
exploration/Average Returns     -115.588
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.12626
evaluation/Rewards Std             1.24591
evaluation/Rewards Max            -0.130666
evaluation/Rewards Min           -11.2814
evaluation/Returns Mean         -112.626
evaluation/Returns Std            76.5959
evaluation/Returns Max           -16.437
evaluation/Returns Min          -227.496
evaluation/Actions Mean           -0.00113838
evaluation/Actions Std             0.186596
evaluation/Actions Max             0.99559
evaluation/Actions Min            -0.997412
evaluation/Num Paths              15
evaluation/Average Returns      -112.626
time/data storing (s)              0.00301515
time/evaluation sampling (s)       0.391256
time/exploration sampling (s)      0.176727
time/logging (s)                   0.00498711
time/saving (s)                    0.00243366
time/training (s)                  2.20894
time/epoch (s)                     2.78735
time/total (s)                    51.5056
Epoch                             18
-----------------------------  --------------
2019-04-22 21:56:51.831346 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   0.928726
trainer/QF2 Loss                   0.916331
trainer/Policy Loss               48.4413
trainer/Q1 Predictions Mean      -48.5902
trainer/Q1 Predictions Std        27.0002
trainer/Q1 Predictions Max       -18.5606
trainer/Q1 Predictions Min      -126.085
trainer/Q2 Predictions Mean      -48.6005
trainer/Q2 Predictions Std        27.0119
trainer/Q2 Predictions Max       -18.6339
trainer/Q2 Predictions Min      -126.514
trainer/Q Targets Mean           -48.8471
trainer/Q Targets Std             27.4305
trainer/Q Targets Max            -18.2093
trainer/Q Targets Min           -125.8
trainer/Log Pis Mean               1.40446
trainer/Log Pis Std                1.71565
trainer/Log Pis Max                7.07568
trainer/Log Pis Min               -3.16661
trainer/Policy mu Mean             0.137206
trainer/Policy mu Std              1.04644
trainer/Policy mu Max              2.89194
trainer/Policy mu Min             -2.95265
trainer/Policy log std Mean       -1.30814
trainer/Policy log std Std         0.360602
trainer/Policy log std Max        -0.429024
trainer/Policy log std Min        -1.75454
trainer/Alpha                      0.0944612
trainer/Alpha Loss                -1.40505
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.92136
exploration/Rewards Std            0.989664
exploration/Rewards Max           -0.0105895
exploration/Rewards Min          -10.0291
exploration/Returns Mean         -92.136
exploration/Returns Std           52.3879
exploration/Returns Max          -33.6836
exploration/Returns Min         -157.973
exploration/Actions Mean          -0.0144612
exploration/Actions Std            0.294443
exploration/Actions Max            0.983477
exploration/Actions Min           -0.999021
exploration/Num Paths              5
exploration/Average Returns      -92.136
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.01647
evaluation/Rewards Std             1.0338
evaluation/Rewards Max            -0.172778
evaluation/Rewards Min           -10.2276
evaluation/Returns Mean         -101.647
evaluation/Returns Std            57.8048
evaluation/Returns Max           -21.6635
evaluation/Returns Min          -184.071
evaluation/Actions Mean            0.0119325
evaluation/Actions Std             0.183711
evaluation/Actions Max             0.994378
evaluation/Actions Min            -0.994952
evaluation/Num Paths              15
evaluation/Average Returns      -101.647
time/data storing (s)              0.00331362
time/evaluation sampling (s)       0.369253
time/exploration sampling (s)      0.165565
time/logging (s)                   0.00518708
time/saving (s)                    0.00216514
time/training (s)                  2.21046
time/epoch (s)                     2.75594
time/total (s)                    54.2658
Epoch                             19
-----------------------------  --------------
2019-04-22 21:56:54.582756 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                   3.99566
trainer/QF2 Loss                   3.99526
trainer/Policy Loss               46.0763
trainer/Q1 Predictions Mean      -46.0477
trainer/Q1 Predictions Std        23.4812
trainer/Q1 Predictions Max       -18.311
trainer/Q1 Predictions Min      -111.747
trainer/Q2 Predictions Mean      -46.0317
trainer/Q2 Predictions Std        23.4981
trainer/Q2 Predictions Max       -18.3769
trainer/Q2 Predictions Min      -111.865
trainer/Q Targets Mean           -46.3997
trainer/Q Targets Std             24.0859
trainer/Q Targets Max             -0.231878
trainer/Q Targets Min           -111.594
trainer/Log Pis Mean               1.72843
trainer/Log Pis Std                1.77315
trainer/Log Pis Max                7.0642
trainer/Log Pis Min               -2.54674
trainer/Policy mu Mean             0.192409
trainer/Policy mu Std              1.11889
trainer/Policy mu Max              2.86448
trainer/Policy mu Min             -2.74921
trainer/Policy log std Mean       -1.35583
trainer/Policy log std Std         0.411648
trainer/Policy log std Max        -0.542934
trainer/Policy log std Min        -1.93771
trainer/Alpha                      0.085095
trainer/Alpha Loss                -0.669089
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.677875
exploration/Rewards Std            1.03945
exploration/Rewards Max           -0.0213992
exploration/Rewards Min           -9.42927
exploration/Returns Mean         -67.7875
exploration/Returns Std           22.2713
exploration/Returns Max          -44.3194
exploration/Returns Min         -106.039
exploration/Actions Mean          -0.027861
exploration/Actions Std            0.313451
exploration/Actions Max            0.984439
exploration/Actions Min           -0.99889
exploration/Num Paths              5
exploration/Average Returns      -67.7875
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.606188
evaluation/Rewards Std             0.994955
evaluation/Rewards Max            -0.184299
evaluation/Rewards Min            -9.63181
evaluation/Returns Mean          -60.6188
evaluation/Returns Std            38.5681
evaluation/Returns Max           -19.1652
evaluation/Returns Min          -139.708
evaluation/Actions Mean           -0.00928872
evaluation/Actions Std             0.185154
evaluation/Actions Max             0.994353
evaluation/Actions Min            -0.998838
evaluation/Num Paths              15
evaluation/Average Returns       -60.6188
time/data storing (s)              0.00322424
time/evaluation sampling (s)       0.357829
time/exploration sampling (s)      0.160827
time/logging (s)                   0.00474322
time/saving (s)                    0.00229927
time/training (s)                  2.21611
time/epoch (s)                     2.74504
time/total (s)                    57.0157
Epoch                             20
-----------------------------  --------------
2019-04-22 21:56:57.286096 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   6.31667
trainer/QF2 Loss                   6.29099
trainer/Policy Loss               48.6848
trainer/Q1 Predictions Mean      -48.1446
trainer/Q1 Predictions Std        24.7219
trainer/Q1 Predictions Max       -18.6151
trainer/Q1 Predictions Min      -120.366
trainer/Q2 Predictions Mean      -48.1715
trainer/Q2 Predictions Std        24.6916
trainer/Q2 Predictions Max       -18.7098
trainer/Q2 Predictions Min      -120.232
trainer/Q Targets Mean           -47.9203
trainer/Q Targets Std             25.3127
trainer/Q Targets Max             -2.14533
trainer/Q Targets Min           -123.178
trainer/Log Pis Mean               1.46482
trainer/Log Pis Std                1.87415
trainer/Log Pis Max                7.51493
trainer/Log Pis Min               -5.68829
trainer/Policy mu Mean             0.242572
trainer/Policy mu Std              1.02219
trainer/Policy mu Max              2.95828
trainer/Policy mu Min             -3.18797
trainer/Policy log std Mean       -1.38588
trainer/Policy log std Std         0.40324
trainer/Policy log std Max        -0.373619
trainer/Policy log std Min        -1.96298
trainer/Alpha                      0.077497
trainer/Alpha Loss                -1.36863
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.13509
exploration/Rewards Std            1.18091
exploration/Rewards Max           -0.0212197
exploration/Rewards Min           -9.18334
exploration/Returns Mean        -113.509
exploration/Returns Std           31.7186
exploration/Returns Max          -66.7081
exploration/Returns Min         -145.793
exploration/Actions Mean           0.0109647
exploration/Actions Std            0.347299
exploration/Actions Max            0.996416
exploration/Actions Min           -0.998603
exploration/Num Paths              5
exploration/Average Returns     -113.509
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.693358
evaluation/Rewards Std             1.0886
evaluation/Rewards Max            -0.0753274
evaluation/Rewards Min            -9.4076
evaluation/Returns Mean          -69.3358
evaluation/Returns Std            48.3573
evaluation/Returns Max            -9.52201
evaluation/Returns Min          -152.806
evaluation/Actions Mean            0.00571665
evaluation/Actions Std             0.185671
evaluation/Actions Max             0.994375
evaluation/Actions Min            -0.996843
evaluation/Num Paths              15
evaluation/Average Returns       -69.3358
time/data storing (s)              0.00303809
time/evaluation sampling (s)       0.363422
time/exploration sampling (s)      0.166731
time/logging (s)                   0.00497673
time/saving (s)                    0.00194706
time/training (s)                  2.15788
time/epoch (s)                     2.698
time/total (s)                    59.7182
Epoch                             21
-----------------------------  --------------
2019-04-22 21:57:00.011577 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                   1.20655
trainer/QF2 Loss                   1.10032
trainer/Policy Loss               48.4896
trainer/Q1 Predictions Mean      -47.8137
trainer/Q1 Predictions Std        24.4327
trainer/Q1 Predictions Max       -18.3112
trainer/Q1 Predictions Min      -116.998
trainer/Q2 Predictions Mean      -47.786
trainer/Q2 Predictions Std        24.4489
trainer/Q2 Predictions Max       -18.2802
trainer/Q2 Predictions Min      -117.484
trainer/Q Targets Mean           -48.3722
trainer/Q Targets Std             25.0309
trainer/Q Targets Max            -18.3216
trainer/Q Targets Min           -118.997
trainer/Log Pis Mean               1.76132
trainer/Log Pis Std                1.65466
trainer/Log Pis Max                7.14285
trainer/Log Pis Min               -3.85492
trainer/Policy mu Mean             0.304466
trainer/Policy mu Std              1.03011
trainer/Policy mu Max              2.93037
trainer/Policy mu Min             -2.5579
trainer/Policy log std Mean       -1.41951
trainer/Policy log std Std         0.419731
trainer/Policy log std Max        -0.462693
trainer/Policy log std Min        -2.03831
trainer/Alpha                      0.0711365
trainer/Alpha Loss                -0.630846
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.608345
exploration/Rewards Std            0.947044
exploration/Rewards Max           -0.0104336
exploration/Rewards Min          -10.6535
exploration/Returns Mean         -60.8345
exploration/Returns Std           33.4501
exploration/Returns Max          -32.1366
exploration/Returns Min         -117.12
exploration/Actions Mean          -0.0276485
exploration/Actions Std            0.254679
exploration/Actions Max            0.984991
exploration/Actions Min           -0.997733
exploration/Num Paths              5
exploration/Average Returns      -60.8345
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.789082
evaluation/Rewards Std             0.931471
evaluation/Rewards Max            -0.196756
evaluation/Rewards Min           -10.8938
evaluation/Returns Mean          -78.9082
evaluation/Returns Std            34.2725
evaluation/Returns Max           -23.9221
evaluation/Returns Min          -119.136
evaluation/Actions Mean           -0.0041117
evaluation/Actions Std             0.169712
evaluation/Actions Max             0.994006
evaluation/Actions Min            -0.998998
evaluation/Num Paths              15
evaluation/Average Returns       -78.9082
time/data storing (s)              0.00324163
time/evaluation sampling (s)       0.36866
time/exploration sampling (s)      0.162625
time/logging (s)                   0.00554871
time/saving (s)                    0.00225587
time/training (s)                  2.17833
time/epoch (s)                     2.72067
time/total (s)                    62.4432
Epoch                             22
-----------------------------  --------------
2019-04-22 21:57:02.743114 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                  55.8425
trainer/QF2 Loss                  55.8268
trainer/Policy Loss               47.7595
trainer/Q1 Predictions Mean      -47.1618
trainer/Q1 Predictions Std        24.1742
trainer/Q1 Predictions Max       -18.3668
trainer/Q1 Predictions Min      -128.131
trainer/Q2 Predictions Mean      -47.1512
trainer/Q2 Predictions Std        24.2122
trainer/Q2 Predictions Max       -18.2707
trainer/Q2 Predictions Min      -128.533
trainer/Q Targets Mean           -47.1031
trainer/Q Targets Std             24.8148
trainer/Q Targets Max             -1.57235
trainer/Q Targets Min           -126.614
trainer/Log Pis Mean               2.01841
trainer/Log Pis Std                1.72753
trainer/Log Pis Max                8.83921
trainer/Log Pis Min               -1.02251
trainer/Policy mu Mean             0.137916
trainer/Policy mu Std              1.13567
trainer/Policy mu Max              3.3518
trainer/Policy mu Min             -3.02385
trainer/Policy log std Mean       -1.56443
trainer/Policy log std Std         0.491607
trainer/Policy log std Max        -0.306011
trainer/Policy log std Min        -2.15315
trainer/Alpha                      0.0671013
trainer/Alpha Loss                 0.0497477
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.907876
exploration/Rewards Std            0.83862
exploration/Rewards Max           -0.0170496
exploration/Rewards Min           -8.58809
exploration/Returns Mean         -90.7876
exploration/Returns Std           30.1512
exploration/Returns Max          -33.0747
exploration/Returns Min         -120.474
exploration/Actions Mean           0.0190502
exploration/Actions Std            0.272507
exploration/Actions Max            0.994288
exploration/Actions Min           -0.974749
exploration/Num Paths              5
exploration/Average Returns      -90.7876
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.49175
evaluation/Rewards Std             1.0183
evaluation/Rewards Max            -0.0557543
evaluation/Rewards Min           -10.0591
evaluation/Returns Mean          -49.175
evaluation/Returns Std            29.8972
evaluation/Returns Max           -15.7916
evaluation/Returns Min          -100.434
evaluation/Actions Mean           -0.0146928
evaluation/Actions Std             0.189709
evaluation/Actions Max             0.993782
evaluation/Actions Min            -0.99917
evaluation/Num Paths              15
evaluation/Average Returns       -49.175
time/data storing (s)              0.00331022
time/evaluation sampling (s)       0.376248
time/exploration sampling (s)      0.163734
time/logging (s)                   0.00497555
time/saving (s)                    0.00208239
time/training (s)                  2.17497
time/epoch (s)                     2.72532
time/total (s)                    65.173
Epoch                             23
-----------------------------  --------------
2019-04-22 21:57:05.568414 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size             12700
trainer/QF1 Loss                  61.165
trainer/QF2 Loss                  61.764
trainer/Policy Loss               48.2984
trainer/Q1 Predictions Mean      -47.57
trainer/Q1 Predictions Std        25.4862
trainer/Q1 Predictions Max       -17.8592
trainer/Q1 Predictions Min      -103.757
trainer/Q2 Predictions Mean      -47.5547
trainer/Q2 Predictions Std        25.4935
trainer/Q2 Predictions Max       -17.8009
trainer/Q2 Predictions Min      -104.141
trainer/Q Targets Mean           -47.4051
trainer/Q Targets Std             25.9501
trainer/Q Targets Max             -5.2068
trainer/Q Targets Min           -106.92
trainer/Log Pis Mean               1.59877
trainer/Log Pis Std                1.4746
trainer/Log Pis Max                7.34593
trainer/Log Pis Min               -2.93127
trainer/Policy mu Mean             0.241521
trainer/Policy mu Std              0.913112
trainer/Policy mu Max              2.6915
trainer/Policy mu Min             -2.71415
trainer/Policy log std Mean       -1.62581
trainer/Policy log std Std         0.469483
trainer/Policy log std Max        -0.548348
trainer/Policy log std Min        -2.26184
trainer/Alpha                      0.0650036
trainer/Alpha Loss                -1.09666
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.78058
exploration/Rewards Std            1.37047
exploration/Rewards Max           -0.0115059
exploration/Rewards Min          -10.101
exploration/Returns Mean         -78.058
exploration/Returns Std           43.151
exploration/Returns Max          -24.2726
exploration/Returns Min         -149.883
exploration/Actions Mean           0.0127627
exploration/Actions Std            0.268384
exploration/Actions Max            0.998492
exploration/Actions Min           -0.998518
exploration/Num Paths              5
exploration/Average Returns      -78.058
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.622558
evaluation/Rewards Std             0.972728
evaluation/Rewards Max            -0.0806417
evaluation/Rewards Min            -9.54777
evaluation/Returns Mean          -62.2558
evaluation/Returns Std            37.4431
evaluation/Returns Max           -14.605
evaluation/Returns Min          -130.475
evaluation/Actions Mean           -0.00653788
evaluation/Actions Std             0.192986
evaluation/Actions Max             0.993104
evaluation/Actions Min            -0.995056
evaluation/Num Paths              15
evaluation/Average Returns       -62.2558
time/data storing (s)              0.00320407
time/evaluation sampling (s)       0.366347
time/exploration sampling (s)      0.16622
time/logging (s)                   0.00501909
time/saving (s)                    0.00215647
time/training (s)                  2.27585
time/epoch (s)                     2.8188
time/total (s)                    67.9973
Epoch                             24
-----------------------------  --------------
2019-04-22 21:57:08.246526 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                  16.2181
trainer/QF2 Loss                  16.2694
trainer/Policy Loss               44.9293
trainer/Q1 Predictions Mean      -44.286
trainer/Q1 Predictions Std        23.8096
trainer/Q1 Predictions Max       -17.428
trainer/Q1 Predictions Min      -122.66
trainer/Q2 Predictions Mean      -44.2839
trainer/Q2 Predictions Std        23.7841
trainer/Q2 Predictions Max       -17.4834
trainer/Q2 Predictions Min      -123.327
trainer/Q Targets Mean           -44.2517
trainer/Q Targets Std             24.7887
trainer/Q Targets Max             -0.301163
trainer/Q Targets Min           -126.944
trainer/Log Pis Mean               1.99425
trainer/Log Pis Std                1.61466
trainer/Log Pis Max                6.88398
trainer/Log Pis Min               -1.65184
trainer/Policy mu Mean             0.203822
trainer/Policy mu Std              1.04483
trainer/Policy mu Max              3.07607
trainer/Policy mu Min             -2.77419
trainer/Policy log std Mean       -1.6671
trainer/Policy log std Std         0.507102
trainer/Policy log std Max        -0.399347
trainer/Policy log std Min        -2.30502
trainer/Alpha                      0.06338
trainer/Alpha Loss                -0.0158598
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.502066
exploration/Rewards Std            0.501132
exploration/Rewards Max           -0.013277
exploration/Rewards Min           -4.63569
exploration/Returns Mean         -50.2066
exploration/Returns Std           32.4833
exploration/Returns Max          -23.6188
exploration/Returns Min         -109.469
exploration/Actions Mean          -0.00887083
exploration/Actions Std            0.200544
exploration/Actions Max            0.960225
exploration/Actions Min           -0.99651
exploration/Num Paths              5
exploration/Average Returns      -50.2066
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.732406
evaluation/Rewards Std             1.0237
evaluation/Rewards Max            -0.0250405
evaluation/Rewards Min           -10.3102
evaluation/Returns Mean          -73.2406
evaluation/Returns Std            44.8482
evaluation/Returns Max           -13.33
evaluation/Returns Min          -153.055
evaluation/Actions Mean            0.019323
evaluation/Actions Std             0.191388
evaluation/Actions Max             0.996824
evaluation/Actions Min            -0.99119
evaluation/Num Paths              15
evaluation/Average Returns       -73.2406
time/data storing (s)              0.00312054
time/evaluation sampling (s)       0.358033
time/exploration sampling (s)      0.159063
time/logging (s)                   0.00546768
time/saving (s)                    0.00205983
time/training (s)                  2.14501
time/epoch (s)                     2.67275
time/total (s)                    70.6748
Epoch                             25
-----------------------------  --------------
2019-04-22 21:57:10.976361 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                   0.405222
trainer/QF2 Loss                   0.394541
trainer/Policy Loss               44.8024
trainer/Q1 Predictions Mean      -43.824
trainer/Q1 Predictions Std        22.9369
trainer/Q1 Predictions Max       -17.3848
trainer/Q1 Predictions Min       -86.1755
trainer/Q2 Predictions Mean      -43.834
trainer/Q2 Predictions Std        22.8979
trainer/Q2 Predictions Max       -17.2557
trainer/Q2 Predictions Min       -86.4281
trainer/Q Targets Mean           -44.0556
trainer/Q Targets Std             23.0238
trainer/Q Targets Max            -17.6294
trainer/Q Targets Min            -87.5758
trainer/Log Pis Mean               2.16067
trainer/Log Pis Std                1.57382
trainer/Log Pis Max                7.00894
trainer/Log Pis Min               -2.63395
trainer/Policy mu Mean             0.150906
trainer/Policy mu Std              1.11027
trainer/Policy mu Max              2.98876
trainer/Policy mu Min             -3.02273
trainer/Policy log std Mean       -1.6636
trainer/Policy log std Std         0.530877
trainer/Policy log std Max        -0.202995
trainer/Policy log std Min        -2.38233
trainer/Alpha                      0.0624848
trainer/Alpha Loss                 0.445519
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.633369
exploration/Rewards Std            1.01248
exploration/Rewards Max           -0.0166608
exploration/Rewards Min          -10.0183
exploration/Returns Mean         -63.3369
exploration/Returns Std           38.8304
exploration/Returns Max          -28.5435
exploration/Returns Min         -136.01
exploration/Actions Mean           0.0147227
exploration/Actions Std            0.252789
exploration/Actions Max            0.998005
exploration/Actions Min           -0.981553
exploration/Num Paths              5
exploration/Average Returns      -63.3369
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.667153
evaluation/Rewards Std             0.871327
evaluation/Rewards Max            -0.0345131
evaluation/Rewards Min            -9.66225
evaluation/Returns Mean          -66.7153
evaluation/Returns Std            36.9558
evaluation/Returns Max           -19.481
evaluation/Returns Min          -118.749
evaluation/Actions Mean           -0.00337917
evaluation/Actions Std             0.177843
evaluation/Actions Max             0.995713
evaluation/Actions Min            -0.998588
evaluation/Num Paths              15
evaluation/Average Returns       -66.7153
time/data storing (s)              0.00494938
time/evaluation sampling (s)       0.361457
time/exploration sampling (s)      0.161848
time/logging (s)                   0.00430008
time/saving (s)                    0.00202979
time/training (s)                  2.18779
time/epoch (s)                     2.72238
time/total (s)                    73.4021
Epoch                             26
-----------------------------  --------------
2019-04-22 21:57:13.720592 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   5.055
trainer/QF2 Loss                   5.19356
trainer/Policy Loss               42.5938
trainer/Q1 Predictions Mean      -41.9302
trainer/Q1 Predictions Std        24.1969
trainer/Q1 Predictions Max       -17.4335
trainer/Q1 Predictions Min      -114.358
trainer/Q2 Predictions Mean      -41.9407
trainer/Q2 Predictions Std        24.2262
trainer/Q2 Predictions Max       -17.4546
trainer/Q2 Predictions Min      -115.485
trainer/Q Targets Mean           -42.0314
trainer/Q Targets Std             24.6751
trainer/Q Targets Max             -1.39974
trainer/Q Targets Min           -111.913
trainer/Log Pis Mean               1.92952
trainer/Log Pis Std                1.6049
trainer/Log Pis Max                7.56786
trainer/Log Pis Min               -3.05189
trainer/Policy mu Mean             0.161595
trainer/Policy mu Std              1.01637
trainer/Policy mu Max              3.1203
trainer/Policy mu Min             -2.74272
trainer/Policy log std Mean       -1.69561
trainer/Policy log std Std         0.481697
trainer/Policy log std Max        -0.358231
trainer/Policy log std Min        -2.46489
trainer/Alpha                      0.063264
trainer/Alpha Loss                -0.194556
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.577878
exploration/Rewards Std            0.923146
exploration/Rewards Max           -0.0285617
exploration/Rewards Min           -8.35731
exploration/Returns Mean         -57.7878
exploration/Returns Std           23.5443
exploration/Returns Max          -32.4208
exploration/Returns Min          -96.9436
exploration/Actions Mean          -0.0120554
exploration/Actions Std            0.239852
exploration/Actions Max            0.995146
exploration/Actions Min           -0.998914
exploration/Num Paths              5
exploration/Average Returns      -57.7878
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.635405
evaluation/Rewards Std             1.11903
evaluation/Rewards Max            -0.0547106
evaluation/Rewards Min           -10.6292
evaluation/Returns Mean          -63.5405
evaluation/Returns Std            35.6904
evaluation/Returns Max           -18.2044
evaluation/Returns Min          -128.568
evaluation/Actions Mean           -0.00282051
evaluation/Actions Std             0.193187
evaluation/Actions Max             0.997433
evaluation/Actions Min            -0.997135
evaluation/Num Paths              15
evaluation/Average Returns       -63.5405
time/data storing (s)              0.00425598
time/evaluation sampling (s)       0.371103
time/exploration sampling (s)      0.164984
time/logging (s)                   0.0049852
time/saving (s)                    0.00200421
time/training (s)                  2.1923
time/epoch (s)                     2.73963
time/total (s)                    76.1459
Epoch                             27
-----------------------------  --------------
2019-04-22 21:57:16.471335 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 28 finished
-----------------------------  ---------------
replay_buffer/size             14700
trainer/QF1 Loss                  35.6616
trainer/QF2 Loss                  36.0022
trainer/Policy Loss               40.4457
trainer/Q1 Predictions Mean      -39.7402
trainer/Q1 Predictions Std        23.1505
trainer/Q1 Predictions Max       -16.8336
trainer/Q1 Predictions Min       -90.8878
trainer/Q2 Predictions Mean      -39.7377
trainer/Q2 Predictions Std        23.1434
trainer/Q2 Predictions Max       -16.6993
trainer/Q2 Predictions Min       -90.693
trainer/Q Targets Mean           -39.5067
trainer/Q Targets Std             24.0676
trainer/Q Targets Max             -0.309304
trainer/Q Targets Min            -91.5964
trainer/Log Pis Mean               1.68279
trainer/Log Pis Std                1.50969
trainer/Log Pis Max                9.00933
trainer/Log Pis Min               -2.13039
trainer/Policy mu Mean             0.148036
trainer/Policy mu Std              0.934256
trainer/Policy mu Max              3.10338
trainer/Policy mu Min             -3.65881
trainer/Policy log std Mean       -1.74143
trainer/Policy log std Std         0.481823
trainer/Policy log std Max         0.0210136
trainer/Policy log std Min        -2.5402
trainer/Alpha                      0.0655592
trainer/Alpha Loss                -0.864314
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.602676
exploration/Rewards Std            1.0429
exploration/Rewards Max           -0.0240732
exploration/Rewards Min           -9.66702
exploration/Returns Mean         -60.2676
exploration/Returns Std           16.9982
exploration/Returns Max          -39.8628
exploration/Returns Min          -81.6491
exploration/Actions Mean          -0.016116
exploration/Actions Std            0.240632
exploration/Actions Max            0.992144
exploration/Actions Min           -0.999917
exploration/Num Paths              5
exploration/Average Returns      -60.2676
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.501695
evaluation/Rewards Std             0.984035
evaluation/Rewards Max            -0.0830024
evaluation/Rewards Min           -10.2746
evaluation/Returns Mean          -50.1695
evaluation/Returns Std            28.8124
evaluation/Returns Max           -15.5429
evaluation/Returns Min          -112.258
evaluation/Actions Mean           -0.000250455
evaluation/Actions Std             0.18968
evaluation/Actions Max             0.996245
evaluation/Actions Min            -0.999235
evaluation/Num Paths              15
evaluation/Average Returns       -50.1695
time/data storing (s)              0.0031792
time/evaluation sampling (s)       0.412519
time/exploration sampling (s)      0.162571
time/logging (s)                   0.00485239
time/saving (s)                    0.001993
time/training (s)                  2.15913
time/epoch (s)                     2.74425
time/total (s)                    78.8954
Epoch                             28
-----------------------------  ---------------
2019-04-22 21:57:19.195355 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   0.499663
trainer/QF2 Loss                   0.406245
trainer/Policy Loss               42.7829
trainer/Q1 Predictions Mean      -42.2806
trainer/Q1 Predictions Std        24.0785
trainer/Q1 Predictions Max       -16.4547
trainer/Q1 Predictions Min      -109.056
trainer/Q2 Predictions Mean      -42.3049
trainer/Q2 Predictions Std        24.0911
trainer/Q2 Predictions Max       -16.4053
trainer/Q2 Predictions Min      -110.147
trainer/Q Targets Mean           -42.5513
trainer/Q Targets Std             24.2141
trainer/Q Targets Max            -16.4953
trainer/Q Targets Min           -112.599
trainer/Log Pis Mean               2.01168
trainer/Log Pis Std                1.8266
trainer/Log Pis Max                8.64677
trainer/Log Pis Min               -4.38295
trainer/Policy mu Mean             0.0798573
trainer/Policy mu Std              1.09373
trainer/Policy mu Max              3.34295
trainer/Policy mu Min             -3.64524
trainer/Policy log std Mean       -1.69333
trainer/Policy log std Std         0.539868
trainer/Policy log std Max        -0.108418
trainer/Policy log std Min        -2.56575
trainer/Alpha                      0.0668503
trainer/Alpha Loss                 0.0315914
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.479849
exploration/Rewards Std            0.725852
exploration/Rewards Max           -0.0042259
exploration/Rewards Min           -8.54847
exploration/Returns Mean         -47.9849
exploration/Returns Std           21.0234
exploration/Returns Max          -23.8423
exploration/Returns Min          -80.6918
exploration/Actions Mean          -0.00305704
exploration/Actions Std            0.228418
exploration/Actions Max            0.999125
exploration/Actions Min           -0.978843
exploration/Num Paths              5
exploration/Average Returns      -47.9849
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.513175
evaluation/Rewards Std             0.959762
evaluation/Rewards Max            -0.0610959
evaluation/Rewards Min           -11.222
evaluation/Returns Mean          -51.3175
evaluation/Returns Std            32.6672
evaluation/Returns Max           -13.6863
evaluation/Returns Min          -103.23
evaluation/Actions Mean            0.0102583
evaluation/Actions Std             0.184266
evaluation/Actions Max             0.99656
evaluation/Actions Min            -0.996693
evaluation/Num Paths              15
evaluation/Average Returns       -51.3175
time/data storing (s)              0.00325416
time/evaluation sampling (s)       0.40971
time/exploration sampling (s)      0.163903
time/logging (s)                   0.00476652
time/saving (s)                    0.00200438
time/training (s)                  2.13454
time/epoch (s)                     2.71818
time/total (s)                    81.6182
Epoch                             29
-----------------------------  --------------
2019-04-22 21:57:21.845118 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                   0.668942
trainer/QF2 Loss                   0.59971
trainer/Policy Loss               44.82
trainer/Q1 Predictions Mean      -44.005
trainer/Q1 Predictions Std        23.5679
trainer/Q1 Predictions Max       -16.3889
trainer/Q1 Predictions Min      -116.715
trainer/Q2 Predictions Mean      -43.9764
trainer/Q2 Predictions Std        23.5686
trainer/Q2 Predictions Max       -16.2838
trainer/Q2 Predictions Min      -117.153
trainer/Q Targets Mean           -44.3134
trainer/Q Targets Std             23.8755
trainer/Q Targets Max            -16.2845
trainer/Q Targets Min           -120.025
trainer/Log Pis Mean               2.25872
trainer/Log Pis Std                1.4501
trainer/Log Pis Max                7.94178
trainer/Log Pis Min               -1.21252
trainer/Policy mu Mean             0.116174
trainer/Policy mu Std              1.006
trainer/Policy mu Max              3.16205
trainer/Policy mu Min             -3.56359
trainer/Policy log std Mean       -1.75567
trainer/Policy log std Std         0.510401
trainer/Policy log std Max        -0.172873
trainer/Policy log std Min        -2.57518
trainer/Alpha                      0.0669804
trainer/Alpha Loss                 0.699404
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.406161
exploration/Rewards Std            0.967201
exploration/Rewards Max           -0.0144611
exploration/Rewards Min           -8.5908
exploration/Returns Mean         -40.6161
exploration/Returns Std           12.6818
exploration/Returns Max          -29.9281
exploration/Returns Min          -61.896
exploration/Actions Mean          -0.00827448
exploration/Actions Std            0.256287
exploration/Actions Max            0.999717
exploration/Actions Min           -0.997314
exploration/Num Paths              5
exploration/Average Returns      -40.6161
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.525464
evaluation/Rewards Std             1.14602
evaluation/Rewards Max            -0.0692911
evaluation/Rewards Min           -10.9997
evaluation/Returns Mean          -52.5464
evaluation/Returns Std            30.4621
evaluation/Returns Max           -11.3726
evaluation/Returns Min          -102.517
evaluation/Actions Mean            0.0139462
evaluation/Actions Std             0.19065
evaluation/Actions Max             0.996936
evaluation/Actions Min            -0.999234
evaluation/Num Paths              15
evaluation/Average Returns       -52.5464
time/data storing (s)              0.00316233
time/evaluation sampling (s)       0.361957
time/exploration sampling (s)      0.161498
time/logging (s)                   0.00564075
time/saving (s)                    0.00231951
time/training (s)                  2.10971
time/epoch (s)                     2.64429
time/total (s)                    84.2677
Epoch                             30
-----------------------------  --------------
2019-04-22 21:57:24.542066 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   0.585953
trainer/QF2 Loss                   0.599599
trainer/Policy Loss               36.7269
trainer/Q1 Predictions Mean      -35.9282
trainer/Q1 Predictions Std        21.5313
trainer/Q1 Predictions Max       -15.4828
trainer/Q1 Predictions Min      -100.111
trainer/Q2 Predictions Mean      -35.9244
trainer/Q2 Predictions Std        21.506
trainer/Q2 Predictions Max       -15.4604
trainer/Q2 Predictions Min       -99.7314
trainer/Q Targets Mean           -36.4193
trainer/Q Targets Std             21.8209
trainer/Q Targets Max            -15.7286
trainer/Q Targets Min           -102.241
trainer/Log Pis Mean               1.85587
trainer/Log Pis Std                1.18882
trainer/Log Pis Max                6.28879
trainer/Log Pis Min               -1.24557
trainer/Policy mu Mean            -0.03306
trainer/Policy mu Std              0.79541
trainer/Policy mu Max              2.65688
trainer/Policy mu Min             -3.08498
trainer/Policy log std Mean       -1.86203
trainer/Policy log std Std         0.439622
trainer/Policy log std Max        -0.436733
trainer/Policy log std Min        -2.67118
trainer/Alpha                      0.066986
trainer/Alpha Loss                -0.389623
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.434452
exploration/Rewards Std            1.11064
exploration/Rewards Max           -0.0127277
exploration/Rewards Min           -9.88499
exploration/Returns Mean         -43.4452
exploration/Returns Std           15.0995
exploration/Returns Max          -27.0322
exploration/Returns Min          -69.4929
exploration/Actions Mean          -0.00434848
exploration/Actions Std            0.245545
exploration/Actions Max            0.999489
exploration/Actions Min           -0.997536
exploration/Num Paths              5
exploration/Average Returns      -43.4452
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.433172
evaluation/Rewards Std             0.979362
evaluation/Rewards Max            -0.00844356
evaluation/Rewards Min            -9.11523
evaluation/Returns Mean          -43.3172
evaluation/Returns Std            37.9043
evaluation/Returns Max           -14.0294
evaluation/Returns Min          -137.033
evaluation/Actions Mean            0.0166055
evaluation/Actions Std             0.178721
evaluation/Actions Max             0.996541
evaluation/Actions Min            -0.99503
evaluation/Num Paths              15
evaluation/Average Returns       -43.3172
time/data storing (s)              0.00427267
time/evaluation sampling (s)       0.359135
time/exploration sampling (s)      0.162161
time/logging (s)                   0.00421723
time/saving (s)                    0.00210801
time/training (s)                  2.15792
time/epoch (s)                     2.68982
time/total (s)                    86.9621
Epoch                             31
-----------------------------  --------------
2019-04-22 21:57:27.205497 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size             16700
trainer/QF1 Loss                   0.446977
trainer/QF2 Loss                   0.453457
trainer/Policy Loss               38.6822
trainer/Q1 Predictions Mean      -37.8766
trainer/Q1 Predictions Std        23.0626
trainer/Q1 Predictions Max       -15.4445
trainer/Q1 Predictions Min      -129.6
trainer/Q2 Predictions Mean      -37.8788
trainer/Q2 Predictions Std        23.0813
trainer/Q2 Predictions Max       -15.3739
trainer/Q2 Predictions Min      -129.721
trainer/Q Targets Mean           -38.1984
trainer/Q Targets Std             23.3557
trainer/Q Targets Max            -15.4608
trainer/Q Targets Min           -131.589
trainer/Log Pis Mean               1.82472
trainer/Log Pis Std                1.37809
trainer/Log Pis Max                6.4055
trainer/Log Pis Min               -4.04952
trainer/Policy mu Mean             0.192252
trainer/Policy mu Std              0.8346
trainer/Policy mu Max              3.55731
trainer/Policy mu Min             -2.4924
trainer/Policy log std Mean       -1.8609
trainer/Policy log std Std         0.456558
trainer/Policy log std Max        -0.351148
trainer/Policy log std Min        -2.6326
trainer/Alpha                      0.0641178
trainer/Alpha Loss                -0.48148
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.65804
exploration/Rewards Std            1.24702
exploration/Rewards Max           -0.0199289
exploration/Rewards Min          -10.1921
exploration/Returns Mean         -65.804
exploration/Returns Std           25.8849
exploration/Returns Max          -32.0548
exploration/Returns Min         -106.094
exploration/Actions Mean           0.0306879
exploration/Actions Std            0.249698
exploration/Actions Max            0.999371
exploration/Actions Min           -0.97608
exploration/Num Paths              5
exploration/Average Returns      -65.804
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.677593
evaluation/Rewards Std             0.960789
evaluation/Rewards Max            -0.0267215
evaluation/Rewards Min           -10.397
evaluation/Returns Mean          -67.7593
evaluation/Returns Std            35.975
evaluation/Returns Max           -15.2875
evaluation/Returns Min          -122.392
evaluation/Actions Mean            0.00346215
evaluation/Actions Std             0.18115
evaluation/Actions Max             0.996527
evaluation/Actions Min            -0.998552
evaluation/Num Paths              15
evaluation/Average Returns       -67.7593
time/data storing (s)              0.00351279
time/evaluation sampling (s)       0.359003
time/exploration sampling (s)      0.169951
time/logging (s)                   0.00511002
time/saving (s)                    0.00183869
time/training (s)                  2.119
time/epoch (s)                     2.65841
time/total (s)                    89.6252
Epoch                             32
-----------------------------  --------------
2019-04-22 21:57:29.916862 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   0.497955
trainer/QF2 Loss                   0.487046
trainer/Policy Loss               35.7721
trainer/Q1 Predictions Mean      -34.8593
trainer/Q1 Predictions Std        19.9876
trainer/Q1 Predictions Max       -15.1249
trainer/Q1 Predictions Min       -84.7975
trainer/Q2 Predictions Mean      -34.8417
trainer/Q2 Predictions Std        20.0212
trainer/Q2 Predictions Max       -15.0758
trainer/Q2 Predictions Min       -84.694
trainer/Q Targets Mean           -35.2411
trainer/Q Targets Std             20.3429
trainer/Q Targets Max            -15.1934
trainer/Q Targets Min            -87.0894
trainer/Log Pis Mean               1.62138
trainer/Log Pis Std                1.06959
trainer/Log Pis Max                5.07059
trainer/Log Pis Min               -1.86319
trainer/Policy mu Mean             0.00423611
trainer/Policy mu Std              0.754973
trainer/Policy mu Max              2.98631
trainer/Policy mu Min             -2.48567
trainer/Policy log std Mean       -1.87991
trainer/Policy log std Std         0.41991
trainer/Policy log std Max        -0.329626
trainer/Policy log std Min        -2.67633
trainer/Alpha                      0.0628965
trainer/Alpha Loss                -1.04731
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.05166
exploration/Rewards Std            0.918094
exploration/Rewards Max           -0.00432697
exploration/Rewards Min           -8.99527
exploration/Returns Mean        -105.166
exploration/Returns Std           35.7738
exploration/Returns Max          -36.6292
exploration/Returns Min         -134.043
exploration/Actions Mean           0.0315015
exploration/Actions Std            0.237975
exploration/Actions Max            0.99887
exploration/Actions Min           -0.94162
exploration/Num Paths              5
exploration/Average Returns     -105.166
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.450865
evaluation/Rewards Std             0.820966
evaluation/Rewards Max            -0.044548
evaluation/Rewards Min            -8.59007
evaluation/Returns Mean          -45.0865
evaluation/Returns Std            36.5192
evaluation/Returns Max           -15.1948
evaluation/Returns Min          -126.559
evaluation/Actions Mean           -0.004218
evaluation/Actions Std             0.172127
evaluation/Actions Max             0.994375
evaluation/Actions Min            -0.999289
evaluation/Num Paths              15
evaluation/Average Returns       -45.0865
time/data storing (s)              0.00404764
time/evaluation sampling (s)       0.358707
time/exploration sampling (s)      0.163967
time/logging (s)                   0.00490737
time/saving (s)                    0.00218706
time/training (s)                  2.17127
time/epoch (s)                     2.70509
time/total (s)                    92.3351
Epoch                             33
-----------------------------  --------------
2019-04-22 21:57:32.577463 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                  42.6842
trainer/QF2 Loss                  42.5762
trainer/Policy Loss               43.5924
trainer/Q1 Predictions Mean      -42.2311
trainer/Q1 Predictions Std        24.6031
trainer/Q1 Predictions Max       -14.6966
trainer/Q1 Predictions Min      -120.43
trainer/Q2 Predictions Mean      -42.2375
trainer/Q2 Predictions Std        24.5906
trainer/Q2 Predictions Max       -14.6473
trainer/Q2 Predictions Min      -120.443
trainer/Q Targets Mean           -42.044
trainer/Q Targets Std             25.2864
trainer/Q Targets Max             -1.30176
trainer/Q Targets Min           -125.66
trainer/Log Pis Mean               2.11323
trainer/Log Pis Std                1.56134
trainer/Log Pis Max                7.93268
trainer/Log Pis Min               -1.13259
trainer/Policy mu Mean             0.0717853
trainer/Policy mu Std              0.981148
trainer/Policy mu Max              3.17494
trainer/Policy mu Min             -2.98037
trainer/Policy log std Mean       -1.7958
trainer/Policy log std Std         0.541654
trainer/Policy log std Max        -0.381423
trainer/Policy log std Min        -2.75057
trainer/Alpha                      0.0625133
trainer/Alpha Loss                 0.313903
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.850438
exploration/Rewards Std            0.956911
exploration/Rewards Max           -0.012398
exploration/Rewards Min           -8.38525
exploration/Returns Mean         -85.0438
exploration/Returns Std           37.1677
exploration/Returns Max          -32.948
exploration/Returns Min         -128.08
exploration/Actions Mean          -0.00162308
exploration/Actions Std            0.237104
exploration/Actions Max            0.99883
exploration/Actions Min           -0.998552
exploration/Num Paths              5
exploration/Average Returns      -85.0438
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.39755
evaluation/Rewards Std             0.748177
evaluation/Rewards Max            -0.0476248
evaluation/Rewards Min            -9.2124
evaluation/Returns Mean          -39.755
evaluation/Returns Std            38.969
evaluation/Returns Max            -8.87295
evaluation/Returns Min          -123.858
evaluation/Actions Mean           -0.00591492
evaluation/Actions Std             0.16292
evaluation/Actions Max             0.995124
evaluation/Actions Min            -0.996744
evaluation/Num Paths              15
evaluation/Average Returns       -39.755
time/data storing (s)              0.00328052
time/evaluation sampling (s)       0.357949
time/exploration sampling (s)      0.165472
time/logging (s)                   0.00454923
time/saving (s)                    0.00199892
time/training (s)                  2.12141
time/epoch (s)                     2.65466
time/total (s)                    94.9942
Epoch                             34
-----------------------------  --------------
2019-04-22 21:57:35.271956 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   0.46363
trainer/QF2 Loss                   0.418401
trainer/Policy Loss               38.2885
trainer/Q1 Predictions Mean      -37.4623
trainer/Q1 Predictions Std        23.9237
trainer/Q1 Predictions Max       -14.3713
trainer/Q1 Predictions Min      -123.561
trainer/Q2 Predictions Mean      -37.4477
trainer/Q2 Predictions Std        23.9479
trainer/Q2 Predictions Max       -14.3412
trainer/Q2 Predictions Min      -124.101
trainer/Q Targets Mean           -37.6987
trainer/Q Targets Std             23.9114
trainer/Q Targets Max            -14.6732
trainer/Q Targets Min           -120.371
trainer/Log Pis Mean               2.45234
trainer/Log Pis Std                1.83316
trainer/Log Pis Max                9.41859
trainer/Log Pis Min               -4.91505
trainer/Policy mu Mean             0.229562
trainer/Policy mu Std              1.17186
trainer/Policy mu Max              3.40213
trainer/Policy mu Min             -3.15301
trainer/Policy log std Mean       -1.6548
trainer/Policy log std Std         0.605751
trainer/Policy log std Max        -0.365856
trainer/Policy log std Min        -2.69918
trainer/Alpha                      0.0640433
trainer/Alpha Loss                 1.24323
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.652066
exploration/Rewards Std            0.641948
exploration/Rewards Max           -0.0250975
exploration/Rewards Min           -6.4747
exploration/Returns Mean         -65.2066
exploration/Returns Std           32.3133
exploration/Returns Max          -29.2822
exploration/Returns Min         -112.514
exploration/Actions Mean          -0.0149956
exploration/Actions Std            0.213797
exploration/Actions Max            0.953625
exploration/Actions Min           -0.984519
exploration/Num Paths              5
exploration/Average Returns      -65.2066
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.816521
evaluation/Rewards Std             1.24899
evaluation/Rewards Max            -0.0474189
evaluation/Rewards Min           -10.6658
evaluation/Returns Mean          -81.6521
evaluation/Returns Std            41.3412
evaluation/Returns Max           -31.9445
evaluation/Returns Min          -142.172
evaluation/Actions Mean           -0.0060381
evaluation/Actions Std             0.213909
evaluation/Actions Max             0.998843
evaluation/Actions Min            -0.998335
evaluation/Num Paths              15
evaluation/Average Returns       -81.6521
time/data storing (s)              0.00321746
time/evaluation sampling (s)       0.356229
time/exploration sampling (s)      0.159754
time/logging (s)                   0.00469398
time/saving (s)                    0.00198209
time/training (s)                  2.16297
time/epoch (s)                     2.68884
time/total (s)                    97.6877
Epoch                             35
-----------------------------  --------------
2019-04-22 21:57:37.941635 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                   2.2622
trainer/QF2 Loss                   2.23642
trainer/Policy Loss               33.5462
trainer/Q1 Predictions Mean      -32.5489
trainer/Q1 Predictions Std        19.9117
trainer/Q1 Predictions Max       -14.0934
trainer/Q1 Predictions Min       -87.8235
trainer/Q2 Predictions Mean      -32.5331
trainer/Q2 Predictions Std        19.8922
trainer/Q2 Predictions Max       -14.0656
trainer/Q2 Predictions Min       -87.9961
trainer/Q Targets Mean           -32.6509
trainer/Q Targets Std             20.2604
trainer/Q Targets Max             -0.143415
trainer/Q Targets Min            -88.6585
trainer/Log Pis Mean               1.68826
trainer/Log Pis Std                1.52491
trainer/Log Pis Max                7.964
trainer/Log Pis Min               -3.44186
trainer/Policy mu Mean             0.110668
trainer/Policy mu Std              0.847028
trainer/Policy mu Max              2.86735
trainer/Policy mu Min             -3.02616
trainer/Policy log std Mean       -1.82377
trainer/Policy log std Std         0.471858
trainer/Policy log std Max        -0.506992
trainer/Policy log std Min        -2.81545
trainer/Alpha                      0.0644896
trainer/Alpha Loss                -0.854575
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.663403
exploration/Rewards Std            1.09142
exploration/Rewards Max           -0.00337341
exploration/Rewards Min           -9.31915
exploration/Returns Mean         -66.3403
exploration/Returns Std           27.7532
exploration/Returns Max          -28.0186
exploration/Returns Min         -114.214
exploration/Actions Mean          -0.0130665
exploration/Actions Std            0.24628
exploration/Actions Max            0.996872
exploration/Actions Min           -0.999994
exploration/Num Paths              5
exploration/Average Returns      -66.3403
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.867666
evaluation/Rewards Std             1.18228
evaluation/Rewards Max            -0.0304073
evaluation/Rewards Min           -10.5648
evaluation/Returns Mean          -86.7666
evaluation/Returns Std            43.0341
evaluation/Returns Max           -21.8948
evaluation/Returns Min          -143.395
evaluation/Actions Mean            0.0108509
evaluation/Actions Std             0.207834
evaluation/Actions Max             0.99733
evaluation/Actions Min            -0.999762
evaluation/Num Paths              15
evaluation/Average Returns       -86.7666
time/data storing (s)              0.00328083
time/evaluation sampling (s)       0.360093
time/exploration sampling (s)      0.16367
time/logging (s)                   0.00443143
time/saving (s)                    0.00181582
time/training (s)                  2.12983
time/epoch (s)                     2.66312
time/total (s)                   100.356
Epoch                             36
-----------------------------  --------------
2019-04-22 21:57:40.605827 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 37 finished
-----------------------------  ---------------
replay_buffer/size             19200
trainer/QF1 Loss                   0.212075
trainer/QF2 Loss                   0.188232
trainer/Policy Loss               33.8365
trainer/Q1 Predictions Mean      -32.7912
trainer/Q1 Predictions Std        18.9496
trainer/Q1 Predictions Max       -14.0702
trainer/Q1 Predictions Min       -79.8947
trainer/Q2 Predictions Mean      -32.7827
trainer/Q2 Predictions Std        18.9002
trainer/Q2 Predictions Max       -14.012
trainer/Q2 Predictions Min       -79.8195
trainer/Q Targets Mean           -32.9053
trainer/Q Targets Std             19.0148
trainer/Q Targets Max            -14.0264
trainer/Q Targets Min            -80.3505
trainer/Log Pis Mean               2.07588
trainer/Log Pis Std                1.56129
trainer/Log Pis Max                8.5947
trainer/Log Pis Min               -1.50151
trainer/Policy mu Mean            -0.0188747
trainer/Policy mu Std              0.923909
trainer/Policy mu Max              2.98929
trainer/Policy mu Min             -3.08842
trainer/Policy log std Mean       -1.82061
trainer/Policy log std Std         0.504289
trainer/Policy log std Max        -0.370544
trainer/Policy log std Min        -2.78601
trainer/Alpha                      0.062967
trainer/Alpha Loss                 0.209818
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.462597
exploration/Rewards Std            0.578624
exploration/Rewards Max           -0.0214589
exploration/Rewards Min           -5.65717
exploration/Returns Mean         -46.2597
exploration/Returns Std           34.6389
exploration/Returns Max          -20.5096
exploration/Returns Min         -113.462
exploration/Actions Mean           0.00905137
exploration/Actions Std            0.207073
exploration/Actions Max            0.995579
exploration/Actions Min           -0.982798
exploration/Num Paths              5
exploration/Average Returns      -46.2597
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.674012
evaluation/Rewards Std             0.904908
evaluation/Rewards Max            -0.072823
evaluation/Rewards Min            -9.88233
evaluation/Returns Mean          -67.4012
evaluation/Returns Std            48.9101
evaluation/Returns Max           -11.7919
evaluation/Returns Min          -143.215
evaluation/Actions Mean            0.000536167
evaluation/Actions Std             0.177498
evaluation/Actions Max             0.996322
evaluation/Actions Min            -0.998864
evaluation/Num Paths              15
evaluation/Average Returns       -67.4012
time/data storing (s)              0.00334357
time/evaluation sampling (s)       0.352446
time/exploration sampling (s)      0.162196
time/logging (s)                   0.00480973
time/saving (s)                    0.00165378
time/training (s)                  2.13409
time/epoch (s)                     2.65854
time/total (s)                   103.019
Epoch                             37
-----------------------------  ---------------
2019-04-22 21:57:43.324885 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                   0.550332
trainer/QF2 Loss                   0.539088
trainer/Policy Loss               33.5704
trainer/Q1 Predictions Mean      -32.8084
trainer/Q1 Predictions Std        19.3047
trainer/Q1 Predictions Max       -13.7271
trainer/Q1 Predictions Min       -85.1833
trainer/Q2 Predictions Mean      -32.8178
trainer/Q2 Predictions Std        19.2872
trainer/Q2 Predictions Max       -13.6908
trainer/Q2 Predictions Min       -84.6528
trainer/Q Targets Mean           -32.9323
trainer/Q Targets Std             19.2726
trainer/Q Targets Max            -13.778
trainer/Q Targets Min            -84.2647
trainer/Log Pis Mean               1.83636
trainer/Log Pis Std                1.90263
trainer/Log Pis Max                8.873
trainer/Log Pis Min               -2.86212
trainer/Policy mu Mean             0.0949462
trainer/Policy mu Std              0.967046
trainer/Policy mu Max              3.12613
trainer/Policy mu Min             -3.08013
trainer/Policy log std Mean       -1.81051
trainer/Policy log std Std         0.512659
trainer/Policy log std Max        -0.261927
trainer/Policy log std Min        -2.73161
trainer/Alpha                      0.0612175
trainer/Alpha Loss                -0.457102
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.603585
exploration/Rewards Std            1.62543
exploration/Rewards Max           -0.00878325
exploration/Rewards Min          -11.1561
exploration/Returns Mean         -60.3585
exploration/Returns Std           18.3709
exploration/Returns Max          -25.4598
exploration/Returns Min          -77.2561
exploration/Actions Mean          -0.0269872
exploration/Actions Std            0.284221
exploration/Actions Max            0.999481
exploration/Actions Min           -0.999884
exploration/Num Paths              5
exploration/Average Returns      -60.3585
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.481011
evaluation/Rewards Std             0.893905
evaluation/Rewards Max            -0.0132108
evaluation/Rewards Min           -10.2401
evaluation/Returns Mean          -48.1011
evaluation/Returns Std            41.1133
evaluation/Returns Max            -6.89569
evaluation/Returns Min          -139.807
evaluation/Actions Mean           -0.00933605
evaluation/Actions Std             0.17555
evaluation/Actions Max             0.998439
evaluation/Actions Min            -0.997095
evaluation/Num Paths              15
evaluation/Average Returns       -48.1011
time/data storing (s)              0.00326015
time/evaluation sampling (s)       0.384533
time/exploration sampling (s)      0.162818
time/logging (s)                   0.00514187
time/saving (s)                    0.00169209
time/training (s)                  2.15631
time/epoch (s)                     2.71375
time/total (s)                   105.737
Epoch                             38
-----------------------------  --------------
2019-04-22 21:57:45.977704 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                  39.5648
trainer/QF2 Loss                  39.423
trainer/Policy Loss               38.2372
trainer/Q1 Predictions Mean      -37.3224
trainer/Q1 Predictions Std        21.3443
trainer/Q1 Predictions Max       -13.4616
trainer/Q1 Predictions Min      -114.675
trainer/Q2 Predictions Mean      -37.3271
trainer/Q2 Predictions Std        21.3346
trainer/Q2 Predictions Max       -13.5045
trainer/Q2 Predictions Min      -114.861
trainer/Q Targets Mean           -36.8257
trainer/Q Targets Std             21.8216
trainer/Q Targets Max             -0.987515
trainer/Q Targets Min           -116.752
trainer/Log Pis Mean               2.09361
trainer/Log Pis Std                1.42536
trainer/Log Pis Max                6.90858
trainer/Log Pis Min               -3.57534
trainer/Policy mu Mean             0.147045
trainer/Policy mu Std              1.00838
trainer/Policy mu Max              3.35498
trainer/Policy mu Min             -2.85934
trainer/Policy log std Mean       -1.74491
trainer/Policy log std Std         0.510088
trainer/Policy log std Max        -0.323903
trainer/Policy log std Min        -2.73769
trainer/Alpha                      0.0597317
trainer/Alpha Loss                 0.263804
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.397916
exploration/Rewards Std            0.975895
exploration/Rewards Max           -0.00800688
exploration/Rewards Min           -9.42118
exploration/Returns Mean         -39.7916
exploration/Returns Std           15.8003
exploration/Returns Max          -21.9801
exploration/Returns Min          -65.5713
exploration/Actions Mean          -0.00644435
exploration/Actions Std            0.233601
exploration/Actions Max            0.999573
exploration/Actions Min           -0.999931
exploration/Num Paths              5
exploration/Average Returns      -39.7916
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.669067
evaluation/Rewards Std             0.826171
evaluation/Rewards Max            -0.146808
evaluation/Rewards Min            -9.2443
evaluation/Returns Mean          -66.9067
evaluation/Returns Std            32.1132
evaluation/Returns Max           -15.1316
evaluation/Returns Min          -106.722
evaluation/Actions Mean           -0.00846339
evaluation/Actions Std             0.172039
evaluation/Actions Max             0.993127
evaluation/Actions Min            -0.998377
evaluation/Num Paths              15
evaluation/Average Returns       -66.9067
time/data storing (s)              0.00311378
time/evaluation sampling (s)       0.355251
time/exploration sampling (s)      0.160326
time/logging (s)                   0.00477618
time/saving (s)                    0.00197303
time/training (s)                  2.12122
time/epoch (s)                     2.64666
time/total (s)                   108.389
Epoch                             39
-----------------------------  --------------
2019-04-22 21:57:48.671845 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 40 finished
-----------------------------  ---------------
replay_buffer/size             20700
trainer/QF1 Loss                   0.633215
trainer/QF2 Loss                   0.661733
trainer/Policy Loss               37.5926
trainer/Q1 Predictions Mean      -36.6574
trainer/Q1 Predictions Std        20.5172
trainer/Q1 Predictions Max       -13.3213
trainer/Q1 Predictions Min       -86.737
trainer/Q2 Predictions Mean      -36.6095
trainer/Q2 Predictions Std        20.4829
trainer/Q2 Predictions Max       -13.3206
trainer/Q2 Predictions Min       -86.7723
trainer/Q Targets Mean           -37.0437
trainer/Q Targets Std             20.8872
trainer/Q Targets Max            -13.393
trainer/Q Targets Min            -89.5556
trainer/Log Pis Mean               1.88343
trainer/Log Pis Std                1.86629
trainer/Log Pis Max                9.41633
trainer/Log Pis Min               -4.47267
trainer/Policy mu Mean             0.0855408
trainer/Policy mu Std              0.918915
trainer/Policy mu Max              3.11111
trainer/Policy mu Min             -3.28105
trainer/Policy log std Mean       -1.84465
trainer/Policy log std Std         0.521707
trainer/Policy log std Max        -0.357046
trainer/Policy log std Min        -2.70316
trainer/Alpha                      0.0582932
trainer/Alpha Loss                -0.331326
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.643522
exploration/Rewards Std            1.13556
exploration/Rewards Max           -0.0116233
exploration/Rewards Min           -9.50811
exploration/Returns Mean         -64.3522
exploration/Returns Std           26.9131
exploration/Returns Max          -35.6879
exploration/Returns Min         -111.921
exploration/Actions Mean          -0.000956848
exploration/Actions Std            0.273026
exploration/Actions Max            0.999898
exploration/Actions Min           -0.999975
exploration/Num Paths              5
exploration/Average Returns      -64.3522
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.454004
evaluation/Rewards Std             1.02189
evaluation/Rewards Max            -0.0748047
evaluation/Rewards Min           -11.1115
evaluation/Returns Mean          -45.4004
evaluation/Returns Std            32.7995
evaluation/Returns Max           -10.6022
evaluation/Returns Min          -148.909
evaluation/Actions Mean            0.0114326
evaluation/Actions Std             0.187159
evaluation/Actions Max             0.998745
evaluation/Actions Min            -0.999316
evaluation/Num Paths              15
evaluation/Average Returns       -45.4004
time/data storing (s)              0.00303272
time/evaluation sampling (s)       0.354103
time/exploration sampling (s)      0.161689
time/logging (s)                   0.00453888
time/saving (s)                    0.00206165
time/training (s)                  2.16287
time/epoch (s)                     2.68829
time/total (s)                   111.081
Epoch                             40
-----------------------------  ---------------
2019-04-22 21:57:51.330336 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                  26.1155
trainer/QF2 Loss                  26.1042
trainer/Policy Loss               35.0433
trainer/Q1 Predictions Mean      -34.0493
trainer/Q1 Predictions Std        17.9338
trainer/Q1 Predictions Max       -12.9687
trainer/Q1 Predictions Min       -71.9598
trainer/Q2 Predictions Mean      -34.0548
trainer/Q2 Predictions Std        17.928
trainer/Q2 Predictions Max       -13.0154
trainer/Q2 Predictions Min       -72.2658
trainer/Q Targets Mean           -33.7829
trainer/Q Targets Std             19.478
trainer/Q Targets Max             -0.196579
trainer/Q Targets Min            -73.3206
trainer/Log Pis Mean               1.93563
trainer/Log Pis Std                1.43297
trainer/Log Pis Max                7.53071
trainer/Log Pis Min               -2.33317
trainer/Policy mu Mean            -0.0208473
trainer/Policy mu Std              0.926075
trainer/Policy mu Max              3.04879
trainer/Policy mu Min             -3.80849
trainer/Policy log std Mean       -1.8166
trainer/Policy log std Std         0.532104
trainer/Policy log std Max         0.0222943
trainer/Policy log std Min        -2.84357
trainer/Alpha                      0.0564866
trainer/Alpha Loss                -0.184978
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.695174
exploration/Rewards Std            1.0704
exploration/Rewards Max           -0.00285854
exploration/Rewards Min          -10.1046
exploration/Returns Mean         -69.5174
exploration/Returns Std           47.2741
exploration/Returns Max          -24.1177
exploration/Returns Min         -144.755
exploration/Actions Mean          -0.00473562
exploration/Actions Std            0.231443
exploration/Actions Max            0.997207
exploration/Actions Min           -0.999134
exploration/Num Paths              5
exploration/Average Returns      -69.5174
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.814015
evaluation/Rewards Std             1.35487
evaluation/Rewards Max            -0.06315
evaluation/Rewards Min           -10.6308
evaluation/Returns Mean          -81.4015
evaluation/Returns Std            32.7293
evaluation/Returns Max           -43.1543
evaluation/Returns Min          -142.512
evaluation/Actions Mean           -0.00530302
evaluation/Actions Std             0.215185
evaluation/Actions Max             0.998182
evaluation/Actions Min            -0.999274
evaluation/Num Paths              15
evaluation/Average Returns       -81.4015
time/data storing (s)              0.00314672
time/evaluation sampling (s)       0.357686
time/exploration sampling (s)      0.165437
time/logging (s)                   0.00519164
time/saving (s)                    0.00192202
time/training (s)                  2.12017
time/epoch (s)                     2.65355
time/total (s)                   113.739
Epoch                             41
-----------------------------  --------------
2019-04-22 21:57:54.355936 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size             21700
trainer/QF1 Loss                  21.2254
trainer/QF2 Loss                  21.2679
trainer/Policy Loss               33.0656
trainer/Q1 Predictions Mean      -31.7888
trainer/Q1 Predictions Std        20.8411
trainer/Q1 Predictions Max       -12.9946
trainer/Q1 Predictions Min      -114.662
trainer/Q2 Predictions Mean      -31.8033
trainer/Q2 Predictions Std        20.8396
trainer/Q2 Predictions Max       -12.9602
trainer/Q2 Predictions Min      -114.694
trainer/Q Targets Mean           -31.2459
trainer/Q Targets Std             22.0222
trainer/Q Targets Max             -0.262546
trainer/Q Targets Min           -119.282
trainer/Log Pis Mean               1.86989
trainer/Log Pis Std                1.56572
trainer/Log Pis Max                8.69684
trainer/Log Pis Min               -2.17893
trainer/Policy mu Mean             0.0838808
trainer/Policy mu Std              0.761534
trainer/Policy mu Max              3.24811
trainer/Policy mu Min             -3.25957
trainer/Policy log std Mean       -1.99654
trainer/Policy log std Std         0.461061
trainer/Policy log std Max        -0.443965
trainer/Policy log std Min        -2.79382
trainer/Alpha                      0.0582434
trainer/Alpha Loss                -0.36994
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.681322
exploration/Rewards Std            0.954456
exploration/Rewards Max           -0.0191083
exploration/Rewards Min           -8.83861
exploration/Returns Mean         -68.1322
exploration/Returns Std           36.2908
exploration/Returns Max          -25.7676
exploration/Returns Min         -117.583
exploration/Actions Mean          -0.00100719
exploration/Actions Std            0.233215
exploration/Actions Max            0.998292
exploration/Actions Min           -0.999346
exploration/Num Paths              5
exploration/Average Returns      -68.1322
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.630325
evaluation/Rewards Std             0.99397
evaluation/Rewards Max            -0.0316006
evaluation/Rewards Min            -9.8919
evaluation/Returns Mean          -63.0325
evaluation/Returns Std            27.5597
evaluation/Returns Max           -20.9474
evaluation/Returns Min          -113.509
evaluation/Actions Mean           -0.00747951
evaluation/Actions Std             0.185212
evaluation/Actions Max             0.995542
evaluation/Actions Min            -0.999002
evaluation/Num Paths              15
evaluation/Average Returns       -63.0325
time/data storing (s)              0.00315481
time/evaluation sampling (s)       0.355065
time/exploration sampling (s)      0.163461
time/logging (s)                   0.00394879
time/saving (s)                    0.00195843
time/training (s)                  2.49093
time/epoch (s)                     3.01852
time/total (s)                   116.762
Epoch                             42
-----------------------------  --------------
2019-04-22 21:57:57.072374 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 43 finished
-----------------------------  --------------
replay_buffer/size             22200
trainer/QF1 Loss                   2.9732
trainer/QF2 Loss                   3.0126
trainer/Policy Loss               33.8076
trainer/Q1 Predictions Mean      -32.7335
trainer/Q1 Predictions Std        20.779
trainer/Q1 Predictions Max       -12.6323
trainer/Q1 Predictions Min      -118.869
trainer/Q2 Predictions Mean      -32.7079
trainer/Q2 Predictions Std        20.7127
trainer/Q2 Predictions Max       -12.644
trainer/Q2 Predictions Min      -117.979
trainer/Q Targets Mean           -32.8584
trainer/Q Targets Std             21.2671
trainer/Q Targets Max             -0.301163
trainer/Q Targets Min           -122.864
trainer/Log Pis Mean               2.20225
trainer/Log Pis Std                1.5792
trainer/Log Pis Max                7.50853
trainer/Log Pis Min               -0.466243
trainer/Policy mu Mean             0.128266
trainer/Policy mu Std              0.991181
trainer/Policy mu Max              3.25925
trainer/Policy mu Min             -3.07414
trainer/Policy log std Mean       -1.84744
trainer/Policy log std Std         0.560003
trainer/Policy log std Max        -0.418468
trainer/Policy log std Min        -2.822
trainer/Alpha                      0.0581319
trainer/Alpha Loss                 0.575449
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.965914
exploration/Rewards Std            1.1901
exploration/Rewards Max           -0.00853927
exploration/Rewards Min          -10.216
exploration/Returns Mean         -96.5914
exploration/Returns Std           17.3733
exploration/Returns Max          -63.8109
exploration/Returns Min         -114.362
exploration/Actions Mean          -0.00587971
exploration/Actions Std            0.232013
exploration/Actions Max            0.999936
exploration/Actions Min           -0.999823
exploration/Num Paths              5
exploration/Average Returns      -96.5914
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.383202
evaluation/Rewards Std             0.597329
evaluation/Rewards Max            -0.121564
evaluation/Rewards Min            -7.33403
evaluation/Returns Mean          -38.3202
evaluation/Returns Std            16.9164
evaluation/Returns Max           -15.569
evaluation/Returns Min           -63.9628
evaluation/Actions Mean            0.00280021
evaluation/Actions Std             0.164973
evaluation/Actions Max             0.99635
evaluation/Actions Min            -0.993256
evaluation/Num Paths              15
evaluation/Average Returns       -38.3202
time/data storing (s)              0.00454219
time/evaluation sampling (s)       0.351317
time/exploration sampling (s)      0.161324
time/logging (s)                   0.00416082
time/saving (s)                    0.00215628
time/training (s)                  2.1883
time/epoch (s)                     2.7118
time/total (s)                   119.478
Epoch                             43
-----------------------------  --------------
2019-04-22 21:57:59.825004 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             22700
trainer/QF1 Loss                   0.415368
trainer/QF2 Loss                   0.376111
trainer/Policy Loss               34.132
trainer/Q1 Predictions Mean      -33.1715
trainer/Q1 Predictions Std        20.9177
trainer/Q1 Predictions Max       -12.999
trainer/Q1 Predictions Min       -95.4973
trainer/Q2 Predictions Mean      -33.1603
trainer/Q2 Predictions Std        20.9214
trainer/Q2 Predictions Max       -12.9035
trainer/Q2 Predictions Min       -96.1618
trainer/Q Targets Mean           -33.3662
trainer/Q Targets Std             21.0401
trainer/Q Targets Max            -12.6818
trainer/Q Targets Min            -98.8912
trainer/Log Pis Mean               2.15773
trainer/Log Pis Std                1.59105
trainer/Log Pis Max                9.54049
trainer/Log Pis Min               -0.683417
trainer/Policy mu Mean             0.131173
trainer/Policy mu Std              0.904275
trainer/Policy mu Max              3.40935
trainer/Policy mu Min             -3.14318
trainer/Policy log std Mean       -1.9182
trainer/Policy log std Std         0.554905
trainer/Policy log std Max        -0.191644
trainer/Policy log std Min        -2.90909
trainer/Alpha                      0.0585762
trainer/Alpha Loss                 0.447569
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.445277
exploration/Rewards Std            0.73939
exploration/Rewards Max           -0.0224905
exploration/Rewards Min           -6.90379
exploration/Returns Mean         -44.5277
exploration/Returns Std            6.75418
exploration/Returns Max          -31.7834
exploration/Returns Min          -50.5855
exploration/Actions Mean          -0.0326916
exploration/Actions Std            0.239167
exploration/Actions Max            0.988966
exploration/Actions Min           -0.999065
exploration/Num Paths              5
exploration/Average Returns      -44.5277
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.516008
evaluation/Rewards Std             0.715568
evaluation/Rewards Max            -0.160192
evaluation/Rewards Min            -9.14106
evaluation/Returns Mean          -51.6008
evaluation/Returns Std            28.1183
evaluation/Returns Max           -21.3026
evaluation/Returns Min          -110.138
evaluation/Actions Mean           -0.00642495
evaluation/Actions Std             0.158444
evaluation/Actions Max             0.995942
evaluation/Actions Min            -0.997054
evaluation/Num Paths              15
evaluation/Average Returns       -51.6008
time/data storing (s)              0.00311714
time/evaluation sampling (s)       0.362293
time/exploration sampling (s)      0.175945
time/logging (s)                   0.00503689
time/saving (s)                    0.00203554
time/training (s)                  2.19953
time/epoch (s)                     2.74795
time/total (s)                   122.23
Epoch                             44
-----------------------------  --------------
2019-04-22 21:58:02.637908 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                   0.279424
trainer/QF2 Loss                   0.229211
trainer/Policy Loss               32.7257
trainer/Q1 Predictions Mean      -31.7028
trainer/Q1 Predictions Std        18.6574
trainer/Q1 Predictions Max       -12.4773
trainer/Q1 Predictions Min       -72.6355
trainer/Q2 Predictions Mean      -31.7244
trainer/Q2 Predictions Std        18.6607
trainer/Q2 Predictions Max       -12.4668
trainer/Q2 Predictions Min       -72.6619
trainer/Q Targets Mean           -31.9595
trainer/Q Targets Std             18.8252
trainer/Q Targets Max            -12.5069
trainer/Q Targets Min            -73.2135
trainer/Log Pis Mean               1.76472
trainer/Log Pis Std                1.07526
trainer/Log Pis Max                6.43116
trainer/Log Pis Min               -1.02394
trainer/Policy mu Mean             0.0429119
trainer/Policy mu Std              0.822246
trainer/Policy mu Max              2.76366
trainer/Policy mu Min             -3.08373
trainer/Policy log std Mean       -1.82961
trainer/Policy log std Std         0.496514
trainer/Policy log std Max        -0.362124
trainer/Policy log std Min        -2.76393
trainer/Alpha                      0.0603308
trainer/Alpha Loss                -0.660612
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.671437
exploration/Rewards Std            0.943413
exploration/Rewards Max           -0.0149709
exploration/Rewards Min          -10.2327
exploration/Returns Mean         -67.1437
exploration/Returns Std           39.4562
exploration/Returns Max          -18.4588
exploration/Returns Min         -104.379
exploration/Actions Mean           0.00832162
exploration/Actions Std            0.208269
exploration/Actions Max            0.999835
exploration/Actions Min           -0.974086
exploration/Num Paths              5
exploration/Average Returns      -67.1437
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.411944
evaluation/Rewards Std             0.69253
evaluation/Rewards Max            -0.0303244
evaluation/Rewards Min            -7.90391
evaluation/Returns Mean          -41.1944
evaluation/Returns Std            31.0066
evaluation/Returns Max           -12.9411
evaluation/Returns Min          -115.181
evaluation/Actions Mean            0.00667061
evaluation/Actions Std             0.171994
evaluation/Actions Max             0.996454
evaluation/Actions Min            -0.995257
evaluation/Num Paths              15
evaluation/Average Returns       -41.1944
time/data storing (s)              0.00374077
time/evaluation sampling (s)       0.360183
time/exploration sampling (s)      0.211149
time/logging (s)                   0.00501229
time/saving (s)                    0.00214679
time/training (s)                  2.22509
time/epoch (s)                     2.80732
time/total (s)                   125.042
Epoch                             45
-----------------------------  --------------
2019-04-22 21:58:05.262719 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                   0.737224
trainer/QF2 Loss                   0.77152
trainer/Policy Loss               32.5554
trainer/Q1 Predictions Mean      -31.4892
trainer/Q1 Predictions Std        18.9421
trainer/Q1 Predictions Max       -12.2984
trainer/Q1 Predictions Min       -78.4648
trainer/Q2 Predictions Mean      -31.478
trainer/Q2 Predictions Std        18.9423
trainer/Q2 Predictions Max       -12.247
trainer/Q2 Predictions Min       -78.558
trainer/Q Targets Mean           -31.7065
trainer/Q Targets Std             19.0585
trainer/Q Targets Max            -12.3508
trainer/Q Targets Min            -72.2576
trainer/Log Pis Mean               1.96074
trainer/Log Pis Std                1.61243
trainer/Log Pis Max                8.20445
trainer/Log Pis Min               -2.49339
trainer/Policy mu Mean            -0.0569174
trainer/Policy mu Std              0.904986
trainer/Policy mu Max              3.03162
trainer/Policy mu Min             -3.03497
trainer/Policy log std Mean       -1.87064
trainer/Policy log std Std         0.535378
trainer/Policy log std Max        -0.395608
trainer/Policy log std Min        -2.76548
trainer/Alpha                      0.0589291
trainer/Alpha Loss                -0.111157
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.65806
exploration/Rewards Std            1.13176
exploration/Rewards Max           -0.0116738
exploration/Rewards Min           -9.28323
exploration/Returns Mean         -65.806
exploration/Returns Std           40.3593
exploration/Returns Max          -17.6219
exploration/Returns Min         -137.04
exploration/Actions Mean           0.0188149
exploration/Actions Std            0.247786
exploration/Actions Max            0.999335
exploration/Actions Min           -0.999943
exploration/Num Paths              5
exploration/Average Returns      -65.806
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.612404
evaluation/Rewards Std             0.960422
evaluation/Rewards Max            -0.0172462
evaluation/Rewards Min            -9.83739
evaluation/Returns Mean          -61.2404
evaluation/Returns Std            41.2898
evaluation/Returns Max           -13.5326
evaluation/Returns Min          -146.75
evaluation/Actions Mean            0.00296114
evaluation/Actions Std             0.180589
evaluation/Actions Max             0.99822
evaluation/Actions Min            -0.998008
evaluation/Num Paths              15
evaluation/Average Returns       -61.2404
time/data storing (s)              0.0032367
time/evaluation sampling (s)       0.343597
time/exploration sampling (s)      0.151449
time/logging (s)                   0.00438133
time/saving (s)                    0.00199417
time/training (s)                  2.11294
time/epoch (s)                     2.6176
time/total (s)                   127.665
Epoch                             46
-----------------------------  --------------
2019-04-22 21:58:07.907116 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size             24200
trainer/QF1 Loss                   4.04265
trainer/QF2 Loss                   3.9794
trainer/Policy Loss               31.0406
trainer/Q1 Predictions Mean      -29.9946
trainer/Q1 Predictions Std        20.3609
trainer/Q1 Predictions Max       -12.2092
trainer/Q1 Predictions Min      -114.593
trainer/Q2 Predictions Mean      -29.9845
trainer/Q2 Predictions Std        20.3814
trainer/Q2 Predictions Max       -12.1446
trainer/Q2 Predictions Min      -114.226
trainer/Q Targets Mean           -29.9229
trainer/Q Targets Std             20.798
trainer/Q Targets Max             -0.22196
trainer/Q Targets Min           -116.82
trainer/Log Pis Mean               1.84205
trainer/Log Pis Std                1.56907
trainer/Log Pis Max                6.87273
trainer/Log Pis Min               -2.93753
trainer/Policy mu Mean             0.0603457
trainer/Policy mu Std              0.843558
trainer/Policy mu Max              3.434
trainer/Policy mu Min             -3.12727
trainer/Policy log std Mean       -1.96297
trainer/Policy log std Std         0.510017
trainer/Policy log std Max        -0.561636
trainer/Policy log std Min        -2.78069
trainer/Alpha                      0.0591526
trainer/Alpha Loss                -0.446647
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.81771
exploration/Rewards Std            1.03694
exploration/Rewards Max           -0.013894
exploration/Rewards Min           -9.41849
exploration/Returns Mean         -81.771
exploration/Returns Std           40.9028
exploration/Returns Max          -18.9326
exploration/Returns Min         -126.089
exploration/Actions Mean           0.020507
exploration/Actions Std            0.225405
exploration/Actions Max            0.998366
exploration/Actions Min           -0.999573
exploration/Num Paths              5
exploration/Average Returns      -81.771
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.489161
evaluation/Rewards Std             1.02639
evaluation/Rewards Max            -0.0562215
evaluation/Rewards Min           -10.6691
evaluation/Returns Mean          -48.9161
evaluation/Returns Std            40.0228
evaluation/Returns Max            -7.34495
evaluation/Returns Min          -122.963
evaluation/Actions Mean           -0.00963594
evaluation/Actions Std             0.180218
evaluation/Actions Max             0.996823
evaluation/Actions Min            -0.999755
evaluation/Num Paths              15
evaluation/Average Returns       -48.9161
time/data storing (s)              0.00365021
time/evaluation sampling (s)       0.348421
time/exploration sampling (s)      0.15747
time/logging (s)                   0.00386661
time/saving (s)                    0.00194868
time/training (s)                  2.12278
time/epoch (s)                     2.63814
time/total (s)                   130.307
Epoch                             47
-----------------------------  --------------
2019-04-22 21:58:10.890599 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                   2.92899
trainer/QF2 Loss                   2.8365
trainer/Policy Loss               32.6984
trainer/Q1 Predictions Mean      -31.3544
trainer/Q1 Predictions Std        21.7443
trainer/Q1 Predictions Max       -12.1873
trainer/Q1 Predictions Min      -112.914
trainer/Q2 Predictions Mean      -31.3934
trainer/Q2 Predictions Std        21.7486
trainer/Q2 Predictions Max       -12.1986
trainer/Q2 Predictions Min      -112.97
trainer/Q Targets Mean           -31.6825
trainer/Q Targets Std             22.439
trainer/Q Targets Max             -0.355165
trainer/Q Targets Min           -116.794
trainer/Log Pis Mean               2.28701
trainer/Log Pis Std                1.7303
trainer/Log Pis Max                9.27058
trainer/Log Pis Min               -1.68545
trainer/Policy mu Mean            -0.0835173
trainer/Policy mu Std              1.0048
trainer/Policy mu Max              3.33093
trainer/Policy mu Min             -3.38887
trainer/Policy log std Mean       -1.85687
trainer/Policy log std Std         0.580571
trainer/Policy log std Max        -0.38274
trainer/Policy log std Min        -2.80552
trainer/Alpha                      0.0574656
trainer/Alpha Loss                 0.819889
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.989604
exploration/Rewards Std            0.969373
exploration/Rewards Max           -0.0281387
exploration/Rewards Min          -10.8064
exploration/Returns Mean         -98.9604
exploration/Returns Std           38.9982
exploration/Returns Max          -25.2468
exploration/Returns Min         -141.675
exploration/Actions Mean           0.0180774
exploration/Actions Std            0.245352
exploration/Actions Max            0.99961
exploration/Actions Min           -0.99828
exploration/Num Paths              5
exploration/Average Returns      -98.9604
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.704827
evaluation/Rewards Std             1.05688
evaluation/Rewards Max            -0.0544117
evaluation/Rewards Min            -9.94142
evaluation/Returns Mean          -70.4827
evaluation/Returns Std            45.0631
evaluation/Returns Max           -11.5097
evaluation/Returns Min          -139.128
evaluation/Actions Mean           -0.0084076
evaluation/Actions Std             0.200434
evaluation/Actions Max             0.997525
evaluation/Actions Min            -0.998723
evaluation/Num Paths              15
evaluation/Average Returns       -70.4827
time/data storing (s)              0.0032047
time/evaluation sampling (s)       0.354576
time/exploration sampling (s)      0.182358
time/logging (s)                   0.00493982
time/saving (s)                    0.00202828
time/training (s)                  2.43171
time/epoch (s)                     2.97882
time/total (s)                   133.29
Epoch                             48
-----------------------------  --------------
2019-04-22 21:58:13.662917 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                   1.61273
trainer/QF2 Loss                   1.58888
trainer/Policy Loss               30.752
trainer/Q1 Predictions Mean      -29.2425
trainer/Q1 Predictions Std        17.3518
trainer/Q1 Predictions Max       -12.0928
trainer/Q1 Predictions Min       -61.3825
trainer/Q2 Predictions Mean      -29.2267
trainer/Q2 Predictions Std        17.3727
trainer/Q2 Predictions Max       -12.0458
trainer/Q2 Predictions Min       -61.5777
trainer/Q Targets Mean           -29.3254
trainer/Q Targets Std             17.6747
trainer/Q Targets Max             -0.438162
trainer/Q Targets Min            -61.4616
trainer/Log Pis Mean               1.98539
trainer/Log Pis Std                1.1845
trainer/Log Pis Max                4.62988
trainer/Log Pis Min               -1.64592
trainer/Policy mu Mean             0.0413976
trainer/Policy mu Std              0.695899
trainer/Policy mu Max              2.85863
trainer/Policy mu Min             -2.86142
trainer/Policy log std Mean       -2.05455
trainer/Policy log std Std         0.513257
trainer/Policy log std Max        -0.664315
trainer/Policy log std Min        -2.82847
trainer/Alpha                      0.0583526
trainer/Alpha Loss                -0.0415164
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.769103
exploration/Rewards Std            1.12733
exploration/Rewards Max           -0.0138792
exploration/Rewards Min           -9.57201
exploration/Returns Mean         -76.9103
exploration/Returns Std           38.2534
exploration/Returns Max          -31.7665
exploration/Returns Min         -138.135
exploration/Actions Mean           0.0029414
exploration/Actions Std            0.240337
exploration/Actions Max            0.998802
exploration/Actions Min           -0.999732
exploration/Num Paths              5
exploration/Average Returns      -76.9103
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.440235
evaluation/Rewards Std             0.930918
evaluation/Rewards Max            -0.0353858
evaluation/Rewards Min            -8.90914
evaluation/Returns Mean          -44.0235
evaluation/Returns Std            31.9959
evaluation/Returns Max           -17.3414
evaluation/Returns Min          -134.777
evaluation/Actions Mean           -0.0119637
evaluation/Actions Std             0.181032
evaluation/Actions Max             0.997343
evaluation/Actions Min            -0.999575
evaluation/Num Paths              15
evaluation/Average Returns       -44.0235
time/data storing (s)              0.00303305
time/evaluation sampling (s)       0.373846
time/exploration sampling (s)      0.166335
time/logging (s)                   0.00447373
time/saving (s)                    0.00208445
time/training (s)                  2.21621
time/epoch (s)                     2.76598
time/total (s)                   136.061
Epoch                             49
-----------------------------  --------------
2019-04-22 21:58:16.335272 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             25700
trainer/QF1 Loss                   0.425251
trainer/QF2 Loss                   0.433742
trainer/Policy Loss               30.5031
trainer/Q1 Predictions Mean      -29.4835
trainer/Q1 Predictions Std        18.0457
trainer/Q1 Predictions Max       -11.7311
trainer/Q1 Predictions Min       -67.7529
trainer/Q2 Predictions Mean      -29.5028
trainer/Q2 Predictions Std        18.043
trainer/Q2 Predictions Max       -11.7443
trainer/Q2 Predictions Min       -67.1871
trainer/Q Targets Mean           -29.8271
trainer/Q Targets Std             18.2222
trainer/Q Targets Max            -11.8159
trainer/Q Targets Min            -67.4712
trainer/Log Pis Mean               1.5605
trainer/Log Pis Std                1.41785
trainer/Log Pis Max                5.94066
trainer/Log Pis Min               -5.34805
trainer/Policy mu Mean            -0.180429
trainer/Policy mu Std              0.649446
trainer/Policy mu Max              2.59796
trainer/Policy mu Min             -2.9518
trainer/Policy log std Mean       -1.89347
trainer/Policy log std Std         0.444901
trainer/Policy log std Max        -0.403849
trainer/Policy log std Min        -2.47806
trainer/Alpha                      0.0581409
trainer/Alpha Loss                -1.25019
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.832772
exploration/Rewards Std            0.861024
exploration/Rewards Max           -0.0114326
exploration/Rewards Min           -8.49552
exploration/Returns Mean         -83.2772
exploration/Returns Std           39.6021
exploration/Returns Max          -43.5512
exploration/Returns Min         -149.861
exploration/Actions Mean           0.0010947
exploration/Actions Std            0.26753
exploration/Actions Max            0.999308
exploration/Actions Min           -0.999055
exploration/Num Paths              5
exploration/Average Returns      -83.2772
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.05973
evaluation/Rewards Std             0.764775
evaluation/Rewards Max            -0.0751088
evaluation/Rewards Min            -8.72699
evaluation/Returns Mean         -105.973
evaluation/Returns Std            52.9338
evaluation/Returns Max           -29.8972
evaluation/Returns Min          -176.031
evaluation/Actions Mean           -0.0109253
evaluation/Actions Std             0.163379
evaluation/Actions Max             0.99374
evaluation/Actions Min            -0.996937
evaluation/Num Paths              15
evaluation/Average Returns      -105.973
time/data storing (s)              0.00344529
time/evaluation sampling (s)       0.354207
time/exploration sampling (s)      0.165424
time/logging (s)                   0.0039618
time/saving (s)                    0.00224092
time/training (s)                  2.13652
time/epoch (s)                     2.6658
time/total (s)                   138.731
Epoch                             50
-----------------------------  --------------
2019-04-22 21:58:19.189429 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             26200
trainer/QF1 Loss                   0.464154
trainer/QF2 Loss                   0.406769
trainer/Policy Loss               31.6692
trainer/Q1 Predictions Mean      -30.576
trainer/Q1 Predictions Std        19.6341
trainer/Q1 Predictions Max       -11.938
trainer/Q1 Predictions Min      -101.227
trainer/Q2 Predictions Mean      -30.5593
trainer/Q2 Predictions Std        19.6698
trainer/Q2 Predictions Max       -11.8624
trainer/Q2 Predictions Min      -101.136
trainer/Q Targets Mean           -30.8221
trainer/Q Targets Std             19.9177
trainer/Q Targets Max            -11.7884
trainer/Q Targets Min           -104.672
trainer/Log Pis Mean               1.90846
trainer/Log Pis Std                1.67208
trainer/Log Pis Max                7.35416
trainer/Log Pis Min               -5.40569
trainer/Policy mu Mean             0.144875
trainer/Policy mu Std              0.781218
trainer/Policy mu Max              3.33598
trainer/Policy mu Min             -2.87724
trainer/Policy log std Mean       -2.04093
trainer/Policy log std Std         0.499893
trainer/Policy log std Max        -0.345849
trainer/Policy log std Min        -2.78995
trainer/Alpha                      0.0576982
trainer/Alpha Loss                -0.261149
exploration/num steps total    26200
exploration/num paths total      262
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.621728
exploration/Rewards Std            0.669561
exploration/Rewards Max           -0.0186386
exploration/Rewards Min           -7.32394
exploration/Returns Mean         -62.1728
exploration/Returns Std           33.511
exploration/Returns Max          -14.1776
exploration/Returns Min         -100.778
exploration/Actions Mean           0.00205436
exploration/Actions Std            0.199151
exploration/Actions Max            0.983663
exploration/Actions Min           -0.999897
exploration/Num Paths              5
exploration/Average Returns      -62.1728
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.606392
evaluation/Rewards Std             1.1065
evaluation/Rewards Max            -0.0148572
evaluation/Rewards Min           -10.416
evaluation/Returns Mean          -60.6392
evaluation/Returns Std            33.7104
evaluation/Returns Max           -21.1035
evaluation/Returns Min          -128.9
evaluation/Actions Mean           -0.00278047
evaluation/Actions Std             0.192833
evaluation/Actions Max             0.997106
evaluation/Actions Min            -0.999326
evaluation/Num Paths              15
evaluation/Average Returns       -60.6392
time/data storing (s)              0.00308487
time/evaluation sampling (s)       0.381133
time/exploration sampling (s)      0.202305
time/logging (s)                   0.00584052
time/saving (s)                    0.00220563
time/training (s)                  2.25597
time/epoch (s)                     2.85054
time/total (s)                   141.586
Epoch                             51
-----------------------------  --------------
2019-04-22 21:58:21.893850 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             26700
trainer/QF1 Loss                   3.80857
trainer/QF2 Loss                   3.8212
trainer/Policy Loss               24.8249
trainer/Q1 Predictions Mean      -23.4495
trainer/Q1 Predictions Std        15.8578
trainer/Q1 Predictions Max       -11.5742
trainer/Q1 Predictions Min       -72.9823
trainer/Q2 Predictions Mean      -23.4755
trainer/Q2 Predictions Std        15.8251
trainer/Q2 Predictions Max       -11.5949
trainer/Q2 Predictions Min       -73.0549
trainer/Q Targets Mean           -23.3941
trainer/Q Targets Std             16.1754
trainer/Q Targets Max             -0.247128
trainer/Q Targets Min            -72.9134
trainer/Log Pis Mean               1.79549
trainer/Log Pis Std                1.26056
trainer/Log Pis Max                8.99989
trainer/Log Pis Min               -2.40339
trainer/Policy mu Mean             0.0386152
trainer/Policy mu Std              0.677697
trainer/Policy mu Max              2.90946
trainer/Policy mu Min             -2.55433
trainer/Policy log std Mean       -1.94311
trainer/Policy log std Std         0.483846
trainer/Policy log std Max        -0.454112
trainer/Policy log std Min        -2.72922
trainer/Alpha                      0.0577558
trainer/Alpha Loss                -0.583141
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.560491
exploration/Rewards Std            1.13532
exploration/Rewards Max           -0.00298215
exploration/Rewards Min          -10.3603
exploration/Returns Mean         -56.0491
exploration/Returns Std           42.7684
exploration/Returns Max          -19.6286
exploration/Returns Min         -134.964
exploration/Actions Mean          -0.0262375
exploration/Actions Std            0.250212
exploration/Actions Max            0.998142
exploration/Actions Min           -0.999777
exploration/Num Paths              5
exploration/Average Returns      -56.0491
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.541705
evaluation/Rewards Std             0.989107
evaluation/Rewards Max            -0.0432686
evaluation/Rewards Min           -10.1986
evaluation/Returns Mean          -54.1705
evaluation/Returns Std            35.9062
evaluation/Returns Max            -6.66307
evaluation/Returns Min          -120.121
evaluation/Actions Mean            0.00502418
evaluation/Actions Std             0.180661
evaluation/Actions Max             0.996311
evaluation/Actions Min            -0.999771
evaluation/Num Paths              15
evaluation/Average Returns       -54.1705
time/data storing (s)              0.00322662
time/evaluation sampling (s)       0.34913
time/exploration sampling (s)      0.16394
time/logging (s)                   0.00510256
time/saving (s)                    0.00197059
time/training (s)                  2.17303
time/epoch (s)                     2.6964
time/total (s)                   144.288
Epoch                             52
-----------------------------  --------------
2019-04-22 21:58:24.748308 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             27200
trainer/QF1 Loss                   2.11909
trainer/QF2 Loss                   2.14667
trainer/Policy Loss               31.6923
trainer/Q1 Predictions Mean      -30.2582
trainer/Q1 Predictions Std        18.7084
trainer/Q1 Predictions Max       -11.6664
trainer/Q1 Predictions Min      -105.65
trainer/Q2 Predictions Mean      -30.2373
trainer/Q2 Predictions Std        18.6799
trainer/Q2 Predictions Max       -11.5777
trainer/Q2 Predictions Min      -105.118
trainer/Q Targets Mean           -30.4226
trainer/Q Targets Std             19.1056
trainer/Q Targets Max             -0.589703
trainer/Q Targets Min           -108.847
trainer/Log Pis Mean               2.19125
trainer/Log Pis Std                1.19672
trainer/Log Pis Max                5.6669
trainer/Log Pis Min               -0.965564
trainer/Policy mu Mean             0.107136
trainer/Policy mu Std              0.888605
trainer/Policy mu Max              3.36577
trainer/Policy mu Min             -3.37616
trainer/Policy log std Mean       -1.93388
trainer/Policy log std Std         0.56703
trainer/Policy log std Max        -0.344449
trainer/Policy log std Min        -2.74873
trainer/Alpha                      0.0603132
trainer/Alpha Loss                 0.537104
exploration/num steps total    27200
exploration/num paths total      272
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.82639
exploration/Rewards Std            1.10729
exploration/Rewards Max           -0.014583
exploration/Rewards Min          -10.1874
exploration/Returns Mean         -82.639
exploration/Returns Std           36.7501
exploration/Returns Max          -20.1576
exploration/Returns Min         -124.892
exploration/Actions Mean           0.0343127
exploration/Actions Std            0.223781
exploration/Actions Max            0.998976
exploration/Actions Min           -0.738186
exploration/Num Paths              5
exploration/Average Returns      -82.639
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.504564
evaluation/Rewards Std             0.974424
evaluation/Rewards Max            -0.0638664
evaluation/Rewards Min           -10.2157
evaluation/Returns Mean          -50.4564
evaluation/Returns Std            34.4221
evaluation/Returns Max            -9.69887
evaluation/Returns Min          -105.093
evaluation/Actions Mean            0.00642356
evaluation/Actions Std             0.182877
evaluation/Actions Max             0.998151
evaluation/Actions Min            -0.999624
evaluation/Num Paths              15
evaluation/Average Returns       -50.4564
time/data storing (s)              0.00313483
time/evaluation sampling (s)       0.37246
time/exploration sampling (s)      0.165349
time/logging (s)                   0.00500299
time/saving (s)                    0.00211867
time/training (s)                  2.3008
time/epoch (s)                     2.84886
time/total (s)                   147.141
Epoch                             53
-----------------------------  --------------
2019-04-22 21:58:27.401754 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 54 finished
-----------------------------  ---------------
replay_buffer/size             27700
trainer/QF1 Loss                   8.25907
trainer/QF2 Loss                   8.18771
trainer/Policy Loss               29.9983
trainer/Q1 Predictions Mean      -28.7542
trainer/Q1 Predictions Std        18.7857
trainer/Q1 Predictions Max       -11.617
trainer/Q1 Predictions Min       -79.6432
trainer/Q2 Predictions Mean      -28.7107
trainer/Q2 Predictions Std        18.7827
trainer/Q2 Predictions Max       -11.5289
trainer/Q2 Predictions Min       -79.3845
trainer/Q Targets Mean           -28.6229
trainer/Q Targets Std             19.3872
trainer/Q Targets Max             -0.84643
trainer/Q Targets Min            -81.4778
trainer/Log Pis Mean               2.08674
trainer/Log Pis Std                1.17959
trainer/Log Pis Max                7.00394
trainer/Log Pis Min               -1.23685
trainer/Policy mu Mean             0.106006
trainer/Policy mu Std              0.858291
trainer/Policy mu Max              3.07996
trainer/Policy mu Min             -3.0512
trainer/Policy log std Mean       -1.99571
trainer/Policy log std Std         0.52938
trainer/Policy log std Max        -0.339483
trainer/Policy log std Min        -2.56598
trainer/Alpha                      0.0598794
trainer/Alpha Loss                 0.244216
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.412854
exploration/Rewards Std            0.647337
exploration/Rewards Max           -0.00963143
exploration/Rewards Min           -6.54301
exploration/Returns Mean         -41.2854
exploration/Returns Std           32.2527
exploration/Returns Max          -17.8657
exploration/Returns Min         -104.662
exploration/Actions Mean          -0.0133588
exploration/Actions Std            0.199119
exploration/Actions Max            0.995667
exploration/Actions Min           -0.996563
exploration/Num Paths              5
exploration/Average Returns      -41.2854
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.443989
evaluation/Rewards Std             0.95052
evaluation/Rewards Max            -0.0744215
evaluation/Rewards Min            -9.63173
evaluation/Returns Mean          -44.3989
evaluation/Returns Std            34.0025
evaluation/Returns Max           -12.3336
evaluation/Returns Min          -135.363
evaluation/Actions Mean           -9.76003e-05
evaluation/Actions Std             0.179026
evaluation/Actions Max             0.998183
evaluation/Actions Min            -0.997647
evaluation/Num Paths              15
evaluation/Average Returns       -44.3989
time/data storing (s)              0.00366196
time/evaluation sampling (s)       0.350677
time/exploration sampling (s)      0.155562
time/logging (s)                   0.00497361
time/saving (s)                    0.00199334
time/training (s)                  2.13043
time/epoch (s)                     2.6473
time/total (s)                   149.793
Epoch                             54
-----------------------------  ---------------
2019-04-22 21:58:30.391503 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             28200
trainer/QF1 Loss                   2.39408
trainer/QF2 Loss                   2.40884
trainer/Policy Loss               28.8816
trainer/Q1 Predictions Mean      -27.583
trainer/Q1 Predictions Std        18.2762
trainer/Q1 Predictions Max       -11.3711
trainer/Q1 Predictions Min       -79.4785
trainer/Q2 Predictions Mean      -27.5753
trainer/Q2 Predictions Std        18.2617
trainer/Q2 Predictions Max       -11.3579
trainer/Q2 Predictions Min       -79.3134
trainer/Q Targets Mean           -27.9785
trainer/Q Targets Std             18.8986
trainer/Q Targets Max             -0.190261
trainer/Q Targets Min            -81.4692
trainer/Log Pis Mean               2.04196
trainer/Log Pis Std                1.69777
trainer/Log Pis Max               10.9589
trainer/Log Pis Min               -2.38195
trainer/Policy mu Mean             0.100294
trainer/Policy mu Std              1.00018
trainer/Policy mu Max              3.20437
trainer/Policy mu Min             -4.15681
trainer/Policy log std Mean       -1.89261
trainer/Policy log std Std         0.537135
trainer/Policy log std Max        -0.0789215
trainer/Policy log std Min        -2.50517
trainer/Alpha                      0.0602377
trainer/Alpha Loss                 0.117888
exploration/num steps total    28200
exploration/num paths total      282
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.493299
exploration/Rewards Std            1.01764
exploration/Rewards Max           -0.00729138
exploration/Rewards Min           -9.16033
exploration/Returns Mean         -49.3299
exploration/Returns Std           11.5934
exploration/Returns Max          -29.4285
exploration/Returns Min          -60.3155
exploration/Actions Mean          -0.00146622
exploration/Actions Std            0.255634
exploration/Actions Max            0.99758
exploration/Actions Min           -0.999956
exploration/Num Paths              5
exploration/Average Returns      -49.3299
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.54957
evaluation/Rewards Std             1.01788
evaluation/Rewards Max            -0.0209247
evaluation/Rewards Min           -10.7456
evaluation/Returns Mean          -54.957
evaluation/Returns Std            34.6485
evaluation/Returns Max           -15.5601
evaluation/Returns Min          -129.587
evaluation/Actions Mean            0.00261399
evaluation/Actions Std             0.190345
evaluation/Actions Max             0.997505
evaluation/Actions Min            -0.999824
evaluation/Num Paths              15
evaluation/Average Returns       -54.957
time/data storing (s)              0.00344846
time/evaluation sampling (s)       0.392682
time/exploration sampling (s)      0.254306
time/logging (s)                   0.00476297
time/saving (s)                    0.00194044
time/training (s)                  2.32651
time/epoch (s)                     2.98365
time/total (s)                   152.781
Epoch                             55
-----------------------------  --------------
2019-04-22 21:58:33.316623 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             28700
trainer/QF1 Loss                  25.8169
trainer/QF2 Loss                  25.9438
trainer/Policy Loss               29.8133
trainer/Q1 Predictions Mean      -28.4516
trainer/Q1 Predictions Std        18.4688
trainer/Q1 Predictions Max       -11.4869
trainer/Q1 Predictions Min       -62.2581
trainer/Q2 Predictions Mean      -28.4701
trainer/Q2 Predictions Std        18.4719
trainer/Q2 Predictions Max       -11.365
trainer/Q2 Predictions Min       -62.1655
trainer/Q Targets Mean           -28.1841
trainer/Q Targets Std             18.5718
trainer/Q Targets Max             -0.934834
trainer/Q Targets Min            -62.4767
trainer/Log Pis Mean               1.86206
trainer/Log Pis Std                1.20629
trainer/Log Pis Max                5.81846
trainer/Log Pis Min               -1.48554
trainer/Policy mu Mean             0.0941844
trainer/Policy mu Std              0.747256
trainer/Policy mu Max              3.11021
trainer/Policy mu Min             -2.78624
trainer/Policy log std Mean       -1.9658
trainer/Policy log std Std         0.487555
trainer/Policy log std Max        -0.564004
trainer/Policy log std Min        -2.5267
trainer/Alpha                      0.0609041
trainer/Alpha Loss                -0.385986
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.595663
exploration/Rewards Std            1.00195
exploration/Rewards Max           -0.016442
exploration/Rewards Min           -9.4297
exploration/Returns Mean         -59.5663
exploration/Returns Std           28.1941
exploration/Returns Max          -36.4344
exploration/Returns Min         -112.902
exploration/Actions Mean          -0.0198005
exploration/Actions Std            0.235575
exploration/Actions Max            0.994105
exploration/Actions Min           -0.999509
exploration/Num Paths              5
exploration/Average Returns      -59.5663
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.471462
evaluation/Rewards Std             0.87837
evaluation/Rewards Max            -0.0247061
evaluation/Rewards Min            -8.87921
evaluation/Returns Mean          -47.1462
evaluation/Returns Std            34.7663
evaluation/Returns Max            -7.98673
evaluation/Returns Min          -116.694
evaluation/Actions Mean           -0.0101354
evaluation/Actions Std             0.178072
evaluation/Actions Max             0.997149
evaluation/Actions Min            -0.998649
evaluation/Num Paths              15
evaluation/Average Returns       -47.1462
time/data storing (s)              0.00320834
time/evaluation sampling (s)       0.352207
time/exploration sampling (s)      0.159197
time/logging (s)                   0.00504814
time/saving (s)                    0.00216685
time/training (s)                  2.39765
time/epoch (s)                     2.91947
time/total (s)                   155.705
Epoch                             56
-----------------------------  --------------
2019-04-22 21:58:36.163519 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             29200
trainer/QF1 Loss                   0.198058
trainer/QF2 Loss                   0.209934
trainer/Policy Loss               29.5988
trainer/Q1 Predictions Mean      -28.3153
trainer/Q1 Predictions Std        18.1559
trainer/Q1 Predictions Max       -11.6988
trainer/Q1 Predictions Min       -77.3402
trainer/Q2 Predictions Mean      -28.3406
trainer/Q2 Predictions Std        18.1584
trainer/Q2 Predictions Max       -11.6113
trainer/Q2 Predictions Min       -76.8942
trainer/Q Targets Mean           -28.339
trainer/Q Targets Std             18.1837
trainer/Q Targets Max            -11.4254
trainer/Q Targets Min            -79.7721
trainer/Log Pis Mean               1.99505
trainer/Log Pis Std                1.53711
trainer/Log Pis Max                8.80193
trainer/Log Pis Min               -2.54655
trainer/Policy mu Mean             0.112531
trainer/Policy mu Std              0.807593
trainer/Policy mu Max              3.04445
trainer/Policy mu Min             -2.80733
trainer/Policy log std Mean       -1.98565
trainer/Policy log std Std         0.492558
trainer/Policy log std Max        -0.517832
trainer/Policy log std Min        -2.64815
trainer/Alpha                      0.0580405
trainer/Alpha Loss                -0.0140864
exploration/num steps total    29200
exploration/num paths total      292
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.63861
exploration/Rewards Std            0.832136
exploration/Rewards Max           -0.00102045
exploration/Rewards Min           -7.84508
exploration/Returns Mean         -63.861
exploration/Returns Std           31.6524
exploration/Returns Max          -23.3864
exploration/Returns Min         -104.333
exploration/Actions Mean           0.00597401
exploration/Actions Std            0.232855
exploration/Actions Max            0.998432
exploration/Actions Min           -0.999747
exploration/Num Paths              5
exploration/Average Returns      -63.861
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.426864
evaluation/Rewards Std             0.832644
evaluation/Rewards Max            -0.100345
evaluation/Rewards Min            -8.83367
evaluation/Returns Mean          -42.6864
evaluation/Returns Std            37.649
evaluation/Returns Max           -11.4216
evaluation/Returns Min          -125.69
evaluation/Actions Mean            0.00387449
evaluation/Actions Std             0.17069
evaluation/Actions Max             0.997118
evaluation/Actions Min            -0.998501
evaluation/Num Paths              15
evaluation/Average Returns       -42.6864
time/data storing (s)              0.00464199
time/evaluation sampling (s)       0.371798
time/exploration sampling (s)      0.192776
time/logging (s)                   0.00493738
time/saving (s)                    0.00206083
time/training (s)                  2.26441
time/epoch (s)                     2.84062
time/total (s)                   158.55
Epoch                             57
-----------------------------  --------------
2019-04-22 21:58:38.930367 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 58 finished
-----------------------------  ---------------
replay_buffer/size             29700
trainer/QF1 Loss                   3.20807
trainer/QF2 Loss                   3.20795
trainer/Policy Loss               30.9703
trainer/Q1 Predictions Mean      -29.4464
trainer/Q1 Predictions Std        18.5142
trainer/Q1 Predictions Max       -11.327
trainer/Q1 Predictions Min       -73.4692
trainer/Q2 Predictions Mean      -29.4537
trainer/Q2 Predictions Std        18.5029
trainer/Q2 Predictions Max       -11.2619
trainer/Q2 Predictions Min       -73.0149
trainer/Q Targets Mean           -29.4673
trainer/Q Targets Std             18.9703
trainer/Q Targets Max             -0.438162
trainer/Q Targets Min            -76.3702
trainer/Log Pis Mean               2.27892
trainer/Log Pis Std                1.56362
trainer/Log Pis Max                8.57598
trainer/Log Pis Min               -1.2767
trainer/Policy mu Mean            -0.0109546
trainer/Policy mu Std              0.919593
trainer/Policy mu Max              3.38125
trainer/Policy mu Min             -3.29711
trainer/Policy log std Mean       -1.96214
trainer/Policy log std Std         0.547141
trainer/Policy log std Max        -0.402334
trainer/Policy log std Min        -2.58446
trainer/Alpha                      0.05721
trainer/Alpha Loss                 0.798022
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.852119
exploration/Rewards Std            0.90979
exploration/Rewards Max           -0.0176259
exploration/Rewards Min           -8.15965
exploration/Returns Mean         -85.2119
exploration/Returns Std           40.9935
exploration/Returns Max          -31.3847
exploration/Returns Min         -131.073
exploration/Actions Mean          -0.000459421
exploration/Actions Std            0.236579
exploration/Actions Max            0.997528
exploration/Actions Min           -0.995287
exploration/Num Paths              5
exploration/Average Returns      -85.2119
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.423133
evaluation/Rewards Std             1.28712
evaluation/Rewards Max            -0.00983538
evaluation/Rewards Min           -10.2173
evaluation/Returns Mean          -42.3133
evaluation/Returns Std            30.2155
evaluation/Returns Max            -3.48532
evaluation/Returns Min          -144.46
evaluation/Actions Mean           -0.0125104
evaluation/Actions Std             0.217295
evaluation/Actions Max             0.996988
evaluation/Actions Min            -0.999609
evaluation/Num Paths              15
evaluation/Average Returns       -42.3133
time/data storing (s)              0.00518721
time/evaluation sampling (s)       0.398617
time/exploration sampling (s)      0.171028
time/logging (s)                   0.00669968
time/saving (s)                    0.00251691
time/training (s)                  2.17863
time/epoch (s)                     2.76268
time/total (s)                   161.318
Epoch                             58
-----------------------------  ---------------
2019-04-22 21:58:41.598299 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             30200
trainer/QF1 Loss                   0.408658
trainer/QF2 Loss                   0.422403
trainer/Policy Loss               28.8909
trainer/Q1 Predictions Mean      -27.3656
trainer/Q1 Predictions Std        19.6004
trainer/Q1 Predictions Max       -11.3678
trainer/Q1 Predictions Min       -95.7739
trainer/Q2 Predictions Mean      -27.347
trainer/Q2 Predictions Std        19.5765
trainer/Q2 Predictions Max       -11.2623
trainer/Q2 Predictions Min       -95.6556
trainer/Q Targets Mean           -27.5902
trainer/Q Targets Std             19.5701
trainer/Q Targets Max            -11.3388
trainer/Q Targets Min            -99.129
trainer/Log Pis Mean               2.42647
trainer/Log Pis Std                1.41113
trainer/Log Pis Max                8.28481
trainer/Log Pis Min               -0.886952
trainer/Policy mu Mean             0.107638
trainer/Policy mu Std              0.966611
trainer/Policy mu Max              3.32613
trainer/Policy mu Min             -3.29689
trainer/Policy log std Mean       -1.94409
trainer/Policy log std Std         0.56732
trainer/Policy log std Max        -0.394717
trainer/Policy log std Min        -2.77193
trainer/Alpha                      0.0569311
trainer/Alpha Loss                 1.22232
exploration/num steps total    30200
exploration/num paths total      302
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.369255
exploration/Rewards Std            1.11054
exploration/Rewards Max           -0.00560781
exploration/Rewards Min          -10.6398
exploration/Returns Mean         -36.9255
exploration/Returns Std           18.2431
exploration/Returns Max          -14.4062
exploration/Returns Min          -69.0203
exploration/Actions Mean          -0.0346507
exploration/Actions Std            0.233586
exploration/Actions Max            0.984851
exploration/Actions Min           -0.999547
exploration/Num Paths              5
exploration/Average Returns      -36.9255
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.643825
evaluation/Rewards Std             1.18537
evaluation/Rewards Max            -0.0565699
evaluation/Rewards Min           -10.3857
evaluation/Returns Mean          -64.3825
evaluation/Returns Std            33.6613
evaluation/Returns Max           -18.1127
evaluation/Returns Min          -127.354
evaluation/Actions Mean            0.00581256
evaluation/Actions Std             0.209383
evaluation/Actions Max             0.998494
evaluation/Actions Min            -0.999403
evaluation/Num Paths              15
evaluation/Average Returns       -64.3825
time/data storing (s)              0.00323181
time/evaluation sampling (s)       0.357852
time/exploration sampling (s)      0.168179
time/logging (s)                   0.0048278
time/saving (s)                    0.00193852
time/training (s)                  2.12377
time/epoch (s)                     2.6598
time/total (s)                   163.982
Epoch                             59
-----------------------------  --------------
2019-04-22 21:58:44.273978 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             30700
trainer/QF1 Loss                   1.70262
trainer/QF2 Loss                   1.59503
trainer/Policy Loss               25.0722
trainer/Q1 Predictions Mean      -23.817
trainer/Q1 Predictions Std        16.9617
trainer/Q1 Predictions Max       -11.1222
trainer/Q1 Predictions Min       -79.8747
trainer/Q2 Predictions Mean      -23.8222
trainer/Q2 Predictions Std        17.0079
trainer/Q2 Predictions Max       -11.1034
trainer/Q2 Predictions Min       -80.0809
trainer/Q Targets Mean           -23.9575
trainer/Q Targets Std             17.1241
trainer/Q Targets Max             -0.487931
trainer/Q Targets Min            -81.4427
trainer/Log Pis Mean               2.12669
trainer/Log Pis Std                1.53721
trainer/Log Pis Max                9.50273
trainer/Log Pis Min               -2.37141
trainer/Policy mu Mean             0.0654529
trainer/Policy mu Std              0.8369
trainer/Policy mu Max              3.41769
trainer/Policy mu Min             -3.06782
trainer/Policy log std Mean       -1.91994
trainer/Policy log std Std         0.488102
trainer/Policy log std Max        -0.237237
trainer/Policy log std Min        -2.59567
trainer/Alpha                      0.0575852
trainer/Alpha Loss                 0.361637
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.363444
exploration/Rewards Std            0.95296
exploration/Rewards Max           -0.014526
exploration/Rewards Min           -9.85034
exploration/Returns Mean         -36.3444
exploration/Returns Std           13.3368
exploration/Returns Max          -19.3024
exploration/Returns Min          -59.4916
exploration/Actions Mean          -0.0214914
exploration/Actions Std            0.252143
exploration/Actions Max            0.99864
exploration/Actions Min           -0.999468
exploration/Num Paths              5
exploration/Average Returns      -36.3444
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.429435
evaluation/Rewards Std             1.01444
evaluation/Rewards Max            -0.0131346
evaluation/Rewards Min            -9.88131
evaluation/Returns Mean          -42.9435
evaluation/Returns Std            36.1429
evaluation/Returns Max            -5.06048
evaluation/Returns Min          -113.932
evaluation/Actions Mean           -0.00294375
evaluation/Actions Std             0.175765
evaluation/Actions Max             0.996969
evaluation/Actions Min            -0.999799
evaluation/Num Paths              15
evaluation/Average Returns       -42.9435
time/data storing (s)              0.00330108
time/evaluation sampling (s)       0.362228
time/exploration sampling (s)      0.163631
time/logging (s)                   0.00474927
time/saving (s)                    0.00225017
time/training (s)                  2.13368
time/epoch (s)                     2.66984
time/total (s)                   166.656
Epoch                             60
-----------------------------  --------------
2019-04-22 21:58:46.966266 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 61 finished
-----------------------------  --------------
replay_buffer/size             31200
trainer/QF1 Loss                   0.119972
trainer/QF2 Loss                   0.128504
trainer/Policy Loss               26.2699
trainer/Q1 Predictions Mean      -24.7726
trainer/Q1 Predictions Std        16.4317
trainer/Q1 Predictions Max       -11.1236
trainer/Q1 Predictions Min       -64.1596
trainer/Q2 Predictions Mean      -24.7686
trainer/Q2 Predictions Std        16.432
trainer/Q2 Predictions Max       -11.1494
trainer/Q2 Predictions Min       -64.2631
trainer/Q Targets Mean           -24.8676
trainer/Q Targets Std             16.471
trainer/Q Targets Max            -11.112
trainer/Q Targets Min            -64.5633
trainer/Log Pis Mean               1.86891
trainer/Log Pis Std                1.35745
trainer/Log Pis Max                6.58486
trainer/Log Pis Min               -3.19862
trainer/Policy mu Mean            -0.00382572
trainer/Policy mu Std              0.674319
trainer/Policy mu Max              3.2666
trainer/Policy mu Min             -2.80306
trainer/Policy log std Mean       -1.98655
trainer/Policy log std Std         0.449647
trainer/Policy log std Max        -0.560666
trainer/Policy log std Min        -2.68598
trainer/Alpha                      0.0560835
trainer/Alpha Loss                -0.37766
exploration/num steps total    31200
exploration/num paths total      312
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.664875
exploration/Rewards Std            0.577031
exploration/Rewards Max           -0.0197733
exploration/Rewards Min           -6.00017
exploration/Returns Mean         -66.4875
exploration/Returns Std           36.6637
exploration/Returns Max          -18.1225
exploration/Returns Min         -100.8
exploration/Actions Mean           0.00166477
exploration/Actions Std            0.199383
exploration/Actions Max            0.998866
exploration/Actions Min           -0.973294
exploration/Num Paths              5
exploration/Average Returns      -66.4875
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.530614
evaluation/Rewards Std             1.00093
evaluation/Rewards Max            -0.00799129
evaluation/Rewards Min            -9.77489
evaluation/Returns Mean          -53.0614
evaluation/Returns Std            40.8141
evaluation/Returns Max            -2.5475
evaluation/Returns Min          -126.953
evaluation/Actions Mean            0.0125893
evaluation/Actions Std             0.190037
evaluation/Actions Max             0.997034
evaluation/Actions Min            -0.999191
evaluation/Num Paths              15
evaluation/Average Returns       -53.0614
time/data storing (s)              0.00324636
time/evaluation sampling (s)       0.349746
time/exploration sampling (s)      0.178506
time/logging (s)                   0.00358631
time/saving (s)                    0.00232349
time/training (s)                  2.14817
time/epoch (s)                     2.68558
time/total (s)                   169.346
Epoch                             61
-----------------------------  --------------
2019-04-22 21:58:49.632721 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             31700
trainer/QF1 Loss                   4.05012
trainer/QF2 Loss                   4.00229
trainer/Policy Loss               27.1111
trainer/Q1 Predictions Mean      -25.6205
trainer/Q1 Predictions Std        17.7227
trainer/Q1 Predictions Max       -11.0252
trainer/Q1 Predictions Min       -67.8167
trainer/Q2 Predictions Mean      -25.6143
trainer/Q2 Predictions Std        17.7462
trainer/Q2 Predictions Max       -11.0009
trainer/Q2 Predictions Min       -68.2023
trainer/Q Targets Mean           -25.6715
trainer/Q Targets Std             17.9258
trainer/Q Targets Max             -0.265077
trainer/Q Targets Min            -69.6266
trainer/Log Pis Mean               2.03525
trainer/Log Pis Std                1.47041
trainer/Log Pis Max                7.2897
trainer/Log Pis Min               -3.60069
trainer/Policy mu Mean             0.0920705
trainer/Policy mu Std              0.831003
trainer/Policy mu Max              3.15485
trainer/Policy mu Min             -3.58681
trainer/Policy log std Mean       -2.00184
trainer/Policy log std Std         0.482261
trainer/Policy log std Max        -0.280831
trainer/Policy log std Min        -2.64536
trainer/Alpha                      0.0560766
trainer/Alpha Loss                 0.101557
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.648545
exploration/Rewards Std            1.06269
exploration/Rewards Max           -0.0160167
exploration/Rewards Min          -10.059
exploration/Returns Mean         -64.8545
exploration/Returns Std           31.3457
exploration/Returns Max          -20.8465
exploration/Returns Min         -107.724
exploration/Actions Mean           0.0104195
exploration/Actions Std            0.23341
exploration/Actions Max            0.998622
exploration/Actions Min           -0.997231
exploration/Num Paths              5
exploration/Average Returns      -64.8545
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.469857
evaluation/Rewards Std             1.19319
evaluation/Rewards Max            -0.0444601
evaluation/Rewards Min           -10.8663
evaluation/Returns Mean          -46.9857
evaluation/Returns Std            37.3679
evaluation/Returns Max            -6.01896
evaluation/Returns Min          -130.787
evaluation/Actions Mean            0.00782648
evaluation/Actions Std             0.20304
evaluation/Actions Max             0.9983
evaluation/Actions Min            -0.999669
evaluation/Num Paths              15
evaluation/Average Returns       -46.9857
time/data storing (s)              0.00317154
time/evaluation sampling (s)       0.356264
time/exploration sampling (s)      0.163639
time/logging (s)                   0.00492177
time/saving (s)                    0.0019499
time/training (s)                  2.13287
time/epoch (s)                     2.66282
time/total (s)                   172.012
Epoch                             62
-----------------------------  --------------
2019-04-22 21:58:52.327187 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size             32200
trainer/QF1 Loss                   4.05244
trainer/QF2 Loss                   4.03252
trainer/Policy Loss               32.1841
trainer/Q1 Predictions Mean      -30.9035
trainer/Q1 Predictions Std        19.3999
trainer/Q1 Predictions Max       -10.9932
trainer/Q1 Predictions Min      -107.93
trainer/Q2 Predictions Mean      -30.8937
trainer/Q2 Predictions Std        19.3963
trainer/Q2 Predictions Max       -11.0103
trainer/Q2 Predictions Min      -108.147
trainer/Q Targets Mean           -30.8728
trainer/Q Targets Std             19.8536
trainer/Q Targets Max             -0.470558
trainer/Q Targets Min           -111.134
trainer/Log Pis Mean               2.09072
trainer/Log Pis Std                1.43028
trainer/Log Pis Max                9.04936
trainer/Log Pis Min               -2.81045
trainer/Policy mu Mean             0.0549345
trainer/Policy mu Std              0.842574
trainer/Policy mu Max              3.32579
trainer/Policy mu Min             -3.96459
trainer/Policy log std Mean       -2.02837
trainer/Policy log std Std         0.525602
trainer/Policy log std Max        -0.0190303
trainer/Policy log std Min        -2.68139
trainer/Alpha                      0.0572931
trainer/Alpha Loss                 0.259436
exploration/num steps total    32200
exploration/num paths total      322
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.536588
exploration/Rewards Std            0.976987
exploration/Rewards Max           -0.00717708
exploration/Rewards Min           -8.09314
exploration/Returns Mean         -53.6588
exploration/Returns Std           28.7601
exploration/Returns Max          -25.2992
exploration/Returns Min         -108.259
exploration/Actions Mean           0.000563266
exploration/Actions Std            0.236544
exploration/Actions Max            0.998456
exploration/Actions Min           -0.997316
exploration/Num Paths              5
exploration/Average Returns      -53.6588
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.585454
evaluation/Rewards Std             1.12233
evaluation/Rewards Max            -0.0466
evaluation/Rewards Min           -10.756
evaluation/Returns Mean          -58.5454
evaluation/Returns Std            35.1433
evaluation/Returns Max            -6.63745
evaluation/Returns Min          -115.327
evaluation/Actions Mean           -0.000979507
evaluation/Actions Std             0.201023
evaluation/Actions Max             0.997695
evaluation/Actions Min            -0.999799
evaluation/Num Paths              15
evaluation/Average Returns       -58.5454
time/data storing (s)              0.00322307
time/evaluation sampling (s)       0.355704
time/exploration sampling (s)      0.161464
time/logging (s)                   0.00547218
time/saving (s)                    0.00181786
time/training (s)                  2.16143
time/epoch (s)                     2.68911
time/total (s)                   174.706
Epoch                             63
-----------------------------  ---------------
2019-04-22 21:58:54.990134 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             32700
trainer/QF1 Loss                   1.46122
trainer/QF2 Loss                   1.45689
trainer/Policy Loss               27.2344
trainer/Q1 Predictions Mean      -25.6589
trainer/Q1 Predictions Std        17.628
trainer/Q1 Predictions Max       -10.8337
trainer/Q1 Predictions Min       -79.6343
trainer/Q2 Predictions Mean      -25.6622
trainer/Q2 Predictions Std        17.6065
trainer/Q2 Predictions Max       -10.8151
trainer/Q2 Predictions Min       -79.625
trainer/Q Targets Mean           -25.8125
trainer/Q Targets Std             17.9085
trainer/Q Targets Max             -0.252146
trainer/Q Targets Min            -83.3371
trainer/Log Pis Mean               2.09861
trainer/Log Pis Std                1.52586
trainer/Log Pis Max                8.32704
trainer/Log Pis Min               -1.10812
trainer/Policy mu Mean             0.0325634
trainer/Policy mu Std              0.873001
trainer/Policy mu Max              3.335
trainer/Policy mu Min             -3.44303
trainer/Policy log std Mean       -1.98797
trainer/Policy log std Std         0.539347
trainer/Policy log std Max        -0.254141
trainer/Policy log std Min        -2.59571
trainer/Alpha                      0.0570983
trainer/Alpha Loss                 0.282329
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.483843
exploration/Rewards Std            0.883602
exploration/Rewards Max           -0.00665179
exploration/Rewards Min           -7.66934
exploration/Returns Mean         -48.3843
exploration/Returns Std           39.839
exploration/Returns Max          -17.5552
exploration/Returns Min         -126.179
exploration/Actions Mean          -0.00355348
exploration/Actions Std            0.227919
exploration/Actions Max            0.991622
exploration/Actions Min           -0.999872
exploration/Num Paths              5
exploration/Average Returns      -48.3843
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.471432
evaluation/Rewards Std             1.14865
evaluation/Rewards Max            -0.0106953
evaluation/Rewards Min           -11.1375
evaluation/Returns Mean          -47.1432
evaluation/Returns Std            39.2212
evaluation/Returns Max            -5.7808
evaluation/Returns Min          -142.685
evaluation/Actions Mean           -0.0114293
evaluation/Actions Std             0.195583
evaluation/Actions Max             0.996606
evaluation/Actions Min            -0.999616
evaluation/Num Paths              15
evaluation/Average Returns       -47.1432
time/data storing (s)              0.00310481
time/evaluation sampling (s)       0.352239
time/exploration sampling (s)      0.165885
time/logging (s)                   0.00395979
time/saving (s)                    0.00209361
time/training (s)                  2.12789
time/epoch (s)                     2.65518
time/total (s)                   177.366
Epoch                             64
-----------------------------  --------------
2019-04-22 21:58:57.791802 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 65 finished
-----------------------------  --------------
replay_buffer/size             33200
trainer/QF1 Loss                   0.106405
trainer/QF2 Loss                   0.0935137
trainer/Policy Loss               27.5106
trainer/Q1 Predictions Mean      -26.2116
trainer/Q1 Predictions Std        16.9392
trainer/Q1 Predictions Max       -11.2274
trainer/Q1 Predictions Min       -53.9418
trainer/Q2 Predictions Mean      -26.2055
trainer/Q2 Predictions Std        16.9265
trainer/Q2 Predictions Max       -11.169
trainer/Q2 Predictions Min       -53.9132
trainer/Q Targets Mean           -26.3214
trainer/Q Targets Std             17.0203
trainer/Q Targets Max            -10.8984
trainer/Q Targets Min            -53.9351
trainer/Log Pis Mean               1.60381
trainer/Log Pis Std                1.08507
trainer/Log Pis Max                4.33302
trainer/Log Pis Min               -1.82312
trainer/Policy mu Mean             0.0368488
trainer/Policy mu Std              0.5242
trainer/Policy mu Max              2.41216
trainer/Policy mu Min             -2.27121
trainer/Policy log std Mean       -2.05095
trainer/Policy log std Std         0.362505
trainer/Policy log std Max        -0.537398
trainer/Policy log std Min        -2.46087
trainer/Alpha                      0.0569596
trainer/Alpha Loss                -1.13517
exploration/num steps total    33200
exploration/num paths total      332
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.548659
exploration/Rewards Std            0.945269
exploration/Rewards Max           -0.0134018
exploration/Rewards Min           -8.16988
exploration/Returns Mean         -54.8659
exploration/Returns Std           27.314
exploration/Returns Max          -24.6393
exploration/Returns Min         -104.707
exploration/Actions Mean           0.00235504
exploration/Actions Std            0.244131
exploration/Actions Max            0.999039
exploration/Actions Min           -0.998591
exploration/Num Paths              5
exploration/Average Returns      -54.8659
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.496135
evaluation/Rewards Std             1.13491
evaluation/Rewards Max            -0.119485
evaluation/Rewards Min           -10.4952
evaluation/Returns Mean          -49.6135
evaluation/Returns Std            30.1302
evaluation/Returns Max           -20.3208
evaluation/Returns Min          -125.446
evaluation/Actions Mean           -0.0154586
evaluation/Actions Std             0.209024
evaluation/Actions Max             0.994583
evaluation/Actions Min            -0.999413
evaluation/Num Paths              15
evaluation/Average Returns       -49.6135
time/data storing (s)              0.00321933
time/evaluation sampling (s)       0.344905
time/exploration sampling (s)      0.160622
time/logging (s)                   0.00482265
time/saving (s)                    0.00199864
time/training (s)                  2.28041
time/epoch (s)                     2.79598
time/total (s)                   180.167
Epoch                             65
-----------------------------  --------------
2019-04-22 21:59:00.690715 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                    2.65236
trainer/QF2 Loss                    2.65345
trainer/Policy Loss                28.9099
trainer/Q1 Predictions Mean       -27.6547
trainer/Q1 Predictions Std         18.6413
trainer/Q1 Predictions Max        -10.8441
trainer/Q1 Predictions Min        -75.0949
trainer/Q2 Predictions Mean       -27.6642
trainer/Q2 Predictions Std         18.6545
trainer/Q2 Predictions Max        -10.7883
trainer/Q2 Predictions Min        -74.8904
trainer/Q Targets Mean            -27.7222
trainer/Q Targets Std              19.1153
trainer/Q Targets Max              -0.253157
trainer/Q Targets Min             -75.7635
trainer/Log Pis Mean                1.94391
trainer/Log Pis Std                 1.5462
trainer/Log Pis Max                 8.2079
trainer/Log Pis Min                -2.42339
trainer/Policy mu Mean              0.160637
trainer/Policy mu Std               0.784422
trainer/Policy mu Max               2.86071
trainer/Policy mu Min              -2.99061
trainer/Policy log std Mean        -1.98867
trainer/Policy log std Std          0.51236
trainer/Policy log std Max         -0.42887
trainer/Policy log std Min         -2.63304
trainer/Alpha                       0.057087
trainer/Alpha Loss                 -0.160613
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.582712
exploration/Rewards Std             1.17652
exploration/Rewards Max            -0.00120514
exploration/Rewards Min           -10.2927
exploration/Returns Mean          -58.2712
exploration/Returns Std            25.8582
exploration/Returns Max           -26.4052
exploration/Returns Min           -98.368
exploration/Actions Mean           -0.0174814
exploration/Actions Std             0.246271
exploration/Actions Max             0.995507
exploration/Actions Min            -0.999045
exploration/Num Paths               5
exploration/Average Returns       -58.2712
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.463825
evaluation/Rewards Std              1.05267
evaluation/Rewards Max             -0.0571448
evaluation/Rewards Min            -10.235
evaluation/Returns Mean           -46.3825
evaluation/Returns Std             38.1946
evaluation/Returns Max            -12.6098
evaluation/Returns Min           -130.161
evaluation/Actions Mean            -0.011228
evaluation/Actions Std              0.187057
evaluation/Actions Max              0.99655
evaluation/Actions Min             -0.999786
evaluation/Num Paths               15
evaluation/Average Returns        -46.3825
time/data storing (s)               0.00450969
time/evaluation sampling (s)        0.405303
time/exploration sampling (s)       0.190461
time/logging (s)                    0.0048307
time/saving (s)                     0.00198422
time/training (s)                   2.28511
time/epoch (s)                      2.8922
time/total (s)                    183.064
Epoch                              66
-----------------------------  ---------------
2019-04-22 21:59:03.621843 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                   17.7345
trainer/QF2 Loss                   17.7544
trainer/Policy Loss                24.367
trainer/Q1 Predictions Mean       -22.9832
trainer/Q1 Predictions Std         15.7041
trainer/Q1 Predictions Max        -10.3651
trainer/Q1 Predictions Min        -62.0837
trainer/Q2 Predictions Mean       -22.9615
trainer/Q2 Predictions Std         15.6829
trainer/Q2 Predictions Max        -10.4224
trainer/Q2 Predictions Min        -62.0946
trainer/Q Targets Mean            -22.6714
trainer/Q Targets Std              16.0637
trainer/Q Targets Max              -0.153374
trainer/Q Targets Min             -62.1489
trainer/Log Pis Mean                1.83538
trainer/Log Pis Std                 1.15111
trainer/Log Pis Max                 6.9327
trainer/Log Pis Min                -2.77801
trainer/Policy mu Mean             -0.0195931
trainer/Policy mu Std               0.642591
trainer/Policy mu Max               2.84648
trainer/Policy mu Min              -2.96358
trainer/Policy log std Mean        -2.01902
trainer/Policy log std Std          0.414168
trainer/Policy log std Max         -0.332372
trainer/Policy log std Min         -2.51935
trainer/Alpha                       0.0582597
trainer/Alpha Loss                 -0.467974
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.312096
exploration/Rewards Std             0.758882
exploration/Rewards Max            -0.0124917
exploration/Rewards Min            -7.09226
exploration/Returns Mean          -31.2096
exploration/Returns Std             9.85952
exploration/Returns Max           -14.5785
exploration/Returns Min           -44.455
exploration/Actions Mean           -0.0203101
exploration/Actions Std             0.227961
exploration/Actions Max             0.995277
exploration/Actions Min            -0.999954
exploration/Num Paths               5
exploration/Average Returns       -31.2096
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.420662
evaluation/Rewards Std              1.0925
evaluation/Rewards Max             -0.0448514
evaluation/Rewards Min            -10.1884
evaluation/Returns Mean           -42.0662
evaluation/Returns Std             42.8105
evaluation/Returns Max             -7.5881
evaluation/Returns Min           -147.779
evaluation/Actions Mean            -0.00590129
evaluation/Actions Std              0.18836
evaluation/Actions Max              0.997955
evaluation/Actions Min             -0.999541
evaluation/Num Paths               15
evaluation/Average Returns        -42.0662
time/data storing (s)               0.0032183
time/evaluation sampling (s)        0.36753
time/exploration sampling (s)       0.175448
time/logging (s)                    0.00475298
time/saving (s)                     0.00208742
time/training (s)                   2.3722
time/epoch (s)                      2.92524
time/total (s)                    185.993
Epoch                              67
-----------------------------  ---------------
2019-04-22 21:59:06.602968 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                   35.3997
trainer/QF2 Loss                   35.1157
trainer/Policy Loss                27.6145
trainer/Q1 Predictions Mean       -26.0618
trainer/Q1 Predictions Std         17.4332
trainer/Q1 Predictions Max        -10.5364
trainer/Q1 Predictions Min        -68.8165
trainer/Q2 Predictions Mean       -26.0357
trainer/Q2 Predictions Std         17.4122
trainer/Q2 Predictions Max        -10.4468
trainer/Q2 Predictions Min        -68.5254
trainer/Q Targets Mean            -25.5377
trainer/Q Targets Std              17.8185
trainer/Q Targets Max              -0.142299
trainer/Q Targets Min             -70.5991
trainer/Log Pis Mean                2.05032
trainer/Log Pis Std                 1.28359
trainer/Log Pis Max                 7.48209
trainer/Log Pis Min                -0.343125
trainer/Policy mu Mean              0.0636743
trainer/Policy mu Std               0.896538
trainer/Policy mu Max               3.35178
trainer/Policy mu Min              -3.94156
trainer/Policy log std Mean        -1.98609
trainer/Policy log std Std          0.503639
trainer/Policy log std Max         -0.0276634
trainer/Policy log std Min         -2.36555
trainer/Alpha                       0.0563662
trainer/Alpha Loss                  0.14472
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.483099
exploration/Rewards Std             1.3381
exploration/Rewards Max            -0.00741025
exploration/Rewards Min           -10.1666
exploration/Returns Mean          -48.3099
exploration/Returns Std            13.5362
exploration/Returns Max           -25.8938
exploration/Returns Min           -64.753
exploration/Actions Mean           -0.00890538
exploration/Actions Std             0.264354
exploration/Actions Max             0.999726
exploration/Actions Min            -0.999718
exploration/Num Paths               5
exploration/Average Returns       -48.3099
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.549736
evaluation/Rewards Std              1.08965
evaluation/Rewards Max             -0.013493
evaluation/Rewards Min            -10.4713
evaluation/Returns Mean           -54.9736
evaluation/Returns Std             40.6966
evaluation/Returns Max            -13.9708
evaluation/Returns Min           -143.063
evaluation/Actions Mean             0.0137259
evaluation/Actions Std              0.200527
evaluation/Actions Max              0.997408
evaluation/Actions Min             -0.99945
evaluation/Num Paths               15
evaluation/Average Returns        -54.9736
time/data storing (s)               0.00342108
time/evaluation sampling (s)        0.375898
time/exploration sampling (s)       0.18475
time/logging (s)                    0.00493114
time/saving (s)                     0.00198046
time/training (s)                   2.40406
time/epoch (s)                      2.97504
time/total (s)                    188.973
Epoch                              68
-----------------------------  ---------------
2019-04-22 21:59:09.486652 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                    0.188342
trainer/QF2 Loss                    0.177894
trainer/Policy Loss                26.3607
trainer/Q1 Predictions Mean       -24.9038
trainer/Q1 Predictions Std         17.6794
trainer/Q1 Predictions Max        -10.4009
trainer/Q1 Predictions Min        -75.9464
trainer/Q2 Predictions Mean       -24.8964
trainer/Q2 Predictions Std         17.6443
trainer/Q2 Predictions Max        -10.3864
trainer/Q2 Predictions Min        -75.7237
trainer/Q Targets Mean            -25.2133
trainer/Q Targets Std              17.6168
trainer/Q Targets Max             -10.5232
trainer/Q Targets Min             -76.8066
trainer/Log Pis Mean                1.87702
trainer/Log Pis Std                 1.31749
trainer/Log Pis Max                 6.82067
trainer/Log Pis Min                -1.87579
trainer/Policy mu Mean              0.0193274
trainer/Policy mu Std               0.731475
trainer/Policy mu Max               2.9348
trainer/Policy mu Min              -3.05131
trainer/Policy log std Mean        -2.05786
trainer/Policy log std Std          0.493747
trainer/Policy log std Max         -0.520129
trainer/Policy log std Min         -2.57558
trainer/Alpha                       0.0585793
trainer/Alpha Loss                 -0.348945
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.653532
exploration/Rewards Std             1.36258
exploration/Rewards Max            -0.00803921
exploration/Rewards Min           -10.6
exploration/Returns Mean          -65.3532
exploration/Returns Std            25.8319
exploration/Returns Max           -24.7558
exploration/Returns Min          -100.097
exploration/Actions Mean            0.00265886
exploration/Actions Std             0.263292
exploration/Actions Max             0.999949
exploration/Actions Min            -0.999897
exploration/Num Paths               5
exploration/Average Returns       -65.3532
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.289087
evaluation/Rewards Std              0.707247
evaluation/Rewards Max             -0.0583826
evaluation/Rewards Min             -8.37689
evaluation/Returns Mean           -28.9087
evaluation/Returns Std             22.6866
evaluation/Returns Max             -7.18026
evaluation/Returns Min           -102.404
evaluation/Actions Mean            -0.0210409
evaluation/Actions Std              0.162757
evaluation/Actions Max              0.994599
evaluation/Actions Min             -0.999077
evaluation/Num Paths               15
evaluation/Average Returns        -28.9087
time/data storing (s)               0.00334079
time/evaluation sampling (s)        0.372038
time/exploration sampling (s)       0.219935
time/logging (s)                    0.00485181
time/saving (s)                     0.00194791
time/training (s)                   2.27494
time/epoch (s)                      2.87705
time/total (s)                    191.855
Epoch                              69
-----------------------------  ---------------
2019-04-22 21:59:12.155592 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 70 finished
-----------------------------  ----------------
replay_buffer/size              35700
trainer/QF1 Loss                    3.72343
trainer/QF2 Loss                    3.72952
trainer/Policy Loss                24.5979
trainer/Q1 Predictions Mean       -23.1538
trainer/Q1 Predictions Std         15.799
trainer/Q1 Predictions Max        -10.3105
trainer/Q1 Predictions Min        -62.2779
trainer/Q2 Predictions Mean       -23.17
trainer/Q2 Predictions Std         15.7877
trainer/Q2 Predictions Max        -10.3548
trainer/Q2 Predictions Min        -61.9818
trainer/Q Targets Mean            -23.1716
trainer/Q Targets Std              16.2117
trainer/Q Targets Max              -2.28793
trainer/Q Targets Min             -64.4301
trainer/Log Pis Mean                2.01488
trainer/Log Pis Std                 1.5139
trainer/Log Pis Max                 7.39156
trainer/Log Pis Min                -2.23965
trainer/Policy mu Mean             -0.0109625
trainer/Policy mu Std               0.809008
trainer/Policy mu Max               2.98071
trainer/Policy mu Min              -3.39315
trainer/Policy log std Mean        -2.02111
trainer/Policy log std Std          0.491822
trainer/Policy log std Max         -0.135454
trainer/Policy log std Min         -2.48355
trainer/Alpha                       0.0599052
trainer/Alpha Loss                  0.0418926
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.53825
exploration/Rewards Std             0.752004
exploration/Rewards Max            -0.000472007
exploration/Rewards Min            -7.71218
exploration/Returns Mean          -53.825
exploration/Returns Std            44.9459
exploration/Returns Max           -14.3271
exploration/Returns Min          -113.064
exploration/Actions Mean            0.0125574
exploration/Actions Std             0.206191
exploration/Actions Max             0.997891
exploration/Actions Min            -0.992863
exploration/Num Paths               5
exploration/Average Returns       -53.825
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.281621
evaluation/Rewards Std              0.735945
evaluation/Rewards Max             -0.021691
evaluation/Rewards Min             -7.62613
evaluation/Returns Mean           -28.1621
evaluation/Returns Std             30.1048
evaluation/Returns Max             -2.43428
evaluation/Returns Min           -100.782
evaluation/Actions Mean             0.000378759
evaluation/Actions Std              0.166744
evaluation/Actions Max              0.997029
evaluation/Actions Min             -0.998441
evaluation/Num Paths               15
evaluation/Average Returns        -28.1621
time/data storing (s)               0.00300869
time/evaluation sampling (s)        0.345948
time/exploration sampling (s)       0.15937
time/logging (s)                    0.00482803
time/saving (s)                     0.0105866
time/training (s)                   2.13928
time/epoch (s)                      2.66302
time/total (s)                    194.522
Epoch                              70
-----------------------------  ----------------
2019-04-22 21:59:14.789938 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                    5.89079
trainer/QF2 Loss                    6.02869
trainer/Policy Loss                25.3819
trainer/Q1 Predictions Mean       -24.0947
trainer/Q1 Predictions Std         16.9526
trainer/Q1 Predictions Max        -10.1629
trainer/Q1 Predictions Min        -70.0932
trainer/Q2 Predictions Mean       -24.1329
trainer/Q2 Predictions Std         16.9604
trainer/Q2 Predictions Max        -10.1934
trainer/Q2 Predictions Min        -70.426
trainer/Q Targets Mean            -24.0139
trainer/Q Targets Std              17.3305
trainer/Q Targets Max              -0.1301
trainer/Q Targets Min             -71.2152
trainer/Log Pis Mean                2.06132
trainer/Log Pis Std                 1.24753
trainer/Log Pis Max                 6.8392
trainer/Log Pis Min                -2.16759
trainer/Policy mu Mean              0.0466719
trainer/Policy mu Std               0.752405
trainer/Policy mu Max               3.09389
trainer/Policy mu Min              -2.76095
trainer/Policy log std Mean        -2.00552
trainer/Policy log std Std          0.479967
trainer/Policy log std Max         -0.628686
trainer/Policy log std Min         -2.44541
trainer/Alpha                       0.0574767
trainer/Alpha Loss                  0.17516
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.705002
exploration/Rewards Std             0.865681
exploration/Rewards Max            -0.0160235
exploration/Rewards Min            -8.10853
exploration/Returns Mean          -70.5002
exploration/Returns Std            23.6588
exploration/Returns Max           -33.8705
exploration/Returns Min           -94.5539
exploration/Actions Mean           -0.00121583
exploration/Actions Std             0.223485
exploration/Actions Max             0.999046
exploration/Actions Min            -0.997508
exploration/Num Paths               5
exploration/Average Returns       -70.5002
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.42773
evaluation/Rewards Std              0.979426
evaluation/Rewards Max             -0.00796677
evaluation/Rewards Min            -10.5712
evaluation/Returns Mean           -42.773
evaluation/Returns Std             35.6903
evaluation/Returns Max             -8.47081
evaluation/Returns Min           -107.245
evaluation/Actions Mean             0.00152822
evaluation/Actions Std              0.192154
evaluation/Actions Max              0.995908
evaluation/Actions Min             -0.999634
evaluation/Num Paths               15
evaluation/Average Returns        -42.773
time/data storing (s)               0.00425387
time/evaluation sampling (s)        0.349611
time/exploration sampling (s)       0.160735
time/logging (s)                    0.00571604
time/saving (s)                     0.00246555
time/training (s)                   2.10612
time/epoch (s)                      2.6289
time/total (s)                    197.156
Epoch                              71
-----------------------------  ---------------
2019-04-22 21:59:17.452331 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                   25.4117
trainer/QF2 Loss                   25.3479
trainer/Policy Loss                28.8843
trainer/Q1 Predictions Mean       -27.6699
trainer/Q1 Predictions Std         20.7921
trainer/Q1 Predictions Max         -9.81986
trainer/Q1 Predictions Min       -103.23
trainer/Q2 Predictions Mean       -27.6624
trainer/Q2 Predictions Std         20.8017
trainer/Q2 Predictions Max         -9.85607
trainer/Q2 Predictions Min       -103.002
trainer/Q Targets Mean            -27.317
trainer/Q Targets Std              21.3142
trainer/Q Targets Max              -0.0689931
trainer/Q Targets Min            -106.658
trainer/Log Pis Mean                2.05308
trainer/Log Pis Std                 1.41261
trainer/Log Pis Max                 8.33741
trainer/Log Pis Min                -1.94544
trainer/Policy mu Mean              0.101233
trainer/Policy mu Std               0.908036
trainer/Policy mu Max               3.32107
trainer/Policy mu Min              -2.97544
trainer/Policy log std Mean        -1.94351
trainer/Policy log std Std          0.52385
trainer/Policy log std Max         -0.298035
trainer/Policy log std Min         -2.42172
trainer/Alpha                       0.0576054
trainer/Alpha Loss                  0.151498
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.740505
exploration/Rewards Std             1.25753
exploration/Rewards Max            -0.00925077
exploration/Rewards Min           -10.5846
exploration/Returns Mean          -74.0505
exploration/Returns Std            39.2586
exploration/Returns Max           -26.5902
exploration/Returns Min          -136.117
exploration/Actions Mean            0.0267133
exploration/Actions Std             0.251173
exploration/Actions Max             0.999447
exploration/Actions Min            -0.999992
exploration/Num Paths               5
exploration/Average Returns       -74.0505
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.360261
evaluation/Rewards Std              0.906406
evaluation/Rewards Max             -0.00440188
evaluation/Rewards Min             -9.54954
evaluation/Returns Mean           -36.0261
evaluation/Returns Std             33.1228
evaluation/Returns Max             -9.49491
evaluation/Returns Min           -129.861
evaluation/Actions Mean             0.00193312
evaluation/Actions Std              0.178608
evaluation/Actions Max              0.996491
evaluation/Actions Min             -0.999048
evaluation/Num Paths               15
evaluation/Average Returns        -36.0261
time/data storing (s)               0.00310277
time/evaluation sampling (s)        0.376959
time/exploration sampling (s)       0.160617
time/logging (s)                    0.00500761
time/saving (s)                     0.0021528
time/training (s)                   2.10716
time/epoch (s)                      2.655
time/total (s)                    199.816
Epoch                              72
-----------------------------  ---------------
2019-04-22 21:59:20.134369 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                   27.2696
trainer/QF2 Loss                   27.1207
trainer/Policy Loss                24.6853
trainer/Q1 Predictions Mean       -23.3456
trainer/Q1 Predictions Std         17.6679
trainer/Q1 Predictions Max         -9.99018
trainer/Q1 Predictions Min        -96.5899
trainer/Q2 Predictions Mean       -23.3725
trainer/Q2 Predictions Std         17.6875
trainer/Q2 Predictions Max         -9.98639
trainer/Q2 Predictions Min        -97.0698
trainer/Q Targets Mean            -22.6019
trainer/Q Targets Std              17.8428
trainer/Q Targets Max              -0.10765
trainer/Q Targets Min            -100.006
trainer/Log Pis Mean                1.95827
trainer/Log Pis Std                 1.19408
trainer/Log Pis Max                 5.27988
trainer/Log Pis Min                -2.25161
trainer/Policy mu Mean              0.0443393
trainer/Policy mu Std               0.823106
trainer/Policy mu Max               3.04343
trainer/Policy mu Min              -3.14844
trainer/Policy log std Mean        -2.00388
trainer/Policy log std Std          0.498375
trainer/Policy log std Max         -0.41284
trainer/Policy log std Min         -2.4712
trainer/Alpha                       0.0549723
trainer/Alpha Loss                 -0.121064
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.665935
exploration/Rewards Std             1.07621
exploration/Rewards Max            -0.00811816
exploration/Rewards Min            -9.85007
exploration/Returns Mean          -66.5935
exploration/Returns Std            35.4524
exploration/Returns Max           -15.8107
exploration/Returns Min          -106.99
exploration/Actions Mean           -0.015067
exploration/Actions Std             0.230102
exploration/Actions Max             0.998228
exploration/Actions Min            -0.99994
exploration/Num Paths               5
exploration/Average Returns       -66.5935
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.622318
evaluation/Rewards Std              1.18289
evaluation/Rewards Max             -0.0500867
evaluation/Rewards Min            -10.5965
evaluation/Returns Mean           -62.2318
evaluation/Returns Std             42.72
evaluation/Returns Max             -5.44834
evaluation/Returns Min           -137.199
evaluation/Actions Mean             0.00283901
evaluation/Actions Std              0.198672
evaluation/Actions Max              0.997649
evaluation/Actions Min             -0.999693
evaluation/Num Paths               15
evaluation/Average Returns        -62.2318
time/data storing (s)               0.0029971
time/evaluation sampling (s)        0.345002
time/exploration sampling (s)       0.160934
time/logging (s)                    0.00485146
time/saving (s)                     0.00197107
time/training (s)                   2.16022
time/epoch (s)                      2.67597
time/total (s)                    202.496
Epoch                              73
-----------------------------  ---------------
2019-04-22 21:59:22.820169 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size              37700
trainer/QF1 Loss                    3.48906
trainer/QF2 Loss                    3.37416
trainer/Policy Loss                26.4044
trainer/Q1 Predictions Mean       -24.8754
trainer/Q1 Predictions Std         18.2522
trainer/Q1 Predictions Max         -9.78283
trainer/Q1 Predictions Min        -76.4384
trainer/Q2 Predictions Mean       -24.8715
trainer/Q2 Predictions Std         18.3064
trainer/Q2 Predictions Max         -9.70573
trainer/Q2 Predictions Min        -76.3369
trainer/Q Targets Mean            -24.8935
trainer/Q Targets Std              18.9064
trainer/Q Targets Max              -0.142927
trainer/Q Targets Min             -78.1117
trainer/Log Pis Mean                1.92828
trainer/Log Pis Std                 1.40314
trainer/Log Pis Max                 5.93828
trainer/Log Pis Min                -3.57636
trainer/Policy mu Mean              0.0340854
trainer/Policy mu Std               0.819652
trainer/Policy mu Max               3.02581
trainer/Policy mu Min              -3.21313
trainer/Policy log std Mean        -2.01528
trainer/Policy log std Std          0.530006
trainer/Policy log std Max         -0.472839
trainer/Policy log std Min         -2.51197
trainer/Alpha                       0.0557967
trainer/Alpha Loss                 -0.206995
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.7568
exploration/Rewards Std             1.32987
exploration/Rewards Max            -0.014939
exploration/Rewards Min            -9.40456
exploration/Returns Mean          -75.68
exploration/Returns Std            30.9314
exploration/Returns Max           -37.2358
exploration/Returns Min          -112.92
exploration/Actions Mean            0.00226991
exploration/Actions Std             0.256059
exploration/Actions Max             0.999459
exploration/Actions Min            -0.999859
exploration/Num Paths               5
exploration/Average Returns       -75.68
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.495423
evaluation/Rewards Std              0.971444
evaluation/Rewards Max             -0.0133549
evaluation/Rewards Min            -10.3885
evaluation/Returns Mean           -49.5423
evaluation/Returns Std             35.2637
evaluation/Returns Max             -7.95647
evaluation/Returns Min           -126.373
evaluation/Actions Mean            -0.00823434
evaluation/Actions Std              0.185927
evaluation/Actions Max              0.99698
evaluation/Actions Min             -0.999609
evaluation/Num Paths               15
evaluation/Average Returns        -49.5423
time/data storing (s)               0.00373463
time/evaluation sampling (s)        0.351883
time/exploration sampling (s)       0.159223
time/logging (s)                    0.00479122
time/saving (s)                     0.0019979
time/training (s)                   2.15778
time/epoch (s)                      2.67941
time/total (s)                    205.18
Epoch                              74
-----------------------------  ---------------
2019-04-22 21:59:25.463712 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    0.205628
trainer/QF2 Loss                    0.199568
trainer/Policy Loss                23.7959
trainer/Q1 Predictions Mean       -22.4938
trainer/Q1 Predictions Std         16.5364
trainer/Q1 Predictions Max         -9.76525
trainer/Q1 Predictions Min        -50.7468
trainer/Q2 Predictions Mean       -22.4765
trainer/Q2 Predictions Std         16.5587
trainer/Q2 Predictions Max         -9.7103
trainer/Q2 Predictions Min        -50.7568
trainer/Q Targets Mean            -22.8152
trainer/Q Targets Std              16.7981
trainer/Q Targets Max              -9.71007
trainer/Q Targets Min             -51.3088
trainer/Log Pis Mean                1.52108
trainer/Log Pis Std                 1.29843
trainer/Log Pis Max                 3.81993
trainer/Log Pis Min                -3.97519
trainer/Policy mu Mean              0.0522061
trainer/Policy mu Std               0.541795
trainer/Policy mu Max               2.25612
trainer/Policy mu Min              -2.69384
trainer/Policy log std Mean        -2.09251
trainer/Policy log std Std          0.392084
trainer/Policy log std Max         -0.472203
trainer/Policy log std Min         -2.46636
trainer/Alpha                       0.0567164
trainer/Alpha Loss                 -1.37441
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.296152
exploration/Rewards Std             0.829941
exploration/Rewards Max            -0.0188437
exploration/Rewards Min            -9.12398
exploration/Returns Mean          -29.6152
exploration/Returns Std            19.4226
exploration/Returns Max           -13.406
exploration/Returns Min           -63.38
exploration/Actions Mean           -0.0149133
exploration/Actions Std             0.19935
exploration/Actions Max             0.885461
exploration/Actions Min            -0.999956
exploration/Num Paths               5
exploration/Average Returns       -29.6152
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.452514
evaluation/Rewards Std              0.905279
evaluation/Rewards Max             -0.0411904
evaluation/Rewards Min             -8.78391
evaluation/Returns Mean           -45.2514
evaluation/Returns Std             32.1079
evaluation/Returns Max            -12.3618
evaluation/Returns Min           -107.902
evaluation/Actions Mean             0.00203848
evaluation/Actions Std              0.183242
evaluation/Actions Max              0.996529
evaluation/Actions Min             -0.996866
evaluation/Num Paths               15
evaluation/Average Returns        -45.2514
time/data storing (s)               0.00308255
time/evaluation sampling (s)        0.343686
time/exploration sampling (s)       0.159546
time/logging (s)                    0.0047527
time/saving (s)                     0.00219033
time/training (s)                   2.1236
time/epoch (s)                      2.63686
time/total (s)                    207.822
Epoch                              75
-----------------------------  ---------------
2019-04-22 21:59:28.154129 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size              38700
trainer/QF1 Loss                    0.425535
trainer/QF2 Loss                    0.4107
trainer/Policy Loss                25.8774
trainer/Q1 Predictions Mean       -24.2746
trainer/Q1 Predictions Std         18.9879
trainer/Q1 Predictions Max         -9.48863
trainer/Q1 Predictions Min        -96.7185
trainer/Q2 Predictions Mean       -24.3271
trainer/Q2 Predictions Std         19.0052
trainer/Q2 Predictions Max         -9.4974
trainer/Q2 Predictions Min        -96.5269
trainer/Q Targets Mean            -24.7223
trainer/Q Targets Std              19.3186
trainer/Q Targets Max              -9.67463
trainer/Q Targets Min            -100.066
trainer/Log Pis Mean                2.18718
trainer/Log Pis Std                 1.27219
trainer/Log Pis Max                 6.63618
trainer/Log Pis Min                -2.26511
trainer/Policy mu Mean              0.0259508
trainer/Policy mu Std               0.763299
trainer/Policy mu Max               3.31814
trainer/Policy mu Min              -3.11383
trainer/Policy log std Mean        -2.05837
trainer/Policy log std Std          0.484056
trainer/Policy log std Max         -0.514854
trainer/Policy log std Min         -2.55043
trainer/Alpha                       0.0560976
trainer/Alpha Loss                  0.539243
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.307026
exploration/Rewards Std             0.892788
exploration/Rewards Max            -0.0102159
exploration/Rewards Min            -8.09784
exploration/Returns Mean          -30.7026
exploration/Returns Std            15.7517
exploration/Returns Max           -12.3751
exploration/Returns Min           -53.6856
exploration/Actions Mean           -0.00190175
exploration/Actions Std             0.224347
exploration/Actions Max             0.999169
exploration/Actions Min            -0.996776
exploration/Num Paths               5
exploration/Average Returns       -30.7026
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.544169
evaluation/Rewards Std              0.996006
evaluation/Rewards Max             -0.0174743
evaluation/Rewards Min             -9.9406
evaluation/Returns Mean           -54.4169
evaluation/Returns Std             37.0637
evaluation/Returns Max             -8.92967
evaluation/Returns Min           -114.728
evaluation/Actions Mean             0.00325794
evaluation/Actions Std              0.187834
evaluation/Actions Max              0.996542
evaluation/Actions Min             -0.999647
evaluation/Num Paths               15
evaluation/Average Returns        -54.4169
time/data storing (s)               0.00302472
time/evaluation sampling (s)        0.348618
time/exploration sampling (s)       0.161961
time/logging (s)                    0.00476217
time/saving (s)                     0.00195329
time/training (s)                   2.16362
time/epoch (s)                      2.68394
time/total (s)                    210.511
Epoch                              76
-----------------------------  ---------------
2019-04-22 21:59:30.788623 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    3.48764
trainer/QF2 Loss                    3.49096
trainer/Policy Loss                23.7828
trainer/Q1 Predictions Mean       -22.2783
trainer/Q1 Predictions Std         16.5935
trainer/Q1 Predictions Max         -9.63616
trainer/Q1 Predictions Min        -70.3055
trainer/Q2 Predictions Mean       -22.3077
trainer/Q2 Predictions Std         16.6328
trainer/Q2 Predictions Max         -9.63279
trainer/Q2 Predictions Min        -70.6876
trainer/Q Targets Mean            -22.3539
trainer/Q Targets Std              17.1615
trainer/Q Targets Max              -0.231878
trainer/Q Targets Min             -73.0314
trainer/Log Pis Mean                1.95972
trainer/Log Pis Std                 1.17042
trainer/Log Pis Max                 6.14339
trainer/Log Pis Min                -2.02559
trainer/Policy mu Mean              0.0862414
trainer/Policy mu Std               0.702588
trainer/Policy mu Max               2.95054
trainer/Policy mu Min              -2.4381
trainer/Policy log std Mean        -2.03582
trainer/Policy log std Std          0.463299
trainer/Policy log std Max         -0.502298
trainer/Policy log std Min         -2.49029
trainer/Alpha                       0.0573807
trainer/Alpha Loss                 -0.115127
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.805406
exploration/Rewards Std             1.10799
exploration/Rewards Max            -0.0138684
exploration/Rewards Min            -9.90671
exploration/Returns Mean          -80.5406
exploration/Returns Std            37.0905
exploration/Returns Max           -22.9298
exploration/Returns Min          -132.065
exploration/Actions Mean            0.00108067
exploration/Actions Std             0.229551
exploration/Actions Max             0.999722
exploration/Actions Min            -0.999451
exploration/Num Paths               5
exploration/Average Returns       -80.5406
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.368713
evaluation/Rewards Std              1.00417
evaluation/Rewards Max             -0.0172558
evaluation/Rewards Min             -9.57902
evaluation/Returns Mean           -36.8713
evaluation/Returns Std             27.772
evaluation/Returns Max             -9.97684
evaluation/Returns Min           -109.166
evaluation/Actions Mean            -0.00186451
evaluation/Actions Std              0.187093
evaluation/Actions Max              0.997668
evaluation/Actions Min             -0.998356
evaluation/Num Paths               15
evaluation/Average Returns        -36.8713
time/data storing (s)               0.00313185
time/evaluation sampling (s)        0.34725
time/exploration sampling (s)       0.16137
time/logging (s)                    0.00445471
time/saving (s)                     0.00202238
time/training (s)                   2.1098
time/epoch (s)                      2.62803
time/total (s)                    213.143
Epoch                              77
-----------------------------  ---------------
2019-04-22 21:59:33.555552 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size              39700
trainer/QF1 Loss                    0.117475
trainer/QF2 Loss                    0.0983767
trainer/Policy Loss                22.2623
trainer/Q1 Predictions Mean       -20.7954
trainer/Q1 Predictions Std         15.2455
trainer/Q1 Predictions Max         -9.63488
trainer/Q1 Predictions Min        -53.6779
trainer/Q2 Predictions Mean       -20.8042
trainer/Q2 Predictions Std         15.2453
trainer/Q2 Predictions Max         -9.64472
trainer/Q2 Predictions Min        -53.7648
trainer/Q Targets Mean            -20.9479
trainer/Q Targets Std              15.4482
trainer/Q Targets Max              -9.52897
trainer/Q Targets Min             -54.1522
trainer/Log Pis Mean                1.88249
trainer/Log Pis Std                 1.37277
trainer/Log Pis Max                 7.50509
trainer/Log Pis Min                -2.37438
trainer/Policy mu Mean             -0.0141646
trainer/Policy mu Std               0.74026
trainer/Policy mu Max               3.14326
trainer/Policy mu Min              -3.20513
trainer/Policy log std Mean        -2.05441
trainer/Policy log std Std          0.463119
trainer/Policy log std Max         -0.432741
trainer/Policy log std Min         -2.53704
trainer/Alpha                       0.0556526
trainer/Alpha Loss                 -0.339418
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.358155
exploration/Rewards Std             1.11184
exploration/Rewards Max            -0.0115715
exploration/Rewards Min           -10.7497
exploration/Returns Mean          -35.8155
exploration/Returns Std            17.1631
exploration/Returns Max           -13.5211
exploration/Returns Min           -65.7965
exploration/Actions Mean           -0.0127816
exploration/Actions Std             0.244877
exploration/Actions Max             0.999007
exploration/Actions Min            -0.999245
exploration/Num Paths               5
exploration/Average Returns       -35.8155
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.312595
evaluation/Rewards Std              0.970095
evaluation/Rewards Max             -0.0079504
evaluation/Rewards Min             -9.42678
evaluation/Returns Mean           -31.2595
evaluation/Returns Std             27.3737
evaluation/Returns Max            -10.7742
evaluation/Returns Min           -121.97
evaluation/Actions Mean            -0.0162989
evaluation/Actions Std              0.190277
evaluation/Actions Max              0.997282
evaluation/Actions Min             -0.999505
evaluation/Num Paths               15
evaluation/Average Returns        -31.2595
time/data storing (s)               0.0033857
time/evaluation sampling (s)        0.347162
time/exploration sampling (s)       0.16208
time/logging (s)                    0.00503662
time/saving (s)                     0.00201668
time/training (s)                   2.24154
time/epoch (s)                      2.76123
time/total (s)                    215.909
Epoch                              78
-----------------------------  ---------------
2019-04-22 21:59:36.344494 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    1.04638
trainer/QF2 Loss                    0.993903
trainer/Policy Loss                23.5589
trainer/Q1 Predictions Mean       -22.0125
trainer/Q1 Predictions Std         16.3904
trainer/Q1 Predictions Max         -9.44722
trainer/Q1 Predictions Min        -62.9438
trainer/Q2 Predictions Mean       -22.0199
trainer/Q2 Predictions Std         16.353
trainer/Q2 Predictions Max         -9.44365
trainer/Q2 Predictions Min        -62.7683
trainer/Q Targets Mean            -21.9527
trainer/Q Targets Std              16.5766
trainer/Q Targets Max              -0.182159
trainer/Q Targets Min             -63.3439
trainer/Log Pis Mean                2.10844
trainer/Log Pis Std                 1.40577
trainer/Log Pis Max                 5.68299
trainer/Log Pis Min                -4.58441
trainer/Policy mu Mean              0.008907
trainer/Policy mu Std               0.855795
trainer/Policy mu Max               3.16909
trainer/Policy mu Min              -3.20409
trainer/Policy log std Mean        -2.0272
trainer/Policy log std Std          0.516794
trainer/Policy log std Max         -0.429995
trainer/Policy log std Min         -2.50797
trainer/Alpha                       0.0557205
trainer/Alpha Loss                  0.313099
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.393357
exploration/Rewards Std             1.1837
exploration/Rewards Max            -0.00386348
exploration/Rewards Min           -10.0146
exploration/Returns Mean          -39.3357
exploration/Returns Std            19.6745
exploration/Returns Max           -18.1142
exploration/Returns Min           -69.6072
exploration/Actions Mean           -0.0251213
exploration/Actions Std             0.242618
exploration/Actions Max             0.999194
exploration/Actions Min            -0.999937
exploration/Num Paths               5
exploration/Average Returns       -39.3357
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.519284
evaluation/Rewards Std              1.24368
evaluation/Rewards Max             -0.0365025
evaluation/Rewards Min            -11.1999
evaluation/Returns Mean           -51.9284
evaluation/Returns Std             34.0821
evaluation/Returns Max             -7.85203
evaluation/Returns Min           -116.957
evaluation/Actions Mean            -0.0137186
evaluation/Actions Std              0.206087
evaluation/Actions Max              0.997039
evaluation/Actions Min             -0.999793
evaluation/Num Paths               15
evaluation/Average Returns        -51.9284
time/data storing (s)               0.00308478
time/evaluation sampling (s)        0.354442
time/exploration sampling (s)       0.161675
time/logging (s)                    0.00548253
time/saving (s)                     0.00198668
time/training (s)                   2.25667
time/epoch (s)                      2.78334
time/total (s)                    218.697
Epoch                              79
-----------------------------  ---------------
2019-04-22 21:59:39.068898 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size              40700
trainer/QF1 Loss                    0.21529
trainer/QF2 Loss                    0.184128
trainer/Policy Loss                20.8897
trainer/Q1 Predictions Mean       -18.9441
trainer/Q1 Predictions Std         14.6329
trainer/Q1 Predictions Max         -9.322
trainer/Q1 Predictions Min        -57.3554
trainer/Q2 Predictions Mean       -18.9525
trainer/Q2 Predictions Std         14.6565
trainer/Q2 Predictions Max         -9.3313
trainer/Q2 Predictions Min        -57.4777
trainer/Q Targets Mean            -19.1722
trainer/Q Targets Std              14.8614
trainer/Q Targets Max              -9.39751
trainer/Q Targets Min             -57.0633
trainer/Log Pis Mean                2.24233
trainer/Log Pis Std                 1.13342
trainer/Log Pis Max                 6.47995
trainer/Log Pis Min                -1.49789
trainer/Policy mu Mean             -0.0271619
trainer/Policy mu Std               0.725081
trainer/Policy mu Max               2.73928
trainer/Policy mu Min              -2.72395
trainer/Policy log std Mean        -2.09272
trainer/Policy log std Std          0.436377
trainer/Policy log std Max         -0.575405
trainer/Policy log std Min         -2.5516
trainer/Alpha                       0.0551358
trainer/Alpha Loss                  0.702288
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.242854
exploration/Rewards Std             0.588002
exploration/Rewards Max            -0.0100929
exploration/Rewards Min            -5.5601
exploration/Returns Mean          -24.2854
exploration/Returns Std             7.38963
exploration/Returns Max           -14.291
exploration/Returns Min           -32.2802
exploration/Actions Mean            0.0110998
exploration/Actions Std             0.19449
exploration/Actions Max             0.99749
exploration/Actions Min            -0.985344
exploration/Num Paths               5
exploration/Average Returns       -24.2854
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.426562
evaluation/Rewards Std              0.63923
evaluation/Rewards Max             -0.0388023
evaluation/Rewards Min             -7.59421
evaluation/Returns Mean           -42.6562
evaluation/Returns Std             39.1178
evaluation/Returns Max             -9.09047
evaluation/Returns Min           -106.913
evaluation/Actions Mean            -0.00450086
evaluation/Actions Std              0.149068
evaluation/Actions Max              0.99524
evaluation/Actions Min             -0.992788
evaluation/Num Paths               15
evaluation/Average Returns        -42.6562
time/data storing (s)               0.00311512
time/evaluation sampling (s)        0.363534
time/exploration sampling (s)       0.161829
time/logging (s)                    0.00483793
time/saving (s)                     0.00200704
time/training (s)                   2.18221
time/epoch (s)                      2.71753
time/total (s)                    221.419
Epoch                              80
-----------------------------  ---------------
2019-04-22 21:59:41.874019 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                    0.958584
trainer/QF2 Loss                    0.941305
trainer/Policy Loss                22.691
trainer/Q1 Predictions Mean       -21.1989
trainer/Q1 Predictions Std         16.12
trainer/Q1 Predictions Max         -9.28215
trainer/Q1 Predictions Min        -49.6384
trainer/Q2 Predictions Mean       -21.2023
trainer/Q2 Predictions Std         16.0785
trainer/Q2 Predictions Max         -9.26537
trainer/Q2 Predictions Min        -49.5454
trainer/Q Targets Mean            -21.2957
trainer/Q Targets Std              16.2731
trainer/Q Targets Max              -0.160301
trainer/Q Targets Min             -50.0875
trainer/Log Pis Mean                1.81983
trainer/Log Pis Std                 1.4158
trainer/Log Pis Max                 9.04249
trainer/Log Pis Min                -2.25077
trainer/Policy mu Mean             -0.0521226
trainer/Policy mu Std               0.66461
trainer/Policy mu Max               3.06091
trainer/Policy mu Min              -3.69516
trainer/Policy log std Mean        -2.04779
trainer/Policy log std Std          0.434044
trainer/Policy log std Max         -0.153819
trainer/Policy log std Min         -2.42446
trainer/Alpha                       0.056815
trainer/Alpha Loss                 -0.51669
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.606679
exploration/Rewards Std             1.40749
exploration/Rewards Max            -0.00794775
exploration/Rewards Min           -10.3981
exploration/Returns Mean          -60.6679
exploration/Returns Std            40.9841
exploration/Returns Max           -15.2585
exploration/Returns Min          -132.326
exploration/Actions Mean            0.0101759
exploration/Actions Std             0.253844
exploration/Actions Max             0.999418
exploration/Actions Min            -0.999552
exploration/Num Paths               5
exploration/Average Returns       -60.6679
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.476168
evaluation/Rewards Std              1.0397
evaluation/Rewards Max             -0.0215012
evaluation/Rewards Min             -9.95184
evaluation/Returns Mean           -47.6168
evaluation/Returns Std             36.507
evaluation/Returns Max             -8.50163
evaluation/Returns Min           -121.906
evaluation/Actions Mean            -0.00372967
evaluation/Actions Std              0.187863
evaluation/Actions Max              0.996152
evaluation/Actions Min             -0.999209
evaluation/Num Paths               15
evaluation/Average Returns        -47.6168
time/data storing (s)               0.0030012
time/evaluation sampling (s)        0.347986
time/exploration sampling (s)       0.161919
time/logging (s)                    0.00434827
time/saving (s)                     0.00813691
time/training (s)                   2.27318
time/epoch (s)                      2.79857
time/total (s)                    224.221
Epoch                              81
-----------------------------  ---------------
2019-04-22 21:59:44.536443 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size              41700
trainer/QF1 Loss                   23.1991
trainer/QF2 Loss                   22.9947
trainer/Policy Loss                23.1813
trainer/Q1 Predictions Mean       -21.7598
trainer/Q1 Predictions Std         17.2629
trainer/Q1 Predictions Max         -9.36695
trainer/Q1 Predictions Min        -60.6982
trainer/Q2 Predictions Mean       -21.7493
trainer/Q2 Predictions Std         17.2499
trainer/Q2 Predictions Max         -9.29861
trainer/Q2 Predictions Min        -60.4051
trainer/Q Targets Mean            -21.4071
trainer/Q Targets Std              17.2158
trainer/Q Targets Max              -2.0487
trainer/Q Targets Min             -62.4536
trainer/Log Pis Mean                1.80193
trainer/Log Pis Std                 1.19549
trainer/Log Pis Max                 8.6491
trainer/Log Pis Min                -3.10784
trainer/Policy mu Mean             -0.0650546
trainer/Policy mu Std               0.58267
trainer/Policy mu Max               2.26166
trainer/Policy mu Min              -3.02251
trainer/Policy log std Mean        -2.07775
trainer/Policy log std Std          0.368192
trainer/Policy log std Max         -0.44067
trainer/Policy log std Min         -2.45298
trainer/Alpha                       0.0545273
trainer/Alpha Loss                 -0.576187
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.581012
exploration/Rewards Std             1.07092
exploration/Rewards Max            -0.0130967
exploration/Rewards Min            -9.61629
exploration/Returns Mean          -58.1012
exploration/Returns Std            39.9898
exploration/Returns Max           -13.716
exploration/Returns Min          -117.913
exploration/Actions Mean            0.0064935
exploration/Actions Std             0.20815
exploration/Actions Max             0.999601
exploration/Actions Min            -0.998247
exploration/Num Paths               5
exploration/Average Returns       -58.1012
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.46065
evaluation/Rewards Std              1.05024
evaluation/Rewards Max             -0.0160283
evaluation/Rewards Min            -10.0593
evaluation/Returns Mean           -46.065
evaluation/Returns Std             27.3159
evaluation/Returns Max             -7.62389
evaluation/Returns Min            -92.6441
evaluation/Actions Mean             0.0057138
evaluation/Actions Std              0.202894
evaluation/Actions Max              0.996627
evaluation/Actions Min             -0.999189
evaluation/Num Paths               15
evaluation/Average Returns        -46.065
time/data storing (s)               0.00302224
time/evaluation sampling (s)        0.348618
time/exploration sampling (s)       0.166003
time/logging (s)                    0.00474504
time/saving (s)                     0.00221808
time/training (s)                   2.13233
time/epoch (s)                      2.65694
time/total (s)                    226.882
Epoch                              82
-----------------------------  ---------------
2019-04-22 21:59:47.544663 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                   22.6274
trainer/QF2 Loss                   22.4567
trainer/Policy Loss                23.8952
trainer/Q1 Predictions Mean       -22.4375
trainer/Q1 Predictions Std         16.5162
trainer/Q1 Predictions Max         -8.95392
trainer/Q1 Predictions Min        -69.7081
trainer/Q2 Predictions Mean       -22.4306
trainer/Q2 Predictions Std         16.549
trainer/Q2 Predictions Max         -9.01334
trainer/Q2 Predictions Min        -69.7229
trainer/Q Targets Mean            -22.384
trainer/Q Targets Std              17.3484
trainer/Q Targets Max              -0.528963
trainer/Q Targets Min             -73.5952
trainer/Log Pis Mean                2.29016
trainer/Log Pis Std                 1.68367
trainer/Log Pis Max                 9.03669
trainer/Log Pis Min                -1.65689
trainer/Policy mu Mean              0.116107
trainer/Policy mu Std               0.866697
trainer/Policy mu Max               3.03299
trainer/Policy mu Min              -2.8861
trainer/Policy log std Mean        -2.03977
trainer/Policy log std Std          0.536037
trainer/Policy log std Max         -0.521349
trainer/Policy log std Min         -2.45573
trainer/Alpha                       0.057746
trainer/Alpha Loss                  0.82756
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.345068
exploration/Rewards Std             0.631875
exploration/Rewards Max            -0.0105072
exploration/Rewards Min            -6.74063
exploration/Returns Mean          -34.5068
exploration/Returns Std            19.8965
exploration/Returns Max           -15.7981
exploration/Returns Min           -70.9722
exploration/Actions Mean           -0.0124452
exploration/Actions Std             0.190331
exploration/Actions Max             0.99433
exploration/Actions Min            -0.999244
exploration/Num Paths               5
exploration/Average Returns       -34.5068
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.3793
evaluation/Rewards Std              1.0882
evaluation/Rewards Max             -0.0377415
evaluation/Rewards Min            -11.0294
evaluation/Returns Mean           -37.93
evaluation/Returns Std             32.9372
evaluation/Returns Max             -4.98458
evaluation/Returns Min           -109.811
evaluation/Actions Mean             0.00138856
evaluation/Actions Std              0.19082
evaluation/Actions Max              0.99684
evaluation/Actions Min             -0.999648
evaluation/Num Paths               15
evaluation/Average Returns        -37.93
time/data storing (s)               0.00359574
time/evaluation sampling (s)        0.433241
time/exploration sampling (s)       0.217578
time/logging (s)                    0.00482284
time/saving (s)                     0.00202038
time/training (s)                   2.34074
time/epoch (s)                      3.002
time/total (s)                    229.889
Epoch                              83
-----------------------------  ---------------
2019-04-22 21:59:50.461865 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                    0.408318
trainer/QF2 Loss                    0.412676
trainer/Policy Loss                20.1459
trainer/Q1 Predictions Mean       -18.4179
trainer/Q1 Predictions Std         14.6808
trainer/Q1 Predictions Max         -8.81076
trainer/Q1 Predictions Min        -56.0148
trainer/Q2 Predictions Mean       -18.433
trainer/Q2 Predictions Std         14.6952
trainer/Q2 Predictions Max         -8.85779
trainer/Q2 Predictions Min        -56.746
trainer/Q Targets Mean            -18.8979
trainer/Q Targets Std              14.9385
trainer/Q Targets Max              -9.14461
trainer/Q Targets Min             -55.7502
trainer/Log Pis Mean                1.93448
trainer/Log Pis Std                 1.44512
trainer/Log Pis Max                 7.53647
trainer/Log Pis Min                -4.16563
trainer/Policy mu Mean              0.0210635
trainer/Policy mu Std               0.659532
trainer/Policy mu Max               2.85294
trainer/Policy mu Min              -3.19303
trainer/Policy log std Mean        -2.08081
trainer/Policy log std Std          0.408574
trainer/Policy log std Max         -0.206837
trainer/Policy log std Min         -2.37604
trainer/Alpha                       0.0573448
trainer/Alpha Loss                 -0.187296
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396034
exploration/Rewards Std             0.508425
exploration/Rewards Max            -0.00750368
exploration/Rewards Min            -4.86183
exploration/Returns Mean          -39.6034
exploration/Returns Std            20.8496
exploration/Returns Max           -17.5811
exploration/Returns Min           -69.8308
exploration/Actions Mean            0.00798524
exploration/Actions Std             0.193231
exploration/Actions Max             0.996331
exploration/Actions Min            -0.999376
exploration/Num Paths               5
exploration/Average Returns       -39.6034
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.461575
evaluation/Rewards Std              1.01002
evaluation/Rewards Max             -0.0152945
evaluation/Rewards Min             -9.94626
evaluation/Returns Mean           -46.1575
evaluation/Returns Std             28.6882
evaluation/Returns Max            -10.1996
evaluation/Returns Min            -96.322
evaluation/Actions Mean             0.00410849
evaluation/Actions Std              0.197471
evaluation/Actions Max              0.997219
evaluation/Actions Min             -0.999388
evaluation/Num Paths               15
evaluation/Average Returns        -46.1575
time/data storing (s)               0.00308235
time/evaluation sampling (s)        0.354149
time/exploration sampling (s)       0.16405
time/logging (s)                    0.00499045
time/saving (s)                     0.00198014
time/training (s)                   2.38247
time/epoch (s)                      2.91073
time/total (s)                    232.804
Epoch                              84
-----------------------------  ---------------
2019-04-22 21:59:53.218620 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                    0.242925
trainer/QF2 Loss                    0.226754
trainer/Policy Loss                22.172
trainer/Q1 Predictions Mean       -20.6281
trainer/Q1 Predictions Std         16.0316
trainer/Q1 Predictions Max         -8.86338
trainer/Q1 Predictions Min        -57.8242
trainer/Q2 Predictions Mean       -20.6146
trainer/Q2 Predictions Std         16.0276
trainer/Q2 Predictions Max         -8.88409
trainer/Q2 Predictions Min        -57.5793
trainer/Q Targets Mean            -20.8773
trainer/Q Targets Std              16.0378
trainer/Q Targets Max              -9.09837
trainer/Q Targets Min             -56.0355
trainer/Log Pis Mean                1.97698
trainer/Log Pis Std                 1.53474
trainer/Log Pis Max                 7.81938
trainer/Log Pis Min                -2.55902
trainer/Policy mu Mean              0.0665986
trainer/Policy mu Std               0.681574
trainer/Policy mu Max               2.97279
trainer/Policy mu Min              -3.27707
trainer/Policy log std Mean        -2.09485
trainer/Policy log std Std          0.425243
trainer/Policy log std Max         -0.264077
trainer/Policy log std Min         -2.42866
trainer/Alpha                       0.0598123
trainer/Alpha Loss                 -0.064842
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.780029
exploration/Rewards Std             0.853739
exploration/Rewards Max            -0.00451318
exploration/Rewards Min            -8.2809
exploration/Returns Mean          -78.0029
exploration/Returns Std            30.6367
exploration/Returns Max           -18.566
exploration/Returns Min          -101.681
exploration/Actions Mean            0.0238272
exploration/Actions Std             0.229919
exploration/Actions Max             0.998505
exploration/Actions Min            -0.957532
exploration/Num Paths               5
exploration/Average Returns       -78.0029
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.43311
evaluation/Rewards Std              1.10347
evaluation/Rewards Max             -0.039482
evaluation/Rewards Min            -10.5061
evaluation/Returns Mean           -43.311
evaluation/Returns Std             28.7929
evaluation/Returns Max             -8.86251
evaluation/Returns Min            -99.9869
evaluation/Actions Mean             0.00239716
evaluation/Actions Std              0.200578
evaluation/Actions Max              0.99659
evaluation/Actions Min             -0.997839
evaluation/Num Paths               15
evaluation/Average Returns        -43.311
time/data storing (s)               0.00307689
time/evaluation sampling (s)        0.387287
time/exploration sampling (s)       0.178775
time/logging (s)                    0.00508491
time/saving (s)                     0.00202614
time/training (s)                   2.17405
time/epoch (s)                      2.7503
time/total (s)                    235.559
Epoch                              85
-----------------------------  ---------------
2019-04-22 21:59:56.051329 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size              43700
trainer/QF1 Loss                    0.297702
trainer/QF2 Loss                    0.323991
trainer/Policy Loss                22.6796
trainer/Q1 Predictions Mean       -21.2514
trainer/Q1 Predictions Std         17.2967
trainer/Q1 Predictions Max         -9.06637
trainer/Q1 Predictions Min        -85.0837
trainer/Q2 Predictions Mean       -21.2668
trainer/Q2 Predictions Std         17.2902
trainer/Q2 Predictions Max         -8.97965
trainer/Q2 Predictions Min        -84.6367
trainer/Q Targets Mean            -21.5845
trainer/Q Targets Std              17.5583
trainer/Q Targets Max              -9.10274
trainer/Q Targets Min             -85.6709
trainer/Log Pis Mean                1.88564
trainer/Log Pis Std                 1.40181
trainer/Log Pis Max                 8.58018
trainer/Log Pis Min                -2.52849
trainer/Policy mu Mean              0.0594831
trainer/Policy mu Std               0.772778
trainer/Policy mu Max               3.08315
trainer/Policy mu Min              -3.71761
trainer/Policy log std Mean        -2.03002
trainer/Policy log std Std          0.477026
trainer/Policy log std Max         -0.382522
trainer/Policy log std Min         -2.44663
trainer/Alpha                       0.0572758
trainer/Alpha Loss                 -0.327053
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.257384
exploration/Rewards Std             0.565564
exploration/Rewards Max            -0.00834363
exploration/Rewards Min            -5.42525
exploration/Returns Mean          -25.7384
exploration/Returns Std             5.06525
exploration/Returns Max           -20.3219
exploration/Returns Min           -33.2279
exploration/Actions Mean           -0.0103383
exploration/Actions Std             0.211346
exploration/Actions Max             0.997889
exploration/Actions Min            -0.997187
exploration/Num Paths               5
exploration/Average Returns       -25.7384
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.445131
evaluation/Rewards Std              1.07852
evaluation/Rewards Max             -0.00480467
evaluation/Rewards Min             -9.51485
evaluation/Returns Mean           -44.5131
evaluation/Returns Std             29.3828
evaluation/Returns Max             -3.35478
evaluation/Returns Min           -104.549
evaluation/Actions Mean             0.00548785
evaluation/Actions Std              0.199472
evaluation/Actions Max              0.996864
evaluation/Actions Min             -0.998969
evaluation/Num Paths               15
evaluation/Average Returns        -44.5131
time/data storing (s)               0.00334516
time/evaluation sampling (s)        0.351996
time/exploration sampling (s)       0.168697
time/logging (s)                    0.00516534
time/saving (s)                     0.00229288
time/training (s)                   2.29474
time/epoch (s)                      2.82623
time/total (s)                    238.39
Epoch                              86
-----------------------------  ---------------
2019-04-22 21:59:58.884132 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 87 finished
-----------------------------  ----------------
replay_buffer/size              44200
trainer/QF1 Loss                    0.4166
trainer/QF2 Loss                    0.43236
trainer/Policy Loss                24.5754
trainer/Q1 Predictions Mean       -22.9229
trainer/Q1 Predictions Std         18.7625
trainer/Q1 Predictions Max         -9.08777
trainer/Q1 Predictions Min       -106.434
trainer/Q2 Predictions Mean       -22.9041
trainer/Q2 Predictions Std         18.707
trainer/Q2 Predictions Max         -9.06868
trainer/Q2 Predictions Min       -105.598
trainer/Q Targets Mean            -23.1825
trainer/Q Targets Std              19.121
trainer/Q Targets Max              -8.92901
trainer/Q Targets Min            -108.542
trainer/Log Pis Mean                2.18132
trainer/Log Pis Std                 1.55284
trainer/Log Pis Max                 8.18872
trainer/Log Pis Min                -0.9148
trainer/Policy mu Mean              0.0769428
trainer/Policy mu Std               0.855048
trainer/Policy mu Max               3.24868
trainer/Policy mu Min              -3.14948
trainer/Policy log std Mean        -2.05665
trainer/Policy log std Std          0.512364
trainer/Policy log std Max         -0.316053
trainer/Policy log std Min         -2.52271
trainer/Alpha                       0.0590961
trainer/Alpha Loss                  0.512897
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.504827
exploration/Rewards Std             1.12024
exploration/Rewards Max            -0.00296177
exploration/Rewards Min           -10.6421
exploration/Returns Mean          -50.4827
exploration/Returns Std            23.7506
exploration/Returns Max           -22.6749
exploration/Returns Min           -87.7522
exploration/Actions Mean           -0.0132245
exploration/Actions Std             0.249988
exploration/Actions Max             0.999534
exploration/Actions Min            -0.999603
exploration/Num Paths               5
exploration/Average Returns       -50.4827
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.491676
evaluation/Rewards Std              1.2715
evaluation/Rewards Max             -0.0896683
evaluation/Rewards Min            -10.6449
evaluation/Returns Mean           -49.1676
evaluation/Returns Std             30.8283
evaluation/Returns Max            -13.7265
evaluation/Returns Min           -117.475
evaluation/Actions Mean            -0.000170932
evaluation/Actions Std              0.213513
evaluation/Actions Max              0.9977
evaluation/Actions Min             -0.999363
evaluation/Num Paths               15
evaluation/Average Returns        -49.1676
time/data storing (s)               0.00345212
time/evaluation sampling (s)        0.366076
time/exploration sampling (s)       0.168093
time/logging (s)                    0.00480566
time/saving (s)                     0.00200531
time/training (s)                   2.2811
time/epoch (s)                      2.82553
time/total (s)                    241.22
Epoch                              87
-----------------------------  ----------------
2019-04-22 22:00:01.536502 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size              44700
trainer/QF1 Loss                    2.55982
trainer/QF2 Loss                    2.55658
trainer/Policy Loss                22.7443
trainer/Q1 Predictions Mean       -21.2826
trainer/Q1 Predictions Std         16.5262
trainer/Q1 Predictions Max         -8.89926
trainer/Q1 Predictions Min        -82.278
trainer/Q2 Predictions Mean       -21.3222
trainer/Q2 Predictions Std         16.5202
trainer/Q2 Predictions Max         -8.89348
trainer/Q2 Predictions Min        -82.0561
trainer/Q Targets Mean            -21.3163
trainer/Q Targets Std              16.8853
trainer/Q Targets Max              -0.121318
trainer/Q Targets Min             -81.9461
trainer/Log Pis Mean                1.78922
trainer/Log Pis Std                 1.41307
trainer/Log Pis Max                 8.09979
trainer/Log Pis Min                -2.89824
trainer/Policy mu Mean              0.0522016
trainer/Policy mu Std               0.682213
trainer/Policy mu Max               3.00504
trainer/Policy mu Min              -2.66536
trainer/Policy log std Mean        -2.04096
trainer/Policy log std Std          0.388179
trainer/Policy log std Max         -0.466775
trainer/Policy log std Min         -2.35169
trainer/Alpha                       0.0565554
trainer/Alpha Loss                 -0.605449
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.468352
exploration/Rewards Std             1.13547
exploration/Rewards Max            -0.00142133
exploration/Rewards Min           -10.0038
exploration/Returns Mean          -46.8352
exploration/Returns Std            32.8749
exploration/Returns Max           -18.9457
exploration/Returns Min          -103.343
exploration/Actions Mean            0.00253914
exploration/Actions Std             0.235387
exploration/Actions Max             0.999066
exploration/Actions Min            -0.99919
exploration/Num Paths               5
exploration/Average Returns       -46.8352
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.299821
evaluation/Rewards Std              0.941119
evaluation/Rewards Max             -0.0450965
evaluation/Rewards Min             -9.32448
evaluation/Returns Mean           -29.9821
evaluation/Returns Std             17.0104
evaluation/Returns Max            -12.7703
evaluation/Returns Min            -75.2499
evaluation/Actions Mean            -0.00158782
evaluation/Actions Std              0.189472
evaluation/Actions Max              0.996347
evaluation/Actions Min             -0.998921
evaluation/Num Paths               15
evaluation/Average Returns        -29.9821
time/data storing (s)               0.00298028
time/evaluation sampling (s)        0.361377
time/exploration sampling (s)       0.161367
time/logging (s)                    0.00477578
time/saving (s)                     0.00204873
time/training (s)                   2.11288
time/epoch (s)                      2.64543
time/total (s)                    243.871
Epoch                              88
-----------------------------  ---------------
2019-04-22 22:00:04.223507 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 89 finished
-----------------------------  ---------------
replay_buffer/size              45200
trainer/QF1 Loss                   19.887
trainer/QF2 Loss                   20.0357
trainer/Policy Loss                23.4393
trainer/Q1 Predictions Mean       -21.8704
trainer/Q1 Predictions Std         17.1109
trainer/Q1 Predictions Max         -8.82135
trainer/Q1 Predictions Min        -67.6428
trainer/Q2 Predictions Mean       -21.8526
trainer/Q2 Predictions Std         17.0812
trainer/Q2 Predictions Max         -8.75119
trainer/Q2 Predictions Min        -67.697
trainer/Q Targets Mean            -21.6787
trainer/Q Targets Std              17.4503
trainer/Q Targets Max              -0.889479
trainer/Q Targets Min             -70.0348
trainer/Log Pis Mean                1.98889
trainer/Log Pis Std                 1.53486
trainer/Log Pis Max                 8.03097
trainer/Log Pis Min                -1.49354
trainer/Policy mu Mean             -0.0141753
trainer/Policy mu Std               0.739973
trainer/Policy mu Max               3.09115
trainer/Policy mu Min              -3.23481
trainer/Policy log std Mean        -2.0214
trainer/Policy log std Std          0.42072
trainer/Policy log std Max         -0.157959
trainer/Policy log std Min         -2.42603
trainer/Alpha                       0.0542751
trainer/Alpha Loss                 -0.0323676
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.448033
exploration/Rewards Std             0.867617
exploration/Rewards Max            -0.0159799
exploration/Rewards Min            -7.31005
exploration/Returns Mean          -44.8033
exploration/Returns Std            27.8604
exploration/Returns Max           -19.7979
exploration/Returns Min           -97.27
exploration/Actions Mean            0.00284262
exploration/Actions Std             0.239289
exploration/Actions Max             0.999256
exploration/Actions Min            -0.996842
exploration/Num Paths               5
exploration/Average Returns       -44.8033
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.307504
evaluation/Rewards Std              0.824639
evaluation/Rewards Max             -0.0418576
evaluation/Rewards Min             -9.73514
evaluation/Returns Mean           -30.7504
evaluation/Returns Std             28.1312
evaluation/Returns Max             -7.01445
evaluation/Returns Min           -105.943
evaluation/Actions Mean             0.00871483
evaluation/Actions Std              0.171163
evaluation/Actions Max              0.997004
evaluation/Actions Min             -0.997025
evaluation/Num Paths               15
evaluation/Average Returns        -30.7504
time/data storing (s)               0.0030107
time/evaluation sampling (s)        0.347706
time/exploration sampling (s)       0.160932
time/logging (s)                    0.00473237
time/saving (s)                     0.00195886
time/training (s)                   2.16233
time/epoch (s)                      2.68067
time/total (s)                    246.556
Epoch                              89
-----------------------------  ---------------
2019-04-22 22:00:06.879257 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size              45700
trainer/QF1 Loss                    0.424625
trainer/QF2 Loss                    0.459249
trainer/Policy Loss                23.746
trainer/Q1 Predictions Mean       -22.1698
trainer/Q1 Predictions Std         17.9425
trainer/Q1 Predictions Max         -8.62672
trainer/Q1 Predictions Min        -98.9453
trainer/Q2 Predictions Mean       -22.1894
trainer/Q2 Predictions Std         17.9627
trainer/Q2 Predictions Max         -8.63514
trainer/Q2 Predictions Min        -98.2423
trainer/Q Targets Mean            -22.5286
trainer/Q Targets Std              18.3467
trainer/Q Targets Max              -8.69542
trainer/Q Targets Min            -102.255
trainer/Log Pis Mean                1.97013
trainer/Log Pis Std                 1.50994
trainer/Log Pis Max                 6.1648
trainer/Log Pis Min                -2.68254
trainer/Policy mu Mean              0.0513377
trainer/Policy mu Std               0.820853
trainer/Policy mu Max               3.27918
trainer/Policy mu Min              -3.06577
trainer/Policy log std Mean        -2.08403
trainer/Policy log std Std          0.466031
trainer/Policy log std Max         -0.456357
trainer/Policy log std Min         -2.45818
trainer/Alpha                       0.051738
trainer/Alpha Loss                 -0.0884511
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354536
exploration/Rewards Std             0.626246
exploration/Rewards Max            -0.00410426
exploration/Rewards Min            -6.6301
exploration/Returns Mean          -35.4536
exploration/Returns Std            23.8493
exploration/Returns Max           -14.2493
exploration/Returns Min           -81.6223
exploration/Actions Mean           -0.018542
exploration/Actions Std             0.204414
exploration/Actions Max             0.995245
exploration/Actions Min            -0.997802
exploration/Num Paths               5
exploration/Average Returns       -35.4536
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.445689
evaluation/Rewards Std              1.08114
evaluation/Rewards Max             -0.0505725
evaluation/Rewards Min            -10.9689
evaluation/Returns Mean           -44.5689
evaluation/Returns Std             36.8064
evaluation/Returns Max             -7.02249
evaluation/Returns Min           -129.545
evaluation/Actions Mean            -0.00612711
evaluation/Actions Std              0.190865
evaluation/Actions Max              0.997382
evaluation/Actions Min             -0.999657
evaluation/Num Paths               15
evaluation/Average Returns        -44.5689
time/data storing (s)               0.00315359
time/evaluation sampling (s)        0.355359
time/exploration sampling (s)       0.161416
time/logging (s)                    0.0050353
time/saving (s)                     0.00197146
time/training (s)                   2.12232
time/epoch (s)                      2.64926
time/total (s)                    249.21
Epoch                              90
-----------------------------  ---------------
2019-04-22 22:00:09.587756 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                   21.0894
trainer/QF2 Loss                   20.9975
trainer/Policy Loss                21.6338
trainer/Q1 Predictions Mean       -20.2215
trainer/Q1 Predictions Std         16.6794
trainer/Q1 Predictions Max         -8.56874
trainer/Q1 Predictions Min        -60.0567
trainer/Q2 Predictions Mean       -20.2221
trainer/Q2 Predictions Std         16.6786
trainer/Q2 Predictions Max         -8.5442
trainer/Q2 Predictions Min        -59.5663
trainer/Q Targets Mean            -19.8509
trainer/Q Targets Std              16.6625
trainer/Q Targets Max              -0.0893291
trainer/Q Targets Min             -58.0653
trainer/Log Pis Mean                1.96403
trainer/Log Pis Std                 1.30352
trainer/Log Pis Max                 6.66715
trainer/Log Pis Min                -2.39974
trainer/Policy mu Mean              0.045746
trainer/Policy mu Std               0.797611
trainer/Policy mu Max               3.17049
trainer/Policy mu Min              -2.84229
trainer/Policy log std Mean        -2.01859
trainer/Policy log std Std          0.490937
trainer/Policy log std Max         -0.514233
trainer/Policy log std Min         -2.4773
trainer/Alpha                       0.0524008
trainer/Alpha Loss                 -0.106083
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.536752
exploration/Rewards Std             1.25264
exploration/Rewards Max            -0.0125956
exploration/Rewards Min           -10.2124
exploration/Returns Mean          -53.6752
exploration/Returns Std            18.2575
exploration/Returns Max           -38.0712
exploration/Returns Min           -82.1098
exploration/Actions Mean           -0.0128514
exploration/Actions Std             0.260039
exploration/Actions Max             0.997369
exploration/Actions Min            -0.999664
exploration/Num Paths               5
exploration/Average Returns       -53.6752
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.425092
evaluation/Rewards Std              1.02254
evaluation/Rewards Max             -0.0127798
evaluation/Rewards Min            -10.785
evaluation/Returns Mean           -42.5092
evaluation/Returns Std             27.8479
evaluation/Returns Max             -9.68499
evaluation/Returns Min            -95.1297
evaluation/Actions Mean             0.0209892
evaluation/Actions Std              0.192467
evaluation/Actions Max              0.995862
evaluation/Actions Min             -0.998571
evaluation/Num Paths               15
evaluation/Average Returns        -42.5092
time/data storing (s)               0.00336978
time/evaluation sampling (s)        0.362239
time/exploration sampling (s)       0.160931
time/logging (s)                    0.00426085
time/saving (s)                     0.00198681
time/training (s)                   2.16841
time/epoch (s)                      2.7012
time/total (s)                    251.916
Epoch                              91
-----------------------------  ---------------
2019-04-22 22:00:12.281026 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size              46700
trainer/QF1 Loss                    2.53111
trainer/QF2 Loss                    2.63653
trainer/Policy Loss                23.1714
trainer/Q1 Predictions Mean       -21.7998
trainer/Q1 Predictions Std         16.6518
trainer/Q1 Predictions Max         -8.40346
trainer/Q1 Predictions Min        -59.064
trainer/Q2 Predictions Mean       -21.7699
trainer/Q2 Predictions Std         16.598
trainer/Q2 Predictions Max         -8.45394
trainer/Q2 Predictions Min        -58.6152
trainer/Q Targets Mean            -22.0074
trainer/Q Targets Std              17.177
trainer/Q Targets Max              -0.184606
trainer/Q Targets Min             -60.8733
trainer/Log Pis Mean                1.88676
trainer/Log Pis Std                 1.49351
trainer/Log Pis Max                 7.41473
trainer/Log Pis Min                -3.64804
trainer/Policy mu Mean             -0.00751663
trainer/Policy mu Std               0.772422
trainer/Policy mu Max               2.84332
trainer/Policy mu Min              -3.27528
trainer/Policy log std Mean        -2.04484
trainer/Policy log std Std          0.488535
trainer/Policy log std Max         -0.224921
trainer/Policy log std Min         -2.5922
trainer/Alpha                       0.0543279
trainer/Alpha Loss                 -0.329829
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.316326
exploration/Rewards Std             1.10873
exploration/Rewards Max            -0.00686494
exploration/Rewards Min           -10.9742
exploration/Returns Mean          -31.6326
exploration/Returns Std            23.6082
exploration/Returns Max           -11.8759
exploration/Returns Min           -69.989
exploration/Actions Mean           -0.0156143
exploration/Actions Std             0.214335
exploration/Actions Max             0.995162
exploration/Actions Min            -0.999798
exploration/Num Paths               5
exploration/Average Returns       -31.6326
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.390557
evaluation/Rewards Std              0.929677
evaluation/Rewards Max             -0.00391144
evaluation/Rewards Min             -9.54596
evaluation/Returns Mean           -39.0557
evaluation/Returns Std             25.0714
evaluation/Returns Max             -6.12276
evaluation/Returns Min            -82.2578
evaluation/Actions Mean            -0.00880321
evaluation/Actions Std              0.192762
evaluation/Actions Max              0.995913
evaluation/Actions Min             -0.999199
evaluation/Num Paths               15
evaluation/Average Returns        -39.0557
time/data storing (s)               0.00355247
time/evaluation sampling (s)        0.350564
time/exploration sampling (s)       0.158079
time/logging (s)                    0.00484058
time/saving (s)                     0.0109393
time/training (s)                   2.16032
time/epoch (s)                      2.68829
time/total (s)                    254.608
Epoch                              92
-----------------------------  ---------------
2019-04-22 22:00:14.975718 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size              47200
trainer/QF1 Loss                    0.94429
trainer/QF2 Loss                    0.966268
trainer/Policy Loss                24.1328
trainer/Q1 Predictions Mean       -22.8419
trainer/Q1 Predictions Std         17.4108
trainer/Q1 Predictions Max         -8.51706
trainer/Q1 Predictions Min        -66.2828
trainer/Q2 Predictions Mean       -22.8326
trainer/Q2 Predictions Std         17.4064
trainer/Q2 Predictions Max         -8.53137
trainer/Q2 Predictions Min        -66.7988
trainer/Q Targets Mean            -22.7971
trainer/Q Targets Std              17.462
trainer/Q Targets Max              -0.192566
trainer/Q Targets Min             -62.7373
trainer/Log Pis Mean                1.77668
trainer/Log Pis Std                 1.18307
trainer/Log Pis Max                 6.56875
trainer/Log Pis Min                -1.68088
trainer/Policy mu Mean              0.0548027
trainer/Policy mu Std               0.716681
trainer/Policy mu Max               3.0786
trainer/Policy mu Min              -3.11761
trainer/Policy log std Mean        -1.97017
trainer/Policy log std Std          0.44947
trainer/Policy log std Max         -0.437094
trainer/Policy log std Min         -2.51408
trainer/Alpha                       0.0549741
trainer/Alpha Loss                 -0.647782
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.635631
exploration/Rewards Std             1.39218
exploration/Rewards Max            -0.00275504
exploration/Rewards Min           -10.2591
exploration/Returns Mean          -63.5631
exploration/Returns Std            20.0401
exploration/Returns Max           -40.8087
exploration/Returns Min           -93.4489
exploration/Actions Mean            0.0158365
exploration/Actions Std             0.264738
exploration/Actions Max             0.998749
exploration/Actions Min            -0.999802
exploration/Num Paths               5
exploration/Average Returns       -63.5631
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.548864
evaluation/Rewards Std              1.09974
evaluation/Rewards Max             -0.0377867
evaluation/Rewards Min             -9.84058
evaluation/Returns Mean           -54.8864
evaluation/Returns Std             30.4564
evaluation/Returns Max             -7.53246
evaluation/Returns Min           -124.15
evaluation/Actions Mean             0.0147089
evaluation/Actions Std              0.19302
evaluation/Actions Max              0.99804
evaluation/Actions Min             -0.998895
evaluation/Num Paths               15
evaluation/Average Returns        -54.8864
time/data storing (s)               0.00329088
time/evaluation sampling (s)        0.357463
time/exploration sampling (s)       0.160917
time/logging (s)                    0.00554621
time/saving (s)                     0.00204357
time/training (s)                   2.15988
time/epoch (s)                      2.68914
time/total (s)                    257.302
Epoch                              93
-----------------------------  ---------------
2019-04-22 22:00:17.644432 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 94 finished
-----------------------------  ----------------
replay_buffer/size              47700
trainer/QF1 Loss                   19.8074
trainer/QF2 Loss                   19.8301
trainer/Policy Loss                20.6224
trainer/Q1 Predictions Mean       -18.8949
trainer/Q1 Predictions Std         15.953
trainer/Q1 Predictions Max         -8.54478
trainer/Q1 Predictions Min        -74.0145
trainer/Q2 Predictions Mean       -18.8718
trainer/Q2 Predictions Std         15.9568
trainer/Q2 Predictions Max         -8.58374
trainer/Q2 Predictions Min        -74.0262
trainer/Q Targets Mean            -18.4161
trainer/Q Targets Std              15.793
trainer/Q Targets Max              -1.03163
trainer/Q Targets Min             -73.2067
trainer/Log Pis Mean                1.89133
trainer/Log Pis Std                 1.40292
trainer/Log Pis Max                 7.38976
trainer/Log Pis Min                -3.37011
trainer/Policy mu Mean              0.0456019
trainer/Policy mu Std               0.577071
trainer/Policy mu Max               3.01284
trainer/Policy mu Min              -2.92294
trainer/Policy log std Mean        -2.1587
trainer/Policy log std Std          0.381887
trainer/Policy log std Max         -0.414391
trainer/Policy log std Min         -2.56402
trainer/Alpha                       0.0560856
trainer/Alpha Loss                 -0.31307
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.250885
exploration/Rewards Std             0.635405
exploration/Rewards Max            -0.00213776
exploration/Rewards Min            -7.7086
exploration/Returns Mean          -25.0885
exploration/Returns Std            12.4155
exploration/Returns Max           -15.3576
exploration/Returns Min           -49.4915
exploration/Actions Mean            0.000722679
exploration/Actions Std             0.189797
exploration/Actions Max             0.992662
exploration/Actions Min            -0.999819
exploration/Num Paths               5
exploration/Average Returns       -25.0885
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.375615
evaluation/Rewards Std              0.988272
evaluation/Rewards Max             -0.0323792
evaluation/Rewards Min            -11.4213
evaluation/Returns Mean           -37.5615
evaluation/Returns Std             28.0629
evaluation/Returns Max             -8.82475
evaluation/Returns Min           -115.194
evaluation/Actions Mean            -0.00304771
evaluation/Actions Std              0.190081
evaluation/Actions Max              0.997417
evaluation/Actions Min             -0.998311
evaluation/Num Paths               15
evaluation/Average Returns        -37.5615
time/data storing (s)               0.00448975
time/evaluation sampling (s)        0.361605
time/exploration sampling (s)       0.163653
time/logging (s)                    0.00526647
time/saving (s)                     0.00187549
time/training (s)                   2.12431
time/epoch (s)                      2.6612
time/total (s)                    259.968
Epoch                              94
-----------------------------  ----------------
2019-04-22 22:00:20.290868 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                    3.12715
trainer/QF2 Loss                    3.12492
trainer/Policy Loss                22.2855
trainer/Q1 Predictions Mean       -20.8231
trainer/Q1 Predictions Std         18.9982
trainer/Q1 Predictions Max         -8.35269
trainer/Q1 Predictions Min       -106.736
trainer/Q2 Predictions Mean       -20.8292
trainer/Q2 Predictions Std         18.9899
trainer/Q2 Predictions Max         -8.36404
trainer/Q2 Predictions Min       -106.45
trainer/Q Targets Mean            -20.8861
trainer/Q Targets Std              19.7188
trainer/Q Targets Max              -0.131161
trainer/Q Targets Min            -108.923
trainer/Log Pis Mean                2.13752
trainer/Log Pis Std                 1.49422
trainer/Log Pis Max                 9.14869
trainer/Log Pis Min                -1.66364
trainer/Policy mu Mean              0.0906712
trainer/Policy mu Std               0.815281
trainer/Policy mu Max               3.26409
trainer/Policy mu Min              -2.78557
trainer/Policy log std Mean        -2.01611
trainer/Policy log std Std          0.527221
trainer/Policy log std Max         -0.317352
trainer/Policy log std Min         -2.50376
trainer/Alpha                       0.0577802
trainer/Alpha Loss                  0.392106
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.536937
exploration/Rewards Std             1.10719
exploration/Rewards Max            -0.0169261
exploration/Rewards Min            -8.39247
exploration/Returns Mean          -53.6937
exploration/Returns Std            27.581
exploration/Returns Max           -24.3521
exploration/Returns Min          -106.213
exploration/Actions Mean           -0.00388546
exploration/Actions Std             0.258066
exploration/Actions Max             0.999014
exploration/Actions Min            -0.998868
exploration/Num Paths               5
exploration/Average Returns       -53.6937
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.448407
evaluation/Rewards Std              1.17373
evaluation/Rewards Max             -0.00311032
evaluation/Rewards Min            -10.0524
evaluation/Returns Mean           -44.8407
evaluation/Returns Std             38.0546
evaluation/Returns Max             -7.6068
evaluation/Returns Min           -121.264
evaluation/Actions Mean            -0.00659018
evaluation/Actions Std              0.202169
evaluation/Actions Max              0.997306
evaluation/Actions Min             -0.998852
evaluation/Num Paths               15
evaluation/Average Returns        -44.8407
time/data storing (s)               0.00354132
time/evaluation sampling (s)        0.353453
time/exploration sampling (s)       0.171409
time/logging (s)                    0.00468088
time/saving (s)                     0.00203676
time/training (s)                   2.10401
time/epoch (s)                      2.63913
time/total (s)                    262.612
Epoch                              95
-----------------------------  ---------------
2019-04-22 22:00:22.985273 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 96 finished
-----------------------------  ----------------
replay_buffer/size              48700
trainer/QF1 Loss                    0.193333
trainer/QF2 Loss                    0.164848
trainer/Policy Loss                23.6141
trainer/Q1 Predictions Mean       -21.788
trainer/Q1 Predictions Std         18.6628
trainer/Q1 Predictions Max         -8.32877
trainer/Q1 Predictions Min        -92.4193
trainer/Q2 Predictions Mean       -21.7968
trainer/Q2 Predictions Std         18.6536
trainer/Q2 Predictions Max         -8.3866
trainer/Q2 Predictions Min        -91.8754
trainer/Q Targets Mean            -21.8382
trainer/Q Targets Std              18.823
trainer/Q Targets Max              -8.36249
trainer/Q Targets Min             -93.2999
trainer/Log Pis Mean                2.01715
trainer/Log Pis Std                 1.48197
trainer/Log Pis Max                 9.29983
trainer/Log Pis Min                -1.95512
trainer/Policy mu Mean              0.1347
trainer/Policy mu Std               0.744472
trainer/Policy mu Max               3.29326
trainer/Policy mu Min              -2.96804
trainer/Policy log std Mean        -2.09876
trainer/Policy log std Std          0.470178
trainer/Policy log std Max         -0.420777
trainer/Policy log std Min         -2.55612
trainer/Alpha                       0.0583814
trainer/Alpha Loss                  0.0487298
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.399159
exploration/Rewards Std             1.25402
exploration/Rewards Max            -0.00526941
exploration/Rewards Min            -9.77059
exploration/Returns Mean          -39.9159
exploration/Returns Std            20.2231
exploration/Returns Max           -11.6056
exploration/Returns Min           -59.8773
exploration/Actions Mean            0.000805953
exploration/Actions Std             0.24053
exploration/Actions Max             0.99957
exploration/Actions Min            -0.999572
exploration/Num Paths               5
exploration/Average Returns       -39.9159
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.35645
evaluation/Rewards Std              0.89462
evaluation/Rewards Max             -0.00900199
evaluation/Rewards Min             -9.4793
evaluation/Returns Mean           -35.645
evaluation/Returns Std             20.4156
evaluation/Returns Max             -7.79587
evaluation/Returns Min            -68.3086
evaluation/Actions Mean             0.00189296
evaluation/Actions Std              0.180677
evaluation/Actions Max              0.9972
evaluation/Actions Min             -0.997261
evaluation/Num Paths               15
evaluation/Average Returns        -35.645
time/data storing (s)               0.00470185
time/evaluation sampling (s)        0.356143
time/exploration sampling (s)       0.190185
time/logging (s)                    0.00523378
time/saving (s)                     0.00222276
time/training (s)                   2.13001
time/epoch (s)                      2.6885
time/total (s)                    265.305
Epoch                              96
-----------------------------  ----------------
2019-04-22 22:00:25.636916 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                    0.957957
trainer/QF2 Loss                    0.982658
trainer/Policy Loss                22.4314
trainer/Q1 Predictions Mean       -20.9981
trainer/Q1 Predictions Std         18.8179
trainer/Q1 Predictions Max         -8.18814
trainer/Q1 Predictions Min        -95.0627
trainer/Q2 Predictions Mean       -20.9848
trainer/Q2 Predictions Std         18.8613
trainer/Q2 Predictions Max         -8.21006
trainer/Q2 Predictions Min        -94.9856
trainer/Q Targets Mean            -21.0971
trainer/Q Targets Std              19.0757
trainer/Q Targets Max              -0.118052
trainer/Q Targets Min             -97.8683
trainer/Log Pis Mean                2.04343
trainer/Log Pis Std                 1.11921
trainer/Log Pis Max                 5.86458
trainer/Log Pis Min                -1.00779
trainer/Policy mu Mean              0.0880135
trainer/Policy mu Std               0.76319
trainer/Policy mu Max               3.25115
trainer/Policy mu Min              -3.69652
trainer/Policy log std Mean        -2.05157
trainer/Policy log std Std          0.502502
trainer/Policy log std Max         -0.387627
trainer/Policy log std Min         -2.49576
trainer/Alpha                       0.0592955
trainer/Alpha Loss                  0.122697
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.319443
exploration/Rewards Std             0.508052
exploration/Rewards Max            -0.012879
exploration/Rewards Min            -5.14391
exploration/Returns Mean          -31.9443
exploration/Returns Std            21.9681
exploration/Returns Max           -14.3466
exploration/Returns Min           -74.9339
exploration/Actions Mean            0.00642493
exploration/Actions Std             0.20106
exploration/Actions Max             0.999157
exploration/Actions Min            -0.995308
exploration/Num Paths               5
exploration/Average Returns       -31.9443
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.379784
evaluation/Rewards Std              0.975827
evaluation/Rewards Max             -0.0185404
evaluation/Rewards Min            -10.1091
evaluation/Returns Mean           -37.9784
evaluation/Returns Std             27.496
evaluation/Returns Max             -4.72747
evaluation/Returns Min            -80.4028
evaluation/Actions Mean            -0.00353904
evaluation/Actions Std              0.182705
evaluation/Actions Max              0.996951
evaluation/Actions Min             -0.999146
evaluation/Num Paths               15
evaluation/Average Returns        -37.9784
time/data storing (s)               0.00335011
time/evaluation sampling (s)        0.348149
time/exploration sampling (s)       0.158377
time/logging (s)                    0.00493011
time/saving (s)                     0.00196662
time/training (s)                   2.12802
time/epoch (s)                      2.64479
time/total (s)                    267.954
Epoch                              97
-----------------------------  ---------------
2019-04-22 22:00:28.341374 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                    0.154634
trainer/QF2 Loss                    0.178049
trainer/Policy Loss                21.8362
trainer/Q1 Predictions Mean       -20.3474
trainer/Q1 Predictions Std         16.3987
trainer/Q1 Predictions Max         -8.15045
trainer/Q1 Predictions Min        -59.0124
trainer/Q2 Predictions Mean       -20.3506
trainer/Q2 Predictions Std         16.3933
trainer/Q2 Predictions Max         -8.23325
trainer/Q2 Predictions Min        -59.6418
trainer/Q Targets Mean            -20.5653
trainer/Q Targets Std              16.5604
trainer/Q Targets Max              -8.27646
trainer/Q Targets Min             -59.5735
trainer/Log Pis Mean                1.95602
trainer/Log Pis Std                 1.43128
trainer/Log Pis Max                 6.96276
trainer/Log Pis Min                -2.10714
trainer/Policy mu Mean              0.0413465
trainer/Policy mu Std               0.76848
trainer/Policy mu Max               2.78441
trainer/Policy mu Min              -3.34412
trainer/Policy log std Mean        -1.97181
trainer/Policy log std Std          0.489697
trainer/Policy log std Max         -0.363164
trainer/Policy log std Min         -2.49444
trainer/Alpha                       0.0590167
trainer/Alpha Loss                 -0.124455
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.728413
exploration/Rewards Std             1.07295
exploration/Rewards Max            -0.0135892
exploration/Rewards Min            -9.26447
exploration/Returns Mean          -72.8413
exploration/Returns Std            45.5271
exploration/Returns Max           -18.8033
exploration/Returns Min          -120.345
exploration/Actions Mean            0.018429
exploration/Actions Std             0.241436
exploration/Actions Max             0.999448
exploration/Actions Min            -0.990676
exploration/Num Paths               5
exploration/Average Returns       -72.8413
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.454734
evaluation/Rewards Std              1.05575
evaluation/Rewards Max             -0.0242067
evaluation/Rewards Min             -9.69646
evaluation/Returns Mean           -45.4734
evaluation/Returns Std             37.2033
evaluation/Returns Max             -7.3568
evaluation/Returns Min           -115.031
evaluation/Actions Mean            -0.0107784
evaluation/Actions Std              0.190864
evaluation/Actions Max              0.996821
evaluation/Actions Min             -0.998058
evaluation/Num Paths               15
evaluation/Average Returns        -45.4734
time/data storing (s)               0.00303491
time/evaluation sampling (s)        0.358208
time/exploration sampling (s)       0.161333
time/logging (s)                    0.00481636
time/saving (s)                     0.001962
time/training (s)                   2.16781
time/epoch (s)                      2.69716
time/total (s)                    270.656
Epoch                              98
-----------------------------  ---------------
2019-04-22 22:00:31.015304 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                    0.58432
trainer/QF2 Loss                    0.53751
trainer/Policy Loss                20.8982
trainer/Q1 Predictions Mean       -19.2066
trainer/Q1 Predictions Std         15.7226
trainer/Q1 Predictions Max         -7.59363
trainer/Q1 Predictions Min        -59.4495
trainer/Q2 Predictions Mean       -19.2366
trainer/Q2 Predictions Std         15.7399
trainer/Q2 Predictions Max         -7.69816
trainer/Q2 Predictions Min        -58.8916
trainer/Q Targets Mean            -19.7882
trainer/Q Targets Std              16.1049
trainer/Q Targets Max              -8.19216
trainer/Q Targets Min             -61.2914
trainer/Log Pis Mean                1.96595
trainer/Log Pis Std                 1.19322
trainer/Log Pis Max                 6.07684
trainer/Log Pis Min                -1.79072
trainer/Policy mu Mean              0.0809367
trainer/Policy mu Std               0.634646
trainer/Policy mu Max               3.26629
trainer/Policy mu Min              -2.7597
trainer/Policy log std Mean        -2.11375
trainer/Policy log std Std          0.417165
trainer/Policy log std Max         -0.415212
trainer/Policy log std Min         -2.52006
trainer/Alpha                       0.057641
trainer/Alpha Loss                 -0.0971553
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.408016
exploration/Rewards Std             1.09095
exploration/Rewards Max            -0.0138485
exploration/Rewards Min            -9.63604
exploration/Returns Mean          -40.8016
exploration/Returns Std            26.4291
exploration/Returns Max           -11.7278
exploration/Returns Min           -81.4334
exploration/Actions Mean            0.0269907
exploration/Actions Std             0.230717
exploration/Actions Max             0.999897
exploration/Actions Min            -0.998446
exploration/Num Paths               5
exploration/Average Returns       -40.8016
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.423696
evaluation/Rewards Std              1.13339
evaluation/Rewards Max             -0.0169661
evaluation/Rewards Min            -11.1359
evaluation/Returns Mean           -42.3696
evaluation/Returns Std             27.5255
evaluation/Returns Max             -4.03609
evaluation/Returns Min            -84.0253
evaluation/Actions Mean            -0.00469715
evaluation/Actions Std              0.194907
evaluation/Actions Max              0.997261
evaluation/Actions Min             -0.998404
evaluation/Num Paths               15
evaluation/Average Returns        -42.3696
time/data storing (s)               0.003249
time/evaluation sampling (s)        0.357292
time/exploration sampling (s)       0.163179
time/logging (s)                    0.00493144
time/saving (s)                     0.00189102
time/training (s)                   2.13762
time/epoch (s)                      2.66816
time/total (s)                    273.328
Epoch                              99
-----------------------------  ---------------
2019-04-22 22:00:33.734794 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 100 finished
-----------------------------  ----------------
replay_buffer/size              50700
trainer/QF1 Loss                   21.1709
trainer/QF2 Loss                   21.0029
trainer/Policy Loss                21.4569
trainer/Q1 Predictions Mean       -19.8505
trainer/Q1 Predictions Std         16.2715
trainer/Q1 Predictions Max         -7.96054
trainer/Q1 Predictions Min        -51.5369
trainer/Q2 Predictions Mean       -19.8305
trainer/Q2 Predictions Std         16.2729
trainer/Q2 Predictions Max         -7.98947
trainer/Q2 Predictions Min        -51.6945
trainer/Q Targets Mean            -19.3692
trainer/Q Targets Std              16.5889
trainer/Q Targets Max              -0.0914623
trainer/Q Targets Min             -51.9464
trainer/Log Pis Mean                2.24118
trainer/Log Pis Std                 1.11305
trainer/Log Pis Max                 5.96077
trainer/Log Pis Min                -0.33052
trainer/Policy mu Mean              0.0743306
trainer/Policy mu Std               0.746246
trainer/Policy mu Max               2.96755
trainer/Policy mu Min              -2.88352
trainer/Policy log std Mean        -2.08173
trainer/Policy log std Std          0.49536
trainer/Policy log std Max         -0.517055
trainer/Policy log std Min         -2.47837
trainer/Alpha                       0.0600198
trainer/Alpha Loss                  0.678517
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.490192
exploration/Rewards Std             1.27849
exploration/Rewards Max            -0.00891598
exploration/Rewards Min           -10.0533
exploration/Returns Mean          -49.0192
exploration/Returns Std            18.8559
exploration/Returns Max           -15.4053
exploration/Returns Min           -67.3278
exploration/Actions Mean           -0.012711
exploration/Actions Std             0.239579
exploration/Actions Max             0.999056
exploration/Actions Min            -0.999526
exploration/Num Paths               5
exploration/Average Returns       -49.0192
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.341515
evaluation/Rewards Std              1.038
evaluation/Rewards Max             -0.00833993
evaluation/Rewards Min            -10.7836
evaluation/Returns Mean           -34.1515
evaluation/Returns Std             19.7156
evaluation/Returns Max             -2.29295
evaluation/Returns Min            -65.0495
evaluation/Actions Mean            -0.000744451
evaluation/Actions Std              0.192642
evaluation/Actions Max              0.997324
evaluation/Actions Min             -0.999618
evaluation/Num Paths               15
evaluation/Average Returns        -34.1515
time/data storing (s)               0.0034818
time/evaluation sampling (s)        0.34978
time/exploration sampling (s)       0.158591
time/logging (s)                    0.00507016
time/saving (s)                     0.00195991
time/training (s)                   2.19444
time/epoch (s)                      2.71332
time/total (s)                    276.046
Epoch                             100
-----------------------------  ----------------
2019-04-22 22:00:36.425072 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              51200
trainer/QF1 Loss                    0.195118
trainer/QF2 Loss                    0.201581
trainer/Policy Loss                22.5415
trainer/Q1 Predictions Mean       -20.7379
trainer/Q1 Predictions Std         16.2838
trainer/Q1 Predictions Max         -8.00663
trainer/Q1 Predictions Min        -59.1475
trainer/Q2 Predictions Mean       -20.7524
trainer/Q2 Predictions Std         16.2741
trainer/Q2 Predictions Max         -8.0221
trainer/Q2 Predictions Min        -59.2987
trainer/Q Targets Mean            -20.9843
trainer/Q Targets Std              16.4532
trainer/Q Targets Max              -7.94026
trainer/Q Targets Min             -58.1787
trainer/Log Pis Mean                2.04363
trainer/Log Pis Std                 1.47624
trainer/Log Pis Max                 9.4553
trainer/Log Pis Min                -2.64213
trainer/Policy mu Mean              0.101693
trainer/Policy mu Std               0.783902
trainer/Policy mu Max               2.65781
trainer/Policy mu Min              -3.60926
trainer/Policy log std Mean        -2.0471
trainer/Policy log std Std          0.499908
trainer/Policy log std Max         -0.208203
trainer/Policy log std Min         -2.52347
trainer/Alpha                       0.0602337
trainer/Alpha Loss                  0.122597
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.47627
exploration/Rewards Std             0.923083
exploration/Rewards Max            -0.0167855
exploration/Rewards Min            -8.71191
exploration/Returns Mean          -47.627
exploration/Returns Std            20.1378
exploration/Returns Max           -13.02
exploration/Returns Min           -75.4344
exploration/Actions Mean            0.00477813
exploration/Actions Std             0.219522
exploration/Actions Max             0.993585
exploration/Actions Min            -0.999095
exploration/Num Paths               5
exploration/Average Returns       -47.627
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.288777
evaluation/Rewards Std              1.11453
evaluation/Rewards Max             -0.0150529
evaluation/Rewards Min            -11.3218
evaluation/Returns Mean           -28.8777
evaluation/Returns Std             18.3872
evaluation/Returns Max             -4.90458
evaluation/Returns Min            -62.8443
evaluation/Actions Mean             0.00168242
evaluation/Actions Std              0.198205
evaluation/Actions Max              0.996506
evaluation/Actions Min             -0.999232
evaluation/Num Paths               15
evaluation/Average Returns        -28.8777
time/data storing (s)               0.00369768
time/evaluation sampling (s)        0.355744
time/exploration sampling (s)       0.16648
time/logging (s)                    0.0048598
time/saving (s)                     0.00200351
time/training (s)                   2.15069
time/epoch (s)                      2.68348
time/total (s)                    278.734
Epoch                             101
-----------------------------  ---------------
2019-04-22 22:00:39.129323 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              51700
trainer/QF1 Loss                   18.4794
trainer/QF2 Loss                   18.4159
trainer/Policy Loss                21.9719
trainer/Q1 Predictions Mean       -20.3091
trainer/Q1 Predictions Std         16.0482
trainer/Q1 Predictions Max         -7.81278
trainer/Q1 Predictions Min        -57.465
trainer/Q2 Predictions Mean       -20.2905
trainer/Q2 Predictions Std         16.04
trainer/Q2 Predictions Max         -7.91825
trainer/Q2 Predictions Min        -57.7471
trainer/Q Targets Mean            -19.9106
trainer/Q Targets Std              15.9677
trainer/Q Targets Max              -1.87697
trainer/Q Targets Min             -57.0154
trainer/Log Pis Mean                2.27476
trainer/Log Pis Std                 1.34795
trainer/Log Pis Max                 8.02938
trainer/Log Pis Min                -1.01237
trainer/Policy mu Mean              0.04012
trainer/Policy mu Std               0.836967
trainer/Policy mu Max               2.82737
trainer/Policy mu Min              -3.11843
trainer/Policy log std Mean        -2.02139
trainer/Policy log std Std          0.529994
trainer/Policy log std Max         -0.420169
trainer/Policy log std Min         -2.47054
trainer/Alpha                       0.0617359
trainer/Alpha Loss                  0.765226
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.490192
exploration/Rewards Std             1.25685
exploration/Rewards Max            -0.00742531
exploration/Rewards Min           -11.1491
exploration/Returns Mean          -49.0192
exploration/Returns Std            20.6686
exploration/Returns Max           -23.4142
exploration/Returns Min           -77.1054
exploration/Actions Mean           -0.0259582
exploration/Actions Std             0.242449
exploration/Actions Max             0.99884
exploration/Actions Min            -0.999955
exploration/Num Paths               5
exploration/Average Returns       -49.0192
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.326287
evaluation/Rewards Std              1.12767
evaluation/Rewards Max             -0.00741092
evaluation/Rewards Min            -10.1804
evaluation/Returns Mean           -32.6287
evaluation/Returns Std             23.8649
evaluation/Returns Max             -5.19293
evaluation/Returns Min            -75.9715
evaluation/Actions Mean            -0.0111209
evaluation/Actions Std              0.188813
evaluation/Actions Max              0.997209
evaluation/Actions Min             -0.999222
evaluation/Num Paths               15
evaluation/Average Returns        -32.6287
time/data storing (s)               0.00360975
time/evaluation sampling (s)        0.346245
time/exploration sampling (s)       0.159813
time/logging (s)                    0.00456758
time/saving (s)                     0.00197719
time/training (s)                   2.18121
time/epoch (s)                      2.69742
time/total (s)                    281.436
Epoch                             102
-----------------------------  ---------------
2019-04-22 22:00:41.846336 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                    1.22412
trainer/QF2 Loss                    1.22156
trainer/Policy Loss                19.0413
trainer/Q1 Predictions Mean       -17.4043
trainer/Q1 Predictions Std         14.8771
trainer/Q1 Predictions Max         -7.66016
trainer/Q1 Predictions Min        -54.6341
trainer/Q2 Predictions Mean       -17.401
trainer/Q2 Predictions Std         14.8991
trainer/Q2 Predictions Max         -7.65354
trainer/Q2 Predictions Min        -54.8342
trainer/Q Targets Mean            -17.5029
trainer/Q Targets Std              15.1859
trainer/Q Targets Max              -0.302242
trainer/Q Targets Min             -54.5972
trainer/Log Pis Mean                1.87713
trainer/Log Pis Std                 0.895723
trainer/Log Pis Max                 4.86216
trainer/Log Pis Min                -1.052
trainer/Policy mu Mean              0.0669943
trainer/Policy mu Std               0.476041
trainer/Policy mu Max               2.86751
trainer/Policy mu Min              -1.02106
trainer/Policy log std Mean        -2.12409
trainer/Policy log std Std          0.299905
trainer/Policy log std Max         -0.446493
trainer/Policy log std Min         -2.46519
trainer/Alpha                       0.0617539
trainer/Alpha Loss                 -0.342151
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.40562
exploration/Rewards Std             0.793823
exploration/Rewards Max            -0.00360736
exploration/Rewards Min            -7.51169
exploration/Returns Mean          -40.562
exploration/Returns Std             9.25591
exploration/Returns Max           -22.6146
exploration/Returns Min           -47.6102
exploration/Actions Mean           -0.010512
exploration/Actions Std             0.233204
exploration/Actions Max             0.995388
exploration/Actions Min            -0.998668
exploration/Num Paths               5
exploration/Average Returns       -40.562
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.246878
evaluation/Rewards Std              0.862472
evaluation/Rewards Max             -0.00174666
evaluation/Rewards Min             -9.35912
evaluation/Returns Mean           -24.6878
evaluation/Returns Std             21.2214
evaluation/Returns Max             -3.34258
evaluation/Returns Min            -84.3862
evaluation/Actions Mean             0.00566488
evaluation/Actions Std              0.171327
evaluation/Actions Max              0.997065
evaluation/Actions Min             -0.998261
evaluation/Num Paths               15
evaluation/Average Returns        -24.6878
time/data storing (s)               0.00329135
time/evaluation sampling (s)        0.357255
time/exploration sampling (s)       0.163398
time/logging (s)                    0.00481144
time/saving (s)                     0.0419611
time/training (s)                   2.13967
time/epoch (s)                      2.71038
time/total (s)                    284.151
Epoch                             103
-----------------------------  ---------------
2019-04-22 22:00:44.512211 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              52700
trainer/QF1 Loss                    0.177432
trainer/QF2 Loss                    0.152051
trainer/Policy Loss                21.6739
trainer/Q1 Predictions Mean       -20.1141
trainer/Q1 Predictions Std         17.518
trainer/Q1 Predictions Max         -7.59182
trainer/Q1 Predictions Min        -90.4564
trainer/Q2 Predictions Mean       -20.1426
trainer/Q2 Predictions Std         17.5202
trainer/Q2 Predictions Max         -7.67386
trainer/Q2 Predictions Min        -90.7726
trainer/Q Targets Mean            -20.3202
trainer/Q Targets Std              17.5355
trainer/Q Targets Max              -7.86846
trainer/Q Targets Min             -92.7531
trainer/Log Pis Mean                2.0926
trainer/Log Pis Std                 1.26313
trainer/Log Pis Max                 7.25667
trainer/Log Pis Min                -1.74902
trainer/Policy mu Mean              0.147003
trainer/Policy mu Std               0.816703
trainer/Policy mu Max               3.14126
trainer/Policy mu Min              -3.14176
trainer/Policy log std Mean        -2.01385
trainer/Policy log std Std          0.51498
trainer/Policy log std Max         -0.435431
trainer/Policy log std Min         -2.46927
trainer/Alpha                       0.0611535
trainer/Alpha Loss                  0.25877
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.488198
exploration/Rewards Std             1.30719
exploration/Rewards Max            -0.00676903
exploration/Rewards Min           -10.3212
exploration/Returns Mean          -48.8198
exploration/Returns Std            16.1608
exploration/Returns Max           -22.8716
exploration/Returns Min           -69.6542
exploration/Actions Mean           -0.0149581
exploration/Actions Std             0.24559
exploration/Actions Max             0.999166
exploration/Actions Min            -0.999588
exploration/Num Paths               5
exploration/Average Returns       -48.8198
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.278159
evaluation/Rewards Std              1.03735
evaluation/Rewards Max             -0.00771699
evaluation/Rewards Min            -10.0978
evaluation/Returns Mean           -27.8159
evaluation/Returns Std             19.0448
evaluation/Returns Max             -2.76317
evaluation/Returns Min            -70.8016
evaluation/Actions Mean             0.00256496
evaluation/Actions Std              0.193961
evaluation/Actions Max              0.99739
evaluation/Actions Min             -0.997657
evaluation/Num Paths               15
evaluation/Average Returns        -27.8159
time/data storing (s)               0.00298054
time/evaluation sampling (s)        0.361928
time/exploration sampling (s)       0.172849
time/logging (s)                    0.00502263
time/saving (s)                     0.0022655
time/training (s)                   2.11416
time/epoch (s)                      2.6592
time/total (s)                    286.815
Epoch                             104
-----------------------------  ---------------
2019-04-22 22:00:47.223339 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                    1.27644
trainer/QF2 Loss                    1.32586
trainer/Policy Loss                21.0814
trainer/Q1 Predictions Mean       -19.3323
trainer/Q1 Predictions Std         14.9677
trainer/Q1 Predictions Max         -7.83667
trainer/Q1 Predictions Min        -50.2351
trainer/Q2 Predictions Mean       -19.3284
trainer/Q2 Predictions Std         14.9508
trainer/Q2 Predictions Max         -7.78223
trainer/Q2 Predictions Min        -49.7521
trainer/Q Targets Mean            -19.4848
trainer/Q Targets Std              15.3497
trainer/Q Targets Max              -0.293323
trainer/Q Targets Min             -52.1829
trainer/Log Pis Mean                2.14499
trainer/Log Pis Std                 1.53751
trainer/Log Pis Max                 6.93387
trainer/Log Pis Min                -3.04041
trainer/Policy mu Mean             -0.0346689
trainer/Policy mu Std               0.776601
trainer/Policy mu Max               2.36421
trainer/Policy mu Min              -3.64551
trainer/Policy log std Mean        -2.0984
trainer/Policy log std Std          0.479312
trainer/Policy log std Max         -0.321062
trainer/Policy log std Min         -2.49974
trainer/Alpha                       0.0606114
trainer/Alpha Loss                  0.406483
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.400511
exploration/Rewards Std             1.17521
exploration/Rewards Max            -0.0103862
exploration/Rewards Min           -11.1731
exploration/Returns Mean          -40.0511
exploration/Returns Std            17.7942
exploration/Returns Max           -17.8011
exploration/Returns Min           -70.4538
exploration/Actions Mean           -0.0364899
exploration/Actions Std             0.241924
exploration/Actions Max             0.981068
exploration/Actions Min            -0.999813
exploration/Num Paths               5
exploration/Average Returns       -40.0511
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.300744
evaluation/Rewards Std              0.889429
evaluation/Rewards Max             -0.0136203
evaluation/Rewards Min             -9.76728
evaluation/Returns Mean           -30.0744
evaluation/Returns Std             19.6209
evaluation/Returns Max             -8.22766
evaluation/Returns Min            -61.9584
evaluation/Actions Mean             0.00716016
evaluation/Actions Std              0.173652
evaluation/Actions Max              0.997643
evaluation/Actions Min             -0.999147
evaluation/Num Paths               15
evaluation/Average Returns        -30.0744
time/data storing (s)               0.0030598
time/evaluation sampling (s)        0.387179
time/exploration sampling (s)       0.171835
time/logging (s)                    0.00477725
time/saving (s)                     0.00196449
time/training (s)                   2.13511
time/epoch (s)                      2.70392
time/total (s)                    289.523
Epoch                             105
-----------------------------  ---------------
2019-04-22 22:00:49.945117 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 106 finished
-----------------------------  ----------------
replay_buffer/size              53700
trainer/QF1 Loss                    0.121181
trainer/QF2 Loss                    0.123692
trainer/Policy Loss                24.9744
trainer/Q1 Predictions Mean       -23.188
trainer/Q1 Predictions Std         17.1903
trainer/Q1 Predictions Max         -7.66723
trainer/Q1 Predictions Min        -90.0993
trainer/Q2 Predictions Mean       -23.2047
trainer/Q2 Predictions Std         17.1782
trainer/Q2 Predictions Max         -7.67971
trainer/Q2 Predictions Min        -89.8142
trainer/Q Targets Mean            -23.4409
trainer/Q Targets Std              17.3324
trainer/Q Targets Max              -7.69641
trainer/Q Targets Min             -91.1374
trainer/Log Pis Mean                2.38747
trainer/Log Pis Std                 1.31151
trainer/Log Pis Max                 8.6008
trainer/Log Pis Min                -0.899942
trainer/Policy mu Mean              0.127942
trainer/Policy mu Std               0.851489
trainer/Policy mu Max               3.15888
trainer/Policy mu Min              -3.44708
trainer/Policy log std Mean        -2.00555
trainer/Policy log std Std          0.527683
trainer/Policy log std Max         -0.280019
trainer/Policy log std Min         -2.51531
trainer/Alpha                       0.0651778
trainer/Alpha Loss                  1.05811
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.430097
exploration/Rewards Std             0.990631
exploration/Rewards Max            -0.000609996
exploration/Rewards Min            -9.27634
exploration/Returns Mean          -43.0097
exploration/Returns Std            20.8369
exploration/Returns Max           -17.6294
exploration/Returns Min           -75.7799
exploration/Actions Mean           -0.00475361
exploration/Actions Std             0.22662
exploration/Actions Max             0.999439
exploration/Actions Min            -0.999752
exploration/Num Paths               5
exploration/Average Returns       -43.0097
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.442757
evaluation/Rewards Std              1.09534
evaluation/Rewards Max             -0.0588337
evaluation/Rewards Min            -10.4946
evaluation/Returns Mean           -44.2757
evaluation/Returns Std             19.0469
evaluation/Returns Max            -10.8996
evaluation/Returns Min            -68.9296
evaluation/Actions Mean             0.0141662
evaluation/Actions Std              0.199802
evaluation/Actions Max              0.995816
evaluation/Actions Min             -0.999415
evaluation/Num Paths               15
evaluation/Average Returns        -44.2757
time/data storing (s)               0.00342473
time/evaluation sampling (s)        0.424853
time/exploration sampling (s)       0.168211
time/logging (s)                    0.00482447
time/saving (s)                     0.00225947
time/training (s)                   2.1117
time/epoch (s)                      2.71527
time/total (s)                    292.243
Epoch                             106
-----------------------------  ----------------
2019-04-22 22:00:52.651664 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 107 finished
-----------------------------  ---------------
replay_buffer/size              54200
trainer/QF1 Loss                    0.880281
trainer/QF2 Loss                    0.826507
trainer/Policy Loss                18.7642
trainer/Q1 Predictions Mean       -17.2302
trainer/Q1 Predictions Std         13.8382
trainer/Q1 Predictions Max         -7.65472
trainer/Q1 Predictions Min        -60.7803
trainer/Q2 Predictions Mean       -17.2128
trainer/Q2 Predictions Std         13.7889
trainer/Q2 Predictions Max         -7.72482
trainer/Q2 Predictions Min        -59.8286
trainer/Q Targets Mean            -17.2628
trainer/Q Targets Std              14.0415
trainer/Q Targets Max              -0.15495
trainer/Q Targets Min             -58.2744
trainer/Log Pis Mean                1.95136
trainer/Log Pis Std                 1.45684
trainer/Log Pis Max                 8.15755
trainer/Log Pis Min                -4.52056
trainer/Policy mu Mean              0.0433725
trainer/Policy mu Std               0.752558
trainer/Policy mu Max               2.80162
trainer/Policy mu Min              -3.01665
trainer/Policy log std Mean        -2.03337
trainer/Policy log std Std          0.477217
trainer/Policy log std Max         -0.380951
trainer/Policy log std Min         -2.52093
trainer/Alpha                       0.0646429
trainer/Alpha Loss                 -0.133206
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.507959
exploration/Rewards Std             1.30939
exploration/Rewards Max            -0.0104272
exploration/Rewards Min            -9.96741
exploration/Returns Mean          -50.7959
exploration/Returns Std            13.87
exploration/Returns Max           -24.4381
exploration/Returns Min           -65.555
exploration/Actions Mean           -0.00628803
exploration/Actions Std             0.262856
exploration/Actions Max             0.998388
exploration/Actions Min            -0.999806
exploration/Num Paths               5
exploration/Average Returns       -50.7959
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.340941
evaluation/Rewards Std              1.03462
evaluation/Rewards Max             -0.00592807
evaluation/Rewards Min             -9.73758
evaluation/Returns Mean           -34.0941
evaluation/Returns Std             18.8721
evaluation/Returns Max             -5.08557
evaluation/Returns Min            -73.0421
evaluation/Actions Mean             0.00742639
evaluation/Actions Std              0.19199
evaluation/Actions Max              0.996508
evaluation/Actions Min             -0.999144
evaluation/Num Paths               15
evaluation/Average Returns        -34.0941
time/data storing (s)               0.00334762
time/evaluation sampling (s)        0.355026
time/exploration sampling (s)       0.166258
time/logging (s)                    0.00524232
time/saving (s)                     0.00231432
time/training (s)                   2.16826
time/epoch (s)                      2.70045
time/total (s)                    294.948
Epoch                             107
-----------------------------  ---------------
2019-04-22 22:00:55.329850 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              54700
trainer/QF1 Loss                    0.950066
trainer/QF2 Loss                    0.965949
trainer/Policy Loss                18.6321
trainer/Q1 Predictions Mean       -17.1516
trainer/Q1 Predictions Std         13.7846
trainer/Q1 Predictions Max         -7.71909
trainer/Q1 Predictions Min        -70.2788
trainer/Q2 Predictions Mean       -17.1789
trainer/Q2 Predictions Std         13.791
trainer/Q2 Predictions Max         -7.69323
trainer/Q2 Predictions Min        -70.4546
trainer/Q Targets Mean            -17.0865
trainer/Q Targets Std              13.7833
trainer/Q Targets Max              -0.0279956
trainer/Q Targets Min             -65.1032
trainer/Log Pis Mean                2.03269
trainer/Log Pis Std                 1.17873
trainer/Log Pis Max                 6.32783
trainer/Log Pis Min                -1.04529
trainer/Policy mu Mean              0.0403011
trainer/Policy mu Std               0.711381
trainer/Policy mu Max               2.811
trainer/Policy mu Min              -3.02357
trainer/Policy log std Mean        -2.09665
trainer/Policy log std Std          0.454308
trainer/Policy log std Max         -0.536514
trainer/Policy log std Min         -2.61034
trainer/Alpha                       0.0624863
trainer/Alpha Loss                  0.0906502
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.353883
exploration/Rewards Std             0.934106
exploration/Rewards Max            -0.00656222
exploration/Rewards Min            -8.33022
exploration/Returns Mean          -35.3883
exploration/Returns Std            11.9124
exploration/Returns Max           -21.8549
exploration/Returns Min           -54.9745
exploration/Actions Mean           -0.0232719
exploration/Actions Std             0.234525
exploration/Actions Max             0.995411
exploration/Actions Min            -0.998897
exploration/Num Paths               5
exploration/Average Returns       -35.3883
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.358341
evaluation/Rewards Std              0.990853
evaluation/Rewards Max             -0.0234284
evaluation/Rewards Min             -8.76625
evaluation/Returns Mean           -35.8341
evaluation/Returns Std             18.1479
evaluation/Returns Max            -11.3678
evaluation/Returns Min            -74.7457
evaluation/Actions Mean             0.00529572
evaluation/Actions Std              0.190254
evaluation/Actions Max              0.996017
evaluation/Actions Min             -0.998847
evaluation/Num Paths               15
evaluation/Average Returns        -35.8341
time/data storing (s)               0.00389357
time/evaluation sampling (s)        0.357785
time/exploration sampling (s)       0.163834
time/logging (s)                    0.00476961
time/saving (s)                     0.00200334
time/training (s)                   2.13867
time/epoch (s)                      2.67096
time/total (s)                    297.624
Epoch                             108
-----------------------------  ---------------
2019-04-22 22:00:58.014988 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                   27.4231
trainer/QF2 Loss                   27.3884
trainer/Policy Loss                18.2648
trainer/Q1 Predictions Mean       -16.6195
trainer/Q1 Predictions Std         13.9599
trainer/Q1 Predictions Max         -7.4938
trainer/Q1 Predictions Min        -72.3747
trainer/Q2 Predictions Mean       -16.6157
trainer/Q2 Predictions Std         13.9811
trainer/Q2 Predictions Max         -7.59476
trainer/Q2 Predictions Min        -72.7731
trainer/Q Targets Mean            -16.0952
trainer/Q Targets Std              14.1315
trainer/Q Targets Max              -0.813969
trainer/Q Targets Min             -74.0279
trainer/Log Pis Mean                2.07573
trainer/Log Pis Std                 1.22654
trainer/Log Pis Max                 6.45744
trainer/Log Pis Min                -4.01808
trainer/Policy mu Mean              0.152854
trainer/Policy mu Std               0.626812
trainer/Policy mu Max               2.89386
trainer/Policy mu Min              -2.51072
trainer/Policy log std Mean        -2.11302
trainer/Policy log std Std          0.441305
trainer/Policy log std Max         -0.583812
trainer/Policy log std Min         -2.58788
trainer/Alpha                       0.0610654
trainer/Alpha Loss                  0.211725
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.223796
exploration/Rewards Std             0.288081
exploration/Rewards Max            -0.00476898
exploration/Rewards Min            -4.17932
exploration/Returns Mean          -22.3796
exploration/Returns Std            12.0917
exploration/Returns Max           -11.8947
exploration/Returns Min           -41.7093
exploration/Actions Mean           -0.00132274
exploration/Actions Std             0.170154
exploration/Actions Max             0.987449
exploration/Actions Min            -0.991479
exploration/Num Paths               5
exploration/Average Returns       -22.3796
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.33109
evaluation/Rewards Std              1.01581
evaluation/Rewards Max             -0.0193813
evaluation/Rewards Min             -9.78155
evaluation/Returns Mean           -33.109
evaluation/Returns Std             17.9328
evaluation/Returns Max             -2.6851
evaluation/Returns Min            -77.5918
evaluation/Actions Mean             0.00537245
evaluation/Actions Std              0.196383
evaluation/Actions Max              0.998364
evaluation/Actions Min             -0.996539
evaluation/Num Paths               15
evaluation/Average Returns        -33.109
time/data storing (s)               0.00324627
time/evaluation sampling (s)        0.349136
time/exploration sampling (s)       0.160001
time/logging (s)                    0.00476825
time/saving (s)                     0.00243042
time/training (s)                   2.15889
time/epoch (s)                      2.67848
time/total (s)                    300.307
Epoch                             109
-----------------------------  ---------------
2019-04-22 22:01:00.684345 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              55700
trainer/QF1 Loss                    0.0513846
trainer/QF2 Loss                    0.0574469
trainer/Policy Loss                15.592
trainer/Q1 Predictions Mean       -13.9962
trainer/Q1 Predictions Std         12.1465
trainer/Q1 Predictions Max         -7.4737
trainer/Q1 Predictions Min        -67.4047
trainer/Q2 Predictions Mean       -14.0137
trainer/Q2 Predictions Std         12.1453
trainer/Q2 Predictions Max         -7.5408
trainer/Q2 Predictions Min        -67.7369
trainer/Q Targets Mean            -14.1416
trainer/Q Targets Std              12.1082
trainer/Q Targets Max              -7.55351
trainer/Q Targets Min             -67.7732
trainer/Log Pis Mean                1.99237
trainer/Log Pis Std                 1.26222
trainer/Log Pis Max                 5.60513
trainer/Log Pis Min                -1.41756
trainer/Policy mu Mean              0.118268
trainer/Policy mu Std               0.753046
trainer/Policy mu Max               3.212
trainer/Policy mu Min              -3.03944
trainer/Policy log std Mean        -2.04231
trainer/Policy log std Std          0.488652
trainer/Policy log std Max         -0.454021
trainer/Policy log std Min         -2.5159
trainer/Alpha                       0.0616112
trainer/Alpha Loss                 -0.0212703
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.44135
exploration/Rewards Std             1.23957
exploration/Rewards Max            -0.00381363
exploration/Rewards Min           -10.0397
exploration/Returns Mean          -44.135
exploration/Returns Std            18.8587
exploration/Returns Max           -21.3915
exploration/Returns Min           -68.6642
exploration/Actions Mean            0.0207107
exploration/Actions Std             0.244265
exploration/Actions Max             0.999063
exploration/Actions Min            -0.999147
exploration/Num Paths               5
exploration/Average Returns       -44.135
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.297744
evaluation/Rewards Std              1.0993
evaluation/Rewards Max             -0.0209519
evaluation/Rewards Min             -9.99531
evaluation/Returns Mean           -29.7744
evaluation/Returns Std             17.0819
evaluation/Returns Max             -6.74033
evaluation/Returns Min            -61.1891
evaluation/Actions Mean            -0.0109793
evaluation/Actions Std              0.203136
evaluation/Actions Max              0.997268
evaluation/Actions Min             -0.997565
evaluation/Num Paths               15
evaluation/Average Returns        -29.7744
time/data storing (s)               0.00343785
time/evaluation sampling (s)        0.358305
time/exploration sampling (s)       0.161906
time/logging (s)                    0.00431978
time/saving (s)                     0.00202507
time/training (s)                   2.13184
time/epoch (s)                      2.66184
time/total (s)                    302.973
Epoch                             110
-----------------------------  ---------------
2019-04-22 22:01:03.393440 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                    2.62388
trainer/QF2 Loss                    2.68507
trainer/Policy Loss                20.4931
trainer/Q1 Predictions Mean       -18.9247
trainer/Q1 Predictions Std         15.8674
trainer/Q1 Predictions Max         -7.51911
trainer/Q1 Predictions Min        -80.3131
trainer/Q2 Predictions Mean       -18.9366
trainer/Q2 Predictions Std         15.8852
trainer/Q2 Predictions Max         -7.58879
trainer/Q2 Predictions Min        -80.7482
trainer/Q Targets Mean            -18.7071
trainer/Q Targets Std              15.8776
trainer/Q Targets Max              -0.179694
trainer/Q Targets Min             -77.7397
trainer/Log Pis Mean                2.26607
trainer/Log Pis Std                 1.68594
trainer/Log Pis Max                 8.73469
trainer/Log Pis Min                -2.79201
trainer/Policy mu Mean              0.205786
trainer/Policy mu Std               0.852565
trainer/Policy mu Max               3.21189
trainer/Policy mu Min              -3.02875
trainer/Policy log std Mean        -2.0223
trainer/Policy log std Std          0.495024
trainer/Policy log std Max         -0.496478
trainer/Policy log std Min         -2.43689
trainer/Alpha                       0.0601457
trainer/Alpha Loss                  0.747936
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.377471
exploration/Rewards Std             0.789578
exploration/Rewards Max            -0.00649166
exploration/Rewards Min            -8.60344
exploration/Returns Mean          -37.7471
exploration/Returns Std            21.6818
exploration/Returns Max           -18.9505
exploration/Returns Min           -77.678
exploration/Actions Mean            0.0218496
exploration/Actions Std             0.216254
exploration/Actions Max             0.997657
exploration/Actions Min            -0.994589
exploration/Num Paths               5
exploration/Average Returns       -37.7471
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.445455
evaluation/Rewards Std              1.15871
evaluation/Rewards Max             -0.0856185
evaluation/Rewards Min            -10.6302
evaluation/Returns Mean           -44.5455
evaluation/Returns Std             25.3174
evaluation/Returns Max             -9.62152
evaluation/Returns Min            -85.3037
evaluation/Actions Mean            -0.00258868
evaluation/Actions Std              0.201254
evaluation/Actions Max              0.998095
evaluation/Actions Min             -0.999152
evaluation/Num Paths               15
evaluation/Average Returns        -44.5455
time/data storing (s)               0.00340302
time/evaluation sampling (s)        0.355974
time/exploration sampling (s)       0.159704
time/logging (s)                    0.00516247
time/saving (s)                     0.00199572
time/training (s)                   2.17666
time/epoch (s)                      2.7029
time/total (s)                    305.681
Epoch                             111
-----------------------------  ---------------
2019-04-22 22:01:06.038148 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              56700
trainer/QF1 Loss                    1.96925
trainer/QF2 Loss                    1.97739
trainer/Policy Loss                18.2893
trainer/Q1 Predictions Mean       -16.6685
trainer/Q1 Predictions Std         13.1472
trainer/Q1 Predictions Max         -7.60828
trainer/Q1 Predictions Min        -68.1444
trainer/Q2 Predictions Mean       -16.6812
trainer/Q2 Predictions Std         13.1747
trainer/Q2 Predictions Max         -7.59202
trainer/Q2 Predictions Min        -68.4549
trainer/Q Targets Mean            -16.6657
trainer/Q Targets Std              13.4573
trainer/Q Targets Max              -0.249509
trainer/Q Targets Min             -68.5943
trainer/Log Pis Mean                1.92324
trainer/Log Pis Std                 1.10029
trainer/Log Pis Max                 6.10769
trainer/Log Pis Min                -1.70252
trainer/Policy mu Mean              0.12109
trainer/Policy mu Std               0.559168
trainer/Policy mu Max               3.20944
trainer/Policy mu Min              -2.85171
trainer/Policy log std Mean        -2.12616
trainer/Policy log std Std          0.358328
trainer/Policy log std Max         -0.470978
trainer/Policy log std Min         -2.52007
trainer/Alpha                       0.0601895
trainer/Alpha Loss                 -0.215701
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.419655
exploration/Rewards Std             1.14528
exploration/Rewards Max            -0.00690501
exploration/Rewards Min            -9.29691
exploration/Returns Mean          -41.9655
exploration/Returns Std            16.5496
exploration/Returns Max           -15.0086
exploration/Returns Min           -60.9491
exploration/Actions Mean           -0.0186166
exploration/Actions Std             0.244488
exploration/Actions Max             0.996676
exploration/Actions Min            -0.99946
exploration/Num Paths               5
exploration/Average Returns       -41.9655
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.264713
evaluation/Rewards Std              0.980762
evaluation/Rewards Max             -0.0551227
evaluation/Rewards Min            -10.0223
evaluation/Returns Mean           -26.4713
evaluation/Returns Std             15.4215
evaluation/Returns Max             -7.70345
evaluation/Returns Min            -62.1684
evaluation/Actions Mean            -0.00501463
evaluation/Actions Std              0.195268
evaluation/Actions Max              0.994395
evaluation/Actions Min             -0.997931
evaluation/Num Paths               15
evaluation/Average Returns        -26.4713
time/data storing (s)               0.00330053
time/evaluation sampling (s)        0.349492
time/exploration sampling (s)       0.160283
time/logging (s)                    0.00468983
time/saving (s)                     0.00160996
time/training (s)                   2.11777
time/epoch (s)                      2.63714
time/total (s)                    308.323
Epoch                             112
-----------------------------  ---------------
2019-04-22 22:01:08.693280 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 113 finished
-----------------------------  ----------------
replay_buffer/size              57200
trainer/QF1 Loss                    1.34046
trainer/QF2 Loss                    1.29867
trainer/Policy Loss                16.9619
trainer/Q1 Predictions Mean       -15.4043
trainer/Q1 Predictions Std         12.4116
trainer/Q1 Predictions Max         -7.5369
trainer/Q1 Predictions Min        -72.8846
trainer/Q2 Predictions Mean       -15.378
trainer/Q2 Predictions Std         12.4665
trainer/Q2 Predictions Max         -7.50333
trainer/Q2 Predictions Min        -73.2908
trainer/Q Targets Mean            -15.3656
trainer/Q Targets Std              12.7658
trainer/Q Targets Max              -0.0689931
trainer/Q Targets Min             -78.6138
trainer/Log Pis Mean                2.03074
trainer/Log Pis Std                 1.39198
trainer/Log Pis Max                 9.46673
trainer/Log Pis Min                -1.31386
trainer/Policy mu Mean              0.0215824
trainer/Policy mu Std               0.67644
trainer/Policy mu Max               3.27169
trainer/Policy mu Min              -2.86931
trainer/Policy log std Mean        -2.12729
trainer/Policy log std Std          0.409671
trainer/Policy log std Max         -0.583565
trainer/Policy log std Min         -2.56783
trainer/Alpha                       0.0610191
trainer/Alpha Loss                  0.0859763
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.483181
exploration/Rewards Std             1.10334
exploration/Rewards Max            -0.0111338
exploration/Rewards Min           -10.0181
exploration/Returns Mean          -48.3181
exploration/Returns Std            22.7067
exploration/Returns Max           -20.6893
exploration/Returns Min           -84.7039
exploration/Actions Mean            0.0270537
exploration/Actions Std             0.215186
exploration/Actions Max             0.999552
exploration/Actions Min            -0.966322
exploration/Num Paths               5
exploration/Average Returns       -48.3181
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.276612
evaluation/Rewards Std              0.851435
evaluation/Rewards Max             -0.0160284
evaluation/Rewards Min            -10.4528
evaluation/Returns Mean           -27.6612
evaluation/Returns Std             18.9831
evaluation/Returns Max             -6.53112
evaluation/Returns Min            -63.2419
evaluation/Actions Mean             0.000374491
evaluation/Actions Std              0.160073
evaluation/Actions Max              0.997743
evaluation/Actions Min             -0.99754
evaluation/Num Paths               15
evaluation/Average Returns        -27.6612
time/data storing (s)               0.00315793
time/evaluation sampling (s)        0.358812
time/exploration sampling (s)       0.165196
time/logging (s)                    0.00510764
time/saving (s)                     0.00197629
time/training (s)                   2.11466
time/epoch (s)                      2.6489
time/total (s)                    310.977
Epoch                             113
-----------------------------  ----------------
2019-04-22 22:01:11.394030 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              57700
trainer/QF1 Loss                    0.719296
trainer/QF2 Loss                    0.648747
trainer/Policy Loss                16.7305
trainer/Q1 Predictions Mean       -15.0516
trainer/Q1 Predictions Std         12.3158
trainer/Q1 Predictions Max         -7.38751
trainer/Q1 Predictions Min        -62.7605
trainer/Q2 Predictions Mean       -15.1026
trainer/Q2 Predictions Std         12.389
trainer/Q2 Predictions Max         -7.4482
trainer/Q2 Predictions Min        -63.1262
trainer/Q Targets Mean            -15.2226
trainer/Q Targets Std              12.5686
trainer/Q Targets Max              -0.234675
trainer/Q Targets Min             -63.9389
trainer/Log Pis Mean                2.03572
trainer/Log Pis Std                 1.1004
trainer/Log Pis Max                 6.63324
trainer/Log Pis Min                -0.743907
trainer/Policy mu Mean              0.0317223
trainer/Policy mu Std               0.638352
trainer/Policy mu Max               2.80281
trainer/Policy mu Min              -3.04768
trainer/Policy log std Mean        -2.111
trainer/Policy log std Std          0.417785
trainer/Policy log std Max         -0.578651
trainer/Policy log std Min         -2.55737
trainer/Alpha                       0.0616248
trainer/Alpha Loss                  0.0995337
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.500028
exploration/Rewards Std             1.34809
exploration/Rewards Max            -0.0108428
exploration/Rewards Min            -9.83714
exploration/Returns Mean          -50.0028
exploration/Returns Std            15.4938
exploration/Returns Max           -32.3587
exploration/Returns Min           -72.606
exploration/Actions Mean            0.0315253
exploration/Actions Std             0.259182
exploration/Actions Max             0.99826
exploration/Actions Min            -0.999874
exploration/Num Paths               5
exploration/Average Returns       -50.0028
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.18142
evaluation/Rewards Std              0.719846
evaluation/Rewards Max             -0.0478868
evaluation/Rewards Min             -8.41516
evaluation/Returns Mean           -18.142
evaluation/Returns Std             10.8533
evaluation/Returns Max             -7.02666
evaluation/Returns Min            -41.8186
evaluation/Actions Mean            -0.00820135
evaluation/Actions Std              0.169908
evaluation/Actions Max              0.994988
evaluation/Actions Min             -0.999051
evaluation/Num Paths               15
evaluation/Average Returns        -18.142
time/data storing (s)               0.00333848
time/evaluation sampling (s)        0.401536
time/exploration sampling (s)       0.166054
time/logging (s)                    0.00469207
time/saving (s)                     0.00174513
time/training (s)                   2.11599
time/epoch (s)                      2.69335
time/total (s)                    313.674
Epoch                             114
-----------------------------  ---------------
2019-04-22 22:01:14.081601 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                    1.08497
trainer/QF2 Loss                    1.09219
trainer/Policy Loss                18.8182
trainer/Q1 Predictions Mean       -17.4251
trainer/Q1 Predictions Std         12.3376
trainer/Q1 Predictions Max         -7.46526
trainer/Q1 Predictions Min        -42.5436
trainer/Q2 Predictions Mean       -17.4323
trainer/Q2 Predictions Std         12.3533
trainer/Q2 Predictions Max         -7.48447
trainer/Q2 Predictions Min        -42.8258
trainer/Q Targets Mean            -17.4745
trainer/Q Targets Std              12.4732
trainer/Q Targets Max              -1.46654
trainer/Q Targets Min             -41.6203
trainer/Log Pis Mean                1.87873
trainer/Log Pis Std                 1.27888
trainer/Log Pis Max                 6.53578
trainer/Log Pis Min                -4.54241
trainer/Policy mu Mean             -0.0273076
trainer/Policy mu Std               0.717137
trainer/Policy mu Max               1.56451
trainer/Policy mu Min              -3.04836
trainer/Policy log std Mean        -2.04472
trainer/Policy log std Std          0.447315
trainer/Policy log std Max         -0.307547
trainer/Policy log std Min         -2.48647
trainer/Alpha                       0.060194
trainer/Alpha Loss                 -0.340812
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.462461
exploration/Rewards Std             1.35834
exploration/Rewards Max            -0.0038892
exploration/Rewards Min           -10.1977
exploration/Returns Mean          -46.2461
exploration/Returns Std            19.5463
exploration/Returns Max           -22.9004
exploration/Returns Min           -70.5583
exploration/Actions Mean           -0.0223403
exploration/Actions Std             0.261026
exploration/Actions Max             0.995404
exploration/Actions Min            -0.999488
exploration/Num Paths               5
exploration/Average Returns       -46.2461
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.283925
evaluation/Rewards Std              1.04678
evaluation/Rewards Max             -0.0214275
evaluation/Rewards Min            -11.0693
evaluation/Returns Mean           -28.3925
evaluation/Returns Std             20.5853
evaluation/Returns Max             -3.71962
evaluation/Returns Min            -78.9529
evaluation/Actions Mean             0.0160556
evaluation/Actions Std              0.1896
evaluation/Actions Max              0.996757
evaluation/Actions Min             -0.998439
evaluation/Num Paths               15
evaluation/Average Returns        -28.3925
time/data storing (s)               0.00543967
time/evaluation sampling (s)        0.395933
time/exploration sampling (s)       0.165489
time/logging (s)                    0.00473931
time/saving (s)                     0.00203719
time/training (s)                   2.10699
time/epoch (s)                      2.68063
time/total (s)                    316.36
Epoch                             115
-----------------------------  ---------------
2019-04-22 22:01:16.786023 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              58700
trainer/QF1 Loss                    0.595589
trainer/QF2 Loss                    0.585705
trainer/Policy Loss                17.4988
trainer/Q1 Predictions Mean       -15.8526
trainer/Q1 Predictions Std         11.2668
trainer/Q1 Predictions Max         -7.37499
trainer/Q1 Predictions Min        -43.7161
trainer/Q2 Predictions Mean       -15.8737
trainer/Q2 Predictions Std         11.2919
trainer/Q2 Predictions Max         -7.38222
trainer/Q2 Predictions Min        -43.9465
trainer/Q Targets Mean            -15.9048
trainer/Q Targets Std              11.4501
trainer/Q Targets Max              -0.284935
trainer/Q Targets Min             -43.8187
trainer/Log Pis Mean                2.20212
trainer/Log Pis Std                 1.10421
trainer/Log Pis Max                 6.06311
trainer/Log Pis Min                -1.26399
trainer/Policy mu Mean              0.06762
trainer/Policy mu Std               0.78978
trainer/Policy mu Max               2.96697
trainer/Policy mu Min              -3.05943
trainer/Policy log std Mean        -2.06318
trainer/Policy log std Std          0.535269
trainer/Policy log std Max         -0.456506
trainer/Policy log std Min         -2.765
trainer/Alpha                       0.0633928
trainer/Alpha Loss                  0.557563
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.333218
exploration/Rewards Std             0.696611
exploration/Rewards Max            -0.00727345
exploration/Rewards Min            -6.70667
exploration/Returns Mean          -33.3218
exploration/Returns Std            12.8051
exploration/Returns Max           -17.5748
exploration/Returns Min           -49.3823
exploration/Actions Mean            0.013533
exploration/Actions Std             0.224575
exploration/Actions Max             0.996362
exploration/Actions Min            -0.994126
exploration/Num Paths               5
exploration/Average Returns       -33.3218
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244732
evaluation/Rewards Std              0.874311
evaluation/Rewards Max             -0.0310222
evaluation/Rewards Min             -9.39147
evaluation/Returns Mean           -24.4732
evaluation/Returns Std             15.6872
evaluation/Returns Max             -4.64196
evaluation/Returns Min            -52.7629
evaluation/Actions Mean            -0.00970628
evaluation/Actions Std              0.181807
evaluation/Actions Max              0.995209
evaluation/Actions Min             -0.998462
evaluation/Num Paths               15
evaluation/Average Returns        -24.4732
time/data storing (s)               0.00308019
time/evaluation sampling (s)        0.356206
time/exploration sampling (s)       0.164238
time/logging (s)                    0.00477958
time/saving (s)                     0.00197398
time/training (s)                   2.16722
time/epoch (s)                      2.69749
time/total (s)                    319.062
Epoch                             116
-----------------------------  ---------------
2019-04-22 22:01:19.549073 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 117 finished
-----------------------------  ----------------
replay_buffer/size              59200
trainer/QF1 Loss                    0.04036
trainer/QF2 Loss                    0.0461455
trainer/Policy Loss                15.9675
trainer/Q1 Predictions Mean       -14.5221
trainer/Q1 Predictions Std         11.0125
trainer/Q1 Predictions Max         -7.20838
trainer/Q1 Predictions Min        -49.6582
trainer/Q2 Predictions Mean       -14.5313
trainer/Q2 Predictions Std         10.9857
trainer/Q2 Predictions Max         -7.31129
trainer/Q2 Predictions Min        -49.6024
trainer/Q Targets Mean            -14.6233
trainer/Q Targets Std              11.067
trainer/Q Targets Max              -7.36822
trainer/Q Targets Min             -49.5219
trainer/Log Pis Mean                1.85685
trainer/Log Pis Std                 1.20597
trainer/Log Pis Max                 8.83381
trainer/Log Pis Min                -1.35915
trainer/Policy mu Mean              0.0273537
trainer/Policy mu Std               0.628381
trainer/Policy mu Max               3.04571
trainer/Policy mu Min              -3.06039
trainer/Policy log std Mean        -2.11699
trainer/Policy log std Std          0.413806
trainer/Policy log std Max         -0.493176
trainer/Policy log std Min         -2.62197
trainer/Alpha                       0.0670474
trainer/Alpha Loss                 -0.386853
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43491
exploration/Rewards Std             1.25411
exploration/Rewards Max            -0.00529082
exploration/Rewards Min           -10.0141
exploration/Returns Mean          -43.491
exploration/Returns Std            19.4655
exploration/Returns Max           -15.4474
exploration/Returns Min           -68.792
exploration/Actions Mean           -0.0115711
exploration/Actions Std             0.240958
exploration/Actions Max             0.999325
exploration/Actions Min            -0.999868
exploration/Num Paths               5
exploration/Average Returns       -43.491
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.327937
evaluation/Rewards Std              1.06816
evaluation/Rewards Max             -0.0311047
evaluation/Rewards Min            -10.5255
evaluation/Returns Mean           -32.7937
evaluation/Returns Std             15.3108
evaluation/Returns Max             -7.04449
evaluation/Returns Min            -61.6759
evaluation/Actions Mean            -0.000800432
evaluation/Actions Std              0.198058
evaluation/Actions Max              0.996861
evaluation/Actions Min             -0.99854
evaluation/Num Paths               15
evaluation/Average Returns        -32.7937
time/data storing (s)               0.00354929
time/evaluation sampling (s)        0.354685
time/exploration sampling (s)       0.15748
time/logging (s)                    0.00493048
time/saving (s)                     0.002124
time/training (s)                   2.23396
time/epoch (s)                      2.75673
time/total (s)                    321.823
Epoch                             117
-----------------------------  ----------------
2019-04-22 22:01:22.258924 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 118 finished
-----------------------------  ---------------
replay_buffer/size              59700
trainer/QF1 Loss                    9.10518
trainer/QF2 Loss                    9.1047
trainer/Policy Loss                16.9009
trainer/Q1 Predictions Mean       -15.4696
trainer/Q1 Predictions Std         12.2733
trainer/Q1 Predictions Max         -7.3103
trainer/Q1 Predictions Min        -76.0361
trainer/Q2 Predictions Mean       -15.4666
trainer/Q2 Predictions Std         12.2898
trainer/Q2 Predictions Max         -7.343
trainer/Q2 Predictions Min        -76.5424
trainer/Q Targets Mean            -15.2093
trainer/Q Targets Std              12.1709
trainer/Q Targets Max              -0.4912
trainer/Q Targets Min             -72.94
trainer/Log Pis Mean                1.90564
trainer/Log Pis Std                 1.45643
trainer/Log Pis Max                 7.36661
trainer/Log Pis Min                -2.37477
trainer/Policy mu Mean              0.117452
trainer/Policy mu Std               0.732558
trainer/Policy mu Max               3.06837
trainer/Policy mu Min              -2.88533
trainer/Policy log std Mean        -2.02648
trainer/Policy log std Std          0.476878
trainer/Policy log std Max         -0.483341
trainer/Policy log std Min         -2.56733
trainer/Alpha                       0.0672561
trainer/Alpha Loss                 -0.254691
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407261
exploration/Rewards Std             1.22508
exploration/Rewards Max            -0.00977653
exploration/Rewards Min           -10.7832
exploration/Returns Mean          -40.7261
exploration/Returns Std            21.6249
exploration/Returns Max           -16.1678
exploration/Returns Min           -66.3722
exploration/Actions Mean           -0.0260684
exploration/Actions Std             0.246475
exploration/Actions Max             0.999441
exploration/Actions Min            -0.999652
exploration/Num Paths               5
exploration/Average Returns       -40.7261
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.179458
evaluation/Rewards Std              0.707129
evaluation/Rewards Max             -0.014246
evaluation/Rewards Min             -8.7894
evaluation/Returns Mean           -17.9458
evaluation/Returns Std             14.1469
evaluation/Returns Max             -4.39546
evaluation/Returns Min            -60.2447
evaluation/Actions Mean             0.0116298
evaluation/Actions Std              0.161466
evaluation/Actions Max              0.99758
evaluation/Actions Min             -0.996087
evaluation/Num Paths               15
evaluation/Average Returns        -17.9458
time/data storing (s)               0.00311539
time/evaluation sampling (s)        0.350227
time/exploration sampling (s)       0.162406
time/logging (s)                    0.00476924
time/saving (s)                     0.00200484
time/training (s)                   2.18048
time/epoch (s)                      2.703
time/total (s)                    324.531
Epoch                             118
-----------------------------  ---------------
2019-04-22 22:01:24.926160 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 119 finished
-----------------------------  ---------------
replay_buffer/size              60200
trainer/QF1 Loss                    0.652242
trainer/QF2 Loss                    0.641803
trainer/Policy Loss                18.205
trainer/Q1 Predictions Mean       -16.5992
trainer/Q1 Predictions Std         11.7073
trainer/Q1 Predictions Max         -7.29641
trainer/Q1 Predictions Min        -63.882
trainer/Q2 Predictions Mean       -16.5885
trainer/Q2 Predictions Std         11.7098
trainer/Q2 Predictions Max         -7.28633
trainer/Q2 Predictions Min        -63.5895
trainer/Q Targets Mean            -16.746
trainer/Q Targets Std              11.9366
trainer/Q Targets Max              -0.362998
trainer/Q Targets Min             -65.4148
trainer/Log Pis Mean                2.02542
trainer/Log Pis Std                 0.99918
trainer/Log Pis Max                 4.79567
trainer/Log Pis Min                -1.00713
trainer/Policy mu Mean              0.11922
trainer/Policy mu Std               0.639219
trainer/Policy mu Max               3.25699
trainer/Policy mu Min              -1.97464
trainer/Policy log std Mean        -2.12484
trainer/Policy log std Std          0.435015
trainer/Policy log std Max         -0.516978
trainer/Policy log std Min         -2.71405
trainer/Alpha                       0.0661806
trainer/Alpha Loss                  0.0690326
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.36789
exploration/Rewards Std             1.08292
exploration/Rewards Max            -0.0125868
exploration/Rewards Min            -9.0739
exploration/Returns Mean          -36.789
exploration/Returns Std            17.0379
exploration/Returns Max           -14.731
exploration/Returns Min           -53.7723
exploration/Actions Mean            0.00974062
exploration/Actions Std             0.232188
exploration/Actions Max             0.999083
exploration/Actions Min            -0.998807
exploration/Num Paths               5
exploration/Average Returns       -36.789
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.260491
evaluation/Rewards Std              0.873778
evaluation/Rewards Max             -0.0515398
evaluation/Rewards Min             -8.63047
evaluation/Returns Mean           -26.0491
evaluation/Returns Std              9.61887
evaluation/Returns Max             -8.73783
evaluation/Returns Min            -47.4398
evaluation/Actions Mean            -0.00997815
evaluation/Actions Std              0.194851
evaluation/Actions Max              0.994752
evaluation/Actions Min             -0.998102
evaluation/Num Paths               15
evaluation/Average Returns        -26.0491
time/data storing (s)               0.00307747
time/evaluation sampling (s)        0.364133
time/exploration sampling (s)       0.164695
time/logging (s)                    0.00462497
time/saving (s)                     0.00200062
time/training (s)                   2.1216
time/epoch (s)                      2.66013
time/total (s)                    327.196
Epoch                             119
-----------------------------  ---------------
2019-04-22 22:01:27.637149 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 120 finished
-----------------------------  ---------------
replay_buffer/size              60700
trainer/QF1 Loss                    1.10679
trainer/QF2 Loss                    1.06703
trainer/Policy Loss                15.4959
trainer/Q1 Predictions Mean       -14.1295
trainer/Q1 Predictions Std          9.8781
trainer/Q1 Predictions Max         -7.20445
trainer/Q1 Predictions Min        -56.1379
trainer/Q2 Predictions Mean       -14.1487
trainer/Q2 Predictions Std          9.93352
trainer/Q2 Predictions Max         -7.28097
trainer/Q2 Predictions Min        -56.6917
trainer/Q Targets Mean            -14.3025
trainer/Q Targets Std              10.1909
trainer/Q Targets Max              -0.134453
trainer/Q Targets Min             -57.9025
trainer/Log Pis Mean                2.10439
trainer/Log Pis Std                 1.24688
trainer/Log Pis Max                 8.25926
trainer/Log Pis Min                -1.1791
trainer/Policy mu Mean              0.0451256
trainer/Policy mu Std               0.725866
trainer/Policy mu Max               2.99777
trainer/Policy mu Min              -2.70915
trainer/Policy log std Mean        -2.06274
trainer/Policy log std Std          0.461424
trainer/Policy log std Max         -0.647275
trainer/Policy log std Min         -2.78293
trainer/Alpha                       0.065443
trainer/Alpha Loss                  0.284645
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.291357
exploration/Rewards Std             0.740083
exploration/Rewards Max            -0.00908589
exploration/Rewards Min            -7.74791
exploration/Returns Mean          -29.1357
exploration/Returns Std            12.3806
exploration/Returns Max           -14.9136
exploration/Returns Min           -51.0866
exploration/Actions Mean            0.0115095
exploration/Actions Std             0.224745
exploration/Actions Max             0.99894
exploration/Actions Min            -0.993086
exploration/Num Paths               5
exploration/Average Returns       -29.1357
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.327761
evaluation/Rewards Std              1.20254
evaluation/Rewards Max             -0.00752041
evaluation/Rewards Min            -11.0486
evaluation/Returns Mean           -32.7761
evaluation/Returns Std             17.6698
evaluation/Returns Max             -2.4793
evaluation/Returns Min            -60.3416
evaluation/Actions Mean            -0.00733275
evaluation/Actions Std              0.208562
evaluation/Actions Max              0.996387
evaluation/Actions Min             -0.998759
evaluation/Num Paths               15
evaluation/Average Returns        -32.7761
time/data storing (s)               0.00317904
time/evaluation sampling (s)        0.357966
time/exploration sampling (s)       0.163704
time/logging (s)                    0.0046336
time/saving (s)                     0.0019599
time/training (s)                   2.17331
time/epoch (s)                      2.70475
time/total (s)                    329.905
Epoch                             120
-----------------------------  ---------------
2019-04-22 22:01:30.292198 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 121 finished
-----------------------------  ----------------
replay_buffer/size              61200
trainer/QF1 Loss                    0.148641
trainer/QF2 Loss                    0.159013
trainer/Policy Loss                16.0719
trainer/Q1 Predictions Mean       -14.3286
trainer/Q1 Predictions Std         10.6151
trainer/Q1 Predictions Max         -7.29541
trainer/Q1 Predictions Min        -58.4145
trainer/Q2 Predictions Mean       -14.3209
trainer/Q2 Predictions Std         10.5901
trainer/Q2 Predictions Max         -7.28634
trainer/Q2 Predictions Min        -58.4203
trainer/Q Targets Mean            -14.5296
trainer/Q Targets Std              10.8055
trainer/Q Targets Max              -7.28883
trainer/Q Targets Min             -60.5551
trainer/Log Pis Mean                2.08362
trainer/Log Pis Std                 1.50827
trainer/Log Pis Max                 7.86933
trainer/Log Pis Min                -5.84047
trainer/Policy mu Mean              0.0855221
trainer/Policy mu Std               0.746194
trainer/Policy mu Max               2.97805
trainer/Policy mu Min              -3.45448
trainer/Policy log std Mean        -2.0581
trainer/Policy log std Std          0.489767
trainer/Policy log std Max         -0.352617
trainer/Policy log std Min         -2.83055
trainer/Alpha                       0.0674127
trainer/Alpha Loss                  0.225515
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.487889
exploration/Rewards Std             1.39925
exploration/Rewards Max            -0.00695229
exploration/Rewards Min           -10.5609
exploration/Returns Mean          -48.7889
exploration/Returns Std            16.2573
exploration/Returns Max           -29.0145
exploration/Returns Min           -68.3202
exploration/Actions Mean           -0.0164612
exploration/Actions Std             0.265992
exploration/Actions Max             0.999801
exploration/Actions Min            -0.998508
exploration/Num Paths               5
exploration/Average Returns       -48.7889
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.2236
evaluation/Rewards Std              0.917741
evaluation/Rewards Max             -0.00534221
evaluation/Rewards Min            -10.5987
evaluation/Returns Mean           -22.36
evaluation/Returns Std             19.4543
evaluation/Returns Max             -2.45867
evaluation/Returns Min            -73.0958
evaluation/Actions Mean            -0.000873927
evaluation/Actions Std              0.189478
evaluation/Actions Max              0.998017
evaluation/Actions Min             -0.999442
evaluation/Num Paths               15
evaluation/Average Returns        -22.36
time/data storing (s)               0.0030337
time/evaluation sampling (s)        0.355327
time/exploration sampling (s)       0.1645
time/logging (s)                    0.00479817
time/saving (s)                     0.00177165
time/training (s)                   2.11893
time/epoch (s)                      2.64836
time/total (s)                    332.558
Epoch                             121
-----------------------------  ----------------
2019-04-22 22:01:33.003998 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              61700
trainer/QF1 Loss                    1.6551
trainer/QF2 Loss                    1.63162
trainer/Policy Loss                15.4158
trainer/Q1 Predictions Mean       -13.967
trainer/Q1 Predictions Std         10.3789
trainer/Q1 Predictions Max         -7.34563
trainer/Q1 Predictions Min        -77.1656
trainer/Q2 Predictions Mean       -13.9429
trainer/Q2 Predictions Std         10.4052
trainer/Q2 Predictions Max         -7.32954
trainer/Q2 Predictions Min        -77.6184
trainer/Q Targets Mean            -13.8588
trainer/Q Targets Std              10.7626
trainer/Q Targets Max              -0.104788
trainer/Q Targets Min             -80.3637
trainer/Log Pis Mean                1.89583
trainer/Log Pis Std                 1.37049
trainer/Log Pis Max                 4.9948
trainer/Log Pis Min                -3.73909
trainer/Policy mu Mean              0.00656919
trainer/Policy mu Std               0.680161
trainer/Policy mu Max               3.1811
trainer/Policy mu Min              -2.86044
trainer/Policy log std Mean        -2.06971
trainer/Policy log std Std          0.478022
trainer/Policy log std Max         -0.472032
trainer/Policy log std Min         -2.60578
trainer/Alpha                       0.0665951
trainer/Alpha Loss                 -0.282198
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.431188
exploration/Rewards Std             1.18003
exploration/Rewards Max            -0.00288887
exploration/Rewards Min           -10.2601
exploration/Returns Mean          -43.1188
exploration/Returns Std            13.9703
exploration/Returns Max           -25.1862
exploration/Returns Min           -66.7221
exploration/Actions Mean           -0.0273446
exploration/Actions Std             0.247075
exploration/Actions Max             0.994691
exploration/Actions Min            -0.999795
exploration/Num Paths               5
exploration/Average Returns       -43.1188
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.324134
evaluation/Rewards Std              1.10764
evaluation/Rewards Max             -0.0404871
evaluation/Rewards Min             -9.50156
evaluation/Returns Mean           -32.4134
evaluation/Returns Std             15.379
evaluation/Returns Max             -9.94439
evaluation/Returns Min            -55.5548
evaluation/Actions Mean             0.0108764
evaluation/Actions Std              0.200896
evaluation/Actions Max              0.996619
evaluation/Actions Min             -0.999231
evaluation/Num Paths               15
evaluation/Average Returns        -32.4134
time/data storing (s)               0.00309187
time/evaluation sampling (s)        0.360394
time/exploration sampling (s)       0.161022
time/logging (s)                    0.00494166
time/saving (s)                     0.00202645
time/training (s)                   2.17306
time/epoch (s)                      2.70454
time/total (s)                    335.267
Epoch                             122
-----------------------------  ---------------
2019-04-22 22:01:35.678588 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                    2.27298
trainer/QF2 Loss                    2.26552
trainer/Policy Loss                16.4048
trainer/Q1 Predictions Mean       -14.8633
trainer/Q1 Predictions Std          8.70078
trainer/Q1 Predictions Max         -7.29102
trainer/Q1 Predictions Min        -33.9731
trainer/Q2 Predictions Mean       -14.8778
trainer/Q2 Predictions Std          8.68917
trainer/Q2 Predictions Max         -7.30511
trainer/Q2 Predictions Min        -34.2988
trainer/Q Targets Mean            -14.7233
trainer/Q Targets Std               8.85606
trainer/Q Targets Max              -0.494953
trainer/Q Targets Min             -33.8891
trainer/Log Pis Mean                1.9232
trainer/Log Pis Std                 1.12471
trainer/Log Pis Max                 4.88484
trainer/Log Pis Min                -1.22989
trainer/Policy mu Mean              0.0995397
trainer/Policy mu Std               0.594605
trainer/Policy mu Max               2.48381
trainer/Policy mu Min              -2.51134
trainer/Policy log std Mean        -2.07536
trainer/Policy log std Std          0.434491
trainer/Policy log std Max         -0.555247
trainer/Policy log std Min         -2.61794
trainer/Alpha                       0.0642623
trainer/Alpha Loss                 -0.210802
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.54437
exploration/Rewards Std             1.48222
exploration/Rewards Max            -0.0190673
exploration/Rewards Min           -10.3399
exploration/Returns Mean          -54.437
exploration/Returns Std            19.9018
exploration/Returns Max           -21.6862
exploration/Returns Min           -74.0944
exploration/Actions Mean            0.0279271
exploration/Actions Std             0.277834
exploration/Actions Max             0.999878
exploration/Actions Min            -0.998723
exploration/Num Paths               5
exploration/Average Returns       -54.437
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.278799
evaluation/Rewards Std              1.022
evaluation/Rewards Max             -0.0247215
evaluation/Rewards Min            -10.9088
evaluation/Returns Mean           -27.8799
evaluation/Returns Std             16.1518
evaluation/Returns Max             -3.10055
evaluation/Returns Min            -66.1111
evaluation/Actions Mean            -0.0170154
evaluation/Actions Std              0.200792
evaluation/Actions Max              0.99271
evaluation/Actions Min             -0.998745
evaluation/Num Paths               15
evaluation/Average Returns        -27.8799
time/data storing (s)               0.00314773
time/evaluation sampling (s)        0.367776
time/exploration sampling (s)       0.163644
time/logging (s)                    0.00449583
time/saving (s)                     0.00187222
time/training (s)                   2.12597
time/epoch (s)                      2.66691
time/total (s)                    337.939
Epoch                             123
-----------------------------  ---------------
2019-04-22 22:01:38.351441 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              62700
trainer/QF1 Loss                    6.68649
trainer/QF2 Loss                    6.7306
trainer/Policy Loss                17.7306
trainer/Q1 Predictions Mean       -16.3689
trainer/Q1 Predictions Std         12.0217
trainer/Q1 Predictions Max         -7.45963
trainer/Q1 Predictions Min        -77.9997
trainer/Q2 Predictions Mean       -16.404
trainer/Q2 Predictions Std         12.0413
trainer/Q2 Predictions Max         -7.44367
trainer/Q2 Predictions Min        -78.3725
trainer/Q Targets Mean            -16.1345
trainer/Q Targets Std              12.2852
trainer/Q Targets Max              -0.161406
trainer/Q Targets Min             -78.6505
trainer/Log Pis Mean                2.06527
trainer/Log Pis Std                 1.83962
trainer/Log Pis Max                 9.63914
trainer/Log Pis Min                -2.51834
trainer/Policy mu Mean              0.0766397
trainer/Policy mu Std               0.963521
trainer/Policy mu Max               3.40942
trainer/Policy mu Min              -3.61548
trainer/Policy log std Mean        -1.95722
trainer/Policy log std Std          0.570866
trainer/Policy log std Max         -0.370284
trainer/Policy log std Min         -2.80403
trainer/Alpha                       0.0618074
trainer/Alpha Loss                  0.181689
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.291666
exploration/Rewards Std             0.733162
exploration/Rewards Max            -0.00913331
exploration/Rewards Min            -7.97076
exploration/Returns Mean          -29.1666
exploration/Returns Std            11.9052
exploration/Returns Max           -16.5299
exploration/Returns Min           -50.1529
exploration/Actions Mean           -0.00189099
exploration/Actions Std             0.229381
exploration/Actions Max             0.992165
exploration/Actions Min            -0.998985
exploration/Num Paths               5
exploration/Average Returns       -29.1666
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.320266
evaluation/Rewards Std              1.19845
evaluation/Rewards Max             -0.0156595
evaluation/Rewards Min            -10.6267
evaluation/Returns Mean           -32.0266
evaluation/Returns Std             19.5912
evaluation/Returns Max             -4.1335
evaluation/Returns Min            -64.2841
evaluation/Actions Mean             0.00496309
evaluation/Actions Std              0.211844
evaluation/Actions Max              0.997728
evaluation/Actions Min             -0.997424
evaluation/Num Paths               15
evaluation/Average Returns        -32.0266
time/data storing (s)               0.00308024
time/evaluation sampling (s)        0.354049
time/exploration sampling (s)       0.157924
time/logging (s)                    0.00489087
time/saving (s)                     0.00205727
time/training (s)                   2.14396
time/epoch (s)                      2.66597
time/total (s)                    340.61
Epoch                             124
-----------------------------  ---------------
2019-04-22 22:01:41.073498 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 125 finished
-----------------------------  ----------------
replay_buffer/size              63200
trainer/QF1 Loss                    0.174214
trainer/QF2 Loss                    0.184581
trainer/Policy Loss                15.0838
trainer/Q1 Predictions Mean       -13.2902
trainer/Q1 Predictions Std          7.60991
trainer/Q1 Predictions Max         -7.30289
trainer/Q1 Predictions Min        -28.6564
trainer/Q2 Predictions Mean       -13.2697
trainer/Q2 Predictions Std          7.6136
trainer/Q2 Predictions Max         -7.2906
trainer/Q2 Predictions Min        -28.7164
trainer/Q Targets Mean            -13.5708
trainer/Q Targets Std               7.8793
trainer/Q Targets Max              -7.30635
trainer/Q Targets Min             -29.7863
trainer/Log Pis Mean                2.09502
trainer/Log Pis Std                 1.18784
trainer/Log Pis Max                 6.3318
trainer/Log Pis Min                -1.97203
trainer/Policy mu Mean              0.17556
trainer/Policy mu Std               0.47654
trainer/Policy mu Max               2.78193
trainer/Policy mu Min              -0.623755
trainer/Policy log std Mean        -2.1669
trainer/Policy log std Std          0.352592
trainer/Policy log std Max         -0.504963
trainer/Policy log std Min         -2.83162
trainer/Alpha                       0.0621692
trainer/Alpha Loss                  0.263978
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.2281
exploration/Rewards Std             0.57676
exploration/Rewards Max            -0.00875307
exploration/Rewards Min            -6.4961
exploration/Returns Mean          -22.81
exploration/Returns Std             8.59144
exploration/Returns Max           -15.4835
exploration/Returns Min           -38.0577
exploration/Actions Mean           -0.000289679
exploration/Actions Std             0.21144
exploration/Actions Max             0.998762
exploration/Actions Min            -0.99547
exploration/Num Paths               5
exploration/Average Returns       -22.81
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207099
evaluation/Rewards Std              0.708396
evaluation/Rewards Max             -0.00266958
evaluation/Rewards Min             -7.58096
evaluation/Returns Mean           -20.7099
evaluation/Returns Std             13.2755
evaluation/Returns Max             -1.63374
evaluation/Returns Min            -44.7934
evaluation/Actions Mean             0.0116334
evaluation/Actions Std              0.176898
evaluation/Actions Max              0.995767
evaluation/Actions Min             -0.998429
evaluation/Num Paths               15
evaluation/Average Returns        -20.7099
time/data storing (s)               0.00443948
time/evaluation sampling (s)        0.356202
time/exploration sampling (s)       0.176099
time/logging (s)                    0.00484528
time/saving (s)                     0.0020063
time/training (s)                   2.17159
time/epoch (s)                      2.71518
time/total (s)                    343.33
Epoch                             125
-----------------------------  ----------------
2019-04-22 22:01:43.772316 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              63700
trainer/QF1 Loss                    0.313097
trainer/QF2 Loss                    0.301919
trainer/Policy Loss                15.1706
trainer/Q1 Predictions Mean       -13.6703
trainer/Q1 Predictions Std         12.589
trainer/Q1 Predictions Max         -7.38403
trainer/Q1 Predictions Min        -86.4575
trainer/Q2 Predictions Mean       -13.7169
trainer/Q2 Predictions Std         12.5995
trainer/Q2 Predictions Max         -7.41797
trainer/Q2 Predictions Min        -86.2516
trainer/Q Targets Mean            -13.8574
trainer/Q Targets Std              13.0101
trainer/Q Targets Max              -7.36087
trainer/Q Targets Min             -90.4221
trainer/Log Pis Mean                1.86621
trainer/Log Pis Std                 1.58056
trainer/Log Pis Max                 9.05565
trainer/Log Pis Min                -2.23917
trainer/Policy mu Mean              0.0182572
trainer/Policy mu Std               0.734639
trainer/Policy mu Max               3.38576
trainer/Policy mu Min              -3.03385
trainer/Policy log std Mean        -2.07034
trainer/Policy log std Std          0.459334
trainer/Policy log std Max         -0.337471
trainer/Policy log std Min         -2.80252
trainer/Alpha                       0.0629047
trainer/Alpha Loss                 -0.370077
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387896
exploration/Rewards Std             1.0389
exploration/Rewards Max            -0.00435733
exploration/Rewards Min            -9.31106
exploration/Returns Mean          -38.7896
exploration/Returns Std            13.7284
exploration/Returns Max           -18.9077
exploration/Returns Min           -60.2164
exploration/Actions Mean            0.00328752
exploration/Actions Std             0.252346
exploration/Actions Max             0.996405
exploration/Actions Min            -0.994796
exploration/Num Paths               5
exploration/Average Returns       -38.7896
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.240829
evaluation/Rewards Std              1.08407
evaluation/Rewards Max             -0.0149187
evaluation/Rewards Min            -10.3157
evaluation/Returns Mean           -24.0829
evaluation/Returns Std             22.6152
evaluation/Returns Max             -1.79736
evaluation/Returns Min            -75.67
evaluation/Actions Mean            -0.0103882
evaluation/Actions Std              0.190806
evaluation/Actions Max              0.99842
evaluation/Actions Min             -0.999621
evaluation/Num Paths               15
evaluation/Average Returns        -24.0829
time/data storing (s)               0.00333467
time/evaluation sampling (s)        0.352993
time/exploration sampling (s)       0.158729
time/logging (s)                    0.00466177
time/saving (s)                     0.012892
time/training (s)                   2.15903
time/epoch (s)                      2.69164
time/total (s)                    346.026
Epoch                             126
-----------------------------  ---------------
2019-04-22 22:01:46.500846 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    1.26454
trainer/QF2 Loss                    1.2
trainer/Policy Loss                16.3734
trainer/Q1 Predictions Mean       -14.679
trainer/Q1 Predictions Std          7.94868
trainer/Q1 Predictions Max         -7.42456
trainer/Q1 Predictions Min        -42.7509
trainer/Q2 Predictions Mean       -14.6525
trainer/Q2 Predictions Std          7.94067
trainer/Q2 Predictions Max         -7.40022
trainer/Q2 Predictions Min        -42.0149
trainer/Q Targets Mean            -14.6906
trainer/Q Targets Std               8.01526
trainer/Q Targets Max              -0.05586
trainer/Q Targets Min             -42.3546
trainer/Log Pis Mean                2.13514
trainer/Log Pis Std                 1.53704
trainer/Log Pis Max                 6.6196
trainer/Log Pis Min                -3.28178
trainer/Policy mu Mean              0.06866
trainer/Policy mu Std               0.878462
trainer/Policy mu Max               2.90531
trainer/Policy mu Min              -3.26825
trainer/Policy log std Mean        -1.96041
trainer/Policy log std Std          0.51994
trainer/Policy log std Max         -0.419938
trainer/Policy log std Min         -2.56945
trainer/Alpha                       0.0625501
trainer/Alpha Loss                  0.374575
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.39334
exploration/Rewards Std             1.11337
exploration/Rewards Max            -0.002447
exploration/Rewards Min            -9.60752
exploration/Returns Mean          -39.334
exploration/Returns Std            18.0973
exploration/Returns Max           -19.5567
exploration/Returns Min           -62.986
exploration/Actions Mean            0.028434
exploration/Actions Std             0.257831
exploration/Actions Max             0.998259
exploration/Actions Min            -0.983505
exploration/Num Paths               5
exploration/Average Returns       -39.334
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.220603
evaluation/Rewards Std              0.777335
evaluation/Rewards Max             -0.0102909
evaluation/Rewards Min             -9.73041
evaluation/Returns Mean           -22.0603
evaluation/Returns Std             19.6822
evaluation/Returns Max             -4.63992
evaluation/Returns Min            -64.1593
evaluation/Actions Mean             0.0121631
evaluation/Actions Std              0.163813
evaluation/Actions Max              0.996232
evaluation/Actions Min             -0.993572
evaluation/Num Paths               15
evaluation/Average Returns        -22.0603
time/data storing (s)               0.0034858
time/evaluation sampling (s)        0.354444
time/exploration sampling (s)       0.159174
time/logging (s)                    0.00514632
time/saving (s)                     0.00198777
time/training (s)                   2.19766
time/epoch (s)                      2.7219
time/total (s)                    348.753
Epoch                             127
-----------------------------  ---------------
2019-04-22 22:01:49.201702 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              64700
trainer/QF1 Loss                   21.23
trainer/QF2 Loss                   22.231
trainer/Policy Loss                13.9459
trainer/Q1 Predictions Mean       -12.719
trainer/Q1 Predictions Std          9.81063
trainer/Q1 Predictions Max         -7.26139
trainer/Q1 Predictions Min        -74.0709
trainer/Q2 Predictions Mean       -12.7295
trainer/Q2 Predictions Std          9.81448
trainer/Q2 Predictions Max         -7.29475
trainer/Q2 Predictions Min        -73.6554
trainer/Q Targets Mean            -12.2743
trainer/Q Targets Std               8.67828
trainer/Q Targets Max              -7.27779
trainer/Q Targets Min             -72.4537
trainer/Log Pis Mean                1.77193
trainer/Log Pis Std                 1.55218
trainer/Log Pis Max                 9.63305
trainer/Log Pis Min                -3.08064
trainer/Policy mu Mean              0.143271
trainer/Policy mu Std               0.689441
trainer/Policy mu Max               3.34634
trainer/Policy mu Min              -2.68454
trainer/Policy log std Mean        -2.05184
trainer/Policy log std Std          0.431126
trainer/Policy log std Max         -0.572122
trainer/Policy log std Min         -2.6764
trainer/Alpha                       0.0629324
trainer/Alpha Loss                 -0.630735
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.35276
exploration/Rewards Std             1.01501
exploration/Rewards Max            -0.00470953
exploration/Rewards Min           -10.1707
exploration/Returns Mean          -35.276
exploration/Returns Std            17.6935
exploration/Returns Max           -18.1035
exploration/Returns Min           -64.5018
exploration/Actions Mean            0.0025156
exploration/Actions Std             0.232418
exploration/Actions Max             0.997348
exploration/Actions Min            -0.999657
exploration/Num Paths               5
exploration/Average Returns       -35.276
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270972
evaluation/Rewards Std              0.986688
evaluation/Rewards Max             -0.00760626
evaluation/Rewards Min            -10.46
evaluation/Returns Mean           -27.0972
evaluation/Returns Std             17.5845
evaluation/Returns Max             -3.39298
evaluation/Returns Min            -58.7335
evaluation/Actions Mean             0.0034443
evaluation/Actions Std              0.180785
evaluation/Actions Max              0.997066
evaluation/Actions Min             -0.996186
evaluation/Num Paths               15
evaluation/Average Returns        -27.0972
time/data storing (s)               0.00319509
time/evaluation sampling (s)        0.363961
time/exploration sampling (s)       0.165238
time/logging (s)                    0.00530269
time/saving (s)                     0.0019804
time/training (s)                   2.15492
time/epoch (s)                      2.6946
time/total (s)                    351.452
Epoch                             128
-----------------------------  ---------------
2019-04-22 22:01:51.927964 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 129 finished
-----------------------------  ----------------
replay_buffer/size              65200
trainer/QF1 Loss                    1.60772
trainer/QF2 Loss                    1.60767
trainer/Policy Loss                14.261
trainer/Q1 Predictions Mean       -12.5302
trainer/Q1 Predictions Std          8.58849
trainer/Q1 Predictions Max         -7.26916
trainer/Q1 Predictions Min        -46.8559
trainer/Q2 Predictions Mean       -12.5278
trainer/Q2 Predictions Std          8.60473
trainer/Q2 Predictions Max         -7.24606
trainer/Q2 Predictions Min        -46.995
trainer/Q Targets Mean            -12.3604
trainer/Q Targets Std               8.60338
trainer/Q Targets Max              -0.182978
trainer/Q Targets Min             -45.9872
trainer/Log Pis Mean                2.15093
trainer/Log Pis Std                 1.26346
trainer/Log Pis Max                 6.6772
trainer/Log Pis Min                -0.983693
trainer/Policy mu Mean              0.137674
trainer/Policy mu Std               0.781567
trainer/Policy mu Max               2.96486
trainer/Policy mu Min              -2.59274
trainer/Policy log std Mean        -2.00641
trainer/Policy log std Std          0.488398
trainer/Policy log std Max         -0.518851
trainer/Policy log std Min         -2.61765
trainer/Alpha                       0.0641821
trainer/Alpha Loss                  0.41448
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.408484
exploration/Rewards Std             1.23379
exploration/Rewards Max            -0.00863509
exploration/Rewards Min            -9.71096
exploration/Returns Mean          -40.8484
exploration/Returns Std            18.6904
exploration/Returns Max           -13.8214
exploration/Returns Min           -63.5882
exploration/Actions Mean            0.00628995
exploration/Actions Std             0.248532
exploration/Actions Max             0.999151
exploration/Actions Min            -0.998979
exploration/Num Paths               5
exploration/Average Returns       -40.8484
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.340443
evaluation/Rewards Std              1.17622
evaluation/Rewards Max             -0.000920071
evaluation/Rewards Min            -10.6028
evaluation/Returns Mean           -34.0443
evaluation/Returns Std             21.3955
evaluation/Returns Max             -0.705075
evaluation/Returns Min            -80.9161
evaluation/Actions Mean            -0.00953595
evaluation/Actions Std              0.204216
evaluation/Actions Max              0.998189
evaluation/Actions Min             -0.998984
evaluation/Num Paths               15
evaluation/Average Returns        -34.0443
time/data storing (s)               0.00350987
time/evaluation sampling (s)        0.361554
time/exploration sampling (s)       0.165507
time/logging (s)                    0.00469641
time/saving (s)                     0.00199733
time/training (s)                   2.18134
time/epoch (s)                      2.71861
time/total (s)                    354.175
Epoch                             129
-----------------------------  ----------------
2019-04-22 22:01:54.583759 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              65700
trainer/QF1 Loss                    0.0557226
trainer/QF2 Loss                    0.0506861
trainer/Policy Loss                12.9788
trainer/Q1 Predictions Mean       -11.3841
trainer/Q1 Predictions Std          6.62617
trainer/Q1 Predictions Max         -7.23341
trainer/Q1 Predictions Min        -37.6151
trainer/Q2 Predictions Mean       -11.409
trainer/Q2 Predictions Std          6.64196
trainer/Q2 Predictions Max         -7.29612
trainer/Q2 Predictions Min        -37.9643
trainer/Q Targets Mean            -11.5261
trainer/Q Targets Std               6.70874
trainer/Q Targets Max              -7.24992
trainer/Q Targets Min             -37.3327
trainer/Log Pis Mean                1.88137
trainer/Log Pis Std                 1.09676
trainer/Log Pis Max                 4.72098
trainer/Log Pis Min                -2.49956
trainer/Policy mu Mean              0.0727077
trainer/Policy mu Std               0.606168
trainer/Policy mu Max               3.00061
trainer/Policy mu Min              -2.9024
trainer/Policy log std Mean        -2.1024
trainer/Policy log std Std          0.38829
trainer/Policy log std Max         -0.494604
trainer/Policy log std Min         -2.67579
trainer/Alpha                       0.0649209
trainer/Alpha Loss                 -0.324405
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.343706
exploration/Rewards Std             0.857665
exploration/Rewards Max            -0.00807179
exploration/Rewards Min            -8.63325
exploration/Returns Mean          -34.3706
exploration/Returns Std            15.4157
exploration/Returns Max           -20.9953
exploration/Returns Min           -64.4389
exploration/Actions Mean           -0.00246406
exploration/Actions Std             0.230594
exploration/Actions Max             0.999222
exploration/Actions Min            -0.998833
exploration/Num Paths               5
exploration/Average Returns       -34.3706
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.312483
evaluation/Rewards Std              1.02305
evaluation/Rewards Max             -0.0334188
evaluation/Rewards Min            -10.3707
evaluation/Returns Mean           -31.2483
evaluation/Returns Std             19.0244
evaluation/Returns Max             -6.74348
evaluation/Returns Min            -67.884
evaluation/Actions Mean             0.00407625
evaluation/Actions Std              0.194456
evaluation/Actions Max              0.997735
evaluation/Actions Min             -0.99948
evaluation/Num Paths               15
evaluation/Average Returns        -31.2483
time/data storing (s)               0.00318676
time/evaluation sampling (s)        0.355766
time/exploration sampling (s)       0.164537
time/logging (s)                    0.00463324
time/saving (s)                     0.00212942
time/training (s)                   2.11845
time/epoch (s)                      2.6487
time/total (s)                    356.829
Epoch                             130
-----------------------------  ---------------
2019-04-22 22:01:57.289658 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    1.60381
trainer/QF2 Loss                    1.61074
trainer/Policy Loss                14.1014
trainer/Q1 Predictions Mean       -12.5861
trainer/Q1 Predictions Std          7.79153
trainer/Q1 Predictions Max         -7.24971
trainer/Q1 Predictions Min        -58.0538
trainer/Q2 Predictions Mean       -12.57
trainer/Q2 Predictions Std          7.80296
trainer/Q2 Predictions Max         -7.26427
trainer/Q2 Predictions Min        -58.1908
trainer/Q Targets Mean            -12.4651
trainer/Q Targets Std               8.01113
trainer/Q Targets Max              -0.109623
trainer/Q Targets Min             -58.4254
trainer/Log Pis Mean                1.99562
trainer/Log Pis Std                 1.36031
trainer/Log Pis Max                 6.94151
trainer/Log Pis Min                -2.78539
trainer/Policy mu Mean              0.0124396
trainer/Policy mu Std               0.78105
trainer/Policy mu Max               3.06833
trainer/Policy mu Min              -2.86171
trainer/Policy log std Mean        -2.01278
trainer/Policy log std Std          0.496514
trainer/Policy log std Max         -0.329841
trainer/Policy log std Min         -2.60239
trainer/Alpha                       0.0653421
trainer/Alpha Loss                 -0.0119501
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.376642
exploration/Rewards Std             1.15588
exploration/Rewards Max            -0.00725553
exploration/Rewards Min           -11.2602
exploration/Returns Mean          -37.6642
exploration/Returns Std            20.9295
exploration/Returns Max           -17.5828
exploration/Returns Min           -77.2388
exploration/Actions Mean           -0.012446
exploration/Actions Std             0.253682
exploration/Actions Max             0.996122
exploration/Actions Min            -0.99995
exploration/Num Paths               5
exploration/Average Returns       -37.6642
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282553
evaluation/Rewards Std              0.99946
evaluation/Rewards Max             -0.00654389
evaluation/Rewards Min            -10.8882
evaluation/Returns Mean           -28.2553
evaluation/Returns Std             19.5918
evaluation/Returns Max             -1.77308
evaluation/Returns Min            -75.8181
evaluation/Actions Mean            -0.00343796
evaluation/Actions Std              0.178835
evaluation/Actions Max              0.996955
evaluation/Actions Min             -0.997123
evaluation/Num Paths               15
evaluation/Average Returns        -28.2553
time/data storing (s)               0.00356982
time/evaluation sampling (s)        0.35416
time/exploration sampling (s)       0.172165
time/logging (s)                    0.00477271
time/saving (s)                     0.00196418
time/training (s)                   2.16221
time/epoch (s)                      2.69884
time/total (s)                    359.532
Epoch                             131
-----------------------------  ---------------
2019-04-22 22:02:00.032330 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 132 finished
-----------------------------  ----------------
replay_buffer/size              66700
trainer/QF1 Loss                    0.65122
trainer/QF2 Loss                    0.664032
trainer/Policy Loss                13.9889
trainer/Q1 Predictions Mean       -12.2157
trainer/Q1 Predictions Std          6.10584
trainer/Q1 Predictions Max         -7.31347
trainer/Q1 Predictions Min        -25.6771
trainer/Q2 Predictions Mean       -12.1876
trainer/Q2 Predictions Std          6.09645
trainer/Q2 Predictions Max         -7.29768
trainer/Q2 Predictions Min        -25.5576
trainer/Q Targets Mean            -12.2898
trainer/Q Targets Std               6.36139
trainer/Q Targets Max              -0.527543
trainer/Q Targets Min             -24.8847
trainer/Log Pis Mean                2.04183
trainer/Log Pis Std                 0.989164
trainer/Log Pis Max                 4.85266
trainer/Log Pis Min                -1.63082
trainer/Policy mu Mean             -0.0161898
trainer/Policy mu Std               0.588584
trainer/Policy mu Max               1.72564
trainer/Policy mu Min              -2.99523
trainer/Policy log std Mean        -2.13106
trainer/Policy log std Std          0.420824
trainer/Policy log std Max         -0.528809
trainer/Policy log std Min         -2.67466
trainer/Alpha                       0.065345
trainer/Alpha Loss                  0.11411
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.267726
exploration/Rewards Std             0.577898
exploration/Rewards Max            -0.00571911
exploration/Rewards Min            -5.53922
exploration/Returns Mean          -26.7726
exploration/Returns Std             2.90233
exploration/Returns Max           -23.3505
exploration/Returns Min           -30.7347
exploration/Actions Mean            0.000821909
exploration/Actions Std             0.223662
exploration/Actions Max             0.994798
exploration/Actions Min            -0.993748
exploration/Num Paths               5
exploration/Average Returns       -26.7726
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262486
evaluation/Rewards Std              0.862744
evaluation/Rewards Max             -0.0144877
evaluation/Rewards Min             -8.73598
evaluation/Returns Mean           -26.2486
evaluation/Returns Std             17.0915
evaluation/Returns Max             -1.93136
evaluation/Returns Min            -62.9885
evaluation/Actions Mean            -0.0004493
evaluation/Actions Std              0.17579
evaluation/Actions Max              0.997281
evaluation/Actions Min             -0.998414
evaluation/Num Paths               15
evaluation/Average Returns        -26.2486
time/data storing (s)               0.00309703
time/evaluation sampling (s)        0.360386
time/exploration sampling (s)       0.16057
time/logging (s)                    0.00477909
time/saving (s)                     0.00202581
time/training (s)                   2.20503
time/epoch (s)                      2.73589
time/total (s)                    362.272
Epoch                             132
-----------------------------  ----------------
2019-04-22 22:02:02.744630 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 133 finished
-----------------------------  ----------------
replay_buffer/size              67200
trainer/QF1 Loss                    4.85983
trainer/QF2 Loss                    4.87753
trainer/Policy Loss                13.2019
trainer/Q1 Predictions Mean       -11.692
trainer/Q1 Predictions Std          6.32927
trainer/Q1 Predictions Max         -7.13524
trainer/Q1 Predictions Min        -34.2454
trainer/Q2 Predictions Mean       -11.7083
trainer/Q2 Predictions Std          6.35909
trainer/Q2 Predictions Max         -7.08323
trainer/Q2 Predictions Min        -34.163
trainer/Q Targets Mean            -11.5091
trainer/Q Targets Std               6.39393
trainer/Q Targets Max              -0.131839
trainer/Q Targets Min             -34.1282
trainer/Log Pis Mean                1.92973
trainer/Log Pis Std                 1.11356
trainer/Log Pis Max                 6.23652
trainer/Log Pis Min                -0.879648
trainer/Policy mu Mean              0.061479
trainer/Policy mu Std               0.6455
trainer/Policy mu Max               2.80029
trainer/Policy mu Min              -2.84909
trainer/Policy log std Mean        -2.06047
trainer/Policy log std Std          0.427766
trainer/Policy log std Max         -0.539955
trainer/Policy log std Min         -2.66734
trainer/Alpha                       0.0631202
trainer/Alpha Loss                 -0.194148
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.304064
exploration/Rewards Std             0.876606
exploration/Rewards Max            -0.00410835
exploration/Rewards Min            -9.44622
exploration/Returns Mean          -30.4064
exploration/Returns Std            12.2942
exploration/Returns Max           -17.7357
exploration/Returns Min           -52.8972
exploration/Actions Mean           -0.00247343
exploration/Actions Std             0.231466
exploration/Actions Max             0.990008
exploration/Actions Min            -0.997557
exploration/Num Paths               5
exploration/Average Returns       -30.4064
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.32129
evaluation/Rewards Std              1.04937
evaluation/Rewards Max             -0.000899479
evaluation/Rewards Min            -10.2295
evaluation/Returns Mean           -32.129
evaluation/Returns Std             13.9982
evaluation/Returns Max            -11.6
evaluation/Returns Min            -59.212
evaluation/Actions Mean            -0.0102527
evaluation/Actions Std              0.202981
evaluation/Actions Max              0.997036
evaluation/Actions Min             -0.999585
evaluation/Num Paths               15
evaluation/Average Returns        -32.129
time/data storing (s)               0.00325388
time/evaluation sampling (s)        0.360233
time/exploration sampling (s)       0.161368
time/logging (s)                    0.00564321
time/saving (s)                     0.00215346
time/training (s)                   2.17364
time/epoch (s)                      2.70629
time/total (s)                    364.983
Epoch                             133
-----------------------------  ----------------
2019-04-22 22:02:05.476214 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              67700
trainer/QF1 Loss                    1.35387
trainer/QF2 Loss                    1.34964
trainer/Policy Loss                15.1324
trainer/Q1 Predictions Mean       -13.7323
trainer/Q1 Predictions Std         10.3683
trainer/Q1 Predictions Max         -7.13439
trainer/Q1 Predictions Min        -71.061
trainer/Q2 Predictions Mean       -13.744
trainer/Q2 Predictions Std         10.3541
trainer/Q2 Predictions Max         -7.18418
trainer/Q2 Predictions Min        -70.8556
trainer/Q Targets Mean            -13.8644
trainer/Q Targets Std              10.8786
trainer/Q Targets Max              -0.161345
trainer/Q Targets Min             -72.9509
trainer/Log Pis Mean                1.736
trainer/Log Pis Std                 1.4573
trainer/Log Pis Max                 6.5742
trainer/Log Pis Min                -3.3096
trainer/Policy mu Mean              0.0745996
trainer/Policy mu Std               0.591769
trainer/Policy mu Max               3.2986
trainer/Policy mu Min              -3.65584
trainer/Policy log std Mean        -2.15867
trainer/Policy log std Std          0.406099
trainer/Policy log std Max         -0.384239
trainer/Policy log std Min         -2.70778
trainer/Alpha                       0.0640978
trainer/Alpha Loss                 -0.725282
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.202979
exploration/Rewards Std             0.391099
exploration/Rewards Max            -0.00508555
exploration/Rewards Min            -4.47458
exploration/Returns Mean          -20.2979
exploration/Returns Std             6.2905
exploration/Returns Max           -12.8184
exploration/Returns Min           -31.1036
exploration/Actions Mean            0.0075601
exploration/Actions Std             0.19992
exploration/Actions Max             0.998833
exploration/Actions Min            -0.984761
exploration/Num Paths               5
exploration/Average Returns       -20.2979
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.34554
evaluation/Rewards Std              0.933883
evaluation/Rewards Max             -0.0304768
evaluation/Rewards Min             -9.69028
evaluation/Returns Mean           -34.554
evaluation/Returns Std             20.2451
evaluation/Returns Max             -5.60708
evaluation/Returns Min            -78.2063
evaluation/Actions Mean            -0.00901314
evaluation/Actions Std              0.185026
evaluation/Actions Max              0.99681
evaluation/Actions Min             -0.998274
evaluation/Num Paths               15
evaluation/Average Returns        -34.554
time/data storing (s)               0.00339769
time/evaluation sampling (s)        0.422311
time/exploration sampling (s)       0.177447
time/logging (s)                    0.00475736
time/saving (s)                     0.00184351
time/training (s)                   2.11247
time/epoch (s)                      2.72222
time/total (s)                    367.711
Epoch                             134
-----------------------------  ---------------
2019-04-22 22:02:08.139907 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                    0.684858
trainer/QF2 Loss                    0.781304
trainer/Policy Loss                16.1526
trainer/Q1 Predictions Mean       -14.5409
trainer/Q1 Predictions Std         11.3859
trainer/Q1 Predictions Max         -7.06779
trainer/Q1 Predictions Min        -82.8492
trainer/Q2 Predictions Mean       -14.5389
trainer/Q2 Predictions Std         11.3192
trainer/Q2 Predictions Max         -7.14088
trainer/Q2 Predictions Min        -82.4286
trainer/Q Targets Mean            -14.515
trainer/Q Targets Std              11.6978
trainer/Q Targets Max              -0.415335
trainer/Q Targets Min             -85.6309
trainer/Log Pis Mean                2.18075
trainer/Log Pis Std                 1.3366
trainer/Log Pis Max                 9.0696
trainer/Log Pis Min                -1.03959
trainer/Policy mu Mean              0.160761
trainer/Policy mu Std               0.758767
trainer/Policy mu Max               3.18154
trainer/Policy mu Min              -2.96955
trainer/Policy log std Mean        -2.02468
trainer/Policy log std Std          0.514293
trainer/Policy log std Max         -0.467639
trainer/Policy log std Min         -2.59686
trainer/Alpha                       0.0623045
trainer/Alpha Loss                  0.50169
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.453854
exploration/Rewards Std             1.26488
exploration/Rewards Max            -0.0224675
exploration/Rewards Min           -10.507
exploration/Returns Mean          -45.3854
exploration/Returns Std            17.1874
exploration/Returns Max           -18.5594
exploration/Returns Min           -66.7776
exploration/Actions Mean           -0.0158717
exploration/Actions Std             0.24671
exploration/Actions Max             0.999233
exploration/Actions Min            -0.999856
exploration/Num Paths               5
exploration/Average Returns       -45.3854
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.304038
evaluation/Rewards Std              1.04837
evaluation/Rewards Max             -0.0127827
evaluation/Rewards Min            -10.3879
evaluation/Returns Mean           -30.4038
evaluation/Returns Std             16.0844
evaluation/Returns Max             -3.02315
evaluation/Returns Min            -62.2751
evaluation/Actions Mean            -0.00204256
evaluation/Actions Std              0.20033
evaluation/Actions Max              0.99704
evaluation/Actions Min             -0.99832
evaluation/Num Paths               15
evaluation/Average Returns        -30.4038
time/data storing (s)               0.00311986
time/evaluation sampling (s)        0.350304
time/exploration sampling (s)       0.163757
time/logging (s)                    0.00479606
time/saving (s)                     0.00201016
time/training (s)                   2.13368
time/epoch (s)                      2.65767
time/total (s)                    370.373
Epoch                             135
-----------------------------  ---------------
2019-04-22 22:02:10.839353 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              68700
trainer/QF1 Loss                    0.608019
trainer/QF2 Loss                    0.611479
trainer/Policy Loss                15.1926
trainer/Q1 Predictions Mean       -13.554
trainer/Q1 Predictions Std          8.62701
trainer/Q1 Predictions Max         -7.31452
trainer/Q1 Predictions Min        -53.205
trainer/Q2 Predictions Mean       -13.5301
trainer/Q2 Predictions Std          8.53539
trainer/Q2 Predictions Max         -7.27826
trainer/Q2 Predictions Min        -52.1492
trainer/Q Targets Mean            -13.6072
trainer/Q Targets Std               8.70252
trainer/Q Targets Max              -0.191968
trainer/Q Targets Min             -53.4341
trainer/Log Pis Mean                2.10173
trainer/Log Pis Std                 1.46366
trainer/Log Pis Max                 7.01203
trainer/Log Pis Min                -2.4106
trainer/Policy mu Mean              0.0842414
trainer/Policy mu Std               0.877007
trainer/Policy mu Max               2.93894
trainer/Policy mu Min              -3.19317
trainer/Policy log std Mean        -1.99612
trainer/Policy log std Std          0.535853
trainer/Policy log std Max         -0.31074
trainer/Policy log std Min         -2.66292
trainer/Alpha                       0.0598306
trainer/Alpha Loss                  0.286514
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.335584
exploration/Rewards Std             0.887029
exploration/Rewards Max            -0.0060797
exploration/Rewards Min            -8.28179
exploration/Returns Mean          -33.5584
exploration/Returns Std            14.4841
exploration/Returns Max           -18.2737
exploration/Returns Min           -60.0821
exploration/Actions Mean            0.00749644
exploration/Actions Std             0.227337
exploration/Actions Max             0.998399
exploration/Actions Min            -0.997187
exploration/Num Paths               5
exploration/Average Returns       -33.5584
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229126
evaluation/Rewards Std              0.736477
evaluation/Rewards Max             -0.014904
evaluation/Rewards Min             -9.29207
evaluation/Returns Mean           -22.9126
evaluation/Returns Std             16.8706
evaluation/Returns Max             -1.59001
evaluation/Returns Min            -54.0829
evaluation/Actions Mean             0.00406627
evaluation/Actions Std              0.164343
evaluation/Actions Max              0.99663
evaluation/Actions Min             -0.998508
evaluation/Num Paths               15
evaluation/Average Returns        -22.9126
time/data storing (s)               0.00395026
time/evaluation sampling (s)        0.34965
time/exploration sampling (s)       0.158945
time/logging (s)                    0.004772
time/saving (s)                     0.00166373
time/training (s)                   2.17345
time/epoch (s)                      2.69244
time/total (s)                    373.07
Epoch                             136
-----------------------------  ---------------
2019-04-22 22:02:13.539238 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                   22.8481
trainer/QF2 Loss                   22.6948
trainer/Policy Loss                14.0332
trainer/Q1 Predictions Mean       -12.2961
trainer/Q1 Predictions Std          8.70196
trainer/Q1 Predictions Max         -7.22601
trainer/Q1 Predictions Min        -58.6107
trainer/Q2 Predictions Mean       -12.2915
trainer/Q2 Predictions Std          8.67207
trainer/Q2 Predictions Max         -7.27022
trainer/Q2 Predictions Min        -58.4386
trainer/Q Targets Mean            -11.8884
trainer/Q Targets Std               7.4269
trainer/Q Targets Max              -7.25252
trainer/Q Targets Min             -51.3215
trainer/Log Pis Mean                2.03509
trainer/Log Pis Std                 1.51406
trainer/Log Pis Max                 9.30369
trainer/Log Pis Min                -2.56436
trainer/Policy mu Mean              0.0851665
trainer/Policy mu Std               0.744763
trainer/Policy mu Max               3.18724
trainer/Policy mu Min              -2.8036
trainer/Policy log std Mean        -2.02945
trainer/Policy log std Std          0.444851
trainer/Policy log std Max         -0.616351
trainer/Policy log std Min         -2.68311
trainer/Alpha                       0.0621496
trainer/Alpha Loss                  0.0974972
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375449
exploration/Rewards Std             1.04444
exploration/Rewards Max            -0.0131915
exploration/Rewards Min            -8.86544
exploration/Returns Mean          -37.5449
exploration/Returns Std            17.3397
exploration/Returns Max           -17.7609
exploration/Returns Min           -60.1268
exploration/Actions Mean            0.00545799
exploration/Actions Std             0.236804
exploration/Actions Max             0.99767
exploration/Actions Min            -0.999863
exploration/Num Paths               5
exploration/Average Returns       -37.5449
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.280468
evaluation/Rewards Std              0.959114
evaluation/Rewards Max             -0.0358643
evaluation/Rewards Min             -9.80003
evaluation/Returns Mean           -28.0468
evaluation/Returns Std             13.3881
evaluation/Returns Max             -9.59889
evaluation/Returns Min            -60.4528
evaluation/Actions Mean            -0.0191532
evaluation/Actions Std              0.197603
evaluation/Actions Max              0.994501
evaluation/Actions Min             -0.998802
evaluation/Num Paths               15
evaluation/Average Returns        -28.0468
time/data storing (s)               0.00327005
time/evaluation sampling (s)        0.364266
time/exploration sampling (s)       0.165368
time/logging (s)                    0.00375549
time/saving (s)                     0.00186951
time/training (s)                   2.15348
time/epoch (s)                      2.69201
time/total (s)                    375.766
Epoch                             137
-----------------------------  ---------------
2019-04-22 22:02:16.242681 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              69700
trainer/QF1 Loss                    0.601343
trainer/QF2 Loss                    0.685333
trainer/Policy Loss                14.343
trainer/Q1 Predictions Mean       -12.8865
trainer/Q1 Predictions Std          9.33417
trainer/Q1 Predictions Max         -7.16011
trainer/Q1 Predictions Min        -64.4513
trainer/Q2 Predictions Mean       -12.8838
trainer/Q2 Predictions Std          9.36691
trainer/Q2 Predictions Max         -7.18196
trainer/Q2 Predictions Min        -64.3124
trainer/Q Targets Mean            -12.8384
trainer/Q Targets Std               9.27427
trainer/Q Targets Max              -0.14021
trainer/Q Targets Min             -64.0022
trainer/Log Pis Mean                2.12927
trainer/Log Pis Std                 1.35737
trainer/Log Pis Max                 6.51996
trainer/Log Pis Min                -2.27352
trainer/Policy mu Mean              0.100656
trainer/Policy mu Std               0.843654
trainer/Policy mu Max               3.03643
trainer/Policy mu Min              -3.0138
trainer/Policy log std Mean        -2.03519
trainer/Policy log std Std          0.524587
trainer/Policy log std Max         -0.579357
trainer/Policy log std Min         -2.67863
trainer/Alpha                       0.0608977
trainer/Alpha Loss                  0.361786
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.416676
exploration/Rewards Std             1.07049
exploration/Rewards Max            -0.0141936
exploration/Rewards Min            -9.74044
exploration/Returns Mean          -41.6676
exploration/Returns Std            16.1794
exploration/Returns Max           -18.8026
exploration/Returns Min           -67.4408
exploration/Actions Mean            0.0263513
exploration/Actions Std             0.232633
exploration/Actions Max             0.999466
exploration/Actions Min            -0.99736
exploration/Num Paths               5
exploration/Average Returns       -41.6676
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.295253
evaluation/Rewards Std              0.993805
evaluation/Rewards Max             -0.0232228
evaluation/Rewards Min            -10.557
evaluation/Returns Mean           -29.5253
evaluation/Returns Std             16.0378
evaluation/Returns Max             -4.73536
evaluation/Returns Min            -69.7
evaluation/Actions Mean            -0.00162698
evaluation/Actions Std              0.206056
evaluation/Actions Max              0.996896
evaluation/Actions Min             -0.997986
evaluation/Num Paths               15
evaluation/Average Returns        -29.5253
time/data storing (s)               0.0035566
time/evaluation sampling (s)        0.352485
time/exploration sampling (s)       0.16728
time/logging (s)                    0.00463132
time/saving (s)                     0.00207505
time/training (s)                   2.16704
time/epoch (s)                      2.69707
time/total (s)                    378.468
Epoch                             138
-----------------------------  ---------------
2019-04-22 22:02:18.930053 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              70200
trainer/QF1 Loss                    0.0418314
trainer/QF2 Loss                    0.0343028
trainer/Policy Loss                12.837
trainer/Q1 Predictions Mean       -11.3718
trainer/Q1 Predictions Std          5.50774
trainer/Q1 Predictions Max         -7.16274
trainer/Q1 Predictions Min        -35.1118
trainer/Q2 Predictions Mean       -11.3564
trainer/Q2 Predictions Std          5.50044
trainer/Q2 Predictions Max         -7.17807
trainer/Q2 Predictions Min        -35.4574
trainer/Q Targets Mean            -11.4633
trainer/Q Targets Std               5.49355
trainer/Q Targets Max              -7.27512
trainer/Q Targets Min             -34.9379
trainer/Log Pis Mean                1.85993
trainer/Log Pis Std                 1.07018
trainer/Log Pis Max                 6.15094
trainer/Log Pis Min                -0.745584
trainer/Policy mu Mean              0.0894495
trainer/Policy mu Std               0.616909
trainer/Policy mu Max               2.85897
trainer/Policy mu Min              -2.62478
trainer/Policy log std Mean        -2.05428
trainer/Policy log std Std          0.408923
trainer/Policy log std Max         -0.340733
trainer/Policy log std Min         -2.61191
trainer/Alpha                       0.0610834
trainer/Alpha Loss                 -0.391571
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.345475
exploration/Rewards Std             0.902225
exploration/Rewards Max            -0.00832037
exploration/Rewards Min            -8.86175
exploration/Returns Mean          -34.5475
exploration/Returns Std            13.9206
exploration/Returns Max           -22.9209
exploration/Returns Min           -61.7433
exploration/Actions Mean            0.0215322
exploration/Actions Std             0.227588
exploration/Actions Max             0.999801
exploration/Actions Min            -0.997604
exploration/Num Paths               5
exploration/Average Returns       -34.5475
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.28543
evaluation/Rewards Std              0.986323
evaluation/Rewards Max             -0.0153114
evaluation/Rewards Min            -10.2389
evaluation/Returns Mean           -28.543
evaluation/Returns Std             17.441
evaluation/Returns Max             -3.55484
evaluation/Returns Min            -67.7587
evaluation/Actions Mean            -0.00400204
evaluation/Actions Std              0.189503
evaluation/Actions Max              0.998046
evaluation/Actions Min             -0.999135
evaluation/Num Paths               15
evaluation/Average Returns        -28.543
time/data storing (s)               0.004021
time/evaluation sampling (s)        0.35792
time/exploration sampling (s)       0.156492
time/logging (s)                    0.00483878
time/saving (s)                     0.00208994
time/training (s)                   2.15532
time/epoch (s)                      2.68068
time/total (s)                    381.153
Epoch                             139
-----------------------------  ---------------
2019-04-22 22:02:21.637559 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              70700
trainer/QF1 Loss                    0.226875
trainer/QF2 Loss                    0.231025
trainer/Policy Loss                14.7631
trainer/Q1 Predictions Mean       -13.5114
trainer/Q1 Predictions Std          8.86801
trainer/Q1 Predictions Max         -7.13018
trainer/Q1 Predictions Min        -73.3212
trainer/Q2 Predictions Mean       -13.4903
trainer/Q2 Predictions Std          8.84551
trainer/Q2 Predictions Max         -7.1323
trainer/Q2 Predictions Min        -73.1876
trainer/Q Targets Mean            -13.5761
trainer/Q Targets Std               9.07641
trainer/Q Targets Max              -7.26057
trainer/Q Targets Min             -77.4706
trainer/Log Pis Mean                1.78053
trainer/Log Pis Std                 1.56093
trainer/Log Pis Max                 9.51154
trainer/Log Pis Min                -2.71143
trainer/Policy mu Mean              0.310048
trainer/Policy mu Std               0.688984
trainer/Policy mu Max               3.50626
trainer/Policy mu Min              -1.28281
trainer/Policy log std Mean        -2.03449
trainer/Policy log std Std          0.470616
trainer/Policy log std Max         -0.547568
trainer/Policy log std Min         -2.64546
trainer/Alpha                       0.0615101
trainer/Alpha Loss                 -0.611987
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.406088
exploration/Rewards Std             1.12562
exploration/Rewards Max            -0.00723855
exploration/Rewards Min           -10.0125
exploration/Returns Mean          -40.6088
exploration/Returns Std            17.2153
exploration/Returns Max           -21.8276
exploration/Returns Min           -70.4886
exploration/Actions Mean           -0.00954287
exploration/Actions Std             0.236514
exploration/Actions Max             0.992484
exploration/Actions Min            -0.99967
exploration/Num Paths               5
exploration/Average Returns       -40.6088
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.320588
evaluation/Rewards Std              1.1535
evaluation/Rewards Max             -0.0285585
evaluation/Rewards Min            -10.4949
evaluation/Returns Mean           -32.0588
evaluation/Returns Std             19.3648
evaluation/Returns Max             -8.39257
evaluation/Returns Min            -65.371
evaluation/Actions Mean            -0.00511208
evaluation/Actions Std              0.202994
evaluation/Actions Max              0.997258
evaluation/Actions Min             -0.998672
evaluation/Num Paths               15
evaluation/Average Returns        -32.0588
time/data storing (s)               0.0034577
time/evaluation sampling (s)        0.354718
time/exploration sampling (s)       0.16425
time/logging (s)                    0.00502328
time/saving (s)                     0.00217563
time/training (s)                   2.17094
time/epoch (s)                      2.70057
time/total (s)                    383.858
Epoch                             140
-----------------------------  ---------------
2019-04-22 22:02:24.295334 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                    0.0693647
trainer/QF2 Loss                    0.109548
trainer/Policy Loss                14.9792
trainer/Q1 Predictions Mean       -13.1787
trainer/Q1 Predictions Std          8.37978
trainer/Q1 Predictions Max         -7.18518
trainer/Q1 Predictions Min        -62.2765
trainer/Q2 Predictions Mean       -13.1754
trainer/Q2 Predictions Std          8.355
trainer/Q2 Predictions Max         -7.20043
trainer/Q2 Predictions Min        -61.378
trainer/Q Targets Mean            -13.2222
trainer/Q Targets Std               8.43542
trainer/Q Targets Max              -7.20466
trainer/Q Targets Min             -62.8923
trainer/Log Pis Mean                2.25327
trainer/Log Pis Std                 1.27853
trainer/Log Pis Max                 6.35363
trainer/Log Pis Min                -1.3794
trainer/Policy mu Mean              0.0639086
trainer/Policy mu Std               0.791567
trainer/Policy mu Max               3.2779
trainer/Policy mu Min              -3.14094
trainer/Policy log std Mean        -2.06288
trainer/Policy log std Std          0.475729
trainer/Policy log std Max         -0.49019
trainer/Policy log std Min         -2.72705
trainer/Alpha                       0.0635542
trainer/Alpha Loss                  0.69802
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.355561
exploration/Rewards Std             1.00599
exploration/Rewards Max            -0.00236546
exploration/Rewards Min            -8.78105
exploration/Returns Mean          -35.5561
exploration/Returns Std            10.2499
exploration/Returns Max           -26.0315
exploration/Returns Min           -54.4284
exploration/Actions Mean            0.0138497
exploration/Actions Std             0.248106
exploration/Actions Max             0.998693
exploration/Actions Min            -0.997978
exploration/Num Paths               5
exploration/Average Returns       -35.5561
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.238825
evaluation/Rewards Std              0.941965
evaluation/Rewards Max             -0.00438341
evaluation/Rewards Min             -9.63414
evaluation/Returns Mean           -23.8825
evaluation/Returns Std             16.2529
evaluation/Returns Max             -3.22059
evaluation/Returns Min            -65.6801
evaluation/Actions Mean            -0.00819345
evaluation/Actions Std              0.184231
evaluation/Actions Max              0.995925
evaluation/Actions Min             -0.999186
evaluation/Num Paths               15
evaluation/Average Returns        -23.8825
time/data storing (s)               0.00379151
time/evaluation sampling (s)        0.356554
time/exploration sampling (s)       0.163958
time/logging (s)                    0.00482598
time/saving (s)                     0.00196286
time/training (s)                   2.11904
time/epoch (s)                      2.65013
time/total (s)                    386.513
Epoch                             141
-----------------------------  ---------------
2019-04-22 22:02:26.974879 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              71700
trainer/QF1 Loss                    3.89698
trainer/QF2 Loss                    3.89896
trainer/Policy Loss                13.5966
trainer/Q1 Predictions Mean       -12.0049
trainer/Q1 Predictions Std          5.56093
trainer/Q1 Predictions Max         -7.25752
trainer/Q1 Predictions Min        -34.0916
trainer/Q2 Predictions Mean       -12.0096
trainer/Q2 Predictions Std          5.59814
trainer/Q2 Predictions Max         -7.24698
trainer/Q2 Predictions Min        -34.4222
trainer/Q Targets Mean            -11.8811
trainer/Q Targets Std               5.81904
trainer/Q Targets Max              -0.586971
trainer/Q Targets Min             -33.6218
trainer/Log Pis Mean                1.90663
trainer/Log Pis Std                 1.29591
trainer/Log Pis Max                 6.85491
trainer/Log Pis Min                -3.8939
trainer/Policy mu Mean              0.0727752
trainer/Policy mu Std               0.730956
trainer/Policy mu Max               2.53068
trainer/Policy mu Min              -3.44211
trainer/Policy log std Mean        -2.04918
trainer/Policy log std Std          0.479311
trainer/Policy log std Max         -0.358121
trainer/Policy log std Min         -2.60327
trainer/Alpha                       0.0647512
trainer/Alpha Loss                 -0.255564
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.369204
exploration/Rewards Std             1.00512
exploration/Rewards Max            -0.00653731
exploration/Rewards Min           -10.4918
exploration/Returns Mean          -36.9204
exploration/Returns Std            15.7098
exploration/Returns Max           -25.1645
exploration/Returns Min           -67.5724
exploration/Actions Mean            0.0181437
exploration/Actions Std             0.247695
exploration/Actions Max             0.999128
exploration/Actions Min            -0.997989
exploration/Num Paths               5
exploration/Average Returns       -36.9204
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.381812
evaluation/Rewards Std              1.32563
evaluation/Rewards Max             -0.0143835
evaluation/Rewards Min            -11.004
evaluation/Returns Mean           -38.1812
evaluation/Returns Std             16.4994
evaluation/Returns Max            -17.8358
evaluation/Returns Min            -68.7056
evaluation/Actions Mean            -0.0126272
evaluation/Actions Std              0.225991
evaluation/Actions Max              0.998115
evaluation/Actions Min             -0.997558
evaluation/Num Paths               15
evaluation/Average Returns        -38.1812
time/data storing (s)               0.00357193
time/evaluation sampling (s)        0.358541
time/exploration sampling (s)       0.16201
time/logging (s)                    0.00648881
time/saving (s)                     0.0021447
time/training (s)                   2.1415
time/epoch (s)                      2.67426
time/total (s)                    389.192
Epoch                             142
-----------------------------  ---------------
2019-04-22 22:02:29.656117 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 143 finished
-----------------------------  ---------------
replay_buffer/size              72200
trainer/QF1 Loss                    3.54646
trainer/QF2 Loss                    3.60127
trainer/Policy Loss                13.644
trainer/Q1 Predictions Mean       -12.0969
trainer/Q1 Predictions Std          8.74856
trainer/Q1 Predictions Max         -7.29271
trainer/Q1 Predictions Min        -81.7831
trainer/Q2 Predictions Mean       -12.1209
trainer/Q2 Predictions Std          8.70507
trainer/Q2 Predictions Max         -7.27527
trainer/Q2 Predictions Min        -80.8578
trainer/Q Targets Mean            -11.9792
trainer/Q Targets Std               9.12905
trainer/Q Targets Max              -0.687669
trainer/Q Targets Min             -83.9679
trainer/Log Pis Mean                2.05474
trainer/Log Pis Std                 1.44773
trainer/Log Pis Max                 8.12704
trainer/Log Pis Min                -1.44171
trainer/Policy mu Mean             -0.00311693
trainer/Policy mu Std               0.684105
trainer/Policy mu Max               3.21164
trainer/Policy mu Min              -3.12832
trainer/Policy log std Mean        -2.0589
trainer/Policy log std Std          0.465765
trainer/Policy log std Max         -0.29083
trainer/Policy log std Min         -2.52506
trainer/Alpha                       0.0638439
trainer/Alpha Loss                  0.150585
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.394018
exploration/Rewards Std             1.07837
exploration/Rewards Max            -0.00859717
exploration/Rewards Min           -10.1618
exploration/Returns Mean          -39.4018
exploration/Returns Std            14.771
exploration/Returns Max           -21.872
exploration/Returns Min           -65.3118
exploration/Actions Mean           -0.0184025
exploration/Actions Std             0.256361
exploration/Actions Max             0.99145
exploration/Actions Min            -0.999465
exploration/Num Paths               5
exploration/Average Returns       -39.4018
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.263553
evaluation/Rewards Std              0.8929
evaluation/Rewards Max             -0.0299398
evaluation/Rewards Min            -10.6521
evaluation/Returns Mean           -26.3553
evaluation/Returns Std             14.1644
evaluation/Returns Max             -7.98841
evaluation/Returns Min            -64.2561
evaluation/Actions Mean            -0.0227468
evaluation/Actions Std              0.189016
evaluation/Actions Max              0.989548
evaluation/Actions Min             -0.998716
evaluation/Num Paths               15
evaluation/Average Returns        -26.3553
time/data storing (s)               0.00325198
time/evaluation sampling (s)        0.370502
time/exploration sampling (s)       0.166999
time/logging (s)                    0.00505221
time/saving (s)                     0.002378
time/training (s)                   2.12299
time/epoch (s)                      2.67117
time/total (s)                    391.868
Epoch                             143
-----------------------------  ---------------
2019-04-22 22:02:32.309807 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              72700
trainer/QF1 Loss                    0.612951
trainer/QF2 Loss                    0.660402
trainer/Policy Loss                12.9091
trainer/Q1 Predictions Mean       -11.2235
trainer/Q1 Predictions Std          5.9141
trainer/Q1 Predictions Max         -7.17887
trainer/Q1 Predictions Min        -42.1738
trainer/Q2 Predictions Mean       -11.2184
trainer/Q2 Predictions Std          5.96772
trainer/Q2 Predictions Max         -7.10603
trainer/Q2 Predictions Min        -41.9742
trainer/Q Targets Mean            -11.2882
trainer/Q Targets Std               5.9547
trainer/Q Targets Max              -0.0971759
trainer/Q Targets Min             -42.0487
trainer/Log Pis Mean                1.95355
trainer/Log Pis Std                 1.21115
trainer/Log Pis Max                 5.76879
trainer/Log Pis Min                -1.471
trainer/Policy mu Mean              0.0135031
trainer/Policy mu Std               0.677232
trainer/Policy mu Max               3.09457
trainer/Policy mu Min              -3.25205
trainer/Policy log std Mean        -2.05753
trainer/Policy log std Std          0.452236
trainer/Policy log std Max         -0.289618
trainer/Policy log std Min         -2.65886
trainer/Alpha                       0.0647003
trainer/Alpha Loss                 -0.127171
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.373018
exploration/Rewards Std             1.0186
exploration/Rewards Max            -0.00254899
exploration/Rewards Min            -8.80367
exploration/Returns Mean          -37.3018
exploration/Returns Std            16.1349
exploration/Returns Max           -16.1377
exploration/Returns Min           -57.2963
exploration/Actions Mean            0.00248414
exploration/Actions Std             0.234037
exploration/Actions Max             0.99825
exploration/Actions Min            -0.997627
exploration/Num Paths               5
exploration/Average Returns       -37.3018
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.326613
evaluation/Rewards Std              1.06401
evaluation/Rewards Max             -0.0129174
evaluation/Rewards Min            -11.1064
evaluation/Returns Mean           -32.6613
evaluation/Returns Std             23.3022
evaluation/Returns Max             -5.21756
evaluation/Returns Min            -73.938
evaluation/Actions Mean            -0.00237793
evaluation/Actions Std              0.189287
evaluation/Actions Max              0.998023
evaluation/Actions Min             -0.998717
evaluation/Num Paths               15
evaluation/Average Returns        -32.6613
time/data storing (s)               0.00373638
time/evaluation sampling (s)        0.350451
time/exploration sampling (s)       0.16152
time/logging (s)                    0.00500007
time/saving (s)                     0.00197523
time/training (s)                   2.12382
time/epoch (s)                      2.64651
time/total (s)                    394.519
Epoch                             144
-----------------------------  ---------------
2019-04-22 22:02:35.016474 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                    0.077909
trainer/QF2 Loss                    0.0729676
trainer/Policy Loss                12.9214
trainer/Q1 Predictions Mean       -11.0784
trainer/Q1 Predictions Std          4.63123
trainer/Q1 Predictions Max         -7.21559
trainer/Q1 Predictions Min        -25.5314
trainer/Q2 Predictions Mean       -11.0747
trainer/Q2 Predictions Std          4.64132
trainer/Q2 Predictions Max         -7.15623
trainer/Q2 Predictions Min        -25.5387
trainer/Q Targets Mean            -11.2488
trainer/Q Targets Std               4.78619
trainer/Q Targets Max              -7.15524
trainer/Q Targets Min             -26.2937
trainer/Log Pis Mean                2.15246
trainer/Log Pis Std                 0.917108
trainer/Log Pis Max                 4.83426
trainer/Log Pis Min                -0.400766
trainer/Policy mu Mean              0.17632
trainer/Policy mu Std               0.647179
trainer/Policy mu Max               2.70697
trainer/Policy mu Min              -2.81863
trainer/Policy log std Mean        -2.09545
trainer/Policy log std Std          0.443962
trainer/Policy log std Max         -0.442008
trainer/Policy log std Min         -2.6069
trainer/Alpha                       0.0615055
trainer/Alpha Loss                  0.425166
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332322
exploration/Rewards Std             0.724338
exploration/Rewards Max            -0.0203424
exploration/Rewards Min            -7.96858
exploration/Returns Mean          -33.2322
exploration/Returns Std            14.1508
exploration/Returns Max           -17.7734
exploration/Returns Min           -57.2696
exploration/Actions Mean            0.0301731
exploration/Actions Std             0.220769
exploration/Actions Max             0.999207
exploration/Actions Min            -0.979806
exploration/Num Paths               5
exploration/Average Returns       -33.2322
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.302232
evaluation/Rewards Std              1.00216
evaluation/Rewards Max             -0.00375312
evaluation/Rewards Min            -10.4985
evaluation/Returns Mean           -30.2232
evaluation/Returns Std             16.6719
evaluation/Returns Max             -9.51954
evaluation/Returns Min            -61.3346
evaluation/Actions Mean            -0.00138743
evaluation/Actions Std              0.201193
evaluation/Actions Max              0.995868
evaluation/Actions Min             -0.999529
evaluation/Num Paths               15
evaluation/Average Returns        -30.2232
time/data storing (s)               0.00302593
time/evaluation sampling (s)        0.353048
time/exploration sampling (s)       0.16257
time/logging (s)                    0.0051091
time/saving (s)                     0.00185646
time/training (s)                   2.17335
time/epoch (s)                      2.69896
time/total (s)                    397.223
Epoch                             145
-----------------------------  ---------------
2019-04-22 22:02:37.683141 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              73700
trainer/QF1 Loss                    0.896722
trainer/QF2 Loss                    0.901165
trainer/Policy Loss                12.7473
trainer/Q1 Predictions Mean       -11.0785
trainer/Q1 Predictions Std          7.10836
trainer/Q1 Predictions Max         -7.18048
trainer/Q1 Predictions Min        -71.1075
trainer/Q2 Predictions Mean       -11.0593
trainer/Q2 Predictions Std          7.13608
trainer/Q2 Predictions Max         -7.17055
trainer/Q2 Predictions Min        -71.349
trainer/Q Targets Mean            -11.135
trainer/Q Targets Std               7.26661
trainer/Q Targets Max              -0.0994763
trainer/Q Targets Min             -71.0958
trainer/Log Pis Mean                1.98911
trainer/Log Pis Std                 1.05625
trainer/Log Pis Max                 6.6614
trainer/Log Pis Min                -1.29352
trainer/Policy mu Mean              0.0460946
trainer/Policy mu Std               0.620485
trainer/Policy mu Max               3.25546
trainer/Policy mu Min              -2.58239
trainer/Policy log std Mean        -2.1094
trainer/Policy log std Std          0.445401
trainer/Policy log std Max         -0.36381
trainer/Policy log std Min         -2.61379
trainer/Alpha                       0.0623435
trainer/Alpha Loss                 -0.0302321
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.546048
exploration/Rewards Std             1.41377
exploration/Rewards Max            -0.0173423
exploration/Rewards Min           -10.062
exploration/Returns Mean          -54.6048
exploration/Returns Std            18.913
exploration/Returns Max           -18.5927
exploration/Returns Min           -70.6833
exploration/Actions Mean           -0.00499577
exploration/Actions Std             0.248518
exploration/Actions Max             0.998441
exploration/Actions Min            -0.999614
exploration/Num Paths               5
exploration/Average Returns       -54.6048
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.323793
evaluation/Rewards Std              0.93385
evaluation/Rewards Max             -0.0124175
evaluation/Rewards Min             -9.77538
evaluation/Returns Mean           -32.3793
evaluation/Returns Std             13.0327
evaluation/Returns Max             -8.16366
evaluation/Returns Min            -54.4689
evaluation/Actions Mean             0.00682189
evaluation/Actions Std              0.177936
evaluation/Actions Max              0.99725
evaluation/Actions Min             -0.995421
evaluation/Num Paths               15
evaluation/Average Returns        -32.3793
time/data storing (s)               0.00311694
time/evaluation sampling (s)        0.349052
time/exploration sampling (s)       0.157127
time/logging (s)                    0.0045019
time/saving (s)                     0.00209884
time/training (s)                   2.14291
time/epoch (s)                      2.65881
time/total (s)                    399.887
Epoch                             146
-----------------------------  ---------------
2019-04-22 22:02:40.389457 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              74200
trainer/QF1 Loss                    0.728599
trainer/QF2 Loss                    0.818675
trainer/Policy Loss                13.0616
trainer/Q1 Predictions Mean       -11.5936
trainer/Q1 Predictions Std          9.08939
trainer/Q1 Predictions Max         -6.9711
trainer/Q1 Predictions Min        -67.6558
trainer/Q2 Predictions Mean       -11.5936
trainer/Q2 Predictions Std          9.0729
trainer/Q2 Predictions Max         -7.01223
trainer/Q2 Predictions Min        -66.8279
trainer/Q Targets Mean            -11.5981
trainer/Q Targets Std               9.02402
trainer/Q Targets Max              -0.256722
trainer/Q Targets Min             -68.8184
trainer/Log Pis Mean                2.01979
trainer/Log Pis Std                 1.39351
trainer/Log Pis Max                 8.20306
trainer/Log Pis Min                -1.9657
trainer/Policy mu Mean              0.136689
trainer/Policy mu Std               0.7173
trainer/Policy mu Max               3.23116
trainer/Policy mu Min              -2.82606
trainer/Policy log std Mean        -2.03367
trainer/Policy log std Std          0.46597
trainer/Policy log std Max         -0.322703
trainer/Policy log std Min         -2.58758
trainer/Alpha                       0.0623384
trainer/Alpha Loss                  0.0549107
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.5119
exploration/Rewards Std             1.39568
exploration/Rewards Max            -0.00667016
exploration/Rewards Min           -10.3514
exploration/Returns Mean          -51.19
exploration/Returns Std            20.0733
exploration/Returns Max           -23.366
exploration/Returns Min           -70.9477
exploration/Actions Mean           -0.0213522
exploration/Actions Std             0.279606
exploration/Actions Max             0.997894
exploration/Actions Min            -0.999222
exploration/Num Paths               5
exploration/Average Returns       -51.19
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.239988
evaluation/Rewards Std              0.936737
evaluation/Rewards Max             -0.0122137
evaluation/Rewards Min             -9.84795
evaluation/Returns Mean           -23.9988
evaluation/Returns Std             16.968
evaluation/Returns Max             -6.08818
evaluation/Returns Min            -66.3894
evaluation/Actions Mean            -0.00632188
evaluation/Actions Std              0.183887
evaluation/Actions Max              0.99712
evaluation/Actions Min             -0.998059
evaluation/Num Paths               15
evaluation/Average Returns        -23.9988
time/data storing (s)               0.00312566
time/evaluation sampling (s)        0.351125
time/exploration sampling (s)       0.159194
time/logging (s)                    0.00491497
time/saving (s)                     0.00200231
time/training (s)                   2.17906
time/epoch (s)                      2.69942
time/total (s)                    402.591
Epoch                             147
-----------------------------  ---------------
2019-04-22 22:02:43.083884 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              74700
trainer/QF1 Loss                    0.0629509
trainer/QF2 Loss                    0.0406736
trainer/Policy Loss                12.5336
trainer/Q1 Predictions Mean       -10.8424
trainer/Q1 Predictions Std          4.51159
trainer/Q1 Predictions Max         -6.85944
trainer/Q1 Predictions Min        -23.3759
trainer/Q2 Predictions Mean       -10.8737
trainer/Q2 Predictions Std          4.49078
trainer/Q2 Predictions Max         -6.91457
trainer/Q2 Predictions Min        -23.3854
trainer/Q Targets Mean            -10.9499
trainer/Q Targets Std               4.40234
trainer/Q Targets Max              -7.03554
trainer/Q Targets Min             -23.8273
trainer/Log Pis Mean                1.98643
trainer/Log Pis Std                 1.03373
trainer/Log Pis Max                 5.1654
trainer/Log Pis Min                -0.42639
trainer/Policy mu Mean              0.147553
trainer/Policy mu Std               0.579857
trainer/Policy mu Max               3.03246
trainer/Policy mu Min              -1.30384
trainer/Policy log std Mean        -2.15703
trainer/Policy log std Std          0.412243
trainer/Policy log std Max         -0.60037
trainer/Policy log std Min         -2.70824
trainer/Alpha                       0.0626671
trainer/Alpha Loss                 -0.0375941
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.372417
exploration/Rewards Std             1.08171
exploration/Rewards Max            -0.00793922
exploration/Rewards Min           -10.0745
exploration/Returns Mean          -37.2417
exploration/Returns Std            18.5447
exploration/Returns Max           -19.76
exploration/Returns Min           -69.6764
exploration/Actions Mean           -0.00279009
exploration/Actions Std             0.248598
exploration/Actions Max             0.998954
exploration/Actions Min            -0.999516
exploration/Num Paths               5
exploration/Average Returns       -37.2417
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282481
evaluation/Rewards Std              0.938502
evaluation/Rewards Max             -0.0310792
evaluation/Rewards Min            -10.4723
evaluation/Returns Mean           -28.2481
evaluation/Returns Std             19.6471
evaluation/Returns Max             -3.58646
evaluation/Returns Min            -74.1707
evaluation/Actions Mean             0.0132723
evaluation/Actions Std              0.182384
evaluation/Actions Max              0.997024
evaluation/Actions Min             -0.996893
evaluation/Num Paths               15
evaluation/Average Returns        -28.2481
time/data storing (s)               0.00311254
time/evaluation sampling (s)        0.356348
time/exploration sampling (s)       0.16926
time/logging (s)                    0.00483036
time/saving (s)                     0.00997813
time/training (s)                   2.14366
time/epoch (s)                      2.68719
time/total (s)                    405.283
Epoch                             148
-----------------------------  ---------------
2019-04-22 22:02:45.787786 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                    0.874748
trainer/QF2 Loss                    0.869689
trainer/Policy Loss                13.0139
trainer/Q1 Predictions Mean       -11.2635
trainer/Q1 Predictions Std          4.47038
trainer/Q1 Predictions Max         -7.0553
trainer/Q1 Predictions Min        -27.4993
trainer/Q2 Predictions Mean       -11.2474
trainer/Q2 Predictions Std          4.45107
trainer/Q2 Predictions Max         -7.00003
trainer/Q2 Predictions Min        -27.4018
trainer/Q Targets Mean            -11.1869
trainer/Q Targets Std               4.5044
trainer/Q Targets Max              -0.57634
trainer/Q Targets Min             -27.1155
trainer/Log Pis Mean                2.1747
trainer/Log Pis Std                 1.33635
trainer/Log Pis Max                 7.72993
trainer/Log Pis Min                -2.71482
trainer/Policy mu Mean              0.148589
trainer/Policy mu Std               0.721664
trainer/Policy mu Max               3.11555
trainer/Policy mu Min              -2.20665
trainer/Policy log std Mean        -2.08965
trainer/Policy log std Std          0.507028
trainer/Policy log std Max         -0.397849
trainer/Policy log std Min         -2.73658
trainer/Alpha                       0.0626856
trainer/Alpha Loss                  0.483852
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.223892
exploration/Rewards Std             0.606524
exploration/Rewards Max            -0.0052275
exploration/Rewards Min            -6.44045
exploration/Returns Mean          -22.3892
exploration/Returns Std             7.89273
exploration/Returns Max           -12.4215
exploration/Returns Min           -32.6847
exploration/Actions Mean            0.0015797
exploration/Actions Std             0.18987
exploration/Actions Max             0.997855
exploration/Actions Min            -0.998558
exploration/Num Paths               5
exploration/Average Returns       -22.3892
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.258939
evaluation/Rewards Std              1.03763
evaluation/Rewards Max             -0.026956
evaluation/Rewards Min            -10.2676
evaluation/Returns Mean           -25.8939
evaluation/Returns Std             17.2295
evaluation/Returns Max             -5.88937
evaluation/Returns Min            -54.272
evaluation/Actions Mean            -0.0045747
evaluation/Actions Std              0.196578
evaluation/Actions Max              0.997691
evaluation/Actions Min             -0.997946
evaluation/Num Paths               15
evaluation/Average Returns        -25.8939
time/data storing (s)               0.00343279
time/evaluation sampling (s)        0.352824
time/exploration sampling (s)       0.161492
time/logging (s)                    0.00477953
time/saving (s)                     0.00199114
time/training (s)                   2.17165
time/epoch (s)                      2.69617
time/total (s)                    407.984
Epoch                             149
-----------------------------  ---------------
2019-04-22 22:02:48.447257 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 150 finished
-----------------------------  ---------------
replay_buffer/size              75700
trainer/QF1 Loss                    0.0114187
trainer/QF2 Loss                    0.0236998
trainer/Policy Loss                12.2244
trainer/Q1 Predictions Mean       -10.5529
trainer/Q1 Predictions Std          4.01338
trainer/Q1 Predictions Max         -7.1288
trainer/Q1 Predictions Min        -24.8131
trainer/Q2 Predictions Mean       -10.5492
trainer/Q2 Predictions Std          3.98019
trainer/Q2 Predictions Max         -7.14278
trainer/Q2 Predictions Min        -24.8139
trainer/Q Targets Mean            -10.5524
trainer/Q Targets Std               4.02965
trainer/Q Targets Max              -7.05347
trainer/Q Targets Min             -24.4675
trainer/Log Pis Mean                1.99243
trainer/Log Pis Std                 1.26465
trainer/Log Pis Max                 6.12666
trainer/Log Pis Min                -4.76854
trainer/Policy mu Mean              0.0664604
trainer/Policy mu Std               0.6486
trainer/Policy mu Max               2.57906
trainer/Policy mu Min              -2.88177
trainer/Policy log std Mean        -2.07283
trainer/Policy log std Std          0.431312
trainer/Policy log std Max         -0.37048
trainer/Policy log std Min         -2.69366
trainer/Alpha                       0.064579
trainer/Alpha Loss                 -0.0207521
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.385719
exploration/Rewards Std             1.07409
exploration/Rewards Max            -0.00886018
exploration/Rewards Min            -9.89271
exploration/Returns Mean          -38.5719
exploration/Returns Std            17.8185
exploration/Returns Max           -18.1036
exploration/Returns Min           -60.4703
exploration/Actions Mean            0.0285235
exploration/Actions Std             0.241189
exploration/Actions Max             0.999454
exploration/Actions Min            -0.999307
exploration/Num Paths               5
exploration/Average Returns       -38.5719
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226154
evaluation/Rewards Std              0.84347
evaluation/Rewards Max             -0.0420047
evaluation/Rewards Min             -9.17622
evaluation/Returns Mean           -22.6154
evaluation/Returns Std             16.6469
evaluation/Returns Max             -6.54636
evaluation/Returns Min            -66.1526
evaluation/Actions Mean             0.00439647
evaluation/Actions Std              0.179317
evaluation/Actions Max              0.997825
evaluation/Actions Min             -0.998163
evaluation/Num Paths               15
evaluation/Average Returns        -22.6154
time/data storing (s)               0.00317231
time/evaluation sampling (s)        0.358597
time/exploration sampling (s)       0.156009
time/logging (s)                    0.00501114
time/saving (s)                     0.00209462
time/training (s)                   2.12742
time/epoch (s)                      2.6523
time/total (s)                    410.641
Epoch                             150
-----------------------------  ---------------
2019-04-22 22:02:51.159363 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              76200
trainer/QF1 Loss                    0.534792
trainer/QF2 Loss                    0.55752
trainer/Policy Loss                12.0066
trainer/Q1 Predictions Mean       -10.508
trainer/Q1 Predictions Std          4.2642
trainer/Q1 Predictions Max         -7.05137
trainer/Q1 Predictions Min        -24.6739
trainer/Q2 Predictions Mean       -10.4871
trainer/Q2 Predictions Std          4.28048
trainer/Q2 Predictions Max         -6.97982
trainer/Q2 Predictions Min        -24.7372
trainer/Q Targets Mean            -10.5266
trainer/Q Targets Std               4.40941
trainer/Q Targets Max              -0.0931507
trainer/Q Targets Min             -25.3033
trainer/Log Pis Mean                1.81551
trainer/Log Pis Std                 1.27988
trainer/Log Pis Max                 6.81337
trainer/Log Pis Min                -0.909465
trainer/Policy mu Mean              0.0210205
trainer/Policy mu Std               0.630097
trainer/Policy mu Max               2.81949
trainer/Policy mu Min              -2.9236
trainer/Policy log std Mean        -2.07678
trainer/Policy log std Std          0.419684
trainer/Policy log std Max         -0.49853
trainer/Policy log std Min         -2.64287
trainer/Alpha                       0.0636469
trainer/Alpha Loss                 -0.50815
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.378812
exploration/Rewards Std             1.0305
exploration/Rewards Max            -0.00709234
exploration/Rewards Min            -9.74852
exploration/Returns Mean          -37.8812
exploration/Returns Std            18.5379
exploration/Returns Max           -13.2724
exploration/Returns Min           -68.6197
exploration/Actions Mean            0.0197463
exploration/Actions Std             0.237747
exploration/Actions Max             0.998284
exploration/Actions Min            -0.99333
exploration/Num Paths               5
exploration/Average Returns       -37.8812
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.147552
evaluation/Rewards Std              0.65068
evaluation/Rewards Max             -0.00234218
evaluation/Rewards Min            -10.4494
evaluation/Returns Mean           -14.7552
evaluation/Returns Std             15.2404
evaluation/Returns Max             -0.442755
evaluation/Returns Min            -61.0632
evaluation/Actions Mean             0.00027506
evaluation/Actions Std              0.148157
evaluation/Actions Max              0.993397
evaluation/Actions Min             -0.999311
evaluation/Num Paths               15
evaluation/Average Returns        -14.7552
time/data storing (s)               0.00302314
time/evaluation sampling (s)        0.365202
time/exploration sampling (s)       0.167075
time/logging (s)                    0.00480709
time/saving (s)                     0.00183361
time/training (s)                   2.16324
time/epoch (s)                      2.70518
time/total (s)                    413.35
Epoch                             151
-----------------------------  ---------------
2019-04-22 22:02:53.837991 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 152 finished
-----------------------------  ---------------
replay_buffer/size              76700
trainer/QF1 Loss                    0.0563319
trainer/QF2 Loss                    0.062806
trainer/Policy Loss                12.8984
trainer/Q1 Predictions Mean       -11.1611
trainer/Q1 Predictions Std          6.94045
trainer/Q1 Predictions Max         -7.09617
trainer/Q1 Predictions Min        -65.4816
trainer/Q2 Predictions Mean       -11.1672
trainer/Q2 Predictions Std          6.9052
trainer/Q2 Predictions Max         -7.09322
trainer/Q2 Predictions Min        -65.2196
trainer/Q Targets Mean            -11.3018
trainer/Q Targets Std               7.02339
trainer/Q Targets Max              -7.1061
trainer/Q Targets Min             -65.9859
trainer/Log Pis Mean                2.12114
trainer/Log Pis Std                 1.32214
trainer/Log Pis Max                 7.88497
trainer/Log Pis Min                -0.948601
trainer/Policy mu Mean              0.0492462
trainer/Policy mu Std               0.729821
trainer/Policy mu Max               3.56455
trainer/Policy mu Min              -2.8096
trainer/Policy log std Mean        -2.09813
trainer/Policy log std Std          0.468644
trainer/Policy log std Max         -0.551115
trainer/Policy log std Min         -2.74543
trainer/Alpha                       0.0645057
trainer/Alpha Loss                  0.332064
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.244373
exploration/Rewards Std             0.553302
exploration/Rewards Max            -0.0080234
exploration/Rewards Min            -5.52867
exploration/Returns Mean          -24.4373
exploration/Returns Std             3.77738
exploration/Returns Max           -19.668
exploration/Returns Min           -31.0138
exploration/Actions Mean            0.00684868
exploration/Actions Std             0.208963
exploration/Actions Max             0.998334
exploration/Actions Min            -0.995499
exploration/Num Paths               5
exploration/Average Returns       -24.4373
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282025
evaluation/Rewards Std              1.05739
evaluation/Rewards Max             -0.0118292
evaluation/Rewards Min            -10.6424
evaluation/Returns Mean           -28.2025
evaluation/Returns Std             21.3016
evaluation/Returns Max             -6.25557
evaluation/Returns Min            -72.5012
evaluation/Actions Mean            -0.0131972
evaluation/Actions Std              0.195369
evaluation/Actions Max              0.998933
evaluation/Actions Min             -0.998468
evaluation/Num Paths               15
evaluation/Average Returns        -28.2025
time/data storing (s)               0.00343537
time/evaluation sampling (s)        0.362604
time/exploration sampling (s)       0.162669
time/logging (s)                    0.00531175
time/saving (s)                     0.00226982
time/training (s)                   2.13626
time/epoch (s)                      2.67255
time/total (s)                    416.027
Epoch                             152
-----------------------------  ---------------
2019-04-22 22:02:56.488269 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 153 finished
-----------------------------  ---------------
replay_buffer/size              77200
trainer/QF1 Loss                    1.19518
trainer/QF2 Loss                    1.33302
trainer/Policy Loss                13.0675
trainer/Q1 Predictions Mean       -11.2104
trainer/Q1 Predictions Std          7.02564
trainer/Q1 Predictions Max         -6.97367
trainer/Q1 Predictions Min        -64.0157
trainer/Q2 Predictions Mean       -11.1961
trainer/Q2 Predictions Std          6.92912
trainer/Q2 Predictions Max         -7.01185
trainer/Q2 Predictions Min        -63.3324
trainer/Q Targets Mean            -11.2395
trainer/Q Targets Std               7.23553
trainer/Q Targets Max              -0.0850456
trainer/Q Targets Min             -64.9855
trainer/Log Pis Mean                2.07168
trainer/Log Pis Std                 1.34724
trainer/Log Pis Max                 7.01861
trainer/Log Pis Min                -2.23168
trainer/Policy mu Mean             -0.0301242
trainer/Policy mu Std               0.7209
trainer/Policy mu Max               3.20464
trainer/Policy mu Min              -2.92391
trainer/Policy log std Mean        -2.11094
trainer/Policy log std Std          0.474419
trainer/Policy log std Max         -0.313608
trainer/Policy log std Min         -2.69064
trainer/Alpha                       0.0636711
trainer/Alpha Loss                  0.197395
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33206
exploration/Rewards Std             0.909876
exploration/Rewards Max            -0.0096737
exploration/Rewards Min            -9.78804
exploration/Returns Mean          -33.206
exploration/Returns Std            12.9612
exploration/Returns Max           -22.0226
exploration/Returns Min           -58.4183
exploration/Actions Mean            0.00534884
exploration/Actions Std             0.226616
exploration/Actions Max             0.99899
exploration/Actions Min            -0.999357
exploration/Num Paths               5
exploration/Average Returns       -33.206
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.227989
evaluation/Rewards Std              0.910102
evaluation/Rewards Max             -0.0271765
evaluation/Rewards Min            -11.4017
evaluation/Returns Mean           -22.7989
evaluation/Returns Std             15.7292
evaluation/Returns Max             -5.02227
evaluation/Returns Min            -63.6101
evaluation/Actions Mean            -0.00458751
evaluation/Actions Std              0.179978
evaluation/Actions Max              0.996569
evaluation/Actions Min             -0.998316
evaluation/Num Paths               15
evaluation/Average Returns        -22.7989
time/data storing (s)               0.00321905
time/evaluation sampling (s)        0.351422
time/exploration sampling (s)       0.157869
time/logging (s)                    0.00481821
time/saving (s)                     0.00206185
time/training (s)                   2.1233
time/epoch (s)                      2.64269
time/total (s)                    418.674
Epoch                             153
-----------------------------  ---------------
2019-04-22 22:02:59.168819 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 154 finished
-----------------------------  ----------------
replay_buffer/size              77700
trainer/QF1 Loss                    2.80511
trainer/QF2 Loss                    2.76691
trainer/Policy Loss                11.5458
trainer/Q1 Predictions Mean        -9.97545
trainer/Q1 Predictions Std          3.44347
trainer/Q1 Predictions Max         -6.85623
trainer/Q1 Predictions Min        -19.4919
trainer/Q2 Predictions Mean        -9.97485
trainer/Q2 Predictions Std          3.38879
trainer/Q2 Predictions Max         -6.91083
trainer/Q2 Predictions Min        -19.1364
trainer/Q Targets Mean             -9.88596
trainer/Q Targets Std               3.61572
trainer/Q Targets Max              -0.360264
trainer/Q Targets Min             -19.7197
trainer/Log Pis Mean                1.78901
trainer/Log Pis Std                 1.14224
trainer/Log Pis Max                 5.24498
trainer/Log Pis Min                -2.44641
trainer/Policy mu Mean              0.0464698
trainer/Policy mu Std               0.535389
trainer/Policy mu Max               2.33319
trainer/Policy mu Min              -2.77507
trainer/Policy log std Mean        -2.1081
trainer/Policy log std Std          0.390655
trainer/Policy log std Max         -0.515796
trainer/Policy log std Min         -2.64693
trainer/Alpha                       0.063435
trainer/Alpha Loss                 -0.58183
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.317803
exploration/Rewards Std             0.853656
exploration/Rewards Max            -0.0154285
exploration/Rewards Min            -9.73185
exploration/Returns Mean          -31.7803
exploration/Returns Std            19.2833
exploration/Returns Max           -18.3693
exploration/Returns Min           -70.0112
exploration/Actions Mean           -0.00364806
exploration/Actions Std             0.204224
exploration/Actions Max             0.996608
exploration/Actions Min            -0.998184
exploration/Num Paths               5
exploration/Average Returns       -31.7803
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.324024
evaluation/Rewards Std              0.994557
evaluation/Rewards Max             -0.0625077
evaluation/Rewards Min            -10.181
evaluation/Returns Mean           -32.4024
evaluation/Returns Std             16.0174
evaluation/Returns Max             -6.36577
evaluation/Returns Min            -68.1999
evaluation/Actions Mean            -0.000586798
evaluation/Actions Std              0.192601
evaluation/Actions Max              0.998679
evaluation/Actions Min             -0.996349
evaluation/Num Paths               15
evaluation/Average Returns        -32.4024
time/data storing (s)               0.00395297
time/evaluation sampling (s)        0.351629
time/exploration sampling (s)       0.173514
time/logging (s)                    0.00461724
time/saving (s)                     0.00197618
time/training (s)                   2.13756
time/epoch (s)                      2.67326
time/total (s)                    421.351
Epoch                             154
-----------------------------  ----------------
2019-04-22 22:03:01.815759 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 155 finished
-----------------------------  ----------------
replay_buffer/size              78200
trainer/QF1 Loss                    0.0821399
trainer/QF2 Loss                    0.13391
trainer/Policy Loss                13.5203
trainer/Q1 Predictions Mean       -11.9863
trainer/Q1 Predictions Std          7.74807
trainer/Q1 Predictions Max         -6.86852
trainer/Q1 Predictions Min        -51.6752
trainer/Q2 Predictions Mean       -12.011
trainer/Q2 Predictions Std          7.76035
trainer/Q2 Predictions Max         -6.87023
trainer/Q2 Predictions Min        -51.232
trainer/Q Targets Mean            -12.1618
trainer/Q Targets Std               7.80465
trainer/Q Targets Max              -6.93731
trainer/Q Targets Min             -52.3587
trainer/Log Pis Mean                2.0006
trainer/Log Pis Std                 1.45281
trainer/Log Pis Max                 6.88785
trainer/Log Pis Min                -3.76814
trainer/Policy mu Mean              0.0321867
trainer/Policy mu Std               0.764812
trainer/Policy mu Max               3.03983
trainer/Policy mu Min              -3.10595
trainer/Policy log std Mean        -2.08951
trainer/Policy log std Std          0.471982
trainer/Policy log std Max         -0.339946
trainer/Policy log std Min         -2.66824
trainer/Alpha                       0.0612992
trainer/Alpha Loss                  0.00168283
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.262699
exploration/Rewards Std             0.704717
exploration/Rewards Max            -0.0095448
exploration/Rewards Min            -7.10956
exploration/Returns Mean          -26.2699
exploration/Returns Std             9.08599
exploration/Returns Max           -16.9443
exploration/Returns Min           -43.521
exploration/Actions Mean           -0.0144221
exploration/Actions Std             0.225368
exploration/Actions Max             0.998547
exploration/Actions Min            -0.999669
exploration/Num Paths               5
exploration/Average Returns       -26.2699
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226168
evaluation/Rewards Std              0.789352
evaluation/Rewards Max             -0.0174785
evaluation/Rewards Min             -9.69991
evaluation/Returns Mean           -22.6168
evaluation/Returns Std             11.4223
evaluation/Returns Max             -9.93039
evaluation/Returns Min            -54.1177
evaluation/Actions Mean             0.000645474
evaluation/Actions Std              0.177443
evaluation/Actions Max              0.996159
evaluation/Actions Min             -0.995599
evaluation/Num Paths               15
evaluation/Average Returns        -22.6168
time/data storing (s)               0.00321726
time/evaluation sampling (s)        0.351765
time/exploration sampling (s)       0.158808
time/logging (s)                    0.00488509
time/saving (s)                     0.0021442
time/training (s)                   2.11919
time/epoch (s)                      2.64001
time/total (s)                    423.995
Epoch                             155
-----------------------------  ----------------
2019-04-22 22:03:04.520447 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              78700
trainer/QF1 Loss                    2.42451
trainer/QF2 Loss                    2.42413
trainer/Policy Loss                11.0335
trainer/Q1 Predictions Mean        -9.48247
trainer/Q1 Predictions Std          4.39152
trainer/Q1 Predictions Max         -6.84604
trainer/Q1 Predictions Min        -38.0028
trainer/Q2 Predictions Mean        -9.51213
trainer/Q2 Predictions Std          4.41979
trainer/Q2 Predictions Max         -6.9169
trainer/Q2 Predictions Min        -38.5849
trainer/Q Targets Mean             -9.39332
trainer/Q Targets Std               4.47598
trainer/Q Targets Max              -0.0527074
trainer/Q Targets Min             -37.9037
trainer/Log Pis Mean                1.7393
trainer/Log Pis Std                 1.04058
trainer/Log Pis Max                 4.75512
trainer/Log Pis Min                -2.71785
trainer/Policy mu Mean              0.0254237
trainer/Policy mu Std               0.478224
trainer/Policy mu Max               2.99102
trainer/Policy mu Min              -2.76396
trainer/Policy log std Mean        -2.16856
trainer/Policy log std Std          0.324216
trainer/Policy log std Max         -0.66564
trainer/Policy log std Min         -2.61102
trainer/Alpha                       0.0614236
trainer/Alpha Loss                 -0.727314
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.260246
exploration/Rewards Std             0.708487
exploration/Rewards Max            -0.00503608
exploration/Rewards Min            -7.46863
exploration/Returns Mean          -26.0246
exploration/Returns Std            12.3301
exploration/Returns Max           -12.0393
exploration/Returns Min           -45.7279
exploration/Actions Mean           -0.00025803
exploration/Actions Std             0.201083
exploration/Actions Max             0.998312
exploration/Actions Min            -0.998926
exploration/Num Paths               5
exploration/Average Returns       -26.0246
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273222
evaluation/Rewards Std              1.01985
evaluation/Rewards Max             -0.0315296
evaluation/Rewards Min            -10.0722
evaluation/Returns Mean           -27.3222
evaluation/Returns Std             16.0578
evaluation/Returns Max             -5.56301
evaluation/Returns Min            -56.8418
evaluation/Actions Mean             0.0135241
evaluation/Actions Std              0.194666
evaluation/Actions Max              0.998341
evaluation/Actions Min             -0.997938
evaluation/Num Paths               15
evaluation/Average Returns        -27.3222
time/data storing (s)               0.00309801
time/evaluation sampling (s)        0.353845
time/exploration sampling (s)       0.157351
time/logging (s)                    0.00425177
time/saving (s)                     0.00202021
time/training (s)                   2.17659
time/epoch (s)                      2.69715
time/total (s)                    426.697
Epoch                             156
-----------------------------  ---------------
2019-04-22 22:03:07.178331 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 157 finished
-----------------------------  ---------------
replay_buffer/size              79200
trainer/QF1 Loss                    1.85018
trainer/QF2 Loss                    1.84993
trainer/Policy Loss                12.1658
trainer/Q1 Predictions Mean       -10.461
trainer/Q1 Predictions Std          4.43992
trainer/Q1 Predictions Max         -6.90075
trainer/Q1 Predictions Min        -35.0872
trainer/Q2 Predictions Mean       -10.4592
trainer/Q2 Predictions Std          4.4718
trainer/Q2 Predictions Max         -6.90452
trainer/Q2 Predictions Min        -35.3836
trainer/Q Targets Mean            -10.4039
trainer/Q Targets Std               4.58556
trainer/Q Targets Max              -0.890364
trainer/Q Targets Min             -35.3805
trainer/Log Pis Mean                2.01847
trainer/Log Pis Std                 1.19474
trainer/Log Pis Max                 6.3202
trainer/Log Pis Min                -0.470221
trainer/Policy mu Mean              0.0683169
trainer/Policy mu Std               0.694601
trainer/Policy mu Max               3.1547
trainer/Policy mu Min              -2.76258
trainer/Policy log std Mean        -2.09153
trainer/Policy log std Std          0.457734
trainer/Policy log std Max         -0.348384
trainer/Policy log std Min         -2.55615
trainer/Alpha                       0.0613221
trainer/Alpha Loss                  0.0515478
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.299453
exploration/Rewards Std             0.630459
exploration/Rewards Max            -0.0122685
exploration/Rewards Min            -6.01793
exploration/Returns Mean          -29.9453
exploration/Returns Std             8.8381
exploration/Returns Max           -17.5876
exploration/Returns Min           -39.5006
exploration/Actions Mean            0.00248202
exploration/Actions Std             0.225487
exploration/Actions Max             0.998153
exploration/Actions Min            -0.995059
exploration/Num Paths               5
exploration/Average Returns       -29.9453
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.267313
evaluation/Rewards Std              0.93686
evaluation/Rewards Max             -0.00767872
evaluation/Rewards Min             -9.92786
evaluation/Returns Mean           -26.7313
evaluation/Returns Std             11.3615
evaluation/Returns Max            -11.0875
evaluation/Returns Min            -56.2214
evaluation/Actions Mean             0.00972176
evaluation/Actions Std              0.200251
evaluation/Actions Max              0.997615
evaluation/Actions Min             -0.996607
evaluation/Num Paths               15
evaluation/Average Returns        -26.7313
time/data storing (s)               0.00313389
time/evaluation sampling (s)        0.35296
time/exploration sampling (s)       0.15928
time/logging (s)                    0.00505731
time/saving (s)                     0.00160889
time/training (s)                   2.12977
time/epoch (s)                      2.65181
time/total (s)                    429.354
Epoch                             157
-----------------------------  ---------------
2019-04-22 22:03:09.871487 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 158 finished
-----------------------------  ---------------
replay_buffer/size              79700
trainer/QF1 Loss                    2.35443
trainer/QF2 Loss                    2.37991
trainer/Policy Loss                11.5889
trainer/Q1 Predictions Mean        -9.91586
trainer/Q1 Predictions Std          3.61973
trainer/Q1 Predictions Max         -6.88684
trainer/Q1 Predictions Min        -24.2529
trainer/Q2 Predictions Mean        -9.92074
trainer/Q2 Predictions Std          3.63003
trainer/Q2 Predictions Max         -6.90093
trainer/Q2 Predictions Min        -23.7638
trainer/Q Targets Mean             -9.83756
trainer/Q Targets Std               3.88213
trainer/Q Targets Max              -0.0287534
trainer/Q Targets Min             -24.3103
trainer/Log Pis Mean                1.95857
trainer/Log Pis Std                 1.23666
trainer/Log Pis Max                 5.51719
trainer/Log Pis Min                -4.76047
trainer/Policy mu Mean              0.0389937
trainer/Policy mu Std               0.713976
trainer/Policy mu Max               2.91461
trainer/Policy mu Min              -2.78912
trainer/Policy log std Mean        -2.06812
trainer/Policy log std Std          0.451018
trainer/Policy log std Max         -0.401835
trainer/Policy log std Min         -2.62985
trainer/Alpha                       0.0604404
trainer/Alpha Loss                 -0.116249
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.367251
exploration/Rewards Std             0.918613
exploration/Rewards Max            -0.0133927
exploration/Rewards Min            -8.97337
exploration/Returns Mean          -36.7251
exploration/Returns Std            12.3729
exploration/Returns Max           -23.8226
exploration/Returns Min           -56.1515
exploration/Actions Mean            0.0376139
exploration/Actions Std             0.222575
exploration/Actions Max             0.999513
exploration/Actions Min            -0.465423
exploration/Num Paths               5
exploration/Average Returns       -36.7251
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273897
evaluation/Rewards Std              0.83457
evaluation/Rewards Max             -0.0413105
evaluation/Rewards Min            -10.3099
evaluation/Returns Mean           -27.3897
evaluation/Returns Std             15.6944
evaluation/Returns Max             -7.54515
evaluation/Returns Min            -70.3573
evaluation/Actions Mean            -0.00627873
evaluation/Actions Std              0.180436
evaluation/Actions Max              0.993441
evaluation/Actions Min             -0.998793
evaluation/Num Paths               15
evaluation/Average Returns        -27.3897
time/data storing (s)               0.0030141
time/evaluation sampling (s)        0.352326
time/exploration sampling (s)       0.158524
time/logging (s)                    0.00471141
time/saving (s)                     0.00198223
time/training (s)                   2.16503
time/epoch (s)                      2.68559
time/total (s)                    432.043
Epoch                             158
-----------------------------  ---------------
2019-04-22 22:03:12.557486 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    1.98464
trainer/QF2 Loss                    2.08522
trainer/Policy Loss                12.7629
trainer/Q1 Predictions Mean       -11.0744
trainer/Q1 Predictions Std          6.67859
trainer/Q1 Predictions Max         -6.90213
trainer/Q1 Predictions Min        -54.5113
trainer/Q2 Predictions Mean       -11.0793
trainer/Q2 Predictions Std          6.58072
trainer/Q2 Predictions Max         -6.86353
trainer/Q2 Predictions Min        -53.0896
trainer/Q Targets Mean            -11.2065
trainer/Q Targets Std               6.88225
trainer/Q Targets Max              -0.987515
trainer/Q Targets Min             -56.5779
trainer/Log Pis Mean                2.07895
trainer/Log Pis Std                 1.46934
trainer/Log Pis Max                 8.70923
trainer/Log Pis Min                -2.32821
trainer/Policy mu Mean              0.173524
trainer/Policy mu Std               0.72378
trainer/Policy mu Max               3.26532
trainer/Policy mu Min              -2.70223
trainer/Policy log std Mean        -2.1329
trainer/Policy log std Std          0.469637
trainer/Policy log std Max         -0.582638
trainer/Policy log std Min         -2.7461
trainer/Alpha                       0.0628956
trainer/Alpha Loss                  0.218396
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.381348
exploration/Rewards Std             1.15349
exploration/Rewards Max            -0.00567332
exploration/Rewards Min           -10.272
exploration/Returns Mean          -38.1348
exploration/Returns Std            21.3819
exploration/Returns Max           -14.7257
exploration/Returns Min           -69.2515
exploration/Actions Mean            0.0365775
exploration/Actions Std             0.222372
exploration/Actions Max             0.999593
exploration/Actions Min            -0.767147
exploration/Num Paths               5
exploration/Average Returns       -38.1348
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.296055
evaluation/Rewards Std              1.08845
evaluation/Rewards Max             -0.0250094
evaluation/Rewards Min             -9.75417
evaluation/Returns Mean           -29.6055
evaluation/Returns Std             19.206
evaluation/Returns Max             -6.00363
evaluation/Returns Min            -58.6585
evaluation/Actions Mean             0.00352745
evaluation/Actions Std              0.195459
evaluation/Actions Max              0.998194
evaluation/Actions Min             -0.998768
evaluation/Num Paths               15
evaluation/Average Returns        -29.6055
time/data storing (s)               0.00315138
time/evaluation sampling (s)        0.357685
time/exploration sampling (s)       0.164054
time/logging (s)                    0.00436113
time/saving (s)                     0.00225293
time/training (s)                   2.14709
time/epoch (s)                      2.67859
time/total (s)                    434.726
Epoch                             159
-----------------------------  ---------------
2019-04-22 22:03:15.256861 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              80700
trainer/QF1 Loss                    0.0817316
trainer/QF2 Loss                    0.137694
trainer/Policy Loss                13.5324
trainer/Q1 Predictions Mean       -11.6992
trainer/Q1 Predictions Std          7.89809
trainer/Q1 Predictions Max         -7.10077
trainer/Q1 Predictions Min        -59.0306
trainer/Q2 Predictions Mean       -11.6952
trainer/Q2 Predictions Std          7.92102
trainer/Q2 Predictions Max         -7.02821
trainer/Q2 Predictions Min        -58.2568
trainer/Q Targets Mean            -11.7918
trainer/Q Targets Std               8.00619
trainer/Q Targets Max              -6.96838
trainer/Q Targets Min             -61.2238
trainer/Log Pis Mean                2.11995
trainer/Log Pis Std                 1.3426
trainer/Log Pis Max                 8.62534
trainer/Log Pis Min                -0.462341
trainer/Policy mu Mean              0.0468053
trainer/Policy mu Std               0.853645
trainer/Policy mu Max               2.95048
trainer/Policy mu Min              -3.1494
trainer/Policy log std Mean        -1.99086
trainer/Policy log std Std          0.523554
trainer/Policy log std Max         -0.406153
trainer/Policy log std Min         -2.69067
trainer/Alpha                       0.0621709
trainer/Alpha Loss                  0.333208
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.276128
exploration/Rewards Std             0.737441
exploration/Rewards Max            -0.00402342
exploration/Rewards Min            -8.3006
exploration/Returns Mean          -27.6128
exploration/Returns Std            11.2089
exploration/Returns Max           -17.1433
exploration/Returns Min           -47.9906
exploration/Actions Mean           -0.00479187
exploration/Actions Std             0.219685
exploration/Actions Max             0.998533
exploration/Actions Min            -0.997228
exploration/Num Paths               5
exploration/Average Returns       -27.6128
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229527
evaluation/Rewards Std              0.888804
evaluation/Rewards Max             -0.00225922
evaluation/Rewards Min             -9.7131
evaluation/Returns Mean           -22.9527
evaluation/Returns Std             15.5093
evaluation/Returns Max             -5.07295
evaluation/Returns Min            -59.1087
evaluation/Actions Mean            -0.00868818
evaluation/Actions Std              0.182935
evaluation/Actions Max              0.99542
evaluation/Actions Min             -0.997779
evaluation/Num Paths               15
evaluation/Average Returns        -22.9527
time/data storing (s)               0.00387749
time/evaluation sampling (s)        0.3577
time/exploration sampling (s)       0.161323
time/logging (s)                    0.00486842
time/saving (s)                     0.00234114
time/training (s)                   2.16227
time/epoch (s)                      2.69238
time/total (s)                    437.423
Epoch                             160
-----------------------------  ---------------
2019-04-22 22:03:17.975698 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              81200
trainer/QF1 Loss                    3.81822
trainer/QF2 Loss                    3.78826
trainer/Policy Loss                12.5002
trainer/Q1 Predictions Mean       -10.5589
trainer/Q1 Predictions Std          5.66999
trainer/Q1 Predictions Max         -6.87237
trainer/Q1 Predictions Min        -43.8845
trainer/Q2 Predictions Mean       -10.5842
trainer/Q2 Predictions Std          5.69516
trainer/Q2 Predictions Max         -6.89996
trainer/Q2 Predictions Min        -44.6299
trainer/Q Targets Mean            -10.3366
trainer/Q Targets Std               5.64871
trainer/Q Targets Max              -0.0997102
trainer/Q Targets Min             -42.9423
trainer/Log Pis Mean                2.1652
trainer/Log Pis Std                 1.15167
trainer/Log Pis Max                 5.87476
trainer/Log Pis Min                -2.48461
trainer/Policy mu Mean              0.133043
trainer/Policy mu Std               0.739321
trainer/Policy mu Max               2.85942
trainer/Policy mu Min              -2.98716
trainer/Policy log std Mean        -2.08207
trainer/Policy log std Std          0.481888
trainer/Policy log std Max         -0.443659
trainer/Policy log std Min         -2.77925
trainer/Alpha                       0.0611469
trainer/Alpha Loss                  0.461653
exploration/num steps total     81200
exploration/num paths total       812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.188399
exploration/Rewards Std             0.372209
exploration/Rewards Max            -0.00248966
exploration/Rewards Min            -4.83706
exploration/Returns Mean          -18.8399
exploration/Returns Std             5.55136
exploration/Returns Max           -12.3439
exploration/Returns Min           -29.0585
exploration/Actions Mean            0.00623038
exploration/Actions Std             0.193654
exploration/Actions Max             0.998691
exploration/Actions Min            -0.996745
exploration/Num Paths               5
exploration/Average Returns       -18.8399
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.277431
evaluation/Rewards Std              1.08369
evaluation/Rewards Max             -0.0233646
evaluation/Rewards Min            -10.2779
evaluation/Returns Mean           -27.7431
evaluation/Returns Std             18.5332
evaluation/Returns Max             -4.73753
evaluation/Returns Min            -62.9375
evaluation/Actions Mean             0.00589149
evaluation/Actions Std              0.196579
evaluation/Actions Max              0.998255
evaluation/Actions Min             -0.997049
evaluation/Num Paths               15
evaluation/Average Returns        -27.7431
time/data storing (s)               0.00347047
time/evaluation sampling (s)        0.35567
time/exploration sampling (s)       0.162779
time/logging (s)                    0.00484595
time/saving (s)                     0.00197259
time/training (s)                   2.18263
time/epoch (s)                      2.71137
time/total (s)                    440.139
Epoch                             161
-----------------------------  ---------------
2019-04-22 22:03:20.639250 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              81700
trainer/QF1 Loss                    0.813681
trainer/QF2 Loss                    0.811556
trainer/Policy Loss                11.9492
trainer/Q1 Predictions Mean       -10.2144
trainer/Q1 Predictions Std          3.14983
trainer/Q1 Predictions Max         -6.96685
trainer/Q1 Predictions Min        -19.4733
trainer/Q2 Predictions Mean       -10.2406
trainer/Q2 Predictions Std          3.19277
trainer/Q2 Predictions Max         -6.9308
trainer/Q2 Predictions Min        -19.3471
trainer/Q Targets Mean            -10.2625
trainer/Q Targets Std               3.38527
trainer/Q Targets Max              -0.260368
trainer/Q Targets Min             -19.3324
trainer/Log Pis Mean                2.039
trainer/Log Pis Std                 1.26769
trainer/Log Pis Max                 5.88053
trainer/Log Pis Min                -3.08739
trainer/Policy mu Mean              0.0932128
trainer/Policy mu Std               0.628904
trainer/Policy mu Max               2.84689
trainer/Policy mu Min              -2.91373
trainer/Policy log std Mean        -2.1219
trainer/Policy log std Std          0.431245
trainer/Policy log std Max         -0.488382
trainer/Policy log std Min         -2.78208
trainer/Alpha                       0.0585041
trainer/Alpha Loss                  0.110718
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.357955
exploration/Rewards Std             1.00005
exploration/Rewards Max            -0.00156867
exploration/Rewards Min            -8.9393
exploration/Returns Mean          -35.7955
exploration/Returns Std            15.4053
exploration/Returns Max           -19.6431
exploration/Returns Min           -57.1904
exploration/Actions Mean           -0.00632557
exploration/Actions Std             0.247095
exploration/Actions Max             0.998049
exploration/Actions Min            -0.999027
exploration/Num Paths               5
exploration/Average Returns       -35.7955
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.187207
evaluation/Rewards Std              0.825072
evaluation/Rewards Max             -0.0036143
evaluation/Rewards Min             -9.38403
evaluation/Returns Mean           -18.7207
evaluation/Returns Std             13.8251
evaluation/Returns Max             -3.61512
evaluation/Returns Min            -51.9357
evaluation/Actions Mean             0.00920363
evaluation/Actions Std              0.181962
evaluation/Actions Max              0.998424
evaluation/Actions Min             -0.996189
evaluation/Num Paths               15
evaluation/Average Returns        -18.7207
time/data storing (s)               0.00307817
time/evaluation sampling (s)        0.35859
time/exploration sampling (s)       0.16011
time/logging (s)                    0.00484916
time/saving (s)                     0.00207742
time/training (s)                   2.12745
time/epoch (s)                      2.65616
time/total (s)                    442.8
Epoch                             162
-----------------------------  ---------------
2019-04-22 22:03:23.337509 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              82200
trainer/QF1 Loss                    2.41407
trainer/QF2 Loss                    2.43974
trainer/Policy Loss                12.6577
trainer/Q1 Predictions Mean       -10.9932
trainer/Q1 Predictions Std          8.77853
trainer/Q1 Predictions Max         -6.71026
trainer/Q1 Predictions Min        -77.4627
trainer/Q2 Predictions Mean       -10.9816
trainer/Q2 Predictions Std          8.71869
trainer/Q2 Predictions Max         -6.75207
trainer/Q2 Predictions Min        -77.5055
trainer/Q Targets Mean            -10.9398
trainer/Q Targets Std               9.05882
trainer/Q Targets Max              -0.0700145
trainer/Q Targets Min             -79.2237
trainer/Log Pis Mean                2.01993
trainer/Log Pis Std                 1.3666
trainer/Log Pis Max                10.8411
trainer/Log Pis Min                -1.55395
trainer/Policy mu Mean              0.115036
trainer/Policy mu Std               0.729432
trainer/Policy mu Max               3.46774
trainer/Policy mu Min              -3.48073
trainer/Policy log std Mean        -2.04827
trainer/Policy log std Std          0.486449
trainer/Policy log std Max         -0.202691
trainer/Policy log std Min         -2.66168
trainer/Alpha                       0.0603338
trainer/Alpha Loss                  0.0559549
exploration/num steps total     82200
exploration/num paths total       822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.305464
exploration/Rewards Std             0.884888
exploration/Rewards Max            -0.0052868
exploration/Rewards Min            -9.34559
exploration/Returns Mean          -30.5464
exploration/Returns Std            16.8204
exploration/Returns Max           -14.6976
exploration/Returns Min           -61.4677
exploration/Actions Mean            0.00683582
exploration/Actions Std             0.23871
exploration/Actions Max             0.992571
exploration/Actions Min            -0.998403
exploration/Num Paths               5
exploration/Average Returns       -30.5464
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.258173
evaluation/Rewards Std              1.0026
evaluation/Rewards Max             -0.0220971
evaluation/Rewards Min             -9.93996
evaluation/Returns Mean           -25.8173
evaluation/Returns Std             16.1999
evaluation/Returns Max             -5.13636
evaluation/Returns Min            -57.2884
evaluation/Actions Mean            -0.00624021
evaluation/Actions Std              0.187169
evaluation/Actions Max              0.996615
evaluation/Actions Min             -0.998108
evaluation/Num Paths               15
evaluation/Average Returns        -25.8173
time/data storing (s)               0.00325943
time/evaluation sampling (s)        0.370071
time/exploration sampling (s)       0.180048
time/logging (s)                    0.00494235
time/saving (s)                     0.0020036
time/training (s)                   2.1306
time/epoch (s)                      2.69092
time/total (s)                    445.495
Epoch                             163
-----------------------------  ---------------
2019-04-22 22:03:25.989104 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              82700
trainer/QF1 Loss                    0.89041
trainer/QF2 Loss                    0.870622
trainer/Policy Loss                12.0732
trainer/Q1 Predictions Mean       -10.4413
trainer/Q1 Predictions Std          6.44719
trainer/Q1 Predictions Max         -6.82658
trainer/Q1 Predictions Min        -54.2409
trainer/Q2 Predictions Mean       -10.4874
trainer/Q2 Predictions Std          6.54561
trainer/Q2 Predictions Max         -6.88123
trainer/Q2 Predictions Min        -54.415
trainer/Q Targets Mean            -10.5683
trainer/Q Targets Std               6.61812
trainer/Q Targets Max              -1.25155
trainer/Q Targets Min             -54.4111
trainer/Log Pis Mean                1.89909
trainer/Log Pis Std                 1.09701
trainer/Log Pis Max                 4.96037
trainer/Log Pis Min                -1.85707
trainer/Policy mu Mean              0.14609
trainer/Policy mu Std               0.721933
trainer/Policy mu Max               3.28593
trainer/Policy mu Min              -3.67673
trainer/Policy log std Mean        -2.03921
trainer/Policy log std Std          0.471255
trainer/Policy log std Max         -0.395085
trainer/Policy log std Min         -2.73179
trainer/Alpha                       0.0619695
trainer/Alpha Loss                 -0.280633
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.276879
exploration/Rewards Std             0.961152
exploration/Rewards Max            -0.00374841
exploration/Rewards Min           -11.4117
exploration/Returns Mean          -27.6879
exploration/Returns Std            23.8708
exploration/Returns Max           -13.9318
exploration/Returns Min           -75.3692
exploration/Actions Mean            0.0168762
exploration/Actions Std             0.221192
exploration/Actions Max             0.997904
exploration/Actions Min            -0.996072
exploration/Num Paths               5
exploration/Average Returns       -27.6879
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.203205
evaluation/Rewards Std              0.843685
evaluation/Rewards Max             -0.0243596
evaluation/Rewards Min             -9.65704
evaluation/Returns Mean           -20.3205
evaluation/Returns Std             12.6676
evaluation/Returns Max             -4.15602
evaluation/Returns Min            -54.3523
evaluation/Actions Mean            -0.0130462
evaluation/Actions Std              0.178546
evaluation/Actions Max              0.997669
evaluation/Actions Min             -0.997748
evaluation/Num Paths               15
evaluation/Average Returns        -20.3205
time/data storing (s)               0.00323976
time/evaluation sampling (s)        0.347048
time/exploration sampling (s)       0.158466
time/logging (s)                    0.00501968
time/saving (s)                     0.00200024
time/training (s)                   2.12826
time/epoch (s)                      2.64403
time/total (s)                    448.144
Epoch                             164
-----------------------------  ---------------
2019-04-22 22:03:28.683796 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              83200
trainer/QF1 Loss                    0.503735
trainer/QF2 Loss                    0.513417
trainer/Policy Loss                11.0772
trainer/Q1 Predictions Mean        -9.61178
trainer/Q1 Predictions Std          3.88135
trainer/Q1 Predictions Max         -6.89111
trainer/Q1 Predictions Min        -39.626
trainer/Q2 Predictions Mean        -9.63049
trainer/Q2 Predictions Std          3.9258
trainer/Q2 Predictions Max         -6.85717
trainer/Q2 Predictions Min        -40.1139
trainer/Q Targets Mean             -9.5729
trainer/Q Targets Std               3.90916
trainer/Q Targets Max              -0.263805
trainer/Q Targets Min             -38.5351
trainer/Log Pis Mean                1.84126
trainer/Log Pis Std                 1.15879
trainer/Log Pis Max                 4.73145
trainer/Log Pis Min                -2.06276
trainer/Policy mu Mean              0.0665041
trainer/Policy mu Std               0.55429
trainer/Policy mu Max               2.93571
trainer/Policy mu Min              -2.66851
trainer/Policy log std Mean        -2.13024
trainer/Policy log std Std          0.38163
trainer/Policy log std Max         -0.471856
trainer/Policy log std Min         -2.68406
trainer/Alpha                       0.0608946
trainer/Alpha Loss                 -0.444287
exploration/num steps total     83200
exploration/num paths total       832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.473073
exploration/Rewards Std             1.30567
exploration/Rewards Max            -0.0126675
exploration/Rewards Min           -10.2243
exploration/Returns Mean          -47.3073
exploration/Returns Std            16.444
exploration/Returns Max           -23.0311
exploration/Returns Min           -72.2864
exploration/Actions Mean           -0.0221241
exploration/Actions Std             0.256859
exploration/Actions Max             0.999183
exploration/Actions Min            -0.998691
exploration/Num Paths               5
exploration/Average Returns       -47.3073
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207139
evaluation/Rewards Std              0.779069
evaluation/Rewards Max             -0.0107413
evaluation/Rewards Min             -9.42798
evaluation/Returns Mean           -20.7139
evaluation/Returns Std             14.0912
evaluation/Returns Max             -6.27885
evaluation/Returns Min            -58.9991
evaluation/Actions Mean             0.00425302
evaluation/Actions Std              0.172219
evaluation/Actions Max              0.997929
evaluation/Actions Min             -0.99696
evaluation/Num Paths               15
evaluation/Average Returns        -20.7139
time/data storing (s)               0.00323428
time/evaluation sampling (s)        0.351087
time/exploration sampling (s)       0.157695
time/logging (s)                    0.00478693
time/saving (s)                     0.00220286
time/training (s)                   2.16814
time/epoch (s)                      2.68714
time/total (s)                    450.836
Epoch                             165
-----------------------------  ---------------
2019-04-22 22:03:31.334121 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              83700
trainer/QF1 Loss                    0.663734
trainer/QF2 Loss                    0.718245
trainer/Policy Loss                12.5603
trainer/Q1 Predictions Mean       -11.0467
trainer/Q1 Predictions Std          8.8145
trainer/Q1 Predictions Max         -6.74647
trainer/Q1 Predictions Min        -74.0558
trainer/Q2 Predictions Mean       -11.0253
trainer/Q2 Predictions Std          8.65817
trainer/Q2 Predictions Max         -6.77127
trainer/Q2 Predictions Min        -72.6591
trainer/Q Targets Mean            -11.046
trainer/Q Targets Std               8.94398
trainer/Q Targets Max              -0.0883165
trainer/Q Targets Min             -75.4312
trainer/Log Pis Mean                1.96093
trainer/Log Pis Std                 1.48004
trainer/Log Pis Max                 8.6338
trainer/Log Pis Min                -3.01703
trainer/Policy mu Mean              0.0399025
trainer/Policy mu Std               0.709273
trainer/Policy mu Max               3.15468
trainer/Policy mu Min              -3.15544
trainer/Policy log std Mean        -2.09215
trainer/Policy log std Std          0.439997
trainer/Policy log std Max         -0.558999
trainer/Policy log std Min         -2.636
trainer/Alpha                       0.0610523
trainer/Alpha Loss                 -0.109231
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.366675
exploration/Rewards Std             0.962012
exploration/Rewards Max            -0.0117534
exploration/Rewards Min            -8.73025
exploration/Returns Mean          -36.6675
exploration/Returns Std            12.6386
exploration/Returns Max           -22.3316
exploration/Returns Min           -59.8661
exploration/Actions Mean           -0.0233051
exploration/Actions Std             0.245619
exploration/Actions Max             0.999358
exploration/Actions Min            -0.999269
exploration/Num Paths               5
exploration/Average Returns       -36.6675
evaluation/num steps total     250500
evaluation/num paths total       2505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.344773
evaluation/Rewards Std              1.09211
evaluation/Rewards Max             -0.00768902
evaluation/Rewards Min            -10.9812
evaluation/Returns Mean           -34.4773
evaluation/Returns Std             19.128
evaluation/Returns Max             -0.997536
evaluation/Returns Min            -73.472
evaluation/Actions Mean             0.0115279
evaluation/Actions Std              0.196616
evaluation/Actions Max              0.998111
evaluation/Actions Min             -0.996333
evaluation/Num Paths               15
evaluation/Average Returns        -34.4773
time/data storing (s)               0.00345279
time/evaluation sampling (s)        0.356284
time/exploration sampling (s)       0.163953
time/logging (s)                    0.004786
time/saving (s)                     0.00198149
time/training (s)                   2.11247
time/epoch (s)                      2.64293
time/total (s)                    453.483
Epoch                             166
-----------------------------  ---------------
2019-04-22 22:03:34.063889 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              84200
trainer/QF1 Loss                    0.0250818
trainer/QF2 Loss                    0.0366455
trainer/Policy Loss                11.3521
trainer/Q1 Predictions Mean        -9.92461
trainer/Q1 Predictions Std          4.9521
trainer/Q1 Predictions Max         -6.81468
trainer/Q1 Predictions Min        -40.4835
trainer/Q2 Predictions Mean        -9.91413
trainer/Q2 Predictions Std          4.93352
trainer/Q2 Predictions Max         -6.7919
trainer/Q2 Predictions Min        -39.6953
trainer/Q Targets Mean             -9.95042
trainer/Q Targets Std               4.93002
trainer/Q Targets Max              -6.85869
trainer/Q Targets Min             -40.3279
trainer/Log Pis Mean                1.7121
trainer/Log Pis Std                 1.33388
trainer/Log Pis Max                 5.26723
trainer/Log Pis Min                -3.15936
trainer/Policy mu Mean              0.0884305
trainer/Policy mu Std               0.579718
trainer/Policy mu Max               3.29041
trainer/Policy mu Min              -2.43378
trainer/Policy log std Mean        -2.14657
trainer/Policy log std Std          0.376908
trainer/Policy log std Max         -0.507557
trainer/Policy log std Min         -2.6172
trainer/Alpha                       0.0581892
trainer/Alpha Loss                 -0.818775
exploration/num steps total     84200
exploration/num paths total       842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.424156
exploration/Rewards Std             1.22318
exploration/Rewards Max            -0.0077619
exploration/Rewards Min           -10.8123
exploration/Returns Mean          -42.4156
exploration/Returns Std            19.7298
exploration/Returns Max           -20.1118
exploration/Returns Min           -72.4038
exploration/Actions Mean           -0.0028398
exploration/Actions Std             0.244857
exploration/Actions Max             0.999602
exploration/Actions Min            -0.998813
exploration/Num Paths               5
exploration/Average Returns       -42.4156
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.206413
evaluation/Rewards Std              0.728933
evaluation/Rewards Max             -0.0264397
evaluation/Rewards Min            -10.1616
evaluation/Returns Mean           -20.6413
evaluation/Returns Std             15.3177
evaluation/Returns Max             -3.87771
evaluation/Returns Min            -64.9759
evaluation/Actions Mean            -0.00648024
evaluation/Actions Std              0.166538
evaluation/Actions Max              0.996843
evaluation/Actions Min             -0.999072
evaluation/Num Paths               15
evaluation/Average Returns        -20.6413
time/data storing (s)               0.00313048
time/evaluation sampling (s)        0.348188
time/exploration sampling (s)       0.159614
time/logging (s)                    0.00483693
time/saving (s)                     0.00221721
time/training (s)                   2.20404
time/epoch (s)                      2.72202
time/total (s)                    456.21
Epoch                             167
-----------------------------  ---------------
2019-04-22 22:03:36.777421 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              84700
trainer/QF1 Loss                    0.626996
trainer/QF2 Loss                    0.636791
trainer/Policy Loss                11.5889
trainer/Q1 Predictions Mean        -9.95763
trainer/Q1 Predictions Std          3.47775
trainer/Q1 Predictions Max         -6.83337
trainer/Q1 Predictions Min        -25.8245
trainer/Q2 Predictions Mean        -9.94461
trainer/Q2 Predictions Std          3.47764
trainer/Q2 Predictions Max         -6.77741
trainer/Q2 Predictions Min        -26.3133
trainer/Q Targets Mean             -9.93882
trainer/Q Targets Std               3.59839
trainer/Q Targets Max              -0.109623
trainer/Q Targets Min             -26.0663
trainer/Log Pis Mean                1.90685
trainer/Log Pis Std                 1.06868
trainer/Log Pis Max                 5.35764
trainer/Log Pis Min                -1.91663
trainer/Policy mu Mean              0.106312
trainer/Policy mu Std               0.659944
trainer/Policy mu Max               2.85914
trainer/Policy mu Min              -2.96009
trainer/Policy log std Mean        -2.08398
trainer/Policy log std Std          0.449842
trainer/Policy log std Max         -0.457615
trainer/Policy log std Min         -2.66087
trainer/Alpha                       0.0582044
trainer/Alpha Loss                 -0.26488
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387605
exploration/Rewards Std             1.12881
exploration/Rewards Max            -0.0188683
exploration/Rewards Min            -9.17514
exploration/Returns Mean          -38.7605
exploration/Returns Std            15.6299
exploration/Returns Max           -17.8728
exploration/Returns Min           -55.4253
exploration/Actions Mean           -0.0107248
exploration/Actions Std             0.247855
exploration/Actions Max             0.998247
exploration/Actions Min            -0.999438
exploration/Num Paths               5
exploration/Average Returns       -38.7605
evaluation/num steps total     253500
evaluation/num paths total       2535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.241789
evaluation/Rewards Std              0.870976
evaluation/Rewards Max             -0.03606
evaluation/Rewards Min             -9.72499
evaluation/Returns Mean           -24.1789
evaluation/Returns Std             13.3712
evaluation/Returns Max             -5.02502
evaluation/Returns Min            -57.3426
evaluation/Actions Mean            -0.0177988
evaluation/Actions Std              0.192748
evaluation/Actions Max              0.998641
evaluation/Actions Min             -0.997282
evaluation/Num Paths               15
evaluation/Average Returns        -24.1789
time/data storing (s)               0.00318972
time/evaluation sampling (s)        0.366502
time/exploration sampling (s)       0.161292
time/logging (s)                    0.00455342
time/saving (s)                     0.00201692
time/training (s)                   2.16852
time/epoch (s)                      2.70607
time/total (s)                    458.921
Epoch                             168
-----------------------------  ---------------
2019-04-22 22:03:39.439415 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              85200
trainer/QF1 Loss                    0.700131
trainer/QF2 Loss                    0.680064
trainer/Policy Loss                12.3641
trainer/Q1 Predictions Mean       -10.4127
trainer/Q1 Predictions Std          7.16346
trainer/Q1 Predictions Max         -6.85934
trainer/Q1 Predictions Min        -59.6817
trainer/Q2 Predictions Mean       -10.4003
trainer/Q2 Predictions Std          7.18539
trainer/Q2 Predictions Max         -6.82018
trainer/Q2 Predictions Min        -59.5082
trainer/Q Targets Mean            -10.5057
trainer/Q Targets Std               7.43269
trainer/Q Targets Max              -0.139303
trainer/Q Targets Min             -60.9879
trainer/Log Pis Mean                2.1854
trainer/Log Pis Std                 1.39849
trainer/Log Pis Max                10.7234
trainer/Log Pis Min                -1.73473
trainer/Policy mu Mean              0.0763346
trainer/Policy mu Std               0.649735
trainer/Policy mu Max               3.12323
trainer/Policy mu Min              -3.61881
trainer/Policy log std Mean        -2.18453
trainer/Policy log std Std          0.406237
trainer/Policy log std Max         -0.597476
trainer/Policy log std Min         -2.67229
trainer/Alpha                       0.0567722
trainer/Alpha Loss                  0.531883
exploration/num steps total     85200
exploration/num paths total       852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.329408
exploration/Rewards Std             0.936485
exploration/Rewards Max            -0.00240654
exploration/Rewards Min            -9.28481
exploration/Returns Mean          -32.9408
exploration/Returns Std            15.1248
exploration/Returns Max           -19.9872
exploration/Returns Min           -62.1212
exploration/Actions Mean           -0.0315774
exploration/Actions Std             0.231772
exploration/Actions Max             0.966276
exploration/Actions Min            -0.998334
exploration/Num Paths               5
exploration/Average Returns       -32.9408
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.276413
evaluation/Rewards Std              1.08988
evaluation/Rewards Max             -0.030153
evaluation/Rewards Min            -10.2042
evaluation/Returns Mean           -27.6413
evaluation/Returns Std             13.5028
evaluation/Returns Max             -4.6242
evaluation/Returns Min            -54.8113
evaluation/Actions Mean            -0.0171303
evaluation/Actions Std              0.212521
evaluation/Actions Max              0.996822
evaluation/Actions Min             -0.996282
evaluation/Num Paths               15
evaluation/Average Returns        -27.6413
time/data storing (s)               0.00333569
time/evaluation sampling (s)        0.353145
time/exploration sampling (s)       0.159806
time/logging (s)                    0.00480431
time/saving (s)                     0.00217412
time/training (s)                   2.13129
time/epoch (s)                      2.65455
time/total (s)                    461.58
Epoch                             169
-----------------------------  ---------------
2019-04-22 22:03:42.174230 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              85700
trainer/QF1 Loss                    0.059312
trainer/QF2 Loss                    0.0522977
trainer/Policy Loss                12.0034
trainer/Q1 Predictions Mean       -10.504
trainer/Q1 Predictions Std          6.91389
trainer/Q1 Predictions Max         -6.76455
trainer/Q1 Predictions Min        -52.0761
trainer/Q2 Predictions Mean       -10.5336
trainer/Q2 Predictions Std          6.97662
trainer/Q2 Predictions Max         -6.73699
trainer/Q2 Predictions Min        -52.3653
trainer/Q Targets Mean            -10.6524
trainer/Q Targets Std               7.02896
trainer/Q Targets Max              -6.76401
trainer/Q Targets Min             -53.064
trainer/Log Pis Mean                1.95311
trainer/Log Pis Std                 1.44937
trainer/Log Pis Max                 8.33906
trainer/Log Pis Min                -1.51416
trainer/Policy mu Mean              0.146168
trainer/Policy mu Std               0.720951
trainer/Policy mu Max               3.03734
trainer/Policy mu Min              -2.83872
trainer/Policy log std Mean        -2.07635
trainer/Policy log std Std          0.469492
trainer/Policy log std Max         -0.541024
trainer/Policy log std Min         -2.63013
trainer/Alpha                       0.0600951
trainer/Alpha Loss                 -0.131841
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.282983
exploration/Rewards Std             0.916913
exploration/Rewards Max            -0.00258015
exploration/Rewards Min           -10.3245
exploration/Returns Mean          -28.2983
exploration/Returns Std            18.7458
exploration/Returns Max           -17.0466
exploration/Returns Min           -65.7354
exploration/Actions Mean            0.00620458
exploration/Actions Std             0.222894
exploration/Actions Max             0.998508
exploration/Actions Min            -0.999033
exploration/Num Paths               5
exploration/Average Returns       -28.2983
evaluation/num steps total     256500
evaluation/num paths total       2565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.206275
evaluation/Rewards Std              0.952685
evaluation/Rewards Max             -0.0141143
evaluation/Rewards Min            -10.469
evaluation/Returns Mean           -20.6275
evaluation/Returns Std             17.947
evaluation/Returns Max             -2.62436
evaluation/Returns Min            -60.2042
evaluation/Actions Mean            -0.00309786
evaluation/Actions Std              0.179364
evaluation/Actions Max              0.997808
evaluation/Actions Min             -0.996353
evaluation/Num Paths               15
evaluation/Average Returns        -20.6275
time/data storing (s)               0.00306629
time/evaluation sampling (s)        0.362565
time/exploration sampling (s)       0.160561
time/logging (s)                    0.0048446
time/saving (s)                     0.0119936
time/training (s)                   2.18392
time/epoch (s)                      2.72695
time/total (s)                    464.312
Epoch                             170
-----------------------------  ---------------
2019-04-22 22:03:44.809950 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 171 finished
-----------------------------  ---------------
replay_buffer/size              86200
trainer/QF1 Loss                    0.0933511
trainer/QF2 Loss                    0.084066
trainer/Policy Loss                12.1548
trainer/Q1 Predictions Mean       -10.2601
trainer/Q1 Predictions Std          6.7602
trainer/Q1 Predictions Max         -6.83614
trainer/Q1 Predictions Min        -59.0002
trainer/Q2 Predictions Mean       -10.2462
trainer/Q2 Predictions Std          6.83353
trainer/Q2 Predictions Max         -6.74917
trainer/Q2 Predictions Min        -59.819
trainer/Q Targets Mean            -10.2806
trainer/Q Targets Std               6.77313
trainer/Q Targets Max              -6.71513
trainer/Q Targets Min             -60.4498
trainer/Log Pis Mean                2.20504
trainer/Log Pis Std                 1.17742
trainer/Log Pis Max                 6.37074
trainer/Log Pis Min                -0.441289
trainer/Policy mu Mean              0.0248917
trainer/Policy mu Std               0.680176
trainer/Policy mu Max               2.81247
trainer/Policy mu Min              -3.18189
trainer/Policy log std Mean        -2.16394
trainer/Policy log std Std          0.438247
trainer/Policy log std Max         -0.451856
trainer/Policy log std Min         -2.64237
trainer/Alpha                       0.0619802
trainer/Alpha Loss                  0.570247
exploration/num steps total     86200
exploration/num paths total       862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.225955
exploration/Rewards Std             0.559655
exploration/Rewards Max            -0.00193641
exploration/Rewards Min            -6.08199
exploration/Returns Mean          -22.5955
exploration/Returns Std             5.84675
exploration/Returns Max           -16.8774
exploration/Returns Min           -32.4959
exploration/Actions Mean            0.00454224
exploration/Actions Std             0.197282
exploration/Actions Max             0.998459
exploration/Actions Min            -0.998865
exploration/Num Paths               5
exploration/Average Returns       -22.5955
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231467
evaluation/Rewards Std              0.931604
evaluation/Rewards Max             -0.0262214
evaluation/Rewards Min            -11.1243
evaluation/Returns Mean           -23.1467
evaluation/Returns Std             16.8867
evaluation/Returns Max             -3.24527
evaluation/Returns Min            -64.3639
evaluation/Actions Mean            -0.00437547
evaluation/Actions Std              0.184976
evaluation/Actions Max              0.99783
evaluation/Actions Min             -0.999289
evaluation/Num Paths               15
evaluation/Average Returns        -23.1467
time/data storing (s)               0.00362224
time/evaluation sampling (s)        0.355011
time/exploration sampling (s)       0.159032
time/logging (s)                    0.00475109
time/saving (s)                     0.00199087
time/training (s)                   2.10331
time/epoch (s)                      2.62772
time/total (s)                    466.944
Epoch                             171
-----------------------------  ---------------
2019-04-22 22:03:47.540391 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                    1.64277
trainer/QF2 Loss                    1.62184
trainer/Policy Loss                11.1948
trainer/Q1 Predictions Mean        -9.53494
trainer/Q1 Predictions Std          3.99958
trainer/Q1 Predictions Max         -6.6897
trainer/Q1 Predictions Min        -32.8259
trainer/Q2 Predictions Mean        -9.54373
trainer/Q2 Predictions Std          4.02851
trainer/Q2 Predictions Max         -6.64551
trainer/Q2 Predictions Min        -32.4455
trainer/Q Targets Mean             -9.4599
trainer/Q Targets Std               4.25089
trainer/Q Targets Max              -0.0907827
trainer/Q Targets Min             -32.3914
trainer/Log Pis Mean                1.8638
trainer/Log Pis Std                 1.36312
trainer/Log Pis Max                 8.98631
trainer/Log Pis Min                -1.89684
trainer/Policy mu Mean              0.0437562
trainer/Policy mu Std               0.663005
trainer/Policy mu Max               2.87987
trainer/Policy mu Min              -2.90602
trainer/Policy log std Mean        -2.08495
trainer/Policy log std Std          0.425383
trainer/Policy log std Max         -0.51026
trainer/Policy log std Min         -2.58122
trainer/Alpha                       0.0611422
trainer/Alpha Loss                 -0.380606
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.316742
exploration/Rewards Std             0.916629
exploration/Rewards Max            -0.00841637
exploration/Rewards Min            -9.93266
exploration/Returns Mean          -31.6742
exploration/Returns Std            19.2686
exploration/Returns Max           -16.3021
exploration/Returns Min           -69.7204
exploration/Actions Mean            0.0203254
exploration/Actions Std             0.222805
exploration/Actions Max             0.998845
exploration/Actions Min            -0.995561
exploration/Num Paths               5
exploration/Average Returns       -31.6742
evaluation/num steps total     259500
evaluation/num paths total       2595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.220191
evaluation/Rewards Std              0.851278
evaluation/Rewards Max             -0.0152569
evaluation/Rewards Min             -9.0541
evaluation/Returns Mean           -22.0191
evaluation/Returns Std             13.7855
evaluation/Returns Max             -7.14039
evaluation/Returns Min            -47.3324
evaluation/Actions Mean            -0.0109329
evaluation/Actions Std              0.175376
evaluation/Actions Max              0.995475
evaluation/Actions Min             -0.996804
evaluation/Num Paths               15
evaluation/Average Returns        -22.0191
time/data storing (s)               0.00304248
time/evaluation sampling (s)        0.355198
time/exploration sampling (s)       0.164066
time/logging (s)                    0.0047736
time/saving (s)                     0.0020366
time/training (s)                   2.19361
time/epoch (s)                      2.72273
time/total (s)                    469.672
Epoch                             172
-----------------------------  ---------------
2019-04-22 22:03:50.192184 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 173 finished
-----------------------------  ---------------
replay_buffer/size              87200
trainer/QF1 Loss                    0.0199755
trainer/QF2 Loss                    0.025484
trainer/Policy Loss                11.4907
trainer/Q1 Predictions Mean        -9.9407
trainer/Q1 Predictions Std          4.89276
trainer/Q1 Predictions Max         -6.68869
trainer/Q1 Predictions Min        -42.2579
trainer/Q2 Predictions Mean        -9.96413
trainer/Q2 Predictions Std          4.93318
trainer/Q2 Predictions Max         -6.70433
trainer/Q2 Predictions Min        -41.9633
trainer/Q Targets Mean            -10.0181
trainer/Q Targets Std               4.90945
trainer/Q Targets Max              -6.65929
trainer/Q Targets Min             -42.3456
trainer/Log Pis Mean                1.81553
trainer/Log Pis Std                 1.56983
trainer/Log Pis Max                 7.63438
trainer/Log Pis Min                -4.07472
trainer/Policy mu Mean              0.0462769
trainer/Policy mu Std               0.614463
trainer/Policy mu Max               3.25743
trainer/Policy mu Min              -2.80189
trainer/Policy log std Mean        -2.1152
trainer/Policy log std Std          0.391473
trainer/Policy log std Max         -0.585939
trainer/Policy log std Min         -2.63091
trainer/Alpha                       0.0578341
trainer/Alpha Loss                 -0.525763
exploration/num steps total     87200
exploration/num paths total       872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.331908
exploration/Rewards Std             1.05961
exploration/Rewards Max            -0.0103296
exploration/Rewards Min            -9.77131
exploration/Returns Mean          -33.1908
exploration/Returns Std            21.5974
exploration/Returns Max           -14.993
exploration/Returns Min           -60.5286
exploration/Actions Mean            0.00565696
exploration/Actions Std             0.227085
exploration/Actions Max             0.998746
exploration/Actions Min            -0.999112
exploration/Num Paths               5
exploration/Average Returns       -33.1908
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256209
evaluation/Rewards Std              0.969315
evaluation/Rewards Max             -0.0315658
evaluation/Rewards Min            -10.2105
evaluation/Returns Mean           -25.6209
evaluation/Returns Std             15.0088
evaluation/Returns Max             -8.63479
evaluation/Returns Min            -52.7108
evaluation/Actions Mean            -0.00913954
evaluation/Actions Std              0.191021
evaluation/Actions Max              0.996381
evaluation/Actions Min             -0.997518
evaluation/Num Paths               15
evaluation/Average Returns        -25.6209
time/data storing (s)               0.00316551
time/evaluation sampling (s)        0.356264
time/exploration sampling (s)       0.165256
time/logging (s)                    0.00430578
time/saving (s)                     0.00235708
time/training (s)                   2.11282
time/epoch (s)                      2.64417
time/total (s)                    472.32
Epoch                             173
-----------------------------  ---------------
2019-04-22 22:03:52.841139 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              87700
trainer/QF1 Loss                    0.0447495
trainer/QF2 Loss                    0.03194
trainer/Policy Loss                11.6663
trainer/Q1 Predictions Mean        -9.88115
trainer/Q1 Predictions Std          3.44149
trainer/Q1 Predictions Max         -6.65456
trainer/Q1 Predictions Min        -29.649
trainer/Q2 Predictions Mean        -9.89061
trainer/Q2 Predictions Std          3.46504
trainer/Q2 Predictions Max         -6.64638
trainer/Q2 Predictions Min        -29.5965
trainer/Q Targets Mean             -9.90726
trainer/Q Targets Std               3.425
trainer/Q Targets Max              -6.70604
trainer/Q Targets Min             -28.6391
trainer/Log Pis Mean                2.06804
trainer/Log Pis Std                 1.09994
trainer/Log Pis Max                 7.37113
trainer/Log Pis Min                -1.55955
trainer/Policy mu Mean              0.0773926
trainer/Policy mu Std               0.604954
trainer/Policy mu Max               2.8622
trainer/Policy mu Min              -2.8137
trainer/Policy log std Mean        -2.13058
trainer/Policy log std Std          0.371022
trainer/Policy log std Max         -0.56611
trainer/Policy log std Min         -2.5596
trainer/Alpha                       0.0577021
trainer/Alpha Loss                  0.19409
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.383379
exploration/Rewards Std             1.10655
exploration/Rewards Max            -0.014851
exploration/Rewards Min            -9.65411
exploration/Returns Mean          -38.3379
exploration/Returns Std            15.4892
exploration/Returns Max           -18.9601
exploration/Returns Min           -60.3314
exploration/Actions Mean            0.0188756
exploration/Actions Std             0.242292
exploration/Actions Max             0.999827
exploration/Actions Min            -0.998889
exploration/Num Paths               5
exploration/Average Returns       -38.3379
evaluation/num steps total     262500
evaluation/num paths total       2625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.201585
evaluation/Rewards Std              0.81087
evaluation/Rewards Max             -0.0295482
evaluation/Rewards Min             -9.68293
evaluation/Returns Mean           -20.1585
evaluation/Returns Std             14.5833
evaluation/Returns Max             -5.98712
evaluation/Returns Min            -57.5265
evaluation/Actions Mean            -0.0017919
evaluation/Actions Std              0.170277
evaluation/Actions Max              0.995883
evaluation/Actions Min             -0.998128
evaluation/Num Paths               15
evaluation/Average Returns        -20.1585
time/data storing (s)               0.00400707
time/evaluation sampling (s)        0.350629
time/exploration sampling (s)       0.15881
time/logging (s)                    0.00485843
time/saving (s)                     0.00196069
time/training (s)                   2.12152
time/epoch (s)                      2.64178
time/total (s)                    474.967
Epoch                             174
-----------------------------  ---------------
2019-04-22 22:03:55.557591 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              88200
trainer/QF1 Loss                    0.0559374
trainer/QF2 Loss                    0.0373422
trainer/Policy Loss                10.806
trainer/Q1 Predictions Mean        -9.16275
trainer/Q1 Predictions Std          2.54787
trainer/Q1 Predictions Max         -6.67713
trainer/Q1 Predictions Min        -19.5606
trainer/Q2 Predictions Mean        -9.15431
trainer/Q2 Predictions Std          2.54111
trainer/Q2 Predictions Max         -6.64123
trainer/Q2 Predictions Min        -20.3705
trainer/Q Targets Mean             -9.26653
trainer/Q Targets Std               2.60466
trainer/Q Targets Max              -6.69498
trainer/Q Targets Min             -21.3886
trainer/Log Pis Mean                1.83939
trainer/Log Pis Std                 1.38144
trainer/Log Pis Max                 4.91432
trainer/Log Pis Min                -2.99457
trainer/Policy mu Mean              0.0392429
trainer/Policy mu Std               0.602056
trainer/Policy mu Max               2.88952
trainer/Policy mu Min              -2.60034
trainer/Policy log std Mean        -2.09679
trainer/Policy log std Std          0.398893
trainer/Policy log std Max         -0.510745
trainer/Policy log std Min         -2.48288
trainer/Alpha                       0.057891
trainer/Alpha Loss                 -0.457572
exploration/num steps total     88200
exploration/num paths total       882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.350748
exploration/Rewards Std             1.10928
exploration/Rewards Max            -0.00424711
exploration/Rewards Min           -10.6335
exploration/Returns Mean          -35.0748
exploration/Returns Std            18.727
exploration/Returns Max           -16.4831
exploration/Returns Min           -66.9888
exploration/Actions Mean           -0.0061543
exploration/Actions Std             0.241536
exploration/Actions Max             0.999038
exploration/Actions Min            -0.998128
exploration/Num Paths               5
exploration/Average Returns       -35.0748
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.262871
evaluation/Rewards Std              0.987901
evaluation/Rewards Max             -0.0251581
evaluation/Rewards Min             -9.6946
evaluation/Returns Mean           -26.2871
evaluation/Returns Std             16.074
evaluation/Returns Max             -2.87415
evaluation/Returns Min            -65.2795
evaluation/Actions Mean             0.00189968
evaluation/Actions Std              0.192413
evaluation/Actions Max              0.998398
evaluation/Actions Min             -0.99788
evaluation/Num Paths               15
evaluation/Average Returns        -26.2871
time/data storing (s)               0.00317844
time/evaluation sampling (s)        0.402719
time/exploration sampling (s)       0.162324
time/logging (s)                    0.00481463
time/saving (s)                     0.00201903
time/training (s)                   2.13288
time/epoch (s)                      2.70793
time/total (s)                    477.68
Epoch                             175
-----------------------------  ---------------
2019-04-22 22:03:58.214937 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              88700
trainer/QF1 Loss                    0.033916
trainer/QF2 Loss                    0.029408
trainer/Policy Loss                11.3293
trainer/Q1 Predictions Mean        -9.47248
trainer/Q1 Predictions Std          4.67547
trainer/Q1 Predictions Max         -6.76649
trainer/Q1 Predictions Min        -41.0832
trainer/Q2 Predictions Mean        -9.48656
trainer/Q2 Predictions Std          4.67771
trainer/Q2 Predictions Max         -6.71046
trainer/Q2 Predictions Min        -41.0342
trainer/Q Targets Mean             -9.58498
trainer/Q Targets Std               4.70087
trainer/Q Targets Max              -6.66706
trainer/Q Targets Min             -41.1828
trainer/Log Pis Mean                2.01724
trainer/Log Pis Std                 1.1652
trainer/Log Pis Max                 7.09289
trainer/Log Pis Min                -1.06705
trainer/Policy mu Mean              0.0309869
trainer/Policy mu Std               0.600284
trainer/Policy mu Max               2.88241
trainer/Policy mu Min              -2.90517
trainer/Policy log std Mean        -2.16756
trainer/Policy log std Std          0.39067
trainer/Policy log std Max         -0.504371
trainer/Policy log std Min         -2.48017
trainer/Alpha                       0.0572917
trainer/Alpha Loss                  0.0492889
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.398277
exploration/Rewards Std             1.21242
exploration/Rewards Max            -0.00563215
exploration/Rewards Min           -10.658
exploration/Returns Mean          -39.8277
exploration/Returns Std            16.3132
exploration/Returns Max           -19.008
exploration/Returns Min           -63.3377
exploration/Actions Mean            0.0174674
exploration/Actions Std             0.246331
exploration/Actions Max             0.998844
exploration/Actions Min            -0.99839
exploration/Num Paths               5
exploration/Average Returns       -39.8277
evaluation/num steps total     265500
evaluation/num paths total       2655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268517
evaluation/Rewards Std              0.988326
evaluation/Rewards Max             -0.0149883
evaluation/Rewards Min             -8.90399
evaluation/Returns Mean           -26.8517
evaluation/Returns Std             15.175
evaluation/Returns Max             -3.66898
evaluation/Returns Min            -50.5645
evaluation/Actions Mean            -0.0238611
evaluation/Actions Std              0.19785
evaluation/Actions Max              0.997588
evaluation/Actions Min             -0.997541
evaluation/Num Paths               15
evaluation/Average Returns        -26.8517
time/data storing (s)               0.0037742
time/evaluation sampling (s)        0.355862
time/exploration sampling (s)       0.170802
time/logging (s)                    0.00406272
time/saving (s)                     0.00196687
time/training (s)                   2.11236
time/epoch (s)                      2.64883
time/total (s)                    480.334
Epoch                             176
-----------------------------  ---------------
2019-04-22 22:04:00.914923 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 177 finished
-----------------------------  ---------------
replay_buffer/size              89200
trainer/QF1 Loss                    0.489234
trainer/QF2 Loss                    0.481806
trainer/Policy Loss                11.8827
trainer/Q1 Predictions Mean       -10.3863
trainer/Q1 Predictions Std          8.14549
trainer/Q1 Predictions Max         -6.67928
trainer/Q1 Predictions Min        -78.8487
trainer/Q2 Predictions Mean       -10.3802
trainer/Q2 Predictions Std          8.05285
trainer/Q2 Predictions Max         -6.6238
trainer/Q2 Predictions Min        -77.6779
trainer/Q Targets Mean            -10.3653
trainer/Q Targets Std               8.1389
trainer/Q Targets Max              -0.578384
trainer/Q Targets Min             -78.8676
trainer/Log Pis Mean                2.04436
trainer/Log Pis Std                 1.23162
trainer/Log Pis Max                 9.19204
trainer/Log Pis Min                -0.894276
trainer/Policy mu Mean              0.192908
trainer/Policy mu Std               0.735299
trainer/Policy mu Max               3.56244
trainer/Policy mu Min              -3.0789
trainer/Policy log std Mean        -2.0216
trainer/Policy log std Std          0.48605
trainer/Policy log std Max         -0.411701
trainer/Policy log std Min         -2.52307
trainer/Alpha                       0.0555817
trainer/Alpha Loss                  0.12818
exploration/num steps total     89200
exploration/num paths total       892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.385499
exploration/Rewards Std             1.20151
exploration/Rewards Max            -0.0127074
exploration/Rewards Min           -10.7051
exploration/Returns Mean          -38.5499
exploration/Returns Std            19.714
exploration/Returns Max           -16.7219
exploration/Returns Min           -67.9893
exploration/Actions Mean            0.00160869
exploration/Actions Std             0.248615
exploration/Actions Max             0.999184
exploration/Actions Min            -0.999583
exploration/Num Paths               5
exploration/Average Returns       -38.5499
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.270594
evaluation/Rewards Std              1.08756
evaluation/Rewards Max             -0.0293454
evaluation/Rewards Min            -10.3078
evaluation/Returns Mean           -27.0594
evaluation/Returns Std             18.9715
evaluation/Returns Max             -6.13203
evaluation/Returns Min            -62.6885
evaluation/Actions Mean            -0.00527636
evaluation/Actions Std              0.193969
evaluation/Actions Max              0.998757
evaluation/Actions Min             -0.996193
evaluation/Num Paths               15
evaluation/Average Returns        -27.0594
time/data storing (s)               0.00349815
time/evaluation sampling (s)        0.349625
time/exploration sampling (s)       0.162217
time/logging (s)                    0.00421366
time/saving (s)                     0.00198039
time/training (s)                   2.17231
time/epoch (s)                      2.69385
time/total (s)                    483.032
Epoch                             177
-----------------------------  ---------------
2019-04-22 22:04:03.556165 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              89700
trainer/QF1 Loss                    0.0399417
trainer/QF2 Loss                    0.0616029
trainer/Policy Loss                11.3544
trainer/Q1 Predictions Mean        -9.74787
trainer/Q1 Predictions Std          5.1348
trainer/Q1 Predictions Max         -6.48791
trainer/Q1 Predictions Min        -43.6269
trainer/Q2 Predictions Mean        -9.77902
trainer/Q2 Predictions Std          5.20629
trainer/Q2 Predictions Max         -6.50539
trainer/Q2 Predictions Min        -44.5683
trainer/Q Targets Mean             -9.83813
trainer/Q Targets Std               5.05844
trainer/Q Targets Max              -6.57853
trainer/Q Targets Min             -43.1228
trainer/Log Pis Mean                1.91
trainer/Log Pis Std                 1.19961
trainer/Log Pis Max                 6.4036
trainer/Log Pis Min                -1.6519
trainer/Policy mu Mean              0.119242
trainer/Policy mu Std               0.715956
trainer/Policy mu Max               3.08666
trainer/Policy mu Min              -2.87563
trainer/Policy log std Mean        -2.03315
trainer/Policy log std Std          0.47712
trainer/Policy log std Max         -0.553934
trainer/Policy log std Min         -2.52803
trainer/Alpha                       0.0564732
trainer/Alpha Loss                 -0.258658
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.30162
exploration/Rewards Std             0.683418
exploration/Rewards Max            -0.00624849
exploration/Rewards Min            -6.439
exploration/Returns Mean          -30.162
exploration/Returns Std             3.88859
exploration/Returns Max           -25.5923
exploration/Returns Min           -35.5679
exploration/Actions Mean           -0.00580471
exploration/Actions Std             0.219868
exploration/Actions Max             0.998776
exploration/Actions Min            -0.998098
exploration/Num Paths               5
exploration/Average Returns       -30.162
evaluation/num steps total     268500
evaluation/num paths total       2685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.193829
evaluation/Rewards Std              0.800256
evaluation/Rewards Max             -0.0225198
evaluation/Rewards Min            -10.1546
evaluation/Returns Mean           -19.3829
evaluation/Returns Std             16.4925
evaluation/Returns Max             -4.04491
evaluation/Returns Min            -61.1876
evaluation/Actions Mean            -0.00487646
evaluation/Actions Std              0.168909
evaluation/Actions Max              0.998288
evaluation/Actions Min             -0.998957
evaluation/Num Paths               15
evaluation/Average Returns        -19.3829
time/data storing (s)               0.00299588
time/evaluation sampling (s)        0.34951
time/exploration sampling (s)       0.158766
time/logging (s)                    0.00479907
time/saving (s)                     0.00210404
time/training (s)                   2.11602
time/epoch (s)                      2.6342
time/total (s)                    485.67
Epoch                             178
-----------------------------  ---------------
2019-04-22 22:04:06.269240 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 179 finished
-----------------------------  ----------------
replay_buffer/size              90200
trainer/QF1 Loss                    0.705921
trainer/QF2 Loss                    0.710154
trainer/Policy Loss                10.8747
trainer/Q1 Predictions Mean        -9.31111
trainer/Q1 Predictions Std          2.58158
trainer/Q1 Predictions Max         -6.53895
trainer/Q1 Predictions Min        -19.9787
trainer/Q2 Predictions Mean        -9.3227
trainer/Q2 Predictions Std          2.55987
trainer/Q2 Predictions Max         -6.53974
trainer/Q2 Predictions Min        -20.0928
trainer/Q Targets Mean             -9.26102
trainer/Q Targets Std               2.71356
trainer/Q Targets Max              -0.275569
trainer/Q Targets Min             -20.6297
trainer/Log Pis Mean                1.68965
trainer/Log Pis Std                 1.42565
trainer/Log Pis Max                 5.49927
trainer/Log Pis Min                -5.25433
trainer/Policy mu Mean              0.0579459
trainer/Policy mu Std               0.525403
trainer/Policy mu Max               2.66368
trainer/Policy mu Min              -2.79847
trainer/Policy log std Mean        -2.134
trainer/Policy log std Std          0.365486
trainer/Policy log std Max         -0.534911
trainer/Policy log std Min         -2.48544
trainer/Alpha                       0.0543496
trainer/Alpha Loss                 -0.903796
exploration/num steps total     90200
exploration/num paths total       902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43133
exploration/Rewards Std             1.31372
exploration/Rewards Max            -0.00430148
exploration/Rewards Min           -10.4773
exploration/Returns Mean          -43.133
exploration/Returns Std            19.26
exploration/Returns Max           -18.4249
exploration/Returns Min           -67.3008
exploration/Actions Mean           -0.000117853
exploration/Actions Std             0.244681
exploration/Actions Max             0.998932
exploration/Actions Min            -0.997874
exploration/Num Paths               5
exploration/Average Returns       -43.133
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.28173
evaluation/Rewards Std              0.966484
evaluation/Rewards Max             -0.0197579
evaluation/Rewards Min             -9.61014
evaluation/Returns Mean           -28.173
evaluation/Returns Std             13.234
evaluation/Returns Max             -8.42923
evaluation/Returns Min            -52.5083
evaluation/Actions Mean             0.00573901
evaluation/Actions Std              0.193568
evaluation/Actions Max              0.997242
evaluation/Actions Min             -0.996999
evaluation/Num Paths               15
evaluation/Average Returns        -28.173
time/data storing (s)               0.00385819
time/evaluation sampling (s)        0.354013
time/exploration sampling (s)       0.16567
time/logging (s)                    0.00470143
time/saving (s)                     0.00195861
time/training (s)                   2.17601
time/epoch (s)                      2.70621
time/total (s)                    488.381
Epoch                             179
-----------------------------  ----------------
2019-04-22 22:04:08.914682 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              90700
trainer/QF1 Loss                    0.726946
trainer/QF2 Loss                    0.799497
trainer/Policy Loss                11.7447
trainer/Q1 Predictions Mean        -9.96137
trainer/Q1 Predictions Std          6.95047
trainer/Q1 Predictions Max         -6.58208
trainer/Q1 Predictions Min        -67.9252
trainer/Q2 Predictions Mean        -9.98004
trainer/Q2 Predictions Std          6.83753
trainer/Q2 Predictions Max         -6.60712
trainer/Q2 Predictions Min        -66.3688
trainer/Q Targets Mean             -9.95313
trainer/Q Targets Std               7.06906
trainer/Q Targets Max              -1.31628
trainer/Q Targets Min             -68.9895
trainer/Log Pis Mean                2.01421
trainer/Log Pis Std                 1.41142
trainer/Log Pis Max                 7.06194
trainer/Log Pis Min                -3.11132
trainer/Policy mu Mean             -0.0103199
trainer/Policy mu Std               0.77723
trainer/Policy mu Max               3.69902
trainer/Policy mu Min              -2.73913
trainer/Policy log std Mean        -2.02366
trainer/Policy log std Std          0.468867
trainer/Policy log std Max         -0.431658
trainer/Policy log std Min         -2.46244
trainer/Alpha                       0.0555429
trainer/Alpha Loss                  0.0410828
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.352968
exploration/Rewards Std             0.971919
exploration/Rewards Max            -0.0066071
exploration/Rewards Min            -9.80584
exploration/Returns Mean          -35.2968
exploration/Returns Std            16.3727
exploration/Returns Max           -20.1042
exploration/Returns Min           -63.7254
exploration/Actions Mean            0.00522406
exploration/Actions Std             0.247061
exploration/Actions Max             0.999361
exploration/Actions Min            -0.999621
exploration/Num Paths               5
exploration/Average Returns       -35.2968
evaluation/num steps total     271500
evaluation/num paths total       2715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.251362
evaluation/Rewards Std              0.851172
evaluation/Rewards Max             -0.0191623
evaluation/Rewards Min            -10.3673
evaluation/Returns Mean           -25.1362
evaluation/Returns Std             13.379
evaluation/Returns Max             -5.98913
evaluation/Returns Min            -53.9558
evaluation/Actions Mean            -0.0117622
evaluation/Actions Std              0.187952
evaluation/Actions Max              0.99771
evaluation/Actions Min             -0.995677
evaluation/Num Paths               15
evaluation/Average Returns        -25.1362
time/data storing (s)               0.00317905
time/evaluation sampling (s)        0.354413
time/exploration sampling (s)       0.161354
time/logging (s)                    0.00514589
time/saving (s)                     0.00197176
time/training (s)                   2.11224
time/epoch (s)                      2.6383
time/total (s)                    491.024
Epoch                             180
-----------------------------  ---------------
2019-04-22 22:04:11.612879 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              91200
trainer/QF1 Loss                    0.0217954
trainer/QF2 Loss                    0.0352676
trainer/Policy Loss                11.2447
trainer/Q1 Predictions Mean        -9.52146
trainer/Q1 Predictions Std          5.96242
trainer/Q1 Predictions Max         -6.51003
trainer/Q1 Predictions Min        -43.3888
trainer/Q2 Predictions Mean        -9.49438
trainer/Q2 Predictions Std          6.00876
trainer/Q2 Predictions Max         -6.42717
trainer/Q2 Predictions Min        -43.0761
trainer/Q Targets Mean             -9.58144
trainer/Q Targets Std               5.92606
trainer/Q Targets Max              -6.53713
trainer/Q Targets Min             -43.0013
trainer/Log Pis Mean                1.85972
trainer/Log Pis Std                 1.14737
trainer/Log Pis Max                 8.42448
trainer/Log Pis Min                -1.13968
trainer/Policy mu Mean              0.0814753
trainer/Policy mu Std               0.633964
trainer/Policy mu Max               2.77435
trainer/Policy mu Min              -3.47937
trainer/Policy log std Mean        -2.08257
trainer/Policy log std Std          0.444878
trainer/Policy log std Max         -0.324693
trainer/Policy log std Min         -2.49448
trainer/Alpha                       0.0543239
trainer/Alpha Loss                 -0.408592
exploration/num steps total     91200
exploration/num paths total       912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.458806
exploration/Rewards Std             1.25351
exploration/Rewards Max            -0.0143777
exploration/Rewards Min            -9.54955
exploration/Returns Mean          -45.8806
exploration/Returns Std            14.3434
exploration/Returns Max           -19.074
exploration/Returns Min           -59.1025
exploration/Actions Mean            0.00489786
exploration/Actions Std             0.270765
exploration/Actions Max             0.998839
exploration/Actions Min            -0.998549
exploration/Num Paths               5
exploration/Average Returns       -45.8806
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.333029
evaluation/Rewards Std              0.950937
evaluation/Rewards Max             -0.0545316
evaluation/Rewards Min             -9.58754
evaluation/Returns Mean           -33.3029
evaluation/Returns Std             17.9297
evaluation/Returns Max            -10.2156
evaluation/Returns Min            -67.7562
evaluation/Actions Mean             0.00724532
evaluation/Actions Std              0.179643
evaluation/Actions Max              0.998418
evaluation/Actions Min             -0.997653
evaluation/Num Paths               15
evaluation/Average Returns        -33.3029
time/data storing (s)               0.00314744
time/evaluation sampling (s)        0.361752
time/exploration sampling (s)       0.165596
time/logging (s)                    0.00495897
time/saving (s)                     0.00205247
time/training (s)                   2.15329
time/epoch (s)                      2.69079
time/total (s)                    493.718
Epoch                             181
-----------------------------  ---------------
2019-04-22 22:04:14.281963 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              91700
trainer/QF1 Loss                    0.0780351
trainer/QF2 Loss                    0.119066
trainer/Policy Loss                13.0032
trainer/Q1 Predictions Mean       -11.4991
trainer/Q1 Predictions Std          8.58966
trainer/Q1 Predictions Max         -6.45417
trainer/Q1 Predictions Min        -66.4377
trainer/Q2 Predictions Mean       -11.4705
trainer/Q2 Predictions Std          8.538
trainer/Q2 Predictions Max         -6.45282
trainer/Q2 Predictions Min        -65.2861
trainer/Q Targets Mean            -11.5754
trainer/Q Targets Std               8.5895
trainer/Q Targets Max              -6.51866
trainer/Q Targets Min             -67.4558
trainer/Log Pis Mean                1.96597
trainer/Log Pis Std                 1.41492
trainer/Log Pis Max                 7.70512
trainer/Log Pis Min                -1.79604
trainer/Policy mu Mean              0.144085
trainer/Policy mu Std               0.838408
trainer/Policy mu Max               3.39187
trainer/Policy mu Min              -2.93948
trainer/Policy log std Mean        -2.03225
trainer/Policy log std Std          0.496616
trainer/Policy log std Max         -0.379176
trainer/Policy log std Min         -2.50933
trainer/Alpha                       0.0554814
trainer/Alpha Loss                 -0.0983978
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.228052
exploration/Rewards Std             0.524023
exploration/Rewards Max            -0.00606264
exploration/Rewards Min            -5.42158
exploration/Returns Mean          -22.8052
exploration/Returns Std             3.04964
exploration/Returns Max           -19.3734
exploration/Returns Min           -27.9556
exploration/Actions Mean            0.0131888
exploration/Actions Std             0.222944
exploration/Actions Max             0.996786
exploration/Actions Min            -0.998698
exploration/Num Paths               5
exploration/Average Returns       -22.8052
evaluation/num steps total     274500
evaluation/num paths total       2745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.215906
evaluation/Rewards Std              0.882776
evaluation/Rewards Max             -0.0239199
evaluation/Rewards Min             -9.15159
evaluation/Returns Mean           -21.5906
evaluation/Returns Std             12.7798
evaluation/Returns Max             -5.66558
evaluation/Returns Min            -47.1727
evaluation/Actions Mean            -0.00490994
evaluation/Actions Std              0.188433
evaluation/Actions Max              0.996314
evaluation/Actions Min             -0.996332
evaluation/Num Paths               15
evaluation/Average Returns        -21.5906
time/data storing (s)               0.00313307
time/evaluation sampling (s)        0.359549
time/exploration sampling (s)       0.162488
time/logging (s)                    0.00484803
time/saving (s)                     0.0109885
time/training (s)                   2.12043
time/epoch (s)                      2.66144
time/total (s)                    496.385
Epoch                             182
-----------------------------  ---------------
2019-04-22 22:04:16.940904 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              92200
trainer/QF1 Loss                    1.93357
trainer/QF2 Loss                    1.90582
trainer/Policy Loss                11.9868
trainer/Q1 Predictions Mean       -10.3456
trainer/Q1 Predictions Std          7.81671
trainer/Q1 Predictions Max         -6.56567
trainer/Q1 Predictions Min        -72.9632
trainer/Q2 Predictions Mean       -10.3643
trainer/Q2 Predictions Std          7.94658
trainer/Q2 Predictions Max         -6.55444
trainer/Q2 Predictions Min        -74.2059
trainer/Q Targets Mean            -10.2395
trainer/Q Targets Std               8.10948
trainer/Q Targets Max              -0.213105
trainer/Q Targets Min             -75.6216
trainer/Log Pis Mean                2.06509
trainer/Log Pis Std                 1.41457
trainer/Log Pis Max                 9.18235
trainer/Log Pis Min                -2.44867
trainer/Policy mu Mean              0.14839
trainer/Policy mu Std               0.733695
trainer/Policy mu Max               3.48371
trainer/Policy mu Min              -2.68041
trainer/Policy log std Mean        -1.99789
trainer/Policy log std Std          0.47578
trainer/Policy log std Max         -0.468198
trainer/Policy log std Min         -2.43237
trainer/Alpha                       0.05526
trainer/Alpha Loss                  0.188482
exploration/num steps total     92200
exploration/num paths total       922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.212945
exploration/Rewards Std             0.371078
exploration/Rewards Max            -0.00500338
exploration/Rewards Min            -5.16788
exploration/Returns Mean          -21.2945
exploration/Returns Std             3.73044
exploration/Returns Max           -15.7562
exploration/Returns Min           -25.1478
exploration/Actions Mean           -0.0133928
exploration/Actions Std             0.198127
exploration/Actions Max             0.985416
exploration/Actions Min            -0.998963
exploration/Num Paths               5
exploration/Average Returns       -21.2945
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.301305
evaluation/Rewards Std              1.07148
evaluation/Rewards Max             -0.0351605
evaluation/Rewards Min             -9.93158
evaluation/Returns Mean           -30.1305
evaluation/Returns Std             15.742
evaluation/Returns Max             -6.42938
evaluation/Returns Min            -59.8023
evaluation/Actions Mean            -0.0195942
evaluation/Actions Std              0.203911
evaluation/Actions Max              0.998788
evaluation/Actions Min             -0.998413
evaluation/Num Paths               15
evaluation/Average Returns        -30.1305
time/data storing (s)               0.003107
time/evaluation sampling (s)        0.353351
time/exploration sampling (s)       0.165648
time/logging (s)                    0.00481806
time/saving (s)                     0.00197479
time/training (s)                   2.12176
time/epoch (s)                      2.65066
time/total (s)                    499.04
Epoch                             183
-----------------------------  ---------------
2019-04-22 22:04:19.667112 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              92700
trainer/QF1 Loss                    0.737085
trainer/QF2 Loss                    0.755413
trainer/Policy Loss                12.5017
trainer/Q1 Predictions Mean       -10.7221
trainer/Q1 Predictions Std          9.27611
trainer/Q1 Predictions Max         -6.67102
trainer/Q1 Predictions Min        -73.6963
trainer/Q2 Predictions Mean       -10.713
trainer/Q2 Predictions Std          9.30268
trainer/Q2 Predictions Max         -6.61126
trainer/Q2 Predictions Min        -74.038
trainer/Q Targets Mean            -10.6895
trainer/Q Targets Std               9.3639
trainer/Q Targets Max              -0.104115
trainer/Q Targets Min             -75.0153
trainer/Log Pis Mean                2.22248
trainer/Log Pis Std                 1.53515
trainer/Log Pis Max                 8.91151
trainer/Log Pis Min                -2.2283
trainer/Policy mu Mean              0.078694
trainer/Policy mu Std               0.779783
trainer/Policy mu Max               3.48739
trainer/Policy mu Min              -2.93883
trainer/Policy log std Mean        -2.06599
trainer/Policy log std Std          0.487778
trainer/Policy log std Max         -0.418426
trainer/Policy log std Min         -2.428
trainer/Alpha                       0.0554428
trainer/Alpha Loss                  0.643534
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.201594
exploration/Rewards Std             0.342124
exploration/Rewards Max            -0.0105484
exploration/Rewards Min            -4.29357
exploration/Returns Mean          -20.1594
exploration/Returns Std             2.79941
exploration/Returns Max           -16.5902
exploration/Returns Min           -23.5952
exploration/Actions Mean           -0.00170665
exploration/Actions Std             0.19368
exploration/Actions Max             0.99097
exploration/Actions Min            -0.998348
exploration/Num Paths               5
exploration/Average Returns       -20.1594
evaluation/num steps total     277500
evaluation/num paths total       2775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.215379
evaluation/Rewards Std              0.937783
evaluation/Rewards Max             -0.00408642
evaluation/Rewards Min            -10.0186
evaluation/Returns Mean           -21.5379
evaluation/Returns Std             16.8066
evaluation/Returns Max             -2.36118
evaluation/Returns Min            -55.5849
evaluation/Actions Mean             0.00122425
evaluation/Actions Std              0.183984
evaluation/Actions Max              0.996218
evaluation/Actions Min             -0.998012
evaluation/Num Paths               15
evaluation/Average Returns        -21.5379
time/data storing (s)               0.00300232
time/evaluation sampling (s)        0.399457
time/exploration sampling (s)       0.164232
time/logging (s)                    0.00491666
time/saving (s)                     0.00191109
time/training (s)                   2.1455
time/epoch (s)                      2.71902
time/total (s)                    501.763
Epoch                             184
-----------------------------  ---------------
2019-04-22 22:04:22.322859 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              93200
trainer/QF1 Loss                    0.0533943
trainer/QF2 Loss                    0.0908887
trainer/Policy Loss                11.2314
trainer/Q1 Predictions Mean        -9.64121
trainer/Q1 Predictions Std          5.88964
trainer/Q1 Predictions Max         -6.57002
trainer/Q1 Predictions Min        -63.558
trainer/Q2 Predictions Mean        -9.62023
trainer/Q2 Predictions Std          5.8002
trainer/Q2 Predictions Max         -6.49546
trainer/Q2 Predictions Min        -62.501
trainer/Q Targets Mean             -9.72764
trainer/Q Targets Std               5.99582
trainer/Q Targets Max              -6.50161
trainer/Q Targets Min             -64.4869
trainer/Log Pis Mean                1.81465
trainer/Log Pis Std                 1.23659
trainer/Log Pis Max                 5.30192
trainer/Log Pis Min                -4.54095
trainer/Policy mu Mean              0.0465501
trainer/Policy mu Std               0.673038
trainer/Policy mu Max               3.63107
trainer/Policy mu Min              -2.98303
trainer/Policy log std Mean        -2.08989
trainer/Policy log std Std          0.42565
trainer/Policy log std Max         -0.512504
trainer/Policy log std Min         -2.45385
trainer/Alpha                       0.0548071
trainer/Alpha Loss                 -0.538252
exploration/num steps total     93200
exploration/num paths total       932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.230601
exploration/Rewards Std             0.668419
exploration/Rewards Max            -0.00367281
exploration/Rewards Min            -8.67843
exploration/Returns Mean          -23.0601
exploration/Returns Std            14.5026
exploration/Returns Max           -14.4506
exploration/Returns Min           -52.013
exploration/Actions Mean            0.0142149
exploration/Actions Std             0.196414
exploration/Actions Max             0.998288
exploration/Actions Min            -0.98461
exploration/Num Paths               5
exploration/Average Returns       -23.0601
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.192251
evaluation/Rewards Std              0.811118
evaluation/Rewards Max             -0.0131169
evaluation/Rewards Min             -8.78014
evaluation/Returns Mean           -19.2251
evaluation/Returns Std             12.1227
evaluation/Returns Max             -2.39799
evaluation/Returns Min            -43.7336
evaluation/Actions Mean            -0.00691057
evaluation/Actions Std              0.178665
evaluation/Actions Max              0.997298
evaluation/Actions Min             -0.998072
evaluation/Num Paths               15
evaluation/Average Returns        -19.2251
time/data storing (s)               0.00359645
time/evaluation sampling (s)        0.351797
time/exploration sampling (s)       0.161746
time/logging (s)                    0.00531844
time/saving (s)                     0.0019451
time/training (s)                   2.12414
time/epoch (s)                      2.64854
time/total (s)                    504.416
Epoch                             185
-----------------------------  ---------------
2019-04-22 22:04:25.027401 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              93700
trainer/QF1 Loss                    2.28194
trainer/QF2 Loss                    2.2909
trainer/Policy Loss                11.1158
trainer/Q1 Predictions Mean        -9.30053
trainer/Q1 Predictions Std          2.51815
trainer/Q1 Predictions Max         -6.5146
trainer/Q1 Predictions Min        -22.9409
trainer/Q2 Predictions Mean        -9.30901
trainer/Q2 Predictions Std          2.53537
trainer/Q2 Predictions Max         -6.48657
trainer/Q2 Predictions Min        -23.22
trainer/Q Targets Mean             -9.18057
trainer/Q Targets Std               2.9185
trainer/Q Targets Max              -0.165701
trainer/Q Targets Min             -22.7514
trainer/Log Pis Mean                2.05687
trainer/Log Pis Std                 0.84636
trainer/Log Pis Max                 5.09711
trainer/Log Pis Min                -0.299073
trainer/Policy mu Mean              0.0430566
trainer/Policy mu Std               0.558196
trainer/Policy mu Max               2.72878
trainer/Policy mu Min              -2.63524
trainer/Policy log std Mean        -2.09648
trainer/Policy log std Std          0.384241
trainer/Policy log std Max         -0.590458
trainer/Policy log std Min         -2.4611
trainer/Alpha                       0.0531002
trainer/Alpha Loss                  0.166954
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.38112
exploration/Rewards Std             1.12819
exploration/Rewards Max            -0.00209234
exploration/Rewards Min            -9.98269
exploration/Returns Mean          -38.112
exploration/Returns Std            16.1482
exploration/Returns Max           -16.6906
exploration/Returns Min           -62.3816
exploration/Actions Mean           -0.0150682
exploration/Actions Std             0.257744
exploration/Actions Max             0.99897
exploration/Actions Min            -0.9997
exploration/Num Paths               5
exploration/Average Returns       -38.112
evaluation/num steps total     280500
evaluation/num paths total       2805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.280928
evaluation/Rewards Std              1.06793
evaluation/Rewards Max             -0.0117076
evaluation/Rewards Min            -10.5511
evaluation/Returns Mean           -28.0928
evaluation/Returns Std             16.9522
evaluation/Returns Max             -5.18754
evaluation/Returns Min            -62.9855
evaluation/Actions Mean            -0.00389173
evaluation/Actions Std              0.20248
evaluation/Actions Max              0.998665
evaluation/Actions Min             -0.99862
evaluation/Num Paths               15
evaluation/Average Returns        -28.0928
time/data storing (s)               0.00307666
time/evaluation sampling (s)        0.353946
time/exploration sampling (s)       0.158904
time/logging (s)                    0.00498853
time/saving (s)                     0.00197946
time/training (s)                   2.17391
time/epoch (s)                      2.69681
time/total (s)                    507.117
Epoch                             186
-----------------------------  ---------------
2019-04-22 22:04:27.680714 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              94200
trainer/QF1 Loss                    3.02576
trainer/QF2 Loss                    2.95074
trainer/Policy Loss                11.7843
trainer/Q1 Predictions Mean        -9.98133
trainer/Q1 Predictions Std          6.79173
trainer/Q1 Predictions Max         -6.54024
trainer/Q1 Predictions Min        -69.3866
trainer/Q2 Predictions Mean        -9.95619
trainer/Q2 Predictions Std          6.71963
trainer/Q2 Predictions Max         -6.50382
trainer/Q2 Predictions Min        -68.5183
trainer/Q Targets Mean             -9.86457
trainer/Q Targets Std               6.74391
trainer/Q Targets Max              -4.42891
trainer/Q Targets Min             -69.6734
trainer/Log Pis Mean                2.12019
trainer/Log Pis Std                 1.34645
trainer/Log Pis Max                 7.84683
trainer/Log Pis Min                -2.13993
trainer/Policy mu Mean              0.0714232
trainer/Policy mu Std               0.759745
trainer/Policy mu Max               3.53488
trainer/Policy mu Min              -2.92953
trainer/Policy log std Mean        -2.09802
trainer/Policy log std Std          0.492561
trainer/Policy log std Max         -0.512269
trainer/Policy log std Min         -2.53049
trainer/Alpha                       0.0538603
trainer/Alpha Loss                  0.351137
exploration/num steps total     94200
exploration/num paths total       942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.305165
exploration/Rewards Std             0.935825
exploration/Rewards Max            -0.00153158
exploration/Rewards Min            -9.62338
exploration/Returns Mean          -30.5165
exploration/Returns Std            16.0333
exploration/Returns Max           -12.7096
exploration/Returns Min           -60.4943
exploration/Actions Mean            0.00053725
exploration/Actions Std             0.226157
exploration/Actions Max             0.994406
exploration/Actions Min            -0.997774
exploration/Num Paths               5
exploration/Average Returns       -30.5165
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.282021
evaluation/Rewards Std              1.11003
evaluation/Rewards Max             -0.0303914
evaluation/Rewards Min            -10.1218
evaluation/Returns Mean           -28.2021
evaluation/Returns Std             18.1414
evaluation/Returns Max             -5.14987
evaluation/Returns Min            -59.4393
evaluation/Actions Mean             0.0172711
evaluation/Actions Std              0.198095
evaluation/Actions Max              0.998844
evaluation/Actions Min             -0.995018
evaluation/Num Paths               15
evaluation/Average Returns        -28.2021
time/data storing (s)               0.00320769
time/evaluation sampling (s)        0.356332
time/exploration sampling (s)       0.16194
time/logging (s)                    0.00453269
time/saving (s)                     0.00209239
time/training (s)                   2.11739
time/epoch (s)                      2.6455
time/total (s)                    509.767
Epoch                             187
-----------------------------  ---------------
2019-04-22 22:04:30.367276 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 188 finished
-----------------------------  ---------------
replay_buffer/size              94700
trainer/QF1 Loss                    0.657995
trainer/QF2 Loss                    0.68184
trainer/Policy Loss                12.0238
trainer/Q1 Predictions Mean       -10.5528
trainer/Q1 Predictions Std          6.59231
trainer/Q1 Predictions Max         -6.64246
trainer/Q1 Predictions Min        -58.8608
trainer/Q2 Predictions Mean       -10.5321
trainer/Q2 Predictions Std          6.60991
trainer/Q2 Predictions Max         -6.54038
trainer/Q2 Predictions Min        -58.5259
trainer/Q Targets Mean            -10.4898
trainer/Q Targets Std               6.63885
trainer/Q Targets Max              -0.1621
trainer/Q Targets Min             -59.5864
trainer/Log Pis Mean                1.71919
trainer/Log Pis Std                 1.40207
trainer/Log Pis Max                 6.34543
trainer/Log Pis Min                -2.93537
trainer/Policy mu Mean              0.261727
trainer/Policy mu Std               0.741822
trainer/Policy mu Max               3.57008
trainer/Policy mu Min              -3.23323
trainer/Policy log std Mean        -2.02357
trainer/Policy log std Std          0.507046
trainer/Policy log std Max         -0.394124
trainer/Policy log std Min         -2.50438
trainer/Alpha                       0.0551629
trainer/Alpha Loss                 -0.813584
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.259556
exploration/Rewards Std             0.720784
exploration/Rewards Max            -0.00902868
exploration/Rewards Min            -8.35342
exploration/Returns Mean          -25.9556
exploration/Returns Std            13.0856
exploration/Returns Max           -14.2829
exploration/Returns Min           -51.4169
exploration/Actions Mean           -0.00502578
exploration/Actions Std             0.218262
exploration/Actions Max             0.99976
exploration/Actions Min            -0.997694
exploration/Num Paths               5
exploration/Average Returns       -25.9556
evaluation/num steps total     283500
evaluation/num paths total       2835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.229358
evaluation/Rewards Std              0.94945
evaluation/Rewards Max             -0.0064664
evaluation/Rewards Min             -9.55672
evaluation/Returns Mean           -22.9358
evaluation/Returns Std             15.6721
evaluation/Returns Max             -8.38536
evaluation/Returns Min            -54.8602
evaluation/Actions Mean             0.00415272
evaluation/Actions Std              0.188546
evaluation/Actions Max              0.997207
evaluation/Actions Min             -0.998637
evaluation/Num Paths               15
evaluation/Average Returns        -22.9358
time/data storing (s)               0.00406697
time/evaluation sampling (s)        0.347898
time/exploration sampling (s)       0.157533
time/logging (s)                    0.00483319
time/saving (s)                     0.00222623
time/training (s)                   2.16337
time/epoch (s)                      2.67993
time/total (s)                    512.452
Epoch                             188
-----------------------------  ---------------
2019-04-22 22:04:33.022374 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              95200
trainer/QF1 Loss                    0.468094
trainer/QF2 Loss                    0.498893
trainer/Policy Loss                12.8688
trainer/Q1 Predictions Mean       -11.1024
trainer/Q1 Predictions Std          9.16467
trainer/Q1 Predictions Max         -6.45621
trainer/Q1 Predictions Min        -55.9351
trainer/Q2 Predictions Mean       -11.0775
trainer/Q2 Predictions Std          9.13176
trainer/Q2 Predictions Max         -6.46754
trainer/Q2 Predictions Min        -54.5249
trainer/Q Targets Mean            -11.0577
trainer/Q Targets Std               9.30621
trainer/Q Targets Max              -0.0743964
trainer/Q Targets Min             -56.7999
trainer/Log Pis Mean                2.05437
trainer/Log Pis Std                 1.9843
trainer/Log Pis Max                 9.25612
trainer/Log Pis Min                -4.74343
trainer/Policy mu Mean              0.100505
trainer/Policy mu Std               0.835008
trainer/Policy mu Max               3.28733
trainer/Policy mu Min              -3.45279
trainer/Policy log std Mean        -2.06431
trainer/Policy log std Std          0.507198
trainer/Policy log std Max         -0.38656
trainer/Policy log std Min         -2.51156
trainer/Alpha                       0.0548724
trainer/Alpha Loss                  0.157822
exploration/num steps total     95200
exploration/num paths total       952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.353677
exploration/Rewards Std             1.09971
exploration/Rewards Max            -0.00648725
exploration/Rewards Min           -11.4975
exploration/Returns Mean          -35.3677
exploration/Returns Std            21.071
exploration/Returns Max           -15.5245
exploration/Returns Min           -73.9416
exploration/Actions Mean           -0.0137334
exploration/Actions Std             0.236973
exploration/Actions Max             0.998907
exploration/Actions Min            -0.999924
exploration/Num Paths               5
exploration/Average Returns       -35.3677
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.256997
evaluation/Rewards Std              1.033
evaluation/Rewards Max             -0.0256744
evaluation/Rewards Min             -9.85673
evaluation/Returns Mean           -25.6997
evaluation/Returns Std             19.9885
evaluation/Returns Max             -4.83705
evaluation/Returns Min            -64.2496
evaluation/Actions Mean            -0.00872716
evaluation/Actions Std              0.183641
evaluation/Actions Max              0.9985
evaluation/Actions Min             -0.997803
evaluation/Num Paths               15
evaluation/Average Returns        -25.6997
time/data storing (s)               0.00396404
time/evaluation sampling (s)        0.358512
time/exploration sampling (s)       0.160903
time/logging (s)                    0.00484425
time/saving (s)                     0.00209043
time/training (s)                   2.11762
time/epoch (s)                      2.64793
time/total (s)                    515.104
Epoch                             189
-----------------------------  ---------------
2019-04-22 22:04:35.709271 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              95700
trainer/QF1 Loss                    0.720336
trainer/QF2 Loss                    0.72016
trainer/Policy Loss                10.8403
trainer/Q1 Predictions Mean        -9.08676
trainer/Q1 Predictions Std          4.74889
trainer/Q1 Predictions Max         -6.2558
trainer/Q1 Predictions Min        -38.6141
trainer/Q2 Predictions Mean        -9.09694
trainer/Q2 Predictions Std          4.78198
trainer/Q2 Predictions Max         -6.25303
trainer/Q2 Predictions Min        -39.3772
trainer/Q Targets Mean             -9.21942
trainer/Q Targets Std               4.96294
trainer/Q Targets Max              -0.0787721
trainer/Q Targets Min             -39.3941
trainer/Log Pis Mean                2.01284
trainer/Log Pis Std                 1.06491
trainer/Log Pis Max                 7.15498
trainer/Log Pis Min                -0.84348
trainer/Policy mu Mean             -0.0100245
trainer/Policy mu Std               0.743331
trainer/Policy mu Max               2.72665
trainer/Policy mu Min              -3.24834
trainer/Policy log std Mean        -2.04342
trainer/Policy log std Std          0.491801
trainer/Policy log std Max         -0.421867
trainer/Policy log std Min         -2.4758
trainer/Alpha                       0.0555826
trainer/Alpha Loss                  0.0370969
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.261669
exploration/Rewards Std             0.742667
exploration/Rewards Max            -0.00562454
exploration/Rewards Min            -8.99677
exploration/Returns Mean          -26.1669
exploration/Returns Std            18.0281
exploration/Returns Max           -14.5181
exploration/Returns Min           -61.9901
exploration/Actions Mean           -0.0117691
exploration/Actions Std             0.197382
exploration/Actions Max             0.966595
exploration/Actions Min            -0.998814
exploration/Num Paths               5
exploration/Average Returns       -26.1669
evaluation/num steps total     286500
evaluation/num paths total       2865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268014
evaluation/Rewards Std              0.965656
evaluation/Rewards Max             -0.0350364
evaluation/Rewards Min             -9.86992
evaluation/Returns Mean           -26.8014
evaluation/Returns Std             16.2392
evaluation/Returns Max             -6.39803
evaluation/Returns Min            -61.7866
evaluation/Actions Mean             0.00656057
evaluation/Actions Std              0.185057
evaluation/Actions Max              0.997588
evaluation/Actions Min             -0.998084
evaluation/Num Paths               15
evaluation/Average Returns        -26.8014
time/data storing (s)               0.00346091
time/evaluation sampling (s)        0.355929
time/exploration sampling (s)       0.160437
time/logging (s)                    0.00451554
time/saving (s)                     0.00192986
time/training (s)                   2.15309
time/epoch (s)                      2.67936
time/total (s)                    517.787
Epoch                             190
-----------------------------  ---------------
2019-04-22 22:04:38.363849 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 191 finished
-----------------------------  ----------------
replay_buffer/size              96200
trainer/QF1 Loss                    0.0386522
trainer/QF2 Loss                    0.0353703
trainer/Policy Loss                10.4983
trainer/Q1 Predictions Mean        -8.91884
trainer/Q1 Predictions Std          2.88623
trainer/Q1 Predictions Max         -6.19867
trainer/Q1 Predictions Min        -24.2208
trainer/Q2 Predictions Mean        -8.92638
trainer/Q2 Predictions Std          2.88496
trainer/Q2 Predictions Max         -6.27958
trainer/Q2 Predictions Min        -24.5895
trainer/Q Targets Mean             -9.05008
trainer/Q Targets Std               2.88031
trainer/Q Targets Max              -6.35494
trainer/Q Targets Min             -24.2963
trainer/Log Pis Mean                1.77611
trainer/Log Pis Std                 1.38685
trainer/Log Pis Max                 5.8821
trainer/Log Pis Min                -3.59447
trainer/Policy mu Mean              0.120645
trainer/Policy mu Std               0.557097
trainer/Policy mu Max               2.83396
trainer/Policy mu Min              -2.75942
trainer/Policy log std Mean        -2.15339
trainer/Policy log std Std          0.40488
trainer/Policy log std Max         -0.493581
trainer/Policy log std Min         -2.48117
trainer/Alpha                       0.0574233
trainer/Alpha Loss                 -0.639742
exploration/num steps total     96200
exploration/num paths total       962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.299447
exploration/Rewards Std             0.826854
exploration/Rewards Max            -0.00845148
exploration/Rewards Min            -7.99549
exploration/Returns Mean          -29.9447
exploration/Returns Std            10.0806
exploration/Returns Max           -15.7956
exploration/Returns Min           -41.5353
exploration/Actions Mean            0.000233945
exploration/Actions Std             0.226646
exploration/Actions Max             0.997482
exploration/Actions Min            -0.998699
exploration/Num Paths               5
exploration/Average Returns       -29.9447
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244661
evaluation/Rewards Std              0.925661
evaluation/Rewards Max             -0.0374595
evaluation/Rewards Min             -9.89849
evaluation/Returns Mean           -24.4661
evaluation/Returns Std             13.6526
evaluation/Returns Max             -9.28171
evaluation/Returns Min            -51.3383
evaluation/Actions Mean             0.00135504
evaluation/Actions Std              0.192154
evaluation/Actions Max              0.996109
evaluation/Actions Min             -0.998117
evaluation/Num Paths               15
evaluation/Average Returns        -24.4661
time/data storing (s)               0.00385693
time/evaluation sampling (s)        0.356091
time/exploration sampling (s)       0.160581
time/logging (s)                    0.00487012
time/saving (s)                     0.00195393
time/training (s)                   2.12067
time/epoch (s)                      2.64803
time/total (s)                    520.439
Epoch                             191
-----------------------------  ----------------
2019-04-22 22:04:41.022473 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 192 finished
-----------------------------  ---------------
replay_buffer/size              96700
trainer/QF1 Loss                    1.34592
trainer/QF2 Loss                    1.3745
trainer/Policy Loss                11.1055
trainer/Q1 Predictions Mean        -9.43495
trainer/Q1 Predictions Std          3.99017
trainer/Q1 Predictions Max         -6.69231
trainer/Q1 Predictions Min        -37.2968
trainer/Q2 Predictions Mean        -9.40602
trainer/Q2 Predictions Std          3.86171
trainer/Q2 Predictions Max         -6.63876
trainer/Q2 Predictions Min        -35.6229
trainer/Q Targets Mean             -9.32236
trainer/Q Targets Std               4.21196
trainer/Q Targets Max              -1.2061
trainer/Q Targets Min             -37.5796
trainer/Log Pis Mean                1.88688
trainer/Log Pis Std                 1.09578
trainer/Log Pis Max                 6.78038
trainer/Log Pis Min                -1.17182
trainer/Policy mu Mean              0.104111
trainer/Policy mu Std               0.724188
trainer/Policy mu Max               3.24268
trainer/Policy mu Min              -2.8455
trainer/Policy log std Mean        -1.98813
trainer/Policy log std Std          0.490943
trainer/Policy log std Max         -0.502045
trainer/Policy log std Min         -2.4766
trainer/Alpha                       0.0586199
trainer/Alpha Loss                 -0.320831
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.330773
exploration/Rewards Std             0.929955
exploration/Rewards Max            -0.00651226
exploration/Rewards Min            -8.92013
exploration/Returns Mean          -33.0773
exploration/Returns Std            16.0524
exploration/Returns Max           -19.7684
exploration/Returns Min           -57.9485
exploration/Actions Mean            0.0111013
exploration/Actions Std             0.235808
exploration/Actions Max             0.997634
exploration/Actions Min            -0.998622
exploration/Num Paths               5
exploration/Average Returns       -33.0773
evaluation/num steps total     289500
evaluation/num paths total       2895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.254236
evaluation/Rewards Std              0.908017
evaluation/Rewards Max             -0.0318778
evaluation/Rewards Min             -9.54195
evaluation/Returns Mean           -25.4236
evaluation/Returns Std             14.8739
evaluation/Returns Max             -3.42062
evaluation/Returns Min            -58.801
evaluation/Actions Mean             0.0131388
evaluation/Actions Std              0.179629
evaluation/Actions Max              0.998887
evaluation/Actions Min             -0.99541
evaluation/Num Paths               15
evaluation/Average Returns        -25.4236
time/data storing (s)               0.0035362
time/evaluation sampling (s)        0.352549
time/exploration sampling (s)       0.164343
time/logging (s)                    0.00543682
time/saving (s)                     0.00205859
time/training (s)                   2.12365
time/epoch (s)                      2.65158
time/total (s)                    523.096
Epoch                             192
-----------------------------  ---------------
2019-04-22 22:04:43.773106 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              97200
trainer/QF1 Loss                    1.85822
trainer/QF2 Loss                    1.89067
trainer/Policy Loss                11.6157
trainer/Q1 Predictions Mean        -9.87617
trainer/Q1 Predictions Std          5.20374
trainer/Q1 Predictions Max         -6.35442
trainer/Q1 Predictions Min        -35.1593
trainer/Q2 Predictions Mean        -9.90309
trainer/Q2 Predictions Std          5.21603
trainer/Q2 Predictions Max         -6.41091
trainer/Q2 Predictions Min        -35.3638
trainer/Q Targets Mean             -9.74408
trainer/Q Targets Std               5.53427
trainer/Q Targets Max              -0.142299
trainer/Q Targets Min             -34.9906
trainer/Log Pis Mean                2.05234
trainer/Log Pis Std                 1.0954
trainer/Log Pis Max                 6.11022
trainer/Log Pis Min                -2.03187
trainer/Policy mu Mean              0.15167
trainer/Policy mu Std               0.803644
trainer/Policy mu Max               2.98163
trainer/Policy mu Min              -2.95914
trainer/Policy log std Mean        -2.05019
trainer/Policy log std Std          0.53671
trainer/Policy log std Max         -0.323811
trainer/Policy log std Min         -2.48927
trainer/Alpha                       0.0582134
trainer/Alpha Loss                  0.148842
exploration/num steps total     97200
exploration/num paths total       972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370141
exploration/Rewards Std             1.1473
exploration/Rewards Max            -0.00618195
exploration/Rewards Min           -10.0171
exploration/Returns Mean          -37.0141
exploration/Returns Std            18.8517
exploration/Returns Max           -15.1866
exploration/Returns Min           -68.0431
exploration/Actions Mean           -0.0155166
exploration/Actions Std             0.243796
exploration/Actions Max             0.996913
exploration/Actions Min            -0.999246
exploration/Num Paths               5
exploration/Average Returns       -37.0141
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.193516
evaluation/Rewards Std              0.82496
evaluation/Rewards Max             -0.0155704
evaluation/Rewards Min             -8.91399
evaluation/Returns Mean           -19.3516
evaluation/Returns Std             12.9118
evaluation/Returns Max             -3.98957
evaluation/Returns Min            -49.2642
evaluation/Actions Mean            -0.0126324
evaluation/Actions Std              0.187147
evaluation/Actions Max              0.995728
evaluation/Actions Min             -0.996698
evaluation/Num Paths               15
evaluation/Average Returns        -19.3516
time/data storing (s)               0.00306996
time/evaluation sampling (s)        0.386678
time/exploration sampling (s)       0.164048
time/logging (s)                    0.0044231
time/saving (s)                     0.0488815
time/training (s)                   2.13303
time/epoch (s)                      2.74013
time/total (s)                    525.841
Epoch                             193
-----------------------------  ---------------
2019-04-22 22:04:46.410297 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              97700
trainer/QF1 Loss                    0.0665546
trainer/QF2 Loss                    0.0644616
trainer/Policy Loss                11.2095
trainer/Q1 Predictions Mean        -9.67355
trainer/Q1 Predictions Std          6.37363
trainer/Q1 Predictions Max         -6.17721
trainer/Q1 Predictions Min        -64.4535
trainer/Q2 Predictions Mean        -9.65257
trainer/Q2 Predictions Std          6.29575
trainer/Q2 Predictions Max         -6.18477
trainer/Q2 Predictions Min        -63.7202
trainer/Q Targets Mean             -9.79086
trainer/Q Targets Std               6.37031
trainer/Q Targets Max              -6.33643
trainer/Q Targets Min             -64.858
trainer/Log Pis Mean                1.69975
trainer/Log Pis Std                 1.54824
trainer/Log Pis Max                 7.47443
trainer/Log Pis Min                -6.28121
trainer/Policy mu Mean              0.0425164
trainer/Policy mu Std               0.647043
trainer/Policy mu Max               3.25901
trainer/Policy mu Min              -2.95364
trainer/Policy log std Mean        -2.1318
trainer/Policy log std Std          0.417372
trainer/Policy log std Max         -0.518962
trainer/Policy log std Min         -2.46845
trainer/Alpha                       0.0588186
trainer/Alpha Loss                 -0.850691
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.275747
exploration/Rewards Std             0.767742
exploration/Rewards Max            -0.0179122
exploration/Rewards Min            -8.18531
exploration/Returns Mean          -27.5747
exploration/Returns Std            10.6293
exploration/Returns Max           -14.9575
exploration/Returns Min           -44.7585
exploration/Actions Mean            0.00542983
exploration/Actions Std             0.225045
exploration/Actions Max             0.998
exploration/Actions Min            -0.994737
exploration/Num Paths               5
exploration/Average Returns       -27.5747
evaluation/num steps total     292500
evaluation/num paths total       2925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.249387
evaluation/Rewards Std              0.854946
evaluation/Rewards Max             -0.00485861
evaluation/Rewards Min             -8.96016
evaluation/Returns Mean           -24.9387
evaluation/Returns Std             15.9324
evaluation/Returns Max             -4.80651
evaluation/Returns Min            -52.1958
evaluation/Actions Mean             0.0124118
evaluation/Actions Std              0.180495
evaluation/Actions Max              0.99814
evaluation/Actions Min             -0.997496
evaluation/Num Paths               15
evaluation/Average Returns        -24.9387
time/data storing (s)               0.00352336
time/evaluation sampling (s)        0.341346
time/exploration sampling (s)       0.159686
time/logging (s)                    0.00461588
time/saving (s)                     0.00198422
time/training (s)                   2.11812
time/epoch (s)                      2.62928
time/total (s)                    528.475
Epoch                             194
-----------------------------  ---------------
2019-04-22 22:04:49.129913 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              98200
trainer/QF1 Loss                    1.75154
trainer/QF2 Loss                    1.76093
trainer/Policy Loss                11.7037
trainer/Q1 Predictions Mean        -9.76265
trainer/Q1 Predictions Std          5.39613
trainer/Q1 Predictions Max         -6.25386
trainer/Q1 Predictions Min        -45.188
trainer/Q2 Predictions Mean        -9.74191
trainer/Q2 Predictions Std          5.36808
trainer/Q2 Predictions Max         -6.24659
trainer/Q2 Predictions Min        -45.2984
trainer/Q Targets Mean             -9.64794
trainer/Q Targets Std               5.49968
trainer/Q Targets Max              -0.165882
trainer/Q Targets Min             -44.9577
trainer/Log Pis Mean                2.07101
trainer/Log Pis Std                 1.12306
trainer/Log Pis Max                 6.10177
trainer/Log Pis Min                -1.3261
trainer/Policy mu Mean              0.0957995
trainer/Policy mu Std               0.72891
trainer/Policy mu Max               3.29895
trainer/Policy mu Min              -2.79374
trainer/Policy log std Mean        -2.1244
trainer/Policy log std Std          0.469179
trainer/Policy log std Max         -0.497402
trainer/Policy log std Min         -2.51079
trainer/Alpha                       0.0566583
trainer/Alpha Loss                  0.203874
exploration/num steps total     98200
exploration/num paths total       982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.401525
exploration/Rewards Std             1.08003
exploration/Rewards Max            -0.00182458
exploration/Rewards Min            -9.34135
exploration/Returns Mean          -40.1525
exploration/Returns Std            10.6014
exploration/Returns Max           -28.036
exploration/Returns Min           -58.6794
exploration/Actions Mean           -0.0179129
exploration/Actions Std             0.245984
exploration/Actions Max             0.992493
exploration/Actions Min            -0.998807
exploration/Num Paths               5
exploration/Average Returns       -40.1525
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.303354
evaluation/Rewards Std              1.0504
evaluation/Rewards Max             -0.0213072
evaluation/Rewards Min            -10.4501
evaluation/Returns Mean           -30.3354
evaluation/Returns Std             14.1804
evaluation/Returns Max            -14.6274
evaluation/Returns Min            -61.2286
evaluation/Actions Mean            -0.00838215
evaluation/Actions Std              0.203694
evaluation/Actions Max              0.997603
evaluation/Actions Min             -0.997369
evaluation/Num Paths               15
evaluation/Average Returns        -30.3354
time/data storing (s)               0.00384996
time/evaluation sampling (s)        0.36114
time/exploration sampling (s)       0.165332
time/logging (s)                    0.00482953
time/saving (s)                     0.00215547
time/training (s)                   2.17519
time/epoch (s)                      2.71249
time/total (s)                    531.192
Epoch                             195
-----------------------------  ---------------
2019-04-22 22:04:51.775595 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              98700
trainer/QF1 Loss                    1.89173
trainer/QF2 Loss                    1.88876
trainer/Policy Loss                11.3182
trainer/Q1 Predictions Mean        -9.68032
trainer/Q1 Predictions Std          4.56646
trainer/Q1 Predictions Max         -6.3972
trainer/Q1 Predictions Min        -45.8351
trainer/Q2 Predictions Mean        -9.64241
trainer/Q2 Predictions Std          4.53224
trainer/Q2 Predictions Max         -6.39576
trainer/Q2 Predictions Min        -45.1191
trainer/Q Targets Mean             -9.52384
trainer/Q Targets Std               4.78059
trainer/Q Targets Max              -0.264946
trainer/Q Targets Min             -45.6812
trainer/Log Pis Mean                1.87165
trainer/Log Pis Std                 1.13593
trainer/Log Pis Max                 6.24527
trainer/Log Pis Min                -1.64718
trainer/Policy mu Mean              0.0278275
trainer/Policy mu Std               0.664957
trainer/Policy mu Max               2.59476
trainer/Policy mu Min              -3.05069
trainer/Policy log std Mean        -2.03256
trainer/Policy log std Std          0.471787
trainer/Policy log std Max         -0.420699
trainer/Policy log std Min         -2.51778
trainer/Alpha                       0.0597234
trainer/Alpha Loss                 -0.361683
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33906
exploration/Rewards Std             0.871893
exploration/Rewards Max            -0.0096248
exploration/Rewards Min            -9.65655
exploration/Returns Mean          -33.906
exploration/Returns Std            12.6143
exploration/Returns Max           -21.8009
exploration/Returns Min           -57.025
exploration/Actions Mean           -0.0161113
exploration/Actions Std             0.237218
exploration/Actions Max             0.999133
exploration/Actions Min            -0.999569
exploration/Num Paths               5
exploration/Average Returns       -33.906
evaluation/num steps total     295500
evaluation/num paths total       2955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.295311
evaluation/Rewards Std              1.00908
evaluation/Rewards Max             -0.0112026
evaluation/Rewards Min            -10.9976
evaluation/Returns Mean           -29.5311
evaluation/Returns Std             15.3873
evaluation/Returns Max            -14.0055
evaluation/Returns Min            -61.0707
evaluation/Actions Mean             0.0021792
evaluation/Actions Std              0.196505
evaluation/Actions Max              0.997014
evaluation/Actions Min             -0.997678
evaluation/Num Paths               15
evaluation/Average Returns        -29.5311
time/data storing (s)               0.00352694
time/evaluation sampling (s)        0.353296
time/exploration sampling (s)       0.157993
time/logging (s)                    0.00485938
time/saving (s)                     0.00206508
time/training (s)                   2.11654
time/epoch (s)                      2.63828
time/total (s)                    533.834
Epoch                             196
-----------------------------  ---------------
2019-04-22 22:04:54.498327 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 197 finished
-----------------------------  ----------------
replay_buffer/size              99200
trainer/QF1 Loss                    0.641021
trainer/QF2 Loss                    0.633704
trainer/Policy Loss                10.8975
trainer/Q1 Predictions Mean        -9.1445
trainer/Q1 Predictions Std          4.35246
trainer/Q1 Predictions Max         -6.15531
trainer/Q1 Predictions Min        -34.6267
trainer/Q2 Predictions Mean        -9.15499
trainer/Q2 Predictions Std          4.39758
trainer/Q2 Predictions Max         -6.14858
trainer/Q2 Predictions Min        -34.8632
trainer/Q Targets Mean             -9.20806
trainer/Q Targets Std               4.41055
trainer/Q Targets Max              -0.264946
trainer/Q Targets Min             -33.4592
trainer/Log Pis Mean                2.07372
trainer/Log Pis Std                 1.25751
trainer/Log Pis Max                 5.5985
trainer/Log Pis Min                -2.88255
trainer/Policy mu Mean              0.117977
trainer/Policy mu Std               0.719572
trainer/Policy mu Max               2.80546
trainer/Policy mu Min              -2.87523
trainer/Policy log std Mean        -2.10101
trainer/Policy log std Std          0.489459
trainer/Policy log std Max         -0.543022
trainer/Policy log std Min         -2.52952
trainer/Alpha                       0.0591007
trainer/Alpha Loss                  0.208523
exploration/num steps total     99200
exploration/num paths total       992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.281019
exploration/Rewards Std             0.930681
exploration/Rewards Max            -0.0064759
exploration/Rewards Min           -10.4311
exploration/Returns Mean          -28.1019
exploration/Returns Std            17.016
exploration/Returns Max           -11.4311
exploration/Returns Min           -60.5395
exploration/Actions Mean            0.0150066
exploration/Actions Std             0.216248
exploration/Actions Max             0.997921
exploration/Actions Min            -0.99931
exploration/Num Paths               5
exploration/Average Returns       -28.1019
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.308838
evaluation/Rewards Std              1.14709
evaluation/Rewards Max             -0.0296696
evaluation/Rewards Min            -10.3086
evaluation/Returns Mean           -30.8838
evaluation/Returns Std             16.2211
evaluation/Returns Max            -10.1479
evaluation/Returns Min            -64.494
evaluation/Actions Mean             0.000163977
evaluation/Actions Std              0.212455
evaluation/Actions Max              0.99711
evaluation/Actions Min             -0.997962
evaluation/Num Paths               15
evaluation/Average Returns        -30.8838
time/data storing (s)               0.0039488
time/evaluation sampling (s)        0.361198
time/exploration sampling (s)       0.162191
time/logging (s)                    0.00477018
time/saving (s)                     0.00226235
time/training (s)                   2.17991
time/epoch (s)                      2.71428
time/total (s)                    536.554
Epoch                             197
-----------------------------  ----------------
2019-04-22 22:04:57.181144 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 198 finished
-----------------------------  ---------------
replay_buffer/size              99700
trainer/QF1 Loss                    0.0422803
trainer/QF2 Loss                    0.0480893
trainer/Policy Loss                10.7937
trainer/Q1 Predictions Mean        -9.12198
trainer/Q1 Predictions Std          6.09104
trainer/Q1 Predictions Max         -6.16197
trainer/Q1 Predictions Min        -54.3621
trainer/Q2 Predictions Mean        -9.13715
trainer/Q2 Predictions Std          6.10905
trainer/Q2 Predictions Max         -6.16966
trainer/Q2 Predictions Min        -54.3106
trainer/Q Targets Mean             -9.2328
trainer/Q Targets Std               5.97367
trainer/Q Targets Max              -6.24101
trainer/Q Targets Min             -53.8853
trainer/Log Pis Mean                1.82826
trainer/Log Pis Std                 1.35184
trainer/Log Pis Max                 8.11139
trainer/Log Pis Min                -3.03335
trainer/Policy mu Mean              0.0831352
trainer/Policy mu Std               0.613117
trainer/Policy mu Max               3.20348
trainer/Policy mu Min              -2.19924
trainer/Policy log std Mean        -2.08027
trainer/Policy log std Std          0.432559
trainer/Policy log std Max         -0.516263
trainer/Policy log std Min         -2.53057
trainer/Alpha                       0.0592448
trainer/Alpha Loss                 -0.485319
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.451291
exploration/Rewards Std             1.31495
exploration/Rewards Max            -0.00851042
exploration/Rewards Min           -10.0278
exploration/Returns Mean          -45.1291
exploration/Returns Std            18.0958
exploration/Returns Max           -19.2099
exploration/Returns Min           -64.6525
exploration/Actions Mean            0.0370533
exploration/Actions Std             0.265092
exploration/Actions Max             0.99856
exploration/Actions Min            -0.988519
exploration/Num Paths               5
exploration/Average Returns       -45.1291
evaluation/num steps total     298500
evaluation/num paths total       2985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.310282
evaluation/Rewards Std              1.14681
evaluation/Rewards Max             -0.0342154
evaluation/Rewards Min            -10.1629
evaluation/Returns Mean           -31.0282
evaluation/Returns Std             17.2984
evaluation/Returns Max            -10.2132
evaluation/Returns Min            -63.2552
evaluation/Actions Mean            -0.0067485
evaluation/Actions Std              0.206848
evaluation/Actions Max              0.997734
evaluation/Actions Min             -0.9986
evaluation/Num Paths               15
evaluation/Average Returns        -31.0282
time/data storing (s)               0.00313516
time/evaluation sampling (s)        0.357811
time/exploration sampling (s)       0.165691
time/logging (s)                    0.00475191
time/saving (s)                     0.0020147
time/training (s)                   2.14147
time/epoch (s)                      2.67487
time/total (s)                    539.233
Epoch                             198
-----------------------------  ---------------
2019-04-22 22:04:59.874611 PDT | [sac-pointmass-multitask-4_2019_04_22_21_55_57_0000--s-0] Epoch 199 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.18924
trainer/QF2 Loss                    1.20059
trainer/Policy Loss                10.6553
trainer/Q1 Predictions Mean        -9.10638
trainer/Q1 Predictions Std          3.83837
trainer/Q1 Predictions Max         -6.36082
trainer/Q1 Predictions Min        -35.2826
trainer/Q2 Predictions Mean        -9.10293
trainer/Q2 Predictions Std          3.86709
trainer/Q2 Predictions Max         -6.31054
trainer/Q2 Predictions Min        -35.9322
trainer/Q Targets Mean             -9.06795
trainer/Q Targets Std               3.89214
trainer/Q Targets Max              -1.06026
trainer/Q Targets Min             -34.3658
trainer/Log Pis Mean                1.88415
trainer/Log Pis Std                 1.12469
trainer/Log Pis Max                 4.7982
trainer/Log Pis Min                -2.14366
trainer/Policy mu Mean              0.116303
trainer/Policy mu Std               0.583687
trainer/Policy mu Max               2.82374
trainer/Policy mu Min              -2.90167
trainer/Policy log std Mean        -2.13142
trainer/Policy log std Std          0.419521
trainer/Policy log std Max         -0.653183
trainer/Policy log std Min         -2.58089
trainer/Alpha                       0.0575818
trainer/Alpha Loss                 -0.330685
exploration/num steps total    100200
exploration/num paths total      1002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.354517
exploration/Rewards Std             1.01888
exploration/Rewards Max            -0.00109133
exploration/Rewards Min            -8.38695
exploration/Returns Mean          -35.4517
exploration/Returns Std            13.4873
exploration/Returns Max           -18.1019
exploration/Returns Min           -52.9517
exploration/Actions Mean            0.0224342
exploration/Actions Std             0.239963
exploration/Actions Max             0.998013
exploration/Actions Min            -0.999756
exploration/Num Paths               5
exploration/Average Returns       -35.4517
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.159696
evaluation/Rewards Std              0.717357
evaluation/Rewards Max             -0.00686961
evaluation/Rewards Min            -11.0547
evaluation/Returns Mean           -15.9696
evaluation/Returns Std             14.6367
evaluation/Returns Max             -3.66835
evaluation/Returns Min            -61.0317
evaluation/Actions Mean            -0.000168165
evaluation/Actions Std              0.159507
evaluation/Actions Max              0.998174
evaluation/Actions Min             -0.999167
evaluation/Num Paths               15
evaluation/Average Returns        -15.9696
time/data storing (s)               0.00317697
time/evaluation sampling (s)        0.35252
time/exploration sampling (s)       0.16028
time/logging (s)                    0.00428716
time/saving (s)                     0.00198751
time/training (s)                   2.16238
time/epoch (s)                      2.68463
time/total (s)                    541.922
Epoch                             199
-----------------------------  ----------------
