2019-04-22 23:53:21.646605 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  52.3542
trainer/QF2 Loss                  52.3238
trainer/Policy Loss               -1.32172
trainer/Q1 Predictions Mean        0.0038845
trainer/Q1 Predictions Std         0.00141069
trainer/Q1 Predictions Max         0.00614362
trainer/Q1 Predictions Min         0.000544338
trainer/Q2 Predictions Mean        0.00169606
trainer/Q2 Predictions Std         0.000742562
trainer/Q2 Predictions Max         0.00299086
trainer/Q2 Predictions Min        -9.2797e-06
trainer/Q Targets Mean            -6.86949
trainer/Q Targets Std              2.26072
trainer/Q Targets Max             -1.66057
trainer/Q Targets Min            -11.3866
trainer/Log Pis Mean              -1.32007
trainer/Log Pis Std                0.345209
trainer/Log Pis Max               -0.558479
trainer/Log Pis Min               -1.96935
trainer/Policy mu Mean             7.39756e-05
trainer/Policy mu Std              0.000668209
trainer/Policy mu Max              0.00170246
trainer/Policy mu Min             -0.000924166
trainer/Policy log std Mean        9.40288e-05
trainer/Policy log std Std         0.00115777
trainer/Policy log std Max         0.00185841
trainer/Policy log std Min        -0.00151962
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -7.02503
exploration/Rewards Std            1.97624
exploration/Rewards Max           -1.69432
exploration/Rewards Min          -11.7446
exploration/Returns Mean        -702.503
exploration/Returns Std          123.242
exploration/Returns Max         -514.319
exploration/Returns Min         -867.39
exploration/Actions Mean          -0.00300537
exploration/Actions Std            0.633267
exploration/Actions Max            0.999832
exploration/Actions Min           -0.994915
exploration/Num Paths              5
exploration/Average Returns     -702.503
evaluation/num steps total      1500
evaluation/num paths total        15
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -8.24476
evaluation/Rewards Std             2.61672
evaluation/Rewards Max            -1.21339
evaluation/Rewards Min           -12.4635
evaluation/Returns Mean         -824.476
evaluation/Returns Std           261.667
evaluation/Returns Max          -122.847
evaluation/Returns Min         -1245.05
evaluation/Actions Mean            1.48939e-05
evaluation/Actions Std             0.000764189
evaluation/Actions Max             0.00180508
evaluation/Actions Min            -0.00108046
evaluation/Num Paths              15
evaluation/Average Returns      -824.476
time/data storing (s)              0.00287353
time/evaluation sampling (s)       0.290655
time/exploration sampling (s)      0.137451
time/logging (s)                   0.00498267
time/saving (s)                    0.0023415
time/training (s)                  1.92964
time/epoch (s)                     2.36794
time/total (s)                     2.56199
Epoch                              0
-----------------------------  ---------------
2019-04-22 23:53:24.149132 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size             1200
trainer/QF1 Loss                  4.21891
trainer/QF2 Loss                  4.04654
trainer/Policy Loss              10.836
trainer/Q1 Predictions Mean     -12.1604
trainer/Q1 Predictions Std        2.8697
trainer/Q1 Predictions Max       -7.38114
trainer/Q1 Predictions Min      -20.3534
trainer/Q2 Predictions Mean     -12.2205
trainer/Q2 Predictions Std        2.84578
trainer/Q2 Predictions Max       -7.36867
trainer/Q2 Predictions Min      -20.4926
trainer/Q Targets Mean          -12.6687
trainer/Q Targets Std             3.28316
trainer/Q Targets Max            -4.96774
trainer/Q Targets Min           -20.4111
trainer/Log Pis Mean             -1.29946
trainer/Log Pis Std               0.439737
trainer/Log Pis Max              -0.237733
trainer/Log Pis Min              -2.57951
trainer/Policy mu Mean            0.145315
trainer/Policy mu Std             0.218881
trainer/Policy mu Max             0.842984
trainer/Policy mu Min            -0.263247
trainer/Policy log std Mean      -0.182209
trainer/Policy log std Std        0.0382625
trainer/Policy log std Max       -0.133875
trainer/Policy log std Min       -0.350634
trainer/Alpha                     0.861153
trainer/Alpha Loss               -0.492253
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -5.44401
exploration/Rewards Std           2.06324
exploration/Rewards Max          -0.666212
exploration/Rewards Min         -12.2074
exploration/Returns Mean       -544.401
exploration/Returns Std         136.244
exploration/Returns Max        -358.164
exploration/Returns Min        -745.575
exploration/Actions Mean          0.018778
exploration/Actions Std           0.585881
exploration/Actions Max           0.982889
exploration/Actions Min          -0.985394
exploration/Num Paths             5
exploration/Average Returns    -544.401
evaluation/num steps total     3000
evaluation/num paths total       30
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -5.24452
evaluation/Rewards Std            1.52835
evaluation/Rewards Max           -1.97356
evaluation/Rewards Min          -12.2078
evaluation/Returns Mean        -524.452
evaluation/Returns Std          128.268
evaluation/Returns Max         -303.716
evaluation/Returns Min         -786.834
evaluation/Actions Mean           0.0192362
evaluation/Actions Std            0.0792042
evaluation/Actions Max            0.58276
evaluation/Actions Min           -0.231619
evaluation/Num Paths             15
evaluation/Average Returns     -524.452
time/data storing (s)             0.00305824
time/evaluation sampling (s)      0.322987
time/exploration sampling (s)     0.139622
time/logging (s)                  0.00475466
time/saving (s)                   0.00194915
time/training (s)                 2.02429
time/epoch (s)                    2.49666
time/total (s)                    5.06347
Epoch                             1
-----------------------------  -------------
2019-04-22 23:53:26.885119 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 2 finished
-----------------------------  --------------
replay_buffer/size             1700
trainer/QF1 Loss                  1.13422
trainer/QF2 Loss                  0.921061
trainer/Policy Loss              20.9325
trainer/Q1 Predictions Mean     -22.4699
trainer/Q1 Predictions Std        5.56772
trainer/Q1 Predictions Max      -14.4774
trainer/Q1 Predictions Min      -37.2907
trainer/Q2 Predictions Mean     -22.5332
trainer/Q2 Predictions Std        5.4917
trainer/Q2 Predictions Max      -14.4436
trainer/Q2 Predictions Min      -37.3106
trainer/Q Targets Mean          -22.5447
trainer/Q Targets Std             5.73293
trainer/Q Targets Max           -14.1636
trainer/Q Targets Min           -37.6311
trainer/Log Pis Mean             -0.841921
trainer/Log Pis Std               1.07066
trainer/Log Pis Max               1.4069
trainer/Log Pis Min              -5.65515
trainer/Policy mu Mean            0.0652985
trainer/Policy mu Std             0.598511
trainer/Policy mu Max             1.29985
trainer/Policy mu Min            -1.16189
trainer/Policy log std Mean      -0.34128
trainer/Policy log std Std        0.063032
trainer/Policy log std Max       -0.209584
trainer/Policy log std Min       -0.489031
trainer/Alpha                     0.749673
trainer/Alpha Loss               -0.818078
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.21504
exploration/Rewards Std           1.19664
exploration/Rewards Max          -1.42492
exploration/Rewards Min          -9.49324
exploration/Returns Mean       -421.504
exploration/Returns Std          83.0362
exploration/Returns Max        -341.176
exploration/Returns Min        -580.452
exploration/Actions Mean          0.00828746
exploration/Actions Std           0.5596
exploration/Actions Max           0.988251
exploration/Actions Min          -0.990284
exploration/Num Paths             5
exploration/Average Returns    -421.504
evaluation/num steps total     4500
evaluation/num paths total       45
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -4.16723
evaluation/Rewards Std            1.01421
evaluation/Rewards Max           -1.6019
evaluation/Rewards Min          -11.1666
evaluation/Returns Mean        -416.723
evaluation/Returns Std           80.9993
evaluation/Returns Max         -307.482
evaluation/Returns Min         -566.285
evaluation/Actions Mean           0.000671511
evaluation/Actions Std            0.0968299
evaluation/Actions Max            0.753968
evaluation/Actions Min           -0.694036
evaluation/Num Paths             15
evaluation/Average Returns     -416.723
time/data storing (s)             0.00299961
time/evaluation sampling (s)      0.342991
time/exploration sampling (s)     0.152375
time/logging (s)                  0.00486866
time/saving (s)                   0.00198365
time/training (s)                 2.22592
time/epoch (s)                    2.73113
time/total (s)                    7.79882
Epoch                             2
-----------------------------  --------------
2019-04-22 23:53:29.511604 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 3 finished
-----------------------------  -------------
replay_buffer/size             2200
trainer/QF1 Loss                 23.0509
trainer/QF2 Loss                 23.5262
trainer/Policy Loss              27.8606
trainer/Q1 Predictions Mean     -29.9134
trainer/Q1 Predictions Std        6.33067
trainer/Q1 Predictions Max      -18.6834
trainer/Q1 Predictions Min      -51.1266
trainer/Q2 Predictions Mean     -29.8591
trainer/Q2 Predictions Std        6.39372
trainer/Q2 Predictions Max      -18.4998
trainer/Q2 Predictions Min      -51.2328
trainer/Q Targets Mean          -29.5174
trainer/Q Targets Std             7.3749
trainer/Q Targets Max            -2.62658
trainer/Q Targets Min           -52.4838
trainer/Log Pis Mean             -0.655258
trainer/Log Pis Std               1.0463
trainer/Log Pis Max               1.21126
trainer/Log Pis Min              -3.73765
trainer/Policy mu Mean            0.0728375
trainer/Policy mu Std             0.676364
trainer/Policy mu Max             1.62913
trainer/Policy mu Min            -1.50455
trainer/Policy log std Mean      -0.400939
trainer/Policy log std Std        0.0759976
trainer/Policy log std Max       -0.271472
trainer/Policy log std Min       -0.60894
trainer/Alpha                     0.656986
trainer/Alpha Loss               -1.11477
exploration/num steps total    2200
exploration/num paths total      22
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -4.60129
exploration/Rewards Std           1.41345
exploration/Rewards Max          -0.739777
exploration/Rewards Min         -10.5959
exploration/Returns Mean       -460.129
exploration/Returns Std          97.7741
exploration/Returns Max        -271.676
exploration/Returns Min        -542.531
exploration/Actions Mean          0.00143227
exploration/Actions Std           0.556275
exploration/Actions Max           0.96924
exploration/Actions Min          -0.989157
exploration/Num Paths             5
exploration/Average Returns    -460.129
evaluation/num steps total     6000
evaluation/num paths total       60
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.85822
evaluation/Rewards Std            1.60098
evaluation/Rewards Max           -1.48836
evaluation/Rewards Min          -11.0754
evaluation/Returns Mean        -385.822
evaluation/Returns Std          145.742
evaluation/Returns Max         -197.751
evaluation/Returns Min         -574.106
evaluation/Actions Mean           0.00785079
evaluation/Actions Std            0.13602
evaluation/Actions Max            0.916659
evaluation/Actions Min           -0.945418
evaluation/Num Paths             15
evaluation/Average Returns     -385.822
time/data storing (s)             0.00288059
time/evaluation sampling (s)      0.40714
time/exploration sampling (s)     0.145424
time/logging (s)                  0.00513851
time/saving (s)                   0.00196947
time/training (s)                 2.0592
time/epoch (s)                    2.62175
time/total (s)                   10.4248
Epoch                             3
-----------------------------  -------------
2019-04-22 23:53:32.338112 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 4 finished
-----------------------------  -------------
replay_buffer/size             2700
trainer/QF1 Loss                  2.13022
trainer/QF2 Loss                  3.59213
trainer/Policy Loss              34.6025
trainer/Q1 Predictions Mean     -36.051
trainer/Q1 Predictions Std       10.2906
trainer/Q1 Predictions Max      -22.7024
trainer/Q1 Predictions Min      -68.3781
trainer/Q2 Predictions Mean     -35.7528
trainer/Q2 Predictions Std       10.4803
trainer/Q2 Predictions Max      -22.8479
trainer/Q2 Predictions Min      -68.7033
trainer/Q Targets Mean          -36.789
trainer/Q Targets Std            10.1232
trainer/Q Targets Max           -22.4571
trainer/Q Targets Min           -70.7218
trainer/Log Pis Mean             -0.435235
trainer/Log Pis Std               1.3592
trainer/Log Pis Max               2.68239
trainer/Log Pis Min              -4.80897
trainer/Policy mu Mean            0.0571727
trainer/Policy mu Std             0.737672
trainer/Policy mu Max             1.72596
trainer/Policy mu Min            -1.70163
trainer/Policy log std Mean      -0.466849
trainer/Policy log std Std        0.0797076
trainer/Policy log std Max       -0.298386
trainer/Policy log std Min       -0.602028
trainer/Alpha                     0.574972
trainer/Alpha Loss               -1.3471
exploration/num steps total    2700
exploration/num paths total      27
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.75015
exploration/Rewards Std           1.45281
exploration/Rewards Max          -0.355311
exploration/Rewards Min          -7.13524
exploration/Returns Mean       -375.015
exploration/Returns Std         122.805
exploration/Returns Max        -188.637
exploration/Returns Min        -494.697
exploration/Actions Mean         -0.0129138
exploration/Actions Std           0.529015
exploration/Actions Max           0.984001
exploration/Actions Min          -0.981983
exploration/Num Paths             5
exploration/Average Returns    -375.015
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.69399
evaluation/Rewards Std            1.44198
evaluation/Rewards Max           -1.84639
evaluation/Rewards Min          -10.6976
evaluation/Returns Mean        -369.399
evaluation/Returns Std          130.38
evaluation/Returns Max         -203.673
evaluation/Returns Min         -577.919
evaluation/Actions Mean          -0.00290905
evaluation/Actions Std            0.141641
evaluation/Actions Max            0.908609
evaluation/Actions Min           -0.960892
evaluation/Num Paths             15
evaluation/Average Returns     -369.399
time/data storing (s)             0.00308426
time/evaluation sampling (s)      0.410098
time/exploration sampling (s)     0.191842
time/logging (s)                  0.00348457
time/saving (s)                   0.00186304
time/training (s)                 2.20927
time/epoch (s)                    2.81964
time/total (s)                   13.2488
Epoch                             4
-----------------------------  -------------
2019-04-22 23:53:34.968024 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 5 finished
-----------------------------  -------------
replay_buffer/size             3200
trainer/QF1 Loss                 36.6737
trainer/QF2 Loss                 36.9638
trainer/Policy Loss              41.401
trainer/Q1 Predictions Mean     -43.3867
trainer/Q1 Predictions Std       11.8694
trainer/Q1 Predictions Max      -25.6201
trainer/Q1 Predictions Min      -80.5739
trainer/Q2 Predictions Mean     -43.4574
trainer/Q2 Predictions Std       11.9069
trainer/Q2 Predictions Max      -25.6398
trainer/Q2 Predictions Min      -80.6255
trainer/Q Targets Mean          -42.9031
trainer/Q Targets Std            12.8843
trainer/Q Targets Max            -5.08767
trainer/Q Targets Min           -82.4657
trainer/Log Pis Mean             -0.370049
trainer/Log Pis Std               1.37559
trainer/Log Pis Max               3.42357
trainer/Log Pis Min              -4.37375
trainer/Policy mu Mean            0.152038
trainer/Policy mu Std             0.780279
trainer/Policy mu Max             1.88072
trainer/Policy mu Min            -1.58632
trainer/Policy log std Mean      -0.482629
trainer/Policy log std Std        0.0935907
trainer/Policy log std Max       -0.298706
trainer/Policy log std Min       -0.664871
trainer/Alpha                     0.50294
trainer/Alpha Loss               -1.62829
exploration/num steps total    3200
exploration/num paths total      32
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -2.75714
exploration/Rewards Std           1.60598
exploration/Rewards Max          -0.0490883
exploration/Rewards Min          -9.10842
exploration/Returns Mean       -275.714
exploration/Returns Std         123.357
exploration/Returns Max        -133.098
exploration/Returns Min        -472.672
exploration/Actions Mean          0.0200422
exploration/Actions Std           0.508048
exploration/Actions Max           0.99829
exploration/Actions Min          -0.972135
exploration/Num Paths             5
exploration/Average Returns    -275.714
evaluation/num steps total     9000
evaluation/num paths total       90
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -3.50994
evaluation/Rewards Std            1.6496
evaluation/Rewards Max           -0.735172
evaluation/Rewards Min          -10.6146
evaluation/Returns Mean        -350.994
evaluation/Returns Std          153.078
evaluation/Returns Max         -107.823
evaluation/Returns Min         -579.961
evaluation/Actions Mean          -0.00175274
evaluation/Actions Std            0.143085
evaluation/Actions Max            0.949217
evaluation/Actions Min           -0.930192
evaluation/Num Paths             15
evaluation/Average Returns     -350.994
time/data storing (s)             0.00281402
time/evaluation sampling (s)      0.3412
time/exploration sampling (s)     0.147891
time/logging (s)                  0.00442808
time/saving (s)                   0.00196832
time/training (s)                 2.12796
time/epoch (s)                    2.62627
time/total (s)                   15.8791
Epoch                             5
-----------------------------  -------------
2019-04-22 23:53:37.508936 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                  49.5565
trainer/QF2 Loss                  50.4525
trainer/Policy Loss               44.4078
trainer/Q1 Predictions Mean      -46.1842
trainer/Q1 Predictions Std        10.449
trainer/Q1 Predictions Max       -27.515
trainer/Q1 Predictions Min       -82.2264
trainer/Q2 Predictions Mean      -46.1338
trainer/Q2 Predictions Std        10.4774
trainer/Q2 Predictions Max       -27.5665
trainer/Q2 Predictions Min       -82.6155
trainer/Q Targets Mean           -45.63
trainer/Q Targets Std             11.6847
trainer/Q Targets Max             -4.89056
trainer/Q Targets Min            -83.1578
trainer/Log Pis Mean              -0.367936
trainer/Log Pis Std                1.20414
trainer/Log Pis Max                2.55516
trainer/Log Pis Min               -2.85692
trainer/Policy mu Mean             0.13955
trainer/Policy mu Std              0.77081
trainer/Policy mu Max              1.70813
trainer/Policy mu Min             -1.96189
trainer/Policy log std Mean       -0.527205
trainer/Policy log std Std         0.0940393
trainer/Policy log std Max        -0.305084
trainer/Policy log std Min        -0.700878
trainer/Alpha                      0.439773
trainer/Alpha Loss                -1.9446
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.53956
exploration/Rewards Std            1.78759
exploration/Rewards Max           -0.466592
exploration/Rewards Min           -9.91831
exploration/Returns Mean        -353.956
exploration/Returns Std          151.317
exploration/Returns Max         -177.429
exploration/Returns Min         -590.333
exploration/Actions Mean          -0.0176202
exploration/Actions Std            0.513696
exploration/Actions Max            0.978976
exploration/Actions Min           -0.984812
exploration/Num Paths              5
exploration/Average Returns     -353.956
evaluation/num steps total     10500
evaluation/num paths total       105
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -4.00441
evaluation/Rewards Std             1.57733
evaluation/Rewards Max            -0.125734
evaluation/Rewards Min            -9.35015
evaluation/Returns Mean         -400.441
evaluation/Returns Std           144.052
evaluation/Returns Max          -193.565
evaluation/Returns Min          -587.097
evaluation/Actions Mean            0.00495319
evaluation/Actions Std             0.158049
evaluation/Actions Max             0.949547
evaluation/Actions Min            -0.922632
evaluation/Num Paths              15
evaluation/Average Returns      -400.441
time/data storing (s)              0.00331366
time/evaluation sampling (s)       0.338064
time/exploration sampling (s)      0.145122
time/logging (s)                   0.00475242
time/saving (s)                    0.002013
time/training (s)                  2.04372
time/epoch (s)                     2.53698
time/total (s)                    18.4196
Epoch                              6
-----------------------------  --------------
2019-04-22 23:53:39.983103 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   1.37502
trainer/QF2 Loss                   1.72809
trainer/Policy Loss               50.7639
trainer/Q1 Predictions Mean      -52.0639
trainer/Q1 Predictions Std        14.5635
trainer/Q1 Predictions Max       -28.5994
trainer/Q1 Predictions Min       -91.0035
trainer/Q2 Predictions Mean      -51.9976
trainer/Q2 Predictions Std        14.6468
trainer/Q2 Predictions Max       -28.2326
trainer/Q2 Predictions Min       -90.7857
trainer/Q Targets Mean           -52.6101
trainer/Q Targets Std             14.7954
trainer/Q Targets Max            -27.9653
trainer/Q Targets Min            -91.8774
trainer/Log Pis Mean               0.105353
trainer/Log Pis Std                1.46732
trainer/Log Pis Max                3.90864
trainer/Log Pis Min               -4.54374
trainer/Policy mu Mean             0.0114187
trainer/Policy mu Std              0.886858
trainer/Policy mu Max              2.16407
trainer/Policy mu Min             -2.20398
trainer/Policy log std Mean       -0.592931
trainer/Policy log std Std         0.115732
trainer/Policy log std Max        -0.339085
trainer/Policy log std Min        -0.861431
trainer/Alpha                      0.384803
trainer/Alpha Loss                -1.80893
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.69623
exploration/Rewards Std            1.74129
exploration/Rewards Max           -0.611614
exploration/Rewards Min           -8.76659
exploration/Returns Mean        -369.623
exploration/Returns Std          164.47
exploration/Returns Max         -175.272
exploration/Returns Min         -597.068
exploration/Actions Mean          -0.0218956
exploration/Actions Std            0.501373
exploration/Actions Max            0.987931
exploration/Actions Min           -0.987394
exploration/Num Paths              5
exploration/Average Returns     -369.623
evaluation/num steps total     12000
evaluation/num paths total       120
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.0621
evaluation/Rewards Std             1.18437
evaluation/Rewards Max            -0.328375
evaluation/Rewards Min            -8.2229
evaluation/Returns Mean         -306.21
evaluation/Returns Std           110.769
evaluation/Returns Max          -163.022
evaluation/Returns Min          -525.03
evaluation/Actions Mean           -0.00107982
evaluation/Actions Std             0.135239
evaluation/Actions Max             0.912865
evaluation/Actions Min            -0.928833
evaluation/Num Paths              15
evaluation/Average Returns      -306.21
time/data storing (s)              0.00303051
time/evaluation sampling (s)       0.333509
time/exploration sampling (s)      0.156012
time/logging (s)                   0.00484684
time/saving (s)                    0.00194836
time/training (s)                  1.96981
time/epoch (s)                     2.46915
time/total (s)                    20.8931
Epoch                              7
-----------------------------  --------------
2019-04-22 23:53:42.484679 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                  25.1822
trainer/QF2 Loss                  25.2804
trainer/Policy Loss               56.0556
trainer/Q1 Predictions Mean      -57.2718
trainer/Q1 Predictions Std        13.1146
trainer/Q1 Predictions Max       -29.8791
trainer/Q1 Predictions Min       -91.8618
trainer/Q2 Predictions Mean      -57.2403
trainer/Q2 Predictions Std        13.1198
trainer/Q2 Predictions Max       -29.8374
trainer/Q2 Predictions Min       -91.8729
trainer/Q Targets Mean           -57.3754
trainer/Q Targets Std             14.1615
trainer/Q Targets Max             -6.1502
trainer/Q Targets Min            -91.9234
trainer/Log Pis Mean              -0.0609501
trainer/Log Pis Std                1.62034
trainer/Log Pis Max                5.53094
trainer/Log Pis Min               -3.47346
trainer/Policy mu Mean             0.192528
trainer/Policy mu Std              0.885239
trainer/Policy mu Max              2.3933
trainer/Policy mu Min             -1.79522
trainer/Policy log std Mean       -0.626521
trainer/Policy log std Std         0.102227
trainer/Policy log std Max        -0.377349
trainer/Policy log std Min        -0.913244
trainer/Alpha                      0.336691
trainer/Alpha Loss                -2.24299
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.11817
exploration/Rewards Std            1.58354
exploration/Rewards Max           -0.424908
exploration/Rewards Min          -12.1228
exploration/Returns Mean        -311.817
exploration/Returns Std          108.415
exploration/Returns Max         -175.292
exploration/Returns Min         -488.303
exploration/Actions Mean           0.0107155
exploration/Actions Std            0.487008
exploration/Actions Max            0.995319
exploration/Actions Min           -0.983135
exploration/Num Paths              5
exploration/Average Returns     -311.817
evaluation/num steps total     13500
evaluation/num paths total       135
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.14204
evaluation/Rewards Std             1.57876
evaluation/Rewards Max            -1.03625
evaluation/Rewards Min            -9.8623
evaluation/Returns Mean         -314.204
evaluation/Returns Std           145.814
evaluation/Returns Max          -106.526
evaluation/Returns Min          -583.306
evaluation/Actions Mean            0.00177102
evaluation/Actions Std             0.156265
evaluation/Actions Max             0.972405
evaluation/Actions Min            -0.965893
evaluation/Num Paths              15
evaluation/Average Returns      -314.204
time/data storing (s)              0.00319407
time/evaluation sampling (s)       0.329938
time/exploration sampling (s)      0.150596
time/logging (s)                   0.00534973
time/saving (s)                    0.0019864
time/training (s)                  2.00585
time/epoch (s)                     2.49691
time/total (s)                    23.3944
Epoch                              8
-----------------------------  --------------
2019-04-22 23:53:44.907813 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                  24.0569
trainer/QF2 Loss                  24.2577
trainer/Policy Loss               60.0546
trainer/Q1 Predictions Mean      -61.4564
trainer/Q1 Predictions Std        16.2321
trainer/Q1 Predictions Max       -29.111
trainer/Q1 Predictions Min      -110.278
trainer/Q2 Predictions Mean      -61.4523
trainer/Q2 Predictions Std        16.2862
trainer/Q2 Predictions Max       -28.6936
trainer/Q2 Predictions Min      -110.886
trainer/Q Targets Mean           -61.8645
trainer/Q Targets Std             17.4269
trainer/Q Targets Max             -2.82491
trainer/Q Targets Min           -113.071
trainer/Log Pis Mean               0.534085
trainer/Log Pis Std                1.54969
trainer/Log Pis Max                4.94961
trainer/Log Pis Min               -2.93929
trainer/Policy mu Mean             0.113659
trainer/Policy mu Std              0.97672
trainer/Policy mu Max              2.25745
trainer/Policy mu Min             -2.13991
trainer/Policy log std Mean       -0.668179
trainer/Policy log std Std         0.113314
trainer/Policy log std Max        -0.378045
trainer/Policy log std Min        -1.02019
trainer/Alpha                      0.295154
trainer/Alpha Loss                -1.78842
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.85504
exploration/Rewards Std            1.37517
exploration/Rewards Max           -0.976411
exploration/Rewards Min          -11.1214
exploration/Returns Mean        -385.504
exploration/Returns Std          108.632
exploration/Returns Max         -245.724
exploration/Returns Min         -566.632
exploration/Actions Mean           0.0151761
exploration/Actions Std            0.488044
exploration/Actions Max            0.984784
exploration/Actions Min           -0.957755
exploration/Num Paths              5
exploration/Average Returns     -385.504
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.47078
evaluation/Rewards Std             1.28015
evaluation/Rewards Max            -0.572029
evaluation/Rewards Min            -8.6223
evaluation/Returns Mean         -247.078
evaluation/Returns Std           123.219
evaluation/Returns Max          -128.638
evaluation/Returns Min          -547.449
evaluation/Actions Mean            0.0112394
evaluation/Actions Std             0.117053
evaluation/Actions Max             0.960334
evaluation/Actions Min            -0.90121
evaluation/Num Paths              15
evaluation/Average Returns      -247.078
time/data storing (s)              0.00318759
time/evaluation sampling (s)       0.337408
time/exploration sampling (s)      0.168143
time/logging (s)                   0.00456098
time/saving (s)                    0.00192443
time/training (s)                  1.9014
time/epoch (s)                     2.41662
time/total (s)                    25.8157
Epoch                              9
-----------------------------  --------------
2019-04-22 23:53:47.490068 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                   1.61416
trainer/QF2 Loss                   1.90669
trainer/Policy Loss               64.7682
trainer/Q1 Predictions Mean      -65.7351
trainer/Q1 Predictions Std        15.2318
trainer/Q1 Predictions Max       -31.1927
trainer/Q1 Predictions Min       -94.8244
trainer/Q2 Predictions Mean      -65.702
trainer/Q2 Predictions Std        15.1983
trainer/Q2 Predictions Max       -31.1728
trainer/Q2 Predictions Min       -94.8811
trainer/Q Targets Mean           -66.5439
trainer/Q Targets Std             15.6552
trainer/Q Targets Max            -30.5366
trainer/Q Targets Min            -94.8908
trainer/Log Pis Mean               0.353914
trainer/Log Pis Std                1.58568
trainer/Log Pis Max                4.874
trainer/Log Pis Min               -3.31685
trainer/Policy mu Mean             0.0130808
trainer/Policy mu Std              0.96111
trainer/Policy mu Max              2.14459
trainer/Policy mu Min             -1.97914
trainer/Policy log std Mean       -0.686569
trainer/Policy log std Std         0.126517
trainer/Policy log std Max        -0.458353
trainer/Policy log std Min        -0.99441
trainer/Alpha                      0.259085
trainer/Alpha Loss                -2.22279
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.05016
exploration/Rewards Std            1.18668
exploration/Rewards Max           -0.0711895
exploration/Rewards Min           -8.21098
exploration/Returns Mean        -205.016
exploration/Returns Std           93.1316
exploration/Returns Max         -117.445
exploration/Returns Min         -379.288
exploration/Actions Mean           0.0222319
exploration/Actions Std            0.433878
exploration/Actions Max            0.991096
exploration/Actions Min           -0.971776
exploration/Num Paths              5
exploration/Average Returns     -205.016
evaluation/num steps total     16500
evaluation/num paths total       165
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.26243
evaluation/Rewards Std             1.10315
evaluation/Rewards Max            -0.507195
evaluation/Rewards Min           -11.0556
evaluation/Returns Mean         -226.243
evaluation/Returns Std            88.7048
evaluation/Returns Max          -118.755
evaluation/Returns Min          -378.32
evaluation/Actions Mean            0.0189331
evaluation/Actions Std             0.155514
evaluation/Actions Max             0.968872
evaluation/Actions Min            -0.965446
evaluation/Num Paths              15
evaluation/Average Returns      -226.243
time/data storing (s)              0.0030893
time/evaluation sampling (s)       0.354724
time/exploration sampling (s)      0.149737
time/logging (s)                   0.0046957
time/saving (s)                    0.00198122
time/training (s)                  2.06308
time/epoch (s)                     2.5773
time/total (s)                    28.3972
Epoch                             10
-----------------------------  --------------
2019-04-22 23:53:49.960816 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                  54.2878
trainer/QF2 Loss                  54.3843
trainer/Policy Loss               70.7598
trainer/Q1 Predictions Mean      -71.6582
trainer/Q1 Predictions Std        15.6764
trainer/Q1 Predictions Max       -29.3447
trainer/Q1 Predictions Min      -100.451
trainer/Q2 Predictions Mean      -71.6971
trainer/Q2 Predictions Std        15.6022
trainer/Q2 Predictions Max       -29.5724
trainer/Q2 Predictions Min      -100.573
trainer/Q Targets Mean           -71.7808
trainer/Q Targets Std             17.2481
trainer/Q Targets Max             -3.56736
trainer/Q Targets Min           -101.122
trainer/Log Pis Mean               0.549226
trainer/Log Pis Std                1.58862
trainer/Log Pis Max                5.33336
trainer/Log Pis Min               -2.85281
trainer/Policy mu Mean             0.0686411
trainer/Policy mu Std              0.982413
trainer/Policy mu Max              2.21544
trainer/Policy mu Min             -2.03013
trainer/Policy log std Mean       -0.779514
trainer/Policy log std Std         0.165793
trainer/Policy log std Max        -0.443216
trainer/Policy log std Min        -1.19556
trainer/Alpha                      0.22858
trainer/Alpha Loss                -2.14078
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.14689
exploration/Rewards Std            1.44252
exploration/Rewards Max           -0.808524
exploration/Rewards Min          -11.4685
exploration/Returns Mean        -314.689
exploration/Returns Std          122.577
exploration/Returns Max         -174.582
exploration/Returns Min         -512.331
exploration/Actions Mean          -0.0050521
exploration/Actions Std            0.456047
exploration/Actions Max            0.97223
exploration/Actions Min           -0.995981
exploration/Num Paths              5
exploration/Average Returns     -314.689
evaluation/num steps total     18000
evaluation/num paths total       180
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.789
evaluation/Rewards Std             1.47062
evaluation/Rewards Max            -0.98871
evaluation/Rewards Min           -10.1292
evaluation/Returns Mean         -278.9
evaluation/Returns Std           134.925
evaluation/Returns Max          -117.12
evaluation/Returns Min          -541.115
evaluation/Actions Mean            0.00222735
evaluation/Actions Std             0.155873
evaluation/Actions Max             0.966839
evaluation/Actions Min            -0.979163
evaluation/Num Paths              15
evaluation/Average Returns      -278.9
time/data storing (s)              0.00278107
time/evaluation sampling (s)       0.320413
time/exploration sampling (s)      0.142336
time/logging (s)                   0.00478386
time/saving (s)                    0.00199415
time/training (s)                  1.99366
time/epoch (s)                     2.46597
time/total (s)                    30.8672
Epoch                             11
-----------------------------  --------------
2019-04-22 23:53:52.354853 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              6700
trainer/QF1 Loss                 118.038
trainer/QF2 Loss                 117.699
trainer/Policy Loss               68.6087
trainer/Q1 Predictions Mean      -69.7652
trainer/Q1 Predictions Std        21.2645
trainer/Q1 Predictions Max       -29.7664
trainer/Q1 Predictions Min      -123.625
trainer/Q2 Predictions Mean      -69.769
trainer/Q2 Predictions Std        21.2494
trainer/Q2 Predictions Max       -30.0898
trainer/Q2 Predictions Min      -122.669
trainer/Q Targets Mean           -69.1167
trainer/Q Targets Std             24.4856
trainer/Q Targets Max             -1.2278
trainer/Q Targets Min           -124.63
trainer/Log Pis Mean               0.558321
trainer/Log Pis Std                1.86118
trainer/Log Pis Max                5.95608
trainer/Log Pis Min               -7.23935
trainer/Policy mu Mean             0.138816
trainer/Policy mu Std              1.01628
trainer/Policy mu Max              2.51007
trainer/Policy mu Min             -2.18514
trainer/Policy log std Mean       -0.845819
trainer/Policy log std Std         0.210679
trainer/Policy log std Max        -0.41559
trainer/Policy log std Min        -1.29011
trainer/Alpha                      0.201343
trainer/Alpha Loss                -2.31027
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.36345
exploration/Rewards Std            2.0151
exploration/Rewards Max           -0.47632
exploration/Rewards Min           -9.12704
exploration/Returns Mean        -336.345
exploration/Returns Std          185.872
exploration/Returns Max         -121.788
exploration/Returns Min         -561.831
exploration/Actions Mean           0.0149723
exploration/Actions Std            0.399641
exploration/Actions Max            0.99173
exploration/Actions Min           -0.982909
exploration/Num Paths              5
exploration/Average Returns     -336.345
evaluation/num steps total     19500
evaluation/num paths total       195
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.39358
evaluation/Rewards Std             1.75867
evaluation/Rewards Max            -0.928559
evaluation/Rewards Min           -10.4985
evaluation/Returns Mean         -339.358
evaluation/Returns Std           165.705
evaluation/Returns Max          -102.839
evaluation/Returns Min          -557.847
evaluation/Actions Mean            0.00205606
evaluation/Actions Std             0.174667
evaluation/Actions Max             0.9793
evaluation/Actions Min            -0.989539
evaluation/Num Paths              15
evaluation/Average Returns      -339.358
time/data storing (s)              0.00301516
time/evaluation sampling (s)       0.332049
time/exploration sampling (s)      0.140545
time/logging (s)                   0.00483346
time/saving (s)                    0.00171251
time/training (s)                  1.90682
time/epoch (s)                     2.38897
time/total (s)                    33.2604
Epoch                             12
-----------------------------  --------------
2019-04-22 23:53:55.011380 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                 265.697
trainer/QF2 Loss                 265.414
trainer/Policy Loss               73.7697
trainer/Q1 Predictions Mean      -74.0408
trainer/Q1 Predictions Std        19.9548
trainer/Q1 Predictions Max       -31.6474
trainer/Q1 Predictions Min      -103.632
trainer/Q2 Predictions Mean      -74.0473
trainer/Q2 Predictions Std        19.9118
trainer/Q2 Predictions Max       -32.0023
trainer/Q2 Predictions Min      -103.571
trainer/Q Targets Mean           -70.747
trainer/Q Targets Std             24.8313
trainer/Q Targets Max             -1.74703
trainer/Q Targets Min           -104.835
trainer/Log Pis Mean               0.884699
trainer/Log Pis Std                1.53132
trainer/Log Pis Max                5.83343
trainer/Log Pis Min               -3.06707
trainer/Policy mu Mean            -0.0938619
trainer/Policy mu Std              0.938269
trainer/Policy mu Max              2.41853
trainer/Policy mu Min             -2.288
trainer/Policy log std Mean       -0.933168
trainer/Policy log std Std         0.234692
trainer/Policy log std Max        -0.475381
trainer/Policy log std Min        -1.41117
trainer/Alpha                      0.177525
trainer/Alpha Loss                -1.92769
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.21258
exploration/Rewards Std            1.56994
exploration/Rewards Max           -0.391263
exploration/Rewards Min           -9.00524
exploration/Returns Mean        -221.258
exploration/Returns Std          133.33
exploration/Returns Max         -127.319
exploration/Returns Min         -480.957
exploration/Actions Mean           0.00923954
exploration/Actions Std            0.365209
exploration/Actions Max            0.991178
exploration/Actions Min           -0.992679
exploration/Num Paths              5
exploration/Average Returns     -221.258
evaluation/num steps total     21000
evaluation/num paths total       210
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.91042
evaluation/Rewards Std             1.43621
evaluation/Rewards Max            -0.903805
evaluation/Rewards Min            -9.87495
evaluation/Returns Mean         -291.042
evaluation/Returns Std           123.357
evaluation/Returns Max          -111.012
evaluation/Returns Min          -519.241
evaluation/Actions Mean            0.00469912
evaluation/Actions Std             0.180246
evaluation/Actions Max             0.984322
evaluation/Actions Min            -0.991833
evaluation/Num Paths              15
evaluation/Average Returns      -291.042
time/data storing (s)              0.00305206
time/evaluation sampling (s)       0.338114
time/exploration sampling (s)      0.173895
time/logging (s)                   0.00476854
time/saving (s)                    0.00194563
time/training (s)                  2.12964
time/epoch (s)                     2.65142
time/total (s)                    35.916
Epoch                             13
-----------------------------  --------------
2019-04-22 23:53:57.439745 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                 141.486
trainer/QF2 Loss                 142.069
trainer/Policy Loss               72.9522
trainer/Q1 Predictions Mean      -73.9466
trainer/Q1 Predictions Std        23.3216
trainer/Q1 Predictions Max       -29.8952
trainer/Q1 Predictions Min      -123.955
trainer/Q2 Predictions Mean      -73.9879
trainer/Q2 Predictions Std        23.2663
trainer/Q2 Predictions Max       -30.1376
trainer/Q2 Predictions Min      -123.609
trainer/Q Targets Mean           -72.2346
trainer/Q Targets Std             27.2301
trainer/Q Targets Max             -1.22007
trainer/Q Targets Min           -124.307
trainer/Log Pis Mean               0.799342
trainer/Log Pis Std                1.93851
trainer/Log Pis Max                4.85802
trainer/Log Pis Min               -6.39266
trainer/Policy mu Mean             0.238061
trainer/Policy mu Std              1.04177
trainer/Policy mu Max              2.73999
trainer/Policy mu Min             -2.38454
trainer/Policy log std Mean       -1.01549
trainer/Policy log std Std         0.270031
trainer/Policy log std Max        -0.469672
trainer/Policy log std Min        -1.4673
trainer/Alpha                      0.156932
trainer/Alpha Loss                -2.22326
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.7929
exploration/Rewards Std            1.10617
exploration/Rewards Max           -0.443604
exploration/Rewards Min          -10.3049
exploration/Returns Mean        -179.29
exploration/Returns Std           41.0959
exploration/Returns Max         -119.56
exploration/Returns Min         -228.284
exploration/Actions Mean          -0.00109571
exploration/Actions Std            0.339131
exploration/Actions Max            0.990815
exploration/Actions Min           -0.996505
exploration/Num Paths              5
exploration/Average Returns     -179.29
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.56816
evaluation/Rewards Std             1.43739
evaluation/Rewards Max            -0.529056
evaluation/Rewards Min           -10.06
evaluation/Returns Mean         -256.816
evaluation/Returns Std           125.535
evaluation/Returns Max          -134.22
evaluation/Returns Min          -550.425
evaluation/Actions Mean            0.0125796
evaluation/Actions Std             0.166487
evaluation/Actions Max             0.985292
evaluation/Actions Min            -0.989825
evaluation/Num Paths              15
evaluation/Average Returns      -256.816
time/data storing (s)              0.00314264
time/evaluation sampling (s)       0.333754
time/exploration sampling (s)      0.144802
time/logging (s)                   0.00480077
time/saving (s)                    0.00196185
time/training (s)                  1.93486
time/epoch (s)                     2.42333
time/total (s)                    38.3435
Epoch                             14
-----------------------------  --------------
2019-04-22 23:53:59.851741 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   2.62704
trainer/QF2 Loss                   2.88064
trainer/Policy Loss               78.3129
trainer/Q1 Predictions Mean      -79.1217
trainer/Q1 Predictions Std        25.7143
trainer/Q1 Predictions Max       -31.4629
trainer/Q1 Predictions Min      -118.351
trainer/Q2 Predictions Mean      -79.0582
trainer/Q2 Predictions Std        25.7235
trainer/Q2 Predictions Max       -31.2494
trainer/Q2 Predictions Min      -118.328
trainer/Q Targets Mean           -79.6026
trainer/Q Targets Std             26.0872
trainer/Q Targets Max            -31.6303
trainer/Q Targets Min           -118.338
trainer/Log Pis Mean               0.899251
trainer/Log Pis Std                1.77323
trainer/Log Pis Max                5.81317
trainer/Log Pis Min               -3.68492
trainer/Policy mu Mean             0.04596
trainer/Policy mu Std              1.06394
trainer/Policy mu Max              2.76829
trainer/Policy mu Min             -2.67519
trainer/Policy log std Mean       -1.02772
trainer/Policy log std Std         0.296186
trainer/Policy log std Max        -0.484326
trainer/Policy log std Min        -1.59405
trainer/Alpha                      0.139317
trainer/Alpha Loss                -2.16932
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.18182
exploration/Rewards Std            1.76132
exploration/Rewards Max           -0.967744
exploration/Rewards Min           -8.51997
exploration/Returns Mean        -418.182
exploration/Returns Std          165.514
exploration/Returns Max         -158.369
exploration/Returns Min         -584.652
exploration/Actions Mean           0.00670558
exploration/Actions Std            0.382598
exploration/Actions Max            0.994085
exploration/Actions Min           -0.993576
exploration/Num Paths              5
exploration/Average Returns     -418.182
evaluation/num steps total     24000
evaluation/num paths total       240
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.47899
evaluation/Rewards Std             1.77978
evaluation/Rewards Max            -0.312485
evaluation/Rewards Min            -9.79599
evaluation/Returns Mean         -247.899
evaluation/Returns Std           162.845
evaluation/Returns Max           -55.923
evaluation/Returns Min          -581.355
evaluation/Actions Mean            0.00324114
evaluation/Actions Std             0.178859
evaluation/Actions Max             0.99274
evaluation/Actions Min            -0.994058
evaluation/Num Paths              15
evaluation/Average Returns      -247.899
time/data storing (s)              0.00300907
time/evaluation sampling (s)       0.331233
time/exploration sampling (s)      0.143891
time/logging (s)                   0.0048301
time/saving (s)                    0.00196984
time/training (s)                  1.92192
time/epoch (s)                     2.40685
time/total (s)                    40.7546
Epoch                             15
-----------------------------  --------------
2019-04-22 23:54:02.277861 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              8700
trainer/QF1 Loss                 136.955
trainer/QF2 Loss                 136.924
trainer/Policy Loss               84.9498
trainer/Q1 Predictions Mean      -85.1952
trainer/Q1 Predictions Std        27.1767
trainer/Q1 Predictions Max       -31.242
trainer/Q1 Predictions Min      -121.406
trainer/Q2 Predictions Mean      -85.2511
trainer/Q2 Predictions Std        27.1234
trainer/Q2 Predictions Max       -31.9648
trainer/Q2 Predictions Min      -121.468
trainer/Q Targets Mean           -85.0952
trainer/Q Targets Std             28.6219
trainer/Q Targets Max             -4.67776
trainer/Q Targets Min           -123.521
trainer/Log Pis Mean               0.801287
trainer/Log Pis Std                1.63336
trainer/Log Pis Max                4.6399
trainer/Log Pis Min               -3.94064
trainer/Policy mu Mean             0.228439
trainer/Policy mu Std              0.938893
trainer/Policy mu Max              2.96763
trainer/Policy mu Min             -2.85024
trainer/Policy log std Mean       -1.08257
trainer/Policy log std Std         0.32762
trainer/Policy log std Max        -0.421101
trainer/Policy log std Min        -1.70363
trainer/Alpha                      0.12285
trainer/Alpha Loss                -2.51317
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.35613
exploration/Rewards Std            1.30963
exploration/Rewards Max           -0.721978
exploration/Rewards Min           -9.32131
exploration/Returns Mean        -235.613
exploration/Returns Std          115.069
exploration/Returns Max         -161.786
exploration/Returns Min         -463.643
exploration/Actions Mean           0.00400797
exploration/Actions Std            0.330166
exploration/Actions Max            0.997573
exploration/Actions Min           -0.997911
exploration/Num Paths              5
exploration/Average Returns     -235.613
evaluation/num steps total     25500
evaluation/num paths total       255
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.79392
evaluation/Rewards Std             2.00445
evaluation/Rewards Max            -0.146726
evaluation/Rewards Min           -10.7751
evaluation/Returns Mean         -279.392
evaluation/Returns Std           183.782
evaluation/Returns Max           -26.3407
evaluation/Returns Min          -609.917
evaluation/Actions Mean           -0.00237247
evaluation/Actions Std             0.195387
evaluation/Actions Max             0.995256
evaluation/Actions Min            -0.99344
evaluation/Num Paths              15
evaluation/Average Returns      -279.392
time/data storing (s)              0.00307539
time/evaluation sampling (s)       0.340193
time/exploration sampling (s)      0.141131
time/logging (s)                   0.00472777
time/saving (s)                    0.00205942
time/training (s)                  1.92968
time/epoch (s)                     2.42086
time/total (s)                    43.1797
Epoch                             16
-----------------------------  --------------
2019-04-22 23:54:04.689172 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 17 finished
-----------------------------  --------------
replay_buffer/size              9200
trainer/QF1 Loss                   4.05347
trainer/QF2 Loss                   4.26286
trainer/Policy Loss               84.0794
trainer/Q1 Predictions Mean      -84.1479
trainer/Q1 Predictions Std        31.1336
trainer/Q1 Predictions Max       -31.8835
trainer/Q1 Predictions Min      -132.05
trainer/Q2 Predictions Mean      -84.1121
trainer/Q2 Predictions Std        31.1105
trainer/Q2 Predictions Max       -32.1681
trainer/Q2 Predictions Min      -131.567
trainer/Q Targets Mean           -85.7396
trainer/Q Targets Std             31.8216
trainer/Q Targets Max            -32.9217
trainer/Q Targets Min           -133.637
trainer/Log Pis Mean               1.19368
trainer/Log Pis Std                1.79758
trainer/Log Pis Max                6.4636
trainer/Log Pis Min               -6.80363
trainer/Policy mu Mean             0.34683
trainer/Policy mu Std              1.00231
trainer/Policy mu Max              2.82223
trainer/Policy mu Min             -3.13503
trainer/Policy log std Mean       -1.18282
trainer/Policy log std Std         0.342069
trainer/Policy log std Max        -0.567632
trainer/Policy log std Min        -1.80183
trainer/Alpha                      0.109551
trainer/Alpha Loss                -1.78292
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.51303
exploration/Rewards Std            1.41252
exploration/Rewards Max           -1.14987
exploration/Rewards Min           -7.20368
exploration/Returns Mean        -451.303
exploration/Returns Std          135.966
exploration/Returns Max         -235.57
exploration/Returns Min         -656.606
exploration/Actions Mean           0.00740193
exploration/Actions Std            0.367207
exploration/Actions Max            0.995746
exploration/Actions Min           -0.951622
exploration/Num Paths              5
exploration/Average Returns     -451.303
evaluation/num steps total     27000
evaluation/num paths total       270
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -3.0515
evaluation/Rewards Std             1.79535
evaluation/Rewards Max            -0.299207
evaluation/Rewards Min            -9.60209
evaluation/Returns Mean         -305.15
evaluation/Returns Std           168.769
evaluation/Returns Max           -66.2776
evaluation/Returns Min          -635.239
evaluation/Actions Mean            0.00767069
evaluation/Actions Std             0.170777
evaluation/Actions Max             0.991365
evaluation/Actions Min            -0.992328
evaluation/Num Paths              15
evaluation/Average Returns      -305.15
time/data storing (s)              0.00294004
time/evaluation sampling (s)       0.335745
time/exploration sampling (s)      0.140031
time/logging (s)                   0.00473221
time/saving (s)                    0.00159192
time/training (s)                  1.92114
time/epoch (s)                     2.40618
time/total (s)                    45.5901
Epoch                             17
-----------------------------  --------------
2019-04-22 23:54:07.100258 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                 360.678
trainer/QF2 Loss                 361.224
trainer/Policy Loss               83.8585
trainer/Q1 Predictions Mean      -83.786
trainer/Q1 Predictions Std        29.8294
trainer/Q1 Predictions Max       -34.169
trainer/Q1 Predictions Min      -151.22
trainer/Q2 Predictions Mean      -83.8161
trainer/Q2 Predictions Std        29.8837
trainer/Q2 Predictions Max       -33.8423
trainer/Q2 Predictions Min      -152.168
trainer/Q Targets Mean           -81.499
trainer/Q Targets Std             33.5951
trainer/Q Targets Max             -3.59238
trainer/Q Targets Min           -153.646
trainer/Log Pis Mean               1.2904
trainer/Log Pis Std                1.76687
trainer/Log Pis Max                7.25334
trainer/Log Pis Min               -3.43475
trainer/Policy mu Mean            -0.015966
trainer/Policy mu Std              0.958766
trainer/Policy mu Max              2.92402
trainer/Policy mu Min             -2.72785
trainer/Policy log std Mean       -1.31303
trainer/Policy log std Std         0.3742
trainer/Policy log std Max        -0.567204
trainer/Policy log std Min        -1.83698
trainer/Alpha                      0.0980535
trainer/Alpha Loss                -1.6477
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.05478
exploration/Rewards Std            1.99564
exploration/Rewards Max           -0.28434
exploration/Rewards Min           -9.07551
exploration/Returns Mean        -205.478
exploration/Returns Std          178.258
exploration/Returns Max         -100.595
exploration/Returns Min         -560.541
exploration/Actions Mean          -0.00132521
exploration/Actions Std            0.291673
exploration/Actions Max            0.995558
exploration/Actions Min           -0.998183
exploration/Num Paths              5
exploration/Average Returns     -205.478
evaluation/num steps total     28500
evaluation/num paths total       285
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.96795
evaluation/Rewards Std             1.70812
evaluation/Rewards Max            -0.622644
evaluation/Rewards Min            -8.66358
evaluation/Returns Mean         -296.795
evaluation/Returns Std           160.913
evaluation/Returns Max           -71.0527
evaluation/Returns Min          -560.702
evaluation/Actions Mean            0.0115219
evaluation/Actions Std             0.155958
evaluation/Actions Max             0.991182
evaluation/Actions Min            -0.981965
evaluation/Num Paths              15
evaluation/Average Returns      -296.795
time/data storing (s)              0.00279765
time/evaluation sampling (s)       0.336315
time/exploration sampling (s)      0.144388
time/logging (s)                   0.00472152
time/saving (s)                    0.00153641
time/training (s)                  1.91662
time/epoch (s)                     2.40638
time/total (s)                    48.0002
Epoch                             18
-----------------------------  --------------
2019-04-22 23:54:09.518958 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   1.27103
trainer/QF2 Loss                   1.16786
trainer/Policy Loss               82.4666
trainer/Q1 Predictions Mean      -82.3004
trainer/Q1 Predictions Std        31.3231
trainer/Q1 Predictions Max       -33.1449
trainer/Q1 Predictions Min      -136.955
trainer/Q2 Predictions Mean      -82.3306
trainer/Q2 Predictions Std        31.2314
trainer/Q2 Predictions Max       -33.2589
trainer/Q2 Predictions Min      -136.558
trainer/Q Targets Mean           -82.9469
trainer/Q Targets Std             31.5202
trainer/Q Targets Max            -33.8876
trainer/Q Targets Min           -136.948
trainer/Log Pis Mean               1.27494
trainer/Log Pis Std                1.67325
trainer/Log Pis Max                5.78176
trainer/Log Pis Min               -3.67544
trainer/Policy mu Mean             0.129567
trainer/Policy mu Std              0.992819
trainer/Policy mu Max              2.77351
trainer/Policy mu Min             -2.65106
trainer/Policy log std Mean       -1.31264
trainer/Policy log std Std         0.383148
trainer/Policy log std Max        -0.362226
trainer/Policy log std Min        -1.94454
trainer/Alpha                      0.0876253
trainer/Alpha Loss                -1.76513
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.20121
exploration/Rewards Std            0.663368
exploration/Rewards Max           -0.154915
exploration/Rewards Min           -7.48894
exploration/Returns Mean        -120.121
exploration/Returns Std           28.655
exploration/Returns Max          -69.1142
exploration/Returns Min         -155.704
exploration/Actions Mean           0.0165505
exploration/Actions Std            0.27434
exploration/Actions Max            0.996926
exploration/Actions Min           -0.997515
exploration/Num Paths              5
exploration/Average Returns     -120.121
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.64667
evaluation/Rewards Std             1.72973
evaluation/Rewards Max            -0.207866
evaluation/Rewards Min           -10.0595
evaluation/Returns Mean         -264.667
evaluation/Returns Std           157.353
evaluation/Returns Max          -108.481
evaluation/Returns Min          -538.489
evaluation/Actions Mean            0.00516564
evaluation/Actions Std             0.16596
evaluation/Actions Max             0.997059
evaluation/Actions Min            -0.996102
evaluation/Num Paths              15
evaluation/Average Returns      -264.667
time/data storing (s)              0.00306126
time/evaluation sampling (s)       0.336804
time/exploration sampling (s)      0.142442
time/logging (s)                   0.00474992
time/saving (s)                    0.00195092
time/training (s)                  1.92467
time/epoch (s)                     2.41368
time/total (s)                    50.4181
Epoch                             19
-----------------------------  --------------
2019-04-22 23:54:11.945966 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                  32.6111
trainer/QF2 Loss                  32.1951
trainer/Policy Loss               89.9229
trainer/Q1 Predictions Mean      -89.6469
trainer/Q1 Predictions Std        34.1456
trainer/Q1 Predictions Max       -33.0434
trainer/Q1 Predictions Min      -137.63
trainer/Q2 Predictions Mean      -89.6544
trainer/Q2 Predictions Std        34.19
trainer/Q2 Predictions Max       -32.9596
trainer/Q2 Predictions Min      -137.823
trainer/Q Targets Mean           -89.7176
trainer/Q Targets Std             35.1958
trainer/Q Targets Max             -4.96774
trainer/Q Targets Min           -139.561
trainer/Log Pis Mean               1.45957
trainer/Log Pis Std                1.56081
trainer/Log Pis Max                5.34884
trainer/Log Pis Min               -2.91652
trainer/Policy mu Mean             0.346786
trainer/Policy mu Std              0.939173
trainer/Policy mu Max              2.75306
trainer/Policy mu Min             -2.25843
trainer/Policy log std Mean       -1.42428
trainer/Policy log std Std         0.380926
trainer/Policy log std Max        -0.472528
trainer/Policy log std Min        -2.13248
trainer/Alpha                      0.0792314
trainer/Alpha Loss                -1.37014
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.25612
exploration/Rewards Std            1.07943
exploration/Rewards Max           -1.06353
exploration/Rewards Min           -5.35536
exploration/Returns Mean        -225.612
exploration/Returns Std          100.738
exploration/Returns Max         -148.066
exploration/Returns Min         -421.69
exploration/Actions Mean           0.012418
exploration/Actions Std            0.272258
exploration/Actions Max            0.9905
exploration/Actions Min           -0.984652
exploration/Num Paths              5
exploration/Average Returns     -225.612
evaluation/num steps total     31500
evaluation/num paths total       315
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.67993
evaluation/Rewards Std             2.22343
evaluation/Rewards Max            -0.445608
evaluation/Rewards Min            -9.89335
evaluation/Returns Mean         -267.993
evaluation/Returns Std           211.885
evaluation/Returns Max           -44.7428
evaluation/Returns Min          -589.313
evaluation/Actions Mean            0.0143197
evaluation/Actions Std             0.179334
evaluation/Actions Max             0.996837
evaluation/Actions Min            -0.995748
evaluation/Num Paths              15
evaluation/Average Returns      -267.993
time/data storing (s)              0.00299432
time/evaluation sampling (s)       0.343089
time/exploration sampling (s)      0.147866
time/logging (s)                   0.00443359
time/saving (s)                    0.0067739
time/training (s)                  1.91629
time/epoch (s)                     2.42144
time/total (s)                    52.8437
Epoch                             20
-----------------------------  --------------
2019-04-22 23:54:14.339614 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   3.36504
trainer/QF2 Loss                   3.52635
trainer/Policy Loss               86.0859
trainer/Q1 Predictions Mean      -85.9915
trainer/Q1 Predictions Std        37.6099
trainer/Q1 Predictions Max       -33.8565
trainer/Q1 Predictions Min      -148.958
trainer/Q2 Predictions Mean      -85.9932
trainer/Q2 Predictions Std        37.5189
trainer/Q2 Predictions Max       -33.8399
trainer/Q2 Predictions Min      -148.515
trainer/Q Targets Mean           -87.5139
trainer/Q Targets Std             38.2054
trainer/Q Targets Max            -34.3692
trainer/Q Targets Min           -150.068
trainer/Log Pis Mean               1.4214
trainer/Log Pis Std                1.76625
trainer/Log Pis Max                7.23353
trainer/Log Pis Min               -3.19984
trainer/Policy mu Mean             0.0504284
trainer/Policy mu Std              1.01824
trainer/Policy mu Max              3.09755
trainer/Policy mu Min             -2.65121
trainer/Policy log std Mean       -1.37466
trainer/Policy log std Std         0.376081
trainer/Policy log std Max        -0.422519
trainer/Policy log std Min        -1.98748
trainer/Alpha                      0.0725318
trainer/Alpha Loss                -1.51797
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.92575
exploration/Rewards Std            1.86338
exploration/Rewards Max           -0.410766
exploration/Rewards Min           -6.17414
exploration/Returns Mean        -292.575
exploration/Returns Std          178.208
exploration/Returns Max          -77.4485
exploration/Returns Min         -511.98
exploration/Actions Mean           0.0319543
exploration/Actions Std            0.316235
exploration/Actions Max            0.998154
exploration/Actions Min           -0.81343
exploration/Num Paths              5
exploration/Average Returns     -292.575
evaluation/num steps total     33000
evaluation/num paths total       330
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.45528
evaluation/Rewards Std             1.70448
evaluation/Rewards Max            -0.5263
evaluation/Rewards Min           -10.5668
evaluation/Returns Mean         -245.528
evaluation/Returns Std           155.468
evaluation/Returns Max           -78.9977
evaluation/Returns Min          -525.067
evaluation/Actions Mean            0.00858275
evaluation/Actions Std             0.18084
evaluation/Actions Max             0.997043
evaluation/Actions Min            -0.997604
evaluation/Num Paths              15
evaluation/Average Returns      -245.528
time/data storing (s)              0.0030391
time/evaluation sampling (s)       0.330428
time/exploration sampling (s)      0.141288
time/logging (s)                   0.00476003
time/saving (s)                    0.00193259
time/training (s)                  1.90747
time/epoch (s)                     2.38892
time/total (s)                    55.237
Epoch                             21
-----------------------------  --------------
2019-04-22 23:54:16.748080 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                  68.0915
trainer/QF2 Loss                  67.7364
trainer/Policy Loss               86.3529
trainer/Q1 Predictions Mean      -85.6218
trainer/Q1 Predictions Std        38.0025
trainer/Q1 Predictions Max       -34.3185
trainer/Q1 Predictions Min      -150.374
trainer/Q2 Predictions Mean      -85.6606
trainer/Q2 Predictions Std        38.0525
trainer/Q2 Predictions Max       -34.1713
trainer/Q2 Predictions Min      -150.155
trainer/Q Targets Mean           -85.7262
trainer/Q Targets Std             39.5134
trainer/Q Targets Max             -2.03642
trainer/Q Targets Min           -151.264
trainer/Log Pis Mean               1.69726
trainer/Log Pis Std                1.50431
trainer/Log Pis Max                6.33766
trainer/Log Pis Min               -1.76289
trainer/Policy mu Mean            -0.0046238
trainer/Policy mu Std              1.00195
trainer/Policy mu Max              2.56657
trainer/Policy mu Min             -2.78919
trainer/Policy log std Mean       -1.47554
trainer/Policy log std Std         0.404577
trainer/Policy log std Max        -0.28459
trainer/Policy log std Min        -2.0262
trainer/Alpha                      0.0660005
trainer/Alpha Loss                -0.822803
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.27518
exploration/Rewards Std            1.27217
exploration/Rewards Max           -0.403025
exploration/Rewards Min           -8.72294
exploration/Returns Mean        -227.518
exploration/Returns Std          120.465
exploration/Returns Max          -90.1962
exploration/Returns Min         -396.058
exploration/Actions Mean          -0.013782
exploration/Actions Std            0.266042
exploration/Actions Max            0.793438
exploration/Actions Min           -0.995761
exploration/Num Paths              5
exploration/Average Returns     -227.518
evaluation/num steps total     34500
evaluation/num paths total       345
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.30559
evaluation/Rewards Std             1.3785
evaluation/Rewards Max            -0.466483
evaluation/Rewards Min           -11.1645
evaluation/Returns Mean         -230.559
evaluation/Returns Std           120.421
evaluation/Returns Max           -69.2018
evaluation/Returns Min          -452.126
evaluation/Actions Mean            0.00220269
evaluation/Actions Std             0.164816
evaluation/Actions Max             0.993462
evaluation/Actions Min            -0.997389
evaluation/Num Paths              15
evaluation/Average Returns      -230.559
time/data storing (s)              0.00299145
time/evaluation sampling (s)       0.333697
time/exploration sampling (s)      0.138808
time/logging (s)                   0.00477573
time/saving (s)                    0.00155938
time/training (s)                  1.92143
time/epoch (s)                     2.40326
time/total (s)                    57.6444
Epoch                             22
-----------------------------  --------------
2019-04-22 23:54:19.152083 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   1.81667
trainer/QF2 Loss                   1.87724
trainer/Policy Loss               86.5062
trainer/Q1 Predictions Mean      -85.8666
trainer/Q1 Predictions Std        36.8889
trainer/Q1 Predictions Max       -34.5592
trainer/Q1 Predictions Min      -156.038
trainer/Q2 Predictions Mean      -85.8862
trainer/Q2 Predictions Std        36.9422
trainer/Q2 Predictions Max       -34.2486
trainer/Q2 Predictions Min      -155.953
trainer/Q Targets Mean           -86.9023
trainer/Q Targets Std             37.2312
trainer/Q Targets Max            -34.9892
trainer/Q Targets Min           -157.437
trainer/Log Pis Mean               1.85414
trainer/Log Pis Std                1.74579
trainer/Log Pis Max                7.14373
trainer/Log Pis Min               -3.09071
trainer/Policy mu Mean             0.031394
trainer/Policy mu Std              1.06148
trainer/Policy mu Max              3.10494
trainer/Policy mu Min             -3.12898
trainer/Policy log std Mean       -1.58763
trainer/Policy log std Std         0.447948
trainer/Policy log std Max        -0.465795
trainer/Policy log std Min        -2.31539
trainer/Alpha                      0.0619351
trainer/Alpha Loss                -0.405714
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.83264
exploration/Rewards Std            1.59223
exploration/Rewards Max           -0.752523
exploration/Rewards Min           -7.88671
exploration/Returns Mean        -283.264
exploration/Returns Std          150.436
exploration/Returns Max         -123.635
exploration/Returns Min         -503.926
exploration/Actions Mean          -0.0145866
exploration/Actions Std            0.270275
exploration/Actions Max            0.993796
exploration/Actions Min           -0.997886
exploration/Num Paths              5
exploration/Average Returns     -283.264
evaluation/num steps total     36000
evaluation/num paths total       360
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.23727
evaluation/Rewards Std             1.41317
evaluation/Rewards Max            -0.612762
evaluation/Rewards Min            -9.54083
evaluation/Returns Mean         -223.727
evaluation/Returns Std           118.13
evaluation/Returns Max           -88.2347
evaluation/Returns Min          -417.843
evaluation/Actions Mean            0.0181311
evaluation/Actions Std             0.168685
evaluation/Actions Max             0.997329
evaluation/Actions Min            -0.969872
evaluation/Num Paths              15
evaluation/Average Returns      -223.727
time/data storing (s)              0.00301182
time/evaluation sampling (s)       0.324997
time/exploration sampling (s)      0.138483
time/logging (s)                   0.00486421
time/saving (s)                    0.00195495
time/training (s)                  1.92567
time/epoch (s)                     2.39898
time/total (s)                    60.0477
Epoch                             23
-----------------------------  --------------
2019-04-22 23:54:21.580170 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size             12700
trainer/QF1 Loss                   1.12258
trainer/QF2 Loss                   0.896221
trainer/Policy Loss               88.0659
trainer/Q1 Predictions Mean      -87.2147
trainer/Q1 Predictions Std        41.5371
trainer/Q1 Predictions Max       -35.8097
trainer/Q1 Predictions Min      -161.987
trainer/Q2 Predictions Mean      -87.2703
trainer/Q2 Predictions Std        41.5473
trainer/Q2 Predictions Max       -35.8031
trainer/Q2 Predictions Min      -164.98
trainer/Q Targets Mean           -87.6127
trainer/Q Targets Std             42.0104
trainer/Q Targets Max            -35.4699
trainer/Q Targets Min           -166.754
trainer/Log Pis Mean               1.78259
trainer/Log Pis Std                1.47
trainer/Log Pis Max                6.34261
trainer/Log Pis Min               -3.18626
trainer/Policy mu Mean             0.0402956
trainer/Policy mu Std              0.908035
trainer/Policy mu Max              3.13391
trainer/Policy mu Min             -2.98217
trainer/Policy log std Mean       -1.62028
trainer/Policy log std Std         0.456833
trainer/Policy log std Max        -0.145022
trainer/Policy log std Min        -2.27569
trainer/Alpha                      0.0586696
trainer/Alpha Loss                -0.616524
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.23556
exploration/Rewards Std            1.82778
exploration/Rewards Max           -0.667001
exploration/Rewards Min          -10.5975
exploration/Returns Mean        -323.556
exploration/Returns Std          140.961
exploration/Returns Max         -159.075
exploration/Returns Min         -479.294
exploration/Actions Mean          -0.01565
exploration/Actions Std            0.336023
exploration/Actions Max            0.994271
exploration/Actions Min           -0.999182
exploration/Num Paths              5
exploration/Average Returns     -323.556
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.51365
evaluation/Rewards Std             1.26743
evaluation/Rewards Max            -0.200166
evaluation/Rewards Min            -9.59257
evaluation/Returns Mean         -251.365
evaluation/Returns Std           111.777
evaluation/Returns Max           -79.3578
evaluation/Returns Min          -446.473
evaluation/Actions Mean           -0.00792299
evaluation/Actions Std             0.15704
evaluation/Actions Max             0.968864
evaluation/Actions Min            -0.997077
evaluation/Num Paths              15
evaluation/Average Returns      -251.365
time/data storing (s)              0.00295079
time/evaluation sampling (s)       0.339466
time/exploration sampling (s)      0.138182
time/logging (s)                   0.00475328
time/saving (s)                    0.00197047
time/training (s)                  1.9354
time/epoch (s)                     2.42272
time/total (s)                    62.4747
Epoch                             24
-----------------------------  --------------
2019-04-22 23:54:24.005440 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   2.82423
trainer/QF2 Loss                   2.87552
trainer/Policy Loss               87.0538
trainer/Q1 Predictions Mean      -86.5757
trainer/Q1 Predictions Std        39.1895
trainer/Q1 Predictions Max       -35.561
trainer/Q1 Predictions Min      -165.433
trainer/Q2 Predictions Mean      -86.6395
trainer/Q2 Predictions Std        39.1785
trainer/Q2 Predictions Max       -35.5013
trainer/Q2 Predictions Min      -165.892
trainer/Q Targets Mean           -87.7021
trainer/Q Targets Std             39.79
trainer/Q Targets Max            -36.4243
trainer/Q Targets Min           -167.489
trainer/Log Pis Mean               1.78946
trainer/Log Pis Std                1.59371
trainer/Log Pis Max                6.40771
trainer/Log Pis Min               -1.9984
trainer/Policy mu Mean            -0.0897626
trainer/Policy mu Std              0.958014
trainer/Policy mu Max              3.22551
trainer/Policy mu Min             -3.42517
trainer/Policy log std Mean       -1.64686
trainer/Policy log std Std         0.456035
trainer/Policy log std Max        -0.134331
trainer/Policy log std Min        -2.22352
trainer/Alpha                      0.0554535
trainer/Alpha Loss                -0.608905
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.38912
exploration/Rewards Std            0.962624
exploration/Rewards Max           -0.436356
exploration/Rewards Min           -8.559
exploration/Returns Mean        -238.912
exploration/Returns Std           77.0869
exploration/Returns Max          -94.3487
exploration/Returns Min         -323.027
exploration/Actions Mean           0.0149787
exploration/Actions Std            0.25794
exploration/Actions Max            0.996955
exploration/Actions Min           -0.994843
exploration/Num Paths              5
exploration/Average Returns     -238.912
evaluation/num steps total     39000
evaluation/num paths total       390
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.55259
evaluation/Rewards Std             1.3563
evaluation/Rewards Max            -0.382063
evaluation/Rewards Min            -8.84698
evaluation/Returns Mean         -255.259
evaluation/Returns Std           121.621
evaluation/Returns Max           -47.6866
evaluation/Returns Min          -378.493
evaluation/Actions Mean            0.0140602
evaluation/Actions Std             0.238345
evaluation/Actions Max             0.994979
evaluation/Actions Min            -0.998476
evaluation/Num Paths              15
evaluation/Average Returns      -255.259
time/data storing (s)              0.00284792
time/evaluation sampling (s)       0.334101
time/exploration sampling (s)      0.142557
time/logging (s)                   0.00480233
time/saving (s)                    0.00197749
time/training (s)                  1.93396
time/epoch (s)                     2.42025
time/total (s)                    64.8989
Epoch                             25
-----------------------------  --------------
2019-04-22 23:54:26.422719 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                   1.88261
trainer/QF2 Loss                   1.82473
trainer/Policy Loss              101.01
trainer/Q1 Predictions Mean     -100.143
trainer/Q1 Predictions Std        46.1566
trainer/Q1 Predictions Max       -37.0426
trainer/Q1 Predictions Min      -172.604
trainer/Q2 Predictions Mean     -100.152
trainer/Q2 Predictions Std        46.1745
trainer/Q2 Predictions Max       -37.1759
trainer/Q2 Predictions Min      -172.279
trainer/Q Targets Mean          -100.634
trainer/Q Targets Std             46.5004
trainer/Q Targets Max            -37.3628
trainer/Q Targets Min           -173.445
trainer/Log Pis Mean               1.96203
trainer/Log Pis Std                1.58337
trainer/Log Pis Max                6.77912
trainer/Log Pis Min               -2.53686
trainer/Policy mu Mean             0.215606
trainer/Policy mu Std              1.02429
trainer/Policy mu Max              3.17926
trainer/Policy mu Min             -3.15947
trainer/Policy log std Mean       -1.62799
trainer/Policy log std Std         0.445861
trainer/Policy log std Max        -0.62142
trainer/Policy log std Min        -2.3576
trainer/Alpha                      0.053143
trainer/Alpha Loss                -0.111444
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -4.11243
exploration/Rewards Std            2.05153
exploration/Rewards Max           -0.934824
exploration/Rewards Min           -8.29576
exploration/Returns Mean        -411.243
exploration/Returns Std          193.335
exploration/Returns Max         -142.455
exploration/Returns Min         -636.92
exploration/Actions Mean           0.00345651
exploration/Actions Std            0.275887
exploration/Actions Max            0.99537
exploration/Actions Min           -0.998215
exploration/Num Paths              5
exploration/Average Returns     -411.243
evaluation/num steps total     40500
evaluation/num paths total       405
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.86966
evaluation/Rewards Std             1.82543
evaluation/Rewards Max            -0.515295
evaluation/Rewards Min           -10.3537
evaluation/Returns Mean         -286.966
evaluation/Returns Std           174.047
evaluation/Returns Max           -58.2502
evaluation/Returns Min          -643.438
evaluation/Actions Mean            0.00209745
evaluation/Actions Std             0.152787
evaluation/Actions Max             0.998249
evaluation/Actions Min            -0.993627
evaluation/Num Paths              15
evaluation/Average Returns      -286.966
time/data storing (s)              0.00304605
time/evaluation sampling (s)       0.321769
time/exploration sampling (s)      0.141056
time/logging (s)                   0.00475958
time/saving (s)                    0.00195339
time/training (s)                  1.93915
time/epoch (s)                     2.41173
time/total (s)                    67.3151
Epoch                             26
-----------------------------  --------------
2019-04-22 23:54:28.886572 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                  18.8641
trainer/QF2 Loss                  18.8911
trainer/Policy Loss               94.9767
trainer/Q1 Predictions Mean      -94.1071
trainer/Q1 Predictions Std        44.8131
trainer/Q1 Predictions Max       -37.6026
trainer/Q1 Predictions Min      -174.556
trainer/Q2 Predictions Mean      -94.1113
trainer/Q2 Predictions Std        44.8227
trainer/Q2 Predictions Max       -37.728
trainer/Q2 Predictions Min      -174.713
trainer/Q Targets Mean           -94.4754
trainer/Q Targets Std             45.8856
trainer/Q Targets Max             -0.939385
trainer/Q Targets Min           -176.373
trainer/Log Pis Mean               2.02744
trainer/Log Pis Std                1.61487
trainer/Log Pis Max                7.89701
trainer/Log Pis Min               -2.17993
trainer/Policy mu Mean            -0.390638
trainer/Policy mu Std              0.993363
trainer/Policy mu Max              2.51654
trainer/Policy mu Min             -3.74902
trainer/Policy log std Mean       -1.59214
trainer/Policy log std Std         0.49261
trainer/Policy log std Max        -0.221808
trainer/Policy log std Min        -2.29514
trainer/Alpha                      0.0499039
trainer/Alpha Loss                 0.0822473
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.37161
exploration/Rewards Std            0.767013
exploration/Rewards Max           -0.537629
exploration/Rewards Min           -8.13787
exploration/Returns Mean        -137.161
exploration/Returns Std           42.5048
exploration/Returns Max          -87.3993
exploration/Returns Min         -215.812
exploration/Actions Mean           0.0133961
exploration/Actions Std            0.235986
exploration/Actions Max            0.995919
exploration/Actions Min           -0.994721
exploration/Num Paths              5
exploration/Average Returns     -137.161
evaluation/num steps total     42000
evaluation/num paths total       420
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.48542
evaluation/Rewards Std             1.24695
evaluation/Rewards Max            -0.0880681
evaluation/Rewards Min            -9.86302
evaluation/Returns Mean         -248.542
evaluation/Returns Std           106.59
evaluation/Returns Max           -84.0973
evaluation/Returns Min          -358.723
evaluation/Actions Mean            0.00989646
evaluation/Actions Std             0.177979
evaluation/Actions Max             0.995577
evaluation/Actions Min            -0.992567
evaluation/Num Paths              15
evaluation/Average Returns      -248.542
time/data storing (s)              0.00309194
time/evaluation sampling (s)       0.329569
time/exploration sampling (s)      0.142224
time/logging (s)                   0.00475386
time/saving (s)                    0.00193994
time/training (s)                  1.97703
time/epoch (s)                     2.45861
time/total (s)                    69.7779
Epoch                             27
-----------------------------  --------------
2019-04-22 23:54:31.314784 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             14700
trainer/QF1 Loss                   3.57078
trainer/QF2 Loss                   3.2684
trainer/Policy Loss               92.1782
trainer/Q1 Predictions Mean      -91.477
trainer/Q1 Predictions Std        49.3235
trainer/Q1 Predictions Max       -38.6971
trainer/Q1 Predictions Min      -176.34
trainer/Q2 Predictions Mean      -91.4591
trainer/Q2 Predictions Std        49.3564
trainer/Q2 Predictions Max       -38.6712
trainer/Q2 Predictions Min      -177.169
trainer/Q Targets Mean           -92.5636
trainer/Q Targets Std             50.0628
trainer/Q Targets Max            -38.792
trainer/Q Targets Min           -179.746
trainer/Log Pis Mean               1.6053
trainer/Log Pis Std                1.58332
trainer/Log Pis Max                6.53203
trainer/Log Pis Min               -2.35273
trainer/Policy mu Mean            -0.117458
trainer/Policy mu Std              0.992075
trainer/Policy mu Max              2.71117
trainer/Policy mu Min             -3.88613
trainer/Policy log std Mean       -1.49016
trainer/Policy log std Std         0.47494
trainer/Policy log std Max         0.171443
trainer/Policy log std Min        -2.40371
trainer/Alpha                      0.0518259
trainer/Alpha Loss                -1.16816
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.65056
exploration/Rewards Std            1.32908
exploration/Rewards Max           -0.319355
exploration/Rewards Min           -5.06216
exploration/Returns Mean        -165.056
exploration/Returns Std          127.49
exploration/Returns Max          -76.2709
exploration/Returns Min         -418.666
exploration/Actions Mean           0.00632297
exploration/Actions Std            0.257334
exploration/Actions Max            0.988263
exploration/Actions Min           -0.995806
exploration/Num Paths              5
exploration/Average Returns     -165.056
evaluation/num steps total     43500
evaluation/num paths total       435
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.34934
evaluation/Rewards Std             1.3592
evaluation/Rewards Max            -0.806025
evaluation/Rewards Min            -9.97851
evaluation/Returns Mean         -234.934
evaluation/Returns Std           113.799
evaluation/Returns Max           -81.9595
evaluation/Returns Min          -423.465
evaluation/Actions Mean            0.0204398
evaluation/Actions Std             0.167898
evaluation/Actions Max             0.997926
evaluation/Actions Min            -0.998296
evaluation/Num Paths              15
evaluation/Average Returns      -234.934
time/data storing (s)              0.00277892
time/evaluation sampling (s)       0.343758
time/exploration sampling (s)      0.142074
time/logging (s)                   0.004752
time/saving (s)                    0.00195864
time/training (s)                  1.92773
time/epoch (s)                     2.42305
time/total (s)                    72.205
Epoch                             28
-----------------------------  --------------
2019-04-22 23:54:33.775848 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                  15.9949
trainer/QF2 Loss                  15.5798
trainer/Policy Loss               89.2888
trainer/Q1 Predictions Mean      -88.2846
trainer/Q1 Predictions Std        46.7029
trainer/Q1 Predictions Max       -39.2118
trainer/Q1 Predictions Min      -190.875
trainer/Q2 Predictions Mean      -88.2638
trainer/Q2 Predictions Std        46.8704
trainer/Q2 Predictions Max       -38.9972
trainer/Q2 Predictions Min      -192.454
trainer/Q Targets Mean           -88.2536
trainer/Q Targets Std             47.544
trainer/Q Targets Max             -1.83084
trainer/Q Targets Min           -192.023
trainer/Log Pis Mean               1.92793
trainer/Log Pis Std                1.87308
trainer/Log Pis Max                9.94425
trainer/Log Pis Min               -2.76375
trainer/Policy mu Mean            -0.30662
trainer/Policy mu Std              1.00327
trainer/Policy mu Max              2.88614
trainer/Policy mu Min             -3.59423
trainer/Policy log std Mean       -1.5678
trainer/Policy log std Std         0.469039
trainer/Policy log std Max        -0.291765
trainer/Policy log std Min        -2.46699
trainer/Alpha                      0.0493055
trainer/Alpha Loss                -0.216903
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.98079
exploration/Rewards Std            1.2042
exploration/Rewards Max           -0.64008
exploration/Rewards Min           -8.59311
exploration/Returns Mean        -198.079
exploration/Returns Std           84.741
exploration/Returns Max         -109.677
exploration/Returns Min         -303.32
exploration/Actions Mean           0.0128988
exploration/Actions Std            0.247127
exploration/Actions Max            0.998603
exploration/Actions Min           -0.986761
exploration/Num Paths              5
exploration/Average Returns     -198.079
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.62335
evaluation/Rewards Std             1.64037
evaluation/Rewards Max            -0.207833
evaluation/Rewards Min           -11.0944
evaluation/Returns Mean         -262.335
evaluation/Returns Std           148.463
evaluation/Returns Max           -28.9141
evaluation/Returns Min          -649.121
evaluation/Actions Mean            0.016222
evaluation/Actions Std             0.259186
evaluation/Actions Max             0.998737
evaluation/Actions Min            -0.999445
evaluation/Num Paths              15
evaluation/Average Returns      -262.335
time/data storing (s)              0.00317071
time/evaluation sampling (s)       0.333299
time/exploration sampling (s)      0.143022
time/logging (s)                   0.00477565
time/saving (s)                    0.00196216
time/training (s)                  1.96954
time/epoch (s)                     2.45577
time/total (s)                    74.665
Epoch                             29
-----------------------------  --------------
2019-04-22 23:54:36.193309 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                  53.3006
trainer/QF2 Loss                  53.3692
trainer/Policy Loss              103.082
trainer/Q1 Predictions Mean     -102.013
trainer/Q1 Predictions Std        49.2253
trainer/Q1 Predictions Max       -40.1477
trainer/Q1 Predictions Min      -183.546
trainer/Q2 Predictions Mean     -102.011
trainer/Q2 Predictions Std        49.2086
trainer/Q2 Predictions Max       -40.1464
trainer/Q2 Predictions Min      -183.305
trainer/Q Targets Mean          -101.866
trainer/Q Targets Std             50.5961
trainer/Q Targets Max             -1.46826
trainer/Q Targets Min           -183.856
trainer/Log Pis Mean               2.00921
trainer/Log Pis Std                1.95612
trainer/Log Pis Max                7.85665
trainer/Log Pis Min               -2.3374
trainer/Policy mu Mean            -0.236209
trainer/Policy mu Std              1.09144
trainer/Policy mu Max              3.34135
trainer/Policy mu Min             -3.1019
trainer/Policy log std Mean       -1.53176
trainer/Policy log std Std         0.583028
trainer/Policy log std Max        -0.262432
trainer/Policy log std Min        -2.46196
trainer/Alpha                      0.0496152
trainer/Alpha Loss                 0.0276656
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.41926
exploration/Rewards Std            1.29632
exploration/Rewards Max           -0.858809
exploration/Rewards Min          -10.7096
exploration/Returns Mean        -241.926
exploration/Returns Std          100.766
exploration/Returns Max         -114.957
exploration/Returns Min         -327.209
exploration/Actions Mean          -0.0203244
exploration/Actions Std            0.254594
exploration/Actions Max            0.993497
exploration/Actions Min           -0.999732
exploration/Num Paths              5
exploration/Average Returns     -241.926
evaluation/num steps total     46500
evaluation/num paths total       465
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.00679
evaluation/Rewards Std             1.27699
evaluation/Rewards Max            -0.424811
evaluation/Rewards Min            -9.7468
evaluation/Returns Mean         -200.679
evaluation/Returns Std           105.821
evaluation/Returns Max           -58.4483
evaluation/Returns Min          -370.495
evaluation/Actions Mean           -0.0136457
evaluation/Actions Std             0.170364
evaluation/Actions Max             0.996318
evaluation/Actions Min            -0.999111
evaluation/Num Paths              15
evaluation/Average Returns      -200.679
time/data storing (s)              0.00289471
time/evaluation sampling (s)       0.327427
time/exploration sampling (s)      0.137423
time/logging (s)                   0.00478578
time/saving (s)                    0.00199458
time/training (s)                  1.93772
time/epoch (s)                     2.41225
time/total (s)                    77.0814
Epoch                             30
-----------------------------  --------------
2019-04-22 23:54:38.612807 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                 222.187
trainer/QF2 Loss                 221.7
trainer/Policy Loss               95.8153
trainer/Q1 Predictions Mean      -94.8437
trainer/Q1 Predictions Std        47.3537
trainer/Q1 Predictions Max       -40.2959
trainer/Q1 Predictions Min      -185.265
trainer/Q2 Predictions Mean      -94.8501
trainer/Q2 Predictions Std        47.3679
trainer/Q2 Predictions Max       -40.4115
trainer/Q2 Predictions Min      -185.472
trainer/Q Targets Mean           -94.0088
trainer/Q Targets Std             48.1308
trainer/Q Targets Max             -4.37435
trainer/Q Targets Min           -186.77
trainer/Log Pis Mean               1.85079
trainer/Log Pis Std                1.46212
trainer/Log Pis Max                5.44256
trainer/Log Pis Min               -1.53562
trainer/Policy mu Mean            -0.41855
trainer/Policy mu Std              0.769794
trainer/Policy mu Max              2.08273
trainer/Policy mu Min             -3.026
trainer/Policy log std Mean       -1.74995
trainer/Policy log std Std         0.520864
trainer/Policy log std Max        -0.339238
trainer/Policy log std Min        -2.55306
trainer/Alpha                      0.0485065
trainer/Alpha Loss                -0.451549
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.41715
exploration/Rewards Std            1.61188
exploration/Rewards Max           -0.0572204
exploration/Rewards Min          -11.507
exploration/Returns Mean        -241.715
exploration/Returns Std          119.237
exploration/Returns Max          -71.7108
exploration/Returns Min         -345.113
exploration/Actions Mean          -0.0154057
exploration/Actions Std            0.326118
exploration/Actions Max            0.99858
exploration/Actions Min           -0.999837
exploration/Num Paths              5
exploration/Average Returns     -241.715
evaluation/num steps total     48000
evaluation/num paths total       480
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.48875
evaluation/Rewards Std             1.196
evaluation/Rewards Max            -0.93032
evaluation/Rewards Min            -9.46534
evaluation/Returns Mean         -248.875
evaluation/Returns Std           105.847
evaluation/Returns Max          -111.169
evaluation/Returns Min          -474.77
evaluation/Actions Mean            0.0244373
evaluation/Actions Std             0.239988
evaluation/Actions Max             0.993994
evaluation/Actions Min            -0.998437
evaluation/Num Paths              15
evaluation/Average Returns      -248.875
time/data storing (s)              0.00315489
time/evaluation sampling (s)       0.331769
time/exploration sampling (s)      0.141219
time/logging (s)                   0.0047681
time/saving (s)                    0.0019744
time/training (s)                  1.93115
time/epoch (s)                     2.41404
time/total (s)                    79.4998
Epoch                             31
-----------------------------  --------------
2019-04-22 23:54:41.034548 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 32 finished
-----------------------------  ---------------
replay_buffer/size             16700
trainer/QF1 Loss                 237.204
trainer/QF2 Loss                 237.318
trainer/Policy Loss               89.5061
trainer/Q1 Predictions Mean      -88.6958
trainer/Q1 Predictions Std        46.2288
trainer/Q1 Predictions Max       -40.9039
trainer/Q1 Predictions Min      -187.864
trainer/Q2 Predictions Mean      -88.6907
trainer/Q2 Predictions Std        46.1747
trainer/Q2 Predictions Max       -41.0288
trainer/Q2 Predictions Min      -188.056
trainer/Q Targets Mean           -88.1539
trainer/Q Targets Std             46.548
trainer/Q Targets Max             -3.38796
trainer/Q Targets Min           -189.004
trainer/Log Pis Mean               2.01354
trainer/Log Pis Std                1.69193
trainer/Log Pis Max                6.74988
trainer/Log Pis Min               -2.50446
trainer/Policy mu Mean            -0.30797
trainer/Policy mu Std              1.02734
trainer/Policy mu Max              3.0958
trainer/Policy mu Min             -3.06088
trainer/Policy log std Mean       -1.64876
trainer/Policy log std Std         0.525269
trainer/Policy log std Max        -0.245202
trainer/Policy log std Min        -2.5084
trainer/Alpha                      0.0485087
trainer/Alpha Loss                 0.0409831
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.3288
exploration/Rewards Std            1.42562
exploration/Rewards Max           -0.15091
exploration/Rewards Min          -10.2826
exploration/Returns Mean        -232.88
exploration/Returns Std          113.196
exploration/Returns Max          -64.9028
exploration/Returns Min         -371.366
exploration/Actions Mean          -0.000444209
exploration/Actions Std            0.304887
exploration/Actions Max            0.996807
exploration/Actions Min           -0.999415
exploration/Num Paths              5
exploration/Average Returns     -232.88
evaluation/num steps total     49500
evaluation/num paths total       495
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.87931
evaluation/Rewards Std             1.27364
evaluation/Rewards Max            -0.522853
evaluation/Rewards Min            -9.64362
evaluation/Returns Mean         -187.931
evaluation/Returns Std           104.027
evaluation/Returns Max           -65.2066
evaluation/Returns Min          -390.087
evaluation/Actions Mean           -0.00709339
evaluation/Actions Std             0.178393
evaluation/Actions Max             0.99809
evaluation/Actions Min            -0.999152
evaluation/Num Paths              15
evaluation/Average Returns      -187.931
time/data storing (s)              0.00306094
time/evaluation sampling (s)       0.328807
time/exploration sampling (s)      0.1431
time/logging (s)                   0.00485418
time/saving (s)                    0.00192513
time/training (s)                  1.93463
time/epoch (s)                     2.41638
time/total (s)                    81.9204
Epoch                             32
-----------------------------  ---------------
2019-04-22 23:54:43.452547 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                  19.3479
trainer/QF2 Loss                  19.1864
trainer/Policy Loss              100.154
trainer/Q1 Predictions Mean      -99.1751
trainer/Q1 Predictions Std        51.847
trainer/Q1 Predictions Max       -42.1556
trainer/Q1 Predictions Min      -193.918
trainer/Q2 Predictions Mean      -99.1699
trainer/Q2 Predictions Std        51.9078
trainer/Q2 Predictions Max       -42.2577
trainer/Q2 Predictions Min      -195.392
trainer/Q Targets Mean           -99.5373
trainer/Q Targets Std             52.8951
trainer/Q Targets Max             -1.03768
trainer/Q Targets Min           -195.131
trainer/Log Pis Mean               1.61307
trainer/Log Pis Std                1.82184
trainer/Log Pis Max                8.98439
trainer/Log Pis Min               -3.91099
trainer/Policy mu Mean            -0.253545
trainer/Policy mu Std              0.951362
trainer/Policy mu Max              3.0379
trainer/Policy mu Min             -3.1494
trainer/Policy log std Mean       -1.68186
trainer/Policy log std Std         0.540358
trainer/Policy log std Max        -0.192515
trainer/Policy log std Min        -2.58439
trainer/Alpha                      0.0483988
trainer/Alpha Loss                -1.17168
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.06061
exploration/Rewards Std            1.35046
exploration/Rewards Max           -0.622436
exploration/Rewards Min           -9.84277
exploration/Returns Mean        -206.061
exploration/Returns Std           99.6349
exploration/Returns Max         -115.654
exploration/Returns Min         -340.251
exploration/Actions Mean           0.010725
exploration/Actions Std            0.259372
exploration/Actions Max            0.998233
exploration/Actions Min           -0.996797
exploration/Num Paths              5
exploration/Average Returns     -206.061
evaluation/num steps total     51000
evaluation/num paths total       510
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.24132
evaluation/Rewards Std             1.40187
evaluation/Rewards Max            -0.189726
evaluation/Rewards Min           -10.6222
evaluation/Returns Mean         -224.132
evaluation/Returns Std           104.933
evaluation/Returns Max           -22.7287
evaluation/Returns Min          -348.584
evaluation/Actions Mean           -0.00468332
evaluation/Actions Std             0.195657
evaluation/Actions Max             0.999448
evaluation/Actions Min            -0.999483
evaluation/Num Paths              15
evaluation/Average Returns      -224.132
time/data storing (s)              0.00308114
time/evaluation sampling (s)       0.331423
time/exploration sampling (s)      0.140953
time/logging (s)                   0.0047678
time/saving (s)                    0.0113859
time/training (s)                  1.92066
time/epoch (s)                     2.41227
time/total (s)                    84.3371
Epoch                             33
-----------------------------  --------------
2019-04-22 23:54:45.861811 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                 148.677
trainer/QF2 Loss                 148.679
trainer/Policy Loss               84.6425
trainer/Q1 Predictions Mean      -83.4676
trainer/Q1 Predictions Std        45.004
trainer/Q1 Predictions Max       -42.8261
trainer/Q1 Predictions Min      -193.188
trainer/Q2 Predictions Mean      -83.4673
trainer/Q2 Predictions Std        44.9754
trainer/Q2 Predictions Max       -42.7148
trainer/Q2 Predictions Min      -193.487
trainer/Q Targets Mean           -83.1396
trainer/Q Targets Std             46.2458
trainer/Q Targets Max             -3.21945
trainer/Q Targets Min           -195.029
trainer/Log Pis Mean               1.79571
trainer/Log Pis Std                1.52927
trainer/Log Pis Max                6.88087
trainer/Log Pis Min               -1.31612
trainer/Policy mu Mean            -0.0949426
trainer/Policy mu Std              0.981025
trainer/Policy mu Max              2.85485
trainer/Policy mu Min             -3.02483
trainer/Policy log std Mean       -1.59787
trainer/Policy log std Std         0.540791
trainer/Policy log std Max        -0.207102
trainer/Policy log std Min        -2.47974
trainer/Alpha                      0.0467491
trainer/Alpha Loss                -0.625685
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.58972
exploration/Rewards Std            1.54855
exploration/Rewards Max           -0.0496958
exploration/Rewards Min           -9.44296
exploration/Returns Mean        -158.972
exploration/Returns Std          123.168
exploration/Returns Max          -34.2664
exploration/Returns Min         -378.147
exploration/Actions Mean          -0.00531354
exploration/Actions Std            0.246104
exploration/Actions Max            0.994657
exploration/Actions Min           -0.999709
exploration/Num Paths              5
exploration/Average Returns     -158.972
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.95193
evaluation/Rewards Std             1.29507
evaluation/Rewards Max            -1.11779
evaluation/Rewards Min           -10.5295
evaluation/Returns Mean         -295.193
evaluation/Returns Std           115.421
evaluation/Returns Max          -132.369
evaluation/Returns Min          -469.47
evaluation/Actions Mean            0.00675939
evaluation/Actions Std             0.179189
evaluation/Actions Max             0.996772
evaluation/Actions Min            -0.998483
evaluation/Num Paths              15
evaluation/Average Returns      -295.193
time/data storing (s)              0.00291472
time/evaluation sampling (s)       0.329865
time/exploration sampling (s)      0.139357
time/logging (s)                   0.00475902
time/saving (s)                    0.00194777
time/training (s)                  1.92477
time/epoch (s)                     2.40361
time/total (s)                    86.7452
Epoch                             34
-----------------------------  --------------
2019-04-22 23:54:48.283174 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   2.49142
trainer/QF2 Loss                   2.5314
trainer/Policy Loss               93.9294
trainer/Q1 Predictions Mean      -92.7598
trainer/Q1 Predictions Std        49.6059
trainer/Q1 Predictions Max       -42.5228
trainer/Q1 Predictions Min      -191.448
trainer/Q2 Predictions Mean      -92.7272
trainer/Q2 Predictions Std        49.6092
trainer/Q2 Predictions Max       -42.4593
trainer/Q2 Predictions Min      -191.251
trainer/Q Targets Mean           -93.8681
trainer/Q Targets Std             50.3464
trainer/Q Targets Max            -44.0797
trainer/Q Targets Min           -195.892
trainer/Log Pis Mean               2.22069
trainer/Log Pis Std                1.63766
trainer/Log Pis Max                9.09528
trainer/Log Pis Min               -2.51489
trainer/Policy mu Mean            -0.37668
trainer/Policy mu Std              1.00596
trainer/Policy mu Max              2.93557
trainer/Policy mu Min             -3.5396
trainer/Policy log std Mean       -1.69774
trainer/Policy log std Std         0.570165
trainer/Policy log std Max         0.0170122
trainer/Policy log std Min        -2.73298
trainer/Alpha                      0.0513494
trainer/Alpha Loss                 0.655263
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.67153
exploration/Rewards Std            1.35142
exploration/Rewards Max           -0.0472566
exploration/Rewards Min           -7.39814
exploration/Returns Mean        -167.153
exploration/Returns Std          124.387
exploration/Returns Max          -24.5512
exploration/Returns Min         -399.964
exploration/Actions Mean          -0.00610059
exploration/Actions Std            0.212786
exploration/Actions Max            0.605117
exploration/Actions Min           -0.999685
exploration/Num Paths              5
exploration/Average Returns     -167.153
evaluation/num steps total     54000
evaluation/num paths total       540
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.31251
evaluation/Rewards Std             1.15985
evaluation/Rewards Max            -0.0920508
evaluation/Rewards Min            -8.63299
evaluation/Returns Mean         -231.251
evaluation/Returns Std            97.814
evaluation/Returns Max           -31.4156
evaluation/Returns Min          -421.02
evaluation/Actions Mean           -0.00257772
evaluation/Actions Std             0.176433
evaluation/Actions Max             0.999387
evaluation/Actions Min            -0.999231
evaluation/Num Paths              15
evaluation/Average Returns      -231.251
time/data storing (s)              0.00311377
time/evaluation sampling (s)       0.335614
time/exploration sampling (s)      0.138215
time/logging (s)                   0.00475696
time/saving (s)                    0.00195983
time/training (s)                  1.93206
time/epoch (s)                     2.41572
time/total (s)                    89.1654
Epoch                             35
-----------------------------  --------------
2019-04-22 23:54:50.688075 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                  25.7629
trainer/QF2 Loss                  25.7654
trainer/Policy Loss               92.8617
trainer/Q1 Predictions Mean      -91.6264
trainer/Q1 Predictions Std        49.8447
trainer/Q1 Predictions Max       -42.5519
trainer/Q1 Predictions Min      -192.727
trainer/Q2 Predictions Mean      -91.5952
trainer/Q2 Predictions Std        49.8407
trainer/Q2 Predictions Max       -42.3445
trainer/Q2 Predictions Min      -192.912
trainer/Q Targets Mean           -92.0803
trainer/Q Targets Std             50.9265
trainer/Q Targets Max             -1.5817
trainer/Q Targets Min           -194.586
trainer/Log Pis Mean               2.00489
trainer/Log Pis Std                1.74732
trainer/Log Pis Max               10.0872
trainer/Log Pis Min               -1.1268
trainer/Policy mu Mean            -0.227056
trainer/Policy mu Std              1.01681
trainer/Policy mu Max              4.30499
trainer/Policy mu Min             -2.84173
trainer/Policy log std Mean       -1.71513
trainer/Policy log std Std         0.553013
trainer/Policy log std Max        -0.530264
trainer/Policy log std Min        -2.61792
trainer/Alpha                      0.0527195
trainer/Alpha Loss                 0.0143998
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.6499
exploration/Rewards Std            1.23606
exploration/Rewards Max           -0.480276
exploration/Rewards Min           -8.61905
exploration/Returns Mean        -164.99
exploration/Returns Std           72.6725
exploration/Returns Max         -116.623
exploration/Returns Min         -308.68
exploration/Actions Mean           0.0221243
exploration/Actions Std            0.258338
exploration/Actions Max            0.999688
exploration/Actions Min           -0.998611
exploration/Num Paths              5
exploration/Average Returns     -164.99
evaluation/num steps total     55500
evaluation/num paths total       555
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.62113
evaluation/Rewards Std             0.962276
evaluation/Rewards Max            -0.808727
evaluation/Rewards Min            -9.22154
evaluation/Returns Mean         -262.113
evaluation/Returns Std            80.6558
evaluation/Returns Max          -106.183
evaluation/Returns Min          -367.044
evaluation/Actions Mean            0.00570651
evaluation/Actions Std             0.16109
evaluation/Actions Max             0.999623
evaluation/Actions Min            -0.996942
evaluation/Num Paths              15
evaluation/Average Returns      -262.113
time/data storing (s)              0.00297688
time/evaluation sampling (s)       0.334211
time/exploration sampling (s)      0.137242
time/logging (s)                   0.00478047
time/saving (s)                    0.00196324
time/training (s)                  1.91839
time/epoch (s)                     2.39956
time/total (s)                    91.5692
Epoch                             36
-----------------------------  --------------
2019-04-22 23:54:53.087598 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                  67.7061
trainer/QF2 Loss                  67.5647
trainer/Policy Loss               92.0982
trainer/Q1 Predictions Mean      -90.8998
trainer/Q1 Predictions Std        52.5515
trainer/Q1 Predictions Max       -42.4695
trainer/Q1 Predictions Min      -202.853
trainer/Q2 Predictions Mean      -90.9114
trainer/Q2 Predictions Std        52.6067
trainer/Q2 Predictions Max       -42.5891
trainer/Q2 Predictions Min      -204.819
trainer/Q Targets Mean           -90.795
trainer/Q Targets Std             54.5182
trainer/Q Targets Max             -0.891615
trainer/Q Targets Min           -203.473
trainer/Log Pis Mean               2.19144
trainer/Log Pis Std                1.73304
trainer/Log Pis Max                7.73655
trainer/Log Pis Min               -3.16961
trainer/Policy mu Mean            -0.366716
trainer/Policy mu Std              1.01941
trainer/Policy mu Max              3.13199
trainer/Policy mu Min             -3.73616
trainer/Policy log std Mean       -1.65173
trainer/Policy log std Std         0.545508
trainer/Policy log std Max        -0.188087
trainer/Policy log std Min        -2.62661
trainer/Alpha                      0.0529552
trainer/Alpha Loss                 0.562501
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.57316
exploration/Rewards Std            1.32156
exploration/Rewards Max           -0.115744
exploration/Rewards Min          -10.8885
exploration/Returns Mean        -157.316
exploration/Returns Std           77.1701
exploration/Returns Max          -76.6648
exploration/Returns Min         -295.144
exploration/Actions Mean          -0.0161256
exploration/Actions Std            0.277118
exploration/Actions Max            0.998108
exploration/Actions Min           -0.999669
exploration/Num Paths              5
exploration/Average Returns     -157.316
evaluation/num steps total     57000
evaluation/num paths total       570
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.40431
evaluation/Rewards Std             1.44532
evaluation/Rewards Max            -0.270342
evaluation/Rewards Min            -9.81313
evaluation/Returns Mean         -240.431
evaluation/Returns Std           124.407
evaluation/Returns Max           -37.1384
evaluation/Returns Min          -432.956
evaluation/Actions Mean            0.00445295
evaluation/Actions Std             0.171316
evaluation/Actions Max             0.99854
evaluation/Actions Min            -0.998561
evaluation/Num Paths              15
evaluation/Average Returns      -240.431
time/data storing (s)              0.00279735
time/evaluation sampling (s)       0.324827
time/exploration sampling (s)      0.140776
time/logging (s)                   0.00481637
time/saving (s)                    0.00207609
time/training (s)                  1.91852
time/epoch (s)                     2.39381
time/total (s)                    93.9675
Epoch                             37
-----------------------------  --------------
2019-04-22 23:54:55.508042 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                 239.761
trainer/QF2 Loss                 238.477
trainer/Policy Loss              102.587
trainer/Q1 Predictions Mean     -101.785
trainer/Q1 Predictions Std        52.1393
trainer/Q1 Predictions Max       -45.4825
trainer/Q1 Predictions Min      -201.057
trainer/Q2 Predictions Mean     -101.834
trainer/Q2 Predictions Std        52.2721
trainer/Q2 Predictions Max       -45.4535
trainer/Q2 Predictions Min      -204.956
trainer/Q Targets Mean          -100.657
trainer/Q Targets Std             53.0076
trainer/Q Targets Max             -2.85768
trainer/Q Targets Min           -205.692
trainer/Log Pis Mean               1.8735
trainer/Log Pis Std                1.59317
trainer/Log Pis Max                6.30829
trainer/Log Pis Min               -1.7607
trainer/Policy mu Mean            -0.337603
trainer/Policy mu Std              1.03348
trainer/Policy mu Max              2.97882
trainer/Policy mu Min             -3.50397
trainer/Policy log std Mean       -1.61143
trainer/Policy log std Std         0.62155
trainer/Policy log std Max        -0.0550989
trainer/Policy log std Min        -2.52446
trainer/Alpha                      0.0547205
trainer/Alpha Loss                -0.367552
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.3412
exploration/Rewards Std            1.37568
exploration/Rewards Max           -0.298047
exploration/Rewards Min           -9.71705
exploration/Returns Mean        -234.12
exploration/Returns Std          117.572
exploration/Returns Max          -83.6926
exploration/Returns Min         -397.966
exploration/Actions Mean          -0.00101053
exploration/Actions Std            0.292697
exploration/Actions Max            0.999358
exploration/Actions Min           -0.988823
exploration/Num Paths              5
exploration/Average Returns     -234.12
evaluation/num steps total     58500
evaluation/num paths total       585
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.43788
evaluation/Rewards Std             1.39544
evaluation/Rewards Max            -0.139668
evaluation/Rewards Min           -10.822
evaluation/Returns Mean         -143.788
evaluation/Returns Std            87.0263
evaluation/Returns Max           -21.0785
evaluation/Returns Min          -389.385
evaluation/Actions Mean           -0.00870347
evaluation/Actions Std             0.212683
evaluation/Actions Max             0.998582
evaluation/Actions Min            -0.998699
evaluation/Num Paths              15
evaluation/Average Returns      -143.788
time/data storing (s)              0.00306132
time/evaluation sampling (s)       0.327803
time/exploration sampling (s)      0.142094
time/logging (s)                   0.00480022
time/saving (s)                    0.00197066
time/training (s)                  1.93462
time/epoch (s)                     2.41435
time/total (s)                    96.3867
Epoch                             38
-----------------------------  --------------
2019-04-22 23:54:57.931036 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 39 finished
-----------------------------  --------------
replay_buffer/size             20200
trainer/QF1 Loss                   2.52126
trainer/QF2 Loss                   2.74423
trainer/Policy Loss               95.2275
trainer/Q1 Predictions Mean      -94.2257
trainer/Q1 Predictions Std        51.3144
trainer/Q1 Predictions Max       -43.8014
trainer/Q1 Predictions Min      -192.607
trainer/Q2 Predictions Mean      -94.2073
trainer/Q2 Predictions Std        51.308
trainer/Q2 Predictions Max       -44.0984
trainer/Q2 Predictions Min      -192.985
trainer/Q Targets Mean           -95.2798
trainer/Q Targets Std             51.957
trainer/Q Targets Max            -45.229
trainer/Q Targets Min           -196.524
trainer/Log Pis Mean               1.96653
trainer/Log Pis Std                1.56518
trainer/Log Pis Max                6.48034
trainer/Log Pis Min               -2.9286
trainer/Policy mu Mean            -0.403942
trainer/Policy mu Std              0.877998
trainer/Policy mu Max              2.90967
trainer/Policy mu Min             -3.21084
trainer/Policy log std Mean       -1.67835
trainer/Policy log std Std         0.533256
trainer/Policy log std Max        -0.0130281
trainer/Policy log std Min        -2.63584
trainer/Alpha                      0.0521278
trainer/Alpha Loss                -0.0988818
exploration/num steps total    20200
exploration/num paths total      202
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.41366
exploration/Rewards Std            1.46958
exploration/Rewards Max           -0.769889
exploration/Rewards Min           -7.75985
exploration/Returns Mean        -341.366
exploration/Returns Std          136.295
exploration/Returns Max         -122.609
exploration/Returns Min         -461.947
exploration/Actions Mean           0.00681003
exploration/Actions Std            0.270226
exploration/Actions Max            0.997291
exploration/Actions Min           -0.994779
exploration/Num Paths              5
exploration/Average Returns     -341.366
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.29633
evaluation/Rewards Std             1.02416
evaluation/Rewards Max            -0.276588
evaluation/Rewards Min            -9.16388
evaluation/Returns Mean         -229.633
evaluation/Returns Std            87.4944
evaluation/Returns Max          -105.4
evaluation/Returns Min          -444.709
evaluation/Actions Mean            0.0125009
evaluation/Actions Std             0.149434
evaluation/Actions Max             0.997344
evaluation/Actions Min            -0.993281
evaluation/Num Paths              15
evaluation/Average Returns      -229.633
time/data storing (s)              0.00301859
time/evaluation sampling (s)       0.334523
time/exploration sampling (s)      0.138085
time/logging (s)                   0.00476199
time/saving (s)                    0.0019457
time/training (s)                  1.93488
time/epoch (s)                     2.41722
time/total (s)                    98.8085
Epoch                             39
-----------------------------  --------------
2019-04-22 23:55:00.372578 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 40 finished
-----------------------------  --------------
replay_buffer/size             20700
trainer/QF1 Loss                   3.55021
trainer/QF2 Loss                   3.3796
trainer/Policy Loss               92.6844
trainer/Q1 Predictions Mean      -91.6735
trainer/Q1 Predictions Std        52.0024
trainer/Q1 Predictions Max       -44.3001
trainer/Q1 Predictions Min      -190.522
trainer/Q2 Predictions Mean      -91.7733
trainer/Q2 Predictions Std        51.9527
trainer/Q2 Predictions Max       -44.3388
trainer/Q2 Predictions Min      -190.558
trainer/Q Targets Mean           -93.1739
trainer/Q Targets Std             52.6698
trainer/Q Targets Max            -44.8366
trainer/Q Targets Min           -194.318
trainer/Log Pis Mean               2.12385
trainer/Log Pis Std                1.66134
trainer/Log Pis Max                6.40604
trainer/Log Pis Min               -1.2699
trainer/Policy mu Mean            -0.250522
trainer/Policy mu Std              1.10896
trainer/Policy mu Max              2.76993
trainer/Policy mu Min             -3.35257
trainer/Policy log std Mean       -1.57227
trainer/Policy log std Std         0.560498
trainer/Policy log std Max        -0.0555438
trainer/Policy log std Min        -2.59206
trainer/Alpha                      0.0522221
trainer/Alpha Loss                 0.365635
exploration/num steps total    20700
exploration/num paths total      207
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.11864
exploration/Rewards Std            1.62143
exploration/Rewards Max           -0.11359
exploration/Rewards Min          -10.4146
exploration/Returns Mean        -211.864
exploration/Returns Std          136.225
exploration/Returns Max          -64.5719
exploration/Returns Min         -424.044
exploration/Actions Mean          -0.00282333
exploration/Actions Std            0.275557
exploration/Actions Max            0.995256
exploration/Actions Min           -0.998124
exploration/Num Paths              5
exploration/Average Returns     -211.864
evaluation/num steps total     61500
evaluation/num paths total       615
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.57448
evaluation/Rewards Std             1.17694
evaluation/Rewards Max            -0.24443
evaluation/Rewards Min           -10.4017
evaluation/Returns Mean         -157.448
evaluation/Returns Std            77.557
evaluation/Returns Max           -35.1866
evaluation/Returns Min          -271.69
evaluation/Actions Mean           -0.014531
evaluation/Actions Std             0.170332
evaluation/Actions Max             0.997238
evaluation/Actions Min            -0.999715
evaluation/Num Paths              15
evaluation/Average Returns      -157.448
time/data storing (s)              0.00299209
time/evaluation sampling (s)       0.337859
time/exploration sampling (s)      0.144462
time/logging (s)                   0.00476975
time/saving (s)                    0.00196247
time/training (s)                  1.94392
time/epoch (s)                     2.43596
time/total (s)                   101.249
Epoch                             40
-----------------------------  --------------
2019-04-22 23:55:02.796824 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 41 finished
-----------------------------  --------------
replay_buffer/size             21200
trainer/QF1 Loss                 355.855
trainer/QF2 Loss                 355.118
trainer/Policy Loss               99.642
trainer/Q1 Predictions Mean      -98.5707
trainer/Q1 Predictions Std        52.9788
trainer/Q1 Predictions Max       -43.7362
trainer/Q1 Predictions Min      -193.318
trainer/Q2 Predictions Mean      -98.5387
trainer/Q2 Predictions Std        52.9177
trainer/Q2 Predictions Max       -43.5395
trainer/Q2 Predictions Min      -193.373
trainer/Q Targets Mean           -96.9059
trainer/Q Targets Std             54.0518
trainer/Q Targets Max             -1.95495
trainer/Q Targets Min           -195.365
trainer/Log Pis Mean               1.94107
trainer/Log Pis Std                1.50676
trainer/Log Pis Max                5.8474
trainer/Log Pis Min               -2.35922
trainer/Policy mu Mean            -0.411434
trainer/Policy mu Std              0.916562
trainer/Policy mu Max              2.23836
trainer/Policy mu Min             -2.67031
trainer/Policy log std Mean       -1.68937
trainer/Policy log std Std         0.54838
trainer/Policy log std Max        -0.458826
trainer/Policy log std Min        -2.64337
trainer/Alpha                      0.051598
trainer/Alpha Loss                -0.17467
exploration/num steps total    21200
exploration/num paths total      212
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.93545
exploration/Rewards Std            1.42144
exploration/Rewards Max           -0.229025
exploration/Rewards Min           -9.29338
exploration/Returns Mean        -293.545
exploration/Returns Std          116.526
exploration/Returns Max          -89.7683
exploration/Returns Min         -453.04
exploration/Actions Mean           0.0102207
exploration/Actions Std            0.252198
exploration/Actions Max            0.994217
exploration/Actions Min           -0.993433
exploration/Num Paths              5
exploration/Average Returns     -293.545
evaluation/num steps total     63000
evaluation/num paths total       630
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.23323
evaluation/Rewards Std             1.5304
evaluation/Rewards Max            -0.0920799
evaluation/Rewards Min            -9.59909
evaluation/Returns Mean         -223.323
evaluation/Returns Std           136.613
evaluation/Returns Max           -19.401
evaluation/Returns Min          -480.377
evaluation/Actions Mean            0.0158436
evaluation/Actions Std             0.166982
evaluation/Actions Max             0.996916
evaluation/Actions Min            -0.998839
evaluation/Num Paths              15
evaluation/Average Returns      -223.323
time/data storing (s)              0.00304424
time/evaluation sampling (s)       0.333446
time/exploration sampling (s)      0.145259
time/logging (s)                   0.00479201
time/saving (s)                    0.00192941
time/training (s)                  1.93104
time/epoch (s)                     2.41951
time/total (s)                   103.672
Epoch                             41
-----------------------------  --------------
2019-04-22 23:55:05.221001 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 42 finished
-----------------------------  --------------
replay_buffer/size             21700
trainer/QF1 Loss                  30.3227
trainer/QF2 Loss                  30.6016
trainer/Policy Loss               95.3767
trainer/Q1 Predictions Mean      -94.2336
trainer/Q1 Predictions Std        52.0632
trainer/Q1 Predictions Max       -42.1414
trainer/Q1 Predictions Min      -190.494
trainer/Q2 Predictions Mean      -94.1741
trainer/Q2 Predictions Std        52.0295
trainer/Q2 Predictions Max       -42.4399
trainer/Q2 Predictions Min      -190.989
trainer/Q Targets Mean           -94.7987
trainer/Q Targets Std             53.4162
trainer/Q Targets Max             -0.950568
trainer/Q Targets Min           -193.186
trainer/Log Pis Mean               1.96283
trainer/Log Pis Std                1.61133
trainer/Log Pis Max                5.97972
trainer/Log Pis Min               -4.25407
trainer/Policy mu Mean            -0.238926
trainer/Policy mu Std              0.858839
trainer/Policy mu Max              1.9537
trainer/Policy mu Min             -2.87773
trainer/Policy log std Mean       -1.79375
trainer/Policy log std Std         0.523907
trainer/Policy log std Max        -0.378843
trainer/Policy log std Min        -2.70682
trainer/Alpha                      0.0510572
trainer/Alpha Loss                -0.110576
exploration/num steps total    21700
exploration/num paths total      217
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.98824
exploration/Rewards Std            1.23874
exploration/Rewards Max           -0.0213999
exploration/Rewards Min           -7.89253
exploration/Returns Mean        -198.824
exploration/Returns Std          114.81
exploration/Returns Max          -25.8288
exploration/Returns Min         -318.49
exploration/Actions Mean           0.017393
exploration/Actions Std            0.23745
exploration/Actions Max            0.979275
exploration/Actions Min           -0.963365
exploration/Num Paths              5
exploration/Average Returns     -198.824
evaluation/num steps total     64500
evaluation/num paths total       645
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.55478
evaluation/Rewards Std             1.59086
evaluation/Rewards Max            -0.0996268
evaluation/Rewards Min           -11.1839
evaluation/Returns Mean         -155.478
evaluation/Returns Std           125.908
evaluation/Returns Max           -24.4097
evaluation/Returns Min          -415.408
evaluation/Actions Mean            0.00620235
evaluation/Actions Std             0.18108
evaluation/Actions Max             0.999261
evaluation/Actions Min            -0.998544
evaluation/Num Paths              15
evaluation/Average Returns      -155.478
time/data storing (s)              0.00287096
time/evaluation sampling (s)       0.337737
time/exploration sampling (s)      0.143104
time/logging (s)                   0.00479627
time/saving (s)                    0.00194816
time/training (s)                  1.92834
time/epoch (s)                     2.41879
time/total (s)                   106.095
Epoch                             42
-----------------------------  --------------
2019-04-22 23:55:07.666258 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 43 finished
-----------------------------  ---------------
replay_buffer/size             22200
trainer/QF1 Loss                  83.1986
trainer/QF2 Loss                  83.8919
trainer/Policy Loss               99.6891
trainer/Q1 Predictions Mean      -98.6978
trainer/Q1 Predictions Std        50.3246
trainer/Q1 Predictions Max       -42.8552
trainer/Q1 Predictions Min      -192.412
trainer/Q2 Predictions Mean      -98.718
trainer/Q2 Predictions Std        50.3749
trainer/Q2 Predictions Max       -42.8691
trainer/Q2 Predictions Min      -192.54
trainer/Q Targets Mean           -98.4414
trainer/Q Targets Std             51.8487
trainer/Q Targets Max             -2.41306
trainer/Q Targets Min           -195.233
trainer/Log Pis Mean               1.98412
trainer/Log Pis Std                1.64931
trainer/Log Pis Max                7.9322
trainer/Log Pis Min               -1.32939
trainer/Policy mu Mean            -0.0971292
trainer/Policy mu Std              0.975077
trainer/Policy mu Max              3.64187
trainer/Policy mu Min             -3.06357
trainer/Policy log std Mean       -1.7363
trainer/Policy log std Std         0.514259
trainer/Policy log std Max        -0.566495
trainer/Policy log std Min        -2.6829
trainer/Alpha                      0.0499971
trainer/Alpha Loss                -0.0475574
exploration/num steps total    22200
exploration/num paths total      222
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -3.1016
exploration/Rewards Std            1.73861
exploration/Rewards Max           -0.0386222
exploration/Rewards Min           -9.97842
exploration/Returns Mean        -310.16
exploration/Returns Std          152.548
exploration/Returns Max          -45.7661
exploration/Returns Min         -467.865
exploration/Actions Mean           0.0101675
exploration/Actions Std            0.281265
exploration/Actions Max            0.998611
exploration/Actions Min           -0.997736
exploration/Num Paths              5
exploration/Average Returns     -310.16
evaluation/num steps total     66000
evaluation/num paths total       660
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.86887
evaluation/Rewards Std             1.63563
evaluation/Rewards Max            -0.0372519
evaluation/Rewards Min           -10.2259
evaluation/Returns Mean         -186.887
evaluation/Returns Std           141.763
evaluation/Returns Max           -29.7213
evaluation/Returns Min          -470.119
evaluation/Actions Mean            0.000853003
evaluation/Actions Std             0.189822
evaluation/Actions Max             0.997897
evaluation/Actions Min            -0.999152
evaluation/Num Paths              15
evaluation/Average Returns      -186.887
time/data storing (s)              0.00313244
time/evaluation sampling (s)       0.33304
time/exploration sampling (s)      0.143626
time/logging (s)                   0.00478917
time/saving (s)                    0.00160071
time/training (s)                  1.95366
time/epoch (s)                     2.43985
time/total (s)                   108.539
Epoch                             43
-----------------------------  ---------------
2019-04-22 23:55:10.398900 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 44 finished
-----------------------------  --------------
replay_buffer/size             22700
trainer/QF1 Loss                   2.42194
trainer/QF2 Loss                   2.44379
trainer/Policy Loss              103.483
trainer/Q1 Predictions Mean     -102.182
trainer/Q1 Predictions Std        55.6549
trainer/Q1 Predictions Max       -41.2641
trainer/Q1 Predictions Min      -192.257
trainer/Q2 Predictions Mean     -102.139
trainer/Q2 Predictions Std        55.7109
trainer/Q2 Predictions Max       -41.2182
trainer/Q2 Predictions Min      -192.187
trainer/Q Targets Mean          -103.298
trainer/Q Targets Std             56.2308
trainer/Q Targets Max            -41.5501
trainer/Q Targets Min           -193.309
trainer/Log Pis Mean               2.30922
trainer/Log Pis Std                1.68976
trainer/Log Pis Max                7.66081
trainer/Log Pis Min               -0.220045
trainer/Policy mu Mean            -0.425385
trainer/Policy mu Std              1.0919
trainer/Policy mu Max              2.50708
trainer/Policy mu Min             -3.13375
trainer/Policy log std Mean       -1.62901
trainer/Policy log std Std         0.611018
trainer/Policy log std Max        -0.20505
trainer/Policy log std Min        -2.65558
trainer/Alpha                      0.0505727
trainer/Alpha Loss                 0.92289
exploration/num steps total    22700
exploration/num paths total      227
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.61132
exploration/Rewards Std            1.69461
exploration/Rewards Max           -0.0168708
exploration/Rewards Min          -10.4133
exploration/Returns Mean        -161.132
exploration/Returns Std          127.078
exploration/Returns Max          -40.5209
exploration/Returns Min         -371.85
exploration/Actions Mean          -0.0326273
exploration/Actions Std            0.30581
exploration/Actions Max            0.998359
exploration/Actions Min           -0.999941
exploration/Num Paths              5
exploration/Average Returns     -161.132
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.19883
evaluation/Rewards Std             1.142
evaluation/Rewards Max            -0.614289
evaluation/Rewards Min            -8.74254
evaluation/Returns Mean         -219.883
evaluation/Returns Std            88.0897
evaluation/Returns Max           -92.2185
evaluation/Returns Min          -365.641
evaluation/Actions Mean           -0.0106957
evaluation/Actions Std             0.180059
evaluation/Actions Max             0.998369
evaluation/Actions Min            -0.99944
evaluation/Num Paths              15
evaluation/Average Returns      -219.883
time/data storing (s)              0.00319227
time/evaluation sampling (s)       0.332568
time/exploration sampling (s)      0.15395
time/logging (s)                   0.00417505
time/saving (s)                    0.00195289
time/training (s)                  2.23159
time/epoch (s)                     2.72743
time/total (s)                   111.27
Epoch                             44
-----------------------------  --------------
2019-04-22 23:55:13.068406 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 45 finished
-----------------------------  --------------
replay_buffer/size             23200
trainer/QF1 Loss                  64.7235
trainer/QF2 Loss                  64.8349
trainer/Policy Loss               92.9505
trainer/Q1 Predictions Mean      -92.0123
trainer/Q1 Predictions Std        49.2705
trainer/Q1 Predictions Max       -39.873
trainer/Q1 Predictions Min      -190.292
trainer/Q2 Predictions Mean      -92.052
trainer/Q2 Predictions Std        49.2372
trainer/Q2 Predictions Max       -39.8889
trainer/Q2 Predictions Min      -190.317
trainer/Q Targets Mean           -90.7387
trainer/Q Targets Std             51.3426
trainer/Q Targets Max             -0.442232
trainer/Q Targets Min           -191.642
trainer/Log Pis Mean               2.22342
trainer/Log Pis Std                1.61322
trainer/Log Pis Max                6.75126
trainer/Log Pis Min               -3.77764
trainer/Policy mu Mean            -0.405374
trainer/Policy mu Std              0.976045
trainer/Policy mu Max              3.11167
trainer/Policy mu Min             -3.38582
trainer/Policy log std Mean       -1.75022
trainer/Policy log std Std         0.601816
trainer/Policy log std Max        -0.278767
trainer/Policy log std Min        -2.72485
trainer/Alpha                      0.0545182
trainer/Alpha Loss                 0.649991
exploration/num steps total    23200
exploration/num paths total      232
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.98048
exploration/Rewards Std            0.699157
exploration/Rewards Max           -0.997987
exploration/Rewards Min           -7.06442
exploration/Returns Mean        -198.048
exploration/Returns Std           56.2545
exploration/Returns Max         -144.418
exploration/Returns Min         -306.627
exploration/Actions Mean          -0.0033421
exploration/Actions Std            0.217412
exploration/Actions Max            0.958914
exploration/Actions Min           -0.99742
exploration/Num Paths              5
exploration/Average Returns     -198.048
evaluation/num steps total     69000
evaluation/num paths total       690
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.31259
evaluation/Rewards Std             1.04452
evaluation/Rewards Max            -0.374975
evaluation/Rewards Min            -9.37021
evaluation/Returns Mean         -231.259
evaluation/Returns Std            77.6107
evaluation/Returns Max           -81.2159
evaluation/Returns Min          -376.864
evaluation/Actions Mean           -0.0211207
evaluation/Actions Std             0.188817
evaluation/Actions Max             0.99873
evaluation/Actions Min            -0.999153
evaluation/Num Paths              15
evaluation/Average Returns      -231.259
time/data storing (s)              0.00292039
time/evaluation sampling (s)       0.347871
time/exploration sampling (s)      0.153107
time/logging (s)                   0.00496822
time/saving (s)                    0.00160491
time/training (s)                  2.15478
time/epoch (s)                     2.66525
time/total (s)                   113.939
Epoch                             45
-----------------------------  --------------
2019-04-22 23:55:15.712211 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 46 finished
-----------------------------  --------------
replay_buffer/size             23700
trainer/QF1 Loss                  95.2752
trainer/QF2 Loss                  95.3383
trainer/Policy Loss               88.3223
trainer/Q1 Predictions Mean      -86.9436
trainer/Q1 Predictions Std        49.4234
trainer/Q1 Predictions Max       -39.2323
trainer/Q1 Predictions Min      -192.58
trainer/Q2 Predictions Mean      -86.889
trainer/Q2 Predictions Std        49.4671
trainer/Q2 Predictions Max       -39.0427
trainer/Q2 Predictions Min      -191.549
trainer/Q Targets Mean           -87.1167
trainer/Q Targets Std             50.9409
trainer/Q Targets Max             -2.46329
trainer/Q Targets Min           -192.676
trainer/Log Pis Mean               2.01971
trainer/Log Pis Std                1.60472
trainer/Log Pis Max                6.44716
trainer/Log Pis Min               -2.22248
trainer/Policy mu Mean            -0.392144
trainer/Policy mu Std              0.949143
trainer/Policy mu Max              1.85288
trainer/Policy mu Min             -3.78318
trainer/Policy log std Mean       -1.70961
trainer/Policy log std Std         0.636718
trainer/Policy log std Max        -0.115718
trainer/Policy log std Min        -2.67685
trainer/Alpha                      0.0573236
trainer/Alpha Loss                 0.0563421
exploration/num steps total    23700
exploration/num paths total      237
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.97906
exploration/Rewards Std            1.16236
exploration/Rewards Max           -0.0285214
exploration/Rewards Min           -9.88099
exploration/Returns Mean        -197.906
exploration/Returns Std           89.3348
exploration/Returns Max          -34.7176
exploration/Returns Min         -290.879
exploration/Actions Mean          -0.00705151
exploration/Actions Std            0.221094
exploration/Actions Max            0.990827
exploration/Actions Min           -0.999556
exploration/Num Paths              5
exploration/Average Returns     -197.906
evaluation/num steps total     70500
evaluation/num paths total       705
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.50349
evaluation/Rewards Std             1.44521
evaluation/Rewards Max            -0.387964
evaluation/Rewards Min           -10.0127
evaluation/Returns Mean         -250.349
evaluation/Returns Std           119.436
evaluation/Returns Max           -82.1629
evaluation/Returns Min          -511.432
evaluation/Actions Mean            0.0108401
evaluation/Actions Std             0.172551
evaluation/Actions Max             0.998658
evaluation/Actions Min            -0.99646
evaluation/Num Paths              15
evaluation/Average Returns      -250.349
time/data storing (s)              0.00340278
time/evaluation sampling (s)       0.343932
time/exploration sampling (s)      0.14885
time/logging (s)                   0.00492685
time/saving (s)                    0.00196659
time/training (s)                  2.13452
time/epoch (s)                     2.63759
time/total (s)                   116.581
Epoch                             46
-----------------------------  --------------
2019-04-22 23:55:18.121446 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 47 finished
-----------------------------  --------------
replay_buffer/size             24200
trainer/QF1 Loss                 329.231
trainer/QF2 Loss                 329.089
trainer/Policy Loss               88.5146
trainer/Q1 Predictions Mean      -87.3099
trainer/Q1 Predictions Std        50.1441
trainer/Q1 Predictions Max       -38.317
trainer/Q1 Predictions Min      -188.224
trainer/Q2 Predictions Mean      -87.3848
trainer/Q2 Predictions Std        50.1328
trainer/Q2 Predictions Max       -38.075
trainer/Q2 Predictions Min      -188.942
trainer/Q Targets Mean           -86.585
trainer/Q Targets Std             50.3762
trainer/Q Targets Max             -6.34097
trainer/Q Targets Min           -191.676
trainer/Log Pis Mean               2.12962
trainer/Log Pis Std                1.54285
trainer/Log Pis Max                5.38347
trainer/Log Pis Min               -2.56727
trainer/Policy mu Mean            -0.308634
trainer/Policy mu Std              0.998524
trainer/Policy mu Max              2.8744
trainer/Policy mu Min             -3.01447
trainer/Policy log std Mean       -1.58981
trainer/Policy log std Std         0.591632
trainer/Policy log std Max        -0.251489
trainer/Policy log std Min        -2.71093
trainer/Alpha                      0.0542925
trainer/Alpha Loss                 0.377616
exploration/num steps total    24200
exploration/num paths total      242
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.36819
exploration/Rewards Std            1.50449
exploration/Rewards Max           -0.0391564
exploration/Rewards Min          -10.0245
exploration/Returns Mean        -136.819
exploration/Returns Std           85.2298
exploration/Returns Max          -63.8335
exploration/Returns Min         -266.781
exploration/Actions Mean           0.00967178
exploration/Actions Std            0.265507
exploration/Actions Max            0.99904
exploration/Actions Min           -0.999647
exploration/Num Paths              5
exploration/Average Returns     -136.819
evaluation/num steps total     72000
evaluation/num paths total       720
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.84512
evaluation/Rewards Std             1.10191
evaluation/Rewards Max            -0.177502
evaluation/Rewards Min            -8.30154
evaluation/Returns Mean         -184.512
evaluation/Returns Std            97.4925
evaluation/Returns Max           -38.4797
evaluation/Returns Min          -365.542
evaluation/Actions Mean            0.00915541
evaluation/Actions Std             0.155805
evaluation/Actions Max             0.994013
evaluation/Actions Min            -0.997994
evaluation/Num Paths              15
evaluation/Average Returns      -184.512
time/data storing (s)              0.00289951
time/evaluation sampling (s)       0.333578
time/exploration sampling (s)      0.139969
time/logging (s)                   0.00485454
time/saving (s)                    0.00193993
time/training (s)                  1.92011
time/epoch (s)                     2.40335
time/total (s)                   118.989
Epoch                             47
-----------------------------  --------------
2019-04-22 23:55:20.533027 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 48 finished
-----------------------------  --------------
replay_buffer/size             24700
trainer/QF1 Loss                   1.12427
trainer/QF2 Loss                   1.34393
trainer/Policy Loss               93.2217
trainer/Q1 Predictions Mean      -92.0332
trainer/Q1 Predictions Std        46.8464
trainer/Q1 Predictions Max       -38.0302
trainer/Q1 Predictions Min      -186.024
trainer/Q2 Predictions Mean      -92.0075
trainer/Q2 Predictions Std        46.8631
trainer/Q2 Predictions Max       -38.085
trainer/Q2 Predictions Min      -185.597
trainer/Q Targets Mean           -92.1766
trainer/Q Targets Std             47.1176
trainer/Q Targets Max            -37.5597
trainer/Q Targets Min           -186.211
trainer/Log Pis Mean               2.23494
trainer/Log Pis Std                1.65308
trainer/Log Pis Max                6.88735
trainer/Log Pis Min               -2.46472
trainer/Policy mu Mean            -0.457969
trainer/Policy mu Std              1.13661
trainer/Policy mu Max              3.40443
trainer/Policy mu Min             -3.5878
trainer/Policy log std Mean       -1.60401
trainer/Policy log std Std         0.650224
trainer/Policy log std Max         0.0987464
trainer/Policy log std Min        -2.67912
trainer/Alpha                      0.0563714
trainer/Alpha Loss                 0.675692
exploration/num steps total    24700
exploration/num paths total      247
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.80922
exploration/Rewards Std            1.52157
exploration/Rewards Max           -0.0476614
exploration/Rewards Min           -9.48632
exploration/Returns Mean        -180.922
exploration/Returns Std          127.004
exploration/Returns Max          -40.7029
exploration/Returns Min         -372.281
exploration/Actions Mean          -0.0162164
exploration/Actions Std            0.227585
exploration/Actions Max            0.99495
exploration/Actions Min           -0.999776
exploration/Num Paths              5
exploration/Average Returns     -180.922
evaluation/num steps total     73500
evaluation/num paths total       735
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.39985
evaluation/Rewards Std             1.67435
evaluation/Rewards Max            -0.189695
evaluation/Rewards Min            -9.55527
evaluation/Returns Mean         -239.985
evaluation/Returns Std           157.814
evaluation/Returns Max           -31.317
evaluation/Returns Min          -526.69
evaluation/Actions Mean           -0.0144308
evaluation/Actions Std             0.169348
evaluation/Actions Max             0.997162
evaluation/Actions Min            -0.998894
evaluation/Num Paths              15
evaluation/Average Returns      -239.985
time/data storing (s)              0.00309655
time/evaluation sampling (s)       0.32606
time/exploration sampling (s)      0.143348
time/logging (s)                   0.00479204
time/saving (s)                    0.00197691
time/training (s)                  1.92635
time/epoch (s)                     2.40562
time/total (s)                   121.399
Epoch                             48
-----------------------------  --------------
2019-04-22 23:55:22.957528 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 49 finished
-----------------------------  --------------
replay_buffer/size             25200
trainer/QF1 Loss                  47.854
trainer/QF2 Loss                  47.5462
trainer/Policy Loss               90.6999
trainer/Q1 Predictions Mean      -89.2963
trainer/Q1 Predictions Std        50.7192
trainer/Q1 Predictions Max       -36.0348
trainer/Q1 Predictions Min      -186.951
trainer/Q2 Predictions Mean      -89.2518
trainer/Q2 Predictions Std        50.6159
trainer/Q2 Predictions Max       -36.1515
trainer/Q2 Predictions Min      -186.671
trainer/Q Targets Mean           -89.2323
trainer/Q Targets Std             52.2486
trainer/Q Targets Max             -1.22975
trainer/Q Targets Min           -186.468
trainer/Log Pis Mean               2.28251
trainer/Log Pis Std                1.27871
trainer/Log Pis Max                5.61074
trainer/Log Pis Min               -1.51939
trainer/Policy mu Mean            -0.354579
trainer/Policy mu Std              0.979217
trainer/Policy mu Max              2.82922
trainer/Policy mu Min             -3.08099
trainer/Policy log std Mean       -1.75156
trainer/Policy log std Std         0.582036
trainer/Policy log std Max        -0.308725
trainer/Policy log std Min        -2.73714
trainer/Alpha                      0.0593872
trainer/Alpha Loss                 0.797796
exploration/num steps total    25200
exploration/num paths total      252
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.92706
exploration/Rewards Std            1.1774
exploration/Rewards Max           -0.497133
exploration/Rewards Min           -7.01736
exploration/Returns Mean        -192.706
exploration/Returns Std          110.875
exploration/Returns Max          -64.5426
exploration/Returns Min         -328.043
exploration/Actions Mean           0.0103628
exploration/Actions Std            0.209667
exploration/Actions Max            0.998224
exploration/Actions Min           -0.935948
exploration/Num Paths              5
exploration/Average Returns     -192.706
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.27767
evaluation/Rewards Std             1.99503
evaluation/Rewards Max            -0.165132
evaluation/Rewards Min           -11.2181
evaluation/Returns Mean         -227.767
evaluation/Returns Std           180.098
evaluation/Returns Max           -41.9405
evaluation/Returns Min          -601.714
evaluation/Actions Mean           -0.0425315
evaluation/Actions Std             0.231137
evaluation/Actions Max             0.997012
evaluation/Actions Min            -0.999641
evaluation/Num Paths              15
evaluation/Average Returns      -227.767
time/data storing (s)              0.0031973
time/evaluation sampling (s)       0.333455
time/exploration sampling (s)      0.141904
time/logging (s)                   0.0046868
time/saving (s)                    0.00198261
time/training (s)                  1.93348
time/epoch (s)                     2.41871
time/total (s)                   123.822
Epoch                             49
-----------------------------  --------------
2019-04-22 23:55:25.352596 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 50 finished
-----------------------------  --------------
replay_buffer/size             25700
trainer/QF1 Loss                   1.97685
trainer/QF2 Loss                   2.14155
trainer/Policy Loss               90.7428
trainer/Q1 Predictions Mean      -89.7517
trainer/Q1 Predictions Std        51.7754
trainer/Q1 Predictions Max       -36.388
trainer/Q1 Predictions Min      -181.566
trainer/Q2 Predictions Mean      -89.6672
trainer/Q2 Predictions Std        51.8067
trainer/Q2 Predictions Max       -36.4021
trainer/Q2 Predictions Min      -181.533
trainer/Q Targets Mean           -90.6659
trainer/Q Targets Std             52.1509
trainer/Q Targets Max            -35.6696
trainer/Q Targets Min           -184.026
trainer/Log Pis Mean               1.8705
trainer/Log Pis Std                1.34189
trainer/Log Pis Max                5.64475
trainer/Log Pis Min               -2.19893
trainer/Policy mu Mean            -0.361739
trainer/Policy mu Std              0.86201
trainer/Policy mu Max              1.69772
trainer/Policy mu Min             -2.90221
trainer/Policy log std Mean       -1.72224
trainer/Policy log std Std         0.559559
trainer/Policy log std Max        -0.381964
trainer/Policy log std Min        -2.57552
trainer/Alpha                      0.0596653
trainer/Alpha Loss                -0.365054
exploration/num steps total    25700
exploration/num paths total      257
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.11493
exploration/Rewards Std            0.797215
exploration/Rewards Max           -0.0225151
exploration/Rewards Min           -6.87524
exploration/Returns Mean        -111.493
exploration/Returns Std           59.39
exploration/Returns Max          -37.8825
exploration/Returns Min         -167.345
exploration/Actions Mean          -0.020241
exploration/Actions Std            0.22872
exploration/Actions Max            0.861478
exploration/Actions Min           -0.999358
exploration/Num Paths              5
exploration/Average Returns     -111.493
evaluation/num steps total     76500
evaluation/num paths total       765
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.32724
evaluation/Rewards Std             1.41312
evaluation/Rewards Max            -0.0537484
evaluation/Rewards Min           -10.8135
evaluation/Returns Mean         -132.724
evaluation/Returns Std           108.037
evaluation/Returns Max            -6.03679
evaluation/Returns Min          -323.487
evaluation/Actions Mean           -0.0176211
evaluation/Actions Std             0.189433
evaluation/Actions Max             0.997962
evaluation/Actions Min            -0.999428
evaluation/Num Paths              15
evaluation/Average Returns      -132.724
time/data storing (s)              0.00303416
time/evaluation sampling (s)       0.335501
time/exploration sampling (s)      0.139466
time/logging (s)                   0.00477944
time/saving (s)                    0.00212182
time/training (s)                  1.90454
time/epoch (s)                     2.38944
time/total (s)                   126.216
Epoch                             50
-----------------------------  --------------
2019-04-22 23:55:27.760446 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 51 finished
-----------------------------  --------------
replay_buffer/size             26200
trainer/QF1 Loss                 259.702
trainer/QF2 Loss                 259.87
trainer/Policy Loss              101.98
trainer/Q1 Predictions Mean     -101.115
trainer/Q1 Predictions Std        51.5343
trainer/Q1 Predictions Max       -34.7955
trainer/Q1 Predictions Min      -180.151
trainer/Q2 Predictions Mean     -101.101
trainer/Q2 Predictions Std        51.4765
trainer/Q2 Predictions Max       -35.0004
trainer/Q2 Predictions Min      -179.871
trainer/Q Targets Mean          -100.022
trainer/Q Targets Std             53.0418
trainer/Q Targets Max             -0.417776
trainer/Q Targets Min           -183.691
trainer/Log Pis Mean               1.71352
trainer/Log Pis Std                1.46563
trainer/Log Pis Max                5.84334
trainer/Log Pis Min               -3.02077
trainer/Policy mu Mean            -0.325019
trainer/Policy mu Std              0.864297
trainer/Policy mu Max              3.52503
trainer/Policy mu Min             -2.58208
trainer/Policy log std Mean       -1.75196
trainer/Policy log std Std         0.537097
trainer/Policy log std Max        -0.533476
trainer/Policy log std Min        -2.68232
trainer/Alpha                      0.0562313
trainer/Alpha Loss                -0.824505
exploration/num steps total    26200
exploration/num paths total      262
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.62344
exploration/Rewards Std            1.27589
exploration/Rewards Max           -0.0056829
exploration/Rewards Min          -10.1807
exploration/Returns Mean        -162.344
exploration/Returns Std          101.41
exploration/Returns Max          -16.0283
exploration/Returns Min         -320.671
exploration/Actions Mean           0.0134835
exploration/Actions Std            0.204109
exploration/Actions Max            0.99868
exploration/Actions Min           -0.999338
exploration/Num Paths              5
exploration/Average Returns     -162.344
evaluation/num steps total     78000
evaluation/num paths total       780
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.22276
evaluation/Rewards Std             1.2183
evaluation/Rewards Max            -0.0113607
evaluation/Rewards Min            -8.93925
evaluation/Returns Mean         -222.276
evaluation/Returns Std           101.778
evaluation/Returns Max           -24.4308
evaluation/Returns Min          -320.076
evaluation/Actions Mean           -0.00223189
evaluation/Actions Std             0.174864
evaluation/Actions Max             0.998546
evaluation/Actions Min            -0.999529
evaluation/Num Paths              15
evaluation/Average Returns      -222.276
time/data storing (s)              0.00298556
time/evaluation sampling (s)       0.335867
time/exploration sampling (s)      0.140926
time/logging (s)                   0.00479163
time/saving (s)                    0.001993
time/training (s)                  1.91553
time/epoch (s)                     2.40209
time/total (s)                   128.622
Epoch                             51
-----------------------------  --------------
2019-04-22 23:55:30.178085 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 52 finished
-----------------------------  --------------
replay_buffer/size             26700
trainer/QF1 Loss                   1.46202
trainer/QF2 Loss                   1.61138
trainer/Policy Loss               82.0298
trainer/Q1 Predictions Mean      -80.609
trainer/Q1 Predictions Std        47.6395
trainer/Q1 Predictions Max       -33.1928
trainer/Q1 Predictions Min      -179.258
trainer/Q2 Predictions Mean      -80.5845
trainer/Q2 Predictions Std        47.6168
trainer/Q2 Predictions Max       -33.3316
trainer/Q2 Predictions Min      -179.323
trainer/Q Targets Mean           -81.3987
trainer/Q Targets Std             48.1956
trainer/Q Targets Max            -33.6276
trainer/Q Targets Min           -181.709
trainer/Log Pis Mean               1.9852
trainer/Log Pis Std                1.5027
trainer/Log Pis Max                7.63004
trainer/Log Pis Min               -1.58202
trainer/Policy mu Mean            -0.319475
trainer/Policy mu Std              0.846084
trainer/Policy mu Max              3.16316
trainer/Policy mu Min             -2.88729
trainer/Policy log std Mean       -1.85894
trainer/Policy log std Std         0.549368
trainer/Policy log std Max        -0.473185
trainer/Policy log std Min        -2.65018
trainer/Alpha                      0.058356
trainer/Alpha Loss                -0.042044
exploration/num steps total    26700
exploration/num paths total      267
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.70133
exploration/Rewards Std            1.17948
exploration/Rewards Max           -0.145501
exploration/Rewards Min           -9.0808
exploration/Returns Mean        -170.133
exploration/Returns Std           89.1969
exploration/Returns Max          -88.5631
exploration/Returns Min         -320.525
exploration/Actions Mean           0.00604779
exploration/Actions Std            0.212094
exploration/Actions Max            0.999595
exploration/Actions Min           -0.994729
exploration/Num Paths              5
exploration/Average Returns     -170.133
evaluation/num steps total     79500
evaluation/num paths total       795
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.99996
evaluation/Rewards Std             1.70811
evaluation/Rewards Max            -0.374945
evaluation/Rewards Min            -8.8515
evaluation/Returns Mean         -199.996
evaluation/Returns Std           155.829
evaluation/Returns Max           -51.9153
evaluation/Returns Min          -534.269
evaluation/Actions Mean            0.00214971
evaluation/Actions Std             0.176402
evaluation/Actions Max             0.995625
evaluation/Actions Min            -0.999196
evaluation/Num Paths              15
evaluation/Average Returns      -199.996
time/data storing (s)              0.00296153
time/evaluation sampling (s)       0.330154
time/exploration sampling (s)      0.140291
time/logging (s)                   0.0048726
time/saving (s)                    0.00195539
time/training (s)                  1.93171
time/epoch (s)                     2.41194
time/total (s)                   131.039
Epoch                             52
-----------------------------  --------------
2019-04-22 23:55:32.591001 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 53 finished
-----------------------------  --------------
replay_buffer/size             27200
trainer/QF1 Loss                 241.193
trainer/QF2 Loss                 241.025
trainer/Policy Loss               94.6456
trainer/Q1 Predictions Mean      -93.6899
trainer/Q1 Predictions Std        48.1917
trainer/Q1 Predictions Max       -32.5634
trainer/Q1 Predictions Min      -173.385
trainer/Q2 Predictions Mean      -93.6941
trainer/Q2 Predictions Std        48.2079
trainer/Q2 Predictions Max       -32.565
trainer/Q2 Predictions Min      -173.132
trainer/Q Targets Mean           -92.9352
trainer/Q Targets Std             49.3109
trainer/Q Targets Max             -3.30169
trainer/Q Targets Min           -176.015
trainer/Log Pis Mean               2.0156
trainer/Log Pis Std                1.6504
trainer/Log Pis Max                8.12777
trainer/Log Pis Min               -1.69682
trainer/Policy mu Mean            -0.373196
trainer/Policy mu Std              1.02142
trainer/Policy mu Max              2.45725
trainer/Policy mu Min             -4.26183
trainer/Policy log std Mean       -1.66229
trainer/Policy log std Std         0.600071
trainer/Policy log std Max         0.21557
trainer/Policy log std Min        -2.49977
trainer/Alpha                      0.0606481
trainer/Alpha Loss                 0.0437227
exploration/num steps total    27200
exploration/num paths total      272
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.06048
exploration/Rewards Std            1.62274
exploration/Rewards Max           -0.018523
exploration/Rewards Min           -9.6392
exploration/Returns Mean        -206.048
exploration/Returns Std          143.616
exploration/Returns Max          -39.4587
exploration/Returns Min         -462.546
exploration/Actions Mean          -0.0235629
exploration/Actions Std            0.259712
exploration/Actions Max            0.964389
exploration/Actions Min           -0.996899
exploration/Num Paths              5
exploration/Average Returns     -206.048
evaluation/num steps total     81000
evaluation/num paths total       810
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.89895
evaluation/Rewards Std             0.978358
evaluation/Rewards Max            -0.141345
evaluation/Rewards Min            -8.85398
evaluation/Returns Mean         -189.895
evaluation/Returns Std            74.0584
evaluation/Returns Max           -49.5617
evaluation/Returns Min          -310.52
evaluation/Actions Mean            0.00304875
evaluation/Actions Std             0.173201
evaluation/Actions Max             0.996599
evaluation/Actions Min            -0.998614
evaluation/Num Paths              15
evaluation/Average Returns      -189.895
time/data storing (s)              0.0027929
time/evaluation sampling (s)       0.33308
time/exploration sampling (s)      0.137712
time/logging (s)                   0.00482018
time/saving (s)                    0.00194529
time/training (s)                  1.92681
time/epoch (s)                     2.40716
time/total (s)                   133.45
Epoch                             53
-----------------------------  --------------
2019-04-22 23:55:35.023456 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 54 finished
-----------------------------  --------------
replay_buffer/size             27700
trainer/QF1 Loss                  44.105
trainer/QF2 Loss                  43.4257
trainer/Policy Loss               93.4489
trainer/Q1 Predictions Mean      -92.1181
trainer/Q1 Predictions Std        48.8478
trainer/Q1 Predictions Max       -31.627
trainer/Q1 Predictions Min      -171.376
trainer/Q2 Predictions Mean      -92.1237
trainer/Q2 Predictions Std        48.8554
trainer/Q2 Predictions Max       -31.7329
trainer/Q2 Predictions Min      -171.352
trainer/Q Targets Mean           -92.5205
trainer/Q Targets Std             50.7047
trainer/Q Targets Max             -3.23162
trainer/Q Targets Min           -174.264
trainer/Log Pis Mean               2.03584
trainer/Log Pis Std                1.65411
trainer/Log Pis Max                8.79853
trainer/Log Pis Min               -2.93576
trainer/Policy mu Mean            -0.205376
trainer/Policy mu Std              0.977716
trainer/Policy mu Max              3.52261
trainer/Policy mu Min             -3.44025
trainer/Policy log std Mean       -1.72978
trainer/Policy log std Std         0.588704
trainer/Policy log std Max        -0.139608
trainer/Policy log std Min        -2.5283
trainer/Alpha                      0.0625124
trainer/Alpha Loss                 0.0993756
exploration/num steps total    27700
exploration/num paths total      277
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.2634
exploration/Rewards Std            2.33593
exploration/Rewards Max           -0.0552863
exploration/Rewards Min          -10.1896
exploration/Returns Mean        -226.34
exploration/Returns Std          208.992
exploration/Returns Max          -61.9409
exploration/Returns Min         -636.788
exploration/Actions Mean          -0.0481533
exploration/Actions Std            0.314134
exploration/Actions Max            0.998468
exploration/Actions Min           -0.999636
exploration/Num Paths              5
exploration/Average Returns     -226.34
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.36303
evaluation/Rewards Std             1.34881
evaluation/Rewards Max            -0.0975759
evaluation/Rewards Min           -10.7025
evaluation/Returns Mean         -136.303
evaluation/Returns Std            92.8843
evaluation/Returns Max           -38.698
evaluation/Returns Min          -383.562
evaluation/Actions Mean           -0.02851
evaluation/Actions Std             0.255633
evaluation/Actions Max             0.996697
evaluation/Actions Min            -0.998228
evaluation/Num Paths              15
evaluation/Average Returns      -136.303
time/data storing (s)              0.0030644
time/evaluation sampling (s)       0.333982
time/exploration sampling (s)      0.143153
time/logging (s)                   0.00492806
time/saving (s)                    0.00213759
time/training (s)                  1.93943
time/epoch (s)                     2.4267
time/total (s)                   135.881
Epoch                             54
-----------------------------  --------------
2019-04-22 23:55:37.445228 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 55 finished
-----------------------------  --------------
replay_buffer/size             28200
trainer/QF1 Loss                 281.54
trainer/QF2 Loss                 285.986
trainer/Policy Loss               91.2617
trainer/Q1 Predictions Mean      -90.1895
trainer/Q1 Predictions Std        49.7836
trainer/Q1 Predictions Max       -31.177
trainer/Q1 Predictions Min      -180.803
trainer/Q2 Predictions Mean      -90.2331
trainer/Q2 Predictions Std        49.8216
trainer/Q2 Predictions Max       -31.0004
trainer/Q2 Predictions Min      -179.231
trainer/Q Targets Mean           -89.5985
trainer/Q Targets Std             51.1635
trainer/Q Targets Max             -0.412685
trainer/Q Targets Min           -189.486
trainer/Log Pis Mean               1.74418
trainer/Log Pis Std                1.57577
trainer/Log Pis Max                8.42285
trainer/Log Pis Min               -3.4767
trainer/Policy mu Mean            -0.158238
trainer/Policy mu Std              0.894528
trainer/Policy mu Max              3.64474
trainer/Policy mu Min             -3.37979
trainer/Policy log std Mean       -1.78931
trainer/Policy log std Std         0.564184
trainer/Policy log std Max        -0.515014
trainer/Policy log std Min        -2.60633
trainer/Alpha                      0.0601632
trainer/Alpha Loss                -0.719025
exploration/num steps total    28200
exploration/num paths total      282
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.40851
exploration/Rewards Std            1.70933
exploration/Rewards Max           -0.0905829
exploration/Rewards Min          -10.1258
exploration/Returns Mean        -240.851
exploration/Returns Std          147.804
exploration/Returns Max          -34.8937
exploration/Returns Min         -492.057
exploration/Actions Mean          -0.0333961
exploration/Actions Std            0.236091
exploration/Actions Max            0.908474
exploration/Actions Min           -0.998114
exploration/Num Paths              5
exploration/Average Returns     -240.851
evaluation/num steps total     84000
evaluation/num paths total       840
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.9161
evaluation/Rewards Std             1.51677
evaluation/Rewards Max            -0.258679
evaluation/Rewards Min           -10.1875
evaluation/Returns Mean         -191.61
evaluation/Returns Std           133.268
evaluation/Returns Max           -28.8317
evaluation/Returns Min          -542.965
evaluation/Actions Mean           -0.00300875
evaluation/Actions Std             0.173948
evaluation/Actions Max             0.998502
evaluation/Actions Min            -0.998292
evaluation/Num Paths              15
evaluation/Average Returns      -191.61
time/data storing (s)              0.0029237
time/evaluation sampling (s)       0.336668
time/exploration sampling (s)      0.1372
time/logging (s)                   0.00477944
time/saving (s)                    0.00196541
time/training (s)                  1.93211
time/epoch (s)                     2.41565
time/total (s)                   138.302
Epoch                             55
-----------------------------  --------------
2019-04-22 23:55:39.857010 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 56 finished
-----------------------------  --------------
replay_buffer/size             28700
trainer/QF1 Loss                   1.87083
trainer/QF2 Loss                   1.9234
trainer/Policy Loss               91.4183
trainer/Q1 Predictions Mean      -90.4957
trainer/Q1 Predictions Std        48.7076
trainer/Q1 Predictions Max       -29.3949
trainer/Q1 Predictions Min      -172.02
trainer/Q2 Predictions Mean      -90.4344
trainer/Q2 Predictions Std        48.6711
trainer/Q2 Predictions Max       -29.5541
trainer/Q2 Predictions Min      -171.208
trainer/Q Targets Mean           -91.2266
trainer/Q Targets Std             49.2903
trainer/Q Targets Max            -30.437
trainer/Q Targets Min           -174.158
trainer/Log Pis Mean               1.74626
trainer/Log Pis Std                1.65303
trainer/Log Pis Max                9.58994
trainer/Log Pis Min               -2.36063
trainer/Policy mu Mean            -0.0734871
trainer/Policy mu Std              0.903143
trainer/Policy mu Max              3.6135
trainer/Policy mu Min             -2.76881
trainer/Policy log std Mean       -1.73463
trainer/Policy log std Std         0.514356
trainer/Policy log std Max        -0.290849
trainer/Policy log std Min        -2.6094
trainer/Alpha                      0.0613507
trainer/Alpha Loss                -0.708135
exploration/num steps total    28700
exploration/num paths total      287
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.42788
exploration/Rewards Std            1.34956
exploration/Rewards Max           -0.016414
exploration/Rewards Min           -8.76134
exploration/Returns Mean        -142.788
exploration/Returns Std           90.2913
exploration/Returns Max          -39.175
exploration/Returns Min         -257.781
exploration/Actions Mean          -0.0132507
exploration/Actions Std            0.221762
exploration/Actions Max            0.99641
exploration/Actions Min           -0.999749
exploration/Num Paths              5
exploration/Average Returns     -142.788
evaluation/num steps total     85500
evaluation/num paths total       855
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.90766
evaluation/Rewards Std             1.60316
evaluation/Rewards Max            -0.182376
evaluation/Rewards Min           -10.499
evaluation/Returns Mean         -190.766
evaluation/Returns Std           140.194
evaluation/Returns Max           -23.1165
evaluation/Returns Min          -591.995
evaluation/Actions Mean            0.00305899
evaluation/Actions Std             0.190964
evaluation/Actions Max             0.997512
evaluation/Actions Min            -0.994126
evaluation/Num Paths              15
evaluation/Average Returns      -190.766
time/data storing (s)              0.0030272
time/evaluation sampling (s)       0.328098
time/exploration sampling (s)      0.139721
time/logging (s)                   0.00481182
time/saving (s)                    0.00195155
time/training (s)                  1.92811
time/epoch (s)                     2.40571
time/total (s)                   140.712
Epoch                             56
-----------------------------  --------------
2019-04-22 23:55:42.292763 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 57 finished
-----------------------------  --------------
replay_buffer/size             29200
trainer/QF1 Loss                 167.718
trainer/QF2 Loss                 167.648
trainer/Policy Loss               97.9892
trainer/Q1 Predictions Mean      -97.1026
trainer/Q1 Predictions Std        48.9205
trainer/Q1 Predictions Max       -29.7903
trainer/Q1 Predictions Min      -168.239
trainer/Q2 Predictions Mean      -97.193
trainer/Q2 Predictions Std        48.9837
trainer/Q2 Predictions Max       -29.9442
trainer/Q2 Predictions Min      -168.208
trainer/Q Targets Mean           -96.95
trainer/Q Targets Std             51.2297
trainer/Q Targets Max             -6.1502
trainer/Q Targets Min           -172.177
trainer/Log Pis Mean               1.76431
trainer/Log Pis Std                1.37714
trainer/Log Pis Max                4.75624
trainer/Log Pis Min               -2.89573
trainer/Policy mu Mean             0.0139266
trainer/Policy mu Std              0.975014
trainer/Policy mu Max              2.7978
trainer/Policy mu Min             -2.50771
trainer/Policy log std Mean       -1.58661
trainer/Policy log std Std         0.545501
trainer/Policy log std Max        -0.441189
trainer/Policy log std Min        -2.57585
trainer/Alpha                      0.0607616
trainer/Alpha Loss                -0.660069
exploration/num steps total    29200
exploration/num paths total      292
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.23218
exploration/Rewards Std            1.61897
exploration/Rewards Max           -0.0839408
exploration/Rewards Min          -10.3234
exploration/Returns Mean        -123.218
exploration/Returns Std          124.268
exploration/Returns Max          -44.7901
exploration/Returns Min         -369.361
exploration/Actions Mean           0.0181175
exploration/Actions Std            0.231033
exploration/Actions Max            0.999398
exploration/Actions Min           -0.992463
exploration/Num Paths              5
exploration/Average Returns     -123.218
evaluation/num steps total     87000
evaluation/num paths total       870
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -2.18435
evaluation/Rewards Std             0.931873
evaluation/Rewards Max            -0.290618
evaluation/Rewards Min           -11.0211
evaluation/Returns Mean         -218.435
evaluation/Returns Std            64.9504
evaluation/Returns Max           -42.6504
evaluation/Returns Min          -335.28
evaluation/Actions Mean            0.0152997
evaluation/Actions Std             0.160717
evaluation/Actions Max             0.99849
evaluation/Actions Min            -0.995695
evaluation/Num Paths              15
evaluation/Average Returns      -218.435
time/data storing (s)              0.00301724
time/evaluation sampling (s)       0.329339
time/exploration sampling (s)      0.141658
time/logging (s)                   0.0047828
time/saving (s)                    0.00954208
time/training (s)                  1.94132
time/epoch (s)                     2.42966
time/total (s)                   143.146
Epoch                             57
-----------------------------  --------------
2019-04-22 23:55:44.712547 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 58 finished
-----------------------------  --------------
replay_buffer/size             29700
trainer/QF1 Loss                 241.769
trainer/QF2 Loss                 241.802
trainer/Policy Loss               92.2413
trainer/Q1 Predictions Mean      -90.9441
trainer/Q1 Predictions Std        49.4258
trainer/Q1 Predictions Max       -28.5908
trainer/Q1 Predictions Min      -163.539
trainer/Q2 Predictions Mean      -90.9845
trainer/Q2 Predictions Std        49.4947
trainer/Q2 Predictions Max       -28.7063
trainer/Q2 Predictions Min      -163.55
trainer/Q Targets Mean           -90.637
trainer/Q Targets Std             50.7897
trainer/Q Targets Max             -2.48163
trainer/Q Targets Min           -169.562
trainer/Log Pis Mean               1.98174
trainer/Log Pis Std                1.5838
trainer/Log Pis Max                8.39215
trainer/Log Pis Min               -2.6057
trainer/Policy mu Mean             0.00400931
trainer/Policy mu Std              0.928535
trainer/Policy mu Max              2.44339
trainer/Policy mu Min             -3.10599
trainer/Policy log std Mean       -1.79177
trainer/Policy log std Std         0.552968
trainer/Policy log std Max        -0.368867
trainer/Policy log std Min        -2.64473
trainer/Alpha                      0.0578238
trainer/Alpha Loss                -0.0520399
exploration/num steps total    29700
exploration/num paths total      297
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.6859
exploration/Rewards Std            1.13238
exploration/Rewards Max           -0.221589
exploration/Rewards Min           -7.70498
exploration/Returns Mean        -168.59
exploration/Returns Std           80.1692
exploration/Returns Max          -56.9569
exploration/Returns Min         -257.384
exploration/Actions Mean           0.0209484
exploration/Actions Std            0.247698
exploration/Actions Max            0.997103
exploration/Actions Min           -0.998908
exploration/Num Paths              5
exploration/Average Returns     -168.59
evaluation/num steps total     88500
evaluation/num paths total       885
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.81852
evaluation/Rewards Std             0.942562
evaluation/Rewards Max            -0.269941
evaluation/Rewards Min           -10.8353
evaluation/Returns Mean         -181.852
evaluation/Returns Std            66.9344
evaluation/Returns Max           -36.1895
evaluation/Returns Min          -301.346
evaluation/Actions Mean           -0.0139608
evaluation/Actions Std             0.171369
evaluation/Actions Max             0.997586
evaluation/Actions Min            -0.99964
evaluation/Num Paths              15
evaluation/Average Returns      -181.852
time/data storing (s)              0.00302786
time/evaluation sampling (s)       0.326914
time/exploration sampling (s)      0.143574
time/logging (s)                   0.00482399
time/saving (s)                    0.00196044
time/training (s)                  1.93366
time/epoch (s)                     2.41396
time/total (s)                   145.565
Epoch                             58
-----------------------------  --------------
2019-04-22 23:55:47.173358 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 59 finished
-----------------------------  --------------
replay_buffer/size             30200
trainer/QF1 Loss                 481.183
trainer/QF2 Loss                 481.664
trainer/Policy Loss               91.4206
trainer/Q1 Predictions Mean      -90.3622
trainer/Q1 Predictions Std        50.1303
trainer/Q1 Predictions Max       -29.6076
trainer/Q1 Predictions Min      -175.274
trainer/Q2 Predictions Mean      -90.3216
trainer/Q2 Predictions Std        50.0383
trainer/Q2 Predictions Max       -29.6824
trainer/Q2 Predictions Min      -175.227
trainer/Q Targets Mean           -88.0715
trainer/Q Targets Std             51.0738
trainer/Q Targets Max             -2.00998
trainer/Q Targets Min           -175.155
trainer/Log Pis Mean               1.81333
trainer/Log Pis Std                1.74924
trainer/Log Pis Max                5.37013
trainer/Log Pis Min               -5.54553
trainer/Policy mu Mean            -0.13621
trainer/Policy mu Std              0.846756
trainer/Policy mu Max              2.28958
trainer/Policy mu Min             -2.51991
trainer/Policy log std Mean       -1.81437
trainer/Policy log std Std         0.545574
trainer/Policy log std Max        -0.496238
trainer/Policy log std Min        -2.60114
trainer/Alpha                      0.0572142
trainer/Alpha Loss                -0.534043
exploration/num steps total    30200
exploration/num paths total      302
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.78015
exploration/Rewards Std            0.835916
exploration/Rewards Max           -0.486639
exploration/Rewards Min           -8.89943
exploration/Returns Mean        -178.015
exploration/Returns Std           52.0908
exploration/Returns Max         -110.623
exploration/Returns Min         -234.184
exploration/Actions Mean          -0.00955965
exploration/Actions Std            0.202089
exploration/Actions Max            0.998251
exploration/Actions Min           -0.995973
exploration/Num Paths              5
exploration/Average Returns     -178.015
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.60727
evaluation/Rewards Std             1.20685
evaluation/Rewards Max            -0.0320858
evaluation/Rewards Min           -11.4147
evaluation/Returns Mean         -160.727
evaluation/Returns Std            87.7595
evaluation/Returns Max           -27.357
evaluation/Returns Min          -312.855
evaluation/Actions Mean           -0.0152573
evaluation/Actions Std             0.172032
evaluation/Actions Max             0.990977
evaluation/Actions Min            -0.99937
evaluation/Num Paths              15
evaluation/Average Returns      -160.727
time/data storing (s)              0.00287616
time/evaluation sampling (s)       0.357584
time/exploration sampling (s)      0.143119
time/logging (s)                   0.00393807
time/saving (s)                    0.00196291
time/training (s)                  1.94493
time/epoch (s)                     2.45441
time/total (s)                   148.023
Epoch                             59
-----------------------------  --------------
2019-04-22 23:55:49.672775 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 60 finished
-----------------------------  --------------
replay_buffer/size             30700
trainer/QF1 Loss                 340.889
trainer/QF2 Loss                 342.885
trainer/Policy Loss               93.0781
trainer/Q1 Predictions Mean      -91.9176
trainer/Q1 Predictions Std        49.7716
trainer/Q1 Predictions Max       -27.1403
trainer/Q1 Predictions Min      -170.881
trainer/Q2 Predictions Mean      -91.8736
trainer/Q2 Predictions Std        49.7051
trainer/Q2 Predictions Max       -27.4267
trainer/Q2 Predictions Min      -170.193
trainer/Q Targets Mean           -90.1453
trainer/Q Targets Std             51.1267
trainer/Q Targets Max             -2.84831
trainer/Q Targets Min           -173.158
trainer/Log Pis Mean               1.98211
trainer/Log Pis Std                1.27361
trainer/Log Pis Max                5.88104
trainer/Log Pis Min               -1.97417
trainer/Policy mu Mean            -0.0923512
trainer/Policy mu Std              0.916295
trainer/Policy mu Max              3.64834
trainer/Policy mu Min             -3.0222
trainer/Policy log std Mean       -1.75448
trainer/Policy log std Std         0.56875
trainer/Policy log std Max        -0.197392
trainer/Policy log std Min        -2.6631
trainer/Alpha                      0.0592277
trainer/Alpha Loss                -0.0505635
exploration/num steps total    30700
exploration/num paths total      307
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.14667
exploration/Rewards Std            0.896552
exploration/Rewards Max           -1.22688
exploration/Rewards Min           -9.43732
exploration/Returns Mean        -214.667
exploration/Returns Std           38.45
exploration/Returns Max         -155.801
exploration/Returns Min         -273.749
exploration/Actions Mean          -0.012804
exploration/Actions Std            0.238966
exploration/Actions Max            0.997955
exploration/Actions Min           -0.999888
exploration/Num Paths              5
exploration/Average Returns     -214.667
evaluation/num steps total     91500
evaluation/num paths total       915
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.98956
evaluation/Rewards Std             1.09102
evaluation/Rewards Max            -0.284448
evaluation/Rewards Min            -9.79238
evaluation/Returns Mean         -198.956
evaluation/Returns Std            82.2686
evaluation/Returns Max           -36.938
evaluation/Returns Min          -305.205
evaluation/Actions Mean            0.00106175
evaluation/Actions Std             0.171781
evaluation/Actions Max             0.987333
evaluation/Actions Min            -0.998295
evaluation/Num Paths              15
evaluation/Average Returns      -198.956
time/data storing (s)              0.00304865
time/evaluation sampling (s)       0.328627
time/exploration sampling (s)      0.142259
time/logging (s)                   0.00477326
time/saving (s)                    0.00158491
time/training (s)                  2.0146
time/epoch (s)                     2.4949
time/total (s)                   150.522
Epoch                             60
-----------------------------  --------------
2019-04-22 23:55:52.141310 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 61 finished
-----------------------------  ---------------
replay_buffer/size             31200
trainer/QF1 Loss                 141.596
trainer/QF2 Loss                 140.478
trainer/Policy Loss               97.607
trainer/Q1 Predictions Mean      -96.559
trainer/Q1 Predictions Std        49.8841
trainer/Q1 Predictions Max       -27.2798
trainer/Q1 Predictions Min      -190.215
trainer/Q2 Predictions Mean      -96.6564
trainer/Q2 Predictions Std        50.0228
trainer/Q2 Predictions Max       -27.3661
trainer/Q2 Predictions Min      -189.581
trainer/Q Targets Mean           -96.3088
trainer/Q Targets Std             51.9171
trainer/Q Targets Max             -0.872064
trainer/Q Targets Min           -190.363
trainer/Log Pis Mean               1.84718
trainer/Log Pis Std                1.58148
trainer/Log Pis Max                7.76996
trainer/Log Pis Min               -1.91337
trainer/Policy mu Mean            -0.0379199
trainer/Policy mu Std              1.06434
trainer/Policy mu Max              3.28571
trainer/Policy mu Min             -3.43469
trainer/Policy log std Mean       -1.62052
trainer/Policy log std Std         0.610717
trainer/Policy log std Max        -0.193001
trainer/Policy log std Min        -2.73352
trainer/Alpha                      0.0601632
trainer/Alpha Loss                -0.429527
exploration/num steps total    31200
exploration/num paths total      312
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.39534
exploration/Rewards Std            1.09105
exploration/Rewards Max           -0.00310327
exploration/Rewards Min           -7.77779
exploration/Returns Mean        -139.534
exploration/Returns Std           83.3517
exploration/Returns Max          -27.327
exploration/Returns Min         -227.813
exploration/Actions Mean           0.00371647
exploration/Actions Std            0.22624
exploration/Actions Max            0.99698
exploration/Actions Min           -0.999746
exploration/Num Paths              5
exploration/Average Returns     -139.534
evaluation/num steps total     93000
evaluation/num paths total       930
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.72715
evaluation/Rewards Std             0.999313
evaluation/Rewards Max            -0.064826
evaluation/Rewards Min            -8.44824
evaluation/Returns Mean         -172.715
evaluation/Returns Std            82.4218
evaluation/Returns Max           -19.9369
evaluation/Returns Min          -318.856
evaluation/Actions Mean           -0.000914954
evaluation/Actions Std             0.157678
evaluation/Actions Max             0.996129
evaluation/Actions Min            -0.998343
evaluation/Num Paths              15
evaluation/Average Returns      -172.715
time/data storing (s)              0.00321155
time/evaluation sampling (s)       0.343066
time/exploration sampling (s)      0.141107
time/logging (s)                   0.00485925
time/saving (s)                    0.0019407
time/training (s)                  1.96863
time/epoch (s)                     2.46281
time/total (s)                   152.989
Epoch                             61
-----------------------------  ---------------
2019-04-22 23:55:54.629176 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 62 finished
-----------------------------  --------------
replay_buffer/size             31700
trainer/QF1 Loss                   9.45487
trainer/QF2 Loss                   9.67453
trainer/Policy Loss               88.6476
trainer/Q1 Predictions Mean      -87.6333
trainer/Q1 Predictions Std        50.5394
trainer/Q1 Predictions Max       -26.6925
trainer/Q1 Predictions Min      -167.418
trainer/Q2 Predictions Mean      -87.5563
trainer/Q2 Predictions Std        50.5068
trainer/Q2 Predictions Max       -26.7816
trainer/Q2 Predictions Min      -166.724
trainer/Q Targets Mean           -88.0918
trainer/Q Targets Std             51.692
trainer/Q Targets Max             -0.162233
trainer/Q Targets Min           -172.476
trainer/Log Pis Mean               1.81096
trainer/Log Pis Std                1.65742
trainer/Log Pis Max                7.54722
trainer/Log Pis Min               -2.91537
trainer/Policy mu Mean            -0.166119
trainer/Policy mu Std              0.937366
trainer/Policy mu Max              3.24896
trainer/Policy mu Min             -2.72626
trainer/Policy log std Mean       -1.74116
trainer/Policy log std Std         0.588458
trainer/Policy log std Max        -0.127138
trainer/Policy log std Min        -2.69284
trainer/Alpha                      0.0603785
trainer/Alpha Loss                -0.530647
exploration/num steps total    31700
exploration/num paths total      317
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.97207
exploration/Rewards Std            1.16666
exploration/Rewards Max           -0.0355105
exploration/Rewards Min           -8.97026
exploration/Returns Mean        -197.207
exploration/Returns Std           96.4902
exploration/Returns Max          -29.2395
exploration/Returns Min         -311.385
exploration/Actions Mean           0.0136066
exploration/Actions Std            0.234544
exploration/Actions Max            0.993546
exploration/Actions Min           -0.995771
exploration/Num Paths              5
exploration/Average Returns     -197.207
evaluation/num steps total     94500
evaluation/num paths total       945
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.66901
evaluation/Rewards Std             1.28632
evaluation/Rewards Max            -0.0557377
evaluation/Rewards Min           -12.1015
evaluation/Returns Mean         -166.901
evaluation/Returns Std           102.25
evaluation/Returns Max           -14.6206
evaluation/Returns Min          -301.784
evaluation/Actions Mean            0.00250376
evaluation/Actions Std             0.176701
evaluation/Actions Max             0.996399
evaluation/Actions Min            -0.999658
evaluation/Num Paths              15
evaluation/Average Returns      -166.901
time/data storing (s)              0.00302203
time/evaluation sampling (s)       0.351315
time/exploration sampling (s)      0.15253
time/logging (s)                   0.00478371
time/saving (s)                    0.00196816
time/training (s)                  1.9684
time/epoch (s)                     2.48202
time/total (s)                   155.475
Epoch                             62
-----------------------------  --------------
2019-04-22 23:55:57.035988 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 63 finished
-----------------------------  --------------
replay_buffer/size             32200
trainer/QF1 Loss                   0.527973
trainer/QF2 Loss                   0.631605
trainer/Policy Loss               85.2459
trainer/Q1 Predictions Mean      -84.2299
trainer/Q1 Predictions Std        49.5184
trainer/Q1 Predictions Max       -26.781
trainer/Q1 Predictions Min      -174.708
trainer/Q2 Predictions Mean      -84.1995
trainer/Q2 Predictions Std        49.5176
trainer/Q2 Predictions Max       -26.8061
trainer/Q2 Predictions Min      -175.219
trainer/Q Targets Mean           -84.3472
trainer/Q Targets Std             49.5942
trainer/Q Targets Max            -26.3486
trainer/Q Targets Min           -173.654
trainer/Log Pis Mean               1.8769
trainer/Log Pis Std                1.51938
trainer/Log Pis Max                5.71428
trainer/Log Pis Min               -2.66389
trainer/Policy mu Mean             0.0846898
trainer/Policy mu Std              0.905257
trainer/Policy mu Max              3.56836
trainer/Policy mu Min             -2.87935
trainer/Policy log std Mean       -1.82057
trainer/Policy log std Std         0.566878
trainer/Policy log std Max        -0.133645
trainer/Policy log std Min        -2.70096
trainer/Alpha                      0.0622705
trainer/Alpha Loss                -0.341719
exploration/num steps total    32200
exploration/num paths total      322
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.87263
exploration/Rewards Std            0.971462
exploration/Rewards Max           -0.444135
exploration/Rewards Min           -9.17136
exploration/Returns Mean        -187.263
exploration/Returns Std           40.8812
exploration/Returns Max         -112.781
exploration/Returns Min         -230.968
exploration/Actions Mean           0.00510292
exploration/Actions Std            0.246567
exploration/Actions Max            0.999029
exploration/Actions Min           -0.999667
exploration/Num Paths              5
exploration/Average Returns     -187.263
evaluation/num steps total     96000
evaluation/num paths total       960
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.20306
evaluation/Rewards Std             1.17164
evaluation/Rewards Max            -0.132629
evaluation/Rewards Min           -10.2734
evaluation/Returns Mean         -120.306
evaluation/Returns Std            80.3381
evaluation/Returns Max           -21.2056
evaluation/Returns Min          -267.924
evaluation/Actions Mean            0.00541866
evaluation/Actions Std             0.18145
evaluation/Actions Max             0.998962
evaluation/Actions Min            -0.998485
evaluation/Num Paths              15
evaluation/Average Returns      -120.306
time/data storing (s)              0.00278313
time/evaluation sampling (s)       0.334235
time/exploration sampling (s)      0.139371
time/logging (s)                   0.00481502
time/saving (s)                    0.00175963
time/training (s)                  1.91812
time/epoch (s)                     2.40109
time/total (s)                   157.88
Epoch                             63
-----------------------------  --------------
2019-04-22 23:55:59.458054 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 64 finished
-----------------------------  --------------
replay_buffer/size             32700
trainer/QF1 Loss                  27.9855
trainer/QF2 Loss                  28.0009
trainer/Policy Loss               90.3739
trainer/Q1 Predictions Mean      -89.2676
trainer/Q1 Predictions Std        48.3999
trainer/Q1 Predictions Max       -26.5789
trainer/Q1 Predictions Min      -190.031
trainer/Q2 Predictions Mean      -89.1832
trainer/Q2 Predictions Std        48.3836
trainer/Q2 Predictions Max       -26.5765
trainer/Q2 Predictions Min      -189.761
trainer/Q Targets Mean           -90.4474
trainer/Q Targets Std             49.7096
trainer/Q Targets Max             -0.865664
trainer/Q Targets Min           -192.123
trainer/Log Pis Mean               2.0014
trainer/Log Pis Std                1.76915
trainer/Log Pis Max               10.0465
trainer/Log Pis Min               -1.39372
trainer/Policy mu Mean            -0.207416
trainer/Policy mu Std              1.04214
trainer/Policy mu Max              3.82023
trainer/Policy mu Min             -4.02776
trainer/Policy log std Mean       -1.65559
trainer/Policy log std Std         0.62912
trainer/Policy log std Max         0.115308
trainer/Policy log std Min        -2.66073
trainer/Alpha                      0.0642584
trainer/Alpha Loss                 0.00384556
exploration/num steps total    32700
exploration/num paths total      327
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.40915
exploration/Rewards Std            1.08189
exploration/Rewards Max           -0.0778577
exploration/Rewards Min           -8.23258
exploration/Returns Mean        -140.915
exploration/Returns Std           73.1976
exploration/Returns Max          -63.68
exploration/Returns Min         -269.013
exploration/Actions Mean           0.00512042
exploration/Actions Std            0.223358
exploration/Actions Max            0.992179
exploration/Actions Min           -0.999844
exploration/Num Paths              5
exploration/Average Returns     -140.915
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.91962
evaluation/Rewards Std             1.04244
evaluation/Rewards Max            -0.283106
evaluation/Rewards Min           -10.9724
evaluation/Returns Mean         -191.962
evaluation/Returns Std            60.6295
evaluation/Returns Max           -47.9977
evaluation/Returns Min          -277.662
evaluation/Actions Mean           -0.014824
evaluation/Actions Std             0.203779
evaluation/Actions Max             0.999376
evaluation/Actions Min            -0.998808
evaluation/Num Paths              15
evaluation/Average Returns      -191.962
time/data storing (s)              0.00296848
time/evaluation sampling (s)       0.332915
time/exploration sampling (s)      0.135796
time/logging (s)                   0.00480521
time/saving (s)                    0.00197806
time/training (s)                  1.93778
time/epoch (s)                     2.41624
time/total (s)                   160.301
Epoch                             64
-----------------------------  --------------
2019-04-22 23:56:01.863087 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 65 finished
-----------------------------  ---------------
replay_buffer/size             33200
trainer/QF1 Loss                 249.706
trainer/QF2 Loss                 251.463
trainer/Policy Loss               88.8155
trainer/Q1 Predictions Mean      -87.5196
trainer/Q1 Predictions Std        47.8215
trainer/Q1 Predictions Max       -25.4254
trainer/Q1 Predictions Min      -166.962
trainer/Q2 Predictions Mean      -87.5306
trainer/Q2 Predictions Std        47.8178
trainer/Q2 Predictions Max       -25.4528
trainer/Q2 Predictions Min      -166.477
trainer/Q Targets Mean           -86.9955
trainer/Q Targets Std             48.6727
trainer/Q Targets Max             -2.59103
trainer/Q Targets Min           -169.955
trainer/Log Pis Mean               2.1801
trainer/Log Pis Std                1.5951
trainer/Log Pis Max               10.1177
trainer/Log Pis Min               -2.34556
trainer/Policy mu Mean            -0.0599056
trainer/Policy mu Std              0.914446
trainer/Policy mu Max              3.15949
trainer/Policy mu Min             -4.08974
trainer/Policy log std Mean       -1.81828
trainer/Policy log std Std         0.553038
trainer/Policy log std Max        -0.360492
trainer/Policy log std Min        -2.75149
trainer/Alpha                      0.0640995
trainer/Alpha Loss                 0.494812
exploration/num steps total    33200
exploration/num paths total      332
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -2.04352
exploration/Rewards Std            0.812008
exploration/Rewards Max           -1.43631
exploration/Rewards Min           -9.5682
exploration/Returns Mean        -204.352
exploration/Returns Std           23.5858
exploration/Returns Max         -180.556
exploration/Returns Min         -247.503
exploration/Actions Mean          -0.000401054
exploration/Actions Std            0.274061
exploration/Actions Max            0.997754
exploration/Actions Min           -0.998562
exploration/Num Paths              5
exploration/Average Returns     -204.352
evaluation/num steps total     99000
evaluation/num paths total       990
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.47089
evaluation/Rewards Std             1.00313
evaluation/Rewards Max            -0.24216
evaluation/Rewards Min            -9.98024
evaluation/Returns Mean         -147.089
evaluation/Returns Std            61.6001
evaluation/Returns Max           -41.8339
evaluation/Returns Min          -227.067
evaluation/Actions Mean           -9.02259e-05
evaluation/Actions Std             0.176584
evaluation/Actions Max             0.998873
evaluation/Actions Min            -0.999656
evaluation/Num Paths              15
evaluation/Average Returns      -147.089
time/data storing (s)              0.00305274
time/evaluation sampling (s)       0.331822
time/exploration sampling (s)      0.139012
time/logging (s)                   0.00448589
time/saving (s)                    0.00196371
time/training (s)                  1.91913
time/epoch (s)                     2.39946
time/total (s)                   162.704
Epoch                             65
-----------------------------  ---------------
2019-04-22 23:56:04.274210 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                  344.19
trainer/QF2 Loss                  344.427
trainer/Policy Loss                93.6298
trainer/Q1 Predictions Mean       -92.7498
trainer/Q1 Predictions Std         46.407
trainer/Q1 Predictions Max        -25.0526
trainer/Q1 Predictions Min       -166.826
trainer/Q2 Predictions Mean       -92.7102
trainer/Q2 Predictions Std         46.4423
trainer/Q2 Predictions Max        -24.959
trainer/Q2 Predictions Min       -166.16
trainer/Q Targets Mean            -91.2792
trainer/Q Targets Std              48.088
trainer/Q Targets Max              -4.1953
trainer/Q Targets Min            -170.416
trainer/Log Pis Mean                1.98727
trainer/Log Pis Std                 1.60212
trainer/Log Pis Max                 7.32544
trainer/Log Pis Min                -2.11893
trainer/Policy mu Mean             -0.0843578
trainer/Policy mu Std               1.06006
trainer/Policy mu Max               3.94421
trainer/Policy mu Min              -3.47673
trainer/Policy log std Mean        -1.7026
trainer/Policy log std Std          0.631223
trainer/Policy log std Max         -0.0956897
trainer/Policy log std Min         -2.73664
trainer/Alpha                       0.0649692
trainer/Alpha Loss                 -0.0347961
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.01955
exploration/Rewards Std             1.10748
exploration/Rewards Max            -0.282287
exploration/Rewards Min            -9.18861
exploration/Returns Mean         -201.955
exploration/Returns Std            69.658
exploration/Returns Max          -100.57
exploration/Returns Min          -307.408
exploration/Actions Mean           -0.0243039
exploration/Actions Std             0.244742
exploration/Actions Max             0.998652
exploration/Actions Min            -0.999532
exploration/Num Paths               5
exploration/Average Returns      -201.955
evaluation/num steps total     100500
evaluation/num paths total       1005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.50486
evaluation/Rewards Std              1.27882
evaluation/Rewards Max             -0.09615
evaluation/Rewards Min             -9.94056
evaluation/Returns Mean          -150.486
evaluation/Returns Std             87.2508
evaluation/Returns Max            -22.7819
evaluation/Returns Min           -294.716
evaluation/Actions Mean            -0.00618268
evaluation/Actions Std              0.182749
evaluation/Actions Max              0.999079
evaluation/Actions Min             -0.999695
evaluation/Num Paths               15
evaluation/Average Returns       -150.486
time/data storing (s)               0.002974
time/evaluation sampling (s)        0.326911
time/exploration sampling (s)       0.142627
time/logging (s)                    0.00479053
time/saving (s)                     0.00196878
time/training (s)                   1.92651
time/epoch (s)                      2.40578
time/total (s)                    165.114
Epoch                              66
-----------------------------  ---------------
2019-04-22 23:56:06.685226 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                   28.4467
trainer/QF2 Loss                   28.5128
trainer/Policy Loss                97.3612
trainer/Q1 Predictions Mean       -96.3208
trainer/Q1 Predictions Std         49.3884
trainer/Q1 Predictions Max        -24.3263
trainer/Q1 Predictions Min       -200.558
trainer/Q2 Predictions Mean       -96.3167
trainer/Q2 Predictions Std         49.4253
trainer/Q2 Predictions Max        -24.1373
trainer/Q2 Predictions Min       -201.084
trainer/Q Targets Mean            -96.897
trainer/Q Targets Std              50.5803
trainer/Q Targets Max              -0.788851
trainer/Q Targets Min            -200.081
trainer/Log Pis Mean                2.15403
trainer/Log Pis Std                 1.71603
trainer/Log Pis Max                10.703
trainer/Log Pis Min                -4.45036
trainer/Policy mu Mean              0.0148333
trainer/Policy mu Std               1.03226
trainer/Policy mu Max               3.41346
trainer/Policy mu Min              -3.60182
trainer/Policy log std Mean        -1.66037
trainer/Policy log std Std          0.657526
trainer/Policy log std Max         -0.113762
trainer/Policy log std Min         -2.69477
trainer/Alpha                       0.0636533
trainer/Alpha Loss                  0.424245
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.99364
exploration/Rewards Std             1.24875
exploration/Rewards Max            -0.0458749
exploration/Rewards Min            -9.43939
exploration/Returns Mean         -199.364
exploration/Returns Std            92.3109
exploration/Returns Max           -50.4508
exploration/Returns Min          -300.454
exploration/Actions Mean           -0.0097057
exploration/Actions Std             0.2256
exploration/Actions Max             0.992651
exploration/Actions Min            -0.997794
exploration/Num Paths               5
exploration/Average Returns      -199.364
evaluation/num steps total     102000
evaluation/num paths total       1020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.70527
evaluation/Rewards Std              1.06219
evaluation/Rewards Max             -0.0667431
evaluation/Rewards Min            -10.6082
evaluation/Returns Mean          -170.527
evaluation/Returns Std             72.6389
evaluation/Returns Max            -43.1281
evaluation/Returns Min           -292.179
evaluation/Actions Mean             0.00507966
evaluation/Actions Std              0.177294
evaluation/Actions Max              0.998256
evaluation/Actions Min             -0.999782
evaluation/Num Paths               15
evaluation/Average Returns       -170.527
time/data storing (s)               0.00304692
time/evaluation sampling (s)        0.328563
time/exploration sampling (s)       0.138499
time/logging (s)                    0.00477354
time/saving (s)                     0.00196862
time/training (s)                   1.92823
time/epoch (s)                      2.40508
time/total (s)                    167.523
Epoch                              67
-----------------------------  ---------------
2019-04-22 23:56:09.095415 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                  160.815
trainer/QF2 Loss                  160.047
trainer/Policy Loss                84.7032
trainer/Q1 Predictions Mean       -83.3851
trainer/Q1 Predictions Std         48.4854
trainer/Q1 Predictions Max        -23.8479
trainer/Q1 Predictions Min       -191.282
trainer/Q2 Predictions Mean       -83.4171
trainer/Q2 Predictions Std         48.5472
trainer/Q2 Predictions Max        -23.9997
trainer/Q2 Predictions Min       -191.989
trainer/Q Targets Mean            -82.5545
trainer/Q Targets Std              49.413
trainer/Q Targets Max              -2.20677
trainer/Q Targets Min            -190.968
trainer/Log Pis Mean                2.20952
trainer/Log Pis Std                 1.40859
trainer/Log Pis Max                 6.95695
trainer/Log Pis Min                -1.68032
trainer/Policy mu Mean             -0.0511828
trainer/Policy mu Std               1.02423
trainer/Policy mu Max               3.40831
trainer/Policy mu Min              -3.58015
trainer/Policy log std Mean        -1.78523
trainer/Policy log std Std          0.64527
trainer/Policy log std Max         -0.164959
trainer/Policy log std Min         -2.85357
trainer/Alpha                       0.0645339
trainer/Alpha Loss                  0.57421
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.34599
exploration/Rewards Std             1.09354
exploration/Rewards Max            -0.22376
exploration/Rewards Min           -10.3927
exploration/Returns Mean         -134.599
exploration/Returns Std            51.2829
exploration/Returns Max           -67.1554
exploration/Returns Min          -202.989
exploration/Actions Mean            0.0138686
exploration/Actions Std             0.223657
exploration/Actions Max             0.998978
exploration/Actions Min            -0.996999
exploration/Num Paths               5
exploration/Average Returns      -134.599
evaluation/num steps total     103500
evaluation/num paths total       1035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.50236
evaluation/Rewards Std              1.17435
evaluation/Rewards Max             -0.106437
evaluation/Rewards Min             -9.73578
evaluation/Returns Mean          -150.236
evaluation/Returns Std             68.8629
evaluation/Returns Max            -30.7187
evaluation/Returns Min           -258.56
evaluation/Actions Mean             0.00883821
evaluation/Actions Std              0.190842
evaluation/Actions Max              0.999408
evaluation/Actions Min             -0.998338
evaluation/Num Paths               15
evaluation/Average Returns       -150.236
time/data storing (s)               0.0029491
time/evaluation sampling (s)        0.333805
time/exploration sampling (s)       0.140448
time/logging (s)                    0.00458212
time/saving (s)                     0.00196496
time/training (s)                   1.92064
time/epoch (s)                      2.40439
time/total (s)                    169.932
Epoch                              68
-----------------------------  ---------------
2019-04-22 23:56:11.508943 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                   16.5259
trainer/QF2 Loss                   16.6416
trainer/Policy Loss                84.021
trainer/Q1 Predictions Mean       -83.1898
trainer/Q1 Predictions Std         46.8465
trainer/Q1 Predictions Max        -23.4366
trainer/Q1 Predictions Min       -165.096
trainer/Q2 Predictions Mean       -83.1129
trainer/Q2 Predictions Std         46.8434
trainer/Q2 Predictions Max        -23.5234
trainer/Q2 Predictions Min       -164.424
trainer/Q Targets Mean            -83.7221
trainer/Q Targets Std              48.4082
trainer/Q Targets Max              -0.374149
trainer/Q Targets Min            -170.271
trainer/Log Pis Mean                2.01595
trainer/Log Pis Std                 1.32477
trainer/Log Pis Max                 5.25877
trainer/Log Pis Min                -1.92385
trainer/Policy mu Mean             -0.116088
trainer/Policy mu Std               0.968526
trainer/Policy mu Max               2.887
trainer/Policy mu Min              -3.02408
trainer/Policy log std Mean        -1.74859
trainer/Policy log std Std          0.596744
trainer/Policy log std Max         -0.293277
trainer/Policy log std Min         -2.62159
trainer/Alpha                       0.0661467
trainer/Alpha Loss                  0.0433087
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.94047
exploration/Rewards Std             0.601524
exploration/Rewards Max            -1.26033
exploration/Rewards Min            -8.69415
exploration/Returns Mean         -194.047
exploration/Returns Std            25.615
exploration/Returns Max          -168.205
exploration/Returns Min          -228.961
exploration/Actions Mean            0.0170769
exploration/Actions Std             0.23825
exploration/Actions Max             0.993198
exploration/Actions Min            -0.999487
exploration/Num Paths               5
exploration/Average Returns      -194.047
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.96132
evaluation/Rewards Std              0.864087
evaluation/Rewards Max             -0.257742
evaluation/Rewards Min             -9.18061
evaluation/Returns Mean          -196.132
evaluation/Returns Std             58.9004
evaluation/Returns Max            -73.5696
evaluation/Returns Min           -292.228
evaluation/Actions Mean             0.0138444
evaluation/Actions Std              0.167558
evaluation/Actions Max              0.996406
evaluation/Actions Min             -0.99844
evaluation/Num Paths               15
evaluation/Average Returns       -196.132
time/data storing (s)               0.00279151
time/evaluation sampling (s)        0.33312
time/exploration sampling (s)       0.136838
time/logging (s)                    0.00475249
time/saving (s)                     0.00197259
time/training (s)                   1.92885
time/epoch (s)                      2.40832
time/total (s)                    172.344
Epoch                              69
-----------------------------  ---------------
2019-04-22 23:56:13.965405 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 70 finished
-----------------------------  ---------------
replay_buffer/size              35700
trainer/QF1 Loss                   25.5839
trainer/QF2 Loss                   25.8407
trainer/Policy Loss                86.2443
trainer/Q1 Predictions Mean       -84.9356
trainer/Q1 Predictions Std         45.601
trainer/Q1 Predictions Max        -23.5221
trainer/Q1 Predictions Min       -180.028
trainer/Q2 Predictions Mean       -84.9425
trainer/Q2 Predictions Std         45.5728
trainer/Q2 Predictions Max        -23.5323
trainer/Q2 Predictions Min       -180.373
trainer/Q Targets Mean            -84.8986
trainer/Q Targets Std              46.3257
trainer/Q Targets Max              -1.62206
trainer/Q Targets Min            -180.343
trainer/Log Pis Mean                2.09325
trainer/Log Pis Std                 1.425
trainer/Log Pis Max                 7.65897
trainer/Log Pis Min                -1.60497
trainer/Policy mu Mean              0.129803
trainer/Policy mu Std               0.914853
trainer/Policy mu Max               3.88028
trainer/Policy mu Min              -3.03504
trainer/Policy log std Mean        -1.82615
trainer/Policy log std Std          0.570939
trainer/Policy log std Max         -0.252631
trainer/Policy log std Min         -2.64885
trainer/Alpha                       0.0666977
trainer/Alpha Loss                  0.25248
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.59152
exploration/Rewards Std             1.20346
exploration/Rewards Max            -0.0220912
exploration/Rewards Min            -6.57723
exploration/Returns Mean         -159.152
exploration/Returns Std           102.463
exploration/Returns Max           -33.0636
exploration/Returns Min          -327.491
exploration/Actions Mean            0.00219348
exploration/Actions Std             0.212228
exploration/Actions Max             0.999745
exploration/Actions Min            -0.999534
exploration/Num Paths               5
exploration/Average Returns      -159.152
evaluation/num steps total     106500
evaluation/num paths total       1065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.29654
evaluation/Rewards Std              1.20487
evaluation/Rewards Max             -0.0843251
evaluation/Rewards Min            -10.4152
evaluation/Returns Mean          -129.654
evaluation/Returns Std             79.2571
evaluation/Returns Max            -30.3556
evaluation/Returns Min           -314.325
evaluation/Actions Mean             0.0196382
evaluation/Actions Std              0.201593
evaluation/Actions Max              0.999176
evaluation/Actions Min             -0.996708
evaluation/Num Paths               15
evaluation/Average Returns       -129.654
time/data storing (s)               0.0028354
time/evaluation sampling (s)        0.35661
time/exploration sampling (s)       0.138868
time/logging (s)                    0.00475293
time/saving (s)                     0.010471
time/training (s)                   1.93785
time/epoch (s)                      2.45139
time/total (s)                    174.799
Epoch                              70
-----------------------------  ---------------
2019-04-22 23:56:16.366748 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                   52.8056
trainer/QF2 Loss                   51.7853
trainer/Policy Loss                93.8534
trainer/Q1 Predictions Mean       -92.4331
trainer/Q1 Predictions Std         46.3488
trainer/Q1 Predictions Max        -23.2405
trainer/Q1 Predictions Min       -169.956
trainer/Q2 Predictions Mean       -92.4216
trainer/Q2 Predictions Std         46.4023
trainer/Q2 Predictions Max        -23.1619
trainer/Q2 Predictions Min       -170.712
trainer/Q Targets Mean            -92.0589
trainer/Q Targets Std              47.2616
trainer/Q Targets Max              -6.55555
trainer/Q Targets Min            -171.579
trainer/Log Pis Mean                2.25571
trainer/Log Pis Std                 1.54414
trainer/Log Pis Max                 6.83031
trainer/Log Pis Min                -2.81978
trainer/Policy mu Mean             -0.0715783
trainer/Policy mu Std               0.947831
trainer/Policy mu Max               3.19586
trainer/Policy mu Min              -2.92129
trainer/Policy log std Mean        -1.84431
trainer/Policy log std Std          0.590831
trainer/Policy log std Max         -0.237197
trainer/Policy log std Min         -2.70249
trainer/Alpha                       0.0661346
trainer/Alpha Loss                  0.69452
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.48824
exploration/Rewards Std             1.18276
exploration/Rewards Max            -0.0192183
exploration/Rewards Min            -8.58604
exploration/Returns Mean         -148.824
exploration/Returns Std            96.5862
exploration/Returns Max           -21.7428
exploration/Returns Min          -253.354
exploration/Actions Mean            0.0140927
exploration/Actions Std             0.221019
exploration/Actions Max             0.998753
exploration/Actions Min            -0.999746
exploration/Num Paths               5
exploration/Average Returns      -148.824
evaluation/num steps total     108000
evaluation/num paths total       1080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.70692
evaluation/Rewards Std              1.12263
evaluation/Rewards Max             -0.118281
evaluation/Rewards Min             -9.75142
evaluation/Returns Mean          -170.692
evaluation/Returns Std             85.053
evaluation/Returns Max            -32.0105
evaluation/Returns Min           -313.547
evaluation/Actions Mean             0.00172475
evaluation/Actions Std              0.174866
evaluation/Actions Max              0.998305
evaluation/Actions Min             -0.998531
evaluation/Num Paths               15
evaluation/Average Returns       -170.692
time/data storing (s)               0.00302003
time/evaluation sampling (s)        0.329702
time/exploration sampling (s)       0.140667
time/logging (s)                    0.00423988
time/saving (s)                     0.00199439
time/training (s)                   1.91511
time/epoch (s)                      2.39473
time/total (s)                    177.199
Epoch                              71
-----------------------------  ---------------
2019-04-22 23:56:18.794338 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                    9.27078
trainer/QF2 Loss                    9.77191
trainer/Policy Loss                91.561
trainer/Q1 Predictions Mean       -90.3643
trainer/Q1 Predictions Std         46.5861
trainer/Q1 Predictions Max        -23.8086
trainer/Q1 Predictions Min       -167.014
trainer/Q2 Predictions Mean       -90.3483
trainer/Q2 Predictions Std         46.4981
trainer/Q2 Predictions Max        -23.8535
trainer/Q2 Predictions Min       -165.947
trainer/Q Targets Mean            -91.1329
trainer/Q Targets Std              47.7862
trainer/Q Targets Max              -0.412685
trainer/Q Targets Min            -170.516
trainer/Log Pis Mean                1.90114
trainer/Log Pis Std                 1.21126
trainer/Log Pis Max                 4.63853
trainer/Log Pis Min                -1.44047
trainer/Policy mu Mean              0.0811326
trainer/Policy mu Std               0.833974
trainer/Policy mu Max               2.56175
trainer/Policy mu Min              -2.39903
trainer/Policy log std Mean        -1.86052
trainer/Policy log std Std          0.59114
trainer/Policy log std Max         -0.544351
trainer/Policy log std Min         -2.74822
trainer/Alpha                       0.0649359
trainer/Alpha Loss                 -0.270305
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.9141
exploration/Rewards Std             1.29688
exploration/Rewards Max            -0.00950324
exploration/Rewards Min            -9.20774
exploration/Returns Mean         -191.41
exploration/Returns Std           113.523
exploration/Returns Max           -28.5617
exploration/Returns Min          -333.079
exploration/Actions Mean           -0.00775729
exploration/Actions Std             0.214319
exploration/Actions Max             0.980201
exploration/Actions Min            -0.999888
exploration/Num Paths               5
exploration/Average Returns      -191.41
evaluation/num steps total     109500
evaluation/num paths total       1095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.44309
evaluation/Rewards Std              0.982901
evaluation/Rewards Max             -0.109084
evaluation/Rewards Min            -10.1543
evaluation/Returns Mean          -144.309
evaluation/Returns Std             72.5456
evaluation/Returns Max            -11.1701
evaluation/Returns Min           -309.495
evaluation/Actions Mean             0.00886301
evaluation/Actions Std              0.167132
evaluation/Actions Max              0.998363
evaluation/Actions Min             -0.998833
evaluation/Num Paths               15
evaluation/Average Returns       -144.309
time/data storing (s)               0.0033087
time/evaluation sampling (s)        0.328222
time/exploration sampling (s)       0.142338
time/logging (s)                    0.00477279
time/saving (s)                     0.00195109
time/training (s)                   1.94132
time/epoch (s)                      2.42191
time/total (s)                    179.625
Epoch                              72
-----------------------------  ---------------
2019-04-22 23:56:21.206425 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    0.711716
trainer/QF2 Loss                    0.920511
trainer/Policy Loss                88.7548
trainer/Q1 Predictions Mean       -87.6521
trainer/Q1 Predictions Std         48.657
trainer/Q1 Predictions Max        -22.9497
trainer/Q1 Predictions Min       -169.706
trainer/Q2 Predictions Mean       -87.6061
trainer/Q2 Predictions Std         48.5991
trainer/Q2 Predictions Max        -22.8484
trainer/Q2 Predictions Min       -169.731
trainer/Q Targets Mean            -88.0341
trainer/Q Targets Std              48.9309
trainer/Q Targets Max             -22.6069
trainer/Q Targets Min            -172.369
trainer/Log Pis Mean                1.93938
trainer/Log Pis Std                 1.2345
trainer/Log Pis Max                 5.49826
trainer/Log Pis Min                -2.86917
trainer/Policy mu Mean              0.0377311
trainer/Policy mu Std               0.901532
trainer/Policy mu Max               3.36401
trainer/Policy mu Min              -3.16671
trainer/Policy log std Mean        -1.77121
trainer/Policy log std Std          0.553656
trainer/Policy log std Max         -0.335274
trainer/Policy log std Min         -2.6761
trainer/Alpha                       0.0667984
trainer/Alpha Loss                 -0.164036
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11257
exploration/Rewards Std             0.94036
exploration/Rewards Max            -0.0277438
exploration/Rewards Min            -9.1061
exploration/Returns Mean         -111.257
exploration/Returns Std            45.9703
exploration/Returns Max           -65.0769
exploration/Returns Min          -195.376
exploration/Actions Mean            0.00424439
exploration/Actions Std             0.211486
exploration/Actions Max             0.992355
exploration/Actions Min            -0.999969
exploration/Num Paths               5
exploration/Average Returns      -111.257
evaluation/num steps total     111000
evaluation/num paths total       1110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.5561
evaluation/Rewards Std              1.09903
evaluation/Rewards Max             -0.0116378
evaluation/Rewards Min            -10.4146
evaluation/Returns Mean          -155.61
evaluation/Returns Std             79.1691
evaluation/Returns Max            -26.3864
evaluation/Returns Min           -327.289
evaluation/Actions Mean             0.00884479
evaluation/Actions Std              0.191393
evaluation/Actions Max              0.998871
evaluation/Actions Min             -0.999288
evaluation/Num Paths               15
evaluation/Average Returns       -155.61
time/data storing (s)               0.00299002
time/evaluation sampling (s)        0.331452
time/exploration sampling (s)       0.136432
time/logging (s)                    0.0047562
time/saving (s)                     0.00158045
time/training (s)                   1.92868
time/epoch (s)                      2.4059
time/total (s)                    182.035
Epoch                              73
-----------------------------  ---------------
2019-04-22 23:56:23.619046 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size              37700
trainer/QF1 Loss                    6.89041
trainer/QF2 Loss                    6.90824
trainer/Policy Loss                86.4187
trainer/Q1 Predictions Mean       -85.3548
trainer/Q1 Predictions Std         44.1521
trainer/Q1 Predictions Max        -21.4628
trainer/Q1 Predictions Min       -161.008
trainer/Q2 Predictions Mean       -85.35
trainer/Q2 Predictions Std         44.1943
trainer/Q2 Predictions Max        -21.7675
trainer/Q2 Predictions Min       -161.615
trainer/Q Targets Mean            -85.6675
trainer/Q Targets Std              44.8974
trainer/Q Targets Max              -1.59017
trainer/Q Targets Min            -164.02
trainer/Log Pis Mean                1.8779
trainer/Log Pis Std                 1.51164
trainer/Log Pis Max                 6.44144
trainer/Log Pis Min                -3.70833
trainer/Policy mu Mean              0.1183
trainer/Policy mu Std               0.753911
trainer/Policy mu Max               3.25119
trainer/Policy mu Min              -2.64236
trainer/Policy log std Mean        -1.97843
trainer/Policy log std Std          0.540232
trainer/Policy log std Max         -0.52926
trainer/Policy log std Min         -2.80886
trainer/Alpha                       0.0679069
trainer/Alpha Loss                 -0.328395
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.42969
exploration/Rewards Std             0.985793
exploration/Rewards Max            -0.375579
exploration/Rewards Min           -10.5241
exploration/Returns Mean         -142.969
exploration/Returns Std            21.0271
exploration/Returns Max          -116.834
exploration/Returns Min          -167.007
exploration/Actions Mean            0.0179895
exploration/Actions Std             0.247969
exploration/Actions Max             0.997796
exploration/Actions Min            -0.998594
exploration/Num Paths               5
exploration/Average Returns      -142.969
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.37565
evaluation/Rewards Std              1.12385
evaluation/Rewards Max             -0.00813103
evaluation/Rewards Min             -9.99223
evaluation/Returns Mean          -137.565
evaluation/Returns Std             88.3992
evaluation/Returns Max            -17.9237
evaluation/Returns Min           -334.254
evaluation/Actions Mean             0.00436759
evaluation/Actions Std              0.165062
evaluation/Actions Max              0.998386
evaluation/Actions Min             -0.997704
evaluation/Num Paths               15
evaluation/Average Returns       -137.565
time/data storing (s)               0.00291337
time/evaluation sampling (s)        0.328311
time/exploration sampling (s)       0.134679
time/logging (s)                    0.00486474
time/saving (s)                     0.00197963
time/training (s)                   1.93375
time/epoch (s)                      2.4065
time/total (s)                    184.447
Epoch                              74
-----------------------------  ---------------
2019-04-22 23:56:26.021792 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                  123.413
trainer/QF2 Loss                  123.586
trainer/Policy Loss                92.1121
trainer/Q1 Predictions Mean       -90.8733
trainer/Q1 Predictions Std         47.6675
trainer/Q1 Predictions Max        -21.2889
trainer/Q1 Predictions Min       -185.807
trainer/Q2 Predictions Mean       -90.9193
trainer/Q2 Predictions Std         47.6409
trainer/Q2 Predictions Max        -21.3676
trainer/Q2 Predictions Min       -186.395
trainer/Q Targets Mean            -90.2458
trainer/Q Targets Std              48.8049
trainer/Q Targets Max              -3.08598
trainer/Q Targets Min            -191.293
trainer/Log Pis Mean                2.00851
trainer/Log Pis Std                 1.49135
trainer/Log Pis Max                 5.27556
trainer/Log Pis Min                -3.71899
trainer/Policy mu Mean             -0.0083022
trainer/Policy mu Std               0.922358
trainer/Policy mu Max               2.64537
trainer/Policy mu Min              -3.18027
trainer/Policy log std Mean        -1.80725
trainer/Policy log std Std          0.633207
trainer/Policy log std Max         -0.256345
trainer/Policy log std Min         -2.69118
trainer/Alpha                       0.0687542
trainer/Alpha Loss                  0.0227752
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.76995
exploration/Rewards Std             1.19613
exploration/Rewards Max            -0.0129472
exploration/Rewards Min            -9.66055
exploration/Returns Mean         -176.995
exploration/Returns Std            93.544
exploration/Returns Max           -27.9089
exploration/Returns Min          -304.572
exploration/Actions Mean           -0.00812007
exploration/Actions Std             0.214735
exploration/Actions Max             0.995459
exploration/Actions Min            -0.999778
exploration/Num Paths               5
exploration/Average Returns      -176.995
evaluation/num steps total     114000
evaluation/num paths total       1140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.8516
evaluation/Rewards Std              1.12758
evaluation/Rewards Max             -0.14006
evaluation/Rewards Min             -9.88044
evaluation/Returns Mean          -185.16
evaluation/Returns Std             88.7048
evaluation/Returns Max            -24.0453
evaluation/Returns Min           -309.927
evaluation/Actions Mean            -0.00148307
evaluation/Actions Std              0.165105
evaluation/Actions Max              0.998181
evaluation/Actions Min             -0.999222
evaluation/Num Paths               15
evaluation/Average Returns       -185.16
time/data storing (s)               0.00297608
time/evaluation sampling (s)        0.32837
time/exploration sampling (s)       0.137584
time/logging (s)                    0.00477845
time/saving (s)                     0.00195603
time/training (s)                   1.92056
time/epoch (s)                      2.39622
time/total (s)                    186.847
Epoch                              75
-----------------------------  ---------------
2019-04-22 23:56:28.432954 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size              38700
trainer/QF1 Loss                   46.8691
trainer/QF2 Loss                   46.4242
trainer/Policy Loss                82.1412
trainer/Q1 Predictions Mean       -81.0602
trainer/Q1 Predictions Std         49.962
trainer/Q1 Predictions Max        -21.1415
trainer/Q1 Predictions Min       -185.849
trainer/Q2 Predictions Mean       -81.0946
trainer/Q2 Predictions Std         50.0039
trainer/Q2 Predictions Max        -21.1177
trainer/Q2 Predictions Min       -186.599
trainer/Q Targets Mean            -80.5919
trainer/Q Targets Std              51.2106
trainer/Q Targets Max              -0.619523
trainer/Q Targets Min            -185.946
trainer/Log Pis Mean                1.99927
trainer/Log Pis Std                 1.6192
trainer/Log Pis Max                 7.06395
trainer/Log Pis Min                -2.60546
trainer/Policy mu Mean             -0.105506
trainer/Policy mu Std               0.956161
trainer/Policy mu Max               3.06072
trainer/Policy mu Min              -3.15979
trainer/Policy log std Mean        -1.76028
trainer/Policy log std Std          0.604313
trainer/Policy log std Max         -0.164535
trainer/Policy log std Min         -2.66635
trainer/Alpha                       0.0687927
trainer/Alpha Loss                 -0.00196055
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.79522
exploration/Rewards Std             1.14423
exploration/Rewards Max            -0.119145
exploration/Rewards Min            -8.59232
exploration/Returns Mean         -179.522
exploration/Returns Std            90.7312
exploration/Returns Max           -61.2059
exploration/Returns Min          -313.019
exploration/Actions Mean            0.00347918
exploration/Actions Std             0.252071
exploration/Actions Max             0.997236
exploration/Actions Min            -0.997672
exploration/Num Paths               5
exploration/Average Returns      -179.522
evaluation/num steps total     115500
evaluation/num paths total       1155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.56556
evaluation/Rewards Std              1.19392
evaluation/Rewards Max             -0.00942054
evaluation/Rewards Min             -9.79136
evaluation/Returns Mean          -156.556
evaluation/Returns Std             91.9578
evaluation/Returns Max             -5.58131
evaluation/Returns Min           -301.998
evaluation/Actions Mean            -0.015698
evaluation/Actions Std              0.179277
evaluation/Actions Max              0.986307
evaluation/Actions Min             -0.999267
evaluation/Num Paths               15
evaluation/Average Returns       -156.556
time/data storing (s)               0.00284827
time/evaluation sampling (s)        0.328797
time/exploration sampling (s)       0.14171
time/logging (s)                    0.00474442
time/saving (s)                     0.00193127
time/training (s)                   1.9249
time/epoch (s)                      2.40493
time/total (s)                    189.257
Epoch                              76
-----------------------------  ---------------
2019-04-22 23:56:30.853048 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    3.24324
trainer/QF2 Loss                    3.32296
trainer/Policy Loss                87.8296
trainer/Q1 Predictions Mean       -86.6064
trainer/Q1 Predictions Std         42.5745
trainer/Q1 Predictions Max        -20.1586
trainer/Q1 Predictions Min       -167.321
trainer/Q2 Predictions Mean       -86.6279
trainer/Q2 Predictions Std         42.6023
trainer/Q2 Predictions Max        -20.3029
trainer/Q2 Predictions Min       -166.252
trainer/Q Targets Mean            -88.009
trainer/Q Targets Std              43.3918
trainer/Q Targets Max             -20.9777
trainer/Q Targets Min            -172.826
trainer/Log Pis Mean                1.91641
trainer/Log Pis Std                 1.15601
trainer/Log Pis Max                 5.67134
trainer/Log Pis Min                -1.61283
trainer/Policy mu Mean              0.0715014
trainer/Policy mu Std               0.843609
trainer/Policy mu Max               3.1424
trainer/Policy mu Min              -2.18348
trainer/Policy log std Mean        -1.82204
trainer/Policy log std Std          0.576215
trainer/Policy log std Max         -0.281882
trainer/Policy log std Min         -2.67633
trainer/Alpha                       0.0690889
trainer/Alpha Loss                 -0.223366
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.34508
exploration/Rewards Std             1.12482
exploration/Rewards Max            -0.00793346
exploration/Rewards Min            -7.16592
exploration/Returns Mean         -134.508
exploration/Returns Std            92.0827
exploration/Returns Max           -17.9285
exploration/Returns Min          -238.507
exploration/Actions Mean           -0.0080659
exploration/Actions Std             0.213423
exploration/Actions Max             0.999189
exploration/Actions Min            -0.999257
exploration/Num Paths               5
exploration/Average Returns      -134.508
evaluation/num steps total     117000
evaluation/num paths total       1170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.54474
evaluation/Rewards Std              1.16968
evaluation/Rewards Max             -0.104048
evaluation/Rewards Min             -9.63225
evaluation/Returns Mean          -154.474
evaluation/Returns Std             84.6898
evaluation/Returns Max            -30.5701
evaluation/Returns Min           -315.595
evaluation/Actions Mean            -0.00195139
evaluation/Actions Std              0.176618
evaluation/Actions Max              0.997028
evaluation/Actions Min             -0.998866
evaluation/Num Paths               15
evaluation/Average Returns       -154.474
time/data storing (s)               0.00297031
time/evaluation sampling (s)        0.327463
time/exploration sampling (s)       0.140198
time/logging (s)                    0.00449165
time/saving (s)                     0.00195611
time/training (s)                   1.937
time/epoch (s)                      2.41408
time/total (s)                    191.675
Epoch                              77
-----------------------------  ---------------
2019-04-22 23:56:33.258199 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size              39700
trainer/QF1 Loss                  126.675
trainer/QF2 Loss                  125.926
trainer/Policy Loss                81.0208
trainer/Q1 Predictions Mean       -79.5534
trainer/Q1 Predictions Std         50.4974
trainer/Q1 Predictions Max        -20.5866
trainer/Q1 Predictions Min       -189.285
trainer/Q2 Predictions Mean       -79.6179
trainer/Q2 Predictions Std         50.5982
trainer/Q2 Predictions Max        -20.5985
trainer/Q2 Predictions Min       -189.698
trainer/Q Targets Mean            -80.0311
trainer/Q Targets Std              51.7959
trainer/Q Targets Max              -1.59875
trainer/Q Targets Min            -192.408
trainer/Log Pis Mean                2.29004
trainer/Log Pis Std                 1.44028
trainer/Log Pis Max                 9.12932
trainer/Log Pis Min                -0.641951
trainer/Policy mu Mean             -0.00184596
trainer/Policy mu Std               1.03552
trainer/Policy mu Max               3.85787
trainer/Policy mu Min              -3.52387
trainer/Policy log std Mean        -1.788
trainer/Policy log std Std          0.621753
trainer/Policy log std Max         -0.177189
trainer/Policy log std Min         -2.68399
trainer/Alpha                       0.0674281
trainer/Alpha Loss                  0.782195
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.5893
exploration/Rewards Std             0.91494
exploration/Rewards Max            -0.899244
exploration/Rewards Min            -9.44489
exploration/Returns Mean         -158.93
exploration/Returns Std            19.4425
exploration/Returns Max          -128.447
exploration/Returns Min          -189.302
exploration/Actions Mean           -0.0015752
exploration/Actions Std             0.238929
exploration/Actions Max             0.99964
exploration/Actions Min            -0.995054
exploration/Num Paths               5
exploration/Average Returns      -158.93
evaluation/num steps total     118500
evaluation/num paths total       1185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.45682
evaluation/Rewards Std              1.2819
evaluation/Rewards Max             -0.0856124
evaluation/Rewards Min            -10.375
evaluation/Returns Mean          -145.682
evaluation/Returns Std             67.2553
evaluation/Returns Max            -55.5588
evaluation/Returns Min           -294.375
evaluation/Actions Mean            -0.00135029
evaluation/Actions Std              0.20275
evaluation/Actions Max              0.99844
evaluation/Actions Min             -0.998888
evaluation/Num Paths               15
evaluation/Average Returns       -145.682
time/data storing (s)               0.00301321
time/evaluation sampling (s)        0.326266
time/exploration sampling (s)       0.136324
time/logging (s)                    0.00373203
time/saving (s)                     0.00197727
time/training (s)                   1.92727
time/epoch (s)                      2.39858
time/total (s)                    194.078
Epoch                              78
-----------------------------  ---------------
2019-04-22 23:56:35.671387 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    5.89141
trainer/QF2 Loss                    6.19843
trainer/Policy Loss                85.7277
trainer/Q1 Predictions Mean       -84.7212
trainer/Q1 Predictions Std         42.6381
trainer/Q1 Predictions Max        -20.2797
trainer/Q1 Predictions Min       -162.405
trainer/Q2 Predictions Mean       -84.6597
trainer/Q2 Predictions Std         42.5807
trainer/Q2 Predictions Max        -20.3339
trainer/Q2 Predictions Min       -162.828
trainer/Q Targets Mean            -85.0561
trainer/Q Targets Std              43.5095
trainer/Q Targets Max              -1.95495
trainer/Q Targets Min            -164.558
trainer/Log Pis Mean                1.79388
trainer/Log Pis Std                 1.35501
trainer/Log Pis Max                 6.48372
trainer/Log Pis Min                -2.58794
trainer/Policy mu Mean             -0.0778267
trainer/Policy mu Std               0.921461
trainer/Policy mu Max               3.15769
trainer/Policy mu Min              -3.0767
trainer/Policy log std Mean        -1.72579
trainer/Policy log std Std          0.605568
trainer/Policy log std Max         -0.0347605
trainer/Policy log std Min         -2.82825
trainer/Alpha                       0.0682025
trainer/Alpha Loss                 -0.55345
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26848
exploration/Rewards Std             1.10618
exploration/Rewards Max            -0.00882994
exploration/Rewards Min            -6.44419
exploration/Returns Mean         -126.848
exploration/Returns Std            89.8744
exploration/Returns Max           -29.6591
exploration/Returns Min          -242.002
exploration/Actions Mean            0.0100812
exploration/Actions Std             0.204489
exploration/Actions Max             0.999896
exploration/Actions Min            -0.996083
exploration/Num Paths               5
exploration/Average Returns      -126.848
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.54916
evaluation/Rewards Std              1.2246
evaluation/Rewards Max             -0.0453238
evaluation/Rewards Min            -10.3623
evaluation/Returns Mean          -154.916
evaluation/Returns Std             86.1713
evaluation/Returns Max             -7.27165
evaluation/Returns Min           -311.315
evaluation/Actions Mean             0.00165244
evaluation/Actions Std              0.187433
evaluation/Actions Max              0.99862
evaluation/Actions Min             -0.999725
evaluation/Num Paths               15
evaluation/Average Returns       -154.916
time/data storing (s)               0.00300781
time/evaluation sampling (s)        0.332351
time/exploration sampling (s)       0.13823
time/logging (s)                    0.0047869
time/saving (s)                     0.00197332
time/training (s)                   1.92786
time/epoch (s)                      2.40821
time/total (s)                    196.49
Epoch                              79
-----------------------------  ---------------
2019-04-22 23:56:38.093068 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size              40700
trainer/QF1 Loss                   56.4628
trainer/QF2 Loss                   56.7236
trainer/Policy Loss                80.1314
trainer/Q1 Predictions Mean       -79.0186
trainer/Q1 Predictions Std         42.4239
trainer/Q1 Predictions Max        -19.5985
trainer/Q1 Predictions Min       -157.821
trainer/Q2 Predictions Mean       -79.0549
trainer/Q2 Predictions Std         42.4085
trainer/Q2 Predictions Max        -19.5671
trainer/Q2 Predictions Min       -158.097
trainer/Q Targets Mean            -78.2303
trainer/Q Targets Std              44.2732
trainer/Q Targets Max              -1.08893
trainer/Q Targets Min            -159.887
trainer/Log Pis Mean                1.85419
trainer/Log Pis Std                 1.40102
trainer/Log Pis Max                 5.61129
trainer/Log Pis Min                -3.95656
trainer/Policy mu Mean             -0.0615029
trainer/Policy mu Std               0.89555
trainer/Policy mu Max               2.8275
trainer/Policy mu Min              -2.99726
trainer/Policy log std Mean        -1.821
trainer/Policy log std Std          0.585907
trainer/Policy log std Max         -0.367903
trainer/Policy log std Min         -2.8688
trainer/Alpha                       0.068801
trainer/Alpha Loss                 -0.390261
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.00809
exploration/Rewards Std             1.27808
exploration/Rewards Max            -0.0265899
exploration/Rewards Min           -10.038
exploration/Returns Mean         -200.809
exploration/Returns Std           107.079
exploration/Returns Max           -24.9945
exploration/Returns Min          -323.438
exploration/Actions Mean           -0.0304201
exploration/Actions Std             0.205843
exploration/Actions Max             0.8402
exploration/Actions Min            -0.997286
exploration/Num Paths               5
exploration/Average Returns      -200.809
evaluation/num steps total     121500
evaluation/num paths total       1215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.77252
evaluation/Rewards Std              1.0396
evaluation/Rewards Max             -0.0766676
evaluation/Rewards Min             -8.93165
evaluation/Returns Mean          -177.252
evaluation/Returns Std             89.3255
evaluation/Returns Max            -25.9432
evaluation/Returns Min           -310.456
evaluation/Actions Mean            -0.00752899
evaluation/Actions Std              0.165417
evaluation/Actions Max              0.997351
evaluation/Actions Min             -0.997342
evaluation/Num Paths               15
evaluation/Average Returns       -177.252
time/data storing (s)               0.00296844
time/evaluation sampling (s)        0.341437
time/exploration sampling (s)       0.148356
time/logging (s)                    0.00349543
time/saving (s)                     0.00158716
time/training (s)                   1.91653
time/epoch (s)                      2.41437
time/total (s)                    198.909
Epoch                              80
-----------------------------  ---------------
2019-04-22 23:56:40.524700 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                   25.6729
trainer/QF2 Loss                   25.5958
trainer/Policy Loss                80.2951
trainer/Q1 Predictions Mean       -78.6786
trainer/Q1 Predictions Std         44.2105
trainer/Q1 Predictions Max        -19.4221
trainer/Q1 Predictions Min       -171.31
trainer/Q2 Predictions Mean       -78.7296
trainer/Q2 Predictions Std         44.3433
trainer/Q2 Predictions Max        -19.4151
trainer/Q2 Predictions Min       -172.802
trainer/Q Targets Mean            -78.8101
trainer/Q Targets Std              45.2296
trainer/Q Targets Max              -1.30416
trainer/Q Targets Min            -171.98
trainer/Log Pis Mean                2.18964
trainer/Log Pis Std                 1.36505
trainer/Log Pis Max                 6.52432
trainer/Log Pis Min                -0.340647
trainer/Policy mu Mean             -0.200509
trainer/Policy mu Std               0.910857
trainer/Policy mu Max               2.56639
trainer/Policy mu Min              -3.62049
trainer/Policy log std Mean        -1.9055
trainer/Policy log std Std          0.570513
trainer/Policy log std Max         -0.435283
trainer/Policy log std Min         -2.84886
trainer/Alpha                       0.069456
trainer/Alpha Loss                  0.505829
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.30389
exploration/Rewards Std             1.25387
exploration/Rewards Max            -0.043663
exploration/Rewards Min            -9.37913
exploration/Returns Mean         -130.389
exploration/Returns Std            79.4785
exploration/Returns Max           -22.747
exploration/Returns Min          -241.357
exploration/Actions Mean            0.00357543
exploration/Actions Std             0.220037
exploration/Actions Max             0.999834
exploration/Actions Min            -0.999247
exploration/Num Paths               5
exploration/Average Returns      -130.389
evaluation/num steps total     123000
evaluation/num paths total       1230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.58351
evaluation/Rewards Std              1.012
evaluation/Rewards Max             -0.177818
evaluation/Rewards Min            -10.7687
evaluation/Returns Mean          -158.351
evaluation/Returns Std             68.9769
evaluation/Returns Max            -30.3926
evaluation/Returns Min           -310.006
evaluation/Actions Mean            -0.0184718
evaluation/Actions Std              0.189326
evaluation/Actions Max              0.99823
evaluation/Actions Min             -0.999649
evaluation/Num Paths               15
evaluation/Average Returns       -158.351
time/data storing (s)               0.00284607
time/evaluation sampling (s)        0.331473
time/exploration sampling (s)       0.138393
time/logging (s)                    0.00475791
time/saving (s)                     0.00193321
time/training (s)                   1.94808
time/epoch (s)                      2.42748
time/total (s)                    201.341
Epoch                              81
-----------------------------  ---------------
2019-04-22 23:56:42.948576 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size              41700
trainer/QF1 Loss                    2.37435
trainer/QF2 Loss                    2.27344
trainer/Policy Loss                85.6501
trainer/Q1 Predictions Mean       -84.3695
trainer/Q1 Predictions Std         46.3945
trainer/Q1 Predictions Max        -19.0925
trainer/Q1 Predictions Min       -190.975
trainer/Q2 Predictions Mean       -84.3243
trainer/Q2 Predictions Std         46.4754
trainer/Q2 Predictions Max        -18.9781
trainer/Q2 Predictions Min       -190.034
trainer/Q Targets Mean            -85.4041
trainer/Q Targets Std              47.121
trainer/Q Targets Max             -19.2952
trainer/Q Targets Min            -191.066
trainer/Log Pis Mean                2.15666
trainer/Log Pis Std                 1.6437
trainer/Log Pis Max                 9.09578
trainer/Log Pis Min                -2.01423
trainer/Policy mu Mean             -0.0873561
trainer/Policy mu Std               0.961658
trainer/Policy mu Max               2.80917
trainer/Policy mu Min              -3.417
trainer/Policy log std Mean        -1.79889
trainer/Policy log std Std          0.623091
trainer/Policy log std Max         -0.0961754
trainer/Policy log std Min         -2.78211
trainer/Alpha                       0.0700001
trainer/Alpha Loss                  0.416581
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.00804
exploration/Rewards Std             1.11718
exploration/Rewards Max            -0.0375763
exploration/Rewards Min            -7.33852
exploration/Returns Mean         -200.804
exploration/Returns Std            98.4639
exploration/Returns Max           -44.5705
exploration/Returns Min          -298.704
exploration/Actions Mean            0.00370293
exploration/Actions Std             0.224883
exploration/Actions Max             0.968277
exploration/Actions Min            -0.997237
exploration/Num Paths               5
exploration/Average Returns      -200.804
evaluation/num steps total     124500
evaluation/num paths total       1245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.55407
evaluation/Rewards Std              0.907444
evaluation/Rewards Max             -0.0169122
evaluation/Rewards Min            -10.4423
evaluation/Returns Mean          -155.407
evaluation/Returns Std             61.2333
evaluation/Returns Max            -26.5777
evaluation/Returns Min           -305.528
evaluation/Actions Mean            -0.0149846
evaluation/Actions Std              0.173442
evaluation/Actions Max              0.998614
evaluation/Actions Min             -0.999779
evaluation/Num Paths               15
evaluation/Average Returns       -155.407
time/data storing (s)               0.00285039
time/evaluation sampling (s)        0.335903
time/exploration sampling (s)       0.142288
time/logging (s)                    0.00477618
time/saving (s)                     0.00949723
time/training (s)                   1.92253
time/epoch (s)                      2.41784
time/total (s)                    203.763
Epoch                              82
-----------------------------  ---------------
2019-04-22 23:56:45.378050 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                    1.40529
trainer/QF2 Loss                    1.58692
trainer/Policy Loss                81.5861
trainer/Q1 Predictions Mean       -80.3484
trainer/Q1 Predictions Std         46.2927
trainer/Q1 Predictions Max        -18.2289
trainer/Q1 Predictions Min       -186.299
trainer/Q2 Predictions Mean       -80.3492
trainer/Q2 Predictions Std         46.2939
trainer/Q2 Predictions Max        -18.1213
trainer/Q2 Predictions Min       -185.884
trainer/Q Targets Mean            -81.1857
trainer/Q Targets Std              46.6343
trainer/Q Targets Max             -18.7773
trainer/Q Targets Min            -186.88
trainer/Log Pis Mean                2.35167
trainer/Log Pis Std                 1.43454
trainer/Log Pis Max                 6.32701
trainer/Log Pis Min                -2.25813
trainer/Policy mu Mean             -0.268286
trainer/Policy mu Std               1.01421
trainer/Policy mu Max               3.0974
trainer/Policy mu Min              -3.34379
trainer/Policy log std Mean        -1.79612
trainer/Policy log std Std          0.653621
trainer/Policy log std Max         -0.195906
trainer/Policy log std Min         -2.98893
trainer/Alpha                       0.0678042
trainer/Alpha Loss                  0.946486
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.32072
exploration/Rewards Std             1.06192
exploration/Rewards Max            -0.00690321
exploration/Rewards Min            -7.7959
exploration/Returns Mean         -132.072
exploration/Returns Std            84.7686
exploration/Returns Max           -28.1287
exploration/Returns Min          -242.167
exploration/Actions Mean            0.0158898
exploration/Actions Std             0.228106
exploration/Actions Max             0.999838
exploration/Actions Min            -0.998684
exploration/Num Paths               5
exploration/Average Returns      -132.072
evaluation/num steps total     126000
evaluation/num paths total       1260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.86751
evaluation/Rewards Std              1.09225
evaluation/Rewards Max             -0.0757652
evaluation/Rewards Min            -10.0157
evaluation/Returns Mean          -186.751
evaluation/Returns Std             79.5629
evaluation/Returns Max            -19.5683
evaluation/Returns Min           -283.441
evaluation/Actions Mean            -0.013096
evaluation/Actions Std              0.184577
evaluation/Actions Max              0.984537
evaluation/Actions Min             -0.999833
evaluation/Num Paths               15
evaluation/Average Returns       -186.751
time/data storing (s)               0.00303816
time/evaluation sampling (s)        0.32315
time/exploration sampling (s)       0.140923
time/logging (s)                    0.00477678
time/saving (s)                     0.00196518
time/training (s)                   1.94929
time/epoch (s)                      2.42315
time/total (s)                    206.19
Epoch                              83
-----------------------------  ---------------
2019-04-22 23:56:47.790063 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                    1.2088
trainer/QF2 Loss                    1.51385
trainer/Policy Loss                80.2063
trainer/Q1 Predictions Mean       -79.0547
trainer/Q1 Predictions Std         45.3548
trainer/Q1 Predictions Max        -17.8912
trainer/Q1 Predictions Min       -161.031
trainer/Q2 Predictions Mean       -79.0254
trainer/Q2 Predictions Std         45.2349
trainer/Q2 Predictions Max        -17.8133
trainer/Q2 Predictions Min       -160.791
trainer/Q Targets Mean            -79.7168
trainer/Q Targets Std              45.7418
trainer/Q Targets Max             -18.5242
trainer/Q Targets Min            -160.848
trainer/Log Pis Mean                2.03168
trainer/Log Pis Std                 1.24321
trainer/Log Pis Max                 6.61599
trainer/Log Pis Min                -1.50494
trainer/Policy mu Mean              0.197304
trainer/Policy mu Std               0.925306
trainer/Policy mu Max               3.60976
trainer/Policy mu Min              -2.65972
trainer/Policy log std Mean        -1.8238
trainer/Policy log std Std          0.625714
trainer/Policy log std Max         -0.0625406
trainer/Policy log std Min         -2.83486
trainer/Alpha                       0.0673646
trainer/Alpha Loss                  0.0854648
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.83431
exploration/Rewards Std             0.956274
exploration/Rewards Max            -0.520606
exploration/Rewards Min            -9.35221
exploration/Returns Mean         -183.431
exploration/Returns Std            62.751
exploration/Returns Max          -136.64
exploration/Returns Min          -304.132
exploration/Actions Mean           -0.016018
exploration/Actions Std             0.235892
exploration/Actions Max             0.998987
exploration/Actions Min            -0.998523
exploration/Num Paths               5
exploration/Average Returns      -183.431
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.45327
evaluation/Rewards Std              1.30306
evaluation/Rewards Max             -0.0657313
evaluation/Rewards Min             -9.88903
evaluation/Returns Mean          -145.327
evaluation/Returns Std             93.9938
evaluation/Returns Max             -7.72392
evaluation/Returns Min           -304.526
evaluation/Actions Mean            -0.00744711
evaluation/Actions Std              0.184405
evaluation/Actions Max              0.997324
evaluation/Actions Min             -0.999139
evaluation/Num Paths               15
evaluation/Average Returns       -145.327
time/data storing (s)               0.00283243
time/evaluation sampling (s)        0.330965
time/exploration sampling (s)       0.138874
time/logging (s)                    0.00482469
time/saving (s)                     0.00194044
time/training (s)                   1.92634
time/epoch (s)                      2.40578
time/total (s)                    208.601
Epoch                              84
-----------------------------  ---------------
2019-04-22 23:56:50.225346 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                    0.836508
trainer/QF2 Loss                    0.878127
trainer/Policy Loss                77.0309
trainer/Q1 Predictions Mean       -76.0188
trainer/Q1 Predictions Std         45.2302
trainer/Q1 Predictions Max        -18.3536
trainer/Q1 Predictions Min       -177.603
trainer/Q2 Predictions Mean       -76.0042
trainer/Q2 Predictions Std         45.2996
trainer/Q2 Predictions Max        -18.2707
trainer/Q2 Predictions Min       -176.763
trainer/Q Targets Mean            -76.6617
trainer/Q Targets Std              45.5029
trainer/Q Targets Max             -18.0696
trainer/Q Targets Min            -175.848
trainer/Log Pis Mean                1.84531
trainer/Log Pis Std                 1.23083
trainer/Log Pis Max                 5.61532
trainer/Log Pis Min                -2.12322
trainer/Policy mu Mean              0.124999
trainer/Policy mu Std               0.86269
trainer/Policy mu Max               3.16991
trainer/Policy mu Min              -2.86527
trainer/Policy log std Mean        -1.81418
trainer/Policy log std Std          0.554385
trainer/Policy log std Max         -0.206934
trainer/Policy log std Min         -2.70643
trainer/Alpha                       0.0679275
trainer/Alpha Loss                 -0.415979
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.48652
exploration/Rewards Std             1.16125
exploration/Rewards Max            -0.0198855
exploration/Rewards Min            -9.95142
exploration/Returns Mean         -148.652
exploration/Returns Std            68.6423
exploration/Returns Max           -54.7278
exploration/Returns Min          -248.774
exploration/Actions Mean            0.00786559
exploration/Actions Std             0.243235
exploration/Actions Max             0.999757
exploration/Actions Min            -0.998841
exploration/Num Paths               5
exploration/Average Returns      -148.652
evaluation/num steps total     129000
evaluation/num paths total       1290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.58348
evaluation/Rewards Std              0.896076
evaluation/Rewards Max             -0.0579767
evaluation/Rewards Min             -7.96301
evaluation/Returns Mean          -158.348
evaluation/Returns Std             72.5691
evaluation/Returns Max            -20.9007
evaluation/Returns Min           -309.696
evaluation/Actions Mean            -0.00292015
evaluation/Actions Std              0.147505
evaluation/Actions Max              0.998327
evaluation/Actions Min             -0.996628
evaluation/Num Paths               15
evaluation/Average Returns       -158.348
time/data storing (s)               0.00302971
time/evaluation sampling (s)        0.332849
time/exploration sampling (s)       0.143198
time/logging (s)                    0.00474039
time/saving (s)                     0.00193967
time/training (s)                   1.94311
time/epoch (s)                      2.42886
time/total (s)                    211.034
Epoch                              85
-----------------------------  ---------------
2019-04-22 23:56:52.656459 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size              43700
trainer/QF1 Loss                    0.677259
trainer/QF2 Loss                    0.876943
trainer/Policy Loss                82.1898
trainer/Q1 Predictions Mean       -80.8573
trainer/Q1 Predictions Std         44.1299
trainer/Q1 Predictions Max        -17.7988
trainer/Q1 Predictions Min       -157.528
trainer/Q2 Predictions Mean       -80.8384
trainer/Q2 Predictions Std         44.1223
trainer/Q2 Predictions Max        -17.7596
trainer/Q2 Predictions Min       -157.21
trainer/Q Targets Mean            -81.2715
trainer/Q Targets Std              44.2332
trainer/Q Targets Max             -17.6653
trainer/Q Targets Min            -158.009
trainer/Log Pis Mean                1.85811
trainer/Log Pis Std                 1.36266
trainer/Log Pis Max                 5.78302
trainer/Log Pis Min                -1.71371
trainer/Policy mu Mean              0.0846908
trainer/Policy mu Std               0.909681
trainer/Policy mu Max               3.16767
trainer/Policy mu Min              -2.69397
trainer/Policy log std Mean        -1.77771
trainer/Policy log std Std          0.570761
trainer/Policy log std Max         -0.069927
trainer/Policy log std Min         -2.6131
trainer/Alpha                       0.0669877
trainer/Alpha Loss                 -0.383566
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.43858
exploration/Rewards Std             0.751355
exploration/Rewards Max            -0.0418688
exploration/Rewards Min            -6.30307
exploration/Returns Mean         -143.858
exploration/Returns Std            62.3793
exploration/Returns Max           -29.7654
exploration/Returns Min          -203.869
exploration/Actions Mean           -0.0154948
exploration/Actions Std             0.20958
exploration/Actions Max             0.937376
exploration/Actions Min            -0.996815
exploration/Num Paths               5
exploration/Average Returns      -143.858
evaluation/num steps total     130500
evaluation/num paths total       1305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.41404
evaluation/Rewards Std              1.16122
evaluation/Rewards Max             -0.142625
evaluation/Rewards Min            -10.0257
evaluation/Returns Mean          -141.404
evaluation/Returns Std             85.1271
evaluation/Returns Max            -39.8876
evaluation/Returns Min           -325.791
evaluation/Actions Mean             0.00741807
evaluation/Actions Std              0.172729
evaluation/Actions Max              0.999386
evaluation/Actions Min             -0.998962
evaluation/Num Paths               15
evaluation/Average Returns       -141.404
time/data storing (s)               0.00307215
time/evaluation sampling (s)        0.326313
time/exploration sampling (s)       0.14216
time/logging (s)                    0.00476913
time/saving (s)                     0.0016118
time/training (s)                   1.94685
time/epoch (s)                      2.42478
time/total (s)                    213.463
Epoch                              86
-----------------------------  ---------------
2019-04-22 23:56:55.082171 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size              44200
trainer/QF1 Loss                    1.16052
trainer/QF2 Loss                    1.16959
trainer/Policy Loss                77.3224
trainer/Q1 Predictions Mean       -75.9885
trainer/Q1 Predictions Std         46.2692
trainer/Q1 Predictions Max        -17.2747
trainer/Q1 Predictions Min       -194.612
trainer/Q2 Predictions Mean       -76.0329
trainer/Q2 Predictions Std         46.2681
trainer/Q2 Predictions Max        -17.3247
trainer/Q2 Predictions Min       -195.222
trainer/Q Targets Mean            -76.7191
trainer/Q Targets Std              46.7304
trainer/Q Targets Max             -17.1742
trainer/Q Targets Min            -197.257
trainer/Log Pis Mean                2.16277
trainer/Log Pis Std                 1.3212
trainer/Log Pis Max                 6.66254
trainer/Log Pis Min                -2.99677
trainer/Policy mu Mean             -0.0639729
trainer/Policy mu Std               0.957777
trainer/Policy mu Max               2.78558
trainer/Policy mu Min              -3.27174
trainer/Policy log std Mean        -1.86408
trainer/Policy log std Std          0.642327
trainer/Policy log std Max         -0.394821
trainer/Policy log std Min         -2.85522
trainer/Alpha                       0.0694425
trainer/Alpha Loss                  0.434177
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.88308
exploration/Rewards Std             0.769368
exploration/Rewards Max            -0.291473
exploration/Rewards Min            -6.41993
exploration/Returns Mean         -188.308
exploration/Returns Std            56.7519
exploration/Returns Max           -76.1798
exploration/Returns Min          -222.807
exploration/Actions Mean            0.0148021
exploration/Actions Std             0.215293
exploration/Actions Max             0.999689
exploration/Actions Min            -0.965033
exploration/Num Paths               5
exploration/Average Returns      -188.308
evaluation/num steps total     132000
evaluation/num paths total       1320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.446
evaluation/Rewards Std              1.0373
evaluation/Rewards Max             -0.0104421
evaluation/Rewards Min             -9.61905
evaluation/Returns Mean          -144.6
evaluation/Returns Std             67.8546
evaluation/Returns Max            -19.8224
evaluation/Returns Min           -288.74
evaluation/Actions Mean            -0.00659499
evaluation/Actions Std              0.180641
evaluation/Actions Max              0.995208
evaluation/Actions Min             -0.999089
evaluation/Num Paths               15
evaluation/Average Returns       -144.6
time/data storing (s)               0.00296077
time/evaluation sampling (s)        0.333462
time/exploration sampling (s)       0.139665
time/logging (s)                    0.00479548
time/saving (s)                     0.0019461
time/training (s)                   1.93655
time/epoch (s)                      2.41938
time/total (s)                    215.887
Epoch                              87
-----------------------------  ---------------
2019-04-22 23:56:57.498644 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size              44700
trainer/QF1 Loss                    0.559611
trainer/QF2 Loss                    0.658394
trainer/Policy Loss                80.5693
trainer/Q1 Predictions Mean       -79.2332
trainer/Q1 Predictions Std         45.0427
trainer/Q1 Predictions Max        -16.7907
trainer/Q1 Predictions Min       -162.185
trainer/Q2 Predictions Mean       -79.323
trainer/Q2 Predictions Std         45.0441
trainer/Q2 Predictions Max        -16.7625
trainer/Q2 Predictions Min       -161.528
trainer/Q Targets Mean            -79.6337
trainer/Q Targets Std              45.3107
trainer/Q Targets Max             -16.8747
trainer/Q Targets Min            -162.956
trainer/Log Pis Mean                2.14728
trainer/Log Pis Std                 1.38594
trainer/Log Pis Max                 7.57356
trainer/Log Pis Min                -1.51743
trainer/Policy mu Mean              0.152597
trainer/Policy mu Std               0.966319
trainer/Policy mu Max               3.85213
trainer/Policy mu Min              -2.86679
trainer/Policy log std Mean        -1.81162
trainer/Policy log std Std          0.612172
trainer/Policy log std Max         -0.0911415
trainer/Policy log std Min         -2.69093
trainer/Alpha                       0.0723584
trainer/Alpha Loss                  0.386747
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.58803
exploration/Rewards Std             0.826869
exploration/Rewards Max            -0.617003
exploration/Rewards Min            -8.90049
exploration/Returns Mean         -158.803
exploration/Returns Std            40.9175
exploration/Returns Max          -120.178
exploration/Returns Min          -233.506
exploration/Actions Mean            0.0175079
exploration/Actions Std             0.250173
exploration/Actions Max             0.999561
exploration/Actions Min            -0.999463
exploration/Num Paths               5
exploration/Average Returns      -158.803
evaluation/num steps total     133500
evaluation/num paths total       1335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.88215
evaluation/Rewards Std              1.14689
evaluation/Rewards Max             -0.00885272
evaluation/Rewards Min             -8.9225
evaluation/Returns Mean          -188.215
evaluation/Returns Std             94.8144
evaluation/Returns Max             -8.71817
evaluation/Returns Min           -316.611
evaluation/Actions Mean            -0.0145101
evaluation/Actions Std              0.179984
evaluation/Actions Max              0.994961
evaluation/Actions Min             -0.999158
evaluation/Num Paths               15
evaluation/Average Returns       -188.215
time/data storing (s)               0.00282743
time/evaluation sampling (s)        0.332436
time/exploration sampling (s)       0.139198
time/logging (s)                    0.00487381
time/saving (s)                     0.00196367
time/training (s)                   1.92912
time/epoch (s)                      2.41042
time/total (s)                    218.302
Epoch                              88
-----------------------------  ---------------
2019-04-22 23:56:59.909471 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 89 finished
-----------------------------  ----------------
replay_buffer/size              45200
trainer/QF1 Loss                    0.776291
trainer/QF2 Loss                    0.914045
trainer/Policy Loss                74.1095
trainer/Q1 Predictions Mean       -72.8819
trainer/Q1 Predictions Std         43.5132
trainer/Q1 Predictions Max        -16.5364
trainer/Q1 Predictions Min       -170.015
trainer/Q2 Predictions Mean       -72.9044
trainer/Q2 Predictions Std         43.5093
trainer/Q2 Predictions Max        -16.5173
trainer/Q2 Predictions Min       -169.621
trainer/Q Targets Mean            -73.1851
trainer/Q Targets Std              43.6641
trainer/Q Targets Max             -16.6034
trainer/Q Targets Min            -173.768
trainer/Log Pis Mean                1.97991
trainer/Log Pis Std                 1.25132
trainer/Log Pis Max                 5.76775
trainer/Log Pis Min                -2.48039
trainer/Policy mu Mean              0.178081
trainer/Policy mu Std               0.954148
trainer/Policy mu Max               3.81003
trainer/Policy mu Min              -3.12642
trainer/Policy log std Mean        -1.75503
trainer/Policy log std Std          0.616568
trainer/Policy log std Max         -0.0481162
trainer/Policy log std Min         -2.6759
trainer/Alpha                       0.0694949
trainer/Alpha Loss                 -0.053583
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36147
exploration/Rewards Std             0.954788
exploration/Rewards Max            -0.0102692
exploration/Rewards Min            -7.29895
exploration/Returns Mean         -136.147
exploration/Returns Std            69.6824
exploration/Returns Max           -34.0448
exploration/Returns Min          -215.856
exploration/Actions Mean           -9.60722e-05
exploration/Actions Std             0.219988
exploration/Actions Max             0.99921
exploration/Actions Min            -0.999343
exploration/Num Paths               5
exploration/Average Returns      -136.147
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.33917
evaluation/Rewards Std              1.21843
evaluation/Rewards Max             -0.0422092
evaluation/Rewards Min            -10.9973
evaluation/Returns Mean          -133.917
evaluation/Returns Std             83.9475
evaluation/Returns Max            -21.2789
evaluation/Returns Min           -325.328
evaluation/Actions Mean             0.00883133
evaluation/Actions Std              0.191536
evaluation/Actions Max              0.998323
evaluation/Actions Min             -0.999261
evaluation/Num Paths               15
evaluation/Average Returns       -133.917
time/data storing (s)               0.00301261
time/evaluation sampling (s)        0.3284
time/exploration sampling (s)       0.142958
time/logging (s)                    0.00478728
time/saving (s)                     0.0019842
time/training (s)                   1.92324
time/epoch (s)                      2.40438
time/total (s)                    220.711
Epoch                              89
-----------------------------  ----------------
2019-04-22 23:57:02.334085 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 90 finished
-----------------------------  ----------------
replay_buffer/size              45700
trainer/QF1 Loss                    1.38679
trainer/QF2 Loss                    1.71676
trainer/Policy Loss                85.102
trainer/Q1 Predictions Mean       -84.0523
trainer/Q1 Predictions Std         44.5489
trainer/Q1 Predictions Max        -16.0814
trainer/Q1 Predictions Min       -185.832
trainer/Q2 Predictions Mean       -84.0042
trainer/Q2 Predictions Std         44.4764
trainer/Q2 Predictions Max        -16.0952
trainer/Q2 Predictions Min       -183.731
trainer/Q Targets Mean            -85.0441
trainer/Q Targets Std              44.7793
trainer/Q Targets Max             -16.2255
trainer/Q Targets Min            -187.393
trainer/Log Pis Mean                1.96028
trainer/Log Pis Std                 1.26499
trainer/Log Pis Max                 5.168
trainer/Log Pis Min                -2.65181
trainer/Policy mu Mean              0.00700249
trainer/Policy mu Std               0.888289
trainer/Policy mu Max               3.09663
trainer/Policy mu Min              -3.0196
trainer/Policy log std Mean        -1.82306
trainer/Policy log std Std          0.603315
trainer/Policy log std Max         -0.141045
trainer/Policy log std Min         -2.64763
trainer/Alpha                       0.0692243
trainer/Alpha Loss                 -0.106066
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.77539
exploration/Rewards Std             1.32151
exploration/Rewards Max            -0.0165497
exploration/Rewards Min            -9.57616
exploration/Returns Mean         -177.539
exploration/Returns Std            90.2733
exploration/Returns Max           -33.7333
exploration/Returns Min          -301.523
exploration/Actions Mean            0.0235307
exploration/Actions Std             0.243862
exploration/Actions Max             0.999678
exploration/Actions Min            -0.989221
exploration/Num Paths               5
exploration/Average Returns      -177.539
evaluation/num steps total     136500
evaluation/num paths total       1365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.51219
evaluation/Rewards Std              1.24011
evaluation/Rewards Max             -0.0140357
evaluation/Rewards Min             -9.72187
evaluation/Returns Mean          -151.219
evaluation/Returns Std            100.067
evaluation/Returns Max             -7.94061
evaluation/Returns Min           -313.143
evaluation/Actions Mean            -0.000384266
evaluation/Actions Std              0.188958
evaluation/Actions Max              0.997603
evaluation/Actions Min             -0.998629
evaluation/Num Paths               15
evaluation/Average Returns       -151.219
time/data storing (s)               0.00296749
time/evaluation sampling (s)        0.331088
time/exploration sampling (s)       0.136359
time/logging (s)                    0.00481755
time/saving (s)                     0.00196101
time/training (s)                   1.94103
time/epoch (s)                      2.41822
time/total (s)                    223.133
Epoch                              90
-----------------------------  ----------------
2019-04-22 23:57:04.748771 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                    0.565595
trainer/QF2 Loss                    0.643551
trainer/Policy Loss                76.8277
trainer/Q1 Predictions Mean       -75.7422
trainer/Q1 Predictions Std         42.2827
trainer/Q1 Predictions Max        -15.5124
trainer/Q1 Predictions Min       -181.238
trainer/Q2 Predictions Mean       -75.7476
trainer/Q2 Predictions Std         42.2031
trainer/Q2 Predictions Max        -15.3886
trainer/Q2 Predictions Min       -180.341
trainer/Q Targets Mean            -76.2501
trainer/Q Targets Std              42.5438
trainer/Q Targets Max             -15.7108
trainer/Q Targets Min            -180.571
trainer/Log Pis Mean                1.8628
trainer/Log Pis Std                 1.50353
trainer/Log Pis Max                 6.99943
trainer/Log Pis Min                -1.91142
trainer/Policy mu Mean              0.00334078
trainer/Policy mu Std               0.855407
trainer/Policy mu Max               3.22323
trainer/Policy mu Min              -3.19458
trainer/Policy log std Mean        -1.83779
trainer/Policy log std Std          0.562673
trainer/Policy log std Max         -0.0885229
trainer/Policy log std Min         -2.75476
trainer/Alpha                       0.069148
trainer/Alpha Loss                 -0.366528
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1066
exploration/Rewards Std             1.38357
exploration/Rewards Max            -0.00465591
exploration/Rewards Min            -9.48118
exploration/Returns Mean         -110.66
exploration/Returns Std            72.6529
exploration/Returns Max           -28.9052
exploration/Returns Min          -199.693
exploration/Actions Mean            0.00854539
exploration/Actions Std             0.245391
exploration/Actions Max             0.999614
exploration/Actions Min            -0.999948
exploration/Num Paths               5
exploration/Average Returns      -110.66
evaluation/num steps total     138000
evaluation/num paths total       1380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.60904
evaluation/Rewards Std              1.19825
evaluation/Rewards Max             -0.0815884
evaluation/Rewards Min            -10.8462
evaluation/Returns Mean          -160.904
evaluation/Returns Std             84.9164
evaluation/Returns Max            -16.8625
evaluation/Returns Min           -301.873
evaluation/Actions Mean             0.00319
evaluation/Actions Std              0.192795
evaluation/Actions Max              0.999583
evaluation/Actions Min             -0.999604
evaluation/Num Paths               15
evaluation/Average Returns       -160.904
time/data storing (s)               0.00296907
time/evaluation sampling (s)        0.331837
time/exploration sampling (s)       0.13847
time/logging (s)                    0.00351697
time/saving (s)                     0.00195615
time/training (s)                   1.92871
time/epoch (s)                      2.40746
time/total (s)                    225.545
Epoch                              91
-----------------------------  ---------------
2019-04-22 23:57:07.163679 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size              46700
trainer/QF1 Loss                  208.561
trainer/QF2 Loss                  208.353
trainer/Policy Loss                84.9702
trainer/Q1 Predictions Mean       -83.4676
trainer/Q1 Predictions Std         46.1203
trainer/Q1 Predictions Max        -15.5989
trainer/Q1 Predictions Min       -157.991
trainer/Q2 Predictions Mean       -83.4493
trainer/Q2 Predictions Std         46.1153
trainer/Q2 Predictions Max        -15.6397
trainer/Q2 Predictions Min       -157.948
trainer/Q Targets Mean            -82.9321
trainer/Q Targets Std              47.0094
trainer/Q Targets Max              -2.89381
trainer/Q Targets Min            -160.74
trainer/Log Pis Mean                2.08628
trainer/Log Pis Std                 1.72023
trainer/Log Pis Max                11.3633
trainer/Log Pis Min                -3.96872
trainer/Policy mu Mean             -0.034297
trainer/Policy mu Std               0.951512
trainer/Policy mu Max               3.28683
trainer/Policy mu Min              -4.24662
trainer/Policy log std Mean        -1.83867
trainer/Policy log std Std          0.605311
trainer/Policy log std Max         -0.130509
trainer/Policy log std Min         -2.72173
trainer/Alpha                       0.0701094
trainer/Alpha Loss                  0.229301
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.48876
exploration/Rewards Std             0.987583
exploration/Rewards Max            -0.196413
exploration/Rewards Min            -9.76656
exploration/Returns Mean         -148.876
exploration/Returns Std            58.1932
exploration/Returns Max           -80.8935
exploration/Returns Min          -232.751
exploration/Actions Mean           -0.0190027
exploration/Actions Std             0.240554
exploration/Actions Max             0.966123
exploration/Actions Min            -0.99957
exploration/Num Paths               5
exploration/Average Returns      -148.876
evaluation/num steps total     139500
evaluation/num paths total       1395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.69621
evaluation/Rewards Std              1.05753
evaluation/Rewards Max             -0.0979718
evaluation/Rewards Min            -10.1126
evaluation/Returns Mean          -169.621
evaluation/Returns Std             87.9297
evaluation/Returns Max            -13.7062
evaluation/Returns Min           -312.956
evaluation/Actions Mean             0.00243123
evaluation/Actions Std              0.15136
evaluation/Actions Max              0.998166
evaluation/Actions Min             -0.999147
evaluation/Num Paths               15
evaluation/Average Returns       -169.621
time/data storing (s)               0.00303999
time/evaluation sampling (s)        0.333468
time/exploration sampling (s)       0.138346
time/logging (s)                    0.00481877
time/saving (s)                     0.00195269
time/training (s)                   1.92935
time/epoch (s)                      2.41098
time/total (s)                    227.96
Epoch                              92
-----------------------------  ---------------
2019-04-22 23:57:09.582550 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 93 finished
-----------------------------  ----------------
replay_buffer/size              47200
trainer/QF1 Loss                   58.9072
trainer/QF2 Loss                   58.2812
trainer/Policy Loss                76.2029
trainer/Q1 Predictions Mean       -75.4196
trainer/Q1 Predictions Std         43.5933
trainer/Q1 Predictions Max        -15.3685
trainer/Q1 Predictions Min       -183.108
trainer/Q2 Predictions Mean       -75.4163
trainer/Q2 Predictions Std         43.6038
trainer/Q2 Predictions Max        -15.358
trainer/Q2 Predictions Min       -183.666
trainer/Q Targets Mean            -75.4999
trainer/Q Targets Std              44.7125
trainer/Q Targets Max              -0.246085
trainer/Q Targets Min            -185.799
trainer/Log Pis Mean                1.78433
trainer/Log Pis Std                 1.45931
trainer/Log Pis Max                 7.14059
trainer/Log Pis Min                -1.836
trainer/Policy mu Mean             -0.0506531
trainer/Policy mu Std               0.91752
trainer/Policy mu Max               2.92859
trainer/Policy mu Min              -3.09189
trainer/Policy log std Mean        -1.75367
trainer/Policy log std Std          0.5776
trainer/Policy log std Max         -0.248613
trainer/Policy log std Min         -2.6554
trainer/Alpha                       0.0702586
trainer/Alpha Loss                 -0.572684
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.68889
exploration/Rewards Std             1.1628
exploration/Rewards Max            -0.0183297
exploration/Rewards Min           -10.7672
exploration/Returns Mean         -168.889
exploration/Returns Std            61.0901
exploration/Returns Max           -74.0318
exploration/Returns Min          -242.248
exploration/Actions Mean            0.00524001
exploration/Actions Std             0.237019
exploration/Actions Max             0.999845
exploration/Actions Min            -0.998972
exploration/Num Paths               5
exploration/Average Returns      -168.889
evaluation/num steps total     141000
evaluation/num paths total       1410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.67852
evaluation/Rewards Std              0.957822
evaluation/Rewards Max             -0.0214868
evaluation/Rewards Min             -8.38207
evaluation/Returns Mean          -167.852
evaluation/Returns Std             78.4555
evaluation/Returns Max            -27.8168
evaluation/Returns Min           -289.882
evaluation/Actions Mean            -0.000138754
evaluation/Actions Std              0.153591
evaluation/Actions Max              0.996986
evaluation/Actions Min             -0.996149
evaluation/Num Paths               15
evaluation/Average Returns       -167.852
time/data storing (s)               0.00305286
time/evaluation sampling (s)        0.330144
time/exploration sampling (s)       0.135795
time/logging (s)                    0.0048168
time/saving (s)                     0.00196459
time/training (s)                   1.93665
time/epoch (s)                      2.41243
time/total (s)                    230.377
Epoch                              93
-----------------------------  ----------------
2019-04-22 23:57:12.005525 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 94 finished
-----------------------------  ----------------
replay_buffer/size              47700
trainer/QF1 Loss                  212.48
trainer/QF2 Loss                  212.821
trainer/Policy Loss                80.4827
trainer/Q1 Predictions Mean       -79.1435
trainer/Q1 Predictions Std         45.2572
trainer/Q1 Predictions Max        -14.8666
trainer/Q1 Predictions Min       -154.702
trainer/Q2 Predictions Mean       -79.1769
trainer/Q2 Predictions Std         45.281
trainer/Q2 Predictions Max        -14.8799
trainer/Q2 Predictions Min       -155.452
trainer/Q Targets Mean            -77.9363
trainer/Q Targets Std              47.9144
trainer/Q Targets Max              -1.28399
trainer/Q Targets Min            -157.604
trainer/Log Pis Mean                1.90156
trainer/Log Pis Std                 1.10555
trainer/Log Pis Max                 7.21836
trainer/Log Pis Min                -1.71677
trainer/Policy mu Mean              0.0690705
trainer/Policy mu Std               0.758872
trainer/Policy mu Max               2.88809
trainer/Policy mu Min              -2.66899
trainer/Policy log std Mean        -1.92132
trainer/Policy log std Std          0.515924
trainer/Policy log std Max         -0.437566
trainer/Policy log std Min         -2.78275
trainer/Alpha                       0.0714708
trainer/Alpha Loss                 -0.259709
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.71362
exploration/Rewards Std             1.09181
exploration/Rewards Max            -0.0212197
exploration/Rewards Min            -7.76801
exploration/Returns Mean         -171.362
exploration/Returns Std            90.4616
exploration/Returns Max           -34.2161
exploration/Returns Min          -292.176
exploration/Actions Mean            0.000536539
exploration/Actions Std             0.23546
exploration/Actions Max             0.99974
exploration/Actions Min            -0.999332
exploration/Num Paths               5
exploration/Average Returns      -171.362
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.65264
evaluation/Rewards Std              1.17006
evaluation/Rewards Max             -0.0710321
evaluation/Rewards Min            -10.9236
evaluation/Returns Mean          -165.264
evaluation/Returns Std             79.2314
evaluation/Returns Max            -19.1928
evaluation/Returns Min           -312.59
evaluation/Actions Mean            -0.0135522
evaluation/Actions Std              0.188892
evaluation/Actions Max              0.999542
evaluation/Actions Min             -0.999753
evaluation/Num Paths               15
evaluation/Average Returns       -165.264
time/data storing (s)               0.00275914
time/evaluation sampling (s)        0.330038
time/exploration sampling (s)       0.144662
time/logging (s)                    0.0048053
time/saving (s)                     0.00767089
time/training (s)                   1.92642
time/epoch (s)                      2.41636
time/total (s)                    232.798
Epoch                              94
-----------------------------  ----------------
2019-04-22 23:57:14.439184 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                  117.233
trainer/QF2 Loss                  116.576
trainer/Policy Loss                82.2785
trainer/Q1 Predictions Mean       -81.1507
trainer/Q1 Predictions Std         38.6041
trainer/Q1 Predictions Max        -14.8681
trainer/Q1 Predictions Min       -159.379
trainer/Q2 Predictions Mean       -81.131
trainer/Q2 Predictions Std         38.6133
trainer/Q2 Predictions Max        -14.6708
trainer/Q2 Predictions Min       -159.261
trainer/Q Targets Mean            -80.6377
trainer/Q Targets Std              40.1772
trainer/Q Targets Max              -0.155822
trainer/Q Targets Min            -160.114
trainer/Log Pis Mean                1.90394
trainer/Log Pis Std                 1.6264
trainer/Log Pis Max                 6.75823
trainer/Log Pis Min                -2.29894
trainer/Policy mu Mean              0.0625834
trainer/Policy mu Std               0.953602
trainer/Policy mu Max               3.46074
trainer/Policy mu Min              -2.8296
trainer/Policy log std Mean        -1.76033
trainer/Policy log std Std          0.610964
trainer/Policy log std Max          0.0932757
trainer/Policy log std Min         -2.65865
trainer/Alpha                       0.0722388
trainer/Alpha Loss                 -0.252438
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.69237
exploration/Rewards Std             1.20681
exploration/Rewards Max            -0.0102581
exploration/Rewards Min           -10.7735
exploration/Returns Mean         -169.237
exploration/Returns Std            72.6397
exploration/Returns Max           -75.3884
exploration/Returns Min          -283.29
exploration/Actions Mean            0.0202753
exploration/Actions Std             0.267701
exploration/Actions Max             0.999848
exploration/Actions Min            -0.994927
exploration/Num Paths               5
exploration/Average Returns      -169.237
evaluation/num steps total     144000
evaluation/num paths total       1440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.43728
evaluation/Rewards Std              1.24612
evaluation/Rewards Max             -0.0284073
evaluation/Rewards Min             -9.70042
evaluation/Returns Mean          -143.728
evaluation/Returns Std             89.6781
evaluation/Returns Max            -20.3643
evaluation/Returns Min           -270.973
evaluation/Actions Mean             0.00132334
evaluation/Actions Std              0.182053
evaluation/Actions Max              0.996765
evaluation/Actions Min             -0.999734
evaluation/Num Paths               15
evaluation/Average Returns       -143.728
time/data storing (s)               0.00309084
time/evaluation sampling (s)        0.327142
time/exploration sampling (s)       0.139975
time/logging (s)                    0.00481089
time/saving (s)                     0.00207525
time/training (s)                   1.95013
time/epoch (s)                      2.42723
time/total (s)                    235.229
Epoch                              95
-----------------------------  ---------------
2019-04-22 23:57:16.867148 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size              48700
trainer/QF1 Loss                    1.55433
trainer/QF2 Loss                    1.93775
trainer/Policy Loss                81.5765
trainer/Q1 Predictions Mean       -80.175
trainer/Q1 Predictions Std         43.8947
trainer/Q1 Predictions Max        -14.3987
trainer/Q1 Predictions Min       -156.818
trainer/Q2 Predictions Mean       -80.093
trainer/Q2 Predictions Std         43.8209
trainer/Q2 Predictions Max        -14.2126
trainer/Q2 Predictions Min       -155.848
trainer/Q Targets Mean            -81.1039
trainer/Q Targets Std              44.5054
trainer/Q Targets Max             -14.6792
trainer/Q Targets Min            -160.252
trainer/Log Pis Mean                2.14192
trainer/Log Pis Std                 0.955057
trainer/Log Pis Max                 5.07073
trainer/Log Pis Min                 0.0257205
trainer/Policy mu Mean             -0.121833
trainer/Policy mu Std               0.868189
trainer/Policy mu Max               2.62168
trainer/Policy mu Min              -3.40896
trainer/Policy log std Mean        -1.87919
trainer/Policy log std Std          0.570158
trainer/Policy log std Max         -0.434474
trainer/Policy log std Min         -2.72713
trainer/Alpha                       0.0729666
trainer/Alpha Loss                  0.371515
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.00494
exploration/Rewards Std             0.812466
exploration/Rewards Max            -1.24753
exploration/Rewards Min            -9.52691
exploration/Returns Mean         -200.494
exploration/Returns Std            37.6212
exploration/Returns Max          -157.336
exploration/Returns Min          -265.431
exploration/Actions Mean            0.0166546
exploration/Actions Std             0.260586
exploration/Actions Max             0.998774
exploration/Actions Min            -0.988031
exploration/Num Paths               5
exploration/Average Returns      -200.494
evaluation/num steps total     145500
evaluation/num paths total       1455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.30902
evaluation/Rewards Std              1.00464
evaluation/Rewards Max             -0.0731248
evaluation/Rewards Min             -8.63058
evaluation/Returns Mean          -130.902
evaluation/Returns Std             72.6598
evaluation/Returns Max            -11.9001
evaluation/Returns Min           -274.862
evaluation/Actions Mean            -0.00769641
evaluation/Actions Std              0.168219
evaluation/Actions Max              0.998447
evaluation/Actions Min             -0.999724
evaluation/Num Paths               15
evaluation/Average Returns       -130.902
time/data storing (s)               0.00292109
time/evaluation sampling (s)        0.333082
time/exploration sampling (s)       0.140797
time/logging (s)                    0.00477519
time/saving (s)                     0.00198687
time/training (s)                   1.93815
time/epoch (s)                      2.42171
time/total (s)                    237.655
Epoch                              96
-----------------------------  ---------------
2019-04-22 23:57:19.294084 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                   90.366
trainer/QF2 Loss                   89.4278
trainer/Policy Loss                76.6438
trainer/Q1 Predictions Mean       -75.4697
trainer/Q1 Predictions Std         42.5061
trainer/Q1 Predictions Max        -14.1441
trainer/Q1 Predictions Min       -165.985
trainer/Q2 Predictions Mean       -75.479
trainer/Q2 Predictions Std         42.5184
trainer/Q2 Predictions Max        -14.1447
trainer/Q2 Predictions Min       -165.689
trainer/Q Targets Mean            -75.0891
trainer/Q Targets Std              43.9166
trainer/Q Targets Max              -0.109758
trainer/Q Targets Min            -167.353
trainer/Log Pis Mean                2.04962
trainer/Log Pis Std                 1.3035
trainer/Log Pis Max                 4.86002
trainer/Log Pis Min                -2.25884
trainer/Policy mu Mean             -0.144236
trainer/Policy mu Std               0.923274
trainer/Policy mu Max               2.76389
trainer/Policy mu Min              -2.93254
trainer/Policy log std Mean        -1.82069
trainer/Policy log std Std          0.620094
trainer/Policy log std Max         -0.24231
trainer/Policy log std Min         -2.73342
trainer/Alpha                       0.0734754
trainer/Alpha Loss                  0.129556
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.39267
exploration/Rewards Std             0.943419
exploration/Rewards Max            -0.0375903
exploration/Rewards Min            -8.9104
exploration/Returns Mean         -139.267
exploration/Returns Std            50.1592
exploration/Returns Max           -62.9038
exploration/Returns Min          -189.622
exploration/Actions Mean            0.013673
exploration/Actions Std             0.241404
exploration/Actions Max             0.999378
exploration/Actions Min            -0.989712
exploration/Num Paths               5
exploration/Average Returns      -139.267
evaluation/num steps total     147000
evaluation/num paths total       1470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25658
evaluation/Rewards Std              1.0574
evaluation/Rewards Max             -0.0611844
evaluation/Rewards Min            -10.4281
evaluation/Returns Mean          -125.658
evaluation/Returns Std             76.3737
evaluation/Returns Max            -18.6159
evaluation/Returns Min           -282.074
evaluation/Actions Mean             0.00735304
evaluation/Actions Std              0.173184
evaluation/Actions Max              0.999244
evaluation/Actions Min             -0.995957
evaluation/Num Paths               15
evaluation/Average Returns       -125.658
time/data storing (s)               0.00303436
time/evaluation sampling (s)        0.330198
time/exploration sampling (s)       0.14239
time/logging (s)                    0.0047855
time/saving (s)                     0.00171064
time/training (s)                   1.93856
time/epoch (s)                      2.42067
time/total (s)                    240.08
Epoch                              97
-----------------------------  ---------------
2019-04-22 23:57:21.702854 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                    1.31909
trainer/QF2 Loss                    1.3369
trainer/Policy Loss                81.874
trainer/Q1 Predictions Mean       -80.968
trainer/Q1 Predictions Std         38.3025
trainer/Q1 Predictions Max        -14.0771
trainer/Q1 Predictions Min       -158.255
trainer/Q2 Predictions Mean       -80.959
trainer/Q2 Predictions Std         38.3162
trainer/Q2 Predictions Max        -13.9108
trainer/Q2 Predictions Min       -157.977
trainer/Q Targets Mean            -81.7559
trainer/Q Targets Std              38.5995
trainer/Q Targets Max             -14.1027
trainer/Q Targets Min            -159.998
trainer/Log Pis Mean                1.84303
trainer/Log Pis Std                 1.50194
trainer/Log Pis Max                 6.54096
trainer/Log Pis Min                -2.94089
trainer/Policy mu Mean             -0.0713307
trainer/Policy mu Std               0.936552
trainer/Policy mu Max               2.81403
trainer/Policy mu Min              -2.82373
trainer/Policy log std Mean        -1.80471
trainer/Policy log std Std          0.611975
trainer/Policy log std Max         -0.458203
trainer/Policy log std Min         -2.61238
trainer/Alpha                       0.0705328
trainer/Alpha Loss                 -0.416224
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.848536
exploration/Rewards Std             0.907308
exploration/Rewards Max            -0.0200356
exploration/Rewards Min            -5.25102
exploration/Returns Mean          -84.8536
exploration/Returns Std            79.7343
exploration/Returns Max           -24.7312
exploration/Returns Min          -228.654
exploration/Actions Mean           -0.00562612
exploration/Actions Std             0.199002
exploration/Actions Max             0.998463
exploration/Actions Min            -0.992051
exploration/Num Paths               5
exploration/Average Returns       -84.8536
evaluation/num steps total     148500
evaluation/num paths total       1485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.39532
evaluation/Rewards Std              0.929432
evaluation/Rewards Max             -0.126427
evaluation/Rewards Min             -8.69779
evaluation/Returns Mean          -139.532
evaluation/Returns Std             61.5916
evaluation/Returns Max            -25.0977
evaluation/Returns Min           -232.869
evaluation/Actions Mean             0.00470535
evaluation/Actions Std              0.179433
evaluation/Actions Max              0.997258
evaluation/Actions Min             -0.998367
evaluation/Num Paths               15
evaluation/Average Returns       -139.532
time/data storing (s)               0.00291826
time/evaluation sampling (s)        0.333451
time/exploration sampling (s)       0.140833
time/logging (s)                    0.00479069
time/saving (s)                     0.00196499
time/training (s)                   1.91995
time/epoch (s)                      2.40391
time/total (s)                    242.487
Epoch                              98
-----------------------------  ---------------
2019-04-22 23:57:24.120276 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                   57.8847
trainer/QF2 Loss                   56.9386
trainer/Policy Loss                77.19
trainer/Q1 Predictions Mean       -76.2017
trainer/Q1 Predictions Std         42.4382
trainer/Q1 Predictions Max        -13.292
trainer/Q1 Predictions Min       -151.855
trainer/Q2 Predictions Mean       -76.201
trainer/Q2 Predictions Std         42.4407
trainer/Q2 Predictions Max        -13.1548
trainer/Q2 Predictions Min       -151.633
trainer/Q Targets Mean            -77.18
trainer/Q Targets Std              43.8982
trainer/Q Targets Max              -6.51036
trainer/Q Targets Min            -154.279
trainer/Log Pis Mean                1.84289
trainer/Log Pis Std                 1.37783
trainer/Log Pis Max                 6.72384
trainer/Log Pis Min                -1.76078
trainer/Policy mu Mean             -0.00141554
trainer/Policy mu Std               0.913149
trainer/Policy mu Max               3.59982
trainer/Policy mu Min              -2.75327
trainer/Policy log std Mean        -1.8371
trainer/Policy log std Std          0.634687
trainer/Policy log std Max         -0.0882225
trainer/Policy log std Min         -2.6379
trainer/Alpha                       0.071076
trainer/Alpha Loss                 -0.41537
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.99405
exploration/Rewards Std             1.19956
exploration/Rewards Max            -0.0229831
exploration/Rewards Min            -9.13789
exploration/Returns Mean          -99.405
exploration/Returns Std            68.53
exploration/Returns Max           -15.5828
exploration/Returns Min          -182.66
exploration/Actions Mean            0.00585474
exploration/Actions Std             0.22594
exploration/Actions Max             0.997108
exploration/Actions Min            -0.999843
exploration/Num Paths               5
exploration/Average Returns       -99.405
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.61031
evaluation/Rewards Std              1.13629
evaluation/Rewards Max             -0.0386072
evaluation/Rewards Min             -9.27746
evaluation/Returns Mean          -161.031
evaluation/Returns Std             87.6123
evaluation/Returns Max            -23.2604
evaluation/Returns Min           -302.133
evaluation/Actions Mean             0.00468706
evaluation/Actions Std              0.178088
evaluation/Actions Max              0.998842
evaluation/Actions Min             -0.99962
evaluation/Num Paths               15
evaluation/Average Returns       -161.031
time/data storing (s)               0.00295796
time/evaluation sampling (s)        0.333647
time/exploration sampling (s)       0.137289
time/logging (s)                    0.00481739
time/saving (s)                     0.00199333
time/training (s)                   1.93058
time/epoch (s)                      2.41128
time/total (s)                    244.903
Epoch                              99
-----------------------------  ---------------
2019-04-22 23:57:26.557308 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 100 finished
-----------------------------  ---------------
replay_buffer/size              50700
trainer/QF1 Loss                   82.9187
trainer/QF2 Loss                   83.1902
trainer/Policy Loss                71.5046
trainer/Q1 Predictions Mean       -70.0537
trainer/Q1 Predictions Std         42.8101
trainer/Q1 Predictions Max        -13.1643
trainer/Q1 Predictions Min       -174.796
trainer/Q2 Predictions Mean       -69.9307
trainer/Q2 Predictions Std         42.7473
trainer/Q2 Predictions Max        -13.1275
trainer/Q2 Predictions Min       -175.854
trainer/Q Targets Mean            -70.3856
trainer/Q Targets Std              43.9945
trainer/Q Targets Max              -2.08975
trainer/Q Targets Min            -181.675
trainer/Log Pis Mean                2.25703
trainer/Log Pis Std                 1.60849
trainer/Log Pis Max                 7.18055
trainer/Log Pis Min                -2.92201
trainer/Policy mu Mean              0.110334
trainer/Policy mu Std               1.08464
trainer/Policy mu Max               4.10675
trainer/Policy mu Min              -3.63933
trainer/Policy log std Mean        -1.81016
trainer/Policy log std Std          0.659917
trainer/Policy log std Max         -0.235375
trainer/Policy log std Min         -2.70235
trainer/Alpha                       0.071845
trainer/Alpha Loss                  0.67686
exploration/num steps total     50700
exploration/num paths total       507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.929543
exploration/Rewards Std             0.810936
exploration/Rewards Max            -0.0061149
exploration/Rewards Min            -7.41362
exploration/Returns Mean          -92.9543
exploration/Returns Std            38.9732
exploration/Returns Max           -23.7417
exploration/Returns Min          -137.737
exploration/Actions Mean           -0.0165559
exploration/Actions Std             0.212317
exploration/Actions Max             0.999238
exploration/Actions Min            -0.999086
exploration/Num Paths               5
exploration/Average Returns       -92.9543
evaluation/num steps total     151500
evaluation/num paths total       1515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.24958
evaluation/Rewards Std              1.39184
evaluation/Rewards Max             -0.0559762
evaluation/Rewards Min             -9.04939
evaluation/Returns Mean          -124.958
evaluation/Returns Std             96.9087
evaluation/Returns Max            -30.115
evaluation/Returns Min           -298.542
evaluation/Actions Mean            -0.00979643
evaluation/Actions Std              0.182471
evaluation/Actions Max              0.998885
evaluation/Actions Min             -0.998984
evaluation/Num Paths               15
evaluation/Average Returns       -124.958
time/data storing (s)               0.00293903
time/evaluation sampling (s)        0.325014
time/exploration sampling (s)       0.141158
time/logging (s)                    0.00479011
time/saving (s)                     0.00196454
time/training (s)                   1.95495
time/epoch (s)                      2.43081
time/total (s)                    247.338
Epoch                             100
-----------------------------  ---------------
2019-04-22 23:57:28.978048 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 101 finished
-----------------------------  ---------------
replay_buffer/size              51200
trainer/QF1 Loss                   27.0867
trainer/QF2 Loss                   27.114
trainer/Policy Loss                74.3618
trainer/Q1 Predictions Mean       -72.9447
trainer/Q1 Predictions Std         39.3568
trainer/Q1 Predictions Max        -13.1619
trainer/Q1 Predictions Min       -157.685
trainer/Q2 Predictions Mean       -72.9326
trainer/Q2 Predictions Std         39.3345
trainer/Q2 Predictions Max        -13.193
trainer/Q2 Predictions Min       -156.804
trainer/Q Targets Mean            -73.3223
trainer/Q Targets Std              40.4052
trainer/Q Targets Max              -0.960527
trainer/Q Targets Min            -158.909
trainer/Log Pis Mean                1.96477
trainer/Log Pis Std                 1.19572
trainer/Log Pis Max                 5.45237
trainer/Log Pis Min                -2.4944
trainer/Policy mu Mean              0.0254776
trainer/Policy mu Std               0.878953
trainer/Policy mu Max               2.51569
trainer/Policy mu Min              -3.03063
trainer/Policy log std Mean        -1.82138
trainer/Policy log std Std          0.604877
trainer/Policy log std Max         -0.243202
trainer/Policy log std Min         -2.76561
trainer/Alpha                       0.0719546
trainer/Alpha Loss                 -0.0927044
exploration/num steps total     51200
exploration/num paths total       512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19407
exploration/Rewards Std             1.0178
exploration/Rewards Max            -0.0200078
exploration/Rewards Min            -7.32595
exploration/Returns Mean         -119.407
exploration/Returns Std            81.0117
exploration/Returns Max           -19.5987
exploration/Returns Min          -211.555
exploration/Actions Mean            0.0100415
exploration/Actions Std             0.245101
exploration/Actions Max             0.998219
exploration/Actions Min            -0.998748
exploration/Num Paths               5
exploration/Average Returns      -119.407
evaluation/num steps total     153000
evaluation/num paths total       1530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.36327
evaluation/Rewards Std              1.29749
evaluation/Rewards Max             -0.0556161
evaluation/Rewards Min            -11.168
evaluation/Returns Mean          -136.327
evaluation/Returns Std             77.4135
evaluation/Returns Max            -18.3889
evaluation/Returns Min           -294.295
evaluation/Actions Mean            -0.00579688
evaluation/Actions Std              0.190562
evaluation/Actions Max              0.998331
evaluation/Actions Min             -0.999632
evaluation/Num Paths               15
evaluation/Average Returns       -136.327
time/data storing (s)               0.00316176
time/evaluation sampling (s)        0.326896
time/exploration sampling (s)       0.137122
time/logging (s)                    0.00481402
time/saving (s)                     0.00195386
time/training (s)                   1.94061
time/epoch (s)                      2.41456
time/total (s)                    249.757
Epoch                             101
-----------------------------  ---------------
2019-04-22 23:57:31.398484 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 102 finished
-----------------------------  ---------------
replay_buffer/size              51700
trainer/QF1 Loss                  139.517
trainer/QF2 Loss                  139.25
trainer/Policy Loss                70.8898
trainer/Q1 Predictions Mean       -69.5942
trainer/Q1 Predictions Std         41.7368
trainer/Q1 Predictions Max        -13.0408
trainer/Q1 Predictions Min       -148.67
trainer/Q2 Predictions Mean       -69.6059
trainer/Q2 Predictions Std         41.7044
trainer/Q2 Predictions Max        -13.1442
trainer/Q2 Predictions Min       -148.361
trainer/Q Targets Mean            -69.0776
trainer/Q Targets Std              42.3418
trainer/Q Targets Max              -3.97314
trainer/Q Targets Min            -150.199
trainer/Log Pis Mean                1.93435
trainer/Log Pis Std                 1.09509
trainer/Log Pis Max                 4.87577
trainer/Log Pis Min                -2.23075
trainer/Policy mu Mean              0.102232
trainer/Policy mu Std               0.789531
trainer/Policy mu Max               3.23164
trainer/Policy mu Min              -2.88122
trainer/Policy log std Mean        -1.90763
trainer/Policy log std Std          0.589224
trainer/Policy log std Max         -0.243282
trainer/Policy log std Min         -2.75129
trainer/Alpha                       0.0733035
trainer/Alpha Loss                 -0.171557
exploration/num steps total     51700
exploration/num paths total       517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36269
exploration/Rewards Std             1.07189
exploration/Rewards Max            -0.00337837
exploration/Rewards Min            -7.26328
exploration/Returns Mean         -136.269
exploration/Returns Std            88.6229
exploration/Returns Max           -32.4381
exploration/Returns Min          -297.407
exploration/Actions Mean           -0.0111668
exploration/Actions Std             0.236387
exploration/Actions Max             0.975614
exploration/Actions Min            -0.999222
exploration/Num Paths               5
exploration/Average Returns      -136.269
evaluation/num steps total     154500
evaluation/num paths total       1545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.38431
evaluation/Rewards Std              1.27213
evaluation/Rewards Max             -0.0132338
evaluation/Rewards Min            -10.1137
evaluation/Returns Mean          -138.431
evaluation/Returns Std             92.8998
evaluation/Returns Max             -7.51998
evaluation/Returns Min           -300.03
evaluation/Actions Mean            -0.0084866
evaluation/Actions Std              0.192268
evaluation/Actions Max              0.998902
evaluation/Actions Min             -0.999381
evaluation/Num Paths               15
evaluation/Average Returns       -138.431
time/data storing (s)               0.00289481
time/evaluation sampling (s)        0.329823
time/exploration sampling (s)       0.135474
time/logging (s)                    0.00482168
time/saving (s)                     0.00159879
time/training (s)                   1.93978
time/epoch (s)                      2.41439
time/total (s)                    252.175
Epoch                             102
-----------------------------  ---------------
2019-04-22 23:57:33.817287 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 103 finished
-----------------------------  ---------------
replay_buffer/size              52200
trainer/QF1 Loss                   22.2863
trainer/QF2 Loss                   22.3316
trainer/Policy Loss                69.9528
trainer/Q1 Predictions Mean       -68.7188
trainer/Q1 Predictions Std         39.5262
trainer/Q1 Predictions Max        -13.204
trainer/Q1 Predictions Min       -149.788
trainer/Q2 Predictions Mean       -68.7122
trainer/Q2 Predictions Std         39.5799
trainer/Q2 Predictions Max        -13.1526
trainer/Q2 Predictions Min       -151.43
trainer/Q Targets Mean            -69.3541
trainer/Q Targets Std              41.0093
trainer/Q Targets Max              -0.304093
trainer/Q Targets Min            -154.444
trainer/Log Pis Mean                1.92772
trainer/Log Pis Std                 1.19521
trainer/Log Pis Max                 5.429
trainer/Log Pis Min                -3.02118
trainer/Policy mu Mean              0.118089
trainer/Policy mu Std               0.807611
trainer/Policy mu Max               3.02732
trainer/Policy mu Min              -2.64315
trainer/Policy log std Mean        -1.92658
trainer/Policy log std Std          0.574051
trainer/Policy log std Max         -0.357434
trainer/Policy log std Min         -2.81799
trainer/Alpha                       0.0736581
trainer/Alpha Loss                 -0.188545
exploration/num steps total     52200
exploration/num paths total       522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.726314
exploration/Rewards Std             0.608526
exploration/Rewards Max            -0.0125395
exploration/Rewards Min            -5.59888
exploration/Returns Mean          -72.6314
exploration/Returns Std            34.1019
exploration/Returns Max           -31.5236
exploration/Returns Min          -118.365
exploration/Actions Mean            0.00102516
exploration/Actions Std             0.188302
exploration/Actions Max             0.992413
exploration/Actions Min            -0.985061
exploration/Num Paths               5
exploration/Average Returns       -72.6314
evaluation/num steps total     156000
evaluation/num paths total       1560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.66773
evaluation/Rewards Std              0.972667
evaluation/Rewards Max             -0.128188
evaluation/Rewards Min             -9.59205
evaluation/Returns Mean          -166.773
evaluation/Returns Std             59.6076
evaluation/Returns Max            -57.7116
evaluation/Returns Min           -294.965
evaluation/Actions Mean             0.00829875
evaluation/Actions Std              0.185007
evaluation/Actions Max              0.998966
evaluation/Actions Min             -0.997653
evaluation/Num Paths               15
evaluation/Average Returns       -166.773
time/data storing (s)               0.00284656
time/evaluation sampling (s)        0.330702
time/exploration sampling (s)       0.138546
time/logging (s)                    0.00476886
time/saving (s)                     0.00193059
time/training (s)                   1.93363
time/epoch (s)                      2.41242
time/total (s)                    254.592
Epoch                             103
-----------------------------  ---------------
2019-04-22 23:57:36.246729 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 104 finished
-----------------------------  ---------------
replay_buffer/size              52700
trainer/QF1 Loss                  169.166
trainer/QF2 Loss                  169.717
trainer/Policy Loss                67.2751
trainer/Q1 Predictions Mean       -66.1027
trainer/Q1 Predictions Std         43.6335
trainer/Q1 Predictions Max        -13.5998
trainer/Q1 Predictions Min       -152.759
trainer/Q2 Predictions Mean       -66.0687
trainer/Q2 Predictions Std         43.6053
trainer/Q2 Predictions Max        -13.439
trainer/Q2 Predictions Min       -154.127
trainer/Q Targets Mean            -64.3779
trainer/Q Targets Std              44.5712
trainer/Q Targets Max              -3.30733
trainer/Q Targets Min            -153.59
trainer/Log Pis Mean                2.02264
trainer/Log Pis Std                 1.29691
trainer/Log Pis Max                 6.27173
trainer/Log Pis Min                -2.58197
trainer/Policy mu Mean             -0.010443
trainer/Policy mu Std               0.969191
trainer/Policy mu Max               2.85056
trainer/Policy mu Min              -3.05033
trainer/Policy log std Mean        -1.83174
trainer/Policy log std Std          0.639785
trainer/Policy log std Max         -0.356737
trainer/Policy log std Min         -2.78204
trainer/Alpha                       0.0747628
trainer/Alpha Loss                  0.0587281
exploration/num steps total     52700
exploration/num paths total       527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.627496
exploration/Rewards Std             1.04299
exploration/Rewards Max            -0.0221932
exploration/Rewards Min            -8.58905
exploration/Returns Mean          -62.7496
exploration/Returns Std            31.9127
exploration/Returns Max           -25.3252
exploration/Returns Min          -102.22
exploration/Actions Mean           -0.0112735
exploration/Actions Std             0.233454
exploration/Actions Max             0.998335
exploration/Actions Min            -0.999337
exploration/Num Paths               5
exploration/Average Returns       -62.7496
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23295
evaluation/Rewards Std              1.34311
evaluation/Rewards Max             -0.0488586
evaluation/Rewards Min            -10.1809
evaluation/Returns Mean          -123.295
evaluation/Returns Std             91.138
evaluation/Returns Max            -10.191
evaluation/Returns Min           -320.627
evaluation/Actions Mean            -0.0129657
evaluation/Actions Std              0.191463
evaluation/Actions Max              0.996111
evaluation/Actions Min             -0.999432
evaluation/Num Paths               15
evaluation/Average Returns       -123.295
time/data storing (s)               0.00302349
time/evaluation sampling (s)        0.332048
time/exploration sampling (s)       0.138866
time/logging (s)                    0.00489105
time/saving (s)                     0.00197508
time/training (s)                   1.94249
time/epoch (s)                      2.42329
time/total (s)                    257.019
Epoch                             104
-----------------------------  ---------------
2019-04-22 23:57:38.676311 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 105 finished
-----------------------------  ---------------
replay_buffer/size              53200
trainer/QF1 Loss                  115.861
trainer/QF2 Loss                  115.376
trainer/Policy Loss                74.384
trainer/Q1 Predictions Mean       -73.1266
trainer/Q1 Predictions Std         46.1776
trainer/Q1 Predictions Max        -12.9107
trainer/Q1 Predictions Min       -162.68
trainer/Q2 Predictions Mean       -73.0914
trainer/Q2 Predictions Std         46.1514
trainer/Q2 Predictions Max        -12.7662
trainer/Q2 Predictions Min       -163.589
trainer/Q Targets Mean            -72.9415
trainer/Q Targets Std              47.3284
trainer/Q Targets Max              -4.89101
trainer/Q Targets Min            -167.393
trainer/Log Pis Mean                1.96589
trainer/Log Pis Std                 1.21116
trainer/Log Pis Max                 6.11618
trainer/Log Pis Min                -1.11945
trainer/Policy mu Mean              0.0613439
trainer/Policy mu Std               0.863227
trainer/Policy mu Max               2.59652
trainer/Policy mu Min              -2.55554
trainer/Policy log std Mean        -1.8078
trainer/Policy log std Std          0.5807
trainer/Policy log std Max         -0.332307
trainer/Policy log std Min         -2.72087
trainer/Alpha                       0.0783349
trainer/Alpha Loss                 -0.0868735
exploration/num steps total     53200
exploration/num paths total       532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.37436
exploration/Rewards Std             1.18915
exploration/Rewards Max            -0.0256001
exploration/Rewards Min            -9.71175
exploration/Returns Mean         -137.436
exploration/Returns Std            96.5166
exploration/Returns Max           -25.9619
exploration/Returns Min          -289.268
exploration/Actions Mean            0.0105213
exploration/Actions Std             0.205736
exploration/Actions Max             0.987692
exploration/Actions Min            -0.979107
exploration/Num Paths               5
exploration/Average Returns      -137.436
evaluation/num steps total     159000
evaluation/num paths total       1590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.62205
evaluation/Rewards Std              0.976598
evaluation/Rewards Max             -0.0925479
evaluation/Rewards Min             -7.75752
evaluation/Returns Mean          -162.205
evaluation/Returns Std             77.6755
evaluation/Returns Max            -16.2529
evaluation/Returns Min           -298.67
evaluation/Actions Mean             0.00888197
evaluation/Actions Std              0.169049
evaluation/Actions Max              0.999635
evaluation/Actions Min             -0.992356
evaluation/Num Paths               15
evaluation/Average Returns       -162.205
time/data storing (s)               0.00293873
time/evaluation sampling (s)        0.33074
time/exploration sampling (s)       0.136536
time/logging (s)                    0.0047805
time/saving (s)                     0.0015653
time/training (s)                   1.94732
time/epoch (s)                      2.42388
time/total (s)                    259.447
Epoch                             105
-----------------------------  ---------------
2019-04-22 23:57:41.083754 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 106 finished
-----------------------------  ---------------
replay_buffer/size              53700
trainer/QF1 Loss                   85.4947
trainer/QF2 Loss                   84.5367
trainer/Policy Loss                67.4242
trainer/Q1 Predictions Mean       -66.2166
trainer/Q1 Predictions Std         39.081
trainer/Q1 Predictions Max        -12.2993
trainer/Q1 Predictions Min       -145.208
trainer/Q2 Predictions Mean       -66.2015
trainer/Q2 Predictions Std         39.1035
trainer/Q2 Predictions Max        -12.2522
trainer/Q2 Predictions Min       -146.274
trainer/Q Targets Mean            -66.0992
trainer/Q Targets Std              40.2926
trainer/Q Targets Max              -1.04202
trainer/Q Targets Min            -148.796
trainer/Log Pis Mean                1.97621
trainer/Log Pis Std                 1.23541
trainer/Log Pis Max                 4.52418
trainer/Log Pis Min                -2.44104
trainer/Policy mu Mean              0.0607646
trainer/Policy mu Std               0.793644
trainer/Policy mu Max               2.38866
trainer/Policy mu Min              -2.83906
trainer/Policy log std Mean        -1.92661
trainer/Policy log std Std          0.581157
trainer/Policy log std Max         -0.363236
trainer/Policy log std Min         -2.67188
trainer/Alpha                       0.0784764
trainer/Alpha Loss                 -0.060538
exploration/num steps total     53700
exploration/num paths total       537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.59218
exploration/Rewards Std             1.34198
exploration/Rewards Max            -0.0191004
exploration/Rewards Min            -9.79623
exploration/Returns Mean         -159.218
exploration/Returns Std            87.1647
exploration/Returns Max           -34.1894
exploration/Returns Min          -280.085
exploration/Actions Mean           -0.0292501
exploration/Actions Std             0.262968
exploration/Actions Max             0.996852
exploration/Actions Min            -0.999872
exploration/Num Paths               5
exploration/Average Returns      -159.218
evaluation/num steps total     160500
evaluation/num paths total       1605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.55528
evaluation/Rewards Std              1.18478
evaluation/Rewards Max             -0.0897627
evaluation/Rewards Min            -10.0369
evaluation/Returns Mean          -155.528
evaluation/Returns Std             92.6689
evaluation/Returns Max            -16.7277
evaluation/Returns Min           -288.129
evaluation/Actions Mean             0.00245033
evaluation/Actions Std              0.180599
evaluation/Actions Max              0.993962
evaluation/Actions Min             -0.998539
evaluation/Num Paths               15
evaluation/Average Returns       -155.528
time/data storing (s)               0.0029245
time/evaluation sampling (s)        0.326292
time/exploration sampling (s)       0.1431
time/logging (s)                    0.00483234
time/saving (s)                     0.00218455
time/training (s)                   1.92173
time/epoch (s)                      2.40106
time/total (s)                    261.852
Epoch                             106
-----------------------------  ---------------
2019-04-22 23:57:43.528260 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 107 finished
-----------------------------  ----------------
replay_buffer/size              54200
trainer/QF1 Loss                    3.11206
trainer/QF2 Loss                    3.08017
trainer/Policy Loss                74.1634
trainer/Q1 Predictions Mean       -72.9892
trainer/Q1 Predictions Std         43.3013
trainer/Q1 Predictions Max        -12.2494
trainer/Q1 Predictions Min       -154.849
trainer/Q2 Predictions Mean       -72.9812
trainer/Q2 Predictions Std         43.2951
trainer/Q2 Predictions Max        -12.1326
trainer/Q2 Predictions Min       -154.943
trainer/Q Targets Mean            -73.4953
trainer/Q Targets Std              43.937
trainer/Q Targets Max              -0.328403
trainer/Q Targets Min            -157.979
trainer/Log Pis Mean                1.91949
trainer/Log Pis Std                 1.15798
trainer/Log Pis Max                 4.55664
trainer/Log Pis Min                -2.31412
trainer/Policy mu Mean              0.0309668
trainer/Policy mu Std               0.85932
trainer/Policy mu Max               2.70199
trainer/Policy mu Min              -2.82653
trainer/Policy log std Mean        -1.82269
trainer/Policy log std Std          0.616559
trainer/Policy log std Max         -0.311098
trainer/Policy log std Min         -2.7472
trainer/Alpha                       0.0776796
trainer/Alpha Loss                 -0.20571
exploration/num steps total     54200
exploration/num paths total       542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17432
exploration/Rewards Std             1.1991
exploration/Rewards Max            -0.013469
exploration/Rewards Min            -9.75287
exploration/Returns Mean         -117.432
exploration/Returns Std            94.2093
exploration/Returns Max           -19.5962
exploration/Returns Min          -297.59
exploration/Actions Mean           -0.00288024
exploration/Actions Std             0.236282
exploration/Actions Max             0.998212
exploration/Actions Min            -0.998527
exploration/Num Paths               5
exploration/Average Returns      -117.432
evaluation/num steps total     162000
evaluation/num paths total       1620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.22215
evaluation/Rewards Std              1.17631
evaluation/Rewards Max             -0.0444461
evaluation/Rewards Min             -9.57292
evaluation/Returns Mean          -122.215
evaluation/Returns Std             75.2258
evaluation/Returns Max            -21.5986
evaluation/Returns Min           -265.117
evaluation/Actions Mean             0.000972001
evaluation/Actions Std              0.187636
evaluation/Actions Max              0.997498
evaluation/Actions Min             -0.998922
evaluation/Num Paths               15
evaluation/Average Returns       -122.215
time/data storing (s)               0.00318046
time/evaluation sampling (s)        0.328962
time/exploration sampling (s)       0.139435
time/logging (s)                    0.00480671
time/saving (s)                     0.0105084
time/training (s)                   1.95109
time/epoch (s)                      2.43798
time/total (s)                    264.295
Epoch                             107
-----------------------------  ----------------
2019-04-22 23:57:45.946729 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 108 finished
-----------------------------  ---------------
replay_buffer/size              54700
trainer/QF1 Loss                    3.97231
trainer/QF2 Loss                    3.958
trainer/Policy Loss                75.7224
trainer/Q1 Predictions Mean       -74.341
trainer/Q1 Predictions Std         43.3845
trainer/Q1 Predictions Max        -12.392
trainer/Q1 Predictions Min       -150.273
trainer/Q2 Predictions Mean       -74.3555
trainer/Q2 Predictions Std         43.3884
trainer/Q2 Predictions Max        -12.4333
trainer/Q2 Predictions Min       -150.155
trainer/Q Targets Mean            -75.3779
trainer/Q Targets Std              44.0884
trainer/Q Targets Max              -0.11087
trainer/Q Targets Min            -152.055
trainer/Log Pis Mean                2.26175
trainer/Log Pis Std                 1.35268
trainer/Log Pis Max                 5.6515
trainer/Log Pis Min                -3.83761
trainer/Policy mu Mean             -0.171556
trainer/Policy mu Std               0.9427
trainer/Policy mu Max               2.79691
trainer/Policy mu Min              -2.84518
trainer/Policy log std Mean        -1.87929
trainer/Policy log std Std          0.689222
trainer/Policy log std Max         -0.327104
trainer/Policy log std Min         -2.84514
trainer/Alpha                       0.0756733
trainer/Alpha Loss                  0.675667
exploration/num steps total     54700
exploration/num paths total       547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.51174
exploration/Rewards Std             1.09697
exploration/Rewards Max            -0.360525
exploration/Rewards Min            -9.95928
exploration/Returns Mean         -151.174
exploration/Returns Std            45.6203
exploration/Returns Max           -63.495
exploration/Returns Min          -188.612
exploration/Actions Mean           -0.0222553
exploration/Actions Std             0.288682
exploration/Actions Max             0.999968
exploration/Actions Min            -0.999845
exploration/Num Paths               5
exploration/Average Returns      -151.174
evaluation/num steps total     163500
evaluation/num paths total       1635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.59146
evaluation/Rewards Std              1.1857
evaluation/Rewards Max             -0.04043
evaluation/Rewards Min            -10.1971
evaluation/Returns Mean          -159.146
evaluation/Returns Std             97.944
evaluation/Returns Max            -13.6671
evaluation/Returns Min           -298.703
evaluation/Actions Mean            -0.017642
evaluation/Actions Std              0.177188
evaluation/Actions Max              0.983791
evaluation/Actions Min             -0.998809
evaluation/Num Paths               15
evaluation/Average Returns       -159.146
time/data storing (s)               0.00297507
time/evaluation sampling (s)        0.32639
time/exploration sampling (s)       0.136425
time/logging (s)                    0.00480887
time/saving (s)                     0.00192751
time/training (s)                   1.9393
time/epoch (s)                      2.41183
time/total (s)                    266.711
Epoch                             108
-----------------------------  ---------------
2019-04-22 23:57:48.374237 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 109 finished
-----------------------------  ---------------
replay_buffer/size              55200
trainer/QF1 Loss                   68.0359
trainer/QF2 Loss                   67.7402
trainer/Policy Loss                77.139
trainer/Q1 Predictions Mean       -75.9358
trainer/Q1 Predictions Std         39.9221
trainer/Q1 Predictions Max        -12.043
trainer/Q1 Predictions Min       -148.113
trainer/Q2 Predictions Mean       -75.9545
trainer/Q2 Predictions Std         39.9478
trainer/Q2 Predictions Max        -12.1041
trainer/Q2 Predictions Min       -148.746
trainer/Q Targets Mean            -75.7685
trainer/Q Targets Std              40.8902
trainer/Q Targets Max              -1.42574
trainer/Q Targets Min            -150.366
trainer/Log Pis Mean                1.9602
trainer/Log Pis Std                 1.37692
trainer/Log Pis Max                 5.43122
trainer/Log Pis Min                -5.04843
trainer/Policy mu Mean             -0.138233
trainer/Policy mu Std               0.809823
trainer/Policy mu Max               2.27713
trainer/Policy mu Min              -2.72368
trainer/Policy log std Mean        -1.91787
trainer/Policy log std Std          0.619968
trainer/Policy log std Max         -0.423789
trainer/Policy log std Min         -2.86406
trainer/Alpha                       0.0738519
trainer/Alpha Loss                 -0.103703
exploration/num steps total     55200
exploration/num paths total       552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.40892
exploration/Rewards Std             0.925569
exploration/Rewards Max            -0.0079436
exploration/Rewards Min            -7.7991
exploration/Returns Mean         -140.892
exploration/Returns Std            72.3318
exploration/Returns Max           -23.4959
exploration/Returns Min          -219.341
exploration/Actions Mean           -0.00837167
exploration/Actions Std             0.217467
exploration/Actions Max             0.99944
exploration/Actions Min            -0.999742
exploration/Num Paths               5
exploration/Average Returns      -140.892
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.45541
evaluation/Rewards Std              1.03877
evaluation/Rewards Max             -0.0438818
evaluation/Rewards Min             -9.66695
evaluation/Returns Mean          -145.541
evaluation/Returns Std             75.7491
evaluation/Returns Max            -13.7743
evaluation/Returns Min           -274.403
evaluation/Actions Mean             0.00678628
evaluation/Actions Std              0.174984
evaluation/Actions Max              0.995999
evaluation/Actions Min             -0.995916
evaluation/Num Paths               15
evaluation/Average Returns       -145.541
time/data storing (s)               0.00288438
time/evaluation sampling (s)        0.328917
time/exploration sampling (s)       0.137011
time/logging (s)                    0.00486316
time/saving (s)                     0.00195654
time/training (s)                   1.94558
time/epoch (s)                      2.42121
time/total (s)                    269.137
Epoch                             109
-----------------------------  ---------------
2019-04-22 23:57:50.832580 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 110 finished
-----------------------------  ---------------
replay_buffer/size              55700
trainer/QF1 Loss                    3.53905
trainer/QF2 Loss                    3.51929
trainer/Policy Loss                73.4724
trainer/Q1 Predictions Mean       -72.1348
trainer/Q1 Predictions Std         38.6005
trainer/Q1 Predictions Max        -12.0153
trainer/Q1 Predictions Min       -155.459
trainer/Q2 Predictions Mean       -72.1735
trainer/Q2 Predictions Std         38.6055
trainer/Q2 Predictions Max        -12.057
trainer/Q2 Predictions Min       -155.782
trainer/Q Targets Mean            -72.9159
trainer/Q Targets Std              39.3009
trainer/Q Targets Max              -0.412685
trainer/Q Targets Min            -156.98
trainer/Log Pis Mean                2.4245
trainer/Log Pis Std                 1.26174
trainer/Log Pis Max                 7.31189
trainer/Log Pis Min                -1.83081
trainer/Policy mu Mean              0.129705
trainer/Policy mu Std               0.965699
trainer/Policy mu Max               3.14559
trainer/Policy mu Min              -2.46488
trainer/Policy log std Mean        -1.83308
trainer/Policy log std Std          0.681892
trainer/Policy log std Max         -0.305202
trainer/Policy log std Min         -2.81405
trainer/Alpha                       0.0734406
trainer/Alpha Loss                  1.10864
exploration/num steps total     55700
exploration/num paths total       557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.35005
exploration/Rewards Std             0.85697
exploration/Rewards Max            -0.0152123
exploration/Rewards Min            -6.74957
exploration/Returns Mean         -135.005
exploration/Returns Std            68.5791
exploration/Returns Max           -26.6296
exploration/Returns Min          -218.814
exploration/Actions Mean           -0.00465659
exploration/Actions Std             0.225393
exploration/Actions Max             0.962929
exploration/Actions Min            -0.997205
exploration/Num Paths               5
exploration/Average Returns      -135.005
evaluation/num steps total     166500
evaluation/num paths total       1665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.33426
evaluation/Rewards Std              1.24505
evaluation/Rewards Max             -0.0170533
evaluation/Rewards Min            -10.167
evaluation/Returns Mean          -133.426
evaluation/Returns Std             87.4955
evaluation/Returns Max            -34.1349
evaluation/Returns Min           -297.301
evaluation/Actions Mean            -0.00456626
evaluation/Actions Std              0.179959
evaluation/Actions Max              0.998761
evaluation/Actions Min             -0.999647
evaluation/Num Paths               15
evaluation/Average Returns       -133.426
time/data storing (s)               0.00292757
time/evaluation sampling (s)        0.348847
time/exploration sampling (s)       0.140601
time/logging (s)                    0.00477399
time/saving (s)                     0.00196323
time/training (s)                   1.95236
time/epoch (s)                      2.45147
time/total (s)                    271.593
Epoch                             110
-----------------------------  ---------------
2019-04-22 23:57:53.263163 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 111 finished
-----------------------------  ---------------
replay_buffer/size              56200
trainer/QF1 Loss                    0.716252
trainer/QF2 Loss                    0.568622
trainer/Policy Loss                63.5581
trainer/Q1 Predictions Mean       -61.8681
trainer/Q1 Predictions Std         40.4797
trainer/Q1 Predictions Max        -12.0366
trainer/Q1 Predictions Min       -152.708
trainer/Q2 Predictions Mean       -61.9197
trainer/Q2 Predictions Std         40.5036
trainer/Q2 Predictions Max        -12.0728
trainer/Q2 Predictions Min       -153.552
trainer/Q Targets Mean            -62.3379
trainer/Q Targets Std              40.8607
trainer/Q Targets Max             -12.1477
trainer/Q Targets Min            -154.115
trainer/Log Pis Mean                2.27488
trainer/Log Pis Std                 0.951988
trainer/Log Pis Max                 5.10562
trainer/Log Pis Min                -0.254858
trainer/Policy mu Mean              0.0776808
trainer/Policy mu Std               0.725191
trainer/Policy mu Max               2.92434
trainer/Policy mu Min              -2.4619
trainer/Policy log std Mean        -2.06562
trainer/Policy log std Std          0.599947
trainer/Policy log std Max         -0.436687
trainer/Policy log std Min         -3.00217
trainer/Alpha                       0.0757499
trainer/Alpha Loss                  0.70931
exploration/num steps total     56200
exploration/num paths total       562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.38831
exploration/Rewards Std             1.24688
exploration/Rewards Max            -0.00630929
exploration/Rewards Min           -11.5244
exploration/Returns Mean         -138.831
exploration/Returns Std            68.007
exploration/Returns Max           -39.0277
exploration/Returns Min          -198.778
exploration/Actions Mean            0.0069518
exploration/Actions Std             0.263354
exploration/Actions Max             0.996996
exploration/Actions Min            -0.994736
exploration/Num Paths               5
exploration/Average Returns      -138.831
evaluation/num steps total     168000
evaluation/num paths total       1680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.30956
evaluation/Rewards Std              1.05911
evaluation/Rewards Max             -0.0672898
evaluation/Rewards Min             -9.14542
evaluation/Returns Mean          -130.956
evaluation/Returns Std             70.1528
evaluation/Returns Max            -30.7262
evaluation/Returns Min           -284.663
evaluation/Actions Mean            -0.00756105
evaluation/Actions Std              0.179991
evaluation/Actions Max              0.997794
evaluation/Actions Min             -0.998415
evaluation/Num Paths               15
evaluation/Average Returns       -130.956
time/data storing (s)               0.00299794
time/evaluation sampling (s)        0.331936
time/exploration sampling (s)       0.139262
time/logging (s)                    0.0047818
time/saving (s)                     0.00193803
time/training (s)                   1.94281
time/epoch (s)                      2.42372
time/total (s)                    274.021
Epoch                             111
-----------------------------  ---------------
2019-04-22 23:57:55.686649 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 112 finished
-----------------------------  ---------------
replay_buffer/size              56700
trainer/QF1 Loss                  112.295
trainer/QF2 Loss                  112.595
trainer/Policy Loss                69.9064
trainer/Q1 Predictions Mean       -68.7673
trainer/Q1 Predictions Std         40.9705
trainer/Q1 Predictions Max        -11.9334
trainer/Q1 Predictions Min       -149.576
trainer/Q2 Predictions Mean       -68.7869
trainer/Q2 Predictions Std         40.9742
trainer/Q2 Predictions Max        -11.8636
trainer/Q2 Predictions Min       -150.618
trainer/Q Targets Mean            -68.4043
trainer/Q Targets Std              41.8603
trainer/Q Targets Max              -0.374149
trainer/Q Targets Min            -151.382
trainer/Log Pis Mean                1.97959
trainer/Log Pis Std                 1.46908
trainer/Log Pis Max                 7.6886
trainer/Log Pis Min                -1.62089
trainer/Policy mu Mean              0.159588
trainer/Policy mu Std               0.936107
trainer/Policy mu Max               3.41054
trainer/Policy mu Min              -3.01549
trainer/Policy log std Mean        -1.80071
trainer/Policy log std Std          0.658594
trainer/Policy log std Max         -0.185731
trainer/Policy log std Min         -2.8543
trainer/Alpha                       0.0800194
trainer/Alpha Loss                 -0.0515455
exploration/num steps total     56700
exploration/num paths total       567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.912502
exploration/Rewards Std             0.921201
exploration/Rewards Max            -0.0414292
exploration/Rewards Min            -7.85546
exploration/Returns Mean          -91.2502
exploration/Returns Std            59.7369
exploration/Returns Max           -33.2765
exploration/Returns Min          -196.379
exploration/Actions Mean            0.00600766
exploration/Actions Std             0.204431
exploration/Actions Max             0.991176
exploration/Actions Min            -0.998821
exploration/Num Paths               5
exploration/Average Returns       -91.2502
evaluation/num steps total     169500
evaluation/num paths total       1695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.27027
evaluation/Rewards Std              1.08362
evaluation/Rewards Max             -0.269157
evaluation/Rewards Min            -10.2152
evaluation/Returns Mean          -127.027
evaluation/Returns Std             67.9704
evaluation/Returns Max            -35.0562
evaluation/Returns Min           -280.084
evaluation/Actions Mean            -0.00727479
evaluation/Actions Std              0.187349
evaluation/Actions Max              0.996572
evaluation/Actions Min             -0.999644
evaluation/Num Paths               15
evaluation/Average Returns       -127.027
time/data storing (s)               0.00296707
time/evaluation sampling (s)        0.329001
time/exploration sampling (s)       0.140552
time/logging (s)                    0.00480612
time/saving (s)                     0.00196802
time/training (s)                   1.93846
time/epoch (s)                      2.41775
time/total (s)                    276.443
Epoch                             112
-----------------------------  ---------------
2019-04-22 23:57:58.124352 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 113 finished
-----------------------------  ---------------
replay_buffer/size              57200
trainer/QF1 Loss                  109.018
trainer/QF2 Loss                  108.777
trainer/Policy Loss                61.9421
trainer/Q1 Predictions Mean       -60.9445
trainer/Q1 Predictions Std         36.7332
trainer/Q1 Predictions Max        -11.67
trainer/Q1 Predictions Min       -145.967
trainer/Q2 Predictions Mean       -60.839
trainer/Q2 Predictions Std         36.6328
trainer/Q2 Predictions Max        -11.657
trainer/Q2 Predictions Min       -146.049
trainer/Q Targets Mean            -60.2833
trainer/Q Targets Std              37.8757
trainer/Q Targets Max              -1.64368
trainer/Q Targets Min            -146.795
trainer/Log Pis Mean                1.81701
trainer/Log Pis Std                 1.48003
trainer/Log Pis Max                 7.25892
trainer/Log Pis Min                -4.42159
trainer/Policy mu Mean              0.0619492
trainer/Policy mu Std               0.88879
trainer/Policy mu Max               2.73606
trainer/Policy mu Min              -2.82178
trainer/Policy log std Mean        -1.88297
trainer/Policy log std Std          0.681802
trainer/Policy log std Max         -0.430354
trainer/Policy log std Min         -2.90026
trainer/Alpha                       0.0809332
trainer/Alpha Loss                 -0.460057
exploration/num steps total     57200
exploration/num paths total       572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01021
exploration/Rewards Std             0.986108
exploration/Rewards Max            -0.00967263
exploration/Rewards Min            -2.94321
exploration/Returns Mean         -101.021
exploration/Returns Std            97.9308
exploration/Returns Max           -13.3661
exploration/Returns Min          -275.474
exploration/Actions Mean            0.00205602
exploration/Actions Std             0.184138
exploration/Actions Max             0.916847
exploration/Actions Min            -0.856033
exploration/Num Paths               5
exploration/Average Returns      -101.021
evaluation/num steps total     171000
evaluation/num paths total       1710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.30424
evaluation/Rewards Std              1.20249
evaluation/Rewards Max             -0.0365328
evaluation/Rewards Min            -11.6485
evaluation/Returns Mean          -130.424
evaluation/Returns Std             71.8877
evaluation/Returns Max            -26.1879
evaluation/Returns Min           -293.525
evaluation/Actions Mean            -0.0020897
evaluation/Actions Std              0.186581
evaluation/Actions Max              0.998241
evaluation/Actions Min             -0.999601
evaluation/Num Paths               15
evaluation/Average Returns       -130.424
time/data storing (s)               0.00296872
time/evaluation sampling (s)        0.331645
time/exploration sampling (s)       0.143988
time/logging (s)                    0.00565166
time/saving (s)                     0.00224273
time/training (s)                   1.94542
time/epoch (s)                      2.43191
time/total (s)                    278.879
Epoch                             113
-----------------------------  ---------------
2019-04-22 23:58:00.550107 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 114 finished
-----------------------------  ---------------
replay_buffer/size              57700
trainer/QF1 Loss                   75.1422
trainer/QF2 Loss                   74.5952
trainer/Policy Loss                70.4096
trainer/Q1 Predictions Mean       -68.8692
trainer/Q1 Predictions Std         42.972
trainer/Q1 Predictions Max        -11.4048
trainer/Q1 Predictions Min       -150.225
trainer/Q2 Predictions Mean       -68.9496
trainer/Q2 Predictions Std         42.9865
trainer/Q2 Predictions Max        -11.4448
trainer/Q2 Predictions Min       -151.308
trainer/Q Targets Mean            -68.7014
trainer/Q Targets Std              43.8766
trainer/Q Targets Max              -4.65199
trainer/Q Targets Min            -154.255
trainer/Log Pis Mean                2.18102
trainer/Log Pis Std                 1.34881
trainer/Log Pis Max                 6.04963
trainer/Log Pis Min                -1.58155
trainer/Policy mu Mean              0.119106
trainer/Policy mu Std               0.929994
trainer/Policy mu Max               2.97137
trainer/Policy mu Min              -2.82703
trainer/Policy log std Mean        -1.87021
trainer/Policy log std Std          0.68593
trainer/Policy log std Max         -0.142448
trainer/Policy log std Min         -2.75678
trainer/Alpha                       0.0812705
trainer/Alpha Loss                  0.454354
exploration/num steps total     57700
exploration/num paths total       577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.28456
exploration/Rewards Std             1.17428
exploration/Rewards Max            -0.0162602
exploration/Rewards Min            -8.24222
exploration/Returns Mean         -128.456
exploration/Returns Std            83.4243
exploration/Returns Max           -50.059
exploration/Returns Min          -288.733
exploration/Actions Mean           -0.0234257
exploration/Actions Std             0.21778
exploration/Actions Max             0.939109
exploration/Actions Min            -0.999862
exploration/Num Paths               5
exploration/Average Returns      -128.456
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.4486
evaluation/Rewards Std              1.29843
evaluation/Rewards Max             -0.0184334
evaluation/Rewards Min            -10.3045
evaluation/Returns Mean          -144.86
evaluation/Returns Std             99.8921
evaluation/Returns Max             -8.82722
evaluation/Returns Min           -300.692
evaluation/Actions Mean            -0.012201
evaluation/Actions Std              0.19002
evaluation/Actions Max              0.996376
evaluation/Actions Min             -0.999468
evaluation/Num Paths               15
evaluation/Average Returns       -144.86
time/data storing (s)               0.00302552
time/evaluation sampling (s)        0.336261
time/exploration sampling (s)       0.137513
time/logging (s)                    0.00477243
time/saving (s)                     0.00197471
time/training (s)                   1.93472
time/epoch (s)                      2.41827
time/total (s)                    281.302
Epoch                             114
-----------------------------  ---------------
2019-04-22 23:58:02.973289 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 115 finished
-----------------------------  ---------------
replay_buffer/size              58200
trainer/QF1 Loss                  201.484
trainer/QF2 Loss                  200.145
trainer/Policy Loss                64.4989
trainer/Q1 Predictions Mean       -62.9748
trainer/Q1 Predictions Std         40.1685
trainer/Q1 Predictions Max        -11.6304
trainer/Q1 Predictions Min       -153.78
trainer/Q2 Predictions Mean       -62.9827
trainer/Q2 Predictions Std         40.1503
trainer/Q2 Predictions Max        -11.5684
trainer/Q2 Predictions Min       -153.897
trainer/Q Targets Mean            -62.1022
trainer/Q Targets Std              40.0122
trainer/Q Targets Max              -2.9042
trainer/Q Targets Min            -155.525
trainer/Log Pis Mean                2.14569
trainer/Log Pis Std                 1.23417
trainer/Log Pis Max                 6.97689
trainer/Log Pis Min                -2.95067
trainer/Policy mu Mean              0.0143193
trainer/Policy mu Std               0.795218
trainer/Policy mu Max               3.02711
trainer/Policy mu Min              -2.6109
trainer/Policy log std Mean        -1.94701
trainer/Policy log std Std          0.579172
trainer/Policy log std Max         -0.1393
trainer/Policy log std Min         -2.73817
trainer/Alpha                       0.0795156
trainer/Alpha Loss                  0.368864
exploration/num steps total     58200
exploration/num paths total       582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12627
exploration/Rewards Std             1.16504
exploration/Rewards Max            -0.0140627
exploration/Rewards Min            -9.07226
exploration/Returns Mean         -112.627
exploration/Returns Std            60.7432
exploration/Returns Max           -50.3525
exploration/Returns Min          -191.25
exploration/Actions Mean           -0.00795225
exploration/Actions Std             0.228578
exploration/Actions Max             0.998158
exploration/Actions Min            -0.999758
exploration/Num Paths               5
exploration/Average Returns      -112.627
evaluation/num steps total     174000
evaluation/num paths total       1740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.972307
evaluation/Rewards Std              1.05916
evaluation/Rewards Max             -0.057531
evaluation/Rewards Min             -9.4804
evaluation/Returns Mean           -97.2307
evaluation/Returns Std             59.7651
evaluation/Returns Max            -25.8889
evaluation/Returns Min           -274.378
evaluation/Actions Mean            -0.00832622
evaluation/Actions Std              0.176398
evaluation/Actions Max              0.993415
evaluation/Actions Min             -0.999785
evaluation/Num Paths               15
evaluation/Average Returns        -97.2307
time/data storing (s)               0.00309702
time/evaluation sampling (s)        0.329719
time/exploration sampling (s)       0.13689
time/logging (s)                    0.00483411
time/saving (s)                     0.00196323
time/training (s)                   1.94032
time/epoch (s)                      2.41682
time/total (s)                    283.723
Epoch                             115
-----------------------------  ---------------
2019-04-22 23:58:05.398035 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 116 finished
-----------------------------  ---------------
replay_buffer/size              58700
trainer/QF1 Loss                  128.778
trainer/QF2 Loss                  128.468
trainer/Policy Loss                70.8705
trainer/Q1 Predictions Mean       -69.5144
trainer/Q1 Predictions Std         40.2244
trainer/Q1 Predictions Max        -11.272
trainer/Q1 Predictions Min       -150.878
trainer/Q2 Predictions Mean       -69.5057
trainer/Q2 Predictions Std         40.1601
trainer/Q2 Predictions Max        -11.1954
trainer/Q2 Predictions Min       -151.133
trainer/Q Targets Mean            -68.9832
trainer/Q Targets Std              41.2933
trainer/Q Targets Max              -0.0672996
trainer/Q Targets Min            -155.893
trainer/Log Pis Mean                2.01209
trainer/Log Pis Std                 1.15745
trainer/Log Pis Max                 4.59928
trainer/Log Pis Min                -1.4994
trainer/Policy mu Mean              0.141085
trainer/Policy mu Std               0.877769
trainer/Policy mu Max               2.76727
trainer/Policy mu Min              -2.94852
trainer/Policy log std Mean        -1.82988
trainer/Policy log std Std          0.622268
trainer/Policy log std Max         -0.33711
trainer/Policy log std Min         -2.7094
trainer/Alpha                       0.0786082
trainer/Alpha Loss                  0.0307459
exploration/num steps total     58700
exploration/num paths total       587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.43873
exploration/Rewards Std             1.37274
exploration/Rewards Max            -0.0255009
exploration/Rewards Min            -9.88275
exploration/Returns Mean         -143.873
exploration/Returns Std           100.435
exploration/Returns Max           -48.163
exploration/Returns Min          -311.21
exploration/Actions Mean           -0.0110862
exploration/Actions Std             0.20783
exploration/Actions Max             0.999246
exploration/Actions Min            -0.999568
exploration/Num Paths               5
exploration/Average Returns      -143.873
evaluation/num steps total     175500
evaluation/num paths total       1755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02668
evaluation/Rewards Std              1.14956
evaluation/Rewards Max             -0.0678638
evaluation/Rewards Min            -10.8869
evaluation/Returns Mean          -102.668
evaluation/Returns Std             81.9206
evaluation/Returns Max            -12.3283
evaluation/Returns Min           -285.997
evaluation/Actions Mean             0.00562201
evaluation/Actions Std              0.181236
evaluation/Actions Max              0.997992
evaluation/Actions Min             -0.999431
evaluation/Num Paths               15
evaluation/Average Returns       -102.668
time/data storing (s)               0.00285949
time/evaluation sampling (s)        0.332234
time/exploration sampling (s)       0.139925
time/logging (s)                    0.00490718
time/saving (s)                     0.00192006
time/training (s)                   1.93653
time/epoch (s)                      2.41838
time/total (s)                    286.145
Epoch                             116
-----------------------------  ---------------
2019-04-22 23:58:07.818476 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 117 finished
-----------------------------  ---------------
replay_buffer/size              59200
trainer/QF1 Loss                   64.3414
trainer/QF2 Loss                   63.6872
trainer/Policy Loss                71.9289
trainer/Q1 Predictions Mean       -70.8612
trainer/Q1 Predictions Std         42.7579
trainer/Q1 Predictions Max        -11.5262
trainer/Q1 Predictions Min       -167.766
trainer/Q2 Predictions Mean       -70.8919
trainer/Q2 Predictions Std         42.8435
trainer/Q2 Predictions Max        -11.4619
trainer/Q2 Predictions Min       -169.694
trainer/Q Targets Mean            -70.8465
trainer/Q Targets Std              43.7733
trainer/Q Targets Max              -1.68827
trainer/Q Targets Min            -167.399
trainer/Log Pis Mean                1.78775
trainer/Log Pis Std                 1.46566
trainer/Log Pis Max                 5.80963
trainer/Log Pis Min                -3.218
trainer/Policy mu Mean              0.0419253
trainer/Policy mu Std               0.80402
trainer/Policy mu Max               2.86551
trainer/Policy mu Min              -2.57107
trainer/Policy log std Mean        -1.88261
trainer/Policy log std Std          0.612585
trainer/Policy log std Max         -0.322775
trainer/Policy log std Min         -2.82457
trainer/Alpha                       0.0783688
trainer/Alpha Loss                 -0.540421
exploration/num steps total     59200
exploration/num paths total       592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.74674
exploration/Rewards Std             0.930671
exploration/Rewards Max            -0.489455
exploration/Rewards Min            -8.53652
exploration/Returns Mean         -174.674
exploration/Returns Std            58.0513
exploration/Returns Max          -113.688
exploration/Returns Min          -284.836
exploration/Actions Mean           -0.0176617
exploration/Actions Std             0.26492
exploration/Actions Max             0.982058
exploration/Actions Min            -0.998645
exploration/Num Paths               5
exploration/Average Returns      -174.674
evaluation/num steps total     177000
evaluation/num paths total       1770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.24729
evaluation/Rewards Std              0.918815
evaluation/Rewards Max             -0.0368013
evaluation/Rewards Min             -8.77277
evaluation/Returns Mean          -124.729
evaluation/Returns Std             70.4438
evaluation/Returns Max            -14.6602
evaluation/Returns Min           -275.82
evaluation/Actions Mean            -0.00168705
evaluation/Actions Std              0.164667
evaluation/Actions Max              0.998192
evaluation/Actions Min             -0.998287
evaluation/Num Paths               15
evaluation/Average Returns       -124.729
time/data storing (s)               0.00283793
time/evaluation sampling (s)        0.330936
time/exploration sampling (s)       0.136912
time/logging (s)                    0.00478199
time/saving (s)                     0.00195692
time/training (s)                   1.93645
time/epoch (s)                      2.41387
time/total (s)                    288.563
Epoch                             117
-----------------------------  ---------------
2019-04-22 23:58:10.260626 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 118 finished
-----------------------------  ----------------
replay_buffer/size              59700
trainer/QF1 Loss                    1.02902
trainer/QF2 Loss                    1.08736
trainer/Policy Loss                74.4225
trainer/Q1 Predictions Mean       -73.0399
trainer/Q1 Predictions Std         40.5474
trainer/Q1 Predictions Max        -11.2379
trainer/Q1 Predictions Min       -167.876
trainer/Q2 Predictions Mean       -72.9764
trainer/Q2 Predictions Std         40.5692
trainer/Q2 Predictions Max        -11.2306
trainer/Q2 Predictions Min       -167.699
trainer/Q Targets Mean            -73.759
trainer/Q Targets Std              40.9577
trainer/Q Targets Max             -11.5082
trainer/Q Targets Min            -170.384
trainer/Log Pis Mean                2.16538
trainer/Log Pis Std                 1.39719
trainer/Log Pis Max                 5.71549
trainer/Log Pis Min                -2.49851
trainer/Policy mu Mean              0.160112
trainer/Policy mu Std               0.864512
trainer/Policy mu Max               2.9608
trainer/Policy mu Min              -3.10076
trainer/Policy log std Mean        -1.86352
trainer/Policy log std Std          0.605642
trainer/Policy log std Max         -0.237548
trainer/Policy log std Min         -2.73477
trainer/Alpha                       0.0785429
trainer/Alpha Loss                  0.420738
exploration/num steps total     59700
exploration/num paths total       597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.68898
exploration/Rewards Std             1.02039
exploration/Rewards Max            -0.407247
exploration/Rewards Min            -9.69835
exploration/Returns Mean         -168.898
exploration/Returns Std            68.6292
exploration/Returns Max           -99.986
exploration/Returns Min          -284.985
exploration/Actions Mean           -0.000997016
exploration/Actions Std             0.222507
exploration/Actions Max             0.991158
exploration/Actions Min            -0.994196
exploration/Num Paths               5
exploration/Average Returns      -168.898
evaluation/num steps total     178500
evaluation/num paths total       1785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16005
evaluation/Rewards Std              1.18527
evaluation/Rewards Max             -0.0369261
evaluation/Rewards Min            -10.1904
evaluation/Returns Mean          -116.005
evaluation/Returns Std             81.8528
evaluation/Returns Max            -12.8588
evaluation/Returns Min           -292.172
evaluation/Actions Mean            -0.00828185
evaluation/Actions Std              0.17046
evaluation/Actions Max              0.997295
evaluation/Actions Min             -0.999825
evaluation/Num Paths               15
evaluation/Average Returns       -116.005
time/data storing (s)               0.00299899
time/evaluation sampling (s)        0.334532
time/exploration sampling (s)       0.137876
time/logging (s)                    0.0047944
time/saving (s)                     0.00196989
time/training (s)                   1.95409
time/epoch (s)                      2.43626
time/total (s)                    291.003
Epoch                             118
-----------------------------  ----------------
2019-04-22 23:58:12.722732 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 119 finished
-----------------------------  ----------------
replay_buffer/size              60200
trainer/QF1 Loss                    1.25674
trainer/QF2 Loss                    1.27752
trainer/Policy Loss                69.6617
trainer/Q1 Predictions Mean       -68.3861
trainer/Q1 Predictions Std         44.5314
trainer/Q1 Predictions Max        -11.4851
trainer/Q1 Predictions Min       -178.292
trainer/Q2 Predictions Mean       -68.3851
trainer/Q2 Predictions Std         44.5066
trainer/Q2 Predictions Max        -11.3332
trainer/Q2 Predictions Min       -176.342
trainer/Q Targets Mean            -69.0953
trainer/Q Targets Std              45.1404
trainer/Q Targets Max             -11.237
trainer/Q Targets Min            -179.666
trainer/Log Pis Mean                1.96984
trainer/Log Pis Std                 1.44442
trainer/Log Pis Max                 5.24402
trainer/Log Pis Min                -2.61435
trainer/Policy mu Mean              0.069248
trainer/Policy mu Std               0.787042
trainer/Policy mu Max               2.23964
trainer/Policy mu Min              -2.98327
trainer/Policy log std Mean        -1.98744
trainer/Policy log std Std          0.620201
trainer/Policy log std Max         -0.389791
trainer/Policy log std Min         -2.86109
trainer/Alpha                       0.0786647
trainer/Alpha Loss                 -0.076686
exploration/num steps total     60200
exploration/num paths total       602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.89539
exploration/Rewards Std             0.95066
exploration/Rewards Max            -0.636334
exploration/Rewards Min            -8.35633
exploration/Returns Mean         -189.539
exploration/Returns Std            65.538
exploration/Returns Max          -103.482
exploration/Returns Min          -306.529
exploration/Actions Mean           -0.00050337
exploration/Actions Std             0.247164
exploration/Actions Max             0.998491
exploration/Actions Min            -0.999641
exploration/Num Paths               5
exploration/Average Returns      -189.539
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.11947
evaluation/Rewards Std              0.958543
evaluation/Rewards Max             -0.0275267
evaluation/Rewards Min             -6.7291
evaluation/Returns Mean          -111.947
evaluation/Returns Std             88.3091
evaluation/Returns Max             -3.96865
evaluation/Returns Min           -295.876
evaluation/Actions Mean             0.000761258
evaluation/Actions Std              0.133222
evaluation/Actions Max              0.984633
evaluation/Actions Min             -0.991103
evaluation/Num Paths               15
evaluation/Average Returns       -111.947
time/data storing (s)               0.00289815
time/evaluation sampling (s)        0.333405
time/exploration sampling (s)       0.13975
time/logging (s)                    0.00480397
time/saving (s)                     0.0112656
time/training (s)                   1.96375
time/epoch (s)                      2.45587
time/total (s)                    293.463
Epoch                             119
-----------------------------  ----------------
2019-04-22 23:58:15.144003 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 120 finished
-----------------------------  ----------------
replay_buffer/size              60700
trainer/QF1 Loss                    0.720239
trainer/QF2 Loss                    0.835613
trainer/Policy Loss                68.1141
trainer/Q1 Predictions Mean       -66.7911
trainer/Q1 Predictions Std         44.2933
trainer/Q1 Predictions Max        -11.1901
trainer/Q1 Predictions Min       -153.304
trainer/Q2 Predictions Mean       -66.7621
trainer/Q2 Predictions Std         44.2622
trainer/Q2 Predictions Max        -11.1399
trainer/Q2 Predictions Min       -153.072
trainer/Q Targets Mean            -67.2555
trainer/Q Targets Std              44.6239
trainer/Q Targets Max             -11.2569
trainer/Q Targets Min            -152.114
trainer/Log Pis Mean                1.95024
trainer/Log Pis Std                 1.29808
trainer/Log Pis Max                 6.04534
trainer/Log Pis Min                -2.27866
trainer/Policy mu Mean              0.0844401
trainer/Policy mu Std               0.786607
trainer/Policy mu Max               3.42089
trainer/Policy mu Min              -2.80957
trainer/Policy log std Mean        -1.94552
trainer/Policy log std Std          0.568134
trainer/Policy log std Max         -0.416516
trainer/Policy log std Min         -2.8389
trainer/Alpha                       0.0763162
trainer/Alpha Loss                 -0.128036
exploration/num steps total     60700
exploration/num paths total       607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.56396
exploration/Rewards Std             1.11997
exploration/Rewards Max            -0.549223
exploration/Rewards Min            -9.03115
exploration/Returns Mean         -156.396
exploration/Returns Std            71.9226
exploration/Returns Max          -102.156
exploration/Returns Min          -293.623
exploration/Actions Mean           -0.000263778
exploration/Actions Std             0.230643
exploration/Actions Max             0.997326
exploration/Actions Min            -0.99784
exploration/Num Paths               5
exploration/Average Returns      -156.396
evaluation/num steps total     181500
evaluation/num paths total       1815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.36341
evaluation/Rewards Std              1.23049
evaluation/Rewards Max             -0.0152099
evaluation/Rewards Min            -11.0548
evaluation/Returns Mean          -136.341
evaluation/Returns Std             66.0328
evaluation/Returns Max            -38.6273
evaluation/Returns Min           -287.655
evaluation/Actions Mean             0.0135905
evaluation/Actions Std              0.204171
evaluation/Actions Max              0.998368
evaluation/Actions Min             -0.999701
evaluation/Num Paths               15
evaluation/Average Returns       -136.341
time/data storing (s)               0.00287653
time/evaluation sampling (s)        0.331627
time/exploration sampling (s)       0.140695
time/logging (s)                    0.00477707
time/saving (s)                     0.00192903
time/training (s)                   1.93257
time/epoch (s)                      2.41448
time/total (s)                    295.882
Epoch                             120
-----------------------------  ----------------
2019-04-22 23:58:17.569476 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 121 finished
-----------------------------  ---------------
replay_buffer/size              61200
trainer/QF1 Loss                   66.0718
trainer/QF2 Loss                   66.014
trainer/Policy Loss                69.5557
trainer/Q1 Predictions Mean       -68.3056
trainer/Q1 Predictions Std         41.1572
trainer/Q1 Predictions Max        -11.3889
trainer/Q1 Predictions Min       -146.747
trainer/Q2 Predictions Mean       -68.3237
trainer/Q2 Predictions Std         41.1734
trainer/Q2 Predictions Max        -11.4664
trainer/Q2 Predictions Min       -147.005
trainer/Q Targets Mean            -67.7436
trainer/Q Targets Std              42.114
trainer/Q Targets Max              -1.1061
trainer/Q Targets Min            -148.675
trainer/Log Pis Mean                2.06077
trainer/Log Pis Std                 1.23893
trainer/Log Pis Max                 6.10424
trainer/Log Pis Min                -0.845176
trainer/Policy mu Mean              0.0718766
trainer/Policy mu Std               0.877205
trainer/Policy mu Max               2.57315
trainer/Policy mu Min              -3.00027
trainer/Policy log std Mean        -1.87749
trainer/Policy log std Std          0.611884
trainer/Policy log std Max         -0.323143
trainer/Policy log std Min         -2.79624
trainer/Alpha                       0.0797653
trainer/Alpha Loss                  0.153681
exploration/num steps total     61200
exploration/num paths total       612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.18246
exploration/Rewards Std             1.00639
exploration/Rewards Max            -0.180882
exploration/Rewards Min            -8.83819
exploration/Returns Mean         -118.246
exploration/Returns Std            44.3032
exploration/Returns Max           -68.482
exploration/Returns Min          -177.792
exploration/Actions Mean            0.0360319
exploration/Actions Std             0.219089
exploration/Actions Max             0.999854
exploration/Actions Min            -0.77467
exploration/Num Paths               5
exploration/Average Returns      -118.246
evaluation/num steps total     183000
evaluation/num paths total       1830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21506
evaluation/Rewards Std              1.33974
evaluation/Rewards Max             -0.0417332
evaluation/Rewards Min            -10.3471
evaluation/Returns Mean          -121.506
evaluation/Returns Std             85.3259
evaluation/Returns Max            -28.0786
evaluation/Returns Min           -309.165
evaluation/Actions Mean             0.00420976
evaluation/Actions Std              0.200914
evaluation/Actions Max              0.999034
evaluation/Actions Min             -0.998932
evaluation/Num Paths               15
evaluation/Average Returns       -121.506
time/data storing (s)               0.00300636
time/evaluation sampling (s)        0.33275
time/exploration sampling (s)       0.139982
time/logging (s)                    0.00422805
time/saving (s)                     0.00198294
time/training (s)                   1.93611
time/epoch (s)                      2.41806
time/total (s)                    298.305
Epoch                             121
-----------------------------  ---------------
2019-04-22 23:58:19.999329 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 122 finished
-----------------------------  ---------------
replay_buffer/size              61700
trainer/QF1 Loss                    2.2613
trainer/QF2 Loss                    2.16311
trainer/Policy Loss                68.3028
trainer/Q1 Predictions Mean       -66.8044
trainer/Q1 Predictions Std         40.3698
trainer/Q1 Predictions Max        -11.1257
trainer/Q1 Predictions Min       -144.148
trainer/Q2 Predictions Mean       -66.8442
trainer/Q2 Predictions Std         40.3812
trainer/Q2 Predictions Max        -11.0599
trainer/Q2 Predictions Min       -143.773
trainer/Q Targets Mean            -67.1958
trainer/Q Targets Std              40.9974
trainer/Q Targets Max              -0.492895
trainer/Q Targets Min            -145.339
trainer/Log Pis Mean                2.15844
trainer/Log Pis Std                 1.21144
trainer/Log Pis Max                 7.04934
trainer/Log Pis Min                -2.12453
trainer/Policy mu Mean              0.259888
trainer/Policy mu Std               0.8403
trainer/Policy mu Max               3.48071
trainer/Policy mu Min              -2.36339
trainer/Policy log std Mean        -1.8539
trainer/Policy log std Std          0.59946
trainer/Policy log std Max         -0.317538
trainer/Policy log std Min         -2.78797
trainer/Alpha                       0.0813034
trainer/Alpha Loss                  0.397637
exploration/num steps total     61700
exploration/num paths total       617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.26486
exploration/Rewards Std             1.14084
exploration/Rewards Max            -0.141364
exploration/Rewards Min            -9.84598
exploration/Returns Mean         -126.486
exploration/Returns Std            52.7674
exploration/Returns Max           -66.6682
exploration/Returns Min          -185.488
exploration/Actions Mean           -0.00435267
exploration/Actions Std             0.257825
exploration/Actions Max             0.999993
exploration/Actions Min            -0.998895
exploration/Num Paths               5
exploration/Average Returns      -126.486
evaluation/num steps total     184500
evaluation/num paths total       1845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25104
evaluation/Rewards Std              1.04546
evaluation/Rewards Max             -0.0868083
evaluation/Rewards Min            -11.0465
evaluation/Returns Mean          -125.104
evaluation/Returns Std             78.703
evaluation/Returns Max            -13.2633
evaluation/Returns Min           -282.694
evaluation/Actions Mean            -0.00776288
evaluation/Actions Std              0.174814
evaluation/Actions Max              0.998156
evaluation/Actions Min             -0.999947
evaluation/Num Paths               15
evaluation/Average Returns       -125.104
time/data storing (s)               0.00301804
time/evaluation sampling (s)        0.32993
time/exploration sampling (s)       0.140517
time/logging (s)                    0.00481517
time/saving (s)                     0.0019668
time/training (s)                   1.9434
time/epoch (s)                      2.42365
time/total (s)                    300.733
Epoch                             122
-----------------------------  ---------------
2019-04-22 23:58:22.426839 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 123 finished
-----------------------------  ---------------
replay_buffer/size              62200
trainer/QF1 Loss                  221.683
trainer/QF2 Loss                  220.434
trainer/Policy Loss                71.954
trainer/Q1 Predictions Mean       -70.5768
trainer/Q1 Predictions Std         38.1735
trainer/Q1 Predictions Max        -11.1317
trainer/Q1 Predictions Min       -157.963
trainer/Q2 Predictions Mean       -70.5623
trainer/Q2 Predictions Std         38.2135
trainer/Q2 Predictions Max        -11.0504
trainer/Q2 Predictions Min       -157.556
trainer/Q Targets Mean            -69.2755
trainer/Q Targets Std              39.2825
trainer/Q Targets Max              -2.25765
trainer/Q Targets Min            -162.283
trainer/Log Pis Mean                1.92872
trainer/Log Pis Std                 1.27506
trainer/Log Pis Max                 7.95485
trainer/Log Pis Min                -1.07902
trainer/Policy mu Mean             -0.0209132
trainer/Policy mu Std               0.73693
trainer/Policy mu Max               3.27468
trainer/Policy mu Min              -2.75257
trainer/Policy log std Mean        -1.95294
trainer/Policy log std Std          0.603626
trainer/Policy log std Max         -0.0382041
trainer/Policy log std Min         -2.76026
trainer/Alpha                       0.0796947
trainer/Alpha Loss                 -0.180298
exploration/num steps total     62200
exploration/num paths total       622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03744
exploration/Rewards Std             1.29059
exploration/Rewards Max            -0.0129508
exploration/Rewards Min            -9.55542
exploration/Returns Mean         -103.744
exploration/Returns Std            65.9157
exploration/Returns Max           -32.4333
exploration/Returns Min          -194.115
exploration/Actions Mean            0.0289949
exploration/Actions Std             0.251917
exploration/Actions Max             0.999711
exploration/Actions Min            -0.978604
exploration/Num Paths               5
exploration/Average Returns      -103.744
evaluation/num steps total     186000
evaluation/num paths total       1860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25274
evaluation/Rewards Std              1.08181
evaluation/Rewards Max             -0.0839714
evaluation/Rewards Min             -7.72808
evaluation/Returns Mean          -125.274
evaluation/Returns Std             83.2791
evaluation/Returns Max            -22.0859
evaluation/Returns Min           -281.886
evaluation/Actions Mean            -0.00954497
evaluation/Actions Std              0.178355
evaluation/Actions Max              0.996516
evaluation/Actions Min             -0.999451
evaluation/Num Paths               15
evaluation/Average Returns       -125.274
time/data storing (s)               0.00296259
time/evaluation sampling (s)        0.332221
time/exploration sampling (s)       0.138248
time/logging (s)                    0.00484412
time/saving (s)                     0.00194513
time/training (s)                   1.94088
time/epoch (s)                      2.4211
time/total (s)                    303.158
Epoch                             123
-----------------------------  ---------------
2019-04-22 23:58:24.830431 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 124 finished
-----------------------------  ---------------
replay_buffer/size              62700
trainer/QF1 Loss                  196.904
trainer/QF2 Loss                  196.687
trainer/Policy Loss                69.1051
trainer/Q1 Predictions Mean       -67.918
trainer/Q1 Predictions Std         39.4382
trainer/Q1 Predictions Max        -11.4156
trainer/Q1 Predictions Min       -149.977
trainer/Q2 Predictions Mean       -67.8858
trainer/Q2 Predictions Std         39.4256
trainer/Q2 Predictions Max        -11.4853
trainer/Q2 Predictions Min       -149.717
trainer/Q Targets Mean            -66.7851
trainer/Q Targets Std              39.5878
trainer/Q Targets Max              -2.73738
trainer/Q Targets Min            -150.219
trainer/Log Pis Mean                2.04691
trainer/Log Pis Std                 1.28075
trainer/Log Pis Max                 5.32807
trainer/Log Pis Min                -0.91523
trainer/Policy mu Mean              0.161498
trainer/Policy mu Std               0.947933
trainer/Policy mu Max               2.74345
trainer/Policy mu Min              -2.9372
trainer/Policy log std Mean        -1.86009
trainer/Policy log std Std          0.666043
trainer/Policy log std Max         -0.379655
trainer/Policy log std Min         -2.76747
trainer/Alpha                       0.0803344
trainer/Alpha Loss                  0.11828
exploration/num steps total     62700
exploration/num paths total       627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.82588
exploration/Rewards Std             1.12867
exploration/Rewards Max            -0.374035
exploration/Rewards Min            -9.40335
exploration/Returns Mean         -182.588
exploration/Returns Std            98.2201
exploration/Returns Max           -72.4925
exploration/Returns Min          -306.478
exploration/Actions Mean           -0.0146696
exploration/Actions Std             0.22596
exploration/Actions Max             0.941208
exploration/Actions Min            -0.999456
exploration/Num Paths               5
exploration/Average Returns      -182.588
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.96449
evaluation/Rewards Std              0.957468
evaluation/Rewards Max             -0.0555845
evaluation/Rewards Min             -9.20002
evaluation/Returns Mean           -96.449
evaluation/Returns Std             57.8286
evaluation/Returns Max            -13.2996
evaluation/Returns Min           -214.73
evaluation/Actions Mean             0.0118911
evaluation/Actions Std              0.172646
evaluation/Actions Max              0.996408
evaluation/Actions Min             -0.997806
evaluation/Num Paths               15
evaluation/Average Returns        -96.449
time/data storing (s)               0.00286855
time/evaluation sampling (s)        0.327788
time/exploration sampling (s)       0.137072
time/logging (s)                    0.004798
time/saving (s)                     0.00195194
time/training (s)                   1.92231
time/epoch (s)                      2.39679
time/total (s)                    305.56
Epoch                             124
-----------------------------  ---------------
2019-04-22 23:58:27.256934 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 125 finished
-----------------------------  ---------------
replay_buffer/size              63200
trainer/QF1 Loss                  326.947
trainer/QF2 Loss                  325.436
trainer/Policy Loss                65.4799
trainer/Q1 Predictions Mean       -64.1237
trainer/Q1 Predictions Std         41.1889
trainer/Q1 Predictions Max        -10.7879
trainer/Q1 Predictions Min       -148.894
trainer/Q2 Predictions Mean       -64.1601
trainer/Q2 Predictions Std         41.1903
trainer/Q2 Predictions Max        -10.757
trainer/Q2 Predictions Min       -149.188
trainer/Q Targets Mean            -60.971
trainer/Q Targets Std              43.2506
trainer/Q Targets Max              -0.730152
trainer/Q Targets Min            -151.484
trainer/Log Pis Mean                2.05368
trainer/Log Pis Std                 1.29921
trainer/Log Pis Max                 6.84497
trainer/Log Pis Min                -1.5985
trainer/Policy mu Mean              0.226947
trainer/Policy mu Std               0.735628
trainer/Policy mu Max               2.50952
trainer/Policy mu Min              -3.06491
trainer/Policy log std Mean        -1.9935
trainer/Policy log std Std          0.547725
trainer/Policy log std Max         -0.37105
trainer/Policy log std Min         -2.73767
trainer/Alpha                       0.0801003
trainer/Alpha Loss                  0.135527
exploration/num steps total     63200
exploration/num paths total       632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.06199
exploration/Rewards Std             1.45889
exploration/Rewards Max            -0.0210156
exploration/Rewards Min           -11.6047
exploration/Returns Mean         -206.199
exploration/Returns Std            89.3789
exploration/Returns Max           -66.3609
exploration/Returns Min          -305.842
exploration/Actions Mean           -0.0227797
exploration/Actions Std             0.267101
exploration/Actions Max             0.992473
exploration/Actions Min            -0.999773
exploration/Num Paths               5
exploration/Average Returns      -206.199
evaluation/num steps total     189000
evaluation/num paths total       1890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03384
evaluation/Rewards Std              0.842275
evaluation/Rewards Max             -0.152325
evaluation/Rewards Min             -8.97268
evaluation/Returns Mean          -103.384
evaluation/Returns Std             58.9244
evaluation/Returns Max            -16.9155
evaluation/Returns Min           -183.117
evaluation/Actions Mean             0.00324644
evaluation/Actions Std              0.162724
evaluation/Actions Max              0.99761
evaluation/Actions Min             -0.998683
evaluation/Num Paths               15
evaluation/Average Returns       -103.384
time/data storing (s)               0.00291187
time/evaluation sampling (s)        0.33139
time/exploration sampling (s)       0.142208
time/logging (s)                    0.00478441
time/saving (s)                     0.00156287
time/training (s)                   1.93681
time/epoch (s)                      2.41966
time/total (s)                    307.984
Epoch                             125
-----------------------------  ---------------
2019-04-22 23:58:29.689545 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 126 finished
-----------------------------  ---------------
replay_buffer/size              63700
trainer/QF1 Loss                    0.703675
trainer/QF2 Loss                    0.566085
trainer/Policy Loss                64.8194
trainer/Q1 Predictions Mean       -63.3624
trainer/Q1 Predictions Std         37.8597
trainer/Q1 Predictions Max        -10.7774
trainer/Q1 Predictions Min       -148.808
trainer/Q2 Predictions Mean       -63.4485
trainer/Q2 Predictions Std         37.9161
trainer/Q2 Predictions Max        -10.7869
trainer/Q2 Predictions Min       -148.711
trainer/Q Targets Mean            -63.9811
trainer/Q Targets Std              38.1702
trainer/Q Targets Max             -10.9035
trainer/Q Targets Min            -149.432
trainer/Log Pis Mean                1.91382
trainer/Log Pis Std                 1.23206
trainer/Log Pis Max                 7.79266
trainer/Log Pis Min                -2.70011
trainer/Policy mu Mean              0.0574375
trainer/Policy mu Std               0.762087
trainer/Policy mu Max               2.92419
trainer/Policy mu Min              -2.79698
trainer/Policy log std Mean        -1.94842
trainer/Policy log std Std          0.573002
trainer/Policy log std Max         -0.430719
trainer/Policy log std Min         -2.77826
trainer/Alpha                       0.0804467
trainer/Alpha Loss                 -0.217163
exploration/num steps total     63700
exploration/num paths total       637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.3559
exploration/Rewards Std             0.737748
exploration/Rewards Max            -0.530721
exploration/Rewards Min            -8.66221
exploration/Returns Mean         -135.59
exploration/Returns Std            44.4401
exploration/Returns Max           -78.3287
exploration/Returns Min          -186.212
exploration/Actions Mean            0.0123216
exploration/Actions Std             0.218174
exploration/Actions Max             0.996493
exploration/Actions Min            -0.994227
exploration/Num Paths               5
exploration/Average Returns      -135.59
evaluation/num steps total     190500
evaluation/num paths total       1905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.33015
evaluation/Rewards Std              1.07394
evaluation/Rewards Max             -0.0347737
evaluation/Rewards Min            -11.0753
evaluation/Returns Mean          -133.015
evaluation/Returns Std             75.9648
evaluation/Returns Max            -13.8198
evaluation/Returns Min           -282.033
evaluation/Actions Mean             0.00773819
evaluation/Actions Std              0.170196
evaluation/Actions Max              0.998531
evaluation/Actions Min             -0.990726
evaluation/Num Paths               15
evaluation/Average Returns       -133.015
time/data storing (s)               0.00462448
time/evaluation sampling (s)        0.332607
time/exploration sampling (s)       0.142939
time/logging (s)                    0.00358494
time/saving (s)                     0.0019305
time/training (s)                   1.93889
time/epoch (s)                      2.42458
time/total (s)                    310.413
Epoch                             126
-----------------------------  ---------------
2019-04-22 23:58:32.117358 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 127 finished
-----------------------------  ---------------
replay_buffer/size              64200
trainer/QF1 Loss                    2.30537
trainer/QF2 Loss                    2.4335
trainer/Policy Loss                67.7248
trainer/Q1 Predictions Mean       -66.7158
trainer/Q1 Predictions Std         41.6611
trainer/Q1 Predictions Max        -10.4416
trainer/Q1 Predictions Min       -152.127
trainer/Q2 Predictions Mean       -66.6987
trainer/Q2 Predictions Std         41.6416
trainer/Q2 Predictions Max        -10.3895
trainer/Q2 Predictions Min       -151.952
trainer/Q Targets Mean            -67.84
trainer/Q Targets Std              42.3963
trainer/Q Targets Max             -10.9024
trainer/Q Targets Min            -154.369
trainer/Log Pis Mean                1.82498
trainer/Log Pis Std                 1.24026
trainer/Log Pis Max                 4.76792
trainer/Log Pis Min                -2.63708
trainer/Policy mu Mean              0.0927214
trainer/Policy mu Std               0.864151
trainer/Policy mu Max               2.74519
trainer/Policy mu Min              -2.65646
trainer/Policy log std Mean        -1.79527
trainer/Policy log std Std          0.63315
trainer/Policy log std Max         -0.463764
trainer/Policy log std Min         -2.74854
trainer/Alpha                       0.0801826
trainer/Alpha Loss                 -0.441635
exploration/num steps total     64200
exploration/num paths total       642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19568
exploration/Rewards Std             1.12443
exploration/Rewards Max            -0.0250714
exploration/Rewards Min            -8.80306
exploration/Returns Mean         -119.568
exploration/Returns Std            62.2144
exploration/Returns Max           -38.0959
exploration/Returns Min          -197.36
exploration/Actions Mean            0.0127989
exploration/Actions Std             0.246054
exploration/Actions Max             0.999609
exploration/Actions Min            -0.997247
exploration/Num Paths               5
exploration/Average Returns      -119.568
evaluation/num steps total     192000
evaluation/num paths total       1920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.945381
evaluation/Rewards Std              1.18358
evaluation/Rewards Max             -0.0237401
evaluation/Rewards Min            -11.6899
evaluation/Returns Mean           -94.5381
evaluation/Returns Std             57.5913
evaluation/Returns Max            -13.8902
evaluation/Returns Min           -200.004
evaluation/Actions Mean            -0.0121886
evaluation/Actions Std              0.1965
evaluation/Actions Max              0.997435
evaluation/Actions Min             -0.99987
evaluation/Num Paths               15
evaluation/Average Returns        -94.5381
time/data storing (s)               0.00291501
time/evaluation sampling (s)        0.330269
time/exploration sampling (s)       0.136889
time/logging (s)                    0.00408128
time/saving (s)                     0.00197682
time/training (s)                   1.94583
time/epoch (s)                      2.42196
time/total (s)                    312.839
Epoch                             127
-----------------------------  ---------------
2019-04-22 23:58:34.538772 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 128 finished
-----------------------------  ---------------
replay_buffer/size              64700
trainer/QF1 Loss                    0.845511
trainer/QF2 Loss                    0.703678
trainer/Policy Loss                62.8561
trainer/Q1 Predictions Mean       -61.766
trainer/Q1 Predictions Std         40.6608
trainer/Q1 Predictions Max        -10.9521
trainer/Q1 Predictions Min       -154.322
trainer/Q2 Predictions Mean       -61.6662
trainer/Q2 Predictions Std         40.6322
trainer/Q2 Predictions Max        -11.0655
trainer/Q2 Predictions Min       -153.711
trainer/Q Targets Mean            -62.0124
trainer/Q Targets Std              41.0321
trainer/Q Targets Max             -10.9876
trainer/Q Targets Min            -155.2
trainer/Log Pis Mean                2.07779
trainer/Log Pis Std                 1.65111
trainer/Log Pis Max                 9.57886
trainer/Log Pis Min                -3.29037
trainer/Policy mu Mean             -0.0272094
trainer/Policy mu Std               0.973473
trainer/Policy mu Max               2.89933
trainer/Policy mu Min              -3.91182
trainer/Policy log std Mean        -1.80379
trainer/Policy log std Std          0.650516
trainer/Policy log std Max         -0.0455028
trainer/Policy log std Min         -2.70178
trainer/Alpha                       0.0824919
trainer/Alpha Loss                  0.194077
exploration/num steps total     64700
exploration/num paths total       647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.924056
exploration/Rewards Std             1.06077
exploration/Rewards Max            -0.00715858
exploration/Rewards Min            -8.5265
exploration/Returns Mean          -92.4056
exploration/Returns Std            54.2534
exploration/Returns Max           -48.877
exploration/Returns Min          -197.101
exploration/Actions Mean            0.00496879
exploration/Actions Std             0.225105
exploration/Actions Max             0.999678
exploration/Actions Min            -0.999228
exploration/Num Paths               5
exploration/Average Returns       -92.4056
evaluation/num steps total     193500
evaluation/num paths total       1935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.50996
evaluation/Rewards Std              1.23371
evaluation/Rewards Max             -0.00251441
evaluation/Rewards Min            -10.5239
evaluation/Returns Mean          -150.996
evaluation/Returns Std             75.5391
evaluation/Returns Max            -17.1528
evaluation/Returns Min           -302.55
evaluation/Actions Mean             0.0178336
evaluation/Actions Std              0.193266
evaluation/Actions Max              0.997546
evaluation/Actions Min             -0.999591
evaluation/Num Paths               15
evaluation/Average Returns       -150.996
time/data storing (s)               0.00285271
time/evaluation sampling (s)        0.331131
time/exploration sampling (s)       0.138554
time/logging (s)                    0.00479721
time/saving (s)                     0.00196762
time/training (s)                   1.93718
time/epoch (s)                      2.41648
time/total (s)                    315.259
Epoch                             128
-----------------------------  ---------------
2019-04-22 23:58:36.960563 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 129 finished
-----------------------------  ---------------
replay_buffer/size              65200
trainer/QF1 Loss                    0.946578
trainer/QF2 Loss                    0.629361
trainer/Policy Loss                67.5232
trainer/Q1 Predictions Mean       -66.0776
trainer/Q1 Predictions Std         41.1487
trainer/Q1 Predictions Max        -10.6959
trainer/Q1 Predictions Min       -149.756
trainer/Q2 Predictions Mean       -66.124
trainer/Q2 Predictions Std         41.1677
trainer/Q2 Predictions Max        -10.7662
trainer/Q2 Predictions Min       -149.538
trainer/Q Targets Mean            -66.3638
trainer/Q Targets Std              41.4945
trainer/Q Targets Max             -10.9393
trainer/Q Targets Min            -152.009
trainer/Log Pis Mean                1.89503
trainer/Log Pis Std                 1.12795
trainer/Log Pis Max                 5.22694
trainer/Log Pis Min                -1.7453
trainer/Policy mu Mean              0.0850384
trainer/Policy mu Std               0.777109
trainer/Policy mu Max               3.04338
trainer/Policy mu Min              -2.56704
trainer/Policy log std Mean        -1.92831
trainer/Policy log std Std          0.588385
trainer/Policy log std Max         -0.284916
trainer/Policy log std Min         -2.79451
trainer/Alpha                       0.0823352
trainer/Alpha Loss                 -0.262108
exploration/num steps total     65200
exploration/num paths total       652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.993045
exploration/Rewards Std             0.734873
exploration/Rewards Max            -0.104611
exploration/Rewards Min            -7.08424
exploration/Returns Mean          -99.3045
exploration/Returns Std            48.4053
exploration/Returns Max           -25.508
exploration/Returns Min          -156.983
exploration/Actions Mean            0.0187264
exploration/Actions Std             0.197995
exploration/Actions Max             0.997292
exploration/Actions Min            -0.9315
exploration/Num Paths               5
exploration/Average Returns       -99.3045
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09438
evaluation/Rewards Std              1.14245
evaluation/Rewards Max             -0.0143889
evaluation/Rewards Min            -10.3687
evaluation/Returns Mean          -109.438
evaluation/Returns Std             77.9326
evaluation/Returns Max            -15.1178
evaluation/Returns Min           -284.559
evaluation/Actions Mean             0.00996795
evaluation/Actions Std              0.177051
evaluation/Actions Max              0.998543
evaluation/Actions Min             -0.996808
evaluation/Num Paths               15
evaluation/Average Returns       -109.438
time/data storing (s)               0.00278943
time/evaluation sampling (s)        0.332441
time/exploration sampling (s)       0.137946
time/logging (s)                    0.004814
time/saving (s)                     0.00193985
time/training (s)                   1.935
time/epoch (s)                      2.41493
time/total (s)                    317.679
Epoch                             129
-----------------------------  ---------------
2019-04-22 23:58:39.388738 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 130 finished
-----------------------------  ---------------
replay_buffer/size              65700
trainer/QF1 Loss                    7.17713
trainer/QF2 Loss                    7.13406
trainer/Policy Loss                65.6401
trainer/Q1 Predictions Mean       -63.8875
trainer/Q1 Predictions Std         39.2412
trainer/Q1 Predictions Max        -10.4886
trainer/Q1 Predictions Min       -150.983
trainer/Q2 Predictions Mean       -63.8494
trainer/Q2 Predictions Std         39.2446
trainer/Q2 Predictions Max        -10.5669
trainer/Q2 Predictions Min       -150.712
trainer/Q Targets Mean            -65.2383
trainer/Q Targets Std              40.7386
trainer/Q Targets Max              -1.0309
trainer/Q Targets Min            -154.258
trainer/Log Pis Mean                2.3696
trainer/Log Pis Std                 1.48635
trainer/Log Pis Max                10.3885
trainer/Log Pis Min                -1.88041
trainer/Policy mu Mean              0.0481213
trainer/Policy mu Std               1.00474
trainer/Policy mu Max               3.14141
trainer/Policy mu Min              -4.08169
trainer/Policy log std Mean        -1.89091
trainer/Policy log std Std          0.629344
trainer/Policy log std Max         -0.321225
trainer/Policy log std Min         -2.83084
trainer/Alpha                       0.0808318
trainer/Alpha Loss                  0.929763
exploration/num steps total     65700
exploration/num paths total       657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02663
exploration/Rewards Std             1.0416
exploration/Rewards Max            -0.0113665
exploration/Rewards Min            -9.78385
exploration/Returns Mean         -102.663
exploration/Returns Std            60.4464
exploration/Returns Max           -21.3457
exploration/Returns Min          -176.419
exploration/Actions Mean            0.0237955
exploration/Actions Std             0.224963
exploration/Actions Max             0.999391
exploration/Actions Min            -0.989614
exploration/Num Paths               5
exploration/Average Returns      -102.663
evaluation/num steps total     196500
evaluation/num paths total       1965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21161
evaluation/Rewards Std              0.99782
evaluation/Rewards Max             -0.0488974
evaluation/Rewards Min             -7.7902
evaluation/Returns Mean          -121.161
evaluation/Returns Std             78.5824
evaluation/Returns Max            -22.6378
evaluation/Returns Min           -285.29
evaluation/Actions Mean             0.00983069
evaluation/Actions Std              0.167984
evaluation/Actions Max              0.99584
evaluation/Actions Min             -0.997125
evaluation/Num Paths               15
evaluation/Average Returns       -121.161
time/data storing (s)               0.00309196
time/evaluation sampling (s)        0.335892
time/exploration sampling (s)       0.141769
time/logging (s)                    0.00354915
time/saving (s)                     0.00193929
time/training (s)                   1.93357
time/epoch (s)                      2.41981
time/total (s)                    320.103
Epoch                             130
-----------------------------  ---------------
2019-04-22 23:58:41.819636 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 131 finished
-----------------------------  ---------------
replay_buffer/size              66200
trainer/QF1 Loss                    2.91193
trainer/QF2 Loss                    2.99147
trainer/Policy Loss                63.7756
trainer/Q1 Predictions Mean       -62.772
trainer/Q1 Predictions Std         37.0231
trainer/Q1 Predictions Max        -10.8059
trainer/Q1 Predictions Min       -160.806
trainer/Q2 Predictions Mean       -62.6986
trainer/Q2 Predictions Std         37.0023
trainer/Q2 Predictions Max        -10.9434
trainer/Q2 Predictions Min       -160.876
trainer/Q Targets Mean            -63.5335
trainer/Q Targets Std              37.7991
trainer/Q Targets Max              -0.250608
trainer/Q Targets Min            -166.778
trainer/Log Pis Mean                1.82312
trainer/Log Pis Std                 1.39801
trainer/Log Pis Max                 6.32624
trainer/Log Pis Min                -2.83406
trainer/Policy mu Mean              0.0842399
trainer/Policy mu Std               0.877673
trainer/Policy mu Max               2.99843
trainer/Policy mu Min              -2.5822
trainer/Policy log std Mean        -1.81959
trainer/Policy log std Std          0.596267
trainer/Policy log std Max         -0.372055
trainer/Policy log std Min         -2.82134
trainer/Alpha                       0.0826258
trainer/Alpha Loss                 -0.441058
exploration/num steps total     66200
exploration/num paths total       662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.07551
exploration/Rewards Std             0.785175
exploration/Rewards Max            -0.298926
exploration/Rewards Min            -7.72462
exploration/Returns Mean         -107.551
exploration/Returns Std            48.9626
exploration/Returns Max           -64.6012
exploration/Returns Min          -167.99
exploration/Actions Mean            0.0114129
exploration/Actions Std             0.229419
exploration/Actions Max             0.999491
exploration/Actions Min            -0.985282
exploration/Num Paths               5
exploration/Average Returns      -107.551
evaluation/num steps total     198000
evaluation/num paths total       1980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0468
evaluation/Rewards Std              1.16691
evaluation/Rewards Max             -0.0285471
evaluation/Rewards Min            -10.5436
evaluation/Returns Mean          -104.68
evaluation/Returns Std             78.7996
evaluation/Returns Max            -12.9123
evaluation/Returns Min           -298.947
evaluation/Actions Mean             0.00801493
evaluation/Actions Std              0.190676
evaluation/Actions Max              0.99914
evaluation/Actions Min             -0.998487
evaluation/Num Paths               15
evaluation/Average Returns       -104.68
time/data storing (s)               0.00290702
time/evaluation sampling (s)        0.329297
time/exploration sampling (s)       0.141129
time/logging (s)                    0.00541071
time/saving (s)                     0.00202925
time/training (s)                   1.94639
time/epoch (s)                      2.42716
time/total (s)                    322.534
Epoch                             131
-----------------------------  ---------------
2019-04-22 23:58:44.249501 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 132 finished
-----------------------------  ---------------
replay_buffer/size              66700
trainer/QF1 Loss                    2.02233
trainer/QF2 Loss                    1.97428
trainer/Policy Loss                68.1224
trainer/Q1 Predictions Mean       -66.5063
trainer/Q1 Predictions Std         37.2684
trainer/Q1 Predictions Max        -10.6529
trainer/Q1 Predictions Min       -145.556
trainer/Q2 Predictions Mean       -66.529
trainer/Q2 Predictions Std         37.245
trainer/Q2 Predictions Max        -10.8274
trainer/Q2 Predictions Min       -145.438
trainer/Q Targets Mean            -66.9225
trainer/Q Targets Std              37.7641
trainer/Q Targets Max              -0.155822
trainer/Q Targets Min            -146.373
trainer/Log Pis Mean                2.26772
trainer/Log Pis Std                 1.20786
trainer/Log Pis Max                 6.87319
trainer/Log Pis Min                -0.46455
trainer/Policy mu Mean              0.0374482
trainer/Policy mu Std               0.852139
trainer/Policy mu Max               2.12585
trainer/Policy mu Min              -3.30983
trainer/Policy log std Mean        -1.94685
trainer/Policy log std Std          0.579147
trainer/Policy log std Max         -0.425149
trainer/Policy log std Min         -2.97666
trainer/Alpha                       0.0822111
trainer/Alpha Loss                  0.668936
exploration/num steps total     66700
exploration/num paths total       667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.7094
exploration/Rewards Std             1.29427
exploration/Rewards Max            -0.0188091
exploration/Rewards Min           -11.0274
exploration/Returns Mean         -170.94
exploration/Returns Std            85.5089
exploration/Returns Max           -29.4944
exploration/Returns Min          -298.601
exploration/Actions Mean            0.00183324
exploration/Actions Std             0.250197
exploration/Actions Max             0.987524
exploration/Actions Min            -0.999755
exploration/Num Paths               5
exploration/Average Returns      -170.94
evaluation/num steps total     199500
evaluation/num paths total       1995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.15412
evaluation/Rewards Std              1.01359
evaluation/Rewards Max             -0.00951909
evaluation/Rewards Min             -7.74935
evaluation/Returns Mean          -115.412
evaluation/Returns Std             82.785
evaluation/Returns Max            -17.9711
evaluation/Returns Min           -276.665
evaluation/Actions Mean             0.00334102
evaluation/Actions Std              0.162257
evaluation/Actions Max              0.997664
evaluation/Actions Min             -0.994329
evaluation/Num Paths               15
evaluation/Average Returns       -115.412
time/data storing (s)               0.00294666
time/evaluation sampling (s)        0.332405
time/exploration sampling (s)       0.140059
time/logging (s)                    0.00485772
time/saving (s)                     0.0104398
time/training (s)                   1.93138
time/epoch (s)                      2.42209
time/total (s)                    324.961
Epoch                             132
-----------------------------  ---------------
2019-04-22 23:58:46.667759 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 133 finished
-----------------------------  ----------------
replay_buffer/size              67200
trainer/QF1 Loss                   33.8665
trainer/QF2 Loss                   33.6139
trainer/Policy Loss                64.9435
trainer/Q1 Predictions Mean       -63.5793
trainer/Q1 Predictions Std         44.6762
trainer/Q1 Predictions Max        -10.7203
trainer/Q1 Predictions Min       -152.552
trainer/Q2 Predictions Mean       -63.5324
trainer/Q2 Predictions Std         44.6308
trainer/Q2 Predictions Max        -10.7959
trainer/Q2 Predictions Min       -151.736
trainer/Q Targets Mean            -62.7774
trainer/Q Targets Std              45.6157
trainer/Q Targets Max              -0.766025
trainer/Q Targets Min            -153.823
trainer/Log Pis Mean                1.90111
trainer/Log Pis Std                 1.30679
trainer/Log Pis Max                 5.06203
trainer/Log Pis Min                -3.01858
trainer/Policy mu Mean              0.0857197
trainer/Policy mu Std               0.753238
trainer/Policy mu Max               2.3929
trainer/Policy mu Min              -2.53579
trainer/Policy log std Mean        -1.98967
trainer/Policy log std Std          0.601712
trainer/Policy log std Max         -0.413929
trainer/Policy log std Min         -2.94566
trainer/Alpha                       0.0814705
trainer/Alpha Loss                 -0.247977
exploration/num steps total     67200
exploration/num paths total       672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.740087
exploration/Rewards Std             1.00082
exploration/Rewards Max            -0.0153501
exploration/Rewards Min            -8.59087
exploration/Returns Mean          -74.0087
exploration/Returns Std            48.9841
exploration/Returns Max           -23.7654
exploration/Returns Min          -165.912
exploration/Actions Mean           -0.000303947
exploration/Actions Std             0.210117
exploration/Actions Max             0.999188
exploration/Actions Min            -0.99719
exploration/Num Paths               5
exploration/Average Returns       -74.0087
evaluation/num steps total     201000
evaluation/num paths total       2010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.30894
evaluation/Rewards Std              1.27714
evaluation/Rewards Max             -0.0184391
evaluation/Rewards Min            -10.6369
evaluation/Returns Mean          -130.894
evaluation/Returns Std             80.4495
evaluation/Returns Max            -24.1054
evaluation/Returns Min           -285.452
evaluation/Actions Mean             0.00616577
evaluation/Actions Std              0.200986
evaluation/Actions Max              0.999197
evaluation/Actions Min             -0.999529
evaluation/Num Paths               15
evaluation/Average Returns       -130.894
time/data storing (s)               0.00300479
time/evaluation sampling (s)        0.328419
time/exploration sampling (s)       0.137845
time/logging (s)                    0.0035394
time/saving (s)                     0.00193724
time/training (s)                   1.93528
time/epoch (s)                      2.41003
time/total (s)                    327.375
Epoch                             133
-----------------------------  ----------------
2019-04-22 23:58:49.078907 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 134 finished
-----------------------------  ---------------
replay_buffer/size              67700
trainer/QF1 Loss                    0.948376
trainer/QF2 Loss                    0.967773
trainer/Policy Loss                58.3195
trainer/Q1 Predictions Mean       -56.9795
trainer/Q1 Predictions Std         40.4201
trainer/Q1 Predictions Max        -10.5616
trainer/Q1 Predictions Min       -146.026
trainer/Q2 Predictions Mean       -56.9644
trainer/Q2 Predictions Std         40.4136
trainer/Q2 Predictions Max        -10.4371
trainer/Q2 Predictions Min       -146.694
trainer/Q Targets Mean            -57.6592
trainer/Q Targets Std              40.8657
trainer/Q Targets Max             -10.7068
trainer/Q Targets Min            -147.056
trainer/Log Pis Mean                1.95302
trainer/Log Pis Std                 1.17987
trainer/Log Pis Max                 5.09498
trainer/Log Pis Min                -2.94899
trainer/Policy mu Mean              0.102765
trainer/Policy mu Std               0.753234
trainer/Policy mu Max               2.39883
trainer/Policy mu Min              -2.89012
trainer/Policy log std Mean        -1.99304
trainer/Policy log std Std          0.565349
trainer/Policy log std Max         -0.361566
trainer/Policy log std Min         -2.94139
trainer/Alpha                       0.0797268
trainer/Alpha Loss                 -0.118826
exploration/num steps total     67700
exploration/num paths total       677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.68701
exploration/Rewards Std             1.32704
exploration/Rewards Max            -0.0330897
exploration/Rewards Min           -11.5519
exploration/Returns Mean         -168.701
exploration/Returns Std            78.5961
exploration/Returns Max           -39.2516
exploration/Returns Min          -284.844
exploration/Actions Mean            0.0230815
exploration/Actions Std             0.262943
exploration/Actions Max             0.999135
exploration/Actions Min            -0.998416
exploration/Num Paths               5
exploration/Average Returns      -168.701
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.27151
evaluation/Rewards Std              1.04061
evaluation/Rewards Max             -0.0143286
evaluation/Rewards Min            -11.1075
evaluation/Returns Mean          -127.151
evaluation/Returns Std             70.6623
evaluation/Returns Max            -13.3801
evaluation/Returns Min           -285.857
evaluation/Actions Mean             0.00936662
evaluation/Actions Std              0.170639
evaluation/Actions Max              0.998525
evaluation/Actions Min             -0.99831
evaluation/Num Paths               15
evaluation/Average Returns       -127.151
time/data storing (s)               0.00284372
time/evaluation sampling (s)        0.334716
time/exploration sampling (s)       0.140176
time/logging (s)                    0.00480609
time/saving (s)                     0.00194768
time/training (s)                   1.92245
time/epoch (s)                      2.40694
time/total (s)                    329.785
Epoch                             134
-----------------------------  ---------------
2019-04-22 23:58:51.491864 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 135 finished
-----------------------------  ---------------
replay_buffer/size              68200
trainer/QF1 Loss                    1.7078
trainer/QF2 Loss                    1.68443
trainer/Policy Loss                62.6628
trainer/Q1 Predictions Mean       -61.3241
trainer/Q1 Predictions Std         39.136
trainer/Q1 Predictions Max        -10.6647
trainer/Q1 Predictions Min       -142.825
trainer/Q2 Predictions Mean       -61.3622
trainer/Q2 Predictions Std         39.1134
trainer/Q2 Predictions Max        -10.8221
trainer/Q2 Predictions Min       -142.328
trainer/Q Targets Mean            -61.5695
trainer/Q Targets Std              39.4322
trainer/Q Targets Max              -0.136167
trainer/Q Targets Min            -142.419
trainer/Log Pis Mean                1.79568
trainer/Log Pis Std                 1.3197
trainer/Log Pis Max                 5.16533
trainer/Log Pis Min                -4.40863
trainer/Policy mu Mean              0.0298719
trainer/Policy mu Std               0.731634
trainer/Policy mu Max               2.68352
trainer/Policy mu Min              -2.82023
trainer/Policy log std Mean        -1.99973
trainer/Policy log std Std          0.552146
trainer/Policy log std Max         -0.317581
trainer/Policy log std Min         -3.01764
trainer/Alpha                       0.0800296
trainer/Alpha Loss                 -0.515966
exploration/num steps total     68200
exploration/num paths total       682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36787
exploration/Rewards Std             1.05481
exploration/Rewards Max            -0.0148926
exploration/Rewards Min            -7.25528
exploration/Returns Mean         -136.787
exploration/Returns Std            86.2744
exploration/Returns Max           -35.652
exploration/Returns Min          -276.967
exploration/Actions Mean            0.0215557
exploration/Actions Std             0.233925
exploration/Actions Max             0.995104
exploration/Actions Min            -0.989047
exploration/Num Paths               5
exploration/Average Returns      -136.787
evaluation/num steps total     204000
evaluation/num paths total       2040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.823161
evaluation/Rewards Std              1.19301
evaluation/Rewards Max             -0.0102453
evaluation/Rewards Min            -10.7892
evaluation/Returns Mean           -82.3161
evaluation/Returns Std             57.2691
evaluation/Returns Max            -18.2891
evaluation/Returns Min           -170.448
evaluation/Actions Mean            -0.00696334
evaluation/Actions Std              0.205815
evaluation/Actions Max              0.998882
evaluation/Actions Min             -0.999465
evaluation/Num Paths               15
evaluation/Average Returns        -82.3161
time/data storing (s)               0.00308997
time/evaluation sampling (s)        0.329079
time/exploration sampling (s)       0.138776
time/logging (s)                    0.00479947
time/saving (s)                     0.0019463
time/training (s)                   1.9294
time/epoch (s)                      2.40709
time/total (s)                    332.196
Epoch                             135
-----------------------------  ---------------
2019-04-22 23:58:53.929421 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 136 finished
-----------------------------  ---------------
replay_buffer/size              68700
trainer/QF1 Loss                   42.247
trainer/QF2 Loss                   42.3452
trainer/Policy Loss                63.7959
trainer/Q1 Predictions Mean       -62.5256
trainer/Q1 Predictions Std         38.1654
trainer/Q1 Predictions Max        -10.0792
trainer/Q1 Predictions Min       -141.539
trainer/Q2 Predictions Mean       -62.4819
trainer/Q2 Predictions Std         38.1323
trainer/Q2 Predictions Max        -10.0753
trainer/Q2 Predictions Min       -141.938
trainer/Q Targets Mean            -62.6819
trainer/Q Targets Std              40.0483
trainer/Q Targets Max              -0.399445
trainer/Q Targets Min            -145.363
trainer/Log Pis Mean                1.92076
trainer/Log Pis Std                 1.40943
trainer/Log Pis Max                 5.20739
trainer/Log Pis Min                -5.14448
trainer/Policy mu Mean              0.0140896
trainer/Policy mu Std               0.781333
trainer/Policy mu Max               2.9445
trainer/Policy mu Min              -2.72321
trainer/Policy log std Mean        -1.98805
trainer/Policy log std Std          0.565063
trainer/Policy log std Max         -0.446729
trainer/Policy log std Min         -2.95733
trainer/Alpha                       0.0791782
trainer/Alpha Loss                 -0.200949
exploration/num steps total     68700
exploration/num paths total       687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.529332
exploration/Rewards Std             1.06067
exploration/Rewards Max            -0.0125086
exploration/Rewards Min           -10.4718
exploration/Returns Mean          -52.9332
exploration/Returns Std            23.6933
exploration/Returns Max           -27.0025
exploration/Returns Min           -86.8094
exploration/Actions Mean           -0.0128353
exploration/Actions Std             0.222183
exploration/Actions Max             0.998993
exploration/Actions Min            -0.998625
exploration/Num Paths               5
exploration/Average Returns       -52.9332
evaluation/num steps total     205500
evaluation/num paths total       2055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.956584
evaluation/Rewards Std              1.01295
evaluation/Rewards Max             -0.0480347
evaluation/Rewards Min             -7.34131
evaluation/Returns Mean           -95.6584
evaluation/Returns Std             83.2549
evaluation/Returns Max             -9.2402
evaluation/Returns Min           -276.244
evaluation/Actions Mean            -0.00797316
evaluation/Actions Std              0.161206
evaluation/Actions Max              0.989875
evaluation/Actions Min             -0.998472
evaluation/Num Paths               15
evaluation/Average Returns        -95.6584
time/data storing (s)               0.00309495
time/evaluation sampling (s)        0.333917
time/exploration sampling (s)       0.141221
time/logging (s)                    0.00479303
time/saving (s)                     0.00198258
time/training (s)                   1.94589
time/epoch (s)                      2.4309
time/total (s)                    334.631
Epoch                             136
-----------------------------  ---------------
2019-04-22 23:58:56.358926 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 137 finished
-----------------------------  ---------------
replay_buffer/size              69200
trainer/QF1 Loss                   60.7851
trainer/QF2 Loss                   62.2192
trainer/Policy Loss                64.322
trainer/Q1 Predictions Mean       -63.0668
trainer/Q1 Predictions Std         40.0371
trainer/Q1 Predictions Max        -10.685
trainer/Q1 Predictions Min       -143.005
trainer/Q2 Predictions Mean       -63.0552
trainer/Q2 Predictions Std         40.0682
trainer/Q2 Predictions Max        -10.522
trainer/Q2 Predictions Min       -142.801
trainer/Q Targets Mean            -62.9442
trainer/Q Targets Std              40.6606
trainer/Q Targets Max              -3.30733
trainer/Q Targets Min            -145.071
trainer/Log Pis Mean                1.86971
trainer/Log Pis Std                 1.4556
trainer/Log Pis Max                 5.83297
trainer/Log Pis Min                -3.80659
trainer/Policy mu Mean              0.0891786
trainer/Policy mu Std               0.797567
trainer/Policy mu Max               3.08935
trainer/Policy mu Min              -3.00586
trainer/Policy log std Mean        -1.94415
trainer/Policy log std Std          0.574268
trainer/Policy log std Max         -0.253421
trainer/Policy log std Min         -3.0063
trainer/Alpha                       0.077313
trainer/Alpha Loss                 -0.333502
exploration/num steps total     69200
exploration/num paths total       692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.489315
exploration/Rewards Std             1.23498
exploration/Rewards Max            -0.0201737
exploration/Rewards Min            -9.19653
exploration/Returns Mean          -48.9315
exploration/Returns Std            12.5724
exploration/Returns Max           -29.5298
exploration/Returns Min           -63.6518
exploration/Actions Mean           -0.0425251
exploration/Actions Std             0.25641
exploration/Actions Max             0.981081
exploration/Actions Min            -0.999555
exploration/Num Paths               5
exploration/Average Returns       -48.9315
evaluation/num steps total     207000
evaluation/num paths total       2070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.828533
evaluation/Rewards Std              1.09013
evaluation/Rewards Max             -0.0551475
evaluation/Rewards Min            -10.0215
evaluation/Returns Mean           -82.8533
evaluation/Returns Std             71.7236
evaluation/Returns Max             -8.13759
evaluation/Returns Min           -283.07
evaluation/Actions Mean             0.00316932
evaluation/Actions Std              0.173393
evaluation/Actions Max              0.999646
evaluation/Actions Min             -0.997292
evaluation/Num Paths               15
evaluation/Average Returns        -82.8533
time/data storing (s)               0.00300363
time/evaluation sampling (s)        0.322411
time/exploration sampling (s)       0.143506
time/logging (s)                    0.00480837
time/saving (s)                     0.0019703
time/training (s)                   1.94747
time/epoch (s)                      2.42317
time/total (s)                    337.058
Epoch                             137
-----------------------------  ---------------
2019-04-22 23:58:58.788260 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 138 finished
-----------------------------  ---------------
replay_buffer/size              69700
trainer/QF1 Loss                  412.754
trainer/QF2 Loss                  410.978
trainer/Policy Loss                59.1225
trainer/Q1 Predictions Mean       -57.769
trainer/Q1 Predictions Std         37.9592
trainer/Q1 Predictions Max        -10.7519
trainer/Q1 Predictions Min       -149.419
trainer/Q2 Predictions Mean       -57.7423
trainer/Q2 Predictions Std         37.9451
trainer/Q2 Predictions Max        -10.7545
trainer/Q2 Predictions Min       -148.648
trainer/Q Targets Mean            -55.3516
trainer/Q Targets Std              37.6965
trainer/Q Targets Max              -2.32736
trainer/Q Targets Min            -143.466
trainer/Log Pis Mean                1.9713
trainer/Log Pis Std                 1.398
trainer/Log Pis Max                 5.67123
trainer/Log Pis Min                -2.75352
trainer/Policy mu Mean              0.10628
trainer/Policy mu Std               0.802688
trainer/Policy mu Max               2.76984
trainer/Policy mu Min              -2.66099
trainer/Policy log std Mean        -1.94934
trainer/Policy log std Std          0.610487
trainer/Policy log std Max         -0.383437
trainer/Policy log std Min         -3.08343
trainer/Alpha                       0.0762703
trainer/Alpha Loss                 -0.0738669
exploration/num steps total     69700
exploration/num paths total       697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11262
exploration/Rewards Std             0.61038
exploration/Rewards Max            -0.160218
exploration/Rewards Min            -7.51341
exploration/Returns Mean         -111.262
exploration/Returns Std            43.3399
exploration/Returns Max           -41.2855
exploration/Returns Min          -160.296
exploration/Actions Mean            0.00506738
exploration/Actions Std             0.172836
exploration/Actions Max             0.986559
exploration/Actions Min            -0.998563
exploration/Num Paths               5
exploration/Average Returns      -111.262
evaluation/num steps total     208500
evaluation/num paths total       2085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.889427
evaluation/Rewards Std              0.809086
evaluation/Rewards Max             -0.0870893
evaluation/Rewards Min             -8.05329
evaluation/Returns Mean           -88.9427
evaluation/Returns Std             53.435
evaluation/Returns Max            -13.894
evaluation/Returns Min           -164.468
evaluation/Actions Mean            -0.00123454
evaluation/Actions Std              0.15225
evaluation/Actions Max              0.998191
evaluation/Actions Min             -0.998769
evaluation/Num Paths               15
evaluation/Average Returns        -88.9427
time/data storing (s)               0.00289023
time/evaluation sampling (s)        0.322672
time/exploration sampling (s)       0.141613
time/logging (s)                    0.00480349
time/saving (s)                     0.00196567
time/training (s)                   1.94865
time/epoch (s)                      2.4226
time/total (s)                    339.485
Epoch                             138
-----------------------------  ---------------
2019-04-22 23:59:01.219911 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 139 finished
-----------------------------  ---------------
replay_buffer/size              70200
trainer/QF1 Loss                  351.294
trainer/QF2 Loss                  351.757
trainer/Policy Loss                61.793
trainer/Q1 Predictions Mean       -60.7238
trainer/Q1 Predictions Std         41.4493
trainer/Q1 Predictions Max        -10.3815
trainer/Q1 Predictions Min       -169.31
trainer/Q2 Predictions Mean       -60.7988
trainer/Q2 Predictions Std         41.4293
trainer/Q2 Predictions Max        -10.3242
trainer/Q2 Predictions Min       -168.991
trainer/Q Targets Mean            -58.4205
trainer/Q Targets Std              42.2259
trainer/Q Targets Max              -1.72983
trainer/Q Targets Min            -170.772
trainer/Log Pis Mean                1.70694
trainer/Log Pis Std                 1.64732
trainer/Log Pis Max                 7.07076
trainer/Log Pis Min                -3.35101
trainer/Policy mu Mean              0.024914
trainer/Policy mu Std               0.80436
trainer/Policy mu Max               3.58271
trainer/Policy mu Min              -3.19909
trainer/Policy log std Mean        -1.8713
trainer/Policy log std Std          0.561464
trainer/Policy log std Max         -0.220725
trainer/Policy log std Min         -2.94996
trainer/Alpha                       0.0783297
trainer/Alpha Loss                 -0.746362
exploration/num steps total     70200
exploration/num paths total       702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.28657
exploration/Rewards Std             1.13422
exploration/Rewards Max            -0.0309976
exploration/Rewards Min            -7.3173
exploration/Returns Mean         -128.657
exploration/Returns Std            93.8952
exploration/Returns Max           -46.8912
exploration/Returns Min          -301.862
exploration/Actions Mean           -0.0119834
exploration/Actions Std             0.216077
exploration/Actions Max             0.999192
exploration/Actions Min            -0.993303
exploration/Num Paths               5
exploration/Average Returns      -128.657
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.771498
evaluation/Rewards Std              1.14115
evaluation/Rewards Max             -0.0184429
evaluation/Rewards Min            -11.0429
evaluation/Returns Mean           -77.1498
evaluation/Returns Std             68.3945
evaluation/Returns Max            -14.5843
evaluation/Returns Min           -223.499
evaluation/Actions Mean             0.00559693
evaluation/Actions Std              0.197607
evaluation/Actions Max              0.997412
evaluation/Actions Min             -0.998596
evaluation/Num Paths               15
evaluation/Average Returns        -77.1498
time/data storing (s)               0.00290374
time/evaluation sampling (s)        0.335188
time/exploration sampling (s)       0.136564
time/logging (s)                    0.00481866
time/saving (s)                     0.00192888
time/training (s)                   1.94358
time/epoch (s)                      2.42498
time/total (s)                    341.914
Epoch                             139
-----------------------------  ---------------
2019-04-22 23:59:03.641763 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 140 finished
-----------------------------  ---------------
replay_buffer/size              70700
trainer/QF1 Loss                   22.5136
trainer/QF2 Loss                   22.3992
trainer/Policy Loss                55.1715
trainer/Q1 Predictions Mean       -53.9868
trainer/Q1 Predictions Std         32.2683
trainer/Q1 Predictions Max        -10.9635
trainer/Q1 Predictions Min       -157.72
trainer/Q2 Predictions Mean       -54.0062
trainer/Q2 Predictions Std         32.3113
trainer/Q2 Predictions Max        -10.9423
trainer/Q2 Predictions Min       -158.046
trainer/Q Targets Mean            -54.1406
trainer/Q Targets Std              32.997
trainer/Q Targets Max              -0.582148
trainer/Q Targets Min            -156.914
trainer/Log Pis Mean                2.20464
trainer/Log Pis Std                 1.66231
trainer/Log Pis Max                 7.88274
trainer/Log Pis Min                -4.30286
trainer/Policy mu Mean              0.180476
trainer/Policy mu Std               0.969191
trainer/Policy mu Max               3.54581
trainer/Policy mu Min              -2.77639
trainer/Policy log std Mean        -1.89044
trainer/Policy log std Std          0.61189
trainer/Policy log std Max         -0.350158
trainer/Policy log std Min         -3.1531
trainer/Alpha                       0.0764994
trainer/Alpha Loss                  0.526034
exploration/num steps total     70700
exploration/num paths total       707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.25876
exploration/Rewards Std             1.21258
exploration/Rewards Max            -0.0150745
exploration/Rewards Min            -9.17769
exploration/Returns Mean         -125.876
exploration/Returns Std            84.5362
exploration/Returns Max           -34.3441
exploration/Returns Min          -279.586
exploration/Actions Mean           -0.00117782
exploration/Actions Std             0.208625
exploration/Actions Max             0.999085
exploration/Actions Min            -0.997334
exploration/Num Paths               5
exploration/Average Returns      -125.876
evaluation/num steps total     211500
evaluation/num paths total       2115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00063
evaluation/Rewards Std              1.11965
evaluation/Rewards Max             -0.0274741
evaluation/Rewards Min             -8.96557
evaluation/Returns Mean          -100.063
evaluation/Returns Std             72.5278
evaluation/Returns Max            -12.4705
evaluation/Returns Min           -283.444
evaluation/Actions Mean            -0.00828649
evaluation/Actions Std              0.184516
evaluation/Actions Max              0.997971
evaluation/Actions Min             -0.999602
evaluation/Num Paths               15
evaluation/Average Returns       -100.063
time/data storing (s)               0.00281622
time/evaluation sampling (s)        0.333583
time/exploration sampling (s)       0.135682
time/logging (s)                    0.00473661
time/saving (s)                     0.00197401
time/training (s)                   1.93625
time/epoch (s)                      2.41504
time/total (s)                    344.334
Epoch                             140
-----------------------------  ---------------
2019-04-22 23:59:06.073755 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 141 finished
-----------------------------  ---------------
replay_buffer/size              71200
trainer/QF1 Loss                    1.20741
trainer/QF2 Loss                    1.12364
trainer/Policy Loss                62.2719
trainer/Q1 Predictions Mean       -61.0282
trainer/Q1 Predictions Std         38.7718
trainer/Q1 Predictions Max        -10.373
trainer/Q1 Predictions Min       -158.508
trainer/Q2 Predictions Mean       -61.0715
trainer/Q2 Predictions Std         38.8604
trainer/Q2 Predictions Max        -10.4104
trainer/Q2 Predictions Min       -159.026
trainer/Q Targets Mean            -61.6076
trainer/Q Targets Std              39.4133
trainer/Q Targets Max             -10.6832
trainer/Q Targets Min            -164.635
trainer/Log Pis Mean                1.86854
trainer/Log Pis Std                 1.45969
trainer/Log Pis Max                 5.96343
trainer/Log Pis Min                -3.55666
trainer/Policy mu Mean              0.00695128
trainer/Policy mu Std               0.752194
trainer/Policy mu Max               2.91257
trainer/Policy mu Min              -2.69133
trainer/Policy log std Mean        -1.97009
trainer/Policy log std Std          0.586618
trainer/Policy log std Max         -0.22315
trainer/Policy log std Min         -3.10314
trainer/Alpha                       0.0782034
trainer/Alpha Loss                 -0.335021
exploration/num steps total     71200
exploration/num paths total       712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.72503
exploration/Rewards Std             1.4128
exploration/Rewards Max            -0.0256701
exploration/Rewards Min            -9.37535
exploration/Returns Mean         -172.503
exploration/Returns Std           107.562
exploration/Returns Max           -40.2749
exploration/Returns Min          -300.988
exploration/Actions Mean           -0.0231119
exploration/Actions Std             0.260884
exploration/Actions Max             0.962175
exploration/Actions Min            -0.999612
exploration/Num Paths               5
exploration/Average Returns      -172.503
evaluation/num steps total     213000
evaluation/num paths total       2130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.16183
evaluation/Rewards Std              1.03764
evaluation/Rewards Max             -0.0405662
evaluation/Rewards Min            -10.3416
evaluation/Returns Mean          -116.183
evaluation/Returns Std             50.3941
evaluation/Returns Max            -34.8246
evaluation/Returns Min           -186.263
evaluation/Actions Mean            -0.00843264
evaluation/Actions Std              0.183115
evaluation/Actions Max              0.997809
evaluation/Actions Min             -0.999908
evaluation/Num Paths               15
evaluation/Average Returns       -116.183
time/data storing (s)               0.00299298
time/evaluation sampling (s)        0.334031
time/exploration sampling (s)       0.140109
time/logging (s)                    0.00354152
time/saving (s)                     0.00194218
time/training (s)                   1.9414
time/epoch (s)                      2.42402
time/total (s)                    346.762
Epoch                             141
-----------------------------  ---------------
2019-04-22 23:59:08.488594 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 142 finished
-----------------------------  ---------------
replay_buffer/size              71700
trainer/QF1 Loss                    0.432461
trainer/QF2 Loss                    0.524461
trainer/Policy Loss                68.2075
trainer/Q1 Predictions Mean       -66.8273
trainer/Q1 Predictions Std         38.1907
trainer/Q1 Predictions Max        -10.584
trainer/Q1 Predictions Min       -147.43
trainer/Q2 Predictions Mean       -66.817
trainer/Q2 Predictions Std         38.2102
trainer/Q2 Predictions Max        -10.6966
trainer/Q2 Predictions Min       -147.002
trainer/Q Targets Mean            -67.067
trainer/Q Targets Std              38.3966
trainer/Q Targets Max             -10.5912
trainer/Q Targets Min            -146.65
trainer/Log Pis Mean                2.05389
trainer/Log Pis Std                 1.19907
trainer/Log Pis Max                 5.52914
trainer/Log Pis Min                -2.76336
trainer/Policy mu Mean              0.0258879
trainer/Policy mu Std               0.876982
trainer/Policy mu Max               2.98692
trainer/Policy mu Min              -2.60058
trainer/Policy log std Mean        -1.82963
trainer/Policy log std Std          0.576951
trainer/Policy log std Max         -0.452883
trainer/Policy log std Min         -3.03597
trainer/Alpha                       0.0795284
trainer/Alpha Loss                  0.13643
exploration/num steps total     71700
exploration/num paths total       717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04527
exploration/Rewards Std             1.21216
exploration/Rewards Max            -0.0143851
exploration/Rewards Min           -10.0966
exploration/Returns Mean         -104.527
exploration/Returns Std            53.1985
exploration/Returns Max           -54.8943
exploration/Returns Min          -175.786
exploration/Actions Mean            0.0036672
exploration/Actions Std             0.243805
exploration/Actions Max             0.997246
exploration/Actions Min            -0.997722
exploration/Num Paths               5
exploration/Average Returns      -104.527
evaluation/num steps total     214500
evaluation/num paths total       2145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02696
evaluation/Rewards Std              0.976406
evaluation/Rewards Max             -0.0413669
evaluation/Rewards Min             -8.15577
evaluation/Returns Mean          -102.696
evaluation/Returns Std             79.6987
evaluation/Returns Max            -11.6827
evaluation/Returns Min           -276.578
evaluation/Actions Mean            -0.0046723
evaluation/Actions Std              0.161422
evaluation/Actions Max              0.989358
evaluation/Actions Min             -0.99931
evaluation/Num Paths               15
evaluation/Average Returns       -102.696
time/data storing (s)               0.00295296
time/evaluation sampling (s)        0.332848
time/exploration sampling (s)       0.137099
time/logging (s)                    0.0047571
time/saving (s)                     0.00194979
time/training (s)                   1.92981
time/epoch (s)                      2.40942
time/total (s)                    349.176
Epoch                             142
-----------------------------  ---------------
2019-04-22 23:59:10.918907 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 143 finished
-----------------------------  ----------------
replay_buffer/size              72200
trainer/QF1 Loss                   91.2945
trainer/QF2 Loss                   91.5893
trainer/Policy Loss                62.9168
trainer/Q1 Predictions Mean       -61.433
trainer/Q1 Predictions Std         38.3079
trainer/Q1 Predictions Max        -10.3919
trainer/Q1 Predictions Min       -144.811
trainer/Q2 Predictions Mean       -61.468
trainer/Q2 Predictions Std         38.349
trainer/Q2 Predictions Max        -10.3507
trainer/Q2 Predictions Min       -144.867
trainer/Q Targets Mean            -60.7631
trainer/Q Targets Std              38.6465
trainer/Q Targets Max              -4.53111
trainer/Q Targets Min            -144.245
trainer/Log Pis Mean                2.15875
trainer/Log Pis Std                 1.11635
trainer/Log Pis Max                 6.15026
trainer/Log Pis Min                -0.829385
trainer/Policy mu Mean              0.1092
trainer/Policy mu Std               0.745188
trainer/Policy mu Max               3.25073
trainer/Policy mu Min              -2.53162
trainer/Policy log std Mean        -1.99623
trainer/Policy log std Std          0.58509
trainer/Policy log std Max         -0.34944
trainer/Policy log std Min         -3.09998
trainer/Alpha                       0.0808003
trainer/Alpha Loss                  0.39939
exploration/num steps total     72200
exploration/num paths total       722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.63579
exploration/Rewards Std             1.43715
exploration/Rewards Max            -0.325712
exploration/Rewards Min            -9.84352
exploration/Returns Mean         -163.579
exploration/Returns Std           104.289
exploration/Returns Max           -60.4349
exploration/Returns Min          -303.523
exploration/Actions Mean            0.00256749
exploration/Actions Std             0.239309
exploration/Actions Max             0.995675
exploration/Actions Min            -0.999644
exploration/Num Paths               5
exploration/Average Returns      -163.579
evaluation/num steps total     216000
evaluation/num paths total       2160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.24914
evaluation/Rewards Std              1.11195
evaluation/Rewards Max             -0.208441
evaluation/Rewards Min            -10.9011
evaluation/Returns Mean          -124.914
evaluation/Returns Std             76.3268
evaluation/Returns Max            -22.3744
evaluation/Returns Min           -291.198
evaluation/Actions Mean            -0.000542428
evaluation/Actions Std              0.176685
evaluation/Actions Max              0.999437
evaluation/Actions Min             -0.999176
evaluation/Num Paths               15
evaluation/Average Returns       -124.914
time/data storing (s)               0.0030373
time/evaluation sampling (s)        0.330281
time/exploration sampling (s)       0.140053
time/logging (s)                    0.00475758
time/saving (s)                     0.00195686
time/training (s)                   1.94343
time/epoch (s)                      2.42352
time/total (s)                    351.603
Epoch                             143
-----------------------------  ----------------
2019-04-22 23:59:13.357630 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 144 finished
-----------------------------  ---------------
replay_buffer/size              72700
trainer/QF1 Loss                   14.1627
trainer/QF2 Loss                   13.8808
trainer/Policy Loss                54.2581
trainer/Q1 Predictions Mean       -52.8517
trainer/Q1 Predictions Std         37.6043
trainer/Q1 Predictions Max        -10.2347
trainer/Q1 Predictions Min       -146.786
trainer/Q2 Predictions Mean       -52.8468
trainer/Q2 Predictions Std         37.6817
trainer/Q2 Predictions Max        -10.1662
trainer/Q2 Predictions Min       -148.044
trainer/Q Targets Mean            -52.8213
trainer/Q Targets Std              38.5884
trainer/Q Targets Max              -0.0580595
trainer/Q Targets Min            -150.584
trainer/Log Pis Mean                2.12585
trainer/Log Pis Std                 1.61705
trainer/Log Pis Max                11.9413
trainer/Log Pis Min                -0.865288
trainer/Policy mu Mean              0.117183
trainer/Policy mu Std               0.941744
trainer/Policy mu Max               2.84051
trainer/Policy mu Min              -4.50863
trainer/Policy log std Mean        -1.83697
trainer/Policy log std Std          0.616341
trainer/Policy log std Max          0.243573
trainer/Policy log std Min         -2.97441
trainer/Alpha                       0.0810245
trainer/Alpha Loss                  0.316268
exploration/num steps total     72700
exploration/num paths total       727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04943
exploration/Rewards Std             0.788487
exploration/Rewards Max            -0.0293739
exploration/Rewards Min            -5.27966
exploration/Returns Mean         -104.943
exploration/Returns Std            65.0683
exploration/Returns Max           -22.3431
exploration/Returns Min          -167.593
exploration/Actions Mean           -0.0181864
exploration/Actions Std             0.210167
exploration/Actions Max             0.944789
exploration/Actions Min            -0.997453
exploration/Num Paths               5
exploration/Average Returns      -104.943
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.35544
evaluation/Rewards Std              1.21126
evaluation/Rewards Max             -0.081663
evaluation/Rewards Min             -9.1787
evaluation/Returns Mean          -135.544
evaluation/Returns Std            106.197
evaluation/Returns Max            -13.7035
evaluation/Returns Min           -309.641
evaluation/Actions Mean             0.0117928
evaluation/Actions Std              0.161554
evaluation/Actions Max              0.998202
evaluation/Actions Min             -0.996703
evaluation/Num Paths               15
evaluation/Average Returns       -135.544
time/data storing (s)               0.00289095
time/evaluation sampling (s)        0.327316
time/exploration sampling (s)       0.141829
time/logging (s)                    0.00440173
time/saving (s)                     0.0102636
time/training (s)                   1.94518
time/epoch (s)                      2.43188
time/total (s)                    354.039
Epoch                             144
-----------------------------  ---------------
2019-04-22 23:59:15.791789 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 145 finished
-----------------------------  ---------------
replay_buffer/size              73200
trainer/QF1 Loss                   56.0267
trainer/QF2 Loss                   56.0685
trainer/Policy Loss                58.2392
trainer/Q1 Predictions Mean       -57.0834
trainer/Q1 Predictions Std         38.7341
trainer/Q1 Predictions Max        -10.5572
trainer/Q1 Predictions Min       -136.9
trainer/Q2 Predictions Mean       -57.077
trainer/Q2 Predictions Std         38.7371
trainer/Q2 Predictions Max        -10.4862
trainer/Q2 Predictions Min       -136.762
trainer/Q Targets Mean            -57.2326
trainer/Q Targets Std              39.7571
trainer/Q Targets Max              -1.69838
trainer/Q Targets Min            -140.311
trainer/Log Pis Mean                1.77201
trainer/Log Pis Std                 1.35595
trainer/Log Pis Max                 5.50684
trainer/Log Pis Min                -2.72169
trainer/Policy mu Mean             -0.0594596
trainer/Policy mu Std               0.844412
trainer/Policy mu Max               3.23792
trainer/Policy mu Min              -2.75731
trainer/Policy log std Mean        -1.84444
trainer/Policy log std Std          0.586757
trainer/Policy log std Max         -0.374862
trainer/Policy log std Min         -3.04674
trainer/Alpha                       0.0783745
trainer/Alpha Loss                 -0.580456
exploration/num steps total     73200
exploration/num paths total       732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.530172
exploration/Rewards Std             0.910601
exploration/Rewards Max            -0.00946055
exploration/Rewards Min            -9.36468
exploration/Returns Mean          -53.0172
exploration/Returns Std            21.3353
exploration/Returns Max           -35.6044
exploration/Returns Min           -89.5409
exploration/Actions Mean           -0.00311221
exploration/Actions Std             0.234117
exploration/Actions Max             0.998186
exploration/Actions Min            -0.998179
exploration/Num Paths               5
exploration/Average Returns       -53.0172
evaluation/num steps total     219000
evaluation/num paths total       2190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01272
evaluation/Rewards Std              1.13521
evaluation/Rewards Max             -0.135398
evaluation/Rewards Min            -10.8383
evaluation/Returns Mean          -101.272
evaluation/Returns Std             63.4685
evaluation/Returns Max            -26.7838
evaluation/Returns Min           -280.836
evaluation/Actions Mean            -0.00180412
evaluation/Actions Std              0.19405
evaluation/Actions Max              0.996479
evaluation/Actions Min             -0.999881
evaluation/Num Paths               15
evaluation/Average Returns       -101.272
time/data storing (s)               0.00294005
time/evaluation sampling (s)        0.330089
time/exploration sampling (s)       0.139697
time/logging (s)                    0.00477047
time/saving (s)                     0.00179054
time/training (s)                   1.94807
time/epoch (s)                      2.42736
time/total (s)                    356.471
Epoch                             145
-----------------------------  ---------------
2019-04-22 23:59:18.211606 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 146 finished
-----------------------------  ---------------
replay_buffer/size              73700
trainer/QF1 Loss                   20.3803
trainer/QF2 Loss                   20.2986
trainer/Policy Loss                57.4367
trainer/Q1 Predictions Mean       -56.2543
trainer/Q1 Predictions Std         40.5022
trainer/Q1 Predictions Max        -10.6808
trainer/Q1 Predictions Min       -146.532
trainer/Q2 Predictions Mean       -56.2358
trainer/Q2 Predictions Std         40.5072
trainer/Q2 Predictions Max        -10.6104
trainer/Q2 Predictions Min       -147.601
trainer/Q Targets Mean            -56.3526
trainer/Q Targets Std              41.2626
trainer/Q Targets Max              -0.500116
trainer/Q Targets Min            -150.205
trainer/Log Pis Mean                2.0244
trainer/Log Pis Std                 1.35279
trainer/Log Pis Max                 5.69939
trainer/Log Pis Min                -2.03825
trainer/Policy mu Mean              0.0771412
trainer/Policy mu Std               0.995655
trainer/Policy mu Max               3.03721
trainer/Policy mu Min              -3.0039
trainer/Policy log std Mean        -1.79678
trainer/Policy log std Std          0.641906
trainer/Policy log std Max         -0.143555
trainer/Policy log std Min         -3.00026
trainer/Alpha                       0.0783646
trainer/Alpha Loss                  0.0621295
exploration/num steps total     73700
exploration/num paths total       737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.813355
exploration/Rewards Std             0.882923
exploration/Rewards Max            -0.0106834
exploration/Rewards Min            -7.60544
exploration/Returns Mean          -81.3355
exploration/Returns Std            49.1182
exploration/Returns Max           -15.3829
exploration/Returns Min          -139.761
exploration/Actions Mean            0.0133146
exploration/Actions Std             0.205291
exploration/Actions Max             0.998592
exploration/Actions Min            -0.99655
exploration/Num Paths               5
exploration/Average Returns       -81.3355
evaluation/num steps total     220500
evaluation/num paths total       2205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.63481
evaluation/Rewards Std              1.25883
evaluation/Rewards Max             -0.0217436
evaluation/Rewards Min            -10.7
evaluation/Returns Mean          -163.481
evaluation/Returns Std             93.0004
evaluation/Returns Max            -20.0548
evaluation/Returns Min           -296.097
evaluation/Actions Mean            -0.00911245
evaluation/Actions Std              0.179591
evaluation/Actions Max              0.997194
evaluation/Actions Min             -0.999918
evaluation/Num Paths               15
evaluation/Average Returns       -163.481
time/data storing (s)               0.00290224
time/evaluation sampling (s)        0.326437
time/exploration sampling (s)       0.136765
time/logging (s)                    0.00477019
time/saving (s)                     0.00195691
time/training (s)                   1.94112
time/epoch (s)                      2.41395
time/total (s)                    358.889
Epoch                             146
-----------------------------  ---------------
2019-04-22 23:59:20.631334 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 147 finished
-----------------------------  ---------------
replay_buffer/size              74200
trainer/QF1 Loss                   75.5707
trainer/QF2 Loss                   75.0859
trainer/Policy Loss                60.6975
trainer/Q1 Predictions Mean       -59.4143
trainer/Q1 Predictions Std         36.7228
trainer/Q1 Predictions Max        -10.2803
trainer/Q1 Predictions Min       -160.964
trainer/Q2 Predictions Mean       -59.407
trainer/Q2 Predictions Std         36.7047
trainer/Q2 Predictions Max        -10.1836
trainer/Q2 Predictions Min       -161.369
trainer/Q Targets Mean            -59.1798
trainer/Q Targets Std              37.7154
trainer/Q Targets Max              -0.276086
trainer/Q Targets Min            -162.758
trainer/Log Pis Mean                1.99496
trainer/Log Pis Std                 1.29569
trainer/Log Pis Max                 5.19061
trainer/Log Pis Min                -1.79156
trainer/Policy mu Mean             -0.0226548
trainer/Policy mu Std               0.902765
trainer/Policy mu Max               2.84498
trainer/Policy mu Min              -2.99605
trainer/Policy log std Mean        -1.88913
trainer/Policy log std Std          0.609736
trainer/Policy log std Max         -0.195534
trainer/Policy log std Min         -3.11877
trainer/Alpha                       0.078824
trainer/Alpha Loss                 -0.01281
exploration/num steps total     74200
exploration/num paths total       742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.38005
exploration/Rewards Std             1.48025
exploration/Rewards Max            -0.177071
exploration/Rewards Min           -10.5466
exploration/Returns Mean         -138.005
exploration/Returns Std            91.6062
exploration/Returns Max           -59.5097
exploration/Returns Min          -314.183
exploration/Actions Mean           -0.00201933
exploration/Actions Std             0.250151
exploration/Actions Max             0.999906
exploration/Actions Min            -0.99865
exploration/Num Paths               5
exploration/Average Returns      -138.005
evaluation/num steps total     222000
evaluation/num paths total       2220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00606
evaluation/Rewards Std              1.26669
evaluation/Rewards Max             -0.0839061
evaluation/Rewards Min            -10.7814
evaluation/Returns Mean          -100.606
evaluation/Returns Std             77.2125
evaluation/Returns Max            -14.6699
evaluation/Returns Min           -312.546
evaluation/Actions Mean            -0.0120643
evaluation/Actions Std              0.189609
evaluation/Actions Max              0.995847
evaluation/Actions Min             -0.999714
evaluation/Num Paths               15
evaluation/Average Returns       -100.606
time/data storing (s)               0.00292525
time/evaluation sampling (s)        0.330055
time/exploration sampling (s)       0.138491
time/logging (s)                    0.00414474
time/saving (s)                     0.00194114
time/training (s)                   1.93446
time/epoch (s)                      2.41201
time/total (s)                    361.305
Epoch                             147
-----------------------------  ---------------
2019-04-22 23:59:23.069260 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 148 finished
-----------------------------  ---------------
replay_buffer/size              74700
trainer/QF1 Loss                    0.781968
trainer/QF2 Loss                    0.926431
trainer/Policy Loss                60.5812
trainer/Q1 Predictions Mean       -59.5513
trainer/Q1 Predictions Std         40.516
trainer/Q1 Predictions Max        -10.8808
trainer/Q1 Predictions Min       -168.187
trainer/Q2 Predictions Mean       -59.4882
trainer/Q2 Predictions Std         40.5214
trainer/Q2 Predictions Max        -10.9576
trainer/Q2 Predictions Min       -167.297
trainer/Q Targets Mean            -59.572
trainer/Q Targets Std              40.864
trainer/Q Targets Max             -10.4217
trainer/Q Targets Min            -168.61
trainer/Log Pis Mean                1.94136
trainer/Log Pis Std                 1.52195
trainer/Log Pis Max                 6.97089
trainer/Log Pis Min                -2.38889
trainer/Policy mu Mean             -0.0107734
trainer/Policy mu Std               0.950376
trainer/Policy mu Max               2.70678
trainer/Policy mu Min              -3.41533
trainer/Policy log std Mean        -1.77236
trainer/Policy log std Std          0.613904
trainer/Policy log std Max         -0.296277
trainer/Policy log std Min         -3.09421
trainer/Alpha                       0.0770667
trainer/Alpha Loss                 -0.150291
exploration/num steps total     74700
exploration/num paths total       747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.31487
exploration/Rewards Std             1.18226
exploration/Rewards Max            -0.0129664
exploration/Rewards Min            -9.74575
exploration/Returns Mean         -131.487
exploration/Returns Std            99.4462
exploration/Returns Max           -29.297
exploration/Returns Min          -310.296
exploration/Actions Mean           -0.012062
exploration/Actions Std             0.230655
exploration/Actions Max             0.997147
exploration/Actions Min            -0.999914
exploration/Num Paths               5
exploration/Average Returns      -131.487
evaluation/num steps total     223500
evaluation/num paths total       2235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.14557
evaluation/Rewards Std              0.904403
evaluation/Rewards Max             -0.0326242
evaluation/Rewards Min             -9.15234
evaluation/Returns Mean          -114.557
evaluation/Returns Std             43.3695
evaluation/Returns Max            -47.359
evaluation/Returns Min           -183.613
evaluation/Actions Mean             0.00701269
evaluation/Actions Std              0.179627
evaluation/Actions Max              0.99884
evaluation/Actions Min             -0.999801
evaluation/Num Paths               15
evaluation/Average Returns       -114.557
time/data storing (s)               0.0028813
time/evaluation sampling (s)        0.333107
time/exploration sampling (s)       0.138721
time/logging (s)                    0.00477479
time/saving (s)                     0.0019292
time/training (s)                   1.95002
time/epoch (s)                      2.43143
time/total (s)                    363.741
Epoch                             148
-----------------------------  ---------------
2019-04-22 23:59:25.500814 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 149 finished
-----------------------------  ---------------
replay_buffer/size              75200
trainer/QF1 Loss                   19.057
trainer/QF2 Loss                   19.3936
trainer/Policy Loss                54.3893
trainer/Q1 Predictions Mean       -53.3169
trainer/Q1 Predictions Std         40.3461
trainer/Q1 Predictions Max        -10.2841
trainer/Q1 Predictions Min       -143.467
trainer/Q2 Predictions Mean       -53.266
trainer/Q2 Predictions Std         40.287
trainer/Q2 Predictions Max        -10.3009
trainer/Q2 Predictions Min       -143.022
trainer/Q Targets Mean            -53.1328
trainer/Q Targets Std              40.7178
trainer/Q Targets Max              -1.64874
trainer/Q Targets Min            -142.747
trainer/Log Pis Mean                1.8265
trainer/Log Pis Std                 1.36975
trainer/Log Pis Max                 4.39664
trainer/Log Pis Min                -5.6252
trainer/Policy mu Mean              0.0970836
trainer/Policy mu Std               0.770204
trainer/Policy mu Max               2.31044
trainer/Policy mu Min              -2.8176
trainer/Policy log std Mean        -1.967
trainer/Policy log std Std          0.559079
trainer/Policy log std Max         -0.463136
trainer/Policy log std Min         -3.09101
trainer/Alpha                       0.0754791
trainer/Alpha Loss                 -0.448338
exploration/num steps total     75200
exploration/num paths total       752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.0423
exploration/Rewards Std             0.939189
exploration/Rewards Max            -0.00905453
exploration/Rewards Min            -9.22447
exploration/Returns Mean         -104.23
exploration/Returns Std            65.0583
exploration/Returns Max           -21.1176
exploration/Returns Min          -171.548
exploration/Actions Mean            0.0150505
exploration/Actions Std             0.218302
exploration/Actions Max             0.999089
exploration/Actions Min            -0.983948
exploration/Num Paths               5
exploration/Average Returns      -104.23
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06068
evaluation/Rewards Std              0.795224
evaluation/Rewards Max             -0.0898549
evaluation/Rewards Min             -7.86317
evaluation/Returns Mean          -106.068
evaluation/Returns Std             58.3358
evaluation/Returns Max            -51.9554
evaluation/Returns Min           -295.346
evaluation/Actions Mean             0.0176611
evaluation/Actions Std              0.166822
evaluation/Actions Max              0.999105
evaluation/Actions Min             -0.995476
evaluation/Num Paths               15
evaluation/Average Returns       -106.068
time/data storing (s)               0.00294227
time/evaluation sampling (s)        0.326039
time/exploration sampling (s)       0.137763
time/logging (s)                    0.00475592
time/saving (s)                     0.00180717
time/training (s)                   1.95147
time/epoch (s)                      2.42478
time/total (s)                    366.17
Epoch                             149
-----------------------------  ---------------
2019-04-22 23:59:27.932012 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 150 finished
-----------------------------  ----------------
replay_buffer/size              75700
trainer/QF1 Loss                  336.381
trainer/QF2 Loss                  335.467
trainer/Policy Loss                61.6734
trainer/Q1 Predictions Mean       -60.2523
trainer/Q1 Predictions Std         38.2048
trainer/Q1 Predictions Max        -10.6346
trainer/Q1 Predictions Min       -148.938
trainer/Q2 Predictions Mean       -60.2833
trainer/Q2 Predictions Std         38.1876
trainer/Q2 Predictions Max        -10.6007
trainer/Q2 Predictions Min       -148.942
trainer/Q Targets Mean            -57.5217
trainer/Q Targets Std              38.7078
trainer/Q Targets Max              -2.54606
trainer/Q Targets Min            -148.963
trainer/Log Pis Mean                1.97067
trainer/Log Pis Std                 1.37515
trainer/Log Pis Max                 5.29978
trainer/Log Pis Min                -3.25039
trainer/Policy mu Mean              0.0407771
trainer/Policy mu Std               0.859293
trainer/Policy mu Max               2.55071
trainer/Policy mu Min              -2.94637
trainer/Policy log std Mean        -1.91671
trainer/Policy log std Std          0.617737
trainer/Policy log std Max         -0.246655
trainer/Policy log std Min         -3.06693
trainer/Alpha                       0.0775426
trainer/Alpha Loss                 -0.0750097
exploration/num steps total     75700
exploration/num paths total       757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19135
exploration/Rewards Std             0.721183
exploration/Rewards Max            -0.00581222
exploration/Rewards Min            -5.72009
exploration/Returns Mean         -119.135
exploration/Returns Std            54.3959
exploration/Returns Max           -18.4016
exploration/Returns Min          -161.923
exploration/Actions Mean           -0.0166884
exploration/Actions Std             0.23659
exploration/Actions Max             0.992723
exploration/Actions Min            -0.998914
exploration/Num Paths               5
exploration/Average Returns      -119.135
evaluation/num steps total     226500
evaluation/num paths total       2265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21473
evaluation/Rewards Std              1.04722
evaluation/Rewards Max             -0.229003
evaluation/Rewards Min            -10.7184
evaluation/Returns Mean          -121.473
evaluation/Returns Std             61.1085
evaluation/Returns Max            -38.6404
evaluation/Returns Min           -279.842
evaluation/Actions Mean            -7.34337e-05
evaluation/Actions Std              0.183054
evaluation/Actions Max              0.997874
evaluation/Actions Min             -0.999389
evaluation/Num Paths               15
evaluation/Average Returns       -121.473
time/data storing (s)               0.00283216
time/evaluation sampling (s)        0.330834
time/exploration sampling (s)       0.139736
time/logging (s)                    0.00479124
time/saving (s)                     0.00197465
time/training (s)                   1.94412
time/epoch (s)                      2.42429
time/total (s)                    368.599
Epoch                             150
-----------------------------  ----------------
2019-04-22 23:59:30.363635 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 151 finished
-----------------------------  ---------------
replay_buffer/size              76200
trainer/QF1 Loss                    1.75313
trainer/QF2 Loss                    1.82268
trainer/Policy Loss                62.1914
trainer/Q1 Predictions Mean       -61.0518
trainer/Q1 Predictions Std         38.638
trainer/Q1 Predictions Max        -10.2461
trainer/Q1 Predictions Min       -146.46
trainer/Q2 Predictions Mean       -61.0202
trainer/Q2 Predictions Std         38.6298
trainer/Q2 Predictions Max        -10.1333
trainer/Q2 Predictions Min       -145.621
trainer/Q Targets Mean            -61.9997
trainer/Q Targets Std              39.194
trainer/Q Targets Max             -10.4311
trainer/Q Targets Min            -146.673
trainer/Log Pis Mean                1.88047
trainer/Log Pis Std                 1.44924
trainer/Log Pis Max                 6.17383
trainer/Log Pis Min                -2.75109
trainer/Policy mu Mean              0.201196
trainer/Policy mu Std               0.84646
trainer/Policy mu Max               2.48162
trainer/Policy mu Min              -3.58229
trainer/Policy log std Mean        -1.81522
trainer/Policy log std Std          0.579891
trainer/Policy log std Max         -0.450258
trainer/Policy log std Min         -3.00482
trainer/Alpha                       0.0758733
trainer/Alpha Loss                 -0.308217
exploration/num steps total     76200
exploration/num paths total       762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.22148
exploration/Rewards Std             1.05634
exploration/Rewards Max            -0.0157189
exploration/Rewards Min            -8.6074
exploration/Returns Mean         -122.148
exploration/Returns Std            80.0505
exploration/Returns Max           -33.4761
exploration/Returns Min          -262.401
exploration/Actions Mean            0.00678697
exploration/Actions Std             0.228363
exploration/Actions Max             0.998417
exploration/Actions Min            -0.997059
exploration/Num Paths               5
exploration/Average Returns      -122.148
evaluation/num steps total     228000
evaluation/num paths total       2280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09629
evaluation/Rewards Std              1.12089
evaluation/Rewards Max             -0.062223
evaluation/Rewards Min             -9.78851
evaluation/Returns Mean          -109.629
evaluation/Returns Std             54.2355
evaluation/Returns Max            -54.7468
evaluation/Returns Min           -272.787
evaluation/Actions Mean             0.016177
evaluation/Actions Std              0.20036
evaluation/Actions Max              0.999141
evaluation/Actions Min             -0.997854
evaluation/Num Paths               15
evaluation/Average Returns       -109.629
time/data storing (s)               0.00317882
time/evaluation sampling (s)        0.32829
time/exploration sampling (s)       0.142249
time/logging (s)                    0.003728
time/saving (s)                     0.00199786
time/training (s)                   1.94424
time/epoch (s)                      2.42369
time/total (s)                    371.026
Epoch                             151
-----------------------------  ---------------
2019-04-22 23:59:32.789154 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 152 finished
-----------------------------  ----------------
replay_buffer/size              76700
trainer/QF1 Loss                    1.65094
trainer/QF2 Loss                    1.78629
trainer/Policy Loss                58.6639
trainer/Q1 Predictions Mean       -57.4982
trainer/Q1 Predictions Std         36.5698
trainer/Q1 Predictions Max        -10.6982
trainer/Q1 Predictions Min       -161.433
trainer/Q2 Predictions Mean       -57.4511
trainer/Q2 Predictions Std         36.5691
trainer/Q2 Predictions Max        -10.6761
trainer/Q2 Predictions Min       -161.731
trainer/Q Targets Mean            -58.4413
trainer/Q Targets Std              37.2284
trainer/Q Targets Max             -10.4889
trainer/Q Targets Min            -165.609
trainer/Log Pis Mean                2.05724
trainer/Log Pis Std                 1.39713
trainer/Log Pis Max                 6.48091
trainer/Log Pis Min                -1.78629
trainer/Policy mu Mean             -0.00138766
trainer/Policy mu Std               0.880341
trainer/Policy mu Max               3.0252
trainer/Policy mu Min              -3.33113
trainer/Policy log std Mean        -1.88027
trainer/Policy log std Std          0.618536
trainer/Policy log std Max         -0.0770489
trainer/Policy log std Min         -2.92355
trainer/Alpha                       0.0755539
trainer/Alpha Loss                  0.147852
exploration/num steps total     76700
exploration/num paths total       767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14948
exploration/Rewards Std             0.983954
exploration/Rewards Max            -0.169292
exploration/Rewards Min            -9.21189
exploration/Returns Mean         -114.948
exploration/Returns Std            43.7693
exploration/Returns Max           -67.2348
exploration/Returns Min          -176.783
exploration/Actions Mean           -0.000863844
exploration/Actions Std             0.259763
exploration/Actions Max             0.990551
exploration/Actions Min            -0.999391
exploration/Num Paths               5
exploration/Average Returns      -114.948
evaluation/num steps total     229500
evaluation/num paths total       2295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00049
evaluation/Rewards Std              1.13625
evaluation/Rewards Max             -0.0536619
evaluation/Rewards Min            -10.0231
evaluation/Returns Mean          -100.049
evaluation/Returns Std             63.386
evaluation/Returns Max            -31.523
evaluation/Returns Min           -275.675
evaluation/Actions Mean            -0.00288059
evaluation/Actions Std              0.191733
evaluation/Actions Max              0.998504
evaluation/Actions Min             -0.999364
evaluation/Num Paths               15
evaluation/Average Returns       -100.049
time/data storing (s)               0.00292464
time/evaluation sampling (s)        0.32992
time/exploration sampling (s)       0.138718
time/logging (s)                    0.0047662
time/saving (s)                     0.00196701
time/training (s)                   1.94267
time/epoch (s)                      2.42096
time/total (s)                    373.451
Epoch                             152
-----------------------------  ----------------
2019-04-22 23:59:35.195997 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 153 finished
-----------------------------  ----------------
replay_buffer/size              77200
trainer/QF1 Loss                    0.389436
trainer/QF2 Loss                    0.435619
trainer/Policy Loss                51.7438
trainer/Q1 Predictions Mean       -50.5011
trainer/Q1 Predictions Std         38.987
trainer/Q1 Predictions Max         -9.9606
trainer/Q1 Predictions Min       -145.002
trainer/Q2 Predictions Mean       -50.5033
trainer/Q2 Predictions Std         38.9413
trainer/Q2 Predictions Max         -9.98078
trainer/Q2 Predictions Min       -144.46
trainer/Q Targets Mean            -50.8855
trainer/Q Targets Std              39.159
trainer/Q Targets Max             -10.3097
trainer/Q Targets Min            -145.179
trainer/Log Pis Mean                1.85171
trainer/Log Pis Std                 1.1782
trainer/Log Pis Max                 4.69424
trainer/Log Pis Min                -0.886067
trainer/Policy mu Mean              0.030159
trainer/Policy mu Std               0.697655
trainer/Policy mu Max               2.18932
trainer/Policy mu Min              -2.49078
trainer/Policy log std Mean        -1.93852
trainer/Policy log std Std          0.550477
trainer/Policy log std Max         -0.376523
trainer/Policy log std Min         -2.74521
trainer/Alpha                       0.0736114
trainer/Alpha Loss                 -0.386871
exploration/num steps total     77200
exploration/num paths total       772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.30429
exploration/Rewards Std             0.701946
exploration/Rewards Max            -0.247629
exploration/Rewards Min            -8.13492
exploration/Returns Mean         -130.429
exploration/Returns Std            31.1806
exploration/Returns Max           -82.1879
exploration/Returns Min          -169.965
exploration/Actions Mean            0.000618656
exploration/Actions Std             0.223811
exploration/Actions Max             0.994589
exploration/Actions Min            -0.994953
exploration/Num Paths               5
exploration/Average Returns      -130.429
evaluation/num steps total     231000
evaluation/num paths total       2310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03712
evaluation/Rewards Std              1.0033
evaluation/Rewards Max             -0.0242738
evaluation/Rewards Min             -9.77325
evaluation/Returns Mean          -103.712
evaluation/Returns Std             65.5653
evaluation/Returns Max            -17.4438
evaluation/Returns Min           -287.159
evaluation/Actions Mean             0.00653109
evaluation/Actions Std              0.178875
evaluation/Actions Max              0.998313
evaluation/Actions Min             -0.997282
evaluation/Num Paths               15
evaluation/Average Returns       -103.712
time/data storing (s)               0.00301197
time/evaluation sampling (s)        0.33208
time/exploration sampling (s)       0.135914
time/logging (s)                    0.0047541
time/saving (s)                     0.00194508
time/training (s)                   1.92221
time/epoch (s)                      2.39991
time/total (s)                    375.855
Epoch                             153
-----------------------------  ----------------
2019-04-22 23:59:37.620349 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 154 finished
-----------------------------  ---------------
replay_buffer/size              77700
trainer/QF1 Loss                    0.554266
trainer/QF2 Loss                    0.491057
trainer/Policy Loss                54.4571
trainer/Q1 Predictions Mean       -53.3675
trainer/Q1 Predictions Std         34.4168
trainer/Q1 Predictions Max        -10.3093
trainer/Q1 Predictions Min       -147.119
trainer/Q2 Predictions Mean       -53.3967
trainer/Q2 Predictions Std         34.4517
trainer/Q2 Predictions Max        -10.4144
trainer/Q2 Predictions Min       -148.521
trainer/Q Targets Mean            -53.5996
trainer/Q Targets Std              34.7795
trainer/Q Targets Max             -10.3185
trainer/Q Targets Min            -149.412
trainer/Log Pis Mean                1.82846
trainer/Log Pis Std                 1.12397
trainer/Log Pis Max                 5.44243
trainer/Log Pis Min                -1.60021
trainer/Policy mu Mean              0.0483387
trainer/Policy mu Std               0.793134
trainer/Policy mu Max               2.9098
trainer/Policy mu Min              -2.81478
trainer/Policy log std Mean        -1.8435
trainer/Policy log std Std          0.535745
trainer/Policy log std Max         -0.413323
trainer/Policy log std Min         -2.64478
trainer/Alpha                       0.0707561
trainer/Alpha Loss                 -0.454311
exploration/num steps total     77700
exploration/num paths total       777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.608765
exploration/Rewards Std             0.876894
exploration/Rewards Max            -0.0127073
exploration/Rewards Min            -9.72384
exploration/Returns Mean          -60.8765
exploration/Returns Std            50.6942
exploration/Returns Max           -20.2898
exploration/Returns Min          -146.237
exploration/Actions Mean           -0.0142375
exploration/Actions Std             0.227472
exploration/Actions Max             0.994574
exploration/Actions Min            -0.999986
exploration/Num Paths               5
exploration/Average Returns       -60.8765
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02145
evaluation/Rewards Std              1.09863
evaluation/Rewards Max             -0.0528647
evaluation/Rewards Min             -9.1827
evaluation/Returns Mean          -102.145
evaluation/Returns Std             66.3939
evaluation/Returns Max             -6.25914
evaluation/Returns Min           -269.635
evaluation/Actions Mean            -0.00589671
evaluation/Actions Std              0.179884
evaluation/Actions Max              0.995065
evaluation/Actions Min             -0.99991
evaluation/Num Paths               15
evaluation/Average Returns       -102.145
time/data storing (s)               0.00297764
time/evaluation sampling (s)        0.332205
time/exploration sampling (s)       0.137757
time/logging (s)                    0.0047655
time/saving (s)                     0.00196445
time/training (s)                   1.93775
time/epoch (s)                      2.41742
time/total (s)                    378.277
Epoch                             154
-----------------------------  ---------------
2019-04-22 23:59:40.066542 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 155 finished
-----------------------------  ----------------
replay_buffer/size              78200
trainer/QF1 Loss                   67.7323
trainer/QF2 Loss                   67.9562
trainer/Policy Loss                55.5858
trainer/Q1 Predictions Mean       -54.6796
trainer/Q1 Predictions Std         36.6054
trainer/Q1 Predictions Max        -10.1339
trainer/Q1 Predictions Min       -144.465
trainer/Q2 Predictions Mean       -54.5587
trainer/Q2 Predictions Std         36.5679
trainer/Q2 Predictions Max        -10.0732
trainer/Q2 Predictions Min       -144.051
trainer/Q Targets Mean            -54.8868
trainer/Q Targets Std              37.7954
trainer/Q Targets Max              -1.61955
trainer/Q Targets Min            -146.584
trainer/Log Pis Mean                1.87662
trainer/Log Pis Std                 1.33224
trainer/Log Pis Max                 5.45232
trainer/Log Pis Min                -2.23578
trainer/Policy mu Mean              0.105306
trainer/Policy mu Std               0.91025
trainer/Policy mu Max               3.20712
trainer/Policy mu Min              -2.65777
trainer/Policy log std Mean        -1.86458
trainer/Policy log std Std          0.63352
trainer/Policy log std Max         -0.261969
trainer/Policy log std Min         -2.89602
trainer/Alpha                       0.0739458
trainer/Alpha Loss                 -0.321316
exploration/num steps total     78200
exploration/num paths total       782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.36019
exploration/Rewards Std             0.969344
exploration/Rewards Max            -0.210338
exploration/Rewards Min            -7.48829
exploration/Returns Mean         -136.019
exploration/Returns Std            78.998
exploration/Returns Max           -70.0798
exploration/Returns Min          -287.542
exploration/Actions Mean           -0.0150661
exploration/Actions Std             0.220295
exploration/Actions Max             0.94459
exploration/Actions Min            -0.999401
exploration/Num Paths               5
exploration/Average Returns      -136.019
evaluation/num steps total     234000
evaluation/num paths total       2340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.11862
evaluation/Rewards Std              0.783334
evaluation/Rewards Max             -0.403798
evaluation/Rewards Min             -9.17126
evaluation/Returns Mean          -111.862
evaluation/Returns Std             51.0921
evaluation/Returns Max            -56.5588
evaluation/Returns Min           -268.494
evaluation/Actions Mean            -0.000806288
evaluation/Actions Std              0.165687
evaluation/Actions Max              0.99502
evaluation/Actions Min             -0.995813
evaluation/Num Paths               15
evaluation/Average Returns       -111.862
time/data storing (s)               0.00288918
time/evaluation sampling (s)        0.332834
time/exploration sampling (s)       0.138975
time/logging (s)                    0.00490903
time/saving (s)                     0.0020329
time/training (s)                   1.95818
time/epoch (s)                      2.43982
time/total (s)                    380.721
Epoch                             155
-----------------------------  ----------------
2019-04-22 23:59:42.511021 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 156 finished
-----------------------------  ---------------
replay_buffer/size              78700
trainer/QF1 Loss                    2.41239
trainer/QF2 Loss                    2.52074
trainer/Policy Loss                51.6716
trainer/Q1 Predictions Mean       -50.0845
trainer/Q1 Predictions Std         34.1401
trainer/Q1 Predictions Max        -10.2354
trainer/Q1 Predictions Min       -148.056
trainer/Q2 Predictions Mean       -50.128
trainer/Q2 Predictions Std         34.1558
trainer/Q2 Predictions Max        -10.2519
trainer/Q2 Predictions Min       -148.102
trainer/Q Targets Mean            -50.479
trainer/Q Targets Std              34.823
trainer/Q Targets Max              -0.263814
trainer/Q Targets Min            -148.593
trainer/Log Pis Mean                2.10673
trainer/Log Pis Std                 1.58738
trainer/Log Pis Max                11.1985
trainer/Log Pis Min                -0.841421
trainer/Policy mu Mean             -0.0642894
trainer/Policy mu Std               0.946528
trainer/Policy mu Max               2.43581
trainer/Policy mu Min              -4.0488
trainer/Policy log std Mean        -1.83833
trainer/Policy log std Std          0.617
trainer/Policy log std Max          0.187746
trainer/Policy log std Min         -2.93192
trainer/Alpha                       0.0749539
trainer/Alpha Loss                  0.276527
exploration/num steps total     78700
exploration/num paths total       787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.549471
exploration/Rewards Std             0.54332
exploration/Rewards Max            -0.0109571
exploration/Rewards Min            -5.96469
exploration/Returns Mean          -54.9471
exploration/Returns Std            24.9994
exploration/Returns Max           -20.2784
exploration/Returns Min           -89.7985
exploration/Actions Mean           -0.00111634
exploration/Actions Std             0.191792
exploration/Actions Max             0.992184
exploration/Actions Min            -0.9965
exploration/Num Paths               5
exploration/Average Returns       -54.9471
evaluation/num steps total     235500
evaluation/num paths total       2355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.05741
evaluation/Rewards Std              1.04179
evaluation/Rewards Max             -0.0800456
evaluation/Rewards Min             -8.706
evaluation/Returns Mean          -105.741
evaluation/Returns Std             86.7777
evaluation/Returns Max            -16.0971
evaluation/Returns Min           -282.787
evaluation/Actions Mean             0.0147878
evaluation/Actions Std              0.157087
evaluation/Actions Max              0.997869
evaluation/Actions Min             -0.997938
evaluation/Num Paths               15
evaluation/Average Returns       -105.741
time/data storing (s)               0.00302101
time/evaluation sampling (s)        0.325848
time/exploration sampling (s)       0.143833
time/logging (s)                    0.00479072
time/saving (s)                     0.00967327
time/training (s)                   1.95015
time/epoch (s)                      2.43732
time/total (s)                    383.163
Epoch                             156
-----------------------------  ---------------
2019-04-22 23:59:44.917601 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 157 finished
-----------------------------  ----------------
replay_buffer/size              79200
trainer/QF1 Loss                    3.25577
trainer/QF2 Loss                    3.47694
trainer/Policy Loss                55.6049
trainer/Q1 Predictions Mean       -54.0386
trainer/Q1 Predictions Std         34.7613
trainer/Q1 Predictions Max        -10.6636
trainer/Q1 Predictions Min       -140.264
trainer/Q2 Predictions Mean       -53.9598
trainer/Q2 Predictions Std         34.7841
trainer/Q2 Predictions Max        -10.5021
trainer/Q2 Predictions Min       -140.802
trainer/Q Targets Mean            -54.8633
trainer/Q Targets Std              35.3153
trainer/Q Targets Max              -0.231987
trainer/Q Targets Min            -142.474
trainer/Log Pis Mean                2.27354
trainer/Log Pis Std                 1.48292
trainer/Log Pis Max                 6.98155
trainer/Log Pis Min                -3.07144
trainer/Policy mu Mean              0.0449266
trainer/Policy mu Std               0.922781
trainer/Policy mu Max               2.89687
trainer/Policy mu Min              -2.79667
trainer/Policy log std Mean        -1.91925
trainer/Policy log std Std          0.643467
trainer/Policy log std Max         -0.540547
trainer/Policy log std Min         -3.03196
trainer/Alpha                       0.0721866
trainer/Alpha Loss                  0.719023
exploration/num steps total     79200
exploration/num paths total       792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.67349
exploration/Rewards Std             1.32415
exploration/Rewards Max            -0.300656
exploration/Rewards Min           -11.2446
exploration/Returns Mean         -167.349
exploration/Returns Std            69.4539
exploration/Returns Max           -87.4665
exploration/Returns Min          -281.809
exploration/Actions Mean            3.18975e-05
exploration/Actions Std             0.239676
exploration/Actions Max             0.999994
exploration/Actions Min            -0.999379
exploration/Num Paths               5
exploration/Average Returns      -167.349
evaluation/num steps total     237000
evaluation/num paths total       2370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.1462
evaluation/Rewards Std              1.30092
evaluation/Rewards Max             -0.0708355
evaluation/Rewards Min            -10.5093
evaluation/Returns Mean          -114.62
evaluation/Returns Std            100.276
evaluation/Returns Max            -18.8286
evaluation/Returns Min           -283.025
evaluation/Actions Mean             0.00333678
evaluation/Actions Std              0.18244
evaluation/Actions Max              0.998615
evaluation/Actions Min             -0.998775
evaluation/Num Paths               15
evaluation/Average Returns       -114.62
time/data storing (s)               0.00295377
time/evaluation sampling (s)        0.332353
time/exploration sampling (s)       0.141295
time/logging (s)                    0.00475841
time/saving (s)                     0.00195894
time/training (s)                   1.91639
time/epoch (s)                      2.39971
time/total (s)                    385.566
Epoch                             157
-----------------------------  ----------------
2019-04-22 23:59:47.346402 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 158 finished
-----------------------------  ----------------
replay_buffer/size              79700
trainer/QF1 Loss                    1.01512
trainer/QF2 Loss                    1.20164
trainer/Policy Loss                55.1843
trainer/Q1 Predictions Mean       -53.6659
trainer/Q1 Predictions Std         39.9558
trainer/Q1 Predictions Max        -10.1296
trainer/Q1 Predictions Min       -161.717
trainer/Q2 Predictions Mean       -53.6422
trainer/Q2 Predictions Std         39.949
trainer/Q2 Predictions Max        -10.1797
trainer/Q2 Predictions Min       -160.302
trainer/Q Targets Mean            -54.3357
trainer/Q Targets Std              40.3946
trainer/Q Targets Max             -10.2645
trainer/Q Targets Min            -164.956
trainer/Log Pis Mean                2.0601
trainer/Log Pis Std                 1.44265
trainer/Log Pis Max                 7.64507
trainer/Log Pis Min                -2.28595
trainer/Policy mu Mean              0.0807406
trainer/Policy mu Std               0.875196
trainer/Policy mu Max               3.09036
trainer/Policy mu Min              -3.42952
trainer/Policy log std Mean        -1.895
trainer/Policy log std Std          0.623574
trainer/Policy log std Max         -0.148318
trainer/Policy log std Min         -2.95437
trainer/Alpha                       0.0726659
trainer/Alpha Loss                  0.157574
exploration/num steps total     79700
exploration/num paths total       797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.7741
exploration/Rewards Std             1.06995
exploration/Rewards Max            -0.0129959
exploration/Rewards Min           -10.0465
exploration/Returns Mean          -77.41
exploration/Returns Std            50.1299
exploration/Returns Max           -20.716
exploration/Returns Min          -166.254
exploration/Actions Mean           -0.000767198
exploration/Actions Std             0.212753
exploration/Actions Max             0.999266
exploration/Actions Min            -0.998027
exploration/Num Paths               5
exploration/Average Returns       -77.41
evaluation/num steps total     238500
evaluation/num paths total       2385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.991945
evaluation/Rewards Std              1.06865
evaluation/Rewards Max             -0.0904565
evaluation/Rewards Min            -10.6431
evaluation/Returns Mean           -99.1945
evaluation/Returns Std             45.1056
evaluation/Returns Max            -20.2831
evaluation/Returns Min           -171.591
evaluation/Actions Mean             0.00550354
evaluation/Actions Std              0.190979
evaluation/Actions Max              0.998841
evaluation/Actions Min             -0.999592
evaluation/Num Paths               15
evaluation/Average Returns        -99.1945
time/data storing (s)               0.00290045
time/evaluation sampling (s)        0.329831
time/exploration sampling (s)       0.139138
time/logging (s)                    0.00376995
time/saving (s)                     0.00195437
time/training (s)                   1.94348
time/epoch (s)                      2.42108
time/total (s)                    387.992
Epoch                             158
-----------------------------  ----------------
2019-04-22 23:59:49.766376 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 159 finished
-----------------------------  ---------------
replay_buffer/size              80200
trainer/QF1 Loss                    1.89864
trainer/QF2 Loss                    1.87086
trainer/Policy Loss                53.8104
trainer/Q1 Predictions Mean       -52.5574
trainer/Q1 Predictions Std         36.9625
trainer/Q1 Predictions Max        -10.2892
trainer/Q1 Predictions Min       -150.065
trainer/Q2 Predictions Mean       -52.4874
trainer/Q2 Predictions Std         36.9306
trainer/Q2 Predictions Max        -10.1866
trainer/Q2 Predictions Min       -149.638
trainer/Q Targets Mean            -52.9776
trainer/Q Targets Std              37.4855
trainer/Q Targets Max              -0.229169
trainer/Q Targets Min            -150.378
trainer/Log Pis Mean                1.93462
trainer/Log Pis Std                 1.36932
trainer/Log Pis Max                 5.58799
trainer/Log Pis Min                -3.48063
trainer/Policy mu Mean             -0.00230981
trainer/Policy mu Std               0.843083
trainer/Policy mu Max               3.11386
trainer/Policy mu Min              -2.99002
trainer/Policy log std Mean        -1.82788
trainer/Policy log std Std          0.564986
trainer/Policy log std Max         -0.175852
trainer/Policy log std Min         -2.83845
trainer/Alpha                       0.0720288
trainer/Alpha Loss                 -0.171976
exploration/num steps total     80200
exploration/num paths total       802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.851617
exploration/Rewards Std             1.0722
exploration/Rewards Max            -0.0224303
exploration/Rewards Min            -9.15403
exploration/Returns Mean          -85.1617
exploration/Returns Std            57.118
exploration/Returns Max           -24.4567
exploration/Returns Min          -187.184
exploration/Actions Mean            0.0241878
exploration/Actions Std             0.248482
exploration/Actions Max             0.999467
exploration/Actions Min            -0.9994
exploration/Num Paths               5
exploration/Average Returns       -85.1617
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.10219
evaluation/Rewards Std              1.16611
evaluation/Rewards Max             -0.0497182
evaluation/Rewards Min             -9.72261
evaluation/Returns Mean          -110.219
evaluation/Returns Std             77.253
evaluation/Returns Max            -10.8967
evaluation/Returns Min           -269.395
evaluation/Actions Mean            -0.00612593
evaluation/Actions Std              0.190679
evaluation/Actions Max              0.999568
evaluation/Actions Min             -0.998058
evaluation/Num Paths               15
evaluation/Average Returns       -110.219
time/data storing (s)               0.00297693
time/evaluation sampling (s)        0.327623
time/exploration sampling (s)       0.13932
time/logging (s)                    0.0047202
time/saving (s)                     0.0020821
time/training (s)                   1.93684
time/epoch (s)                      2.41356
time/total (s)                    390.41
Epoch                             159
-----------------------------  ---------------
2019-04-22 23:59:52.204979 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 160 finished
-----------------------------  ---------------
replay_buffer/size              80700
trainer/QF1 Loss                    3.65947
trainer/QF2 Loss                    3.66538
trainer/Policy Loss                52.0505
trainer/Q1 Predictions Mean       -50.9295
trainer/Q1 Predictions Std         35.0505
trainer/Q1 Predictions Max         -9.9792
trainer/Q1 Predictions Min       -141.479
trainer/Q2 Predictions Mean       -50.94
trainer/Q2 Predictions Std         35.0366
trainer/Q2 Predictions Max         -9.99561
trainer/Q2 Predictions Min       -141.801
trainer/Q Targets Mean            -51.6848
trainer/Q Targets Std              35.8428
trainer/Q Targets Max              -1.93391
trainer/Q Targets Min            -143.881
trainer/Log Pis Mean                1.90554
trainer/Log Pis Std                 1.44552
trainer/Log Pis Max                 6.68755
trainer/Log Pis Min                -2.2604
trainer/Policy mu Mean              0.0783319
trainer/Policy mu Std               0.832828
trainer/Policy mu Max               2.80914
trainer/Policy mu Min              -2.92131
trainer/Policy log std Mean        -1.88826
trainer/Policy log std Std          0.55569
trainer/Policy log std Max         -0.440563
trainer/Policy log std Min         -2.8517
trainer/Alpha                       0.0696868
trainer/Alpha Loss                 -0.251618
exploration/num steps total     80700
exploration/num paths total       807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17678
exploration/Rewards Std             1.33409
exploration/Rewards Max            -0.00926822
exploration/Rewards Min           -10.3841
exploration/Returns Mean         -117.678
exploration/Returns Std            75.6967
exploration/Returns Max           -29.4631
exploration/Returns Min          -198.754
exploration/Actions Mean            0.00170383
exploration/Actions Std             0.241536
exploration/Actions Max             0.995673
exploration/Actions Min            -0.999891
exploration/Num Paths               5
exploration/Average Returns      -117.678
evaluation/num steps total     241500
evaluation/num paths total       2415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21254
evaluation/Rewards Std              1.16643
evaluation/Rewards Max             -0.104049
evaluation/Rewards Min             -9.8334
evaluation/Returns Mean          -121.254
evaluation/Returns Std             85.0209
evaluation/Returns Max            -26.597
evaluation/Returns Min           -290.747
evaluation/Actions Mean            -0.0110218
evaluation/Actions Std              0.178174
evaluation/Actions Max              0.996986
evaluation/Actions Min             -0.999688
evaluation/Num Paths               15
evaluation/Average Returns       -121.254
time/data storing (s)               0.00281542
time/evaluation sampling (s)        0.32514
time/exploration sampling (s)       0.136362
time/logging (s)                    0.00478027
time/saving (s)                     0.00196009
time/training (s)                   1.9603
time/epoch (s)                      2.43136
time/total (s)                    392.846
Epoch                             160
-----------------------------  ---------------
2019-04-22 23:59:54.615616 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 161 finished
-----------------------------  ---------------
replay_buffer/size              81200
trainer/QF1 Loss                  186.698
trainer/QF2 Loss                  188.808
trainer/Policy Loss                61.6179
trainer/Q1 Predictions Mean       -60.461
trainer/Q1 Predictions Std         42.2486
trainer/Q1 Predictions Max         -9.81237
trainer/Q1 Predictions Min       -169.556
trainer/Q2 Predictions Mean       -60.4684
trainer/Q2 Predictions Std         42.3481
trainer/Q2 Predictions Max         -9.82182
trainer/Q2 Predictions Min       -169.992
trainer/Q Targets Mean            -59.648
trainer/Q Targets Std              43.0331
trainer/Q Targets Max              -1.80928
trainer/Q Targets Min            -169.764
trainer/Log Pis Mean                1.95595
trainer/Log Pis Std                 1.46138
trainer/Log Pis Max                 6.67627
trainer/Log Pis Min                -3.25913
trainer/Policy mu Mean              0.0676896
trainer/Policy mu Std               0.971237
trainer/Policy mu Max               3.43446
trainer/Policy mu Min              -3.51707
trainer/Policy log std Mean        -1.76148
trainer/Policy log std Std          0.612188
trainer/Policy log std Max         -0.0309943
trainer/Policy log std Min         -2.82537
trainer/Alpha                       0.072031
trainer/Alpha Loss                 -0.115879
exploration/num steps total     81200
exploration/num paths total       812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.7411
exploration/Rewards Std             1.31669
exploration/Rewards Max            -0.0304119
exploration/Rewards Min           -11.5732
exploration/Returns Mean         -174.11
exploration/Returns Std            70.0604
exploration/Returns Max           -81.8039
exploration/Returns Min          -290.462
exploration/Actions Mean           -0.00617267
exploration/Actions Std             0.265047
exploration/Actions Max             0.9985
exploration/Actions Min            -0.995899
exploration/Num Paths               5
exploration/Average Returns      -174.11
evaluation/num steps total     243000
evaluation/num paths total       2430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.1217
evaluation/Rewards Std              0.841483
evaluation/Rewards Max             -0.125759
evaluation/Rewards Min            -10.2815
evaluation/Returns Mean          -112.17
evaluation/Returns Std             48.5907
evaluation/Returns Max            -17.431
evaluation/Returns Min           -171.118
evaluation/Actions Mean            -0.00250879
evaluation/Actions Std              0.173311
evaluation/Actions Max              0.999198
evaluation/Actions Min             -0.99929
evaluation/Num Paths               15
evaluation/Average Returns       -112.17
time/data storing (s)               0.00297902
time/evaluation sampling (s)        0.332704
time/exploration sampling (s)       0.13873
time/logging (s)                    0.00482079
time/saving (s)                     0.00197146
time/training (s)                   1.9222
time/epoch (s)                      2.4034
time/total (s)                    395.254
Epoch                             161
-----------------------------  ---------------
2019-04-22 23:59:57.039011 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 162 finished
-----------------------------  ---------------
replay_buffer/size              81700
trainer/QF1 Loss                   24.4442
trainer/QF2 Loss                   24.477
trainer/Policy Loss                52.3451
trainer/Q1 Predictions Mean       -51.0391
trainer/Q1 Predictions Std         34.9676
trainer/Q1 Predictions Max        -10.2057
trainer/Q1 Predictions Min       -138.199
trainer/Q2 Predictions Mean       -51.0771
trainer/Q2 Predictions Std         34.9933
trainer/Q2 Predictions Max        -10.1407
trainer/Q2 Predictions Min       -138.118
trainer/Q Targets Mean            -50.8557
trainer/Q Targets Std              35.5541
trainer/Q Targets Max              -1.22975
trainer/Q Targets Min            -139.87
trainer/Log Pis Mean                2.07011
trainer/Log Pis Std                 1.42825
trainer/Log Pis Max                 7.14187
trainer/Log Pis Min                -2.79637
trainer/Policy mu Mean             -0.00502863
trainer/Policy mu Std               0.965898
trainer/Policy mu Max               2.7331
trainer/Policy mu Min              -3.59367
trainer/Policy log std Mean        -1.80742
trainer/Policy log std Std          0.616287
trainer/Policy log std Max         -0.299948
trainer/Policy log std Min         -2.84969
trainer/Alpha                       0.0698722
trainer/Alpha Loss                  0.186562
exploration/num steps total     81700
exploration/num paths total       817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.990884
exploration/Rewards Std             0.98396
exploration/Rewards Max            -0.257647
exploration/Rewards Min           -10.0816
exploration/Returns Mean          -99.0884
exploration/Returns Std            17.1413
exploration/Returns Max           -80.057
exploration/Returns Min          -130.454
exploration/Actions Mean            0.00111379
exploration/Actions Std             0.229095
exploration/Actions Max             0.999897
exploration/Actions Min            -0.99996
exploration/Num Paths               5
exploration/Average Returns       -99.0884
evaluation/num steps total     244500
evaluation/num paths total       2445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08147
evaluation/Rewards Std              0.888486
evaluation/Rewards Max             -0.119429
evaluation/Rewards Min             -9.63364
evaluation/Returns Mean          -108.147
evaluation/Returns Std             47.6178
evaluation/Returns Max            -25.9968
evaluation/Returns Min           -182.793
evaluation/Actions Mean             0.0116529
evaluation/Actions Std              0.177194
evaluation/Actions Max              0.99732
evaluation/Actions Min             -0.997813
evaluation/Num Paths               15
evaluation/Average Returns       -108.147
time/data storing (s)               0.00278715
time/evaluation sampling (s)        0.329206
time/exploration sampling (s)       0.139614
time/logging (s)                    0.00479212
time/saving (s)                     0.00204073
time/training (s)                   1.93743
time/epoch (s)                      2.41587
time/total (s)                    397.674
Epoch                             162
-----------------------------  ---------------
2019-04-22 23:59:59.458376 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 163 finished
-----------------------------  ---------------
replay_buffer/size              82200
trainer/QF1 Loss                    0.786067
trainer/QF2 Loss                    0.702564
trainer/Policy Loss                53.7649
trainer/Q1 Predictions Mean       -52.6259
trainer/Q1 Predictions Std         40.4226
trainer/Q1 Predictions Max        -10.338
trainer/Q1 Predictions Min       -140.498
trainer/Q2 Predictions Mean       -52.6734
trainer/Q2 Predictions Std         40.4587
trainer/Q2 Predictions Max        -10.2797
trainer/Q2 Predictions Min       -141.212
trainer/Q Targets Mean            -53.2928
trainer/Q Targets Std              40.8434
trainer/Q Targets Max             -10.2336
trainer/Q Targets Min            -142.277
trainer/Log Pis Mean                1.6892
trainer/Log Pis Std                 1.31694
trainer/Log Pis Max                 4.455
trainer/Log Pis Min                -1.74355
trainer/Policy mu Mean              0.00103056
trainer/Policy mu Std               0.74249
trainer/Policy mu Max               2.16508
trainer/Policy mu Min              -2.77623
trainer/Policy log std Mean        -1.91747
trainer/Policy log std Std          0.525621
trainer/Policy log std Max         -0.549454
trainer/Policy log std Min         -2.99374
trainer/Alpha                       0.0698548
trainer/Alpha Loss                 -0.82714
exploration/num steps total     82200
exploration/num paths total       822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1951
exploration/Rewards Std             1.10066
exploration/Rewards Max            -0.00772324
exploration/Rewards Min            -8.59231
exploration/Returns Mean         -119.51
exploration/Returns Std            89.5181
exploration/Returns Max           -15.4955
exploration/Returns Min          -254.056
exploration/Actions Mean            0.00119338
exploration/Actions Std             0.240747
exploration/Actions Max             0.99826
exploration/Actions Min            -0.989293
exploration/Num Paths               5
exploration/Average Returns      -119.51
evaluation/num steps total     246000
evaluation/num paths total       2460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.24354
evaluation/Rewards Std              0.851656
evaluation/Rewards Max             -0.0575244
evaluation/Rewards Min             -9.1043
evaluation/Returns Mean          -124.354
evaluation/Returns Std             59.1526
evaluation/Returns Max             -6.96064
evaluation/Returns Min           -247.539
evaluation/Actions Mean            -0.00101248
evaluation/Actions Std              0.150048
evaluation/Actions Max              0.999217
evaluation/Actions Min             -0.998541
evaluation/Num Paths               15
evaluation/Average Returns       -124.354
time/data storing (s)               0.00302885
time/evaluation sampling (s)        0.32974
time/exploration sampling (s)       0.140688
time/logging (s)                    0.00452945
time/saving (s)                     0.00194359
time/training (s)                   1.93287
time/epoch (s)                      2.4128
time/total (s)                    400.091
Epoch                             163
-----------------------------  ---------------
2019-04-23 00:00:01.916797 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 164 finished
-----------------------------  ---------------
replay_buffer/size              82700
trainer/QF1 Loss                  111.378
trainer/QF2 Loss                  111.552
trainer/Policy Loss                54.3963
trainer/Q1 Predictions Mean       -53.0675
trainer/Q1 Predictions Std         38.1177
trainer/Q1 Predictions Max        -10.5114
trainer/Q1 Predictions Min       -145.845
trainer/Q2 Predictions Mean       -53.0007
trainer/Q2 Predictions Std         38.1305
trainer/Q2 Predictions Max        -10.4471
trainer/Q2 Predictions Min       -145.739
trainer/Q Targets Mean            -51.7104
trainer/Q Targets Std              38.6196
trainer/Q Targets Max              -1.07806
trainer/Q Targets Min            -144.422
trainer/Log Pis Mean                2.17435
trainer/Log Pis Std                 1.49984
trainer/Log Pis Max                 7.84003
trainer/Log Pis Min                -2.50483
trainer/Policy mu Mean              0.0522603
trainer/Policy mu Std               0.958067
trainer/Policy mu Max               2.94811
trainer/Policy mu Min              -2.97034
trainer/Policy log std Mean        -1.84582
trainer/Policy log std Std          0.585751
trainer/Policy log std Max         -0.51685
trainer/Policy log std Min         -2.82798
trainer/Alpha                       0.0680094
trainer/Alpha Loss                  0.46866
exploration/num steps total     82700
exploration/num paths total       827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.975778
exploration/Rewards Std             1.1226
exploration/Rewards Max            -0.0326621
exploration/Rewards Min            -9.60224
exploration/Returns Mean          -97.5778
exploration/Returns Std            38.5197
exploration/Returns Max           -55.1489
exploration/Returns Min          -158.435
exploration/Actions Mean            0.0077173
exploration/Actions Std             0.235985
exploration/Actions Max             0.999856
exploration/Actions Min            -0.999715
exploration/Num Paths               5
exploration/Average Returns       -97.5778
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.38257
evaluation/Rewards Std              1.20017
evaluation/Rewards Max             -0.0594293
evaluation/Rewards Min            -10.2857
evaluation/Returns Mean          -138.257
evaluation/Returns Std             85.7114
evaluation/Returns Max            -17.5816
evaluation/Returns Min           -274.814
evaluation/Actions Mean            -0.00565901
evaluation/Actions Std              0.186264
evaluation/Actions Max              0.998459
evaluation/Actions Min             -0.999528
evaluation/Num Paths               15
evaluation/Average Returns       -138.257
time/data storing (s)               0.00294198
time/evaluation sampling (s)        0.329443
time/exploration sampling (s)       0.140584
time/logging (s)                    0.00477615
time/saving (s)                     0.00197545
time/training (s)                   1.97176
time/epoch (s)                      2.45148
time/total (s)                    402.547
Epoch                             164
-----------------------------  ---------------
2019-04-23 00:00:04.350965 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 165 finished
-----------------------------  ---------------
replay_buffer/size              83200
trainer/QF1 Loss                   24.9805
trainer/QF2 Loss                   24.6109
trainer/Policy Loss                55.6275
trainer/Q1 Predictions Mean       -54.218
trainer/Q1 Predictions Std         37.0376
trainer/Q1 Predictions Max        -10.5207
trainer/Q1 Predictions Min       -136.995
trainer/Q2 Predictions Mean       -54.2648
trainer/Q2 Predictions Std         37.0317
trainer/Q2 Predictions Max        -10.6575
trainer/Q2 Predictions Min       -136.816
trainer/Q Targets Mean            -54.0131
trainer/Q Targets Std              37.7848
trainer/Q Targets Max              -2.76212
trainer/Q Targets Min            -137.165
trainer/Log Pis Mean                2.01936
trainer/Log Pis Std                 1.05009
trainer/Log Pis Max                 4.80966
trainer/Log Pis Min                -2.3177
trainer/Policy mu Mean              0.022193
trainer/Policy mu Std               0.76883
trainer/Policy mu Max               2.59491
trainer/Policy mu Min              -2.84331
trainer/Policy log std Mean        -1.91296
trainer/Policy log std Std          0.542239
trainer/Policy log std Max         -0.287752
trainer/Policy log std Min         -2.80342
trainer/Alpha                       0.0690222
trainer/Alpha Loss                  0.0517586
exploration/num steps total     83200
exploration/num paths total       832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.877044
exploration/Rewards Std             0.847155
exploration/Rewards Max            -0.0128135
exploration/Rewards Min            -7.2698
exploration/Returns Mean          -87.7044
exploration/Returns Std            53.6092
exploration/Returns Max           -25.2508
exploration/Returns Min          -182.476
exploration/Actions Mean            0.00152213
exploration/Actions Std             0.218274
exploration/Actions Max             0.999803
exploration/Actions Min            -0.998103
exploration/Num Paths               5
exploration/Average Returns       -87.7044
evaluation/num steps total     249000
evaluation/num paths total       2490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.12119
evaluation/Rewards Std              0.996881
evaluation/Rewards Max             -0.0901555
evaluation/Rewards Min             -9.75307
evaluation/Returns Mean          -112.119
evaluation/Returns Std             56.9504
evaluation/Returns Max            -28.0335
evaluation/Returns Min           -275.055
evaluation/Actions Mean            -0.0047076
evaluation/Actions Std              0.183304
evaluation/Actions Max              0.998453
evaluation/Actions Min             -0.999655
evaluation/Num Paths               15
evaluation/Average Returns       -112.119
time/data storing (s)               0.0028087
time/evaluation sampling (s)        0.33597
time/exploration sampling (s)       0.135145
time/logging (s)                    0.0047606
time/saving (s)                     0.00171021
time/training (s)                   1.94642
time/epoch (s)                      2.42681
time/total (s)                    404.979
Epoch                             165
-----------------------------  ---------------
2019-04-23 00:00:06.789953 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 166 finished
-----------------------------  ---------------
replay_buffer/size              83700
trainer/QF1 Loss                    7.36328
trainer/QF2 Loss                    7.30002
trainer/Policy Loss                54.2457
trainer/Q1 Predictions Mean       -52.8652
trainer/Q1 Predictions Std         41.3319
trainer/Q1 Predictions Max        -10.3949
trainer/Q1 Predictions Min       -163.862
trainer/Q2 Predictions Mean       -52.8974
trainer/Q2 Predictions Std         41.3615
trainer/Q2 Predictions Max        -10.3372
trainer/Q2 Predictions Min       -163.506
trainer/Q Targets Mean            -52.6651
trainer/Q Targets Std              41.9511
trainer/Q Targets Max              -1.05619
trainer/Q Targets Min            -167.154
trainer/Log Pis Mean                1.86923
trainer/Log Pis Std                 1.62711
trainer/Log Pis Max                 5.34982
trainer/Log Pis Min                -7.55361
trainer/Policy mu Mean              0.0636923
trainer/Policy mu Std               0.880197
trainer/Policy mu Max               3.15134
trainer/Policy mu Min              -3.79863
trainer/Policy log std Mean        -1.88086
trainer/Policy log std Std          0.555243
trainer/Policy log std Max         -0.24302
trainer/Policy log std Min         -2.83797
trainer/Alpha                       0.0699114
trainer/Alpha Loss                 -0.347907
exploration/num steps total     83700
exploration/num paths total       837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.18214
exploration/Rewards Std             0.843332
exploration/Rewards Max            -0.267696
exploration/Rewards Min            -8.76699
exploration/Returns Mean         -118.214
exploration/Returns Std            33.314
exploration/Returns Max           -65.9356
exploration/Returns Min          -153.377
exploration/Actions Mean           -0.00360358
exploration/Actions Std             0.222966
exploration/Actions Max             0.995895
exploration/Actions Min            -0.999401
exploration/Num Paths               5
exploration/Average Returns      -118.214
evaluation/num steps total     250500
evaluation/num paths total       2505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0106
evaluation/Rewards Std              1.17806
evaluation/Rewards Max             -0.00730637
evaluation/Rewards Min            -10.1721
evaluation/Returns Mean          -101.06
evaluation/Returns Std             68.8719
evaluation/Returns Max            -23.8051
evaluation/Returns Min           -251.781
evaluation/Actions Mean             0.00862215
evaluation/Actions Std              0.194006
evaluation/Actions Max              0.998691
evaluation/Actions Min             -0.999514
evaluation/Num Paths               15
evaluation/Average Returns       -101.06
time/data storing (s)               0.00286086
time/evaluation sampling (s)        0.331338
time/exploration sampling (s)       0.13584
time/logging (s)                    0.00480529
time/saving (s)                     0.0019817
time/training (s)                   1.95483
time/epoch (s)                      2.43166
time/total (s)                    407.415
Epoch                             166
-----------------------------  ---------------
2019-04-23 00:00:09.231483 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 167 finished
-----------------------------  ---------------
replay_buffer/size              84200
trainer/QF1 Loss                    0.599366
trainer/QF2 Loss                    0.867931
trainer/Policy Loss                51.7011
trainer/Q1 Predictions Mean       -50.4235
trainer/Q1 Predictions Std         37.5888
trainer/Q1 Predictions Max        -10.4195
trainer/Q1 Predictions Min       -160.477
trainer/Q2 Predictions Mean       -50.3986
trainer/Q2 Predictions Std         37.5271
trainer/Q2 Predictions Max        -10.3569
trainer/Q2 Predictions Min       -158.468
trainer/Q Targets Mean            -50.8179
trainer/Q Targets Std              37.9859
trainer/Q Targets Max             -10.2634
trainer/Q Targets Min            -165.165
trainer/Log Pis Mean                2.02059
trainer/Log Pis Std                 1.49546
trainer/Log Pis Max                 6.5076
trainer/Log Pis Min                -2.24085
trainer/Policy mu Mean              0.114776
trainer/Policy mu Std               0.929577
trainer/Policy mu Max               2.92061
trainer/Policy mu Min              -3.71825
trainer/Policy log std Mean        -1.78197
trainer/Policy log std Std          0.616839
trainer/Policy log std Max          0.0893654
trainer/Policy log std Min         -2.79401
trainer/Alpha                       0.0694591
trainer/Alpha Loss                  0.054903
exploration/num steps total     84200
exploration/num paths total       842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.32394
exploration/Rewards Std             1.19624
exploration/Rewards Max            -0.103958
exploration/Rewards Min            -9.46889
exploration/Returns Mean         -132.394
exploration/Returns Std            78.9037
exploration/Returns Max           -42.1267
exploration/Returns Min          -278.551
exploration/Actions Mean           -0.0102194
exploration/Actions Std             0.261713
exploration/Actions Max             0.995482
exploration/Actions Min            -0.999847
exploration/Num Paths               5
exploration/Average Returns      -132.394
evaluation/num steps total     252000
evaluation/num paths total       2520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.3701
evaluation/Rewards Std              1.07307
evaluation/Rewards Max             -0.058574
evaluation/Rewards Min             -8.59173
evaluation/Returns Mean          -137.01
evaluation/Returns Std             78.0079
evaluation/Returns Max             -7.08076
evaluation/Returns Min           -276.823
evaluation/Actions Mean             0.00264201
evaluation/Actions Std              0.176523
evaluation/Actions Max              0.997339
evaluation/Actions Min             -0.999416
evaluation/Num Paths               15
evaluation/Average Returns       -137.01
time/data storing (s)               0.00320982
time/evaluation sampling (s)        0.331663
time/exploration sampling (s)       0.14515
time/logging (s)                    0.00479317
time/saving (s)                     0.00196448
time/training (s)                   1.94738
time/epoch (s)                      2.43416
time/total (s)                    409.853
Epoch                             167
-----------------------------  ---------------
2019-04-23 00:00:11.641180 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 168 finished
-----------------------------  ---------------
replay_buffer/size              84700
trainer/QF1 Loss                    1.48227
trainer/QF2 Loss                    1.27062
trainer/Policy Loss                53.9685
trainer/Q1 Predictions Mean       -52.6291
trainer/Q1 Predictions Std         37.708
trainer/Q1 Predictions Max        -10.175
trainer/Q1 Predictions Min       -141.843
trainer/Q2 Predictions Mean       -52.661
trainer/Q2 Predictions Std         37.7605
trainer/Q2 Predictions Max        -10.2218
trainer/Q2 Predictions Min       -142.062
trainer/Q Targets Mean            -53.4612
trainer/Q Targets Std              38.362
trainer/Q Targets Max             -10.2283
trainer/Q Targets Min            -143.109
trainer/Log Pis Mean                1.92397
trainer/Log Pis Std                 1.70877
trainer/Log Pis Max                 9.00711
trainer/Log Pis Min                -2.74017
trainer/Policy mu Mean              0.0697767
trainer/Policy mu Std               0.978348
trainer/Policy mu Max               2.89087
trainer/Policy mu Min              -3.92962
trainer/Policy log std Mean        -1.75328
trainer/Policy log std Std          0.593136
trainer/Policy log std Max         -0.155059
trainer/Policy log std Min         -2.72194
trainer/Alpha                       0.0685868
trainer/Alpha Loss                 -0.203727
exploration/num steps total     84700
exploration/num paths total       847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.900209
exploration/Rewards Std             1.06671
exploration/Rewards Max            -0.0228319
exploration/Rewards Min            -9.19927
exploration/Returns Mean          -90.0209
exploration/Returns Std            47.9339
exploration/Returns Max           -29.6495
exploration/Returns Min          -157.212
exploration/Actions Mean            0.0020898
exploration/Actions Std             0.249298
exploration/Actions Max             0.998675
exploration/Actions Min            -0.99787
exploration/Num Paths               5
exploration/Average Returns       -90.0209
evaluation/num steps total     253500
evaluation/num paths total       2535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.32422
evaluation/Rewards Std              1.10446
evaluation/Rewards Max             -0.0252643
evaluation/Rewards Min             -9.33282
evaluation/Returns Mean          -132.422
evaluation/Returns Std             71.7187
evaluation/Returns Max            -29.9032
evaluation/Returns Min           -268.611
evaluation/Actions Mean             0.0105495
evaluation/Actions Std              0.195757
evaluation/Actions Max              0.997926
evaluation/Actions Min             -0.999898
evaluation/Num Paths               15
evaluation/Average Returns       -132.422
time/data storing (s)               0.00295191
time/evaluation sampling (s)        0.328549
time/exploration sampling (s)       0.137572
time/logging (s)                    0.00480862
time/saving (s)                     0.00160362
time/training (s)                   1.9276
time/epoch (s)                      2.40309
time/total (s)                    412.26
Epoch                             168
-----------------------------  ---------------
2019-04-23 00:00:14.082861 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 169 finished
-----------------------------  ---------------
replay_buffer/size              85200
trainer/QF1 Loss                    1.96817
trainer/QF2 Loss                    1.72849
trainer/Policy Loss                55.843
trainer/Q1 Predictions Mean       -54.4628
trainer/Q1 Predictions Std         37.7218
trainer/Q1 Predictions Max         -9.96357
trainer/Q1 Predictions Min       -139.141
trainer/Q2 Predictions Mean       -54.5449
trainer/Q2 Predictions Std         37.809
trainer/Q2 Predictions Max         -9.9256
trainer/Q2 Predictions Min       -138.911
trainer/Q Targets Mean            -55.4186
trainer/Q Targets Std              38.4431
trainer/Q Targets Max             -10.1372
trainer/Q Targets Min            -141.153
trainer/Log Pis Mean                2.21598
trainer/Log Pis Std                 1.3801
trainer/Log Pis Max                 6.88891
trainer/Log Pis Min                -2.59413
trainer/Policy mu Mean              0.101112
trainer/Policy mu Std               0.937576
trainer/Policy mu Max               3.08799
trainer/Policy mu Min              -2.58922
trainer/Policy log std Mean        -1.81737
trainer/Policy log std Std          0.638982
trainer/Policy log std Max         -0.269752
trainer/Policy log std Min         -2.90428
trainer/Alpha                       0.0684534
trainer/Alpha Loss                  0.579184
exploration/num steps total     85200
exploration/num paths total       852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00603
exploration/Rewards Std             0.738023
exploration/Rewards Max            -0.277945
exploration/Rewards Min            -6.4321
exploration/Returns Mean         -100.603
exploration/Returns Std            45.126
exploration/Returns Max           -53.079
exploration/Returns Min          -170.956
exploration/Actions Mean            0.0107396
exploration/Actions Std             0.222816
exploration/Actions Max             0.999746
exploration/Actions Min            -0.984595
exploration/Num Paths               5
exploration/Average Returns      -100.603
evaluation/num steps total     255000
evaluation/num paths total       2550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.99848
evaluation/Rewards Std              0.932687
evaluation/Rewards Max             -0.0980932
evaluation/Rewards Min            -10.1273
evaluation/Returns Mean           -99.848
evaluation/Returns Std             54.9887
evaluation/Returns Max            -16.5984
evaluation/Returns Min           -189.659
evaluation/Actions Mean             0.00274572
evaluation/Actions Std              0.179047
evaluation/Actions Max              0.998927
evaluation/Actions Min             -0.999236
evaluation/Num Paths               15
evaluation/Average Returns        -99.848
time/data storing (s)               0.00290664
time/evaluation sampling (s)        0.35212
time/exploration sampling (s)       0.141745
time/logging (s)                    0.0035876
time/saving (s)                     0.0104504
time/training (s)                   1.92259
time/epoch (s)                      2.4334
time/total (s)                    414.698
Epoch                             169
-----------------------------  ---------------
2019-04-23 00:00:16.498129 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 170 finished
-----------------------------  ---------------
replay_buffer/size              85700
trainer/QF1 Loss                    1.6538
trainer/QF2 Loss                    1.79384
trainer/Policy Loss                56.9598
trainer/Q1 Predictions Mean       -55.8631
trainer/Q1 Predictions Std         40.1942
trainer/Q1 Predictions Max        -10.1761
trainer/Q1 Predictions Min       -180.379
trainer/Q2 Predictions Mean       -55.8157
trainer/Q2 Predictions Std         40.1756
trainer/Q2 Predictions Max        -10.1356
trainer/Q2 Predictions Min       -180.056
trainer/Q Targets Mean            -55.9795
trainer/Q Targets Std              40.4333
trainer/Q Targets Max              -0.117739
trainer/Q Targets Min            -178.509
trainer/Log Pis Mean                2.17309
trainer/Log Pis Std                 1.61053
trainer/Log Pis Max                10.3589
trainer/Log Pis Min                -2.59163
trainer/Policy mu Mean             -0.00268659
trainer/Policy mu Std               1.06332
trainer/Policy mu Max               2.66837
trainer/Policy mu Min              -3.67075
trainer/Policy log std Mean        -1.75337
trainer/Policy log std Std          0.646471
trainer/Policy log std Max         -0.194879
trainer/Policy log std Min         -2.71414
trainer/Alpha                       0.0700736
trainer/Alpha Loss                  0.460082
exploration/num steps total     85700
exploration/num paths total       857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.62082
exploration/Rewards Std             1.08094
exploration/Rewards Max            -0.0119662
exploration/Rewards Min            -8.34372
exploration/Returns Mean         -162.082
exploration/Returns Std            92.6364
exploration/Returns Max           -16.2699
exploration/Returns Min          -263.97
exploration/Actions Mean           -0.0182058
exploration/Actions Std             0.22372
exploration/Actions Max             0.91814
exploration/Actions Min            -0.999531
exploration/Num Paths               5
exploration/Average Returns      -162.082
evaluation/num steps total     256500
evaluation/num paths total       2565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.37489
evaluation/Rewards Std              1.07759
evaluation/Rewards Max             -0.0686237
evaluation/Rewards Min             -8.94987
evaluation/Returns Mean          -137.489
evaluation/Returns Std             54.4211
evaluation/Returns Max            -34.261
evaluation/Returns Min           -243.451
evaluation/Actions Mean             0.0087342
evaluation/Actions Std              0.19759
evaluation/Actions Max              0.999011
evaluation/Actions Min             -0.997796
evaluation/Num Paths               15
evaluation/Average Returns       -137.489
time/data storing (s)               0.00311888
time/evaluation sampling (s)        0.317909
time/exploration sampling (s)       0.140158
time/logging (s)                    0.0048091
time/saving (s)                     0.0019407
time/training (s)                   1.94158
time/epoch (s)                      2.40951
time/total (s)                    417.112
Epoch                             170
-----------------------------  ---------------
2019-04-23 00:00:18.931188 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 171 finished
-----------------------------  ----------------
replay_buffer/size              86200
trainer/QF1 Loss                    0.288624
trainer/QF2 Loss                    0.283757
trainer/Policy Loss                51.5792
trainer/Q1 Predictions Mean       -50.6043
trainer/Q1 Predictions Std         33.5006
trainer/Q1 Predictions Max        -10.19
trainer/Q1 Predictions Min       -135.327
trainer/Q2 Predictions Mean       -50.6059
trainer/Q2 Predictions Std         33.4753
trainer/Q2 Predictions Max        -10.3178
trainer/Q2 Predictions Min       -135.318
trainer/Q Targets Mean            -50.5593
trainer/Q Targets Std              33.7781
trainer/Q Targets Max              -9.99041
trainer/Q Targets Min            -137.049
trainer/Log Pis Mean                1.70583
trainer/Log Pis Std                 1.39078
trainer/Log Pis Max                 7.13992
trainer/Log Pis Min                -1.1578
trainer/Policy mu Mean             -0.0138069
trainer/Policy mu Std               0.886178
trainer/Policy mu Max               2.43577
trainer/Policy mu Min              -3.42722
trainer/Policy log std Mean        -1.7444
trainer/Policy log std Std          0.577764
trainer/Policy log std Max         -0.410447
trainer/Policy log std Min         -2.63317
trainer/Alpha                       0.067915
trainer/Alpha Loss                 -0.791142
exploration/num steps total     86200
exploration/num paths total       862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.40534
exploration/Rewards Std             0.996452
exploration/Rewards Max            -0.0338005
exploration/Rewards Min            -8.08699
exploration/Returns Mean         -140.534
exploration/Returns Std            57.1106
exploration/Returns Max           -31.1586
exploration/Returns Min          -185.675
exploration/Actions Mean            0.000947394
exploration/Actions Std             0.244416
exploration/Actions Max             0.997866
exploration/Actions Min            -0.999989
exploration/Num Paths               5
exploration/Average Returns      -140.534
evaluation/num steps total     258000
evaluation/num paths total       2580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.950232
evaluation/Rewards Std              0.869355
evaluation/Rewards Max             -0.105265
evaluation/Rewards Min             -8.94174
evaluation/Returns Mean           -95.0232
evaluation/Returns Std             54.1998
evaluation/Returns Max            -16.5476
evaluation/Returns Min           -193.424
evaluation/Actions Mean            -0.00420686
evaluation/Actions Std              0.165546
evaluation/Actions Max              0.998741
evaluation/Actions Min             -0.999766
evaluation/Num Paths               15
evaluation/Average Returns        -95.0232
time/data storing (s)               0.00283743
time/evaluation sampling (s)        0.331917
time/exploration sampling (s)       0.137791
time/logging (s)                    0.00478578
time/saving (s)                     0.00160268
time/training (s)                   1.94661
time/epoch (s)                      2.42555
time/total (s)                    419.542
Epoch                             171
-----------------------------  ----------------
2019-04-23 00:00:21.368993 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 172 finished
-----------------------------  ---------------
replay_buffer/size              86700
trainer/QF1 Loss                   52.5195
trainer/QF2 Loss                   52.1236
trainer/Policy Loss                50.4316
trainer/Q1 Predictions Mean       -49.053
trainer/Q1 Predictions Std         29.6827
trainer/Q1 Predictions Max         -9.85764
trainer/Q1 Predictions Min       -130.736
trainer/Q2 Predictions Mean       -49.0554
trainer/Q2 Predictions Std         29.7228
trainer/Q2 Predictions Max         -9.94423
trainer/Q2 Predictions Min       -130.752
trainer/Q Targets Mean            -48.8067
trainer/Q Targets Std              30.3182
trainer/Q Targets Max              -2.46329
trainer/Q Targets Min            -132.75
trainer/Log Pis Mean                2.02302
trainer/Log Pis Std                 1.58805
trainer/Log Pis Max                 9.66603
trainer/Log Pis Min                -2.65578
trainer/Policy mu Mean              0.0489865
trainer/Policy mu Std               0.93222
trainer/Policy mu Max               3.12992
trainer/Policy mu Min              -3.5503
trainer/Policy log std Mean        -1.81201
trainer/Policy log std Std          0.613813
trainer/Policy log std Max         -0.212977
trainer/Policy log std Min         -2.84054
trainer/Alpha                       0.0662609
trainer/Alpha Loss                  0.062484
exploration/num steps total     86700
exploration/num paths total       867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.71795
exploration/Rewards Std             1.06615
exploration/Rewards Max            -0.665876
exploration/Rewards Min           -10.7105
exploration/Returns Mean         -171.795
exploration/Returns Std            55.0219
exploration/Returns Max          -117.563
exploration/Returns Min          -276.221
exploration/Actions Mean            0.0101709
exploration/Actions Std             0.271285
exploration/Actions Max             0.999156
exploration/Actions Min            -0.999797
exploration/Num Paths               5
exploration/Average Returns      -171.795
evaluation/num steps total     259500
evaluation/num paths total       2595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03083
evaluation/Rewards Std              1.06376
evaluation/Rewards Max             -0.0137297
evaluation/Rewards Min            -10.5674
evaluation/Returns Mean          -103.083
evaluation/Returns Std             63.4947
evaluation/Returns Max            -11.57
evaluation/Returns Min           -271.175
evaluation/Actions Mean             0.00572495
evaluation/Actions Std              0.187569
evaluation/Actions Max              0.99879
evaluation/Actions Min             -0.999586
evaluation/Num Paths               15
evaluation/Average Returns       -103.083
time/data storing (s)               0.0031101
time/evaluation sampling (s)        0.330642
time/exploration sampling (s)       0.14063
time/logging (s)                    0.00479523
time/saving (s)                     0.00156898
time/training (s)                   1.95001
time/epoch (s)                      2.43076
time/total (s)                    421.977
Epoch                             172
-----------------------------  ---------------
2019-04-23 00:00:23.809079 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 173 finished
-----------------------------  ----------------
replay_buffer/size              87200
trainer/QF1 Loss                    7.31049
trainer/QF2 Loss                    7.45043
trainer/Policy Loss                54.009
trainer/Q1 Predictions Mean       -52.6537
trainer/Q1 Predictions Std         32.6537
trainer/Q1 Predictions Max         -9.83528
trainer/Q1 Predictions Min       -132.522
trainer/Q2 Predictions Mean       -52.6397
trainer/Q2 Predictions Std         32.657
trainer/Q2 Predictions Max         -9.82629
trainer/Q2 Predictions Min       -132.836
trainer/Q Targets Mean            -52.8152
trainer/Q Targets Std              33.8918
trainer/Q Targets Max              -0.168862
trainer/Q Targets Min            -135.213
trainer/Log Pis Mean                1.9842
trainer/Log Pis Std                 1.36329
trainer/Log Pis Max                 5.80551
trainer/Log Pis Min                -2.83418
trainer/Policy mu Mean              0.186926
trainer/Policy mu Std               0.86795
trainer/Policy mu Max               2.62597
trainer/Policy mu Min              -2.72796
trainer/Policy log std Mean        -1.87274
trainer/Policy log std Std          0.612342
trainer/Policy log std Max         -0.490619
trainer/Policy log std Min         -2.72604
trainer/Alpha                       0.0665199
trainer/Alpha Loss                 -0.042811
exploration/num steps total     87200
exploration/num paths total       872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.27389
exploration/Rewards Std             1.19997
exploration/Rewards Max            -0.120824
exploration/Rewards Min           -10.1533
exploration/Returns Mean         -127.389
exploration/Returns Std            90.2717
exploration/Returns Max           -42.0043
exploration/Returns Min          -281.521
exploration/Actions Mean           -0.00651723
exploration/Actions Std             0.229402
exploration/Actions Max             0.984746
exploration/Actions Min            -0.999993
exploration/Num Paths               5
exploration/Average Returns      -127.389
evaluation/num steps total     261000
evaluation/num paths total       2610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0915
evaluation/Rewards Std              1.15992
evaluation/Rewards Max             -0.0462186
evaluation/Rewards Min            -10.4023
evaluation/Returns Mean          -109.15
evaluation/Returns Std             69.9707
evaluation/Returns Max            -20.5851
evaluation/Returns Min           -251.486
evaluation/Actions Mean             0.000204294
evaluation/Actions Std              0.176854
evaluation/Actions Max              0.998565
evaluation/Actions Min             -0.999698
evaluation/Num Paths               15
evaluation/Average Returns       -109.15
time/data storing (s)               0.00301232
time/evaluation sampling (s)        0.332118
time/exploration sampling (s)       0.139589
time/logging (s)                    0.00477516
time/saving (s)                     0.00186265
time/training (s)                   1.95124
time/epoch (s)                      2.4326
time/total (s)                    424.414
Epoch                             173
-----------------------------  ----------------
2019-04-23 00:00:26.254287 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 174 finished
-----------------------------  ---------------
replay_buffer/size              87700
trainer/QF1 Loss                    0.568255
trainer/QF2 Loss                    0.67253
trainer/Policy Loss                53.818
trainer/Q1 Predictions Mean       -52.3006
trainer/Q1 Predictions Std         34
trainer/Q1 Predictions Max        -10.2805
trainer/Q1 Predictions Min       -160.485
trainer/Q2 Predictions Mean       -52.2621
trainer/Q2 Predictions Std         33.9894
trainer/Q2 Predictions Max        -10.2413
trainer/Q2 Predictions Min       -160.835
trainer/Q Targets Mean            -52.6705
trainer/Q Targets Std              34.2957
trainer/Q Targets Max             -10.0783
trainer/Q Targets Min            -159.714
trainer/Log Pis Mean                2.04518
trainer/Log Pis Std                 1.80486
trainer/Log Pis Max                 9.79822
trainer/Log Pis Min                -4.78263
trainer/Policy mu Mean              0.0254469
trainer/Policy mu Std               0.99348
trainer/Policy mu Max               3.63884
trainer/Policy mu Min              -4.71508
trainer/Policy log std Mean        -1.83559
trainer/Policy log std Std          0.600275
trainer/Policy log std Max          0.408597
trainer/Policy log std Min         -2.66467
trainer/Alpha                       0.0681927
trainer/Alpha Loss                  0.121333
exploration/num steps total     87700
exploration/num paths total       877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.54842
exploration/Rewards Std             1.1752
exploration/Rewards Max            -0.016453
exploration/Rewards Min            -9.67039
exploration/Returns Mean         -154.842
exploration/Returns Std            91.7851
exploration/Returns Max           -29.3569
exploration/Returns Min          -269.123
exploration/Actions Mean           -0.00194033
exploration/Actions Std             0.244298
exploration/Actions Max             0.999377
exploration/Actions Min            -0.999243
exploration/Num Paths               5
exploration/Average Returns      -154.842
evaluation/num steps total     262500
evaluation/num paths total       2625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08703
evaluation/Rewards Std              1.12824
evaluation/Rewards Max             -0.0295801
evaluation/Rewards Min             -9.67608
evaluation/Returns Mean          -108.703
evaluation/Returns Std             84.5137
evaluation/Returns Max             -9.88669
evaluation/Returns Min           -264.199
evaluation/Actions Mean            -0.00190504
evaluation/Actions Std              0.169633
evaluation/Actions Max              0.996916
evaluation/Actions Min             -0.999613
evaluation/Num Paths               15
evaluation/Average Returns       -108.703
time/data storing (s)               0.00310728
time/evaluation sampling (s)        0.324577
time/exploration sampling (s)       0.138031
time/logging (s)                    0.00481636
time/saving (s)                     0.00193096
time/training (s)                   1.96548
time/epoch (s)                      2.43795
time/total (s)                    426.857
Epoch                             174
-----------------------------  ---------------
2019-04-23 00:00:28.679856 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 175 finished
-----------------------------  ---------------
replay_buffer/size              88200
trainer/QF1 Loss                    0.395356
trainer/QF2 Loss                    0.50981
trainer/Policy Loss                48.7536
trainer/Q1 Predictions Mean       -47.1307
trainer/Q1 Predictions Std         34.0734
trainer/Q1 Predictions Max        -10.2916
trainer/Q1 Predictions Min       -135.5
trainer/Q2 Predictions Mean       -47.0693
trainer/Q2 Predictions Std         34.0482
trainer/Q2 Predictions Max        -10.2291
trainer/Q2 Predictions Min       -134.819
trainer/Q Targets Mean            -47.2404
trainer/Q Targets Std              34.2228
trainer/Q Targets Max              -9.82339
trainer/Q Targets Min            -137.216
trainer/Log Pis Mean                2.32588
trainer/Log Pis Std                 1.43905
trainer/Log Pis Max                 8.9165
trainer/Log Pis Min                -2.39965
trainer/Policy mu Mean              0.0473819
trainer/Policy mu Std               1.04154
trainer/Policy mu Max               3.09915
trainer/Policy mu Min              -3.36549
trainer/Policy log std Mean        -1.75445
trainer/Policy log std Std          0.640302
trainer/Policy log std Max         -0.193462
trainer/Policy log std Min         -2.65528
trainer/Alpha                       0.0685376
trainer/Alpha Loss                  0.873469
exploration/num steps total     88200
exploration/num paths total       882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.91631
exploration/Rewards Std             0.685556
exploration/Rewards Max            -0.946926
exploration/Rewards Min            -3.76899
exploration/Returns Mean         -191.631
exploration/Returns Std            64.632
exploration/Returns Max          -136.05
exploration/Returns Min          -272.272
exploration/Actions Mean            0.00375838
exploration/Actions Std             0.230159
exploration/Actions Max             0.972136
exploration/Actions Min            -0.995471
exploration/Num Paths               5
exploration/Average Returns      -191.631
evaluation/num steps total     264000
evaluation/num paths total       2640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.37961
evaluation/Rewards Std              1.304
evaluation/Rewards Max             -0.0623484
evaluation/Rewards Min            -10.5716
evaluation/Returns Mean          -137.961
evaluation/Returns Std            100.051
evaluation/Returns Max             -7.4192
evaluation/Returns Min           -300.16
evaluation/Actions Mean             0.00461722
evaluation/Actions Std              0.188189
evaluation/Actions Max              0.999069
evaluation/Actions Min             -0.999515
evaluation/Num Paths               15
evaluation/Average Returns       -137.961
time/data storing (s)               0.00315317
time/evaluation sampling (s)        0.330429
time/exploration sampling (s)       0.137106
time/logging (s)                    0.0048235
time/saving (s)                     0.0019477
time/training (s)                   1.94102
time/epoch (s)                      2.41848
time/total (s)                    429.28
Epoch                             175
-----------------------------  ---------------
2019-04-23 00:00:31.100757 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 176 finished
-----------------------------  ---------------
replay_buffer/size              88700
trainer/QF1 Loss                    0.760975
trainer/QF2 Loss                    0.7756
trainer/Policy Loss                49.8071
trainer/Q1 Predictions Mean       -48.3619
trainer/Q1 Predictions Std         38.0929
trainer/Q1 Predictions Max         -9.74013
trainer/Q1 Predictions Min       -140.431
trainer/Q2 Predictions Mean       -48.3619
trainer/Q2 Predictions Std         38.0485
trainer/Q2 Predictions Max         -9.8061
trainer/Q2 Predictions Min       -139.663
trainer/Q Targets Mean            -48.94
trainer/Q Targets Std              38.5741
trainer/Q Targets Max              -9.86682
trainer/Q Targets Min            -142.868
trainer/Log Pis Mean                1.94194
trainer/Log Pis Std                 1.19922
trainer/Log Pis Max                 5.41948
trainer/Log Pis Min                -2.20513
trainer/Policy mu Mean              0.14271
trainer/Policy mu Std               0.718621
trainer/Policy mu Max               2.82527
trainer/Policy mu Min              -2.78293
trainer/Policy log std Mean        -1.95879
trainer/Policy log std Std          0.530559
trainer/Policy log std Max         -0.37679
trainer/Policy log std Min         -2.71708
trainer/Alpha                       0.0672332
trainer/Alpha Loss                 -0.156733
exploration/num steps total     88700
exploration/num paths total       887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.61841
exploration/Rewards Std             0.919693
exploration/Rewards Max            -0.378874
exploration/Rewards Min            -8.7076
exploration/Returns Mean         -161.841
exploration/Returns Std            52.5201
exploration/Returns Max           -86.5155
exploration/Returns Min          -251.128
exploration/Actions Mean           -0.00300854
exploration/Actions Std             0.232605
exploration/Actions Max             0.994372
exploration/Actions Min            -0.999783
exploration/Num Paths               5
exploration/Average Returns      -161.841
evaluation/num steps total     265500
evaluation/num paths total       2655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23127
evaluation/Rewards Std              1.16886
evaluation/Rewards Max             -0.0329015
evaluation/Rewards Min             -9.58817
evaluation/Returns Mean          -123.127
evaluation/Returns Std             82.5554
evaluation/Returns Max            -34.6249
evaluation/Returns Min           -244.392
evaluation/Actions Mean            -0.00126385
evaluation/Actions Std              0.184619
evaluation/Actions Max              0.997179
evaluation/Actions Min             -0.999566
evaluation/Num Paths               15
evaluation/Average Returns       -123.127
time/data storing (s)               0.00289612
time/evaluation sampling (s)        0.330489
time/exploration sampling (s)       0.14307
time/logging (s)                    0.00495901
time/saving (s)                     0.00196943
time/training (s)                   1.93015
time/epoch (s)                      2.41354
time/total (s)                    431.698
Epoch                             176
-----------------------------  ---------------
2019-04-23 00:00:33.535630 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 177 finished
-----------------------------  ----------------
replay_buffer/size              89200
trainer/QF1 Loss                  103.99
trainer/QF2 Loss                  104.964
trainer/Policy Loss                52.0007
trainer/Q1 Predictions Mean       -50.8531
trainer/Q1 Predictions Std         37.3914
trainer/Q1 Predictions Max         -9.80225
trainer/Q1 Predictions Min       -157.27
trainer/Q2 Predictions Mean       -50.92
trainer/Q2 Predictions Std         37.4358
trainer/Q2 Predictions Max         -9.83806
trainer/Q2 Predictions Min       -157.769
trainer/Q Targets Mean            -49.8155
trainer/Q Targets Std              38.144
trainer/Q Targets Max              -1.47373
trainer/Q Targets Min            -156.855
trainer/Log Pis Mean                1.94931
trainer/Log Pis Std                 1.54403
trainer/Log Pis Max                 6.0929
trainer/Log Pis Min                -5.31782
trainer/Policy mu Mean              0.0177132
trainer/Policy mu Std               1.04123
trainer/Policy mu Max               2.83007
trainer/Policy mu Min              -2.76837
trainer/Policy log std Mean        -1.74391
trainer/Policy log std Std          0.632738
trainer/Policy log std Max         -0.29252
trainer/Policy log std Min         -2.65133
trainer/Alpha                       0.0665516
trainer/Alpha Loss                 -0.137363
exploration/num steps total     89200
exploration/num paths total       892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.479434
exploration/Rewards Std             1.08728
exploration/Rewards Max            -0.0145941
exploration/Rewards Min           -10.1304
exploration/Returns Mean          -47.9434
exploration/Returns Std            27.3274
exploration/Returns Max           -13.1113
exploration/Returns Min           -87.2961
exploration/Actions Mean           -0.000412193
exploration/Actions Std             0.251969
exploration/Actions Max             0.999558
exploration/Actions Min            -0.999993
exploration/Num Paths               5
exploration/Average Returns       -47.9434
evaluation/num steps total     267000
evaluation/num paths total       2670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25326
evaluation/Rewards Std              1.26374
evaluation/Rewards Max             -0.0129234
evaluation/Rewards Min            -11.6298
evaluation/Returns Mean          -125.326
evaluation/Returns Std             79.4202
evaluation/Returns Max             -8.73729
evaluation/Returns Min           -283.436
evaluation/Actions Mean             0.00173309
evaluation/Actions Std              0.198824
evaluation/Actions Max              0.99956
evaluation/Actions Min             -0.999771
evaluation/Num Paths               15
evaluation/Average Returns       -125.326
time/data storing (s)               0.00328213
time/evaluation sampling (s)        0.328085
time/exploration sampling (s)       0.138332
time/logging (s)                    0.0048228
time/saving (s)                     0.0019842
time/training (s)                   1.95068
time/epoch (s)                      2.42718
time/total (s)                    434.129
Epoch                             177
-----------------------------  ----------------
2019-04-23 00:00:35.971245 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 178 finished
-----------------------------  ---------------
replay_buffer/size              89700
trainer/QF1 Loss                    0.833924
trainer/QF2 Loss                    0.91436
trainer/Policy Loss                51.1503
trainer/Q1 Predictions Mean       -49.9975
trainer/Q1 Predictions Std         34.2288
trainer/Q1 Predictions Max        -10.1953
trainer/Q1 Predictions Min       -139.208
trainer/Q2 Predictions Mean       -49.966
trainer/Q2 Predictions Std         34.2369
trainer/Q2 Predictions Max        -10.2299
trainer/Q2 Predictions Min       -138.781
trainer/Q Targets Mean            -50.5158
trainer/Q Targets Std              34.5124
trainer/Q Targets Max              -9.85237
trainer/Q Targets Min            -141.123
trainer/Log Pis Mean                1.80375
trainer/Log Pis Std                 1.35832
trainer/Log Pis Max                 5.54433
trainer/Log Pis Min                -2.13855
trainer/Policy mu Mean              0.0448165
trainer/Policy mu Std               0.852534
trainer/Policy mu Max               2.71772
trainer/Policy mu Min              -2.78669
trainer/Policy log std Mean        -1.83435
trainer/Policy log std Std          0.608537
trainer/Policy log std Max         -0.433729
trainer/Policy log std Min         -2.65046
trainer/Alpha                       0.064686
trainer/Alpha Loss                 -0.537374
exploration/num steps total     89700
exploration/num paths total       897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04526
exploration/Rewards Std             1.31304
exploration/Rewards Max            -0.0483996
exploration/Rewards Min           -10.0553
exploration/Returns Mean         -104.526
exploration/Returns Std           101.45
exploration/Returns Max           -29.6149
exploration/Returns Min          -298.726
exploration/Actions Mean           -0.0197221
exploration/Actions Std             0.254349
exploration/Actions Max             0.996287
exploration/Actions Min            -0.999981
exploration/Num Paths               5
exploration/Average Returns      -104.526
evaluation/num steps total     268500
evaluation/num paths total       2685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.968832
evaluation/Rewards Std              1.11799
evaluation/Rewards Max             -0.0424699
evaluation/Rewards Min            -10.2176
evaluation/Returns Mean           -96.8832
evaluation/Returns Std             72.6897
evaluation/Returns Max             -6.77217
evaluation/Returns Min           -271.785
evaluation/Actions Mean             0.00231329
evaluation/Actions Std              0.180935
evaluation/Actions Max              0.999631
evaluation/Actions Min             -0.999716
evaluation/Num Paths               15
evaluation/Average Returns        -96.8832
time/data storing (s)               0.00330811
time/evaluation sampling (s)        0.321949
time/exploration sampling (s)       0.138557
time/logging (s)                    0.00481698
time/saving (s)                     0.00195761
time/training (s)                   1.95745
time/epoch (s)                      2.42803
time/total (s)                    436.562
Epoch                             178
-----------------------------  ---------------
2019-04-23 00:00:38.391614 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 179 finished
-----------------------------  ---------------
replay_buffer/size              90200
trainer/QF1 Loss                    0.990764
trainer/QF2 Loss                    1.05656
trainer/Policy Loss                54.4887
trainer/Q1 Predictions Mean       -53.498
trainer/Q1 Predictions Std         36.6762
trainer/Q1 Predictions Max         -9.57269
trainer/Q1 Predictions Min       -143.926
trainer/Q2 Predictions Mean       -53.4528
trainer/Q2 Predictions Std         36.6929
trainer/Q2 Predictions Max         -9.62088
trainer/Q2 Predictions Min       -145.516
trainer/Q Targets Mean            -54.1523
trainer/Q Targets Std              36.9667
trainer/Q Targets Max              -9.92889
trainer/Q Targets Min            -145.075
trainer/Log Pis Mean                1.99451
trainer/Log Pis Std                 1.44378
trainer/Log Pis Max                 6.18912
trainer/Log Pis Min                -3.57554
trainer/Policy mu Mean              0.106852
trainer/Policy mu Std               1.07575
trainer/Policy mu Max               3.12788
trainer/Policy mu Min              -3.13182
trainer/Policy log std Mean        -1.65771
trainer/Policy log std Std          0.644449
trainer/Policy log std Max         -0.291205
trainer/Policy log std Min         -2.67333
trainer/Alpha                       0.0654108
trainer/Alpha Loss                 -0.0149581
exploration/num steps total     90200
exploration/num paths total       902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.810012
exploration/Rewards Std             1.02102
exploration/Rewards Max            -0.0125369
exploration/Rewards Min            -9.21344
exploration/Returns Mean          -81.0012
exploration/Returns Std            55.6136
exploration/Returns Max           -21.2087
exploration/Returns Min          -153.179
exploration/Actions Mean           -0.000748
exploration/Actions Std             0.242074
exploration/Actions Max             0.997087
exploration/Actions Min            -0.999136
exploration/Num Paths               5
exploration/Average Returns       -81.0012
evaluation/num steps total     270000
evaluation/num paths total       2700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.08522
evaluation/Rewards Std              1.19387
evaluation/Rewards Max             -0.0596382
evaluation/Rewards Min            -10.8109
evaluation/Returns Mean          -108.522
evaluation/Returns Std             68.1577
evaluation/Returns Max            -10.9089
evaluation/Returns Min           -285.562
evaluation/Actions Mean             0.00440541
evaluation/Actions Std              0.206842
evaluation/Actions Max              0.997779
evaluation/Actions Min             -0.999245
evaluation/Num Paths               15
evaluation/Average Returns       -108.522
time/data storing (s)               0.00281699
time/evaluation sampling (s)        0.332597
time/exploration sampling (s)       0.136244
time/logging (s)                    0.00481156
time/saving (s)                     0.00195596
time/training (s)                   1.93444
time/epoch (s)                      2.41286
time/total (s)                    438.979
Epoch                             179
-----------------------------  ---------------
2019-04-23 00:00:40.821732 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 180 finished
-----------------------------  ---------------
replay_buffer/size              90700
trainer/QF1 Loss                    0.308073
trainer/QF2 Loss                    0.272812
trainer/Policy Loss                46.0549
trainer/Q1 Predictions Mean       -44.5109
trainer/Q1 Predictions Std         30.981
trainer/Q1 Predictions Max         -9.64781
trainer/Q1 Predictions Min       -135.922
trainer/Q2 Predictions Mean       -44.5699
trainer/Q2 Predictions Std         30.9732
trainer/Q2 Predictions Max         -9.64505
trainer/Q2 Predictions Min       -136.07
trainer/Q Targets Mean            -44.8436
trainer/Q Targets Std              31.1621
trainer/Q Targets Max              -9.65371
trainer/Q Targets Min            -138.034
trainer/Log Pis Mean                2.2306
trainer/Log Pis Std                 1.35633
trainer/Log Pis Max                 6.63748
trainer/Log Pis Min                -1.55651
trainer/Policy mu Mean              0.0373422
trainer/Policy mu Std               0.933664
trainer/Policy mu Max               3.23781
trainer/Policy mu Min              -2.6932
trainer/Policy log std Mean        -1.83605
trainer/Policy log std Std          0.598698
trainer/Policy log std Max         -0.400757
trainer/Policy log std Min         -2.76003
trainer/Alpha                       0.0642683
trainer/Alpha Loss                  0.632951
exploration/num steps total     90700
exploration/num paths total       907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.87235
exploration/Rewards Std             0.811002
exploration/Rewards Max            -0.00462408
exploration/Rewards Min            -8.10705
exploration/Returns Mean          -87.235
exploration/Returns Std            40.1357
exploration/Returns Max           -19.5443
exploration/Returns Min          -130.571
exploration/Actions Mean            0.010413
exploration/Actions Std             0.20287
exploration/Actions Max             0.999622
exploration/Actions Min            -0.999715
exploration/Num Paths               5
exploration/Average Returns       -87.235
evaluation/num steps total     271500
evaluation/num paths total       2715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.2376
evaluation/Rewards Std              1.27468
evaluation/Rewards Max             -0.0100518
evaluation/Rewards Min            -11.8257
evaluation/Returns Mean          -123.76
evaluation/Returns Std             78.8166
evaluation/Returns Max             -3.5272
evaluation/Returns Min           -265.897
evaluation/Actions Mean             0.00118391
evaluation/Actions Std              0.202581
evaluation/Actions Max              0.999684
evaluation/Actions Min             -0.999261
evaluation/Num Paths               15
evaluation/Average Returns       -123.76
time/data storing (s)               0.00300612
time/evaluation sampling (s)        0.323585
time/exploration sampling (s)       0.140116
time/logging (s)                    0.00482756
time/saving (s)                     0.00196927
time/training (s)                   1.94909
time/epoch (s)                      2.42259
time/total (s)                    441.407
Epoch                             180
-----------------------------  ---------------
2019-04-23 00:00:43.264497 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 181 finished
-----------------------------  ---------------
replay_buffer/size              91200
trainer/QF1 Loss                    0.697824
trainer/QF2 Loss                    0.667672
trainer/Policy Loss                50.4751
trainer/Q1 Predictions Mean       -48.93
trainer/Q1 Predictions Std         35.3455
trainer/Q1 Predictions Max         -9.57106
trainer/Q1 Predictions Min       -154.269
trainer/Q2 Predictions Mean       -48.9008
trainer/Q2 Predictions Std         35.3243
trainer/Q2 Predictions Max         -9.54439
trainer/Q2 Predictions Min       -154.06
trainer/Q Targets Mean            -49.4959
trainer/Q Targets Std              35.6989
trainer/Q Targets Max              -9.57496
trainer/Q Targets Min            -153.48
trainer/Log Pis Mean                2.08557
trainer/Log Pis Std                 1.58198
trainer/Log Pis Max                 7.1034
trainer/Log Pis Min                -4.1928
trainer/Policy mu Mean              0.0687327
trainer/Policy mu Std               0.922197
trainer/Policy mu Max               2.80613
trainer/Policy mu Min              -3.03362
trainer/Policy log std Mean        -1.88771
trainer/Policy log std Std          0.603216
trainer/Policy log std Max         -0.490162
trainer/Policy log std Min         -2.767
trainer/Alpha                       0.0641639
trainer/Alpha Loss                  0.235006
exploration/num steps total     91200
exploration/num paths total       912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.77944
exploration/Rewards Std             1.13549
exploration/Rewards Max            -0.0282183
exploration/Rewards Min            -9.95826
exploration/Returns Mean         -177.944
exploration/Returns Std            85.5108
exploration/Returns Max           -32.2398
exploration/Returns Min          -275.848
exploration/Actions Mean           -0.00650953
exploration/Actions Std             0.247741
exploration/Actions Max             0.99865
exploration/Actions Min            -0.999768
exploration/Num Paths               5
exploration/Average Returns      -177.944
evaluation/num steps total     273000
evaluation/num paths total       2730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.20642
evaluation/Rewards Std              0.970392
evaluation/Rewards Max             -0.0539632
evaluation/Rewards Min            -10.4115
evaluation/Returns Mean          -120.642
evaluation/Returns Std             61.1738
evaluation/Returns Max            -32.7412
evaluation/Returns Min           -242.814
evaluation/Actions Mean             0.0153065
evaluation/Actions Std              0.17541
evaluation/Actions Max              0.998699
evaluation/Actions Min             -0.998455
evaluation/Num Paths               15
evaluation/Average Returns       -120.642
time/data storing (s)               0.00308332
time/evaluation sampling (s)        0.329415
time/exploration sampling (s)       0.138245
time/logging (s)                    0.00480121
time/saving (s)                     0.0100404
time/training (s)                   1.94958
time/epoch (s)                      2.43516
time/total (s)                    443.846
Epoch                             181
-----------------------------  ---------------
2019-04-23 00:00:45.655324 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 182 finished
-----------------------------  ---------------
replay_buffer/size              91700
trainer/QF1 Loss                    2.10258
trainer/QF2 Loss                    2.1276
trainer/Policy Loss                52.0757
trainer/Q1 Predictions Mean       -50.8431
trainer/Q1 Predictions Std         34.654
trainer/Q1 Predictions Max         -9.84903
trainer/Q1 Predictions Min       -140.125
trainer/Q2 Predictions Mean       -50.8695
trainer/Q2 Predictions Std         34.6373
trainer/Q2 Predictions Max         -9.78737
trainer/Q2 Predictions Min       -139.913
trainer/Q Targets Mean            -51.1303
trainer/Q Targets Std              35.2619
trainer/Q Targets Max              -0.223179
trainer/Q Targets Min            -141.195
trainer/Log Pis Mean                1.83937
trainer/Log Pis Std                 1.31217
trainer/Log Pis Max                 5.46885
trainer/Log Pis Min                -1.70018
trainer/Policy mu Mean              0.0174772
trainer/Policy mu Std               0.811566
trainer/Policy mu Max               2.40878
trainer/Policy mu Min              -2.82868
trainer/Policy log std Mean        -1.89782
trainer/Policy log std Std          0.616507
trainer/Policy log std Max         -0.421984
trainer/Policy log std Min         -2.82585
trainer/Alpha                       0.0654908
trainer/Alpha Loss                 -0.437836
exploration/num steps total     91700
exploration/num paths total       917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.972668
exploration/Rewards Std             0.589009
exploration/Rewards Max            -0.0127659
exploration/Rewards Min            -4.77746
exploration/Returns Mean          -97.2668
exploration/Returns Std            54.5605
exploration/Returns Max           -17.8238
exploration/Returns Min          -144.009
exploration/Actions Mean           -0.00322134
exploration/Actions Std             0.196228
exploration/Actions Max             0.9925
exploration/Actions Min            -0.987571
exploration/Num Paths               5
exploration/Average Returns       -97.2668
evaluation/num steps total     274500
evaluation/num paths total       2745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.17589
evaluation/Rewards Std              1.31982
evaluation/Rewards Max             -0.0512214
evaluation/Rewards Min            -10.1734
evaluation/Returns Mean          -117.589
evaluation/Returns Std             87.4501
evaluation/Returns Max             -6.40946
evaluation/Returns Min           -266.143
evaluation/Actions Mean            -0.0202594
evaluation/Actions Std              0.19033
evaluation/Actions Max              0.993692
evaluation/Actions Min             -0.99962
evaluation/Num Paths               15
evaluation/Average Returns       -117.589
time/data storing (s)               0.00294216
time/evaluation sampling (s)        0.331328
time/exploration sampling (s)       0.137471
time/logging (s)                    0.00476954
time/saving (s)                     0.00194551
time/training (s)                   1.90482
time/epoch (s)                      2.38328
time/total (s)                    446.234
Epoch                             182
-----------------------------  ---------------
2019-04-23 00:00:48.084479 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 183 finished
-----------------------------  ---------------
replay_buffer/size              92200
trainer/QF1 Loss                    0.264278
trainer/QF2 Loss                    0.275677
trainer/Policy Loss                46.6002
trainer/Q1 Predictions Mean       -45.5551
trainer/Q1 Predictions Std         30.9875
trainer/Q1 Predictions Max         -9.57152
trainer/Q1 Predictions Min       -139.006
trainer/Q2 Predictions Mean       -45.5438
trainer/Q2 Predictions Std         30.9625
trainer/Q2 Predictions Max         -9.54231
trainer/Q2 Predictions Min       -138.72
trainer/Q Targets Mean            -45.835
trainer/Q Targets Std              31.2343
trainer/Q Targets Max              -9.63597
trainer/Q Targets Min            -141.212
trainer/Log Pis Mean                1.67517
trainer/Log Pis Std                 1.27679
trainer/Log Pis Max                 5.46009
trainer/Log Pis Min                -2.85297
trainer/Policy mu Mean             -0.0664618
trainer/Policy mu Std               0.798854
trainer/Policy mu Max               2.73619
trainer/Policy mu Min              -2.8564
trainer/Policy log std Mean        -1.79206
trainer/Policy log std Std          0.563508
trainer/Policy log std Max         -0.315962
trainer/Policy log std Min         -2.65348
trainer/Alpha                       0.064412
trainer/Alpha Loss                 -0.890735
exploration/num steps total     92200
exploration/num paths total       922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.04959
exploration/Rewards Std             1.11963
exploration/Rewards Max            -0.0194579
exploration/Rewards Min            -8.84061
exploration/Returns Mean         -104.959
exploration/Returns Std            94.495
exploration/Returns Max           -13.5588
exploration/Returns Min          -266.505
exploration/Actions Mean           -0.00364144
exploration/Actions Std             0.232375
exploration/Actions Max             0.997149
exploration/Actions Min            -0.999362
exploration/Num Paths               5
exploration/Average Returns      -104.959
evaluation/num steps total     276000
evaluation/num paths total       2760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.49241
evaluation/Rewards Std              1.18356
evaluation/Rewards Max             -0.0572803
evaluation/Rewards Min            -10.6221
evaluation/Returns Mean          -149.241
evaluation/Returns Std             80.1439
evaluation/Returns Max            -23.4916
evaluation/Returns Min           -264.386
evaluation/Actions Mean             0.00677863
evaluation/Actions Std              0.191781
evaluation/Actions Max              0.995688
evaluation/Actions Min             -0.99798
evaluation/Num Paths               15
evaluation/Average Returns       -149.241
time/data storing (s)               0.00285804
time/evaluation sampling (s)        0.333639
time/exploration sampling (s)       0.138794
time/logging (s)                    0.00353264
time/saving (s)                     0.00176876
time/training (s)                   1.93963
time/epoch (s)                      2.42023
time/total (s)                    448.659
Epoch                             183
-----------------------------  ---------------
2019-04-23 00:00:50.507414 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 184 finished
-----------------------------  ---------------
replay_buffer/size              92700
trainer/QF1 Loss                    0.315205
trainer/QF2 Loss                    0.422039
trainer/Policy Loss                50.1466
trainer/Q1 Predictions Mean       -48.6237
trainer/Q1 Predictions Std         34.1593
trainer/Q1 Predictions Max         -9.72458
trainer/Q1 Predictions Min       -139.953
trainer/Q2 Predictions Mean       -48.638
trainer/Q2 Predictions Std         34.1098
trainer/Q2 Predictions Max         -9.79241
trainer/Q2 Predictions Min       -139.496
trainer/Q Targets Mean            -48.7529
trainer/Q Targets Std              34.3515
trainer/Q Targets Max              -9.61727
trainer/Q Targets Min            -141.865
trainer/Log Pis Mean                1.8816
trainer/Log Pis Std                 1.27717
trainer/Log Pis Max                 4.78681
trainer/Log Pis Min                -1.5041
trainer/Policy mu Mean             -0.0242601
trainer/Policy mu Std               0.806793
trainer/Policy mu Max               2.30582
trainer/Policy mu Min              -2.82459
trainer/Policy log std Mean        -1.83735
trainer/Policy log std Std          0.565783
trainer/Policy log std Max         -0.555298
trainer/Policy log std Min         -2.81828
trainer/Alpha                       0.0627275
trainer/Alpha Loss                 -0.327836
exploration/num steps total     92700
exploration/num paths total       927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.6326
exploration/Rewards Std             0.972457
exploration/Rewards Max            -0.0812447
exploration/Rewards Min            -8.7346
exploration/Returns Mean         -163.26
exploration/Returns Std            60.5392
exploration/Returns Max           -78.9201
exploration/Returns Min          -257.222
exploration/Actions Mean            0.0111043
exploration/Actions Std             0.236953
exploration/Actions Max             0.999698
exploration/Actions Min            -0.985557
exploration/Num Paths               5
exploration/Average Returns      -163.26
evaluation/num steps total     277500
evaluation/num paths total       2775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.41543
evaluation/Rewards Std              1.12072
evaluation/Rewards Max             -0.0207941
evaluation/Rewards Min            -10.1818
evaluation/Returns Mean          -141.543
evaluation/Returns Std             81.1581
evaluation/Returns Max            -20.3799
evaluation/Returns Min           -286.45
evaluation/Actions Mean            -0.00566787
evaluation/Actions Std              0.177741
evaluation/Actions Max              0.997973
evaluation/Actions Min             -0.999331
evaluation/Num Paths               15
evaluation/Average Returns       -141.543
time/data storing (s)               0.00297311
time/evaluation sampling (s)        0.330515
time/exploration sampling (s)       0.135592
time/logging (s)                    0.00478572
time/saving (s)                     0.00195765
time/training (s)                   1.94086
time/epoch (s)                      2.41668
time/total (s)                    451.08
Epoch                             184
-----------------------------  ---------------
2019-04-23 00:00:52.938262 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 185 finished
-----------------------------  ---------------
replay_buffer/size              93200
trainer/QF1 Loss                   71.3723
trainer/QF2 Loss                   71.3136
trainer/Policy Loss                50.7758
trainer/Q1 Predictions Mean       -49.6255
trainer/Q1 Predictions Std         36.7089
trainer/Q1 Predictions Max         -9.4941
trainer/Q1 Predictions Min       -136.779
trainer/Q2 Predictions Mean       -49.601
trainer/Q2 Predictions Std         36.7148
trainer/Q2 Predictions Max         -9.41281
trainer/Q2 Predictions Min       -136.805
trainer/Q Targets Mean            -49.1079
trainer/Q Targets Std              37.7749
trainer/Q Targets Max              -1.55583
trainer/Q Targets Min            -138.551
trainer/Log Pis Mean                1.85713
trainer/Log Pis Std                 1.1415
trainer/Log Pis Max                 4.754
trainer/Log Pis Min                -1.43005
trainer/Policy mu Mean             -0.0226009
trainer/Policy mu Std               0.855161
trainer/Policy mu Max               2.64041
trainer/Policy mu Min              -2.70809
trainer/Policy log std Mean        -1.84854
trainer/Policy log std Std          0.576003
trainer/Policy log std Max         -0.453664
trainer/Policy log std Min         -2.74972
trainer/Alpha                       0.0643393
trainer/Alpha Loss                 -0.391957
exploration/num steps total     93200
exploration/num paths total       932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01784
exploration/Rewards Std             0.943415
exploration/Rewards Max            -0.0315575
exploration/Rewards Min            -8.79864
exploration/Returns Mean         -101.784
exploration/Returns Std            52.7544
exploration/Returns Max           -42.2328
exploration/Returns Min          -171.905
exploration/Actions Mean            0.0158952
exploration/Actions Std             0.225449
exploration/Actions Max             0.998902
exploration/Actions Min            -0.994439
exploration/Num Paths               5
exploration/Average Returns      -101.784
evaluation/num steps total     279000
evaluation/num paths total       2790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.29905
evaluation/Rewards Std              0.929974
evaluation/Rewards Max             -0.390622
evaluation/Rewards Min             -7.84924
evaluation/Returns Mean          -129.905
evaluation/Returns Std             59.8155
evaluation/Returns Max            -58.948
evaluation/Returns Min           -251.406
evaluation/Actions Mean            -0.00952977
evaluation/Actions Std              0.179185
evaluation/Actions Max              0.998488
evaluation/Actions Min             -0.999784
evaluation/Num Paths               15
evaluation/Average Returns       -129.905
time/data storing (s)               0.00296764
time/evaluation sampling (s)        0.335162
time/exploration sampling (s)       0.140179
time/logging (s)                    0.00478949
time/saving (s)                     0.00198107
time/training (s)                   1.93821
time/epoch (s)                      2.42329
time/total (s)                    453.508
Epoch                             185
-----------------------------  ---------------
2019-04-23 00:00:55.348714 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 186 finished
-----------------------------  ---------------
replay_buffer/size              93700
trainer/QF1 Loss                   53.7597
trainer/QF2 Loss                   53.9965
trainer/Policy Loss                53.6382
trainer/Q1 Predictions Mean       -52.0523
trainer/Q1 Predictions Std         34.5279
trainer/Q1 Predictions Max         -9.74827
trainer/Q1 Predictions Min       -137.484
trainer/Q2 Predictions Mean       -52.0684
trainer/Q2 Predictions Std         34.4688
trainer/Q2 Predictions Max         -9.65619
trainer/Q2 Predictions Min       -136.86
trainer/Q Targets Mean            -52.3532
trainer/Q Targets Std              35.3069
trainer/Q Targets Max              -2.30818
trainer/Q Targets Min            -139.287
trainer/Log Pis Mean                2.1169
trainer/Log Pis Std                 1.06679
trainer/Log Pis Max                 5.31284
trainer/Log Pis Min                -0.347572
trainer/Policy mu Mean              0.169609
trainer/Policy mu Std               0.889082
trainer/Policy mu Max               2.87835
trainer/Policy mu Min              -3.10541
trainer/Policy log std Mean        -1.83145
trainer/Policy log std Std          0.58139
trainer/Policy log std Max         -0.287052
trainer/Policy log std Min         -2.76621
trainer/Alpha                       0.0641078
trainer/Alpha Loss                  0.321165
exploration/num steps total     93700
exploration/num paths total       937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.828716
exploration/Rewards Std             1.02607
exploration/Rewards Max            -0.0175176
exploration/Rewards Min            -5.70233
exploration/Returns Mean          -82.8716
exploration/Returns Std            89.0088
exploration/Returns Max           -20.1725
exploration/Returns Min          -259.19
exploration/Actions Mean           -0.00988444
exploration/Actions Std             0.206119
exploration/Actions Max             0.997666
exploration/Actions Min            -0.998502
exploration/Num Paths               5
exploration/Average Returns       -82.8716
evaluation/num steps total     280500
evaluation/num paths total       2805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06117
evaluation/Rewards Std              0.950861
evaluation/Rewards Max             -0.0999563
evaluation/Rewards Min             -8.85662
evaluation/Returns Mean          -106.117
evaluation/Returns Std             69.6247
evaluation/Returns Max            -14.643
evaluation/Returns Min           -257.245
evaluation/Actions Mean             0.0138194
evaluation/Actions Std              0.175992
evaluation/Actions Max              0.996282
evaluation/Actions Min             -0.998269
evaluation/Num Paths               15
evaluation/Average Returns       -106.117
time/data storing (s)               0.00290771
time/evaluation sampling (s)        0.333986
time/exploration sampling (s)       0.137273
time/logging (s)                    0.0043703
time/saving (s)                     0.00194355
time/training (s)                   1.92207
time/epoch (s)                      2.40255
time/total (s)                    455.915
Epoch                             186
-----------------------------  ---------------
2019-04-23 00:00:57.788400 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 187 finished
-----------------------------  ---------------
replay_buffer/size              94200
trainer/QF1 Loss                   20.5244
trainer/QF2 Loss                   20.4321
trainer/Policy Loss                55.4279
trainer/Q1 Predictions Mean       -54.028
trainer/Q1 Predictions Std         31.4077
trainer/Q1 Predictions Max        -10.0625
trainer/Q1 Predictions Min       -129.583
trainer/Q2 Predictions Mean       -53.9917
trainer/Q2 Predictions Std         31.4174
trainer/Q2 Predictions Max        -10.1338
trainer/Q2 Predictions Min       -130.107
trainer/Q Targets Mean            -54.0404
trainer/Q Targets Std              32.1636
trainer/Q Targets Max              -1.47529
trainer/Q Targets Min            -131.264
trainer/Log Pis Mean                1.95391
trainer/Log Pis Std                 1.21651
trainer/Log Pis Max                 7.95975
trainer/Log Pis Min                -1.55012
trainer/Policy mu Mean              0.0905045
trainer/Policy mu Std               0.850786
trainer/Policy mu Max               2.70955
trainer/Policy mu Min              -4.07475
trainer/Policy log std Mean        -1.85082
trainer/Policy log std Std          0.576161
trainer/Policy log std Max         -0.139388
trainer/Policy log std Min         -2.83484
trainer/Alpha                       0.0669814
trainer/Alpha Loss                 -0.1246
exploration/num steps total     94200
exploration/num paths total       942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14369
exploration/Rewards Std             1.13217
exploration/Rewards Max            -0.0141222
exploration/Rewards Min           -10.0642
exploration/Returns Mean         -114.369
exploration/Returns Std            52.576
exploration/Returns Max           -29.8057
exploration/Returns Min          -163.12
exploration/Actions Mean            0.00220852
exploration/Actions Std             0.250253
exploration/Actions Max             0.999921
exploration/Actions Min            -0.999803
exploration/Num Paths               5
exploration/Average Returns      -114.369
evaluation/num steps total     282000
evaluation/num paths total       2820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.40339
evaluation/Rewards Std              1.37885
evaluation/Rewards Max             -0.0672366
evaluation/Rewards Min            -11.5028
evaluation/Returns Mean          -140.339
evaluation/Returns Std             73.4161
evaluation/Returns Max            -39.8418
evaluation/Returns Min           -282.063
evaluation/Actions Mean             0.0100647
evaluation/Actions Std              0.216507
evaluation/Actions Max              0.999626
evaluation/Actions Min             -0.999843
evaluation/Num Paths               15
evaluation/Average Returns       -140.339
time/data storing (s)               0.00302949
time/evaluation sampling (s)        0.329485
time/exploration sampling (s)       0.137268
time/logging (s)                    0.0048084
time/saving (s)                     0.00195648
time/training (s)                   1.95655
time/epoch (s)                      2.4331
time/total (s)                    458.352
Epoch                             187
-----------------------------  ---------------
2019-04-23 00:01:00.234770 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 188 finished
-----------------------------  ----------------
replay_buffer/size              94700
trainer/QF1 Loss                    1.92393
trainer/QF2 Loss                    1.95301
trainer/Policy Loss                54.7379
trainer/Q1 Predictions Mean       -53.4981
trainer/Q1 Predictions Std         36.5565
trainer/Q1 Predictions Max         -9.56896
trainer/Q1 Predictions Min       -140.959
trainer/Q2 Predictions Mean       -53.4957
trainer/Q2 Predictions Std         36.5466
trainer/Q2 Predictions Max         -9.54293
trainer/Q2 Predictions Min       -141.101
trainer/Q Targets Mean            -53.7032
trainer/Q Targets Std              36.8278
trainer/Q Targets Max              -0.0359541
trainer/Q Targets Min            -140.884
trainer/Log Pis Mean                1.90915
trainer/Log Pis Std                 1.52764
trainer/Log Pis Max                 8.8051
trainer/Log Pis Min                -2.10327
trainer/Policy mu Mean              0.130278
trainer/Policy mu Std               0.927944
trainer/Policy mu Max               3.83468
trainer/Policy mu Min              -2.51822
trainer/Policy log std Mean        -1.80131
trainer/Policy log std Std          0.580303
trainer/Policy log std Max         -0.418601
trainer/Policy log std Min         -2.90209
trainer/Alpha                       0.0661117
trainer/Alpha Loss                 -0.246762
exploration/num steps total     94700
exploration/num paths total       947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.34255
exploration/Rewards Std             1.26402
exploration/Rewards Max            -0.0120367
exploration/Rewards Min            -9.69874
exploration/Returns Mean         -134.255
exploration/Returns Std            89.5113
exploration/Returns Max           -26.2011
exploration/Returns Min          -255.544
exploration/Actions Mean            0.0204338
exploration/Actions Std             0.24678
exploration/Actions Max             0.998809
exploration/Actions Min            -0.998638
exploration/Num Paths               5
exploration/Average Returns      -134.255
evaluation/num steps total     283500
evaluation/num paths total       2835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.01865
evaluation/Rewards Std              1.24585
evaluation/Rewards Max             -0.00222126
evaluation/Rewards Min            -11.9832
evaluation/Returns Mean          -101.865
evaluation/Returns Std             81.3022
evaluation/Returns Max             -5.0114
evaluation/Returns Min           -278.427
evaluation/Actions Mean             0.000486943
evaluation/Actions Std              0.19669
evaluation/Actions Max              0.999171
evaluation/Actions Min             -0.99892
evaluation/Num Paths               15
evaluation/Average Returns       -101.865
time/data storing (s)               0.00281099
time/evaluation sampling (s)        0.334415
time/exploration sampling (s)       0.140715
time/logging (s)                    0.00409332
time/saving (s)                     0.00196645
time/training (s)                   1.95575
time/epoch (s)                      2.43975
time/total (s)                    460.795
Epoch                             188
-----------------------------  ----------------
2019-04-23 00:01:02.636139 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 189 finished
-----------------------------  ---------------
replay_buffer/size              95200
trainer/QF1 Loss                  149.013
trainer/QF2 Loss                  148.846
trainer/Policy Loss                49.6202
trainer/Q1 Predictions Mean       -48.1442
trainer/Q1 Predictions Std         32.6756
trainer/Q1 Predictions Max         -9.52326
trainer/Q1 Predictions Min       -135.751
trainer/Q2 Predictions Mean       -48.1546
trainer/Q2 Predictions Std         32.664
trainer/Q2 Predictions Max         -9.48062
trainer/Q2 Predictions Min       -136.001
trainer/Q Targets Mean            -47.7238
trainer/Q Targets Std              32.8109
trainer/Q Targets Max              -2.8971
trainer/Q Targets Min            -139.799
trainer/Log Pis Mean                1.94917
trainer/Log Pis Std                 1.33312
trainer/Log Pis Max                 5.79429
trainer/Log Pis Min                -5.02878
trainer/Policy mu Mean              0.126945
trainer/Policy mu Std               0.857646
trainer/Policy mu Max               3.40625
trainer/Policy mu Min              -3.21101
trainer/Policy log std Mean        -1.96458
trainer/Policy log std Std          0.572279
trainer/Policy log std Max         -0.287004
trainer/Policy log std Min         -2.90053
trainer/Alpha                       0.0636473
trainer/Alpha Loss                 -0.140006
exploration/num steps total     95200
exploration/num paths total       952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.32784
exploration/Rewards Std             1.12846
exploration/Rewards Max            -0.00983541
exploration/Rewards Min            -9.07529
exploration/Returns Mean         -132.784
exploration/Returns Std            78.9485
exploration/Returns Max           -25.7129
exploration/Returns Min          -251.472
exploration/Actions Mean           -0.023031
exploration/Actions Std             0.246247
exploration/Actions Max             0.997944
exploration/Actions Min            -0.999493
exploration/Num Paths               5
exploration/Average Returns      -132.784
evaluation/num steps total     285000
evaluation/num paths total       2850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.25805
evaluation/Rewards Std              0.892749
evaluation/Rewards Max             -0.328631
evaluation/Rewards Min             -9.46535
evaluation/Returns Mean          -125.805
evaluation/Returns Std             42.2345
evaluation/Returns Max            -47.3119
evaluation/Returns Min           -186.451
evaluation/Actions Mean             0.00980642
evaluation/Actions Std              0.181983
evaluation/Actions Max              0.99839
evaluation/Actions Min             -0.998978
evaluation/Num Paths               15
evaluation/Average Returns       -125.805
time/data storing (s)               0.00313394
time/evaluation sampling (s)        0.33079
time/exploration sampling (s)       0.141869
time/logging (s)                    0.0047858
time/saving (s)                     0.00199584
time/training (s)                   1.91209
time/epoch (s)                      2.39466
time/total (s)                    463.195
Epoch                             189
-----------------------------  ---------------
2019-04-23 00:01:05.064108 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 190 finished
-----------------------------  ---------------
replay_buffer/size              95700
trainer/QF1 Loss                    0.190469
trainer/QF2 Loss                    0.182368
trainer/Policy Loss                51.5536
trainer/Q1 Predictions Mean       -50.0375
trainer/Q1 Predictions Std         34.676
trainer/Q1 Predictions Max         -9.65354
trainer/Q1 Predictions Min       -136.265
trainer/Q2 Predictions Mean       -50.0278
trainer/Q2 Predictions Std         34.6782
trainer/Q2 Predictions Max         -9.72938
trainer/Q2 Predictions Min       -135.576
trainer/Q Targets Mean            -50.1327
trainer/Q Targets Std              34.707
trainer/Q Targets Max              -9.62327
trainer/Q Targets Min            -135.982
trainer/Log Pis Mean                2.02513
trainer/Log Pis Std                 1.22863
trainer/Log Pis Max                 4.82347
trainer/Log Pis Min                -1.45786
trainer/Policy mu Mean              0.125184
trainer/Policy mu Std               0.749427
trainer/Policy mu Max               2.95782
trainer/Policy mu Min              -2.54582
trainer/Policy log std Mean        -1.96153
trainer/Policy log std Std          0.554908
trainer/Policy log std Max         -0.438097
trainer/Policy log std Min         -2.73391
trainer/Alpha                       0.0624999
trainer/Alpha Loss                  0.0696891
exploration/num steps total     95700
exploration/num paths total       957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19865
exploration/Rewards Std             1.09146
exploration/Rewards Max            -0.413132
exploration/Rewards Min            -9.59566
exploration/Returns Mean         -119.865
exploration/Returns Std            21.1653
exploration/Returns Max           -94.6508
exploration/Returns Min          -159.059
exploration/Actions Mean           -0.00612679
exploration/Actions Std             0.25858
exploration/Actions Max             0.999567
exploration/Actions Min            -0.999714
exploration/Num Paths               5
exploration/Average Returns      -119.865
evaluation/num steps total     286500
evaluation/num paths total       2865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.926348
evaluation/Rewards Std              1.00318
evaluation/Rewards Max             -0.0352346
evaluation/Rewards Min             -9.88787
evaluation/Returns Mean           -92.6348
evaluation/Returns Std             63.2367
evaluation/Returns Max             -7.39842
evaluation/Returns Min           -262.806
evaluation/Actions Mean             0.0080165
evaluation/Actions Std              0.186044
evaluation/Actions Max              0.998222
evaluation/Actions Min             -0.998614
evaluation/Num Paths               15
evaluation/Average Returns        -92.6348
time/data storing (s)               0.00280268
time/evaluation sampling (s)        0.335326
time/exploration sampling (s)       0.136694
time/logging (s)                    0.00439105
time/saving (s)                     0.00158506
time/training (s)                   1.93912
time/epoch (s)                      2.41992
time/total (s)                    465.619
Epoch                             190
-----------------------------  ---------------
2019-04-23 00:01:07.484778 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 191 finished
-----------------------------  ---------------
replay_buffer/size              96200
trainer/QF1 Loss                    1.75078
trainer/QF2 Loss                    1.78097
trainer/Policy Loss                51.5258
trainer/Q1 Predictions Mean       -50.1624
trainer/Q1 Predictions Std         34.0791
trainer/Q1 Predictions Max         -9.7951
trainer/Q1 Predictions Min       -134.748
trainer/Q2 Predictions Mean       -50.1227
trainer/Q2 Predictions Std         34.0496
trainer/Q2 Predictions Max         -9.83074
trainer/Q2 Predictions Min       -133.775
trainer/Q Targets Mean            -50.1293
trainer/Q Targets Std              34.4107
trainer/Q Targets Max              -0.0965726
trainer/Q Targets Min            -134.611
trainer/Log Pis Mean                2.10314
trainer/Log Pis Std                 1.34118
trainer/Log Pis Max                 6.79942
trainer/Log Pis Min                -1.25164
trainer/Policy mu Mean              0.162785
trainer/Policy mu Std               0.886641
trainer/Policy mu Max               2.97098
trainer/Policy mu Min              -2.90847
trainer/Policy log std Mean        -1.84784
trainer/Policy log std Std          0.623445
trainer/Policy log std Max         -0.357494
trainer/Policy log std Min         -2.76261
trainer/Alpha                       0.061864
trainer/Alpha Loss                  0.28703
exploration/num steps total     96200
exploration/num paths total       962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.13013
exploration/Rewards Std             0.980182
exploration/Rewards Max            -0.0122729
exploration/Rewards Min            -7.30621
exploration/Returns Mean         -113.013
exploration/Returns Std            72.7328
exploration/Returns Max           -16.7903
exploration/Returns Min          -178.934
exploration/Actions Mean            0.0233816
exploration/Actions Std             0.245939
exploration/Actions Max             0.999285
exploration/Actions Min            -0.964826
exploration/Num Paths               5
exploration/Average Returns      -113.013
evaluation/num steps total     288000
evaluation/num paths total       2880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04077
evaluation/Rewards Std              1.12611
evaluation/Rewards Max             -0.00966245
evaluation/Rewards Min             -9.97509
evaluation/Returns Mean          -104.077
evaluation/Returns Std             77.3045
evaluation/Returns Max             -5.8808
evaluation/Returns Min           -261.384
evaluation/Actions Mean             0.00191982
evaluation/Actions Std              0.179818
evaluation/Actions Max              0.995572
evaluation/Actions Min             -0.998503
evaluation/Num Paths               15
evaluation/Average Returns       -104.077
time/data storing (s)               0.00288139
time/evaluation sampling (s)        0.332867
time/exploration sampling (s)       0.136834
time/logging (s)                    0.00478704
time/saving (s)                     0.00194498
time/training (s)                   1.93441
time/epoch (s)                      2.41372
time/total (s)                    468.037
Epoch                             191
-----------------------------  ---------------
2019-04-23 00:01:09.876439 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 192 finished
-----------------------------  ----------------
replay_buffer/size              96700
trainer/QF1 Loss                   19.8279
trainer/QF2 Loss                   19.4189
trainer/Policy Loss                57.974
trainer/Q1 Predictions Mean       -56.5309
trainer/Q1 Predictions Std         33.7846
trainer/Q1 Predictions Max         -9.46888
trainer/Q1 Predictions Min       -144.44
trainer/Q2 Predictions Mean       -56.5123
trainer/Q2 Predictions Std         33.7781
trainer/Q2 Predictions Max         -9.44662
trainer/Q2 Predictions Min       -144.027
trainer/Q Targets Mean            -56.4155
trainer/Q Targets Std              34.6204
trainer/Q Targets Max              -0.347949
trainer/Q Targets Min            -145.379
trainer/Log Pis Mean                2.19281
trainer/Log Pis Std                 1.32746
trainer/Log Pis Max                 7.0282
trainer/Log Pis Min                -0.577983
trainer/Policy mu Mean              0.0811346
trainer/Policy mu Std               0.868514
trainer/Policy mu Max               3.05371
trainer/Policy mu Min              -2.79487
trainer/Policy log std Mean        -1.90216
trainer/Policy log std Std          0.576156
trainer/Policy log std Max         -0.368815
trainer/Policy log std Min         -2.84403
trainer/Alpha                       0.0622127
trainer/Alpha Loss                  0.535474
exploration/num steps total     96700
exploration/num paths total       967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.757763
exploration/Rewards Std             0.778441
exploration/Rewards Max            -0.00943516
exploration/Rewards Min            -7.50117
exploration/Returns Mean          -75.7763
exploration/Returns Std            44.4861
exploration/Returns Max           -37.8118
exploration/Returns Min          -159.268
exploration/Actions Mean            0.0067602
exploration/Actions Std             0.216962
exploration/Actions Max             0.998141
exploration/Actions Min            -0.998666
exploration/Num Paths               5
exploration/Average Returns       -75.7763
evaluation/num steps total     289500
evaluation/num paths total       2895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.995496
evaluation/Rewards Std              1.01891
evaluation/Rewards Max             -0.101685
evaluation/Rewards Min             -9.18547
evaluation/Returns Mean           -99.5496
evaluation/Returns Std             62.0712
evaluation/Returns Max            -20.6012
evaluation/Returns Min           -267.176
evaluation/Actions Mean             0.000646262
evaluation/Actions Std              0.180117
evaluation/Actions Max              0.998353
evaluation/Actions Min             -0.99957
evaluation/Num Paths               15
evaluation/Average Returns        -99.5496
time/data storing (s)               0.00284432
time/evaluation sampling (s)        0.328345
time/exploration sampling (s)       0.136449
time/logging (s)                    0.00479289
time/saving (s)                     0.00196906
time/training (s)                   1.90989
time/epoch (s)                      2.38429
time/total (s)                    470.425
Epoch                             192
-----------------------------  ----------------
2019-04-23 00:01:12.301085 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 193 finished
-----------------------------  ---------------
replay_buffer/size              97200
trainer/QF1 Loss                   11.4059
trainer/QF2 Loss                   11.7404
trainer/Policy Loss                48.9681
trainer/Q1 Predictions Mean       -47.4174
trainer/Q1 Predictions Std         33.6081
trainer/Q1 Predictions Max         -9.77444
trainer/Q1 Predictions Min       -158.635
trainer/Q2 Predictions Mean       -47.4561
trainer/Q2 Predictions Std         33.5276
trainer/Q2 Predictions Max         -9.85421
trainer/Q2 Predictions Min       -156.805
trainer/Q Targets Mean            -46.9637
trainer/Q Targets Std              34.2639
trainer/Q Targets Max              -0.223179
trainer/Q Targets Min            -160.293
trainer/Log Pis Mean                2.2365
trainer/Log Pis Std                 1.49561
trainer/Log Pis Max                 7.29386
trainer/Log Pis Min                -1.26305
trainer/Policy mu Mean             -0.0307243
trainer/Policy mu Std               0.88505
trainer/Policy mu Max               3.45711
trainer/Policy mu Min              -3.01659
trainer/Policy log std Mean        -1.96244
trainer/Policy log std Std          0.572293
trainer/Policy log std Max         -0.345543
trainer/Policy log std Min         -2.87657
trainer/Alpha                       0.0614791
trainer/Alpha Loss                  0.659649
exploration/num steps total     97200
exploration/num paths total       972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03631
exploration/Rewards Std             1.13315
exploration/Rewards Max            -0.258036
exploration/Rewards Min           -10.9526
exploration/Returns Mean         -103.631
exploration/Returns Std            48.8557
exploration/Returns Max           -49.6713
exploration/Returns Min          -183.739
exploration/Actions Mean            0.0309982
exploration/Actions Std             0.22683
exploration/Actions Max             0.999631
exploration/Actions Min            -0.973966
exploration/Num Paths               5
exploration/Average Returns      -103.631
evaluation/num steps total     291000
evaluation/num paths total       2910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.22743
evaluation/Rewards Std              1.15757
evaluation/Rewards Max             -0.116063
evaluation/Rewards Min            -10.0154
evaluation/Returns Mean          -122.743
evaluation/Returns Std             78.8007
evaluation/Returns Max            -30.6308
evaluation/Returns Min           -271.819
evaluation/Actions Mean            -0.00617909
evaluation/Actions Std              0.187308
evaluation/Actions Max              0.997148
evaluation/Actions Min             -0.999093
evaluation/Num Paths               15
evaluation/Average Returns       -122.743
time/data storing (s)               0.00280725
time/evaluation sampling (s)        0.323924
time/exploration sampling (s)       0.138137
time/logging (s)                    0.00429634
time/saving (s)                     0.0100134
time/training (s)                   1.93754
time/epoch (s)                      2.41671
time/total (s)                    472.846
Epoch                             193
-----------------------------  ---------------
2019-04-23 00:01:14.705927 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 194 finished
-----------------------------  ---------------
replay_buffer/size              97700
trainer/QF1 Loss                    0.917667
trainer/QF2 Loss                    0.75371
trainer/Policy Loss                47.4993
trainer/Q1 Predictions Mean       -46.1792
trainer/Q1 Predictions Std         32.9147
trainer/Q1 Predictions Max         -9.29063
trainer/Q1 Predictions Min       -130.697
trainer/Q2 Predictions Mean       -46.2521
trainer/Q2 Predictions Std         32.9645
trainer/Q2 Predictions Max         -9.35364
trainer/Q2 Predictions Min       -131.211
trainer/Q Targets Mean            -46.8265
trainer/Q Targets Std              33.4025
trainer/Q Targets Max              -9.50423
trainer/Q Targets Min            -134.307
trainer/Log Pis Mean                2.0035
trainer/Log Pis Std                 1.47875
trainer/Log Pis Max                 5.82832
trainer/Log Pis Min                -4.39703
trainer/Policy mu Mean             -0.0353528
trainer/Policy mu Std               0.936871
trainer/Policy mu Max               2.88843
trainer/Policy mu Min              -3.17966
trainer/Policy log std Mean        -1.81293
trainer/Policy log std Std          0.59126
trainer/Policy log std Max         -0.389139
trainer/Policy log std Min         -2.76671
trainer/Alpha                       0.0618644
trainer/Alpha Loss                  0.00974585
exploration/num steps total     97700
exploration/num paths total       977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.25379
exploration/Rewards Std             1.277
exploration/Rewards Max            -0.0134531
exploration/Rewards Min            -8.76665
exploration/Returns Mean         -125.379
exploration/Returns Std            86.2055
exploration/Returns Max           -37.5108
exploration/Returns Min          -262.504
exploration/Actions Mean           -0.00423477
exploration/Actions Std             0.256847
exploration/Actions Max             0.996569
exploration/Actions Min            -0.998661
exploration/Num Paths               5
exploration/Average Returns      -125.379
evaluation/num steps total     292500
evaluation/num paths total       2925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.10959
evaluation/Rewards Std              0.987022
evaluation/Rewards Max             -0.222873
evaluation/Rewards Min            -10.771
evaluation/Returns Mean          -110.959
evaluation/Returns Std             47.718
evaluation/Returns Max            -28.608
evaluation/Returns Min           -196.006
evaluation/Actions Mean            -0.00762974
evaluation/Actions Std              0.201155
evaluation/Actions Max              0.997849
evaluation/Actions Min             -0.999707
evaluation/Num Paths               15
evaluation/Average Returns       -110.959
time/data storing (s)               0.00302332
time/evaluation sampling (s)        0.32973
time/exploration sampling (s)       0.138787
time/logging (s)                    0.0048524
time/saving (s)                     0.00199841
time/training (s)                   1.92119
time/epoch (s)                      2.39958
time/total (s)                    475.249
Epoch                             194
-----------------------------  ---------------
2019-04-23 00:01:17.133111 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 195 finished
-----------------------------  ---------------
replay_buffer/size              98200
trainer/QF1 Loss                    0.29547
trainer/QF2 Loss                    0.315638
trainer/Policy Loss                57.6854
trainer/Q1 Predictions Mean       -56.4367
trainer/Q1 Predictions Std         33.54
trainer/Q1 Predictions Max         -9.33127
trainer/Q1 Predictions Min       -136.143
trainer/Q2 Predictions Mean       -56.3993
trainer/Q2 Predictions Std         33.4979
trainer/Q2 Predictions Max         -9.31721
trainer/Q2 Predictions Min       -135.529
trainer/Q Targets Mean            -56.7731
trainer/Q Targets Std              33.6961
trainer/Q Targets Max              -9.51913
trainer/Q Targets Min            -136.502
trainer/Log Pis Mean                1.95804
trainer/Log Pis Std                 1.48861
trainer/Log Pis Max                 6.16297
trainer/Log Pis Min                -4.17671
trainer/Policy mu Mean             -0.0122073
trainer/Policy mu Std               0.984805
trainer/Policy mu Max               2.85257
trainer/Policy mu Min              -3.08637
trainer/Policy log std Mean        -1.76724
trainer/Policy log std Std          0.65159
trainer/Policy log std Max         -0.267806
trainer/Policy log std Min         -2.66507
trainer/Alpha                       0.0618617
trainer/Alpha Loss                 -0.116769
exploration/num steps total     98200
exploration/num paths total       982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.38408
exploration/Rewards Std             1.01203
exploration/Rewards Max            -0.223081
exploration/Rewards Min            -7.83178
exploration/Returns Mean         -138.408
exploration/Returns Std            71.4401
exploration/Returns Max           -60.7566
exploration/Returns Min          -239.98
exploration/Actions Mean           -0.0105086
exploration/Actions Std             0.241364
exploration/Actions Max             0.991167
exploration/Actions Min            -0.999883
exploration/Num Paths               5
exploration/Average Returns      -138.408
evaluation/num steps total     294000
evaluation/num paths total       2940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.33216
evaluation/Rewards Std              0.88051
evaluation/Rewards Max             -0.0671952
evaluation/Rewards Min             -8.37756
evaluation/Returns Mean          -133.216
evaluation/Returns Std             63.0789
evaluation/Returns Max            -16.9964
evaluation/Returns Min           -229.842
evaluation/Actions Mean             0.00231373
evaluation/Actions Std              0.167777
evaluation/Actions Max              0.997352
evaluation/Actions Min             -0.999099
evaluation/Num Paths               15
evaluation/Average Returns       -133.216
time/data storing (s)               0.00294607
time/evaluation sampling (s)        0.327486
time/exploration sampling (s)       0.135971
time/logging (s)                    0.0048123
time/saving (s)                     0.00203481
time/training (s)                   1.94609
time/epoch (s)                      2.41934
time/total (s)                    477.673
Epoch                             195
-----------------------------  ---------------
2019-04-23 00:01:19.551796 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 196 finished
-----------------------------  ---------------
replay_buffer/size              98700
trainer/QF1 Loss                   65.7699
trainer/QF2 Loss                   65.807
trainer/Policy Loss                52.6584
trainer/Q1 Predictions Mean       -51.5255
trainer/Q1 Predictions Std         37.241
trainer/Q1 Predictions Max         -9.29238
trainer/Q1 Predictions Min       -160.229
trainer/Q2 Predictions Mean       -51.5308
trainer/Q2 Predictions Std         37.2165
trainer/Q2 Predictions Max         -9.32131
trainer/Q2 Predictions Min       -159.972
trainer/Q Targets Mean            -50.7799
trainer/Q Targets Std              38.115
trainer/Q Targets Max              -0.251084
trainer/Q Targets Min            -159.721
trainer/Log Pis Mean                1.95451
trainer/Log Pis Std                 1.72923
trainer/Log Pis Max                 6.05551
trainer/Log Pis Min                -4.88159
trainer/Policy mu Mean             -0.0118026
trainer/Policy mu Std               0.912595
trainer/Policy mu Max               2.9557
trainer/Policy mu Min              -3.07841
trainer/Policy log std Mean        -1.85802
trainer/Policy log std Std          0.598111
trainer/Policy log std Max         -0.361973
trainer/Policy log std Min         -2.80284
trainer/Alpha                       0.0619419
trainer/Alpha Loss                 -0.126528
exploration/num steps total     98700
exploration/num paths total       987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.791334
exploration/Rewards Std             1.39226
exploration/Rewards Max            -0.008357
exploration/Rewards Min           -10.3575
exploration/Returns Mean          -79.1334
exploration/Returns Std            36.7067
exploration/Returns Max           -19.1584
exploration/Returns Min          -132.901
exploration/Actions Mean            0.0159887
exploration/Actions Std             0.238735
exploration/Actions Max             0.999674
exploration/Actions Min            -0.999714
exploration/Num Paths               5
exploration/Average Returns       -79.1334
evaluation/num steps total     295500
evaluation/num paths total       2955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04738
evaluation/Rewards Std              1.21007
evaluation/Rewards Max             -0.0777144
evaluation/Rewards Min            -10.6478
evaluation/Returns Mean          -104.738
evaluation/Returns Std             80.5039
evaluation/Returns Max             -7.91149
evaluation/Returns Min           -274.393
evaluation/Actions Mean            -0.0098013
evaluation/Actions Std              0.19924
evaluation/Actions Max              0.999005
evaluation/Actions Min             -0.999512
evaluation/Num Paths               15
evaluation/Average Returns       -104.738
time/data storing (s)               0.0028661
time/evaluation sampling (s)        0.329233
time/exploration sampling (s)       0.136158
time/logging (s)                    0.00480868
time/saving (s)                     0.00156592
time/training (s)                   1.9363
time/epoch (s)                      2.41093
time/total (s)                    480.088
Epoch                             196
-----------------------------  ---------------
2019-04-23 00:01:21.981297 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 197 finished
-----------------------------  ---------------
replay_buffer/size              99200
trainer/QF1 Loss                   54.8611
trainer/QF2 Loss                   55.0139
trainer/Policy Loss                57.3292
trainer/Q1 Predictions Mean       -55.9072
trainer/Q1 Predictions Std         34.5872
trainer/Q1 Predictions Max         -9.15003
trainer/Q1 Predictions Min       -126.676
trainer/Q2 Predictions Mean       -55.8759
trainer/Q2 Predictions Std         34.5651
trainer/Q2 Predictions Max         -9.1825
trainer/Q2 Predictions Min       -126.313
trainer/Q Targets Mean            -55.6984
trainer/Q Targets Std              35.0938
trainer/Q Targets Max              -2.30818
trainer/Q Targets Min            -128.025
trainer/Log Pis Mean                2.04629
trainer/Log Pis Std                 1.31323
trainer/Log Pis Max                 5.30627
trainer/Log Pis Min                -1.82749
trainer/Policy mu Mean             -0.0464929
trainer/Policy mu Std               0.866314
trainer/Policy mu Max               2.65676
trainer/Policy mu Min              -2.91979
trainer/Policy log std Mean        -1.90245
trainer/Policy log std Std          0.574501
trainer/Policy log std Max         -0.501978
trainer/Policy log std Min         -2.74889
trainer/Alpha                       0.0623671
trainer/Alpha Loss                  0.128446
exploration/num steps total     99200
exploration/num paths total       992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.27708
exploration/Rewards Std             1.16188
exploration/Rewards Max            -0.0187783
exploration/Rewards Min            -8.84078
exploration/Returns Mean         -127.708
exploration/Returns Std            84.5102
exploration/Returns Max           -19.4084
exploration/Returns Min          -262.78
exploration/Actions Mean            0.00148409
exploration/Actions Std             0.232426
exploration/Actions Max             0.999193
exploration/Actions Min            -0.999271
exploration/Num Paths               5
exploration/Average Returns      -127.708
evaluation/num steps total     297000
evaluation/num paths total       2970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.99022
evaluation/Rewards Std              1.06859
evaluation/Rewards Max             -0.0222785
evaluation/Rewards Min             -8.87597
evaluation/Returns Mean           -99.022
evaluation/Returns Std             63.2554
evaluation/Returns Max            -28.4043
evaluation/Returns Min           -236.629
evaluation/Actions Mean            -0.00610821
evaluation/Actions Std              0.185212
evaluation/Actions Max              0.997789
evaluation/Actions Min             -0.999816
evaluation/Num Paths               15
evaluation/Average Returns        -99.022
time/data storing (s)               0.00287903
time/evaluation sampling (s)        0.324372
time/exploration sampling (s)       0.140861
time/logging (s)                    0.00477396
time/saving (s)                     0.00196781
time/training (s)                   1.94807
time/epoch (s)                      2.42292
time/total (s)                    482.515
Epoch                             197
-----------------------------  ---------------
2019-04-23 00:01:24.413334 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 198 finished
-----------------------------  ----------------
replay_buffer/size              99700
trainer/QF1 Loss                    1.63227
trainer/QF2 Loss                    1.85701
trainer/Policy Loss                48.9102
trainer/Q1 Predictions Mean       -47.4152
trainer/Q1 Predictions Std         31.989
trainer/Q1 Predictions Max         -9.18945
trainer/Q1 Predictions Min       -125.506
trainer/Q2 Predictions Mean       -47.4149
trainer/Q2 Predictions Std         32.0074
trainer/Q2 Predictions Max         -9.08093
trainer/Q2 Predictions Min       -125.288
trainer/Q Targets Mean            -47.6187
trainer/Q Targets Std              32.3271
trainer/Q Targets Max              -0.279664
trainer/Q Targets Min            -127.023
trainer/Log Pis Mean                2.0976
trainer/Log Pis Std                 1.49425
trainer/Log Pis Max                 8.90066
trainer/Log Pis Min                -2.99557
trainer/Policy mu Mean             -0.0686317
trainer/Policy mu Std               0.904276
trainer/Policy mu Max               2.79115
trainer/Policy mu Min              -3.20408
trainer/Policy log std Mean        -1.85177
trainer/Policy log std Std          0.594333
trainer/Policy log std Max         -0.207218
trainer/Policy log std Min         -2.76797
trainer/Alpha                       0.0619972
trainer/Alpha Loss                  0.271377
exploration/num steps total     99700
exploration/num paths total       997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.835919
exploration/Rewards Std             1.14772
exploration/Rewards Max            -0.0157124
exploration/Rewards Min            -9.45948
exploration/Returns Mean          -83.5919
exploration/Returns Std            53.2809
exploration/Returns Max           -49.5646
exploration/Returns Min          -189.868
exploration/Actions Mean            0.0265838
exploration/Actions Std             0.246741
exploration/Actions Max             0.99991
exploration/Actions Min            -0.997821
exploration/Num Paths               5
exploration/Average Returns       -83.5919
evaluation/num steps total     298500
evaluation/num paths total       2985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.875317
evaluation/Rewards Std              1.07707
evaluation/Rewards Max             -0.0265702
evaluation/Rewards Min            -10.2238
evaluation/Returns Mean           -87.5317
evaluation/Returns Std             65.7239
evaluation/Returns Max            -11.1424
evaluation/Returns Min           -252.373
evaluation/Actions Mean             0.000489614
evaluation/Actions Std              0.172642
evaluation/Actions Max              0.998297
evaluation/Actions Min             -0.998589
evaluation/Num Paths               15
evaluation/Average Returns        -87.5317
time/data storing (s)               0.00280512
time/evaluation sampling (s)        0.334002
time/exploration sampling (s)       0.135478
time/logging (s)                    0.00480923
time/saving (s)                     0.00158441
time/training (s)                   1.94621
time/epoch (s)                      2.42489
time/total (s)                    484.944
Epoch                             198
-----------------------------  ----------------
2019-04-23 00:01:26.842432 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 199 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.738612
trainer/QF2 Loss                    0.681923
trainer/Policy Loss                50.1621
trainer/Q1 Predictions Mean       -48.4835
trainer/Q1 Predictions Std         32.5777
trainer/Q1 Predictions Max         -9.25912
trainer/Q1 Predictions Min       -129.061
trainer/Q2 Predictions Mean       -48.5443
trainer/Q2 Predictions Std         32.5923
trainer/Q2 Predictions Max         -9.39922
trainer/Q2 Predictions Min       -128.843
trainer/Q Targets Mean            -48.9969
trainer/Q Targets Std              33.0833
trainer/Q Targets Max              -9.38302
trainer/Q Targets Min            -130.756
trainer/Log Pis Mean                2.05596
trainer/Log Pis Std                 1.19096
trainer/Log Pis Max                 6.30164
trainer/Log Pis Min                -1.55318
trainer/Policy mu Mean              0.141339
trainer/Policy mu Std               0.875141
trainer/Policy mu Max               3.13984
trainer/Policy mu Min              -2.94411
trainer/Policy log std Mean        -1.81138
trainer/Policy log std Std          0.570716
trainer/Policy log std Max         -0.38344
trainer/Policy log std Min         -2.74248
trainer/Alpha                       0.0608111
trainer/Alpha Loss                  0.156689
exploration/num steps total    100200
exploration/num paths total      1002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00744
exploration/Rewards Std             1.08695
exploration/Rewards Max            -0.19269
exploration/Rewards Min            -6.81712
exploration/Returns Mean         -100.744
exploration/Returns Std            78.1422
exploration/Returns Max           -56.335
exploration/Returns Min          -256.874
exploration/Actions Mean           -0.0138963
exploration/Actions Std             0.221043
exploration/Actions Max             0.992704
exploration/Actions Min            -0.999515
exploration/Num Paths               5
exploration/Average Returns      -100.744
evaluation/num steps total     300000
evaluation/num paths total       3000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.999585
evaluation/Rewards Std              1.00517
evaluation/Rewards Max             -0.0788775
evaluation/Rewards Min             -9.05422
evaluation/Returns Mean           -99.9585
evaluation/Returns Std             66.7023
evaluation/Returns Max            -14.6817
evaluation/Returns Min           -263.161
evaluation/Actions Mean             0.00790654
evaluation/Actions Std              0.176561
evaluation/Actions Max              0.997829
evaluation/Actions Min             -0.998681
evaluation/Num Paths               15
evaluation/Average Returns        -99.9585
time/data storing (s)               0.00280974
time/evaluation sampling (s)        0.314683
time/exploration sampling (s)       0.141226
time/logging (s)                    0.00478749
time/saving (s)                     0.00196012
time/training (s)                   1.95624
time/epoch (s)                      2.4217
time/total (s)                    487.37
Epoch                             199
-----------------------------  ---------------
2019-04-23 00:01:29.274974 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 200 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.44501
trainer/QF2 Loss                    0.504466
trainer/Policy Loss                53.5848
trainer/Q1 Predictions Mean       -52.4072
trainer/Q1 Predictions Std         33.8087
trainer/Q1 Predictions Max         -9.48808
trainer/Q1 Predictions Min       -134.636
trainer/Q2 Predictions Mean       -52.3803
trainer/Q2 Predictions Std         33.8013
trainer/Q2 Predictions Max         -9.55519
trainer/Q2 Predictions Min       -134.351
trainer/Q Targets Mean            -52.77
trainer/Q Targets Std              34.1322
trainer/Q Targets Max              -9.37379
trainer/Q Targets Min            -136.365
trainer/Log Pis Mean                1.77364
trainer/Log Pis Std                 1.59089
trainer/Log Pis Max                 7.42905
trainer/Log Pis Min                -3.06022
trainer/Policy mu Mean              0.0858988
trainer/Policy mu Std               0.926126
trainer/Policy mu Max               3.05803
trainer/Policy mu Min              -2.8063
trainer/Policy log std Mean        -1.80568
trainer/Policy log std Std          0.580837
trainer/Policy log std Max         -0.37833
trainer/Policy log std Min         -2.77333
trainer/Alpha                       0.0597501
trainer/Alpha Loss                 -0.637754
exploration/num steps total    100700
exploration/num paths total      1007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.13026
exploration/Rewards Std             1.20428
exploration/Rewards Max            -0.0169004
exploration/Rewards Min            -8.86748
exploration/Returns Mean         -113.026
exploration/Returns Std            86.3454
exploration/Returns Max           -29.6688
exploration/Returns Min          -259.8
exploration/Actions Mean            0.0211847
exploration/Actions Std             0.261083
exploration/Actions Max             0.999403
exploration/Actions Min            -0.993992
exploration/Num Paths               5
exploration/Average Returns      -113.026
evaluation/num steps total     301500
evaluation/num paths total       3015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.831059
evaluation/Rewards Std              1.1765
evaluation/Rewards Max             -0.0461262
evaluation/Rewards Min            -12.0224
evaluation/Returns Mean           -83.1059
evaluation/Returns Std             46.7867
evaluation/Returns Max             -6.91057
evaluation/Returns Min           -166.627
evaluation/Actions Mean             0.011654
evaluation/Actions Std              0.203942
evaluation/Actions Max              0.998841
evaluation/Actions Min             -0.999384
evaluation/Num Paths               15
evaluation/Average Returns        -83.1059
time/data storing (s)               0.00266434
time/evaluation sampling (s)        0.324376
time/exploration sampling (s)       0.139941
time/logging (s)                    0.00478192
time/saving (s)                     0.00196043
time/training (s)                   1.9521
time/epoch (s)                      2.42582
time/total (s)                    489.799
Epoch                             200
-----------------------------  ---------------
2019-04-23 00:01:31.677995 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 201 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.532536
trainer/QF2 Loss                    0.534764
trainer/Policy Loss                55.5654
trainer/Q1 Predictions Mean       -54.0244
trainer/Q1 Predictions Std         35.3578
trainer/Q1 Predictions Max         -9.58168
trainer/Q1 Predictions Min       -141.842
trainer/Q2 Predictions Mean       -54.0789
trainer/Q2 Predictions Std         35.3385
trainer/Q2 Predictions Max         -9.60688
trainer/Q2 Predictions Min       -142.242
trainer/Q Targets Mean            -54.3302
trainer/Q Targets Std              35.4935
trainer/Q Targets Max              -9.34379
trainer/Q Targets Min            -141.716
trainer/Log Pis Mean                2.19498
trainer/Log Pis Std                 1.41601
trainer/Log Pis Max                 8.29658
trainer/Log Pis Min                -1.26228
trainer/Policy mu Mean             -0.00346466
trainer/Policy mu Std               1.00144
trainer/Policy mu Max               2.76849
trainer/Policy mu Min              -2.85005
trainer/Policy log std Mean        -1.77879
trainer/Policy log std Std          0.658211
trainer/Policy log std Max         -0.252234
trainer/Policy log std Min         -2.72696
trainer/Alpha                       0.0593106
trainer/Alpha Loss                  0.550829
exploration/num steps total    101200
exploration/num paths total      1012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.07024
exploration/Rewards Std             1.26345
exploration/Rewards Max            -0.0114738
exploration/Rewards Min           -11.6788
exploration/Returns Mean         -107.024
exploration/Returns Std            42.4461
exploration/Returns Max           -51.4043
exploration/Returns Min          -147.568
exploration/Actions Mean            0.00473805
exploration/Actions Std             0.259793
exploration/Actions Max             0.999765
exploration/Actions Min            -0.994584
exploration/Num Paths               5
exploration/Average Returns      -107.024
evaluation/num steps total     303000
evaluation/num paths total       3030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.823735
evaluation/Rewards Std              1.03132
evaluation/Rewards Max             -0.0164114
evaluation/Rewards Min             -9.6653
evaluation/Returns Mean           -82.3735
evaluation/Returns Std             62.9452
evaluation/Returns Max             -5.75522
evaluation/Returns Min           -241.455
evaluation/Actions Mean            -0.0185613
evaluation/Actions Std              0.181025
evaluation/Actions Max              0.996802
evaluation/Actions Min             -0.999823
evaluation/Num Paths               15
evaluation/Average Returns        -82.3735
time/data storing (s)               0.00267267
time/evaluation sampling (s)        0.325277
time/exploration sampling (s)       0.140742
time/logging (s)                    0.0048349
time/saving (s)                     0.00196844
time/training (s)                   1.9198
time/epoch (s)                      2.3953
time/total (s)                    492.199
Epoch                             201
-----------------------------  ---------------
2019-04-23 00:01:34.106802 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 202 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   10.7092
trainer/QF2 Loss                   10.6493
trainer/Policy Loss                52.3294
trainer/Q1 Predictions Mean       -51.0903
trainer/Q1 Predictions Std         31.6983
trainer/Q1 Predictions Max         -9.19042
trainer/Q1 Predictions Min       -131.152
trainer/Q2 Predictions Mean       -51.1053
trainer/Q2 Predictions Std         31.6788
trainer/Q2 Predictions Max         -9.27309
trainer/Q2 Predictions Min       -130.993
trainer/Q Targets Mean            -51.1288
trainer/Q Targets Std              32.6198
trainer/Q Targets Max              -0.122477
trainer/Q Targets Min            -132.062
trainer/Log Pis Mean                1.95326
trainer/Log Pis Std                 1.41039
trainer/Log Pis Max                 7.75958
trainer/Log Pis Min                -1.82082
trainer/Policy mu Mean              0.0677659
trainer/Policy mu Std               0.954452
trainer/Policy mu Max               2.98592
trainer/Policy mu Min              -2.92458
trainer/Policy log std Mean        -1.78111
trainer/Policy log std Std          0.643928
trainer/Policy log std Max         -0.463531
trainer/Policy log std Min         -2.79561
trainer/Alpha                       0.0587646
trainer/Alpha Loss                 -0.132468
exploration/num steps total    101700
exploration/num paths total      1017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.877739
exploration/Rewards Std             1.19841
exploration/Rewards Max            -0.00436025
exploration/Rewards Min           -10.4642
exploration/Returns Mean          -87.7739
exploration/Returns Std            66.5038
exploration/Returns Max           -16.0661
exploration/Returns Min          -169.772
exploration/Actions Mean            0.0162682
exploration/Actions Std             0.258456
exploration/Actions Max             0.998394
exploration/Actions Min            -0.996131
exploration/Num Paths               5
exploration/Average Returns       -87.7739
evaluation/num steps total     304500
evaluation/num paths total       3045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21554
evaluation/Rewards Std              1.21964
evaluation/Rewards Max             -0.0258879
evaluation/Rewards Min            -11.9511
evaluation/Returns Mean          -121.554
evaluation/Returns Std             79.186
evaluation/Returns Max            -29.3427
evaluation/Returns Min           -247.549
evaluation/Actions Mean            -0.00436111
evaluation/Actions Std              0.197949
evaluation/Actions Max              0.999271
evaluation/Actions Min             -0.999294
evaluation/Num Paths               15
evaluation/Average Returns       -121.554
time/data storing (s)               0.00284439
time/evaluation sampling (s)        0.325476
time/exploration sampling (s)       0.138937
time/logging (s)                    0.00481372
time/saving (s)                     0.00194608
time/training (s)                   1.94794
time/epoch (s)                      2.42196
time/total (s)                    494.625
Epoch                             202
-----------------------------  ---------------
2019-04-23 00:01:36.554941 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 203 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  138.52
trainer/QF2 Loss                  138.604
trainer/Policy Loss                55.0349
trainer/Q1 Predictions Mean       -53.7475
trainer/Q1 Predictions Std         35.2214
trainer/Q1 Predictions Max         -9.16626
trainer/Q1 Predictions Min       -130.443
trainer/Q2 Predictions Mean       -53.7465
trainer/Q2 Predictions Std         35.2836
trainer/Q2 Predictions Max         -9.25836
trainer/Q2 Predictions Min       -130.012
trainer/Q Targets Mean            -52.6629
trainer/Q Targets Std              35.0735
trainer/Q Targets Max              -2.7671
trainer/Q Targets Min            -129.334
trainer/Log Pis Mean                1.82944
trainer/Log Pis Std                 1.35449
trainer/Log Pis Max                 5.13007
trainer/Log Pis Min                -1.64273
trainer/Policy mu Mean             -0.0799624
trainer/Policy mu Std               0.853232
trainer/Policy mu Max               2.90619
trainer/Policy mu Min              -2.87692
trainer/Policy log std Mean        -1.8756
trainer/Policy log std Std          0.580719
trainer/Policy log std Max         -0.392372
trainer/Policy log std Min         -2.75621
trainer/Alpha                       0.0591915
trainer/Alpha Loss                 -0.482151
exploration/num steps total    102200
exploration/num paths total      1022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.40708
exploration/Rewards Std             0.999728
exploration/Rewards Max            -0.0173132
exploration/Rewards Min            -5.24658
exploration/Returns Mean         -140.708
exploration/Returns Std            89.7143
exploration/Returns Max           -37.1809
exploration/Returns Min          -242.209
exploration/Actions Mean           -0.000254153
exploration/Actions Std             0.191549
exploration/Actions Max             0.999196
exploration/Actions Min            -0.996031
exploration/Num Paths               5
exploration/Average Returns      -140.708
evaluation/num steps total     306000
evaluation/num paths total       3060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.673374
evaluation/Rewards Std              1.03123
evaluation/Rewards Max             -0.0246223
evaluation/Rewards Min             -8.792
evaluation/Returns Mean           -67.3374
evaluation/Returns Std             57.6168
evaluation/Returns Max             -6.49743
evaluation/Returns Min           -242.227
evaluation/Actions Mean            -5.26269e-06
evaluation/Actions Std              0.185377
evaluation/Actions Max              0.999014
evaluation/Actions Min             -0.998602
evaluation/Num Paths               15
evaluation/Average Returns        -67.3374
time/data storing (s)               0.00279251
time/evaluation sampling (s)        0.333891
time/exploration sampling (s)       0.136705
time/logging (s)                    0.00480357
time/saving (s)                     0.00195411
time/training (s)                   1.96023
time/epoch (s)                      2.44037
time/total (s)                    497.07
Epoch                             203
-----------------------------  ----------------
2019-04-23 00:01:38.975919 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 204 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.39196
trainer/QF2 Loss                    6.41749
trainer/Policy Loss                42.1896
trainer/Q1 Predictions Mean       -40.8093
trainer/Q1 Predictions Std         28.8085
trainer/Q1 Predictions Max         -9.19867
trainer/Q1 Predictions Min       -128.226
trainer/Q2 Predictions Mean       -40.8488
trainer/Q2 Predictions Std         28.7689
trainer/Q2 Predictions Max         -9.36396
trainer/Q2 Predictions Min       -127.576
trainer/Q Targets Mean            -40.8649
trainer/Q Targets Std              29.3569
trainer/Q Targets Max              -0.442075
trainer/Q Targets Min            -131.353
trainer/Log Pis Mean                1.91105
trainer/Log Pis Std                 1.31901
trainer/Log Pis Max                 5.56646
trainer/Log Pis Min                -2.9015
trainer/Policy mu Mean             -0.054671
trainer/Policy mu Std               0.796618
trainer/Policy mu Max               3.06413
trainer/Policy mu Min              -2.74536
trainer/Policy log std Mean        -1.91387
trainer/Policy log std Std          0.576277
trainer/Policy log std Max         -0.332273
trainer/Policy log std Min         -2.82595
trainer/Alpha                       0.0575055
trainer/Alpha Loss                 -0.254023
exploration/num steps total    102700
exploration/num paths total      1027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.593903
exploration/Rewards Std             0.575606
exploration/Rewards Max            -0.00126343
exploration/Rewards Min            -4.30073
exploration/Returns Mean          -59.3903
exploration/Returns Std            41.5686
exploration/Returns Max           -23.5197
exploration/Returns Min          -137.818
exploration/Actions Mean           -0.00172644
exploration/Actions Std             0.200839
exploration/Actions Max             0.987215
exploration/Actions Min            -0.990149
exploration/Num Paths               5
exploration/Average Returns       -59.3903
evaluation/num steps total     307500
evaluation/num paths total       3075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.4013
evaluation/Rewards Std              1.23354
evaluation/Rewards Max             -0.0819805
evaluation/Rewards Min            -10.0316
evaluation/Returns Mean          -140.13
evaluation/Returns Std             80.8878
evaluation/Returns Max            -23.3712
evaluation/Returns Min           -274.126
evaluation/Actions Mean            -0.00257447
evaluation/Actions Std              0.203125
evaluation/Actions Max              0.999478
evaluation/Actions Min             -0.999865
evaluation/Num Paths               15
evaluation/Average Returns       -140.13
time/data storing (s)               0.00263347
time/evaluation sampling (s)        0.323722
time/exploration sampling (s)       0.137115
time/logging (s)                    0.00477448
time/saving (s)                     0.00193624
time/training (s)                   1.94291
time/epoch (s)                      2.41309
time/total (s)                    499.487
Epoch                             204
-----------------------------  ---------------
2019-04-23 00:01:41.405333 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 205 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.3309
trainer/QF2 Loss                    1.28274
trainer/Policy Loss                46.2348
trainer/Q1 Predictions Mean       -44.7962
trainer/Q1 Predictions Std         31.9151
trainer/Q1 Predictions Max         -9.07951
trainer/Q1 Predictions Min       -120.283
trainer/Q2 Predictions Mean       -44.78
trainer/Q2 Predictions Std         31.9115
trainer/Q2 Predictions Max         -9.04861
trainer/Q2 Predictions Min       -120.069
trainer/Q Targets Mean            -45.1474
trainer/Q Targets Std              32.2825
trainer/Q Targets Max              -0.0472254
trainer/Q Targets Min            -121.05
trainer/Log Pis Mean                1.93372
trainer/Log Pis Std                 1.17888
trainer/Log Pis Max                 4.21621
trainer/Log Pis Min                -2.55903
trainer/Policy mu Mean             -0.00119859
trainer/Policy mu Std               0.775537
trainer/Policy mu Max               2.25935
trainer/Policy mu Min              -2.92766
trainer/Policy log std Mean        -1.98939
trainer/Policy log std Std          0.553764
trainer/Policy log std Max         -0.26085
trainer/Policy log std Min         -2.78397
trainer/Alpha                       0.0560773
trainer/Alpha Loss                 -0.190949
exploration/num steps total    103200
exploration/num paths total      1032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.22144
exploration/Rewards Std             1.49003
exploration/Rewards Max            -0.00877492
exploration/Rewards Min            -9.96728
exploration/Returns Mean         -122.144
exploration/Returns Std            91.5178
exploration/Returns Max           -29.4562
exploration/Returns Min          -284.499
exploration/Actions Mean           -0.00129156
exploration/Actions Std             0.255736
exploration/Actions Max             0.999887
exploration/Actions Min            -0.999321
exploration/Num Paths               5
exploration/Average Returns      -122.144
evaluation/num steps total     309000
evaluation/num paths total       3090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.933598
evaluation/Rewards Std              1.13646
evaluation/Rewards Max             -0.0193028
evaluation/Rewards Min            -11.3461
evaluation/Returns Mean           -93.3598
evaluation/Returns Std             64.5537
evaluation/Returns Max             -4.40944
evaluation/Returns Min           -260.611
evaluation/Actions Mean            -0.000989396
evaluation/Actions Std              0.1851
evaluation/Actions Max              0.994895
evaluation/Actions Min             -0.999112
evaluation/Num Paths               15
evaluation/Average Returns        -93.3598
time/data storing (s)               0.00269352
time/evaluation sampling (s)        0.325127
time/exploration sampling (s)       0.139635
time/logging (s)                    0.00482839
time/saving (s)                     0.00196553
time/training (s)                   1.94755
time/epoch (s)                      2.4218
time/total (s)                    501.914
Epoch                             205
-----------------------------  ----------------
2019-04-23 00:01:43.870585 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 206 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.471059
trainer/QF2 Loss                    0.452588
trainer/Policy Loss                47.16
trainer/Q1 Predictions Mean       -45.9075
trainer/Q1 Predictions Std         32.0024
trainer/Q1 Predictions Max         -9.14599
trainer/Q1 Predictions Min       -136.783
trainer/Q2 Predictions Mean       -45.9668
trainer/Q2 Predictions Std         32.0226
trainer/Q2 Predictions Max         -9.2033
trainer/Q2 Predictions Min       -137.702
trainer/Q Targets Mean            -46.3023
trainer/Q Targets Std              32.2065
trainer/Q Targets Max              -9.10867
trainer/Q Targets Min            -135.385
trainer/Log Pis Mean                1.75336
trainer/Log Pis Std                 1.29825
trainer/Log Pis Max                 6.62909
trainer/Log Pis Min                -2.45239
trainer/Policy mu Mean             -0.0422331
trainer/Policy mu Std               0.813372
trainer/Policy mu Max               2.41332
trainer/Policy mu Min              -2.90561
trainer/Policy log std Mean        -1.88805
trainer/Policy log std Std          0.546891
trainer/Policy log std Max         -0.511885
trainer/Policy log std Min         -2.80424
trainer/Alpha                       0.0579617
trainer/Alpha Loss                 -0.702416
exploration/num steps total    103700
exploration/num paths total      1037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.510117
exploration/Rewards Std             0.677715
exploration/Rewards Max            -0.10378
exploration/Rewards Min            -6.81476
exploration/Returns Mean          -51.0117
exploration/Returns Std             5.16775
exploration/Returns Max           -41.1872
exploration/Returns Min           -56.3983
exploration/Actions Mean            0.00107073
exploration/Actions Std             0.209997
exploration/Actions Max             0.999047
exploration/Actions Min            -0.999504
exploration/Num Paths               5
exploration/Average Returns       -51.0117
evaluation/num steps total     310500
evaluation/num paths total       3105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.800021
evaluation/Rewards Std              1.08714
evaluation/Rewards Max             -0.111348
evaluation/Rewards Min             -8.96452
evaluation/Returns Mean           -80.0021
evaluation/Returns Std             62.0652
evaluation/Returns Max            -19.367
evaluation/Returns Min           -263.627
evaluation/Actions Mean            -0.0148353
evaluation/Actions Std              0.18787
evaluation/Actions Max              0.998881
evaluation/Actions Min             -0.999684
evaluation/Num Paths               15
evaluation/Average Returns        -80.0021
time/data storing (s)               0.00300881
time/evaluation sampling (s)        0.328804
time/exploration sampling (s)       0.167868
time/logging (s)                    0.00483153
time/saving (s)                     0.00963166
time/training (s)                   1.94346
time/epoch (s)                      2.4576
time/total (s)                    504.375
Epoch                             206
-----------------------------  ---------------
2019-04-23 00:01:46.289550 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 207 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.778223
trainer/QF2 Loss                    0.770054
trainer/Policy Loss                51.4787
trainer/Q1 Predictions Mean       -49.9182
trainer/Q1 Predictions Std         33.801
trainer/Q1 Predictions Max         -9.04044
trainer/Q1 Predictions Min       -127.119
trainer/Q2 Predictions Mean       -49.9064
trainer/Q2 Predictions Std         33.7817
trainer/Q2 Predictions Max         -9.02931
trainer/Q2 Predictions Min       -127.208
trainer/Q Targets Mean            -50.3833
trainer/Q Targets Std              34.2449
trainer/Q Targets Max              -9.08893
trainer/Q Targets Min            -125.946
trainer/Log Pis Mean                1.98651
trainer/Log Pis Std                 1.29566
trainer/Log Pis Max                 7.86975
trainer/Log Pis Min                -0.680203
trainer/Policy mu Mean             -0.069351
trainer/Policy mu Std               0.901416
trainer/Policy mu Max               3.12712
trainer/Policy mu Min              -3.34101
trainer/Policy log std Mean        -1.90807
trainer/Policy log std Std          0.604408
trainer/Policy log std Max         -0.110792
trainer/Policy log std Min         -2.7914
trainer/Alpha                       0.0592012
trainer/Alpha Loss                 -0.0381394
exploration/num steps total    104200
exploration/num paths total      1042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.673181
exploration/Rewards Std             0.937636
exploration/Rewards Max            -0.00729251
exploration/Rewards Min            -8.4312
exploration/Returns Mean          -67.3181
exploration/Returns Std            37.8641
exploration/Returns Max           -32.8269
exploration/Returns Min          -140.473
exploration/Actions Mean            0.0154494
exploration/Actions Std             0.221554
exploration/Actions Max             0.998486
exploration/Actions Min            -0.993116
exploration/Num Paths               5
exploration/Average Returns       -67.3181
evaluation/num steps total     312000
evaluation/num paths total       3120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06058
evaluation/Rewards Std              1.11117
evaluation/Rewards Max             -0.0836896
evaluation/Rewards Min            -10.8066
evaluation/Returns Mean          -106.058
evaluation/Returns Std             62.3126
evaluation/Returns Max            -30.652
evaluation/Returns Min           -265.953
evaluation/Actions Mean            -0.00046644
evaluation/Actions Std              0.196325
evaluation/Actions Max              0.9994
evaluation/Actions Min             -0.999629
evaluation/Num Paths               15
evaluation/Average Returns       -106.058
time/data storing (s)               0.00282544
time/evaluation sampling (s)        0.323095
time/exploration sampling (s)       0.137737
time/logging (s)                    0.00354314
time/saving (s)                     0.00198441
time/training (s)                   1.94038
time/epoch (s)                      2.40957
time/total (s)                    506.789
Epoch                             207
-----------------------------  ---------------
2019-04-23 00:01:48.721027 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 208 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   50.738
trainer/QF2 Loss                   50.1429
trainer/Policy Loss                50.1418
trainer/Q1 Predictions Mean       -48.5607
trainer/Q1 Predictions Std         35.0924
trainer/Q1 Predictions Max         -9.13023
trainer/Q1 Predictions Min       -132.689
trainer/Q2 Predictions Mean       -48.5747
trainer/Q2 Predictions Std         35.0652
trainer/Q2 Predictions Max         -9.22174
trainer/Q2 Predictions Min       -133.329
trainer/Q Targets Mean            -48.1644
trainer/Q Targets Std              35.4138
trainer/Q Targets Max              -1.91271
trainer/Q Targets Min            -133.384
trainer/Log Pis Mean                2.04403
trainer/Log Pis Std                 1.51679
trainer/Log Pis Max                 6.79337
trainer/Log Pis Min                -5.48411
trainer/Policy mu Mean              0.00608056
trainer/Policy mu Std               0.955676
trainer/Policy mu Max               3.03135
trainer/Policy mu Min              -2.62317
trainer/Policy log std Mean        -1.82637
trainer/Policy log std Std          0.617302
trainer/Policy log std Max         -0.212978
trainer/Policy log std Min         -2.80245
trainer/Alpha                       0.0593774
trainer/Alpha Loss                  0.124335
exploration/num steps total    104700
exploration/num paths total      1047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.30803
exploration/Rewards Std             1.55427
exploration/Rewards Max            -0.0276587
exploration/Rewards Min           -11.6456
exploration/Returns Mean         -130.803
exploration/Returns Std            86.7435
exploration/Returns Max           -59.7181
exploration/Returns Min          -293.143
exploration/Actions Mean           -0.000891878
exploration/Actions Std             0.269571
exploration/Actions Max             0.999906
exploration/Actions Min            -0.999873
exploration/Num Paths               5
exploration/Average Returns      -130.803
evaluation/num steps total     313500
evaluation/num paths total       3135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.72341
evaluation/Rewards Std              0.80928
evaluation/Rewards Max             -0.0361499
evaluation/Rewards Min             -8.68111
evaluation/Returns Mean           -72.341
evaluation/Returns Std             46.5158
evaluation/Returns Max             -6.12008
evaluation/Returns Min           -152.435
evaluation/Actions Mean            -0.00212132
evaluation/Actions Std              0.172989
evaluation/Actions Max              0.998548
evaluation/Actions Min             -0.999338
evaluation/Num Paths               15
evaluation/Average Returns        -72.341
time/data storing (s)               0.00272909
time/evaluation sampling (s)        0.330221
time/exploration sampling (s)       0.139097
time/logging (s)                    0.00478108
time/saving (s)                     0.00195829
time/training (s)                   1.94792
time/epoch (s)                      2.42671
time/total (s)                    509.22
Epoch                             208
-----------------------------  ----------------
2019-04-23 00:01:51.142231 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 209 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   51.6716
trainer/QF2 Loss                   51.3863
trainer/Policy Loss                54.0997
trainer/Q1 Predictions Mean       -52.9196
trainer/Q1 Predictions Std         36.6601
trainer/Q1 Predictions Max         -8.87439
trainer/Q1 Predictions Min       -122.042
trainer/Q2 Predictions Mean       -52.9242
trainer/Q2 Predictions Std         36.6464
trainer/Q2 Predictions Max         -8.91011
trainer/Q2 Predictions Min       -122.185
trainer/Q Targets Mean            -52.677
trainer/Q Targets Std              37.2893
trainer/Q Targets Max              -1.34995
trainer/Q Targets Min            -124.189
trainer/Log Pis Mean                1.61779
trainer/Log Pis Std                 1.2612
trainer/Log Pis Max                 4.8598
trainer/Log Pis Min                -4.53897
trainer/Policy mu Mean             -0.026729
trainer/Policy mu Std               0.693325
trainer/Policy mu Max               2.87315
trainer/Policy mu Min              -2.73913
trainer/Policy log std Mean        -2.01671
trainer/Policy log std Std          0.514089
trainer/Policy log std Max         -0.220683
trainer/Policy log std Min         -2.87052
trainer/Alpha                       0.0587845
trainer/Alpha Loss                 -1.08313
exploration/num steps total    105200
exploration/num paths total      1052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.50823
exploration/Rewards Std             1.36764
exploration/Rewards Max            -0.0879861
exploration/Rewards Min           -10.7972
exploration/Returns Mean         -150.823
exploration/Returns Std            65.8729
exploration/Returns Max           -65.2679
exploration/Returns Min          -263.248
exploration/Actions Mean            0.00172317
exploration/Actions Std             0.250419
exploration/Actions Max             0.998969
exploration/Actions Min            -0.999864
exploration/Num Paths               5
exploration/Average Returns      -150.823
evaluation/num steps total     315000
evaluation/num paths total       3150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21517
evaluation/Rewards Std              1.3403
evaluation/Rewards Max             -0.0357934
evaluation/Rewards Min            -11.5685
evaluation/Returns Mean          -121.517
evaluation/Returns Std             84.0109
evaluation/Returns Max            -20.2217
evaluation/Returns Min           -281.704
evaluation/Actions Mean            -0.00370485
evaluation/Actions Std              0.207032
evaluation/Actions Max              0.999587
evaluation/Actions Min             -0.999654
evaluation/Num Paths               15
evaluation/Average Returns       -121.517
time/data storing (s)               0.00283219
time/evaluation sampling (s)        0.320419
time/exploration sampling (s)       0.139246
time/logging (s)                    0.00356395
time/saving (s)                     0.00157921
time/training (s)                   1.94466
time/epoch (s)                      2.4123
time/total (s)                    511.636
Epoch                             209
-----------------------------  ---------------
2019-04-23 00:01:53.564644 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 210 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.46588
trainer/QF2 Loss                    6.5117
trainer/Policy Loss                51.7441
trainer/Q1 Predictions Mean       -50.0929
trainer/Q1 Predictions Std         32.6555
trainer/Q1 Predictions Max         -9.08662
trainer/Q1 Predictions Min       -135.285
trainer/Q2 Predictions Mean       -50.1332
trainer/Q2 Predictions Std         32.6239
trainer/Q2 Predictions Max         -9.14957
trainer/Q2 Predictions Min       -134.488
trainer/Q Targets Mean            -50.7255
trainer/Q Targets Std              33.4273
trainer/Q Targets Max              -0.588206
trainer/Q Targets Min            -138.504
trainer/Log Pis Mean                2.07246
trainer/Log Pis Std                 1.21189
trainer/Log Pis Max                 7.06307
trainer/Log Pis Min                -1.74177
trainer/Policy mu Mean             -0.0710781
trainer/Policy mu Std               0.785871
trainer/Policy mu Max               3.30466
trainer/Policy mu Min              -4.31923
trainer/Policy log std Mean        -1.98
trainer/Policy log std Std          0.560705
trainer/Policy log std Max         -0.0102207
trainer/Policy log std Min         -2.74406
trainer/Alpha                       0.0591689
trainer/Alpha Loss                  0.204877
exploration/num steps total    105700
exploration/num paths total      1057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.613245
exploration/Rewards Std             1.10848
exploration/Rewards Max            -0.00595166
exploration/Rewards Min            -9.58767
exploration/Returns Mean          -61.3245
exploration/Returns Std            49.5593
exploration/Returns Max           -24.5875
exploration/Returns Min          -159.039
exploration/Actions Mean           -0.00675227
exploration/Actions Std             0.252906
exploration/Actions Max             0.997009
exploration/Actions Min            -0.999988
exploration/Num Paths               5
exploration/Average Returns       -61.3245
evaluation/num steps total     316500
evaluation/num paths total       3165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.833018
evaluation/Rewards Std              1.00337
evaluation/Rewards Max             -0.0538354
evaluation/Rewards Min             -9.78216
evaluation/Returns Mean           -83.3018
evaluation/Returns Std             54.6742
evaluation/Returns Max            -23.5274
evaluation/Returns Min           -241.792
evaluation/Actions Mean            -0.01464
evaluation/Actions Std              0.190128
evaluation/Actions Max              0.992991
evaluation/Actions Min             -0.999327
evaluation/Num Paths               15
evaluation/Average Returns        -83.3018
time/data storing (s)               0.00277651
time/evaluation sampling (s)        0.326669
time/exploration sampling (s)       0.140018
time/logging (s)                    0.00479826
time/saving (s)                     0.00198106
time/training (s)                   1.94121
time/epoch (s)                      2.41746
time/total (s)                    514.058
Epoch                             210
-----------------------------  ---------------
2019-04-23 00:01:56.007024 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 211 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.757344
trainer/QF2 Loss                    0.813846
trainer/Policy Loss                48.2999
trainer/Q1 Predictions Mean       -46.8428
trainer/Q1 Predictions Std         33.369
trainer/Q1 Predictions Max         -8.87016
trainer/Q1 Predictions Min       -128.11
trainer/Q2 Predictions Mean       -46.8375
trainer/Q2 Predictions Std         33.3293
trainer/Q2 Predictions Max         -8.90457
trainer/Q2 Predictions Min       -127.861
trainer/Q Targets Mean            -47.3944
trainer/Q Targets Std              33.5897
trainer/Q Targets Max              -8.96156
trainer/Q Targets Min            -128.33
trainer/Log Pis Mean                1.92872
trainer/Log Pis Std                 1.28013
trainer/Log Pis Max                 6.49991
trainer/Log Pis Min                -2.96041
trainer/Policy mu Mean              0.199552
trainer/Policy mu Std               0.774676
trainer/Policy mu Max               2.74643
trainer/Policy mu Min              -2.5013
trainer/Policy log std Mean        -1.91871
trainer/Policy log std Std          0.573797
trainer/Policy log std Max         -0.264866
trainer/Policy log std Min         -2.79985
trainer/Alpha                       0.0585144
trainer/Alpha Loss                 -0.202309
exploration/num steps total    106200
exploration/num paths total      1062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.724015
exploration/Rewards Std             1.32058
exploration/Rewards Max            -0.034649
exploration/Rewards Min           -11.0887
exploration/Returns Mean          -72.4015
exploration/Returns Std            31.7392
exploration/Returns Max           -32.7305
exploration/Returns Min          -114.11
exploration/Actions Mean            0.0474175
exploration/Actions Std             0.25436
exploration/Actions Max             0.999948
exploration/Actions Min            -0.990713
exploration/Num Paths               5
exploration/Average Returns       -72.4015
evaluation/num steps total     318000
evaluation/num paths total       3180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.868822
evaluation/Rewards Std              0.9889
evaluation/Rewards Max             -0.0589652
evaluation/Rewards Min             -9.12528
evaluation/Returns Mean           -86.8822
evaluation/Returns Std             65.3308
evaluation/Returns Max            -17.9041
evaluation/Returns Min           -229.463
evaluation/Actions Mean            -0.00362907
evaluation/Actions Std              0.159096
evaluation/Actions Max              0.99912
evaluation/Actions Min             -0.999508
evaluation/Num Paths               15
evaluation/Average Returns        -86.8822
time/data storing (s)               0.00279387
time/evaluation sampling (s)        0.326039
time/exploration sampling (s)       0.140187
time/logging (s)                    0.00481079
time/saving (s)                     0.00195674
time/training (s)                   1.95863
time/epoch (s)                      2.43442
time/total (s)                    516.497
Epoch                             211
-----------------------------  ---------------
2019-04-23 00:01:58.476138 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 212 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   50.2815
trainer/QF2 Loss                   50.4899
trainer/Policy Loss                48.0686
trainer/Q1 Predictions Mean       -46.4398
trainer/Q1 Predictions Std         29.5372
trainer/Q1 Predictions Max         -8.86703
trainer/Q1 Predictions Min       -119.927
trainer/Q2 Predictions Mean       -46.4971
trainer/Q2 Predictions Std         29.5666
trainer/Q2 Predictions Max         -8.78387
trainer/Q2 Predictions Min       -121.383
trainer/Q Targets Mean            -46.4129
trainer/Q Targets Std              30.4225
trainer/Q Targets Max              -0.157877
trainer/Q Targets Min            -124.317
trainer/Log Pis Mean                1.98399
trainer/Log Pis Std                 1.13493
trainer/Log Pis Max                 4.89589
trainer/Log Pis Min                -1.54429
trainer/Policy mu Mean              0.0365564
trainer/Policy mu Std               0.761047
trainer/Policy mu Max               2.57641
trainer/Policy mu Min              -2.74923
trainer/Policy log std Mean        -1.94667
trainer/Policy log std Std          0.546878
trainer/Policy log std Max         -0.392448
trainer/Policy log std Min         -2.70159
trainer/Alpha                       0.0579087
trainer/Alpha Loss                 -0.0456214
exploration/num steps total    106700
exploration/num paths total      1067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.806677
exploration/Rewards Std             1.14526
exploration/Rewards Max            -0.0217819
exploration/Rewards Min            -7.99962
exploration/Returns Mean          -80.6677
exploration/Returns Std            92.7996
exploration/Returns Max           -22.3033
exploration/Returns Min          -265.067
exploration/Actions Mean           -0.0111259
exploration/Actions Std             0.202932
exploration/Actions Max             0.996742
exploration/Actions Min            -0.99945
exploration/Num Paths               5
exploration/Average Returns       -80.6677
evaluation/num steps total     319500
evaluation/num paths total       3195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.932245
evaluation/Rewards Std              1.24108
evaluation/Rewards Max             -0.0758687
evaluation/Rewards Min            -10.6711
evaluation/Returns Mean           -93.2245
evaluation/Returns Std             43.2097
evaluation/Returns Max            -38.0438
evaluation/Returns Min           -162.755
evaluation/Actions Mean             0.0244461
evaluation/Actions Std              0.210952
evaluation/Actions Max              0.999654
evaluation/Actions Min             -0.995778
evaluation/Num Paths               15
evaluation/Average Returns        -93.2245
time/data storing (s)               0.00284617
time/evaluation sampling (s)        0.327914
time/exploration sampling (s)       0.140663
time/logging (s)                    0.00481048
time/saving (s)                     0.00157282
time/training (s)                   1.98316
time/epoch (s)                      2.46097
time/total (s)                    518.962
Epoch                             212
-----------------------------  ---------------
2019-04-23 00:02:00.965915 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 213 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   14.6674
trainer/QF2 Loss                   14.7043
trainer/Policy Loss                49.8089
trainer/Q1 Predictions Mean       -48.1151
trainer/Q1 Predictions Std         30.5375
trainer/Q1 Predictions Max         -8.96105
trainer/Q1 Predictions Min       -120.092
trainer/Q2 Predictions Mean       -48.09
trainer/Q2 Predictions Std         30.5619
trainer/Q2 Predictions Max         -8.87257
trainer/Q2 Predictions Min       -120.396
trainer/Q Targets Mean            -47.9952
trainer/Q Targets Std              31.0911
trainer/Q Targets Max              -0.255333
trainer/Q Targets Min            -120.402
trainer/Log Pis Mean                2.11124
trainer/Log Pis Std                 1.5414
trainer/Log Pis Max                 7.5414
trainer/Log Pis Min                -2.86183
trainer/Policy mu Mean              0.129238
trainer/Policy mu Std               0.869219
trainer/Policy mu Max               3.10009
trainer/Policy mu Min              -3.10445
trainer/Policy log std Mean        -1.94291
trainer/Policy log std Std          0.558923
trainer/Policy log std Max         -0.234801
trainer/Policy log std Min         -2.712
trainer/Alpha                       0.0568309
trainer/Alpha Loss                  0.319
exploration/num steps total    107200
exploration/num paths total      1072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.36018
exploration/Rewards Std             0.531291
exploration/Rewards Max            -0.00941009
exploration/Rewards Min            -6.01818
exploration/Returns Mean          -36.018
exploration/Returns Std            16.5464
exploration/Returns Max           -11.4052
exploration/Returns Min           -61.7719
exploration/Actions Mean            0.000674561
exploration/Actions Std             0.182032
exploration/Actions Max             0.997982
exploration/Actions Min            -0.999504
exploration/Num Paths               5
exploration/Average Returns       -36.018
evaluation/num steps total     321000
evaluation/num paths total       3210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.932154
evaluation/Rewards Std              1.04569
evaluation/Rewards Max             -0.028693
evaluation/Rewards Min            -10.5032
evaluation/Returns Mean           -93.2154
evaluation/Returns Std             61.2786
evaluation/Returns Max            -22.26
evaluation/Returns Min           -243.236
evaluation/Actions Mean             0.0177708
evaluation/Actions Std              0.187247
evaluation/Actions Max              0.999013
evaluation/Actions Min             -0.997842
evaluation/Num Paths               15
evaluation/Average Returns        -93.2154
time/data storing (s)               0.00287276
time/evaluation sampling (s)        0.357279
time/exploration sampling (s)       0.150318
time/logging (s)                    0.0046572
time/saving (s)                     0.00159688
time/training (s)                   1.96486
time/epoch (s)                      2.48158
time/total (s)                    521.448
Epoch                             213
-----------------------------  ----------------
2019-04-23 00:02:03.406314 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 214 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    8.25591
trainer/QF2 Loss                    8.28107
trainer/Policy Loss                52.2463
trainer/Q1 Predictions Mean       -50.8338
trainer/Q1 Predictions Std         36.1149
trainer/Q1 Predictions Max         -8.47766
trainer/Q1 Predictions Min       -117.776
trainer/Q2 Predictions Mean       -50.782
trainer/Q2 Predictions Std         36.1241
trainer/Q2 Predictions Max         -8.37195
trainer/Q2 Predictions Min       -118.913
trainer/Q Targets Mean            -50.9987
trainer/Q Targets Std              36.5154
trainer/Q Targets Max              -0.653101
trainer/Q Targets Min            -118.81
trainer/Log Pis Mean                1.90844
trainer/Log Pis Std                 1.27284
trainer/Log Pis Max                 7.21571
trainer/Log Pis Min                -2.35608
trainer/Policy mu Mean              0.0138338
trainer/Policy mu Std               0.723863
trainer/Policy mu Max               3.13154
trainer/Policy mu Min              -2.72796
trainer/Policy log std Mean        -2.08281
trainer/Policy log std Std          0.518152
trainer/Policy log std Max         -0.431246
trainer/Policy log std Min         -2.77036
trainer/Alpha                       0.0570369
trainer/Alpha Loss                 -0.26223
exploration/num steps total    107700
exploration/num paths total      1077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.78162
exploration/Rewards Std             0.806927
exploration/Rewards Max            -0.69828
exploration/Rewards Min            -7.78639
exploration/Returns Mean         -178.162
exploration/Returns Std            53.3386
exploration/Returns Max          -109.301
exploration/Returns Min          -241.207
exploration/Actions Mean            0.0168798
exploration/Actions Std             0.241929
exploration/Actions Max             0.999085
exploration/Actions Min            -0.991042
exploration/Num Paths               5
exploration/Average Returns      -178.162
evaluation/num steps total     322500
evaluation/num paths total       3225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.875455
evaluation/Rewards Std              1.10928
evaluation/Rewards Max             -0.0365808
evaluation/Rewards Min            -10.1554
evaluation/Returns Mean           -87.5455
evaluation/Returns Std             59.5333
evaluation/Returns Max            -13.0512
evaluation/Returns Min           -244.909
evaluation/Actions Mean            -0.0116665
evaluation/Actions Std              0.190162
evaluation/Actions Max              0.997241
evaluation/Actions Min             -0.999777
evaluation/Num Paths               15
evaluation/Average Returns        -87.5455
time/data storing (s)               0.00277675
time/evaluation sampling (s)        0.322829
time/exploration sampling (s)       0.135878
time/logging (s)                    0.00427187
time/saving (s)                     0.00158184
time/training (s)                   1.9649
time/epoch (s)                      2.43224
time/total (s)                    523.885
Epoch                             214
-----------------------------  ---------------
2019-04-23 00:02:05.835857 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 215 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.767171
trainer/QF2 Loss                    0.873484
trainer/Policy Loss                49.9227
trainer/Q1 Predictions Mean       -48.4396
trainer/Q1 Predictions Std         32.3654
trainer/Q1 Predictions Max         -8.39979
trainer/Q1 Predictions Min       -124.589
trainer/Q2 Predictions Mean       -48.3813
trainer/Q2 Predictions Std         32.3851
trainer/Q2 Predictions Max         -8.29905
trainer/Q2 Predictions Min       -123.982
trainer/Q Targets Mean            -49.1384
trainer/Q Targets Std              32.8016
trainer/Q Targets Max              -8.55635
trainer/Q Targets Min            -126.391
trainer/Log Pis Mean                1.89698
trainer/Log Pis Std                 1.1723
trainer/Log Pis Max                 5.36524
trainer/Log Pis Min                -1.55702
trainer/Policy mu Mean             -0.010519
trainer/Policy mu Std               0.634606
trainer/Policy mu Max               2.45371
trainer/Policy mu Min              -2.82274
trainer/Policy log std Mean        -2.02526
trainer/Policy log std Std          0.468699
trainer/Policy log std Max         -0.534068
trainer/Policy log std Min         -2.65939
trainer/Alpha                       0.0580197
trainer/Alpha Loss                 -0.293294
exploration/num steps total    108200
exploration/num paths total      1082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.46796
exploration/Rewards Std             0.65265
exploration/Rewards Max            -0.16809
exploration/Rewards Min            -5.87296
exploration/Returns Mean         -146.796
exploration/Returns Std            45.6264
exploration/Returns Max           -55.8098
exploration/Returns Min          -174.182
exploration/Actions Mean           -0.0059359
exploration/Actions Std             0.277791
exploration/Actions Max             0.996304
exploration/Actions Min            -0.998127
exploration/Num Paths               5
exploration/Average Returns      -146.796
evaluation/num steps total     324000
evaluation/num paths total       3240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.871317
evaluation/Rewards Std              1.18265
evaluation/Rewards Max             -0.112153
evaluation/Rewards Min            -10.8377
evaluation/Returns Mean           -87.1317
evaluation/Returns Std             64.375
evaluation/Returns Max            -15.775
evaluation/Returns Min           -265.518
evaluation/Actions Mean             0.0060029
evaluation/Actions Std              0.18874
evaluation/Actions Max              0.999309
evaluation/Actions Min             -0.999488
evaluation/Num Paths               15
evaluation/Average Returns        -87.1317
time/data storing (s)               0.00278296
time/evaluation sampling (s)        0.326941
time/exploration sampling (s)       0.143158
time/logging (s)                    0.00475339
time/saving (s)                     0.00198548
time/training (s)                   1.94342
time/epoch (s)                      2.42304
time/total (s)                    526.313
Epoch                             215
-----------------------------  ---------------
2019-04-23 00:02:08.264041 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 216 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   60.0351
trainer/QF2 Loss                   59.9838
trainer/Policy Loss                49.9846
trainer/Q1 Predictions Mean       -48.3635
trainer/Q1 Predictions Std         32.8361
trainer/Q1 Predictions Max         -8.2178
trainer/Q1 Predictions Min       -123.017
trainer/Q2 Predictions Mean       -48.3328
trainer/Q2 Predictions Std         32.8552
trainer/Q2 Predictions Max         -8.15847
trainer/Q2 Predictions Min       -123.219
trainer/Q Targets Mean            -47.7969
trainer/Q Targets Std              33.6178
trainer/Q Targets Max              -0.586894
trainer/Q Targets Min            -121.372
trainer/Log Pis Mean                1.95095
trainer/Log Pis Std                 1.40186
trainer/Log Pis Max                 5.20579
trainer/Log Pis Min                -4.00757
trainer/Policy mu Mean              0.110529
trainer/Policy mu Std               0.706259
trainer/Policy mu Max               2.55705
trainer/Policy mu Min              -2.68457
trainer/Policy log std Mean        -2.00308
trainer/Policy log std Std          0.551952
trainer/Policy log std Max         -0.516821
trainer/Policy log std Min         -2.79419
trainer/Alpha                       0.0566966
trainer/Alpha Loss                 -0.14079
exploration/num steps total    108700
exploration/num paths total      1087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.835991
exploration/Rewards Std             1.22556
exploration/Rewards Max            -0.0144096
exploration/Rewards Min           -10.5621
exploration/Returns Mean          -83.5991
exploration/Returns Std            68.0045
exploration/Returns Max           -15.9082
exploration/Returns Min          -181.326
exploration/Actions Mean           -0.00728506
exploration/Actions Std             0.267925
exploration/Actions Max             0.999218
exploration/Actions Min            -0.998894
exploration/Num Paths               5
exploration/Average Returns       -83.5991
evaluation/num steps total     325500
evaluation/num paths total       3255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23105
evaluation/Rewards Std              1.06812
evaluation/Rewards Max             -0.0149827
evaluation/Rewards Min            -10.1746
evaluation/Returns Mean          -123.105
evaluation/Returns Std             85.011
evaluation/Returns Max            -20.61
evaluation/Returns Min           -280.22
evaluation/Actions Mean            -0.00164371
evaluation/Actions Std              0.172069
evaluation/Actions Max              0.998069
evaluation/Actions Min             -0.998013
evaluation/Num Paths               15
evaluation/Average Returns       -123.105
time/data storing (s)               0.00258593
time/evaluation sampling (s)        0.333154
time/exploration sampling (s)       0.13719
time/logging (s)                    0.00480919
time/saving (s)                     0.00196782
time/training (s)                   1.94047
time/epoch (s)                      2.42017
time/total (s)                    528.737
Epoch                             216
-----------------------------  ---------------
2019-04-23 00:02:10.701928 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 217 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.00513
trainer/QF2 Loss                    7.14138
trainer/Policy Loss                43.0527
trainer/Q1 Predictions Mean       -41.5441
trainer/Q1 Predictions Std         31.18
trainer/Q1 Predictions Max         -8.27507
trainer/Q1 Predictions Min       -117.832
trainer/Q2 Predictions Mean       -41.5244
trainer/Q2 Predictions Std         31.1369
trainer/Q2 Predictions Max         -8.30281
trainer/Q2 Predictions Min       -117.288
trainer/Q Targets Mean            -41.734
trainer/Q Targets Std              31.9314
trainer/Q Targets Max              -0.114399
trainer/Q Targets Min            -118.885
trainer/Log Pis Mean                2.00148
trainer/Log Pis Std                 1.20691
trainer/Log Pis Max                 7.38407
trainer/Log Pis Min                -2.62019
trainer/Policy mu Mean              0.0900234
trainer/Policy mu Std               0.824414
trainer/Policy mu Max               2.53818
trainer/Policy mu Min              -2.93451
trainer/Policy log std Mean        -1.88024
trainer/Policy log std Std          0.584478
trainer/Policy log std Max         -0.554197
trainer/Policy log std Min         -2.80271
trainer/Alpha                       0.0557551
trainer/Alpha Loss                  0.0042797
exploration/num steps total    109200
exploration/num paths total      1092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.24103
exploration/Rewards Std             0.931688
exploration/Rewards Max            -0.146422
exploration/Rewards Min            -8.63118
exploration/Returns Mean         -124.103
exploration/Returns Std            61.1107
exploration/Returns Max           -36.1024
exploration/Returns Min          -184.349
exploration/Actions Mean           -0.00479921
exploration/Actions Std             0.272446
exploration/Actions Max             0.999201
exploration/Actions Min            -0.998648
exploration/Num Paths               5
exploration/Average Returns      -124.103
evaluation/num steps total     327000
evaluation/num paths total       3270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.19804
evaluation/Rewards Std              1.14891
evaluation/Rewards Max             -0.14213
evaluation/Rewards Min            -10.433
evaluation/Returns Mean          -119.804
evaluation/Returns Std             72.9576
evaluation/Returns Max            -38.585
evaluation/Returns Min           -257.917
evaluation/Actions Mean            -0.00945322
evaluation/Actions Std              0.187469
evaluation/Actions Max              0.998488
evaluation/Actions Min             -0.999619
evaluation/Num Paths               15
evaluation/Average Returns       -119.804
time/data storing (s)               0.00260813
time/evaluation sampling (s)        0.325905
time/exploration sampling (s)       0.136138
time/logging (s)                    0.00348094
time/saving (s)                     0.00196438
time/training (s)                   1.95872
time/epoch (s)                      2.42882
time/total (s)                    531.17
Epoch                             217
-----------------------------  ---------------
2019-04-23 00:02:13.160793 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 218 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.369252
trainer/QF2 Loss                    0.37317
trainer/Policy Loss                53.0946
trainer/Q1 Predictions Mean       -51.6632
trainer/Q1 Predictions Std         31.9204
trainer/Q1 Predictions Max         -8.65051
trainer/Q1 Predictions Min       -116.308
trainer/Q2 Predictions Mean       -51.6683
trainer/Q2 Predictions Std         31.9453
trainer/Q2 Predictions Max         -8.61558
trainer/Q2 Predictions Min       -116.594
trainer/Q Targets Mean            -52.0234
trainer/Q Targets Std              32.2394
trainer/Q Targets Max              -8.65342
trainer/Q Targets Min            -117.164
trainer/Log Pis Mean                1.91411
trainer/Log Pis Std                 1.32681
trainer/Log Pis Max                 6.97092
trainer/Log Pis Min                -4.40783
trainer/Policy mu Mean              0.0205633
trainer/Policy mu Std               0.775741
trainer/Policy mu Max               3.44783
trainer/Policy mu Min              -2.77433
trainer/Policy log std Mean        -1.98484
trainer/Policy log std Std          0.552391
trainer/Policy log std Max         -0.485179
trainer/Policy log std Min         -2.83015
trainer/Alpha                       0.0565061
trainer/Alpha Loss                 -0.246802
exploration/num steps total    109700
exploration/num paths total      1097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.12727
exploration/Rewards Std             1.07657
exploration/Rewards Max            -0.179225
exploration/Rewards Min           -10.0015
exploration/Returns Mean         -112.727
exploration/Returns Std            75.1305
exploration/Returns Max           -32.8523
exploration/Returns Min          -247.452
exploration/Actions Mean           -0.0109076
exploration/Actions Std             0.209696
exploration/Actions Max             0.993338
exploration/Actions Min            -0.999476
exploration/Num Paths               5
exploration/Average Returns      -112.727
evaluation/num steps total     328500
evaluation/num paths total       3285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.832789
evaluation/Rewards Std              0.969236
evaluation/Rewards Max             -0.0243418
evaluation/Rewards Min             -9.97199
evaluation/Returns Mean           -83.2789
evaluation/Returns Std             38.9823
evaluation/Returns Max            -37.4479
evaluation/Returns Min           -154.196
evaluation/Actions Mean            -0.00182609
evaluation/Actions Std              0.190136
evaluation/Actions Max              0.999784
evaluation/Actions Min             -0.999376
evaluation/Num Paths               15
evaluation/Average Returns        -83.2789
time/data storing (s)               0.00263954
time/evaluation sampling (s)        0.335302
time/exploration sampling (s)       0.136963
time/logging (s)                    0.00477992
time/saving (s)                     0.00991696
time/training (s)                   1.96397
time/epoch (s)                      2.45357
time/total (s)                    533.628
Epoch                             218
-----------------------------  ---------------
2019-04-23 00:02:15.581907 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 219 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   57.1
trainer/QF2 Loss                   57.1025
trainer/Policy Loss                48.3439
trainer/Q1 Predictions Mean       -46.7514
trainer/Q1 Predictions Std         32.3827
trainer/Q1 Predictions Max         -8.51913
trainer/Q1 Predictions Min       -117.729
trainer/Q2 Predictions Mean       -46.7323
trainer/Q2 Predictions Std         32.4026
trainer/Q2 Predictions Max         -8.44386
trainer/Q2 Predictions Min       -117.814
trainer/Q Targets Mean            -46.5133
trainer/Q Targets Std              33.3096
trainer/Q Targets Max              -0.382165
trainer/Q Targets Min            -118.909
trainer/Log Pis Mean                1.986
trainer/Log Pis Std                 1.20148
trainer/Log Pis Max                 5.9212
trainer/Log Pis Min                -1.63584
trainer/Policy mu Mean             -0.0767419
trainer/Policy mu Std               0.807292
trainer/Policy mu Max               2.99048
trainer/Policy mu Min              -2.84227
trainer/Policy log std Mean        -1.95316
trainer/Policy log std Std          0.588257
trainer/Policy log std Max         -0.374177
trainer/Policy log std Min         -2.87671
trainer/Alpha                       0.0582851
trainer/Alpha Loss                 -0.0397899
exploration/num steps total    110200
exploration/num paths total      1102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.69671
exploration/Rewards Std             1.14638
exploration/Rewards Max            -0.233319
exploration/Rewards Min            -7.81535
exploration/Returns Mean         -169.671
exploration/Returns Std            87.5385
exploration/Returns Max           -58.9648
exploration/Returns Min          -247.148
exploration/Actions Mean           -0.00879557
exploration/Actions Std             0.237642
exploration/Actions Max             0.999436
exploration/Actions Min            -0.999632
exploration/Num Paths               5
exploration/Average Returns      -169.671
evaluation/num steps total     330000
evaluation/num paths total       3300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.084
evaluation/Rewards Std              1.17865
evaluation/Rewards Max             -0.0165307
evaluation/Rewards Min             -9.98544
evaluation/Returns Mean          -108.4
evaluation/Returns Std             75.2739
evaluation/Returns Max            -12.3509
evaluation/Returns Min           -264.892
evaluation/Actions Mean            -0.00486973
evaluation/Actions Std              0.179306
evaluation/Actions Max              0.99921
evaluation/Actions Min             -0.999853
evaluation/Num Paths               15
evaluation/Average Returns       -108.4
time/data storing (s)               0.0027838
time/evaluation sampling (s)        0.328346
time/exploration sampling (s)       0.138965
time/logging (s)                    0.004157
time/saving (s)                     0.00198554
time/training (s)                   1.93597
time/epoch (s)                      2.41221
time/total (s)                    536.045
Epoch                             219
-----------------------------  ---------------
2019-04-23 00:02:17.982318 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 220 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.376786
trainer/QF2 Loss                    0.34857
trainer/Policy Loss                45.836
trainer/Q1 Predictions Mean       -44.3794
trainer/Q1 Predictions Std         28.1334
trainer/Q1 Predictions Max         -8.39068
trainer/Q1 Predictions Min       -125.995
trainer/Q2 Predictions Mean       -44.4208
trainer/Q2 Predictions Std         28.1684
trainer/Q2 Predictions Max         -8.30272
trainer/Q2 Predictions Min       -126.649
trainer/Q Targets Mean            -44.7426
trainer/Q Targets Std              28.421
trainer/Q Targets Max              -8.46699
trainer/Q Targets Min            -126.582
trainer/Log Pis Mean                1.81265
trainer/Log Pis Std                 1.71584
trainer/Log Pis Max                11.6716
trainer/Log Pis Min                -2.52719
trainer/Policy mu Mean              0.00540524
trainer/Policy mu Std               0.900319
trainer/Policy mu Max               3.12637
trainer/Policy mu Min              -4.26743
trainer/Policy log std Mean        -1.87559
trainer/Policy log std Std          0.562157
trainer/Policy log std Max         -0.17918
trainer/Policy log std Min         -2.69632
trainer/Alpha                       0.0586299
trainer/Alpha Loss                 -0.531427
exploration/num steps total    110700
exploration/num paths total      1107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.897673
exploration/Rewards Std             1.2724
exploration/Rewards Max            -0.0040409
exploration/Rewards Min           -11.1064
exploration/Returns Mean          -89.7673
exploration/Returns Std            60.305
exploration/Returns Max           -16.3943
exploration/Returns Min          -182.154
exploration/Actions Mean           -0.0071132
exploration/Actions Std             0.255268
exploration/Actions Max             0.999126
exploration/Actions Min            -0.999865
exploration/Num Paths               5
exploration/Average Returns       -89.7673
evaluation/num steps total     331500
evaluation/num paths total       3315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.83143
evaluation/Rewards Std              0.939685
evaluation/Rewards Max             -0.0685422
evaluation/Rewards Min             -9.16781
evaluation/Returns Mean           -83.143
evaluation/Returns Std             62.065
evaluation/Returns Max            -22.3287
evaluation/Returns Min           -258.428
evaluation/Actions Mean            -9.05336e-05
evaluation/Actions Std              0.169416
evaluation/Actions Max              0.999108
evaluation/Actions Min             -0.99909
evaluation/Num Paths               15
evaluation/Average Returns        -83.143
time/data storing (s)               0.00280464
time/evaluation sampling (s)        0.333918
time/exploration sampling (s)       0.139941
time/logging (s)                    0.00476832
time/saving (s)                     0.00196019
time/training (s)                   1.90956
time/epoch (s)                      2.39295
time/total (s)                    538.442
Epoch                             220
-----------------------------  ----------------
2019-04-23 00:02:20.416405 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 221 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.102
trainer/QF2 Loss                    1.14474
trainer/Policy Loss                47.4391
trainer/Q1 Predictions Mean       -45.4775
trainer/Q1 Predictions Std         31.0554
trainer/Q1 Predictions Max         -8.08412
trainer/Q1 Predictions Min       -115.749
trainer/Q2 Predictions Mean       -45.4516
trainer/Q2 Predictions Std         31.0612
trainer/Q2 Predictions Max         -8.01641
trainer/Q2 Predictions Min       -116.145
trainer/Q Targets Mean            -45.8511
trainer/Q Targets Std              31.4873
trainer/Q Targets Max              -0.239025
trainer/Q Targets Min            -117.364
trainer/Log Pis Mean                2.34968
trainer/Log Pis Std                 1.18744
trainer/Log Pis Max                 8.73399
trainer/Log Pis Min                -0.681351
trainer/Policy mu Mean             -0.0702402
trainer/Policy mu Std               0.629471
trainer/Policy mu Max               2.34684
trainer/Policy mu Min              -3.07568
trainer/Policy log std Mean        -2.16144
trainer/Policy log std Std          0.500146
trainer/Policy log std Max         -0.475803
trainer/Policy log std Min         -2.87009
trainer/Alpha                       0.0577873
trainer/Alpha Loss                  0.997015
exploration/num steps total    111200
exploration/num paths total      1112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.71397
exploration/Rewards Std             1.04254
exploration/Rewards Max            -0.04264
exploration/Rewards Min            -8.48288
exploration/Returns Mean         -171.397
exploration/Returns Std            84.9196
exploration/Returns Max           -36.2223
exploration/Returns Min          -245.318
exploration/Actions Mean           -0.0144472
exploration/Actions Std             0.201803
exploration/Actions Max             0.971321
exploration/Actions Min            -0.998574
exploration/Num Paths               5
exploration/Average Returns      -171.397
evaluation/num steps total     333000
evaluation/num paths total       3330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.847793
evaluation/Rewards Std              1.19679
evaluation/Rewards Max             -0.0983247
evaluation/Rewards Min            -11.2031
evaluation/Returns Mean           -84.7793
evaluation/Returns Std             62.9195
evaluation/Returns Max            -28.32
evaluation/Returns Min           -252.792
evaluation/Actions Mean            -0.0106147
evaluation/Actions Std              0.204034
evaluation/Actions Max              0.998557
evaluation/Actions Min             -0.999141
evaluation/Num Paths               15
evaluation/Average Returns        -84.7793
time/data storing (s)               0.00273172
time/evaluation sampling (s)        0.328109
time/exploration sampling (s)       0.135311
time/logging (s)                    0.00474504
time/saving (s)                     0.00200525
time/training (s)                   1.95466
time/epoch (s)                      2.42756
time/total (s)                    540.873
Epoch                             221
-----------------------------  ---------------
2019-04-23 00:02:22.818375 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 222 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   59.9189
trainer/QF2 Loss                   59.8051
trainer/Policy Loss                48.2958
trainer/Q1 Predictions Mean       -46.9068
trainer/Q1 Predictions Std         33.3465
trainer/Q1 Predictions Max         -8.63988
trainer/Q1 Predictions Min       -115.675
trainer/Q2 Predictions Mean       -46.8852
trainer/Q2 Predictions Std         33.3948
trainer/Q2 Predictions Max         -8.66864
trainer/Q2 Predictions Min       -115.943
trainer/Q Targets Mean            -46.1954
trainer/Q Targets Std              33.8591
trainer/Q Targets Max              -0.988659
trainer/Q Targets Min            -115.672
trainer/Log Pis Mean                1.88209
trainer/Log Pis Std                 1.32009
trainer/Log Pis Max                 7.3328
trainer/Log Pis Min                -2.59031
trainer/Policy mu Mean             -0.151781
trainer/Policy mu Std               0.807738
trainer/Policy mu Max               1.9818
trainer/Policy mu Min              -3.00616
trainer/Policy log std Mean        -1.92574
trainer/Policy log std Std          0.548345
trainer/Policy log std Max         -0.453354
trainer/Policy log std Min         -2.79996
trainer/Alpha                       0.0560579
trainer/Alpha Loss                 -0.339743
exploration/num steps total    111700
exploration/num paths total      1117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.24045
exploration/Rewards Std             1.30867
exploration/Rewards Max            -0.0161395
exploration/Rewards Min           -10.1329
exploration/Returns Mean         -124.045
exploration/Returns Std           103.47
exploration/Returns Max           -25.7364
exploration/Returns Min          -261.886
exploration/Actions Mean           -0.0231238
exploration/Actions Std             0.236658
exploration/Actions Max             0.996812
exploration/Actions Min            -0.999687
exploration/Num Paths               5
exploration/Average Returns      -124.045
evaluation/num steps total     334500
evaluation/num paths total       3345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.23434
evaluation/Rewards Std              1.28711
evaluation/Rewards Max             -0.0278774
evaluation/Rewards Min            -11.2697
evaluation/Returns Mean          -123.434
evaluation/Returns Std             76.6076
evaluation/Returns Max            -22.2632
evaluation/Returns Min           -258.923
evaluation/Actions Mean            -0.0042367
evaluation/Actions Std              0.203987
evaluation/Actions Max              0.998651
evaluation/Actions Min             -0.999382
evaluation/Num Paths               15
evaluation/Average Returns       -123.434
time/data storing (s)               0.00258468
time/evaluation sampling (s)        0.330437
time/exploration sampling (s)       0.136534
time/logging (s)                    0.00417216
time/saving (s)                     0.00197802
time/training (s)                   1.91769
time/epoch (s)                      2.3934
time/total (s)                    543.271
Epoch                             222
-----------------------------  ---------------
2019-04-23 00:02:25.252957 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 223 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   86.4616
trainer/QF2 Loss                   86.2557
trainer/Policy Loss                44.716
trainer/Q1 Predictions Mean       -42.9039
trainer/Q1 Predictions Std         33.0525
trainer/Q1 Predictions Max         -8.30696
trainer/Q1 Predictions Min       -115.654
trainer/Q2 Predictions Mean       -42.8965
trainer/Q2 Predictions Std         33.0411
trainer/Q2 Predictions Max         -8.26446
trainer/Q2 Predictions Min       -115.942
trainer/Q Targets Mean            -42.0566
trainer/Q Targets Std              33.6063
trainer/Q Targets Max              -1.7245
trainer/Q Targets Min            -116.648
trainer/Log Pis Mean                2.11599
trainer/Log Pis Std                 1.21841
trainer/Log Pis Max                 4.89223
trainer/Log Pis Min                -2.52039
trainer/Policy mu Mean             -0.0263528
trainer/Policy mu Std               0.729035
trainer/Policy mu Max               2.92569
trainer/Policy mu Min              -2.83875
trainer/Policy log std Mean        -2.04401
trainer/Policy log std Std          0.535218
trainer/Policy log std Max         -0.423326
trainer/Policy log std Min         -2.9054
trainer/Alpha                       0.058824
trainer/Alpha Loss                  0.328637
exploration/num steps total    112200
exploration/num paths total      1122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.270473
exploration/Rewards Std             0.54974
exploration/Rewards Max            -0.00729226
exploration/Rewards Min            -6.43343
exploration/Returns Mean          -27.0473
exploration/Returns Std             8.40328
exploration/Returns Max           -18.0339
exploration/Returns Min           -38.007
exploration/Actions Mean           -0.0201804
exploration/Actions Std             0.196826
exploration/Actions Max             0.966383
exploration/Actions Min            -0.99979
exploration/Num Paths               5
exploration/Average Returns       -27.0473
evaluation/num steps total     336000
evaluation/num paths total       3360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.777418
evaluation/Rewards Std              1.10684
evaluation/Rewards Max             -0.00505518
evaluation/Rewards Min             -8.95246
evaluation/Returns Mean           -77.7418
evaluation/Returns Std             60.0963
evaluation/Returns Max            -16.1172
evaluation/Returns Min           -253.926
evaluation/Actions Mean            -0.00223261
evaluation/Actions Std              0.196851
evaluation/Actions Max              0.999381
evaluation/Actions Min             -0.999746
evaluation/Num Paths               15
evaluation/Average Returns        -77.7418
time/data storing (s)               0.0027194
time/evaluation sampling (s)        0.330631
time/exploration sampling (s)       0.13644
time/logging (s)                    0.00480307
time/saving (s)                     0.00160087
time/training (s)                   1.95143
time/epoch (s)                      2.42762
time/total (s)                    545.703
Epoch                             223
-----------------------------  ---------------
2019-04-23 00:02:27.671004 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 224 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.04667
trainer/QF2 Loss                    5.07427
trainer/Policy Loss                48.4199
trainer/Q1 Predictions Mean       -46.907
trainer/Q1 Predictions Std         31.8623
trainer/Q1 Predictions Max         -8.30273
trainer/Q1 Predictions Min       -116.957
trainer/Q2 Predictions Mean       -46.9602
trainer/Q2 Predictions Std         31.8596
trainer/Q2 Predictions Max         -8.35304
trainer/Q2 Predictions Min       -116.96
trainer/Q Targets Mean            -46.9759
trainer/Q Targets Std              32.2408
trainer/Q Targets Max              -0.586217
trainer/Q Targets Min            -117.134
trainer/Log Pis Mean                1.93368
trainer/Log Pis Std                 1.41864
trainer/Log Pis Max                 7.92653
trainer/Log Pis Min                -1.45149
trainer/Policy mu Mean             -0.034836
trainer/Policy mu Std               0.880077
trainer/Policy mu Max               3.02556
trainer/Policy mu Min              -2.75039
trainer/Policy log std Mean        -1.86695
trainer/Policy log std Std          0.586622
trainer/Policy log std Max         -0.457508
trainer/Policy log std Min         -2.90125
trainer/Alpha                       0.0599922
trainer/Alpha Loss                 -0.186599
exploration/num steps total    112700
exploration/num paths total      1127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.683171
exploration/Rewards Std             1.26473
exploration/Rewards Max            -0.00549823
exploration/Rewards Min            -9.80335
exploration/Returns Mean          -68.3171
exploration/Returns Std            28.8482
exploration/Returns Max           -50.0918
exploration/Returns Min          -125.359
exploration/Actions Mean           -0.00230461
exploration/Actions Std             0.260324
exploration/Actions Max             0.999856
exploration/Actions Min            -0.998951
exploration/Num Paths               5
exploration/Average Returns       -68.3171
evaluation/num steps total     337500
evaluation/num paths total       3375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.836091
evaluation/Rewards Std              1.22556
evaluation/Rewards Max             -0.0265977
evaluation/Rewards Min            -11.9658
evaluation/Returns Mean           -83.6091
evaluation/Returns Std             68.7209
evaluation/Returns Max             -6.85856
evaluation/Returns Min           -247.058
evaluation/Actions Mean             0.0020197
evaluation/Actions Std              0.185874
evaluation/Actions Max              0.999511
evaluation/Actions Min             -0.998835
evaluation/Num Paths               15
evaluation/Average Returns        -83.6091
time/data storing (s)               0.00277364
time/evaluation sampling (s)        0.329297
time/exploration sampling (s)       0.137604
time/logging (s)                    0.00475974
time/saving (s)                     0.00158385
time/training (s)                   1.93411
time/epoch (s)                      2.41013
time/total (s)                    548.118
Epoch                             224
-----------------------------  ---------------
2019-04-23 00:02:30.099943 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 225 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.678922
trainer/QF2 Loss                    0.678644
trainer/Policy Loss                48.3838
trainer/Q1 Predictions Mean       -46.8454
trainer/Q1 Predictions Std         33.4776
trainer/Q1 Predictions Max         -8.01809
trainer/Q1 Predictions Min       -125.15
trainer/Q2 Predictions Mean       -46.8565
trainer/Q2 Predictions Std         33.5066
trainer/Q2 Predictions Max         -7.95366
trainer/Q2 Predictions Min       -125.134
trainer/Q Targets Mean            -47.5143
trainer/Q Targets Std              33.78
trainer/Q Targets Max              -8.22939
trainer/Q Targets Min            -125.721
trainer/Log Pis Mean                1.86366
trainer/Log Pis Std                 1.121
trainer/Log Pis Max                 4.42729
trainer/Log Pis Min                -1.82703
trainer/Policy mu Mean              0.00730809
trainer/Policy mu Std               0.693637
trainer/Policy mu Max               2.53428
trainer/Policy mu Min              -2.86301
trainer/Policy log std Mean        -1.9846
trainer/Policy log std Std          0.539085
trainer/Policy log std Max         -0.392728
trainer/Policy log std Min         -2.82003
trainer/Alpha                       0.0580767
trainer/Alpha Loss                 -0.388032
exploration/num steps total    113200
exploration/num paths total      1132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.39375
exploration/Rewards Std             0.965986
exploration/Rewards Max            -0.0102691
exploration/Rewards Min            -8.51756
exploration/Returns Mean         -139.375
exploration/Returns Std            61.6838
exploration/Returns Max           -51.2865
exploration/Returns Min          -230.423
exploration/Actions Mean           -0.00428326
exploration/Actions Std             0.23777
exploration/Actions Max             0.999397
exploration/Actions Min            -0.999781
exploration/Num Paths               5
exploration/Average Returns      -139.375
evaluation/num steps total     339000
evaluation/num paths total       3390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.990939
evaluation/Rewards Std              1.17085
evaluation/Rewards Max             -0.0139909
evaluation/Rewards Min            -11.1801
evaluation/Returns Mean           -99.0939
evaluation/Returns Std             73.7916
evaluation/Returns Max             -6.97162
evaluation/Returns Min           -253.403
evaluation/Actions Mean             0.000314347
evaluation/Actions Std              0.191335
evaluation/Actions Max              0.998487
evaluation/Actions Min             -0.999932
evaluation/Num Paths               15
evaluation/Average Returns        -99.0939
time/data storing (s)               0.0028814
time/evaluation sampling (s)        0.324114
time/exploration sampling (s)       0.140817
time/logging (s)                    0.00486111
time/saving (s)                     0.00209149
time/training (s)                   1.94645
time/epoch (s)                      2.42121
time/total (s)                    550.543
Epoch                             225
-----------------------------  ----------------
2019-04-23 00:02:32.507541 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 226 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   81.7971
trainer/QF2 Loss                   81.6107
trainer/Policy Loss                45.2476
trainer/Q1 Predictions Mean       -43.5399
trainer/Q1 Predictions Std         29.4934
trainer/Q1 Predictions Max         -8.32126
trainer/Q1 Predictions Min       -115.753
trainer/Q2 Predictions Mean       -43.557
trainer/Q2 Predictions Std         29.4869
trainer/Q2 Predictions Max         -8.27208
trainer/Q2 Predictions Min       -115.814
trainer/Q Targets Mean            -42.5267
trainer/Q Targets Std              30.3308
trainer/Q Targets Max              -0.416784
trainer/Q Targets Min            -116.85
trainer/Log Pis Mean                2.10382
trainer/Log Pis Std                 1.13154
trainer/Log Pis Max                 4.76458
trainer/Log Pis Min                -3.05364
trainer/Policy mu Mean              0.0607001
trainer/Policy mu Std               0.659893
trainer/Policy mu Max               2.15305
trainer/Policy mu Min              -2.15086
trainer/Policy log std Mean        -2.05655
trainer/Policy log std Std          0.537848
trainer/Policy log std Max         -0.532786
trainer/Policy log std Min         -2.92442
trainer/Alpha                       0.0601929
trainer/Alpha Loss                  0.291786
exploration/num steps total    113700
exploration/num paths total      1137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.569833
exploration/Rewards Std             1.04813
exploration/Rewards Max            -0.00523767
exploration/Rewards Min            -9.37704
exploration/Returns Mean          -56.9833
exploration/Returns Std            20.29
exploration/Returns Max           -32.0023
exploration/Returns Min           -89.6372
exploration/Actions Mean           -0.0414945
exploration/Actions Std             0.217279
exploration/Actions Max             0.782425
exploration/Actions Min            -0.999979
exploration/Num Paths               5
exploration/Average Returns       -56.9833
evaluation/num steps total     340500
evaluation/num paths total       3405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.764037
evaluation/Rewards Std              0.997504
evaluation/Rewards Max             -0.00819731
evaluation/Rewards Min             -8.04008
evaluation/Returns Mean           -76.4037
evaluation/Returns Std             66.9428
evaluation/Returns Max            -24.877
evaluation/Returns Min           -235.421
evaluation/Actions Mean             0.000877757
evaluation/Actions Std              0.182301
evaluation/Actions Max              0.99913
evaluation/Actions Min             -0.998743
evaluation/Num Paths               15
evaluation/Average Returns        -76.4037
time/data storing (s)               0.00283251
time/evaluation sampling (s)        0.330204
time/exploration sampling (s)       0.138022
time/logging (s)                    0.00476113
time/saving (s)                     0.00195986
time/training (s)                   1.9214
time/epoch (s)                      2.39918
time/total (s)                    552.947
Epoch                             226
-----------------------------  ----------------
2019-04-23 00:02:34.932141 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 227 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.322098
trainer/QF2 Loss                    0.38624
trainer/Policy Loss                55.9767
trainer/Q1 Predictions Mean       -54.407
trainer/Q1 Predictions Std         32.3753
trainer/Q1 Predictions Max         -8.15759
trainer/Q1 Predictions Min       -137.578
trainer/Q2 Predictions Mean       -54.381
trainer/Q2 Predictions Std         32.3832
trainer/Q2 Predictions Max         -8.21492
trainer/Q2 Predictions Min       -136.758
trainer/Q Targets Mean            -54.8058
trainer/Q Targets Std              32.5525
trainer/Q Targets Max              -8.05509
trainer/Q Targets Min            -137.443
trainer/Log Pis Mean                2.00082
trainer/Log Pis Std                 1.19192
trainer/Log Pis Max                 6.03858
trainer/Log Pis Min                -1.29879
trainer/Policy mu Mean              0.0307133
trainer/Policy mu Std               0.796521
trainer/Policy mu Max               3.30912
trainer/Policy mu Min              -2.90119
trainer/Policy log std Mean        -1.91213
trainer/Policy log std Std          0.544573
trainer/Policy log std Max         -0.35973
trainer/Policy log std Min         -2.80489
trainer/Alpha                       0.0603527
trainer/Alpha Loss                  0.00229809
exploration/num steps total    114200
exploration/num paths total      1142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.584249
exploration/Rewards Std             0.78078
exploration/Rewards Max            -0.0437506
exploration/Rewards Min            -8.4429
exploration/Returns Mean          -58.4249
exploration/Returns Std            50.9503
exploration/Returns Max           -25.6037
exploration/Returns Min          -159.751
exploration/Actions Mean            0.00899876
exploration/Actions Std             0.201008
exploration/Actions Max             0.998688
exploration/Actions Min            -0.99908
exploration/Num Paths               5
exploration/Average Returns       -58.4249
evaluation/num steps total     342000
evaluation/num paths total       3420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.945506
evaluation/Rewards Std              1.04026
evaluation/Rewards Max             -0.0509162
evaluation/Rewards Min             -8.84099
evaluation/Returns Mean           -94.5506
evaluation/Returns Std             61.8339
evaluation/Returns Max            -23.3113
evaluation/Returns Min           -233.626
evaluation/Actions Mean             0.0121938
evaluation/Actions Std              0.185301
evaluation/Actions Max              0.999163
evaluation/Actions Min             -0.997884
evaluation/Num Paths               15
evaluation/Average Returns        -94.5506
time/data storing (s)               0.00279801
time/evaluation sampling (s)        0.324321
time/exploration sampling (s)       0.138497
time/logging (s)                    0.00480126
time/saving (s)                     0.00199007
time/training (s)                   1.94422
time/epoch (s)                      2.41663
time/total (s)                    555.368
Epoch                             227
-----------------------------  ---------------
2019-04-23 00:02:37.359814 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 228 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   44.9935
trainer/QF2 Loss                   44.8205
trainer/Policy Loss                48.3808
trainer/Q1 Predictions Mean       -46.5913
trainer/Q1 Predictions Std         35.2407
trainer/Q1 Predictions Max         -8.07021
trainer/Q1 Predictions Min       -125.791
trainer/Q2 Predictions Mean       -46.5851
trainer/Q2 Predictions Std         35.3408
trainer/Q2 Predictions Max         -7.93357
trainer/Q2 Predictions Min       -126.656
trainer/Q Targets Mean            -46.4448
trainer/Q Targets Std              35.7818
trainer/Q Targets Max              -2.83383
trainer/Q Targets Min            -126.153
trainer/Log Pis Mean                2.20765
trainer/Log Pis Std                 1.25204
trainer/Log Pis Max                 5.91452
trainer/Log Pis Min                -2.49077
trainer/Policy mu Mean              0.0562415
trainer/Policy mu Std               0.79231
trainer/Policy mu Max               3.89217
trainer/Policy mu Min              -2.67942
trainer/Policy log std Mean        -2.05641
trainer/Policy log std Std          0.586451
trainer/Policy log std Max         -0.21777
trainer/Policy log std Min         -2.90135
trainer/Alpha                       0.0594956
trainer/Alpha Loss                  0.585988
exploration/num steps total    114700
exploration/num paths total      1147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.754333
exploration/Rewards Std             1.35778
exploration/Rewards Max            -0.0167336
exploration/Rewards Min           -10.3678
exploration/Returns Mean          -75.4333
exploration/Returns Std            24.7582
exploration/Returns Max           -52.7443
exploration/Returns Min          -122.792
exploration/Actions Mean            0.00102816
exploration/Actions Std             0.245591
exploration/Actions Max             0.998868
exploration/Actions Min            -0.999974
exploration/Num Paths               5
exploration/Average Returns       -75.4333
evaluation/num steps total     343500
evaluation/num paths total       3435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.500559
evaluation/Rewards Std              0.9737
evaluation/Rewards Max             -0.0329419
evaluation/Rewards Min            -10.2479
evaluation/Returns Mean           -50.0559
evaluation/Returns Std             30.2986
evaluation/Returns Max             -8.53505
evaluation/Returns Min           -117.938
evaluation/Actions Mean             0.00495629
evaluation/Actions Std              0.187058
evaluation/Actions Max              0.999116
evaluation/Actions Min             -0.999056
evaluation/Num Paths               15
evaluation/Average Returns        -50.0559
time/data storing (s)               0.002779
time/evaluation sampling (s)        0.333661
time/exploration sampling (s)       0.140731
time/logging (s)                    0.00476986
time/saving (s)                     0.00197725
time/training (s)                   1.93742
time/epoch (s)                      2.42134
time/total (s)                    557.793
Epoch                             228
-----------------------------  ---------------
2019-04-23 00:02:39.792418 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 229 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.391721
trainer/QF2 Loss                    0.385343
trainer/Policy Loss                46.5552
trainer/Q1 Predictions Mean       -44.8881
trainer/Q1 Predictions Std         31.9183
trainer/Q1 Predictions Max         -8.28865
trainer/Q1 Predictions Min       -116.164
trainer/Q2 Predictions Mean       -44.8688
trainer/Q2 Predictions Std         31.9287
trainer/Q2 Predictions Max         -8.28186
trainer/Q2 Predictions Min       -116.261
trainer/Q Targets Mean            -45.0562
trainer/Q Targets Std              32.3279
trainer/Q Targets Max              -7.95408
trainer/Q Targets Min            -117.86
trainer/Log Pis Mean                2.02131
trainer/Log Pis Std                 1.24241
trainer/Log Pis Max                 6.39792
trainer/Log Pis Min                -2.64534
trainer/Policy mu Mean              0.0963921
trainer/Policy mu Std               0.744485
trainer/Policy mu Max               3.79908
trainer/Policy mu Min              -2.48322
trainer/Policy log std Mean        -1.9289
trainer/Policy log std Std          0.575548
trainer/Policy log std Max         -0.189221
trainer/Policy log std Min         -2.85691
trainer/Alpha                       0.0605515
trainer/Alpha Loss                  0.0597577
exploration/num steps total    115200
exploration/num paths total      1152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.20035
exploration/Rewards Std             0.772706
exploration/Rewards Max            -0.109934
exploration/Rewards Min            -6.19239
exploration/Returns Mean         -120.035
exploration/Returns Std            68.5857
exploration/Returns Max           -54.1997
exploration/Returns Min          -231.75
exploration/Actions Mean           -0.00273791
exploration/Actions Std             0.210186
exploration/Actions Max             0.996281
exploration/Actions Min            -0.991089
exploration/Num Paths               5
exploration/Average Returns      -120.035
evaluation/num steps total     345000
evaluation/num paths total       3450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.839634
evaluation/Rewards Std              1.16815
evaluation/Rewards Max             -0.0249573
evaluation/Rewards Min            -11.5725
evaluation/Returns Mean           -83.9634
evaluation/Returns Std             61.2675
evaluation/Returns Max            -23.0965
evaluation/Returns Min           -236.406
evaluation/Actions Mean             0.000933792
evaluation/Actions Std              0.19898
evaluation/Actions Max              0.999094
evaluation/Actions Min             -0.998229
evaluation/Num Paths               15
evaluation/Average Returns        -83.9634
time/data storing (s)               0.00281114
time/evaluation sampling (s)        0.322171
time/exploration sampling (s)       0.137724
time/logging (s)                    0.00478241
time/saving (s)                     0.0015895
time/training (s)                   1.95566
time/epoch (s)                      2.42474
time/total (s)                    560.222
Epoch                             229
-----------------------------  ----------------
2019-04-23 00:02:42.250977 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 230 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   11.3739
trainer/QF2 Loss                   11.4658
trainer/Policy Loss                52.0574
trainer/Q1 Predictions Mean       -50.4369
trainer/Q1 Predictions Std         33.0773
trainer/Q1 Predictions Max         -7.82258
trainer/Q1 Predictions Min       -116.757
trainer/Q2 Predictions Mean       -50.4694
trainer/Q2 Predictions Std         33.109
trainer/Q2 Predictions Max         -7.91307
trainer/Q2 Predictions Min       -116.979
trainer/Q Targets Mean            -50.6632
trainer/Q Targets Std              33.8348
trainer/Q Targets Max              -0.755167
trainer/Q Targets Min            -118.336
trainer/Log Pis Mean                1.92338
trainer/Log Pis Std                 1.53462
trainer/Log Pis Max                 7.79101
trainer/Log Pis Min                -1.95433
trainer/Policy mu Mean              0.00448177
trainer/Policy mu Std               0.804262
trainer/Policy mu Max               3.72362
trainer/Policy mu Min              -3.0997
trainer/Policy log std Mean        -1.96666
trainer/Policy log std Std          0.554212
trainer/Policy log std Max         -0.30999
trainer/Policy log std Min         -2.78361
trainer/Alpha                       0.0612384
trainer/Alpha Loss                 -0.214011
exploration/num steps total    115700
exploration/num paths total      1157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.888092
exploration/Rewards Std             1.28624
exploration/Rewards Max            -0.0181133
exploration/Rewards Min           -10.2196
exploration/Returns Mean          -88.8092
exploration/Returns Std            48.5572
exploration/Returns Max           -38.5569
exploration/Returns Min          -171.34
exploration/Actions Mean           -0.00977027
exploration/Actions Std             0.269835
exploration/Actions Max             0.999002
exploration/Actions Min            -0.999993
exploration/Num Paths               5
exploration/Average Returns       -88.8092
evaluation/num steps total     346500
evaluation/num paths total       3465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.654317
evaluation/Rewards Std              1.13339
evaluation/Rewards Max             -0.0478913
evaluation/Rewards Min            -10.1282
evaluation/Returns Mean           -65.4317
evaluation/Returns Std             51.1317
evaluation/Returns Max            -22.1943
evaluation/Returns Min           -181.317
evaluation/Actions Mean            -0.00286971
evaluation/Actions Std              0.197303
evaluation/Actions Max              0.99863
evaluation/Actions Min             -0.999721
evaluation/Num Paths               15
evaluation/Average Returns        -65.4317
time/data storing (s)               0.00281202
time/evaluation sampling (s)        0.329695
time/exploration sampling (s)       0.13697
time/logging (s)                    0.00476826
time/saving (s)                     0.0100193
time/training (s)                   1.96645
time/epoch (s)                      2.45071
time/total (s)                    562.677
Epoch                             230
-----------------------------  ---------------
2019-04-23 00:02:44.673831 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 231 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.537117
trainer/QF2 Loss                    0.614033
trainer/Policy Loss                46.6188
trainer/Q1 Predictions Mean       -44.8995
trainer/Q1 Predictions Std         34.6001
trainer/Q1 Predictions Max         -7.87155
trainer/Q1 Predictions Min       -137.391
trainer/Q2 Predictions Mean       -44.8641
trainer/Q2 Predictions Std         34.5404
trainer/Q2 Predictions Max         -7.81424
trainer/Q2 Predictions Min       -137.223
trainer/Q Targets Mean            -45.4579
trainer/Q Targets Std              34.8587
trainer/Q Targets Max              -7.82687
trainer/Q Targets Min            -138.389
trainer/Log Pis Mean                2.00227
trainer/Log Pis Std                 1.42195
trainer/Log Pis Max                 6.36873
trainer/Log Pis Min                -2.6515
trainer/Policy mu Mean              0.0826221
trainer/Policy mu Std               0.803571
trainer/Policy mu Max               2.70948
trainer/Policy mu Min              -3.13868
trainer/Policy log std Mean        -1.98104
trainer/Policy log std Std          0.588839
trainer/Policy log std Max         -0.342301
trainer/Policy log std Min         -2.87974
trainer/Alpha                       0.0627151
trainer/Alpha Loss                  0.00628098
exploration/num steps total    116200
exploration/num paths total      1162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.963437
exploration/Rewards Std             1.51392
exploration/Rewards Max            -0.00394767
exploration/Rewards Min           -11.5382
exploration/Returns Mean          -96.3437
exploration/Returns Std            68.9186
exploration/Returns Max           -30.3497
exploration/Returns Min          -196.153
exploration/Actions Mean            0.0348556
exploration/Actions Std             0.271726
exploration/Actions Max             0.998933
exploration/Actions Min            -0.997811
exploration/Num Paths               5
exploration/Average Returns       -96.3437
evaluation/num steps total     348000
evaluation/num paths total       3480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.873386
evaluation/Rewards Std              1.28083
evaluation/Rewards Max             -0.0107442
evaluation/Rewards Min            -11.5752
evaluation/Returns Mean           -87.3386
evaluation/Returns Std             66.3457
evaluation/Returns Max            -10.7483
evaluation/Returns Min           -188.433
evaluation/Actions Mean             0.0101176
evaluation/Actions Std              0.204356
evaluation/Actions Max              0.999132
evaluation/Actions Min             -0.999918
evaluation/Num Paths               15
evaluation/Average Returns        -87.3386
time/data storing (s)               0.00274358
time/evaluation sampling (s)        0.324753
time/exploration sampling (s)       0.138875
time/logging (s)                    0.00477329
time/saving (s)                     0.00181291
time/training (s)                   1.94173
time/epoch (s)                      2.41468
time/total (s)                    565.096
Epoch                             231
-----------------------------  ---------------
2019-04-23 00:02:47.113468 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 232 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.20701
trainer/QF2 Loss                    6.01131
trainer/Policy Loss                46.0898
trainer/Q1 Predictions Mean       -44.2586
trainer/Q1 Predictions Std         33.8109
trainer/Q1 Predictions Max         -7.54444
trainer/Q1 Predictions Min       -116.533
trainer/Q2 Predictions Mean       -44.2569
trainer/Q2 Predictions Std         33.8351
trainer/Q2 Predictions Max         -7.6126
trainer/Q2 Predictions Min       -116.716
trainer/Q Targets Mean            -44.7679
trainer/Q Targets Std              34.631
trainer/Q Targets Max              -1.93391
trainer/Q Targets Min            -118.391
trainer/Log Pis Mean                2.19007
trainer/Log Pis Std                 1.1749
trainer/Log Pis Max                 7.30495
trainer/Log Pis Min                -1.58133
trainer/Policy mu Mean              0.166632
trainer/Policy mu Std               0.634515
trainer/Policy mu Max               3.19315
trainer/Policy mu Min              -1.36315
trainer/Policy log std Mean        -2.06802
trainer/Policy log std Std          0.504055
trainer/Policy log std Max         -0.201075
trainer/Policy log std Min         -2.76238
trainer/Alpha                       0.0592025
trainer/Alpha Loss                  0.537309
exploration/num steps total    116700
exploration/num paths total      1167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.994275
exploration/Rewards Std             1.11499
exploration/Rewards Max            -0.0744308
exploration/Rewards Min           -10.8948
exploration/Returns Mean          -99.4275
exploration/Returns Std            42.9062
exploration/Returns Max           -28.2218
exploration/Returns Min          -159.907
exploration/Actions Mean            0.010407
exploration/Actions Std             0.206323
exploration/Actions Max             0.999423
exploration/Actions Min            -0.999786
exploration/Num Paths               5
exploration/Average Returns       -99.4275
evaluation/num steps total     349500
evaluation/num paths total       3495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.918344
evaluation/Rewards Std              1.04411
evaluation/Rewards Max             -0.00973878
evaluation/Rewards Min             -9.17699
evaluation/Returns Mean           -91.8344
evaluation/Returns Std             67.2392
evaluation/Returns Max            -21.5079
evaluation/Returns Min           -268.659
evaluation/Actions Mean            -0.00101602
evaluation/Actions Std              0.194407
evaluation/Actions Max              0.998418
evaluation/Actions Min             -0.999187
evaluation/Num Paths               15
evaluation/Average Returns        -91.8344
time/data storing (s)               0.00260904
time/evaluation sampling (s)        0.323436
time/exploration sampling (s)       0.143311
time/logging (s)                    0.0047942
time/saving (s)                     0.00158944
time/training (s)                   1.9557
time/epoch (s)                      2.43144
time/total (s)                    567.532
Epoch                             232
-----------------------------  ---------------
2019-04-23 00:02:49.533053 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 233 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   35.9599
trainer/QF2 Loss                   35.2981
trainer/Policy Loss                39.1304
trainer/Q1 Predictions Mean       -37.352
trainer/Q1 Predictions Std         29.6298
trainer/Q1 Predictions Max         -7.76703
trainer/Q1 Predictions Min       -116.665
trainer/Q2 Predictions Mean       -37.3692
trainer/Q2 Predictions Std         29.6147
trainer/Q2 Predictions Max         -7.82118
trainer/Q2 Predictions Min       -116.983
trainer/Q Targets Mean            -37.0251
trainer/Q Targets Std              29.9547
trainer/Q Targets Max              -0.0618239
trainer/Q Targets Min            -117.193
trainer/Log Pis Mean                2.08569
trainer/Log Pis Std                 1.56895
trainer/Log Pis Max                 8.22497
trainer/Log Pis Min                -2.57178
trainer/Policy mu Mean              0.0302869
trainer/Policy mu Std               0.797233
trainer/Policy mu Max               3.03265
trainer/Policy mu Min              -3.06713
trainer/Policy log std Mean        -2.00768
trainer/Policy log std Std          0.553598
trainer/Policy log std Max         -0.20911
trainer/Policy log std Min         -2.76172
trainer/Alpha                       0.054613
trainer/Alpha Loss                  0.249128
exploration/num steps total    117200
exploration/num paths total      1172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.09411
exploration/Rewards Std             1.21752
exploration/Rewards Max            -0.0107952
exploration/Rewards Min           -11.8156
exploration/Returns Mean         -109.411
exploration/Returns Std            78.5946
exploration/Returns Max           -28.9933
exploration/Returns Min          -232.006
exploration/Actions Mean            0.0277258
exploration/Actions Std             0.221612
exploration/Actions Max             0.998673
exploration/Actions Min            -0.99728
exploration/Num Paths               5
exploration/Average Returns      -109.411
evaluation/num steps total     351000
evaluation/num paths total       3510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.991799
evaluation/Rewards Std              1.10995
evaluation/Rewards Max             -0.0374953
evaluation/Rewards Min             -9.95815
evaluation/Returns Mean           -99.1799
evaluation/Returns Std             76.0358
evaluation/Returns Max             -6.4764
evaluation/Returns Min           -260.022
evaluation/Actions Mean             0.015521
evaluation/Actions Std              0.180783
evaluation/Actions Max              0.999628
evaluation/Actions Min             -0.999163
evaluation/Num Paths               15
evaluation/Average Returns        -99.1799
time/data storing (s)               0.00269836
time/evaluation sampling (s)        0.332351
time/exploration sampling (s)       0.134995
time/logging (s)                    0.00476386
time/saving (s)                     0.00197166
time/training (s)                   1.93459
time/epoch (s)                      2.41137
time/total (s)                    569.948
Epoch                             233
-----------------------------  ---------------
2019-04-23 00:02:51.954050 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 234 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.290069
trainer/QF2 Loss                    0.253646
trainer/Policy Loss                41.6446
trainer/Q1 Predictions Mean       -39.9058
trainer/Q1 Predictions Std         32.2529
trainer/Q1 Predictions Max         -8.02411
trainer/Q1 Predictions Min       -116.809
trainer/Q2 Predictions Mean       -39.9352
trainer/Q2 Predictions Std         32.2467
trainer/Q2 Predictions Max         -7.96981
trainer/Q2 Predictions Min       -117.06
trainer/Q Targets Mean            -40.1532
trainer/Q Targets Std              32.5532
trainer/Q Targets Max              -7.8257
trainer/Q Targets Min            -117.77
trainer/Log Pis Mean                2.07316
trainer/Log Pis Std                 1.13914
trainer/Log Pis Max                 6.46813
trainer/Log Pis Min                -0.806986
trainer/Policy mu Mean              0.0450939
trainer/Policy mu Std               0.632337
trainer/Policy mu Max               3.44345
trainer/Policy mu Min              -1.64764
trainer/Policy log std Mean        -2.14062
trainer/Policy log std Std          0.505771
trainer/Policy log std Max         -0.43662
trainer/Policy log std Min         -2.88526
trainer/Alpha                       0.0550471
trainer/Alpha Loss                  0.212154
exploration/num steps total    117700
exploration/num paths total      1177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.469199
exploration/Rewards Std             0.870277
exploration/Rewards Max            -0.00555437
exploration/Rewards Min            -8.251
exploration/Returns Mean          -46.9199
exploration/Returns Std            35.5404
exploration/Returns Max           -18.6945
exploration/Returns Min          -114.446
exploration/Actions Mean           -0.0177075
exploration/Actions Std             0.203663
exploration/Actions Max             0.995038
exploration/Actions Min            -0.998329
exploration/Num Paths               5
exploration/Average Returns       -46.9199
evaluation/num steps total     352500
evaluation/num paths total       3525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.524963
evaluation/Rewards Std              1.06785
evaluation/Rewards Max             -0.0265193
evaluation/Rewards Min            -10.904
evaluation/Returns Mean           -52.4963
evaluation/Returns Std             39.3612
evaluation/Returns Max             -4.97222
evaluation/Returns Min           -133.476
evaluation/Actions Mean             0.0135586
evaluation/Actions Std              0.190664
evaluation/Actions Max              0.999172
evaluation/Actions Min             -0.998738
evaluation/Num Paths               15
evaluation/Average Returns        -52.4963
time/data storing (s)               0.00275625
time/evaluation sampling (s)        0.330296
time/exploration sampling (s)       0.140534
time/logging (s)                    0.00478161
time/saving (s)                     0.00194837
time/training (s)                   1.93249
time/epoch (s)                      2.41281
time/total (s)                    572.365
Epoch                             234
-----------------------------  ---------------
2019-04-23 00:02:54.382206 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 235 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.374536
trainer/QF2 Loss                    0.433158
trainer/Policy Loss                46.3029
trainer/Q1 Predictions Mean       -44.7724
trainer/Q1 Predictions Std         33.3761
trainer/Q1 Predictions Max         -7.77199
trainer/Q1 Predictions Min       -122.076
trainer/Q2 Predictions Mean       -44.7992
trainer/Q2 Predictions Std         33.3681
trainer/Q2 Predictions Max         -7.77184
trainer/Q2 Predictions Min       -122.611
trainer/Q Targets Mean            -45.203
trainer/Q Targets Std              33.541
trainer/Q Targets Max              -7.88298
trainer/Q Targets Min            -120.889
trainer/Log Pis Mean                1.89594
trainer/Log Pis Std                 0.999157
trainer/Log Pis Max                 6.02644
trainer/Log Pis Min                -1.06344
trainer/Policy mu Mean             -0.0554027
trainer/Policy mu Std               0.714216
trainer/Policy mu Max               2.47431
trainer/Policy mu Min              -3.20274
trainer/Policy log std Mean        -1.97486
trainer/Policy log std Std          0.511957
trainer/Policy log std Max         -0.342313
trainer/Policy log std Min         -2.72435
trainer/Alpha                       0.0555344
trainer/Alpha Loss                 -0.300816
exploration/num steps total    118200
exploration/num paths total      1182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.937255
exploration/Rewards Std             0.852802
exploration/Rewards Max            -0.0250225
exploration/Rewards Min            -8.421
exploration/Returns Mean          -93.7255
exploration/Returns Std            50.9711
exploration/Returns Max           -35.3256
exploration/Returns Min          -155.082
exploration/Actions Mean            0.0162555
exploration/Actions Std             0.218021
exploration/Actions Max             0.999414
exploration/Actions Min            -0.976245
exploration/Num Paths               5
exploration/Average Returns       -93.7255
evaluation/num steps total     354000
evaluation/num paths total       3540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.724819
evaluation/Rewards Std              1.20587
evaluation/Rewards Max             -0.0515549
evaluation/Rewards Min            -10.0751
evaluation/Returns Mean           -72.4819
evaluation/Returns Std             48.5467
evaluation/Returns Max             -9.92745
evaluation/Returns Min           -182.127
evaluation/Actions Mean            -0.00179483
evaluation/Actions Std              0.203665
evaluation/Actions Max              0.99844
evaluation/Actions Min             -0.999857
evaluation/Num Paths               15
evaluation/Average Returns        -72.4819
time/data storing (s)               0.00269954
time/evaluation sampling (s)        0.328946
time/exploration sampling (s)       0.136429
time/logging (s)                    0.00370921
time/saving (s)                     0.00197787
time/training (s)                   1.94481
time/epoch (s)                      2.41857
time/total (s)                    574.788
Epoch                             235
-----------------------------  ---------------
2019-04-23 00:02:56.823957 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 236 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.102322
trainer/QF2 Loss                    0.123112
trainer/Policy Loss                42.0012
trainer/Q1 Predictions Mean       -40.3627
trainer/Q1 Predictions Std         33.6998
trainer/Q1 Predictions Max         -7.91563
trainer/Q1 Predictions Min       -117.555
trainer/Q2 Predictions Mean       -40.3741
trainer/Q2 Predictions Std         33.6835
trainer/Q2 Predictions Max         -7.98004
trainer/Q2 Predictions Min       -117.863
trainer/Q Targets Mean            -40.4055
trainer/Q Targets Std              33.7965
trainer/Q Targets Max              -7.81161
trainer/Q Targets Min            -117.284
trainer/Log Pis Mean                1.94144
trainer/Log Pis Std                 1.1458
trainer/Log Pis Max                 4.94357
trainer/Log Pis Min                -1.21615
trainer/Policy mu Mean              0.0571901
trainer/Policy mu Std               0.664054
trainer/Policy mu Max               3.32829
trainer/Policy mu Min              -2.76864
trainer/Policy log std Mean        -2.08986
trainer/Policy log std Std          0.51281
trainer/Policy log std Max         -0.575558
trainer/Policy log std Min         -2.84879
trainer/Alpha                       0.0575276
trainer/Alpha Loss                 -0.167236
exploration/num steps total    118700
exploration/num paths total      1187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.42886
exploration/Rewards Std             0.48514
exploration/Rewards Max            -0.00974731
exploration/Rewards Min            -5.34614
exploration/Returns Mean          -42.886
exploration/Returns Std            12.7806
exploration/Returns Max           -29.0038
exploration/Returns Min           -63.8722
exploration/Actions Mean           -0.0142
exploration/Actions Std             0.169027
exploration/Actions Max             0.740968
exploration/Actions Min            -0.998596
exploration/Num Paths               5
exploration/Average Returns       -42.886
evaluation/num steps total     355500
evaluation/num paths total       3555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.971438
evaluation/Rewards Std              0.993421
evaluation/Rewards Max             -0.0486055
evaluation/Rewards Min             -9.07746
evaluation/Returns Mean           -97.1438
evaluation/Returns Std             70.4662
evaluation/Returns Max            -25.0701
evaluation/Returns Min           -264.296
evaluation/Actions Mean             0.0150713
evaluation/Actions Std              0.187564
evaluation/Actions Max              0.997801
evaluation/Actions Min             -0.997606
evaluation/Num Paths               15
evaluation/Average Returns        -97.1438
time/data storing (s)               0.00268
time/evaluation sampling (s)        0.322817
time/exploration sampling (s)       0.138668
time/logging (s)                    0.00480252
time/saving (s)                     0.00198027
time/training (s)                   1.96435
time/epoch (s)                      2.4353
time/total (s)                    577.228
Epoch                             236
-----------------------------  ---------------
2019-04-23 00:02:59.301049 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 237 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.270862
trainer/QF2 Loss                    0.324254
trainer/Policy Loss                44.9682
trainer/Q1 Predictions Mean       -43.4131
trainer/Q1 Predictions Std         34.1286
trainer/Q1 Predictions Max         -7.98242
trainer/Q1 Predictions Min       -117.284
trainer/Q2 Predictions Mean       -43.3981
trainer/Q2 Predictions Std         34.0892
trainer/Q2 Predictions Max         -7.97523
trainer/Q2 Predictions Min       -117.363
trainer/Q Targets Mean            -43.4862
trainer/Q Targets Std              34.2832
trainer/Q Targets Max              -7.73203
trainer/Q Targets Min            -118.175
trainer/Log Pis Mean                1.95877
trainer/Log Pis Std                 1.04436
trainer/Log Pis Max                 4.01715
trainer/Log Pis Min                -1.19224
trainer/Policy mu Mean             -0.0155799
trainer/Policy mu Std               0.605706
trainer/Policy mu Max               2.06529
trainer/Policy mu Min              -2.96827
trainer/Policy log std Mean        -2.1099
trainer/Policy log std Std          0.487706
trainer/Policy log std Max         -0.406829
trainer/Policy log std Min         -2.78213
trainer/Alpha                       0.0581856
trainer/Alpha Loss                 -0.117245
exploration/num steps total    119200
exploration/num paths total      1192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.810865
exploration/Rewards Std             0.991891
exploration/Rewards Max            -0.0145631
exploration/Rewards Min            -9.29674
exploration/Returns Mean          -81.0865
exploration/Returns Std            44.6049
exploration/Returns Max           -36.1243
exploration/Returns Min          -150.642
exploration/Actions Mean           -0.00769433
exploration/Actions Std             0.227848
exploration/Actions Max             0.997758
exploration/Actions Min            -0.997363
exploration/Num Paths               5
exploration/Average Returns       -81.0865
evaluation/num steps total     357000
evaluation/num paths total       3570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.696109
evaluation/Rewards Std              0.967289
evaluation/Rewards Max             -0.0153998
evaluation/Rewards Min             -8.88003
evaluation/Returns Mean           -69.6109
evaluation/Returns Std             54.5555
evaluation/Returns Max             -9.76874
evaluation/Returns Min           -167.93
evaluation/Actions Mean             0.00948081
evaluation/Actions Std              0.170654
evaluation/Actions Max              0.998424
evaluation/Actions Min             -0.999241
evaluation/Num Paths               15
evaluation/Average Returns        -69.6109
time/data storing (s)               0.00266712
time/evaluation sampling (s)        0.32401
time/exploration sampling (s)       0.139745
time/logging (s)                    0.00478635
time/saving (s)                     0.00195131
time/training (s)                   1.99603
time/epoch (s)                      2.46919
time/total (s)                    579.702
Epoch                             237
-----------------------------  ---------------
2019-04-23 00:03:01.788166 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 238 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   52.5121
trainer/QF2 Loss                   52.4575
trainer/Policy Loss                44.8367
trainer/Q1 Predictions Mean       -43.2141
trainer/Q1 Predictions Std         32.1475
trainer/Q1 Predictions Max         -7.72901
trainer/Q1 Predictions Min       -126.745
trainer/Q2 Predictions Mean       -43.2349
trainer/Q2 Predictions Std         32.1196
trainer/Q2 Predictions Max         -7.72554
trainer/Q2 Predictions Min       -126.181
trainer/Q Targets Mean            -42.4896
trainer/Q Targets Std              32.9115
trainer/Q Targets Max              -0.117567
trainer/Q Targets Min            -127.959
trainer/Log Pis Mean                2.09254
trainer/Log Pis Std                 1.25624
trainer/Log Pis Max                 7.69179
trainer/Log Pis Min                -1.4595
trainer/Policy mu Mean             -0.0158684
trainer/Policy mu Std               0.823034
trainer/Policy mu Max               2.29074
trainer/Policy mu Min              -2.73584
trainer/Policy log std Mean        -1.9105
trainer/Policy log std Std          0.561675
trainer/Policy log std Max         -0.371974
trainer/Policy log std Min         -2.78886
trainer/Alpha                       0.0564935
trainer/Alpha Loss                  0.265908
exploration/num steps total    119700
exploration/num paths total      1197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.539247
exploration/Rewards Std             0.933102
exploration/Rewards Max            -0.0249605
exploration/Rewards Min            -9.04266
exploration/Returns Mean          -53.9247
exploration/Returns Std            13.9181
exploration/Returns Max           -27.5589
exploration/Returns Min           -65.7023
exploration/Actions Mean            0.0208607
exploration/Actions Std             0.229406
exploration/Actions Max             0.999511
exploration/Actions Min            -0.999611
exploration/Num Paths               5
exploration/Average Returns       -53.9247
evaluation/num steps total     358500
evaluation/num paths total       3585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.09113
evaluation/Rewards Std              1.06841
evaluation/Rewards Max             -0.0466988
evaluation/Rewards Min            -10.3383
evaluation/Returns Mean          -109.113
evaluation/Returns Std             67.3213
evaluation/Returns Max            -24.6715
evaluation/Returns Min           -238.567
evaluation/Actions Mean             0.00559642
evaluation/Actions Std              0.177412
evaluation/Actions Max              0.996513
evaluation/Actions Min             -0.998939
evaluation/Num Paths               15
evaluation/Average Returns       -109.113
time/data storing (s)               0.00293995
time/evaluation sampling (s)        0.328879
time/exploration sampling (s)       0.140494
time/logging (s)                    0.00479387
time/saving (s)                     0.00158627
time/training (s)                   2.0002
time/epoch (s)                      2.47889
time/total (s)                    582.185
Epoch                             238
-----------------------------  ---------------
2019-04-23 00:03:04.252225 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 239 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.421637
trainer/QF2 Loss                    0.421291
trainer/Policy Loss                39.2734
trainer/Q1 Predictions Mean       -37.4873
trainer/Q1 Predictions Std         29.4453
trainer/Q1 Predictions Max         -7.61928
trainer/Q1 Predictions Min       -115.561
trainer/Q2 Predictions Mean       -37.4767
trainer/Q2 Predictions Std         29.3993
trainer/Q2 Predictions Max         -7.63736
trainer/Q2 Predictions Min       -115.506
trainer/Q Targets Mean            -37.683
trainer/Q Targets Std              29.7392
trainer/Q Targets Max              -7.57423
trainer/Q Targets Min            -116.671
trainer/Log Pis Mean                2.12745
trainer/Log Pis Std                 1.20654
trainer/Log Pis Max                 6.57645
trainer/Log Pis Min                -2.75909
trainer/Policy mu Mean             -0.0672743
trainer/Policy mu Std               0.632089
trainer/Policy mu Max               2.1277
trainer/Policy mu Min              -2.73337
trainer/Policy log std Mean        -2.10903
trainer/Policy log std Std          0.495574
trainer/Policy log std Max         -0.579603
trainer/Policy log std Min         -2.79159
trainer/Alpha                       0.0561887
trainer/Alpha Loss                  0.366962
exploration/num steps total    120200
exploration/num paths total      1202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.449914
exploration/Rewards Std             1.28652
exploration/Rewards Max            -0.000657455
exploration/Rewards Min           -10.4465
exploration/Returns Mean          -44.9914
exploration/Returns Std            19.7329
exploration/Returns Max           -14.6379
exploration/Returns Min           -67.3602
exploration/Actions Mean            0.0131198
exploration/Actions Std             0.235282
exploration/Actions Max             0.999892
exploration/Actions Min            -0.999537
exploration/Num Paths               5
exploration/Average Returns       -44.9914
evaluation/num steps total     360000
evaluation/num paths total       3600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.961154
evaluation/Rewards Std              1.26442
evaluation/Rewards Max             -0.0427451
evaluation/Rewards Min            -10.0616
evaluation/Returns Mean           -96.1154
evaluation/Returns Std             77.1066
evaluation/Returns Max             -8.60722
evaluation/Returns Min           -246.492
evaluation/Actions Mean            -0.000486788
evaluation/Actions Std              0.192009
evaluation/Actions Max              0.999139
evaluation/Actions Min             -0.999275
evaluation/Num Paths               15
evaluation/Average Returns        -96.1154
time/data storing (s)               0.00286324
time/evaluation sampling (s)        0.330671
time/exploration sampling (s)       0.142958
time/logging (s)                    0.00480242
time/saving (s)                     0.00199546
time/training (s)                   1.97252
time/epoch (s)                      2.45581
time/total (s)                    584.646
Epoch                             239
-----------------------------  ----------------
2019-04-23 00:03:06.668861 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 240 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.09121
trainer/QF2 Loss                    1.28161
trainer/Policy Loss                47.4449
trainer/Q1 Predictions Mean       -45.5251
trainer/Q1 Predictions Std         32.1006
trainer/Q1 Predictions Max         -7.45993
trainer/Q1 Predictions Min       -129.309
trainer/Q2 Predictions Mean       -45.4854
trainer/Q2 Predictions Std         32.1281
trainer/Q2 Predictions Max         -7.39269
trainer/Q2 Predictions Min       -129.916
trainer/Q Targets Mean            -46.1874
trainer/Q Targets Std              32.7123
trainer/Q Targets Max              -7.53644
trainer/Q Targets Min            -128.827
trainer/Log Pis Mean                2.14246
trainer/Log Pis Std                 1.84019
trainer/Log Pis Max                 9.32238
trainer/Log Pis Min                -2.57544
trainer/Policy mu Mean             -0.0488895
trainer/Policy mu Std               0.863079
trainer/Policy mu Max               3.66996
trainer/Policy mu Min              -3.49369
trainer/Policy log std Mean        -2.09742
trainer/Policy log std Std          0.575528
trainer/Policy log std Max         -0.103565
trainer/Policy log std Min         -2.82287
trainer/Alpha                       0.0580289
trainer/Alpha Loss                  0.405575
exploration/num steps total    120700
exploration/num paths total      1207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.07894
exploration/Rewards Std             0.983887
exploration/Rewards Max            -0.0792844
exploration/Rewards Min            -8.26853
exploration/Returns Mean         -107.894
exploration/Returns Std            87.9333
exploration/Returns Max           -32.104
exploration/Returns Min          -259.574
exploration/Actions Mean           -0.0101951
exploration/Actions Std             0.180189
exploration/Actions Max             0.868173
exploration/Actions Min            -0.998963
exploration/Num Paths               5
exploration/Average Returns      -107.894
evaluation/num steps total     361500
evaluation/num paths total       3615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.722113
evaluation/Rewards Std              1.04887
evaluation/Rewards Max             -0.0359522
evaluation/Rewards Min             -9.6878
evaluation/Returns Mean           -72.2113
evaluation/Returns Std             50.8755
evaluation/Returns Max            -16.4112
evaluation/Returns Min           -153.551
evaluation/Actions Mean             0.00925931
evaluation/Actions Std              0.19127
evaluation/Actions Max              0.998788
evaluation/Actions Min             -0.998946
evaluation/Num Paths               15
evaluation/Average Returns        -72.2113
time/data storing (s)               0.00283494
time/evaluation sampling (s)        0.329217
time/exploration sampling (s)       0.137583
time/logging (s)                    0.00476192
time/saving (s)                     0.0015831
time/training (s)                   1.93204
time/epoch (s)                      2.40802
time/total (s)                    587.058
Epoch                             240
-----------------------------  ---------------
2019-04-23 00:03:09.088428 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 241 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.79739
trainer/QF2 Loss                    7.87453
trainer/Policy Loss                42.6445
trainer/Q1 Predictions Mean       -41.105
trainer/Q1 Predictions Std         33.2644
trainer/Q1 Predictions Max         -7.71725
trainer/Q1 Predictions Min       -116.06
trainer/Q2 Predictions Mean       -41.1418
trainer/Q2 Predictions Std         33.2838
trainer/Q2 Predictions Max         -7.74944
trainer/Q2 Predictions Min       -116.122
trainer/Q Targets Mean            -40.9793
trainer/Q Targets Std              33.8169
trainer/Q Targets Max              -0.699258
trainer/Q Targets Min            -117.046
trainer/Log Pis Mean                1.8284
trainer/Log Pis Std                 1.41059
trainer/Log Pis Max                 7.86809
trainer/Log Pis Min                -3.39977
trainer/Policy mu Mean              0.0675125
trainer/Policy mu Std               0.613125
trainer/Policy mu Max               3.13614
trainer/Policy mu Min              -3.0844
trainer/Policy log std Mean        -2.12307
trainer/Policy log std Std          0.481921
trainer/Policy log std Max         -0.471424
trainer/Policy log std Min         -2.7805
trainer/Alpha                       0.0604103
trainer/Alpha Loss                 -0.481597
exploration/num steps total    121200
exploration/num paths total      1212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.03461
exploration/Rewards Std             1.09594
exploration/Rewards Max            -0.0240972
exploration/Rewards Min            -9.37618
exploration/Returns Mean         -103.461
exploration/Returns Std            86.5638
exploration/Returns Max           -35.4151
exploration/Returns Min          -269.321
exploration/Actions Mean           -0.0179413
exploration/Actions Std             0.186797
exploration/Actions Max             0.869036
exploration/Actions Min            -0.999571
exploration/Num Paths               5
exploration/Average Returns      -103.461
evaluation/num steps total     363000
evaluation/num paths total       3630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.27049
evaluation/Rewards Std              1.08377
evaluation/Rewards Max             -0.0403711
evaluation/Rewards Min             -9.71607
evaluation/Returns Mean          -127.049
evaluation/Returns Std             77.0282
evaluation/Returns Max            -23.2576
evaluation/Returns Min           -253.321
evaluation/Actions Mean            -0.00545967
evaluation/Actions Std              0.174178
evaluation/Actions Max              0.998731
evaluation/Actions Min             -0.999816
evaluation/Num Paths               15
evaluation/Average Returns       -127.049
time/data storing (s)               0.0027545
time/evaluation sampling (s)        0.326419
time/exploration sampling (s)       0.139128
time/logging (s)                    0.0048027
time/saving (s)                     0.00196373
time/training (s)                   1.93629
time/epoch (s)                      2.41135
time/total (s)                    589.474
Epoch                             241
-----------------------------  ---------------
2019-04-23 00:03:11.501556 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 242 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  120.124
trainer/QF2 Loss                  120.06
trainer/Policy Loss                45.9357
trainer/Q1 Predictions Mean       -44.1987
trainer/Q1 Predictions Std         32.1127
trainer/Q1 Predictions Max         -7.09735
trainer/Q1 Predictions Min       -113.042
trainer/Q2 Predictions Mean       -44.1976
trainer/Q2 Predictions Std         32.1157
trainer/Q2 Predictions Max         -7.04676
trainer/Q2 Predictions Min       -112.789
trainer/Q Targets Mean            -44.0787
trainer/Q Targets Std              32.4166
trainer/Q Targets Max              -2.45319
trainer/Q Targets Min            -116.062
trainer/Log Pis Mean                2.0082
trainer/Log Pis Std                 0.997878
trainer/Log Pis Max                 4.22222
trainer/Log Pis Min                -1.45364
trainer/Policy mu Mean             -0.0302034
trainer/Policy mu Std               0.504504
trainer/Policy mu Max               3.23049
trainer/Policy mu Min              -2.09995
trainer/Policy log std Mean        -2.15395
trainer/Policy log std Std          0.422253
trainer/Policy log std Max         -0.46642
trainer/Policy log std Min         -2.8818
trainer/Alpha                       0.060923
trainer/Alpha Loss                  0.0229519
exploration/num steps total    121700
exploration/num paths total      1217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.481351
exploration/Rewards Std             0.837107
exploration/Rewards Max            -0.00627778
exploration/Rewards Min            -6.23353
exploration/Returns Mean          -48.1351
exploration/Returns Std            38.1071
exploration/Returns Max           -19.6597
exploration/Returns Min          -123.536
exploration/Actions Mean           -0.0108693
exploration/Actions Std             0.208735
exploration/Actions Max             0.994072
exploration/Actions Min            -0.998467
exploration/Num Paths               5
exploration/Average Returns       -48.1351
evaluation/num steps total     364500
evaluation/num paths total       3645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.63532
evaluation/Rewards Std              1.15211
evaluation/Rewards Max             -0.0697773
evaluation/Rewards Min            -10.0418
evaluation/Returns Mean           -63.532
evaluation/Returns Std             57.8007
evaluation/Returns Max            -16.2026
evaluation/Returns Min           -249.521
evaluation/Actions Mean            -0.0208269
evaluation/Actions Std              0.194669
evaluation/Actions Max              0.995194
evaluation/Actions Min             -0.99933
evaluation/Num Paths               15
evaluation/Average Returns        -63.532
time/data storing (s)               0.00277476
time/evaluation sampling (s)        0.323258
time/exploration sampling (s)       0.13783
time/logging (s)                    0.00479029
time/saving (s)                     0.00195814
time/training (s)                   1.93504
time/epoch (s)                      2.40565
time/total (s)                    591.884
Epoch                             242
-----------------------------  ---------------
2019-04-23 00:03:13.932519 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 243 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  117.84
trainer/QF2 Loss                  117.678
trainer/Policy Loss                38.1149
trainer/Q1 Predictions Mean       -36.1988
trainer/Q1 Predictions Std         29.3745
trainer/Q1 Predictions Max         -7.51845
trainer/Q1 Predictions Min       -111.644
trainer/Q2 Predictions Mean       -36.112
trainer/Q2 Predictions Std         29.3529
trainer/Q2 Predictions Max         -7.35661
trainer/Q2 Predictions Min       -111.241
trainer/Q Targets Mean            -35.6415
trainer/Q Targets Std              29.2136
trainer/Q Targets Max              -2.46488
trainer/Q Targets Min            -114.247
trainer/Log Pis Mean                2.21136
trainer/Log Pis Std                 1.15529
trainer/Log Pis Max                 5.59037
trainer/Log Pis Min                -2.74979
trainer/Policy mu Mean             -0.0314146
trainer/Policy mu Std               0.624206
trainer/Policy mu Max               2.59631
trainer/Policy mu Min              -3.05032
trainer/Policy log std Mean        -2.21471
trainer/Policy log std Std          0.477647
trainer/Policy log std Max         -0.271642
trainer/Policy log std Min         -2.89922
trainer/Alpha                       0.0597436
trainer/Alpha Loss                  0.59558
exploration/num steps total    122200
exploration/num paths total      1222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.758502
exploration/Rewards Std             1.03292
exploration/Rewards Max            -0.00320066
exploration/Rewards Min           -11.4353
exploration/Returns Mean          -75.8502
exploration/Returns Std            54.9645
exploration/Returns Max           -10.3782
exploration/Returns Min          -133.861
exploration/Actions Mean            0.000475016
exploration/Actions Std             0.191809
exploration/Actions Max             0.989712
exploration/Actions Min            -0.993465
exploration/Num Paths               5
exploration/Average Returns       -75.8502
evaluation/num steps total     366000
evaluation/num paths total       3660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.04949
evaluation/Rewards Std              1.32913
evaluation/Rewards Max             -0.0127714
evaluation/Rewards Min            -10.2987
evaluation/Returns Mean          -104.949
evaluation/Returns Std             83.4805
evaluation/Returns Max            -17.2954
evaluation/Returns Min           -277.083
evaluation/Actions Mean            -0.00385391
evaluation/Actions Std              0.200147
evaluation/Actions Max              0.997769
evaluation/Actions Min             -0.999761
evaluation/Num Paths               15
evaluation/Average Returns       -104.949
time/data storing (s)               0.00265177
time/evaluation sampling (s)        0.329953
time/exploration sampling (s)       0.140258
time/logging (s)                    0.00483041
time/saving (s)                     0.0105898
time/training (s)                   1.93462
time/epoch (s)                      2.4229
time/total (s)                    594.311
Epoch                             243
-----------------------------  ----------------
2019-04-23 00:03:16.366657 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 244 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.549721
trainer/QF2 Loss                    0.55862
trainer/Policy Loss                49.4866
trainer/Q1 Predictions Mean       -47.6619
trainer/Q1 Predictions Std         33.1615
trainer/Q1 Predictions Max         -7.46748
trainer/Q1 Predictions Min       -114.075
trainer/Q2 Predictions Mean       -47.6958
trainer/Q2 Predictions Std         33.1904
trainer/Q2 Predictions Max         -7.49943
trainer/Q2 Predictions Min       -114.121
trainer/Q Targets Mean            -48.0913
trainer/Q Targets Std              33.5368
trainer/Q Targets Max              -7.48817
trainer/Q Targets Min            -115.529
trainer/Log Pis Mean                2.19436
trainer/Log Pis Std                 1.14572
trainer/Log Pis Max                 5.3614
trainer/Log Pis Min                -2.026
trainer/Policy mu Mean              0.074239
trainer/Policy mu Std               0.743859
trainer/Policy mu Max               3.57057
trainer/Policy mu Min              -2.57327
trainer/Policy log std Mean        -2.10206
trainer/Policy log std Std          0.515846
trainer/Policy log std Max         -0.629191
trainer/Policy log std Min         -2.88
trainer/Alpha                       0.059004
trainer/Alpha Loss                  0.550084
exploration/num steps total    122700
exploration/num paths total      1227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.541112
exploration/Rewards Std             0.92521
exploration/Rewards Max            -0.0105756
exploration/Rewards Min            -9.3218
exploration/Returns Mean          -54.1112
exploration/Returns Std             8.32193
exploration/Returns Max           -46.9942
exploration/Returns Min           -68.7224
exploration/Actions Mean            0.0192714
exploration/Actions Std             0.205354
exploration/Actions Max             0.999029
exploration/Actions Min            -0.982732
exploration/Num Paths               5
exploration/Average Returns       -54.1112
evaluation/num steps total     367500
evaluation/num paths total       3675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.716816
evaluation/Rewards Std              0.920585
evaluation/Rewards Max             -0.0205788
evaluation/Rewards Min             -9.47256
evaluation/Returns Mean           -71.6816
evaluation/Returns Std             58.6551
evaluation/Returns Max            -11.3016
evaluation/Returns Min           -241.807
evaluation/Actions Mean            -0.00199986
evaluation/Actions Std              0.173173
evaluation/Actions Max              0.997235
evaluation/Actions Min             -0.995844
evaluation/Num Paths               15
evaluation/Average Returns        -71.6816
time/data storing (s)               0.00261294
time/evaluation sampling (s)        0.331224
time/exploration sampling (s)       0.141241
time/logging (s)                    0.00479432
time/saving (s)                     0.00199056
time/training (s)                   1.94393
time/epoch (s)                      2.42579
time/total (s)                    596.741
Epoch                             244
-----------------------------  ---------------
2019-04-23 00:03:18.819802 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 245 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.27905
trainer/QF2 Loss                    1.35164
trainer/Policy Loss                44.3548
trainer/Q1 Predictions Mean       -42.6928
trainer/Q1 Predictions Std         32.8344
trainer/Q1 Predictions Max         -7.0725
trainer/Q1 Predictions Min       -121.653
trainer/Q2 Predictions Mean       -42.6645
trainer/Q2 Predictions Std         32.8337
trainer/Q2 Predictions Max         -7.04418
trainer/Q2 Predictions Min       -121.376
trainer/Q Targets Mean            -43.5276
trainer/Q Targets Std              33.4973
trainer/Q Targets Max              -7.39379
trainer/Q Targets Min            -123.279
trainer/Log Pis Mean                2.0467
trainer/Log Pis Std                 1.33342
trainer/Log Pis Max                 7.35724
trainer/Log Pis Min                -3.87658
trainer/Policy mu Mean             -0.0835397
trainer/Policy mu Std               0.709354
trainer/Policy mu Max               3.0587
trainer/Policy mu Min              -2.7039
trainer/Policy log std Mean        -2.08386
trainer/Policy log std Std          0.543862
trainer/Policy log std Max         -0.318331
trainer/Policy log std Min         -2.83698
trainer/Alpha                       0.0576683
trainer/Alpha Loss                  0.133238
exploration/num steps total    123200
exploration/num paths total      1232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.14837
exploration/Rewards Std             1.20678
exploration/Rewards Max            -0.00381462
exploration/Rewards Min            -9.23568
exploration/Returns Mean         -114.837
exploration/Returns Std            60.4471
exploration/Returns Max           -30.733
exploration/Returns Min          -180.315
exploration/Actions Mean            0.0226268
exploration/Actions Std             0.259853
exploration/Actions Max             0.998811
exploration/Actions Min            -0.996748
exploration/Num Paths               5
exploration/Average Returns      -114.837
evaluation/num steps total     369000
evaluation/num paths total       3690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.617547
evaluation/Rewards Std              1.29337
evaluation/Rewards Max             -0.0300991
evaluation/Rewards Min            -10.8377
evaluation/Returns Mean           -61.7547
evaluation/Returns Std             49.5831
evaluation/Returns Max            -18.1919
evaluation/Returns Min           -231.356
evaluation/Actions Mean            -0.0194781
evaluation/Actions Std              0.208804
evaluation/Actions Max              0.998549
evaluation/Actions Min             -0.999779
evaluation/Num Paths               15
evaluation/Average Returns        -61.7547
time/data storing (s)               0.00285414
time/evaluation sampling (s)        0.325286
time/exploration sampling (s)       0.142088
time/logging (s)                    0.00353679
time/saving (s)                     0.00160345
time/training (s)                   1.96813
time/epoch (s)                      2.4435
time/total (s)                    599.189
Epoch                             245
-----------------------------  ---------------
2019-04-23 00:03:21.213769 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 246 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   43.7078
trainer/QF2 Loss                   43.76
trainer/Policy Loss                38.932
trainer/Q1 Predictions Mean       -37.0953
trainer/Q1 Predictions Std         27.1923
trainer/Q1 Predictions Max         -7.20894
trainer/Q1 Predictions Min       -113.729
trainer/Q2 Predictions Mean       -37.1344
trainer/Q2 Predictions Std         27.2194
trainer/Q2 Predictions Max         -7.31249
trainer/Q2 Predictions Min       -114.084
trainer/Q Targets Mean            -36.7561
trainer/Q Targets Std              27.4482
trainer/Q Targets Max              -2.07117
trainer/Q Targets Min            -113.882
trainer/Log Pis Mean                2.10106
trainer/Log Pis Std                 1.21402
trainer/Log Pis Max                 7.46131
trainer/Log Pis Min                -2.0282
trainer/Policy mu Mean             -0.00854122
trainer/Policy mu Std               0.599743
trainer/Policy mu Max               2.64159
trainer/Policy mu Min              -4.25106
trainer/Policy log std Mean        -2.16491
trainer/Policy log std Std          0.456626
trainer/Policy log std Max         -0.13435
trainer/Policy log std Min         -2.8534
trainer/Alpha                       0.0600116
trainer/Alpha Loss                  0.284285
exploration/num steps total    123700
exploration/num paths total      1237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.587467
exploration/Rewards Std             0.920777
exploration/Rewards Max            -0.0132392
exploration/Rewards Min            -7.41639
exploration/Returns Mean          -58.7467
exploration/Returns Std            33.2213
exploration/Returns Max           -29.9583
exploration/Returns Min          -122.445
exploration/Actions Mean            0.00278583
exploration/Actions Std             0.21731
exploration/Actions Max             0.998358
exploration/Actions Min            -0.994899
exploration/Num Paths               5
exploration/Average Returns       -58.7467
evaluation/num steps total     370500
evaluation/num paths total       3705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.615806
evaluation/Rewards Std              1.19136
evaluation/Rewards Max             -0.020268
evaluation/Rewards Min            -10.6756
evaluation/Returns Mean           -61.5806
evaluation/Returns Std             57.3874
evaluation/Returns Max            -13.1295
evaluation/Returns Min           -237.918
evaluation/Actions Mean            -0.0196677
evaluation/Actions Std              0.202427
evaluation/Actions Max              0.998745
evaluation/Actions Min             -0.999784
evaluation/Num Paths               15
evaluation/Average Returns        -61.5806
time/data storing (s)               0.00259209
time/evaluation sampling (s)        0.327252
time/exploration sampling (s)       0.135711
time/logging (s)                    0.00478261
time/saving (s)                     0.00196102
time/training (s)                   1.91516
time/epoch (s)                      2.38746
time/total (s)                    601.581
Epoch                             246
-----------------------------  ---------------
2019-04-23 00:03:23.654750 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 247 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  123.638
trainer/QF2 Loss                  123.929
trainer/Policy Loss                41.6948
trainer/Q1 Predictions Mean       -40.0451
trainer/Q1 Predictions Std         32.1138
trainer/Q1 Predictions Max         -7.30588
trainer/Q1 Predictions Min       -114.347
trainer/Q2 Predictions Mean       -40.0585
trainer/Q2 Predictions Std         32.1115
trainer/Q2 Predictions Max         -7.25873
trainer/Q2 Predictions Min       -114.527
trainer/Q Targets Mean            -39.2196
trainer/Q Targets Std              31.6494
trainer/Q Targets Max              -2.7798
trainer/Q Targets Min            -115.37
trainer/Log Pis Mean                1.89532
trainer/Log Pis Std                 1.03785
trainer/Log Pis Max                 3.29117
trainer/Log Pis Min                -2.68937
trainer/Policy mu Mean             -0.0320456
trainer/Policy mu Std               0.453591
trainer/Policy mu Max               2.78072
trainer/Policy mu Min              -2.01157
trainer/Policy log std Mean        -2.19016
trainer/Policy log std Std          0.3862
trainer/Policy log std Max         -0.753982
trainer/Policy log std Min         -2.76754
trainer/Alpha                       0.061824
trainer/Alpha Loss                 -0.291357
exploration/num steps total    124200
exploration/num paths total      1242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.761979
exploration/Rewards Std             0.823511
exploration/Rewards Max            -0.0618177
exploration/Rewards Min            -7.97837
exploration/Returns Mean          -76.1979
exploration/Returns Std            58.3051
exploration/Returns Max           -28.6124
exploration/Returns Min          -185.489
exploration/Actions Mean            0.00917712
exploration/Actions Std             0.219429
exploration/Actions Max             0.995822
exploration/Actions Min            -0.995921
exploration/Num Paths               5
exploration/Average Returns       -76.1979
evaluation/num steps total     372000
evaluation/num paths total       3720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.741876
evaluation/Rewards Std              1.17163
evaluation/Rewards Max             -0.073574
evaluation/Rewards Min            -11.0884
evaluation/Returns Mean           -74.1876
evaluation/Returns Std             58.3526
evaluation/Returns Max            -15.5299
evaluation/Returns Min           -229.359
evaluation/Actions Mean             0.00425205
evaluation/Actions Std              0.190274
evaluation/Actions Max              0.998687
evaluation/Actions Min             -0.999479
evaluation/Num Paths               15
evaluation/Average Returns        -74.1876
time/data storing (s)               0.00267234
time/evaluation sampling (s)        0.327116
time/exploration sampling (s)       0.137245
time/logging (s)                    0.00476434
time/saving (s)                     0.00195669
time/training (s)                   1.95891
time/epoch (s)                      2.43266
time/total (s)                    604.018
Epoch                             247
-----------------------------  ---------------
2019-04-23 00:03:26.090728 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 248 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   26.5873
trainer/QF2 Loss                   26.8187
trainer/Policy Loss                49.1809
trainer/Q1 Predictions Mean       -47.4937
trainer/Q1 Predictions Std         31.0567
trainer/Q1 Predictions Max         -7.55528
trainer/Q1 Predictions Min       -117.571
trainer/Q2 Predictions Mean       -47.4718
trainer/Q2 Predictions Std         31.0669
trainer/Q2 Predictions Max         -7.32593
trainer/Q2 Predictions Min       -117.175
trainer/Q Targets Mean            -47.317
trainer/Q Targets Std              31.8003
trainer/Q Targets Max              -0.743527
trainer/Q Targets Min            -117.667
trainer/Log Pis Mean                2.04732
trainer/Log Pis Std                 1.39026
trainer/Log Pis Max                 8.05343
trainer/Log Pis Min                -2.00481
trainer/Policy mu Mean             -0.0208501
trainer/Policy mu Std               0.716115
trainer/Policy mu Max               3.58726
trainer/Policy mu Min              -3.11636
trainer/Policy log std Mean        -2.0653
trainer/Policy log std Std          0.548101
trainer/Policy log std Max         -0.133324
trainer/Policy log std Min         -2.80007
trainer/Alpha                       0.0627365
trainer/Alpha Loss                  0.131022
exploration/num steps total    124700
exploration/num paths total      1247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.587925
exploration/Rewards Std             1.09372
exploration/Rewards Max            -0.0022717
exploration/Rewards Min           -11.2567
exploration/Returns Mean          -58.7925
exploration/Returns Std            43.6818
exploration/Returns Max           -10.0314
exploration/Returns Min          -116.967
exploration/Actions Mean           -0.00855258
exploration/Actions Std             0.210785
exploration/Actions Max             0.996573
exploration/Actions Min            -0.998794
exploration/Num Paths               5
exploration/Average Returns       -58.7925
evaluation/num steps total     373500
evaluation/num paths total       3735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.919324
evaluation/Rewards Std              1.31773
evaluation/Rewards Max             -0.0106172
evaluation/Rewards Min            -10.4254
evaluation/Returns Mean           -91.9324
evaluation/Returns Std             89.9794
evaluation/Returns Max             -8.87097
evaluation/Returns Min           -268.626
evaluation/Actions Mean             0.00311681
evaluation/Actions Std              0.197182
evaluation/Actions Max              0.999776
evaluation/Actions Min             -0.999453
evaluation/Num Paths               15
evaluation/Average Returns        -91.9324
time/data storing (s)               0.00273998
time/evaluation sampling (s)        0.320227
time/exploration sampling (s)       0.137576
time/logging (s)                    0.00482145
time/saving (s)                     0.0016144
time/training (s)                   1.96068
time/epoch (s)                      2.42766
time/total (s)                    606.45
Epoch                             248
-----------------------------  ---------------
2019-04-23 00:03:28.502005 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 249 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  121.809
trainer/QF2 Loss                  121.677
trainer/Policy Loss                40.5704
trainer/Q1 Predictions Mean       -38.7916
trainer/Q1 Predictions Std         30.2151
trainer/Q1 Predictions Max         -7.30482
trainer/Q1 Predictions Min       -113.006
trainer/Q2 Predictions Mean       -38.7459
trainer/Q2 Predictions Std         30.2111
trainer/Q2 Predictions Max         -7.13999
trainer/Q2 Predictions Min       -113.095
trainer/Q Targets Mean            -38.3122
trainer/Q Targets Std              30.0779
trainer/Q Targets Max              -2.87935
trainer/Q Targets Min            -115.323
trainer/Log Pis Mean                2.0347
trainer/Log Pis Std                 1.07187
trainer/Log Pis Max                 5.00353
trainer/Log Pis Min                -1.99187
trainer/Policy mu Mean              0.0414069
trainer/Policy mu Std               0.592227
trainer/Policy mu Max               3.35284
trainer/Policy mu Min              -2.64001
trainer/Policy log std Mean        -2.13869
trainer/Policy log std Std          0.494126
trainer/Policy log std Max         -0.174275
trainer/Policy log std Min         -2.84301
trainer/Alpha                       0.0629539
trainer/Alpha Loss                  0.0959682
exploration/num steps total    125200
exploration/num paths total      1252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.496385
exploration/Rewards Std             0.580023
exploration/Rewards Max            -0.00365522
exploration/Rewards Min            -4.59742
exploration/Returns Mean          -49.6385
exploration/Returns Std            45.7389
exploration/Returns Max           -20.4016
exploration/Returns Min          -140.835
exploration/Actions Mean           -0.00119168
exploration/Actions Std             0.180213
exploration/Actions Max             0.993029
exploration/Actions Min            -0.991502
exploration/Num Paths               5
exploration/Average Returns       -49.6385
evaluation/num steps total     375000
evaluation/num paths total       3750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.71324
evaluation/Rewards Std              0.962252
evaluation/Rewards Max             -0.0360813
evaluation/Rewards Min            -10.2465
evaluation/Returns Mean           -71.324
evaluation/Returns Std             56.9039
evaluation/Returns Max            -13.0558
evaluation/Returns Min           -168.277
evaluation/Actions Mean             0.000881263
evaluation/Actions Std              0.174724
evaluation/Actions Max              0.998601
evaluation/Actions Min             -0.99813
evaluation/Num Paths               15
evaluation/Average Returns        -71.324
time/data storing (s)               0.00263709
time/evaluation sampling (s)        0.332521
time/exploration sampling (s)       0.136242
time/logging (s)                    0.00351562
time/saving (s)                     0.00199713
time/training (s)                   1.92464
time/epoch (s)                      2.40155
time/total (s)                    608.856
Epoch                             249
-----------------------------  ----------------
2019-04-23 00:03:30.939757 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 250 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.175713
trainer/QF2 Loss                    0.198148
trainer/Policy Loss                47.9318
trainer/Q1 Predictions Mean       -45.9696
trainer/Q1 Predictions Std         35.2641
trainer/Q1 Predictions Max         -7.14805
trainer/Q1 Predictions Min       -124.101
trainer/Q2 Predictions Mean       -45.9858
trainer/Q2 Predictions Std         35.2806
trainer/Q2 Predictions Max         -7.22583
trainer/Q2 Predictions Min       -124.232
trainer/Q Targets Mean            -46.2068
trainer/Q Targets Std              35.2931
trainer/Q Targets Max              -7.32738
trainer/Q Targets Min            -123.744
trainer/Log Pis Mean                2.17798
trainer/Log Pis Std                 1.13877
trainer/Log Pis Max                 7.50737
trainer/Log Pis Min                -1.73704
trainer/Policy mu Mean              0.00895814
trainer/Policy mu Std               0.725704
trainer/Policy mu Max               3.53703
trainer/Policy mu Min              -3.46107
trainer/Policy log std Mean        -2.1467
trainer/Policy log std Std          0.552587
trainer/Policy log std Max         -0.0620239
trainer/Policy log std Min         -2.91271
trainer/Alpha                       0.061943
trainer/Alpha Loss                  0.495106
exploration/num steps total    125700
exploration/num paths total      1257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01616
exploration/Rewards Std             0.977847
exploration/Rewards Max            -0.00724207
exploration/Rewards Min            -8.94684
exploration/Returns Mean         -101.616
exploration/Returns Std            51.2361
exploration/Returns Max           -39.455
exploration/Returns Min          -155.695
exploration/Actions Mean            0.013631
exploration/Actions Std             0.226271
exploration/Actions Max             0.998507
exploration/Actions Min            -0.994946
exploration/Num Paths               5
exploration/Average Returns      -101.616
evaluation/num steps total     376500
evaluation/num paths total       3765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.520069
evaluation/Rewards Std              0.845108
evaluation/Rewards Max             -0.026598
evaluation/Rewards Min             -8.41493
evaluation/Returns Mean           -52.0069
evaluation/Returns Std             51.0756
evaluation/Returns Max             -6.78345
evaluation/Returns Min           -167.724
evaluation/Actions Mean            -0.00839702
evaluation/Actions Std              0.158815
evaluation/Actions Max              0.9908
evaluation/Actions Min             -0.999581
evaluation/Num Paths               15
evaluation/Average Returns        -52.0069
time/data storing (s)               0.00262922
time/evaluation sampling (s)        0.328279
time/exploration sampling (s)       0.139696
time/logging (s)                    0.00413894
time/saving (s)                     0.00195605
time/training (s)                   1.95392
time/epoch (s)                      2.43062
time/total (s)                    611.292
Epoch                             250
-----------------------------  ---------------
2019-04-23 00:03:33.363527 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 251 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  124.558
trainer/QF2 Loss                  124.716
trainer/Policy Loss                43.1823
trainer/Q1 Predictions Mean       -41.48
trainer/Q1 Predictions Std         33.3122
trainer/Q1 Predictions Max         -7.26855
trainer/Q1 Predictions Min       -125.229
trainer/Q2 Predictions Mean       -41.5234
trainer/Q2 Predictions Std         33.3032
trainer/Q2 Predictions Max         -7.43217
trainer/Q2 Predictions Min       -125.207
trainer/Q Targets Mean            -40.4567
trainer/Q Targets Std              32.8833
trainer/Q Targets Max              -2.44093
trainer/Q Targets Min            -125.822
trainer/Log Pis Mean                1.99287
trainer/Log Pis Std                 1.40998
trainer/Log Pis Max                 7.17713
trainer/Log Pis Min                -4.67884
trainer/Policy mu Mean             -0.000418442
trainer/Policy mu Std               0.717307
trainer/Policy mu Max               2.45755
trainer/Policy mu Min              -2.74982
trainer/Policy log std Mean        -2.01463
trainer/Policy log std Std          0.564353
trainer/Policy log std Max         -0.497744
trainer/Policy log std Min         -2.82206
trainer/Alpha                       0.0639556
trainer/Alpha Loss                 -0.0196007
exploration/num steps total    126200
exploration/num paths total      1262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.385984
exploration/Rewards Std             0.776203
exploration/Rewards Max            -0.00253099
exploration/Rewards Min            -7.84092
exploration/Returns Mean          -38.5984
exploration/Returns Std            23.1732
exploration/Returns Max           -12.9428
exploration/Returns Min           -72.4774
exploration/Actions Mean           -0.00894037
exploration/Actions Std             0.19605
exploration/Actions Max             0.999629
exploration/Actions Min            -0.998213
exploration/Num Paths               5
exploration/Average Returns       -38.5984
evaluation/num steps total     378000
evaluation/num paths total       3780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.94234
evaluation/Rewards Std              1.18219
evaluation/Rewards Max             -0.068731
evaluation/Rewards Min            -10.3583
evaluation/Returns Mean           -94.234
evaluation/Returns Std             75.2672
evaluation/Returns Max            -10.4683
evaluation/Returns Min           -270.825
evaluation/Actions Mean            -0.00608061
evaluation/Actions Std              0.191498
evaluation/Actions Max              0.998873
evaluation/Actions Min             -0.999663
evaluation/Num Paths               15
evaluation/Average Returns        -94.234
time/data storing (s)               0.00272053
time/evaluation sampling (s)        0.325686
time/exploration sampling (s)       0.138609
time/logging (s)                    0.00354764
time/saving (s)                     0.00158537
time/training (s)                   1.9426
time/epoch (s)                      2.41475
time/total (s)                    613.711
Epoch                             251
-----------------------------  ----------------
2019-04-23 00:03:35.768508 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 252 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.349941
trainer/QF2 Loss                    0.303801
trainer/Policy Loss                40.821
trainer/Q1 Predictions Mean       -39.2008
trainer/Q1 Predictions Std         31.5748
trainer/Q1 Predictions Max         -7.31902
trainer/Q1 Predictions Min       -114.136
trainer/Q2 Predictions Mean       -39.227
trainer/Q2 Predictions Std         31.5894
trainer/Q2 Predictions Max         -7.37301
trainer/Q2 Predictions Min       -114.016
trainer/Q Targets Mean            -39.571
trainer/Q Targets Std              31.9492
trainer/Q Targets Max              -7.38213
trainer/Q Targets Min            -115.561
trainer/Log Pis Mean                1.77656
trainer/Log Pis Std                 1.19877
trainer/Log Pis Max                 5.86889
trainer/Log Pis Min                -1.91243
trainer/Policy mu Mean             -0.0621606
trainer/Policy mu Std               0.50507
trainer/Policy mu Max               3.53189
trainer/Policy mu Min              -2.41043
trainer/Policy log std Mean        -2.15908
trainer/Policy log std Std          0.441407
trainer/Policy log std Max         -0.543181
trainer/Policy log std Min         -2.76436
trainer/Alpha                       0.0643598
trainer/Alpha Loss                 -0.612951
exploration/num steps total    126700
exploration/num paths total      1267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.67978
exploration/Rewards Std             1.30558
exploration/Rewards Max            -0.0144969
exploration/Rewards Min           -10.048
exploration/Returns Mean          -67.978
exploration/Returns Std            39.6306
exploration/Returns Max           -27.4685
exploration/Returns Min          -140.069
exploration/Actions Mean            0.00605818
exploration/Actions Std             0.250582
exploration/Actions Max             0.999958
exploration/Actions Min            -0.999365
exploration/Num Paths               5
exploration/Average Returns       -67.978
evaluation/num steps total     379500
evaluation/num paths total       3795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.814605
evaluation/Rewards Std              0.926572
evaluation/Rewards Max             -0.0585673
evaluation/Rewards Min             -8.62205
evaluation/Returns Mean           -81.4605
evaluation/Returns Std             63.1434
evaluation/Returns Max            -15.8721
evaluation/Returns Min           -238.409
evaluation/Actions Mean            -0.00628185
evaluation/Actions Std              0.170799
evaluation/Actions Max              0.997922
evaluation/Actions Min             -0.999649
evaluation/Num Paths               15
evaluation/Average Returns        -81.4605
time/data storing (s)               0.00260263
time/evaluation sampling (s)        0.324714
time/exploration sampling (s)       0.137005
time/logging (s)                    0.00479933
time/saving (s)                     0.00186509
time/training (s)                   1.92688
time/epoch (s)                      2.39787
time/total (s)                    616.113
Epoch                             252
-----------------------------  ---------------
2019-04-23 00:03:38.212217 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 253 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   53.7418
trainer/QF2 Loss                   53.6584
trainer/Policy Loss                48.1377
trainer/Q1 Predictions Mean       -46.2136
trainer/Q1 Predictions Std         34.2208
trainer/Q1 Predictions Max         -7.01574
trainer/Q1 Predictions Min       -112.929
trainer/Q2 Predictions Mean       -46.2586
trainer/Q2 Predictions Std         34.2827
trainer/Q2 Predictions Max         -7.0467
trainer/Q2 Predictions Min       -113.101
trainer/Q Targets Mean            -46.3595
trainer/Q Targets Std              35.2223
trainer/Q Targets Max              -1.43355
trainer/Q Targets Min            -116.449
trainer/Log Pis Mean                2.09061
trainer/Log Pis Std                 1.19375
trainer/Log Pis Max                 5.82291
trainer/Log Pis Min                -2.15804
trainer/Policy mu Mean             -0.0651085
trainer/Policy mu Std               0.649127
trainer/Policy mu Max               2.86129
trainer/Policy mu Min              -3.05809
trainer/Policy log std Mean        -2.07439
trainer/Policy log std Std          0.507327
trainer/Policy log std Max         -0.557828
trainer/Policy log std Min         -2.9464
trainer/Alpha                       0.0648939
trainer/Alpha Loss                  0.247823
exploration/num steps total    127200
exploration/num paths total      1272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.708671
exploration/Rewards Std             0.778997
exploration/Rewards Max            -0.0175992
exploration/Rewards Min            -7.94129
exploration/Returns Mean          -70.8671
exploration/Returns Std            41.02
exploration/Returns Max           -25.3289
exploration/Returns Min          -136.923
exploration/Actions Mean            0.00521489
exploration/Actions Std             0.214199
exploration/Actions Max             0.99788
exploration/Actions Min            -0.998958
exploration/Num Paths               5
exploration/Average Returns       -70.8671
evaluation/num steps total     381000
evaluation/num paths total       3810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.833271
evaluation/Rewards Std              1.31285
evaluation/Rewards Max             -0.056065
evaluation/Rewards Min            -11.1318
evaluation/Returns Mean           -83.3271
evaluation/Returns Std             63.4063
evaluation/Returns Max            -15.6483
evaluation/Returns Min           -253.023
evaluation/Actions Mean            -0.00106672
evaluation/Actions Std              0.20832
evaluation/Actions Max              0.998989
evaluation/Actions Min             -0.999452
evaluation/Num Paths               15
evaluation/Average Returns        -83.3271
time/data storing (s)               0.00272071
time/evaluation sampling (s)        0.326275
time/exploration sampling (s)       0.139487
time/logging (s)                    0.00479601
time/saving (s)                     0.00195981
time/training (s)                   1.96006
time/epoch (s)                      2.43529
time/total (s)                    618.553
Epoch                             253
-----------------------------  ---------------
2019-04-23 00:03:40.624798 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 254 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   41.5669
trainer/QF2 Loss                   41.267
trainer/Policy Loss                39.9869
trainer/Q1 Predictions Mean       -38.0546
trainer/Q1 Predictions Std         31.4862
trainer/Q1 Predictions Max         -7.29157
trainer/Q1 Predictions Min       -116.248
trainer/Q2 Predictions Mean       -38.012
trainer/Q2 Predictions Std         31.43
trainer/Q2 Predictions Max         -7.31426
trainer/Q2 Predictions Min       -116.504
trainer/Q Targets Mean            -37.4972
trainer/Q Targets Std              31.5781
trainer/Q Targets Max              -1.2983
trainer/Q Targets Min            -116.667
trainer/Log Pis Mean                2.24869
trainer/Log Pis Std                 1.3436
trainer/Log Pis Max                 8.88664
trainer/Log Pis Min                -1.67773
trainer/Policy mu Mean             -0.0734455
trainer/Policy mu Std               0.649197
trainer/Policy mu Max               3.58845
trainer/Policy mu Min              -2.68065
trainer/Policy log std Mean        -2.24372
trainer/Policy log std Std          0.471662
trainer/Policy log std Max         -0.235806
trainer/Policy log std Min         -3.08559
trainer/Alpha                       0.0655047
trainer/Alpha Loss                  0.67786
exploration/num steps total    127700
exploration/num paths total      1277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.624331
exploration/Rewards Std             0.987856
exploration/Rewards Max            -0.00804843
exploration/Rewards Min            -8.79043
exploration/Returns Mean          -62.4331
exploration/Returns Std            49.6407
exploration/Returns Max           -16.9879
exploration/Returns Min          -156.534
exploration/Actions Mean            0.00889177
exploration/Actions Std             0.212933
exploration/Actions Max             0.997574
exploration/Actions Min            -0.991842
exploration/Num Paths               5
exploration/Average Returns       -62.4331
evaluation/num steps total     382500
evaluation/num paths total       3825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.898444
evaluation/Rewards Std              1.16001
evaluation/Rewards Max             -0.0736225
evaluation/Rewards Min            -10.8345
evaluation/Returns Mean           -89.8444
evaluation/Returns Std             73.6498
evaluation/Returns Max            -26.5801
evaluation/Returns Min           -259.688
evaluation/Actions Mean            -0.0109523
evaluation/Actions Std              0.188661
evaluation/Actions Max              0.995809
evaluation/Actions Min             -0.999775
evaluation/Num Paths               15
evaluation/Average Returns        -89.8444
time/data storing (s)               0.00275516
time/evaluation sampling (s)        0.333588
time/exploration sampling (s)       0.134497
time/logging (s)                    0.00479894
time/saving (s)                     0.00197988
time/training (s)                   1.92661
time/epoch (s)                      2.40423
time/total (s)                    620.962
Epoch                             254
-----------------------------  ---------------
2019-04-23 00:03:43.074683 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 255 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.597291
trainer/QF2 Loss                    0.619705
trainer/Policy Loss                37.6019
trainer/Q1 Predictions Mean       -35.8374
trainer/Q1 Predictions Std         29.6636
trainer/Q1 Predictions Max         -7.04332
trainer/Q1 Predictions Min       -115.688
trainer/Q2 Predictions Mean       -35.8151
trainer/Q2 Predictions Std         29.6825
trainer/Q2 Predictions Max         -6.94414
trainer/Q2 Predictions Min       -115.932
trainer/Q Targets Mean            -36.4434
trainer/Q Targets Std              30.0607
trainer/Q Targets Max              -7.30733
trainer/Q Targets Min            -117.15
trainer/Log Pis Mean                2.04703
trainer/Log Pis Std                 1.27663
trainer/Log Pis Max                 7.71294
trainer/Log Pis Min                -1.84375
trainer/Policy mu Mean              0.00659507
trainer/Policy mu Std               0.655839
trainer/Policy mu Max               2.24309
trainer/Policy mu Min              -3.14537
trainer/Policy log std Mean        -2.10619
trainer/Policy log std Std          0.534969
trainer/Policy log std Max         -0.585217
trainer/Policy log std Min         -2.94275
trainer/Alpha                       0.0660623
trainer/Alpha Loss                  0.127779
exploration/num steps total    128200
exploration/num paths total      1282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.514187
exploration/Rewards Std             1.30028
exploration/Rewards Max            -0.0151725
exploration/Rewards Min            -9.85814
exploration/Returns Mean          -51.4187
exploration/Returns Std            23.3668
exploration/Returns Max           -13.7198
exploration/Returns Min           -76.8696
exploration/Actions Mean            0.00728064
exploration/Actions Std             0.236137
exploration/Actions Max             0.99843
exploration/Actions Min            -0.99971
exploration/Num Paths               5
exploration/Average Returns       -51.4187
evaluation/num steps total     384000
evaluation/num paths total       3840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.713504
evaluation/Rewards Std              1.02178
evaluation/Rewards Max             -0.0722901
evaluation/Rewards Min             -8.77959
evaluation/Returns Mean           -71.3504
evaluation/Returns Std             60.9465
evaluation/Returns Max             -7.61783
evaluation/Returns Min           -239.579
evaluation/Actions Mean            -0.00131999
evaluation/Actions Std              0.190455
evaluation/Actions Max              0.997859
evaluation/Actions Min             -0.998473
evaluation/Num Paths               15
evaluation/Average Returns        -71.3504
time/data storing (s)               0.00274141
time/evaluation sampling (s)        0.327988
time/exploration sampling (s)       0.138685
time/logging (s)                    0.0047942
time/saving (s)                     0.0102906
time/training (s)                   1.95762
time/epoch (s)                      2.44212
time/total (s)                    623.408
Epoch                             255
-----------------------------  ---------------
2019-04-23 00:03:45.489655 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 256 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.68922
trainer/QF2 Loss                    3.63188
trainer/Policy Loss                40.9904
trainer/Q1 Predictions Mean       -39.3644
trainer/Q1 Predictions Std         31.7617
trainer/Q1 Predictions Max         -7.3651
trainer/Q1 Predictions Min       -116.703
trainer/Q2 Predictions Mean       -39.351
trainer/Q2 Predictions Std         31.8181
trainer/Q2 Predictions Max         -7.39334
trainer/Q2 Predictions Min       -117.741
trainer/Q Targets Mean            -39.4941
trainer/Q Targets Std              32.198
trainer/Q Targets Max              -0.216993
trainer/Q Targets Min            -117.941
trainer/Log Pis Mean                1.91299
trainer/Log Pis Std                 1.03516
trainer/Log Pis Max                 4.38144
trainer/Log Pis Min                -1.59919
trainer/Policy mu Mean             -0.0761189
trainer/Policy mu Std               0.540882
trainer/Policy mu Max               2.05881
trainer/Policy mu Min              -2.47859
trainer/Policy log std Mean        -2.09707
trainer/Policy log std Std          0.507738
trainer/Policy log std Max         -0.324425
trainer/Policy log std Min         -3.20028
trainer/Alpha                       0.0673905
trainer/Alpha Loss                 -0.234664
exploration/num steps total    128700
exploration/num paths total      1287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11035
exploration/Rewards Std             1.22934
exploration/Rewards Max            -0.00252492
exploration/Rewards Min            -7.10477
exploration/Returns Mean         -111.035
exploration/Returns Std           109.898
exploration/Returns Max           -14.7532
exploration/Returns Min          -247.041
exploration/Actions Mean           -0.00719037
exploration/Actions Std             0.210129
exploration/Actions Max             0.998674
exploration/Actions Min            -0.99129
exploration/Num Paths               5
exploration/Average Returns      -111.035
evaluation/num steps total     385500
evaluation/num paths total       3855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.765515
evaluation/Rewards Std              1.10499
evaluation/Rewards Max             -0.022383
evaluation/Rewards Min             -9.91244
evaluation/Returns Mean           -76.5515
evaluation/Returns Std             62.7974
evaluation/Returns Max            -10.4629
evaluation/Returns Min           -231.312
evaluation/Actions Mean             0.0116
evaluation/Actions Std              0.190394
evaluation/Actions Max              0.999433
evaluation/Actions Min             -0.99877
evaluation/Num Paths               15
evaluation/Average Returns        -76.5515
time/data storing (s)               0.00270708
time/evaluation sampling (s)        0.328214
time/exploration sampling (s)       0.14103
time/logging (s)                    0.00364962
time/saving (s)                     0.00205059
time/training (s)                   1.92825
time/epoch (s)                      2.4059
time/total (s)                    625.817
Epoch                             256
-----------------------------  ---------------
2019-04-23 00:03:47.887964 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 257 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.18555
trainer/QF2 Loss                    4.21691
trainer/Policy Loss                47.8581
trainer/Q1 Predictions Mean       -46.0621
trainer/Q1 Predictions Std         40.1378
trainer/Q1 Predictions Max         -7.21089
trainer/Q1 Predictions Min       -125.345
trainer/Q2 Predictions Mean       -46.0731
trainer/Q2 Predictions Std         40.1392
trainer/Q2 Predictions Max         -7.29534
trainer/Q2 Predictions Min       -125.927
trainer/Q Targets Mean            -46.3669
trainer/Q Targets Std              40.6783
trainer/Q Targets Max              -1.23483
trainer/Q Targets Min            -122.478
trainer/Log Pis Mean                2.17466
trainer/Log Pis Std                 1.16135
trainer/Log Pis Max                 7.37434
trainer/Log Pis Min                -1.54613
trainer/Policy mu Mean              0.0273257
trainer/Policy mu Std               0.631835
trainer/Policy mu Max               2.52764
trainer/Policy mu Min              -2.69371
trainer/Policy log std Mean        -2.12779
trainer/Policy log std Std          0.555437
trainer/Policy log std Max         -0.270862
trainer/Policy log std Min         -3.12721
trainer/Alpha                       0.0675644
trainer/Alpha Loss                  0.470657
exploration/num steps total    129200
exploration/num paths total      1292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.965213
exploration/Rewards Std             1.02819
exploration/Rewards Max            -0.0228186
exploration/Rewards Min            -7.34321
exploration/Returns Mean          -96.5213
exploration/Returns Std            78.5434
exploration/Returns Max           -23.4637
exploration/Returns Min          -214.875
exploration/Actions Mean           -0.00876923
exploration/Actions Std             0.229132
exploration/Actions Max             0.995477
exploration/Actions Min            -0.993339
exploration/Num Paths               5
exploration/Average Returns       -96.5213
evaluation/num steps total     387000
evaluation/num paths total       3870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.417295
evaluation/Rewards Std              1.01812
evaluation/Rewards Max             -0.0171331
evaluation/Rewards Min            -10.036
evaluation/Returns Mean           -41.7295
evaluation/Returns Std             34.5487
evaluation/Returns Max             -7.24752
evaluation/Returns Min           -149.193
evaluation/Actions Mean            -0.0118392
evaluation/Actions Std              0.178839
evaluation/Actions Max              0.999307
evaluation/Actions Min             -0.999173
evaluation/Num Paths               15
evaluation/Average Returns        -41.7295
time/data storing (s)               0.00282787
time/evaluation sampling (s)        0.332109
time/exploration sampling (s)       0.135804
time/logging (s)                    0.00479249
time/saving (s)                     0.00160667
time/training (s)                   1.91411
time/epoch (s)                      2.39125
time/total (s)                    628.213
Epoch                             257
-----------------------------  ---------------
2019-04-23 00:03:50.301003 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 258 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.97251
trainer/QF2 Loss                    2.94646
trainer/Policy Loss                35.9309
trainer/Q1 Predictions Mean       -34.1523
trainer/Q1 Predictions Std         27.246
trainer/Q1 Predictions Max         -7.23708
trainer/Q1 Predictions Min       -115.416
trainer/Q2 Predictions Mean       -34.1727
trainer/Q2 Predictions Std         27.2822
trainer/Q2 Predictions Max         -7.16146
trainer/Q2 Predictions Min       -115.511
trainer/Q Targets Mean            -34.7013
trainer/Q Targets Std              27.7151
trainer/Q Targets Max              -0.125326
trainer/Q Targets Min            -117.127
trainer/Log Pis Mean                2.06879
trainer/Log Pis Std                 1.05115
trainer/Log Pis Max                 5.07085
trainer/Log Pis Min                -3.17738
trainer/Policy mu Mean             -0.0322827
trainer/Policy mu Std               0.464021
trainer/Policy mu Max               2.61692
trainer/Policy mu Min              -1.41961
trainer/Policy log std Mean        -2.21122
trainer/Policy log std Std          0.464007
trainer/Policy log std Max         -0.534091
trainer/Policy log std Min         -3.06904
trainer/Alpha                       0.0670518
trainer/Alpha Loss                  0.185882
exploration/num steps total    129700
exploration/num paths total      1297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.919291
exploration/Rewards Std             1.01547
exploration/Rewards Max            -0.0497377
exploration/Rewards Min            -6.76989
exploration/Returns Mean          -91.9291
exploration/Returns Std            74.8527
exploration/Returns Max           -33.4938
exploration/Returns Min          -239.716
exploration/Actions Mean           -0.00560763
exploration/Actions Std             0.212707
exploration/Actions Max             0.987998
exploration/Actions Min            -0.999244
exploration/Num Paths               5
exploration/Average Returns       -91.9291
evaluation/num steps total     388500
evaluation/num paths total       3885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.877742
evaluation/Rewards Std              1.08134
evaluation/Rewards Max             -0.0382028
evaluation/Rewards Min             -9.6895
evaluation/Returns Mean           -87.7742
evaluation/Returns Std             56.7095
evaluation/Returns Max            -15.0472
evaluation/Returns Min           -235.113
evaluation/Actions Mean            -0.00814771
evaluation/Actions Std              0.179341
evaluation/Actions Max              0.998729
evaluation/Actions Min             -0.998727
evaluation/Num Paths               15
evaluation/Average Returns        -87.7742
time/data storing (s)               0.00278022
time/evaluation sampling (s)        0.323309
time/exploration sampling (s)       0.136401
time/logging (s)                    0.00478039
time/saving (s)                     0.00196223
time/training (s)                   1.93642
time/epoch (s)                      2.40565
time/total (s)                    630.622
Epoch                             258
-----------------------------  ---------------
2019-04-23 00:03:52.744443 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 259 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.466987
trainer/QF2 Loss                    0.438133
trainer/Policy Loss                40.028
trainer/Q1 Predictions Mean       -38.3239
trainer/Q1 Predictions Std         33.4545
trainer/Q1 Predictions Max         -7.38551
trainer/Q1 Predictions Min       -115.341
trainer/Q2 Predictions Mean       -38.256
trainer/Q2 Predictions Std         33.4753
trainer/Q2 Predictions Max         -7.30423
trainer/Q2 Predictions Min       -115.498
trainer/Q Targets Mean            -38.647
trainer/Q Targets Std              33.8794
trainer/Q Targets Max              -7.32852
trainer/Q Targets Min            -117.214
trainer/Log Pis Mean                1.91277
trainer/Log Pis Std                 1.22627
trainer/Log Pis Max                 6.53329
trainer/Log Pis Min                -1.10972
trainer/Policy mu Mean             -0.062058
trainer/Policy mu Std               0.574269
trainer/Policy mu Max               2.7319
trainer/Policy mu Min              -2.33339
trainer/Policy log std Mean        -2.12124
trainer/Policy log std Std          0.518132
trainer/Policy log std Max         -0.574112
trainer/Policy log std Min         -3.12349
trainer/Alpha                       0.0675829
trainer/Alpha Loss                 -0.235041
exploration/num steps total    130200
exploration/num paths total      1302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.949345
exploration/Rewards Std             1.29292
exploration/Rewards Max            -0.0037076
exploration/Rewards Min            -9.26686
exploration/Returns Mean          -94.9345
exploration/Returns Std            63.7834
exploration/Returns Max           -30.3805
exploration/Returns Min          -181.277
exploration/Actions Mean            0.0128616
exploration/Actions Std             0.285734
exploration/Actions Max             0.999714
exploration/Actions Min            -0.995462
exploration/Num Paths               5
exploration/Average Returns       -94.9345
evaluation/num steps total     390000
evaluation/num paths total       3900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.600457
evaluation/Rewards Std              1.02769
evaluation/Rewards Max             -0.0151292
evaluation/Rewards Min             -9.83045
evaluation/Returns Mean           -60.0457
evaluation/Returns Std             59.3735
evaluation/Returns Max             -4.48401
evaluation/Returns Min           -227.789
evaluation/Actions Mean             0.00957906
evaluation/Actions Std              0.177376
evaluation/Actions Max              0.99887
evaluation/Actions Min             -0.998284
evaluation/Num Paths               15
evaluation/Average Returns        -60.0457
time/data storing (s)               0.00263131
time/evaluation sampling (s)        0.327691
time/exploration sampling (s)       0.137268
time/logging (s)                    0.00477983
time/saving (s)                     0.00157695
time/training (s)                   1.96097
time/epoch (s)                      2.43491
time/total (s)                    633.062
Epoch                             259
-----------------------------  ---------------
2019-04-23 00:03:55.159433 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 260 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.50428
trainer/QF2 Loss                    3.52664
trainer/Policy Loss                37.2206
trainer/Q1 Predictions Mean       -35.3376
trainer/Q1 Predictions Std         32.1095
trainer/Q1 Predictions Max         -7.18951
trainer/Q1 Predictions Min       -136.188
trainer/Q2 Predictions Mean       -35.3047
trainer/Q2 Predictions Std         32.1378
trainer/Q2 Predictions Max         -7.12734
trainer/Q2 Predictions Min       -137.204
trainer/Q Targets Mean            -35.2167
trainer/Q Targets Std              32.3553
trainer/Q Targets Max              -0.283691
trainer/Q Targets Min            -135.863
trainer/Log Pis Mean                2.1105
trainer/Log Pis Std                 1.08911
trainer/Log Pis Max                 5.86661
trainer/Log Pis Min                -1.22841
trainer/Policy mu Mean             -0.0249405
trainer/Policy mu Std               0.609596
trainer/Policy mu Max               2.39494
trainer/Policy mu Min              -2.71884
trainer/Policy log std Mean        -2.13335
trainer/Policy log std Std          0.558912
trainer/Policy log std Max         -0.62164
trainer/Policy log std Min         -2.86519
trainer/Alpha                       0.0705152
trainer/Alpha Loss                  0.293057
exploration/num steps total    130700
exploration/num paths total      1307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.418904
exploration/Rewards Std             0.754618
exploration/Rewards Max            -0.0100277
exploration/Rewards Min            -7.41861
exploration/Returns Mean          -41.8904
exploration/Returns Std            11.6013
exploration/Returns Max           -25.5947
exploration/Returns Min           -57.7015
exploration/Actions Mean            0.00896681
exploration/Actions Std             0.218731
exploration/Actions Max             0.999617
exploration/Actions Min            -0.999352
exploration/Num Paths               5
exploration/Average Returns       -41.8904
evaluation/num steps total     391500
evaluation/num paths total       3915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.03062
evaluation/Rewards Std              0.982454
evaluation/Rewards Max             -0.0104071
evaluation/Rewards Min             -7.71638
evaluation/Returns Mean          -103.062
evaluation/Returns Std             75.5581
evaluation/Returns Max             -7.9976
evaluation/Returns Min           -219.841
evaluation/Actions Mean             0.0157972
evaluation/Actions Std              0.159068
evaluation/Actions Max              0.998964
evaluation/Actions Min             -0.997235
evaluation/Num Paths               15
evaluation/Average Returns       -103.062
time/data storing (s)               0.00281161
time/evaluation sampling (s)        0.324117
time/exploration sampling (s)       0.137195
time/logging (s)                    0.00476924
time/saving (s)                     0.0019818
time/training (s)                   1.93576
time/epoch (s)                      2.40663
time/total (s)                    635.473
Epoch                             260
-----------------------------  ---------------
2019-04-23 00:03:57.581350 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 261 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    8.21158
trainer/QF2 Loss                    8.30252
trainer/Policy Loss                42.4086
trainer/Q1 Predictions Mean       -40.6691
trainer/Q1 Predictions Std         30.4612
trainer/Q1 Predictions Max         -7.41558
trainer/Q1 Predictions Min       -115.484
trainer/Q2 Predictions Mean       -40.729
trainer/Q2 Predictions Std         30.4854
trainer/Q2 Predictions Max         -7.37451
trainer/Q2 Predictions Min       -115.434
trainer/Q Targets Mean            -40.5547
trainer/Q Targets Std              31.0966
trainer/Q Targets Max              -0.202724
trainer/Q Targets Min            -116.835
trainer/Log Pis Mean                2.00989
trainer/Log Pis Std                 1.1648
trainer/Log Pis Max                 4.92649
trainer/Log Pis Min                -3.01339
trainer/Policy mu Mean             -0.000665281
trainer/Policy mu Std               0.599878
trainer/Policy mu Max               2.77854
trainer/Policy mu Min              -2.48967
trainer/Policy log std Mean        -2.15353
trainer/Policy log std Std          0.560891
trainer/Policy log std Max         -0.406629
trainer/Policy log std Min         -2.9462
trainer/Alpha                       0.0690951
trainer/Alpha Loss                  0.0264417
exploration/num steps total    131200
exploration/num paths total      1312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.72584
exploration/Rewards Std             0.940616
exploration/Rewards Max            -0.0147892
exploration/Rewards Min            -8.90442
exploration/Returns Mean          -72.584
exploration/Returns Std            58.0185
exploration/Returns Max           -24.4662
exploration/Returns Min          -182.223
exploration/Actions Mean            0.00570999
exploration/Actions Std             0.216969
exploration/Actions Max             0.998165
exploration/Actions Min            -0.998945
exploration/Num Paths               5
exploration/Average Returns       -72.584
evaluation/num steps total     393000
evaluation/num paths total       3930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.12615
evaluation/Rewards Std              1.10842
evaluation/Rewards Max             -0.0509506
evaluation/Rewards Min             -9.02699
evaluation/Returns Mean          -112.615
evaluation/Returns Std             84.1831
evaluation/Returns Max            -18.5645
evaluation/Returns Min           -252.445
evaluation/Actions Mean            -0.00841381
evaluation/Actions Std              0.180145
evaluation/Actions Max              0.995814
evaluation/Actions Min             -0.998548
evaluation/Num Paths               15
evaluation/Average Returns       -112.615
time/data storing (s)               0.00258414
time/evaluation sampling (s)        0.329376
time/exploration sampling (s)       0.139653
time/logging (s)                    0.00481996
time/saving (s)                     0.00159091
time/training (s)                   1.93565
time/epoch (s)                      2.41368
time/total (s)                    637.891
Epoch                             261
-----------------------------  ----------------
2019-04-23 00:04:00.033079 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 262 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.9637
trainer/QF2 Loss                   22.1456
trainer/Policy Loss                40.5968
trainer/Q1 Predictions Mean       -38.8748
trainer/Q1 Predictions Std         30.8654
trainer/Q1 Predictions Max         -7.46314
trainer/Q1 Predictions Min       -126.687
trainer/Q2 Predictions Mean       -38.8636
trainer/Q2 Predictions Std         30.8474
trainer/Q2 Predictions Max         -7.43512
trainer/Q2 Predictions Min       -126.29
trainer/Q Targets Mean            -38.8941
trainer/Q Targets Std              31.3251
trainer/Q Targets Max              -0.824854
trainer/Q Targets Min            -126.722
trainer/Log Pis Mean                1.94901
trainer/Log Pis Std                 1.17737
trainer/Log Pis Max                 6.79535
trainer/Log Pis Min                -1.7856
trainer/Policy mu Mean             -0.0561856
trainer/Policy mu Std               0.61461
trainer/Policy mu Max               3.41548
trainer/Policy mu Min              -2.74692
trainer/Policy log std Mean        -2.10908
trainer/Policy log std Std          0.497301
trainer/Policy log std Max         -0.0619657
trainer/Policy log std Min         -2.9336
trainer/Alpha                       0.0719282
trainer/Alpha Loss                 -0.134202
exploration/num steps total    131700
exploration/num paths total      1317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.77168
exploration/Rewards Std             0.860083
exploration/Rewards Max            -0.0130158
exploration/Rewards Min            -8.27154
exploration/Returns Mean          -77.168
exploration/Returns Std            61.5046
exploration/Returns Max           -15.108
exploration/Returns Min          -155.456
exploration/Actions Mean            0.000676075
exploration/Actions Std             0.205283
exploration/Actions Max             0.999406
exploration/Actions Min            -0.98694
exploration/Num Paths               5
exploration/Average Returns       -77.168
evaluation/num steps total     394500
evaluation/num paths total       3945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.747351
evaluation/Rewards Std              1.02971
evaluation/Rewards Max             -0.0194214
evaluation/Rewards Min            -10.6753
evaluation/Returns Mean           -74.7351
evaluation/Returns Std             61.1705
evaluation/Returns Max            -12.4942
evaluation/Returns Min           -243.875
evaluation/Actions Mean            -0.0042324
evaluation/Actions Std              0.187181
evaluation/Actions Max              0.998684
evaluation/Actions Min             -0.999487
evaluation/Num Paths               15
evaluation/Average Returns        -74.7351
time/data storing (s)               0.00414549
time/evaluation sampling (s)        0.326359
time/exploration sampling (s)       0.147135
time/logging (s)                    0.00463016
time/saving (s)                     0.00200342
time/training (s)                   1.95877
time/epoch (s)                      2.44304
time/total (s)                    640.338
Epoch                             262
-----------------------------  ----------------
2019-04-23 00:04:02.470577 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 263 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.442561
trainer/QF2 Loss                    0.454778
trainer/Policy Loss                41.3497
trainer/Q1 Predictions Mean       -39.6451
trainer/Q1 Predictions Std         32.0012
trainer/Q1 Predictions Max         -7.25977
trainer/Q1 Predictions Min       -115.551
trainer/Q2 Predictions Mean       -39.6324
trainer/Q2 Predictions Std         31.983
trainer/Q2 Predictions Max         -7.20972
trainer/Q2 Predictions Min       -115.602
trainer/Q Targets Mean            -40.17
trainer/Q Targets Std              32.2652
trainer/Q Targets Max              -7.28137
trainer/Q Targets Min            -116.456
trainer/Log Pis Mean                1.94557
trainer/Log Pis Std                 1.03641
trainer/Log Pis Max                 4.52437
trainer/Log Pis Min                -1.82651
trainer/Policy mu Mean              0.00840744
trainer/Policy mu Std               0.485458
trainer/Policy mu Max               2.3324
trainer/Policy mu Min              -2.37444
trainer/Policy log std Mean        -2.17122
trainer/Policy log std Std          0.46778
trainer/Policy log std Max         -0.370864
trainer/Policy log std Min         -2.85418
trainer/Alpha                       0.0715531
trainer/Alpha Loss                 -0.143528
exploration/num steps total    132200
exploration/num paths total      1322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.867719
exploration/Rewards Std             1.36988
exploration/Rewards Max            -0.0124065
exploration/Rewards Min            -9.58881
exploration/Returns Mean          -86.7719
exploration/Returns Std            78.003
exploration/Returns Max           -33.2662
exploration/Returns Min          -241.437
exploration/Actions Mean           -0.0248471
exploration/Actions Std             0.2279
exploration/Actions Max             0.998365
exploration/Actions Min            -0.998578
exploration/Num Paths               5
exploration/Average Returns       -86.7719
evaluation/num steps total     396000
evaluation/num paths total       3960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.620051
evaluation/Rewards Std              1.07674
evaluation/Rewards Max             -0.0274125
evaluation/Rewards Min            -10.5091
evaluation/Returns Mean           -62.0051
evaluation/Returns Std             66.3461
evaluation/Returns Max            -10.4397
evaluation/Returns Min           -233.884
evaluation/Actions Mean             0.0117718
evaluation/Actions Std              0.168696
evaluation/Actions Max              0.998975
evaluation/Actions Min             -0.995491
evaluation/Num Paths               15
evaluation/Average Returns        -62.0051
time/data storing (s)               0.00276814
time/evaluation sampling (s)        0.323805
time/exploration sampling (s)       0.137484
time/logging (s)                    0.00496269
time/saving (s)                     0.00199284
time/training (s)                   1.95848
time/epoch (s)                      2.4295
time/total (s)                    642.772
Epoch                             263
-----------------------------  ---------------
2019-04-23 00:04:04.887625 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 264 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.415177
trainer/QF2 Loss                    0.410217
trainer/Policy Loss                42.6913
trainer/Q1 Predictions Mean       -40.9452
trainer/Q1 Predictions Std         32.7089
trainer/Q1 Predictions Max         -7.05268
trainer/Q1 Predictions Min       -114.241
trainer/Q2 Predictions Mean       -40.9538
trainer/Q2 Predictions Std         32.7218
trainer/Q2 Predictions Max         -7.1147
trainer/Q2 Predictions Min       -114.366
trainer/Q Targets Mean            -41.3017
trainer/Q Targets Std              33.154
trainer/Q Targets Max              -7.19678
trainer/Q Targets Min            -115.968
trainer/Log Pis Mean                2.05747
trainer/Log Pis Std                 0.94772
trainer/Log Pis Max                 5.66793
trainer/Log Pis Min                -0.718284
trainer/Policy mu Mean             -0.0110082
trainer/Policy mu Std               0.458421
trainer/Policy mu Max               1.97097
trainer/Policy mu Min              -2.28639
trainer/Policy log std Mean        -2.17641
trainer/Policy log std Std          0.419701
trainer/Policy log std Max         -0.746142
trainer/Policy log std Min         -3.01866
trainer/Alpha                       0.0705955
trainer/Alpha Loss                  0.152344
exploration/num steps total    132700
exploration/num paths total      1327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.28774
exploration/Rewards Std             0.995168
exploration/Rewards Max            -0.00978778
exploration/Rewards Min            -5.77514
exploration/Returns Mean         -128.774
exploration/Returns Std            85.6767
exploration/Returns Max           -28.6961
exploration/Returns Min          -223.66
exploration/Actions Mean            0.0106197
exploration/Actions Std             0.202425
exploration/Actions Max             0.997046
exploration/Actions Min            -0.990908
exploration/Num Paths               5
exploration/Average Returns      -128.774
evaluation/num steps total     397500
evaluation/num paths total       3975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.15766
evaluation/Rewards Std              1.15775
evaluation/Rewards Max             -0.0768315
evaluation/Rewards Min             -9.69597
evaluation/Returns Mean          -115.766
evaluation/Returns Std             87.4106
evaluation/Returns Max             -9.80425
evaluation/Returns Min           -241.035
evaluation/Actions Mean            -0.00838685
evaluation/Actions Std              0.180053
evaluation/Actions Max              0.990043
evaluation/Actions Min             -0.999308
evaluation/Num Paths               15
evaluation/Average Returns       -115.766
time/data storing (s)               0.00261165
time/evaluation sampling (s)        0.328056
time/exploration sampling (s)       0.136283
time/logging (s)                    0.00476249
time/saving (s)                     0.00163436
time/training (s)                   1.93519
time/epoch (s)                      2.40854
time/total (s)                    645.185
Epoch                             264
-----------------------------  ---------------
2019-04-23 00:04:07.329462 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 265 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.72589
trainer/QF2 Loss                    4.75913
trainer/Policy Loss                48.3188
trainer/Q1 Predictions Mean       -46.4009
trainer/Q1 Predictions Std         37.0597
trainer/Q1 Predictions Max         -7.16795
trainer/Q1 Predictions Min       -137.632
trainer/Q2 Predictions Mean       -46.4057
trainer/Q2 Predictions Std         37.0744
trainer/Q2 Predictions Max         -7.15573
trainer/Q2 Predictions Min       -139.308
trainer/Q Targets Mean            -46.5977
trainer/Q Targets Std              37.566
trainer/Q Targets Max              -0.303539
trainer/Q Targets Min            -140.01
trainer/Log Pis Mean                2.14726
trainer/Log Pis Std                 1.36548
trainer/Log Pis Max                 7.16498
trainer/Log Pis Min                -2.44407
trainer/Policy mu Mean             -0.0458937
trainer/Policy mu Std               0.728133
trainer/Policy mu Max               3.19013
trainer/Policy mu Min              -2.82378
trainer/Policy log std Mean        -2.09625
trainer/Policy log std Std          0.576436
trainer/Policy log std Max         -0.305287
trainer/Policy log std Min         -3.2027
trainer/Alpha                       0.070914
trainer/Alpha Loss                  0.389733
exploration/num steps total    133200
exploration/num paths total      1332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370146
exploration/Rewards Std             0.896138
exploration/Rewards Max            -0.0111053
exploration/Rewards Min            -7.65184
exploration/Returns Mean          -37.0146
exploration/Returns Std             8.73601
exploration/Returns Max           -26.7274
exploration/Returns Min           -48.0358
exploration/Actions Mean            0.00467398
exploration/Actions Std             0.218746
exploration/Actions Max             0.998943
exploration/Actions Min            -0.995005
exploration/Num Paths               5
exploration/Average Returns       -37.0146
evaluation/num steps total     399000
evaluation/num paths total       3990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.22953
evaluation/Rewards Std              1.20019
evaluation/Rewards Max             -0.0809268
evaluation/Rewards Min            -11.0127
evaluation/Returns Mean          -122.953
evaluation/Returns Std             91.0102
evaluation/Returns Max             -8.22265
evaluation/Returns Min           -265.12
evaluation/Actions Mean             0.00188507
evaluation/Actions Std              0.180982
evaluation/Actions Max              0.99957
evaluation/Actions Min             -0.999194
evaluation/Num Paths               15
evaluation/Average Returns       -122.953
time/data storing (s)               0.00291837
time/evaluation sampling (s)        0.331298
time/exploration sampling (s)       0.139449
time/logging (s)                    0.00484267
time/saving (s)                     0.00196385
time/training (s)                   1.95316
time/epoch (s)                      2.43363
time/total (s)                    647.623
Epoch                             265
-----------------------------  ---------------
2019-04-23 00:04:09.727687 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 266 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.8681
trainer/QF2 Loss                    4.82026
trainer/Policy Loss                37.2048
trainer/Q1 Predictions Mean       -35.3304
trainer/Q1 Predictions Std         32.5865
trainer/Q1 Predictions Max         -7.53394
trainer/Q1 Predictions Min       -115.243
trainer/Q2 Predictions Mean       -35.336
trainer/Q2 Predictions Std         32.6076
trainer/Q2 Predictions Max         -7.54338
trainer/Q2 Predictions Min       -115.291
trainer/Q Targets Mean            -35.3174
trainer/Q Targets Std              33.2075
trainer/Q Targets Max              -0.23262
trainer/Q Targets Min            -116.746
trainer/Log Pis Mean                2.06699
trainer/Log Pis Std                 1.24351
trainer/Log Pis Max                 7.13655
trainer/Log Pis Min                -0.937588
trainer/Policy mu Mean             -0.0103488
trainer/Policy mu Std               0.635987
trainer/Policy mu Max               3.28171
trainer/Policy mu Min              -3.02379
trainer/Policy log std Mean        -2.1629
trainer/Policy log std Std          0.516465
trainer/Policy log std Max         -0.373346
trainer/Policy log std Min         -3.20696
trainer/Alpha                       0.0710215
trainer/Alpha Loss                  0.177174
exploration/num steps total    133700
exploration/num paths total      1337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.15771
exploration/Rewards Std             1.30619
exploration/Rewards Max            -0.0120221
exploration/Rewards Min            -8.19831
exploration/Returns Mean         -115.771
exploration/Returns Std            70.6266
exploration/Returns Max           -52.7815
exploration/Returns Min          -237.004
exploration/Actions Mean            0.0352659
exploration/Actions Std             0.245617
exploration/Actions Max             0.999774
exploration/Actions Min            -1
exploration/Num Paths               5
exploration/Average Returns      -115.771
evaluation/num steps total     400500
evaluation/num paths total       4005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.20414
evaluation/Rewards Std              1.21568
evaluation/Rewards Max             -0.00968747
evaluation/Rewards Min            -11.1607
evaluation/Returns Mean          -120.414
evaluation/Returns Std             62.6189
evaluation/Returns Max            -19.0992
evaluation/Returns Min           -260.865
evaluation/Actions Mean             0.00398595
evaluation/Actions Std              0.197876
evaluation/Actions Max              0.999686
evaluation/Actions Min             -0.999186
evaluation/Num Paths               15
evaluation/Average Returns       -120.414
time/data storing (s)               0.00281819
time/evaluation sampling (s)        0.327267
time/exploration sampling (s)       0.138243
time/logging (s)                    0.00480104
time/saving (s)                     0.0019756
time/training (s)                   1.91478
time/epoch (s)                      2.38989
time/total (s)                    650.017
Epoch                             266
-----------------------------  ---------------
2019-04-23 00:04:12.183020 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 267 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.738683
trainer/QF2 Loss                    0.815962
trainer/Policy Loss                44.6883
trainer/Q1 Predictions Mean       -42.889
trainer/Q1 Predictions Std         35.7997
trainer/Q1 Predictions Max         -7.08452
trainer/Q1 Predictions Min       -114.835
trainer/Q2 Predictions Mean       -42.8738
trainer/Q2 Predictions Std         35.7723
trainer/Q2 Predictions Max         -6.95903
trainer/Q2 Predictions Min       -114.415
trainer/Q Targets Mean            -43.5081
trainer/Q Targets Std              36.2205
trainer/Q Targets Max              -7.28166
trainer/Q Targets Min            -116.357
trainer/Log Pis Mean                2.03466
trainer/Log Pis Std                 1.20739
trainer/Log Pis Max                 5.71395
trainer/Log Pis Min                -2.67027
trainer/Policy mu Mean             -0.0213928
trainer/Policy mu Std               0.52867
trainer/Policy mu Max               3.38357
trainer/Policy mu Min              -2.91758
trainer/Policy log std Mean        -2.22549
trainer/Policy log std Std          0.499805
trainer/Policy log std Max         -0.583379
trainer/Policy log std Min         -3.2462
trainer/Alpha                       0.0693978
trainer/Alpha Loss                  0.0924686
exploration/num steps total    134200
exploration/num paths total      1342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19011
exploration/Rewards Std             1.36198
exploration/Rewards Max            -0.0328576
exploration/Rewards Min           -10.9165
exploration/Returns Mean         -119.011
exploration/Returns Std            79.8627
exploration/Returns Max           -51.2111
exploration/Returns Min          -260.691
exploration/Actions Mean           -0.0169511
exploration/Actions Std             0.251203
exploration/Actions Max             0.998536
exploration/Actions Min            -0.998709
exploration/Num Paths               5
exploration/Average Returns      -119.011
evaluation/num steps total     402000
evaluation/num paths total       4020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.920283
evaluation/Rewards Std              1.02484
evaluation/Rewards Max             -0.0721335
evaluation/Rewards Min            -10.1723
evaluation/Returns Mean           -92.0283
evaluation/Returns Std             59.986
evaluation/Returns Max            -15.7327
evaluation/Returns Min           -240.973
evaluation/Actions Mean            -0.00391583
evaluation/Actions Std              0.179891
evaluation/Actions Max              0.999649
evaluation/Actions Min             -0.999501
evaluation/Num Paths               15
evaluation/Average Returns        -92.0283
time/data storing (s)               0.0027785
time/evaluation sampling (s)        0.334327
time/exploration sampling (s)       0.139863
time/logging (s)                    0.00484159
time/saving (s)                     0.0115423
time/training (s)                   1.95357
time/epoch (s)                      2.44692
time/total (s)                    652.468
Epoch                             267
-----------------------------  ---------------
2019-04-23 00:04:14.623576 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 268 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   51.7544
trainer/QF2 Loss                   51.6379
trainer/Policy Loss                41.4342
trainer/Q1 Predictions Mean       -39.7714
trainer/Q1 Predictions Std         32.3661
trainer/Q1 Predictions Max         -6.93635
trainer/Q1 Predictions Min       -114.513
trainer/Q2 Predictions Mean       -39.7654
trainer/Q2 Predictions Std         32.3813
trainer/Q2 Predictions Max         -6.86133
trainer/Q2 Predictions Min       -114.501
trainer/Q Targets Mean            -39.9032
trainer/Q Targets Std              32.996
trainer/Q Targets Max              -1.34879
trainer/Q Targets Min            -116.945
trainer/Log Pis Mean                1.86287
trainer/Log Pis Std                 1.12927
trainer/Log Pis Max                 5.02102
trainer/Log Pis Min                -1.41395
trainer/Policy mu Mean              0.00157967
trainer/Policy mu Std               0.429513
trainer/Policy mu Max               2.6784
trainer/Policy mu Min              -1.6336
trainer/Policy log std Mean        -2.14365
trainer/Policy log std Std          0.475846
trainer/Policy log std Max         -0.633625
trainer/Policy log std Min         -3.09292
trainer/Alpha                       0.0679611
trainer/Alpha Loss                 -0.368707
exploration/num steps total    134700
exploration/num paths total      1347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43053
exploration/Rewards Std             1.05891
exploration/Rewards Max            -0.00527821
exploration/Rewards Min            -9.67203
exploration/Returns Mean          -43.053
exploration/Returns Std            20.3479
exploration/Returns Max           -17.7286
exploration/Returns Min           -66.1734
exploration/Actions Mean           -0.00407669
exploration/Actions Std             0.213252
exploration/Actions Max             0.991368
exploration/Actions Min            -0.999417
exploration/Num Paths               5
exploration/Average Returns       -43.053
evaluation/num steps total     403500
evaluation/num paths total       4035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.756429
evaluation/Rewards Std              1.16041
evaluation/Rewards Max             -0.139117
evaluation/Rewards Min            -10.9896
evaluation/Returns Mean           -75.6429
evaluation/Returns Std             58.528
evaluation/Returns Max            -27.3835
evaluation/Returns Min           -232.34
evaluation/Actions Mean             0.00131304
evaluation/Actions Std              0.194711
evaluation/Actions Max              0.999273
evaluation/Actions Min             -0.99889
evaluation/Num Paths               15
evaluation/Average Returns        -75.6429
time/data storing (s)               0.00270151
time/evaluation sampling (s)        0.326779
time/exploration sampling (s)       0.140608
time/logging (s)                    0.00509938
time/saving (s)                     0.00199448
time/training (s)                   1.95501
time/epoch (s)                      2.4322
time/total (s)                    654.904
Epoch                             268
-----------------------------  ---------------
2019-04-23 00:04:17.066557 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 269 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.41127
trainer/QF2 Loss                    4.27465
trainer/Policy Loss                41.4922
trainer/Q1 Predictions Mean       -39.5503
trainer/Q1 Predictions Std         35.5383
trainer/Q1 Predictions Max         -6.97457
trainer/Q1 Predictions Min       -145.011
trainer/Q2 Predictions Mean       -39.4989
trainer/Q2 Predictions Std         35.5224
trainer/Q2 Predictions Max         -6.92719
trainer/Q2 Predictions Min       -144.18
trainer/Q Targets Mean            -40.0455
trainer/Q Targets Std              36.2659
trainer/Q Targets Max              -0.757195
trainer/Q Targets Min            -146.675
trainer/Log Pis Mean                2.21437
trainer/Log Pis Std                 1.08394
trainer/Log Pis Max                 6.99322
trainer/Log Pis Min                -2.24386
trainer/Policy mu Mean             -0.0913214
trainer/Policy mu Std               0.577248
trainer/Policy mu Max               2.32034
trainer/Policy mu Min              -3.16761
trainer/Policy log std Mean        -2.18014
trainer/Policy log std Std          0.508855
trainer/Policy log std Max         -0.295666
trainer/Policy log std Min         -3.08883
trainer/Alpha                       0.067155
trainer/Alpha Loss                  0.578967
exploration/num steps total    135200
exploration/num paths total      1352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.48551
exploration/Rewards Std             1.17611
exploration/Rewards Max            -0.165545
exploration/Rewards Min            -9.54335
exploration/Returns Mean         -148.551
exploration/Returns Std            74.0866
exploration/Returns Max           -52.2302
exploration/Returns Min          -231.054
exploration/Actions Mean           -0.00127191
exploration/Actions Std             0.228499
exploration/Actions Max             0.998594
exploration/Actions Min            -0.998924
exploration/Num Paths               5
exploration/Average Returns      -148.551
evaluation/num steps total     405000
evaluation/num paths total       4050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.761436
evaluation/Rewards Std              1.17824
evaluation/Rewards Max             -0.0281206
evaluation/Rewards Min             -9.35055
evaluation/Returns Mean           -76.1436
evaluation/Returns Std             64.7851
evaluation/Returns Max             -9.78569
evaluation/Returns Min           -227.162
evaluation/Actions Mean             0.0126363
evaluation/Actions Std              0.199292
evaluation/Actions Max              0.996779
evaluation/Actions Min             -0.995848
evaluation/Num Paths               15
evaluation/Average Returns        -76.1436
time/data storing (s)               0.00285547
time/evaluation sampling (s)        0.32134
time/exploration sampling (s)       0.140644
time/logging (s)                    0.00479281
time/saving (s)                     0.0074749
time/training (s)                   1.9568
time/epoch (s)                      2.43391
time/total (s)                    657.343
Epoch                             269
-----------------------------  ---------------
2019-04-23 00:04:19.504414 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 270 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   40.2774
trainer/QF2 Loss                   40.2105
trainer/Policy Loss                41.1247
trainer/Q1 Predictions Mean       -39.3772
trainer/Q1 Predictions Std         35.27
trainer/Q1 Predictions Max         -7.11263
trainer/Q1 Predictions Min       -114.931
trainer/Q2 Predictions Mean       -39.3699
trainer/Q2 Predictions Std         35.2779
trainer/Q2 Predictions Max         -6.98785
trainer/Q2 Predictions Min       -114.765
trainer/Q Targets Mean            -39.6004
trainer/Q Targets Std              36.0532
trainer/Q Targets Max              -1.70471
trainer/Q Targets Min            -117.145
trainer/Log Pis Mean                1.9648
trainer/Log Pis Std                 1.15843
trainer/Log Pis Max                 9.24096
trainer/Log Pis Min                -0.347564
trainer/Policy mu Mean              0.0254295
trainer/Policy mu Std               0.61511
trainer/Policy mu Max               3.14805
trainer/Policy mu Min              -3.56592
trainer/Policy log std Mean        -2.17152
trainer/Policy log std Std          0.549218
trainer/Policy log std Max         -0.461006
trainer/Policy log std Min         -3.13264
trainer/Alpha                       0.0669363
trainer/Alpha Loss                 -0.0951882
exploration/num steps total    135700
exploration/num paths total      1357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.38959
exploration/Rewards Std             1.1104
exploration/Rewards Max            -0.016122
exploration/Rewards Min            -8.63534
exploration/Returns Mean         -138.959
exploration/Returns Std            75.7112
exploration/Returns Max           -22.3528
exploration/Returns Min          -232.209
exploration/Actions Mean            0.00503502
exploration/Actions Std             0.250425
exploration/Actions Max             0.998284
exploration/Actions Min            -0.999751
exploration/Num Paths               5
exploration/Average Returns      -138.959
evaluation/num steps total     406500
evaluation/num paths total       4065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.841858
evaluation/Rewards Std              1.27636
evaluation/Rewards Max             -0.00867078
evaluation/Rewards Min            -11.1309
evaluation/Returns Mean           -84.1858
evaluation/Returns Std             70.5526
evaluation/Returns Max             -6.78298
evaluation/Returns Min           -203.032
evaluation/Actions Mean             0.00426376
evaluation/Actions Std              0.190271
evaluation/Actions Max              0.998945
evaluation/Actions Min             -0.999773
evaluation/Num Paths               15
evaluation/Average Returns        -84.1858
time/data storing (s)               0.00264119
time/evaluation sampling (s)        0.324688
time/exploration sampling (s)       0.137427
time/logging (s)                    0.00480867
time/saving (s)                     0.00199845
time/training (s)                   1.9587
time/epoch (s)                      2.43027
time/total (s)                    659.778
Epoch                             270
-----------------------------  ---------------
2019-04-23 00:04:21.947745 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 271 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.331613
trainer/QF2 Loss                    0.382377
trainer/Policy Loss                41.6473
trainer/Q1 Predictions Mean       -40.1414
trainer/Q1 Predictions Std         34.9596
trainer/Q1 Predictions Max         -7.16029
trainer/Q1 Predictions Min       -116.518
trainer/Q2 Predictions Mean       -40.1272
trainer/Q2 Predictions Std         34.9407
trainer/Q2 Predictions Max         -7.15398
trainer/Q2 Predictions Min       -116.719
trainer/Q Targets Mean            -40.4079
trainer/Q Targets Std              35.2112
trainer/Q Targets Max              -7.24925
trainer/Q Targets Min            -117.24
trainer/Log Pis Mean                1.6599
trainer/Log Pis Std                 1.4515
trainer/Log Pis Max                 6.39321
trainer/Log Pis Min                -2.21179
trainer/Policy mu Mean             -0.0719224
trainer/Policy mu Std               0.540777
trainer/Policy mu Max               2.8696
trainer/Policy mu Min              -3.10719
trainer/Policy log std Mean        -2.14618
trainer/Policy log std Std          0.503993
trainer/Policy log std Max         -0.273913
trainer/Policy log std Min         -2.97577
trainer/Alpha                       0.0652715
trainer/Alpha Loss                 -0.928112
exploration/num steps total    136200
exploration/num paths total      1362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.22251
exploration/Rewards Std             1.39443
exploration/Rewards Max            -0.012379
exploration/Rewards Min           -10.2049
exploration/Returns Mean         -122.251
exploration/Returns Std            84.1196
exploration/Returns Max           -22.421
exploration/Returns Min          -243.637
exploration/Actions Mean            0.026953
exploration/Actions Std             0.238537
exploration/Actions Max             0.999087
exploration/Actions Min            -0.995544
exploration/Num Paths               5
exploration/Average Returns      -122.251
evaluation/num steps total     408000
evaluation/num paths total       4080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.716092
evaluation/Rewards Std              1.13546
evaluation/Rewards Max             -0.0344612
evaluation/Rewards Min             -9.04364
evaluation/Returns Mean           -71.6092
evaluation/Returns Std             80.5856
evaluation/Returns Max            -10.9625
evaluation/Returns Min           -262.783
evaluation/Actions Mean            -0.0114191
evaluation/Actions Std              0.172762
evaluation/Actions Max              0.995327
evaluation/Actions Min             -0.999248
evaluation/Num Paths               15
evaluation/Average Returns        -71.6092
time/data storing (s)               0.0027682
time/evaluation sampling (s)        0.323364
time/exploration sampling (s)       0.143824
time/logging (s)                    0.00480445
time/saving (s)                     0.0019656
time/training (s)                   1.95859
time/epoch (s)                      2.43531
time/total (s)                    662.217
Epoch                             271
-----------------------------  ---------------
2019-04-23 00:04:24.361499 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 272 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.169007
trainer/QF2 Loss                    0.188451
trainer/Policy Loss                36.6918
trainer/Q1 Predictions Mean       -35.0703
trainer/Q1 Predictions Std         30.0992
trainer/Q1 Predictions Max         -7.30246
trainer/Q1 Predictions Min       -116.018
trainer/Q2 Predictions Mean       -35.0748
trainer/Q2 Predictions Std         30.084
trainer/Q2 Predictions Max         -7.28175
trainer/Q2 Predictions Min       -116.072
trainer/Q Targets Mean            -35.3351
trainer/Q Targets Std              30.3103
trainer/Q Targets Max              -7.15145
trainer/Q Targets Min            -116.572
trainer/Log Pis Mean                1.82501
trainer/Log Pis Std                 1.22446
trainer/Log Pis Max                 7.05165
trainer/Log Pis Min                -3.43769
trainer/Policy mu Mean             -0.0607744
trainer/Policy mu Std               0.497296
trainer/Policy mu Max               3.65775
trainer/Policy mu Min              -1.87624
trainer/Policy log std Mean        -2.13104
trainer/Policy log std Std          0.428599
trainer/Policy log std Max         -0.730572
trainer/Policy log std Min         -2.95853
trainer/Alpha                       0.0648573
trainer/Alpha Loss                 -0.478675
exploration/num steps total    136700
exploration/num paths total      1367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.851633
exploration/Rewards Std             1.30384
exploration/Rewards Max            -0.00296251
exploration/Rewards Min           -10.4231
exploration/Returns Mean          -85.1633
exploration/Returns Std            84.6717
exploration/Returns Max           -24.2102
exploration/Returns Min          -250.607
exploration/Actions Mean           -0.024492
exploration/Actions Std             0.227835
exploration/Actions Max             0.994746
exploration/Actions Min            -0.999573
exploration/Num Paths               5
exploration/Average Returns       -85.1633
evaluation/num steps total     409500
evaluation/num paths total       4095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.05095
evaluation/Rewards Std              1.13529
evaluation/Rewards Max             -0.0280325
evaluation/Rewards Min            -10.6493
evaluation/Returns Mean          -105.095
evaluation/Returns Std             81.1134
evaluation/Returns Max             -7.31564
evaluation/Returns Min           -238.195
evaluation/Actions Mean             0.00412208
evaluation/Actions Std              0.170982
evaluation/Actions Max              0.999516
evaluation/Actions Min             -0.997745
evaluation/Num Paths               15
evaluation/Average Returns       -105.095
time/data storing (s)               0.00274528
time/evaluation sampling (s)        0.330166
time/exploration sampling (s)       0.134523
time/logging (s)                    0.00433933
time/saving (s)                     0.00160131
time/training (s)                   1.93125
time/epoch (s)                      2.40463
time/total (s)                    664.626
Epoch                             272
-----------------------------  ---------------
2019-04-23 00:04:26.799012 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 273 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.09931
trainer/QF2 Loss                    2.1069
trainer/Policy Loss                42.4847
trainer/Q1 Predictions Mean       -40.7379
trainer/Q1 Predictions Std         33.9163
trainer/Q1 Predictions Max         -7.3388
trainer/Q1 Predictions Min       -118.801
trainer/Q2 Predictions Mean       -40.7839
trainer/Q2 Predictions Std         33.9494
trainer/Q2 Predictions Max         -7.35468
trainer/Q2 Predictions Min       -119.611
trainer/Q Targets Mean            -40.8269
trainer/Q Targets Std              34.1887
trainer/Q Targets Max              -0.964074
trainer/Q Targets Min            -118.595
trainer/Log Pis Mean                1.87712
trainer/Log Pis Std                 1.27847
trainer/Log Pis Max                 8.79468
trainer/Log Pis Min                -2.403
trainer/Policy mu Mean             -0.0212422
trainer/Policy mu Std               0.619799
trainer/Policy mu Max               2.91663
trainer/Policy mu Min              -2.72547
trainer/Policy log std Mean        -2.14849
trainer/Policy log std Std          0.51491
trainer/Policy log std Max         -0.501215
trainer/Policy log std Min         -3.17013
trainer/Alpha                       0.0668376
trainer/Alpha Loss                 -0.332446
exploration/num steps total    137200
exploration/num paths total      1372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.645022
exploration/Rewards Std             0.984891
exploration/Rewards Max            -0.00940969
exploration/Rewards Min            -8.43772
exploration/Returns Mean          -64.5022
exploration/Returns Std            55.6115
exploration/Returns Max           -30.7591
exploration/Returns Min          -174.885
exploration/Actions Mean            0.00937726
exploration/Actions Std             0.222215
exploration/Actions Max             0.995516
exploration/Actions Min            -0.999345
exploration/Num Paths               5
exploration/Average Returns       -64.5022
evaluation/num steps total     411000
evaluation/num paths total       4110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.781865
evaluation/Rewards Std              1.06949
evaluation/Rewards Max             -0.0428198
evaluation/Rewards Min             -9.88457
evaluation/Returns Mean           -78.1865
evaluation/Returns Std             69.7161
evaluation/Returns Max            -13.7192
evaluation/Returns Min           -262.801
evaluation/Actions Mean            -0.0152542
evaluation/Actions Std              0.172787
evaluation/Actions Max              0.996232
evaluation/Actions Min             -0.998624
evaluation/Num Paths               15
evaluation/Average Returns        -78.1865
time/data storing (s)               0.00275274
time/evaluation sampling (s)        0.324083
time/exploration sampling (s)       0.138298
time/logging (s)                    0.00478094
time/saving (s)                     0.00164881
time/training (s)                   1.95816
time/epoch (s)                      2.42972
time/total (s)                    667.06
Epoch                             273
-----------------------------  ---------------
2019-04-23 00:04:29.227539 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 274 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   17.5659
trainer/QF2 Loss                   17.5458
trainer/Policy Loss                43.179
trainer/Q1 Predictions Mean       -41.5226
trainer/Q1 Predictions Std         33.8771
trainer/Q1 Predictions Max         -7.13007
trainer/Q1 Predictions Min       -114.763
trainer/Q2 Predictions Mean       -41.5434
trainer/Q2 Predictions Std         33.9201
trainer/Q2 Predictions Max         -7.06034
trainer/Q2 Predictions Min       -114.873
trainer/Q Targets Mean            -41.491
trainer/Q Targets Std              34.352
trainer/Q Targets Max              -1.80906
trainer/Q Targets Min            -115.274
trainer/Log Pis Mean                1.82552
trainer/Log Pis Std                 1.19991
trainer/Log Pis Max                 3.72861
trainer/Log Pis Min                -2.58623
trainer/Policy mu Mean             -0.0405246
trainer/Policy mu Std               0.411382
trainer/Policy mu Max               1.58889
trainer/Policy mu Min              -1.63083
trainer/Policy log std Mean        -2.19589
trainer/Policy log std Std          0.432889
trainer/Policy log std Max         -0.80233
trainer/Policy log std Min         -3.21896
trainer/Alpha                       0.0658984
trainer/Alpha Loss                 -0.474507
exploration/num steps total    137700
exploration/num paths total      1377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.852885
exploration/Rewards Std             1.33595
exploration/Rewards Max            -0.00176548
exploration/Rewards Min            -9.52889
exploration/Returns Mean          -85.2885
exploration/Returns Std            79.9431
exploration/Returns Max           -22.9168
exploration/Returns Min          -243.014
exploration/Actions Mean           -0.0376749
exploration/Actions Std             0.23781
exploration/Actions Max             0.993574
exploration/Actions Min            -0.999931
exploration/Num Paths               5
exploration/Average Returns       -85.2885
evaluation/num steps total     412500
evaluation/num paths total       4125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.673136
evaluation/Rewards Std              1.18096
evaluation/Rewards Max             -0.0131965
evaluation/Rewards Min            -10.5758
evaluation/Returns Mean           -67.3136
evaluation/Returns Std             74.7712
evaluation/Returns Max             -3.31092
evaluation/Returns Min           -238.359
evaluation/Actions Mean             0.00212992
evaluation/Actions Std              0.182441
evaluation/Actions Max              0.997063
evaluation/Actions Min             -0.999823
evaluation/Num Paths               15
evaluation/Average Returns        -67.3136
time/data storing (s)               0.00261613
time/evaluation sampling (s)        0.327472
time/exploration sampling (s)       0.139359
time/logging (s)                    0.0040055
time/saving (s)                     0.00198314
time/training (s)                   1.94361
time/epoch (s)                      2.41905
time/total (s)                    669.483
Epoch                             274
-----------------------------  ---------------
2019-04-23 00:04:31.652498 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 275 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   52.1169
trainer/QF2 Loss                   51.9326
trainer/Policy Loss                40.4768
trainer/Q1 Predictions Mean       -38.6312
trainer/Q1 Predictions Std         33.5053
trainer/Q1 Predictions Max         -6.97553
trainer/Q1 Predictions Min       -125.404
trainer/Q2 Predictions Mean       -38.6881
trainer/Q2 Predictions Std         33.5097
trainer/Q2 Predictions Max         -7.06126
trainer/Q2 Predictions Min       -126.074
trainer/Q Targets Mean            -38.2155
trainer/Q Targets Std              33.6079
trainer/Q Targets Max              -1.60901
trainer/Q Targets Min            -122.019
trainer/Log Pis Mean                2.09469
trainer/Log Pis Std                 1.43777
trainer/Log Pis Max                 8.55439
trainer/Log Pis Min                -1.75784
trainer/Policy mu Mean              0.0542137
trainer/Policy mu Std               0.694278
trainer/Policy mu Max               3.47564
trainer/Policy mu Min              -2.6794
trainer/Policy log std Mean        -2.14398
trainer/Policy log std Std          0.550899
trainer/Policy log std Max         -0.0240507
trainer/Policy log std Min         -3.19882
trainer/Alpha                       0.0681818
trainer/Alpha Loss                  0.254293
exploration/num steps total    138200
exploration/num paths total      1382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.836251
exploration/Rewards Std             1.20948
exploration/Rewards Max            -0.00777933
exploration/Rewards Min            -7.67267
exploration/Returns Mean          -83.6251
exploration/Returns Std            84.3127
exploration/Returns Max           -27.9817
exploration/Returns Min          -249.054
exploration/Actions Mean           -0.0355712
exploration/Actions Std             0.231301
exploration/Actions Max             0.997293
exploration/Actions Min            -0.999707
exploration/Num Paths               5
exploration/Average Returns       -83.6251
evaluation/num steps total     414000
evaluation/num paths total       4140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.845894
evaluation/Rewards Std              0.986477
evaluation/Rewards Max             -0.0537151
evaluation/Rewards Min             -9.61652
evaluation/Returns Mean           -84.5894
evaluation/Returns Std             40.0673
evaluation/Returns Max            -14.4941
evaluation/Returns Min           -166.64
evaluation/Actions Mean            -0.00559205
evaluation/Actions Std              0.185779
evaluation/Actions Max              0.996902
evaluation/Actions Min             -0.998641
evaluation/Num Paths               15
evaluation/Average Returns        -84.5894
time/data storing (s)               0.00277501
time/evaluation sampling (s)        0.32706
time/exploration sampling (s)       0.139695
time/logging (s)                    0.00494671
time/saving (s)                     0.0019762
time/training (s)                   1.94113
time/epoch (s)                      2.41758
time/total (s)                    671.905
Epoch                             275
-----------------------------  ---------------
2019-04-23 00:04:34.091967 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 276 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.624573
trainer/QF2 Loss                    0.681075
trainer/Policy Loss                43.2769
trainer/Q1 Predictions Mean       -41.5778
trainer/Q1 Predictions Std         33.2302
trainer/Q1 Predictions Max         -7.09981
trainer/Q1 Predictions Min       -114.808
trainer/Q2 Predictions Mean       -41.5837
trainer/Q2 Predictions Std         33.2205
trainer/Q2 Predictions Max         -7.05587
trainer/Q2 Predictions Min       -115.478
trainer/Q Targets Mean            -42.0825
trainer/Q Targets Std              33.6631
trainer/Q Targets Max              -7.1859
trainer/Q Targets Min            -117.639
trainer/Log Pis Mean                1.9158
trainer/Log Pis Std                 1.10566
trainer/Log Pis Max                 5.57066
trainer/Log Pis Min                -1.42148
trainer/Policy mu Mean              0.00156766
trainer/Policy mu Std               0.595489
trainer/Policy mu Max               3.06385
trainer/Policy mu Min              -3.84885
trainer/Policy log std Mean        -2.12538
trainer/Policy log std Std          0.509896
trainer/Policy log std Max         -0.130155
trainer/Policy log std Min         -3.0505
trainer/Alpha                       0.067701
trainer/Alpha Loss                 -0.226696
exploration/num steps total    138700
exploration/num paths total      1387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.22874
exploration/Rewards Std             1.30989
exploration/Rewards Max            -0.0166885
exploration/Rewards Min           -11.5676
exploration/Returns Mean         -122.874
exploration/Returns Std            87.5414
exploration/Returns Max           -14.1942
exploration/Returns Min          -265.345
exploration/Actions Mean           -0.0202489
exploration/Actions Std             0.248382
exploration/Actions Max             0.999328
exploration/Actions Min            -0.999551
exploration/Num Paths               5
exploration/Average Returns      -122.874
evaluation/num steps total     415500
evaluation/num paths total       4155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.783443
evaluation/Rewards Std              1.18178
evaluation/Rewards Max             -0.0500897
evaluation/Rewards Min            -10.8289
evaluation/Returns Mean           -78.3443
evaluation/Returns Std             58.0819
evaluation/Returns Max            -10.1751
evaluation/Returns Min           -176.972
evaluation/Actions Mean             0.0118925
evaluation/Actions Std              0.201814
evaluation/Actions Max              0.997914
evaluation/Actions Min             -0.999392
evaluation/Num Paths               15
evaluation/Average Returns        -78.3443
time/data storing (s)               0.00265446
time/evaluation sampling (s)        0.325061
time/exploration sampling (s)       0.137067
time/logging (s)                    0.00469528
time/saving (s)                     0.00159585
time/training (s)                   1.95941
time/epoch (s)                      2.43048
time/total (s)                    674.34
Epoch                             276
-----------------------------  ---------------
2019-04-23 00:04:36.536178 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 277 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.67746
trainer/QF2 Loss                    1.67015
trainer/Policy Loss                37.2478
trainer/Q1 Predictions Mean       -35.2666
trainer/Q1 Predictions Std         31.9789
trainer/Q1 Predictions Max         -7.20675
trainer/Q1 Predictions Min       -113.345
trainer/Q2 Predictions Mean       -35.3166
trainer/Q2 Predictions Std         31.9531
trainer/Q2 Predictions Max         -7.29295
trainer/Q2 Predictions Min       -113.237
trainer/Q Targets Mean            -35.4406
trainer/Q Targets Std              32.4466
trainer/Q Targets Max              -0.150765
trainer/Q Targets Min            -114
trainer/Log Pis Mean                2.10547
trainer/Log Pis Std                 1.09207
trainer/Log Pis Max                 4.52025
trainer/Log Pis Min                -2.91892
trainer/Policy mu Mean             -0.0150324
trainer/Policy mu Std               0.457148
trainer/Policy mu Max               1.92246
trainer/Policy mu Min              -2.16698
trainer/Policy log std Mean        -2.2501
trainer/Policy log std Std          0.422286
trainer/Policy log std Max         -0.656213
trainer/Policy log std Min         -3.07749
trainer/Alpha                       0.0676812
trainer/Alpha Loss                  0.28405
exploration/num steps total    139200
exploration/num paths total      1392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.472938
exploration/Rewards Std             1.09645
exploration/Rewards Max            -0.0085465
exploration/Rewards Min           -10.1393
exploration/Returns Mean          -47.2938
exploration/Returns Std            10.0797
exploration/Returns Max           -36.6062
exploration/Returns Min           -66.4694
exploration/Actions Mean            0.0157283
exploration/Actions Std             0.228312
exploration/Actions Max             0.994811
exploration/Actions Min            -0.998171
exploration/Num Paths               5
exploration/Average Returns       -47.2938
evaluation/num steps total     417000
evaluation/num paths total       4170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.62362
evaluation/Rewards Std              1.1303
evaluation/Rewards Max             -0.0292183
evaluation/Rewards Min            -10.828
evaluation/Returns Mean           -62.362
evaluation/Returns Std             59.0688
evaluation/Returns Max             -8.46663
evaluation/Returns Min           -248.248
evaluation/Actions Mean            -0.0136074
evaluation/Actions Std              0.17944
evaluation/Actions Max              0.997421
evaluation/Actions Min             -0.999135
evaluation/Num Paths               15
evaluation/Average Returns        -62.362
time/data storing (s)               0.0028421
time/evaluation sampling (s)        0.325002
time/exploration sampling (s)       0.137619
time/logging (s)                    0.00351758
time/saving (s)                     0.00197793
time/training (s)                   1.96322
time/epoch (s)                      2.43418
time/total (s)                    676.779
Epoch                             277
-----------------------------  ---------------
2019-04-23 00:04:38.953371 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 278 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.995018
trainer/QF2 Loss                    1.03847
trainer/Policy Loss                37.456
trainer/Q1 Predictions Mean       -35.5883
trainer/Q1 Predictions Std         31.8394
trainer/Q1 Predictions Max         -7.14108
trainer/Q1 Predictions Min       -117.313
trainer/Q2 Predictions Mean       -35.5604
trainer/Q2 Predictions Std         31.8122
trainer/Q2 Predictions Max         -7.08186
trainer/Q2 Predictions Min       -116.548
trainer/Q Targets Mean            -35.8257
trainer/Q Targets Std              32.0834
trainer/Q Targets Max              -0.162625
trainer/Q Targets Min            -117.968
trainer/Log Pis Mean                2.08431
trainer/Log Pis Std                 1.08597
trainer/Log Pis Max                 5.47945
trainer/Log Pis Min                -2.43045
trainer/Policy mu Mean             -0.0530721
trainer/Policy mu Std               0.53301
trainer/Policy mu Max               3.37937
trainer/Policy mu Min              -2.29792
trainer/Policy log std Mean        -2.18372
trainer/Policy log std Std          0.443575
trainer/Policy log std Max         -0.631131
trainer/Policy log std Min         -3.10044
trainer/Alpha                       0.0692979
trainer/Alpha Loss                  0.225043
exploration/num steps total    139700
exploration/num paths total      1397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.997141
exploration/Rewards Std             1.12698
exploration/Rewards Max            -0.00509349
exploration/Rewards Min            -9.26426
exploration/Returns Mean          -99.7141
exploration/Returns Std            90.1576
exploration/Returns Max           -15.5561
exploration/Returns Min          -235.624
exploration/Actions Mean           -0.00331136
exploration/Actions Std             0.221487
exploration/Actions Max             0.999897
exploration/Actions Min            -0.997681
exploration/Num Paths               5
exploration/Average Returns       -99.7141
evaluation/num steps total     418500
evaluation/num paths total       4185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06526
evaluation/Rewards Std              1.20365
evaluation/Rewards Max             -0.0518444
evaluation/Rewards Min            -10.2622
evaluation/Returns Mean          -106.526
evaluation/Returns Std             76.1277
evaluation/Returns Max            -15.532
evaluation/Returns Min           -239.679
evaluation/Actions Mean            -0.00316049
evaluation/Actions Std              0.19987
evaluation/Actions Max              0.999394
evaluation/Actions Min             -0.999643
evaluation/Num Paths               15
evaluation/Average Returns       -106.526
time/data storing (s)               0.00286184
time/evaluation sampling (s)        0.324895
time/exploration sampling (s)       0.137486
time/logging (s)                    0.0047369
time/saving (s)                     0.0019968
time/training (s)                   1.93831
time/epoch (s)                      2.41028
time/total (s)                    679.194
Epoch                             278
-----------------------------  ---------------
2019-04-23 00:04:41.365167 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 279 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.621232
trainer/QF2 Loss                    0.687591
trainer/Policy Loss                45.7219
trainer/Q1 Predictions Mean       -43.6312
trainer/Q1 Predictions Std         35.117
trainer/Q1 Predictions Max         -7.18211
trainer/Q1 Predictions Min       -119.652
trainer/Q2 Predictions Mean       -43.6018
trainer/Q2 Predictions Std         35.0907
trainer/Q2 Predictions Max         -7.06231
trainer/Q2 Predictions Min       -119.725
trainer/Q Targets Mean            -44.3085
trainer/Q Targets Std              35.4164
trainer/Q Targets Max              -7.31692
trainer/Q Targets Min            -120.485
trainer/Log Pis Mean                2.25616
trainer/Log Pis Std                 1.55113
trainer/Log Pis Max                11.7516
trainer/Log Pis Min                -1.31128
trainer/Policy mu Mean              0.0106345
trainer/Policy mu Std               0.594836
trainer/Policy mu Max               3.30785
trainer/Policy mu Min              -3.73447
trainer/Policy log std Mean        -2.22461
trainer/Policy log std Std          0.483225
trainer/Policy log std Max         -0.529721
trainer/Policy log std Min         -3.19776
trainer/Alpha                       0.0684303
trainer/Alpha Loss                  0.687019
exploration/num steps total    140200
exploration/num paths total      1402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.557255
exploration/Rewards Std             0.59973
exploration/Rewards Max            -0.0120599
exploration/Rewards Min            -6.69903
exploration/Returns Mean          -55.7255
exploration/Returns Std            32.0207
exploration/Returns Max           -28.291
exploration/Returns Min          -116.202
exploration/Actions Mean           -0.012814
exploration/Actions Std             0.178945
exploration/Actions Max             0.992319
exploration/Actions Min            -0.9978
exploration/Num Paths               5
exploration/Average Returns       -55.7255
evaluation/num steps total     420000
evaluation/num paths total       4200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.684479
evaluation/Rewards Std              0.922023
evaluation/Rewards Max             -0.0222746
evaluation/Rewards Min             -8.03167
evaluation/Returns Mean           -68.4479
evaluation/Returns Std             67.0928
evaluation/Returns Max             -8.89871
evaluation/Returns Min           -230.692
evaluation/Actions Mean            -0.00526832
evaluation/Actions Std              0.164435
evaluation/Actions Max              0.998367
evaluation/Actions Min             -0.997559
evaluation/Num Paths               15
evaluation/Average Returns        -68.4479
time/data storing (s)               0.00264265
time/evaluation sampling (s)        0.318319
time/exploration sampling (s)       0.140903
time/logging (s)                    0.00475495
time/saving (s)                     0.00194361
time/training (s)                   1.9352
time/epoch (s)                      2.40376
time/total (s)                    681.601
Epoch                             279
-----------------------------  ---------------
2019-04-23 00:04:43.818943 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 280 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.32933
trainer/QF2 Loss                    1.2239
trainer/Policy Loss                39.8703
trainer/Q1 Predictions Mean       -37.983
trainer/Q1 Predictions Std         32.4914
trainer/Q1 Predictions Max         -7.00567
trainer/Q1 Predictions Min       -109.239
trainer/Q2 Predictions Mean       -37.9893
trainer/Q2 Predictions Std         32.522
trainer/Q2 Predictions Max         -6.87938
trainer/Q2 Predictions Min       -109.424
trainer/Q Targets Mean            -38.6804
trainer/Q Targets Std              33.1893
trainer/Q Targets Max              -7.28207
trainer/Q Targets Min            -112.418
trainer/Log Pis Mean                2.00898
trainer/Log Pis Std                 1.28931
trainer/Log Pis Max                 8.5096
trainer/Log Pis Min                -1.19069
trainer/Policy mu Mean             -0.0224849
trainer/Policy mu Std               0.559454
trainer/Policy mu Max               1.85681
trainer/Policy mu Min              -4.03834
trainer/Policy log std Mean        -2.17012
trainer/Policy log std Std          0.453919
trainer/Policy log std Max         -0.0315827
trainer/Policy log std Min         -3.009
trainer/Alpha                       0.0710652
trainer/Alpha Loss                  0.0237333
exploration/num steps total    140700
exploration/num paths total      1407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.590691
exploration/Rewards Std             0.628829
exploration/Rewards Max            -0.00981508
exploration/Rewards Min            -5.11523
exploration/Returns Mean          -59.0691
exploration/Returns Std            44.0968
exploration/Returns Max           -29.1769
exploration/Returns Min          -145.805
exploration/Actions Mean            0.00688722
exploration/Actions Std             0.212614
exploration/Actions Max             0.992679
exploration/Actions Min            -0.982892
exploration/Num Paths               5
exploration/Average Returns       -59.0691
evaluation/num steps total     421500
evaluation/num paths total       4215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00237
evaluation/Rewards Std              1.08398
evaluation/Rewards Max             -0.132757
evaluation/Rewards Min             -8.9414
evaluation/Returns Mean          -100.237
evaluation/Returns Std             80.4779
evaluation/Returns Max            -16.3185
evaluation/Returns Min           -257.063
evaluation/Actions Mean             0.00200346
evaluation/Actions Std              0.177982
evaluation/Actions Max              0.998608
evaluation/Actions Min             -0.998862
evaluation/Num Paths               15
evaluation/Average Returns       -100.237
time/data storing (s)               0.00385753
time/evaluation sampling (s)        0.322884
time/exploration sampling (s)       0.159366
time/logging (s)                    0.00477342
time/saving (s)                     0.0097859
time/training (s)                   1.94466
time/epoch (s)                      2.44533
time/total (s)                    684.051
Epoch                             280
-----------------------------  ---------------
2019-04-23 00:04:46.304404 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 281 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.789
trainer/QF2 Loss                    4.9243
trainer/Policy Loss                43.277
trainer/Q1 Predictions Mean       -41.4709
trainer/Q1 Predictions Std         32.7155
trainer/Q1 Predictions Max         -7.15985
trainer/Q1 Predictions Min       -126.736
trainer/Q2 Predictions Mean       -41.4725
trainer/Q2 Predictions Std         32.6326
trainer/Q2 Predictions Max         -7.0805
trainer/Q2 Predictions Min       -123.72
trainer/Q Targets Mean            -41.65
trainer/Q Targets Std              33.2112
trainer/Q Targets Max              -0.138465
trainer/Q Targets Min            -126.926
trainer/Log Pis Mean                2.02774
trainer/Log Pis Std                 1.5301
trainer/Log Pis Max                 9.15054
trainer/Log Pis Min                -3.63453
trainer/Policy mu Mean              0.00559522
trainer/Policy mu Std               0.681316
trainer/Policy mu Max               2.98317
trainer/Policy mu Min              -3.19365
trainer/Policy log std Mean        -2.15776
trainer/Policy log std Std          0.549893
trainer/Policy log std Max         -0.428026
trainer/Policy log std Min         -2.99903
trainer/Alpha                       0.0730874
trainer/Alpha Loss                  0.072564
exploration/num steps total    141200
exploration/num paths total      1412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.361088
exploration/Rewards Std             0.988709
exploration/Rewards Max            -0.00409114
exploration/Rewards Min            -9.77868
exploration/Returns Mean          -36.1088
exploration/Returns Std            12.4827
exploration/Returns Max           -22.8845
exploration/Returns Min           -57.7861
exploration/Actions Mean           -0.0026892
exploration/Actions Std             0.224833
exploration/Actions Max             0.998933
exploration/Actions Min            -0.999729
exploration/Num Paths               5
exploration/Average Returns       -36.1088
evaluation/num steps total     423000
evaluation/num paths total       4230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.997199
evaluation/Rewards Std              1.1153
evaluation/Rewards Max             -0.0100225
evaluation/Rewards Min             -9.94346
evaluation/Returns Mean           -99.7199
evaluation/Returns Std             74.343
evaluation/Returns Max             -7.36297
evaluation/Returns Min           -234.353
evaluation/Actions Mean             0.00397476
evaluation/Actions Std              0.172895
evaluation/Actions Max              0.998213
evaluation/Actions Min             -0.997982
evaluation/Num Paths               15
evaluation/Average Returns        -99.7199
time/data storing (s)               0.00262353
time/evaluation sampling (s)        0.331432
time/exploration sampling (s)       0.139669
time/logging (s)                    0.00476644
time/saving (s)                     0.00208946
time/training (s)                   1.99611
time/epoch (s)                      2.47669
time/total (s)                    686.532
Epoch                             281
-----------------------------  ---------------
2019-04-23 00:04:48.735326 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 282 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   90.4225
trainer/QF2 Loss                   90.2392
trainer/Policy Loss                40.3298
trainer/Q1 Predictions Mean       -38.3958
trainer/Q1 Predictions Std         34.7738
trainer/Q1 Predictions Max         -7.18976
trainer/Q1 Predictions Min       -117.57
trainer/Q2 Predictions Mean       -38.3853
trainer/Q2 Predictions Std         34.7629
trainer/Q2 Predictions Max         -7.14679
trainer/Q2 Predictions Min       -117.39
trainer/Q Targets Mean            -37.0663
trainer/Q Targets Std              35.2599
trainer/Q Targets Max              -0.823901
trainer/Q Targets Min            -114.417
trainer/Log Pis Mean                2.1087
trainer/Log Pis Std                 1.13964
trainer/Log Pis Max                 7.03124
trainer/Log Pis Min                -0.476169
trainer/Policy mu Mean             -0.0316965
trainer/Policy mu Std               0.541316
trainer/Policy mu Max               2.90471
trainer/Policy mu Min              -2.54655
trainer/Policy log std Mean        -2.23622
trainer/Policy log std Std          0.501822
trainer/Policy log std Max         -0.488388
trainer/Policy log std Min         -3.23005
trainer/Alpha                       0.0728673
trainer/Alpha Loss                  0.2847
exploration/num steps total    141700
exploration/num paths total      1417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.16866
exploration/Rewards Std             1.16908
exploration/Rewards Max            -0.00484275
exploration/Rewards Min            -8.37766
exploration/Returns Mean         -116.866
exploration/Returns Std            92.2471
exploration/Returns Max           -15.7957
exploration/Returns Min          -253.735
exploration/Actions Mean            0.00356727
exploration/Actions Std             0.230681
exploration/Actions Max             0.997288
exploration/Actions Min            -0.999723
exploration/Num Paths               5
exploration/Average Returns      -116.866
evaluation/num steps total     424500
evaluation/num paths total       4245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.64722
evaluation/Rewards Std              1.1244
evaluation/Rewards Max             -0.0309265
evaluation/Rewards Min             -8.93618
evaluation/Returns Mean           -64.722
evaluation/Returns Std             62.6789
evaluation/Returns Max             -9.13753
evaluation/Returns Min           -230.996
evaluation/Actions Mean             0.00628376
evaluation/Actions Std              0.182057
evaluation/Actions Max              0.997781
evaluation/Actions Min             -0.998974
evaluation/Num Paths               15
evaluation/Average Returns        -64.722
time/data storing (s)               0.00280923
time/evaluation sampling (s)        0.324326
time/exploration sampling (s)       0.139732
time/logging (s)                    0.00480158
time/saving (s)                     0.00195942
time/training (s)                   1.94853
time/epoch (s)                      2.42216
time/total (s)                    688.959
Epoch                             282
-----------------------------  ---------------
2019-04-23 00:04:51.169337 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 283 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  118.209
trainer/QF2 Loss                  118.559
trainer/Policy Loss                41.8741
trainer/Q1 Predictions Mean       -40.1849
trainer/Q1 Predictions Std         33.4073
trainer/Q1 Predictions Max         -7.43151
trainer/Q1 Predictions Min       -112.962
trainer/Q2 Predictions Mean       -40.2112
trainer/Q2 Predictions Std         33.3837
trainer/Q2 Predictions Max         -7.4531
trainer/Q2 Predictions Min       -112.832
trainer/Q Targets Mean            -39.1909
trainer/Q Targets Std              32.9743
trainer/Q Targets Max              -2.32911
trainer/Q Targets Min            -113.589
trainer/Log Pis Mean                1.90953
trainer/Log Pis Std                 1.39285
trainer/Log Pis Max                 7.74065
trainer/Log Pis Min                -2.15549
trainer/Policy mu Mean              0.0816999
trainer/Policy mu Std               0.70469
trainer/Policy mu Max               2.95849
trainer/Policy mu Min              -2.85389
trainer/Policy log std Mean        -2.09746
trainer/Policy log std Std          0.589437
trainer/Policy log std Max         -0.37903
trainer/Policy log std Min         -3.15579
trainer/Alpha                       0.0733769
trainer/Alpha Loss                 -0.236341
exploration/num steps total    142200
exploration/num paths total      1422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.519482
exploration/Rewards Std             0.841059
exploration/Rewards Max            -0.00828604
exploration/Rewards Min            -7.21583
exploration/Returns Mean          -51.9482
exploration/Returns Std            33.6258
exploration/Returns Max           -21.6136
exploration/Returns Min          -117.228
exploration/Actions Mean            0.00878613
exploration/Actions Std             0.215244
exploration/Actions Max             0.998977
exploration/Actions Min            -0.998761
exploration/Num Paths               5
exploration/Average Returns       -51.9482
evaluation/num steps total     426000
evaluation/num paths total       4260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.716717
evaluation/Rewards Std              1.14546
evaluation/Rewards Max             -0.0116107
evaluation/Rewards Min             -9.30702
evaluation/Returns Mean           -71.6717
evaluation/Returns Std             74.9729
evaluation/Returns Max             -9.68664
evaluation/Returns Min           -231.828
evaluation/Actions Mean             0.00204744
evaluation/Actions Std              0.185036
evaluation/Actions Max              0.999198
evaluation/Actions Min             -0.999408
evaluation/Num Paths               15
evaluation/Average Returns        -71.6717
time/data storing (s)               0.0026796
time/evaluation sampling (s)        0.32838
time/exploration sampling (s)       0.136869
time/logging (s)                    0.00482659
time/saving (s)                     0.00202774
time/training (s)                   1.95034
time/epoch (s)                      2.42512
time/total (s)                    691.389
Epoch                             283
-----------------------------  ---------------
2019-04-23 00:04:53.614102 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 284 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.178427
trainer/QF2 Loss                    0.181591
trainer/Policy Loss                36.5524
trainer/Q1 Predictions Mean       -34.8145
trainer/Q1 Predictions Std         34.1808
trainer/Q1 Predictions Max         -7.37335
trainer/Q1 Predictions Min       -124.5
trainer/Q2 Predictions Mean       -34.8504
trainer/Q2 Predictions Std         34.1344
trainer/Q2 Predictions Max         -7.47523
trainer/Q2 Predictions Min       -123.579
trainer/Q Targets Mean            -35.0266
trainer/Q Targets Std              34.4126
trainer/Q Targets Max              -7.38646
trainer/Q Targets Min            -124.619
trainer/Log Pis Mean                1.87889
trainer/Log Pis Std                 1.21928
trainer/Log Pis Max                 3.48919
trainer/Log Pis Min                -2.95155
trainer/Policy mu Mean             -0.0957957
trainer/Policy mu Std               0.579176
trainer/Policy mu Max               1.30412
trainer/Policy mu Min              -4.35689
trainer/Policy log std Mean        -2.1557
trainer/Policy log std Std          0.506868
trainer/Policy log std Max          0.353401
trainer/Policy log std Min         -2.92464
trainer/Alpha                       0.0734338
trainer/Alpha Loss                 -0.31627
exploration/num steps total    142700
exploration/num paths total      1427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.19313
exploration/Rewards Std             1.33254
exploration/Rewards Max            -0.00721959
exploration/Rewards Min           -10.2578
exploration/Returns Mean         -119.313
exploration/Returns Std            57.7672
exploration/Returns Max           -45.7837
exploration/Returns Min          -194.293
exploration/Actions Mean            0.0358685
exploration/Actions Std             0.280948
exploration/Actions Max             0.999916
exploration/Actions Min            -0.998931
exploration/Num Paths               5
exploration/Average Returns      -119.313
evaluation/num steps total     427500
evaluation/num paths total       4275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.58633
evaluation/Rewards Std              0.979938
evaluation/Rewards Max             -0.00583146
evaluation/Rewards Min            -10.8674
evaluation/Returns Mean           -58.633
evaluation/Returns Std             61.836
evaluation/Returns Max             -6.92034
evaluation/Returns Min           -229.776
evaluation/Actions Mean            -0.00759703
evaluation/Actions Std              0.173932
evaluation/Actions Max              0.995785
evaluation/Actions Min             -0.999604
evaluation/Num Paths               15
evaluation/Average Returns        -58.633
time/data storing (s)               0.00289528
time/evaluation sampling (s)        0.331466
time/exploration sampling (s)       0.144024
time/logging (s)                    0.00477625
time/saving (s)                     0.00180187
time/training (s)                   1.95095
time/epoch (s)                      2.43591
time/total (s)                    693.829
Epoch                             284
-----------------------------  ---------------
2019-04-23 00:04:56.033138 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 285 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.405001
trainer/QF2 Loss                    0.421443
trainer/Policy Loss                37.3477
trainer/Q1 Predictions Mean       -35.6213
trainer/Q1 Predictions Std         31.3879
trainer/Q1 Predictions Max         -7.41325
trainer/Q1 Predictions Min       -120.368
trainer/Q2 Predictions Mean       -35.6047
trainer/Q2 Predictions Std         31.3438
trainer/Q2 Predictions Max         -7.33826
trainer/Q2 Predictions Min       -119.874
trainer/Q Targets Mean            -36.0756
trainer/Q Targets Std              31.6562
trainer/Q Targets Max              -7.36939
trainer/Q Targets Min            -120.979
trainer/Log Pis Mean                1.94321
trainer/Log Pis Std                 1.35666
trainer/Log Pis Max                 5.97894
trainer/Log Pis Min                -2.22812
trainer/Policy mu Mean             -0.0510471
trainer/Policy mu Std               0.588034
trainer/Policy mu Max               2.80316
trainer/Policy mu Min              -2.35109
trainer/Policy log std Mean        -2.16132
trainer/Policy log std Std          0.52864
trainer/Policy log std Max         -0.409828
trainer/Policy log std Min         -3.12858
trainer/Alpha                       0.0748907
trainer/Alpha Loss                 -0.147176
exploration/num steps total    143200
exploration/num paths total      1432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.06824
exploration/Rewards Std             1.15189
exploration/Rewards Max            -0.00645927
exploration/Rewards Min            -8.29858
exploration/Returns Mean         -106.824
exploration/Returns Std            77.1607
exploration/Returns Max           -28.5783
exploration/Returns Min          -235.971
exploration/Actions Mean           -0.0040159
exploration/Actions Std             0.233958
exploration/Actions Max             0.999347
exploration/Actions Min            -1
exploration/Num Paths               5
exploration/Average Returns      -106.824
evaluation/num steps total     429000
evaluation/num paths total       4290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.864033
evaluation/Rewards Std              1.16401
evaluation/Rewards Max             -0.0059638
evaluation/Rewards Min             -9.54228
evaluation/Returns Mean           -86.4033
evaluation/Returns Std             85.3945
evaluation/Returns Max            -12.4518
evaluation/Returns Min           -254.473
evaluation/Actions Mean            -0.0181919
evaluation/Actions Std              0.179885
evaluation/Actions Max              0.997585
evaluation/Actions Min             -0.998838
evaluation/Num Paths               15
evaluation/Average Returns        -86.4033
time/data storing (s)               0.00262395
time/evaluation sampling (s)        0.337507
time/exploration sampling (s)       0.138651
time/logging (s)                    0.00365298
time/saving (s)                     0.00196978
time/training (s)                   1.92487
time/epoch (s)                      2.40928
time/total (s)                    696.242
Epoch                             285
-----------------------------  ---------------
2019-04-23 00:04:58.476512 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 286 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.533
trainer/QF2 Loss                    1.59773
trainer/Policy Loss                42.586
trainer/Q1 Predictions Mean       -40.8132
trainer/Q1 Predictions Std         31.7998
trainer/Q1 Predictions Max         -7.39286
trainer/Q1 Predictions Min       -112.406
trainer/Q2 Predictions Mean       -40.7929
trainer/Q2 Predictions Std         31.7916
trainer/Q2 Predictions Max         -7.379
trainer/Q2 Predictions Min       -112.492
trainer/Q Targets Mean            -41.1041
trainer/Q Targets Std              32.2918
trainer/Q Targets Max              -0.121414
trainer/Q Targets Min            -113.209
trainer/Log Pis Mean                1.9426
trainer/Log Pis Std                 1.46606
trainer/Log Pis Max                 9.10479
trainer/Log Pis Min                -2.74192
trainer/Policy mu Mean              0.064407
trainer/Policy mu Std               0.657169
trainer/Policy mu Max               3.13841
trainer/Policy mu Min              -2.58813
trainer/Policy log std Mean        -2.0708
trainer/Policy log std Std          0.508458
trainer/Policy log std Max         -0.369098
trainer/Policy log std Min         -3.02233
trainer/Alpha                       0.0744396
trainer/Alpha Loss                 -0.149097
exploration/num steps total    143700
exploration/num paths total      1437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.4368
exploration/Rewards Std             1.27221
exploration/Rewards Max            -0.207823
exploration/Rewards Min           -10.7959
exploration/Returns Mean         -143.68
exploration/Returns Std            37.7478
exploration/Returns Max           -72.4265
exploration/Returns Min          -175.245
exploration/Actions Mean            0.0122645
exploration/Actions Std             0.306522
exploration/Actions Max             0.999872
exploration/Actions Min            -0.998936
exploration/Num Paths               5
exploration/Average Returns      -143.68
evaluation/num steps total     430500
evaluation/num paths total       4305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.62855
evaluation/Rewards Std              1.2729
evaluation/Rewards Max             -0.0186762
evaluation/Rewards Min            -11.1621
evaluation/Returns Mean           -62.855
evaluation/Returns Std             66.0911
evaluation/Returns Max             -5.80563
evaluation/Returns Min           -235.201
evaluation/Actions Mean            -0.0138183
evaluation/Actions Std              0.195058
evaluation/Actions Max              0.998874
evaluation/Actions Min             -0.999649
evaluation/Num Paths               15
evaluation/Average Returns        -62.855
time/data storing (s)               0.00288646
time/evaluation sampling (s)        0.328475
time/exploration sampling (s)       0.138421
time/logging (s)                    0.00476224
time/saving (s)                     0.00199173
time/training (s)                   1.95919
time/epoch (s)                      2.43573
time/total (s)                    698.683
Epoch                             286
-----------------------------  ---------------
2019-04-23 00:05:00.919105 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 287 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.96669
trainer/QF2 Loss                    1.98751
trainer/Policy Loss                40.785
trainer/Q1 Predictions Mean       -38.9686
trainer/Q1 Predictions Std         31.4677
trainer/Q1 Predictions Max         -7.50186
trainer/Q1 Predictions Min       -114.116
trainer/Q2 Predictions Mean       -39.0021
trainer/Q2 Predictions Std         31.4868
trainer/Q2 Predictions Max         -7.57975
trainer/Q2 Predictions Min       -113.57
trainer/Q Targets Mean            -39.1874
trainer/Q Targets Std              32.0842
trainer/Q Targets Max              -0.685939
trainer/Q Targets Min            -115.86
trainer/Log Pis Mean                2.03721
trainer/Log Pis Std                 1.38426
trainer/Log Pis Max                10.3437
trainer/Log Pis Min                -1.95055
trainer/Policy mu Mean              0.0266807
trainer/Policy mu Std               0.677677
trainer/Policy mu Max               4.21052
trainer/Policy mu Min              -3.36484
trainer/Policy log std Mean        -2.10598
trainer/Policy log std Std          0.526302
trainer/Policy log std Max         -0.152383
trainer/Policy log std Min         -3.08024
trainer/Alpha                       0.0761862
trainer/Alpha Loss                  0.0957965
exploration/num steps total    144200
exploration/num paths total      1442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.454235
exploration/Rewards Std             0.772597
exploration/Rewards Max            -0.00737966
exploration/Rewards Min            -6.85876
exploration/Returns Mean          -45.4235
exploration/Returns Std            33.3911
exploration/Returns Max           -19.1389
exploration/Returns Min          -109.673
exploration/Actions Mean            0.00118976
exploration/Actions Std             0.21102
exploration/Actions Max             0.999447
exploration/Actions Min            -0.993746
exploration/Num Paths               5
exploration/Average Returns       -45.4235
evaluation/num steps total     432000
evaluation/num paths total       4320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.585829
evaluation/Rewards Std              0.9846
evaluation/Rewards Max             -0.0220187
evaluation/Rewards Min            -10.8888
evaluation/Returns Mean           -58.5829
evaluation/Returns Std             41.0345
evaluation/Returns Max             -8.12602
evaluation/Returns Min           -169.408
evaluation/Actions Mean             0.00194896
evaluation/Actions Std              0.183868
evaluation/Actions Max              0.998513
evaluation/Actions Min             -0.999334
evaluation/Num Paths               15
evaluation/Average Returns        -58.5829
time/data storing (s)               0.00278141
time/evaluation sampling (s)        0.319978
time/exploration sampling (s)       0.136615
time/logging (s)                    0.00481842
time/saving (s)                     0.00198824
time/training (s)                   1.96752
time/epoch (s)                      2.4337
time/total (s)                    701.121
Epoch                             287
-----------------------------  ---------------
2019-04-23 00:05:03.353598 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 288 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.778136
trainer/QF2 Loss                    0.743965
trainer/Policy Loss                40.0713
trainer/Q1 Predictions Mean       -38.1198
trainer/Q1 Predictions Std         28.1415
trainer/Q1 Predictions Max         -7.29013
trainer/Q1 Predictions Min       -116.919
trainer/Q2 Predictions Mean       -38.1248
trainer/Q2 Predictions Std         28.1725
trainer/Q2 Predictions Max         -7.24875
trainer/Q2 Predictions Min       -116.168
trainer/Q Targets Mean            -38.7287
trainer/Q Targets Std              28.6283
trainer/Q Targets Max              -7.32514
trainer/Q Targets Min            -117.304
trainer/Log Pis Mean                2.09201
trainer/Log Pis Std                 1.43801
trainer/Log Pis Max                 8.58681
trainer/Log Pis Min                -2.38121
trainer/Policy mu Mean              0.113213
trainer/Policy mu Std               0.668011
trainer/Policy mu Max               3.26709
trainer/Policy mu Min              -2.74902
trainer/Policy log std Mean        -2.17613
trainer/Policy log std Std          0.523582
trainer/Policy log std Max         -0.22961
trainer/Policy log std Min         -2.98435
trainer/Alpha                       0.0769405
trainer/Alpha Loss                  0.235984
exploration/num steps total    144700
exploration/num paths total      1447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.32449
exploration/Rewards Std             1.51403
exploration/Rewards Max            -0.00729305
exploration/Rewards Min            -9.98834
exploration/Returns Mean         -132.449
exploration/Returns Std            84.5723
exploration/Returns Max           -19.7846
exploration/Returns Min          -261.858
exploration/Actions Mean            0.0125439
exploration/Actions Std             0.265362
exploration/Actions Max             0.999414
exploration/Actions Min            -0.999363
exploration/Num Paths               5
exploration/Average Returns      -132.449
evaluation/num steps total     433500
evaluation/num paths total       4335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.626669
evaluation/Rewards Std              1.25657
evaluation/Rewards Max             -0.0048205
evaluation/Rewards Min            -11.3535
evaluation/Returns Mean           -62.6669
evaluation/Returns Std             46.2736
evaluation/Returns Max             -1.73276
evaluation/Returns Min           -156.15
evaluation/Actions Mean             0.00641097
evaluation/Actions Std              0.20434
evaluation/Actions Max              0.999086
evaluation/Actions Min             -0.99915
evaluation/Num Paths               15
evaluation/Average Returns        -62.6669
time/data storing (s)               0.00263241
time/evaluation sampling (s)        0.327733
time/exploration sampling (s)       0.140253
time/logging (s)                    0.00478611
time/saving (s)                     0.00197293
time/training (s)                   1.94819
time/epoch (s)                      2.42557
time/total (s)                    703.551
Epoch                             288
-----------------------------  ---------------
2019-04-23 00:05:05.778701 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 289 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.618689
trainer/QF2 Loss                    0.604089
trainer/Policy Loss                40.7173
trainer/Q1 Predictions Mean       -38.8931
trainer/Q1 Predictions Std         33.9774
trainer/Q1 Predictions Max         -7.583
trainer/Q1 Predictions Min       -114.506
trainer/Q2 Predictions Mean       -38.8983
trainer/Q2 Predictions Std         33.994
trainer/Q2 Predictions Max         -7.58826
trainer/Q2 Predictions Min       -114.013
trainer/Q Targets Mean            -39.2771
trainer/Q Targets Std              34.5603
trainer/Q Targets Max              -7.32965
trainer/Q Targets Min            -115.191
trainer/Log Pis Mean                2.02374
trainer/Log Pis Std                 0.989536
trainer/Log Pis Max                 5.68688
trainer/Log Pis Min                -0.955358
trainer/Policy mu Mean              0.0310305
trainer/Policy mu Std               0.523066
trainer/Policy mu Max               2.6989
trainer/Policy mu Min              -2.53039
trainer/Policy log std Mean        -2.22441
trainer/Policy log std Std          0.513986
trainer/Policy log std Max         -0.620731
trainer/Policy log std Min         -3.10431
trainer/Alpha                       0.077911
trainer/Alpha Loss                  0.0605776
exploration/num steps total    145200
exploration/num paths total      1452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.507952
exploration/Rewards Std             0.968708
exploration/Rewards Max            -0.0185222
exploration/Rewards Min            -8.03916
exploration/Returns Mean          -50.7952
exploration/Returns Std            22.6732
exploration/Returns Max           -14.4923
exploration/Returns Min           -73.524
exploration/Actions Mean            0.0323092
exploration/Actions Std             0.207495
exploration/Actions Max             0.999728
exploration/Actions Min            -0.676061
exploration/Num Paths               5
exploration/Average Returns       -50.7952
evaluation/num steps total     435000
evaluation/num paths total       4350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.998542
evaluation/Rewards Std              1.2536
evaluation/Rewards Max             -0.0135276
evaluation/Rewards Min            -11.5697
evaluation/Returns Mean           -99.8542
evaluation/Returns Std             82.3422
evaluation/Returns Max            -12.0513
evaluation/Returns Min           -248.124
evaluation/Actions Mean             0.00297997
evaluation/Actions Std              0.192355
evaluation/Actions Max              0.999297
evaluation/Actions Min             -0.999026
evaluation/Num Paths               15
evaluation/Average Returns        -99.8542
time/data storing (s)               0.00266784
time/evaluation sampling (s)        0.32265
time/exploration sampling (s)       0.140221
time/logging (s)                    0.00479034
time/saving (s)                     0.00197062
time/training (s)                   1.94398
time/epoch (s)                      2.41628
time/total (s)                    705.972
Epoch                             289
-----------------------------  ---------------
2019-04-23 00:05:08.211425 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 290 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.172501
trainer/QF2 Loss                    0.201997
trainer/Policy Loss                41.5495
trainer/Q1 Predictions Mean       -39.7942
trainer/Q1 Predictions Std         37.6382
trainer/Q1 Predictions Max         -7.41294
trainer/Q1 Predictions Min       -113.293
trainer/Q2 Predictions Mean       -39.7251
trainer/Q2 Predictions Std         37.6403
trainer/Q2 Predictions Max         -7.22068
trainer/Q2 Predictions Min       -113.401
trainer/Q Targets Mean            -40.0135
trainer/Q Targets Std              37.8502
trainer/Q Targets Max              -7.37876
trainer/Q Targets Min            -113.788
trainer/Log Pis Mean                1.94578
trainer/Log Pis Std                 1.00813
trainer/Log Pis Max                 3.9104
trainer/Log Pis Min                -1.26789
trainer/Policy mu Mean             -0.0353604
trainer/Policy mu Std               0.537008
trainer/Policy mu Max               3.11982
trainer/Policy mu Min              -2.57903
trainer/Policy log std Mean        -2.2096
trainer/Policy log std Std          0.507065
trainer/Policy log std Max         -0.670224
trainer/Policy log std Min         -3.00675
trainer/Alpha                       0.0784798
trainer/Alpha Loss                 -0.137987
exploration/num steps total    145700
exploration/num paths total      1457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.771306
exploration/Rewards Std             1.07339
exploration/Rewards Max            -0.00874027
exploration/Rewards Min            -9.83158
exploration/Returns Mean          -77.1306
exploration/Returns Std            69.4222
exploration/Returns Max           -20.4733
exploration/Returns Min          -195.583
exploration/Actions Mean            0.0204046
exploration/Actions Std             0.23958
exploration/Actions Max             0.999929
exploration/Actions Min            -0.996348
exploration/Num Paths               5
exploration/Average Returns       -77.1306
evaluation/num steps total     436500
evaluation/num paths total       4365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.6608
evaluation/Rewards Std              1.03448
evaluation/Rewards Max             -0.0113158
evaluation/Rewards Min             -9.93214
evaluation/Returns Mean           -66.08
evaluation/Returns Std             66.317
evaluation/Returns Max             -9.08408
evaluation/Returns Min           -244.288
evaluation/Actions Mean             0.0179392
evaluation/Actions Std              0.178224
evaluation/Actions Max              0.999259
evaluation/Actions Min             -0.996904
evaluation/Num Paths               15
evaluation/Average Returns        -66.08
time/data storing (s)               0.0026654
time/evaluation sampling (s)        0.33024
time/exploration sampling (s)       0.134626
time/logging (s)                    0.00476488
time/saving (s)                     0.00195618
time/training (s)                   1.95052
time/epoch (s)                      2.42477
time/total (s)                    708.401
Epoch                             290
-----------------------------  ---------------
2019-04-23 00:05:10.634986 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 291 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.26754
trainer/QF2 Loss                    2.36497
trainer/Policy Loss                36.0167
trainer/Q1 Predictions Mean       -34.3148
trainer/Q1 Predictions Std         31.7054
trainer/Q1 Predictions Max         -7.38932
trainer/Q1 Predictions Min       -115.893
trainer/Q2 Predictions Mean       -34.2602
trainer/Q2 Predictions Std         31.6827
trainer/Q2 Predictions Max         -7.32206
trainer/Q2 Predictions Min       -115.584
trainer/Q Targets Mean            -34.3754
trainer/Q Targets Std              32.0298
trainer/Q Targets Max              -0.881219
trainer/Q Targets Min            -116.314
trainer/Log Pis Mean                1.85145
trainer/Log Pis Std                 1.62238
trainer/Log Pis Max                 6.53699
trainer/Log Pis Min                -8.12712
trainer/Policy mu Mean              0.0205328
trainer/Policy mu Std               0.625669
trainer/Policy mu Max               3.95728
trainer/Policy mu Min              -2.78157
trainer/Policy log std Mean        -2.165
trainer/Policy log std Std          0.545359
trainer/Policy log std Max         -0.144798
trainer/Policy log std Min         -3.08782
trainer/Alpha                       0.0782104
trainer/Alpha Loss                 -0.378544
exploration/num steps total    146200
exploration/num paths total      1462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.928946
exploration/Rewards Std             1.46136
exploration/Rewards Max            -0.0135951
exploration/Rewards Min           -11.0603
exploration/Returns Mean          -92.8946
exploration/Returns Std            81.4649
exploration/Returns Max           -35.8342
exploration/Returns Min          -254.607
exploration/Actions Mean            0.0123871
exploration/Actions Std             0.235843
exploration/Actions Max             0.998001
exploration/Actions Min            -0.999957
exploration/Num Paths               5
exploration/Average Returns       -92.8946
evaluation/num steps total     438000
evaluation/num paths total       4380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.850157
evaluation/Rewards Std              1.22126
evaluation/Rewards Max             -0.0569953
evaluation/Rewards Min            -10.1558
evaluation/Returns Mean           -85.0157
evaluation/Returns Std             75.7534
evaluation/Returns Max            -11.1429
evaluation/Returns Min           -267.634
evaluation/Actions Mean             0.00280389
evaluation/Actions Std              0.184459
evaluation/Actions Max              0.99802
evaluation/Actions Min             -0.999317
evaluation/Num Paths               15
evaluation/Average Returns        -85.0157
time/data storing (s)               0.00259234
time/evaluation sampling (s)        0.32951
time/exploration sampling (s)       0.136601
time/logging (s)                    0.00483526
time/saving (s)                     0.00197422
time/training (s)                   1.93944
time/epoch (s)                      2.41495
time/total (s)                    710.82
Epoch                             291
-----------------------------  ---------------
2019-04-23 00:05:13.081386 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 292 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    5.30638
trainer/QF2 Loss                    5.25623
trainer/Policy Loss                37.2213
trainer/Q1 Predictions Mean       -35.4326
trainer/Q1 Predictions Std         34.206
trainer/Q1 Predictions Max         -7.45773
trainer/Q1 Predictions Min       -112.996
trainer/Q2 Predictions Mean       -35.4432
trainer/Q2 Predictions Std         34.2435
trainer/Q2 Predictions Max         -7.45583
trainer/Q2 Predictions Min       -113.115
trainer/Q Targets Mean            -35.3528
trainer/Q Targets Std              34.9867
trainer/Q Targets Max              -0.392585
trainer/Q Targets Min            -114.796
trainer/Log Pis Mean                1.9344
trainer/Log Pis Std                 1.33073
trainer/Log Pis Max                 8.12376
trainer/Log Pis Min                -2.54307
trainer/Policy mu Mean             -0.0183908
trainer/Policy mu Std               0.620367
trainer/Policy mu Max               2.96163
trainer/Policy mu Min              -2.27793
trainer/Policy log std Mean        -2.14305
trainer/Policy log std Std          0.530586
trainer/Policy log std Max         -0.692394
trainer/Policy log std Min         -3.07186
trainer/Alpha                       0.0786356
trainer/Alpha Loss                 -0.1668
exploration/num steps total    146700
exploration/num paths total      1467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.582616
exploration/Rewards Std             0.889697
exploration/Rewards Max            -0.00782699
exploration/Rewards Min            -8.12987
exploration/Returns Mean          -58.2616
exploration/Returns Std            49.1907
exploration/Returns Max           -21.202
exploration/Returns Min          -154.077
exploration/Actions Mean           -0.00798404
exploration/Actions Std             0.220798
exploration/Actions Max             0.995816
exploration/Actions Min            -0.999162
exploration/Num Paths               5
exploration/Average Returns       -58.2616
evaluation/num steps total     439500
evaluation/num paths total       4395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.899438
evaluation/Rewards Std              1.07424
evaluation/Rewards Max             -0.021695
evaluation/Rewards Min             -9.78953
evaluation/Returns Mean           -89.9438
evaluation/Returns Std             62.3241
evaluation/Returns Max            -12.9391
evaluation/Returns Min           -235.412
evaluation/Actions Mean             0.0108675
evaluation/Actions Std              0.180391
evaluation/Actions Max              0.996604
evaluation/Actions Min             -0.998579
evaluation/Num Paths               15
evaluation/Average Returns        -89.9438
time/data storing (s)               0.00282867
time/evaluation sampling (s)        0.326393
time/exploration sampling (s)       0.141508
time/logging (s)                    0.00476739
time/saving (s)                     0.00988704
time/training (s)                   1.95203
time/epoch (s)                      2.43741
time/total (s)                    713.262
Epoch                             292
-----------------------------  ---------------
2019-04-23 00:05:15.501403 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 293 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.164749
trainer/QF2 Loss                    0.189699
trainer/Policy Loss                39.9658
trainer/Q1 Predictions Mean       -37.8919
trainer/Q1 Predictions Std         34.6956
trainer/Q1 Predictions Max         -7.34379
trainer/Q1 Predictions Min       -114.605
trainer/Q2 Predictions Mean       -37.888
trainer/Q2 Predictions Std         34.7223
trainer/Q2 Predictions Max         -7.37939
trainer/Q2 Predictions Min       -114.921
trainer/Q Targets Mean            -38.0935
trainer/Q Targets Std              34.8861
trainer/Q Targets Max              -7.40457
trainer/Q Targets Min            -115.188
trainer/Log Pis Mean                2.2024
trainer/Log Pis Std                 1.26886
trainer/Log Pis Max                 7.10452
trainer/Log Pis Min                -2.5146
trainer/Policy mu Mean              0.0470028
trainer/Policy mu Std               0.635598
trainer/Policy mu Max               3.06205
trainer/Policy mu Min              -3.31008
trainer/Policy log std Mean        -2.21727
trainer/Policy log std Std          0.51918
trainer/Policy log std Max         -0.268021
trainer/Policy log std Min         -2.98743
trainer/Alpha                       0.0780562
trainer/Alpha Loss                  0.516194
exploration/num steps total    147200
exploration/num paths total      1472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.309249
exploration/Rewards Std             0.909278
exploration/Rewards Max            -0.0139268
exploration/Rewards Min            -9.14481
exploration/Returns Mean          -30.9249
exploration/Returns Std            17.3245
exploration/Returns Max           -13.4843
exploration/Returns Min           -59.8247
exploration/Actions Mean           -0.00817401
exploration/Actions Std             0.190054
exploration/Actions Max             0.998894
exploration/Actions Min            -0.998429
exploration/Num Paths               5
exploration/Average Returns       -30.9249
evaluation/num steps total     441000
evaluation/num paths total       4410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.805255
evaluation/Rewards Std              1.19716
evaluation/Rewards Max             -0.0675757
evaluation/Rewards Min            -10.6532
evaluation/Returns Mean           -80.5255
evaluation/Returns Std             58.4283
evaluation/Returns Max            -13.7753
evaluation/Returns Min           -236.335
evaluation/Actions Mean            -0.00784074
evaluation/Actions Std              0.200011
evaluation/Actions Max              0.998062
evaluation/Actions Min             -0.999563
evaluation/Num Paths               15
evaluation/Average Returns        -80.5255
time/data storing (s)               0.00291713
time/evaluation sampling (s)        0.32672
time/exploration sampling (s)       0.136912
time/logging (s)                    0.00476643
time/saving (s)                     0.00195327
time/training (s)                   1.93764
time/epoch (s)                      2.41091
time/total (s)                    715.677
Epoch                             293
-----------------------------  ---------------
2019-04-23 00:05:17.909399 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 294 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.61363
trainer/QF2 Loss                    2.62167
trainer/Policy Loss                38.7104
trainer/Q1 Predictions Mean       -37.1197
trainer/Q1 Predictions Std         33.7743
trainer/Q1 Predictions Max         -7.73014
trainer/Q1 Predictions Min       -114.729
trainer/Q2 Predictions Mean       -37.0698
trainer/Q2 Predictions Std         33.7952
trainer/Q2 Predictions Max         -7.6397
trainer/Q2 Predictions Min       -114.482
trainer/Q Targets Mean            -37.1467
trainer/Q Targets Std              33.9415
trainer/Q Targets Max              -0.547303
trainer/Q Targets Min            -114.551
trainer/Log Pis Mean                1.92476
trainer/Log Pis Std                 1.08629
trainer/Log Pis Max                 5.32006
trainer/Log Pis Min                -1.49384
trainer/Policy mu Mean             -0.0928595
trainer/Policy mu Std               0.586015
trainer/Policy mu Max               2.62941
trainer/Policy mu Min              -2.74484
trainer/Policy log std Mean        -2.11987
trainer/Policy log std Std          0.504875
trainer/Policy log std Max         -0.585227
trainer/Policy log std Min         -2.96683
trainer/Alpha                       0.0739962
trainer/Alpha Loss                 -0.195905
exploration/num steps total    147700
exploration/num paths total      1477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.873574
exploration/Rewards Std             1.08862
exploration/Rewards Max            -0.0149849
exploration/Rewards Min           -10.1955
exploration/Returns Mean          -87.3574
exploration/Returns Std            61.0088
exploration/Returns Max           -38.2284
exploration/Returns Min          -195.729
exploration/Actions Mean            0.0227786
exploration/Actions Std             0.244953
exploration/Actions Max             0.999547
exploration/Actions Min            -0.998105
exploration/Num Paths               5
exploration/Average Returns       -87.3574
evaluation/num steps total     442500
evaluation/num paths total       4425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.921483
evaluation/Rewards Std              1.21253
evaluation/Rewards Max             -0.0256638
evaluation/Rewards Min             -9.85435
evaluation/Returns Mean           -92.1483
evaluation/Returns Std             83.0719
evaluation/Returns Max             -9.9721
evaluation/Returns Min           -246.29
evaluation/Actions Mean             0.00259902
evaluation/Actions Std              0.181939
evaluation/Actions Max              0.999078
evaluation/Actions Min             -0.999787
evaluation/Num Paths               15
evaluation/Average Returns        -92.1483
time/data storing (s)               0.00271963
time/evaluation sampling (s)        0.326884
time/exploration sampling (s)       0.140821
time/logging (s)                    0.00490499
time/saving (s)                     0.00249095
time/training (s)                   1.92138
time/epoch (s)                      2.3992
time/total (s)                    718.081
Epoch                             294
-----------------------------  ---------------
2019-04-23 00:05:20.316335 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 295 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   37.4858
trainer/QF2 Loss                   37.3045
trainer/Policy Loss                39.5441
trainer/Q1 Predictions Mean       -37.6376
trainer/Q1 Predictions Std         32.9884
trainer/Q1 Predictions Max         -7.27425
trainer/Q1 Predictions Min       -112.316
trainer/Q2 Predictions Mean       -37.6254
trainer/Q2 Predictions Std         32.9852
trainer/Q2 Predictions Max         -7.23252
trainer/Q2 Predictions Min       -112.247
trainer/Q Targets Mean            -37.7842
trainer/Q Targets Std              33.6628
trainer/Q Targets Max              -1.72342
trainer/Q Targets Min            -114.033
trainer/Log Pis Mean                2.09227
trainer/Log Pis Std                 1.19884
trainer/Log Pis Max                 6.40526
trainer/Log Pis Min                -1.47068
trainer/Policy mu Mean             -0.00590797
trainer/Policy mu Std               0.550224
trainer/Policy mu Max               2.40661
trainer/Policy mu Min              -2.87898
trainer/Policy log std Mean        -2.29162
trainer/Policy log std Std          0.465899
trainer/Policy log std Max         -0.56501
trainer/Policy log std Min         -3.12629
trainer/Alpha                       0.0728547
trainer/Alpha Loss                  0.241701
exploration/num steps total    148200
exploration/num paths total      1482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.333734
exploration/Rewards Std             0.991296
exploration/Rewards Max            -0.00210185
exploration/Rewards Min            -8.10265
exploration/Returns Mean          -33.3734
exploration/Returns Std            10.3101
exploration/Returns Max           -16.2028
exploration/Returns Min           -45.5177
exploration/Actions Mean            0.00943904
exploration/Actions Std             0.230113
exploration/Actions Max             0.998598
exploration/Actions Min            -0.997805
exploration/Num Paths               5
exploration/Average Returns       -33.3734
evaluation/num steps total     444000
evaluation/num paths total       4440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.518609
evaluation/Rewards Std              0.875817
evaluation/Rewards Max             -0.00133748
evaluation/Rewards Min            -10.1655
evaluation/Returns Mean           -51.8609
evaluation/Returns Std             42.0355
evaluation/Returns Max             -4.31453
evaluation/Returns Min           -144.113
evaluation/Actions Mean             0.0135364
evaluation/Actions Std              0.165083
evaluation/Actions Max              0.998337
evaluation/Actions Min             -0.998197
evaluation/Num Paths               15
evaluation/Average Returns        -51.8609
time/data storing (s)               0.00280175
time/evaluation sampling (s)        0.325455
time/exploration sampling (s)       0.140072
time/logging (s)                    0.00480297
time/saving (s)                     0.0017078
time/training (s)                   1.92373
time/epoch (s)                      2.39857
time/total (s)                    720.484
Epoch                             295
-----------------------------  ---------------
2019-04-23 00:05:22.738407 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 296 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.62455
trainer/QF2 Loss                    3.6271
trainer/Policy Loss                37.1716
trainer/Q1 Predictions Mean       -35.3356
trainer/Q1 Predictions Std         30.9796
trainer/Q1 Predictions Max         -7.39927
trainer/Q1 Predictions Min       -110.57
trainer/Q2 Predictions Mean       -35.3421
trainer/Q2 Predictions Std         30.9884
trainer/Q2 Predictions Max         -7.31264
trainer/Q2 Predictions Min       -110.734
trainer/Q Targets Mean            -35.7376
trainer/Q Targets Std              31.8348
trainer/Q Targets Max              -0.492101
trainer/Q Targets Min            -114.242
trainer/Log Pis Mean                2.00307
trainer/Log Pis Std                 1.36581
trainer/Log Pis Max                 6.34207
trainer/Log Pis Min                -2.82059
trainer/Policy mu Mean             -0.0202642
trainer/Policy mu Std               0.578853
trainer/Policy mu Max               2.51702
trainer/Policy mu Min              -2.71557
trainer/Policy log std Mean        -2.16694
trainer/Policy log std Std          0.490522
trainer/Policy log std Max         -0.598208
trainer/Policy log std Min         -2.92642
trainer/Alpha                       0.0722872
trainer/Alpha Loss                  0.00806092
exploration/num steps total    148700
exploration/num paths total      1487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.996538
exploration/Rewards Std             0.998919
exploration/Rewards Max            -0.0159416
exploration/Rewards Min            -7.51096
exploration/Returns Mean          -99.6538
exploration/Returns Std            82.1889
exploration/Returns Max           -28.5073
exploration/Returns Min          -253.976
exploration/Actions Mean           -0.0104568
exploration/Actions Std             0.201004
exploration/Actions Max             0.983117
exploration/Actions Min            -0.997555
exploration/Num Paths               5
exploration/Average Returns       -99.6538
evaluation/num steps total     445500
evaluation/num paths total       4455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.633632
evaluation/Rewards Std              0.949949
evaluation/Rewards Max             -0.0291978
evaluation/Rewards Min             -8.73155
evaluation/Returns Mean           -63.3632
evaluation/Returns Std             62.0939
evaluation/Returns Max            -13.9156
evaluation/Returns Min           -234.366
evaluation/Actions Mean             0.00579071
evaluation/Actions Std              0.175098
evaluation/Actions Max              0.998682
evaluation/Actions Min             -0.99819
evaluation/Num Paths               15
evaluation/Average Returns        -63.3632
time/data storing (s)               0.00271515
time/evaluation sampling (s)        0.325744
time/exploration sampling (s)       0.135837
time/logging (s)                    0.00415794
time/saving (s)                     0.00199562
time/training (s)                   1.94207
time/epoch (s)                      2.41252
time/total (s)                    722.901
Epoch                             296
-----------------------------  ---------------
2019-04-23 00:05:25.151747 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 297 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.281203
trainer/QF2 Loss                    0.326675
trainer/Policy Loss                37.0282
trainer/Q1 Predictions Mean       -35.3128
trainer/Q1 Predictions Std         35.7611
trainer/Q1 Predictions Max         -7.65248
trainer/Q1 Predictions Min       -113.533
trainer/Q2 Predictions Mean       -35.3339
trainer/Q2 Predictions Std         35.7412
trainer/Q2 Predictions Max         -7.67136
trainer/Q2 Predictions Min       -113.565
trainer/Q Targets Mean            -35.3939
trainer/Q Targets Std              35.9649
trainer/Q Targets Max              -7.32767
trainer/Q Targets Min            -114.234
trainer/Log Pis Mean                1.83327
trainer/Log Pis Std                 1.12317
trainer/Log Pis Max                 3.47762
trainer/Log Pis Min                -4.14616
trainer/Policy mu Mean              0.0400732
trainer/Policy mu Std               0.30186
trainer/Policy mu Max               2.39527
trainer/Policy mu Min              -1.08074
trainer/Policy log std Mean        -2.28286
trainer/Policy log std Std          0.361054
trainer/Policy log std Max         -0.796502
trainer/Policy log std Min         -2.95754
trainer/Alpha                       0.0753634
trainer/Alpha Loss                 -0.431074
exploration/num steps total    149200
exploration/num paths total      1492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.484751
exploration/Rewards Std             1.06093
exploration/Rewards Max            -0.014542
exploration/Rewards Min            -7.80324
exploration/Returns Mean          -48.4751
exploration/Returns Std            10.165
exploration/Returns Max           -33.7905
exploration/Returns Min           -65.3608
exploration/Actions Mean            0.0209904
exploration/Actions Std             0.244579
exploration/Actions Max             0.999292
exploration/Actions Min            -0.996876
exploration/Num Paths               5
exploration/Average Returns       -48.4751
evaluation/num steps total     447000
evaluation/num paths total       4470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.642063
evaluation/Rewards Std              1.01545
evaluation/Rewards Max             -0.0587061
evaluation/Rewards Min             -9.18804
evaluation/Returns Mean           -64.2063
evaluation/Returns Std             48.2262
evaluation/Returns Max            -15.1236
evaluation/Returns Min           -161.136
evaluation/Actions Mean             0.00577925
evaluation/Actions Std              0.190505
evaluation/Actions Max              0.997968
evaluation/Actions Min             -0.998581
evaluation/Num Paths               15
evaluation/Average Returns        -64.2063
time/data storing (s)               0.00268088
time/evaluation sampling (s)        0.331552
time/exploration sampling (s)       0.141968
time/logging (s)                    0.00479472
time/saving (s)                     0.00199417
time/training (s)                   1.92262
time/epoch (s)                      2.40561
time/total (s)                    725.31
Epoch                             297
-----------------------------  ---------------
2019-04-23 00:05:27.579028 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 298 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.249524
trainer/QF2 Loss                    0.238972
trainer/Policy Loss                34.4362
trainer/Q1 Predictions Mean       -32.6431
trainer/Q1 Predictions Std         29.9815
trainer/Q1 Predictions Max         -7.81285
trainer/Q1 Predictions Min       -112.005
trainer/Q2 Predictions Mean       -32.6308
trainer/Q2 Predictions Std         29.987
trainer/Q2 Predictions Max         -7.69448
trainer/Q2 Predictions Min       -112.002
trainer/Q Targets Mean            -32.8632
trainer/Q Targets Std              30.2758
trainer/Q Targets Max              -7.48668
trainer/Q Targets Min            -112.909
trainer/Log Pis Mean                2.01615
trainer/Log Pis Std                 1.13035
trainer/Log Pis Max                 5.97001
trainer/Log Pis Min                -1.9791
trainer/Policy mu Mean              0.0375774
trainer/Policy mu Std               0.476263
trainer/Policy mu Max               3.24489
trainer/Policy mu Min              -2.51299
trainer/Policy log std Mean        -2.22784
trainer/Policy log std Std          0.445848
trainer/Policy log std Max         -0.320178
trainer/Policy log std Min         -2.89595
trainer/Alpha                       0.0769543
trainer/Alpha Loss                  0.0414113
exploration/num steps total    149700
exploration/num paths total      1497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.58088
exploration/Rewards Std             1.09585
exploration/Rewards Max            -0.021443
exploration/Rewards Min            -8.81297
exploration/Returns Mean         -158.088
exploration/Returns Std            74.9802
exploration/Returns Max           -51.6859
exploration/Returns Min          -250.779
exploration/Actions Mean           -0.0146414
exploration/Actions Std             0.227253
exploration/Actions Max             0.985092
exploration/Actions Min            -0.999675
exploration/Num Paths               5
exploration/Average Returns      -158.088
evaluation/num steps total     448500
evaluation/num paths total       4485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.644418
evaluation/Rewards Std              1.19221
evaluation/Rewards Max             -0.0198812
evaluation/Rewards Min             -9.55301
evaluation/Returns Mean           -64.4418
evaluation/Returns Std             65.3982
evaluation/Returns Max             -9.32665
evaluation/Returns Min           -244.71
evaluation/Actions Mean            -0.000303367
evaluation/Actions Std              0.195902
evaluation/Actions Max              0.999597
evaluation/Actions Min             -0.999167
evaluation/Num Paths               15
evaluation/Average Returns        -64.4418
time/data storing (s)               0.0028103
time/evaluation sampling (s)        0.330505
time/exploration sampling (s)       0.137619
time/logging (s)                    0.00475008
time/saving (s)                     0.00160616
time/training (s)                   1.94117
time/epoch (s)                      2.41846
time/total (s)                    727.733
Epoch                             298
-----------------------------  ----------------
2019-04-23 00:05:30.001037 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 299 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.124866
trainer/QF2 Loss                    0.154158
trainer/Policy Loss                45.2804
trainer/Q1 Predictions Mean       -43.331
trainer/Q1 Predictions Std         37.6035
trainer/Q1 Predictions Max         -7.39534
trainer/Q1 Predictions Min       -114.452
trainer/Q2 Predictions Mean       -43.368
trainer/Q2 Predictions Std         37.6099
trainer/Q2 Predictions Max         -7.32154
trainer/Q2 Predictions Min       -114.71
trainer/Q Targets Mean            -43.5142
trainer/Q Targets Std              37.6853
trainer/Q Targets Max              -7.36982
trainer/Q Targets Min            -114.681
trainer/Log Pis Mean                2.06704
trainer/Log Pis Std                 1.1467
trainer/Log Pis Max                 5.72152
trainer/Log Pis Min                -2.72725
trainer/Policy mu Mean             -0.0171343
trainer/Policy mu Std               0.539209
trainer/Policy mu Max               2.75283
trainer/Policy mu Min              -2.88013
trainer/Policy log std Mean        -2.21634
trainer/Policy log std Std          0.515073
trainer/Policy log std Max         -0.64536
trainer/Policy log std Min         -2.96236
trainer/Alpha                       0.0769816
trainer/Alpha Loss                  0.171906
exploration/num steps total    150200
exploration/num paths total      1502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.455907
exploration/Rewards Std             0.88956
exploration/Rewards Max            -0.0054092
exploration/Rewards Min            -8.36323
exploration/Returns Mean          -45.5907
exploration/Returns Std            37.6293
exploration/Returns Max           -12.5455
exploration/Returns Min          -115.486
exploration/Actions Mean            0.0084127
exploration/Actions Std             0.195563
exploration/Actions Max             0.999262
exploration/Actions Min            -0.995188
exploration/Num Paths               5
exploration/Average Returns       -45.5907
evaluation/num steps total     450000
evaluation/num paths total       4500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0048
evaluation/Rewards Std              1.18331
evaluation/Rewards Max             -0.0414653
evaluation/Rewards Min             -9.06776
evaluation/Returns Mean          -100.48
evaluation/Returns Std             82.6137
evaluation/Returns Max             -8.58617
evaluation/Returns Min           -243.812
evaluation/Actions Mean            -0.00467803
evaluation/Actions Std              0.186963
evaluation/Actions Max              0.996047
evaluation/Actions Min             -0.999173
evaluation/Num Paths               15
evaluation/Average Returns       -100.48
time/data storing (s)               0.00277829
time/evaluation sampling (s)        0.323208
time/exploration sampling (s)       0.143437
time/logging (s)                    0.00489649
time/saving (s)                     0.00197126
time/training (s)                   1.93705
time/epoch (s)                      2.41334
time/total (s)                    730.151
Epoch                             299
-----------------------------  ---------------
2019-04-23 00:05:32.466980 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 300 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   87.0075
trainer/QF2 Loss                   87.7295
trainer/Policy Loss                40.8506
trainer/Q1 Predictions Mean       -38.9202
trainer/Q1 Predictions Std         35.3799
trainer/Q1 Predictions Max         -7.22749
trainer/Q1 Predictions Min       -114.13
trainer/Q2 Predictions Mean       -38.8835
trainer/Q2 Predictions Std         35.3584
trainer/Q2 Predictions Max         -7.12357
trainer/Q2 Predictions Min       -113.995
trainer/Q Targets Mean            -37.7765
trainer/Q Targets Std              35.8342
trainer/Q Targets Max              -0.442996
trainer/Q Targets Min            -114.279
trainer/Log Pis Mean                2.06248
trainer/Log Pis Std                 1.22145
trainer/Log Pis Max                 5.59172
trainer/Log Pis Min                -4.05371
trainer/Policy mu Mean              0.0291514
trainer/Policy mu Std               0.447737
trainer/Policy mu Max               2.22132
trainer/Policy mu Min              -2.83175
trainer/Policy log std Mean        -2.28542
trainer/Policy log std Std          0.44265
trainer/Policy log std Max         -0.746035
trainer/Policy log std Min         -2.97014
trainer/Alpha                       0.0773509
trainer/Alpha Loss                  0.159908
exploration/num steps total    150700
exploration/num paths total      1507
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.921401
exploration/Rewards Std             1.25284
exploration/Rewards Max            -0.0135961
exploration/Rewards Min           -10.6601
exploration/Returns Mean          -92.1401
exploration/Returns Std            81.4663
exploration/Returns Max           -16.2766
exploration/Returns Min          -229.212
exploration/Actions Mean            0.0266045
exploration/Actions Std             0.231802
exploration/Actions Max             0.999182
exploration/Actions Min            -0.993405
exploration/Num Paths               5
exploration/Average Returns       -92.1401
evaluation/num steps total     451500
evaluation/num paths total       4515
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.595635
evaluation/Rewards Std              1.17598
evaluation/Rewards Max             -0.0354987
evaluation/Rewards Min            -12.3347
evaluation/Returns Mean           -59.5635
evaluation/Returns Std             66.4023
evaluation/Returns Max             -8.11613
evaluation/Returns Min           -240.568
evaluation/Actions Mean            -0.0144586
evaluation/Actions Std              0.191148
evaluation/Actions Max              0.997526
evaluation/Actions Min             -0.998844
evaluation/Num Paths               15
evaluation/Average Returns        -59.5635
time/data storing (s)               0.0026262
time/evaluation sampling (s)        0.33597
time/exploration sampling (s)       0.139658
time/logging (s)                    0.00350922
time/saving (s)                     0.00200935
time/training (s)                   1.97193
time/epoch (s)                      2.4557
time/total (s)                    732.611
Epoch                             300
-----------------------------  ---------------
2019-04-23 00:05:34.936512 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 301 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    9.66962
trainer/QF2 Loss                    9.52219
trainer/Policy Loss                36.0107
trainer/Q1 Predictions Mean       -34.2975
trainer/Q1 Predictions Std         31.8254
trainer/Q1 Predictions Max         -7.55517
trainer/Q1 Predictions Min       -113.606
trainer/Q2 Predictions Mean       -34.2708
trainer/Q2 Predictions Std         31.85
trainer/Q2 Predictions Max         -7.45845
trainer/Q2 Predictions Min       -113.396
trainer/Q Targets Mean            -34.2565
trainer/Q Targets Std              32.2229
trainer/Q Targets Max              -1.72119
trainer/Q Targets Min            -113.961
trainer/Log Pis Mean                1.8946
trainer/Log Pis Std                 1.36285
trainer/Log Pis Max                 6.72642
trainer/Log Pis Min                -3.1201
trainer/Policy mu Mean              0.00995241
trainer/Policy mu Std               0.52082
trainer/Policy mu Max               2.96102
trainer/Policy mu Min              -2.87943
trainer/Policy log std Mean        -2.24478
trainer/Policy log std Std          0.428523
trainer/Policy log std Max         -0.584667
trainer/Policy log std Min         -3.14203
trainer/Alpha                       0.0773088
trainer/Alpha Loss                 -0.269841
exploration/num steps total    151200
exploration/num paths total      1512
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.537965
exploration/Rewards Std             1.37436
exploration/Rewards Max            -0.0107451
exploration/Rewards Min           -10.0467
exploration/Returns Mean          -53.7965
exploration/Returns Std            22.7076
exploration/Returns Max           -24.0166
exploration/Returns Min           -78.1022
exploration/Actions Mean           -0.008061
exploration/Actions Std             0.233613
exploration/Actions Max             0.996883
exploration/Actions Min            -0.998787
exploration/Num Paths               5
exploration/Average Returns       -53.7965
evaluation/num steps total     453000
evaluation/num paths total       4530
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.832553
evaluation/Rewards Std              1.33923
evaluation/Rewards Max             -0.0205439
evaluation/Rewards Min            -10.6444
evaluation/Returns Mean           -83.2553
evaluation/Returns Std             81.2361
evaluation/Returns Max            -10.3796
evaluation/Returns Min           -268.007
evaluation/Actions Mean             0.00197931
evaluation/Actions Std              0.204745
evaluation/Actions Max              0.998512
evaluation/Actions Min             -0.999154
evaluation/Num Paths               15
evaluation/Average Returns        -83.2553
time/data storing (s)               0.00261203
time/evaluation sampling (s)        0.328304
time/exploration sampling (s)       0.138835
time/logging (s)                    0.0035816
time/saving (s)                     0.00187564
time/training (s)                   1.98606
time/epoch (s)                      2.46127
time/total (s)                    735.076
Epoch                             301
-----------------------------  ---------------
2019-04-23 00:05:37.372302 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 302 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   51.1611
trainer/QF2 Loss                   51.6527
trainer/Policy Loss                38.1991
trainer/Q1 Predictions Mean       -36.583
trainer/Q1 Predictions Std         33.538
trainer/Q1 Predictions Max         -7.22053
trainer/Q1 Predictions Min       -114.74
trainer/Q2 Predictions Mean       -36.6202
trainer/Q2 Predictions Std         33.5452
trainer/Q2 Predictions Max         -7.21709
trainer/Q2 Predictions Min       -114.111
trainer/Q Targets Mean            -36.3502
trainer/Q Targets Std              33.9902
trainer/Q Targets Max              -1.375
trainer/Q Targets Min            -115.442
trainer/Log Pis Mean                1.77072
trainer/Log Pis Std                 1.17499
trainer/Log Pis Max                 3.54685
trainer/Log Pis Min                -3.10207
trainer/Policy mu Mean              0.0557869
trainer/Policy mu Std               0.448638
trainer/Policy mu Max               2.99469
trainer/Policy mu Min              -1.37097
trainer/Policy log std Mean        -2.18243
trainer/Policy log std Std          0.468697
trainer/Policy log std Max         -0.609204
trainer/Policy log std Min         -2.92438
trainer/Alpha                       0.0793798
trainer/Alpha Loss                 -0.58086
exploration/num steps total    151700
exploration/num paths total      1517
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.752367
exploration/Rewards Std             1.12042
exploration/Rewards Max            -0.00551767
exploration/Rewards Min            -6.89248
exploration/Returns Mean          -75.2367
exploration/Returns Std            82.617
exploration/Returns Max           -19.8129
exploration/Returns Min          -239.066
exploration/Actions Mean           -0.012608
exploration/Actions Std             0.209323
exploration/Actions Max             0.993518
exploration/Actions Min            -0.998182
exploration/Num Paths               5
exploration/Average Returns       -75.2367
evaluation/num steps total     454500
evaluation/num paths total       4545
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.60831
evaluation/Rewards Std              1.0757
evaluation/Rewards Max             -0.0621744
evaluation/Rewards Min            -10.5104
evaluation/Returns Mean           -60.831
evaluation/Returns Std             60.2653
evaluation/Returns Max            -12.9325
evaluation/Returns Min           -240.129
evaluation/Actions Mean             0.002302
evaluation/Actions Std              0.170251
evaluation/Actions Max              0.996956
evaluation/Actions Min             -0.998636
evaluation/Num Paths               15
evaluation/Average Returns        -60.831
time/data storing (s)               0.00284829
time/evaluation sampling (s)        0.325926
time/exploration sampling (s)       0.137754
time/logging (s)                    0.00480025
time/saving (s)                     0.001989
time/training (s)                   1.95557
time/epoch (s)                      2.42888
time/total (s)                    737.51
Epoch                             302
-----------------------------  ---------------
2019-04-23 00:05:39.822962 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 303 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.56604
trainer/QF2 Loss                    4.59926
trainer/Policy Loss                35.2241
trainer/Q1 Predictions Mean       -33.3801
trainer/Q1 Predictions Std         32.4437
trainer/Q1 Predictions Max         -7.43148
trainer/Q1 Predictions Min       -113.897
trainer/Q2 Predictions Mean       -33.3332
trainer/Q2 Predictions Std         32.4151
trainer/Q2 Predictions Max         -7.3511
trainer/Q2 Predictions Min       -113.807
trainer/Q Targets Mean            -33.2824
trainer/Q Targets Std              32.5832
trainer/Q Targets Max              -0.414509
trainer/Q Targets Min            -114.238
trainer/Log Pis Mean                1.9695
trainer/Log Pis Std                 1.62123
trainer/Log Pis Max                12.0858
trainer/Log Pis Min                -3.9763
trainer/Policy mu Mean              0.0427514
trainer/Policy mu Std               0.608046
trainer/Policy mu Max               4.10866
trainer/Policy mu Min              -2.84616
trainer/Policy log std Mean        -2.21189
trainer/Policy log std Std          0.520713
trainer/Policy log std Max         -0.440946
trainer/Policy log std Min         -2.956
trainer/Alpha                       0.0793044
trainer/Alpha Loss                 -0.0772978
exploration/num steps total    152200
exploration/num paths total      1522
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31355
exploration/Rewards Std             0.820325
exploration/Rewards Max            -0.0079761
exploration/Rewards Min            -8.44392
exploration/Returns Mean          -31.355
exploration/Returns Std            15.3366
exploration/Returns Max           -16.2318
exploration/Returns Min           -55.0244
exploration/Actions Mean            0.005511
exploration/Actions Std             0.220013
exploration/Actions Max             0.998396
exploration/Actions Min            -0.997653
exploration/Num Paths               5
exploration/Average Returns       -31.355
evaluation/num steps total     456000
evaluation/num paths total       4560
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.835939
evaluation/Rewards Std              1.29696
evaluation/Rewards Max             -0.0255858
evaluation/Rewards Min             -9.94322
evaluation/Returns Mean           -83.5939
evaluation/Returns Std             88.3065
evaluation/Returns Max             -2.99712
evaluation/Returns Min           -266.674
evaluation/Actions Mean            -0.0107656
evaluation/Actions Std              0.189157
evaluation/Actions Max              0.997067
evaluation/Actions Min             -0.99944
evaluation/Num Paths               15
evaluation/Average Returns        -83.5939
time/data storing (s)               0.00272405
time/evaluation sampling (s)        0.329124
time/exploration sampling (s)       0.137351
time/logging (s)                    0.00484221
time/saving (s)                     0.00160396
time/training (s)                   1.96669
time/epoch (s)                      2.44234
time/total (s)                    739.956
Epoch                             303
-----------------------------  ---------------
2019-04-23 00:05:42.287978 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 304 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.50441
trainer/QF2 Loss                    1.55225
trainer/Policy Loss                32.6334
trainer/Q1 Predictions Mean       -30.7773
trainer/Q1 Predictions Std         27.4866
trainer/Q1 Predictions Max         -7.44536
trainer/Q1 Predictions Min       -113.164
trainer/Q2 Predictions Mean       -30.7527
trainer/Q2 Predictions Std         27.4805
trainer/Q2 Predictions Max         -7.40296
trainer/Q2 Predictions Min       -113.088
trainer/Q Targets Mean            -30.9917
trainer/Q Targets Std              27.9017
trainer/Q Targets Max              -0.167053
trainer/Q Targets Min            -114.396
trainer/Log Pis Mean                1.98003
trainer/Log Pis Std                 1.46835
trainer/Log Pis Max                 7.19778
trainer/Log Pis Min                -3.80367
trainer/Policy mu Mean              0.0595483
trainer/Policy mu Std               0.475232
trainer/Policy mu Max               2.29199
trainer/Policy mu Min              -2.72386
trainer/Policy log std Mean        -2.25108
trainer/Policy log std Std          0.484851
trainer/Policy log std Max         -0.465148
trainer/Policy log std Min         -3.03779
trainer/Alpha                       0.0767667
trainer/Alpha Loss                 -0.0512549
exploration/num steps total    152700
exploration/num paths total      1527
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.812225
exploration/Rewards Std             1.14648
exploration/Rewards Max            -0.0158783
exploration/Rewards Min           -10.4258
exploration/Returns Mean          -81.2225
exploration/Returns Std            56.4265
exploration/Returns Max           -13.6482
exploration/Returns Min          -164.121
exploration/Actions Mean            0.026376
exploration/Actions Std             0.230075
exploration/Actions Max             0.999722
exploration/Actions Min            -0.994872
exploration/Num Paths               5
exploration/Average Returns       -81.2225
evaluation/num steps total     457500
evaluation/num paths total       4575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.811517
evaluation/Rewards Std              1.07645
evaluation/Rewards Max             -0.0160857
evaluation/Rewards Min             -8.89201
evaluation/Returns Mean           -81.1517
evaluation/Returns Std             78.8618
evaluation/Returns Max             -2.55195
evaluation/Returns Min           -242.49
evaluation/Actions Mean            -0.00221857
evaluation/Actions Std              0.158627
evaluation/Actions Max              0.99788
evaluation/Actions Min             -0.999212
evaluation/Num Paths               15
evaluation/Average Returns        -81.1517
time/data storing (s)               0.00285896
time/evaluation sampling (s)        0.332482
time/exploration sampling (s)       0.137684
time/logging (s)                    0.00434733
time/saving (s)                     0.0103351
time/training (s)                   1.96797
time/epoch (s)                      2.45568
time/total (s)                    742.415
Epoch                             304
-----------------------------  ---------------
2019-04-23 00:05:44.735156 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 305 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.51166
trainer/QF2 Loss                    4.55652
trainer/Policy Loss                42.8787
trainer/Q1 Predictions Mean       -40.9164
trainer/Q1 Predictions Std         37.838
trainer/Q1 Predictions Max         -7.53529
trainer/Q1 Predictions Min       -121.008
trainer/Q2 Predictions Mean       -40.9261
trainer/Q2 Predictions Std         37.8355
trainer/Q2 Predictions Max         -7.50815
trainer/Q2 Predictions Min       -120.248
trainer/Q Targets Mean            -40.8054
trainer/Q Targets Std              38.1216
trainer/Q Targets Max              -0.536402
trainer/Q Targets Min            -120.64
trainer/Log Pis Mean                2.08104
trainer/Log Pis Std                 1.44706
trainer/Log Pis Max                 7.67052
trainer/Log Pis Min                -2.80185
trainer/Policy mu Mean             -0.0254447
trainer/Policy mu Std               0.576126
trainer/Policy mu Max               2.8099
trainer/Policy mu Min              -3.39493
trainer/Policy log std Mean        -2.18428
trainer/Policy log std Std          0.534306
trainer/Policy log std Max         -0.33578
trainer/Policy log std Min         -3.00188
trainer/Alpha                       0.079157
trainer/Alpha Loss                  0.205547
exploration/num steps total    153200
exploration/num paths total      1532
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.692727
exploration/Rewards Std             1.11992
exploration/Rewards Max            -0.0182245
exploration/Rewards Min            -8.68119
exploration/Returns Mean          -69.2727
exploration/Returns Std            59.2358
exploration/Returns Max           -12.683
exploration/Returns Min          -182.029
exploration/Actions Mean            0.00293248
exploration/Actions Std             0.233544
exploration/Actions Max             0.998599
exploration/Actions Min            -0.997163
exploration/Num Paths               5
exploration/Average Returns       -69.2727
evaluation/num steps total     459000
evaluation/num paths total       4590
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.698834
evaluation/Rewards Std              1.18705
evaluation/Rewards Max             -0.0344945
evaluation/Rewards Min            -10.8175
evaluation/Returns Mean           -69.8834
evaluation/Returns Std             71.0369
evaluation/Returns Max            -11.3737
evaluation/Returns Min           -244.267
evaluation/Actions Mean            -0.00561283
evaluation/Actions Std              0.193033
evaluation/Actions Max              0.999024
evaluation/Actions Min             -0.999576
evaluation/Num Paths               15
evaluation/Average Returns        -69.8834
time/data storing (s)               0.00265546
time/evaluation sampling (s)        0.321996
time/exploration sampling (s)       0.138012
time/logging (s)                    0.00479887
time/saving (s)                     0.00198505
time/training (s)                   1.97102
time/epoch (s)                      2.44046
time/total (s)                    744.86
Epoch                             305
-----------------------------  ---------------
2019-04-23 00:05:47.188984 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 306 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.06659
trainer/QF2 Loss                    2.04341
trainer/Policy Loss                37.2278
trainer/Q1 Predictions Mean       -35.3536
trainer/Q1 Predictions Std         32.9849
trainer/Q1 Predictions Max         -7.29047
trainer/Q1 Predictions Min       -111.909
trainer/Q2 Predictions Mean       -35.3529
trainer/Q2 Predictions Std         32.995
trainer/Q2 Predictions Max         -7.22333
trainer/Q2 Predictions Min       -111.762
trainer/Q Targets Mean            -35.7832
trainer/Q Targets Std              33.7949
trainer/Q Targets Max              -0.261891
trainer/Q Targets Min            -114.405
trainer/Log Pis Mean                2.03008
trainer/Log Pis Std                 1.3864
trainer/Log Pis Max                 7.97064
trainer/Log Pis Min                -2.3097
trainer/Policy mu Mean              0.0974613
trainer/Policy mu Std               0.591867
trainer/Policy mu Max               3.07933
trainer/Policy mu Min              -3.03785
trainer/Policy log std Mean        -2.24861
trainer/Policy log std Std          0.479203
trainer/Policy log std Max         -0.502563
trainer/Policy log std Min         -2.87745
trainer/Alpha                       0.0763633
trainer/Alpha Loss                  0.0773601
exploration/num steps total    153700
exploration/num paths total      1537
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.888299
exploration/Rewards Std             1.08425
exploration/Rewards Max            -0.00705672
exploration/Rewards Min            -8.01714
exploration/Returns Mean          -88.8299
exploration/Returns Std            91.9044
exploration/Returns Max           -17.1421
exploration/Returns Min          -257.773
exploration/Actions Mean           -0.00274806
exploration/Actions Std             0.209663
exploration/Actions Max             0.99903
exploration/Actions Min            -0.998217
exploration/Num Paths               5
exploration/Average Returns       -88.8299
evaluation/num steps total     460500
evaluation/num paths total       4605
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.96808
evaluation/Rewards Std              1.24056
evaluation/Rewards Max             -0.0519174
evaluation/Rewards Min             -9.9592
evaluation/Returns Mean           -96.808
evaluation/Returns Std             82.4843
evaluation/Returns Max            -18.3538
evaluation/Returns Min           -259.703
evaluation/Actions Mean             0.0183826
evaluation/Actions Std              0.19224
evaluation/Actions Max              0.998651
evaluation/Actions Min             -0.996429
evaluation/Num Paths               15
evaluation/Average Returns        -96.808
time/data storing (s)               0.00276215
time/evaluation sampling (s)        0.323143
time/exploration sampling (s)       0.138216
time/logging (s)                    0.0047816
time/saving (s)                     0.00199033
time/training (s)                   1.97377
time/epoch (s)                      2.44466
time/total (s)                    747.309
Epoch                             306
-----------------------------  ---------------
2019-04-23 00:05:49.602721 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 307 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  121.726
trainer/QF2 Loss                  121.593
trainer/Policy Loss                41.3966
trainer/Q1 Predictions Mean       -39.325
trainer/Q1 Predictions Std         36.0682
trainer/Q1 Predictions Max         -7.28767
trainer/Q1 Predictions Min       -113.523
trainer/Q2 Predictions Mean       -39.3377
trainer/Q2 Predictions Std         36.0408
trainer/Q2 Predictions Max         -7.26192
trainer/Q2 Predictions Min       -113.494
trainer/Q Targets Mean            -38.5637
trainer/Q Targets Std              36.112
trainer/Q Targets Max              -0.388885
trainer/Q Targets Min            -114.938
trainer/Log Pis Mean                2.18431
trainer/Log Pis Std                 1.34926
trainer/Log Pis Max                 8.154
trainer/Log Pis Min                -1.12451
trainer/Policy mu Mean              0.0395076
trainer/Policy mu Std               0.684388
trainer/Policy mu Max               3.54271
trainer/Policy mu Min              -2.94764
trainer/Policy log std Mean        -2.20763
trainer/Policy log std Std          0.528105
trainer/Policy log std Max         -0.427463
trainer/Policy log std Min         -2.926
trainer/Alpha                       0.0743162
trainer/Alpha Loss                  0.479107
exploration/num steps total    154200
exploration/num paths total      1542
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.810692
exploration/Rewards Std             0.906748
exploration/Rewards Max            -0.00772901
exploration/Rewards Min            -4.82911
exploration/Returns Mean          -81.0692
exploration/Returns Std            86.0607
exploration/Returns Max           -14.076
exploration/Returns Min          -232.242
exploration/Actions Mean            0.00913458
exploration/Actions Std             0.172607
exploration/Actions Max             0.988626
exploration/Actions Min            -0.997412
exploration/Num Paths               5
exploration/Average Returns       -81.0692
evaluation/num steps total     462000
evaluation/num paths total       4620
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.643996
evaluation/Rewards Std              1.20078
evaluation/Rewards Max             -0.00397496
evaluation/Rewards Min            -10.9311
evaluation/Returns Mean           -64.3996
evaluation/Returns Std             63.3461
evaluation/Returns Max            -14.4204
evaluation/Returns Min           -247.746
evaluation/Actions Mean             7.70594e-05
evaluation/Actions Std              0.201619
evaluation/Actions Max              0.998257
evaluation/Actions Min             -0.998715
evaluation/Num Paths               15
evaluation/Average Returns        -64.3996
time/data storing (s)               0.00261461
time/evaluation sampling (s)        0.321853
time/exploration sampling (s)       0.138318
time/logging (s)                    0.00476372
time/saving (s)                     0.00159881
time/training (s)                   1.93538
time/epoch (s)                      2.40452
time/total (s)                    749.718
Epoch                             307
-----------------------------  ----------------
2019-04-23 00:05:52.040762 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 308 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  122.173
trainer/QF2 Loss                  121.642
trainer/Policy Loss                45.5566
trainer/Q1 Predictions Mean       -43.7888
trainer/Q1 Predictions Std         38.7188
trainer/Q1 Predictions Max         -7.64878
trainer/Q1 Predictions Min       -124.963
trainer/Q2 Predictions Mean       -43.7687
trainer/Q2 Predictions Std         38.6347
trainer/Q2 Predictions Max         -7.63351
trainer/Q2 Predictions Min       -124.182
trainer/Q Targets Mean            -42.9221
trainer/Q Targets Std              38.4887
trainer/Q Targets Max              -2.51589
trainer/Q Targets Min            -124.548
trainer/Log Pis Mean                1.92144
trainer/Log Pis Std                 1.27961
trainer/Log Pis Max                 4.71724
trainer/Log Pis Min                -2.05724
trainer/Policy mu Mean             -0.048464
trainer/Policy mu Std               0.603795
trainer/Policy mu Max               2.60089
trainer/Policy mu Min              -2.90005
trainer/Policy log std Mean        -2.24584
trainer/Policy log std Std          0.49156
trainer/Policy log std Max         -0.56695
trainer/Policy log std Min         -3.08424
trainer/Alpha                       0.0716646
trainer/Alpha Loss                 -0.207059
exploration/num steps total    154700
exploration/num paths total      1547
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.774259
exploration/Rewards Std             0.881235
exploration/Rewards Max            -0.00973329
exploration/Rewards Min            -7.92927
exploration/Returns Mean          -77.4259
exploration/Returns Std            47.0497
exploration/Returns Max           -21.8814
exploration/Returns Min          -148.105
exploration/Actions Mean            0.0177443
exploration/Actions Std             0.221912
exploration/Actions Max             0.996387
exploration/Actions Min            -0.950452
exploration/Num Paths               5
exploration/Average Returns       -77.4259
evaluation/num steps total     463500
evaluation/num paths total       4635
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.59842
evaluation/Rewards Std              1.08753
evaluation/Rewards Max             -0.0281137
evaluation/Rewards Min            -10.5604
evaluation/Returns Mean           -59.842
evaluation/Returns Std             62.0127
evaluation/Returns Max             -9.63105
evaluation/Returns Min           -235.026
evaluation/Actions Mean             0.00572799
evaluation/Actions Std              0.1876
evaluation/Actions Max              0.999324
evaluation/Actions Min             -0.998805
evaluation/Num Paths               15
evaluation/Average Returns        -59.842
time/data storing (s)               0.00276601
time/evaluation sampling (s)        0.321758
time/exploration sampling (s)       0.144216
time/logging (s)                    0.00437152
time/saving (s)                     0.00197215
time/training (s)                   1.95341
time/epoch (s)                      2.4285
time/total (s)                    752.151
Epoch                             308
-----------------------------  ---------------
2019-04-23 00:05:54.475444 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 309 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.538858
trainer/QF2 Loss                    0.523711
trainer/Policy Loss                40.5537
trainer/Q1 Predictions Mean       -38.8829
trainer/Q1 Predictions Std         32.8703
trainer/Q1 Predictions Max         -7.402
trainer/Q1 Predictions Min       -124.928
trainer/Q2 Predictions Mean       -38.8655
trainer/Q2 Predictions Std         32.8597
trainer/Q2 Predictions Max         -7.38816
trainer/Q2 Predictions Min       -124.912
trainer/Q Targets Mean            -39.3547
trainer/Q Targets Std              33.1182
trainer/Q Targets Max              -7.47297
trainer/Q Targets Min            -126.042
trainer/Log Pis Mean                1.84651
trainer/Log Pis Std                 1.3038
trainer/Log Pis Max                 8.45135
trainer/Log Pis Min                -1.43251
trainer/Policy mu Mean             -0.0718246
trainer/Policy mu Std               0.457134
trainer/Policy mu Max               2.66099
trainer/Policy mu Min              -2.83767
trainer/Policy log std Mean        -2.19209
trainer/Policy log std Std          0.438668
trainer/Policy log std Max         -0.542654
trainer/Policy log std Min         -3.02084
trainer/Alpha                       0.0730737
trainer/Alpha Loss                 -0.40157
exploration/num steps total    155200
exploration/num paths total      1552
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.917429
exploration/Rewards Std             1.09657
exploration/Rewards Max            -0.0124436
exploration/Rewards Min            -9.87094
exploration/Returns Mean          -91.7429
exploration/Returns Std            60.8858
exploration/Returns Max           -23.1242
exploration/Returns Min          -174.655
exploration/Actions Mean           -0.0270064
exploration/Actions Std             0.246106
exploration/Actions Max             0.99724
exploration/Actions Min            -0.99666
exploration/Num Paths               5
exploration/Average Returns       -91.7429
evaluation/num steps total     465000
evaluation/num paths total       4650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.14112
evaluation/Rewards Std              1.12378
evaluation/Rewards Max             -0.0375105
evaluation/Rewards Min             -9.12078
evaluation/Returns Mean          -114.112
evaluation/Returns Std             75.4934
evaluation/Returns Max            -13.2289
evaluation/Returns Min           -232.742
evaluation/Actions Mean             0.0148732
evaluation/Actions Std              0.176082
evaluation/Actions Max              0.999016
evaluation/Actions Min             -0.999175
evaluation/Num Paths               15
evaluation/Average Returns       -114.112
time/data storing (s)               0.00272857
time/evaluation sampling (s)        0.32504
time/exploration sampling (s)       0.136814
time/logging (s)                    0.00468174
time/saving (s)                     0.00197744
time/training (s)                   1.95539
time/epoch (s)                      2.42663
time/total (s)                    754.582
Epoch                             309
-----------------------------  ---------------
2019-04-23 00:05:56.891003 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 310 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.39044
trainer/QF2 Loss                    6.37091
trainer/Policy Loss                35.0935
trainer/Q1 Predictions Mean       -33.0679
trainer/Q1 Predictions Std         29.9175
trainer/Q1 Predictions Max         -7.58011
trainer/Q1 Predictions Min       -112.872
trainer/Q2 Predictions Mean       -33.0617
trainer/Q2 Predictions Std         29.9232
trainer/Q2 Predictions Max         -7.45289
trainer/Q2 Predictions Min       -113.997
trainer/Q Targets Mean            -33.202
trainer/Q Targets Std              30.6758
trainer/Q Targets Max              -0.261975
trainer/Q Targets Min            -114.8
trainer/Log Pis Mean                2.12825
trainer/Log Pis Std                 1.37323
trainer/Log Pis Max                 6.79801
trainer/Log Pis Min                -1.98267
trainer/Policy mu Mean              0.0278844
trainer/Policy mu Std               0.59644
trainer/Policy mu Max               3.81316
trainer/Policy mu Min              -3.15216
trainer/Policy log std Mean        -2.23676
trainer/Policy log std Std          0.478133
trainer/Policy log std Max         -0.169637
trainer/Policy log std Min         -3.0288
trainer/Alpha                       0.0755085
trainer/Alpha Loss                  0.331338
exploration/num steps total    155700
exploration/num paths total      1557
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.784969
exploration/Rewards Std             0.933166
exploration/Rewards Max            -0.0109037
exploration/Rewards Min            -7.70296
exploration/Returns Mean          -78.4969
exploration/Returns Std            55.8676
exploration/Returns Max           -17.7962
exploration/Returns Min          -171.442
exploration/Actions Mean           -0.00348246
exploration/Actions Std             0.207398
exploration/Actions Max             0.999329
exploration/Actions Min            -0.998916
exploration/Num Paths               5
exploration/Average Returns       -78.4969
evaluation/num steps total     466500
evaluation/num paths total       4665
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.846966
evaluation/Rewards Std              1.28328
evaluation/Rewards Max             -0.0354047
evaluation/Rewards Min            -11.2462
evaluation/Returns Mean           -84.6966
evaluation/Returns Std             80.9644
evaluation/Returns Max             -8.35156
evaluation/Returns Min           -240.393
evaluation/Actions Mean             0.0131569
evaluation/Actions Std              0.185224
evaluation/Actions Max              0.999291
evaluation/Actions Min             -0.999206
evaluation/Num Paths               15
evaluation/Average Returns        -84.6966
time/data storing (s)               0.00265599
time/evaluation sampling (s)        0.331358
time/exploration sampling (s)       0.137027
time/logging (s)                    0.00476825
time/saving (s)                     0.00158823
time/training (s)                   1.92917
time/epoch (s)                      2.40657
time/total (s)                    756.993
Epoch                             310
-----------------------------  ---------------
2019-04-23 00:05:59.317347 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 311 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.63705
trainer/QF2 Loss                    2.51539
trainer/Policy Loss                40.1487
trainer/Q1 Predictions Mean       -38.2469
trainer/Q1 Predictions Std         35.6976
trainer/Q1 Predictions Max         -7.30769
trainer/Q1 Predictions Min       -113.89
trainer/Q2 Predictions Mean       -38.2584
trainer/Q2 Predictions Std         35.7595
trainer/Q2 Predictions Max         -7.22584
trainer/Q2 Predictions Min       -114.962
trainer/Q Targets Mean            -38.9986
trainer/Q Targets Std              36.5806
trainer/Q Targets Max              -0.418685
trainer/Q Targets Min            -116.356
trainer/Log Pis Mean                2.02324
trainer/Log Pis Std                 1.10296
trainer/Log Pis Max                 4.30011
trainer/Log Pis Min                -1.01783
trainer/Policy mu Mean             -0.00856385
trainer/Policy mu Std               0.442059
trainer/Policy mu Max               2.71079
trainer/Policy mu Min              -2.60928
trainer/Policy log std Mean        -2.22243
trainer/Policy log std Std          0.44557
trainer/Policy log std Max         -0.822928
trainer/Policy log std Min         -2.9829
trainer/Alpha                       0.0792339
trainer/Alpha Loss                  0.058917
exploration/num steps total    156200
exploration/num paths total      1562
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.586029
exploration/Rewards Std             1.05626
exploration/Rewards Max            -0.00421055
exploration/Rewards Min            -8.37244
exploration/Returns Mean          -58.6029
exploration/Returns Std            31.9611
exploration/Returns Max           -36.3225
exploration/Returns Min          -121.332
exploration/Actions Mean           -0.0148202
exploration/Actions Std             0.231106
exploration/Actions Max             0.996612
exploration/Actions Min            -0.999099
exploration/Num Paths               5
exploration/Average Returns       -58.6029
evaluation/num steps total     468000
evaluation/num paths total       4680
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.579776
evaluation/Rewards Std              0.994796
evaluation/Rewards Max             -0.0282076
evaluation/Rewards Min             -9.81554
evaluation/Returns Mean           -57.9776
evaluation/Returns Std             55.6608
evaluation/Returns Max             -4.58472
evaluation/Returns Min           -163.156
evaluation/Actions Mean             0.00490473
evaluation/Actions Std              0.18142
evaluation/Actions Max              0.995809
evaluation/Actions Min             -0.99956
evaluation/Num Paths               15
evaluation/Average Returns        -57.9776
time/data storing (s)               0.00266011
time/evaluation sampling (s)        0.330008
time/exploration sampling (s)       0.136929
time/logging (s)                    0.00478325
time/saving (s)                     0.00195731
time/training (s)                   1.94164
time/epoch (s)                      2.41798
time/total (s)                    759.415
Epoch                             311
-----------------------------  ---------------
2019-04-23 00:06:01.757099 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 312 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.29869
trainer/QF2 Loss                    1.33257
trainer/Policy Loss                31.463
trainer/Q1 Predictions Mean       -29.8086
trainer/Q1 Predictions Std         30.8738
trainer/Q1 Predictions Max         -7.51279
trainer/Q1 Predictions Min       -114.14
trainer/Q2 Predictions Mean       -29.7869
trainer/Q2 Predictions Std         30.8337
trainer/Q2 Predictions Max         -7.48055
trainer/Q2 Predictions Min       -113.749
trainer/Q Targets Mean            -29.9043
trainer/Q Targets Std              31.2105
trainer/Q Targets Max              -0.268246
trainer/Q Targets Min            -114.452
trainer/Log Pis Mean                1.78587
trainer/Log Pis Std                 1.23802
trainer/Log Pis Max                 5.9659
trainer/Log Pis Min                -1.34622
trainer/Policy mu Mean             -0.0785669
trainer/Policy mu Std               0.434265
trainer/Policy mu Max               1.50511
trainer/Policy mu Min              -3.36866
trainer/Policy log std Mean        -2.1766
trainer/Policy log std Std          0.456665
trainer/Policy log std Max         -0.0984715
trainer/Policy log std Min         -3.145
trainer/Alpha                       0.0820942
trainer/Alpha Loss                 -0.535273
exploration/num steps total    156700
exploration/num paths total      1567
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.79854
exploration/Rewards Std             1.10679
exploration/Rewards Max            -0.0296734
exploration/Rewards Min            -8.22239
exploration/Returns Mean         -179.854
exploration/Returns Std            80.7447
exploration/Returns Max           -52.1334
exploration/Returns Min          -252.621
exploration/Actions Mean           -0.0158783
exploration/Actions Std             0.196279
exploration/Actions Max             0.99886
exploration/Actions Min            -0.996447
exploration/Num Paths               5
exploration/Average Returns      -179.854
evaluation/num steps total     469500
evaluation/num paths total       4695
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.21778
evaluation/Rewards Std              1.24189
evaluation/Rewards Max             -0.0294795
evaluation/Rewards Min            -10.0458
evaluation/Returns Mean          -121.778
evaluation/Returns Std             93.3093
evaluation/Returns Max             -6.43763
evaluation/Returns Min           -259.793
evaluation/Actions Mean            -0.00718357
evaluation/Actions Std              0.183773
evaluation/Actions Max              0.997814
evaluation/Actions Min             -0.99976
evaluation/Num Paths               15
evaluation/Average Returns       -121.778
time/data storing (s)               0.00261232
time/evaluation sampling (s)        0.330495
time/exploration sampling (s)       0.141524
time/logging (s)                    0.00476975
time/saving (s)                     0.00196159
time/training (s)                   1.94919
time/epoch (s)                      2.43055
time/total (s)                    761.851
Epoch                             312
-----------------------------  ---------------
2019-04-23 00:06:04.206678 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 313 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.69882
trainer/QF2 Loss                    1.64135
trainer/Policy Loss                36.9827
trainer/Q1 Predictions Mean       -35.1234
trainer/Q1 Predictions Std         35.29
trainer/Q1 Predictions Max         -7.69968
trainer/Q1 Predictions Min       -134.146
trainer/Q2 Predictions Mean       -35.142
trainer/Q2 Predictions Std         35.2957
trainer/Q2 Predictions Max         -7.61199
trainer/Q2 Predictions Min       -134.753
trainer/Q Targets Mean            -35.2597
trainer/Q Targets Std              35.8632
trainer/Q Targets Max              -0.129939
trainer/Q Targets Min            -132.898
trainer/Log Pis Mean                1.93037
trainer/Log Pis Std                 1.27252
trainer/Log Pis Max                 6.20178
trainer/Log Pis Min                -1.17803
trainer/Policy mu Mean              0.0190535
trainer/Policy mu Std               0.558695
trainer/Policy mu Max               2.9522
trainer/Policy mu Min              -2.63458
trainer/Policy log std Mean        -2.19098
trainer/Policy log std Std          0.497845
trainer/Policy log std Max         -0.325827
trainer/Policy log std Min         -2.98604
trainer/Alpha                       0.0827851
trainer/Alpha Loss                 -0.173481
exploration/num steps total    157200
exploration/num paths total      1572
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.20531
exploration/Rewards Std             1.27722
exploration/Rewards Max            -0.015936
exploration/Rewards Min            -8.6376
exploration/Returns Mean         -120.531
exploration/Returns Std            97.9818
exploration/Returns Max           -30.1109
exploration/Returns Min          -245.393
exploration/Actions Mean            0.0087272
exploration/Actions Std             0.212789
exploration/Actions Max             0.99984
exploration/Actions Min            -0.997258
exploration/Num Paths               5
exploration/Average Returns      -120.531
evaluation/num steps total     471000
evaluation/num paths total       4710
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.529957
evaluation/Rewards Std              1.15854
evaluation/Rewards Max             -0.0753824
evaluation/Rewards Min            -10.3797
evaluation/Returns Mean           -52.9957
evaluation/Returns Std             40.2612
evaluation/Returns Max            -17.2304
evaluation/Returns Min           -153.958
evaluation/Actions Mean            -0.00428369
evaluation/Actions Std              0.204333
evaluation/Actions Max              0.998348
evaluation/Actions Min             -0.999522
evaluation/Num Paths               15
evaluation/Average Returns        -52.9957
time/data storing (s)               0.00261175
time/evaluation sampling (s)        0.329725
time/exploration sampling (s)       0.138566
time/logging (s)                    0.0048423
time/saving (s)                     0.00198657
time/training (s)                   1.96289
time/epoch (s)                      2.44062
time/total (s)                    764.295
Epoch                             313
-----------------------------  ---------------
2019-04-23 00:06:06.638348 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 314 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.66584
trainer/QF2 Loss                    1.74829
trainer/Policy Loss                40.024
trainer/Q1 Predictions Mean       -38.2531
trainer/Q1 Predictions Std         34.0571
trainer/Q1 Predictions Max         -7.50315
trainer/Q1 Predictions Min       -114.277
trainer/Q2 Predictions Mean       -38.2036
trainer/Q2 Predictions Std         34.0705
trainer/Q2 Predictions Max         -7.50063
trainer/Q2 Predictions Min       -114.18
trainer/Q Targets Mean            -38.569
trainer/Q Targets Std              34.4883
trainer/Q Targets Max              -0.214117
trainer/Q Targets Min            -115.464
trainer/Log Pis Mean                1.9036
trainer/Log Pis Std                 1.21957
trainer/Log Pis Max                 5.40969
trainer/Log Pis Min                -1.87149
trainer/Policy mu Mean              0.0268661
trainer/Policy mu Std               0.448033
trainer/Policy mu Max               2.75176
trainer/Policy mu Min              -3.32406
trainer/Policy log std Mean        -2.25876
trainer/Policy log std Std          0.43015
trainer/Policy log std Max         -0.072366
trainer/Policy log std Min         -2.94124
trainer/Alpha                       0.0830227
trainer/Alpha Loss                 -0.239893
exploration/num steps total    157700
exploration/num paths total      1577
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.83423
exploration/Rewards Std             1.0495
exploration/Rewards Max            -0.00325347
exploration/Rewards Min            -7.32369
exploration/Returns Mean          -83.423
exploration/Returns Std            91.6059
exploration/Returns Max           -13.3781
exploration/Returns Min          -242.605
exploration/Actions Mean            0.00385316
exploration/Actions Std             0.179559
exploration/Actions Max             0.998697
exploration/Actions Min            -0.990248
exploration/Num Paths               5
exploration/Average Returns       -83.423
evaluation/num steps total     472500
evaluation/num paths total       4725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.74961
evaluation/Rewards Std              1.20883
evaluation/Rewards Max             -0.00303268
evaluation/Rewards Min            -10.998
evaluation/Returns Mean           -74.961
evaluation/Returns Std             77.9389
evaluation/Returns Max             -7.99135
evaluation/Returns Min           -242.256
evaluation/Actions Mean            -0.00745436
evaluation/Actions Std              0.183362
evaluation/Actions Max              0.999028
evaluation/Actions Min             -0.999473
evaluation/Num Paths               15
evaluation/Average Returns        -74.961
time/data storing (s)               0.00275113
time/evaluation sampling (s)        0.328698
time/exploration sampling (s)       0.137314
time/logging (s)                    0.00483459
time/saving (s)                     0.0019833
time/training (s)                   1.94743
time/epoch (s)                      2.42301
time/total (s)                    766.723
Epoch                             314
-----------------------------  ---------------
2019-04-23 00:06:09.071855 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 315 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.254497
trainer/QF2 Loss                    0.193695
trainer/Policy Loss                39.2757
trainer/Q1 Predictions Mean       -37.4118
trainer/Q1 Predictions Std         36.5752
trainer/Q1 Predictions Max         -7.80294
trainer/Q1 Predictions Min       -113.545
trainer/Q2 Predictions Mean       -37.4422
trainer/Q2 Predictions Std         36.5487
trainer/Q2 Predictions Max         -7.89082
trainer/Q2 Predictions Min       -113.589
trainer/Q Targets Mean            -37.5069
trainer/Q Targets Std              36.8511
trainer/Q Targets Max              -7.6708
trainer/Q Targets Min            -114.817
trainer/Log Pis Mean                2.08307
trainer/Log Pis Std                 1.16749
trainer/Log Pis Max                 4.75696
trainer/Log Pis Min                -2.67681
trainer/Policy mu Mean             -0.110176
trainer/Policy mu Std               0.502033
trainer/Policy mu Max               1.56851
trainer/Policy mu Min              -3.96663
trainer/Policy log std Mean        -2.24343
trainer/Policy log std Std          0.444828
trainer/Policy log std Max          0.0384197
trainer/Policy log std Min         -3.0286
trainer/Alpha                       0.0803903
trainer/Alpha Loss                  0.209398
exploration/num steps total    158200
exploration/num paths total      1582
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.717176
exploration/Rewards Std             1.38176
exploration/Rewards Max            -0.0026515
exploration/Rewards Min           -10.1769
exploration/Returns Mean          -71.7176
exploration/Returns Std            57.4643
exploration/Returns Max           -21.7125
exploration/Returns Min          -182.305
exploration/Actions Mean            0.0196147
exploration/Actions Std             0.249624
exploration/Actions Max             0.999641
exploration/Actions Min            -0.997322
exploration/Num Paths               5
exploration/Average Returns       -71.7176
evaluation/num steps total     474000
evaluation/num paths total       4740
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.629695
evaluation/Rewards Std              1.09237
evaluation/Rewards Max             -0.00648555
evaluation/Rewards Min             -9.11565
evaluation/Returns Mean           -62.9695
evaluation/Returns Std             74.3416
evaluation/Returns Max             -6.15792
evaluation/Returns Min           -245.133
evaluation/Actions Mean            -0.0207506
evaluation/Actions Std              0.179195
evaluation/Actions Max              0.996288
evaluation/Actions Min             -0.998361
evaluation/Num Paths               15
evaluation/Average Returns        -62.9695
time/data storing (s)               0.00268736
time/evaluation sampling (s)        0.32217
time/exploration sampling (s)       0.14075
time/logging (s)                    0.00432509
time/saving (s)                     0.00199914
time/training (s)                   1.95163
time/epoch (s)                      2.42356
time/total (s)                    769.151
Epoch                             315
-----------------------------  ---------------
2019-04-23 00:06:11.492128 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 316 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    7.85457
trainer/QF2 Loss                    7.85764
trainer/Policy Loss                35.2884
trainer/Q1 Predictions Mean       -33.6366
trainer/Q1 Predictions Std         32.3207
trainer/Q1 Predictions Max         -7.75387
trainer/Q1 Predictions Min       -137.087
trainer/Q2 Predictions Mean       -33.6022
trainer/Q2 Predictions Std         32.2905
trainer/Q2 Predictions Max         -7.74004
trainer/Q2 Predictions Min       -137.635
trainer/Q Targets Mean            -33.8327
trainer/Q Targets Std              33.1929
trainer/Q Targets Max              -0.315025
trainer/Q Targets Min            -139.909
trainer/Log Pis Mean                1.76948
trainer/Log Pis Std                 1.35964
trainer/Log Pis Max                 5.27806
trainer/Log Pis Min                -2.51246
trainer/Policy mu Mean             -0.0147178
trainer/Policy mu Std               0.635735
trainer/Policy mu Max               3.4732
trainer/Policy mu Min              -3.00089
trainer/Policy log std Mean        -2.19443
trainer/Policy log std Std          0.475806
trainer/Policy log std Max         -0.450505
trainer/Policy log std Min         -2.97055
trainer/Alpha                       0.0806834
trainer/Alpha Loss                 -0.580302
exploration/num steps total    158700
exploration/num paths total      1587
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11643
exploration/Rewards Std             1.19852
exploration/Rewards Max            -0.00771816
exploration/Rewards Min            -7.45178
exploration/Returns Mean         -111.643
exploration/Returns Std            92.248
exploration/Returns Max           -34.7436
exploration/Returns Min          -227.617
exploration/Actions Mean           -0.0189884
exploration/Actions Std             0.202987
exploration/Actions Max             0.997739
exploration/Actions Min            -0.997488
exploration/Num Paths               5
exploration/Average Returns      -111.643
evaluation/num steps total     475500
evaluation/num paths total       4755
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.697418
evaluation/Rewards Std              1.11572
evaluation/Rewards Max             -0.0174472
evaluation/Rewards Min             -9.46942
evaluation/Returns Mean           -69.7418
evaluation/Returns Std             77.1373
evaluation/Returns Max             -7.1772
evaluation/Returns Min           -236.707
evaluation/Actions Mean            -0.0145971
evaluation/Actions Std              0.176748
evaluation/Actions Max              0.994953
evaluation/Actions Min             -0.999329
evaluation/Num Paths               15
evaluation/Average Returns        -69.7418
time/data storing (s)               0.00276978
time/evaluation sampling (s)        0.328033
time/exploration sampling (s)       0.137425
time/logging (s)                    0.00476547
time/saving (s)                     0.00196395
time/training (s)                   1.93688
time/epoch (s)                      2.41184
time/total (s)                    771.567
Epoch                             316
-----------------------------  ---------------
2019-04-23 00:06:13.969767 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 317 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    6.00228
trainer/QF2 Loss                    5.98702
trainer/Policy Loss                35.0187
trainer/Q1 Predictions Mean       -33.1802
trainer/Q1 Predictions Std         34.4003
trainer/Q1 Predictions Max         -7.53389
trainer/Q1 Predictions Min       -147.624
trainer/Q2 Predictions Mean       -33.2301
trainer/Q2 Predictions Std         34.4161
trainer/Q2 Predictions Max         -7.52983
trainer/Q2 Predictions Min       -148.897
trainer/Q Targets Mean            -33.4084
trainer/Q Targets Std              35.0138
trainer/Q Targets Max              -0.502248
trainer/Q Targets Min            -150.096
trainer/Log Pis Mean                1.94044
trainer/Log Pis Std                 1.24746
trainer/Log Pis Max                 6.63069
trainer/Log Pis Min                -1.71941
trainer/Policy mu Mean             -0.0379575
trainer/Policy mu Std               0.474999
trainer/Policy mu Max               2.53151
trainer/Policy mu Min              -3.25796
trainer/Policy log std Mean        -2.30272
trainer/Policy log std Std          0.408872
trainer/Policy log std Max         -0.611549
trainer/Policy log std Min         -3.09759
trainer/Alpha                       0.0828017
trainer/Alpha Loss                 -0.148384
exploration/num steps total    159200
exploration/num paths total      1592
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.944728
exploration/Rewards Std             1.23083
exploration/Rewards Max            -0.0122081
exploration/Rewards Min           -11.3902
exploration/Returns Mean          -94.4728
exploration/Returns Std            84.7191
exploration/Returns Max           -12.3147
exploration/Returns Min          -230.067
exploration/Actions Mean            0.022995
exploration/Actions Std             0.192855
exploration/Actions Max             0.998607
exploration/Actions Min            -0.97876
exploration/Num Paths               5
exploration/Average Returns       -94.4728
evaluation/num steps total     477000
evaluation/num paths total       4770
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.669809
evaluation/Rewards Std              1.10715
evaluation/Rewards Max             -0.0462276
evaluation/Rewards Min            -10.2709
evaluation/Returns Mean           -66.9809
evaluation/Returns Std             66.2764
evaluation/Returns Max             -7.50016
evaluation/Returns Min           -243.469
evaluation/Actions Mean             0.00364835
evaluation/Actions Std              0.188781
evaluation/Actions Max              0.997913
evaluation/Actions Min             -0.999386
evaluation/Num Paths               15
evaluation/Average Returns        -66.9809
time/data storing (s)               0.00272235
time/evaluation sampling (s)        0.339957
time/exploration sampling (s)       0.158765
time/logging (s)                    0.00475982
time/saving (s)                     0.0099325
time/training (s)                   1.95382
time/epoch (s)                      2.46996
time/total (s)                    774.041
Epoch                             317
-----------------------------  ---------------
2019-04-23 00:06:16.418546 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 318 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  235.034
trainer/QF2 Loss                  235.667
trainer/Policy Loss                33.9934
trainer/Q1 Predictions Mean       -32.1076
trainer/Q1 Predictions Std         33.3905
trainer/Q1 Predictions Max         -7.59501
trainer/Q1 Predictions Min       -112.009
trainer/Q2 Predictions Mean       -32.0438
trainer/Q2 Predictions Std         33.3887
trainer/Q2 Predictions Max         -7.4823
trainer/Q2 Predictions Min       -111.842
trainer/Q Targets Mean            -30.3929
trainer/Q Targets Std              32.024
trainer/Q Targets Max              -2.27071
trainer/Q Targets Min            -113.266
trainer/Log Pis Mean                2.04414
trainer/Log Pis Std                 1.17549
trainer/Log Pis Max                 5.15726
trainer/Log Pis Min                -1.09251
trainer/Policy mu Mean             -0.0312029
trainer/Policy mu Std               0.592574
trainer/Policy mu Max               3.78332
trainer/Policy mu Min              -2.73687
trainer/Policy log std Mean        -2.22746
trainer/Policy log std Std          0.445707
trainer/Policy log std Max         -0.441234
trainer/Policy log std Min         -2.94566
trainer/Alpha                       0.0829397
trainer/Alpha Loss                  0.1099
exploration/num steps total    159700
exploration/num paths total      1597
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.922648
exploration/Rewards Std             1.21007
exploration/Rewards Max            -0.0176665
exploration/Rewards Min            -9.32281
exploration/Returns Mean          -92.2648
exploration/Returns Std            66.5018
exploration/Returns Max           -22.177
exploration/Returns Min          -179.853
exploration/Actions Mean            0.0128547
exploration/Actions Std             0.245895
exploration/Actions Max             0.996983
exploration/Actions Min            -0.996352
exploration/Num Paths               5
exploration/Average Returns       -92.2648
evaluation/num steps total     478500
evaluation/num paths total       4785
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.957691
evaluation/Rewards Std              1.19972
evaluation/Rewards Max             -0.0370317
evaluation/Rewards Min            -10.091
evaluation/Returns Mean           -95.7691
evaluation/Returns Std             91.5955
evaluation/Returns Max             -4.34451
evaluation/Returns Min           -264.8
evaluation/Actions Mean             0.000327764
evaluation/Actions Std              0.170284
evaluation/Actions Max              0.998118
evaluation/Actions Min             -0.998595
evaluation/Num Paths               15
evaluation/Average Returns        -95.7691
time/data storing (s)               0.00282676
time/evaluation sampling (s)        0.325446
time/exploration sampling (s)       0.138113
time/logging (s)                    0.00349128
time/saving (s)                     0.00196781
time/training (s)                   1.96623
time/epoch (s)                      2.43807
time/total (s)                    776.484
Epoch                             318
-----------------------------  ----------------
2019-04-23 00:06:18.863000 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 319 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.333686
trainer/QF2 Loss                    0.301529
trainer/Policy Loss                35.4888
trainer/Q1 Predictions Mean       -33.5494
trainer/Q1 Predictions Std         31.6606
trainer/Q1 Predictions Max         -7.89604
trainer/Q1 Predictions Min       -120.901
trainer/Q2 Predictions Mean       -33.5808
trainer/Q2 Predictions Std         31.6875
trainer/Q2 Predictions Max         -7.76279
trainer/Q2 Predictions Min       -121.306
trainer/Q Targets Mean            -33.8711
trainer/Q Targets Std              32.0533
trainer/Q Targets Max              -7.83177
trainer/Q Targets Min            -122.004
trainer/Log Pis Mean                2.04629
trainer/Log Pis Std                 1.10038
trainer/Log Pis Max                 5.64615
trainer/Log Pis Min                -0.89478
trainer/Policy mu Mean             -0.0170904
trainer/Policy mu Std               0.558368
trainer/Policy mu Max               2.79178
trainer/Policy mu Min              -2.4628
trainer/Policy log std Mean        -2.18335
trainer/Policy log std Std          0.459149
trainer/Policy log std Max         -0.521723
trainer/Policy log std Min         -3.03505
trainer/Alpha                       0.0827511
trainer/Alpha Loss                  0.115354
exploration/num steps total    160200
exploration/num paths total      1602
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.1528
exploration/Rewards Std             0.995926
exploration/Rewards Max            -0.0152125
exploration/Rewards Min            -6.91298
exploration/Returns Mean         -115.28
exploration/Returns Std            84.5851
exploration/Returns Max           -16.9035
exploration/Returns Min          -250.291
exploration/Actions Mean           -0.0154706
exploration/Actions Std             0.209926
exploration/Actions Max             0.995129
exploration/Actions Min            -0.998298
exploration/Num Paths               5
exploration/Average Returns      -115.28
evaluation/num steps total     480000
evaluation/num paths total       4800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.36098
evaluation/Rewards Std              1.16126
evaluation/Rewards Max             -0.0354805
evaluation/Rewards Min            -11.467
evaluation/Returns Mean          -136.098
evaluation/Returns Std             73.8818
evaluation/Returns Max            -21.9827
evaluation/Returns Min           -252.705
evaluation/Actions Mean             0.0141395
evaluation/Actions Std              0.19193
evaluation/Actions Max              0.999511
evaluation/Actions Min             -0.995506
evaluation/Num Paths               15
evaluation/Average Returns       -136.098
time/data storing (s)               0.00268882
time/evaluation sampling (s)        0.324603
time/exploration sampling (s)       0.137088
time/logging (s)                    0.00479708
time/saving (s)                     0.00199986
time/training (s)                   1.96569
time/epoch (s)                      2.43687
time/total (s)                    778.925
Epoch                             319
-----------------------------  ---------------
2019-04-23 00:06:21.313595 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 320 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    4.35979
trainer/QF2 Loss                    4.42057
trainer/Policy Loss                39.0445
trainer/Q1 Predictions Mean       -37.0087
trainer/Q1 Predictions Std         34.7076
trainer/Q1 Predictions Max         -8.12627
trainer/Q1 Predictions Min       -132.915
trainer/Q2 Predictions Mean       -37.011
trainer/Q2 Predictions Std         34.6505
trainer/Q2 Predictions Max         -8.17182
trainer/Q2 Predictions Min       -132.06
trainer/Q Targets Mean            -36.9762
trainer/Q Targets Std              34.9485
trainer/Q Targets Max              -0.552577
trainer/Q Targets Min            -132.753
trainer/Log Pis Mean                2.20487
trainer/Log Pis Std                 0.96745
trainer/Log Pis Max                 5.56917
trainer/Log Pis Min                -0.516627
trainer/Policy mu Mean              0.0276525
trainer/Policy mu Std               0.456397
trainer/Policy mu Max               2.6578
trainer/Policy mu Min              -2.54308
trainer/Policy log std Mean        -2.28764
trainer/Policy log std Std          0.433754
trainer/Policy log std Max         -0.559539
trainer/Policy log std Min         -3.10217
trainer/Alpha                       0.0815242
trainer/Alpha Loss                  0.513592
exploration/num steps total    160700
exploration/num paths total      1607
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.827981
exploration/Rewards Std             1.02321
exploration/Rewards Max            -0.0013107
exploration/Rewards Min            -9.10826
exploration/Returns Mean          -82.7981
exploration/Returns Std            48.3702
exploration/Returns Max           -31.8081
exploration/Returns Min          -142.252
exploration/Actions Mean           -0.00544111
exploration/Actions Std             0.239816
exploration/Actions Max             0.997184
exploration/Actions Min            -0.999343
exploration/Num Paths               5
exploration/Average Returns       -82.7981
evaluation/num steps total     481500
evaluation/num paths total       4815
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.673173
evaluation/Rewards Std              1.10099
evaluation/Rewards Max             -0.0248975
evaluation/Rewards Min            -11.5246
evaluation/Returns Mean           -67.3173
evaluation/Returns Std             71.3653
evaluation/Returns Max             -6.85437
evaluation/Returns Min           -255.527
evaluation/Actions Mean             0.00037009
evaluation/Actions Std              0.192234
evaluation/Actions Max              0.999437
evaluation/Actions Min             -0.997649
evaluation/Num Paths               15
evaluation/Average Returns        -67.3173
time/data storing (s)               0.00284821
time/evaluation sampling (s)        0.326805
time/exploration sampling (s)       0.136493
time/logging (s)                    0.00481323
time/saving (s)                     0.00197402
time/training (s)                   1.9691
time/epoch (s)                      2.44203
time/total (s)                    781.371
Epoch                             320
-----------------------------  ---------------
2019-04-23 00:06:23.760976 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 321 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   35.5115
trainer/QF2 Loss                   35.716
trainer/Policy Loss                34.3049
trainer/Q1 Predictions Mean       -32.4978
trainer/Q1 Predictions Std         33.5669
trainer/Q1 Predictions Max         -8.01281
trainer/Q1 Predictions Min       -113.575
trainer/Q2 Predictions Mean       -32.5005
trainer/Q2 Predictions Std         33.5859
trainer/Q2 Predictions Max         -7.9855
trainer/Q2 Predictions Min       -113.428
trainer/Q Targets Mean            -32.0464
trainer/Q Targets Std              34.0221
trainer/Q Targets Max              -1.04258
trainer/Q Targets Min            -114.16
trainer/Log Pis Mean                1.95406
trainer/Log Pis Std                 1.24058
trainer/Log Pis Max                 5.2635
trainer/Log Pis Min                -2.66187
trainer/Policy mu Mean             -0.0358074
trainer/Policy mu Std               0.428521
trainer/Policy mu Max               3.09186
trainer/Policy mu Min              -2.01124
trainer/Policy log std Mean        -2.28877
trainer/Policy log std Std          0.436429
trainer/Policy log std Max         -0.502321
trainer/Policy log std Min         -3.10511
trainer/Alpha                       0.0823301
trainer/Alpha Loss                 -0.114707
exploration/num steps total    161200
exploration/num paths total      1612
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.622235
exploration/Rewards Std             0.984654
exploration/Rewards Max            -0.000491006
exploration/Rewards Min            -7.13887
exploration/Returns Mean          -62.2235
exploration/Returns Std            87.3734
exploration/Returns Max           -13.9954
exploration/Returns Min          -236.76
exploration/Actions Mean           -0.00613731
exploration/Actions Std             0.181633
exploration/Actions Max             0.99405
exploration/Actions Min            -0.992159
exploration/Num Paths               5
exploration/Average Returns       -62.2235
evaluation/num steps total     483000
evaluation/num paths total       4830
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.767091
evaluation/Rewards Std              1.18395
evaluation/Rewards Max             -0.00287535
evaluation/Rewards Min            -11.2435
evaluation/Returns Mean           -76.7091
evaluation/Returns Std             72.433
evaluation/Returns Max             -4.97795
evaluation/Returns Min           -230.462
evaluation/Actions Mean            -0.00112601
evaluation/Actions Std              0.184943
evaluation/Actions Max              0.998277
evaluation/Actions Min             -0.999588
evaluation/Num Paths               15
evaluation/Average Returns        -76.7091
time/data storing (s)               0.00266576
time/evaluation sampling (s)        0.332148
time/exploration sampling (s)       0.140765
time/logging (s)                    0.00482959
time/saving (s)                     0.00202951
time/training (s)                   1.95561
time/epoch (s)                      2.43804
time/total (s)                    783.814
Epoch                             321
-----------------------------  ----------------
2019-04-23 00:06:26.211936 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 322 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    9.51658
trainer/QF2 Loss                    9.45485
trainer/Policy Loss                42.5961
trainer/Q1 Predictions Mean       -40.6892
trainer/Q1 Predictions Std         38.2063
trainer/Q1 Predictions Max         -8.00589
trainer/Q1 Predictions Min       -114.008
trainer/Q2 Predictions Mean       -40.7317
trainer/Q2 Predictions Std         38.2221
trainer/Q2 Predictions Max         -8.01807
trainer/Q2 Predictions Min       -113.901
trainer/Q Targets Mean            -40.4985
trainer/Q Targets Std              38.8553
trainer/Q Targets Max              -0.266282
trainer/Q Targets Min            -114.826
trainer/Log Pis Mean                2.02517
trainer/Log Pis Std                 1.25969
trainer/Log Pis Max                 7.70795
trainer/Log Pis Min                -1.84528
trainer/Policy mu Mean             -0.0637184
trainer/Policy mu Std               0.492128
trainer/Policy mu Max               2.66689
trainer/Policy mu Min              -3.84627
trainer/Policy log std Mean        -2.2686
trainer/Policy log std Std          0.467452
trainer/Policy log std Max         -0.263628
trainer/Policy log std Min         -3.07733
trainer/Alpha                       0.0819962
trainer/Alpha Loss                  0.0629665
exploration/num steps total    161700
exploration/num paths total      1617
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.708639
exploration/Rewards Std             1.1293
exploration/Rewards Max            -0.00549285
exploration/Rewards Min            -7.65124
exploration/Returns Mean          -70.8639
exploration/Returns Std            85.8493
exploration/Returns Max           -20.2679
exploration/Returns Min          -242.043
exploration/Actions Mean            0.00213106
exploration/Actions Std             0.213271
exploration/Actions Max             0.995805
exploration/Actions Min            -0.99853
exploration/Num Paths               5
exploration/Average Returns       -70.8639
evaluation/num steps total     484500
evaluation/num paths total       4845
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.797093
evaluation/Rewards Std              1.3037
evaluation/Rewards Max             -0.0203306
evaluation/Rewards Min            -12.02
evaluation/Returns Mean           -79.7093
evaluation/Returns Std             68.715
evaluation/Returns Max             -3.86864
evaluation/Returns Min           -229.84
evaluation/Actions Mean             0.00668221
evaluation/Actions Std              0.197428
evaluation/Actions Max              0.998688
evaluation/Actions Min             -0.999484
evaluation/Num Paths               15
evaluation/Average Returns        -79.7093
time/data storing (s)               0.00279705
time/evaluation sampling (s)        0.330129
time/exploration sampling (s)       0.141126
time/logging (s)                    0.00466035
time/saving (s)                     0.00201568
time/training (s)                   1.96074
time/epoch (s)                      2.44147
time/total (s)                    786.26
Epoch                             322
-----------------------------  ---------------
2019-04-23 00:06:28.651989 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 323 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.180696
trainer/QF2 Loss                    0.211641
trainer/Policy Loss                33.1761
trainer/Q1 Predictions Mean       -31.5635
trainer/Q1 Predictions Std         30.8868
trainer/Q1 Predictions Max         -7.95312
trainer/Q1 Predictions Min       -113.634
trainer/Q2 Predictions Mean       -31.6016
trainer/Q2 Predictions Std         30.8862
trainer/Q2 Predictions Max         -7.8888
trainer/Q2 Predictions Min       -113.639
trainer/Q Targets Mean            -31.7922
trainer/Q Targets Std              31.1207
trainer/Q Targets Max              -8.02617
trainer/Q Targets Min            -114.151
trainer/Log Pis Mean                1.76939
trainer/Log Pis Std                 1.26784
trainer/Log Pis Max                 5.88204
trainer/Log Pis Min                -1.96961
trainer/Policy mu Mean              0.0445677
trainer/Policy mu Std               0.38918
trainer/Policy mu Max               2.9702
trainer/Policy mu Min              -0.688537
trainer/Policy log std Mean        -2.23365
trainer/Policy log std Std          0.402182
trainer/Policy log std Max         -0.446536
trainer/Policy log std Min         -2.79077
trainer/Alpha                       0.0834617
trainer/Alpha Loss                 -0.57269
exploration/num steps total    162200
exploration/num paths total      1622
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.798543
exploration/Rewards Std             1.07901
exploration/Rewards Max            -0.0135385
exploration/Rewards Min            -9.99574
exploration/Returns Mean          -79.8543
exploration/Returns Std            65.9428
exploration/Returns Max           -18.1437
exploration/Returns Min          -180.409
exploration/Actions Mean            0.0221666
exploration/Actions Std             0.216451
exploration/Actions Max             0.999352
exploration/Actions Min            -0.940454
exploration/Num Paths               5
exploration/Average Returns       -79.8543
evaluation/num steps total     486000
evaluation/num paths total       4860
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.818348
evaluation/Rewards Std              1.36073
evaluation/Rewards Max             -0.0981205
evaluation/Rewards Min            -12.0835
evaluation/Returns Mean           -81.8348
evaluation/Returns Std             79.1079
evaluation/Returns Max            -11.8626
evaluation/Returns Min           -261.292
evaluation/Actions Mean             0.00468456
evaluation/Actions Std              0.20933
evaluation/Actions Max              0.998737
evaluation/Actions Min             -0.998299
evaluation/Num Paths               15
evaluation/Average Returns        -81.8348
time/data storing (s)               0.00275361
time/evaluation sampling (s)        0.324938
time/exploration sampling (s)       0.139844
time/logging (s)                    0.00483371
time/saving (s)                     0.00198538
time/training (s)                   1.95653
time/epoch (s)                      2.43088
time/total (s)                    788.695
Epoch                             323
-----------------------------  ---------------
2019-04-23 00:06:31.079303 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 324 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.824166
trainer/QF2 Loss                    0.807465
trainer/Policy Loss                35.9694
trainer/Q1 Predictions Mean       -34.1393
trainer/Q1 Predictions Std         32.7704
trainer/Q1 Predictions Max         -8.10375
trainer/Q1 Predictions Min       -111.067
trainer/Q2 Predictions Mean       -34.1431
trainer/Q2 Predictions Std         32.7767
trainer/Q2 Predictions Max         -8.05324
trainer/Q2 Predictions Min       -111.202
trainer/Q Targets Mean            -34.6482
trainer/Q Targets Std              33.4181
trainer/Q Targets Max              -8.0677
trainer/Q Targets Min            -113.577
trainer/Log Pis Mean                1.886
trainer/Log Pis Std                 1.13889
trainer/Log Pis Max                 4.18016
trainer/Log Pis Min                -2.1398
trainer/Policy mu Mean              0.00744212
trainer/Policy mu Std               0.380608
trainer/Policy mu Max               2.50591
trainer/Policy mu Min              -2.33942
trainer/Policy log std Mean        -2.2457
trainer/Policy log std Std          0.454569
trainer/Policy log std Max         -0.754617
trainer/Policy log std Min         -2.92861
trainer/Alpha                       0.0829755
trainer/Alpha Loss                 -0.283769
exploration/num steps total    162700
exploration/num paths total      1627
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.328629
exploration/Rewards Std             0.753633
exploration/Rewards Max            -0.0133984
exploration/Rewards Min            -6.97353
exploration/Returns Mean          -32.8629
exploration/Returns Std            11.7766
exploration/Returns Max           -16.6648
exploration/Returns Min           -47.3336
exploration/Actions Mean           -0.0178285
exploration/Actions Std             0.195929
exploration/Actions Max             0.987746
exploration/Actions Min            -0.999037
exploration/Num Paths               5
exploration/Average Returns       -32.8629
evaluation/num steps total     487500
evaluation/num paths total       4875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.654734
evaluation/Rewards Std              1.06771
evaluation/Rewards Max             -0.0213432
evaluation/Rewards Min             -8.74389
evaluation/Returns Mean           -65.4734
evaluation/Returns Std             62.0259
evaluation/Returns Max             -9.49874
evaluation/Returns Min           -228.352
evaluation/Actions Mean            -0.0111062
evaluation/Actions Std              0.175338
evaluation/Actions Max              0.998282
evaluation/Actions Min             -0.998277
evaluation/Num Paths               15
evaluation/Average Returns        -65.4734
time/data storing (s)               0.00262479
time/evaluation sampling (s)        0.32605
time/exploration sampling (s)       0.138407
time/logging (s)                    0.00478753
time/saving (s)                     0.00159827
time/training (s)                   1.94451
time/epoch (s)                      2.41798
time/total (s)                    791.118
Epoch                             324
-----------------------------  ---------------
2019-04-23 00:06:33.516870 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 325 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.550654
trainer/QF2 Loss                    0.696707
trainer/Policy Loss                35.4799
trainer/Q1 Predictions Mean       -33.5199
trainer/Q1 Predictions Std         35.1588
trainer/Q1 Predictions Max         -7.96764
trainer/Q1 Predictions Min       -112.085
trainer/Q2 Predictions Mean       -33.4956
trainer/Q2 Predictions Std         35.1407
trainer/Q2 Predictions Max         -7.90394
trainer/Q2 Predictions Min       -111.867
trainer/Q Targets Mean            -33.9741
trainer/Q Targets Std              35.6242
trainer/Q Targets Max              -8.09005
trainer/Q Targets Min            -113.539
trainer/Log Pis Mean                2.10878
trainer/Log Pis Std                 1.29968
trainer/Log Pis Max                 7.52284
trainer/Log Pis Min                -1.06347
trainer/Policy mu Mean              0.0136786
trainer/Policy mu Std               0.576639
trainer/Policy mu Max               3.11967
trainer/Policy mu Min              -3.50068
trainer/Policy log std Mean        -2.28382
trainer/Policy log std Std          0.486825
trainer/Policy log std Max         -0.208529
trainer/Policy log std Min         -3.12209
trainer/Alpha                       0.0859941
trainer/Alpha Loss                  0.266919
exploration/num steps total    163200
exploration/num paths total      1632
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.439742
exploration/Rewards Std             1.10128
exploration/Rewards Max            -0.00918088
exploration/Rewards Min            -9.83997
exploration/Returns Mean          -43.9742
exploration/Returns Std            15.3951
exploration/Returns Max           -22.8234
exploration/Returns Min           -65.7824
exploration/Actions Mean           -0.00140604
exploration/Actions Std             0.226408
exploration/Actions Max             0.996776
exploration/Actions Min            -0.99968
exploration/Num Paths               5
exploration/Average Returns       -43.9742
evaluation/num steps total     489000
evaluation/num paths total       4890
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.705844
evaluation/Rewards Std              0.98453
evaluation/Rewards Max             -0.00427544
evaluation/Rewards Min            -10.0874
evaluation/Returns Mean           -70.5844
evaluation/Returns Std             61.8743
evaluation/Returns Max             -3.53026
evaluation/Returns Min           -162.498
evaluation/Actions Mean             0.0117872
evaluation/Actions Std              0.166943
evaluation/Actions Max              0.998118
evaluation/Actions Min             -0.989224
evaluation/Num Paths               15
evaluation/Average Returns        -70.5844
time/data storing (s)               0.00274812
time/evaluation sampling (s)        0.330213
time/exploration sampling (s)       0.136929
time/logging (s)                    0.00355495
time/saving (s)                     0.00200333
time/training (s)                   1.95144
time/epoch (s)                      2.42689
time/total (s)                    793.549
Epoch                             325
-----------------------------  ---------------
2019-04-23 00:06:35.958950 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 326 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   31.5387
trainer/QF2 Loss                   31.5253
trainer/Policy Loss                33.9637
trainer/Q1 Predictions Mean       -32.041
trainer/Q1 Predictions Std         32.2465
trainer/Q1 Predictions Max         -8.14076
trainer/Q1 Predictions Min       -113.776
trainer/Q2 Predictions Mean       -32.0019
trainer/Q2 Predictions Std         32.2482
trainer/Q2 Predictions Max         -8.05456
trainer/Q2 Predictions Min       -113.594
trainer/Q Targets Mean            -31.7457
trainer/Q Targets Std              32.5146
trainer/Q Targets Max              -1.24248
trainer/Q Targets Min            -115.007
trainer/Log Pis Mean                2.06192
trainer/Log Pis Std                 1.03539
trainer/Log Pis Max                 4.72692
trainer/Log Pis Min                -0.953711
trainer/Policy mu Mean             -0.0441875
trainer/Policy mu Std               0.415155
trainer/Policy mu Max               2.49626
trainer/Policy mu Min              -2.64823
trainer/Policy log std Mean        -2.28184
trainer/Policy log std Std          0.395019
trainer/Policy log std Max         -0.56215
trainer/Policy log std Min         -3.01421
trainer/Alpha                       0.0859235
trainer/Alpha Loss                  0.151962
exploration/num steps total    163700
exploration/num paths total      1637
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.827392
exploration/Rewards Std             1.0755
exploration/Rewards Max            -0.0345666
exploration/Rewards Min            -6.98357
exploration/Returns Mean          -82.7392
exploration/Returns Std            78.2912
exploration/Returns Max           -23.6871
exploration/Returns Min          -237.397
exploration/Actions Mean           -0.0191176
exploration/Actions Std             0.192121
exploration/Actions Max             0.954861
exploration/Actions Min            -0.998815
exploration/Num Paths               5
exploration/Average Returns       -82.7392
evaluation/num steps total     490500
evaluation/num paths total       4905
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.664437
evaluation/Rewards Std              1.1794
evaluation/Rewards Max             -0.0290631
evaluation/Rewards Min            -11.4244
evaluation/Returns Mean           -66.4437
evaluation/Returns Std             55.5253
evaluation/Returns Max            -10.8328
evaluation/Returns Min           -186.631
evaluation/Actions Mean             0.0152808
evaluation/Actions Std              0.202214
evaluation/Actions Max              0.997942
evaluation/Actions Min             -0.999137
evaluation/Num Paths               15
evaluation/Average Returns        -66.4437
time/data storing (s)               0.00263408
time/evaluation sampling (s)        0.33151
time/exploration sampling (s)       0.136571
time/logging (s)                    0.00354752
time/saving (s)                     0.00194746
time/training (s)                   1.95658
time/epoch (s)                      2.43279
time/total (s)                    795.986
Epoch                             326
-----------------------------  ---------------
2019-04-23 00:06:38.404609 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 327 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   32.9813
trainer/QF2 Loss                   32.9251
trainer/Policy Loss                37.3228
trainer/Q1 Predictions Mean       -35.6301
trainer/Q1 Predictions Std         36.1487
trainer/Q1 Predictions Max         -8.00917
trainer/Q1 Predictions Min       -116.076
trainer/Q2 Predictions Mean       -35.6001
trainer/Q2 Predictions Std         36.1856
trainer/Q2 Predictions Max         -7.92175
trainer/Q2 Predictions Min       -116.963
trainer/Q Targets Mean            -35.2743
trainer/Q Targets Std              36.6025
trainer/Q Targets Max              -0.907044
trainer/Q Targets Min            -115.023
trainer/Log Pis Mean                1.81423
trainer/Log Pis Std                 1.1564
trainer/Log Pis Max                 3.98336
trainer/Log Pis Min                -2.87597
trainer/Policy mu Mean             -0.0192437
trainer/Policy mu Std               0.330311
trainer/Policy mu Max               0.643852
trainer/Policy mu Min              -2.31469
trainer/Policy log std Mean        -2.28119
trainer/Policy log std Std          0.400142
trainer/Policy log std Max         -0.529022
trainer/Policy log std Min         -3.00335
trainer/Alpha                       0.0841435
trainer/Alpha Loss                 -0.459822
exploration/num steps total    164200
exploration/num paths total      1642
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.363277
exploration/Rewards Std             0.921722
exploration/Rewards Max            -0.0107045
exploration/Rewards Min            -9.20776
exploration/Returns Mean          -36.3277
exploration/Returns Std            16.3841
exploration/Returns Max           -22.1473
exploration/Returns Min           -58.927
exploration/Actions Mean           -0.00607304
exploration/Actions Std             0.228361
exploration/Actions Max             0.999215
exploration/Actions Min            -0.997498
exploration/Num Paths               5
exploration/Average Returns       -36.3277
evaluation/num steps total     492000
evaluation/num paths total       4920
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.41213
evaluation/Rewards Std              1.07642
evaluation/Rewards Max             -0.0142265
evaluation/Rewards Min             -9.52155
evaluation/Returns Mean           -41.213
evaluation/Returns Std             53.9496
evaluation/Returns Max             -6.99624
evaluation/Returns Min           -233.878
evaluation/Actions Mean            -0.00423124
evaluation/Actions Std              0.185616
evaluation/Actions Max              0.998834
evaluation/Actions Min             -0.995228
evaluation/Num Paths               15
evaluation/Average Returns        -41.213
time/data storing (s)               0.00262328
time/evaluation sampling (s)        0.32799
time/exploration sampling (s)       0.136346
time/logging (s)                    0.00480003
time/saving (s)                     0.00197825
time/training (s)                   1.96439
time/epoch (s)                      2.43813
time/total (s)                    798.429
Epoch                             327
-----------------------------  ---------------
2019-04-23 00:06:40.820239 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 328 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  116.65
trainer/QF2 Loss                  116.803
trainer/Policy Loss                34.8153
trainer/Q1 Predictions Mean       -32.8771
trainer/Q1 Predictions Std         34.2004
trainer/Q1 Predictions Max         -7.89561
trainer/Q1 Predictions Min       -111.037
trainer/Q2 Predictions Mean       -32.8869
trainer/Q2 Predictions Std         34.1774
trainer/Q2 Predictions Max         -7.89137
trainer/Q2 Predictions Min       -111.143
trainer/Q Targets Mean            -32.1775
trainer/Q Targets Std              33.9567
trainer/Q Targets Max              -2.33868
trainer/Q Targets Min            -113.213
trainer/Log Pis Mean                2.04825
trainer/Log Pis Std                 1.38244
trainer/Log Pis Max                 7.38433
trainer/Log Pis Min                -2.97026
trainer/Policy mu Mean              0.000787053
trainer/Policy mu Std               0.513215
trainer/Policy mu Max               2.75555
trainer/Policy mu Min              -3.13799
trainer/Policy log std Mean        -2.25159
trainer/Policy log std Std          0.464231
trainer/Policy log std Max         -0.382803
trainer/Policy log std Min         -3.03119
trainer/Alpha                       0.0852757
trainer/Alpha Loss                  0.118777
exploration/num steps total    164700
exploration/num paths total      1647
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.700837
exploration/Rewards Std             1.04672
exploration/Rewards Max            -0.00858624
exploration/Rewards Min            -6.36829
exploration/Returns Mean          -70.0837
exploration/Returns Std            80.5289
exploration/Returns Max           -20.7048
exploration/Returns Min          -230.802
exploration/Actions Mean            0.0239649
exploration/Actions Std             0.204727
exploration/Actions Max             0.998441
exploration/Actions Min            -0.981801
exploration/Num Paths               5
exploration/Average Returns       -70.0837
evaluation/num steps total     493500
evaluation/num paths total       4935
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.703356
evaluation/Rewards Std              1.0874
evaluation/Rewards Max             -0.0766105
evaluation/Rewards Min             -9.67228
evaluation/Returns Mean           -70.3356
evaluation/Returns Std             72.2967
evaluation/Returns Max             -9.25285
evaluation/Returns Min           -230.367
evaluation/Actions Mean             0.0020836
evaluation/Actions Std              0.175717
evaluation/Actions Max              0.997929
evaluation/Actions Min             -0.998987
evaluation/Num Paths               15
evaluation/Average Returns        -70.3356
time/data storing (s)               0.00267328
time/evaluation sampling (s)        0.324362
time/exploration sampling (s)       0.137914
time/logging (s)                    0.0042862
time/saving (s)                     0.00195625
time/training (s)                   1.93447
time/epoch (s)                      2.40566
time/total (s)                    800.839
Epoch                             328
-----------------------------  ----------------
2019-04-23 00:06:43.268186 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 329 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.37085
trainer/QF2 Loss                    0.3805
trainer/Policy Loss                34.6751
trainer/Q1 Predictions Mean       -32.8035
trainer/Q1 Predictions Std         34.325
trainer/Q1 Predictions Max         -7.74532
trainer/Q1 Predictions Min       -112.368
trainer/Q2 Predictions Mean       -32.7848
trainer/Q2 Predictions Std         34.3271
trainer/Q2 Predictions Max         -7.80488
trainer/Q2 Predictions Min       -111.823
trainer/Q Targets Mean            -33.241
trainer/Q Targets Std              34.5653
trainer/Q Targets Max              -7.9903
trainer/Q Targets Min            -112.795
trainer/Log Pis Mean                1.99845
trainer/Log Pis Std                 1.19276
trainer/Log Pis Max                 5.6151
trainer/Log Pis Min                -1.96148
trainer/Policy mu Mean             -0.017636
trainer/Policy mu Std               0.414692
trainer/Policy mu Max               2.19314
trainer/Policy mu Min              -2.28035
trainer/Policy log std Mean        -2.26445
trainer/Policy log std Std          0.410468
trainer/Policy log std Max         -0.681241
trainer/Policy log std Min         -2.97774
trainer/Alpha                       0.0862988
trainer/Alpha Loss                 -0.00380847
exploration/num steps total    165200
exploration/num paths total      1652
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.447196
exploration/Rewards Std             0.503436
exploration/Rewards Max            -0.0212143
exploration/Rewards Min            -4.27166
exploration/Returns Mean          -44.7196
exploration/Returns Std            37.5532
exploration/Returns Max           -21.1599
exploration/Returns Min          -119.197
exploration/Actions Mean           -0.00113665
exploration/Actions Std             0.161532
exploration/Actions Max             0.97719
exploration/Actions Min            -0.989894
exploration/Num Paths               5
exploration/Average Returns       -44.7196
evaluation/num steps total     495000
evaluation/num paths total       4950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.505856
evaluation/Rewards Std              0.954718
evaluation/Rewards Max             -0.0191861
evaluation/Rewards Min             -9.2548
evaluation/Returns Mean           -50.5856
evaluation/Returns Std             41.2834
evaluation/Returns Max             -8.14067
evaluation/Returns Min           -135.936
evaluation/Actions Mean             0.00763676
evaluation/Actions Std              0.191881
evaluation/Actions Max              0.996721
evaluation/Actions Min             -0.999578
evaluation/Num Paths               15
evaluation/Average Returns        -50.5856
time/data storing (s)               0.00278097
time/evaluation sampling (s)        0.327442
time/exploration sampling (s)       0.139087
time/logging (s)                    0.0047862
time/saving (s)                     0.00957678
time/training (s)                   1.95539
time/epoch (s)                      2.43906
time/total (s)                    803.283
Epoch                             329
-----------------------------  ---------------
2019-04-23 00:06:45.707626 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 330 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   31.795
trainer/QF2 Loss                   31.5919
trainer/Policy Loss                34.2184
trainer/Q1 Predictions Mean       -32.3001
trainer/Q1 Predictions Std         32.2238
trainer/Q1 Predictions Max         -7.99787
trainer/Q1 Predictions Min       -111.86
trainer/Q2 Predictions Mean       -32.2648
trainer/Q2 Predictions Std         32.2099
trainer/Q2 Predictions Max         -7.94482
trainer/Q2 Predictions Min       -111.582
trainer/Q Targets Mean            -31.9899
trainer/Q Targets Std              32.5422
trainer/Q Targets Max              -1.21973
trainer/Q Targets Min            -113.013
trainer/Log Pis Mean                2.04943
trainer/Log Pis Std                 0.960417
trainer/Log Pis Max                 4.16383
trainer/Log Pis Min                -0.769398
trainer/Policy mu Mean              0.0246303
trainer/Policy mu Std               0.291286
trainer/Policy mu Max               1.6315
trainer/Policy mu Min              -1.48158
trainer/Policy log std Mean        -2.29219
trainer/Policy log std Std          0.356365
trainer/Policy log std Max         -0.967739
trainer/Policy log std Min         -2.93604
trainer/Alpha                       0.0885291
trainer/Alpha Loss                  0.119845
exploration/num steps total    165700
exploration/num paths total      1657
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.712602
exploration/Rewards Std             1.25705
exploration/Rewards Max            -0.0196445
exploration/Rewards Min            -9.37204
exploration/Returns Mean          -71.2602
exploration/Returns Std            57.3829
exploration/Returns Max           -20.7006
exploration/Returns Min          -180.513
exploration/Actions Mean           -0.0105071
exploration/Actions Std             0.227508
exploration/Actions Max             0.992199
exploration/Actions Min            -0.997768
exploration/Num Paths               5
exploration/Average Returns       -71.2602
evaluation/num steps total     496500
evaluation/num paths total       4965
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.570877
evaluation/Rewards Std              1.01066
evaluation/Rewards Max             -0.0176323
evaluation/Rewards Min             -8.34287
evaluation/Returns Mean           -57.0877
evaluation/Returns Std             64.7161
evaluation/Returns Max             -9.99532
evaluation/Returns Min           -230.126
evaluation/Actions Mean             0.00793793
evaluation/Actions Std              0.172819
evaluation/Actions Max              0.998803
evaluation/Actions Min             -0.996725
evaluation/Num Paths               15
evaluation/Average Returns        -57.0877
time/data storing (s)               0.00273517
time/evaluation sampling (s)        0.320249
time/exploration sampling (s)       0.137694
time/logging (s)                    0.00482715
time/saving (s)                     0.00198489
time/training (s)                   1.96256
time/epoch (s)                      2.43005
time/total (s)                    805.717
Epoch                             330
-----------------------------  ---------------
2019-04-23 00:06:48.186519 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 331 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.34271
trainer/QF2 Loss                    2.35305
trainer/Policy Loss                34.4346
trainer/Q1 Predictions Mean       -32.4181
trainer/Q1 Predictions Std         33.5844
trainer/Q1 Predictions Max         -8.26937
trainer/Q1 Predictions Min       -112.364
trainer/Q2 Predictions Mean       -32.4297
trainer/Q2 Predictions Std         33.5797
trainer/Q2 Predictions Max         -8.24957
trainer/Q2 Predictions Min       -112.09
trainer/Q Targets Mean            -32.2585
trainer/Q Targets Std              33.8429
trainer/Q Targets Max              -0.0792209
trainer/Q Targets Min            -112.047
trainer/Log Pis Mean                2.1253
trainer/Log Pis Std                 1.07905
trainer/Log Pis Max                 4.54762
trainer/Log Pis Min                -1.19686
trainer/Policy mu Mean             -0.0549362
trainer/Policy mu Std               0.582188
trainer/Policy mu Max               2.52398
trainer/Policy mu Min              -2.54059
trainer/Policy log std Mean        -2.21679
trainer/Policy log std Std          0.496269
trainer/Policy log std Max         -0.480349
trainer/Policy log std Min         -3.16983
trainer/Alpha                       0.084762
trainer/Alpha Loss                  0.309246
exploration/num steps total    166200
exploration/num paths total      1662
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.989362
exploration/Rewards Std             1.15918
exploration/Rewards Max            -0.00761099
exploration/Rewards Min            -9.08385
exploration/Returns Mean          -98.9362
exploration/Returns Std            61.6888
exploration/Returns Max           -17.0605
exploration/Returns Min          -177.014
exploration/Actions Mean            0.040408
exploration/Actions Std             0.235055
exploration/Actions Max             0.999199
exploration/Actions Min            -0.936748
exploration/Num Paths               5
exploration/Average Returns       -98.9362
evaluation/num steps total     498000
evaluation/num paths total       4980
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.650097
evaluation/Rewards Std              1.07015
evaluation/Rewards Max             -0.0250485
evaluation/Rewards Min             -9.70251
evaluation/Returns Mean           -65.0097
evaluation/Returns Std             53.73
evaluation/Returns Max             -2.7771
evaluation/Returns Min           -154.328
evaluation/Actions Mean             0.01754
evaluation/Actions Std              0.180494
evaluation/Actions Max              0.998841
evaluation/Actions Min             -0.998589
evaluation/Num Paths               15
evaluation/Average Returns        -65.0097
time/data storing (s)               0.00276446
time/evaluation sampling (s)        0.342554
time/exploration sampling (s)       0.138666
time/logging (s)                    0.0048051
time/saving (s)                     0.00196611
time/training (s)                   1.97949
time/epoch (s)                      2.47025
time/total (s)                    808.191
Epoch                             331
-----------------------------  ---------------
2019-04-23 00:06:50.676694 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 332 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.62576
trainer/QF2 Loss                    1.67846
trainer/Policy Loss                37.0827
trainer/Q1 Predictions Mean       -35.4577
trainer/Q1 Predictions Std         33.4434
trainer/Q1 Predictions Max         -8.01845
trainer/Q1 Predictions Min       -109.615
trainer/Q2 Predictions Mean       -35.4381
trainer/Q2 Predictions Std         33.4055
trainer/Q2 Predictions Max         -8.03624
trainer/Q2 Predictions Min       -109.745
trainer/Q Targets Mean            -35.5842
trainer/Q Targets Std              33.867
trainer/Q Targets Max              -0.16365
trainer/Q Targets Min            -111.007
trainer/Log Pis Mean                1.75334
trainer/Log Pis Std                 1.34114
trainer/Log Pis Max                 4.28178
trainer/Log Pis Min                -3.84887
trainer/Policy mu Mean             -0.0154047
trainer/Policy mu Std               0.399344
trainer/Policy mu Max               2.63518
trainer/Policy mu Min              -2.46546
trainer/Policy log std Mean        -2.23562
trainer/Policy log std Std          0.443006
trainer/Policy log std Max         -0.6957
trainer/Policy log std Min         -3.09199
trainer/Alpha                       0.0820656
trainer/Alpha Loss                 -0.616663
exploration/num steps total    166700
exploration/num paths total      1667
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.82233
exploration/Rewards Std             1.34277
exploration/Rewards Max            -0.0108564
exploration/Rewards Min           -10.197
exploration/Returns Mean          -82.233
exploration/Returns Std            82.7271
exploration/Returns Max           -27.8448
exploration/Returns Min          -246.096
exploration/Actions Mean           -0.0195601
exploration/Actions Std             0.245866
exploration/Actions Max             0.999631
exploration/Actions Min            -0.998903
exploration/Num Paths               5
exploration/Average Returns       -82.233
evaluation/num steps total     499500
evaluation/num paths total       4995
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.585541
evaluation/Rewards Std              1.20522
evaluation/Rewards Max             -0.020976
evaluation/Rewards Min             -9.98802
evaluation/Returns Mean           -58.5541
evaluation/Returns Std             75.1062
evaluation/Returns Max            -10.1243
evaluation/Returns Min           -259.371
evaluation/Actions Mean            -0.0143299
evaluation/Actions Std              0.199548
evaluation/Actions Max              0.997843
evaluation/Actions Min             -0.998487
evaluation/Num Paths               15
evaluation/Average Returns        -58.5541
time/data storing (s)               0.0028862
time/evaluation sampling (s)        0.33038
time/exploration sampling (s)       0.141916
time/logging (s)                    0.00478093
time/saving (s)                     0.00199473
time/training (s)                   1.9989
time/epoch (s)                      2.48086
time/total (s)                    810.677
Epoch                             332
-----------------------------  ---------------
2019-04-23 00:06:53.116641 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 333 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   32.4694
trainer/QF2 Loss                   32.3394
trainer/Policy Loss                27.9816
trainer/Q1 Predictions Mean       -26.087
trainer/Q1 Predictions Std         26.3657
trainer/Q1 Predictions Max         -8.06287
trainer/Q1 Predictions Min       -108.533
trainer/Q2 Predictions Mean       -26.1068
trainer/Q2 Predictions Std         26.3878
trainer/Q2 Predictions Max         -8.05899
trainer/Q2 Predictions Min       -108.546
trainer/Q Targets Mean            -25.8751
trainer/Q Targets Std              26.6007
trainer/Q Targets Max              -1.21973
trainer/Q Targets Min            -110.511
trainer/Log Pis Mean                1.98844
trainer/Log Pis Std                 1.29834
trainer/Log Pis Max                 6.18142
trainer/Log Pis Min                -2.82436
trainer/Policy mu Mean             -0.0286313
trainer/Policy mu Std               0.613001
trainer/Policy mu Max               2.80268
trainer/Policy mu Min              -2.69964
trainer/Policy log std Mean        -2.09977
trainer/Policy log std Std          0.458479
trainer/Policy log std Max         -0.362836
trainer/Policy log std Min         -3.10011
trainer/Alpha                       0.0826664
trainer/Alpha Loss                 -0.0288134
exploration/num steps total    167200
exploration/num paths total      1672
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.737249
exploration/Rewards Std             0.913921
exploration/Rewards Max            -0.00479215
exploration/Rewards Min            -7.12617
exploration/Returns Mean          -73.7249
exploration/Returns Std            45.8922
exploration/Returns Max           -32.8841
exploration/Returns Min          -137.911
exploration/Actions Mean            0.0167956
exploration/Actions Std             0.221211
exploration/Actions Max             0.999157
exploration/Actions Min            -0.995579
exploration/Num Paths               5
exploration/Average Returns       -73.7249
evaluation/num steps total     501000
evaluation/num paths total       5010
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.78933
evaluation/Rewards Std              1.15358
evaluation/Rewards Max             -0.0119441
evaluation/Rewards Min             -9.59055
evaluation/Returns Mean           -78.933
evaluation/Returns Std             72.3472
evaluation/Returns Max             -1.36092
evaluation/Returns Min           -272.17
evaluation/Actions Mean            -0.000370779
evaluation/Actions Std              0.191163
evaluation/Actions Max              0.999247
evaluation/Actions Min             -0.999855
evaluation/Num Paths               15
evaluation/Average Returns        -78.933
time/data storing (s)               0.00277841
time/evaluation sampling (s)        0.331445
time/exploration sampling (s)       0.136399
time/logging (s)                    0.00477315
time/saving (s)                     0.0019748
time/training (s)                   1.95368
time/epoch (s)                      2.43105
time/total (s)                    813.112
Epoch                             333
-----------------------------  ----------------
2019-04-23 00:06:55.558088 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 334 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   34.1102
trainer/QF2 Loss                   33.9835
trainer/Policy Loss                39.351
trainer/Q1 Predictions Mean       -37.4477
trainer/Q1 Predictions Std         36.9605
trainer/Q1 Predictions Max         -8.13586
trainer/Q1 Predictions Min       -109.137
trainer/Q2 Predictions Mean       -37.456
trainer/Q2 Predictions Std         36.9426
trainer/Q2 Predictions Max         -8.01846
trainer/Q2 Predictions Min       -109.167
trainer/Q Targets Mean            -37.4074
trainer/Q Targets Std              37.7823
trainer/Q Targets Max              -0.0690321
trainer/Q Targets Min            -110.807
trainer/Log Pis Mean                1.97911
trainer/Log Pis Std                 1.24585
trainer/Log Pis Max                 7.01351
trainer/Log Pis Min                -2.57457
trainer/Policy mu Mean             -0.0590166
trainer/Policy mu Std               0.398707
trainer/Policy mu Max               2.27468
trainer/Policy mu Min              -2.48674
trainer/Policy log std Mean        -2.34854
trainer/Policy log std Std          0.429601
trainer/Policy log std Max         -0.456364
trainer/Policy log std Min         -3.15042
trainer/Alpha                       0.0842824
trainer/Alpha Loss                 -0.0516874
exploration/num steps total    167700
exploration/num paths total      1677
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.275768
exploration/Rewards Std             0.758066
exploration/Rewards Max            -0.000236724
exploration/Rewards Min            -8.77125
exploration/Returns Mean          -27.5768
exploration/Returns Std            13.8078
exploration/Returns Max           -13.7615
exploration/Returns Min           -53.8045
exploration/Actions Mean            0.0136188
exploration/Actions Std             0.179978
exploration/Actions Max             0.997614
exploration/Actions Min            -0.998693
exploration/Num Paths               5
exploration/Average Returns       -27.5768
evaluation/num steps total     502500
evaluation/num paths total       5025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.725438
evaluation/Rewards Std              1.16371
evaluation/Rewards Max             -0.00865818
evaluation/Rewards Min            -10.5971
evaluation/Returns Mean           -72.5438
evaluation/Returns Std             78.9616
evaluation/Returns Max             -4.56844
evaluation/Returns Min           -241.383
evaluation/Actions Mean             0.0189869
evaluation/Actions Std              0.172608
evaluation/Actions Max              0.998378
evaluation/Actions Min             -0.990036
evaluation/Num Paths               15
evaluation/Average Returns        -72.5438
time/data storing (s)               0.00273194
time/evaluation sampling (s)        0.331484
time/exploration sampling (s)       0.137019
time/logging (s)                    0.00480488
time/saving (s)                     0.00156358
time/training (s)                   1.95474
time/epoch (s)                      2.43234
time/total (s)                    815.548
Epoch                             334
-----------------------------  ----------------
2019-04-23 00:06:57.996860 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 335 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.174193
trainer/QF2 Loss                    0.185218
trainer/Policy Loss                40.9235
trainer/Q1 Predictions Mean       -39.054
trainer/Q1 Predictions Std         35.5676
trainer/Q1 Predictions Max         -8.27998
trainer/Q1 Predictions Min       -111.906
trainer/Q2 Predictions Mean       -39.1073
trainer/Q2 Predictions Std         35.5538
trainer/Q2 Predictions Max         -8.26654
trainer/Q2 Predictions Min       -112.247
trainer/Q Targets Mean            -39.0225
trainer/Q Targets Std              35.589
trainer/Q Targets Max              -8.08011
trainer/Q Targets Min            -111.594
trainer/Log Pis Mean                2.03517
trainer/Log Pis Std                 1.00283
trainer/Log Pis Max                 3.75751
trainer/Log Pis Min                -3.00535
trainer/Policy mu Mean             -0.045275
trainer/Policy mu Std               0.370525
trainer/Policy mu Max               2.34224
trainer/Policy mu Min              -2.767
trainer/Policy log std Mean        -2.27907
trainer/Policy log std Std          0.391374
trainer/Policy log std Max         -0.655649
trainer/Policy log std Min         -3.08526
trainer/Alpha                       0.0820385
trainer/Alpha Loss                  0.0879351
exploration/num steps total    168200
exploration/num paths total      1682
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.05269
exploration/Rewards Std             1.22453
exploration/Rewards Max            -0.010486
exploration/Rewards Min            -8.6263
exploration/Returns Mean         -105.269
exploration/Returns Std            82.6978
exploration/Returns Max           -27.3219
exploration/Returns Min          -232.775
exploration/Actions Mean           -0.02466
exploration/Actions Std             0.232965
exploration/Actions Max             0.993119
exploration/Actions Min            -0.997914
exploration/Num Paths               5
exploration/Average Returns      -105.269
evaluation/num steps total     504000
evaluation/num paths total       5040
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.879199
evaluation/Rewards Std              1.24138
evaluation/Rewards Max             -0.0273311
evaluation/Rewards Min            -10.7907
evaluation/Returns Mean           -87.9199
evaluation/Returns Std             70.0447
evaluation/Returns Max            -15.1296
evaluation/Returns Min           -224.66
evaluation/Actions Mean             0.0174353
evaluation/Actions Std              0.194927
evaluation/Actions Max              0.997531
evaluation/Actions Min             -0.998007
evaluation/Num Paths               15
evaluation/Average Returns        -87.9199
time/data storing (s)               0.00269544
time/evaluation sampling (s)        0.324496
time/exploration sampling (s)       0.13868
time/logging (s)                    0.00482999
time/saving (s)                     0.0019701
time/training (s)                   1.95672
time/epoch (s)                      2.42939
time/total (s)                    817.982
Epoch                             335
-----------------------------  ---------------
2019-04-23 00:07:00.446860 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 336 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.369862
trainer/QF2 Loss                    0.480177
trainer/Policy Loss                36.7213
trainer/Q1 Predictions Mean       -34.7113
trainer/Q1 Predictions Std         33.4997
trainer/Q1 Predictions Max         -8.13439
trainer/Q1 Predictions Min       -109.839
trainer/Q2 Predictions Mean       -34.6535
trainer/Q2 Predictions Std         33.4744
trainer/Q2 Predictions Max         -8.15064
trainer/Q2 Predictions Min       -109.561
trainer/Q Targets Mean            -35.0504
trainer/Q Targets Std              33.9044
trainer/Q Targets Max              -8.16028
trainer/Q Targets Min            -111.093
trainer/Log Pis Mean                2.08711
trainer/Log Pis Std                 1.14791
trainer/Log Pis Max                 6.62188
trainer/Log Pis Min                -0.787176
trainer/Policy mu Mean              0.018428
trainer/Policy mu Std               0.524083
trainer/Policy mu Max               3.31103
trainer/Policy mu Min              -3.57875
trainer/Policy log std Mean        -2.24883
trainer/Policy log std Std          0.44405
trainer/Policy log std Max         -0.0734201
trainer/Policy log std Min         -3.02737
trainer/Alpha                       0.0808674
trainer/Alpha Loss                  0.21909
exploration/num steps total    168700
exploration/num paths total      1687
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.584152
exploration/Rewards Std             1.02025
exploration/Rewards Max            -0.00437671
exploration/Rewards Min           -10.2013
exploration/Returns Mean          -58.4152
exploration/Returns Std            46.2089
exploration/Returns Max           -22.411
exploration/Returns Min          -141.89
exploration/Actions Mean            0.0223456
exploration/Actions Std             0.22045
exploration/Actions Max             0.999682
exploration/Actions Min            -0.947472
exploration/Num Paths               5
exploration/Average Returns       -58.4152
evaluation/num steps total     505500
evaluation/num paths total       5055
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.893466
evaluation/Rewards Std              1.17929
evaluation/Rewards Max             -0.0343261
evaluation/Rewards Min            -10.6838
evaluation/Returns Mean           -89.3466
evaluation/Returns Std             76.9582
evaluation/Returns Max            -12.6355
evaluation/Returns Min           -256.392
evaluation/Actions Mean             0.00244486
evaluation/Actions Std              0.18135
evaluation/Actions Max              0.998858
evaluation/Actions Min             -0.997773
evaluation/Num Paths               15
evaluation/Average Returns        -89.3466
time/data storing (s)               0.00270704
time/evaluation sampling (s)        0.32782
time/exploration sampling (s)       0.14077
time/logging (s)                    0.00481346
time/saving (s)                     0.00199526
time/training (s)                   1.96195
time/epoch (s)                      2.44006
time/total (s)                    820.427
Epoch                             336
-----------------------------  ---------------
2019-04-23 00:07:02.888441 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 337 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.59602
trainer/QF2 Loss                    3.54709
trainer/Policy Loss                31.0856
trainer/Q1 Predictions Mean       -29.1063
trainer/Q1 Predictions Std         28.2146
trainer/Q1 Predictions Max         -7.76991
trainer/Q1 Predictions Min       -108.588
trainer/Q2 Predictions Mean       -29.0553
trainer/Q2 Predictions Std         28.182
trainer/Q2 Predictions Max         -7.85795
trainer/Q2 Predictions Min       -108.581
trainer/Q Targets Mean            -29.3321
trainer/Q Targets Std              28.6911
trainer/Q Targets Max              -0.907866
trainer/Q Targets Min            -109.919
trainer/Log Pis Mean                2.06923
trainer/Log Pis Std                 1.33492
trainer/Log Pis Max                 6.87176
trainer/Log Pis Min                -4.14165
trainer/Policy mu Mean             -0.0087576
trainer/Policy mu Std               0.553586
trainer/Policy mu Max               2.81797
trainer/Policy mu Min              -3.1268
trainer/Policy log std Mean        -2.26646
trainer/Policy log std Std          0.471931
trainer/Policy log std Max         -0.540371
trainer/Policy log std Min         -2.89416
trainer/Alpha                       0.0796623
trainer/Alpha Loss                  0.175155
exploration/num steps total    169200
exploration/num paths total      1692
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.686432
exploration/Rewards Std             1.05145
exploration/Rewards Max            -0.00727744
exploration/Rewards Min            -8.38224
exploration/Returns Mean          -68.6432
exploration/Returns Std            87.9062
exploration/Returns Max           -13.8296
exploration/Returns Min          -244.029
exploration/Actions Mean            0.000640253
exploration/Actions Std             0.198899
exploration/Actions Max             0.998737
exploration/Actions Min            -0.997252
exploration/Num Paths               5
exploration/Average Returns       -68.6432
evaluation/num steps total     507000
evaluation/num paths total       5070
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.853078
evaluation/Rewards Std              1.14113
evaluation/Rewards Max             -0.00586034
evaluation/Rewards Min             -9.10062
evaluation/Returns Mean           -85.3078
evaluation/Returns Std             82.406
evaluation/Returns Max             -5.415
evaluation/Returns Min           -251.897
evaluation/Actions Mean            -0.00775498
evaluation/Actions Std              0.174967
evaluation/Actions Max              0.996922
evaluation/Actions Min             -0.998305
evaluation/Num Paths               15
evaluation/Average Returns        -85.3078
time/data storing (s)               0.00261724
time/evaluation sampling (s)        0.329347
time/exploration sampling (s)       0.145852
time/logging (s)                    0.00478259
time/saving (s)                     0.00198306
time/training (s)                   1.9475
time/epoch (s)                      2.43208
time/total (s)                    822.864
Epoch                             337
-----------------------------  ----------------
2019-04-23 00:07:05.330732 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 338 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.71294
trainer/QF2 Loss                    1.7087
trainer/Policy Loss                38.021
trainer/Q1 Predictions Mean       -36.4105
trainer/Q1 Predictions Std         36.6262
trainer/Q1 Predictions Max         -8.0471
trainer/Q1 Predictions Min       -130.47
trainer/Q2 Predictions Mean       -36.4241
trainer/Q2 Predictions Std         36.6652
trainer/Q2 Predictions Max         -8.03682
trainer/Q2 Predictions Min       -131.906
trainer/Q Targets Mean            -36.4705
trainer/Q Targets Std              36.981
trainer/Q Targets Max              -1.51638
trainer/Q Targets Min            -129.936
trainer/Log Pis Mean                1.70319
trainer/Log Pis Std                 1.26798
trainer/Log Pis Max                 3.94691
trainer/Log Pis Min                -4.00228
trainer/Policy mu Mean             -0.0649384
trainer/Policy mu Std               0.469878
trainer/Policy mu Max               1.99696
trainer/Policy mu Min              -2.69998
trainer/Policy log std Mean        -2.22357
trainer/Policy log std Std          0.454029
trainer/Policy log std Max         -0.372556
trainer/Policy log std Min         -2.85896
trainer/Alpha                       0.0816201
trainer/Alpha Loss                 -0.743684
exploration/num steps total    169700
exploration/num paths total      1697
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.638757
exploration/Rewards Std             0.891595
exploration/Rewards Max            -0.00560669
exploration/Rewards Min            -8.63027
exploration/Returns Mean          -63.8757
exploration/Returns Std            37.1175
exploration/Returns Max           -18.5281
exploration/Returns Min          -108.484
exploration/Actions Mean            0.00782354
exploration/Actions Std             0.206769
exploration/Actions Max             0.993373
exploration/Actions Min            -0.999678
exploration/Num Paths               5
exploration/Average Returns       -63.8757
evaluation/num steps total     508500
evaluation/num paths total       5085
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.673269
evaluation/Rewards Std              1.08833
evaluation/Rewards Max             -0.010855
evaluation/Rewards Min             -8.73522
evaluation/Returns Mean           -67.3269
evaluation/Returns Std             66.8437
evaluation/Returns Max             -7.19151
evaluation/Returns Min           -239.28
evaluation/Actions Mean             0.0035963
evaluation/Actions Std              0.189255
evaluation/Actions Max              0.997489
evaluation/Actions Min             -0.998598
evaluation/Num Paths               15
evaluation/Average Returns        -67.3269
time/data storing (s)               0.00301995
time/evaluation sampling (s)        0.331407
time/exploration sampling (s)       0.140342
time/logging (s)                    0.00478197
time/saving (s)                     0.0019733
time/training (s)                   1.95189
time/epoch (s)                      2.43341
time/total (s)                    825.301
Epoch                             338
-----------------------------  ---------------
2019-04-23 00:07:07.759240 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 339 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   33.5676
trainer/QF2 Loss                   33.2262
trainer/Policy Loss                38.1926
trainer/Q1 Predictions Mean       -36.1677
trainer/Q1 Predictions Std         32.7942
trainer/Q1 Predictions Max         -8.11375
trainer/Q1 Predictions Min       -110.484
trainer/Q2 Predictions Mean       -36.1201
trainer/Q2 Predictions Std         32.808
trainer/Q2 Predictions Max         -8.10779
trainer/Q2 Predictions Min       -110.566
trainer/Q Targets Mean            -35.642
trainer/Q Targets Std              33.2511
trainer/Q Targets Max              -0.204002
trainer/Q Targets Min            -111.367
trainer/Log Pis Mean                2.09964
trainer/Log Pis Std                 1.17922
trainer/Log Pis Max                 7.11688
trainer/Log Pis Min                -0.689707
trainer/Policy mu Mean              0.0447679
trainer/Policy mu Std               0.566317
trainer/Policy mu Max               3.20362
trainer/Policy mu Min              -2.95933
trainer/Policy log std Mean        -2.21985
trainer/Policy log std Std          0.443136
trainer/Policy log std Max         -0.316068
trainer/Policy log std Min         -2.93758
trainer/Alpha                       0.0818053
trainer/Alpha Loss                  0.24944
exploration/num steps total    170200
exploration/num paths total      1702
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.44029
exploration/Rewards Std             1.30362
exploration/Rewards Max            -0.0260992
exploration/Rewards Min           -10.1944
exploration/Returns Mean         -144.029
exploration/Returns Std            84.8648
exploration/Returns Max           -35.8101
exploration/Returns Min          -239.643
exploration/Actions Mean            0.0217791
exploration/Actions Std             0.213046
exploration/Actions Max             0.999572
exploration/Actions Min            -0.994321
exploration/Num Paths               5
exploration/Average Returns      -144.029
evaluation/num steps total     510000
evaluation/num paths total       5100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.556505
evaluation/Rewards Std              1.12376
evaluation/Rewards Max             -0.00949644
evaluation/Rewards Min            -11.0161
evaluation/Returns Mean           -55.6505
evaluation/Returns Std             64.9938
evaluation/Returns Max             -4.34555
evaluation/Returns Min           -232.274
evaluation/Actions Mean             0.00225642
evaluation/Actions Std              0.176815
evaluation/Actions Max              0.999277
evaluation/Actions Min             -0.998718
evaluation/Num Paths               15
evaluation/Average Returns        -55.6505
time/data storing (s)               0.00265017
time/evaluation sampling (s)        0.330289
time/exploration sampling (s)       0.136775
time/logging (s)                    0.00476763
time/saving (s)                     0.00159683
time/training (s)                   1.94291
time/epoch (s)                      2.41899
time/total (s)                    827.725
Epoch                             339
-----------------------------  ---------------
2019-04-23 00:07:10.194547 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 340 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.15644
trainer/QF2 Loss                    0.179969
trainer/Policy Loss                27.9273
trainer/Q1 Predictions Mean       -25.9293
trainer/Q1 Predictions Std         28.6269
trainer/Q1 Predictions Max         -8.04389
trainer/Q1 Predictions Min       -128.258
trainer/Q2 Predictions Mean       -25.9328
trainer/Q2 Predictions Std         28.6744
trainer/Q2 Predictions Max         -7.99714
trainer/Q2 Predictions Min       -129.609
trainer/Q Targets Mean            -26.1231
trainer/Q Targets Std              28.796
trainer/Q Targets Max              -8.16756
trainer/Q Targets Min            -128.56
trainer/Log Pis Mean                2.10502
trainer/Log Pis Std                 1.27778
trainer/Log Pis Max                 6.20448
trainer/Log Pis Min                -2.30855
trainer/Policy mu Mean             -0.0129276
trainer/Policy mu Std               0.531867
trainer/Policy mu Max               2.87056
trainer/Policy mu Min              -2.63095
trainer/Policy log std Mean        -2.25782
trainer/Policy log std Std          0.454053
trainer/Policy log std Max         -0.631678
trainer/Policy log std Min         -3.16038
trainer/Alpha                       0.0824971
trainer/Alpha Loss                  0.262033
exploration/num steps total    170700
exploration/num paths total      1707
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.79656
exploration/Rewards Std             1.10379
exploration/Rewards Max            -0.0194108
exploration/Rewards Min            -9.56522
exploration/Returns Mean          -79.656
exploration/Returns Std            43.7613
exploration/Returns Max           -24.382
exploration/Returns Min          -150.047
exploration/Actions Mean            0.0100061
exploration/Actions Std             0.229006
exploration/Actions Max             0.999146
exploration/Actions Min            -0.989378
exploration/Num Paths               5
exploration/Average Returns       -79.656
evaluation/num steps total     511500
evaluation/num paths total       5115
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.680253
evaluation/Rewards Std              0.918074
evaluation/Rewards Max             -0.0362087
evaluation/Rewards Min             -8.15199
evaluation/Returns Mean           -68.0253
evaluation/Returns Std             55.2768
evaluation/Returns Max             -8.65664
evaluation/Returns Min           -158.475
evaluation/Actions Mean             0.00220798
evaluation/Actions Std              0.180203
evaluation/Actions Max              0.99794
evaluation/Actions Min             -0.998127
evaluation/Num Paths               15
evaluation/Average Returns        -68.0253
time/data storing (s)               0.0027853
time/evaluation sampling (s)        0.331617
time/exploration sampling (s)       0.139812
time/logging (s)                    0.00427423
time/saving (s)                     0.00158279
time/training (s)                   1.94522
time/epoch (s)                      2.42529
time/total (s)                    830.154
Epoch                             340
-----------------------------  ---------------
2019-04-23 00:07:12.634561 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 341 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.203982
trainer/QF2 Loss                    0.215928
trainer/Policy Loss                30.7098
trainer/Q1 Predictions Mean       -28.8474
trainer/Q1 Predictions Std         31.1218
trainer/Q1 Predictions Max         -8.15342
trainer/Q1 Predictions Min       -111.269
trainer/Q2 Predictions Mean       -28.8202
trainer/Q2 Predictions Std         31.141
trainer/Q2 Predictions Max         -8.07932
trainer/Q2 Predictions Min       -111.3
trainer/Q Targets Mean            -28.9801
trainer/Q Targets Std              31.4418
trainer/Q Targets Max              -8.183
trainer/Q Targets Min            -111.168
trainer/Log Pis Mean                2.03391
trainer/Log Pis Std                 1.03743
trainer/Log Pis Max                 5.3891
trainer/Log Pis Min                 0.0945976
trainer/Policy mu Mean              0.00765772
trainer/Policy mu Std               0.513434
trainer/Policy mu Max               2.53999
trainer/Policy mu Min              -3.1199
trainer/Policy log std Mean        -2.27562
trainer/Policy log std Std          0.464277
trainer/Policy log std Max         -0.307525
trainer/Policy log std Min         -3.12214
trainer/Alpha                       0.083184
trainer/Alpha Loss                  0.0843239
exploration/num steps total    171200
exploration/num paths total      1712
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.756229
exploration/Rewards Std             1.22685
exploration/Rewards Max            -0.00883241
exploration/Rewards Min           -10.0565
exploration/Returns Mean          -75.6229
exploration/Returns Std            72.7204
exploration/Returns Max           -25.769
exploration/Returns Min          -217.881
exploration/Actions Mean           -0.0087249
exploration/Actions Std             0.218903
exploration/Actions Max             0.999032
exploration/Actions Min            -0.99991
exploration/Num Paths               5
exploration/Average Returns       -75.6229
evaluation/num steps total     513000
evaluation/num paths total       5130
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.922099
evaluation/Rewards Std              0.902918
evaluation/Rewards Max             -0.0662089
evaluation/Rewards Min             -9.0888
evaluation/Returns Mean           -92.2099
evaluation/Returns Std             74.9129
evaluation/Returns Max             -8.594
evaluation/Returns Min           -236.064
evaluation/Actions Mean            -0.00282623
evaluation/Actions Std              0.151471
evaluation/Actions Max              0.997968
evaluation/Actions Min             -0.997205
evaluation/Num Paths               15
evaluation/Average Returns        -92.2099
time/data storing (s)               0.0025783
time/evaluation sampling (s)        0.329081
time/exploration sampling (s)       0.135854
time/logging (s)                    0.00354828
time/saving (s)                     0.0106862
time/training (s)                   1.94808
time/epoch (s)                      2.42983
time/total (s)                    832.588
Epoch                             341
-----------------------------  ---------------
2019-04-23 00:07:15.055848 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 342 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.78847
trainer/QF2 Loss                    1.72052
trainer/Policy Loss                33.4057
trainer/Q1 Predictions Mean       -31.7688
trainer/Q1 Predictions Std         33.6325
trainer/Q1 Predictions Max         -8.04681
trainer/Q1 Predictions Min       -111.309
trainer/Q2 Predictions Mean       -31.7416
trainer/Q2 Predictions Std         33.6146
trainer/Q2 Predictions Max         -8.00984
trainer/Q2 Predictions Min       -111.252
trainer/Q Targets Mean            -31.7492
trainer/Q Targets Std              33.9815
trainer/Q Targets Max              -0.238243
trainer/Q Targets Min            -112.169
trainer/Log Pis Mean                1.79969
trainer/Log Pis Std                 1.19788
trainer/Log Pis Max                 4.63667
trainer/Log Pis Min                -2.52248
trainer/Policy mu Mean             -0.0450682
trainer/Policy mu Std               0.485447
trainer/Policy mu Max               2.60308
trainer/Policy mu Min              -1.80559
trainer/Policy log std Mean        -2.15785
trainer/Policy log std Std          0.425763
trainer/Policy log std Max         -0.487598
trainer/Policy log std Min         -2.97072
trainer/Alpha                       0.0820365
trainer/Alpha Loss                 -0.500886
exploration/num steps total    171700
exploration/num paths total      1717
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.741061
exploration/Rewards Std             0.807696
exploration/Rewards Max            -0.0213801
exploration/Rewards Min            -6.43596
exploration/Returns Mean          -74.1061
exploration/Returns Std            47.807
exploration/Returns Max           -26.2587
exploration/Returns Min          -146.094
exploration/Actions Mean            0.0130035
exploration/Actions Std             0.232062
exploration/Actions Max             0.994579
exploration/Actions Min            -0.994543
exploration/Num Paths               5
exploration/Average Returns       -74.1061
evaluation/num steps total     514500
evaluation/num paths total       5145
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.584605
evaluation/Rewards Std              0.996171
evaluation/Rewards Max             -0.0113567
evaluation/Rewards Min            -10.3259
evaluation/Returns Mean           -58.4605
evaluation/Returns Std             46.7158
evaluation/Returns Max             -1.67921
evaluation/Returns Min           -139.457
evaluation/Actions Mean            -0.012627
evaluation/Actions Std              0.179035
evaluation/Actions Max              0.995125
evaluation/Actions Min             -0.999902
evaluation/Num Paths               15
evaluation/Average Returns        -58.4605
time/data storing (s)               0.00271926
time/evaluation sampling (s)        0.322536
time/exploration sampling (s)       0.140212
time/logging (s)                    0.0047877
time/saving (s)                     0.00196989
time/training (s)                   1.94235
time/epoch (s)                      2.41457
time/total (s)                    835.007
Epoch                             342
-----------------------------  ---------------
2019-04-23 00:07:17.498558 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 343 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.448155
trainer/QF2 Loss                    0.416717
trainer/Policy Loss                38.3368
trainer/Q1 Predictions Mean       -36.5731
trainer/Q1 Predictions Std         33.7267
trainer/Q1 Predictions Max         -8.12528
trainer/Q1 Predictions Min       -109.824
trainer/Q2 Predictions Mean       -36.5301
trainer/Q2 Predictions Std         33.7695
trainer/Q2 Predictions Max         -8.04272
trainer/Q2 Predictions Min       -109.957
trainer/Q Targets Mean            -36.8677
trainer/Q Targets Std              34.0784
trainer/Q Targets Max              -8.12129
trainer/Q Targets Min            -111.246
trainer/Log Pis Mean                1.91748
trainer/Log Pis Std                 1.23635
trainer/Log Pis Max                 8.17416
trainer/Log Pis Min                -1.34249
trainer/Policy mu Mean              0.00776097
trainer/Policy mu Std               0.480802
trainer/Policy mu Max               2.84441
trainer/Policy mu Min              -2.37407
trainer/Policy log std Mean        -2.23526
trainer/Policy log std Std          0.449283
trainer/Policy log std Max         -0.466862
trainer/Policy log std Min         -3.12974
trainer/Alpha                       0.0842041
trainer/Alpha Loss                 -0.204205
exploration/num steps total    172200
exploration/num paths total      1722
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43498
exploration/Rewards Std             1.10761
exploration/Rewards Max            -0.0127875
exploration/Rewards Min            -8.26777
exploration/Returns Mean          -43.498
exploration/Returns Std            13.9791
exploration/Returns Max           -22.9069
exploration/Returns Min           -56.7839
exploration/Actions Mean            0.00427624
exploration/Actions Std             0.226558
exploration/Actions Max             0.999386
exploration/Actions Min            -0.997838
exploration/Num Paths               5
exploration/Average Returns       -43.498
evaluation/num steps total     516000
evaluation/num paths total       5160
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.625899
evaluation/Rewards Std              1.0083
evaluation/Rewards Max             -0.0538626
evaluation/Rewards Min            -10.4815
evaluation/Returns Mean           -62.5899
evaluation/Returns Std             59.386
evaluation/Returns Max             -6.4481
evaluation/Returns Min           -218.323
evaluation/Actions Mean             0.00882555
evaluation/Actions Std              0.168977
evaluation/Actions Max              0.999097
evaluation/Actions Min             -0.994971
evaluation/Num Paths               15
evaluation/Average Returns        -62.5899
time/data storing (s)               0.00263923
time/evaluation sampling (s)        0.327859
time/exploration sampling (s)       0.139285
time/logging (s)                    0.00480459
time/saving (s)                     0.00173705
time/training (s)                   1.95711
time/epoch (s)                      2.43343
time/total (s)                    837.445
Epoch                             343
-----------------------------  ---------------
2019-04-23 00:07:19.923368 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 344 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.11087
trainer/QF2 Loss                    3.13465
trainer/Policy Loss                33.8254
trainer/Q1 Predictions Mean       -32.0087
trainer/Q1 Predictions Std         34.0163
trainer/Q1 Predictions Max         -8.19064
trainer/Q1 Predictions Min       -110.766
trainer/Q2 Predictions Mean       -32.0128
trainer/Q2 Predictions Std         33.9673
trainer/Q2 Predictions Max         -8.27376
trainer/Q2 Predictions Min       -110.654
trainer/Q Targets Mean            -31.9978
trainer/Q Targets Std              34.0852
trainer/Q Targets Max              -0.418172
trainer/Q Targets Min            -110.489
trainer/Log Pis Mean                1.90587
trainer/Log Pis Std                 1.11602
trainer/Log Pis Max                 7.17303
trainer/Log Pis Min                -2.41927
trainer/Policy mu Mean             -0.0233865
trainer/Policy mu Std               0.566657
trainer/Policy mu Max               3.4823
trainer/Policy mu Min              -3.25845
trainer/Policy log std Mean        -2.16772
trainer/Policy log std Std          0.467684
trainer/Policy log std Max         -0.19399
trainer/Policy log std Min         -3.01051
trainer/Alpha                       0.0855726
trainer/Alpha Loss                 -0.23141
exploration/num steps total    172700
exploration/num paths total      1727
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.11167
exploration/Rewards Std             0.779951
exploration/Rewards Max            -0.0156033
exploration/Rewards Min            -9.35735
exploration/Returns Mean         -111.167
exploration/Returns Std            47.9128
exploration/Returns Max           -15.8207
exploration/Returns Min          -138.556
exploration/Actions Mean            0.0143536
exploration/Actions Std             0.207267
exploration/Actions Max             0.998747
exploration/Actions Min            -0.966029
exploration/Num Paths               5
exploration/Average Returns      -111.167
evaluation/num steps total     517500
evaluation/num paths total       5175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.860414
evaluation/Rewards Std              1.17636
evaluation/Rewards Max             -0.0345427
evaluation/Rewards Min             -9.66398
evaluation/Returns Mean           -86.0414
evaluation/Returns Std             87.8297
evaluation/Returns Max            -16.2584
evaluation/Returns Min           -261.434
evaluation/Actions Mean            -0.00318752
evaluation/Actions Std              0.185319
evaluation/Actions Max              0.996899
evaluation/Actions Min             -0.997642
evaluation/Num Paths               15
evaluation/Average Returns        -86.0414
time/data storing (s)               0.00266885
time/evaluation sampling (s)        0.322071
time/exploration sampling (s)       0.133898
time/logging (s)                    0.00475373
time/saving (s)                     0.00196319
time/training (s)                   1.94954
time/epoch (s)                      2.4149
time/total (s)                    839.865
Epoch                             344
-----------------------------  ---------------
2019-04-23 00:07:22.356879 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 345 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.20461
trainer/QF2 Loss                    1.2208
trainer/Policy Loss                31.5602
trainer/Q1 Predictions Mean       -29.758
trainer/Q1 Predictions Std         31.8316
trainer/Q1 Predictions Max         -8.21872
trainer/Q1 Predictions Min       -108.504
trainer/Q2 Predictions Mean       -29.7208
trainer/Q2 Predictions Std         31.8619
trainer/Q2 Predictions Max         -8.1644
trainer/Q2 Predictions Min       -108.516
trainer/Q Targets Mean            -30.0926
trainer/Q Targets Std              32.3503
trainer/Q Targets Max              -0.199175
trainer/Q Targets Min            -109.877
trainer/Log Pis Mean                1.90438
trainer/Log Pis Std                 1.07992
trainer/Log Pis Max                 3.98413
trainer/Log Pis Min                -1.62784
trainer/Policy mu Mean             -0.0039801
trainer/Policy mu Std               0.339599
trainer/Policy mu Max               2.75805
trainer/Policy mu Min              -2.75953
trainer/Policy log std Mean        -2.32025
trainer/Policy log std Std          0.379094
trainer/Policy log std Max         -0.584075
trainer/Policy log std Min         -2.99233
trainer/Alpha                       0.0841667
trainer/Alpha Loss                 -0.236632
exploration/num steps total    173200
exploration/num paths total      1732
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.695628
exploration/Rewards Std             0.823861
exploration/Rewards Max            -0.00480239
exploration/Rewards Min            -7.34393
exploration/Returns Mean          -69.5628
exploration/Returns Std            50.1861
exploration/Returns Max           -17.5567
exploration/Returns Min          -152.406
exploration/Actions Mean            0.000711991
exploration/Actions Std             0.203198
exploration/Actions Max             0.998764
exploration/Actions Min            -0.998775
exploration/Num Paths               5
exploration/Average Returns       -69.5628
evaluation/num steps total     519000
evaluation/num paths total       5190
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.782203
evaluation/Rewards Std              1.11613
evaluation/Rewards Max             -0.00860479
evaluation/Rewards Min            -11.4599
evaluation/Returns Mean           -78.2203
evaluation/Returns Std             73.2042
evaluation/Returns Max             -3.35627
evaluation/Returns Min           -234.266
evaluation/Actions Mean            -0.0033948
evaluation/Actions Std              0.171879
evaluation/Actions Max              0.992418
evaluation/Actions Min             -0.999716
evaluation/Num Paths               15
evaluation/Average Returns        -78.2203
time/data storing (s)               0.00259787
time/evaluation sampling (s)        0.318309
time/exploration sampling (s)       0.137949
time/logging (s)                    0.00373048
time/saving (s)                     0.00173498
time/training (s)                   1.95867
time/epoch (s)                      2.423
time/total (s)                    842.292
Epoch                             345
-----------------------------  ----------------
2019-04-23 00:07:24.769976 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 346 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.84059
trainer/QF2 Loss                    3.88542
trainer/Policy Loss                34.985
trainer/Q1 Predictions Mean       -33.176
trainer/Q1 Predictions Std         34.2261
trainer/Q1 Predictions Max         -8.27499
trainer/Q1 Predictions Min       -124.339
trainer/Q2 Predictions Mean       -33.1601
trainer/Q2 Predictions Std         34.2124
trainer/Q2 Predictions Max         -8.14741
trainer/Q2 Predictions Min       -123.164
trainer/Q Targets Mean            -33.576
trainer/Q Targets Std              35.0382
trainer/Q Targets Max              -0.291697
trainer/Q Targets Min            -125.215
trainer/Log Pis Mean                1.89329
trainer/Log Pis Std                 1.44261
trainer/Log Pis Max                 4.78766
trainer/Log Pis Min                -6.2504
trainer/Policy mu Mean              0.0582876
trainer/Policy mu Std               0.4924
trainer/Policy mu Max               2.96003
trainer/Policy mu Min              -2.76173
trainer/Policy log std Mean        -2.27043
trainer/Policy log std Std          0.458556
trainer/Policy log std Max         -0.474228
trainer/Policy log std Min         -3.02828
trainer/Alpha                       0.0840608
trainer/Alpha Loss                 -0.264234
exploration/num steps total    173700
exploration/num paths total      1737
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.508992
exploration/Rewards Std             0.814239
exploration/Rewards Max            -0.00446572
exploration/Rewards Min            -9.22806
exploration/Returns Mean          -50.8992
exploration/Returns Std            26.8517
exploration/Returns Max           -29.4879
exploration/Returns Min          -102.116
exploration/Actions Mean           -0.00104986
exploration/Actions Std             0.203736
exploration/Actions Max             0.999481
exploration/Actions Min            -0.999386
exploration/Num Paths               5
exploration/Average Returns       -50.8992
evaluation/num steps total     520500
evaluation/num paths total       5205
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.621778
evaluation/Rewards Std              1.12434
evaluation/Rewards Max             -0.0028237
evaluation/Rewards Min            -10.3959
evaluation/Returns Mean           -62.1778
evaluation/Returns Std             65.9697
evaluation/Returns Max            -12.6424
evaluation/Returns Min           -261.954
evaluation/Actions Mean            -0.0157266
evaluation/Actions Std              0.196422
evaluation/Actions Max              0.995664
evaluation/Actions Min             -0.999311
evaluation/Num Paths               15
evaluation/Average Returns        -62.1778
time/data storing (s)               0.00268054
time/evaluation sampling (s)        0.326622
time/exploration sampling (s)       0.136289
time/logging (s)                    0.00485639
time/saving (s)                     0.00197561
time/training (s)                   1.93216
time/epoch (s)                      2.40459
time/total (s)                    844.701
Epoch                             346
-----------------------------  ---------------
2019-04-23 00:07:27.206384 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 347 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.920046
trainer/QF2 Loss                    1.05806
trainer/Policy Loss                35.7811
trainer/Q1 Predictions Mean       -33.9279
trainer/Q1 Predictions Std         34.5794
trainer/Q1 Predictions Max         -8.04736
trainer/Q1 Predictions Min       -110.077
trainer/Q2 Predictions Mean       -33.8681
trainer/Q2 Predictions Std         34.5321
trainer/Q2 Predictions Max         -7.92921
trainer/Q2 Predictions Min       -109.645
trainer/Q Targets Mean            -34.6506
trainer/Q Targets Std              35.0989
trainer/Q Targets Max              -8.27055
trainer/Q Targets Min            -111.478
trainer/Log Pis Mean                1.94855
trainer/Log Pis Std                 1.07604
trainer/Log Pis Max                 6.12758
trainer/Log Pis Min                -1.4127
trainer/Policy mu Mean              0.00197744
trainer/Policy mu Std               0.489889
trainer/Policy mu Max               3.13573
trainer/Policy mu Min              -2.60133
trainer/Policy log std Mean        -2.22453
trainer/Policy log std Std          0.452072
trainer/Policy log std Max         -0.589238
trainer/Policy log std Min         -2.96079
trainer/Alpha                       0.0822266
trainer/Alpha Loss                 -0.128532
exploration/num steps total    174200
exploration/num paths total      1742
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.721416
exploration/Rewards Std             1.08999
exploration/Rewards Max            -0.0181495
exploration/Rewards Min            -8.73937
exploration/Returns Mean          -72.1416
exploration/Returns Std            83.7167
exploration/Returns Max           -22.2613
exploration/Returns Min          -238.229
exploration/Actions Mean            0.00145302
exploration/Actions Std             0.196985
exploration/Actions Max             0.999306
exploration/Actions Min            -0.984497
exploration/Num Paths               5
exploration/Average Returns       -72.1416
evaluation/num steps total     522000
evaluation/num paths total       5220
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.734352
evaluation/Rewards Std              1.19178
evaluation/Rewards Max             -0.0207811
evaluation/Rewards Min             -9.84901
evaluation/Returns Mean           -73.4352
evaluation/Returns Std             80.5361
evaluation/Returns Max             -6.52459
evaluation/Returns Min           -266.723
evaluation/Actions Mean            -0.00921167
evaluation/Actions Std              0.189078
evaluation/Actions Max              0.998067
evaluation/Actions Min             -0.999042
evaluation/Num Paths               15
evaluation/Average Returns        -73.4352
time/data storing (s)               0.00276204
time/evaluation sampling (s)        0.325125
time/exploration sampling (s)       0.137261
time/logging (s)                    0.00474632
time/saving (s)                     0.0015685
time/training (s)                   1.95531
time/epoch (s)                      2.42678
time/total (s)                    847.133
Epoch                             347
-----------------------------  ---------------
2019-04-23 00:07:29.651689 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 348 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.8659
trainer/QF2 Loss                    3.74146
trainer/Policy Loss                34.9802
trainer/Q1 Predictions Mean       -33.1649
trainer/Q1 Predictions Std         32.071
trainer/Q1 Predictions Max         -7.64983
trainer/Q1 Predictions Min       -106.426
trainer/Q2 Predictions Mean       -33.1563
trainer/Q2 Predictions Std         32.0964
trainer/Q2 Predictions Max         -7.57914
trainer/Q2 Predictions Min       -106.454
trainer/Q Targets Mean            -33.7119
trainer/Q Targets Std              32.9604
trainer/Q Targets Max              -0.0406703
trainer/Q Targets Min            -110.646
trainer/Log Pis Mean                1.92675
trainer/Log Pis Std                 1.22711
trainer/Log Pis Max                 6.26301
trainer/Log Pis Min                -4.01652
trainer/Policy mu Mean              0.0154196
trainer/Policy mu Std               0.450536
trainer/Policy mu Max               2.72006
trainer/Policy mu Min              -1.11996
trainer/Policy log std Mean        -2.18377
trainer/Policy log std Std          0.445577
trainer/Policy log std Max         -0.550632
trainer/Policy log std Min         -2.96696
trainer/Alpha                       0.0826599
trainer/Alpha Loss                 -0.182616
exploration/num steps total    174700
exploration/num paths total      1747
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.819718
exploration/Rewards Std             1.31295
exploration/Rewards Max            -0.00823711
exploration/Rewards Min           -10.526
exploration/Returns Mean          -81.9718
exploration/Returns Std            74.3556
exploration/Returns Max           -26.1325
exploration/Returns Min          -228.559
exploration/Actions Mean            0.0195735
exploration/Actions Std             0.243516
exploration/Actions Max             0.999361
exploration/Actions Min            -0.999971
exploration/Num Paths               5
exploration/Average Returns       -81.9718
evaluation/num steps total     523500
evaluation/num paths total       5235
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.924319
evaluation/Rewards Std              1.23632
evaluation/Rewards Max             -0.0173847
evaluation/Rewards Min             -9.50715
evaluation/Returns Mean           -92.4319
evaluation/Returns Std             66.0173
evaluation/Returns Max            -22.0845
evaluation/Returns Min           -250.8
evaluation/Actions Mean             0.00107624
evaluation/Actions Std              0.202342
evaluation/Actions Max              0.99907
evaluation/Actions Min             -0.99926
evaluation/Num Paths               15
evaluation/Average Returns        -92.4319
time/data storing (s)               0.00277617
time/evaluation sampling (s)        0.326877
time/exploration sampling (s)       0.1366
time/logging (s)                    0.00389534
time/saving (s)                     0.00198696
time/training (s)                   1.96296
time/epoch (s)                      2.4351
time/total (s)                    849.572
Epoch                             348
-----------------------------  ---------------
2019-04-23 00:07:32.110900 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 349 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.22593
trainer/QF2 Loss                    1.23969
trainer/Policy Loss                32.8231
trainer/Q1 Predictions Mean       -30.8052
trainer/Q1 Predictions Std         34.7957
trainer/Q1 Predictions Max         -8.19487
trainer/Q1 Predictions Min       -108.795
trainer/Q2 Predictions Mean       -30.8064
trainer/Q2 Predictions Std         34.798
trainer/Q2 Predictions Max         -8.11227
trainer/Q2 Predictions Min       -108.566
trainer/Q Targets Mean            -30.9731
trainer/Q Targets Std              35.3182
trainer/Q Targets Max              -0.0665051
trainer/Q Targets Min            -110.072
trainer/Log Pis Mean                2.15091
trainer/Log Pis Std                 1.20728
trainer/Log Pis Max                 8.67987
trainer/Log Pis Min                -1.64215
trainer/Policy mu Mean             -0.0473853
trainer/Policy mu Std               0.456199
trainer/Policy mu Max               3.36973
trainer/Policy mu Min              -2.66961
trainer/Policy log std Mean        -2.29366
trainer/Policy log std Std          0.431751
trainer/Policy log std Max         -0.519012
trainer/Policy log std Min         -3.09755
trainer/Alpha                       0.0788175
trainer/Alpha Loss                  0.383409
exploration/num steps total    175200
exploration/num paths total      1752
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.610623
exploration/Rewards Std             0.963265
exploration/Rewards Max            -0.0491923
exploration/Rewards Min            -7.86031
exploration/Returns Mean          -61.0623
exploration/Returns Std            27.6424
exploration/Returns Max           -38.2297
exploration/Returns Min          -115.206
exploration/Actions Mean           -0.00207672
exploration/Actions Std             0.231901
exploration/Actions Max             0.998088
exploration/Actions Min            -0.999077
exploration/Num Paths               5
exploration/Average Returns       -61.0623
evaluation/num steps total     525000
evaluation/num paths total       5250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.482235
evaluation/Rewards Std              1.0104
evaluation/Rewards Max             -0.0112542
evaluation/Rewards Min            -11.1638
evaluation/Returns Mean           -48.2235
evaluation/Returns Std             41.5653
evaluation/Returns Max             -7.89057
evaluation/Returns Min           -145.563
evaluation/Actions Mean             0.00374072
evaluation/Actions Std              0.188453
evaluation/Actions Max              0.996889
evaluation/Actions Min             -0.998971
evaluation/Num Paths               15
evaluation/Average Returns        -48.2235
time/data storing (s)               0.00261554
time/evaluation sampling (s)        0.326802
time/exploration sampling (s)       0.146112
time/logging (s)                    0.0047716
time/saving (s)                     0.0019547
time/training (s)                   1.96815
time/epoch (s)                      2.45041
time/total (s)                    852.027
Epoch                             349
-----------------------------  ---------------
2019-04-23 00:07:34.540329 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 350 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.40374
trainer/QF2 Loss                    1.389
trainer/Policy Loss                40.7684
trainer/Q1 Predictions Mean       -38.8027
trainer/Q1 Predictions Std         36.9945
trainer/Q1 Predictions Max         -8.18702
trainer/Q1 Predictions Min       -111.196
trainer/Q2 Predictions Mean       -38.8056
trainer/Q2 Predictions Std         37.0346
trainer/Q2 Predictions Max         -8.14919
trainer/Q2 Predictions Min       -111.76
trainer/Q Targets Mean            -39.1778
trainer/Q Targets Std              37.5792
trainer/Q Targets Max              -0.217157
trainer/Q Targets Min            -111.159
trainer/Log Pis Mean                2.10079
trainer/Log Pis Std                 1.07662
trainer/Log Pis Max                 5.08838
trainer/Log Pis Min                -1.16118
trainer/Policy mu Mean              0.0101145
trainer/Policy mu Std               0.458139
trainer/Policy mu Max               1.73124
trainer/Policy mu Min              -2.9911
trainer/Policy log std Mean        -2.28195
trainer/Policy log std Std          0.479421
trainer/Policy log std Max         -0.668592
trainer/Policy log std Min         -3.12365
trainer/Alpha                       0.0816785
trainer/Alpha Loss                  0.252486
exploration/num steps total    175700
exploration/num paths total      1757
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.809281
exploration/Rewards Std             0.979269
exploration/Rewards Max            -0.0164347
exploration/Rewards Min            -8.08096
exploration/Returns Mean          -80.9281
exploration/Returns Std            58.1169
exploration/Returns Max           -20.629
exploration/Returns Min          -155.297
exploration/Actions Mean           -0.0107586
exploration/Actions Std             0.224144
exploration/Actions Max             0.993461
exploration/Actions Min            -0.997284
exploration/Num Paths               5
exploration/Average Returns       -80.9281
evaluation/num steps total     526500
evaluation/num paths total       5265
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.955147
evaluation/Rewards Std              1.219
evaluation/Rewards Max             -0.0242027
evaluation/Rewards Min             -9.89479
evaluation/Returns Mean           -95.5147
evaluation/Returns Std            103.821
evaluation/Returns Max             -3.20016
evaluation/Returns Min           -267.467
evaluation/Actions Mean            -0.00845968
evaluation/Actions Std              0.16746
evaluation/Actions Max              0.993472
evaluation/Actions Min             -0.998843
evaluation/Num Paths               15
evaluation/Average Returns        -95.5147
time/data storing (s)               0.00310477
time/evaluation sampling (s)        0.326271
time/exploration sampling (s)       0.13931
time/logging (s)                    0.00477096
time/saving (s)                     0.00198125
time/training (s)                   1.94441
time/epoch (s)                      2.41984
time/total (s)                    854.451
Epoch                             350
-----------------------------  ---------------
2019-04-23 00:07:36.973604 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 351 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.52009
trainer/QF2 Loss                    1.51248
trainer/Policy Loss                31.0642
trainer/Q1 Predictions Mean       -29.3314
trainer/Q1 Predictions Std         30.2613
trainer/Q1 Predictions Max         -7.97919
trainer/Q1 Predictions Min       -110.36
trainer/Q2 Predictions Mean       -29.3723
trainer/Q2 Predictions Std         30.2608
trainer/Q2 Predictions Max         -8.23705
trainer/Q2 Predictions Min       -110.192
trainer/Q Targets Mean            -29.3802
trainer/Q Targets Std              30.3596
trainer/Q Targets Max              -0.167463
trainer/Q Targets Min            -110.133
trainer/Log Pis Mean                1.73645
trainer/Log Pis Std                 1.47384
trainer/Log Pis Max                 9.48768
trainer/Log Pis Min                -3.05582
trainer/Policy mu Mean              0.0228276
trainer/Policy mu Std               0.622466
trainer/Policy mu Max               3.25001
trainer/Policy mu Min              -3.74778
trainer/Policy log std Mean        -2.15143
trainer/Policy log std Std          0.504448
trainer/Policy log std Max         -0.0835207
trainer/Policy log std Min         -3.05497
trainer/Alpha                       0.0833268
trainer/Alpha Loss                 -0.654904
exploration/num steps total    176200
exploration/num paths total      1762
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.710272
exploration/Rewards Std             0.718918
exploration/Rewards Max            -0.01057
exploration/Rewards Min            -6.11876
exploration/Returns Mean          -71.0272
exploration/Returns Std            50.5941
exploration/Returns Max           -25.4218
exploration/Returns Min          -154.473
exploration/Actions Mean            0.00966205
exploration/Actions Std             0.205241
exploration/Actions Max             0.999483
exploration/Actions Min            -0.999784
exploration/Num Paths               5
exploration/Average Returns       -71.0272
evaluation/num steps total     528000
evaluation/num paths total       5280
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.686535
evaluation/Rewards Std              1.24685
evaluation/Rewards Max             -0.0564199
evaluation/Rewards Min             -9.75843
evaluation/Returns Mean           -68.6535
evaluation/Returns Std             59.1362
evaluation/Returns Max            -17.5226
evaluation/Returns Min           -219.586
evaluation/Actions Mean            -0.0237112
evaluation/Actions Std              0.205904
evaluation/Actions Max              0.996138
evaluation/Actions Min             -0.999371
evaluation/Num Paths               15
evaluation/Average Returns        -68.6535
time/data storing (s)               0.0027164
time/evaluation sampling (s)        0.326706
time/exploration sampling (s)       0.13929
time/logging (s)                    0.00476104
time/saving (s)                     0.00196592
time/training (s)                   1.94963
time/epoch (s)                      2.42507
time/total (s)                    856.88
Epoch                             351
-----------------------------  ---------------
2019-04-23 00:07:39.398409 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 352 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.20711
trainer/QF2 Loss                    1.18966
trainer/Policy Loss                30.7743
trainer/Q1 Predictions Mean       -28.7205
trainer/Q1 Predictions Std         29.6569
trainer/Q1 Predictions Max         -8.12379
trainer/Q1 Predictions Min       -107.389
trainer/Q2 Predictions Mean       -28.7571
trainer/Q2 Predictions Std         29.6737
trainer/Q2 Predictions Max         -8.12461
trainer/Q2 Predictions Min       -107.319
trainer/Q Targets Mean            -29.0999
trainer/Q Targets Std              30.2147
trainer/Q Targets Max              -0.103659
trainer/Q Targets Min            -109.022
trainer/Log Pis Mean                2.09651
trainer/Log Pis Std                 1.24397
trainer/Log Pis Max                 4.96531
trainer/Log Pis Min                -4.28801
trainer/Policy mu Mean              0.0522432
trainer/Policy mu Std               0.547533
trainer/Policy mu Max               2.8684
trainer/Policy mu Min              -2.20075
trainer/Policy log std Mean        -2.26729
trainer/Policy log std Std          0.468231
trainer/Policy log std Max         -0.489916
trainer/Policy log std Min         -3.13161
trainer/Alpha                       0.0799578
trainer/Alpha Loss                  0.243799
exploration/num steps total    176700
exploration/num paths total      1767
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31219
exploration/Rewards Std             0.755733
exploration/Rewards Max            -0.00891896
exploration/Rewards Min            -7.25845
exploration/Returns Mean          -31.219
exploration/Returns Std             9.19322
exploration/Returns Max           -14.857
exploration/Returns Min           -39.4998
exploration/Actions Mean           -0.0117798
exploration/Actions Std             0.200772
exploration/Actions Max             0.996229
exploration/Actions Min            -0.998889
exploration/Num Paths               5
exploration/Average Returns       -31.219
evaluation/num steps total     529500
evaluation/num paths total       5295
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.576293
evaluation/Rewards Std              1.11886
evaluation/Rewards Max             -0.00952813
evaluation/Rewards Min            -10.0898
evaluation/Returns Mean           -57.6293
evaluation/Returns Std             50.2613
evaluation/Returns Max             -9.88727
evaluation/Returns Min           -173.519
evaluation/Actions Mean            -0.00462392
evaluation/Actions Std              0.199992
evaluation/Actions Max              0.997384
evaluation/Actions Min             -0.999723
evaluation/Num Paths               15
evaluation/Average Returns        -57.6293
time/data storing (s)               0.00270382
time/evaluation sampling (s)        0.330103
time/exploration sampling (s)       0.13618
time/logging (s)                    0.00477562
time/saving (s)                     0.00192344
time/training (s)                   1.93943
time/epoch (s)                      2.41511
time/total (s)                    859.3
Epoch                             352
-----------------------------  ---------------
2019-04-23 00:07:41.825941 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 353 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.310939
trainer/QF2 Loss                    0.366875
trainer/Policy Loss                37.666
trainer/Q1 Predictions Mean       -35.6581
trainer/Q1 Predictions Std         39.2747
trainer/Q1 Predictions Max         -8.07363
trainer/Q1 Predictions Min       -108.433
trainer/Q2 Predictions Mean       -35.6255
trainer/Q2 Predictions Std         39.2453
trainer/Q2 Predictions Max         -8.02738
trainer/Q2 Predictions Min       -108.426
trainer/Q Targets Mean            -36.0137
trainer/Q Targets Std              39.6778
trainer/Q Targets Max              -8.07291
trainer/Q Targets Min            -109.356
trainer/Log Pis Mean                2.10464
trainer/Log Pis Std                 0.882206
trainer/Log Pis Max                 3.41291
trainer/Log Pis Min                -0.553519
trainer/Policy mu Mean             -0.0214294
trainer/Policy mu Std               0.296405
trainer/Policy mu Max               2.22971
trainer/Policy mu Min              -1.12046
trainer/Policy log std Mean        -2.36543
trainer/Policy log std Std          0.356686
trainer/Policy log std Max         -0.745319
trainer/Policy log std Min         -3.06111
trainer/Alpha                       0.080536
trainer/Alpha Loss                  0.263604
exploration/num steps total    177200
exploration/num paths total      1772
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.40021
exploration/Rewards Std             1.34509
exploration/Rewards Max            -0.00354195
exploration/Rewards Min           -10.3884
exploration/Returns Mean         -140.021
exploration/Returns Std            82.6837
exploration/Returns Max           -33.7184
exploration/Returns Min          -238.699
exploration/Actions Mean            0.00063761
exploration/Actions Std             0.223557
exploration/Actions Max             0.994879
exploration/Actions Min            -0.998654
exploration/Num Paths               5
exploration/Average Returns      -140.021
evaluation/num steps total     531000
evaluation/num paths total       5310
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.976301
evaluation/Rewards Std              1.18156
evaluation/Rewards Max             -0.0295792
evaluation/Rewards Min             -9.92891
evaluation/Returns Mean           -97.6301
evaluation/Returns Std             88.1827
evaluation/Returns Max             -9.2402
evaluation/Returns Min           -253.734
evaluation/Actions Mean             0.00212195
evaluation/Actions Std              0.176052
evaluation/Actions Max              0.997954
evaluation/Actions Min             -0.999432
evaluation/Num Paths               15
evaluation/Average Returns        -97.6301
time/data storing (s)               0.0026386
time/evaluation sampling (s)        0.334151
time/exploration sampling (s)       0.134996
time/logging (s)                    0.00544409
time/saving (s)                     0.00221297
time/training (s)                   1.93905
time/epoch (s)                      2.41849
time/total (s)                    861.723
Epoch                             353
-----------------------------  ---------------
2019-04-23 00:07:44.284173 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 354 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.55577
trainer/QF2 Loss                    2.58846
trainer/Policy Loss                34.7019
trainer/Q1 Predictions Mean       -32.7869
trainer/Q1 Predictions Std         32.4328
trainer/Q1 Predictions Max         -7.90975
trainer/Q1 Predictions Min       -109.326
trainer/Q2 Predictions Mean       -32.7253
trainer/Q2 Predictions Std         32.4308
trainer/Q2 Predictions Max         -7.896
trainer/Q2 Predictions Min       -108.961
trainer/Q Targets Mean            -32.8698
trainer/Q Targets Std              32.7442
trainer/Q Targets Max              -0.477169
trainer/Q Targets Min            -109.561
trainer/Log Pis Mean                1.96072
trainer/Log Pis Std                 1.32686
trainer/Log Pis Max                 7.13909
trainer/Log Pis Min                -4.23786
trainer/Policy mu Mean             -0.0120997
trainer/Policy mu Std               0.469532
trainer/Policy mu Max               2.75023
trainer/Policy mu Min              -2.16241
trainer/Policy log std Mean        -2.32033
trainer/Policy log std Std          0.452303
trainer/Policy log std Max         -0.539145
trainer/Policy log std Min         -3.10182
trainer/Alpha                       0.0822031
trainer/Alpha Loss                 -0.0981599
exploration/num steps total    177700
exploration/num paths total      1777
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.33833
exploration/Rewards Std             1.06939
exploration/Rewards Max            -0.0120719
exploration/Rewards Min            -6.92721
exploration/Returns Mean         -133.833
exploration/Returns Std            95.9167
exploration/Returns Max           -13.5282
exploration/Returns Min          -235.946
exploration/Actions Mean            0.00100485
exploration/Actions Std             0.186056
exploration/Actions Max             0.996364
exploration/Actions Min            -0.997711
exploration/Num Paths               5
exploration/Average Returns      -133.833
evaluation/num steps total     532500
evaluation/num paths total       5325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.56331
evaluation/Rewards Std              1.19629
evaluation/Rewards Max             -0.0163165
evaluation/Rewards Min            -11.3182
evaluation/Returns Mean           -56.331
evaluation/Returns Std             68.2349
evaluation/Returns Max             -9.54093
evaluation/Returns Min           -226.682
evaluation/Actions Mean            -0.00179638
evaluation/Actions Std              0.181584
evaluation/Actions Max              0.999366
evaluation/Actions Min             -0.99964
evaluation/Num Paths               15
evaluation/Average Returns        -56.331
time/data storing (s)               0.00263642
time/evaluation sampling (s)        0.333226
time/exploration sampling (s)       0.134712
time/logging (s)                    0.00478448
time/saving (s)                     0.0105763
time/training (s)                   1.96175
time/epoch (s)                      2.44768
time/total (s)                    864.175
Epoch                             354
-----------------------------  ---------------
2019-04-23 00:07:46.720467 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 355 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.49585
trainer/QF2 Loss                    3.40664
trainer/Policy Loss                40.5078
trainer/Q1 Predictions Mean       -38.7293
trainer/Q1 Predictions Std         35.7408
trainer/Q1 Predictions Max         -8.12046
trainer/Q1 Predictions Min       -108.217
trainer/Q2 Predictions Mean       -38.782
trainer/Q2 Predictions Std         35.7684
trainer/Q2 Predictions Max         -8.14005
trainer/Q2 Predictions Min       -108.569
trainer/Q Targets Mean            -39.005
trainer/Q Targets Std              36.4109
trainer/Q Targets Max              -0.467226
trainer/Q Targets Min            -109.866
trainer/Log Pis Mean                1.82191
trainer/Log Pis Std                 1.20633
trainer/Log Pis Max                 4.67957
trainer/Log Pis Min                -2.0349
trainer/Policy mu Mean              0.00349662
trainer/Policy mu Std               0.409081
trainer/Policy mu Max               2.45847
trainer/Policy mu Min              -1.17063
trainer/Policy log std Mean        -2.2336
trainer/Policy log std Std          0.438579
trainer/Policy log std Max         -0.528011
trainer/Policy log std Min         -3.04512
trainer/Alpha                       0.0836317
trainer/Alpha Loss                 -0.441915
exploration/num steps total    178200
exploration/num paths total      1782
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.867303
exploration/Rewards Std             0.864882
exploration/Rewards Max            -0.0123012
exploration/Rewards Min            -4.63601
exploration/Returns Mean          -86.7303
exploration/Returns Std            81.744
exploration/Returns Max           -19.896
exploration/Returns Min          -217.619
exploration/Actions Mean            0.00276586
exploration/Actions Std             0.177137
exploration/Actions Max             0.98814
exploration/Actions Min            -0.988155
exploration/Num Paths               5
exploration/Average Returns       -86.7303
evaluation/num steps total     534000
evaluation/num paths total       5340
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.744476
evaluation/Rewards Std              1.10475
evaluation/Rewards Max             -0.0302855
evaluation/Rewards Min             -8.37913
evaluation/Returns Mean           -74.4476
evaluation/Returns Std             61.2074
evaluation/Returns Max            -14.9758
evaluation/Returns Min           -232.043
evaluation/Actions Mean            -0.00279649
evaluation/Actions Std              0.189676
evaluation/Actions Max              0.997547
evaluation/Actions Min             -0.999138
evaluation/Num Paths               15
evaluation/Average Returns        -74.4476
time/data storing (s)               0.00282733
time/evaluation sampling (s)        0.318296
time/exploration sampling (s)       0.139263
time/logging (s)                    0.00440047
time/saving (s)                     0.00158575
time/training (s)                   1.96158
time/epoch (s)                      2.42796
time/total (s)                    866.607
Epoch                             355
-----------------------------  ---------------
2019-04-23 00:07:49.162578 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 356 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.348059
trainer/QF2 Loss                    0.3263
trainer/Policy Loss                32.9288
trainer/Q1 Predictions Mean       -30.74
trainer/Q1 Predictions Std         31.7439
trainer/Q1 Predictions Max         -7.91204
trainer/Q1 Predictions Min       -110.23
trainer/Q2 Predictions Mean       -30.7379
trainer/Q2 Predictions Std         31.7191
trainer/Q2 Predictions Max         -8.00201
trainer/Q2 Predictions Min       -109.809
trainer/Q Targets Mean            -31.1067
trainer/Q Targets Std              32.0447
trainer/Q Targets Max              -7.98501
trainer/Q Targets Min            -110.357
trainer/Log Pis Mean                2.29701
trainer/Log Pis Std                 1.21344
trainer/Log Pis Max                 8.28901
trainer/Log Pis Min                 0.0741052
trainer/Policy mu Mean             -0.0242974
trainer/Policy mu Std               0.560092
trainer/Policy mu Max               3.34019
trainer/Policy mu Min              -3.47021
trainer/Policy log std Mean        -2.28671
trainer/Policy log std Std          0.439749
trainer/Policy log std Max         -0.358915
trainer/Policy log std Min         -3.11469
trainer/Alpha                       0.0815572
trainer/Alpha Loss                  0.744496
exploration/num steps total    178700
exploration/num paths total      1787
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.84445
exploration/Rewards Std             1.36591
exploration/Rewards Max            -0.00844011
exploration/Rewards Min            -9.69021
exploration/Returns Mean          -84.445
exploration/Returns Std            47.7544
exploration/Returns Max           -28.1934
exploration/Returns Min          -150.392
exploration/Actions Mean            0.0177388
exploration/Actions Std             0.255503
exploration/Actions Max             0.999862
exploration/Actions Min            -0.997299
exploration/Num Paths               5
exploration/Average Returns       -84.445
evaluation/num steps total     535500
evaluation/num paths total       5355
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.810295
evaluation/Rewards Std              1.26462
evaluation/Rewards Max             -0.014014
evaluation/Rewards Min             -8.78045
evaluation/Returns Mean           -81.0295
evaluation/Returns Std             94.0673
evaluation/Returns Max             -9.80402
evaluation/Returns Min           -245.617
evaluation/Actions Mean            -0.0150968
evaluation/Actions Std              0.181819
evaluation/Actions Max              0.997524
evaluation/Actions Min             -0.996224
evaluation/Num Paths               15
evaluation/Average Returns        -81.0295
time/data storing (s)               0.00268579
time/evaluation sampling (s)        0.325599
time/exploration sampling (s)       0.141348
time/logging (s)                    0.00481123
time/saving (s)                     0.00229468
time/training (s)                   1.95673
time/epoch (s)                      2.43347
time/total (s)                    869.044
Epoch                             356
-----------------------------  ---------------
2019-04-23 00:07:51.575655 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 357 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.58451
trainer/QF2 Loss                    3.62306
trainer/Policy Loss                35.5464
trainer/Q1 Predictions Mean       -33.642
trainer/Q1 Predictions Std         34.0049
trainer/Q1 Predictions Max         -8.12064
trainer/Q1 Predictions Min       -113.782
trainer/Q2 Predictions Mean       -33.6617
trainer/Q2 Predictions Std         34.0559
trainer/Q2 Predictions Max         -8.07992
trainer/Q2 Predictions Min       -114.16
trainer/Q Targets Mean            -33.5312
trainer/Q Targets Std              34.3825
trainer/Q Targets Max              -0.132052
trainer/Q Targets Min            -112.103
trainer/Log Pis Mean                1.96517
trainer/Log Pis Std                 1.34132
trainer/Log Pis Max                 5.02071
trainer/Log Pis Min                -4.95318
trainer/Policy mu Mean             -0.00305137
trainer/Policy mu Std               0.409769
trainer/Policy mu Max               2.3152
trainer/Policy mu Min              -3.54336
trainer/Policy log std Mean        -2.30402
trainer/Policy log std Std          0.42593
trainer/Policy log std Max         -0.459684
trainer/Policy log std Min         -3.27531
trainer/Alpha                       0.0821294
trainer/Alpha Loss                 -0.0870731
exploration/num steps total    179200
exploration/num paths total      1792
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.790989
exploration/Rewards Std             1.27523
exploration/Rewards Max            -0.00539946
exploration/Rewards Min            -9.80245
exploration/Returns Mean          -79.0989
exploration/Returns Std            85.5868
exploration/Returns Max           -22.0632
exploration/Returns Min          -247.568
exploration/Actions Mean           -0.0100907
exploration/Actions Std             0.220525
exploration/Actions Max             0.999736
exploration/Actions Min            -0.997648
exploration/Num Paths               5
exploration/Average Returns       -79.0989
evaluation/num steps total     537000
evaluation/num paths total       5370
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.02271
evaluation/Rewards Std              1.15675
evaluation/Rewards Max             -0.0115707
evaluation/Rewards Min             -9.33066
evaluation/Returns Mean          -102.271
evaluation/Returns Std             83.5309
evaluation/Returns Max             -6.49375
evaluation/Returns Min           -261.985
evaluation/Actions Mean             0.0129523
evaluation/Actions Std              0.190993
evaluation/Actions Max              0.997647
evaluation/Actions Min             -0.998984
evaluation/Num Paths               15
evaluation/Average Returns       -102.271
time/data storing (s)               0.00273875
time/evaluation sampling (s)        0.326597
time/exploration sampling (s)       0.138426
time/logging (s)                    0.00477628
time/saving (s)                     0.00197634
time/training (s)                   1.92919
time/epoch (s)                      2.4037
time/total (s)                    871.453
Epoch                             357
-----------------------------  ---------------
2019-04-23 00:07:54.026048 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 358 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   50.2008
trainer/QF2 Loss                   50.1743
trainer/Policy Loss                34.767
trainer/Q1 Predictions Mean       -32.9072
trainer/Q1 Predictions Std         32.4629
trainer/Q1 Predictions Max         -7.93842
trainer/Q1 Predictions Min       -108.336
trainer/Q2 Predictions Mean       -32.9252
trainer/Q2 Predictions Std         32.5139
trainer/Q2 Predictions Max         -7.93928
trainer/Q2 Predictions Min       -108.264
trainer/Q Targets Mean            -32.6747
trainer/Q Targets Std              33.2569
trainer/Q Targets Max              -0.129939
trainer/Q Targets Min            -110.602
trainer/Log Pis Mean                1.90827
trainer/Log Pis Std                 1.23352
trainer/Log Pis Max                 6.18831
trainer/Log Pis Min                -2.71145
trainer/Policy mu Mean              0.0198729
trainer/Policy mu Std               0.483476
trainer/Policy mu Max               3.31528
trainer/Policy mu Min              -2.55675
trainer/Policy log std Mean        -2.18605
trainer/Policy log std Std          0.474426
trainer/Policy log std Max         -0.399408
trainer/Policy log std Min         -3.14899
trainer/Alpha                       0.0824725
trainer/Alpha Loss                 -0.228865
exploration/num steps total    179700
exploration/num paths total      1797
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -2.05628
exploration/Rewards Std             1.15355
exploration/Rewards Max            -0.013586
exploration/Rewards Min           -10.7143
exploration/Returns Mean         -205.628
exploration/Returns Std            84.977
exploration/Returns Max           -37.5823
exploration/Returns Min          -271.646
exploration/Actions Mean           -0.0180133
exploration/Actions Std             0.201764
exploration/Actions Max             0.998899
exploration/Actions Min            -0.998866
exploration/Num Paths               5
exploration/Average Returns      -205.628
evaluation/num steps total     538500
evaluation/num paths total       5385
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.578073
evaluation/Rewards Std              1.13176
evaluation/Rewards Max             -0.0299661
evaluation/Rewards Min            -10.1243
evaluation/Returns Mean           -57.8073
evaluation/Returns Std             59.7031
evaluation/Returns Max            -15.315
evaluation/Returns Min           -238.357
evaluation/Actions Mean             0.00107395
evaluation/Actions Std              0.189696
evaluation/Actions Max              0.998543
evaluation/Actions Min             -0.998717
evaluation/Num Paths               15
evaluation/Average Returns        -57.8073
time/data storing (s)               0.00263573
time/evaluation sampling (s)        0.326325
time/exploration sampling (s)       0.137016
time/logging (s)                    0.00479583
time/saving (s)                     0.00197775
time/training (s)                   1.968
time/epoch (s)                      2.44075
time/total (s)                    873.898
Epoch                             358
-----------------------------  ---------------
2019-04-23 00:07:56.476721 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 359 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.75045
trainer/QF2 Loss                    2.75533
trainer/Policy Loss                41.928
trainer/Q1 Predictions Mean       -39.8819
trainer/Q1 Predictions Std         38.9378
trainer/Q1 Predictions Max         -7.97571
trainer/Q1 Predictions Min       -115.753
trainer/Q2 Predictions Mean       -39.8953
trainer/Q2 Predictions Std         38.9512
trainer/Q2 Predictions Max         -7.94928
trainer/Q2 Predictions Min       -115.151
trainer/Q Targets Mean            -40.0638
trainer/Q Targets Std              39.2381
trainer/Q Targets Max              -1.27839
trainer/Q Targets Min            -115.284
trainer/Log Pis Mean                2.09714
trainer/Log Pis Std                 1.2723
trainer/Log Pis Max                 4.20703
trainer/Log Pis Min                -3.54917
trainer/Policy mu Mean             -0.0258457
trainer/Policy mu Std               0.431749
trainer/Policy mu Max               2.5257
trainer/Policy mu Min              -2.01721
trainer/Policy log std Mean        -2.26255
trainer/Policy log std Std          0.450112
trainer/Policy log std Max         -0.642009
trainer/Policy log std Min         -3.08082
trainer/Alpha                       0.0805898
trainer/Alpha Loss                  0.244636
exploration/num steps total    180200
exploration/num paths total      1802
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.470385
exploration/Rewards Std             1.37489
exploration/Rewards Max            -0.0101441
exploration/Rewards Min           -11.0182
exploration/Returns Mean          -47.0385
exploration/Returns Std             9.38688
exploration/Returns Max           -35.851
exploration/Returns Min           -63.4534
exploration/Actions Mean           -0.00266085
exploration/Actions Std             0.264934
exploration/Actions Max             0.999406
exploration/Actions Min            -0.999916
exploration/Num Paths               5
exploration/Average Returns       -47.0385
evaluation/num steps total     540000
evaluation/num paths total       5400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.622093
evaluation/Rewards Std              1.08766
evaluation/Rewards Max             -0.00252224
evaluation/Rewards Min             -9.82601
evaluation/Returns Mean           -62.2093
evaluation/Returns Std             73.397
evaluation/Returns Max             -1.40622
evaluation/Returns Min           -252.767
evaluation/Actions Mean             0.00152315
evaluation/Actions Std              0.179305
evaluation/Actions Max              0.997829
evaluation/Actions Min             -0.999235
evaluation/Num Paths               15
evaluation/Average Returns        -62.2093
time/data storing (s)               0.00277045
time/evaluation sampling (s)        0.328885
time/exploration sampling (s)       0.138489
time/logging (s)                    0.00478211
time/saving (s)                     0.00197448
time/training (s)                   1.96409
time/epoch (s)                      2.44099
time/total (s)                    876.343
Epoch                             359
-----------------------------  ---------------
2019-04-23 00:07:58.918111 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 360 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.239432
trainer/QF2 Loss                    0.185555
trainer/Policy Loss                39.2604
trainer/Q1 Predictions Mean       -37.4172
trainer/Q1 Predictions Std         37.1798
trainer/Q1 Predictions Max         -8.16541
trainer/Q1 Predictions Min       -112.004
trainer/Q2 Predictions Mean       -37.4847
trainer/Q2 Predictions Std         37.1882
trainer/Q2 Predictions Max         -8.19535
trainer/Q2 Predictions Min       -112.144
trainer/Q Targets Mean            -37.6651
trainer/Q Targets Std              37.502
trainer/Q Targets Max              -8.0857
trainer/Q Targets Min            -112.106
trainer/Log Pis Mean                1.87843
trainer/Log Pis Std                 1.23616
trainer/Log Pis Max                 5.97698
trainer/Log Pis Min                -2.98662
trainer/Policy mu Mean             -0.0189057
trainer/Policy mu Std               0.42106
trainer/Policy mu Max               2.91873
trainer/Policy mu Min              -2.1485
trainer/Policy log std Mean        -2.2549
trainer/Policy log std Std          0.416478
trainer/Policy log std Max         -0.749707
trainer/Policy log std Min         -3.08679
trainer/Alpha                       0.0803027
trainer/Alpha Loss                 -0.306596
exploration/num steps total    180700
exploration/num paths total      1807
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.21123
exploration/Rewards Std             1.31748
exploration/Rewards Max            -0.00755665
exploration/Rewards Min           -10.7738
exploration/Returns Mean         -121.123
exploration/Returns Std            67.2298
exploration/Returns Max           -45.9924
exploration/Returns Min          -231.854
exploration/Actions Mean           -0.00252771
exploration/Actions Std             0.248686
exploration/Actions Max             0.998447
exploration/Actions Min            -0.999773
exploration/Num Paths               5
exploration/Average Returns      -121.123
evaluation/num steps total     541500
evaluation/num paths total       5415
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.466583
evaluation/Rewards Std              1.053
evaluation/Rewards Max             -0.0499968
evaluation/Rewards Min            -10.9866
evaluation/Returns Mean           -46.6583
evaluation/Returns Std             56.9528
evaluation/Returns Max             -5.91829
evaluation/Returns Min           -241.593
evaluation/Actions Mean            -0.00424192
evaluation/Actions Std              0.170926
evaluation/Actions Max              0.998345
evaluation/Actions Min             -0.996097
evaluation/Num Paths               15
evaluation/Average Returns        -46.6583
time/data storing (s)               0.00273391
time/evaluation sampling (s)        0.331408
time/exploration sampling (s)       0.136291
time/logging (s)                    0.00350566
time/saving (s)                     0.00159893
time/training (s)                   1.95616
time/epoch (s)                      2.4317
time/total (s)                    878.778
Epoch                             360
-----------------------------  ---------------
2019-04-23 00:08:01.343921 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 361 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.87149
trainer/QF2 Loss                    1.8495
trainer/Policy Loss                37.0882
trainer/Q1 Predictions Mean       -35.1731
trainer/Q1 Predictions Std         34.7675
trainer/Q1 Predictions Max         -7.94224
trainer/Q1 Predictions Min       -109.391
trainer/Q2 Predictions Mean       -35.1418
trainer/Q2 Predictions Std         34.7454
trainer/Q2 Predictions Max         -7.98879
trainer/Q2 Predictions Min       -109.554
trainer/Q Targets Mean            -35.1326
trainer/Q Targets Std              35.1496
trainer/Q Targets Max              -0.0173132
trainer/Q Targets Min            -110.415
trainer/Log Pis Mean                2.0311
trainer/Log Pis Std                 1.48096
trainer/Log Pis Max                 8.0183
trainer/Log Pis Min                -3.54016
trainer/Policy mu Mean             -0.0271667
trainer/Policy mu Std               0.650457
trainer/Policy mu Max               3.39208
trainer/Policy mu Min              -2.93072
trainer/Policy log std Mean        -2.18941
trainer/Policy log std Std          0.501918
trainer/Policy log std Max         -0.61405
trainer/Policy log std Min         -3.09553
trainer/Alpha                       0.0816093
trainer/Alpha Loss                  0.0779315
exploration/num steps total    181200
exploration/num paths total      1812
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.739743
exploration/Rewards Std             1.23248
exploration/Rewards Max            -0.00542656
exploration/Rewards Min            -9.58051
exploration/Returns Mean          -73.9743
exploration/Returns Std            83.4242
exploration/Returns Max           -14.9968
exploration/Returns Min          -238.438
exploration/Actions Mean           -0.00404019
exploration/Actions Std             0.22297
exploration/Actions Max             0.996663
exploration/Actions Min            -0.998166
exploration/Num Paths               5
exploration/Average Returns       -73.9743
evaluation/num steps total     543000
evaluation/num paths total       5430
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.728336
evaluation/Rewards Std              1.15966
evaluation/Rewards Max             -0.0242846
evaluation/Rewards Min             -9.13836
evaluation/Returns Mean           -72.8336
evaluation/Returns Std             77.0448
evaluation/Returns Max             -6.20218
evaluation/Returns Min           -248.199
evaluation/Actions Mean             0.010656
evaluation/Actions Std              0.188683
evaluation/Actions Max              0.996129
evaluation/Actions Min             -0.996279
evaluation/Num Paths               15
evaluation/Average Returns        -72.8336
time/data storing (s)               0.00282216
time/evaluation sampling (s)        0.323664
time/exploration sampling (s)       0.136508
time/logging (s)                    0.00364412
time/saving (s)                     0.00195189
time/training (s)                   1.94806
time/epoch (s)                      2.41665
time/total (s)                    881.2
Epoch                             361
-----------------------------  ---------------
2019-04-23 00:08:03.800332 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 362 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  113.122
trainer/QF2 Loss                  113.077
trainer/Policy Loss                38.3636
trainer/Q1 Predictions Mean       -36.4414
trainer/Q1 Predictions Std         36.1927
trainer/Q1 Predictions Max         -8.01825
trainer/Q1 Predictions Min       -118.363
trainer/Q2 Predictions Mean       -36.387
trainer/Q2 Predictions Std         36.1736
trainer/Q2 Predictions Max         -7.97281
trainer/Q2 Predictions Min       -117.415
trainer/Q Targets Mean            -35.7179
trainer/Q Targets Std              35.897
trainer/Q Targets Max              -2.58564
trainer/Q Targets Min            -118.241
trainer/Log Pis Mean                2.02263
trainer/Log Pis Std                 1.27906
trainer/Log Pis Max                 4.96111
trainer/Log Pis Min                -3.10657
trainer/Policy mu Mean              0.00292877
trainer/Policy mu Std               0.599154
trainer/Policy mu Max               2.91608
trainer/Policy mu Min              -2.65078
trainer/Policy log std Mean        -2.22154
trainer/Policy log std Std          0.520352
trainer/Policy log std Max         -0.585665
trainer/Policy log std Min         -3.11811
trainer/Alpha                       0.0826756
trainer/Alpha Loss                  0.0564038
exploration/num steps total    181700
exploration/num paths total      1817
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.670745
exploration/Rewards Std             0.852298
exploration/Rewards Max            -0.00928516
exploration/Rewards Min            -7.1457
exploration/Returns Mean          -67.0745
exploration/Returns Std            55.9297
exploration/Returns Max           -12.165
exploration/Returns Min          -157.822
exploration/Actions Mean           -0.000638017
exploration/Actions Std             0.212777
exploration/Actions Max             0.999352
exploration/Actions Min            -0.997393
exploration/Num Paths               5
exploration/Average Returns       -67.0745
evaluation/num steps total     544500
evaluation/num paths total       5445
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.573983
evaluation/Rewards Std              0.834551
evaluation/Rewards Max             -0.073067
evaluation/Rewards Min             -9.02049
evaluation/Returns Mean           -57.3983
evaluation/Returns Std             51.1653
evaluation/Returns Max            -14.5653
evaluation/Returns Min           -148.295
evaluation/Actions Mean             0.00889527
evaluation/Actions Std              0.159822
evaluation/Actions Max              0.997572
evaluation/Actions Min             -0.997101
evaluation/Num Paths               15
evaluation/Average Returns        -57.3983
time/data storing (s)               0.00265865
time/evaluation sampling (s)        0.327893
time/exploration sampling (s)       0.141397
time/logging (s)                    0.00481879
time/saving (s)                     0.00197331
time/training (s)                   1.96902
time/epoch (s)                      2.44776
time/total (s)                    883.652
Epoch                             362
-----------------------------  ----------------
2019-04-23 00:08:06.228260 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 363 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.3692
trainer/QF2 Loss                    2.32996
trainer/Policy Loss                31.7488
trainer/Q1 Predictions Mean       -29.8499
trainer/Q1 Predictions Std         27.994
trainer/Q1 Predictions Max         -8.15765
trainer/Q1 Predictions Min       -113.889
trainer/Q2 Predictions Mean       -29.8132
trainer/Q2 Predictions Std         27.9411
trainer/Q2 Predictions Max         -8.08416
trainer/Q2 Predictions Min       -113.483
trainer/Q Targets Mean            -29.8185
trainer/Q Targets Std              28.2594
trainer/Q Targets Max              -1.01167
trainer/Q Targets Min            -113.507
trainer/Log Pis Mean                1.98929
trainer/Log Pis Std                 1.25446
trainer/Log Pis Max                 5.88603
trainer/Log Pis Min                -2.41091
trainer/Policy mu Mean             -0.00533555
trainer/Policy mu Std               0.559596
trainer/Policy mu Max               2.89409
trainer/Policy mu Min              -2.41621
trainer/Policy log std Mean        -2.23875
trainer/Policy log std Std          0.448737
trainer/Policy log std Max         -0.736135
trainer/Policy log std Min         -3.25368
trainer/Alpha                       0.0828008
trainer/Alpha Loss                 -0.0266779
exploration/num steps total    182200
exploration/num paths total      1822
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.978359
exploration/Rewards Std             1.36042
exploration/Rewards Max            -0.00633897
exploration/Rewards Min            -8.79205
exploration/Returns Mean          -97.8359
exploration/Returns Std            85.6543
exploration/Returns Max           -27.8062
exploration/Returns Min          -258.731
exploration/Actions Mean            0.0253933
exploration/Actions Std             0.236755
exploration/Actions Max             0.999289
exploration/Actions Min            -0.997685
exploration/Num Paths               5
exploration/Average Returns       -97.8359
evaluation/num steps total     546000
evaluation/num paths total       5460
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.950085
evaluation/Rewards Std              1.18891
evaluation/Rewards Max             -0.00957732
evaluation/Rewards Min             -8.86353
evaluation/Returns Mean           -95.0085
evaluation/Returns Std             94.5295
evaluation/Returns Max            -12.6703
evaluation/Returns Min           -262.407
evaluation/Actions Mean            -0.00993716
evaluation/Actions Std              0.173939
evaluation/Actions Max              0.994476
evaluation/Actions Min             -0.999715
evaluation/Num Paths               15
evaluation/Average Returns        -95.0085
time/data storing (s)               0.00278596
time/evaluation sampling (s)        0.325462
time/exploration sampling (s)       0.137957
time/logging (s)                    0.0048643
time/saving (s)                     0.00196229
time/training (s)                   1.94506
time/epoch (s)                      2.41809
time/total (s)                    886.074
Epoch                             363
-----------------------------  ---------------
2019-04-23 00:08:08.673850 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 364 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.97948
trainer/QF2 Loss                    1.03622
trainer/Policy Loss                36.5255
trainer/Q1 Predictions Mean       -34.5426
trainer/Q1 Predictions Std         35.0691
trainer/Q1 Predictions Max         -8.0473
trainer/Q1 Predictions Min       -111.263
trainer/Q2 Predictions Mean       -34.5588
trainer/Q2 Predictions Std         35.0554
trainer/Q2 Predictions Max         -7.87549
trainer/Q2 Predictions Min       -111.347
trainer/Q Targets Mean            -34.8369
trainer/Q Targets Std              35.3287
trainer/Q Targets Max              -0.141282
trainer/Q Targets Min            -111.627
trainer/Log Pis Mean                2.03045
trainer/Log Pis Std                 1.13105
trainer/Log Pis Max                 8.63932
trainer/Log Pis Min                -1.14458
trainer/Policy mu Mean              0.0367129
trainer/Policy mu Std               0.407294
trainer/Policy mu Max               3.6047
trainer/Policy mu Min              -0.806867
trainer/Policy log std Mean        -2.29139
trainer/Policy log std Std          0.383835
trainer/Policy log std Max         -0.267091
trainer/Policy log std Min         -2.90606
trainer/Alpha                       0.0811476
trainer/Alpha Loss                  0.0764721
exploration/num steps total    182700
exploration/num paths total      1827
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.59608
exploration/Rewards Std             1.59603
exploration/Rewards Max            -0.0052613
exploration/Rewards Min           -10.58
exploration/Returns Mean          -59.608
exploration/Returns Std            10.7083
exploration/Returns Max           -44.4128
exploration/Returns Min           -70.3356
exploration/Actions Mean           -0.00826471
exploration/Actions Std             0.26565
exploration/Actions Max             0.999403
exploration/Actions Min            -0.999319
exploration/Num Paths               5
exploration/Average Returns       -59.608
evaluation/num steps total     547500
evaluation/num paths total       5475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.741981
evaluation/Rewards Std              1.31413
evaluation/Rewards Max             -0.0237152
evaluation/Rewards Min            -11.2513
evaluation/Returns Mean           -74.1981
evaluation/Returns Std             97.5095
evaluation/Returns Max             -4.59315
evaluation/Returns Min           -273.403
evaluation/Actions Mean            -0.0119265
evaluation/Actions Std              0.190942
evaluation/Actions Max              0.997803
evaluation/Actions Min             -0.998666
evaluation/Num Paths               15
evaluation/Average Returns        -74.1981
time/data storing (s)               0.00268714
time/evaluation sampling (s)        0.328226
time/exploration sampling (s)       0.135817
time/logging (s)                    0.0036617
time/saving (s)                     0.00197943
time/training (s)                   1.96269
time/epoch (s)                      2.43506
time/total (s)                    888.514
Epoch                             364
-----------------------------  ---------------
2019-04-23 00:08:11.101918 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 365 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.56701
trainer/QF2 Loss                    2.59168
trainer/Policy Loss                28.5858
trainer/Q1 Predictions Mean       -26.643
trainer/Q1 Predictions Std         31.7221
trainer/Q1 Predictions Max         -7.89113
trainer/Q1 Predictions Min       -109.933
trainer/Q2 Predictions Mean       -26.6327
trainer/Q2 Predictions Std         31.7307
trainer/Q2 Predictions Max         -7.8442
trainer/Q2 Predictions Min       -110.141
trainer/Q Targets Mean            -26.9538
trainer/Q Targets Std              32.3509
trainer/Q Targets Max              -0.260847
trainer/Q Targets Min            -111.547
trainer/Log Pis Mean                2.11658
trainer/Log Pis Std                 1.57021
trainer/Log Pis Max                 9.75122
trainer/Log Pis Min                -1.77968
trainer/Policy mu Mean              0.0296023
trainer/Policy mu Std               0.694071
trainer/Policy mu Max               3.53714
trainer/Policy mu Min              -3.12619
trainer/Policy log std Mean        -2.21299
trainer/Policy log std Std          0.505806
trainer/Policy log std Max         -0.189454
trainer/Policy log std Min         -3.10758
trainer/Alpha                       0.0828197
trainer/Alpha Loss                  0.290412
exploration/num steps total    183200
exploration/num paths total      1832
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.73867
exploration/Rewards Std             1.08216
exploration/Rewards Max            -0.00559289
exploration/Rewards Min            -8.85559
exploration/Returns Mean          -73.867
exploration/Returns Std            42.2456
exploration/Returns Max           -34.6188
exploration/Returns Min          -128.127
exploration/Actions Mean            0.0153173
exploration/Actions Std             0.23258
exploration/Actions Max             0.999446
exploration/Actions Min            -0.999397
exploration/Num Paths               5
exploration/Average Returns       -73.867
evaluation/num steps total     549000
evaluation/num paths total       5490
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.593482
evaluation/Rewards Std              1.15706
evaluation/Rewards Max             -0.018353
evaluation/Rewards Min             -9.94247
evaluation/Returns Mean           -59.3482
evaluation/Returns Std             72.0977
evaluation/Returns Max             -7.57202
evaluation/Returns Min           -239.305
evaluation/Actions Mean            -0.0135555
evaluation/Actions Std              0.179205
evaluation/Actions Max              0.994507
evaluation/Actions Min             -0.999736
evaluation/Num Paths               15
evaluation/Average Returns        -59.3482
time/data storing (s)               0.00282638
time/evaluation sampling (s)        0.326306
time/exploration sampling (s)       0.137105
time/logging (s)                    0.00478564
time/saving (s)                     0.00199064
time/training (s)                   1.94649
time/epoch (s)                      2.4195
time/total (s)                    890.938
Epoch                             365
-----------------------------  ---------------
2019-04-23 00:08:13.580470 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 366 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.41985
trainer/QF2 Loss                    1.398
trainer/Policy Loss                27.9344
trainer/Q1 Predictions Mean       -25.9655
trainer/Q1 Predictions Std         30.4122
trainer/Q1 Predictions Max         -7.95866
trainer/Q1 Predictions Min       -109.666
trainer/Q2 Predictions Mean       -25.9424
trainer/Q2 Predictions Std         30.4167
trainer/Q2 Predictions Max         -7.93264
trainer/Q2 Predictions Min       -109.842
trainer/Q Targets Mean            -26.4269
trainer/Q Targets Std              31.0336
trainer/Q Targets Max              -0.313885
trainer/Q Targets Min            -112.061
trainer/Log Pis Mean                2.02922
trainer/Log Pis Std                 1.05248
trainer/Log Pis Max                 3.64549
trainer/Log Pis Min                -2.62398
trainer/Policy mu Mean              0.00376138
trainer/Policy mu Std               0.209691
trainer/Policy mu Max               1.65922
trainer/Policy mu Min              -1.12294
trainer/Policy log std Mean        -2.37915
trainer/Policy log std Std          0.29782
trainer/Policy log std Max         -1.31995
trainer/Policy log std Min         -3.09248
trainer/Alpha                       0.0835457
trainer/Alpha Loss                  0.0725276
exploration/num steps total    183700
exploration/num paths total      1837
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.673206
exploration/Rewards Std             0.961155
exploration/Rewards Max            -0.00179131
exploration/Rewards Min            -8.68315
exploration/Returns Mean          -67.3206
exploration/Returns Std            45.4823
exploration/Returns Max           -18.3656
exploration/Returns Min          -137.186
exploration/Actions Mean            0.0129791
exploration/Actions Std             0.214907
exploration/Actions Max             0.998544
exploration/Actions Min            -0.997439
exploration/Num Paths               5
exploration/Average Returns       -67.3206
evaluation/num steps total     550500
evaluation/num paths total       5505
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.674091
evaluation/Rewards Std              1.29295
evaluation/Rewards Max             -0.0103395
evaluation/Rewards Min            -10.5752
evaluation/Returns Mean           -67.4091
evaluation/Returns Std             59.4927
evaluation/Returns Max            -13.3862
evaluation/Returns Min           -241.66
evaluation/Actions Mean             0.00103482
evaluation/Actions Std              0.196966
evaluation/Actions Max              0.99782
evaluation/Actions Min             -0.999757
evaluation/Num Paths               15
evaluation/Average Returns        -67.4091
time/data storing (s)               0.0028341
time/evaluation sampling (s)        0.334014
time/exploration sampling (s)       0.137669
time/logging (s)                    0.00482255
time/saving (s)                     0.00976758
time/training (s)                   1.97966
time/epoch (s)                      2.46877
time/total (s)                    893.411
Epoch                             366
-----------------------------  ---------------
2019-04-23 00:08:16.005933 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 367 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.39291
trainer/QF2 Loss                    3.44438
trainer/Policy Loss                31.7514
trainer/Q1 Predictions Mean       -29.9412
trainer/Q1 Predictions Std         30.7691
trainer/Q1 Predictions Max         -7.89303
trainer/Q1 Predictions Min       -111.689
trainer/Q2 Predictions Mean       -29.9306
trainer/Q2 Predictions Std         30.7545
trainer/Q2 Predictions Max         -7.90017
trainer/Q2 Predictions Min       -112.278
trainer/Q Targets Mean            -29.731
trainer/Q Targets Std              31.1423
trainer/Q Targets Max              -0.117447
trainer/Q Targets Min            -111.629
trainer/Log Pis Mean                1.83522
trainer/Log Pis Std                 1.16681
trainer/Log Pis Max                 6.86635
trainer/Log Pis Min                -1.80519
trainer/Policy mu Mean              0.0102139
trainer/Policy mu Std               0.453148
trainer/Policy mu Max               2.89044
trainer/Policy mu Min              -1.02336
trainer/Policy log std Mean        -2.2115
trainer/Policy log std Std          0.402255
trainer/Policy log std Max         -0.375636
trainer/Policy log std Min         -3.02763
trainer/Alpha                       0.0854702
trainer/Alpha Loss                 -0.405259
exploration/num steps total    184200
exploration/num paths total      1842
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.295306
exploration/Rewards Std             0.623197
exploration/Rewards Max            -0.0124622
exploration/Rewards Min            -6.30418
exploration/Returns Mean          -29.5306
exploration/Returns Std             8.66141
exploration/Returns Max           -20.7493
exploration/Returns Min           -45.7774
exploration/Actions Mean           -0.0172885
exploration/Actions Std             0.20697
exploration/Actions Max             0.99783
exploration/Actions Min            -0.999006
exploration/Num Paths               5
exploration/Average Returns       -29.5306
evaluation/num steps total     552000
evaluation/num paths total       5520
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.8619
evaluation/Rewards Std              1.28123
evaluation/Rewards Max             -0.0213481
evaluation/Rewards Min            -11.4115
evaluation/Returns Mean           -86.19
evaluation/Returns Std             84.8333
evaluation/Returns Max             -3.28612
evaluation/Returns Min           -243.515
evaluation/Actions Mean            -0.0204147
evaluation/Actions Std              0.178824
evaluation/Actions Max              0.992581
evaluation/Actions Min             -0.999756
evaluation/Num Paths               15
evaluation/Average Returns        -86.19
time/data storing (s)               0.00276312
time/evaluation sampling (s)        0.329161
time/exploration sampling (s)       0.140306
time/logging (s)                    0.00479282
time/saving (s)                     0.00197503
time/training (s)                   1.93743
time/epoch (s)                      2.41643
time/total (s)                    895.832
Epoch                             367
-----------------------------  ---------------
2019-04-23 00:08:18.442408 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 368 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.09435
trainer/QF2 Loss                    3.11257
trainer/Policy Loss                31.3023
trainer/Q1 Predictions Mean       -29.2578
trainer/Q1 Predictions Std         33.5941
trainer/Q1 Predictions Max         -7.93453
trainer/Q1 Predictions Min       -112.381
trainer/Q2 Predictions Mean       -29.2239
trainer/Q2 Predictions Std         33.599
trainer/Q2 Predictions Max         -7.94955
trainer/Q2 Predictions Min       -110.359
trainer/Q Targets Mean            -29.4873
trainer/Q Targets Std              34.3434
trainer/Q Targets Max              -0.733541
trainer/Q Targets Min            -113.338
trainer/Log Pis Mean                2.12529
trainer/Log Pis Std                 1.12386
trainer/Log Pis Max                 6.43519
trainer/Log Pis Min                -0.843353
trainer/Policy mu Mean              0.054585
trainer/Policy mu Std               0.528138
trainer/Policy mu Max               3.12381
trainer/Policy mu Min              -2.62594
trainer/Policy log std Mean        -2.31229
trainer/Policy log std Std          0.429375
trainer/Policy log std Max         -0.350387
trainer/Policy log std Min         -3.03757
trainer/Alpha                       0.0874109
trainer/Alpha Loss                  0.30536
exploration/num steps total    184700
exploration/num paths total      1847
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.391214
exploration/Rewards Std             1.11568
exploration/Rewards Max            -0.0102754
exploration/Rewards Min           -10.2539
exploration/Returns Mean          -39.1214
exploration/Returns Std            17.4744
exploration/Returns Max           -14.6451
exploration/Returns Min           -60.375
exploration/Actions Mean            0.0117694
exploration/Actions Std             0.225035
exploration/Actions Max             0.999423
exploration/Actions Min            -0.995384
exploration/Num Paths               5
exploration/Average Returns       -39.1214
evaluation/num steps total     553500
evaluation/num paths total       5535
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.808348
evaluation/Rewards Std              1.2772
evaluation/Rewards Max             -0.0217668
evaluation/Rewards Min            -10.5818
evaluation/Returns Mean           -80.8348
evaluation/Returns Std             74.2207
evaluation/Returns Max             -5.44073
evaluation/Returns Min           -244.776
evaluation/Actions Mean             0.00741519
evaluation/Actions Std              0.207854
evaluation/Actions Max              0.998352
evaluation/Actions Min             -0.999127
evaluation/Num Paths               15
evaluation/Average Returns        -80.8348
time/data storing (s)               0.00290115
time/evaluation sampling (s)        0.330751
time/exploration sampling (s)       0.136078
time/logging (s)                    0.00499942
time/saving (s)                     0.00197893
time/training (s)                   1.94989
time/epoch (s)                      2.42659
time/total (s)                    898.264
Epoch                             368
-----------------------------  ---------------
2019-04-23 00:08:20.888477 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 369 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.990446
trainer/QF2 Loss                    1.01155
trainer/Policy Loss                34.4777
trainer/Q1 Predictions Mean       -32.4512
trainer/Q1 Predictions Std         37.5113
trainer/Q1 Predictions Max         -8.02573
trainer/Q1 Predictions Min       -138.101
trainer/Q2 Predictions Mean       -32.4144
trainer/Q2 Predictions Std         37.513
trainer/Q2 Predictions Max         -8.00431
trainer/Q2 Predictions Min       -139.515
trainer/Q Targets Mean            -32.5573
trainer/Q Targets Std              37.5552
trainer/Q Targets Max              -0.0823224
trainer/Q Targets Min            -137.814
trainer/Log Pis Mean                2.07304
trainer/Log Pis Std                 1.35978
trainer/Log Pis Max                 8.40437
trainer/Log Pis Min                -1.19255
trainer/Policy mu Mean             -0.0704009
trainer/Policy mu Std               0.490922
trainer/Policy mu Max               3.02481
trainer/Policy mu Min              -2.92366
trainer/Policy log std Mean        -2.26382
trainer/Policy log std Std          0.427552
trainer/Policy log std Max         -0.480979
trainer/Policy log std Min         -3.0798
trainer/Alpha                       0.0851661
trainer/Alpha Loss                  0.179892
exploration/num steps total    185200
exploration/num paths total      1852
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.399786
exploration/Rewards Std             1.12643
exploration/Rewards Max            -0.00817698
exploration/Rewards Min            -9.55379
exploration/Returns Mean          -39.9786
exploration/Returns Std            18.2515
exploration/Returns Max           -13.2552
exploration/Returns Min           -61.1614
exploration/Actions Mean            0.0151835
exploration/Actions Std             0.213058
exploration/Actions Max             0.997868
exploration/Actions Min            -0.984879
exploration/Num Paths               5
exploration/Average Returns       -39.9786
evaluation/num steps total     555000
evaluation/num paths total       5550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.708066
evaluation/Rewards Std              1.11842
evaluation/Rewards Max             -0.00203245
evaluation/Rewards Min            -10.4335
evaluation/Returns Mean           -70.8066
evaluation/Returns Std             70.0079
evaluation/Returns Max             -6.72652
evaluation/Returns Min           -230.565
evaluation/Actions Mean             0.00214183
evaluation/Actions Std              0.187341
evaluation/Actions Max              0.999081
evaluation/Actions Min             -0.998122
evaluation/Num Paths               15
evaluation/Average Returns        -70.8066
time/data storing (s)               0.00275645
time/evaluation sampling (s)        0.32291
time/exploration sampling (s)       0.140442
time/logging (s)                    0.00479327
time/saving (s)                     0.00198761
time/training (s)                   1.96329
time/epoch (s)                      2.43618
time/total (s)                    900.704
Epoch                             369
-----------------------------  ---------------
2019-04-23 00:08:23.299580 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 370 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.121425
trainer/QF2 Loss                    0.109881
trainer/Policy Loss                34.1027
trainer/Q1 Predictions Mean       -32.1971
trainer/Q1 Predictions Std         35.2673
trainer/Q1 Predictions Max         -8.18056
trainer/Q1 Predictions Min       -111.424
trainer/Q2 Predictions Mean       -32.1915
trainer/Q2 Predictions Std         35.2625
trainer/Q2 Predictions Max         -8.14317
trainer/Q2 Predictions Min       -111.47
trainer/Q Targets Mean            -32.3092
trainer/Q Targets Std              35.3809
trainer/Q Targets Max              -8.12091
trainer/Q Targets Min            -111.429
trainer/Log Pis Mean                2.00069
trainer/Log Pis Std                 1.42309
trainer/Log Pis Max                 7.24864
trainer/Log Pis Min                -5.01911
trainer/Policy mu Mean             -0.0860869
trainer/Policy mu Std               0.416333
trainer/Policy mu Max               2.5677
trainer/Policy mu Min              -3.07707
trainer/Policy log std Mean        -2.28469
trainer/Policy log std Std          0.406944
trainer/Policy log std Max         -0.636741
trainer/Policy log std Min         -3.03853
trainer/Alpha                       0.0828576
trainer/Alpha Loss                  0.00171061
exploration/num steps total    185700
exploration/num paths total      1857
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.927814
exploration/Rewards Std             1.19755
exploration/Rewards Max            -0.00200641
exploration/Rewards Min            -8.17757
exploration/Returns Mean          -92.7814
exploration/Returns Std            75.2089
exploration/Returns Max           -31.85
exploration/Returns Min          -234.405
exploration/Actions Mean            0.00445636
exploration/Actions Std             0.21394
exploration/Actions Max             0.999267
exploration/Actions Min            -0.993545
exploration/Num Paths               5
exploration/Average Returns       -92.7814
evaluation/num steps total     556500
evaluation/num paths total       5565
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.816673
evaluation/Rewards Std              1.09399
evaluation/Rewards Max             -0.0180578
evaluation/Rewards Min             -9.75817
evaluation/Returns Mean           -81.6673
evaluation/Returns Std             68.4405
evaluation/Returns Max             -6.42769
evaluation/Returns Min           -243.807
evaluation/Actions Mean             0.00351962
evaluation/Actions Std              0.186232
evaluation/Actions Max              0.999127
evaluation/Actions Min             -0.998988
evaluation/Num Paths               15
evaluation/Average Returns        -81.6673
time/data storing (s)               0.00259261
time/evaluation sampling (s)        0.324029
time/exploration sampling (s)       0.139824
time/logging (s)                    0.00478802
time/saving (s)                     0.00202959
time/training (s)                   1.92879
time/epoch (s)                      2.40205
time/total (s)                    903.111
Epoch                             370
-----------------------------  ---------------
2019-04-23 00:08:25.735887 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 371 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.427507
trainer/QF2 Loss                    0.523705
trainer/Policy Loss                43.388
trainer/Q1 Predictions Mean       -41.3593
trainer/Q1 Predictions Std         39.0425
trainer/Q1 Predictions Max         -8.27612
trainer/Q1 Predictions Min       -111.224
trainer/Q2 Predictions Mean       -41.3654
trainer/Q2 Predictions Std         38.987
trainer/Q2 Predictions Max         -8.21681
trainer/Q2 Predictions Min       -111.067
trainer/Q Targets Mean            -41.7013
trainer/Q Targets Std              39.4597
trainer/Q Targets Max              -8.1086
trainer/Q Targets Min            -111.681
trainer/Log Pis Mean                2.1307
trainer/Log Pis Std                 1.60694
trainer/Log Pis Max                11.8973
trainer/Log Pis Min                -3.43413
trainer/Policy mu Mean              0.0263067
trainer/Policy mu Std               0.595402
trainer/Policy mu Max               3.60732
trainer/Policy mu Min              -2.82525
trainer/Policy log std Mean        -2.32061
trainer/Policy log std Std          0.515392
trainer/Policy log std Max         -0.496168
trainer/Policy log std Min         -3.0564
trainer/Alpha                       0.0818502
trainer/Alpha Loss                  0.327134
exploration/num steps total    186200
exploration/num paths total      1862
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.866424
exploration/Rewards Std             0.940859
exploration/Rewards Max            -0.015542
exploration/Rewards Min            -6.36294
exploration/Returns Mean          -86.6424
exploration/Returns Std            79.4097
exploration/Returns Max           -15.5777
exploration/Returns Min          -218.494
exploration/Actions Mean            0.00132296
exploration/Actions Std             0.187827
exploration/Actions Max             0.999071
exploration/Actions Min            -0.992381
exploration/Num Paths               5
exploration/Average Returns       -86.6424
evaluation/num steps total     558000
evaluation/num paths total       5580
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.561399
evaluation/Rewards Std              1.0612
evaluation/Rewards Max             -0.0544054
evaluation/Rewards Min             -9.84162
evaluation/Returns Mean           -56.1399
evaluation/Returns Std             53.9541
evaluation/Returns Max             -9.44261
evaluation/Returns Min           -216.308
evaluation/Actions Mean            -0.00242272
evaluation/Actions Std              0.184794
evaluation/Actions Max              0.997572
evaluation/Actions Min             -0.999217
evaluation/Num Paths               15
evaluation/Average Returns        -56.1399
time/data storing (s)               0.00282789
time/evaluation sampling (s)        0.324689
time/exploration sampling (s)       0.137047
time/logging (s)                    0.00477738
time/saving (s)                     0.00198783
time/training (s)                   1.95498
time/epoch (s)                      2.42631
time/total (s)                    905.542
Epoch                             371
-----------------------------  ---------------
2019-04-23 00:08:28.184953 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 372 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.244501
trainer/QF2 Loss                    0.205152
trainer/Policy Loss                34.3359
trainer/Q1 Predictions Mean       -32.2318
trainer/Q1 Predictions Std         35.1034
trainer/Q1 Predictions Max         -8.25531
trainer/Q1 Predictions Min       -111.275
trainer/Q2 Predictions Mean       -32.2662
trainer/Q2 Predictions Std         35.0952
trainer/Q2 Predictions Max         -8.213
trainer/Q2 Predictions Min       -110.992
trainer/Q Targets Mean            -32.4133
trainer/Q Targets Std              35.2927
trainer/Q Targets Max              -8.16095
trainer/Q Targets Min            -111.148
trainer/Log Pis Mean                2.14633
trainer/Log Pis Std                 1.37689
trainer/Log Pis Max                10.8912
trainer/Log Pis Min                -1.02192
trainer/Policy mu Mean              0.019762
trainer/Policy mu Std               0.5533
trainer/Policy mu Max               3.19574
trainer/Policy mu Min              -3.43716
trainer/Policy log std Mean        -2.28028
trainer/Policy log std Std          0.414182
trainer/Policy log std Max         -0.692264
trainer/Policy log std Min         -2.99579
trainer/Alpha                       0.0849361
trainer/Alpha Loss                  0.360846
exploration/num steps total    186700
exploration/num paths total      1867
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.915117
exploration/Rewards Std             0.989485
exploration/Rewards Max            -0.0050234
exploration/Rewards Min            -8.91106
exploration/Returns Mean          -91.5117
exploration/Returns Std            58.0015
exploration/Returns Max           -13.9176
exploration/Returns Min          -169.92
exploration/Actions Mean            0.0229124
exploration/Actions Std             0.202859
exploration/Actions Max             0.999539
exploration/Actions Min            -0.977267
exploration/Num Paths               5
exploration/Average Returns       -91.5117
evaluation/num steps total     559500
evaluation/num paths total       5595
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.564226
evaluation/Rewards Std              1.13839
evaluation/Rewards Max             -0.0263996
evaluation/Rewards Min             -9.99552
evaluation/Returns Mean           -56.4226
evaluation/Returns Std             61.8145
evaluation/Returns Max             -4.38464
evaluation/Returns Min           -223.106
evaluation/Actions Mean             0.0145023
evaluation/Actions Std              0.189213
evaluation/Actions Max              0.998731
evaluation/Actions Min             -0.998776
evaluation/Num Paths               15
evaluation/Average Returns        -56.4226
time/data storing (s)               0.00260692
time/evaluation sampling (s)        0.33124
time/exploration sampling (s)       0.134798
time/logging (s)                    0.00479544
time/saving (s)                     0.00198197
time/training (s)                   1.96462
time/epoch (s)                      2.44004
time/total (s)                    907.986
Epoch                             372
-----------------------------  ---------------
2019-04-23 00:08:30.610802 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 373 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  144.873
trainer/QF2 Loss                  145.269
trainer/Policy Loss                42.2177
trainer/Q1 Predictions Mean       -40.2469
trainer/Q1 Predictions Std         40.1527
trainer/Q1 Predictions Max         -8.30918
trainer/Q1 Predictions Min       -118.75
trainer/Q2 Predictions Mean       -40.1767
trainer/Q2 Predictions Std         40.1007
trainer/Q2 Predictions Max         -8.21807
trainer/Q2 Predictions Min       -117.428
trainer/Q Targets Mean            -38.7543
trainer/Q Targets Std              40.1175
trainer/Q Targets Max              -0.319475
trainer/Q Targets Min            -117.54
trainer/Log Pis Mean                2.10153
trainer/Log Pis Std                 1.0634
trainer/Log Pis Max                 3.98707
trainer/Log Pis Min                -1.39683
trainer/Policy mu Mean             -0.0546475
trainer/Policy mu Std               0.426102
trainer/Policy mu Max               1.51113
trainer/Policy mu Min              -3.16361
trainer/Policy log std Mean        -2.31348
trainer/Policy log std Std          0.422961
trainer/Policy log std Max         -0.603316
trainer/Policy log std Min         -2.93867
trainer/Alpha                       0.0837129
trainer/Alpha Loss                  0.251826
exploration/num steps total    187200
exploration/num paths total      1872
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.562111
exploration/Rewards Std             0.939209
exploration/Rewards Max            -0.00897155
exploration/Rewards Min            -9.06867
exploration/Returns Mean          -56.2111
exploration/Returns Std            47.6833
exploration/Returns Max           -21.5092
exploration/Returns Min          -149.599
exploration/Actions Mean           -0.0106318
exploration/Actions Std             0.228773
exploration/Actions Max             0.995103
exploration/Actions Min            -0.99929
exploration/Num Paths               5
exploration/Average Returns       -56.2111
evaluation/num steps total     561000
evaluation/num paths total       5610
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.566228
evaluation/Rewards Std              1.07324
evaluation/Rewards Max             -0.0515732
evaluation/Rewards Min             -9.50954
evaluation/Returns Mean           -56.6228
evaluation/Returns Std             57.7643
evaluation/Returns Max            -11.3614
evaluation/Returns Min           -216.507
evaluation/Actions Mean             0.00720867
evaluation/Actions Std              0.180687
evaluation/Actions Max              0.998348
evaluation/Actions Min             -0.997822
evaluation/Num Paths               15
evaluation/Average Returns        -56.6228
time/data storing (s)               0.00270593
time/evaluation sampling (s)        0.326678
time/exploration sampling (s)       0.134853
time/logging (s)                    0.00477505
time/saving (s)                     0.00204603
time/training (s)                   1.94485
time/epoch (s)                      2.41591
time/total (s)                    910.406
Epoch                             373
-----------------------------  ---------------
2019-04-23 00:08:33.033075 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 374 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.88811
trainer/QF2 Loss                    0.881851
trainer/Policy Loss                30.313
trainer/Q1 Predictions Mean       -28.371
trainer/Q1 Predictions Std         31.701
trainer/Q1 Predictions Max         -8.21771
trainer/Q1 Predictions Min       -110.764
trainer/Q2 Predictions Mean       -28.4315
trainer/Q2 Predictions Std         31.7094
trainer/Q2 Predictions Max         -8.12945
trainer/Q2 Predictions Min       -110.785
trainer/Q Targets Mean            -28.3138
trainer/Q Targets Std              31.9442
trainer/Q Targets Max              -0.1775
trainer/Q Targets Min            -111
trainer/Log Pis Mean                1.97229
trainer/Log Pis Std                 1.24914
trainer/Log Pis Max                 5.27861
trainer/Log Pis Min                -1.87674
trainer/Policy mu Mean              0.0417058
trainer/Policy mu Std               0.483055
trainer/Policy mu Max               2.37318
trainer/Policy mu Min              -2.47653
trainer/Policy log std Mean        -2.25396
trainer/Policy log std Std          0.43469
trainer/Policy log std Max         -0.301191
trainer/Policy log std Min         -2.95413
trainer/Alpha                       0.084193
trainer/Alpha Loss                 -0.0685765
exploration/num steps total    187700
exploration/num paths total      1877
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.564131
exploration/Rewards Std             1.05789
exploration/Rewards Max            -0.0083723
exploration/Rewards Min            -8.29719
exploration/Returns Mean          -56.4131
exploration/Returns Std            30.4899
exploration/Returns Max           -23.5273
exploration/Returns Min          -109.853
exploration/Actions Mean           -0.00941166
exploration/Actions Std             0.229006
exploration/Actions Max             0.997592
exploration/Actions Min            -0.997818
exploration/Num Paths               5
exploration/Average Returns       -56.4131
evaluation/num steps total     562500
evaluation/num paths total       5625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.70313
evaluation/Rewards Std              1.02423
evaluation/Rewards Max             -0.0218891
evaluation/Rewards Min             -9.32399
evaluation/Returns Mean           -70.313
evaluation/Returns Std             45.6009
evaluation/Returns Max            -16.2209
evaluation/Returns Min           -162.414
evaluation/Actions Mean             0.00705582
evaluation/Actions Std              0.189524
evaluation/Actions Max              0.99784
evaluation/Actions Min             -0.998697
evaluation/Num Paths               15
evaluation/Average Returns        -70.313
time/data storing (s)               0.00265665
time/evaluation sampling (s)        0.328972
time/exploration sampling (s)       0.138754
time/logging (s)                    0.00477577
time/saving (s)                     0.00197489
time/training (s)                   1.93575
time/epoch (s)                      2.41289
time/total (s)                    912.823
Epoch                             374
-----------------------------  ---------------
2019-04-23 00:08:35.477825 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 375 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   32.4619
trainer/QF2 Loss                   32.4028
trainer/Policy Loss                32.7092
trainer/Q1 Predictions Mean       -30.9908
trainer/Q1 Predictions Std         31.6561
trainer/Q1 Predictions Max         -8.04416
trainer/Q1 Predictions Min       -109.874
trainer/Q2 Predictions Mean       -30.955
trainer/Q2 Predictions Std         31.6455
trainer/Q2 Predictions Max         -8.06032
trainer/Q2 Predictions Min       -109.795
trainer/Q Targets Mean            -30.5701
trainer/Q Targets Std              32.1405
trainer/Q Targets Max              -0.372543
trainer/Q Targets Min            -110.872
trainer/Log Pis Mean                1.81562
trainer/Log Pis Std                 1.27498
trainer/Log Pis Max                 8.17307
trainer/Log Pis Min                -1.22044
trainer/Policy mu Mean             -0.0167798
trainer/Policy mu Std               0.384372
trainer/Policy mu Max               2.40689
trainer/Policy mu Min              -3.23843
trainer/Policy log std Mean        -2.27915
trainer/Policy log std Std          0.349501
trainer/Policy log std Max         -0.696561
trainer/Policy log std Min         -2.99932
trainer/Alpha                       0.0836933
trainer/Alpha Loss                 -0.457374
exploration/num steps total    188200
exploration/num paths total      1882
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.643473
exploration/Rewards Std             1.24835
exploration/Rewards Max            -0.00807967
exploration/Rewards Min           -10.899
exploration/Returns Mean          -64.3473
exploration/Returns Std            52.1509
exploration/Returns Max           -13.7117
exploration/Returns Min          -157.033
exploration/Actions Mean           -0.003686
exploration/Actions Std             0.219956
exploration/Actions Max             0.99968
exploration/Actions Min            -0.999915
exploration/Num Paths               5
exploration/Average Returns       -64.3473
evaluation/num steps total     564000
evaluation/num paths total       5640
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.707409
evaluation/Rewards Std              1.19417
evaluation/Rewards Max             -0.0618721
evaluation/Rewards Min            -11.697
evaluation/Returns Mean           -70.7409
evaluation/Returns Std             60.9783
evaluation/Returns Max            -12.4543
evaluation/Returns Min           -224.656
evaluation/Actions Mean             0.0126782
evaluation/Actions Std              0.18165
evaluation/Actions Max              0.998776
evaluation/Actions Min             -0.995739
evaluation/Num Paths               15
evaluation/Average Returns        -70.7409
time/data storing (s)               0.00262009
time/evaluation sampling (s)        0.326442
time/exploration sampling (s)       0.13835
time/logging (s)                    0.00478756
time/saving (s)                     0.00198599
time/training (s)                   1.96161
time/epoch (s)                      2.4358
time/total (s)                    915.263
Epoch                             375
-----------------------------  ---------------
2019-04-23 00:08:37.913920 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 376 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  118.753
trainer/QF2 Loss                  118.026
trainer/Policy Loss                29.2094
trainer/Q1 Predictions Mean       -27.2413
trainer/Q1 Predictions Std         33.4883
trainer/Q1 Predictions Max         -8.2504
trainer/Q1 Predictions Min       -111.366
trainer/Q2 Predictions Mean       -27.2454
trainer/Q2 Predictions Std         33.4754
trainer/Q2 Predictions Max         -8.24042
trainer/Q2 Predictions Min       -111.181
trainer/Q Targets Mean            -26.2479
trainer/Q Targets Std              32.5379
trainer/Q Targets Max              -2.33753
trainer/Q Targets Min            -111.273
trainer/Log Pis Mean                1.98842
trainer/Log Pis Std                 1.04415
trainer/Log Pis Max                 4.94394
trainer/Log Pis Min                -3.05965
trainer/Policy mu Mean             -0.0082197
trainer/Policy mu Std               0.407619
trainer/Policy mu Max               2.64127
trainer/Policy mu Min              -2.82843
trainer/Policy log std Mean        -2.2515
trainer/Policy log std Std          0.404944
trainer/Policy log std Max         -0.471127
trainer/Policy log std Min         -3.08477
trainer/Alpha                       0.0848135
trainer/Alpha Loss                 -0.0285718
exploration/num steps total    188700
exploration/num paths total      1887
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.823545
exploration/Rewards Std             0.933648
exploration/Rewards Max            -0.0154823
exploration/Rewards Min            -5.17777
exploration/Returns Mean          -82.3545
exploration/Returns Std            86.3607
exploration/Returns Max           -15.9797
exploration/Returns Min          -238.565
exploration/Actions Mean            0.00515816
exploration/Actions Std             0.169787
exploration/Actions Max             0.999678
exploration/Actions Min            -0.995281
exploration/Num Paths               5
exploration/Average Returns       -82.3545
evaluation/num steps total     565500
evaluation/num paths total       5655
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.495771
evaluation/Rewards Std              0.850242
evaluation/Rewards Max             -0.0309875
evaluation/Rewards Min             -6.52561
evaluation/Returns Mean           -49.5771
evaluation/Returns Std             65.5573
evaluation/Returns Max             -6.57577
evaluation/Returns Min           -247.581
evaluation/Actions Mean             0.000973402
evaluation/Actions Std              0.15991
evaluation/Actions Max              0.99083
evaluation/Actions Min             -0.997873
evaluation/Num Paths               15
evaluation/Average Returns        -49.5771
time/data storing (s)               0.00259285
time/evaluation sampling (s)        0.325174
time/exploration sampling (s)       0.139354
time/logging (s)                    0.00385128
time/saving (s)                     0.00196625
time/training (s)                   1.95215
time/epoch (s)                      2.42509
time/total (s)                    917.692
Epoch                             376
-----------------------------  ----------------
2019-04-23 00:08:40.352891 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 377 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.197712
trainer/QF2 Loss                    0.170018
trainer/Policy Loss                30.2852
trainer/Q1 Predictions Mean       -28.1284
trainer/Q1 Predictions Std         32.5841
trainer/Q1 Predictions Max         -8.19667
trainer/Q1 Predictions Min       -110.343
trainer/Q2 Predictions Mean       -28.2526
trainer/Q2 Predictions Std         32.6357
trainer/Q2 Predictions Max         -8.24904
trainer/Q2 Predictions Min       -110.717
trainer/Q Targets Mean            -28.2916
trainer/Q Targets Std              32.8832
trainer/Q Targets Max              -8.12225
trainer/Q Targets Min            -111.013
trainer/Log Pis Mean                2.08605
trainer/Log Pis Std                 1.30931
trainer/Log Pis Max                 6.90515
trainer/Log Pis Min                -3.01268
trainer/Policy mu Mean              0.0297628
trainer/Policy mu Std               0.466505
trainer/Policy mu Max               3.00215
trainer/Policy mu Min              -2.08167
trainer/Policy log std Mean        -2.30313
trainer/Policy log std Std          0.381158
trainer/Policy log std Max         -0.711191
trainer/Policy log std Min         -2.99463
trainer/Alpha                       0.0840923
trainer/Alpha Loss                  0.213041
exploration/num steps total    189200
exploration/num paths total      1892
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.511529
exploration/Rewards Std             0.797353
exploration/Rewards Max            -0.00736905
exploration/Rewards Min            -7.27328
exploration/Returns Mean          -51.1529
exploration/Returns Std            49.8205
exploration/Returns Max           -16.6296
exploration/Returns Min          -149.28
exploration/Actions Mean            0.0111811
exploration/Actions Std             0.198474
exploration/Actions Max             0.99569
exploration/Actions Min            -0.992576
exploration/Num Paths               5
exploration/Average Returns       -51.1529
evaluation/num steps total     567000
evaluation/num paths total       5670
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.890839
evaluation/Rewards Std              1.20138
evaluation/Rewards Max             -0.00701002
evaluation/Rewards Min            -11.7416
evaluation/Returns Mean           -89.0839
evaluation/Returns Std             91.3694
evaluation/Returns Max             -2.67651
evaluation/Returns Min           -246.674
evaluation/Actions Mean            -0.00547324
evaluation/Actions Std              0.177461
evaluation/Actions Max              0.99923
evaluation/Actions Min             -0.998254
evaluation/Num Paths               15
evaluation/Average Returns        -89.0839
time/data storing (s)               0.00290084
time/evaluation sampling (s)        0.31949
time/exploration sampling (s)       0.139476
time/logging (s)                    0.0048101
time/saving (s)                     0.00196849
time/training (s)                   1.96133
time/epoch (s)                      2.42998
time/total (s)                    920.126
Epoch                             377
-----------------------------  ---------------
2019-04-23 00:08:42.815033 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 378 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.6243
trainer/QF2 Loss                    1.60957
trainer/Policy Loss                34.1434
trainer/Q1 Predictions Mean       -32.1956
trainer/Q1 Predictions Std         33.96
trainer/Q1 Predictions Max         -8.26629
trainer/Q1 Predictions Min       -110.367
trainer/Q2 Predictions Mean       -32.237
trainer/Q2 Predictions Std         33.971
trainer/Q2 Predictions Max         -8.23175
trainer/Q2 Predictions Min       -110.481
trainer/Q Targets Mean            -32.3675
trainer/Q Targets Std              34.2269
trainer/Q Targets Max              -0.323235
trainer/Q Targets Min            -110.43
trainer/Log Pis Mean                2.00154
trainer/Log Pis Std                 1.0408
trainer/Log Pis Max                 4.37391
trainer/Log Pis Min                -1.29296
trainer/Policy mu Mean             -0.0184171
trainer/Policy mu Std               0.418301
trainer/Policy mu Max               2.07552
trainer/Policy mu Min              -2.96687
trainer/Policy log std Mean        -2.24712
trainer/Policy log std Std          0.412077
trainer/Policy log std Max         -0.550264
trainer/Policy log std Min         -3.02749
trainer/Alpha                       0.0836765
trainer/Alpha Loss                  0.00383053
exploration/num steps total    189700
exploration/num paths total      1897
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.604946
exploration/Rewards Std             1.21057
exploration/Rewards Max            -0.00481025
exploration/Rewards Min           -10.2223
exploration/Returns Mean          -60.4946
exploration/Returns Std            45.8386
exploration/Returns Max           -14.2828
exploration/Returns Min          -142.207
exploration/Actions Mean           -0.0178605
exploration/Actions Std             0.228005
exploration/Actions Max             0.992626
exploration/Actions Min            -0.999759
exploration/Num Paths               5
exploration/Average Returns       -60.4946
evaluation/num steps total     568500
evaluation/num paths total       5685
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.982039
evaluation/Rewards Std              1.10359
evaluation/Rewards Max             -0.0376404
evaluation/Rewards Min            -10.4146
evaluation/Returns Mean           -98.2039
evaluation/Returns Std             52.5219
evaluation/Returns Max            -23.4903
evaluation/Returns Min           -233.173
evaluation/Actions Mean            -0.00274537
evaluation/Actions Std              0.189261
evaluation/Actions Max              0.999034
evaluation/Actions Min             -0.999484
evaluation/Num Paths               15
evaluation/Average Returns        -98.2039
time/data storing (s)               0.0027122
time/evaluation sampling (s)        0.330144
time/exploration sampling (s)       0.137175
time/logging (s)                    0.00482287
time/saving (s)                     0.00983114
time/training (s)                   1.96815
time/epoch (s)                      2.45283
time/total (s)                    922.584
Epoch                             378
-----------------------------  ---------------
2019-04-23 00:08:45.242327 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 379 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.25463
trainer/QF2 Loss                    2.33799
trainer/Policy Loss                30.8906
trainer/Q1 Predictions Mean       -28.9309
trainer/Q1 Predictions Std         30.8537
trainer/Q1 Predictions Max         -7.97919
trainer/Q1 Predictions Min       -107.793
trainer/Q2 Predictions Mean       -28.896
trainer/Q2 Predictions Std         30.882
trainer/Q2 Predictions Max         -7.85487
trainer/Q2 Predictions Min       -107.91
trainer/Q Targets Mean            -29.3046
trainer/Q Targets Std              31.5153
trainer/Q Targets Max              -0.430154
trainer/Q Targets Min            -110.257
trainer/Log Pis Mean                2.06294
trainer/Log Pis Std                 1.1006
trainer/Log Pis Max                 5.71245
trainer/Log Pis Min                -3.31828
trainer/Policy mu Mean              0.0180381
trainer/Policy mu Std               0.485904
trainer/Policy mu Max               2.49358
trainer/Policy mu Min              -3.16758
trainer/Policy log std Mean        -2.24617
trainer/Policy log std Std          0.387741
trainer/Policy log std Max         -0.436704
trainer/Policy log std Min         -2.82472
trainer/Alpha                       0.085356
trainer/Alpha Loss                  0.154896
exploration/num steps total    190200
exploration/num paths total      1902
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.84764
exploration/Rewards Std             1.31614
exploration/Rewards Max            -0.00107967
exploration/Rewards Min           -10.1476
exploration/Returns Mean          -84.764
exploration/Returns Std            38.6197
exploration/Returns Max           -38.9111
exploration/Returns Min          -142.1
exploration/Actions Mean           -0.0308969
exploration/Actions Std             0.253231
exploration/Actions Max             0.997194
exploration/Actions Min            -0.999551
exploration/Num Paths               5
exploration/Average Returns       -84.764
evaluation/num steps total     570000
evaluation/num paths total       5700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.638037
evaluation/Rewards Std              0.94592
evaluation/Rewards Max             -0.0172241
evaluation/Rewards Min             -8.24243
evaluation/Returns Mean           -63.8037
evaluation/Returns Std             68.5068
evaluation/Returns Max             -6.47159
evaluation/Returns Min           -238.659
evaluation/Actions Mean            -0.00307447
evaluation/Actions Std              0.15733
evaluation/Actions Max              0.998744
evaluation/Actions Min             -0.997841
evaluation/Num Paths               15
evaluation/Average Returns        -63.8037
time/data storing (s)               0.00281277
time/evaluation sampling (s)        0.32287
time/exploration sampling (s)       0.13967
time/logging (s)                    0.00483293
time/saving (s)                     0.00199741
time/training (s)                   1.94514
time/epoch (s)                      2.41732
time/total (s)                    925.006
Epoch                             379
-----------------------------  ---------------
2019-04-23 00:08:47.675409 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 380 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.88367
trainer/QF2 Loss                    2.83472
trainer/Policy Loss                34.5254
trainer/Q1 Predictions Mean       -32.6385
trainer/Q1 Predictions Std         35.416
trainer/Q1 Predictions Max         -8.15448
trainer/Q1 Predictions Min       -122.046
trainer/Q2 Predictions Mean       -32.6887
trainer/Q2 Predictions Std         35.4313
trainer/Q2 Predictions Max         -8.09509
trainer/Q2 Predictions Min       -121.509
trainer/Q Targets Mean            -32.5646
trainer/Q Targets Std              35.6989
trainer/Q Targets Max              -0.107458
trainer/Q Targets Min            -121.301
trainer/Log Pis Mean                1.90375
trainer/Log Pis Std                 1.07781
trainer/Log Pis Max                 3.24973
trainer/Log Pis Min                -3.49322
trainer/Policy mu Mean              0.00295874
trainer/Policy mu Std               0.369828
trainer/Policy mu Max               2.50379
trainer/Policy mu Min              -2.54815
trainer/Policy log std Mean        -2.27381
trainer/Policy log std Std          0.366619
trainer/Policy log std Max         -0.11838
trainer/Policy log std Min         -2.83825
trainer/Alpha                       0.0855616
trainer/Alpha Loss                 -0.236625
exploration/num steps total    190700
exploration/num paths total      1907
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.615814
exploration/Rewards Std             1.12123
exploration/Rewards Max            -0.00769367
exploration/Rewards Min            -9.90811
exploration/Returns Mean          -61.5814
exploration/Returns Std            47.7918
exploration/Returns Max           -14.5916
exploration/Returns Min          -144.385
exploration/Actions Mean           -0.0258692
exploration/Actions Std             0.209946
exploration/Actions Max             0.993932
exploration/Actions Min            -0.999919
exploration/Num Paths               5
exploration/Average Returns       -61.5814
evaluation/num steps total     571500
evaluation/num paths total       5715
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.576104
evaluation/Rewards Std              0.905593
evaluation/Rewards Max             -0.046199
evaluation/Rewards Min             -8.35072
evaluation/Returns Mean           -57.6104
evaluation/Returns Std             58.9305
evaluation/Returns Max             -5.9994
evaluation/Returns Min           -226.205
evaluation/Actions Mean             0.0119934
evaluation/Actions Std              0.162836
evaluation/Actions Max              0.9966
evaluation/Actions Min             -0.994479
evaluation/Num Paths               15
evaluation/Average Returns        -57.6104
time/data storing (s)               0.00282674
time/evaluation sampling (s)        0.328101
time/exploration sampling (s)       0.138823
time/logging (s)                    0.00480025
time/saving (s)                     0.0019778
time/training (s)                   1.9464
time/epoch (s)                      2.42293
time/total (s)                    927.433
Epoch                             380
-----------------------------  ---------------
2019-04-23 00:08:50.110792 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 381 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.51605
trainer/QF2 Loss                    2.41106
trainer/Policy Loss                30.3653
trainer/Q1 Predictions Mean       -28.5673
trainer/Q1 Predictions Std         33.1921
trainer/Q1 Predictions Max         -7.74068
trainer/Q1 Predictions Min       -108.808
trainer/Q2 Predictions Mean       -28.56
trainer/Q2 Predictions Std         33.2295
trainer/Q2 Predictions Max         -7.73283
trainer/Q2 Predictions Min       -108.908
trainer/Q Targets Mean            -29.0289
trainer/Q Targets Std              33.9334
trainer/Q Targets Max              -0.647282
trainer/Q Targets Min            -111.557
trainer/Log Pis Mean                1.80265
trainer/Log Pis Std                 1.26288
trainer/Log Pis Max                 5.00603
trainer/Log Pis Min                -2.5695
trainer/Policy mu Mean             -0.0290818
trainer/Policy mu Std               0.547841
trainer/Policy mu Max               2.94963
trainer/Policy mu Min              -2.34475
trainer/Policy log std Mean        -2.19284
trainer/Policy log std Std          0.433805
trainer/Policy log std Max         -0.421191
trainer/Policy log std Min         -2.88756
trainer/Alpha                       0.0864391
trainer/Alpha Loss                 -0.483145
exploration/num steps total    191200
exploration/num paths total      1912
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.868371
exploration/Rewards Std             1.174
exploration/Rewards Max            -0.00495516
exploration/Rewards Min            -9.44086
exploration/Returns Mean          -86.8371
exploration/Returns Std            43.9777
exploration/Returns Max           -15.7211
exploration/Returns Min          -131.19
exploration/Actions Mean            0.048155
exploration/Actions Std             0.224374
exploration/Actions Max             0.997258
exploration/Actions Min            -0.651467
exploration/Num Paths               5
exploration/Average Returns       -86.8371
evaluation/num steps total     573000
evaluation/num paths total       5730
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.565881
evaluation/Rewards Std              1.22995
evaluation/Rewards Max             -0.0214113
evaluation/Rewards Min            -10.6555
evaluation/Returns Mean           -56.5881
evaluation/Returns Std             50.5444
evaluation/Returns Max            -10.192
evaluation/Returns Min           -179.593
evaluation/Actions Mean             0.0120091
evaluation/Actions Std              0.206493
evaluation/Actions Max              0.99911
evaluation/Actions Min             -0.999358
evaluation/Num Paths               15
evaluation/Average Returns        -56.5881
time/data storing (s)               0.0025686
time/evaluation sampling (s)        0.325845
time/exploration sampling (s)       0.137774
time/logging (s)                    0.00482423
time/saving (s)                     0.00199566
time/training (s)                   1.95247
time/epoch (s)                      2.42548
time/total (s)                    929.863
Epoch                             381
-----------------------------  ---------------
2019-04-23 00:08:52.555473 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 382 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   29.74
trainer/QF2 Loss                   29.8625
trainer/Policy Loss                30.3016
trainer/Q1 Predictions Mean       -28.4552
trainer/Q1 Predictions Std         30.6885
trainer/Q1 Predictions Max         -8.07372
trainer/Q1 Predictions Min       -109.976
trainer/Q2 Predictions Mean       -28.4096
trainer/Q2 Predictions Std         30.6802
trainer/Q2 Predictions Max         -8.06592
trainer/Q2 Predictions Min       -109.795
trainer/Q Targets Mean            -28.0049
trainer/Q Targets Std              31.067
trainer/Q Targets Max              -0.0138487
trainer/Q Targets Min            -111.262
trainer/Log Pis Mean                1.9454
trainer/Log Pis Std                 1.20533
trainer/Log Pis Max                 4.51475
trainer/Log Pis Min                -2.69886
trainer/Policy mu Mean              0.0625761
trainer/Policy mu Std               0.346222
trainer/Policy mu Max               2.59498
trainer/Policy mu Min              -1.51712
trainer/Policy log std Mean        -2.30376
trainer/Policy log std Std          0.340569
trainer/Policy log std Max         -0.778691
trainer/Policy log std Min         -2.93782
trainer/Alpha                       0.0869875
trainer/Alpha Loss                 -0.133349
exploration/num steps total    191700
exploration/num paths total      1917
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.861302
exploration/Rewards Std             0.915407
exploration/Rewards Max            -0.0201856
exploration/Rewards Min            -7.69696
exploration/Returns Mean          -86.1302
exploration/Returns Std            43.1238
exploration/Returns Max           -27.7935
exploration/Returns Min          -140.287
exploration/Actions Mean            0.0111396
exploration/Actions Std             0.211012
exploration/Actions Max             0.999748
exploration/Actions Min            -0.998975
exploration/Num Paths               5
exploration/Average Returns       -86.1302
evaluation/num steps total     574500
evaluation/num paths total       5745
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.709291
evaluation/Rewards Std              1.0313
evaluation/Rewards Max             -0.0427468
evaluation/Rewards Min             -9.09584
evaluation/Returns Mean           -70.9291
evaluation/Returns Std             54.5279
evaluation/Returns Max            -12.4924
evaluation/Returns Min           -160.057
evaluation/Actions Mean             0.023984
evaluation/Actions Std              0.184337
evaluation/Actions Max              0.998104
evaluation/Actions Min             -0.996636
evaluation/Num Paths               15
evaluation/Average Returns        -70.9291
time/data storing (s)               0.00268944
time/evaluation sampling (s)        0.326111
time/exploration sampling (s)       0.136281
time/logging (s)                    0.00477594
time/saving (s)                     0.00198322
time/training (s)                   1.96277
time/epoch (s)                      2.43461
time/total (s)                    932.302
Epoch                             382
-----------------------------  ---------------
2019-04-23 00:08:54.992455 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 383 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.238489
trainer/QF2 Loss                    0.174644
trainer/Policy Loss                34.7935
trainer/Q1 Predictions Mean       -32.8842
trainer/Q1 Predictions Std         33.8845
trainer/Q1 Predictions Max         -7.97354
trainer/Q1 Predictions Min       -116.085
trainer/Q2 Predictions Mean       -32.894
trainer/Q2 Predictions Std         33.892
trainer/Q2 Predictions Max         -7.95318
trainer/Q2 Predictions Min       -115.621
trainer/Q Targets Mean            -32.9921
trainer/Q Targets Std              33.9459
trainer/Q Targets Max              -8.05801
trainer/Q Targets Min            -112.98
trainer/Log Pis Mean                1.94541
trainer/Log Pis Std                 1.12935
trainer/Log Pis Max                 4.85332
trainer/Log Pis Min                -1.19742
trainer/Policy mu Mean              0.0170744
trainer/Policy mu Std               0.586045
trainer/Policy mu Max               2.8599
trainer/Policy mu Min              -3.61427
trainer/Policy log std Mean        -2.18149
trainer/Policy log std Std          0.428401
trainer/Policy log std Max         -0.343579
trainer/Policy log std Min         -2.66555
trainer/Alpha                       0.0850333
trainer/Alpha Loss                 -0.13455
exploration/num steps total    192200
exploration/num paths total      1922
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.566077
exploration/Rewards Std             1.22528
exploration/Rewards Max            -0.00591956
exploration/Rewards Min           -10.442
exploration/Returns Mean          -56.6077
exploration/Returns Std            42.111
exploration/Returns Max           -19.0969
exploration/Returns Min          -133.04
exploration/Actions Mean            0.00814372
exploration/Actions Std             0.23035
exploration/Actions Max             0.99971
exploration/Actions Min            -0.999356
exploration/Num Paths               5
exploration/Average Returns       -56.6077
evaluation/num steps total     576000
evaluation/num paths total       5760
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.743048
evaluation/Rewards Std              1.01586
evaluation/Rewards Max             -0.0168949
evaluation/Rewards Min            -10.0958
evaluation/Returns Mean           -74.3048
evaluation/Returns Std             73.1434
evaluation/Returns Max            -14.1815
evaluation/Returns Min           -222.162
evaluation/Actions Mean            -0.00464236
evaluation/Actions Std              0.17132
evaluation/Actions Max              0.998623
evaluation/Actions Min             -0.996087
evaluation/Num Paths               15
evaluation/Average Returns        -74.3048
time/data storing (s)               0.00270372
time/evaluation sampling (s)        0.322054
time/exploration sampling (s)       0.139
time/logging (s)                    0.00482415
time/saving (s)                     0.00199473
time/training (s)                   1.9573
time/epoch (s)                      2.42788
time/total (s)                    934.734
Epoch                             383
-----------------------------  ---------------
2019-04-23 00:08:57.421648 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 384 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  114.001
trainer/QF2 Loss                  114.197
trainer/Policy Loss                29.5204
trainer/Q1 Predictions Mean       -27.4072
trainer/Q1 Predictions Std         30.4834
trainer/Q1 Predictions Max         -7.77626
trainer/Q1 Predictions Min       -108.892
trainer/Q2 Predictions Mean       -27.304
trainer/Q2 Predictions Std         30.4441
trainer/Q2 Predictions Max         -7.76218
trainer/Q2 Predictions Min       -108.601
trainer/Q Targets Mean            -26.7989
trainer/Q Targets Std              30.2062
trainer/Q Targets Max              -0.123091
trainer/Q Targets Min            -111.523
trainer/Log Pis Mean                2.20979
trainer/Log Pis Std                 1.28952
trainer/Log Pis Max                 8.61913
trainer/Log Pis Min                -2.27578
trainer/Policy mu Mean              0.0274462
trainer/Policy mu Std               0.564901
trainer/Policy mu Max               3.30075
trainer/Policy mu Min              -3.06515
trainer/Policy log std Mean        -2.27133
trainer/Policy log std Std          0.438801
trainer/Policy log std Max         -0.407776
trainer/Policy log std Min         -3.01887
trainer/Alpha                       0.0869906
trainer/Alpha Loss                  0.51233
exploration/num steps total    192700
exploration/num paths total      1927
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.18648
exploration/Rewards Std             1.3095
exploration/Rewards Max            -0.0102009
exploration/Rewards Min            -8.57119
exploration/Returns Mean         -118.648
exploration/Returns Std           105.399
exploration/Returns Max           -20.4478
exploration/Returns Min          -251.505
exploration/Actions Mean           -0.0375752
exploration/Actions Std             0.218926
exploration/Actions Max             0.981044
exploration/Actions Min            -0.997963
exploration/Num Paths               5
exploration/Average Returns      -118.648
evaluation/num steps total     577500
evaluation/num paths total       5775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.81019
evaluation/Rewards Std              1.18742
evaluation/Rewards Max             -0.0110345
evaluation/Rewards Min             -9.21481
evaluation/Returns Mean           -81.019
evaluation/Returns Std             77.1939
evaluation/Returns Max             -9.6541
evaluation/Returns Min           -242.397
evaluation/Actions Mean            -0.00219125
evaluation/Actions Std              0.192336
evaluation/Actions Max              0.996123
evaluation/Actions Min             -0.999385
evaluation/Num Paths               15
evaluation/Average Returns        -81.019
time/data storing (s)               0.00301919
time/evaluation sampling (s)        0.327346
time/exploration sampling (s)       0.137288
time/logging (s)                    0.00476445
time/saving (s)                     0.00205047
time/training (s)                   1.94434
time/epoch (s)                      2.41881
time/total (s)                    937.157
Epoch                             384
-----------------------------  ---------------
2019-04-23 00:08:59.876043 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 385 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.323111
trainer/QF2 Loss                    0.282482
trainer/Policy Loss                38.5068
trainer/Q1 Predictions Mean       -36.4431
trainer/Q1 Predictions Std         37.3359
trainer/Q1 Predictions Max         -7.89129
trainer/Q1 Predictions Min       -110.1
trainer/Q2 Predictions Mean       -36.4558
trainer/Q2 Predictions Std         37.3707
trainer/Q2 Predictions Max         -7.86947
trainer/Q2 Predictions Min       -110.185
trainer/Q Targets Mean            -36.7795
trainer/Q Targets Std              37.6254
trainer/Q Targets Max              -7.95694
trainer/Q Targets Min            -111.159
trainer/Log Pis Mean                2.12463
trainer/Log Pis Std                 1.32185
trainer/Log Pis Max                 7.09783
trainer/Log Pis Min                -2.39891
trainer/Policy mu Mean              0.0109474
trainer/Policy mu Std               0.638396
trainer/Policy mu Max               2.86192
trainer/Policy mu Min              -3.12822
trainer/Policy log std Mean        -2.23018
trainer/Policy log std Std          0.488941
trainer/Policy log std Max         -0.485971
trainer/Policy log std Min         -3.03006
trainer/Alpha                       0.0855849
trainer/Alpha Loss                  0.306394
exploration/num steps total    193200
exploration/num paths total      1932
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.771464
exploration/Rewards Std             0.810148
exploration/Rewards Max            -0.0138219
exploration/Rewards Min            -5.71724
exploration/Returns Mean          -77.1464
exploration/Returns Std            60.8978
exploration/Returns Max           -18.0496
exploration/Returns Min          -155.358
exploration/Actions Mean           -0.00280093
exploration/Actions Std             0.202893
exploration/Actions Max             0.995207
exploration/Actions Min            -0.995693
exploration/Num Paths               5
exploration/Average Returns       -77.1464
evaluation/num steps total     579000
evaluation/num paths total       5790
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.28121
evaluation/Rewards Std              1.16264
evaluation/Rewards Max             -0.0278171
evaluation/Rewards Min             -9.74088
evaluation/Returns Mean          -128.121
evaluation/Returns Std             70.8831
evaluation/Returns Max            -12.1209
evaluation/Returns Min           -239.089
evaluation/Actions Mean             0.00320762
evaluation/Actions Std              0.190945
evaluation/Actions Max              0.998116
evaluation/Actions Min             -0.997872
evaluation/Num Paths               15
evaluation/Average Returns       -128.121
time/data storing (s)               0.00275887
time/evaluation sampling (s)        0.324849
time/exploration sampling (s)       0.138534
time/logging (s)                    0.00477629
time/saving (s)                     0.00199699
time/training (s)                   1.9715
time/epoch (s)                      2.44441
time/total (s)                    939.606
Epoch                             385
-----------------------------  ---------------
2019-04-23 00:09:02.325143 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 386 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  145.258
trainer/QF2 Loss                  145.328
trainer/Policy Loss                35.8323
trainer/Q1 Predictions Mean       -33.9357
trainer/Q1 Predictions Std         33.9893
trainer/Q1 Predictions Max         -8.20933
trainer/Q1 Predictions Min       -114.518
trainer/Q2 Predictions Mean       -33.9164
trainer/Q2 Predictions Std         33.9633
trainer/Q2 Predictions Max         -8.205
trainer/Q2 Predictions Min       -113.93
trainer/Q Targets Mean            -32.176
trainer/Q Targets Std              33.2554
trainer/Q Targets Max              -0.871453
trainer/Q Targets Min            -112.872
trainer/Log Pis Mean                1.89179
trainer/Log Pis Std                 1.23252
trainer/Log Pis Max                 6.32139
trainer/Log Pis Min                -1.35281
trainer/Policy mu Mean              0.00849594
trainer/Policy mu Std               0.446694
trainer/Policy mu Max               2.73394
trainer/Policy mu Min              -2.90608
trainer/Policy log std Mean        -2.22891
trainer/Policy log std Std          0.400929
trainer/Policy log std Max         -0.408223
trainer/Policy log std Min         -2.89041
trainer/Alpha                       0.0847565
trainer/Alpha Loss                 -0.267023
exploration/num steps total    193700
exploration/num paths total      1937
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.73041
exploration/Rewards Std             1.1991
exploration/Rewards Max            -0.00371472
exploration/Rewards Min           -10.0699
exploration/Returns Mean          -73.041
exploration/Returns Std            77.9986
exploration/Returns Max           -17.995
exploration/Returns Min          -226.149
exploration/Actions Mean           -0.00573675
exploration/Actions Std             0.231945
exploration/Actions Max             0.99414
exploration/Actions Min            -0.998779
exploration/Num Paths               5
exploration/Average Returns       -73.041
evaluation/num steps total     580500
evaluation/num paths total       5805
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.468229
evaluation/Rewards Std              1.19046
evaluation/Rewards Max             -0.00394087
evaluation/Rewards Min            -10.4668
evaluation/Returns Mean           -46.8229
evaluation/Returns Std             55.8385
evaluation/Returns Max             -4.44492
evaluation/Returns Min           -236.662
evaluation/Actions Mean            -0.00818732
evaluation/Actions Std              0.199799
evaluation/Actions Max              0.998868
evaluation/Actions Min             -0.999356
evaluation/Num Paths               15
evaluation/Average Returns        -46.8229
time/data storing (s)               0.00266266
time/evaluation sampling (s)        0.331122
time/exploration sampling (s)       0.136992
time/logging (s)                    0.00477778
time/saving (s)                     0.00197882
time/training (s)                   1.96149
time/epoch (s)                      2.43903
time/total (s)                    942.049
Epoch                             386
-----------------------------  ---------------
2019-04-23 00:09:04.767429 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 387 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  115.117
trainer/QF2 Loss                  115.463
trainer/Policy Loss                35.4474
trainer/Q1 Predictions Mean       -33.4111
trainer/Q1 Predictions Std         34.9588
trainer/Q1 Predictions Max         -8.01446
trainer/Q1 Predictions Min       -110.568
trainer/Q2 Predictions Mean       -33.4323
trainer/Q2 Predictions Std         34.9603
trainer/Q2 Predictions Max         -7.99219
trainer/Q2 Predictions Min       -110.553
trainer/Q Targets Mean            -32.3361
trainer/Q Targets Std              34.3154
trainer/Q Targets Max              -2.28301
trainer/Q Targets Min            -110.855
trainer/Log Pis Mean                2.08323
trainer/Log Pis Std                 1.06497
trainer/Log Pis Max                 6.25927
trainer/Log Pis Min                -3.10189
trainer/Policy mu Mean              0.0232453
trainer/Policy mu Std               0.383163
trainer/Policy mu Max               2.24759
trainer/Policy mu Min              -2.30114
trainer/Policy log std Mean        -2.2785
trainer/Policy log std Std          0.372833
trainer/Policy log std Max         -0.575574
trainer/Policy log std Min         -2.7774
trainer/Alpha                       0.0828326
trainer/Alpha Loss                  0.207311
exploration/num steps total    194200
exploration/num paths total      1942
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.852747
exploration/Rewards Std             1.07204
exploration/Rewards Max            -0.0112986
exploration/Rewards Min            -8.7346
exploration/Returns Mean          -85.2747
exploration/Returns Std            75.5407
exploration/Returns Max           -20.3577
exploration/Returns Min          -228.302
exploration/Actions Mean            0.0133498
exploration/Actions Std             0.221478
exploration/Actions Max             0.998731
exploration/Actions Min            -0.99507
exploration/Num Paths               5
exploration/Average Returns       -85.2747
evaluation/num steps total     582000
evaluation/num paths total       5820
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.988524
evaluation/Rewards Std              1.09148
evaluation/Rewards Max             -0.0147242
evaluation/Rewards Min             -8.13596
evaluation/Returns Mean           -98.8524
evaluation/Returns Std             94.3107
evaluation/Returns Max             -5.17136
evaluation/Returns Min           -237.415
evaluation/Actions Mean            -0.0102289
evaluation/Actions Std              0.160154
evaluation/Actions Max              0.993372
evaluation/Actions Min             -0.994662
evaluation/Num Paths               15
evaluation/Average Returns        -98.8524
time/data storing (s)               0.00279912
time/evaluation sampling (s)        0.327155
time/exploration sampling (s)       0.140166
time/logging (s)                    0.00477952
time/saving (s)                     0.00197603
time/training (s)                   1.95559
time/epoch (s)                      2.43247
time/total (s)                    944.486
Epoch                             387
-----------------------------  ---------------
2019-04-23 00:09:07.205766 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 388 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   49.1483
trainer/QF2 Loss                   48.6826
trainer/Policy Loss                35.1386
trainer/Q1 Predictions Mean       -33.2575
trainer/Q1 Predictions Std         35.3274
trainer/Q1 Predictions Max         -8.1773
trainer/Q1 Predictions Min       -110.479
trainer/Q2 Predictions Mean       -33.358
trainer/Q2 Predictions Std         35.3072
trainer/Q2 Predictions Max         -8.16998
trainer/Q2 Predictions Min       -110.73
trainer/Q Targets Mean            -32.6782
trainer/Q Targets Std              35.5029
trainer/Q Targets Max              -1.18937
trainer/Q Targets Min            -111.008
trainer/Log Pis Mean                1.8543
trainer/Log Pis Std                 1.24967
trainer/Log Pis Max                 6.62928
trainer/Log Pis Min                -2.479
trainer/Policy mu Mean              0.00951974
trainer/Policy mu Std               0.521255
trainer/Policy mu Max               2.85155
trainer/Policy mu Min              -2.66666
trainer/Policy log std Mean        -2.16925
trainer/Policy log std Std          0.437971
trainer/Policy log std Max         -0.445854
trainer/Policy log std Min         -2.87506
trainer/Alpha                       0.0836977
trainer/Alpha Loss                 -0.361383
exploration/num steps total    194700
exploration/num paths total      1947
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.81991
exploration/Rewards Std             1.36088
exploration/Rewards Max            -0.00540627
exploration/Rewards Min            -8.65895
exploration/Returns Mean          -81.991
exploration/Returns Std            79.965
exploration/Returns Max           -27.6773
exploration/Returns Min          -240.915
exploration/Actions Mean           -0.0122196
exploration/Actions Std             0.238798
exploration/Actions Max             0.995181
exploration/Actions Min            -0.999106
exploration/Num Paths               5
exploration/Average Returns       -81.991
evaluation/num steps total     583500
evaluation/num paths total       5835
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.592026
evaluation/Rewards Std              1.04454
evaluation/Rewards Max             -0.0141813
evaluation/Rewards Min            -10.2027
evaluation/Returns Mean           -59.2026
evaluation/Returns Std             61.1068
evaluation/Returns Max             -8.72542
evaluation/Returns Min           -225.523
evaluation/Actions Mean             0.00185258
evaluation/Actions Std              0.180203
evaluation/Actions Max              0.998402
evaluation/Actions Min             -0.997753
evaluation/Num Paths               15
evaluation/Average Returns        -59.2026
time/data storing (s)               0.00267239
time/evaluation sampling (s)        0.332722
time/exploration sampling (s)       0.137346
time/logging (s)                    0.00482016
time/saving (s)                     0.00200099
time/training (s)                   1.94866
time/epoch (s)                      2.42822
time/total (s)                    946.919
Epoch                             388
-----------------------------  ---------------
2019-04-23 00:09:09.653772 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 389 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   48.3747
trainer/QF2 Loss                   48.6039
trainer/Policy Loss                33.0388
trainer/Q1 Predictions Mean       -31.1708
trainer/Q1 Predictions Std         32.937
trainer/Q1 Predictions Max         -7.85929
trainer/Q1 Predictions Min       -110.67
trainer/Q2 Predictions Mean       -31.1994
trainer/Q2 Predictions Std         32.9403
trainer/Q2 Predictions Max         -7.84478
trainer/Q2 Predictions Min       -110.331
trainer/Q Targets Mean            -30.679
trainer/Q Targets Std              33.068
trainer/Q Targets Max              -0.047405
trainer/Q Targets Min            -110.455
trainer/Log Pis Mean                1.83653
trainer/Log Pis Std                 1.25789
trainer/Log Pis Max                 7.35009
trainer/Log Pis Min                -3.02293
trainer/Policy mu Mean              0.0319761
trainer/Policy mu Std               0.423327
trainer/Policy mu Max               3.21336
trainer/Policy mu Min              -0.733932
trainer/Policy log std Mean        -2.29407
trainer/Policy log std Std          0.38162
trainer/Policy log std Max         -0.474255
trainer/Policy log std Min         -2.79469
trainer/Alpha                       0.0808583
trainer/Alpha Loss                 -0.411096
exploration/num steps total    195200
exploration/num paths total      1952
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.931428
exploration/Rewards Std             1.06941
exploration/Rewards Max            -0.0181006
exploration/Rewards Min            -7.19643
exploration/Returns Mean          -93.1428
exploration/Returns Std            74.2109
exploration/Returns Max           -24.4404
exploration/Returns Min          -220.161
exploration/Actions Mean            0.00213515
exploration/Actions Std             0.206753
exploration/Actions Max             0.991866
exploration/Actions Min            -0.997963
exploration/Num Paths               5
exploration/Average Returns       -93.1428
evaluation/num steps total     585000
evaluation/num paths total       5850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.576876
evaluation/Rewards Std              1.04415
evaluation/Rewards Max             -0.00749661
evaluation/Rewards Min             -9.67027
evaluation/Returns Mean           -57.6876
evaluation/Returns Std             62.1462
evaluation/Returns Max             -3.37896
evaluation/Returns Min           -222.934
evaluation/Actions Mean            -0.0103435
evaluation/Actions Std              0.180772
evaluation/Actions Max              0.998053
evaluation/Actions Min             -0.999378
evaluation/Num Paths               15
evaluation/Average Returns        -57.6876
time/data storing (s)               0.00311244
time/evaluation sampling (s)        0.331317
time/exploration sampling (s)       0.137691
time/logging (s)                    0.00369185
time/saving (s)                     0.00197317
time/training (s)                   1.959
time/epoch (s)                      2.43678
time/total (s)                    949.36
Epoch                             389
-----------------------------  ---------------
2019-04-23 00:09:12.112772 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 390 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.24785
trainer/QF2 Loss                    2.13046
trainer/Policy Loss                30.2242
trainer/Q1 Predictions Mean       -27.9004
trainer/Q1 Predictions Std         31.7969
trainer/Q1 Predictions Max         -7.61583
trainer/Q1 Predictions Min       -112.608
trainer/Q2 Predictions Mean       -27.9802
trainer/Q2 Predictions Std         31.7707
trainer/Q2 Predictions Max         -7.8659
trainer/Q2 Predictions Min       -112.402
trainer/Q Targets Mean            -28.4204
trainer/Q Targets Std              32.3973
trainer/Q Targets Max              -0.557328
trainer/Q Targets Min            -113.103
trainer/Log Pis Mean                2.32025
trainer/Log Pis Std                 1.11431
trainer/Log Pis Max                 5.73729
trainer/Log Pis Min                -2.2722
trainer/Policy mu Mean             -0.0355194
trainer/Policy mu Std               0.60819
trainer/Policy mu Max               2.52696
trainer/Policy mu Min              -2.98561
trainer/Policy log std Mean        -2.24583
trainer/Policy log std Std          0.517857
trainer/Policy log std Max         -0.39319
trainer/Policy log std Min         -3.00753
trainer/Alpha                       0.0794325
trainer/Alpha Loss                  0.811223
exploration/num steps total    195700
exploration/num paths total      1957
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.06814
exploration/Rewards Std             1.14597
exploration/Rewards Max            -0.0136265
exploration/Rewards Min            -7.38368
exploration/Returns Mean         -106.814
exploration/Returns Std            85.6426
exploration/Returns Max           -34.3068
exploration/Returns Min          -212.496
exploration/Actions Mean           -0.00244066
exploration/Actions Std             0.227205
exploration/Actions Max             0.999522
exploration/Actions Min            -0.998019
exploration/Num Paths               5
exploration/Average Returns      -106.814
evaluation/num steps total     586500
evaluation/num paths total       5865
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.664535
evaluation/Rewards Std              1.12592
evaluation/Rewards Max             -0.0461177
evaluation/Rewards Min             -8.97898
evaluation/Returns Mean           -66.4535
evaluation/Returns Std             66.1409
evaluation/Returns Max             -8.10678
evaluation/Returns Min           -224.862
evaluation/Actions Mean            -0.00346626
evaluation/Actions Std              0.182435
evaluation/Actions Max              0.997893
evaluation/Actions Min             -0.999018
evaluation/Num Paths               15
evaluation/Average Returns        -66.4535
time/data storing (s)               0.00273901
time/evaluation sampling (s)        0.329471
time/exploration sampling (s)       0.139323
time/logging (s)                    0.00480187
time/saving (s)                     0.0100747
time/training (s)                   1.96416
time/epoch (s)                      2.45057
time/total (s)                    951.815
Epoch                             390
-----------------------------  ---------------
2019-04-23 00:09:14.537601 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 391 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.386439
trainer/QF2 Loss                    0.432763
trainer/Policy Loss                29.5653
trainer/Q1 Predictions Mean       -27.6796
trainer/Q1 Predictions Std         32.1602
trainer/Q1 Predictions Max         -7.76873
trainer/Q1 Predictions Min       -108.925
trainer/Q2 Predictions Mean       -27.738
trainer/Q2 Predictions Std         32.1453
trainer/Q2 Predictions Max         -7.85631
trainer/Q2 Predictions Min       -108.892
trainer/Q Targets Mean            -27.8308
trainer/Q Targets Std              32.5718
trainer/Q Targets Max              -7.97953
trainer/Q Targets Min            -109.619
trainer/Log Pis Mean                1.92814
trainer/Log Pis Std                 1.12421
trainer/Log Pis Max                 4.686
trainer/Log Pis Min                -1.53144
trainer/Policy mu Mean              0.00737404
trainer/Policy mu Std               0.418147
trainer/Policy mu Max               2.55435
trainer/Policy mu Min              -2.5412
trainer/Policy log std Mean        -2.27519
trainer/Policy log std Std          0.380348
trainer/Policy log std Max         -0.518651
trainer/Policy log std Min         -3.01779
trainer/Alpha                       0.0845017
trainer/Alpha Loss                 -0.177576
exploration/num steps total    196200
exploration/num paths total      1962
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.39636
exploration/Rewards Std             0.733545
exploration/Rewards Max            -0.004704
exploration/Rewards Min            -7.27869
exploration/Returns Mean          -39.636
exploration/Returns Std            30.4099
exploration/Returns Max           -14.3331
exploration/Returns Min           -97.4679
exploration/Actions Mean            0.0183745
exploration/Actions Std             0.185807
exploration/Actions Max             0.997055
exploration/Actions Min            -0.938157
exploration/Num Paths               5
exploration/Average Returns       -39.636
evaluation/num steps total     588000
evaluation/num paths total       5880
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.675052
evaluation/Rewards Std              1.05395
evaluation/Rewards Max             -0.0396398
evaluation/Rewards Min             -9.44802
evaluation/Returns Mean           -67.5052
evaluation/Returns Std             65.2482
evaluation/Returns Max            -10.7034
evaluation/Returns Min           -227.108
evaluation/Actions Mean             0.0188041
evaluation/Actions Std              0.171364
evaluation/Actions Max              0.998546
evaluation/Actions Min             -0.993449
evaluation/Num Paths               15
evaluation/Average Returns        -67.5052
time/data storing (s)               0.00266675
time/evaluation sampling (s)        0.329508
time/exploration sampling (s)       0.140291
time/logging (s)                    0.00476842
time/saving (s)                     0.00196867
time/training (s)                   1.93552
time/epoch (s)                      2.41472
time/total (s)                    954.235
Epoch                             391
-----------------------------  ---------------
2019-04-23 00:09:16.953605 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 392 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.02359
trainer/QF2 Loss                    3.00042
trainer/Policy Loss                29.1144
trainer/Q1 Predictions Mean       -27.2593
trainer/Q1 Predictions Std         31.8854
trainer/Q1 Predictions Max         -8.02553
trainer/Q1 Predictions Min       -109.098
trainer/Q2 Predictions Mean       -27.2804
trainer/Q2 Predictions Std         31.8821
trainer/Q2 Predictions Max         -7.96933
trainer/Q2 Predictions Min       -109.077
trainer/Q Targets Mean            -27.2556
trainer/Q Targets Std              32.2583
trainer/Q Targets Max              -0.178699
trainer/Q Targets Min            -109.948
trainer/Log Pis Mean                1.95393
trainer/Log Pis Std                 1.31801
trainer/Log Pis Max                 8.2087
trainer/Log Pis Min                -2.86353
trainer/Policy mu Mean             -0.0704772
trainer/Policy mu Std               0.414215
trainer/Policy mu Max               1.8942
trainer/Policy mu Min              -3.14867
trainer/Policy log std Mean        -2.28716
trainer/Policy log std Std          0.347897
trainer/Policy log std Max         -0.399264
trainer/Policy log std Min         -2.9611
trainer/Alpha                       0.0871957
trainer/Alpha Loss                 -0.112406
exploration/num steps total    196700
exploration/num paths total      1967
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.810366
exploration/Rewards Std             0.878877
exploration/Rewards Max            -0.0109168
exploration/Rewards Min            -7.10937
exploration/Returns Mean          -81.0366
exploration/Returns Std            58.4722
exploration/Returns Max           -17.0927
exploration/Returns Min          -153.086
exploration/Actions Mean           -0.0105176
exploration/Actions Std             0.198131
exploration/Actions Max             0.978328
exploration/Actions Min            -0.997715
exploration/Num Paths               5
exploration/Average Returns       -81.0366
evaluation/num steps total     589500
evaluation/num paths total       5895
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.956849
evaluation/Rewards Std              1.05767
evaluation/Rewards Max             -0.00268305
evaluation/Rewards Min             -9.27231
evaluation/Returns Mean           -95.6849
evaluation/Returns Std             83.6202
evaluation/Returns Max             -3.44259
evaluation/Returns Min           -228.096
evaluation/Actions Mean             0.00967983
evaluation/Actions Std              0.171858
evaluation/Actions Max              0.997206
evaluation/Actions Min             -0.996606
evaluation/Num Paths               15
evaluation/Average Returns        -95.6849
time/data storing (s)               0.00333688
time/evaluation sampling (s)        0.327591
time/exploration sampling (s)       0.136728
time/logging (s)                    0.00482046
time/saving (s)                     0.00197056
time/training (s)                   1.93218
time/epoch (s)                      2.40663
time/total (s)                    956.645
Epoch                             392
-----------------------------  ---------------
2019-04-23 00:09:19.378604 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 393 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.38202
trainer/QF2 Loss                    2.44032
trainer/Policy Loss                32.5855
trainer/Q1 Predictions Mean       -30.8236
trainer/Q1 Predictions Std         30.5793
trainer/Q1 Predictions Max         -7.90358
trainer/Q1 Predictions Min       -106.1
trainer/Q2 Predictions Mean       -30.7811
trainer/Q2 Predictions Std         30.554
trainer/Q2 Predictions Max         -7.81938
trainer/Q2 Predictions Min       -105.756
trainer/Q Targets Mean            -31.4498
trainer/Q Targets Std              31.2908
trainer/Q Targets Max              -0.342313
trainer/Q Targets Min            -108.956
trainer/Log Pis Mean                1.81612
trainer/Log Pis Std                 1.28895
trainer/Log Pis Max                 6.98787
trainer/Log Pis Min                -2.42829
trainer/Policy mu Mean              0.0294555
trainer/Policy mu Std               0.47035
trainer/Policy mu Max               3.00105
trainer/Policy mu Min              -2.42384
trainer/Policy log std Mean        -2.20451
trainer/Policy log std Std          0.353305
trainer/Policy log std Max         -0.521826
trainer/Policy log std Min         -2.82923
trainer/Alpha                       0.0849077
trainer/Alpha Loss                 -0.453437
exploration/num steps total    197200
exploration/num paths total      1972
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.07461
exploration/Rewards Std             0.916151
exploration/Rewards Max            -0.00958809
exploration/Rewards Min            -6.95505
exploration/Returns Mean         -107.461
exploration/Returns Std            64.4152
exploration/Returns Max           -24.3022
exploration/Returns Min          -161.772
exploration/Actions Mean           -8.52346e-06
exploration/Actions Std             0.232017
exploration/Actions Max             0.999497
exploration/Actions Min            -0.998555
exploration/Num Paths               5
exploration/Average Returns      -107.461
evaluation/num steps total     591000
evaluation/num paths total       5910
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.635024
evaluation/Rewards Std              1.07445
evaluation/Rewards Max             -0.0456829
evaluation/Rewards Min             -9.29449
evaluation/Returns Mean           -63.5024
evaluation/Returns Std             47.8468
evaluation/Returns Max            -18.1425
evaluation/Returns Min           -166.708
evaluation/Actions Mean             0.0115748
evaluation/Actions Std              0.193029
evaluation/Actions Max              0.996726
evaluation/Actions Min             -0.99799
evaluation/Num Paths               15
evaluation/Average Returns        -63.5024
time/data storing (s)               0.00277254
time/evaluation sampling (s)        0.327135
time/exploration sampling (s)       0.136536
time/logging (s)                    0.00354876
time/saving (s)                     0.00160149
time/training (s)                   1.94191
time/epoch (s)                      2.4135
time/total (s)                    959.062
Epoch                             393
-----------------------------  ----------------
2019-04-23 00:09:21.824646 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 394 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   27.8758
trainer/QF2 Loss                   27.5671
trainer/Policy Loss                32.8399
trainer/Q1 Predictions Mean       -30.8786
trainer/Q1 Predictions Std         30.8948
trainer/Q1 Predictions Max         -7.9872
trainer/Q1 Predictions Min       -107.198
trainer/Q2 Predictions Mean       -30.8348
trainer/Q2 Predictions Std         30.9163
trainer/Q2 Predictions Max         -7.86835
trainer/Q2 Predictions Min       -107.256
trainer/Q Targets Mean            -30.8194
trainer/Q Targets Std              31.4371
trainer/Q Targets Max              -1.08092
trainer/Q Targets Min            -109.74
trainer/Log Pis Mean                2.03175
trainer/Log Pis Std                 1.21918
trainer/Log Pis Max                 7.79157
trainer/Log Pis Min                -1.46973
trainer/Policy mu Mean             -0.0121378
trainer/Policy mu Std               0.403322
trainer/Policy mu Max               1.35463
trainer/Policy mu Min              -4.09229
trainer/Policy log std Mean        -2.32376
trainer/Policy log std Std          0.322664
trainer/Policy log std Max         -0.584741
trainer/Policy log std Min         -2.86257
trainer/Alpha                       0.0822479
trainer/Alpha Loss                  0.0793178
exploration/num steps total    197700
exploration/num paths total      1977
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.510205
exploration/Rewards Std             0.897822
exploration/Rewards Max            -0.0108718
exploration/Rewards Min            -7.87327
exploration/Returns Mean          -51.0205
exploration/Returns Std            24.6715
exploration/Returns Max           -31.5172
exploration/Returns Min           -98.5076
exploration/Actions Mean           -0.015717
exploration/Actions Std             0.220319
exploration/Actions Max             0.997728
exploration/Actions Min            -0.999451
exploration/Num Paths               5
exploration/Average Returns       -51.0205
evaluation/num steps total     592500
evaluation/num paths total       5925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.642548
evaluation/Rewards Std              1.06061
evaluation/Rewards Max             -0.0136323
evaluation/Rewards Min             -8.91497
evaluation/Returns Mean           -64.2548
evaluation/Returns Std             61.5341
evaluation/Returns Max             -6.77519
evaluation/Returns Min           -213.382
evaluation/Actions Mean             0.0105847
evaluation/Actions Std              0.187796
evaluation/Actions Max              0.998724
evaluation/Actions Min             -0.99892
evaluation/Num Paths               15
evaluation/Average Returns        -64.2548
time/data storing (s)               0.00259566
time/evaluation sampling (s)        0.326234
time/exploration sampling (s)       0.14324
time/logging (s)                    0.00357371
time/saving (s)                     0.00198455
time/training (s)                   1.95962
time/epoch (s)                      2.43725
time/total (s)                    961.505
Epoch                             394
-----------------------------  ---------------
2019-04-23 00:09:24.258276 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 395 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.548404
trainer/QF2 Loss                    0.565173
trainer/Policy Loss                37.5583
trainer/Q1 Predictions Mean       -35.5013
trainer/Q1 Predictions Std         34.5318
trainer/Q1 Predictions Max         -7.89283
trainer/Q1 Predictions Min       -108.628
trainer/Q2 Predictions Mean       -35.5102
trainer/Q2 Predictions Std         34.5306
trainer/Q2 Predictions Max         -7.74587
trainer/Q2 Predictions Min       -108.997
trainer/Q Targets Mean            -36.0597
trainer/Q Targets Std              34.9609
trainer/Q Targets Max              -8.04274
trainer/Q Targets Min            -110.138
trainer/Log Pis Mean                2.06717
trainer/Log Pis Std                 1.15481
trainer/Log Pis Max                 7.5862
trainer/Log Pis Min                -2.18215
trainer/Policy mu Mean             -0.0178443
trainer/Policy mu Std               0.426032
trainer/Policy mu Max               1.76281
trainer/Policy mu Min              -3.13573
trainer/Policy log std Mean        -2.29231
trainer/Policy log std Std          0.411602
trainer/Policy log std Max         -0.643562
trainer/Policy log std Min         -2.9579
trainer/Alpha                       0.081126
trainer/Alpha Loss                  0.168715
exploration/num steps total    198200
exploration/num paths total      1982
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.731432
exploration/Rewards Std             1.24014
exploration/Rewards Max            -0.0106584
exploration/Rewards Min           -10.8978
exploration/Returns Mean          -73.1432
exploration/Returns Std            80.9023
exploration/Returns Max           -19.8636
exploration/Returns Min          -232.144
exploration/Actions Mean            0.00187576
exploration/Actions Std             0.216672
exploration/Actions Max             0.998757
exploration/Actions Min            -0.998842
exploration/Num Paths               5
exploration/Average Returns       -73.1432
evaluation/num steps total     594000
evaluation/num paths total       5940
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.496935
evaluation/Rewards Std              0.859238
evaluation/Rewards Max             -0.00628044
evaluation/Rewards Min            -10.3652
evaluation/Returns Mean           -49.6935
evaluation/Returns Std             51.0197
evaluation/Returns Max             -9.62722
evaluation/Returns Min           -177.747
evaluation/Actions Mean            -0.00439702
evaluation/Actions Std              0.156218
evaluation/Actions Max              0.999097
evaluation/Actions Min             -0.998019
evaluation/Num Paths               15
evaluation/Average Returns        -49.6935
time/data storing (s)               0.00273121
time/evaluation sampling (s)        0.327726
time/exploration sampling (s)       0.136402
time/logging (s)                    0.00484951
time/saving (s)                     0.00196769
time/training (s)                   1.95159
time/epoch (s)                      2.42527
time/total (s)                    963.934
Epoch                             395
-----------------------------  ---------------
2019-04-23 00:09:26.713390 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 396 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                  112.128
trainer/QF2 Loss                  112.037
trainer/Policy Loss                33.5429
trainer/Q1 Predictions Mean       -31.3048
trainer/Q1 Predictions Std         32.7862
trainer/Q1 Predictions Max         -7.7379
trainer/Q1 Predictions Min       -108.572
trainer/Q2 Predictions Mean       -31.3089
trainer/Q2 Predictions Std         32.7724
trainer/Q2 Predictions Max         -7.63701
trainer/Q2 Predictions Min       -108.323
trainer/Q Targets Mean            -30.3639
trainer/Q Targets Std              32.2791
trainer/Q Targets Max              -2.40696
trainer/Q Targets Min            -108.897
trainer/Log Pis Mean                2.29826
trainer/Log Pis Std                 1.27917
trainer/Log Pis Max                 8.41904
trainer/Log Pis Min                -0.955582
trainer/Policy mu Mean              0.0668533
trainer/Policy mu Std               0.573689
trainer/Policy mu Max               3.11936
trainer/Policy mu Min              -2.79729
trainer/Policy log std Mean        -2.30326
trainer/Policy log std Std          0.435857
trainer/Policy log std Max         -0.533786
trainer/Policy log std Min         -2.98196
trainer/Alpha                       0.0812187
trainer/Alpha Loss                  0.748868
exploration/num steps total    198700
exploration/num paths total      1987
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.348244
exploration/Rewards Std             1.00318
exploration/Rewards Max            -0.000854578
exploration/Rewards Min            -9.06542
exploration/Returns Mean          -34.8244
exploration/Returns Std            10.2642
exploration/Returns Max           -15.1319
exploration/Returns Min           -44.9314
exploration/Actions Mean            0.00830196
exploration/Actions Std             0.231989
exploration/Actions Max             0.999159
exploration/Actions Min            -0.998602
exploration/Num Paths               5
exploration/Average Returns       -34.8244
evaluation/num steps total     595500
evaluation/num paths total       5955
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.0596
evaluation/Rewards Std              1.28561
evaluation/Rewards Max             -0.00664888
evaluation/Rewards Min            -10.5527
evaluation/Returns Mean          -105.96
evaluation/Returns Std             83.5138
evaluation/Returns Max             -6.72511
evaluation/Returns Min           -226.965
evaluation/Actions Mean            -0.00947388
evaluation/Actions Std              0.195607
evaluation/Actions Max              0.998153
evaluation/Actions Min             -0.999019
evaluation/Num Paths               15
evaluation/Average Returns       -105.96
time/data storing (s)               0.002685
time/evaluation sampling (s)        0.32579
time/exploration sampling (s)       0.138069
time/logging (s)                    0.00444378
time/saving (s)                     0.00161556
time/training (s)                   1.97341
time/epoch (s)                      2.44601
time/total (s)                    966.383
Epoch                             396
-----------------------------  ----------------
2019-04-23 00:09:29.224644 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 397 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.144351
trainer/QF2 Loss                    0.216461
trainer/Policy Loss                32.1578
trainer/Q1 Predictions Mean       -30.4115
trainer/Q1 Predictions Std         33.793
trainer/Q1 Predictions Max         -7.99768
trainer/Q1 Predictions Min       -108.597
trainer/Q2 Predictions Mean       -30.3608
trainer/Q2 Predictions Std         33.7389
trainer/Q2 Predictions Max         -7.86796
trainer/Q2 Predictions Min       -108.405
trainer/Q Targets Mean            -30.5945
trainer/Q Targets Std              34.0032
trainer/Q Targets Max              -7.99824
trainer/Q Targets Min            -109.133
trainer/Log Pis Mean                1.80965
trainer/Log Pis Std                 1.02114
trainer/Log Pis Max                 6.52032
trainer/Log Pis Min                -0.768839
trainer/Policy mu Mean             -0.0268202
trainer/Policy mu Std               0.44684
trainer/Policy mu Max               2.34945
trainer/Policy mu Min              -2.60215
trainer/Policy log std Mean        -2.19557
trainer/Policy log std Std          0.356567
trainer/Policy log std Max         -0.603545
trainer/Policy log std Min         -2.76763
trainer/Alpha                       0.0820729
trainer/Alpha Loss                 -0.475851
exploration/num steps total    199200
exploration/num paths total      1992
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.664335
exploration/Rewards Std             0.846198
exploration/Rewards Max            -0.00312538
exploration/Rewards Min            -7.07506
exploration/Returns Mean          -66.4335
exploration/Returns Std            55.5697
exploration/Returns Max           -14.1414
exploration/Returns Min          -157.976
exploration/Actions Mean            0.00519325
exploration/Actions Std             0.205903
exploration/Actions Max             0.997895
exploration/Actions Min            -0.99166
exploration/Num Paths               5
exploration/Average Returns       -66.4335
evaluation/num steps total     597000
evaluation/num paths total       5970
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.828007
evaluation/Rewards Std              1.1305
evaluation/Rewards Max             -0.0306121
evaluation/Rewards Min            -10.4435
evaluation/Returns Mean           -82.8007
evaluation/Returns Std             70.557
evaluation/Returns Max            -10.7731
evaluation/Returns Min           -212.41
evaluation/Actions Mean             0.00764272
evaluation/Actions Std              0.18538
evaluation/Actions Max              0.999349
evaluation/Actions Min             -0.998977
evaluation/Num Paths               15
evaluation/Average Returns        -82.8007
time/data storing (s)               0.00261914
time/evaluation sampling (s)        0.326493
time/exploration sampling (s)       0.140745
time/logging (s)                    0.00479929
time/saving (s)                     0.00198209
time/training (s)                   2.02647
time/epoch (s)                      2.50311
time/total (s)                    968.891
Epoch                             397
-----------------------------  ---------------
2019-04-23 00:09:31.659889 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 398 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   47.7257
trainer/QF2 Loss                   47.7332
trainer/Policy Loss                30.6354
trainer/Q1 Predictions Mean       -28.8955
trainer/Q1 Predictions Std         31.7094
trainer/Q1 Predictions Max         -7.92983
trainer/Q1 Predictions Min       -109.532
trainer/Q2 Predictions Mean       -28.8759
trainer/Q2 Predictions Std         31.7024
trainer/Q2 Predictions Max         -7.88608
trainer/Q2 Predictions Min       -109.44
trainer/Q Targets Mean            -28.2187
trainer/Q Targets Std              31.6305
trainer/Q Targets Max              -0.212477
trainer/Q Targets Min            -109.834
trainer/Log Pis Mean                1.80989
trainer/Log Pis Std                 1.35998
trainer/Log Pis Max                 5.27995
trainer/Log Pis Min                -2.76192
trainer/Policy mu Mean              0.0333476
trainer/Policy mu Std               0.288292
trainer/Policy mu Max               2.35461
trainer/Policy mu Min              -1.55669
trainer/Policy log std Mean        -2.31183
trainer/Policy log std Std          0.328937
trainer/Policy log std Max         -0.652644
trainer/Policy log std Min         -2.98052
trainer/Alpha                       0.080794
trainer/Alpha Loss                 -0.47831
exploration/num steps total    199700
exploration/num paths total      1997
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.498707
exploration/Rewards Std             0.696563
exploration/Rewards Max            -0.00518602
exploration/Rewards Min            -5.95359
exploration/Returns Mean          -49.8707
exploration/Returns Std            47.2996
exploration/Returns Max           -16.294
exploration/Returns Min          -142.982
exploration/Actions Mean            0.00452434
exploration/Actions Std             0.170846
exploration/Actions Max             0.994541
exploration/Actions Min            -0.996666
exploration/Num Paths               5
exploration/Average Returns       -49.8707
evaluation/num steps total     598500
evaluation/num paths total       5985
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.86826
evaluation/Rewards Std              1.11464
evaluation/Rewards Max             -0.0193697
evaluation/Rewards Min             -9.06911
evaluation/Returns Mean           -86.826
evaluation/Returns Std             68.7477
evaluation/Returns Max            -12.7361
evaluation/Returns Min           -241.886
evaluation/Actions Mean             0.00197814
evaluation/Actions Std              0.178913
evaluation/Actions Max              0.995896
evaluation/Actions Min             -0.999033
evaluation/Num Paths               15
evaluation/Average Returns        -86.826
time/data storing (s)               0.00276474
time/evaluation sampling (s)        0.326425
time/exploration sampling (s)       0.142059
time/logging (s)                    0.00487207
time/saving (s)                     0.00744148
time/training (s)                   1.94157
time/epoch (s)                      2.42513
time/total (s)                    971.321
Epoch                             398
-----------------------------  ---------------
2019-04-23 00:09:34.184632 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 399 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.304534
trainer/QF2 Loss                    0.335446
trainer/Policy Loss                33.847
trainer/Q1 Predictions Mean       -31.8413
trainer/Q1 Predictions Std         33.2999
trainer/Q1 Predictions Max         -7.67979
trainer/Q1 Predictions Min       -109.365
trainer/Q2 Predictions Mean       -31.8253
trainer/Q2 Predictions Std         33.2733
trainer/Q2 Predictions Max         -7.68849
trainer/Q2 Predictions Min       -109.284
trainer/Q Targets Mean            -32.1813
trainer/Q Targets Std              33.6383
trainer/Q Targets Max              -7.79194
trainer/Q Targets Min            -110.477
trainer/Log Pis Mean                2.05058
trainer/Log Pis Std                 1.2298
trainer/Log Pis Max                 8.7959
trainer/Log Pis Min                -1.09462
trainer/Policy mu Mean             -0.00923111
trainer/Policy mu Std               0.495656
trainer/Policy mu Max               2.69337
trainer/Policy mu Min              -3.66264
trainer/Policy log std Mean        -2.23979
trainer/Policy log std Std          0.411611
trainer/Policy log std Max         -0.357989
trainer/Policy log std Min         -2.7894
trainer/Alpha                       0.0798653
trainer/Alpha Loss                  0.127844
exploration/num steps total    200200
exploration/num paths total      2002
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.655704
exploration/Rewards Std             1.00738
exploration/Rewards Max            -0.00730175
exploration/Rewards Min            -9.72567
exploration/Returns Mean          -65.5704
exploration/Returns Std            31.2998
exploration/Returns Max           -29.1674
exploration/Returns Min          -107.518
exploration/Actions Mean            0.00997076
exploration/Actions Std             0.226053
exploration/Actions Max             0.99897
exploration/Actions Min            -0.998355
exploration/Num Paths               5
exploration/Average Returns       -65.5704
evaluation/num steps total     600000
evaluation/num paths total       6000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.911524
evaluation/Rewards Std              1.2014
evaluation/Rewards Max             -0.0175261
evaluation/Rewards Min            -10.5145
evaluation/Returns Mean           -91.1524
evaluation/Returns Std             71.1808
evaluation/Returns Max            -15.095
evaluation/Returns Min           -244.8
evaluation/Actions Mean            -0.00482225
evaluation/Actions Std              0.188998
evaluation/Actions Max              0.997582
evaluation/Actions Min             -0.99972
evaluation/Num Paths               15
evaluation/Average Returns        -91.1524
time/data storing (s)               0.00268285
time/evaluation sampling (s)        0.325767
time/exploration sampling (s)       0.141892
time/logging (s)                    0.00518315
time/saving (s)                     0.00280279
time/training (s)                   2.03649
time/epoch (s)                      2.51482
time/total (s)                    973.84
Epoch                             399
-----------------------------  ---------------
2019-04-23 00:09:36.667793 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 400 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.19035
trainer/QF2 Loss                    0.27681
trainer/Policy Loss                35.3189
trainer/Q1 Predictions Mean       -33.3484
trainer/Q1 Predictions Std         36.7261
trainer/Q1 Predictions Max         -7.59638
trainer/Q1 Predictions Min       -110.005
trainer/Q2 Predictions Mean       -33.3166
trainer/Q2 Predictions Std         36.6713
trainer/Q2 Predictions Max         -7.56968
trainer/Q2 Predictions Min       -109.946
trainer/Q Targets Mean            -33.5123
trainer/Q Targets Std              37.0409
trainer/Q Targets Max              -7.75752
trainer/Q Targets Min            -110.5
trainer/Log Pis Mean                2.1049
trainer/Log Pis Std                 1.10501
trainer/Log Pis Max                 6.63594
trainer/Log Pis Min                -1.25576
trainer/Policy mu Mean              0.0798553
trainer/Policy mu Std               0.469202
trainer/Policy mu Max               3.2279
trainer/Policy mu Min              -2.33698
trainer/Policy log std Mean        -2.30588
trainer/Policy log std Std          0.405271
trainer/Policy log std Max         -0.473148
trainer/Policy log std Min         -2.84854
trainer/Alpha                       0.0827038
trainer/Alpha Loss                  0.261479
exploration/num steps total    200700
exploration/num paths total      2007
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.694491
exploration/Rewards Std             0.825204
exploration/Rewards Max            -0.0113887
exploration/Rewards Min            -7.64186
exploration/Returns Mean          -69.4491
exploration/Returns Std            46.4066
exploration/Returns Max           -17.2674
exploration/Returns Min          -149.01
exploration/Actions Mean           -0.0186757
exploration/Actions Std             0.181675
exploration/Actions Max             0.925376
exploration/Actions Min            -0.998566
exploration/Num Paths               5
exploration/Average Returns       -69.4491
evaluation/num steps total     601500
evaluation/num paths total       6015
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.652549
evaluation/Rewards Std              1.14477
evaluation/Rewards Max             -0.0477711
evaluation/Rewards Min            -11.1334
evaluation/Returns Mean           -65.2549
evaluation/Returns Std             57.3785
evaluation/Returns Max            -11.7073
evaluation/Returns Min           -209.338
evaluation/Actions Mean             0.0208071
evaluation/Actions Std              0.19635
evaluation/Actions Max              0.998962
evaluation/Actions Min             -0.997572
evaluation/Num Paths               15
evaluation/Average Returns        -65.2549
time/data storing (s)               0.00292716
time/evaluation sampling (s)        0.34598
time/exploration sampling (s)       0.149542
time/logging (s)                    0.00477839
time/saving (s)                     0.00201588
time/training (s)                   1.96688
time/epoch (s)                      2.47213
time/total (s)                    976.316
Epoch                             400
-----------------------------  ---------------
2019-04-23 00:09:39.110231 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 401 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.654311
trainer/QF2 Loss                    0.623863
trainer/Policy Loss                29.2039
trainer/Q1 Predictions Mean       -27.2738
trainer/Q1 Predictions Std         30.2117
trainer/Q1 Predictions Max         -7.63134
trainer/Q1 Predictions Min       -108.368
trainer/Q2 Predictions Mean       -27.3646
trainer/Q2 Predictions Std         30.2036
trainer/Q2 Predictions Max         -7.67144
trainer/Q2 Predictions Min       -108.477
trainer/Q Targets Mean            -27.6553
trainer/Q Targets Std              30.8427
trainer/Q Targets Max              -7.69304
trainer/Q Targets Min            -110.327
trainer/Log Pis Mean                1.91169
trainer/Log Pis Std                 0.977145
trainer/Log Pis Max                 3.95388
trainer/Log Pis Min                -1.18629
trainer/Policy mu Mean              0.0134215
trainer/Policy mu Std               0.480672
trainer/Policy mu Max               2.6125
trainer/Policy mu Min              -2.73486
trainer/Policy log std Mean        -2.18831
trainer/Policy log std Std          0.400271
trainer/Policy log std Max         -0.449493
trainer/Policy log std Min         -2.78515
trainer/Alpha                       0.0826956
trainer/Alpha Loss                 -0.220106
exploration/num steps total    201200
exploration/num paths total      2012
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.618579
exploration/Rewards Std             0.885074
exploration/Rewards Max            -0.00956302
exploration/Rewards Min            -6.55776
exploration/Returns Mean          -61.8579
exploration/Returns Std            71.8887
exploration/Returns Max           -14.3133
exploration/Returns Min          -204.61
exploration/Actions Mean           -0.0106967
exploration/Actions Std             0.206022
exploration/Actions Max             0.995587
exploration/Actions Min            -0.998404
exploration/Num Paths               5
exploration/Average Returns       -61.8579
evaluation/num steps total     603000
evaluation/num paths total       6030
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.450807
evaluation/Rewards Std              1.09188
evaluation/Rewards Max             -0.00772322
evaluation/Rewards Min            -10.6044
evaluation/Returns Mean           -45.0807
evaluation/Returns Std             62.9427
evaluation/Returns Max             -6.23446
evaluation/Returns Min           -236.287
evaluation/Actions Mean            -0.0123791
evaluation/Actions Std              0.186633
evaluation/Actions Max              0.991972
evaluation/Actions Min             -0.999461
evaluation/Num Paths               15
evaluation/Average Returns        -45.0807
time/data storing (s)               0.00279765
time/evaluation sampling (s)        0.324755
time/exploration sampling (s)       0.141088
time/logging (s)                    0.00481593
time/saving (s)                     0.00200739
time/training (s)                   1.95774
time/epoch (s)                      2.4332
time/total (s)                    978.754
Epoch                             401
-----------------------------  ---------------
2019-04-23 00:09:41.535816 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 402 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.56081
trainer/QF2 Loss                    1.56558
trainer/Policy Loss                31.9619
trainer/Q1 Predictions Mean       -30.1185
trainer/Q1 Predictions Std         31.7918
trainer/Q1 Predictions Max         -7.75668
trainer/Q1 Predictions Min       -110.178
trainer/Q2 Predictions Mean       -30.151
trainer/Q2 Predictions Std         31.7806
trainer/Q2 Predictions Max         -7.73632
trainer/Q2 Predictions Min       -109.943
trainer/Q Targets Mean            -30.1513
trainer/Q Targets Std              32.0456
trainer/Q Targets Max              -0.0973074
trainer/Q Targets Min            -109.379
trainer/Log Pis Mean                1.89976
trainer/Log Pis Std                 0.994841
trainer/Log Pis Max                 3.52223
trainer/Log Pis Min                -1.9202
trainer/Policy mu Mean             -0.0160264
trainer/Policy mu Std               0.304864
trainer/Policy mu Max               0.670676
trainer/Policy mu Min              -2.13779
trainer/Policy log std Mean        -2.29709
trainer/Policy log std Std          0.343071
trainer/Policy log std Max         -0.621173
trainer/Policy log std Min         -3.07096
trainer/Alpha                       0.0811857
trainer/Alpha Loss                 -0.251691
exploration/num steps total    201700
exploration/num paths total      2017
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.25815
exploration/Rewards Std             1.21355
exploration/Rewards Max            -0.00497671
exploration/Rewards Min            -8.71695
exploration/Returns Mean         -125.815
exploration/Returns Std            86.415
exploration/Returns Max           -35.5322
exploration/Returns Min          -235.837
exploration/Actions Mean           -0.00449725
exploration/Actions Std             0.211808
exploration/Actions Max             0.998933
exploration/Actions Min            -0.99971
exploration/Num Paths               5
exploration/Average Returns      -125.815
evaluation/num steps total     604500
evaluation/num paths total       6045
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.701055
evaluation/Rewards Std              1.15274
evaluation/Rewards Max             -0.0249247
evaluation/Rewards Min             -9.96563
evaluation/Returns Mean           -70.1055
evaluation/Returns Std             78.7275
evaluation/Returns Max             -9.66613
evaluation/Returns Min           -250.488
evaluation/Actions Mean             0.00507732
evaluation/Actions Std              0.180153
evaluation/Actions Max              0.99924
evaluation/Actions Min             -0.997896
evaluation/Num Paths               15
evaluation/Average Returns        -70.1055
time/data storing (s)               0.00276909
time/evaluation sampling (s)        0.330581
time/exploration sampling (s)       0.139876
time/logging (s)                    0.00350082
time/saving (s)                     0.00197834
time/training (s)                   1.93509
time/epoch (s)                      2.4138
time/total (s)                    981.173
Epoch                             402
-----------------------------  ---------------
2019-04-23 00:09:44.022528 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 403 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   47.6531
trainer/QF2 Loss                   46.9412
trainer/Policy Loss                26.9098
trainer/Q1 Predictions Mean       -24.8852
trainer/Q1 Predictions Std         30.0999
trainer/Q1 Predictions Max         -7.33731
trainer/Q1 Predictions Min       -108.313
trainer/Q2 Predictions Mean       -24.9116
trainer/Q2 Predictions Std         30.161
trainer/Q2 Predictions Max         -7.2822
trainer/Q2 Predictions Min       -108.334
trainer/Q Targets Mean            -24.6367
trainer/Q Targets Std              30.5915
trainer/Q Targets Max              -0.0402762
trainer/Q Targets Min            -109.997
trainer/Log Pis Mean                2.0117
trainer/Log Pis Std                 1.39393
trainer/Log Pis Max                10.3015
trainer/Log Pis Min                -1.91722
trainer/Policy mu Mean              0.0110653
trainer/Policy mu Std               0.36196
trainer/Policy mu Max               3.24322
trainer/Policy mu Min              -3.45553
trainer/Policy log std Mean        -2.34345
trainer/Policy log std Std          0.326682
trainer/Policy log std Max         -0.507416
trainer/Policy log std Min         -2.90652
trainer/Alpha                       0.0791601
trainer/Alpha Loss                  0.0296793
exploration/num steps total    202200
exploration/num paths total      2022
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.41895
exploration/Rewards Std             1.22868
exploration/Rewards Max            -0.00178826
exploration/Rewards Min            -9.70789
exploration/Returns Mean          -41.895
exploration/Returns Std            14.2261
exploration/Returns Max           -16.8089
exploration/Returns Min           -58.2479
exploration/Actions Mean            0.00684695
exploration/Actions Std             0.232792
exploration/Actions Max             0.998553
exploration/Actions Min            -0.999402
exploration/Num Paths               5
exploration/Average Returns       -41.895
evaluation/num steps total     606000
evaluation/num paths total       6060
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.468749
evaluation/Rewards Std              0.964231
evaluation/Rewards Max             -0.00696808
evaluation/Rewards Min             -8.88713
evaluation/Returns Mean           -46.8749
evaluation/Returns Std             52.756
evaluation/Returns Max             -6.93613
evaluation/Returns Min           -204.777
evaluation/Actions Mean             0.00697567
evaluation/Actions Std              0.17601
evaluation/Actions Max              0.997157
evaluation/Actions Min             -0.998974
evaluation/Num Paths               15
evaluation/Average Returns        -46.8749
time/data storing (s)               0.00278319
time/evaluation sampling (s)        0.367392
time/exploration sampling (s)       0.137683
time/logging (s)                    0.00483619
time/saving (s)                     0.00978604
time/training (s)                   1.95591
time/epoch (s)                      2.47839
time/total (s)                    983.656
Epoch                             403
-----------------------------  ---------------
2019-04-23 00:09:46.454339 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 404 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.61129
trainer/QF2 Loss                    1.63142
trainer/Policy Loss                32.0587
trainer/Q1 Predictions Mean       -30.2499
trainer/Q1 Predictions Std         34.7333
trainer/Q1 Predictions Max         -7.75681
trainer/Q1 Predictions Min       -109.045
trainer/Q2 Predictions Mean       -30.2178
trainer/Q2 Predictions Std         34.7241
trainer/Q2 Predictions Max         -7.62086
trainer/Q2 Predictions Min       -108.582
trainer/Q Targets Mean            -30.2876
trainer/Q Targets Std              35.0522
trainer/Q Targets Max              -0.293213
trainer/Q Targets Min            -109.508
trainer/Log Pis Mean                1.85555
trainer/Log Pis Std                 1.2122
trainer/Log Pis Max                 4.07354
trainer/Log Pis Min                -2.5036
trainer/Policy mu Mean              0.0491039
trainer/Policy mu Std               0.340336
trainer/Policy mu Max               2.8558
trainer/Policy mu Min              -0.39332
trainer/Policy log std Mean        -2.32106
trainer/Policy log std Std          0.35442
trainer/Policy log std Max         -0.710052
trainer/Policy log std Min         -2.88594
trainer/Alpha                       0.0781315
trainer/Alpha Loss                 -0.36826
exploration/num steps total    202700
exploration/num paths total      2027
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.40744
exploration/Rewards Std             1.2049
exploration/Rewards Max            -0.00255716
exploration/Rewards Min            -9.28891
exploration/Returns Mean          -40.744
exploration/Returns Std            12.9554
exploration/Returns Max           -21.2175
exploration/Returns Min           -55.7045
exploration/Actions Mean            0.0189284
exploration/Actions Std             0.231951
exploration/Actions Max             0.999759
exploration/Actions Min            -0.998747
exploration/Num Paths               5
exploration/Average Returns       -40.744
evaluation/num steps total     607500
evaluation/num paths total       6075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.80921
evaluation/Rewards Std              1.28477
evaluation/Rewards Max             -0.0102596
evaluation/Rewards Min            -10.2776
evaluation/Returns Mean           -80.921
evaluation/Returns Std             68.7998
evaluation/Returns Max             -8.09369
evaluation/Returns Min           -207.373
evaluation/Actions Mean             0.00195934
evaluation/Actions Std              0.196657
evaluation/Actions Max              0.998891
evaluation/Actions Min             -0.999001
evaluation/Num Paths               15
evaluation/Average Returns        -80.921
time/data storing (s)               0.00273011
time/evaluation sampling (s)        0.32474
time/exploration sampling (s)       0.136052
time/logging (s)                    0.0048072
time/saving (s)                     0.00196948
time/training (s)                   1.95121
time/epoch (s)                      2.42151
time/total (s)                    986.082
Epoch                             404
-----------------------------  ---------------
2019-04-23 00:09:48.881597 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 405 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.42807
trainer/QF2 Loss                    3.40293
trainer/Policy Loss                31.0858
trainer/Q1 Predictions Mean       -29.0379
trainer/Q1 Predictions Std         32.4623
trainer/Q1 Predictions Max         -7.42656
trainer/Q1 Predictions Min       -108.218
trainer/Q2 Predictions Mean       -29.0549
trainer/Q2 Predictions Std         32.4842
trainer/Q2 Predictions Max         -7.36278
trainer/Q2 Predictions Min       -108.15
trainer/Q Targets Mean            -29.0748
trainer/Q Targets Std              33.1068
trainer/Q Targets Max              -0.326631
trainer/Q Targets Min            -109.624
trainer/Log Pis Mean                2.05293
trainer/Log Pis Std                 1.34838
trainer/Log Pis Max                 8.5287
trainer/Log Pis Min                -1.95876
trainer/Policy mu Mean              0.0172042
trainer/Policy mu Std               0.457491
trainer/Policy mu Max               2.76233
trainer/Policy mu Min              -2.7905
trainer/Policy log std Mean        -2.30535
trainer/Policy log std Std          0.419802
trainer/Policy log std Max         -0.555345
trainer/Policy log std Min         -2.87426
trainer/Alpha                       0.078479
trainer/Alpha Loss                  0.134702
exploration/num steps total    203200
exploration/num paths total      2032
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.343247
exploration/Rewards Std             1.08195
exploration/Rewards Max            -0.000649955
exploration/Rewards Min           -10.8123
exploration/Returns Mean          -34.3247
exploration/Returns Std            15.6776
exploration/Returns Max           -16.6578
exploration/Returns Min           -63.1516
exploration/Actions Mean           -5.78599e-05
exploration/Actions Std             0.222514
exploration/Actions Max             0.996831
exploration/Actions Min            -0.997561
exploration/Num Paths               5
exploration/Average Returns       -34.3247
evaluation/num steps total     609000
evaluation/num paths total       6090
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.404987
evaluation/Rewards Std              1.02019
evaluation/Rewards Max             -0.0239106
evaluation/Rewards Min             -9.87982
evaluation/Returns Mean           -40.4987
evaluation/Returns Std             38.3941
evaluation/Returns Max             -4.83433
evaluation/Returns Min           -137.692
evaluation/Actions Mean             0.0106875
evaluation/Actions Std              0.191365
evaluation/Actions Max              0.998866
evaluation/Actions Min             -0.999383
evaluation/Num Paths               15
evaluation/Average Returns        -40.4987
time/data storing (s)               0.00280516
time/evaluation sampling (s)        0.326035
time/exploration sampling (s)       0.136843
time/logging (s)                    0.00481415
time/saving (s)                     0.00201222
time/training (s)                   1.94549
time/epoch (s)                      2.418
time/total (s)                    988.503
Epoch                             405
-----------------------------  ----------------
2019-04-23 00:09:51.312365 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 406 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   25.9252
trainer/QF2 Loss                   25.996
trainer/Policy Loss                32.9391
trainer/Q1 Predictions Mean       -30.9663
trainer/Q1 Predictions Std         32.4749
trainer/Q1 Predictions Max         -7.66741
trainer/Q1 Predictions Min       -109.027
trainer/Q2 Predictions Mean       -30.9929
trainer/Q2 Predictions Std         32.4672
trainer/Q2 Predictions Max         -7.60854
trainer/Q2 Predictions Min       -109.017
trainer/Q Targets Mean            -30.5039
trainer/Q Targets Std              32.733
trainer/Q Targets Max              -0.870416
trainer/Q Targets Min            -109.84
trainer/Log Pis Mean                2.02293
trainer/Log Pis Std                 1.22759
trainer/Log Pis Max                 7.03487
trainer/Log Pis Min                -2.73615
trainer/Policy mu Mean             -0.0925189
trainer/Policy mu Std               0.500849
trainer/Policy mu Max               0.742891
trainer/Policy mu Min              -3.85769
trainer/Policy log std Mean        -2.281
trainer/Policy log std Std          0.392125
trainer/Policy log std Max         -0.338798
trainer/Policy log std Min         -2.79273
trainer/Alpha                       0.0799982
trainer/Alpha Loss                  0.0579256
exploration/num steps total    203700
exploration/num paths total      2037
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.01108
exploration/Rewards Std             1.22851
exploration/Rewards Max            -0.00780256
exploration/Rewards Min           -10.6123
exploration/Returns Mean         -101.108
exploration/Returns Std           101.415
exploration/Returns Max           -17.6347
exploration/Returns Min          -240.643
exploration/Actions Mean           -0.0299579
exploration/Actions Std             0.202429
exploration/Actions Max             0.989537
exploration/Actions Min            -0.999784
exploration/Num Paths               5
exploration/Average Returns      -101.108
evaluation/num steps total     610500
evaluation/num paths total       6105
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.660547
evaluation/Rewards Std              1.11836
evaluation/Rewards Max             -0.0164626
evaluation/Rewards Min             -8.21409
evaluation/Returns Mean           -66.0547
evaluation/Returns Std             67.3978
evaluation/Returns Max            -14.574
evaluation/Returns Min           -222.762
evaluation/Actions Mean             0.0155792
evaluation/Actions Std              0.197428
evaluation/Actions Max              0.997334
evaluation/Actions Min             -0.998753
evaluation/Num Paths               15
evaluation/Average Returns        -66.0547
time/data storing (s)               0.00271659
time/evaluation sampling (s)        0.332125
time/exploration sampling (s)       0.137846
time/logging (s)                    0.00478021
time/saving (s)                     0.00197044
time/training (s)                   1.94184
time/epoch (s)                      2.42128
time/total (s)                    990.928
Epoch                             406
-----------------------------  ---------------
2019-04-23 00:09:53.735057 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 407 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   48.1819
trainer/QF2 Loss                   48.5124
trainer/Policy Loss                39.8454
trainer/Q1 Predictions Mean       -37.7944
trainer/Q1 Predictions Std         37.0407
trainer/Q1 Predictions Max         -7.513
trainer/Q1 Predictions Min       -110.226
trainer/Q2 Predictions Mean       -37.8566
trainer/Q2 Predictions Std         37.1077
trainer/Q2 Predictions Max         -7.43574
trainer/Q2 Predictions Min       -110.456
trainer/Q Targets Mean            -37.6346
trainer/Q Targets Std              37.7365
trainer/Q Targets Max              -1.57052
trainer/Q Targets Min            -110.883
trainer/Log Pis Mean                2.07445
trainer/Log Pis Std                 1.27989
trainer/Log Pis Max                 7.31474
trainer/Log Pis Min                -0.961542
trainer/Policy mu Mean             -0.0287822
trainer/Policy mu Std               0.577568
trainer/Policy mu Max               2.99711
trainer/Policy mu Min              -3.10654
trainer/Policy log std Mean        -2.20393
trainer/Policy log std Std          0.486122
trainer/Policy log std Max         -0.455834
trainer/Policy log std Min         -2.9006
trainer/Alpha                       0.0827843
trainer/Alpha Loss                  0.185504
exploration/num steps total    204200
exploration/num paths total      2042
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17655
exploration/Rewards Std             1.40073
exploration/Rewards Max            -0.00415999
exploration/Rewards Min            -9.1676
exploration/Returns Mean         -117.655
exploration/Returns Std           103.375
exploration/Returns Max           -21.8521
exploration/Returns Min          -244.823
exploration/Actions Mean           -0.0236041
exploration/Actions Std             0.220032
exploration/Actions Max             0.995569
exploration/Actions Min            -0.999594
exploration/Num Paths               5
exploration/Average Returns      -117.655
evaluation/num steps total     612000
evaluation/num paths total       6120
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.593872
evaluation/Rewards Std              0.829319
evaluation/Rewards Max             -0.00778182
evaluation/Rewards Min             -7.95204
evaluation/Returns Mean           -59.3872
evaluation/Returns Std             58.2961
evaluation/Returns Max             -8.14824
evaluation/Returns Min           -228.123
evaluation/Actions Mean             0.000438845
evaluation/Actions Std              0.161696
evaluation/Actions Max              0.998141
evaluation/Actions Min             -0.998278
evaluation/Num Paths               15
evaluation/Average Returns        -59.3872
time/data storing (s)               0.00277794
time/evaluation sampling (s)        0.320117
time/exploration sampling (s)       0.139548
time/logging (s)                    0.00482365
time/saving (s)                     0.00195668
time/training (s)                   1.94328
time/epoch (s)                      2.4125
time/total (s)                    993.344
Epoch                             407
-----------------------------  ----------------
2019-04-23 00:09:56.170482 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 408 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.97049
trainer/QF2 Loss                    2.075
trainer/Policy Loss                38.4775
trainer/Q1 Predictions Mean       -36.6447
trainer/Q1 Predictions Std         36.3685
trainer/Q1 Predictions Max         -7.47628
trainer/Q1 Predictions Min       -108.219
trainer/Q2 Predictions Mean       -36.5742
trainer/Q2 Predictions Std         36.3279
trainer/Q2 Predictions Max         -7.43717
trainer/Q2 Predictions Min       -108.594
trainer/Q Targets Mean            -36.9497
trainer/Q Targets Std              36.9124
trainer/Q Targets Max              -0.12313
trainer/Q Targets Min            -109.777
trainer/Log Pis Mean                1.89205
trainer/Log Pis Std                 1.08731
trainer/Log Pis Max                 5.86204
trainer/Log Pis Min                -2.03131
trainer/Policy mu Mean              0.0315164
trainer/Policy mu Std               0.367365
trainer/Policy mu Max               3.00485
trainer/Policy mu Min              -2.35689
trainer/Policy log std Mean        -2.23125
trainer/Policy log std Std          0.392513
trainer/Policy log std Max         -0.548625
trainer/Policy log std Min         -2.81931
trainer/Alpha                       0.0840395
trainer/Alpha Loss                 -0.267331
exploration/num steps total    204700
exploration/num paths total      2047
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.632709
exploration/Rewards Std             0.741859
exploration/Rewards Max            -0.0107553
exploration/Rewards Min            -6.16688
exploration/Returns Mean          -63.2709
exploration/Returns Std            47.8808
exploration/Returns Max           -14.6229
exploration/Returns Min          -143.773
exploration/Actions Mean            0.00454948
exploration/Actions Std             0.192938
exploration/Actions Max             0.996154
exploration/Actions Min            -0.994252
exploration/Num Paths               5
exploration/Average Returns       -63.2709
evaluation/num steps total     613500
evaluation/num paths total       6135
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.880327
evaluation/Rewards Std              1.22211
evaluation/Rewards Max             -0.0200592
evaluation/Rewards Min            -10.2326
evaluation/Returns Mean           -88.0327
evaluation/Returns Std             76.8585
evaluation/Returns Max             -6.88037
evaluation/Returns Min           -236.776
evaluation/Actions Mean             0.0111256
evaluation/Actions Std              0.188127
evaluation/Actions Max              0.999397
evaluation/Actions Min             -0.998696
evaluation/Num Paths               15
evaluation/Average Returns        -88.0327
time/data storing (s)               0.00265066
time/evaluation sampling (s)        0.330847
time/exploration sampling (s)       0.139939
time/logging (s)                    0.00480503
time/saving (s)                     0.00198648
time/training (s)                   1.94576
time/epoch (s)                      2.42599
time/total (s)                    995.775
Epoch                             408
-----------------------------  ---------------
2019-04-23 00:09:58.646691 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 409 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                   49.8309
trainer/QF2 Loss                   50.0321
trainer/Policy Loss                30.1159
trainer/Q1 Predictions Mean       -28.4425
trainer/Q1 Predictions Std         31.9041
trainer/Q1 Predictions Max         -7.04524
trainer/Q1 Predictions Min       -107.199
trainer/Q2 Predictions Mean       -28.5472
trainer/Q2 Predictions Std         31.8982
trainer/Q2 Predictions Max         -7.19845
trainer/Q2 Predictions Min       -107.283
trainer/Q Targets Mean            -27.9906
trainer/Q Targets Std              32.3799
trainer/Q Targets Max              -0.502248
trainer/Q Targets Min            -109.047
trainer/Log Pis Mean                1.55581
trainer/Log Pis Std                 1.2948
trainer/Log Pis Max                 5.79986
trainer/Log Pis Min                -3.4116
trainer/Policy mu Mean             -0.0145863
trainer/Policy mu Std               0.406232
trainer/Policy mu Max               1.66447
trainer/Policy mu Min              -2.72555
trainer/Policy log std Mean        -2.22285
trainer/Policy log std Std          0.41874
trainer/Policy log std Max         -0.628555
trainer/Policy log std Min         -2.96453
trainer/Alpha                       0.0840284
trainer/Alpha Loss                 -1.09999
exploration/num steps total    205200
exploration/num paths total      2052
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.792377
exploration/Rewards Std             1.28327
exploration/Rewards Max            -0.00896897
exploration/Rewards Min           -10.6935
exploration/Returns Mean          -79.2377
exploration/Returns Std            74.4613
exploration/Returns Max           -26.9275
exploration/Returns Min          -224.511
exploration/Actions Mean           -0.000862654
exploration/Actions Std             0.223163
exploration/Actions Max             0.997724
exploration/Actions Min            -0.999597
exploration/Num Paths               5
exploration/Average Returns       -79.2377
evaluation/num steps total     615000
evaluation/num paths total       6150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.617179
evaluation/Rewards Std              1.03217
evaluation/Rewards Max             -0.0378022
evaluation/Rewards Min             -9.4457
evaluation/Returns Mean           -61.7179
evaluation/Returns Std             65.9835
evaluation/Returns Max             -9.02676
evaluation/Returns Min           -250.037
evaluation/Actions Mean            -0.0130216
evaluation/Actions Std              0.172923
evaluation/Actions Max              0.997194
evaluation/Actions Min             -0.997467
evaluation/Num Paths               15
evaluation/Average Returns        -61.7179
time/data storing (s)               0.00280945
time/evaluation sampling (s)        0.35038
time/exploration sampling (s)       0.13896
time/logging (s)                    0.00482644
time/saving (s)                     0.00201192
time/training (s)                   1.96788
time/epoch (s)                      2.46687
time/total (s)                    998.246
Epoch                             409
-----------------------------  ----------------
2019-04-23 00:10:01.116130 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 410 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.927352
trainer/QF2 Loss                    0.902336
trainer/Policy Loss                35.9225
trainer/Q1 Predictions Mean       -33.8105
trainer/Q1 Predictions Std         36.2037
trainer/Q1 Predictions Max         -7.26952
trainer/Q1 Predictions Min       -112.537
trainer/Q2 Predictions Mean       -33.8809
trainer/Q2 Predictions Std         36.1873
trainer/Q2 Predictions Max         -7.3115
trainer/Q2 Predictions Min       -112.346
trainer/Q Targets Mean            -33.9243
trainer/Q Targets Std              36.6083
trainer/Q Targets Max              -0.133115
trainer/Q Targets Min            -112.416
trainer/Log Pis Mean                2.07612
trainer/Log Pis Std                 1.306
trainer/Log Pis Max                 7.39096
trainer/Log Pis Min                -3.09556
trainer/Policy mu Mean             -0.0523967
trainer/Policy mu Std               0.500322
trainer/Policy mu Max               3.16964
trainer/Policy mu Min              -3.6274
trainer/Policy log std Mean        -2.23276
trainer/Policy log std Std          0.423763
trainer/Policy log std Max         -0.564632
trainer/Policy log std Min         -3.00858
trainer/Alpha                       0.0799484
trainer/Alpha Loss                  0.192309
exploration/num steps total    205700
exploration/num paths total      2057
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.587055
exploration/Rewards Std             0.917435
exploration/Rewards Max            -0.00649949
exploration/Rewards Min            -7.27128
exploration/Returns Mean          -58.7055
exploration/Returns Std            48.1133
exploration/Returns Max           -21.8093
exploration/Returns Min          -152.382
exploration/Actions Mean           -0.0206749
exploration/Actions Std             0.226465
exploration/Actions Max             0.995403
exploration/Actions Min            -0.998764
exploration/Num Paths               5
exploration/Average Returns       -58.7055
evaluation/num steps total     616500
evaluation/num paths total       6165
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.784599
evaluation/Rewards Std              0.96225
evaluation/Rewards Max             -0.00673947
evaluation/Rewards Min             -9.26664
evaluation/Returns Mean           -78.4599
evaluation/Returns Std             63.6057
evaluation/Returns Max            -10.6233
evaluation/Returns Min           -214.825
evaluation/Actions Mean             0.00224786
evaluation/Actions Std              0.179993
evaluation/Actions Max              0.996131
evaluation/Actions Min             -0.99795
evaluation/Num Paths               15
evaluation/Average Returns        -78.4599
time/data storing (s)               0.00258187
time/evaluation sampling (s)        0.343357
time/exploration sampling (s)       0.138974
time/logging (s)                    0.00483063
time/saving (s)                     0.0018956
time/training (s)                   1.9673
time/epoch (s)                      2.45894
time/total (s)                   1000.71
Epoch                             410
-----------------------------  ---------------
2019-04-23 00:10:03.544380 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 411 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.09786
trainer/QF2 Loss                    2.11437
trainer/Policy Loss                27.0157
trainer/Q1 Predictions Mean       -24.8897
trainer/Q1 Predictions Std         27.8934
trainer/Q1 Predictions Max         -7.54823
trainer/Q1 Predictions Min       -109.248
trainer/Q2 Predictions Mean       -24.9158
trainer/Q2 Predictions Std         27.8912
trainer/Q2 Predictions Max         -7.44088
trainer/Q2 Predictions Min       -109.25
trainer/Q Targets Mean            -24.7386
trainer/Q Targets Std              28.0313
trainer/Q Targets Max              -0.0922893
trainer/Q Targets Min            -109.87
trainer/Log Pis Mean                2.15904
trainer/Log Pis Std                 1.23523
trainer/Log Pis Max                 6.57307
trainer/Log Pis Min                -2.26866
trainer/Policy mu Mean              0.0601164
trainer/Policy mu Std               0.453827
trainer/Policy mu Max               2.77077
trainer/Policy mu Min              -2.2135
trainer/Policy log std Mean        -2.28972
trainer/Policy log std Std          0.381103
trainer/Policy log std Max         -0.596579
trainer/Policy log std Min         -2.86638
trainer/Alpha                       0.0797914
trainer/Alpha Loss                  0.402122
exploration/num steps total    206200
exploration/num paths total      2062
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387146
exploration/Rewards Std             0.588595
exploration/Rewards Max            -0.00101613
exploration/Rewards Min            -5.25125
exploration/Returns Mean          -38.7146
exploration/Returns Std            29.9569
exploration/Returns Max           -18.8825
exploration/Returns Min           -98.1033
exploration/Actions Mean           -0.00245058
exploration/Actions Std             0.192471
exploration/Actions Max             0.988027
exploration/Actions Min            -0.997394
exploration/Num Paths               5
exploration/Average Returns       -38.7146
evaluation/num steps total     618000
evaluation/num paths total       6180
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.06257
evaluation/Rewards Std              1.1085
evaluation/Rewards Max             -0.0177278
evaluation/Rewards Min             -9.57234
evaluation/Returns Mean          -106.257
evaluation/Returns Std             73.9358
evaluation/Returns Max            -10.2338
evaluation/Returns Min           -248.73
evaluation/Actions Mean             0.00558031
evaluation/Actions Std              0.188847
evaluation/Actions Max              0.998017
evaluation/Actions Min             -0.999377
evaluation/Num Paths               15
evaluation/Average Returns       -106.257
time/data storing (s)               0.00280224
time/evaluation sampling (s)        0.327442
time/exploration sampling (s)       0.136633
time/logging (s)                    0.004811
time/saving (s)                     0.0017425
time/training (s)                   1.94432
time/epoch (s)                      2.41775
time/total (s)                   1003.13
Epoch                             411
-----------------------------  ---------------
2019-04-23 00:10:05.976447 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 412 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.301825
trainer/QF2 Loss                    0.286962
trainer/Policy Loss                31.6424
trainer/Q1 Predictions Mean       -29.6965
trainer/Q1 Predictions Std         32.0563
trainer/Q1 Predictions Max         -7.60322
trainer/Q1 Predictions Min       -108.631
trainer/Q2 Predictions Mean       -29.6734
trainer/Q2 Predictions Std         32.0535
trainer/Q2 Predictions Max         -7.59387
trainer/Q2 Predictions Min       -108.547
trainer/Q Targets Mean            -30.0199
trainer/Q Targets Std              32.3103
trainer/Q Targets Max              -7.38656
trainer/Q Targets Min            -110.07
trainer/Log Pis Mean                1.95491
trainer/Log Pis Std                 1.23548
trainer/Log Pis Max                 5.52749
trainer/Log Pis Min                -1.34076
trainer/Policy mu Mean              0.00921475
trainer/Policy mu Std               0.50639
trainer/Policy mu Max               2.83719
trainer/Policy mu Min              -2.7768
trainer/Policy log std Mean        -2.18298
trainer/Policy log std Std          0.455566
trainer/Policy log std Max         -0.397668
trainer/Policy log std Min         -2.92637
trainer/Alpha                       0.0767547
trainer/Alpha Loss                 -0.11575
exploration/num steps total    206700
exploration/num paths total      2067
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.977228
exploration/Rewards Std             0.987349
exploration/Rewards Max            -0.0140293
exploration/Rewards Min            -9.02067
exploration/Returns Mean          -97.7228
exploration/Returns Std            71.5442
exploration/Returns Max           -25.9784
exploration/Returns Min          -221.1
exploration/Actions Mean            0.0012866
exploration/Actions Std             0.215013
exploration/Actions Max             0.999218
exploration/Actions Min            -0.998108
exploration/Num Paths               5
exploration/Average Returns       -97.7228
evaluation/num steps total     619500
evaluation/num paths total       6195
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.83992
evaluation/Rewards Std              1.47801
evaluation/Rewards Max             -0.0133849
evaluation/Rewards Min            -11.3044
evaluation/Returns Mean           -83.992
evaluation/Returns Std             70.5744
evaluation/Returns Max             -8.70361
evaluation/Returns Min           -234.169
evaluation/Actions Mean            -0.00216551
evaluation/Actions Std              0.224745
evaluation/Actions Max              0.998703
evaluation/Actions Min             -0.999368
evaluation/Num Paths               15
evaluation/Average Returns        -83.992
time/data storing (s)               0.00290327
time/evaluation sampling (s)        0.331426
time/exploration sampling (s)       0.139006
time/logging (s)                    0.00483411
time/saving (s)                     0.00195842
time/training (s)                   1.94204
time/epoch (s)                      2.42217
time/total (s)                   1005.56
Epoch                             412
-----------------------------  ---------------
2019-04-23 00:10:08.433081 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 413 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.801812
trainer/QF2 Loss                    0.80191
trainer/Policy Loss                31.3565
trainer/Q1 Predictions Mean       -29.3009
trainer/Q1 Predictions Std         33.4008
trainer/Q1 Predictions Max         -7.41891
trainer/Q1 Predictions Min       -123.155
trainer/Q2 Predictions Mean       -29.3542
trainer/Q2 Predictions Std         33.3849
trainer/Q2 Predictions Max         -7.43184
trainer/Q2 Predictions Min       -123.595
trainer/Q Targets Mean            -29.4019
trainer/Q Targets Std              33.6962
trainer/Q Targets Max              -0.204632
trainer/Q Targets Min            -123.246
trainer/Log Pis Mean                2.07235
trainer/Log Pis Std                 1.16516
trainer/Log Pis Max                 6.73251
trainer/Log Pis Min                -2.99209
trainer/Policy mu Mean              0.0230612
trainer/Policy mu Std               0.367733
trainer/Policy mu Max               2.12672
trainer/Policy mu Min              -2.84289
trainer/Policy log std Mean        -2.33264
trainer/Policy log std Std          0.346214
trainer/Policy log std Max         -0.691994
trainer/Policy log std Min         -2.96531
trainer/Alpha                       0.0732001
trainer/Alpha Loss                  0.189184
exploration/num steps total    207200
exploration/num paths total      2072
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.288651
exploration/Rewards Std             0.779629
exploration/Rewards Max            -0.00410316
exploration/Rewards Min            -7.54505
exploration/Returns Mean          -28.8651
exploration/Returns Std            13.1713
exploration/Returns Max           -10.5401
exploration/Returns Min           -45.0477
exploration/Actions Mean           -0.0114423
exploration/Actions Std             0.198148
exploration/Actions Max             0.999344
exploration/Actions Min            -0.997569
exploration/Num Paths               5
exploration/Average Returns       -28.8651
evaluation/num steps total     621000
evaluation/num paths total       6210
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.954589
evaluation/Rewards Std              1.28476
evaluation/Rewards Max             -0.0313194
evaluation/Rewards Min            -10.3912
evaluation/Returns Mean           -95.4589
evaluation/Returns Std             83.5737
evaluation/Returns Max             -8.2373
evaluation/Returns Min           -235.612
evaluation/Actions Mean            -0.00276432
evaluation/Actions Std              0.196219
evaluation/Actions Max              0.999076
evaluation/Actions Min             -0.998597
evaluation/Num Paths               15
evaluation/Average Returns        -95.4589
time/data storing (s)               0.0027648
time/evaluation sampling (s)        0.328795
time/exploration sampling (s)       0.136535
time/logging (s)                    0.00477853
time/saving (s)                     0.00198388
time/training (s)                   1.97119
time/epoch (s)                      2.44605
time/total (s)                   1008.01
Epoch                             413
-----------------------------  ---------------
2019-04-23 00:10:10.880031 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 414 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    3.31567
trainer/QF2 Loss                    3.24198
trainer/Policy Loss                32.3802
trainer/Q1 Predictions Mean       -30.3877
trainer/Q1 Predictions Std         35.2756
trainer/Q1 Predictions Max         -7.20254
trainer/Q1 Predictions Min       -109.149
trainer/Q2 Predictions Mean       -30.3671
trainer/Q2 Predictions Std         35.2692
trainer/Q2 Predictions Max         -7.16048
trainer/Q2 Predictions Min       -109.76
trainer/Q Targets Mean            -30.3248
trainer/Q Targets Std              35.7593
trainer/Q Targets Max              -0.31113
trainer/Q Targets Min            -109.853
trainer/Log Pis Mean                2.00897
trainer/Log Pis Std                 1.28368
trainer/Log Pis Max                 6.57808
trainer/Log Pis Min                -1.57921
trainer/Policy mu Mean              0.00978768
trainer/Policy mu Std               0.659063
trainer/Policy mu Max               3.18903
trainer/Policy mu Min              -2.73676
trainer/Policy log std Mean        -2.17664
trainer/Policy log std Std          0.482665
trainer/Policy log std Max         -0.484015
trainer/Policy log std Min         -2.81852
trainer/Alpha                       0.0725065
trainer/Alpha Loss                  0.0235249
exploration/num steps total    207700
exploration/num paths total      2077
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.694615
exploration/Rewards Std             1.24292
exploration/Rewards Max            -0.01275
exploration/Rewards Min           -10.3929
exploration/Returns Mean          -69.4615
exploration/Returns Std            85.0594
exploration/Returns Max           -17.6912
exploration/Returns Min          -239.15
exploration/Actions Mean           -0.0205226
exploration/Actions Std             0.236934
exploration/Actions Max             0.997388
exploration/Actions Min            -0.999222
exploration/Num Paths               5
exploration/Average Returns       -69.4615
evaluation/num steps total     622500
evaluation/num paths total       6225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.413861
evaluation/Rewards Std              0.992085
evaluation/Rewards Max             -0.028283
evaluation/Rewards Min             -8.83879
evaluation/Returns Mean           -41.3861
evaluation/Returns Std             38.7978
evaluation/Returns Max             -8.59857
evaluation/Returns Min           -138.707
evaluation/Actions Mean            -0.00387255
evaluation/Actions Std              0.190116
evaluation/Actions Max              0.994566
evaluation/Actions Min             -0.99966
evaluation/Num Paths               15
evaluation/Average Returns        -41.3861
time/data storing (s)               0.00261326
time/evaluation sampling (s)        0.327077
time/exploration sampling (s)       0.138543
time/logging (s)                    0.00453862
time/saving (s)                     0.00157754
time/training (s)                   1.96258
time/epoch (s)                      2.43693
time/total (s)                   1010.45
Epoch                             414
-----------------------------  ---------------
2019-04-23 00:10:13.341064 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 415 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.12551
trainer/QF2 Loss                    0.191762
trainer/Policy Loss                36.0812
trainer/Q1 Predictions Mean       -33.7079
trainer/Q1 Predictions Std         36.4768
trainer/Q1 Predictions Max         -7.32416
trainer/Q1 Predictions Min       -110.097
trainer/Q2 Predictions Mean       -33.6817
trainer/Q2 Predictions Std         36.4362
trainer/Q2 Predictions Max         -7.38036
trainer/Q2 Predictions Min       -109.387
trainer/Q Targets Mean            -33.8916
trainer/Q Targets Std              36.5885
trainer/Q Targets Max              -7.41284
trainer/Q Targets Min            -109.809
trainer/Log Pis Mean                2.40567
trainer/Log Pis Std                 1.47639
trainer/Log Pis Max                 9.52278
trainer/Log Pis Min                -0.909731
trainer/Policy mu Mean              0.000928054
trainer/Policy mu Std               0.678938
trainer/Policy mu Max               3.62376
trainer/Policy mu Min              -3.30808
trainer/Policy log std Mean        -2.28775
trainer/Policy log std Std          0.520878
trainer/Policy log std Max         -0.0488609
trainer/Policy log std Min         -3.02172
trainer/Alpha                       0.0726208
trainer/Alpha Loss                  1.06394
exploration/num steps total    208200
exploration/num paths total      2082
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.34837
exploration/Rewards Std             1.04971
exploration/Rewards Max            -0.0192181
exploration/Rewards Min            -8.47051
exploration/Returns Mean         -134.837
exploration/Returns Std            76.4385
exploration/Returns Max           -24.8979
exploration/Returns Min          -222.178
exploration/Actions Mean            0.00906931
exploration/Actions Std             0.210301
exploration/Actions Max             0.99841
exploration/Actions Min            -0.996041
exploration/Num Paths               5
exploration/Average Returns      -134.837
evaluation/num steps total     624000
evaluation/num paths total       6240
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.613447
evaluation/Rewards Std              1.29754
evaluation/Rewards Max             -0.0178201
evaluation/Rewards Min            -10.7216
evaluation/Returns Mean           -61.3447
evaluation/Returns Std             75.1954
evaluation/Returns Max             -6.46044
evaluation/Returns Min           -250.026
evaluation/Actions Mean            -0.00132974
evaluation/Actions Std              0.20589
evaluation/Actions Max              0.99882
evaluation/Actions Min             -0.998888
evaluation/Num Paths               15
evaluation/Average Returns        -61.3447
time/data storing (s)               0.00278051
time/evaluation sampling (s)        0.324327
time/exploration sampling (s)       0.141873
time/logging (s)                    0.00484767
time/saving (s)                     0.00979629
time/training (s)                   1.96739
time/epoch (s)                      2.45102
time/total (s)                   1012.9
Epoch                             415
-----------------------------  ----------------
2019-04-23 00:10:15.782778 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 416 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.162721
trainer/QF2 Loss                    0.16234
trainer/Policy Loss                33.323
trainer/Q1 Predictions Mean       -31.4708
trainer/Q1 Predictions Std         35.7926
trainer/Q1 Predictions Max         -7.11281
trainer/Q1 Predictions Min       -109.516
trainer/Q2 Predictions Mean       -31.4825
trainer/Q2 Predictions Std         35.7593
trainer/Q2 Predictions Max         -7.12351
trainer/Q2 Predictions Min       -109.045
trainer/Q Targets Mean            -31.684
trainer/Q Targets Std              35.8995
trainer/Q Targets Max              -7.54224
trainer/Q Targets Min            -109.398
trainer/Log Pis Mean                1.888
trainer/Log Pis Std                 1.15188
trainer/Log Pis Max                 5.32173
trainer/Log Pis Min                -1.92456
trainer/Policy mu Mean             -0.00470855
trainer/Policy mu Std               0.444361
trainer/Policy mu Max               3.17157
trainer/Policy mu Min              -2.74035
trainer/Policy log std Mean        -2.31435
trainer/Policy log std Std          0.358304
trainer/Policy log std Max         -0.674588
trainer/Policy log std Min         -2.86602
trainer/Alpha                       0.0772371
trainer/Alpha Loss                 -0.286822
exploration/num steps total    208700
exploration/num paths total      2087
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.541119
exploration/Rewards Std             1.08294
exploration/Rewards Max            -0.00624209
exploration/Rewards Min            -8.39498
exploration/Returns Mean          -54.1119
exploration/Returns Std            21.0288
exploration/Returns Max           -19.0095
exploration/Returns Min           -83.8286
exploration/Actions Mean           -0.0280354
exploration/Actions Std             0.226156
exploration/Actions Max             0.943817
exploration/Actions Min            -0.999572
exploration/Num Paths               5
exploration/Average Returns       -54.1119
evaluation/num steps total     625500
evaluation/num paths total       6255
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.586533
evaluation/Rewards Std              1.19545
evaluation/Rewards Max             -0.0350213
evaluation/Rewards Min             -9.57678
evaluation/Returns Mean           -58.6533
evaluation/Returns Std             58.5615
evaluation/Returns Max            -10.4981
evaluation/Returns Min           -224.47
evaluation/Actions Mean            -0.00566762
evaluation/Actions Std              0.193284
evaluation/Actions Max              0.997718
evaluation/Actions Min             -0.999275
evaluation/Num Paths               15
evaluation/Average Returns        -58.6533
time/data storing (s)               0.00278961
time/evaluation sampling (s)        0.32711
time/exploration sampling (s)       0.139365
time/logging (s)                    0.00486427
time/saving (s)                     0.0019835
time/training (s)                   1.95613
time/epoch (s)                      2.43224
time/total (s)                   1015.34
Epoch                             416
-----------------------------  ---------------
2019-04-23 00:10:18.223275 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 417 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.92599
trainer/QF2 Loss                    1.96297
trainer/Policy Loss                32.4339
trainer/Q1 Predictions Mean       -30.6725
trainer/Q1 Predictions Std         35.1596
trainer/Q1 Predictions Max         -7.60774
trainer/Q1 Predictions Min       -122.216
trainer/Q2 Predictions Mean       -30.6538
trainer/Q2 Predictions Std         35.1589
trainer/Q2 Predictions Max         -7.33408
trainer/Q2 Predictions Min       -122.106
trainer/Q Targets Mean            -30.7572
trainer/Q Targets Std              35.6499
trainer/Q Targets Max              -0.0699619
trainer/Q Targets Min            -121.927
trainer/Log Pis Mean                1.7903
trainer/Log Pis Std                 1.102
trainer/Log Pis Max                 5.54169
trainer/Log Pis Min                -1.23967
trainer/Policy mu Mean             -0.0286803
trainer/Policy mu Std               0.347189
trainer/Policy mu Max               1.8908
trainer/Policy mu Min              -2.84543
trainer/Policy log std Mean        -2.27637
trainer/Policy log std Std          0.366183
trainer/Policy log std Max         -0.605606
trainer/Policy log std Min         -2.85459
trainer/Alpha                       0.0733831
trainer/Alpha Loss                 -0.547731
exploration/num steps total    209200
exploration/num paths total      2092
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.35047
exploration/Rewards Std             0.91653
exploration/Rewards Max            -0.00164935
exploration/Rewards Min            -8.0165
exploration/Returns Mean          -35.047
exploration/Returns Std             7.29577
exploration/Returns Max           -24.8547
exploration/Returns Min           -45.1005
exploration/Actions Mean           -0.019727
exploration/Actions Std             0.247095
exploration/Actions Max             0.99863
exploration/Actions Min            -0.998524
exploration/Num Paths               5
exploration/Average Returns       -35.047
evaluation/num steps total     627000
evaluation/num paths total       6270
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.555938
evaluation/Rewards Std              0.931019
evaluation/Rewards Max             -0.0183112
evaluation/Rewards Min             -9.31106
evaluation/Returns Mean           -55.5938
evaluation/Returns Std             56.2045
evaluation/Returns Max             -9.2902
evaluation/Returns Min           -183.935
evaluation/Actions Mean            -0.00704696
evaluation/Actions Std              0.172839
evaluation/Actions Max              0.997345
evaluation/Actions Min             -0.9985
evaluation/Num Paths               15
evaluation/Average Returns        -55.5938
time/data storing (s)               0.00286564
time/evaluation sampling (s)        0.325789
time/exploration sampling (s)       0.137367
time/logging (s)                    0.004722
time/saving (s)                     0.00199469
time/training (s)                   1.95861
time/epoch (s)                      2.43134
time/total (s)                   1017.78
Epoch                             417
-----------------------------  ---------------
2019-04-23 00:10:20.665285 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 418 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.449606
trainer/QF2 Loss                    0.422639
trainer/Policy Loss                30.0832
trainer/Q1 Predictions Mean       -28.1784
trainer/Q1 Predictions Std         31.4145
trainer/Q1 Predictions Max         -7.00635
trainer/Q1 Predictions Min       -108.257
trainer/Q2 Predictions Mean       -28.2013
trainer/Q2 Predictions Std         31.3957
trainer/Q2 Predictions Max         -7.05233
trainer/Q2 Predictions Min       -107.763
trainer/Q Targets Mean            -28.5947
trainer/Q Targets Std              31.8307
trainer/Q Targets Max              -7.33668
trainer/Q Targets Min            -109.037
trainer/Log Pis Mean                1.9237
trainer/Log Pis Std                 1.05985
trainer/Log Pis Max                 3.61059
trainer/Log Pis Min                -1.88829
trainer/Policy mu Mean              4.86851e-06
trainer/Policy mu Std               0.410956
trainer/Policy mu Max               3.52796
trainer/Policy mu Min              -1.57959
trainer/Policy log std Mean        -2.29286
trainer/Policy log std Std          0.362798
trainer/Policy log std Max         -0.35034
trainer/Policy log std Min         -2.9144
trainer/Alpha                       0.0732947
trainer/Alpha Loss                 -0.199399
exploration/num steps total    209700
exploration/num paths total      2097
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02327
exploration/Rewards Std             1.32863
exploration/Rewards Max            -0.00743283
exploration/Rewards Min           -11.1952
exploration/Returns Mean         -102.327
exploration/Returns Std            92.6695
exploration/Returns Max           -15.7642
exploration/Returns Min          -230.65
exploration/Actions Mean           -0.0223784
exploration/Actions Std             0.209265
exploration/Actions Max             0.988202
exploration/Actions Min            -0.999863
exploration/Num Paths               5
exploration/Average Returns      -102.327
evaluation/num steps total     628500
evaluation/num paths total       6285
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.608606
evaluation/Rewards Std              1.33394
evaluation/Rewards Max             -0.00875054
evaluation/Rewards Min            -10.4266
evaluation/Returns Mean           -60.8606
evaluation/Returns Std             62.2532
evaluation/Returns Max             -2.18623
evaluation/Returns Min           -204.576
evaluation/Actions Mean             0.00475971
evaluation/Actions Std              0.215778
evaluation/Actions Max              0.998791
evaluation/Actions Min             -0.999356
evaluation/Num Paths               15
evaluation/Average Returns        -60.8606
time/data storing (s)               0.00260477
time/evaluation sampling (s)        0.326873
time/exploration sampling (s)       0.135589
time/logging (s)                    0.00486084
time/saving (s)                     0.00198585
time/training (s)                   1.96078
time/epoch (s)                      2.4327
time/total (s)                   1020.21
Epoch                             418
-----------------------------  ----------------
2019-04-23 00:10:23.118119 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 419 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0964151
trainer/QF2 Loss                    0.0849068
trainer/Policy Loss                30.1733
trainer/Q1 Predictions Mean       -28.4363
trainer/Q1 Predictions Std         31.4435
trainer/Q1 Predictions Max         -7.29855
trainer/Q1 Predictions Min       -108.411
trainer/Q2 Predictions Mean       -28.4294
trainer/Q2 Predictions Std         31.3605
trainer/Q2 Predictions Max         -7.28351
trainer/Q2 Predictions Min       -107.364
trainer/Q Targets Mean            -28.3953
trainer/Q Targets Std              31.4294
trainer/Q Targets Max              -7.39356
trainer/Q Targets Min            -106.991
trainer/Log Pis Mean                1.81674
trainer/Log Pis Std                 1.17881
trainer/Log Pis Max                 3.537
trainer/Log Pis Min                -1.91169
trainer/Policy mu Mean             -0.0058455
trainer/Policy mu Std               0.185463
trainer/Policy mu Max               1.7002
trainer/Policy mu Min              -0.536801
trainer/Policy log std Mean        -2.33818
trainer/Policy log std Std          0.289201
trainer/Policy log std Max         -0.921604
trainer/Policy log std Min         -3.06915
trainer/Alpha                       0.0752651
trainer/Alpha Loss                 -0.474052
exploration/num steps total    210200
exploration/num paths total      2102
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.721031
exploration/Rewards Std             1.34639
exploration/Rewards Max            -0.01394
exploration/Rewards Min           -10.1733
exploration/Returns Mean          -72.1031
exploration/Returns Std            73.3458
exploration/Returns Max           -16.2837
exploration/Returns Min          -215.487
exploration/Actions Mean           -0.0215368
exploration/Actions Std             0.245854
exploration/Actions Max             0.999062
exploration/Actions Min            -0.999632
exploration/Num Paths               5
exploration/Average Returns       -72.1031
evaluation/num steps total     630000
evaluation/num paths total       6300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.549606
evaluation/Rewards Std              0.948215
evaluation/Rewards Max             -0.0418938
evaluation/Rewards Min             -8.283
evaluation/Returns Mean           -54.9606
evaluation/Returns Std             56.6415
evaluation/Returns Max             -5.11266
evaluation/Returns Min           -195.957
evaluation/Actions Mean             0.00192787
evaluation/Actions Std              0.174564
evaluation/Actions Max              0.997213
evaluation/Actions Min             -0.998794
evaluation/Num Paths               15
evaluation/Average Returns        -54.9606
time/data storing (s)               0.002821
time/evaluation sampling (s)        0.323045
time/exploration sampling (s)       0.139987
time/logging (s)                    0.0047827
time/saving (s)                     0.00198535
time/training (s)                   1.96954
time/epoch (s)                      2.44216
time/total (s)                   1022.66
Epoch                             419
-----------------------------  ---------------
2019-04-23 00:10:25.558126 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 420 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.00425
trainer/QF2 Loss                    1.95151
trainer/Policy Loss                29.7172
trainer/Q1 Predictions Mean       -27.8109
trainer/Q1 Predictions Std         31.7314
trainer/Q1 Predictions Max         -7.1811
trainer/Q1 Predictions Min       -104.423
trainer/Q2 Predictions Mean       -27.852
trainer/Q2 Predictions Std         31.7298
trainer/Q2 Predictions Max         -7.19043
trainer/Q2 Predictions Min       -104.413
trainer/Q Targets Mean            -28.2244
trainer/Q Targets Std              32.401
trainer/Q Targets Max              -0.246545
trainer/Q Targets Min            -105.853
trainer/Log Pis Mean                1.96426
trainer/Log Pis Std                 1.22925
trainer/Log Pis Max                 5.89704
trainer/Log Pis Min                -1.70564
trainer/Policy mu Mean             -0.0568682
trainer/Policy mu Std               0.496167
trainer/Policy mu Max               2.87182
trainer/Policy mu Min              -2.75353
trainer/Policy log std Mean        -2.25655
trainer/Policy log std Std          0.420571
trainer/Policy log std Max         -0.493841
trainer/Policy log std Min         -2.92367
trainer/Alpha                       0.0727006
trainer/Alpha Loss                 -0.0936714
exploration/num steps total    210700
exploration/num paths total      2107
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.02264
exploration/Rewards Std             0.989793
exploration/Rewards Max            -0.0249977
exploration/Rewards Min            -7.59483
exploration/Returns Mean         -102.264
exploration/Returns Std            60.5595
exploration/Returns Max           -32.6494
exploration/Returns Min          -186.4
exploration/Actions Mean           -0.0183322
exploration/Actions Std             0.22823
exploration/Actions Max             0.997115
exploration/Actions Min            -0.998256
exploration/Num Paths               5
exploration/Average Returns      -102.264
evaluation/num steps total     631500
evaluation/num paths total       6315
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.456029
evaluation/Rewards Std              0.894496
evaluation/Rewards Max             -0.0160378
evaluation/Rewards Min             -8.43535
evaluation/Returns Mean           -45.6029
evaluation/Returns Std             40.0457
evaluation/Returns Max            -15.3559
evaluation/Returns Min           -177.997
evaluation/Actions Mean            -0.0115166
evaluation/Actions Std              0.171941
evaluation/Actions Max              0.998115
evaluation/Actions Min             -0.999806
evaluation/Num Paths               15
evaluation/Average Returns        -45.6029
time/data storing (s)               0.00265414
time/evaluation sampling (s)        0.331706
time/exploration sampling (s)       0.13741
time/logging (s)                    0.00473211
time/saving (s)                     0.00201322
time/training (s)                   1.95077
time/epoch (s)                      2.42929
time/total (s)                   1025.09
Epoch                             420
-----------------------------  ---------------
2019-04-23 00:10:27.987680 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 421 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.40688
trainer/QF2 Loss                    1.3948
trainer/Policy Loss                32.766
trainer/Q1 Predictions Mean       -30.9505
trainer/Q1 Predictions Std         32.913
trainer/Q1 Predictions Max         -7.30875
trainer/Q1 Predictions Min       -125.624
trainer/Q2 Predictions Mean       -30.963
trainer/Q2 Predictions Std         32.9416
trainer/Q2 Predictions Max         -7.42264
trainer/Q2 Predictions Min       -125.686
trainer/Q Targets Mean            -31.421
trainer/Q Targets Std              33.4822
trainer/Q Targets Max              -0.176475
trainer/Q Targets Min            -127.504
trainer/Log Pis Mean                1.89403
trainer/Log Pis Std                 1.18029
trainer/Log Pis Max                 6.28612
trainer/Log Pis Min                -1.23376
trainer/Policy mu Mean             -0.102727
trainer/Policy mu Std               0.386463
trainer/Policy mu Max               2.11461
trainer/Policy mu Min              -2.8475
trainer/Policy log std Mean        -2.23584
trainer/Policy log std Std          0.400248
trainer/Policy log std Max         -0.554024
trainer/Policy log std Min         -2.95363
trainer/Alpha                       0.0721037
trainer/Alpha Loss                 -0.278653
exploration/num steps total    211200
exploration/num paths total      2112
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.653461
exploration/Rewards Std             0.688319
exploration/Rewards Max            -0.00621678
exploration/Rewards Min            -5.42061
exploration/Returns Mean          -65.3461
exploration/Returns Std            58.0185
exploration/Returns Max           -17.2026
exploration/Returns Min          -159.159
exploration/Actions Mean           -0.00363362
exploration/Actions Std             0.197748
exploration/Actions Max             0.99138
exploration/Actions Min            -0.998405
exploration/Num Paths               5
exploration/Average Returns       -65.3461
evaluation/num steps total     633000
evaluation/num paths total       6330
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.805963
evaluation/Rewards Std              1.08593
evaluation/Rewards Max             -0.024339
evaluation/Rewards Min            -10.3897
evaluation/Returns Mean           -80.5963
evaluation/Returns Std             70.3003
evaluation/Returns Max             -7.37852
evaluation/Returns Min           -187.251
evaluation/Actions Mean             0.00841487
evaluation/Actions Std              0.185498
evaluation/Actions Max              0.994383
evaluation/Actions Min             -0.999285
evaluation/Num Paths               15
evaluation/Average Returns        -80.5963
time/data storing (s)               0.00268094
time/evaluation sampling (s)        0.327001
time/exploration sampling (s)       0.138661
time/logging (s)                    0.00477845
time/saving (s)                     0.00198078
time/training (s)                   1.94393
time/epoch (s)                      2.41904
time/total (s)                   1027.52
Epoch                             421
-----------------------------  ---------------
2019-04-23 00:10:30.437440 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 422 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.74157
trainer/QF2 Loss                    2.76684
trainer/Policy Loss                34.4654
trainer/Q1 Predictions Mean       -32.3897
trainer/Q1 Predictions Std         34.0506
trainer/Q1 Predictions Max         -7.24453
trainer/Q1 Predictions Min       -126.772
trainer/Q2 Predictions Mean       -32.3804
trainer/Q2 Predictions Std         34.0282
trainer/Q2 Predictions Max         -6.94703
trainer/Q2 Predictions Min       -125.61
trainer/Q Targets Mean            -32.584
trainer/Q Targets Std              34.6554
trainer/Q Targets Max              -0.147184
trainer/Q Targets Min            -125.829
trainer/Log Pis Mean                2.19651
trainer/Log Pis Std                 1.11631
trainer/Log Pis Max                 7.46771
trainer/Log Pis Min                -0.922742
trainer/Policy mu Mean             -0.0675366
trainer/Policy mu Std               0.47021
trainer/Policy mu Max               3.29639
trainer/Policy mu Min              -3.45906
trainer/Policy log std Mean        -2.25091
trainer/Policy log std Std          0.358122
trainer/Policy log std Max         -0.613709
trainer/Policy log std Min         -2.92926
trainer/Alpha                       0.0728866
trainer/Alpha Loss                  0.514665
exploration/num steps total    211700
exploration/num paths total      2117
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.87334
exploration/Rewards Std             1.2856
exploration/Rewards Max            -0.016975
exploration/Rewards Min            -9.66008
exploration/Returns Mean          -87.334
exploration/Returns Std            60.8384
exploration/Returns Max           -26.1324
exploration/Returns Min          -198.71
exploration/Actions Mean            0.0208352
exploration/Actions Std             0.230778
exploration/Actions Max             0.999384
exploration/Actions Min            -0.999707
exploration/Num Paths               5
exploration/Average Returns       -87.334
evaluation/num steps total     634500
evaluation/num paths total       6345
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.873062
evaluation/Rewards Std              1.15213
evaluation/Rewards Max             -0.0356581
evaluation/Rewards Min            -10.6544
evaluation/Returns Mean           -87.3062
evaluation/Returns Std             59.1842
evaluation/Returns Max            -12.0367
evaluation/Returns Min           -177.302
evaluation/Actions Mean             0.0030117
evaluation/Actions Std              0.193972
evaluation/Actions Max              0.999406
evaluation/Actions Min             -0.99964
evaluation/Num Paths               15
evaluation/Average Returns        -87.3062
time/data storing (s)               0.00261366
time/evaluation sampling (s)        0.329836
time/exploration sampling (s)       0.138861
time/logging (s)                    0.00481018
time/saving (s)                     0.00198511
time/training (s)                   1.9625
time/epoch (s)                      2.44061
time/total (s)                   1029.96
Epoch                             422
-----------------------------  ---------------
2019-04-23 00:10:32.880419 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 423 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.46443
trainer/QF2 Loss                    2.46477
trainer/Policy Loss                30.512
trainer/Q1 Predictions Mean       -28.58
trainer/Q1 Predictions Std         30.7232
trainer/Q1 Predictions Max         -7.53353
trainer/Q1 Predictions Min       -100.087
trainer/Q2 Predictions Mean       -28.512
trainer/Q2 Predictions Std         30.7359
trainer/Q2 Predictions Max         -7.34903
trainer/Q2 Predictions Min       -100.594
trainer/Q Targets Mean            -28.5253
trainer/Q Targets Std              31.1791
trainer/Q Targets Max              -0.0665051
trainer/Q Targets Min            -101.037
trainer/Log Pis Mean                2.04037
trainer/Log Pis Std                 1.45566
trainer/Log Pis Max                 6.60319
trainer/Log Pis Min                -3.20519
trainer/Policy mu Mean             -0.0525254
trainer/Policy mu Std               0.583942
trainer/Policy mu Max               2.86456
trainer/Policy mu Min              -3.3928
trainer/Policy log std Mean        -2.30858
trainer/Policy log std Std          0.464976
trainer/Policy log std Max         -0.479711
trainer/Policy log std Min         -3.05015
trainer/Alpha                       0.0734197
trainer/Alpha Loss                  0.105421
exploration/num steps total    212200
exploration/num paths total      2122
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.15746
exploration/Rewards Std             1.11776
exploration/Rewards Max            -0.0134086
exploration/Rewards Min            -8.6236
exploration/Returns Mean         -115.746
exploration/Returns Std            60.4551
exploration/Returns Max           -45.4371
exploration/Returns Min          -197.828
exploration/Actions Mean            0.0102407
exploration/Actions Std             0.221157
exploration/Actions Max             0.998828
exploration/Actions Min            -0.999897
exploration/Num Paths               5
exploration/Average Returns      -115.746
evaluation/num steps total     636000
evaluation/num paths total       6360
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.573182
evaluation/Rewards Std              0.982746
evaluation/Rewards Max             -0.0103727
evaluation/Rewards Min             -8.61073
evaluation/Returns Mean           -57.3182
evaluation/Returns Std             67.0961
evaluation/Returns Max             -7.64834
evaluation/Returns Min           -205.011
evaluation/Actions Mean             0.00367673
evaluation/Actions Std              0.173189
evaluation/Actions Max              0.996112
evaluation/Actions Min             -0.998451
evaluation/Num Paths               15
evaluation/Average Returns        -57.3182
time/data storing (s)               0.00260608
time/evaluation sampling (s)        0.335759
time/exploration sampling (s)       0.140088
time/logging (s)                    0.00351601
time/saving (s)                     0.00197256
time/training (s)                   1.94702
time/epoch (s)                      2.43096
time/total (s)                   1032.4
Epoch                             423
-----------------------------  ---------------
2019-04-23 00:10:35.313494 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 424 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.843399
trainer/QF2 Loss                    0.846561
trainer/Policy Loss                27.8766
trainer/Q1 Predictions Mean       -25.956
trainer/Q1 Predictions Std         28.6259
trainer/Q1 Predictions Max         -7.41744
trainer/Q1 Predictions Min        -98.2892
trainer/Q2 Predictions Mean       -25.9335
trainer/Q2 Predictions Std         28.6259
trainer/Q2 Predictions Max         -7.30385
trainer/Q2 Predictions Min        -98.1539
trainer/Q Targets Mean            -26.1083
trainer/Q Targets Std              28.8518
trainer/Q Targets Max              -0.060541
trainer/Q Targets Min             -99.2916
trainer/Log Pis Mean                1.97775
trainer/Log Pis Std                 1.234
trainer/Log Pis Max                 5.84273
trainer/Log Pis Min                -1.74397
trainer/Policy mu Mean             -0.0277697
trainer/Policy mu Std               0.581658
trainer/Policy mu Max               2.89413
trainer/Policy mu Min              -4.05917
trainer/Policy log std Mean        -2.21629
trainer/Policy log std Std          0.477184
trainer/Policy log std Max          0.137296
trainer/Policy log std Min         -2.89215
trainer/Alpha                       0.0730326
trainer/Alpha Loss                 -0.0582316
exploration/num steps total    212700
exploration/num paths total      2127
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.546216
exploration/Rewards Std             0.646733
exploration/Rewards Max            -0.00146729
exploration/Rewards Min            -5.11474
exploration/Returns Mean          -54.6216
exploration/Returns Std            51.3685
exploration/Returns Max           -19.81
exploration/Returns Min          -156.907
exploration/Actions Mean            0.00917367
exploration/Actions Std             0.210986
exploration/Actions Max             0.999853
exploration/Actions Min            -0.989883
exploration/Num Paths               5
exploration/Average Returns       -54.6216
evaluation/num steps total     637500
evaluation/num paths total       6375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.49276
evaluation/Rewards Std              1.14026
evaluation/Rewards Max             -0.0412595
evaluation/Rewards Min            -10.9717
evaluation/Returns Mean           -49.276
evaluation/Returns Std             46.8781
evaluation/Returns Max             -8.86667
evaluation/Returns Min           -165.363
evaluation/Actions Mean            -0.00378299
evaluation/Actions Std              0.193236
evaluation/Actions Max              0.998512
evaluation/Actions Min             -0.999656
evaluation/Num Paths               15
evaluation/Average Returns        -49.276
time/data storing (s)               0.00278876
time/evaluation sampling (s)        0.326623
time/exploration sampling (s)       0.139743
time/logging (s)                    0.00478265
time/saving (s)                     0.00159809
time/training (s)                   1.94885
time/epoch (s)                      2.42438
time/total (s)                   1034.82
Epoch                             424
-----------------------------  ---------------
2019-04-23 00:10:37.765837 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 425 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   45.8365
trainer/QF2 Loss                   45.7603
trainer/Policy Loss                33.1669
trainer/Q1 Predictions Mean       -31.1691
trainer/Q1 Predictions Std         33.1175
trainer/Q1 Predictions Max         -7.21456
trainer/Q1 Predictions Min       -126.61
trainer/Q2 Predictions Mean       -31.139
trainer/Q2 Predictions Std         33.1583
trainer/Q2 Predictions Max         -7.14128
trainer/Q2 Predictions Min       -125.858
trainer/Q Targets Mean            -31.3343
trainer/Q Targets Std              33.9087
trainer/Q Targets Max              -1.5164
trainer/Q Targets Min            -129.115
trainer/Log Pis Mean                2.13307
trainer/Log Pis Std                 1.12638
trainer/Log Pis Max                 5.93601
trainer/Log Pis Min                -1.07116
trainer/Policy mu Mean             -0.040675
trainer/Policy mu Std               0.406437
trainer/Policy mu Max               2.66792
trainer/Policy mu Min              -3.34154
trainer/Policy log std Mean        -2.32939
trainer/Policy log std Std          0.352654
trainer/Policy log std Max         -0.50002
trainer/Policy log std Min         -2.88876
trainer/Alpha                       0.07298
trainer/Alpha Loss                  0.348331
exploration/num steps total    213200
exploration/num paths total      2132
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.784236
exploration/Rewards Std             1.13573
exploration/Rewards Max            -0.00502692
exploration/Rewards Min            -8.46745
exploration/Returns Mean          -78.4236
exploration/Returns Std            50.3248
exploration/Returns Max           -31.6513
exploration/Returns Min          -167.888
exploration/Actions Mean           -0.0115039
exploration/Actions Std             0.232914
exploration/Actions Max             0.998852
exploration/Actions Min            -0.999407
exploration/Num Paths               5
exploration/Average Returns       -78.4236
evaluation/num steps total     639000
evaluation/num paths total       6390
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.646266
evaluation/Rewards Std              1.10247
evaluation/Rewards Max             -0.036259
evaluation/Rewards Min             -9.90692
evaluation/Returns Mean           -64.6266
evaluation/Returns Std             52.9983
evaluation/Returns Max             -8.43244
evaluation/Returns Min           -171.335
evaluation/Actions Mean             0.00248855
evaluation/Actions Std              0.194462
evaluation/Actions Max              0.99875
evaluation/Actions Min             -0.999446
evaluation/Num Paths               15
evaluation/Average Returns        -64.6266
time/data storing (s)               0.00270419
time/evaluation sampling (s)        0.329976
time/exploration sampling (s)       0.137719
time/logging (s)                    0.00484447
time/saving (s)                     0.00198101
time/training (s)                   1.96549
time/epoch (s)                      2.44271
time/total (s)                   1037.27
Epoch                             425
-----------------------------  ---------------
2019-04-23 00:10:40.226231 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 426 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.13841
trainer/QF2 Loss                    1.06187
trainer/Policy Loss                33.4422
trainer/Q1 Predictions Mean       -31.3656
trainer/Q1 Predictions Std         31.5274
trainer/Q1 Predictions Max         -7.25474
trainer/Q1 Predictions Min        -96.4151
trainer/Q2 Predictions Mean       -31.3924
trainer/Q2 Predictions Std         31.6099
trainer/Q2 Predictions Max         -7.31209
trainer/Q2 Predictions Min        -96.2163
trainer/Q Targets Mean            -31.6933
trainer/Q Targets Std              32.0486
trainer/Q Targets Max              -0.342313
trainer/Q Targets Min             -97.2922
trainer/Log Pis Mean                2.14808
trainer/Log Pis Std                 1.26536
trainer/Log Pis Max                 7.21367
trainer/Log Pis Min                -2.61804
trainer/Policy mu Mean             -0.0202409
trainer/Policy mu Std               0.519361
trainer/Policy mu Max               2.88762
trainer/Policy mu Min              -3.31101
trainer/Policy log std Mean        -2.26852
trainer/Policy log std Std          0.403525
trainer/Policy log std Max         -0.482406
trainer/Policy log std Min         -2.92652
trainer/Alpha                       0.0704821
trainer/Alpha Loss                  0.392755
exploration/num steps total    213700
exploration/num paths total      2137
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.396064
exploration/Rewards Std             0.555387
exploration/Rewards Max            -0.00429824
exploration/Rewards Min            -4.535
exploration/Returns Mean          -39.6064
exploration/Returns Std            40.7029
exploration/Returns Max           -11.7058
exploration/Returns Min          -120.506
exploration/Actions Mean           -0.000695692
exploration/Actions Std             0.190981
exploration/Actions Max             0.996085
exploration/Actions Min            -0.999278
exploration/Num Paths               5
exploration/Average Returns       -39.6064
evaluation/num steps total     640500
evaluation/num paths total       6405
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.429514
evaluation/Rewards Std              0.909171
evaluation/Rewards Max             -0.0129892
evaluation/Rewards Min             -9.58075
evaluation/Returns Mean           -42.9514
evaluation/Returns Std             35.1741
evaluation/Returns Max             -6.79126
evaluation/Returns Min           -126.358
evaluation/Actions Mean             0.00168521
evaluation/Actions Std              0.174933
evaluation/Actions Max              0.99788
evaluation/Actions Min             -0.999065
evaluation/Num Paths               15
evaluation/Average Returns        -42.9514
time/data storing (s)               0.00276484
time/evaluation sampling (s)        0.330023
time/exploration sampling (s)       0.139768
time/logging (s)                    0.00480365
time/saving (s)                     0.00200595
time/training (s)                   1.97031
time/epoch (s)                      2.44967
time/total (s)                   1039.73
Epoch                             426
-----------------------------  ----------------
2019-04-23 00:10:42.681915 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 427 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.760109
trainer/QF2 Loss                    0.498812
trainer/Policy Loss                32.971
trainer/Q1 Predictions Mean       -31.1866
trainer/Q1 Predictions Std         31.5066
trainer/Q1 Predictions Max         -7.06108
trainer/Q1 Predictions Min        -95.8429
trainer/Q2 Predictions Mean       -31.2401
trainer/Q2 Predictions Std         31.5275
trainer/Q2 Predictions Max         -7.20272
trainer/Q2 Predictions Min        -95.5766
trainer/Q Targets Mean            -31.6691
trainer/Q Targets Std              32.0001
trainer/Q Targets Max              -7.39955
trainer/Q Targets Min             -97.2558
trainer/Log Pis Mean                1.80437
trainer/Log Pis Std                 0.937872
trainer/Log Pis Max                 4.46149
trainer/Log Pis Min                -0.765704
trainer/Policy mu Mean              0.0323501
trainer/Policy mu Std               0.367805
trainer/Policy mu Max               3.17031
trainer/Policy mu Min              -0.434752
trainer/Policy log std Mean        -2.23934
trainer/Policy log std Std          0.351535
trainer/Policy log std Max         -0.521013
trainer/Policy log std Min         -2.7849
trainer/Alpha                       0.0706853
trainer/Alpha Loss                 -0.518278
exploration/num steps total    214200
exploration/num paths total      2142
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.852222
exploration/Rewards Std             1.10395
exploration/Rewards Max            -0.0102268
exploration/Rewards Min            -9.80147
exploration/Returns Mean          -85.2222
exploration/Returns Std            58.0524
exploration/Returns Max           -25.2601
exploration/Returns Min          -176.021
exploration/Actions Mean           -0.0126221
exploration/Actions Std             0.228517
exploration/Actions Max             0.996498
exploration/Actions Min            -0.999655
exploration/Num Paths               5
exploration/Average Returns       -85.2222
evaluation/num steps total     642000
evaluation/num paths total       6420
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.594604
evaluation/Rewards Std              1.07659
evaluation/Rewards Max             -0.0253738
evaluation/Rewards Min             -8.91771
evaluation/Returns Mean           -59.4604
evaluation/Returns Std             56.4974
evaluation/Returns Max             -8.29008
evaluation/Returns Min           -185.178
evaluation/Actions Mean            -0.0115088
evaluation/Actions Std              0.19007
evaluation/Actions Max              0.995967
evaluation/Actions Min             -0.99994
evaluation/Num Paths               15
evaluation/Average Returns        -59.4604
time/data storing (s)               0.00273951
time/evaluation sampling (s)        0.327763
time/exploration sampling (s)       0.138898
time/logging (s)                    0.00478575
time/saving (s)                     0.00974699
time/training (s)                   1.96102
time/epoch (s)                      2.44496
time/total (s)                   1042.17
Epoch                             427
-----------------------------  ---------------
2019-04-23 00:10:45.128843 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 428 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.12918
trainer/QF2 Loss                    0.114941
trainer/Policy Loss                32.2837
trainer/Q1 Predictions Mean       -30.4306
trainer/Q1 Predictions Std         31.0716
trainer/Q1 Predictions Max         -7.35528
trainer/Q1 Predictions Min        -96.0125
trainer/Q2 Predictions Mean       -30.4891
trainer/Q2 Predictions Std         31.0886
trainer/Q2 Predictions Max         -7.3056
trainer/Q2 Predictions Min        -95.7578
trainer/Q Targets Mean            -30.6636
trainer/Q Targets Std              31.2562
trainer/Q Targets Max              -7.26302
trainer/Q Targets Min             -96.3979
trainer/Log Pis Mean                1.88246
trainer/Log Pis Std                 1.27218
trainer/Log Pis Max                 8.65778
trainer/Log Pis Min                -0.943791
trainer/Policy mu Mean              0.0531661
trainer/Policy mu Std               0.485373
trainer/Policy mu Max               3.19925
trainer/Policy mu Min              -3.36668
trainer/Policy log std Mean        -2.17741
trainer/Policy log std Std          0.373479
trainer/Policy log std Max         -0.327521
trainer/Policy log std Min         -2.92446
trainer/Alpha                       0.0677355
trainer/Alpha Loss                 -0.316412
exploration/num steps total    214700
exploration/num paths total      2147
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.804256
exploration/Rewards Std             0.984714
exploration/Rewards Max            -0.00764199
exploration/Rewards Min            -7.6427
exploration/Returns Mean          -80.4256
exploration/Returns Std            57.5661
exploration/Returns Max           -24.8441
exploration/Returns Min          -163.66
exploration/Actions Mean            0.0114096
exploration/Actions Std             0.205802
exploration/Actions Max             0.998433
exploration/Actions Min            -0.997669
exploration/Num Paths               5
exploration/Average Returns       -80.4256
evaluation/num steps total     643500
evaluation/num paths total       6435
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.580564
evaluation/Rewards Std              1.11046
evaluation/Rewards Max             -0.0144632
evaluation/Rewards Min            -11.3611
evaluation/Returns Mean           -58.0564
evaluation/Returns Std             44.8028
evaluation/Returns Max             -8.48995
evaluation/Returns Min           -178.886
evaluation/Actions Mean            -0.0113779
evaluation/Actions Std              0.192949
evaluation/Actions Max              0.998817
evaluation/Actions Min             -0.999642
evaluation/Num Paths               15
evaluation/Average Returns        -58.0564
time/data storing (s)               0.00263144
time/evaluation sampling (s)        0.327464
time/exploration sampling (s)       0.138834
time/logging (s)                    0.0048076
time/saving (s)                     0.00208827
time/training (s)                   1.96053
time/epoch (s)                      2.43635
time/total (s)                   1044.62
Epoch                             428
-----------------------------  ---------------
2019-04-23 00:10:47.581794 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 429 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.256926
trainer/QF2 Loss                    0.28805
trainer/Policy Loss                32.6228
trainer/Q1 Predictions Mean       -30.6729
trainer/Q1 Predictions Std         30.6872
trainer/Q1 Predictions Max         -7.25691
trainer/Q1 Predictions Min        -95.4586
trainer/Q2 Predictions Mean       -30.6684
trainer/Q2 Predictions Std         30.6947
trainer/Q2 Predictions Max         -7.22923
trainer/Q2 Predictions Min        -95.276
trainer/Q Targets Mean            -31.009
trainer/Q Targets Std              30.8823
trainer/Q Targets Max              -7.258
trainer/Q Targets Min             -95.3615
trainer/Log Pis Mean                1.99068
trainer/Log Pis Std                 1.0777
trainer/Log Pis Max                 4.66596
trainer/Log Pis Min                -1.02505
trainer/Policy mu Mean             -0.0372422
trainer/Policy mu Std               0.391765
trainer/Policy mu Max               2.71417
trainer/Policy mu Min              -2.38285
trainer/Policy log std Mean        -2.27613
trainer/Policy log std Std          0.388448
trainer/Policy log std Max         -0.699377
trainer/Policy log std Min         -2.84894
trainer/Alpha                       0.0678914
trainer/Alpha Loss                 -0.0250785
exploration/num steps total    215200
exploration/num paths total      2152
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.675144
exploration/Rewards Std             0.954275
exploration/Rewards Max            -0.00809516
exploration/Rewards Min            -8.02282
exploration/Returns Mean          -67.5144
exploration/Returns Std            46.6897
exploration/Returns Max           -15.2095
exploration/Returns Min          -134.642
exploration/Actions Mean            0.0188808
exploration/Actions Std             0.198968
exploration/Actions Max             0.999335
exploration/Actions Min            -0.998906
exploration/Num Paths               5
exploration/Average Returns       -67.5144
evaluation/num steps total     645000
evaluation/num paths total       6450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.640769
evaluation/Rewards Std              1.05695
evaluation/Rewards Max             -0.0381522
evaluation/Rewards Min            -11.3723
evaluation/Returns Mean           -64.0769
evaluation/Returns Std             57.0395
evaluation/Returns Max            -13.4257
evaluation/Returns Min           -163.943
evaluation/Actions Mean             0.000153333
evaluation/Actions Std              0.183694
evaluation/Actions Max              0.996996
evaluation/Actions Min             -0.998689
evaluation/Num Paths               15
evaluation/Average Returns        -64.0769
time/data storing (s)               0.00269809
time/evaluation sampling (s)        0.329063
time/exploration sampling (s)       0.135289
time/logging (s)                    0.00437307
time/saving (s)                     0.00199798
time/training (s)                   1.96856
time/epoch (s)                      2.44198
time/total (s)                   1047.06
Epoch                             429
-----------------------------  ----------------
2019-04-23 00:10:50.026982 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 430 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0648609
trainer/QF2 Loss                    0.0527164
trainer/Policy Loss                28.8912
trainer/Q1 Predictions Mean       -26.776
trainer/Q1 Predictions Std         28.5347
trainer/Q1 Predictions Max         -7.44148
trainer/Q1 Predictions Min        -94.9849
trainer/Q2 Predictions Mean       -26.7885
trainer/Q2 Predictions Std         28.5688
trainer/Q2 Predictions Max         -7.40113
trainer/Q2 Predictions Min        -95.0022
trainer/Q Targets Mean            -26.8692
trainer/Q Targets Std              28.6476
trainer/Q Targets Max              -7.46977
trainer/Q Targets Min             -95.4084
trainer/Log Pis Mean                2.15226
trainer/Log Pis Std                 1.07266
trainer/Log Pis Max                 6.7901
trainer/Log Pis Min                -1.72674
trainer/Policy mu Mean             -0.00125558
trainer/Policy mu Std               0.488444
trainer/Policy mu Max               2.48297
trainer/Policy mu Min              -3.98685
trainer/Policy log std Mean        -2.29538
trainer/Policy log std Std          0.427636
trainer/Policy log std Max         -0.370665
trainer/Policy log std Min         -2.80129
trainer/Alpha                       0.0682691
trainer/Alpha Loss                  0.40874
exploration/num steps total    215700
exploration/num paths total      2157
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.407718
exploration/Rewards Std             0.970469
exploration/Rewards Max            -0.00784173
exploration/Rewards Min            -9.41708
exploration/Returns Mean          -40.7718
exploration/Returns Std            18.8068
exploration/Returns Max           -16.5935
exploration/Returns Min           -59.2699
exploration/Actions Mean           -0.0108257
exploration/Actions Std             0.226092
exploration/Actions Max             0.99664
exploration/Actions Min            -0.998449
exploration/Num Paths               5
exploration/Average Returns       -40.7718
evaluation/num steps total     646500
evaluation/num paths total       6465
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.66353
evaluation/Rewards Std              1.15964
evaluation/Rewards Max             -0.0372627
evaluation/Rewards Min             -9.98498
evaluation/Returns Mean           -66.353
evaluation/Returns Std             66.7902
evaluation/Returns Max             -7.08363
evaluation/Returns Min           -203.938
evaluation/Actions Mean            -0.000658676
evaluation/Actions Std              0.186441
evaluation/Actions Max              0.997963
evaluation/Actions Min             -0.999144
evaluation/Num Paths               15
evaluation/Average Returns        -66.353
time/data storing (s)               0.00273295
time/evaluation sampling (s)        0.316404
time/exploration sampling (s)       0.140055
time/logging (s)                    0.00349165
time/saving (s)                     0.00176242
time/training (s)                   1.96948
time/epoch (s)                      2.43393
time/total (s)                   1049.5
Epoch                             430
-----------------------------  ----------------
2019-04-23 00:10:52.451650 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 431 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.05001
trainer/QF2 Loss                    1.03258
trainer/Policy Loss                32.2297
trainer/Q1 Predictions Mean       -30.3055
trainer/Q1 Predictions Std         32.4061
trainer/Q1 Predictions Max         -7.00841
trainer/Q1 Predictions Min        -95.759
trainer/Q2 Predictions Mean       -30.2892
trainer/Q2 Predictions Std         32.3818
trainer/Q2 Predictions Max         -7.08756
trainer/Q2 Predictions Min        -95.0242
trainer/Q Targets Mean            -30.529
trainer/Q Targets Std              32.6507
trainer/Q Targets Max              -0.0484948
trainer/Q Targets Min             -95.6747
trainer/Log Pis Mean                2.03063
trainer/Log Pis Std                 1.14355
trainer/Log Pis Max                 4.68392
trainer/Log Pis Min                -1.81038
trainer/Policy mu Mean             -0.0197988
trainer/Policy mu Std               0.430761
trainer/Policy mu Max               2.17292
trainer/Policy mu Min              -3.07502
trainer/Policy log std Mean        -2.33116
trainer/Policy log std Std          0.350075
trainer/Policy log std Max         -0.794579
trainer/Policy log std Min         -2.73798
trainer/Alpha                       0.0721523
trainer/Alpha Loss                  0.0805168
exploration/num steps total    216200
exploration/num paths total      2162
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.633029
exploration/Rewards Std             1.22363
exploration/Rewards Max            -0.00549246
exploration/Rewards Min           -10.2286
exploration/Returns Mean          -63.3029
exploration/Returns Std            63.0445
exploration/Returns Max           -17.9909
exploration/Returns Min          -184.098
exploration/Actions Mean            0.0173907
exploration/Actions Std             0.217994
exploration/Actions Max             0.999361
exploration/Actions Min            -0.996204
exploration/Num Paths               5
exploration/Average Returns       -63.3029
evaluation/num steps total     648000
evaluation/num paths total       6480
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -1.00837
evaluation/Rewards Std              1.41176
evaluation/Rewards Max             -0.0361016
evaluation/Rewards Min            -11.6374
evaluation/Returns Mean          -100.837
evaluation/Returns Std             63.9228
evaluation/Returns Max            -17.1304
evaluation/Returns Min           -193.304
evaluation/Actions Mean             0.00861697
evaluation/Actions Std              0.221787
evaluation/Actions Max              0.999375
evaluation/Actions Min             -0.999063
evaluation/Num Paths               15
evaluation/Average Returns       -100.837
time/data storing (s)               0.00256125
time/evaluation sampling (s)        0.324085
time/exploration sampling (s)       0.141243
time/logging (s)                    0.00379069
time/saving (s)                     0.00164492
time/training (s)                   1.94075
time/epoch (s)                      2.41407
time/total (s)                   1051.92
Epoch                             431
-----------------------------  ---------------
2019-04-23 00:10:54.902022 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 432 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   71.0596
trainer/QF2 Loss                   71.3191
trainer/Policy Loss                29.0537
trainer/Q1 Predictions Mean       -27.0728
trainer/Q1 Predictions Std         28.8754
trainer/Q1 Predictions Max         -6.97781
trainer/Q1 Predictions Min        -93.7334
trainer/Q2 Predictions Mean       -27.0798
trainer/Q2 Predictions Std         28.872
trainer/Q2 Predictions Max         -7.0987
trainer/Q2 Predictions Min        -93.4721
trainer/Q Targets Mean            -26.1981
trainer/Q Targets Std              28.9832
trainer/Q Targets Max              -1.09333
trainer/Q Targets Min             -95.1489
trainer/Log Pis Mean                1.99067
trainer/Log Pis Std                 1.22072
trainer/Log Pis Max                 8.12645
trainer/Log Pis Min                -1.22345
trainer/Policy mu Mean              0.0555404
trainer/Policy mu Std               0.44235
trainer/Policy mu Max               2.93834
trainer/Policy mu Min              -2.96229
trainer/Policy log std Mean        -2.30771
trainer/Policy log std Std          0.398027
trainer/Policy log std Max         -0.505436
trainer/Policy log std Min         -2.86856
trainer/Alpha                       0.0726503
trainer/Alpha Loss                 -0.0244711
exploration/num steps total    216700
exploration/num paths total      2167
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.412739
exploration/Rewards Std             0.840791
exploration/Rewards Max            -0.0038815
exploration/Rewards Min            -9.28547
exploration/Returns Mean          -41.2739
exploration/Returns Std            28.1745
exploration/Returns Max           -14.1086
exploration/Returns Min           -86.5855
exploration/Actions Mean            0.0187543
exploration/Actions Std             0.194082
exploration/Actions Max             0.999341
exploration/Actions Min            -0.850075
exploration/Num Paths               5
exploration/Average Returns       -41.2739
evaluation/num steps total     649500
evaluation/num paths total       6495
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.512477
evaluation/Rewards Std              1.15067
evaluation/Rewards Max             -0.0151597
evaluation/Rewards Min            -10.9413
evaluation/Returns Mean           -51.2477
evaluation/Returns Std             44.1994
evaluation/Returns Max             -8.46375
evaluation/Returns Min           -164.273
evaluation/Actions Mean             0.00763226
evaluation/Actions Std              0.198
evaluation/Actions Max              0.999158
evaluation/Actions Min             -0.999302
evaluation/Num Paths               15
evaluation/Average Returns        -51.2477
time/data storing (s)               0.00311341
time/evaluation sampling (s)        0.326967
time/exploration sampling (s)       0.137509
time/logging (s)                    0.00355702
time/saving (s)                     0.00198695
time/training (s)                   1.9671
time/epoch (s)                      2.44024
time/total (s)                   1054.36
Epoch                             432
-----------------------------  ---------------
2019-04-23 00:10:57.347120 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 433 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.737893
trainer/QF2 Loss                    0.770202
trainer/Policy Loss                32.6816
trainer/Q1 Predictions Mean       -30.7688
trainer/Q1 Predictions Std         30.2627
trainer/Q1 Predictions Max         -7.22306
trainer/Q1 Predictions Min        -95.357
trainer/Q2 Predictions Mean       -30.8332
trainer/Q2 Predictions Std         30.2386
trainer/Q2 Predictions Max         -7.20455
trainer/Q2 Predictions Min        -95.1359
trainer/Q Targets Mean            -30.8727
trainer/Q Targets Std              30.5195
trainer/Q Targets Max              -0.3259
trainer/Q Targets Min             -95.8185
trainer/Log Pis Mean                1.93891
trainer/Log Pis Std                 1.14737
trainer/Log Pis Max                 6.29257
trainer/Log Pis Min                -0.714802
trainer/Policy mu Mean              0.0192943
trainer/Policy mu Std               0.41708
trainer/Policy mu Max               3.13862
trainer/Policy mu Min              -2.2981
trainer/Policy log std Mean        -2.25888
trainer/Policy log std Std          0.404084
trainer/Policy log std Max         -0.730237
trainer/Policy log std Min         -2.74773
trainer/Alpha                       0.0734774
trainer/Alpha Loss                 -0.159493
exploration/num steps total    217200
exploration/num paths total      2172
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.716792
exploration/Rewards Std             0.987271
exploration/Rewards Max            -0.0124493
exploration/Rewards Min            -9.18049
exploration/Returns Mean          -71.6792
exploration/Returns Std            38.9964
exploration/Returns Max           -20.1585
exploration/Returns Min          -131.071
exploration/Actions Mean           -0.00510385
exploration/Actions Std             0.240358
exploration/Actions Max             0.99848
exploration/Actions Min            -0.999392
exploration/Num Paths               5
exploration/Average Returns       -71.6792
evaluation/num steps total     651000
evaluation/num paths total       6510
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.916074
evaluation/Rewards Std              0.95261
evaluation/Rewards Max             -0.0236804
evaluation/Rewards Min             -8.21902
evaluation/Returns Mean           -91.6074
evaluation/Returns Std             63.6515
evaluation/Returns Max            -10.5543
evaluation/Returns Min           -190.626
evaluation/Actions Mean             0.00924209
evaluation/Actions Std              0.179067
evaluation/Actions Max              0.997726
evaluation/Actions Min             -0.989711
evaluation/Num Paths               15
evaluation/Average Returns        -91.6074
time/data storing (s)               0.00277011
time/evaluation sampling (s)        0.331852
time/exploration sampling (s)       0.137294
time/logging (s)                    0.00478529
time/saving (s)                     0.00198038
time/training (s)                   1.95704
time/epoch (s)                      2.43572
time/total (s)                   1056.8
Epoch                             433
-----------------------------  ---------------
2019-04-23 00:10:59.809471 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 434 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.54818
trainer/QF2 Loss                    1.59864
trainer/Policy Loss                33.4519
trainer/Q1 Predictions Mean       -31.5845
trainer/Q1 Predictions Std         30.3686
trainer/Q1 Predictions Max         -7.16502
trainer/Q1 Predictions Min        -95.2748
trainer/Q2 Predictions Mean       -31.5929
trainer/Q2 Predictions Std         30.3324
trainer/Q2 Predictions Max         -7.08513
trainer/Q2 Predictions Min        -94.8143
trainer/Q Targets Mean            -31.708
trainer/Q Targets Std              30.8757
trainer/Q Targets Max              -0.0381586
trainer/Q Targets Min             -96.0661
trainer/Log Pis Mean                1.94279
trainer/Log Pis Std                 1.24548
trainer/Log Pis Max                 6.08581
trainer/Log Pis Min                -1.80273
trainer/Policy mu Mean              0.0881444
trainer/Policy mu Std               0.584814
trainer/Policy mu Max               3.10518
trainer/Policy mu Min              -2.95245
trainer/Policy log std Mean        -2.16829
trainer/Policy log std Std          0.453345
trainer/Policy log std Max         -0.534689
trainer/Policy log std Min         -2.72334
trainer/Alpha                       0.0746191
trainer/Alpha Loss                 -0.148469
exploration/num steps total    217700
exploration/num paths total      2177
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.29269
exploration/Rewards Std             1.31945
exploration/Rewards Max            -0.00562636
exploration/Rewards Min            -9.14953
exploration/Returns Mean         -129.269
exploration/Returns Std            60.9356
exploration/Returns Max           -41.387
exploration/Returns Min          -190.839
exploration/Actions Mean           -0.0336657
exploration/Actions Std             0.247994
exploration/Actions Max             0.998298
exploration/Actions Min            -0.999876
exploration/Num Paths               5
exploration/Average Returns      -129.269
evaluation/num steps total     652500
evaluation/num paths total       6525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.562833
evaluation/Rewards Std              1.01591
evaluation/Rewards Max             -0.00732862
evaluation/Rewards Min            -10.11
evaluation/Returns Mean           -56.2833
evaluation/Returns Std             49.783
evaluation/Returns Max            -17.131
evaluation/Returns Min           -174.499
evaluation/Actions Mean             0.00815677
evaluation/Actions Std              0.182009
evaluation/Actions Max              0.99845
evaluation/Actions Min             -0.999605
evaluation/Num Paths               15
evaluation/Average Returns        -56.2833
time/data storing (s)               0.00265906
time/evaluation sampling (s)        0.327618
time/exploration sampling (s)       0.136932
time/logging (s)                    0.00487336
time/saving (s)                     0.00198846
time/training (s)                   1.97867
time/epoch (s)                      2.45274
time/total (s)                   1059.26
Epoch                             434
-----------------------------  ---------------
2019-04-23 00:11:02.247848 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 435 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.04329
trainer/QF2 Loss                    0.157997
trainer/Policy Loss                32.8364
trainer/Q1 Predictions Mean       -30.8249
trainer/Q1 Predictions Std         33.9299
trainer/Q1 Predictions Max         -7.08488
trainer/Q1 Predictions Min        -96.4416
trainer/Q2 Predictions Mean       -30.7979
trainer/Q2 Predictions Std         33.9753
trainer/Q2 Predictions Max         -7.14511
trainer/Q2 Predictions Min        -96.3042
trainer/Q Targets Mean            -30.8045
trainer/Q Targets Std              33.8368
trainer/Q Targets Max              -7.09254
trainer/Q Targets Min             -96.2127
trainer/Log Pis Mean                2.06154
trainer/Log Pis Std                 1.11772
trainer/Log Pis Max                 6.00805
trainer/Log Pis Min                -0.9044
trainer/Policy mu Mean              0.00223964
trainer/Policy mu Std               0.512536
trainer/Policy mu Max               2.83629
trainer/Policy mu Min              -2.77846
trainer/Policy log std Mean        -2.27988
trainer/Policy log std Std          0.395855
trainer/Policy log std Max         -0.493898
trainer/Policy log std Min         -2.68541
trainer/Alpha                       0.0754941
trainer/Alpha Loss                  0.159008
exploration/num steps total    218200
exploration/num paths total      2182
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17985
exploration/Rewards Std             0.922991
exploration/Rewards Max            -0.0224073
exploration/Rewards Min            -7.40182
exploration/Returns Mean         -117.985
exploration/Returns Std            66.0789
exploration/Returns Max           -20.627
exploration/Returns Min          -181.744
exploration/Actions Mean           -0.00708525
exploration/Actions Std             0.213398
exploration/Actions Max             0.99691
exploration/Actions Min            -0.99896
exploration/Num Paths               5
exploration/Average Returns      -117.985
evaluation/num steps total     654000
evaluation/num paths total       6540
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.482785
evaluation/Rewards Std              1.03469
evaluation/Rewards Max             -0.0117121
evaluation/Rewards Min            -10.5462
evaluation/Returns Mean           -48.2785
evaluation/Returns Std             58.7387
evaluation/Returns Max             -4.47839
evaluation/Returns Min           -206.598
evaluation/Actions Mean             0.00612094
evaluation/Actions Std              0.186459
evaluation/Actions Max              0.998422
evaluation/Actions Min             -0.997384
evaluation/Num Paths               15
evaluation/Average Returns        -48.2785
time/data storing (s)               0.00261621
time/evaluation sampling (s)        0.32957
time/exploration sampling (s)       0.135402
time/logging (s)                    0.00476808
time/saving (s)                     0.00196651
time/training (s)                   1.95316
time/epoch (s)                      2.42748
time/total (s)                   1061.69
Epoch                             435
-----------------------------  ---------------
2019-04-23 00:11:04.700804 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 436 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.217119
trainer/QF2 Loss                    0.188753
trainer/Policy Loss                32.7421
trainer/Q1 Predictions Mean       -30.8042
trainer/Q1 Predictions Std         28.9943
trainer/Q1 Predictions Max         -7.15165
trainer/Q1 Predictions Min        -95.8107
trainer/Q2 Predictions Mean       -30.7719
trainer/Q2 Predictions Std         29.0012
trainer/Q2 Predictions Max         -7.02967
trainer/Q2 Predictions Min        -95.7242
trainer/Q Targets Mean            -31.0112
trainer/Q Targets Std              29.1262
trainer/Q Targets Max              -6.99329
trainer/Q Targets Min             -96.9819
trainer/Log Pis Mean                2.03633
trainer/Log Pis Std                 1.26107
trainer/Log Pis Max                 7.16882
trainer/Log Pis Min                -3.03785
trainer/Policy mu Mean              0.0345014
trainer/Policy mu Std               0.465598
trainer/Policy mu Max               3.16443
trainer/Policy mu Min              -3.7369
trainer/Policy log std Mean        -2.29766
trainer/Policy log std Std          0.394208
trainer/Policy log std Max         -0.416754
trainer/Policy log std Min         -2.81555
trainer/Alpha                       0.0745119
trainer/Alpha Loss                  0.0943337
exploration/num steps total    218700
exploration/num paths total      2187
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.78715
exploration/Rewards Std             1.07927
exploration/Rewards Max            -0.00515686
exploration/Rewards Min            -9.18526
exploration/Returns Mean          -78.715
exploration/Returns Std            37.9865
exploration/Returns Max           -27.4449
exploration/Returns Min          -130.027
exploration/Actions Mean            0.00890917
exploration/Actions Std             0.246221
exploration/Actions Max             0.999187
exploration/Actions Min            -0.998386
exploration/Num Paths               5
exploration/Average Returns       -78.715
evaluation/num steps total     655500
evaluation/num paths total       6555
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.735161
evaluation/Rewards Std              0.910537
evaluation/Rewards Max             -0.0384514
evaluation/Rewards Min             -9.82736
evaluation/Returns Mean           -73.5161
evaluation/Returns Std             52.6691
evaluation/Returns Max             -5.3403
evaluation/Returns Min           -160.977
evaluation/Actions Mean             0.00115081
evaluation/Actions Std              0.167753
evaluation/Actions Max              0.998234
evaluation/Actions Min             -0.999706
evaluation/Num Paths               15
evaluation/Average Returns        -73.5161
time/data storing (s)               0.00276095
time/evaluation sampling (s)        0.329239
time/exploration sampling (s)       0.141481
time/logging (s)                    0.0048403
time/saving (s)                     0.00199112
time/training (s)                   1.96191
time/epoch (s)                      2.44222
time/total (s)                   1064.14
Epoch                             436
-----------------------------  ---------------
2019-04-23 00:11:07.122596 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 437 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   23.7974
trainer/QF2 Loss                   23.7685
trainer/Policy Loss                30.4226
trainer/Q1 Predictions Mean       -28.3961
trainer/Q1 Predictions Std         31.6263
trainer/Q1 Predictions Max         -6.95665
trainer/Q1 Predictions Min        -97.9584
trainer/Q2 Predictions Mean       -28.3492
trainer/Q2 Predictions Std         31.5896
trainer/Q2 Predictions Max         -6.92259
trainer/Q2 Predictions Min        -97.1106
trainer/Q Targets Mean            -27.936
trainer/Q Targets Std              31.6543
trainer/Q Targets Max              -0.900218
trainer/Q Targets Min             -97.3721
trainer/Log Pis Mean                2.1204
trainer/Log Pis Std                 1.25233
trainer/Log Pis Max                 5.77664
trainer/Log Pis Min                -2.73025
trainer/Policy mu Mean              0.0282342
trainer/Policy mu Std               0.411403
trainer/Policy mu Max               2.56637
trainer/Policy mu Min              -1.88459
trainer/Policy log std Mean        -2.35451
trainer/Policy log std Std          0.400747
trainer/Policy log std Max         -0.654956
trainer/Policy log std Min         -3.00565
trainer/Alpha                       0.0759321
trainer/Alpha Loss                  0.310405
exploration/num steps total    219200
exploration/num paths total      2192
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.988199
exploration/Rewards Std             1.28565
exploration/Rewards Max            -0.0031791
exploration/Rewards Min            -9.41545
exploration/Returns Mean          -98.8199
exploration/Returns Std            85.1182
exploration/Returns Max           -13.2293
exploration/Returns Min          -220.035
exploration/Actions Mean           -0.00923222
exploration/Actions Std             0.208899
exploration/Actions Max             0.994535
exploration/Actions Min            -0.999271
exploration/Num Paths               5
exploration/Average Returns       -98.8199
evaluation/num steps total     657000
evaluation/num paths total       6570
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.710733
evaluation/Rewards Std              0.964108
evaluation/Rewards Max             -0.0293146
evaluation/Rewards Min             -9.50908
evaluation/Returns Mean           -71.0733
evaluation/Returns Std             55.3859
evaluation/Returns Max             -9.81679
evaluation/Returns Min           -183.889
evaluation/Actions Mean             0.00254333
evaluation/Actions Std              0.170646
evaluation/Actions Max              0.99675
evaluation/Actions Min             -0.999081
evaluation/Num Paths               15
evaluation/Average Returns        -71.0733
time/data storing (s)               0.00271095
time/evaluation sampling (s)        0.332683
time/exploration sampling (s)       0.142454
time/logging (s)                    0.00480922
time/saving (s)                     0.00200554
time/training (s)                   1.92623
time/epoch (s)                      2.41089
time/total (s)                   1066.56
Epoch                             437
-----------------------------  ---------------
2019-04-23 00:11:09.556030 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 438 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0825234
trainer/QF2 Loss                    0.0839386
trainer/Policy Loss                28.1675
trainer/Q1 Predictions Mean       -26.38
trainer/Q1 Predictions Std         28.4431
trainer/Q1 Predictions Max         -6.98966
trainer/Q1 Predictions Min        -98.1739
trainer/Q2 Predictions Mean       -26.35
trainer/Q2 Predictions Std         28.504
trainer/Q2 Predictions Max         -7.02903
trainer/Q2 Predictions Min        -98.6412
trainer/Q Targets Mean            -26.5525
trainer/Q Targets Std              28.6013
trainer/Q Targets Max              -6.91976
trainer/Q Targets Min             -98.5029
trainer/Log Pis Mean                1.80377
trainer/Log Pis Std                 1.14119
trainer/Log Pis Max                 3.98273
trainer/Log Pis Min                -2.5531
trainer/Policy mu Mean             -0.0365576
trainer/Policy mu Std               0.313184
trainer/Policy mu Max               2.65211
trainer/Policy mu Min              -2.37018
trainer/Policy log std Mean        -2.29462
trainer/Policy log std Std          0.337904
trainer/Policy log std Max         -0.757675
trainer/Policy log std Min         -2.88373
trainer/Alpha                       0.0758494
trainer/Alpha Loss                 -0.506065
exploration/num steps total    219700
exploration/num paths total      2197
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.361283
exploration/Rewards Std             1.08403
exploration/Rewards Max            -0.00284088
exploration/Rewards Min            -9.13945
exploration/Returns Mean          -36.1283
exploration/Returns Std            13.519
exploration/Returns Max           -14.5488
exploration/Returns Min           -54.0198
exploration/Actions Mean            0.0231245
exploration/Actions Std             0.230582
exploration/Actions Max             0.998856
exploration/Actions Min            -0.999701
exploration/Num Paths               5
exploration/Average Returns       -36.1283
evaluation/num steps total     658500
evaluation/num paths total       6585
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.5843
evaluation/Rewards Std              0.9633
evaluation/Rewards Max             -0.0127984
evaluation/Rewards Min             -8.62429
evaluation/Returns Mean           -58.43
evaluation/Returns Std             52.4874
evaluation/Returns Max             -3.55347
evaluation/Returns Min           -183.426
evaluation/Actions Mean             0.0148178
evaluation/Actions Std              0.173972
evaluation/Actions Max              0.997175
evaluation/Actions Min             -0.997291
evaluation/Num Paths               15
evaluation/Average Returns        -58.43
time/data storing (s)               0.00283392
time/evaluation sampling (s)        0.328202
time/exploration sampling (s)       0.141405
time/logging (s)                    0.00532038
time/saving (s)                     0.00199754
time/training (s)                   1.94337
time/epoch (s)                      2.42313
time/total (s)                   1068.98
Epoch                             438
-----------------------------  ---------------
2019-04-23 00:11:11.999975 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 439 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.730481
trainer/QF2 Loss                    0.693053
trainer/Policy Loss                31.3146
trainer/Q1 Predictions Mean       -29.4107
trainer/Q1 Predictions Std         31.5589
trainer/Q1 Predictions Max         -6.79376
trainer/Q1 Predictions Min        -97.23
trainer/Q2 Predictions Mean       -29.3976
trainer/Q2 Predictions Std         31.5529
trainer/Q2 Predictions Max         -6.89812
trainer/Q2 Predictions Min        -96.4923
trainer/Q Targets Mean            -29.6188
trainer/Q Targets Std              31.8188
trainer/Q Targets Max              -0.0895763
trainer/Q Targets Min             -97.0153
trainer/Log Pis Mean                1.92646
trainer/Log Pis Std                 1.41315
trainer/Log Pis Max                 6.46746
trainer/Log Pis Min                -4.50926
trainer/Policy mu Mean              0.0092239
trainer/Policy mu Std               0.449751
trainer/Policy mu Max               2.85296
trainer/Policy mu Min              -2.57336
trainer/Policy log std Mean        -2.27233
trainer/Policy log std Std          0.386597
trainer/Policy log std Max         -0.565796
trainer/Policy log std Min         -2.78181
trainer/Alpha                       0.079772
trainer/Alpha Loss                 -0.185937
exploration/num steps total    220200
exploration/num paths total      2202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.503259
exploration/Rewards Std             1.02349
exploration/Rewards Max            -0.00239912
exploration/Rewards Min            -8.65221
exploration/Returns Mean          -50.3259
exploration/Returns Std            37.1876
exploration/Returns Max           -10.5763
exploration/Returns Min          -118.317
exploration/Actions Mean           -3.513e-05
exploration/Actions Std             0.223134
exploration/Actions Max             0.998194
exploration/Actions Min            -0.997863
exploration/Num Paths               5
exploration/Average Returns       -50.3259
evaluation/num steps total     660000
evaluation/num paths total       6600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.628525
evaluation/Rewards Std              1.20355
evaluation/Rewards Max             -0.00591552
evaluation/Rewards Min            -10.6196
evaluation/Returns Mean           -62.8525
evaluation/Returns Std             52.7036
evaluation/Returns Max            -15.7992
evaluation/Returns Min           -227.548
evaluation/Actions Mean            -0.000955737
evaluation/Actions Std              0.195151
evaluation/Actions Max              0.997018
evaluation/Actions Min             -0.999387
evaluation/Num Paths               15
evaluation/Average Returns        -62.8525
time/data storing (s)               0.00281242
time/evaluation sampling (s)        0.328441
time/exploration sampling (s)       0.141932
time/logging (s)                    0.00480318
time/saving (s)                     0.0063402
time/training (s)                   1.9482
time/epoch (s)                      2.43253
time/total (s)                   1071.42
Epoch                             439
-----------------------------  ----------------
2019-04-23 00:11:14.429394 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 440 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.441872
trainer/QF2 Loss                    0.473251
trainer/Policy Loss                32.9216
trainer/Q1 Predictions Mean       -30.7374
trainer/Q1 Predictions Std         31.9648
trainer/Q1 Predictions Max         -7.01796
trainer/Q1 Predictions Min        -95.7423
trainer/Q2 Predictions Mean       -30.7498
trainer/Q2 Predictions Std         31.9626
trainer/Q2 Predictions Max         -6.97402
trainer/Q2 Predictions Min        -95.0626
trainer/Q Targets Mean            -31.1584
trainer/Q Targets Std              32.3945
trainer/Q Targets Max              -7.01419
trainer/Q Targets Min             -96.3577
trainer/Log Pis Mean                2.26024
trainer/Log Pis Std                 1.45633
trainer/Log Pis Max                 9.46504
trainer/Log Pis Min                -3.48557
trainer/Policy mu Mean              0.0403169
trainer/Policy mu Std               0.492413
trainer/Policy mu Max               3.35095
trainer/Policy mu Min              -3.03592
trainer/Policy log std Mean        -2.35317
trainer/Policy log std Std          0.377334
trainer/Policy log std Max         -0.430504
trainer/Policy log std Min         -2.90874
trainer/Alpha                       0.079307
trainer/Alpha Loss                  0.659613
exploration/num steps total    220700
exploration/num paths total      2207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.565249
exploration/Rewards Std             1.05646
exploration/Rewards Max            -0.00160137
exploration/Rewards Min            -8.23164
exploration/Returns Mean          -56.5249
exploration/Returns Std            41.044
exploration/Returns Max           -21.52
exploration/Returns Min          -136.459
exploration/Actions Mean           -0.00827343
exploration/Actions Std             0.221395
exploration/Actions Max             0.989793
exploration/Actions Min            -0.998313
exploration/Num Paths               5
exploration/Average Returns       -56.5249
evaluation/num steps total     661500
evaluation/num paths total       6615
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.446647
evaluation/Rewards Std              1.07081
evaluation/Rewards Max             -0.0279757
evaluation/Rewards Min            -11.2665
evaluation/Returns Mean           -44.6647
evaluation/Returns Std             34.9962
evaluation/Returns Max             -7.415
evaluation/Returns Min           -150.763
evaluation/Actions Mean            -0.00122591
evaluation/Actions Std              0.183905
evaluation/Actions Max              0.998085
evaluation/Actions Min             -0.99987
evaluation/Num Paths               15
evaluation/Average Returns        -44.6647
time/data storing (s)               0.00260566
time/evaluation sampling (s)        0.329927
time/exploration sampling (s)       0.135134
time/logging (s)                    0.00475667
time/saving (s)                     0.00198463
time/training (s)                   1.9451
time/epoch (s)                      2.41951
time/total (s)                   1073.84
Epoch                             440
-----------------------------  ---------------
2019-04-23 00:11:16.878581 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 441 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   46.1578
trainer/QF2 Loss                   45.7339
trainer/Policy Loss                28.0326
trainer/Q1 Predictions Mean       -26.0649
trainer/Q1 Predictions Std         28.6267
trainer/Q1 Predictions Max         -7.02852
trainer/Q1 Predictions Min        -95.1097
trainer/Q2 Predictions Mean       -26.0721
trainer/Q2 Predictions Std         28.6128
trainer/Q2 Predictions Max         -7.04672
trainer/Q2 Predictions Min        -94.8085
trainer/Q Targets Mean            -25.5795
trainer/Q Targets Std              28.4657
trainer/Q Targets Max              -1.50586
trainer/Q Targets Min             -95.8318
trainer/Log Pis Mean                2.01816
trainer/Log Pis Std                 1.51889
trainer/Log Pis Max                 9.46993
trainer/Log Pis Min                -1.91599
trainer/Policy mu Mean             -0.00370791
trainer/Policy mu Std               0.601227
trainer/Policy mu Max               2.91002
trainer/Policy mu Min              -3.24105
trainer/Policy log std Mean        -2.18645
trainer/Policy log std Std          0.453099
trainer/Policy log std Max         -0.320744
trainer/Policy log std Min         -2.70669
trainer/Alpha                       0.0773593
trainer/Alpha Loss                  0.0464638
exploration/num steps total    221200
exploration/num paths total      2212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.474702
exploration/Rewards Std             1.39512
exploration/Rewards Max            -0.0143532
exploration/Rewards Min           -11.8344
exploration/Returns Mean          -47.4702
exploration/Returns Std            17.158
exploration/Returns Max           -25.074
exploration/Returns Min           -67.7367
exploration/Actions Mean           -0.0193754
exploration/Actions Std             0.250718
exploration/Actions Max             0.998516
exploration/Actions Min            -0.999968
exploration/Num Paths               5
exploration/Average Returns       -47.4702
evaluation/num steps total     663000
evaluation/num paths total       6630
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.535485
evaluation/Rewards Std              1.21659
evaluation/Rewards Max             -0.0206147
evaluation/Rewards Min            -10.8591
evaluation/Returns Mean           -53.5485
evaluation/Returns Std             42.7556
evaluation/Returns Max            -10.3859
evaluation/Returns Min           -164.661
evaluation/Actions Mean            -0.00135428
evaluation/Actions Std              0.205282
evaluation/Actions Max              0.998891
evaluation/Actions Min             -0.999305
evaluation/Num Paths               15
evaluation/Average Returns        -53.5485
time/data storing (s)               0.00273218
time/evaluation sampling (s)        0.332477
time/exploration sampling (s)       0.140495
time/logging (s)                    0.00478285
time/saving (s)                     0.0019842
time/training (s)                   1.95706
time/epoch (s)                      2.43953
time/total (s)                   1076.29
Epoch                             441
-----------------------------  ---------------
2019-04-23 00:11:19.315826 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 442 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.1709
trainer/QF2 Loss                    1.15761
trainer/Policy Loss                29.3977
trainer/Q1 Predictions Mean       -27.4584
trainer/Q1 Predictions Std         31.5587
trainer/Q1 Predictions Max         -7.08968
trainer/Q1 Predictions Min       -108.338
trainer/Q2 Predictions Mean       -27.4573
trainer/Q2 Predictions Std         31.5497
trainer/Q2 Predictions Max         -7.0787
trainer/Q2 Predictions Min       -106.655
trainer/Q Targets Mean            -27.4536
trainer/Q Targets Std              31.7465
trainer/Q Targets Max              -0.409558
trainer/Q Targets Min            -107.484
trainer/Log Pis Mean                1.96553
trainer/Log Pis Std                 1.37678
trainer/Log Pis Max                 6.45642
trainer/Log Pis Min                -5.0091
trainer/Policy mu Mean              0.0126616
trainer/Policy mu Std               0.387906
trainer/Policy mu Max               3.5002
trainer/Policy mu Min              -2.09649
trainer/Policy log std Mean        -2.30376
trainer/Policy log std Std          0.36543
trainer/Policy log std Max         -0.334166
trainer/Policy log std Min         -2.96145
trainer/Alpha                       0.0744323
trainer/Alpha Loss                 -0.0895409
exploration/num steps total    221700
exploration/num paths total      2217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.545714
exploration/Rewards Std             0.85218
exploration/Rewards Max            -0.0107194
exploration/Rewards Min            -5.84856
exploration/Returns Mean          -54.5714
exploration/Returns Std            63.9518
exploration/Returns Max           -12.9314
exploration/Returns Min          -181.452
exploration/Actions Mean           -0.0129339
exploration/Actions Std             0.18098
exploration/Actions Max             0.996206
exploration/Actions Min            -0.998984
exploration/Num Paths               5
exploration/Average Returns       -54.5714
evaluation/num steps total     664500
evaluation/num paths total       6645
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.793535
evaluation/Rewards Std              1.16711
evaluation/Rewards Max             -0.0241615
evaluation/Rewards Min             -9.88091
evaluation/Returns Mean           -79.3535
evaluation/Returns Std             60.2489
evaluation/Returns Max             -5.61475
evaluation/Returns Min           -179.868
evaluation/Actions Mean             0.0102236
evaluation/Actions Std              0.18559
evaluation/Actions Max              0.998831
evaluation/Actions Min             -0.998532
evaluation/Num Paths               15
evaluation/Average Returns        -79.3535
time/data storing (s)               0.00275385
time/evaluation sampling (s)        0.330673
time/exploration sampling (s)       0.139356
time/logging (s)                    0.00480849
time/saving (s)                     0.00198434
time/training (s)                   1.94684
time/epoch (s)                      2.42642
time/total (s)                   1078.72
Epoch                             442
-----------------------------  ---------------
2019-04-23 00:11:21.749794 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 443 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.67212
trainer/QF2 Loss                    1.66275
trainer/Policy Loss                32.103
trainer/Q1 Predictions Mean       -30.1558
trainer/Q1 Predictions Std         31.5245
trainer/Q1 Predictions Max         -6.94395
trainer/Q1 Predictions Min        -95.2297
trainer/Q2 Predictions Mean       -30.1318
trainer/Q2 Predictions Std         31.5294
trainer/Q2 Predictions Max         -6.90852
trainer/Q2 Predictions Min        -95.0248
trainer/Q Targets Mean            -30.4414
trainer/Q Targets Std              32.0907
trainer/Q Targets Max              -0.0742299
trainer/Q Targets Min             -96.7152
trainer/Log Pis Mean                1.99198
trainer/Log Pis Std                 1.17784
trainer/Log Pis Max                 8.16919
trainer/Log Pis Min                -2.72996
trainer/Policy mu Mean             -0.0335245
trainer/Policy mu Std               0.381227
trainer/Policy mu Max               2.48508
trainer/Policy mu Min              -2.91709
trainer/Policy log std Mean        -2.33549
trainer/Policy log std Std          0.382614
trainer/Policy log std Max         -0.393095
trainer/Policy log std Min         -2.92971
trainer/Alpha                       0.0800861
trainer/Alpha Loss                 -0.0202526
exploration/num steps total    222200
exploration/num paths total      2222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.677258
exploration/Rewards Std             0.97507
exploration/Rewards Max            -0.00739267
exploration/Rewards Min            -8.69977
exploration/Returns Mean          -67.7258
exploration/Returns Std            63.8668
exploration/Returns Max           -26.4349
exploration/Returns Min          -193.156
exploration/Actions Mean            0.0194379
exploration/Actions Std             0.223816
exploration/Actions Max             0.999878
exploration/Actions Min            -0.98535
exploration/Num Paths               5
exploration/Average Returns       -67.7258
evaluation/num steps total     666000
evaluation/num paths total       6660
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.754564
evaluation/Rewards Std              1.10997
evaluation/Rewards Max             -0.0584497
evaluation/Rewards Min            -11.0324
evaluation/Returns Mean           -75.4564
evaluation/Returns Std             59.4773
evaluation/Returns Max            -11.5703
evaluation/Returns Min           -191.597
evaluation/Actions Mean            -0.00365425
evaluation/Actions Std              0.190855
evaluation/Actions Max              0.999334
evaluation/Actions Min             -0.999061
evaluation/Num Paths               15
evaluation/Average Returns        -75.4564
time/data storing (s)               0.00280517
time/evaluation sampling (s)        0.325575
time/exploration sampling (s)       0.142743
time/logging (s)                    0.00483661
time/saving (s)                     0.00163103
time/training (s)                   1.94545
time/epoch (s)                      2.42304
time/total (s)                   1081.14
Epoch                             443
-----------------------------  ---------------
2019-04-23 00:11:24.190866 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 444 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.549887
trainer/QF2 Loss                    0.541719
trainer/Policy Loss                28.0184
trainer/Q1 Predictions Mean       -26.0813
trainer/Q1 Predictions Std         30.2743
trainer/Q1 Predictions Max         -6.88776
trainer/Q1 Predictions Min        -94.8526
trainer/Q2 Predictions Mean       -26.0891
trainer/Q2 Predictions Std         30.2759
trainer/Q2 Predictions Max         -6.91649
trainer/Q2 Predictions Min        -94.8405
trainer/Q Targets Mean            -26.5006
trainer/Q Targets Std              30.8406
trainer/Q Targets Max              -7.06046
trainer/Q Targets Min             -96.5972
trainer/Log Pis Mean                2.0069
trainer/Log Pis Std                 1.21676
trainer/Log Pis Max                 7.69053
trainer/Log Pis Min                -0.871773
trainer/Policy mu Mean             -0.045668
trainer/Policy mu Std               0.436603
trainer/Policy mu Max               1.85837
trainer/Policy mu Min              -3.94138
trainer/Policy log std Mean        -2.33788
trainer/Policy log std Std          0.360706
trainer/Policy log std Max         -0.228558
trainer/Policy log std Min         -2.7981
trainer/Alpha                       0.079161
trainer/Alpha Loss                  0.0175089
exploration/num steps total    222700
exploration/num paths total      2227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.578001
exploration/Rewards Std             0.930267
exploration/Rewards Max            -0.00254853
exploration/Rewards Min            -8.20287
exploration/Returns Mean          -57.8001
exploration/Returns Std            55.2227
exploration/Returns Max           -20.0672
exploration/Returns Min          -166.708
exploration/Actions Mean            0.00412762
exploration/Actions Std             0.209725
exploration/Actions Max             0.995027
exploration/Actions Min            -0.99971
exploration/Num Paths               5
exploration/Average Returns       -57.8001
evaluation/num steps total     667500
evaluation/num paths total       6675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.541609
evaluation/Rewards Std              1.04965
evaluation/Rewards Max             -0.00757291
evaluation/Rewards Min             -9.83641
evaluation/Returns Mean           -54.1609
evaluation/Returns Std             37.6272
evaluation/Returns Max             -7.50637
evaluation/Returns Min           -127.1
evaluation/Actions Mean             0.0101432
evaluation/Actions Std              0.18388
evaluation/Actions Max              0.998343
evaluation/Actions Min             -0.999088
evaluation/Num Paths               15
evaluation/Average Returns        -54.1609
time/data storing (s)               0.00275036
time/evaluation sampling (s)        0.327787
time/exploration sampling (s)       0.139952
time/logging (s)                    0.00480782
time/saving (s)                     0.00197861
time/training (s)                   1.95288
time/epoch (s)                      2.43016
time/total (s)                   1083.58
Epoch                             444
-----------------------------  ---------------
2019-04-23 00:11:26.651480 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 445 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   21.3208
trainer/QF2 Loss                   21.4395
trainer/Policy Loss                31.6588
trainer/Q1 Predictions Mean       -29.5608
trainer/Q1 Predictions Std         32.3709
trainer/Q1 Predictions Max         -6.72383
trainer/Q1 Predictions Min       -105.401
trainer/Q2 Predictions Mean       -29.5483
trainer/Q2 Predictions Std         32.3601
trainer/Q2 Predictions Max         -6.79173
trainer/Q2 Predictions Min       -105.089
trainer/Q Targets Mean            -29.1193
trainer/Q Targets Std              32.4847
trainer/Q Targets Max              -0.871453
trainer/Q Targets Min            -105.476
trainer/Log Pis Mean                2.13612
trainer/Log Pis Std                 1.06242
trainer/Log Pis Max                 4.39306
trainer/Log Pis Min                -2.07684
trainer/Policy mu Mean              0.0053511
trainer/Policy mu Std               0.448666
trainer/Policy mu Max               2.72978
trainer/Policy mu Min              -2.62974
trainer/Policy log std Mean        -2.30477
trainer/Policy log std Std          0.40465
trainer/Policy log std Max         -0.565292
trainer/Policy log std Min         -2.9294
trainer/Alpha                       0.0805315
trainer/Alpha Loss                  0.342923
exploration/num steps total    223200
exploration/num paths total      2232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.32571
exploration/Rewards Std             1.36597
exploration/Rewards Max            -0.00460469
exploration/Rewards Min            -9.04166
exploration/Returns Mean         -132.571
exploration/Returns Std            68.6439
exploration/Returns Max           -43.4377
exploration/Returns Min          -197.658
exploration/Actions Mean           -0.00457714
exploration/Actions Std             0.228699
exploration/Actions Max             0.998216
exploration/Actions Min            -0.999356
exploration/Num Paths               5
exploration/Average Returns      -132.571
evaluation/num steps total     669000
evaluation/num paths total       6690
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.643234
evaluation/Rewards Std              1.19735
evaluation/Rewards Max             -0.0205846
evaluation/Rewards Min            -11.084
evaluation/Returns Mean           -64.3234
evaluation/Returns Std             50.3454
evaluation/Returns Max            -10.5036
evaluation/Returns Min           -190.582
evaluation/Actions Mean             0.00933766
evaluation/Actions Std              0.197797
evaluation/Actions Max              0.999165
evaluation/Actions Min             -0.999066
evaluation/Num Paths               15
evaluation/Average Returns        -64.3234
time/data storing (s)               0.00276827
time/evaluation sampling (s)        0.326835
time/exploration sampling (s)       0.140632
time/logging (s)                    0.00483269
time/saving (s)                     0.00166027
time/training (s)                   1.97298
time/epoch (s)                      2.4497
time/total (s)                   1086.03
Epoch                             445
-----------------------------  ---------------
2019-04-23 00:11:29.086686 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 446 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   83.259
trainer/QF2 Loss                   83.6455
trainer/Policy Loss                26.444
trainer/Q1 Predictions Mean       -24.4171
trainer/Q1 Predictions Std         28.6582
trainer/Q1 Predictions Max         -6.75848
trainer/Q1 Predictions Min        -94.2688
trainer/Q2 Predictions Mean       -24.4023
trainer/Q2 Predictions Std         28.6735
trainer/Q2 Predictions Max         -6.83293
trainer/Q2 Predictions Min        -94.1582
trainer/Q Targets Mean            -24.0628
trainer/Q Targets Std              28.5396
trainer/Q Targets Max              -2.3444
trainer/Q Targets Min             -96.4944
trainer/Log Pis Mean                2.06216
trainer/Log Pis Std                 1.13818
trainer/Log Pis Max                 5.67206
trainer/Log Pis Min                -2.41183
trainer/Policy mu Mean              0.0349842
trainer/Policy mu Std               0.59622
trainer/Policy mu Max               3.21413
trainer/Policy mu Min              -3.22093
trainer/Policy log std Mean        -2.19061
trainer/Policy log std Std          0.449372
trainer/Policy log std Max         -0.314565
trainer/Policy log std Min         -2.8731
trainer/Alpha                       0.0804932
trainer/Alpha Loss                  0.156622
exploration/num steps total    223700
exploration/num paths total      2237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.537836
exploration/Rewards Std             1.20168
exploration/Rewards Max            -0.0155656
exploration/Rewards Min           -10.9567
exploration/Returns Mean          -53.7836
exploration/Returns Std            43.4258
exploration/Returns Max           -16.223
exploration/Returns Min          -131.191
exploration/Actions Mean           -0.0204363
exploration/Actions Std             0.242396
exploration/Actions Max             0.998828
exploration/Actions Min            -0.99965
exploration/Num Paths               5
exploration/Average Returns       -53.7836
evaluation/num steps total     670500
evaluation/num paths total       6705
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.809223
evaluation/Rewards Std              1.06976
evaluation/Rewards Max             -0.0365804
evaluation/Rewards Min             -9.96031
evaluation/Returns Mean           -80.9223
evaluation/Returns Std             53.7843
evaluation/Returns Max            -13.9406
evaluation/Returns Min           -173.732
evaluation/Actions Mean             0.0150555
evaluation/Actions Std              0.190134
evaluation/Actions Max              0.997086
evaluation/Actions Min             -0.994554
evaluation/Num Paths               15
evaluation/Average Returns        -80.9223
time/data storing (s)               0.00271786
time/evaluation sampling (s)        0.322801
time/exploration sampling (s)       0.142251
time/logging (s)                    0.00482272
time/saving (s)                     0.00207122
time/training (s)                   1.94925
time/epoch (s)                      2.42391
time/total (s)                   1088.46
Epoch                             446
-----------------------------  ---------------
2019-04-23 00:11:31.538788 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 447 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.37256
trainer/QF2 Loss                    2.36317
trainer/Policy Loss                27.4667
trainer/Q1 Predictions Mean       -25.5771
trainer/Q1 Predictions Std         26.1376
trainer/Q1 Predictions Max         -6.75322
trainer/Q1 Predictions Min        -93.7256
trainer/Q2 Predictions Mean       -25.6194
trainer/Q2 Predictions Std         26.1688
trainer/Q2 Predictions Max         -6.80599
trainer/Q2 Predictions Min        -93.5891
trainer/Q Targets Mean            -25.8267
trainer/Q Targets Std              26.8523
trainer/Q Targets Max              -0.0861988
trainer/Q Targets Min             -95.2908
trainer/Log Pis Mean                1.85877
trainer/Log Pis Std                 1.40427
trainer/Log Pis Max                 7.19035
trainer/Log Pis Min                -3.51194
trainer/Policy mu Mean              0.00428685
trainer/Policy mu Std               0.595233
trainer/Policy mu Max               2.89915
trainer/Policy mu Min              -2.77776
trainer/Policy log std Mean        -2.18414
trainer/Policy log std Std          0.484975
trainer/Policy log std Max         -0.430346
trainer/Policy log std Min         -2.82713
trainer/Alpha                       0.0791137
trainer/Alpha Loss                 -0.358271
exploration/num steps total    224200
exploration/num paths total      2242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.00804
exploration/Rewards Std             0.811912
exploration/Rewards Max            -0.00851987
exploration/Rewards Min            -6.25729
exploration/Returns Mean         -100.804
exploration/Returns Std            61.0012
exploration/Returns Max           -32.1278
exploration/Returns Min          -175.525
exploration/Actions Mean            0.000478894
exploration/Actions Std             0.204732
exploration/Actions Max             0.991547
exploration/Actions Min            -0.996748
exploration/Num Paths               5
exploration/Average Returns      -100.804
evaluation/num steps total     672000
evaluation/num paths total       6720
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.484095
evaluation/Rewards Std              0.999832
evaluation/Rewards Max             -0.0181977
evaluation/Rewards Min             -9.0544
evaluation/Returns Mean           -48.4095
evaluation/Returns Std             43.3769
evaluation/Returns Max             -5.34055
evaluation/Returns Min           -172.026
evaluation/Actions Mean             0.00680789
evaluation/Actions Std              0.181566
evaluation/Actions Max              0.997593
evaluation/Actions Min             -0.998905
evaluation/Num Paths               15
evaluation/Average Returns        -48.4095
time/data storing (s)               0.00281737
time/evaluation sampling (s)        0.331519
time/exploration sampling (s)       0.139545
time/logging (s)                    0.00498428
time/saving (s)                     0.00198912
time/training (s)                   1.96023
time/epoch (s)                      2.44109
time/total (s)                   1090.91
Epoch                             447
-----------------------------  ----------------
2019-04-23 00:11:33.975340 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 448 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.4473
trainer/QF2 Loss                    1.4752
trainer/Policy Loss                29.9579
trainer/Q1 Predictions Mean       -27.9173
trainer/Q1 Predictions Std         29.7749
trainer/Q1 Predictions Max         -6.84653
trainer/Q1 Predictions Min        -92.6658
trainer/Q2 Predictions Mean       -27.9542
trainer/Q2 Predictions Std         29.7431
trainer/Q2 Predictions Max         -6.9119
trainer/Q2 Predictions Min        -92.5143
trainer/Q Targets Mean            -28.106
trainer/Q Targets Std              30.3027
trainer/Q Targets Max              -0.0428016
trainer/Q Targets Min             -95.0451
trainer/Log Pis Mean                2.08236
trainer/Log Pis Std                 1.02067
trainer/Log Pis Max                 4.93891
trainer/Log Pis Min                -1.7677
trainer/Policy mu Mean              0.0382389
trainer/Policy mu Std               0.23649
trainer/Policy mu Max               1.7684
trainer/Policy mu Min              -0.430773
trainer/Policy log std Mean        -2.35693
trainer/Policy log std Std          0.318279
trainer/Policy log std Max         -0.875438
trainer/Policy log std Min         -3.00929
trainer/Alpha                       0.0801496
trainer/Alpha Loss                  0.20788
exploration/num steps total    224700
exploration/num paths total      2247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.907693
exploration/Rewards Std             1.21473
exploration/Rewards Max            -0.0118919
exploration/Rewards Min            -8.31611
exploration/Returns Mean          -90.7693
exploration/Returns Std            72.1234
exploration/Returns Max           -19.4591
exploration/Returns Min          -206.883
exploration/Actions Mean           -0.0134879
exploration/Actions Std             0.211975
exploration/Actions Max             0.999838
exploration/Actions Min            -0.998803
exploration/Num Paths               5
exploration/Average Returns       -90.7693
evaluation/num steps total     673500
evaluation/num paths total       6735
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.481484
evaluation/Rewards Std              1.09811
evaluation/Rewards Max             -0.016568
evaluation/Rewards Min            -10.208
evaluation/Returns Mean           -48.1484
evaluation/Returns Std             51.7572
evaluation/Returns Max             -7.19691
evaluation/Returns Min           -207.864
evaluation/Actions Mean            -0.00880738
evaluation/Actions Std              0.183568
evaluation/Actions Max              0.999097
evaluation/Actions Min             -0.996711
evaluation/Num Paths               15
evaluation/Average Returns        -48.1484
time/data storing (s)               0.00280416
time/evaluation sampling (s)        0.329369
time/exploration sampling (s)       0.136906
time/logging (s)                    0.00481623
time/saving (s)                     0.00199935
time/training (s)                   1.94975
time/epoch (s)                      2.42565
time/total (s)                   1093.34
Epoch                             448
-----------------------------  ---------------
2019-04-23 00:11:36.426777 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 449 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   45.0919
trainer/QF2 Loss                   45.2942
trainer/Policy Loss                29.902
trainer/Q1 Predictions Mean       -27.9384
trainer/Q1 Predictions Std         30.616
trainer/Q1 Predictions Max         -6.82631
trainer/Q1 Predictions Min       -105.837
trainer/Q2 Predictions Mean       -27.877
trainer/Q2 Predictions Std         30.5564
trainer/Q2 Predictions Max         -6.82766
trainer/Q2 Predictions Min       -103.294
trainer/Q Targets Mean            -27.4801
trainer/Q Targets Std              30.8037
trainer/Q Targets Max              -0.102245
trainer/Q Targets Min            -106.02
trainer/Log Pis Mean                2.05838
trainer/Log Pis Std                 1.45986
trainer/Log Pis Max                 8.21933
trainer/Log Pis Min                -2.08055
trainer/Policy mu Mean             -0.00721858
trainer/Policy mu Std               0.549408
trainer/Policy mu Max               3.44883
trainer/Policy mu Min              -3.37993
trainer/Policy log std Mean        -2.2564
trainer/Policy log std Std          0.450796
trainer/Policy log std Max         -0.367159
trainer/Policy log std Min         -2.94146
trainer/Alpha                       0.0824203
trainer/Alpha Loss                  0.14572
exploration/num steps total    225200
exploration/num paths total      2252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.835852
exploration/Rewards Std             0.830696
exploration/Rewards Max            -0.00548217
exploration/Rewards Min            -6.58438
exploration/Returns Mean          -83.5852
exploration/Returns Std            65.8593
exploration/Returns Max           -14.6854
exploration/Returns Min          -162.972
exploration/Actions Mean           -0.0217843
exploration/Actions Std             0.191164
exploration/Actions Max             0.967741
exploration/Actions Min            -0.993082
exploration/Num Paths               5
exploration/Average Returns       -83.5852
evaluation/num steps total     675000
evaluation/num paths total       6750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.544338
evaluation/Rewards Std              1.17294
evaluation/Rewards Max             -0.00861314
evaluation/Rewards Min            -10.8158
evaluation/Returns Mean           -54.4338
evaluation/Returns Std             41.9439
evaluation/Returns Max            -10.8421
evaluation/Returns Min           -168.505
evaluation/Actions Mean             0.0304829
evaluation/Actions Std              0.200043
evaluation/Actions Max              0.999511
evaluation/Actions Min             -0.998564
evaluation/Num Paths               15
evaluation/Average Returns        -54.4338
time/data storing (s)               0.00261512
time/evaluation sampling (s)        0.327585
time/exploration sampling (s)       0.136715
time/logging (s)                    0.00350703
time/saving (s)                     0.00200096
time/training (s)                   1.96666
time/epoch (s)                      2.43908
time/total (s)                   1095.78
Epoch                             449
-----------------------------  ---------------
2019-04-23 00:11:38.858303 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 450 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.246081
trainer/QF2 Loss                    0.2153
trainer/Policy Loss                27.4866
trainer/Q1 Predictions Mean       -25.6285
trainer/Q1 Predictions Std         28.6444
trainer/Q1 Predictions Max         -6.71329
trainer/Q1 Predictions Min        -98.3258
trainer/Q2 Predictions Mean       -25.6238
trainer/Q2 Predictions Std         28.6408
trainer/Q2 Predictions Max         -6.78032
trainer/Q2 Predictions Min        -99.1728
trainer/Q Targets Mean            -25.9003
trainer/Q Targets Std              28.7505
trainer/Q Targets Max              -6.867
trainer/Q Targets Min             -98.7457
trainer/Log Pis Mean                1.89843
trainer/Log Pis Std                 1.50547
trainer/Log Pis Max                 7.77004
trainer/Log Pis Min                -2.57004
trainer/Policy mu Mean             -0.0376835
trainer/Policy mu Std               0.504244
trainer/Policy mu Max               2.70591
trainer/Policy mu Min              -3.02132
trainer/Policy log std Mean        -2.22781
trainer/Policy log std Std          0.420877
trainer/Policy log std Max         -0.582055
trainer/Policy log std Min         -2.79853
trainer/Alpha                       0.0801376
trainer/Alpha Loss                 -0.25635
exploration/num steps total    225700
exploration/num paths total      2257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.515939
exploration/Rewards Std             0.761445
exploration/Rewards Max            -0.00365952
exploration/Rewards Min            -6.69881
exploration/Returns Mean          -51.5939
exploration/Returns Std            57.1484
exploration/Returns Max           -19.563
exploration/Returns Min          -165.81
exploration/Actions Mean            0.00285331
exploration/Actions Std             0.195383
exploration/Actions Max             0.991083
exploration/Actions Min            -0.99919
exploration/Num Paths               5
exploration/Average Returns       -51.5939
evaluation/num steps total     676500
evaluation/num paths total       6765
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.562748
evaluation/Rewards Std              0.800233
evaluation/Rewards Max             -0.0281444
evaluation/Rewards Min             -9.01499
evaluation/Returns Mean           -56.2748
evaluation/Returns Std             52.8847
evaluation/Returns Max             -7.57104
evaluation/Returns Min           -163.177
evaluation/Actions Mean             0.00103537
evaluation/Actions Std              0.147072
evaluation/Actions Max              0.995923
evaluation/Actions Min             -0.997884
evaluation/Num Paths               15
evaluation/Average Returns        -56.2748
time/data storing (s)               0.00272116
time/evaluation sampling (s)        0.323068
time/exploration sampling (s)       0.137754
time/logging (s)                    0.00485822
time/saving (s)                     0.00198731
time/training (s)                   1.9516
time/epoch (s)                      2.42198
time/total (s)                   1098.21
Epoch                             450
-----------------------------  ---------------
2019-04-23 00:11:41.296943 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 451 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   99.5528
trainer/QF2 Loss                   99.7085
trainer/Policy Loss                31.1202
trainer/Q1 Predictions Mean       -28.816
trainer/Q1 Predictions Std         30.5188
trainer/Q1 Predictions Max         -6.58187
trainer/Q1 Predictions Min        -90.891
trainer/Q2 Predictions Mean       -28.8448
trainer/Q2 Predictions Std         30.5225
trainer/Q2 Predictions Max         -6.70476
trainer/Q2 Predictions Min        -91.0195
trainer/Q Targets Mean            -27.863
trainer/Q Targets Std              30.5816
trainer/Q Targets Max              -1.08164
trainer/Q Targets Min             -92.3164
trainer/Log Pis Mean                2.37823
trainer/Log Pis Std                 1.27981
trainer/Log Pis Max                 6.7982
trainer/Log Pis Min                -1.04462
trainer/Policy mu Mean             -0.0511478
trainer/Policy mu Std               0.574086
trainer/Policy mu Max               2.71498
trainer/Policy mu Min              -3.21778
trainer/Policy log std Mean        -2.28951
trainer/Policy log std Std          0.47313
trainer/Policy log std Max         -0.169626
trainer/Policy log std Min         -2.94756
trainer/Alpha                       0.0817888
trainer/Alpha Loss                  0.947036
exploration/num steps total    226200
exploration/num paths total      2262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.526621
exploration/Rewards Std             0.890439
exploration/Rewards Max            -0.0098396
exploration/Rewards Min            -7.77244
exploration/Returns Mean          -52.6621
exploration/Returns Std            28.9903
exploration/Returns Max           -27.7174
exploration/Returns Min          -108.577
exploration/Actions Mean           -0.0149139
exploration/Actions Std             0.233792
exploration/Actions Max             0.997841
exploration/Actions Min            -0.999479
exploration/Num Paths               5
exploration/Average Returns       -52.6621
evaluation/num steps total     678000
evaluation/num paths total       6780
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.598871
evaluation/Rewards Std              1.02958
evaluation/Rewards Max             -0.00180917
evaluation/Rewards Min             -9.72871
evaluation/Returns Mean           -59.8871
evaluation/Returns Std             40.8136
evaluation/Returns Max            -12.6695
evaluation/Returns Min           -147.245
evaluation/Actions Mean             0.019923
evaluation/Actions Std              0.192443
evaluation/Actions Max              0.998286
evaluation/Actions Min             -0.998982
evaluation/Num Paths               15
evaluation/Average Returns        -59.8871
time/data storing (s)               0.00262593
time/evaluation sampling (s)        0.32953
time/exploration sampling (s)       0.136514
time/logging (s)                    0.00485216
time/saving (s)                     0.00201058
time/training (s)                   1.95268
time/epoch (s)                      2.42821
time/total (s)                   1100.64
Epoch                             451
-----------------------------  ---------------
2019-04-23 00:11:43.761090 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 452 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   24.8148
trainer/QF2 Loss                   24.8785
trainer/Policy Loss                27.2494
trainer/Q1 Predictions Mean       -25.3041
trainer/Q1 Predictions Std         28.1814
trainer/Q1 Predictions Max         -6.69674
trainer/Q1 Predictions Min        -91.322
trainer/Q2 Predictions Mean       -25.3245
trainer/Q2 Predictions Std         28.1967
trainer/Q2 Predictions Max         -6.62297
trainer/Q2 Predictions Min        -91.1006
trainer/Q Targets Mean            -24.8965
trainer/Q Targets Std              28.6226
trainer/Q Targets Max              -0.106824
trainer/Q Targets Min             -91.971
trainer/Log Pis Mean                1.97965
trainer/Log Pis Std                 1.00543
trainer/Log Pis Max                 5.26924
trainer/Log Pis Min                -1.15237
trainer/Policy mu Mean             -0.0278663
trainer/Policy mu Std               0.413982
trainer/Policy mu Max               2.86977
trainer/Policy mu Min              -2.6346
trainer/Policy log std Mean        -2.23568
trainer/Policy log std Std          0.422925
trainer/Policy log std Max         -0.431686
trainer/Policy log std Min         -3.03198
trainer/Alpha                       0.0837097
trainer/Alpha Loss                 -0.050473
exploration/num steps total    226700
exploration/num paths total      2267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.465759
exploration/Rewards Std             1.2731
exploration/Rewards Max            -0.00827524
exploration/Rewards Min            -9.02087
exploration/Returns Mean          -46.5759
exploration/Returns Std            13.4536
exploration/Returns Max           -30.0247
exploration/Returns Min           -62.6498
exploration/Actions Mean           -0.00874507
exploration/Actions Std             0.255474
exploration/Actions Max             0.999089
exploration/Actions Min            -0.999744
exploration/Num Paths               5
exploration/Average Returns       -46.5759
evaluation/num steps total     679500
evaluation/num paths total       6795
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.534895
evaluation/Rewards Std              0.988901
evaluation/Rewards Max             -0.00892396
evaluation/Rewards Min             -9.54695
evaluation/Returns Mean           -53.4895
evaluation/Returns Std             62.3216
evaluation/Returns Max             -4.72833
evaluation/Returns Min           -179.302
evaluation/Actions Mean             0.00550132
evaluation/Actions Std              0.183886
evaluation/Actions Max              0.995763
evaluation/Actions Min             -0.997849
evaluation/Num Paths               15
evaluation/Average Returns        -53.4895
time/data storing (s)               0.00280599
time/evaluation sampling (s)        0.325321
time/exploration sampling (s)       0.142519
time/logging (s)                    0.00484155
time/saving (s)                     0.0102398
time/training (s)                   1.96741
time/epoch (s)                      2.45313
time/total (s)                   1103.1
Epoch                             452
-----------------------------  ---------------
2019-04-23 00:11:46.184816 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 453 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.507682
trainer/QF2 Loss                    0.492792
trainer/Policy Loss                29.1008
trainer/Q1 Predictions Mean       -27.1905
trainer/Q1 Predictions Std         30.0828
trainer/Q1 Predictions Max         -6.69982
trainer/Q1 Predictions Min        -89.8018
trainer/Q2 Predictions Mean       -27.1354
trainer/Q2 Predictions Std         30.1095
trainer/Q2 Predictions Max         -6.54283
trainer/Q2 Predictions Min        -89.6579
trainer/Q Targets Mean            -27.618
trainer/Q Targets Std              30.4808
trainer/Q Targets Max              -6.96578
trainer/Q Targets Min             -91.2289
trainer/Log Pis Mean                2.00216
trainer/Log Pis Std                 1.37586
trainer/Log Pis Max                 5.42685
trainer/Log Pis Min                -2.82176
trainer/Policy mu Mean             -0.0286947
trainer/Policy mu Std               0.490032
trainer/Policy mu Max               2.85257
trainer/Policy mu Min              -3.14212
trainer/Policy log std Mean        -2.30068
trainer/Policy log std Std          0.439843
trainer/Policy log std Max         -0.419323
trainer/Policy log std Min         -2.99557
trainer/Alpha                       0.0832818
trainer/Alpha Loss                  0.00537627
exploration/num steps total    227200
exploration/num paths total      2272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.449645
exploration/Rewards Std             1.23043
exploration/Rewards Max            -0.0157084
exploration/Rewards Min            -9.98355
exploration/Returns Mean          -44.9645
exploration/Returns Std             9.53602
exploration/Returns Max           -28.4953
exploration/Returns Min           -57.2885
exploration/Actions Mean            0.0201283
exploration/Actions Std             0.262047
exploration/Actions Max             0.999685
exploration/Actions Min            -0.999494
exploration/Num Paths               5
exploration/Average Returns       -44.9645
evaluation/num steps total     681000
evaluation/num paths total       6810
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.552755
evaluation/Rewards Std              1.02292
evaluation/Rewards Max             -0.0167176
evaluation/Rewards Min             -9.86239
evaluation/Returns Mean           -55.2755
evaluation/Returns Std             31.9425
evaluation/Returns Max            -12.1397
evaluation/Returns Min           -104.384
evaluation/Actions Mean            -0.0148253
evaluation/Actions Std              0.190784
evaluation/Actions Max              0.995537
evaluation/Actions Min             -0.999528
evaluation/Num Paths               15
evaluation/Average Returns        -55.2755
time/data storing (s)               0.00288689
time/evaluation sampling (s)        0.329626
time/exploration sampling (s)       0.14014
time/logging (s)                    0.0048363
time/saving (s)                     0.00199104
time/training (s)                   1.93322
time/epoch (s)                      2.4127
time/total (s)                   1105.51
Epoch                             453
-----------------------------  ---------------
2019-04-23 00:11:48.641394 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 454 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.924161
trainer/QF2 Loss                    0.936592
trainer/Policy Loss                27.8418
trainer/Q1 Predictions Mean       -26.2599
trainer/Q1 Predictions Std         29.1699
trainer/Q1 Predictions Max         -6.74632
trainer/Q1 Predictions Min        -96.5928
trainer/Q2 Predictions Mean       -26.2201
trainer/Q2 Predictions Std         29.1756
trainer/Q2 Predictions Max         -6.75006
trainer/Q2 Predictions Min        -96.6701
trainer/Q Targets Mean            -26.4474
trainer/Q Targets Std              29.4136
trainer/Q Targets Max              -0.14364
trainer/Q Targets Min             -96.9805
trainer/Log Pis Mean                1.62074
trainer/Log Pis Std                 1.18422
trainer/Log Pis Max                 3.84259
trainer/Log Pis Min                -1.63529
trainer/Policy mu Mean             -0.0409612
trainer/Policy mu Std               0.282995
trainer/Policy mu Max               0.452312
trainer/Policy mu Min              -2.24369
trainer/Policy log std Mean        -2.26303
trainer/Policy log std Std          0.367038
trainer/Policy log std Max         -0.713658
trainer/Policy log std Min         -2.98119
trainer/Alpha                       0.0847516
trainer/Alpha Loss                 -0.935968
exploration/num steps total    227700
exploration/num paths total      2277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.388668
exploration/Rewards Std             1.09288
exploration/Rewards Max            -0.0139681
exploration/Rewards Min            -9.57962
exploration/Returns Mean          -38.8668
exploration/Returns Std            22.2543
exploration/Returns Max           -14.8092
exploration/Returns Min           -74.599
exploration/Actions Mean           -0.0194264
exploration/Actions Std             0.230757
exploration/Actions Max             0.994908
exploration/Actions Min            -0.999651
exploration/Num Paths               5
exploration/Average Returns       -38.8668
evaluation/num steps total     682500
evaluation/num paths total       6825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.464358
evaluation/Rewards Std              1.00815
evaluation/Rewards Max             -0.0130712
evaluation/Rewards Min            -11.8621
evaluation/Returns Mean           -46.4358
evaluation/Returns Std             47.0953
evaluation/Returns Max             -7.5889
evaluation/Returns Min           -166.374
evaluation/Actions Mean            -0.00877855
evaluation/Actions Std              0.176112
evaluation/Actions Max              0.997393
evaluation/Actions Min             -0.999714
evaluation/Num Paths               15
evaluation/Average Returns        -46.4358
time/data storing (s)               0.00279204
time/evaluation sampling (s)        0.329089
time/exploration sampling (s)       0.135131
time/logging (s)                    0.00479105
time/saving (s)                     0.00196656
time/training (s)                   1.97171
time/epoch (s)                      2.44548
time/total (s)                   1107.96
Epoch                             454
-----------------------------  ---------------
2019-04-23 00:11:51.074503 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 455 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0743762
trainer/QF2 Loss                    0.0731148
trainer/Policy Loss                29.3762
trainer/Q1 Predictions Mean       -27.6454
trainer/Q1 Predictions Std         28.8121
trainer/Q1 Predictions Max         -6.78185
trainer/Q1 Predictions Min        -89.1452
trainer/Q2 Predictions Mean       -27.6736
trainer/Q2 Predictions Std         28.7985
trainer/Q2 Predictions Max         -6.90696
trainer/Q2 Predictions Min        -89.1673
trainer/Q Targets Mean            -27.8382
trainer/Q Targets Std              28.9275
trainer/Q Targets Max              -6.91109
trainer/Q Targets Min             -89.4816
trainer/Log Pis Mean                1.75896
trainer/Log Pis Std                 1.12552
trainer/Log Pis Max                 3.47991
trainer/Log Pis Min                -3.49741
trainer/Policy mu Mean             -0.0422372
trainer/Policy mu Std               0.28257
trainer/Policy mu Max               2.49923
trainer/Policy mu Min              -1.1753
trainer/Policy log std Mean        -2.23722
trainer/Policy log std Std          0.341505
trainer/Policy log std Max         -0.546977
trainer/Policy log std Min         -2.80233
trainer/Alpha                       0.080869
trainer/Alpha Loss                 -0.606139
exploration/num steps total    228200
exploration/num paths total      2282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.659863
exploration/Rewards Std             1.26942
exploration/Rewards Max            -0.00978695
exploration/Rewards Min           -10.5072
exploration/Returns Mean          -65.9863
exploration/Returns Std            52.0512
exploration/Returns Max           -23.2183
exploration/Returns Min          -164.802
exploration/Actions Mean            0.00196059
exploration/Actions Std             0.241015
exploration/Actions Max             0.999595
exploration/Actions Min            -0.999396
exploration/Num Paths               5
exploration/Average Returns       -65.9863
evaluation/num steps total     684000
evaluation/num paths total       6840
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.52082
evaluation/Rewards Std              1.2421
evaluation/Rewards Max             -0.00490805
evaluation/Rewards Min            -10.7657
evaluation/Returns Mean           -52.082
evaluation/Returns Std             42.977
evaluation/Returns Max             -4.02565
evaluation/Returns Min           -142.579
evaluation/Actions Mean            -0.0156016
evaluation/Actions Std              0.204272
evaluation/Actions Max              0.997067
evaluation/Actions Min             -0.999482
evaluation/Num Paths               15
evaluation/Average Returns        -52.082
time/data storing (s)               0.00275558
time/evaluation sampling (s)        0.322732
time/exploration sampling (s)       0.138632
time/logging (s)                    0.00481647
time/saving (s)                     0.00198963
time/training (s)                   1.951
time/epoch (s)                      2.42192
time/total (s)                   1110.39
Epoch                             455
-----------------------------  ---------------
2019-04-23 00:11:53.529620 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 456 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   73.9375
trainer/QF2 Loss                   73.8029
trainer/Policy Loss                25.8541
trainer/Q1 Predictions Mean       -23.973
trainer/Q1 Predictions Std         26.4285
trainer/Q1 Predictions Max         -7.04133
trainer/Q1 Predictions Min        -88.3826
trainer/Q2 Predictions Mean       -23.9644
trainer/Q2 Predictions Std         26.4257
trainer/Q2 Predictions Max         -6.95892
trainer/Q2 Predictions Min        -88.5334
trainer/Q Targets Mean            -23.2046
trainer/Q Targets Std              25.8067
trainer/Q Targets Max              -2.28268
trainer/Q Targets Min             -88.8147
trainer/Log Pis Mean                1.90173
trainer/Log Pis Std                 1.22904
trainer/Log Pis Max                 4.31093
trainer/Log Pis Min                -2.09116
trainer/Policy mu Mean              0.00402829
trainer/Policy mu Std               0.387978
trainer/Policy mu Max               2.60591
trainer/Policy mu Min              -2.39015
trainer/Policy log std Mean        -2.30664
trainer/Policy log std Std          0.360422
trainer/Policy log std Max         -0.727611
trainer/Policy log std Min         -2.89961
trainer/Alpha                       0.077733
trainer/Alpha Loss                 -0.25103
exploration/num steps total    228700
exploration/num paths total      2287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.456122
exploration/Rewards Std             1.34827
exploration/Rewards Max            -0.00489977
exploration/Rewards Min           -10.3622
exploration/Returns Mean          -45.6122
exploration/Returns Std            16.2034
exploration/Returns Max           -22.8803
exploration/Returns Min           -65.3325
exploration/Actions Mean            0.0292972
exploration/Actions Std             0.239184
exploration/Actions Max             0.998875
exploration/Actions Min            -0.99945
exploration/Num Paths               5
exploration/Average Returns       -45.6122
evaluation/num steps total     685500
evaluation/num paths total       6855
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.59335
evaluation/Rewards Std              1.10211
evaluation/Rewards Max             -0.00813311
evaluation/Rewards Min             -9.6235
evaluation/Returns Mean           -59.335
evaluation/Returns Std             47.8683
evaluation/Returns Max             -6.53584
evaluation/Returns Min           -181.166
evaluation/Actions Mean             0.00254588
evaluation/Actions Std              0.195471
evaluation/Actions Max              0.999365
evaluation/Actions Min             -0.998693
evaluation/Num Paths               15
evaluation/Average Returns        -59.335
time/data storing (s)               0.00275694
time/evaluation sampling (s)        0.33075
time/exploration sampling (s)       0.13643
time/logging (s)                    0.00480445
time/saving (s)                     0.00196525
time/training (s)                   1.96732
time/epoch (s)                      2.44403
time/total (s)                   1112.84
Epoch                             456
-----------------------------  ---------------
2019-04-23 00:11:55.978167 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 457 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.842325
trainer/QF2 Loss                    0.815702
trainer/Policy Loss                25.0057
trainer/Q1 Predictions Mean       -23.0994
trainer/Q1 Predictions Std         25.8602
trainer/Q1 Predictions Max         -6.80688
trainer/Q1 Predictions Min        -87.319
trainer/Q2 Predictions Mean       -23.1177
trainer/Q2 Predictions Std         25.8811
trainer/Q2 Predictions Max         -6.78959
trainer/Q2 Predictions Min        -87.2226
trainer/Q Targets Mean            -23.3766
trainer/Q Targets Std              26.3505
trainer/Q Targets Max              -0.083058
trainer/Q Targets Min             -88.8421
trainer/Log Pis Mean                1.98469
trainer/Log Pis Std                 1.0608
trainer/Log Pis Max                 4.71192
trainer/Log Pis Min                -2.32043
trainer/Policy mu Mean             -0.0467672
trainer/Policy mu Std               0.344078
trainer/Policy mu Max               2.4946
trainer/Policy mu Min              -2.3434
trainer/Policy log std Mean        -2.28984
trainer/Policy log std Std          0.350582
trainer/Policy log std Max         -0.488073
trainer/Policy log std Min         -2.85327
trainer/Alpha                       0.0749762
trainer/Alpha Loss                 -0.039667
exploration/num steps total    229200
exploration/num paths total      2292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.24539
exploration/Rewards Std             0.628798
exploration/Rewards Max            -0.010556
exploration/Rewards Min            -6.8454
exploration/Returns Mean          -24.539
exploration/Returns Std             6.87595
exploration/Returns Max           -18.5437
exploration/Returns Min           -37.725
exploration/Actions Mean            0.0124599
exploration/Actions Std             0.206521
exploration/Actions Max             0.99834
exploration/Actions Min            -0.99533
exploration/Num Paths               5
exploration/Average Returns       -24.539
evaluation/num steps total     687000
evaluation/num paths total       6870
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.534334
evaluation/Rewards Std              1.03886
evaluation/Rewards Max             -0.00766409
evaluation/Rewards Min            -10.7212
evaluation/Returns Mean           -53.4334
evaluation/Returns Std             51.3066
evaluation/Returns Max             -3.27715
evaluation/Returns Min           -140.893
evaluation/Actions Mean             0.00126979
evaluation/Actions Std              0.168741
evaluation/Actions Max              0.997839
evaluation/Actions Min             -0.999614
evaluation/Num Paths               15
evaluation/Average Returns        -53.4334
time/data storing (s)               0.00313229
time/evaluation sampling (s)        0.327732
time/exploration sampling (s)       0.13658
time/logging (s)                    0.00480992
time/saving (s)                     0.00206128
time/training (s)                   1.96344
time/epoch (s)                      2.43775
time/total (s)                   1115.28
Epoch                             457
-----------------------------  ---------------
2019-04-23 00:11:58.416473 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 458 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   19.5679
trainer/QF2 Loss                   19.5528
trainer/Policy Loss                27.8008
trainer/Q1 Predictions Mean       -25.9118
trainer/Q1 Predictions Std         28.2635
trainer/Q1 Predictions Max         -6.65569
trainer/Q1 Predictions Min        -87.8113
trainer/Q2 Predictions Mean       -25.8807
trainer/Q2 Predictions Std         28.2499
trainer/Q2 Predictions Max         -6.74636
trainer/Q2 Predictions Min        -87.8293
trainer/Q Targets Mean            -25.7647
trainer/Q Targets Std              28.6575
trainer/Q Targets Max              -0.883895
trainer/Q Targets Min             -88.4782
trainer/Log Pis Mean                2.04495
trainer/Log Pis Std                 1.04561
trainer/Log Pis Max                 4.62915
trainer/Log Pis Min                -2.3669
trainer/Policy mu Mean             -0.0659949
trainer/Policy mu Std               0.316738
trainer/Policy mu Max               2.61156
trainer/Policy mu Min              -2.30297
trainer/Policy log std Mean        -2.27829
trainer/Policy log std Std          0.356314
trainer/Policy log std Max         -0.485907
trainer/Policy log std Min         -2.88107
trainer/Alpha                       0.0755546
trainer/Alpha Loss                  0.116117
exploration/num steps total    229700
exploration/num paths total      2297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.17091
exploration/Rewards Std             0.932022
exploration/Rewards Max            -0.0919029
exploration/Rewards Min            -8.39467
exploration/Returns Mean         -117.091
exploration/Returns Std            27.8191
exploration/Returns Max           -63.5096
exploration/Returns Min          -141.276
exploration/Actions Mean           -0.0208728
exploration/Actions Std             0.231615
exploration/Actions Max             0.997396
exploration/Actions Min            -0.999865
exploration/Num Paths               5
exploration/Average Returns      -117.091
evaluation/num steps total     688500
evaluation/num paths total       6885
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.524749
evaluation/Rewards Std              0.949765
evaluation/Rewards Max             -0.00449027
evaluation/Rewards Min             -9.97102
evaluation/Returns Mean           -52.4749
evaluation/Returns Std             53.1552
evaluation/Returns Max             -9.42755
evaluation/Returns Min           -165.271
evaluation/Actions Mean             0.00618189
evaluation/Actions Std              0.170757
evaluation/Actions Max              0.997581
evaluation/Actions Min             -0.999285
evaluation/Num Paths               15
evaluation/Average Returns        -52.4749
time/data storing (s)               0.00274774
time/evaluation sampling (s)        0.332751
time/exploration sampling (s)       0.13647
time/logging (s)                    0.00478424
time/saving (s)                     0.00225947
time/training (s)                   1.9483
time/epoch (s)                      2.42731
time/total (s)                   1117.71
Epoch                             458
-----------------------------  ---------------
2019-04-23 00:12:00.873342 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 459 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.18885
trainer/QF2 Loss                    0.169828
trainer/Policy Loss                26.8259
trainer/Q1 Predictions Mean       -24.7686
trainer/Q1 Predictions Std         27.6497
trainer/Q1 Predictions Max         -6.69197
trainer/Q1 Predictions Min        -86.7239
trainer/Q2 Predictions Mean       -24.7416
trainer/Q2 Predictions Std         27.6356
trainer/Q2 Predictions Max         -6.75592
trainer/Q2 Predictions Min        -86.59
trainer/Q Targets Mean            -24.9739
trainer/Q Targets Std              27.865
trainer/Q Targets Max              -6.86567
trainer/Q Targets Min             -87.6462
trainer/Log Pis Mean                2.17122
trainer/Log Pis Std                 1.09089
trainer/Log Pis Max                 5.10587
trainer/Log Pis Min                -1.84953
trainer/Policy mu Mean              0.0270798
trainer/Policy mu Std               0.579346
trainer/Policy mu Max               2.78033
trainer/Policy mu Min              -2.90313
trainer/Policy log std Mean        -2.22161
trainer/Policy log std Std          0.451325
trainer/Policy log std Max         -0.5113
trainer/Policy log std Min         -2.90392
trainer/Alpha                       0.0759884
trainer/Alpha Loss                  0.441241
exploration/num steps total    230200
exploration/num paths total      2302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.543964
exploration/Rewards Std             0.899218
exploration/Rewards Max            -0.00684351
exploration/Rewards Min            -7.97032
exploration/Returns Mean          -54.3964
exploration/Returns Std            43.2524
exploration/Returns Max           -17.9855
exploration/Returns Min          -138.533
exploration/Actions Mean            0.0231394
exploration/Actions Std             0.205813
exploration/Actions Max             0.999241
exploration/Actions Min            -0.921153
exploration/Num Paths               5
exploration/Average Returns       -54.3964
evaluation/num steps total     690000
evaluation/num paths total       6900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.777864
evaluation/Rewards Std              1.03384
evaluation/Rewards Max             -0.00915124
evaluation/Rewards Min            -11.1269
evaluation/Returns Mean           -77.7864
evaluation/Returns Std             50.9747
evaluation/Returns Max             -9.82021
evaluation/Returns Min           -176.606
evaluation/Actions Mean            -0.00999215
evaluation/Actions Std              0.182112
evaluation/Actions Max              0.998836
evaluation/Actions Min             -0.999313
evaluation/Num Paths               15
evaluation/Average Returns        -77.7864
time/data storing (s)               0.0028292
time/evaluation sampling (s)        0.326726
time/exploration sampling (s)       0.141898
time/logging (s)                    0.00485472
time/saving (s)                     0.00200914
time/training (s)                   1.96751
time/epoch (s)                      2.44583
time/total (s)                   1120.16
Epoch                             459
-----------------------------  ---------------
2019-04-23 00:12:03.311645 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 460 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.90902
trainer/QF2 Loss                    1.90098
trainer/Policy Loss                28.484
trainer/Q1 Predictions Mean       -26.4467
trainer/Q1 Predictions Std         26.9443
trainer/Q1 Predictions Max         -6.69394
trainer/Q1 Predictions Min        -86.3963
trainer/Q2 Predictions Mean       -26.5087
trainer/Q2 Predictions Std         26.9133
trainer/Q2 Predictions Max         -6.72029
trainer/Q2 Predictions Min        -86.3057
trainer/Q Targets Mean            -26.4355
trainer/Q Targets Std              27.0937
trainer/Q Targets Max              -0.28467
trainer/Q Targets Min             -86.186
trainer/Log Pis Mean                2.08732
trainer/Log Pis Std                 0.918176
trainer/Log Pis Max                 5.52546
trainer/Log Pis Min                -0.567372
trainer/Policy mu Mean              0.0154606
trainer/Policy mu Std               0.375249
trainer/Policy mu Max               2.56251
trainer/Policy mu Min              -2.10368
trainer/Policy log std Mean        -2.26013
trainer/Policy log std Std          0.369236
trainer/Policy log std Max         -0.661343
trainer/Policy log std Min         -2.88033
trainer/Alpha                       0.0734897
trainer/Alpha Loss                  0.227959
exploration/num steps total    230700
exploration/num paths total      2307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.404993
exploration/Rewards Std             0.672321
exploration/Rewards Max            -0.00382272
exploration/Rewards Min            -7.19525
exploration/Returns Mean          -40.4993
exploration/Returns Std            24.5673
exploration/Returns Max           -13.9022
exploration/Returns Min           -85.5968
exploration/Actions Mean           -0.0114358
exploration/Actions Std             0.192698
exploration/Actions Max             0.999332
exploration/Actions Min            -0.989532
exploration/Num Paths               5
exploration/Average Returns       -40.4993
evaluation/num steps total     691500
evaluation/num paths total       6915
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.558725
evaluation/Rewards Std              0.949862
evaluation/Rewards Max             -0.00910037
evaluation/Rewards Min             -9.10205
evaluation/Returns Mean           -55.8725
evaluation/Returns Std             40.6834
evaluation/Returns Max             -5.5499
evaluation/Returns Min           -123.595
evaluation/Actions Mean            -0.00862079
evaluation/Actions Std              0.181137
evaluation/Actions Max              0.997394
evaluation/Actions Min             -0.998868
evaluation/Num Paths               15
evaluation/Average Returns        -55.8725
time/data storing (s)               0.00269724
time/evaluation sampling (s)        0.327845
time/exploration sampling (s)       0.140829
time/logging (s)                    0.00480594
time/saving (s)                     0.00201474
time/training (s)                   1.95054
time/epoch (s)                      2.42873
time/total (s)                   1122.6
Epoch                             460
-----------------------------  ---------------
2019-04-23 00:12:05.753778 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 461 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   85.9832
trainer/QF2 Loss                   85.9736
trainer/Policy Loss                27.8288
trainer/Q1 Predictions Mean       -25.8486
trainer/Q1 Predictions Std         27.8096
trainer/Q1 Predictions Max         -6.61629
trainer/Q1 Predictions Min        -92.4874
trainer/Q2 Predictions Mean       -25.798
trainer/Q2 Predictions Std         27.8042
trainer/Q2 Predictions Max         -6.65006
trainer/Q2 Predictions Min        -92.3999
trainer/Q Targets Mean            -24.6882
trainer/Q Targets Std              27.7922
trainer/Q Targets Max              -0.367104
trainer/Q Targets Min             -92.9003
trainer/Log Pis Mean                2.01703
trainer/Log Pis Std                 1.19428
trainer/Log Pis Max                 6.46926
trainer/Log Pis Min                -0.895215
trainer/Policy mu Mean             -0.0104278
trainer/Policy mu Std               0.553027
trainer/Policy mu Max               2.60773
trainer/Policy mu Min              -2.68798
trainer/Policy log std Mean        -2.17538
trainer/Policy log std Std          0.484832
trainer/Policy log std Max         -0.412456
trainer/Policy log std Min         -2.93562
trainer/Alpha                       0.077637
trainer/Alpha Loss                  0.0435308
exploration/num steps total    231200
exploration/num paths total      2312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.24379
exploration/Rewards Std             1.03716
exploration/Rewards Max            -0.0117318
exploration/Rewards Min           -10.2571
exploration/Returns Mean         -124.379
exploration/Returns Std            56.1727
exploration/Returns Max           -14.864
exploration/Returns Min          -168.12
exploration/Actions Mean           -0.0246706
exploration/Actions Std             0.208691
exploration/Actions Max             0.999412
exploration/Actions Min            -0.999121
exploration/Num Paths               5
exploration/Average Returns      -124.379
evaluation/num steps total     693000
evaluation/num paths total       6930
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.475925
evaluation/Rewards Std              0.952522
evaluation/Rewards Max             -0.0314824
evaluation/Rewards Min             -9.67754
evaluation/Returns Mean           -47.5925
evaluation/Returns Std             43.3579
evaluation/Returns Max             -9.25024
evaluation/Returns Min           -167.053
evaluation/Actions Mean            -0.00627803
evaluation/Actions Std              0.170567
evaluation/Actions Max              0.998641
evaluation/Actions Min             -0.999321
evaluation/Num Paths               15
evaluation/Average Returns        -47.5925
time/data storing (s)               0.0027016
time/evaluation sampling (s)        0.328221
time/exploration sampling (s)       0.139067
time/logging (s)                    0.00481194
time/saving (s)                     0.00196804
time/training (s)                   1.95371
time/epoch (s)                      2.43048
time/total (s)                   1125.03
Epoch                             461
-----------------------------  ---------------
2019-04-23 00:12:08.207415 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 462 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.430946
trainer/QF2 Loss                    0.422702
trainer/Policy Loss                27.2046
trainer/Q1 Predictions Mean       -25.295
trainer/Q1 Predictions Std         26.9006
trainer/Q1 Predictions Max         -6.76646
trainer/Q1 Predictions Min        -85.9842
trainer/Q2 Predictions Mean       -25.3136
trainer/Q2 Predictions Std         26.9179
trainer/Q2 Predictions Max         -6.8039
trainer/Q2 Predictions Min        -86.0403
trainer/Q Targets Mean            -25.6717
trainer/Q Targets Std              27.2718
trainer/Q Targets Max              -6.91645
trainer/Q Targets Min             -85.5558
trainer/Log Pis Mean                1.95358
trainer/Log Pis Std                 1.28977
trainer/Log Pis Max                 8.38479
trainer/Log Pis Min                -3.05753
trainer/Policy mu Mean              0.0300005
trainer/Policy mu Std               0.445906
trainer/Policy mu Max               2.90562
trainer/Policy mu Min              -2.42941
trainer/Policy log std Mean        -2.19059
trainer/Policy log std Std          0.426889
trainer/Policy log std Max         -0.254389
trainer/Policy log std Min         -2.86818
trainer/Alpha                       0.0792511
trainer/Alpha Loss                 -0.117666
exploration/num steps total    231700
exploration/num paths total      2317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.868899
exploration/Rewards Std             1.29731
exploration/Rewards Max            -0.0111063
exploration/Rewards Min           -11.3238
exploration/Returns Mean          -86.8899
exploration/Returns Std            49.8936
exploration/Returns Max           -33.7523
exploration/Returns Min          -167.531
exploration/Actions Mean            0.00190104
exploration/Actions Std             0.257437
exploration/Actions Max             0.999835
exploration/Actions Min            -0.998925
exploration/Num Paths               5
exploration/Average Returns       -86.8899
evaluation/num steps total     694500
evaluation/num paths total       6945
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.626337
evaluation/Rewards Std              1.00056
evaluation/Rewards Max             -0.0256616
evaluation/Rewards Min             -9.81794
evaluation/Returns Mean           -62.6337
evaluation/Returns Std             52.5638
evaluation/Returns Max             -7.31164
evaluation/Returns Min           -154.877
evaluation/Actions Mean             0.0074643
evaluation/Actions Std              0.174635
evaluation/Actions Max              0.998367
evaluation/Actions Min             -0.999459
evaluation/Num Paths               15
evaluation/Average Returns        -62.6337
time/data storing (s)               0.00284609
time/evaluation sampling (s)        0.332355
time/exploration sampling (s)       0.142979
time/logging (s)                    0.00478425
time/saving (s)                     0.00197375
time/training (s)                   1.95759
time/epoch (s)                      2.44253
time/total (s)                   1127.48
Epoch                             462
-----------------------------  ---------------
2019-04-23 00:12:10.645955 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 463 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   44.1112
trainer/QF2 Loss                   44.4464
trainer/Policy Loss                33.2215
trainer/Q1 Predictions Mean       -31.207
trainer/Q1 Predictions Std         29.7636
trainer/Q1 Predictions Max         -6.91185
trainer/Q1 Predictions Min       -104.423
trainer/Q2 Predictions Mean       -31.1768
trainer/Q2 Predictions Std         29.682
trainer/Q2 Predictions Max         -6.91933
trainer/Q2 Predictions Min       -103.337
trainer/Q Targets Mean            -30.7096
trainer/Q Targets Std              29.9742
trainer/Q Targets Max              -0.0485411
trainer/Q Targets Min            -105.443
trainer/Log Pis Mean                2.12657
trainer/Log Pis Std                 1.21653
trainer/Log Pis Max                 7.71382
trainer/Log Pis Min                -1.36586
trainer/Policy mu Mean              0.0720262
trainer/Policy mu Std               0.563423
trainer/Policy mu Max               3.35974
trainer/Policy mu Min              -2.58514
trainer/Policy log std Mean        -2.22415
trainer/Policy log std Std          0.389283
trainer/Policy log std Max         -0.504922
trainer/Policy log std Min         -2.87342
trainer/Alpha                       0.0766265
trainer/Alpha Loss                  0.325137
exploration/num steps total    232200
exploration/num paths total      2322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.584001
exploration/Rewards Std             1.07465
exploration/Rewards Max            -0.00759242
exploration/Rewards Min            -9.18335
exploration/Returns Mean          -58.4001
exploration/Returns Std            15.2214
exploration/Returns Max           -44.292
exploration/Returns Min           -86.8581
exploration/Actions Mean           -0.0169482
exploration/Actions Std             0.241062
exploration/Actions Max             0.999018
exploration/Actions Min            -0.999872
exploration/Num Paths               5
exploration/Average Returns       -58.4001
evaluation/num steps total     696000
evaluation/num paths total       6960
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.665736
evaluation/Rewards Std              0.954781
evaluation/Rewards Max             -0.00996664
evaluation/Rewards Min            -10.4873
evaluation/Returns Mean           -66.5736
evaluation/Returns Std             47.5341
evaluation/Returns Max             -8.27574
evaluation/Returns Min           -145.009
evaluation/Actions Mean            -0.00805038
evaluation/Actions Std              0.16804
evaluation/Actions Max              0.998978
evaluation/Actions Min             -0.999117
evaluation/Num Paths               15
evaluation/Average Returns        -66.5736
time/data storing (s)               0.00282572
time/evaluation sampling (s)        0.32523
time/exploration sampling (s)       0.137581
time/logging (s)                    0.00485773
time/saving (s)                     0.00198097
time/training (s)                   1.95504
time/epoch (s)                      2.42752
time/total (s)                   1129.91
Epoch                             463
-----------------------------  ---------------
2019-04-23 00:12:13.105039 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 464 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  126.375
trainer/QF2 Loss                  126.784
trainer/Policy Loss                26.465
trainer/Q1 Predictions Mean       -24.7446
trainer/Q1 Predictions Std         27.3141
trainer/Q1 Predictions Max         -6.81438
trainer/Q1 Predictions Min        -81.9591
trainer/Q2 Predictions Mean       -24.7289
trainer/Q2 Predictions Std         27.3265
trainer/Q2 Predictions Max         -6.88109
trainer/Q2 Predictions Min        -82.191
trainer/Q Targets Mean            -23.3509
trainer/Q Targets Std              26.6775
trainer/Q Targets Max              -0.279568
trainer/Q Targets Min             -82.7014
trainer/Log Pis Mean                1.82908
trainer/Log Pis Std                 0.970367
trainer/Log Pis Max                 3.34662
trainer/Log Pis Min                -1.39823
trainer/Policy mu Mean             -0.0624795
trainer/Policy mu Std               0.293724
trainer/Policy mu Max               2.38346
trainer/Policy mu Min              -2.27096
trainer/Policy log std Mean        -2.26338
trainer/Policy log std Std          0.303366
trainer/Policy log std Max         -0.688387
trainer/Policy log std Min         -2.77406
trainer/Alpha                       0.0740201
trainer/Alpha Loss                 -0.444947
exploration/num steps total    232700
exploration/num paths total      2327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.695391
exploration/Rewards Std             1.07844
exploration/Rewards Max            -0.00666767
exploration/Rewards Min           -10.6801
exploration/Returns Mean          -69.5391
exploration/Returns Std            54.6904
exploration/Returns Max           -18.9374
exploration/Returns Min          -166.131
exploration/Actions Mean            0.00577969
exploration/Actions Std             0.225591
exploration/Actions Max             0.999212
exploration/Actions Min            -0.999505
exploration/Num Paths               5
exploration/Average Returns       -69.5391
evaluation/num steps total     697500
evaluation/num paths total       6975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.588323
evaluation/Rewards Std              0.892708
evaluation/Rewards Max             -0.0129193
evaluation/Rewards Min             -8.74817
evaluation/Returns Mean           -58.8323
evaluation/Returns Std             47.1328
evaluation/Returns Max             -5.80319
evaluation/Returns Min           -137.872
evaluation/Actions Mean             0.00242264
evaluation/Actions Std              0.165408
evaluation/Actions Max              0.996526
evaluation/Actions Min             -0.998874
evaluation/Num Paths               15
evaluation/Average Returns        -58.8323
time/data storing (s)               0.00263907
time/evaluation sampling (s)        0.323802
time/exploration sampling (s)       0.140263
time/logging (s)                    0.0048509
time/saving (s)                     0.00997668
time/training (s)                   1.96724
time/epoch (s)                      2.44877
time/total (s)                   1132.36
Epoch                             464
-----------------------------  ---------------
2019-04-23 00:12:15.518049 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 465 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   20.1332
trainer/QF2 Loss                   20.0132
trainer/Policy Loss                27.6412
trainer/Q1 Predictions Mean       -25.7513
trainer/Q1 Predictions Std         26.0441
trainer/Q1 Predictions Max         -6.99557
trainer/Q1 Predictions Min        -97.2643
trainer/Q2 Predictions Mean       -25.7483
trainer/Q2 Predictions Std         26.0187
trainer/Q2 Predictions Max         -7.03567
trainer/Q2 Predictions Min        -96.8771
trainer/Q Targets Mean            -25.4102
trainer/Q Targets Std              26.2759
trainer/Q Targets Max              -0.0480589
trainer/Q Targets Min             -97.5604
trainer/Log Pis Mean                1.94784
trainer/Log Pis Std                 1.13775
trainer/Log Pis Max                 6.23177
trainer/Log Pis Min                -1.64379
trainer/Policy mu Mean              0.0069977
trainer/Policy mu Std               0.421902
trainer/Policy mu Max               3.26125
trainer/Policy mu Min              -1.62567
trainer/Policy log std Mean        -2.22717
trainer/Policy log std Std          0.325681
trainer/Policy log std Max         -0.589376
trainer/Policy log std Min         -2.7752
trainer/Alpha                       0.071228
trainer/Alpha Loss                 -0.13779
exploration/num steps total    233200
exploration/num paths total      2332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.835525
exploration/Rewards Std             0.966995
exploration/Rewards Max            -0.015695
exploration/Rewards Min            -9.14885
exploration/Returns Mean          -83.5525
exploration/Returns Std            39.0087
exploration/Returns Max           -18.71
exploration/Returns Min          -132.478
exploration/Actions Mean            0.00705526
exploration/Actions Std             0.209198
exploration/Actions Max             0.998074
exploration/Actions Min            -0.99971
exploration/Num Paths               5
exploration/Average Returns       -83.5525
evaluation/num steps total     699000
evaluation/num paths total       6990
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.589284
evaluation/Rewards Std              1.20646
evaluation/Rewards Max             -0.00993873
evaluation/Rewards Min            -10.682
evaluation/Returns Mean           -58.9284
evaluation/Returns Std             44.7933
evaluation/Returns Max             -6.01364
evaluation/Returns Min           -155.861
evaluation/Actions Mean            -0.0148067
evaluation/Actions Std              0.199941
evaluation/Actions Max              0.998382
evaluation/Actions Min             -0.998885
evaluation/Num Paths               15
evaluation/Average Returns        -58.9284
time/data storing (s)               0.00273136
time/evaluation sampling (s)        0.325239
time/exploration sampling (s)       0.141391
time/logging (s)                    0.00482333
time/saving (s)                     0.00199906
time/training (s)                   1.9267
time/epoch (s)                      2.40288
time/total (s)                   1134.77
Epoch                             465
-----------------------------  ---------------
2019-04-23 00:12:17.958287 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 466 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   42.6405
trainer/QF2 Loss                   42.7072
trainer/Policy Loss                26.6623
trainer/Q1 Predictions Mean       -24.5799
trainer/Q1 Predictions Std         26.2337
trainer/Q1 Predictions Max         -6.91818
trainer/Q1 Predictions Min        -82.9078
trainer/Q2 Predictions Mean       -24.6027
trainer/Q2 Predictions Std         26.2825
trainer/Q2 Predictions Max         -6.83917
trainer/Q2 Predictions Min        -84.2317
trainer/Q Targets Mean            -24.2332
trainer/Q Targets Std              26.5119
trainer/Q Targets Max              -0.912176
trainer/Q Targets Min             -84.0525
trainer/Log Pis Mean                2.17292
trainer/Log Pis Std                 1.114
trainer/Log Pis Max                 5.9638
trainer/Log Pis Min                -1.86906
trainer/Policy mu Mean             -0.113645
trainer/Policy mu Std               0.470823
trainer/Policy mu Max               3.02052
trainer/Policy mu Min              -2.94714
trainer/Policy log std Mean        -2.37508
trainer/Policy log std Std          0.434889
trainer/Policy log std Max         -0.598111
trainer/Policy log std Min         -3.06746
trainer/Alpha                       0.0723581
trainer/Alpha Loss                  0.454157
exploration/num steps total    233700
exploration/num paths total      2337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.625604
exploration/Rewards Std             0.790866
exploration/Rewards Max            -0.0131486
exploration/Rewards Min            -6.96568
exploration/Returns Mean          -62.5604
exploration/Returns Std            35.9084
exploration/Returns Max           -21.8191
exploration/Returns Min          -107.331
exploration/Actions Mean           -0.0221889
exploration/Actions Std             0.19955
exploration/Actions Max             0.889409
exploration/Actions Min            -0.999934
exploration/Num Paths               5
exploration/Average Returns       -62.5604
evaluation/num steps total     700500
evaluation/num paths total       7005
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.763512
evaluation/Rewards Std              0.960384
evaluation/Rewards Max             -0.0136741
evaluation/Rewards Min             -8.87789
evaluation/Returns Mean           -76.3512
evaluation/Returns Std             62.5476
evaluation/Returns Max             -6.46765
evaluation/Returns Min           -183.835
evaluation/Actions Mean             0.00307944
evaluation/Actions Std              0.16479
evaluation/Actions Max              0.998174
evaluation/Actions Min             -0.997791
evaluation/Num Paths               15
evaluation/Average Returns        -76.3512
time/data storing (s)               0.00275576
time/evaluation sampling (s)        0.326116
time/exploration sampling (s)       0.144921
time/logging (s)                    0.0048516
time/saving (s)                     0.00200016
time/training (s)                   1.94934
time/epoch (s)                      2.42999
time/total (s)                   1137.2
Epoch                             466
-----------------------------  ---------------
2019-04-23 00:12:20.415876 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 467 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.18976
trainer/QF2 Loss                    0.189275
trainer/Policy Loss                25.7084
trainer/Q1 Predictions Mean       -23.9979
trainer/Q1 Predictions Std         26.6392
trainer/Q1 Predictions Max         -6.87561
trainer/Q1 Predictions Min        -90.2695
trainer/Q2 Predictions Mean       -24.033
trainer/Q2 Predictions Std         26.6356
trainer/Q2 Predictions Max         -6.91349
trainer/Q2 Predictions Min        -90.7134
trainer/Q Targets Mean            -24.1864
trainer/Q Targets Std              26.8584
trainer/Q Targets Max              -6.96196
trainer/Q Targets Min             -90.4344
trainer/Log Pis Mean                1.85988
trainer/Log Pis Std                 1.26617
trainer/Log Pis Max                 5.61891
trainer/Log Pis Min                -1.37932
trainer/Policy mu Mean             -0.0899767
trainer/Policy mu Std               0.384787
trainer/Policy mu Max               0.474874
trainer/Policy mu Min              -2.91927
trainer/Policy log std Mean        -2.22975
trainer/Policy log std Std          0.387113
trainer/Policy log std Max         -0.551463
trainer/Policy log std Min         -2.97716
trainer/Alpha                       0.0733925
trainer/Alpha Loss                 -0.365976
exploration/num steps total    234200
exploration/num paths total      2342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.43999
exploration/Rewards Std             1.09134
exploration/Rewards Max            -0.00663658
exploration/Rewards Min            -9.60946
exploration/Returns Mean          -43.999
exploration/Returns Std            20.1422
exploration/Returns Max           -24.0872
exploration/Returns Min           -77.9739
exploration/Actions Mean           -0.0111087
exploration/Actions Std             0.248497
exploration/Actions Max             0.99748
exploration/Actions Min            -0.999067
exploration/Num Paths               5
exploration/Average Returns       -43.999
evaluation/num steps total     702000
evaluation/num paths total       7020
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.527673
evaluation/Rewards Std              1.10222
evaluation/Rewards Max             -0.00586047
evaluation/Rewards Min             -9.42514
evaluation/Returns Mean           -52.7673
evaluation/Returns Std             40.4528
evaluation/Returns Max            -12.9757
evaluation/Returns Min           -154.966
evaluation/Actions Mean             0.00351719
evaluation/Actions Std              0.199619
evaluation/Actions Max              0.999125
evaluation/Actions Min             -0.999066
evaluation/Num Paths               15
evaluation/Average Returns        -52.7673
time/data storing (s)               0.00269719
time/evaluation sampling (s)        0.331505
time/exploration sampling (s)       0.140803
time/logging (s)                    0.00354544
time/saving (s)                     0.00168743
time/training (s)                   1.96459
time/epoch (s)                      2.44483
time/total (s)                   1139.65
Epoch                             467
-----------------------------  ---------------
2019-04-23 00:12:22.853659 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 468 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.89521
trainer/QF2 Loss                    1.88305
trainer/Policy Loss                24.249
trainer/Q1 Predictions Mean       -22.2294
trainer/Q1 Predictions Std         24.4506
trainer/Q1 Predictions Max         -6.86613
trainer/Q1 Predictions Min        -78.5707
trainer/Q2 Predictions Mean       -22.2195
trainer/Q2 Predictions Std         24.411
trainer/Q2 Predictions Max         -6.682
trainer/Q2 Predictions Min        -78.605
trainer/Q Targets Mean            -22.1934
trainer/Q Targets Std              24.6715
trainer/Q Targets Max              -0.269255
trainer/Q Targets Min             -78.9869
trainer/Log Pis Mean                2.08563
trainer/Log Pis Std                 1.14845
trainer/Log Pis Max                 5.47801
trainer/Log Pis Min                -2.68158
trainer/Policy mu Mean             -0.0890183
trainer/Policy mu Std               0.558651
trainer/Policy mu Max               3.37201
trainer/Policy mu Min              -3.87118
trainer/Policy log std Mean        -2.26838
trainer/Policy log std Std          0.457016
trainer/Policy log std Max         -0.170455
trainer/Policy log std Min         -2.85365
trainer/Alpha                       0.0732864
trainer/Alpha Loss                  0.223775
exploration/num steps total    234700
exploration/num paths total      2347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.409661
exploration/Rewards Std             1.14198
exploration/Rewards Max            -0.00459161
exploration/Rewards Min            -9.49744
exploration/Returns Mean          -40.9661
exploration/Returns Std            13.9842
exploration/Returns Max           -17.4184
exploration/Returns Min           -60.4745
exploration/Actions Mean            0.00265606
exploration/Actions Std             0.235734
exploration/Actions Max             0.999222
exploration/Actions Min            -0.998466
exploration/Num Paths               5
exploration/Average Returns       -40.9661
evaluation/num steps total     703500
evaluation/num paths total       7035
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.479788
evaluation/Rewards Std              0.999948
evaluation/Rewards Max             -0.00576649
evaluation/Rewards Min            -10.9095
evaluation/Returns Mean           -47.9788
evaluation/Returns Std             48.6051
evaluation/Returns Max             -3.87994
evaluation/Returns Min           -150.236
evaluation/Actions Mean             0.0072019
evaluation/Actions Std              0.178627
evaluation/Actions Max              0.999198
evaluation/Actions Min             -0.998827
evaluation/Num Paths               15
evaluation/Average Returns        -47.9788
time/data storing (s)               0.00275061
time/evaluation sampling (s)        0.337831
time/exploration sampling (s)       0.139464
time/logging (s)                    0.00479132
time/saving (s)                     0.00198276
time/training (s)                   1.94194
time/epoch (s)                      2.42876
time/total (s)                   1142.09
Epoch                             468
-----------------------------  ---------------
2019-04-23 00:12:25.309631 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 469 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.13988
trainer/QF2 Loss                    1.1084
trainer/Policy Loss                30.9022
trainer/Q1 Predictions Mean       -29.1471
trainer/Q1 Predictions Std         27.7253
trainer/Q1 Predictions Max         -6.92225
trainer/Q1 Predictions Min        -76.8568
trainer/Q2 Predictions Mean       -29.197
trainer/Q2 Predictions Std         27.7362
trainer/Q2 Predictions Max         -7.01073
trainer/Q2 Predictions Min        -76.6132
trainer/Q Targets Mean            -29.4665
trainer/Q Targets Std              28.3397
trainer/Q Targets Max              -0.270129
trainer/Q Targets Min             -77.414
trainer/Log Pis Mean                2.03009
trainer/Log Pis Std                 1.30777
trainer/Log Pis Max                 7.51619
trainer/Log Pis Min                -1.17942
trainer/Policy mu Mean             -0.127039
trainer/Policy mu Std               0.507782
trainer/Policy mu Max               2.91147
trainer/Policy mu Min              -4.20269
trainer/Policy log std Mean        -2.32607
trainer/Policy log std Std          0.422007
trainer/Policy log std Max         -0.152722
trainer/Policy log std Min         -3.15798
trainer/Alpha                       0.0748461
trainer/Alpha Loss                  0.078012
exploration/num steps total    235200
exploration/num paths total      2352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.329681
exploration/Rewards Std             0.880362
exploration/Rewards Max            -0.00854186
exploration/Rewards Min            -9.2398
exploration/Returns Mean          -32.9681
exploration/Returns Std            12.9287
exploration/Returns Max           -17.4378
exploration/Returns Min           -49.1089
exploration/Actions Mean            0.00824585
exploration/Actions Std             0.228857
exploration/Actions Max             0.998932
exploration/Actions Min            -0.998436
exploration/Num Paths               5
exploration/Average Returns       -32.9681
evaluation/num steps total     705000
evaluation/num paths total       7050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.398123
evaluation/Rewards Std              0.963695
evaluation/Rewards Max             -0.00509842
evaluation/Rewards Min             -9.671
evaluation/Returns Mean           -39.8123
evaluation/Returns Std             48.1376
evaluation/Returns Max             -5.2811
evaluation/Returns Min           -161.322
evaluation/Actions Mean             0.000563413
evaluation/Actions Std              0.17695
evaluation/Actions Max              0.996236
evaluation/Actions Min             -0.999696
evaluation/Num Paths               15
evaluation/Average Returns        -39.8123
time/data storing (s)               0.00276421
time/evaluation sampling (s)        0.332339
time/exploration sampling (s)       0.137964
time/logging (s)                    0.00354638
time/saving (s)                     0.00198976
time/training (s)                   1.9649
time/epoch (s)                      2.4435
time/total (s)                   1144.53
Epoch                             469
-----------------------------  ----------------
2019-04-23 00:12:27.756219 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 470 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.176866
trainer/QF2 Loss                    0.180164
trainer/Policy Loss                29.4154
trainer/Q1 Predictions Mean       -27.7056
trainer/Q1 Predictions Std         26.2939
trainer/Q1 Predictions Max         -6.93757
trainer/Q1 Predictions Min        -75.3751
trainer/Q2 Predictions Mean       -27.6814
trainer/Q2 Predictions Std         26.3053
trainer/Q2 Predictions Max         -6.78605
trainer/Q2 Predictions Min        -75.1903
trainer/Q Targets Mean            -27.906
trainer/Q Targets Std              26.5331
trainer/Q Targets Max              -6.89662
trainer/Q Targets Min             -75.7825
trainer/Log Pis Mean                1.86098
trainer/Log Pis Std                 1.29144
trainer/Log Pis Max                 7.41449
trainer/Log Pis Min                -1.75366
trainer/Policy mu Mean             -0.0934709
trainer/Policy mu Std               0.492527
trainer/Policy mu Max               2.32205
trainer/Policy mu Min              -2.88919
trainer/Policy log std Mean        -2.22034
trainer/Policy log std Std          0.416652
trainer/Policy log std Max         -0.719259
trainer/Policy log std Min         -3.09694
trainer/Alpha                       0.0757892
trainer/Alpha Loss                 -0.358638
exploration/num steps total    235700
exploration/num paths total      2357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.941597
exploration/Rewards Std             1.20553
exploration/Rewards Max            -0.00844705
exploration/Rewards Min            -8.88334
exploration/Returns Mean          -94.1597
exploration/Returns Std            72.185
exploration/Returns Max           -32.6951
exploration/Returns Min          -193.996
exploration/Actions Mean            0.0182096
exploration/Actions Std             0.236125
exploration/Actions Max             0.998977
exploration/Actions Min            -0.999852
exploration/Num Paths               5
exploration/Average Returns       -94.1597
evaluation/num steps total     706500
evaluation/num paths total       7065
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.447081
evaluation/Rewards Std              0.996601
evaluation/Rewards Max             -0.00899124
evaluation/Rewards Min            -10.5482
evaluation/Returns Mean           -44.7081
evaluation/Returns Std             40.2605
evaluation/Returns Max             -3.97259
evaluation/Returns Min           -130.987
evaluation/Actions Mean            -0.00401555
evaluation/Actions Std              0.182548
evaluation/Actions Max              0.999185
evaluation/Actions Min             -0.999034
evaluation/Num Paths               15
evaluation/Average Returns        -44.7081
time/data storing (s)               0.00278278
time/evaluation sampling (s)        0.327196
time/exploration sampling (s)       0.136066
time/logging (s)                    0.00481571
time/saving (s)                     0.00195562
time/training (s)                   1.9644
time/epoch (s)                      2.43722
time/total (s)                   1146.98
Epoch                             470
-----------------------------  ---------------
2019-04-23 00:12:30.192388 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 471 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.00898
trainer/QF2 Loss                    0.888412
trainer/Policy Loss                27.006
trainer/Q1 Predictions Mean       -24.8733
trainer/Q1 Predictions Std         24.6734
trainer/Q1 Predictions Max         -6.80193
trainer/Q1 Predictions Min       -105.029
trainer/Q2 Predictions Mean       -24.8767
trainer/Q2 Predictions Std         24.7499
trainer/Q2 Predictions Max         -6.7843
trainer/Q2 Predictions Min       -107.682
trainer/Q Targets Mean            -25.0774
trainer/Q Targets Std              25.0064
trainer/Q Targets Max              -0.0475917
trainer/Q Targets Min            -108.495
trainer/Log Pis Mean                2.09465
trainer/Log Pis Std                 1.62412
trainer/Log Pis Max                 9.71709
trainer/Log Pis Min                -6.19667
trainer/Policy mu Mean             -0.0454314
trainer/Policy mu Std               0.655256
trainer/Policy mu Max               3.43159
trainer/Policy mu Min              -3.1728
trainer/Policy log std Mean        -2.20133
trainer/Policy log std Std          0.470651
trainer/Policy log std Max         -0.400367
trainer/Policy log std Min         -3.12254
trainer/Alpha                       0.0754965
trainer/Alpha Loss                  0.244557
exploration/num steps total    236200
exploration/num paths total      2362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.849813
exploration/Rewards Std             0.959524
exploration/Rewards Max            -0.0160135
exploration/Rewards Min            -7.67854
exploration/Returns Mean          -84.9813
exploration/Returns Std            61.582
exploration/Returns Max           -20.8604
exploration/Returns Min          -166.042
exploration/Actions Mean           -0.0048078
exploration/Actions Std             0.221534
exploration/Actions Max             0.998552
exploration/Actions Min            -0.998844
exploration/Num Paths               5
exploration/Average Returns       -84.9813
evaluation/num steps total     708000
evaluation/num paths total       7080
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.480057
evaluation/Rewards Std              1.03625
evaluation/Rewards Max             -0.00155841
evaluation/Rewards Min            -10.3283
evaluation/Returns Mean           -48.0057
evaluation/Returns Std             52.4165
evaluation/Returns Max             -1.9911
evaluation/Returns Min           -156.963
evaluation/Actions Mean             0.00650461
evaluation/Actions Std              0.175352
evaluation/Actions Max              0.996384
evaluation/Actions Min             -0.998965
evaluation/Num Paths               15
evaluation/Average Returns        -48.0057
time/data storing (s)               0.00275088
time/evaluation sampling (s)        0.329694
time/exploration sampling (s)       0.135757
time/logging (s)                    0.00481947
time/saving (s)                     0.00199182
time/training (s)                   1.9499
time/epoch (s)                      2.42492
time/total (s)                   1149.41
Epoch                             471
-----------------------------  ---------------
2019-04-23 00:12:32.636315 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 472 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   20.5376
trainer/QF2 Loss                   20.492
trainer/Policy Loss                29.762
trainer/Q1 Predictions Mean       -27.6267
trainer/Q1 Predictions Std         26.0118
trainer/Q1 Predictions Max         -6.90036
trainer/Q1 Predictions Min        -72.35
trainer/Q2 Predictions Mean       -27.5737
trainer/Q2 Predictions Std         26.0296
trainer/Q2 Predictions Max         -6.93611
trainer/Q2 Predictions Min        -72.1114
trainer/Q Targets Mean            -27.6126
trainer/Q Targets Std              26.6675
trainer/Q Targets Max              -0.315025
trainer/Q Targets Min             -73.4885
trainer/Log Pis Mean                2.27528
trainer/Log Pis Std                 1.28413
trainer/Log Pis Max                 7.51757
trainer/Log Pis Min                -2.83813
trainer/Policy mu Mean             -0.0498098
trainer/Policy mu Std               0.548385
trainer/Policy mu Max               3.59689
trainer/Policy mu Min              -2.52533
trainer/Policy log std Mean        -2.27858
trainer/Policy log std Std          0.480139
trainer/Policy log std Max         -0.317861
trainer/Policy log std Min         -3.22919
trainer/Alpha                       0.0765004
trainer/Alpha Loss                  0.70766
exploration/num steps total    236700
exploration/num paths total      2367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.761639
exploration/Rewards Std             1.3758
exploration/Rewards Max            -0.00443699
exploration/Rewards Min           -10.9699
exploration/Returns Mean          -76.1639
exploration/Returns Std            41.7565
exploration/Returns Max           -15.5683
exploration/Returns Min          -133.604
exploration/Actions Mean            0.0118982
exploration/Actions Std             0.249309
exploration/Actions Max             0.998737
exploration/Actions Min            -0.999878
exploration/Num Paths               5
exploration/Average Returns       -76.1639
evaluation/num steps total     709500
evaluation/num paths total       7095
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.436155
evaluation/Rewards Std              0.977217
evaluation/Rewards Max             -0.0083572
evaluation/Rewards Min            -10.3289
evaluation/Returns Mean           -43.6155
evaluation/Returns Std             43.5561
evaluation/Returns Max             -2.06756
evaluation/Returns Min           -139.106
evaluation/Actions Mean            -0.012531
evaluation/Actions Std              0.163328
evaluation/Actions Max              0.997967
evaluation/Actions Min             -0.999504
evaluation/Num Paths               15
evaluation/Average Returns        -43.6155
time/data storing (s)               0.00281866
time/evaluation sampling (s)        0.331381
time/exploration sampling (s)       0.136099
time/logging (s)                    0.00488475
time/saving (s)                     0.00198912
time/training (s)                   1.95562
time/epoch (s)                      2.43279
time/total (s)                   1151.84
Epoch                             472
-----------------------------  ---------------
2019-04-23 00:12:35.083763 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 473 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.85227
trainer/QF2 Loss                    1.8863
trainer/Policy Loss                26.2166
trainer/Q1 Predictions Mean       -24.3873
trainer/Q1 Predictions Std         23.8341
trainer/Q1 Predictions Max         -6.97786
trainer/Q1 Predictions Min        -72.2602
trainer/Q2 Predictions Mean       -24.3967
trainer/Q2 Predictions Std         23.8332
trainer/Q2 Predictions Max         -7.06168
trainer/Q2 Predictions Min        -72.2687
trainer/Q Targets Mean            -24.498
trainer/Q Targets Std              24.0552
trainer/Q Targets Max              -0.28467
trainer/Q Targets Min             -72.2696
trainer/Log Pis Mean                1.87067
trainer/Log Pis Std                 1.23619
trainer/Log Pis Max                 5.08336
trainer/Log Pis Min                -1.37112
trainer/Policy mu Mean             -0.0884059
trainer/Policy mu Std               0.476765
trainer/Policy mu Max               2.66938
trainer/Policy mu Min              -2.94468
trainer/Policy log std Mean        -2.18454
trainer/Policy log std Std          0.412509
trainer/Policy log std Max         -0.56421
trainer/Policy log std Min         -3.17755
trainer/Alpha                       0.0769416
trainer/Alpha Loss                 -0.331698
exploration/num steps total    237200
exploration/num paths total      2372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.705392
exploration/Rewards Std             0.912647
exploration/Rewards Max            -0.00363285
exploration/Rewards Min            -8.45693
exploration/Returns Mean          -70.5392
exploration/Returns Std            41.7016
exploration/Returns Max           -23.2143
exploration/Returns Min          -141.838
exploration/Actions Mean           -0.0109551
exploration/Actions Std             0.225822
exploration/Actions Max             0.999031
exploration/Actions Min            -0.998127
exploration/Num Paths               5
exploration/Average Returns       -70.5392
evaluation/num steps total     711000
evaluation/num paths total       7110
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.498863
evaluation/Rewards Std              1.10462
evaluation/Rewards Max             -0.0170777
evaluation/Rewards Min            -10.1677
evaluation/Returns Mean           -49.8863
evaluation/Returns Std             35.31
evaluation/Returns Max            -10.1605
evaluation/Returns Min           -137.259
evaluation/Actions Mean            -0.0166253
evaluation/Actions Std              0.193693
evaluation/Actions Max              0.994295
evaluation/Actions Min             -0.999773
evaluation/Num Paths               15
evaluation/Average Returns        -49.8863
time/data storing (s)               0.00285238
time/evaluation sampling (s)        0.324983
time/exploration sampling (s)       0.138937
time/logging (s)                    0.00383265
time/saving (s)                     0.00213718
time/training (s)                   1.96204
time/epoch (s)                      2.43478
time/total (s)                   1154.28
Epoch                             473
-----------------------------  ---------------
2019-04-23 00:12:37.528011 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 474 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.289957
trainer/QF2 Loss                    0.254352
trainer/Policy Loss                31.3206
trainer/Q1 Predictions Mean       -29.2721
trainer/Q1 Predictions Std         26.3039
trainer/Q1 Predictions Max         -6.81307
trainer/Q1 Predictions Min        -69.9793
trainer/Q2 Predictions Mean       -29.2981
trainer/Q2 Predictions Std         26.2852
trainer/Q2 Predictions Max         -6.88101
trainer/Q2 Predictions Min        -70.1409
trainer/Q Targets Mean            -29.5271
trainer/Q Targets Std              26.5817
trainer/Q Targets Max              -6.91664
trainer/Q Targets Min             -71.2891
trainer/Log Pis Mean                2.19044
trainer/Log Pis Std                 1.30238
trainer/Log Pis Max                 9.2341
trainer/Log Pis Min                -2.03072
trainer/Policy mu Mean             -0.073023
trainer/Policy mu Std               0.535427
trainer/Policy mu Max               2.72201
trainer/Policy mu Min              -3.62203
trainer/Policy log std Mean        -2.29222
trainer/Policy log std Std          0.419779
trainer/Policy log std Max         -0.580931
trainer/Policy log std Min         -3.26114
trainer/Alpha                       0.0774107
trainer/Alpha Loss                  0.487287
exploration/num steps total    237700
exploration/num paths total      2377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -1.10979
exploration/Rewards Std             0.869952
exploration/Rewards Max            -0.00677823
exploration/Rewards Min            -8.76741
exploration/Returns Mean         -110.979
exploration/Returns Std            32.4437
exploration/Returns Max           -53.6111
exploration/Returns Min          -146.022
exploration/Actions Mean            0.000988673
exploration/Actions Std             0.203688
exploration/Actions Max             0.998056
exploration/Actions Min            -0.998462
exploration/Num Paths               5
exploration/Average Returns      -110.979
evaluation/num steps total     712500
evaluation/num paths total       7125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.841576
evaluation/Rewards Std              0.970558
evaluation/Rewards Max             -0.00183198
evaluation/Rewards Min             -9.88016
evaluation/Returns Mean           -84.1576
evaluation/Returns Std             43.7112
evaluation/Returns Max            -19.4379
evaluation/Returns Min           -151.85
evaluation/Actions Mean             0.0050896
evaluation/Actions Std              0.163587
evaluation/Actions Max              0.997619
evaluation/Actions Min             -0.998745
evaluation/Num Paths               15
evaluation/Average Returns        -84.1576
time/data storing (s)               0.002776
time/evaluation sampling (s)        0.325552
time/exploration sampling (s)       0.143183
time/logging (s)                    0.00482091
time/saving (s)                     0.00160317
time/training (s)                   1.95604
time/epoch (s)                      2.43397
time/total (s)                   1156.72
Epoch                             474
-----------------------------  ----------------
2019-04-23 00:12:39.981478 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 475 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   43.7183
trainer/QF2 Loss                   43.4593
trainer/Policy Loss                29.0166
trainer/Q1 Predictions Mean       -27.0533
trainer/Q1 Predictions Std         24.7888
trainer/Q1 Predictions Max         -6.67326
trainer/Q1 Predictions Min        -81.1575
trainer/Q2 Predictions Mean       -27.0335
trainer/Q2 Predictions Std         24.7729
trainer/Q2 Predictions Max         -6.64077
trainer/Q2 Predictions Min        -80.4672
trainer/Q Targets Mean            -26.5402
trainer/Q Targets Std              24.7084
trainer/Q Targets Max              -0.0886021
trainer/Q Targets Min             -80.2003
trainer/Log Pis Mean                2.18979
trainer/Log Pis Std                 1.36104
trainer/Log Pis Max                 9.68927
trainer/Log Pis Min                -1.88891
trainer/Policy mu Mean             -0.0480446
trainer/Policy mu Std               0.507893
trainer/Policy mu Max               3.88627
trainer/Policy mu Min              -2.34592
trainer/Policy log std Mean        -2.29191
trainer/Policy log std Std          0.390124
trainer/Policy log std Max         -0.184122
trainer/Policy log std Min         -3.10594
trainer/Alpha                       0.0796453
trainer/Alpha Loss                  0.480211
exploration/num steps total    238200
exploration/num paths total      2382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.933921
exploration/Rewards Std             1.13234
exploration/Rewards Max            -0.011709
exploration/Rewards Min            -9.72136
exploration/Returns Mean          -93.3921
exploration/Returns Std            53.0178
exploration/Returns Max           -18.4074
exploration/Returns Min          -145.003
exploration/Actions Mean           -0.00377946
exploration/Actions Std             0.228473
exploration/Actions Max             0.997003
exploration/Actions Min            -0.999992
exploration/Num Paths               5
exploration/Average Returns       -93.3921
evaluation/num steps total     714000
evaluation/num paths total       7140
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.393831
evaluation/Rewards Std              0.877098
evaluation/Rewards Max             -0.0261748
evaluation/Rewards Min             -8.88834
evaluation/Returns Mean           -39.3831
evaluation/Returns Std             40.9238
evaluation/Returns Max             -8.04348
evaluation/Returns Min           -135.357
evaluation/Actions Mean             0.0010914
evaluation/Actions Std              0.172307
evaluation/Actions Max              0.997404
evaluation/Actions Min             -0.999027
evaluation/Num Paths               15
evaluation/Average Returns        -39.3831
time/data storing (s)               0.00318639
time/evaluation sampling (s)        0.327062
time/exploration sampling (s)       0.138933
time/logging (s)                    0.00476748
time/saving (s)                     0.00195595
time/training (s)                   1.96624
time/epoch (s)                      2.44215
time/total (s)                   1159.17
Epoch                             475
-----------------------------  ---------------
2019-04-23 00:12:42.465733 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 476 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.0988436
trainer/QF2 Loss                    0.0935626
trainer/Policy Loss                23.6623
trainer/Q1 Predictions Mean       -21.6672
trainer/Q1 Predictions Std         22.2744
trainer/Q1 Predictions Max         -6.84422
trainer/Q1 Predictions Min        -73.6753
trainer/Q2 Predictions Mean       -21.652
trainer/Q2 Predictions Std         22.1874
trainer/Q2 Predictions Max         -6.82808
trainer/Q2 Predictions Min        -73.9544
trainer/Q Targets Mean            -21.5963
trainer/Q Targets Std              22.0618
trainer/Q Targets Max              -6.94665
trainer/Q Targets Min             -72.6438
trainer/Log Pis Mean                2.05553
trainer/Log Pis Std                 1.32283
trainer/Log Pis Max                 6.04288
trainer/Log Pis Min                -4.57621
trainer/Policy mu Mean             -0.0552159
trainer/Policy mu Std               0.607929
trainer/Policy mu Max               3.59838
trainer/Policy mu Min              -3.29841
trainer/Policy log std Mean        -2.25136
trainer/Policy log std Std          0.443243
trainer/Policy log std Max         -0.402495
trainer/Policy log std Min         -3.08893
trainer/Alpha                       0.0777679
trainer/Alpha Loss                  0.141807
exploration/num steps total    238700
exploration/num paths total      2387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.266668
exploration/Rewards Std             0.665713
exploration/Rewards Max            -0.00954952
exploration/Rewards Min            -7.36664
exploration/Returns Mean          -26.6668
exploration/Returns Std            12.3528
exploration/Returns Max           -11.7281
exploration/Returns Min           -46.441
exploration/Actions Mean           -0.015457
exploration/Actions Std             0.208511
exploration/Actions Max             0.922575
exploration/Actions Min            -0.999158
exploration/Num Paths               5
exploration/Average Returns       -26.6668
evaluation/num steps total     715500
evaluation/num paths total       7155
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.603856
evaluation/Rewards Std              0.972636
evaluation/Rewards Max             -0.00527451
evaluation/Rewards Min             -9.55073
evaluation/Returns Mean           -60.3856
evaluation/Returns Std             49.9011
evaluation/Returns Max             -7.77295
evaluation/Returns Min           -131.678
evaluation/Actions Mean             0.0163944
evaluation/Actions Std              0.170272
evaluation/Actions Max              0.997697
evaluation/Actions Min             -0.997967
evaluation/Num Paths               15
evaluation/Average Returns        -60.3856
time/data storing (s)               0.00270604
time/evaluation sampling (s)        0.332892
time/exploration sampling (s)       0.136844
time/logging (s)                    0.00484618
time/saving (s)                     0.00956994
time/training (s)                   1.98616
time/epoch (s)                      2.47302
time/total (s)                   1161.64
Epoch                             476
-----------------------------  ---------------
2019-04-23 00:12:44.914019 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 477 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   17.6623
trainer/QF2 Loss                   17.7369
trainer/Policy Loss                25.2032
trainer/Q1 Predictions Mean       -23.365
trainer/Q1 Predictions Std         23.2068
trainer/Q1 Predictions Max         -6.86994
trainer/Q1 Predictions Min        -81.4175
trainer/Q2 Predictions Mean       -23.3994
trainer/Q2 Predictions Std         23.2058
trainer/Q2 Predictions Max         -6.90568
trainer/Q2 Predictions Min        -81.3706
trainer/Q Targets Mean            -23.2356
trainer/Q Targets Std              23.4386
trainer/Q Targets Max              -0.801581
trainer/Q Targets Min             -80.5598
trainer/Log Pis Mean                2.00945
trainer/Log Pis Std                 1.32039
trainer/Log Pis Max                 5.64415
trainer/Log Pis Min                -2.39975
trainer/Policy mu Mean             -0.104852
trainer/Policy mu Std               0.426871
trainer/Policy mu Max               2.39134
trainer/Policy mu Min              -3.08462
trainer/Policy log std Mean        -2.2929
trainer/Policy log std Std          0.382614
trainer/Policy log std Max         -0.511189
trainer/Policy log std Min         -3.09197
trainer/Alpha                       0.0775224
trainer/Alpha Loss                  0.0241737
exploration/num steps total    239200
exploration/num paths total      2392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.575565
exploration/Rewards Std             0.936923
exploration/Rewards Max            -0.00470395
exploration/Rewards Min            -8.36015
exploration/Returns Mean          -57.5565
exploration/Returns Std            36.4743
exploration/Returns Max           -20.7365
exploration/Returns Min          -117.531
exploration/Actions Mean            0.0105564
exploration/Actions Std             0.201199
exploration/Actions Max             0.999911
exploration/Actions Min            -0.998719
exploration/Num Paths               5
exploration/Average Returns       -57.5565
evaluation/num steps total     717000
evaluation/num paths total       7170
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.532117
evaluation/Rewards Std              1.00137
evaluation/Rewards Max             -0.00602023
evaluation/Rewards Min             -9.36796
evaluation/Returns Mean           -53.2117
evaluation/Returns Std             41.4984
evaluation/Returns Max             -8.51676
evaluation/Returns Min           -132.576
evaluation/Actions Mean            -0.00619382
evaluation/Actions Std              0.186849
evaluation/Actions Max              0.996797
evaluation/Actions Min             -0.998842
evaluation/Num Paths               15
evaluation/Average Returns        -53.2117
time/data storing (s)               0.00283877
time/evaluation sampling (s)        0.325412
time/exploration sampling (s)       0.14115
time/logging (s)                    0.00487266
time/saving (s)                     0.00198232
time/training (s)                   1.96208
time/epoch (s)                      2.43833
time/total (s)                   1164.09
Epoch                             477
-----------------------------  ---------------
2019-04-23 00:12:47.345491 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 478 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.225014
trainer/QF2 Loss                    0.286159
trainer/Policy Loss                21.9896
trainer/Q1 Predictions Mean       -20.0904
trainer/Q1 Predictions Std         22.2749
trainer/Q1 Predictions Max         -7.03058
trainer/Q1 Predictions Min       -109.802
trainer/Q2 Predictions Mean       -20.0617
trainer/Q2 Predictions Std         22.2432
trainer/Q2 Predictions Max         -7.05056
trainer/Q2 Predictions Min       -108.714
trainer/Q Targets Mean            -20.2409
trainer/Q Targets Std              22.5514
trainer/Q Targets Max              -6.96128
trainer/Q Targets Min            -111.883
trainer/Log Pis Mean                2.00903
trainer/Log Pis Std                 1.39905
trainer/Log Pis Max                 7.20574
trainer/Log Pis Min                -2.73067
trainer/Policy mu Mean             -0.0563073
trainer/Policy mu Std               0.537872
trainer/Policy mu Max               3.35755
trainer/Policy mu Min              -3.19338
trainer/Policy log std Mean        -2.22174
trainer/Policy log std Std          0.406207
trainer/Policy log std Max         -0.56433
trainer/Policy log std Min         -3.02605
trainer/Alpha                       0.0756521
trainer/Alpha Loss                  0.0233067
exploration/num steps total    239700
exploration/num paths total      2397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.356988
exploration/Rewards Std             0.577928
exploration/Rewards Max            -0.00609229
exploration/Rewards Min            -6.95096
exploration/Returns Mean          -35.6988
exploration/Returns Std            29.6477
exploration/Returns Max            -9.95849
exploration/Returns Min           -92.9158
exploration/Actions Mean            0.00557079
exploration/Actions Std             0.179679
exploration/Actions Max             0.998241
exploration/Actions Min            -0.994917
exploration/Num Paths               5
exploration/Average Returns       -35.6988
evaluation/num steps total     718500
evaluation/num paths total       7185
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.545067
evaluation/Rewards Std              1.18694
evaluation/Rewards Max             -0.0132702
evaluation/Rewards Min            -10.48
evaluation/Returns Mean           -54.5067
evaluation/Returns Std             40.8873
evaluation/Returns Max             -5.47731
evaluation/Returns Min           -153.522
evaluation/Actions Mean            -0.000595692
evaluation/Actions Std              0.204263
evaluation/Actions Max              0.99677
evaluation/Actions Min             -0.999403
evaluation/Num Paths               15
evaluation/Average Returns        -54.5067
time/data storing (s)               0.00265097
time/evaluation sampling (s)        0.33201
time/exploration sampling (s)       0.137365
time/logging (s)                    0.00483269
time/saving (s)                     0.00197971
time/training (s)                   1.94123
time/epoch (s)                      2.42007
time/total (s)                   1166.51
Epoch                             478
-----------------------------  ----------------
2019-04-23 00:12:49.806458 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 479 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.168118
trainer/QF2 Loss                    0.161339
trainer/Policy Loss                29.7233
trainer/Q1 Predictions Mean       -27.8583
trainer/Q1 Predictions Std         25.0943
trainer/Q1 Predictions Max         -6.95052
trainer/Q1 Predictions Min        -68.5424
trainer/Q2 Predictions Mean       -27.8971
trainer/Q2 Predictions Std         25.1143
trainer/Q2 Predictions Max         -6.92393
trainer/Q2 Predictions Min        -68.7045
trainer/Q Targets Mean            -28.0522
trainer/Q Targets Std              25.2332
trainer/Q Targets Max              -6.93204
trainer/Q Targets Min             -69.2151
trainer/Log Pis Mean                1.99682
trainer/Log Pis Std                 1.23754
trainer/Log Pis Max                 8.69458
trainer/Log Pis Min                -1.10063
trainer/Policy mu Mean             -0.0696031
trainer/Policy mu Std               0.414422
trainer/Policy mu Max               2.74426
trainer/Policy mu Min              -3.66809
trainer/Policy log std Mean        -2.24833
trainer/Policy log std Std          0.363914
trainer/Policy log std Max         -0.395186
trainer/Policy log std Min         -3.0865
trainer/Alpha                       0.0743827
trainer/Alpha Loss                 -0.00826988
exploration/num steps total    240200
exploration/num paths total      2402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.827072
exploration/Rewards Std             1.28358
exploration/Rewards Max            -0.0147523
exploration/Rewards Min           -10.9262
exploration/Returns Mean          -82.7072
exploration/Returns Std            50.3303
exploration/Returns Max           -28.894
exploration/Returns Min          -143.488
exploration/Actions Mean           -0.0202425
exploration/Actions Std             0.251054
exploration/Actions Max             0.998337
exploration/Actions Min            -0.999867
exploration/Num Paths               5
exploration/Average Returns       -82.7072
evaluation/num steps total     720000
evaluation/num paths total       7200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.519061
evaluation/Rewards Std              1.00165
evaluation/Rewards Max             -0.0527304
evaluation/Rewards Min             -9.86988
evaluation/Returns Mean           -51.9061
evaluation/Returns Std             39.4163
evaluation/Returns Max            -11.0202
evaluation/Returns Min           -138.268
evaluation/Actions Mean             0.0017038
evaluation/Actions Std              0.181075
evaluation/Actions Max              0.998372
evaluation/Actions Min             -0.999512
evaluation/Num Paths               15
evaluation/Average Returns        -51.9061
time/data storing (s)               0.00273093
time/evaluation sampling (s)        0.327901
time/exploration sampling (s)       0.136822
time/logging (s)                    0.00477177
time/saving (s)                     0.00199951
time/training (s)                   1.97516
time/epoch (s)                      2.44938
time/total (s)                   1168.97
Epoch                             479
-----------------------------  ---------------
2019-04-23 00:12:52.232262 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 480 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.11657
trainer/QF2 Loss                    0.160817
trainer/Policy Loss                24.2299
trainer/Q1 Predictions Mean       -22.4702
trainer/Q1 Predictions Std         23.2034
trainer/Q1 Predictions Max         -6.82819
trainer/Q1 Predictions Min        -69.3532
trainer/Q2 Predictions Mean       -22.472
trainer/Q2 Predictions Std         23.1792
trainer/Q2 Predictions Max         -6.73157
trainer/Q2 Predictions Min        -69.5446
trainer/Q Targets Mean            -22.6311
trainer/Q Targets Std              23.3652
trainer/Q Targets Max              -6.90724
trainer/Q Targets Min             -69.2541
trainer/Log Pis Mean                1.84164
trainer/Log Pis Std                 1.29084
trainer/Log Pis Max                 4.9795
trainer/Log Pis Min                -4.1978
trainer/Policy mu Mean              0.0104296
trainer/Policy mu Std               0.507446
trainer/Policy mu Max               3.16834
trainer/Policy mu Min              -2.10983
trainer/Policy log std Mean        -2.19965
trainer/Policy log std Std          0.399669
trainer/Policy log std Max         -0.348636
trainer/Policy log std Min         -3.02224
trainer/Alpha                       0.0738518
trainer/Alpha Loss                 -0.412601
exploration/num steps total    240700
exploration/num paths total      2407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.555182
exploration/Rewards Std             1.0976
exploration/Rewards Max            -0.0139041
exploration/Rewards Min            -8.67405
exploration/Returns Mean          -55.5182
exploration/Returns Std            37.5096
exploration/Returns Max           -20.4221
exploration/Returns Min          -125.766
exploration/Actions Mean           -0.00904453
exploration/Actions Std             0.224019
exploration/Actions Max             0.999922
exploration/Actions Min            -0.999545
exploration/Num Paths               5
exploration/Average Returns       -55.5182
evaluation/num steps total     721500
evaluation/num paths total       7215
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.608671
evaluation/Rewards Std              1.16141
evaluation/Rewards Max             -0.0046229
evaluation/Rewards Min             -9.51721
evaluation/Returns Mean           -60.8671
evaluation/Returns Std             52.2734
evaluation/Returns Max            -18.5685
evaluation/Returns Min           -167.152
evaluation/Actions Mean             0.0109754
evaluation/Actions Std              0.199704
evaluation/Actions Max              0.998126
evaluation/Actions Min             -0.998796
evaluation/Num Paths               15
evaluation/Average Returns        -60.8671
time/data storing (s)               0.00270043
time/evaluation sampling (s)        0.321359
time/exploration sampling (s)       0.136851
time/logging (s)                    0.00360946
time/saving (s)                     0.00198081
time/training (s)                   1.94676
time/epoch (s)                      2.41326
time/total (s)                   1171.38
Epoch                             480
-----------------------------  ---------------
2019-04-23 00:12:54.681430 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 481 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   39.0651
trainer/QF2 Loss                   39.0074
trainer/Policy Loss                29.552
trainer/Q1 Predictions Mean       -27.8974
trainer/Q1 Predictions Std         25.5728
trainer/Q1 Predictions Max         -6.83919
trainer/Q1 Predictions Min        -67.9683
trainer/Q2 Predictions Mean       -27.9092
trainer/Q2 Predictions Std         25.568
trainer/Q2 Predictions Max         -6.70766
trainer/Q2 Predictions Min        -67.7845
trainer/Q Targets Mean            -27.4263
trainer/Q Targets Std              25.6246
trainer/Q Targets Max              -2.08804
trainer/Q Targets Min             -68.9031
trainer/Log Pis Mean                1.78486
trainer/Log Pis Std                 1.31046
trainer/Log Pis Max                 4.12515
trainer/Log Pis Min                -4.99994
trainer/Policy mu Mean             -0.0639462
trainer/Policy mu Std               0.194239
trainer/Policy mu Max               0.307592
trainer/Policy mu Min              -0.732858
trainer/Policy log std Mean        -2.2672
trainer/Policy log std Std          0.306896
trainer/Policy log std Max         -1.56021
trainer/Policy log std Min         -3.11281
trainer/Alpha                       0.0744941
trainer/Alpha Loss                 -0.558721
exploration/num steps total    241200
exploration/num paths total      2412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.565619
exploration/Rewards Std             1.04945
exploration/Rewards Max            -0.0102777
exploration/Rewards Min            -9.606
exploration/Returns Mean          -56.5619
exploration/Returns Std            55.6537
exploration/Returns Max           -19.9358
exploration/Returns Min          -166.807
exploration/Actions Mean            0.00541766
exploration/Actions Std             0.232397
exploration/Actions Max             0.999899
exploration/Actions Min            -0.98765
exploration/Num Paths               5
exploration/Average Returns       -56.5619
evaluation/num steps total     723000
evaluation/num paths total       7230
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.291487
evaluation/Rewards Std              0.814827
evaluation/Rewards Max             -0.0428287
evaluation/Rewards Min             -9.70391
evaluation/Returns Mean           -29.1487
evaluation/Returns Std             22.661
evaluation/Returns Max             -8.63562
evaluation/Returns Min            -98.8274
evaluation/Actions Mean            -0.00942444
evaluation/Actions Std              0.177835
evaluation/Actions Max              0.996176
evaluation/Actions Min             -0.999238
evaluation/Num Paths               15
evaluation/Average Returns        -29.1487
time/data storing (s)               0.0026528
time/evaluation sampling (s)        0.326505
time/exploration sampling (s)       0.138883
time/logging (s)                    0.00483377
time/saving (s)                     0.00200782
time/training (s)                   1.96506
time/epoch (s)                      2.43994
time/total (s)                   1173.83
Epoch                             481
-----------------------------  ---------------
2019-04-23 00:12:57.131133 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 482 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   18.8155
trainer/QF2 Loss                   18.7528
trainer/Policy Loss                28.8452
trainer/Q1 Predictions Mean       -26.9251
trainer/Q1 Predictions Std         24.7844
trainer/Q1 Predictions Max         -6.52794
trainer/Q1 Predictions Min        -68.0724
trainer/Q2 Predictions Mean       -26.9158
trainer/Q2 Predictions Std         24.789
trainer/Q2 Predictions Max         -6.5751
trainer/Q2 Predictions Min        -67.8003
trainer/Q Targets Mean            -26.9228
trainer/Q Targets Std              25.33
trainer/Q Targets Max              -0.147832
trainer/Q Targets Min             -68.7666
trainer/Log Pis Mean                2.05636
trainer/Log Pis Std                 0.963353
trainer/Log Pis Max                 6.01053
trainer/Log Pis Min                -0.325062
trainer/Policy mu Mean             -0.0596087
trainer/Policy mu Std               0.391966
trainer/Policy mu Max               1.92564
trainer/Policy mu Min              -2.61643
trainer/Policy log std Mean        -2.30526
trainer/Policy log std Std          0.376935
trainer/Policy log std Max         -0.463809
trainer/Policy log std Min         -3.03974
trainer/Alpha                       0.0749443
trainer/Alpha Loss                  0.146031
exploration/num steps total    241700
exploration/num paths total      2417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.589441
exploration/Rewards Std             1.51585
exploration/Rewards Max            -0.00851117
exploration/Rewards Min           -12.0108
exploration/Returns Mean          -58.9441
exploration/Returns Std            15.6965
exploration/Returns Max           -40.7653
exploration/Returns Min           -85.2662
exploration/Actions Mean           -0.0435776
exploration/Actions Std             0.284866
exploration/Actions Max             0.997337
exploration/Actions Min            -0.99994
exploration/Num Paths               5
exploration/Average Returns       -58.9441
evaluation/num steps total     724500
evaluation/num paths total       7245
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.462469
evaluation/Rewards Std              1.21381
evaluation/Rewards Max             -0.0191311
evaluation/Rewards Min            -10.9224
evaluation/Returns Mean           -46.2469
evaluation/Returns Std             36.6554
evaluation/Returns Max            -10.0846
evaluation/Returns Min           -131.601
evaluation/Actions Mean            -0.0218095
evaluation/Actions Std              0.201415
evaluation/Actions Max              0.998857
evaluation/Actions Min             -0.999392
evaluation/Num Paths               15
evaluation/Average Returns        -46.2469
time/data storing (s)               0.00270649
time/evaluation sampling (s)        0.324055
time/exploration sampling (s)       0.143234
time/logging (s)                    0.00479952
time/saving (s)                     0.00198378
time/training (s)                   1.96145
time/epoch (s)                      2.43823
time/total (s)                   1176.27
Epoch                             482
-----------------------------  ---------------
2019-04-23 00:12:59.587740 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 483 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.00374
trainer/QF2 Loss                    1.0765
trainer/Policy Loss                31.4057
trainer/Q1 Predictions Mean       -29.2562
trainer/Q1 Predictions Std         25.6805
trainer/Q1 Predictions Max         -7.14422
trainer/Q1 Predictions Min        -72.7008
trainer/Q2 Predictions Mean       -29.2331
trainer/Q2 Predictions Std         25.6595
trainer/Q2 Predictions Max         -7.11432
trainer/Q2 Predictions Min        -72.3461
trainer/Q Targets Mean            -29.3806
trainer/Q Targets Std              26.0225
trainer/Q Targets Max              -0.23327
trainer/Q Targets Min             -72.5269
trainer/Log Pis Mean                2.30141
trainer/Log Pis Std                 1.17681
trainer/Log Pis Max                 5.58619
trainer/Log Pis Min                -1.0903
trainer/Policy mu Mean             -0.132299
trainer/Policy mu Std               0.505229
trainer/Policy mu Max               2.38683
trainer/Policy mu Min              -2.91935
trainer/Policy log std Mean        -2.32454
trainer/Policy log std Std          0.424901
trainer/Policy log std Max         -0.553882
trainer/Policy log std Min         -3.06743
trainer/Alpha                       0.0742068
trainer/Alpha Loss                  0.783954
exploration/num steps total    242200
exploration/num paths total      2422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.627813
exploration/Rewards Std             1.18992
exploration/Rewards Max            -0.0100476
exploration/Rewards Min            -9.60753
exploration/Returns Mean          -62.7813
exploration/Returns Std            26.6255
exploration/Returns Max           -18.7246
exploration/Returns Min          -102.242
exploration/Actions Mean           -0.0237041
exploration/Actions Std             0.253093
exploration/Actions Max             0.998191
exploration/Actions Min            -0.99978
exploration/Num Paths               5
exploration/Average Returns       -62.7813
evaluation/num steps total     726000
evaluation/num paths total       7260
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.53776
evaluation/Rewards Std              0.924711
evaluation/Rewards Max             -0.043261
evaluation/Rewards Min             -9.51023
evaluation/Returns Mean           -53.776
evaluation/Returns Std             45.0624
evaluation/Returns Max            -11.3853
evaluation/Returns Min           -146.493
evaluation/Actions Mean            -0.00215095
evaluation/Actions Std              0.174964
evaluation/Actions Max              0.997083
evaluation/Actions Min             -0.99926
evaluation/Num Paths               15
evaluation/Average Returns        -53.776
time/data storing (s)               0.0028041
time/evaluation sampling (s)        0.328258
time/exploration sampling (s)       0.140796
time/logging (s)                    0.00483917
time/saving (s)                     0.00197136
time/training (s)                   1.96644
time/epoch (s)                      2.44511
time/total (s)                   1178.72
Epoch                             483
-----------------------------  ---------------
2019-04-23 00:13:02.029626 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 484 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.466441
trainer/QF2 Loss                    0.5217
trainer/Policy Loss                26.7947
trainer/Q1 Predictions Mean       -24.6991
trainer/Q1 Predictions Std         22.7141
trainer/Q1 Predictions Max         -6.95424
trainer/Q1 Predictions Min        -66.7152
trainer/Q2 Predictions Mean       -24.6676
trainer/Q2 Predictions Std         22.6925
trainer/Q2 Predictions Max         -6.95963
trainer/Q2 Predictions Min        -66.9487
trainer/Q Targets Mean            -25.1419
trainer/Q Targets Std              23.0991
trainer/Q Targets Max              -6.95916
trainer/Q Targets Min             -67.9448
trainer/Log Pis Mean                2.21155
trainer/Log Pis Std                 1.14618
trainer/Log Pis Max                 6.05839
trainer/Log Pis Min                -1.28938
trainer/Policy mu Mean             -0.0697517
trainer/Policy mu Std               0.49457
trainer/Policy mu Max               2.74672
trainer/Policy mu Min              -3.21556
trainer/Policy log std Mean        -2.28311
trainer/Policy log std Std          0.396798
trainer/Policy log std Max         -0.433592
trainer/Policy log std Min         -3.05234
trainer/Alpha                       0.0755663
trainer/Alpha Loss                  0.546369
exploration/num steps total    242700
exploration/num paths total      2427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.559571
exploration/Rewards Std             1.03336
exploration/Rewards Max            -0.0110382
exploration/Rewards Min            -8.79254
exploration/Returns Mean          -55.9571
exploration/Returns Std            27.4542
exploration/Returns Max           -29.6004
exploration/Returns Min          -106.872
exploration/Actions Mean           -0.00761979
exploration/Actions Std             0.230476
exploration/Actions Max             0.9993
exploration/Actions Min            -0.998261
exploration/Num Paths               5
exploration/Average Returns       -55.9571
evaluation/num steps total     727500
evaluation/num paths total       7275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.522767
evaluation/Rewards Std              1.17346
evaluation/Rewards Max             -0.0156128
evaluation/Rewards Min            -10.2796
evaluation/Returns Mean           -52.2767
evaluation/Returns Std             46.2511
evaluation/Returns Max            -10.8262
evaluation/Returns Min           -173.725
evaluation/Actions Mean            -0.00864116
evaluation/Actions Std              0.206462
evaluation/Actions Max              0.999154
evaluation/Actions Min             -0.999453
evaluation/Num Paths               15
evaluation/Average Returns        -52.2767
time/data storing (s)               0.00265537
time/evaluation sampling (s)        0.332033
time/exploration sampling (s)       0.142844
time/logging (s)                    0.00482615
time/saving (s)                     0.00156628
time/training (s)                   1.94654
time/epoch (s)                      2.43047
time/total (s)                   1181.15
Epoch                             484
-----------------------------  ---------------
2019-04-23 00:13:04.527010 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 485 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   37.175
trainer/QF2 Loss                   37.1014
trainer/Policy Loss                30.5268
trainer/Q1 Predictions Mean       -28.6288
trainer/Q1 Predictions Std         24.5104
trainer/Q1 Predictions Max         -7.06879
trainer/Q1 Predictions Min       -104.305
trainer/Q2 Predictions Mean       -28.6082
trainer/Q2 Predictions Std         24.5347
trainer/Q2 Predictions Max         -7.12334
trainer/Q2 Predictions Min       -105.388
trainer/Q Targets Mean            -28.273
trainer/Q Targets Std              24.8729
trainer/Q Targets Max              -0.613332
trainer/Q Targets Min            -106.086
trainer/Log Pis Mean                2.11206
trainer/Log Pis Std                 1.67155
trainer/Log Pis Max                 9.67003
trainer/Log Pis Min                -1.03466
trainer/Policy mu Mean             -0.0553027
trainer/Policy mu Std               0.613734
trainer/Policy mu Max               3.19904
trainer/Policy mu Min              -3.49741
trainer/Policy log std Mean        -2.26407
trainer/Policy log std Std          0.409595
trainer/Policy log std Max         -0.495857
trainer/Policy log std Min         -3.14272
trainer/Alpha                       0.0770056
trainer/Alpha Loss                  0.287301
exploration/num steps total    243200
exploration/num paths total      2432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.746688
exploration/Rewards Std             0.770606
exploration/Rewards Max            -0.00289252
exploration/Rewards Min            -6.98673
exploration/Returns Mean          -74.6688
exploration/Returns Std            39.7843
exploration/Returns Max           -20.0362
exploration/Returns Min          -133.522
exploration/Actions Mean            0.0127489
exploration/Actions Std             0.192256
exploration/Actions Max             0.99754
exploration/Actions Min            -0.92683
exploration/Num Paths               5
exploration/Average Returns       -74.6688
evaluation/num steps total     729000
evaluation/num paths total       7290
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.655003
evaluation/Rewards Std              1.17373
evaluation/Rewards Max             -0.0499986
evaluation/Rewards Min            -10.3533
evaluation/Returns Mean           -65.5003
evaluation/Returns Std             36.9171
evaluation/Returns Max             -9.76852
evaluation/Returns Min           -133.336
evaluation/Actions Mean             0.0166443
evaluation/Actions Std              0.195245
evaluation/Actions Max              0.999251
evaluation/Actions Min             -0.999283
evaluation/Num Paths               15
evaluation/Average Returns        -65.5003
time/data storing (s)               0.00295905
time/evaluation sampling (s)        0.33077
time/exploration sampling (s)       0.140354
time/logging (s)                    0.00483633
time/saving (s)                     0.0019886
time/training (s)                   2.00509
time/epoch (s)                      2.486
time/total (s)                   1183.65
Epoch                             485
-----------------------------  ---------------
2019-04-23 00:13:06.996792 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 486 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.122575
trainer/QF2 Loss                    0.129931
trainer/Policy Loss                25.1081
trainer/Q1 Predictions Mean       -23.4152
trainer/Q1 Predictions Std         22.4758
trainer/Q1 Predictions Max         -6.92666
trainer/Q1 Predictions Min        -69.5051
trainer/Q2 Predictions Mean       -23.4599
trainer/Q2 Predictions Std         22.4973
trainer/Q2 Predictions Max         -6.83513
trainer/Q2 Predictions Min        -69.9162
trainer/Q Targets Mean            -23.4701
trainer/Q Targets Std              22.6145
trainer/Q Targets Max              -6.86993
trainer/Q Targets Min             -69.2837
trainer/Log Pis Mean                1.75031
trainer/Log Pis Std                 1.44607
trainer/Log Pis Max                 9.09987
trainer/Log Pis Min                -5.57054
trainer/Policy mu Mean             -0.0347093
trainer/Policy mu Std               0.512799
trainer/Policy mu Max               2.94161
trainer/Policy mu Min              -2.92924
trainer/Policy log std Mean        -2.17398
trainer/Policy log std Std          0.416117
trainer/Policy log std Max         -0.368091
trainer/Policy log std Min         -3.07547
trainer/Alpha                       0.0772033
trainer/Alpha Loss                 -0.63952
exploration/num steps total    243700
exploration/num paths total      2437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.516156
exploration/Rewards Std             0.761985
exploration/Rewards Max            -0.0112399
exploration/Rewards Min            -7.58042
exploration/Returns Mean          -51.6156
exploration/Returns Std            27.0387
exploration/Returns Max           -23.0712
exploration/Returns Min           -88.9367
exploration/Actions Mean           -0.00830976
exploration/Actions Std             0.22931
exploration/Actions Max             0.984732
exploration/Actions Min            -0.997682
exploration/Num Paths               5
exploration/Average Returns       -51.6156
evaluation/num steps total     730500
evaluation/num paths total       7305
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.659212
evaluation/Rewards Std              0.986674
evaluation/Rewards Max             -0.0275434
evaluation/Rewards Min            -10.6375
evaluation/Returns Mean           -65.9212
evaluation/Returns Std             41.4926
evaluation/Returns Max             -8.7133
evaluation/Returns Min           -127.326
evaluation/Actions Mean             0.00259421
evaluation/Actions Std              0.1778
evaluation/Actions Max              0.998504
evaluation/Actions Min             -0.99914
evaluation/Num Paths               15
evaluation/Average Returns        -65.9212
time/data storing (s)               0.00280101
time/evaluation sampling (s)        0.339146
time/exploration sampling (s)       0.136306
time/logging (s)                    0.00502743
time/saving (s)                     0.00158269
time/training (s)                   1.97388
time/epoch (s)                      2.45875
time/total (s)                   1186.11
Epoch                             486
-----------------------------  ---------------
2019-04-23 00:13:09.443829 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 487 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.42928
trainer/QF2 Loss                    1.45305
trainer/Policy Loss                26.465
trainer/Q1 Predictions Mean       -24.8447
trainer/Q1 Predictions Std         23.5956
trainer/Q1 Predictions Max         -6.69779
trainer/Q1 Predictions Min        -67.4569
trainer/Q2 Predictions Mean       -24.8332
trainer/Q2 Predictions Std         23.6085
trainer/Q2 Predictions Max         -6.64461
trainer/Q2 Predictions Min        -67.8668
trainer/Q Targets Mean            -24.8698
trainer/Q Targets Std              23.8501
trainer/Q Targets Max              -0.060329
trainer/Q Targets Min             -68.4225
trainer/Log Pis Mean                1.69784
trainer/Log Pis Std                 1.21408
trainer/Log Pis Max                 4.7609
trainer/Log Pis Min                -3.11821
trainer/Policy mu Mean             -0.0450547
trainer/Policy mu Std               0.282347
trainer/Policy mu Max               0.915618
trainer/Policy mu Min              -2.53177
trainer/Policy log std Mean        -2.24951
trainer/Policy log std Std          0.320956
trainer/Policy log std Max         -0.671508
trainer/Policy log std Min         -2.97541
trainer/Alpha                       0.0756073
trainer/Alpha Loss                 -0.780206
exploration/num steps total    244200
exploration/num paths total      2442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.349586
exploration/Rewards Std             1.01465
exploration/Rewards Max            -0.00183516
exploration/Rewards Min           -10.109
exploration/Returns Mean          -34.9586
exploration/Returns Std            19.3015
exploration/Returns Max           -13.6553
exploration/Returns Min           -71.3176
exploration/Actions Mean           -0.0282285
exploration/Actions Std             0.215011
exploration/Actions Max             0.939906
exploration/Actions Min            -0.999551
exploration/Num Paths               5
exploration/Average Returns       -34.9586
evaluation/num steps total     732000
evaluation/num paths total       7320
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.515391
evaluation/Rewards Std              0.912454
evaluation/Rewards Max             -0.038549
evaluation/Rewards Min             -9.3627
evaluation/Returns Mean           -51.5391
evaluation/Returns Std             47.6595
evaluation/Returns Max            -10.1165
evaluation/Returns Min           -145.113
evaluation/Actions Mean            -0.000107602
evaluation/Actions Std              0.18163
evaluation/Actions Max              0.99543
evaluation/Actions Min             -0.999004
evaluation/Num Paths               15
evaluation/Average Returns        -51.5391
time/data storing (s)               0.00253736
time/evaluation sampling (s)        0.32776
time/exploration sampling (s)       0.13621
time/logging (s)                    0.00476829
time/saving (s)                     0.00198986
time/training (s)                   1.96225
time/epoch (s)                      2.43552
time/total (s)                   1188.55
Epoch                             487
-----------------------------  ----------------
2019-04-23 00:13:11.897515 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 488 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.13177
trainer/QF2 Loss                    1.13864
trainer/Policy Loss                26.4251
trainer/Q1 Predictions Mean       -24.5491
trainer/Q1 Predictions Std         23.1409
trainer/Q1 Predictions Max         -7.08914
trainer/Q1 Predictions Min        -73.8379
trainer/Q2 Predictions Mean       -24.4963
trainer/Q2 Predictions Std         23.1353
trainer/Q2 Predictions Max         -6.8909
trainer/Q2 Predictions Min        -73.3777
trainer/Q Targets Mean            -24.8188
trainer/Q Targets Std              23.6123
trainer/Q Targets Max              -0.040821
trainer/Q Targets Min             -73.8086
trainer/Log Pis Mean                1.9794
trainer/Log Pis Std                 1.15392
trainer/Log Pis Max                 4.00237
trainer/Log Pis Min                -2.57735
trainer/Policy mu Mean             -0.0656764
trainer/Policy mu Std               0.267879
trainer/Policy mu Max               0.335333
trainer/Policy mu Min              -2.23218
trainer/Policy log std Mean        -2.3333
trainer/Policy log std Std          0.359416
trainer/Policy log std Max         -0.7535
trainer/Policy log std Min         -3.08715
trainer/Alpha                       0.0759818
trainer/Alpha Loss                 -0.0530972
exploration/num steps total    244700
exploration/num paths total      2447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.467605
exploration/Rewards Std             0.983161
exploration/Rewards Max            -0.0081004
exploration/Rewards Min            -8.0891
exploration/Returns Mean          -46.7605
exploration/Returns Std            17.7081
exploration/Returns Max           -25.8373
exploration/Returns Min           -79.4079
exploration/Actions Mean            0.0129615
exploration/Actions Std             0.214065
exploration/Actions Max             0.999746
exploration/Actions Min            -0.998797
exploration/Num Paths               5
exploration/Average Returns       -46.7605
evaluation/num steps total     733500
evaluation/num paths total       7335
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.325877
evaluation/Rewards Std              0.798393
evaluation/Rewards Max             -0.0300172
evaluation/Rewards Min             -8.98738
evaluation/Returns Mean           -32.5877
evaluation/Returns Std             24.8461
evaluation/Returns Max             -7.09299
evaluation/Returns Min            -85.7481
evaluation/Actions Mean            -0.00347842
evaluation/Actions Std              0.171697
evaluation/Actions Max              0.996588
evaluation/Actions Min             -0.998784
evaluation/Num Paths               15
evaluation/Average Returns        -32.5877
time/data storing (s)               0.00269668
time/evaluation sampling (s)        0.328834
time/exploration sampling (s)       0.136181
time/logging (s)                    0.00502351
time/saving (s)                     0.00206867
time/training (s)                   1.96767
time/epoch (s)                      2.44248
time/total (s)                   1191
Epoch                             488
-----------------------------  ---------------
2019-04-23 00:13:14.328861 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 489 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.53088
trainer/QF2 Loss                    1.52288
trainer/Policy Loss                28.8328
trainer/Q1 Predictions Mean       -26.8419
trainer/Q1 Predictions Std         23.5542
trainer/Q1 Predictions Max         -6.94485
trainer/Q1 Predictions Min        -74.6866
trainer/Q2 Predictions Mean       -26.8341
trainer/Q2 Predictions Std         23.5799
trainer/Q2 Predictions Max         -6.89974
trainer/Q2 Predictions Min        -75.5554
trainer/Q Targets Mean            -27.0286
trainer/Q Targets Std              24.0275
trainer/Q Targets Max              -0.0633038
trainer/Q Targets Min             -75.7487
trainer/Log Pis Mean                2.15264
trainer/Log Pis Std                 1.26582
trainer/Log Pis Max                 4.92998
trainer/Log Pis Min                -5.12471
trainer/Policy mu Mean             -0.0865657
trainer/Policy mu Std               0.518923
trainer/Policy mu Max               2.51949
trainer/Policy mu Min              -2.92382
trainer/Policy log std Mean        -2.31138
trainer/Policy log std Std          0.448297
trainer/Policy log std Max         -0.521402
trainer/Policy log std Min         -3.0761
trainer/Alpha                       0.0766895
trainer/Alpha Loss                  0.392008
exploration/num steps total    245200
exploration/num paths total      2452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.56624
exploration/Rewards Std             1.13104
exploration/Rewards Max            -0.010752
exploration/Rewards Min           -10.43
exploration/Returns Mean          -56.624
exploration/Returns Std            48.8674
exploration/Returns Max           -16.7378
exploration/Returns Min          -147.097
exploration/Actions Mean            0.00775105
exploration/Actions Std             0.221456
exploration/Actions Max             0.99822
exploration/Actions Min            -0.999291
exploration/Num Paths               5
exploration/Average Returns       -56.624
evaluation/num steps total     735000
evaluation/num paths total       7350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.662914
evaluation/Rewards Std              1.05539
evaluation/Rewards Max             -0.0259615
evaluation/Rewards Min            -10.0832
evaluation/Returns Mean           -66.2914
evaluation/Returns Std             46.6761
evaluation/Returns Max             -6.98253
evaluation/Returns Min           -160.033
evaluation/Actions Mean            -0.00167416
evaluation/Actions Std              0.173576
evaluation/Actions Max              0.998593
evaluation/Actions Min             -0.999321
evaluation/Num Paths               15
evaluation/Average Returns        -66.2914
time/data storing (s)               0.0027197
time/evaluation sampling (s)        0.325732
time/exploration sampling (s)       0.136986
time/logging (s)                    0.00475156
time/saving (s)                     0.002012
time/training (s)                   1.94546
time/epoch (s)                      2.41766
time/total (s)                   1193.42
Epoch                             489
-----------------------------  ---------------
2019-04-23 00:13:16.771409 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 490 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.79256
trainer/QF2 Loss                    1.74546
trainer/Policy Loss                21.2341
trainer/Q1 Predictions Mean       -19.4746
trainer/Q1 Predictions Std         20.0493
trainer/Q1 Predictions Max         -6.93475
trainer/Q1 Predictions Min        -66.1153
trainer/Q2 Predictions Mean       -19.479
trainer/Q2 Predictions Std         20.0907
trainer/Q2 Predictions Max         -6.85286
trainer/Q2 Predictions Min        -66.8735
trainer/Q Targets Mean            -19.5207
trainer/Q Targets Std              20.3501
trainer/Q Targets Max              -0.519115
trainer/Q Targets Min             -67.6167
trainer/Log Pis Mean                1.84943
trainer/Log Pis Std                 1.31929
trainer/Log Pis Max                 5.86533
trainer/Log Pis Min                -2.6981
trainer/Policy mu Mean             -0.063955
trainer/Policy mu Std               0.371112
trainer/Policy mu Max               2.05845
trainer/Policy mu Min              -2.25358
trainer/Policy log std Mean        -2.22665
trainer/Policy log std Std          0.37359
trainer/Policy log std Max         -0.495074
trainer/Policy log std Min         -2.99959
trainer/Alpha                       0.0777685
trainer/Alpha Loss                 -0.384546
exploration/num steps total    245700
exploration/num paths total      2457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.550498
exploration/Rewards Std             0.687717
exploration/Rewards Max            -0.00951322
exploration/Rewards Min            -7.19448
exploration/Returns Mean          -55.0498
exploration/Returns Std            42.3766
exploration/Returns Max           -16.3986
exploration/Returns Min          -114.947
exploration/Actions Mean            0.00279192
exploration/Actions Std             0.186757
exploration/Actions Max             0.987937
exploration/Actions Min            -0.998644
exploration/Num Paths               5
exploration/Average Returns       -55.0498
evaluation/num steps total     736500
evaluation/num paths total       7365
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.545478
evaluation/Rewards Std              1.00076
evaluation/Rewards Max             -0.022015
evaluation/Rewards Min             -9.98547
evaluation/Returns Mean           -54.5478
evaluation/Returns Std             45.5449
evaluation/Returns Max             -4.46131
evaluation/Returns Min           -145.387
evaluation/Actions Mean             0.0167516
evaluation/Actions Std              0.182262
evaluation/Actions Max              0.998673
evaluation/Actions Min             -0.99918
evaluation/Num Paths               15
evaluation/Average Returns        -54.5478
time/data storing (s)               0.00258518
time/evaluation sampling (s)        0.325525
time/exploration sampling (s)       0.140257
time/logging (s)                    0.00370887
time/saving (s)                     0.00197288
time/training (s)                   1.95571
time/epoch (s)                      2.42976
time/total (s)                   1195.85
Epoch                             490
-----------------------------  ---------------
2019-04-23 00:13:19.220942 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 491 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    2.21829
trainer/QF2 Loss                    2.1314
trainer/Policy Loss                29.4923
trainer/Q1 Predictions Mean       -27.4785
trainer/Q1 Predictions Std         25.0188
trainer/Q1 Predictions Max         -6.70207
trainer/Q1 Predictions Min        -77.9201
trainer/Q2 Predictions Mean       -27.5481
trainer/Q2 Predictions Std         25.0472
trainer/Q2 Predictions Max         -6.86236
trainer/Q2 Predictions Min        -78.1253
trainer/Q Targets Mean            -27.6728
trainer/Q Targets Std              25.4108
trainer/Q Targets Max              -0.279927
trainer/Q Targets Min             -78.0261
trainer/Log Pis Mean                2.02487
trainer/Log Pis Std                 1.22407
trainer/Log Pis Max                 6.43611
trainer/Log Pis Min                -1.44854
trainer/Policy mu Mean             -0.0566128
trainer/Policy mu Std               0.532633
trainer/Policy mu Max               2.87867
trainer/Policy mu Min              -2.71519
trainer/Policy log std Mean        -2.22327
trainer/Policy log std Std          0.411886
trainer/Policy log std Max         -0.673816
trainer/Policy log std Min         -2.9099
trainer/Alpha                       0.0800918
trainer/Alpha Loss                  0.0627885
exploration/num steps total    246200
exploration/num paths total      2462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.398875
exploration/Rewards Std             0.779044
exploration/Rewards Max            -0.00276404
exploration/Rewards Min            -6.29515
exploration/Returns Mean          -39.8875
exploration/Returns Std            18.3539
exploration/Returns Max           -21.4492
exploration/Returns Min           -75.1613
exploration/Actions Mean            0.0153907
exploration/Actions Std             0.232962
exploration/Actions Max             0.998945
exploration/Actions Min            -0.990886
exploration/Num Paths               5
exploration/Average Returns       -39.8875
evaluation/num steps total     738000
evaluation/num paths total       7380
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.361486
evaluation/Rewards Std              1.12648
evaluation/Rewards Max             -0.010791
evaluation/Rewards Min            -10.2017
evaluation/Returns Mean           -36.1486
evaluation/Returns Std             24.4089
evaluation/Returns Max             -3.52987
evaluation/Returns Min            -98.1553
evaluation/Actions Mean             0.00249153
evaluation/Actions Std              0.197914
evaluation/Actions Max              0.999163
evaluation/Actions Min             -0.999567
evaluation/Num Paths               15
evaluation/Average Returns        -36.1486
time/data storing (s)               0.00293846
time/evaluation sampling (s)        0.332989
time/exploration sampling (s)       0.139854
time/logging (s)                    0.00478213
time/saving (s)                     0.00196535
time/training (s)                   1.95672
time/epoch (s)                      2.43925
time/total (s)                   1198.3
Epoch                             491
-----------------------------  ---------------
2019-04-23 00:13:21.663571 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 492 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                   14.9089
trainer/QF2 Loss                   15.0421
trainer/Policy Loss                24.247
trainer/Q1 Predictions Mean       -22.5251
trainer/Q1 Predictions Std         22.1969
trainer/Q1 Predictions Max         -7.01437
trainer/Q1 Predictions Min        -66.2378
trainer/Q2 Predictions Mean       -22.5603
trainer/Q2 Predictions Std         22.1873
trainer/Q2 Predictions Max         -7.09125
trainer/Q2 Predictions Min        -66.2527
trainer/Q Targets Mean            -22.3167
trainer/Q Targets Std              22.3241
trainer/Q Targets Max              -0.818421
trainer/Q Targets Min             -66.4023
trainer/Log Pis Mean                1.78858
trainer/Log Pis Std                 1.33927
trainer/Log Pis Max                 5.43332
trainer/Log Pis Min                -3.61673
trainer/Policy mu Mean             -0.0607572
trainer/Policy mu Std               0.2907
trainer/Policy mu Max               2.07316
trainer/Policy mu Min              -2.21134
trainer/Policy log std Mean        -2.29475
trainer/Policy log std Std          0.314035
trainer/Policy log std Max         -0.784647
trainer/Policy log std Min         -3.08886
trainer/Alpha                       0.0800381
trainer/Alpha Loss                 -0.533917
exploration/num steps total    246700
exploration/num paths total      2467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.791011
exploration/Rewards Std             1.29252
exploration/Rewards Max            -0.0186704
exploration/Rewards Min            -9.06791
exploration/Returns Mean          -79.1011
exploration/Returns Std            46.7909
exploration/Returns Max           -29.4515
exploration/Returns Min          -163.48
exploration/Actions Mean            0.016647
exploration/Actions Std             0.260675
exploration/Actions Max             0.999984
exploration/Actions Min            -0.997161
exploration/Num Paths               5
exploration/Average Returns       -79.1011
evaluation/num steps total     739500
evaluation/num paths total       7395
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.356191
evaluation/Rewards Std              0.838471
evaluation/Rewards Max             -0.0132617
evaluation/Rewards Min             -9.73627
evaluation/Returns Mean           -35.6191
evaluation/Returns Std             38.2247
evaluation/Returns Max             -3.80514
evaluation/Returns Min           -135.555
evaluation/Actions Mean            -0.0017299
evaluation/Actions Std              0.156537
evaluation/Actions Max              0.993894
evaluation/Actions Min             -0.99915
evaluation/Num Paths               15
evaluation/Average Returns        -35.6191
time/data storing (s)               0.00272827
time/evaluation sampling (s)        0.330191
time/exploration sampling (s)       0.13664
time/logging (s)                    0.00481016
time/saving (s)                     0.00199462
time/training (s)                   1.95628
time/epoch (s)                      2.43265
time/total (s)                   1200.73
Epoch                             492
-----------------------------  ---------------
2019-04-23 00:13:24.119441 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 493 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.061151
trainer/QF2 Loss                    0.0499085
trainer/Policy Loss                26.7547
trainer/Q1 Predictions Mean       -25.0121
trainer/Q1 Predictions Std         23.6455
trainer/Q1 Predictions Max         -7.19855
trainer/Q1 Predictions Min        -65.9844
trainer/Q2 Predictions Mean       -24.9715
trainer/Q2 Predictions Std         23.6513
trainer/Q2 Predictions Max         -7.05773
trainer/Q2 Predictions Min        -65.6591
trainer/Q Targets Mean            -25.0339
trainer/Q Targets Std              23.7182
trainer/Q Targets Max              -7.12764
trainer/Q Targets Min             -66.3201
trainer/Log Pis Mean                1.86438
trainer/Log Pis Std                 1.06126
trainer/Log Pis Max                 3.68079
trainer/Log Pis Min                -2.07639
trainer/Policy mu Mean             -0.0674858
trainer/Policy mu Std               0.351749
trainer/Policy mu Max               2.61963
trainer/Policy mu Min              -1.80111
trainer/Policy log std Mean        -2.30864
trainer/Policy log std Std          0.321836
trainer/Policy log std Max         -0.443051
trainer/Policy log std Min         -2.92011
trainer/Alpha                       0.0774629
trainer/Alpha Loss                 -0.346918
exploration/num steps total    247200
exploration/num paths total      2472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.82333
exploration/Rewards Std             1.00623
exploration/Rewards Max            -0.0204841
exploration/Rewards Min            -7.76723
exploration/Returns Mean          -82.333
exploration/Returns Std            33.0552
exploration/Returns Max           -42.8616
exploration/Returns Min          -119.551
exploration/Actions Mean           -0.00120718
exploration/Actions Std             0.217689
exploration/Actions Max             0.998992
exploration/Actions Min            -0.996628
exploration/Num Paths               5
exploration/Average Returns       -82.333
evaluation/num steps total     741000
evaluation/num paths total       7410
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.444513
evaluation/Rewards Std              1.05724
evaluation/Rewards Max             -0.0211532
evaluation/Rewards Min            -10.2608
evaluation/Returns Mean           -44.4513
evaluation/Returns Std             27.7634
evaluation/Returns Max            -12.9826
evaluation/Returns Min           -101.484
evaluation/Actions Mean            -0.0057709
evaluation/Actions Std              0.199996
evaluation/Actions Max              0.997596
evaluation/Actions Min             -0.999482
evaluation/Num Paths               15
evaluation/Average Returns        -44.4513
time/data storing (s)               0.00265819
time/evaluation sampling (s)        0.32634
time/exploration sampling (s)       0.137988
time/logging (s)                    0.00481746
time/saving (s)                     0.00197849
time/training (s)                   1.97054
time/epoch (s)                      2.44432
time/total (s)                   1203.18
Epoch                             493
-----------------------------  ---------------
2019-04-23 00:13:26.581532 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 494 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.214221
trainer/QF2 Loss                    0.18426
trainer/Policy Loss                29.3466
trainer/Q1 Predictions Mean       -27.3729
trainer/Q1 Predictions Std         23.8597
trainer/Q1 Predictions Max         -7.04103
trainer/Q1 Predictions Min        -66.1863
trainer/Q2 Predictions Mean       -27.3554
trainer/Q2 Predictions Std         23.8841
trainer/Q2 Predictions Max         -7.01756
trainer/Q2 Predictions Min        -66.3541
trainer/Q Targets Mean            -27.698
trainer/Q Targets Std              24.0723
trainer/Q Targets Max              -7.17822
trainer/Q Targets Min             -67.1629
trainer/Log Pis Mean                2.12845
trainer/Log Pis Std                 1.19058
trainer/Log Pis Max                 7.29617
trainer/Log Pis Min                -1.31248
trainer/Policy mu Mean             -0.0743139
trainer/Policy mu Std               0.511356
trainer/Policy mu Max               2.86862
trainer/Policy mu Min              -3.32974
trainer/Policy log std Mean        -2.24831
trainer/Policy log std Std          0.389167
trainer/Policy log std Max         -0.570379
trainer/Policy log std Min         -2.90924
trainer/Alpha                       0.0786394
trainer/Alpha Loss                  0.326649
exploration/num steps total    247700
exploration/num paths total      2477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.238804
exploration/Rewards Std             0.621766
exploration/Rewards Max            -0.00937683
exploration/Rewards Min            -6.34506
exploration/Returns Mean          -23.8804
exploration/Returns Std            11.8012
exploration/Returns Max           -12.4256
exploration/Returns Min           -38.5051
exploration/Actions Mean           -0.0246547
exploration/Actions Std             0.188683
exploration/Actions Max             0.733058
exploration/Actions Min            -0.999552
exploration/Num Paths               5
exploration/Average Returns       -23.8804
evaluation/num steps total     742500
evaluation/num paths total       7425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.65921
evaluation/Rewards Std              1.02617
evaluation/Rewards Max             -0.0246939
evaluation/Rewards Min            -10.0945
evaluation/Returns Mean           -65.921
evaluation/Returns Std             54.3148
evaluation/Returns Max             -3.81982
evaluation/Returns Min           -167.727
evaluation/Actions Mean            -0.00224235
evaluation/Actions Std              0.17962
evaluation/Actions Max              0.996976
evaluation/Actions Min             -0.999326
evaluation/Num Paths               15
evaluation/Average Returns        -65.921
time/data storing (s)               0.00286711
time/evaluation sampling (s)        0.33001
time/exploration sampling (s)       0.137002
time/logging (s)                    0.00481732
time/saving (s)                     0.00201257
time/training (s)                   1.97383
time/epoch (s)                      2.45054
time/total (s)                   1205.64
Epoch                             494
-----------------------------  ---------------
2019-04-23 00:13:29.031152 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 495 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.296386
trainer/QF2 Loss                    0.268594
trainer/Policy Loss                22.6008
trainer/Q1 Predictions Mean       -20.7428
trainer/Q1 Predictions Std         20.3045
trainer/Q1 Predictions Max         -7.04033
trainer/Q1 Predictions Min        -69.1667
trainer/Q2 Predictions Mean       -20.7626
trainer/Q2 Predictions Std         20.3493
trainer/Q2 Predictions Max         -7.03718
trainer/Q2 Predictions Min        -69.9223
trainer/Q Targets Mean            -21.1157
trainer/Q Targets Std              20.5867
trainer/Q Targets Max              -6.95115
trainer/Q Targets Min             -69.9139
trainer/Log Pis Mean                1.86684
trainer/Log Pis Std                 1.503
trainer/Log Pis Max                 8.65676
trainer/Log Pis Min                -1.84505
trainer/Policy mu Mean             -0.0396292
trainer/Policy mu Std               0.620142
trainer/Policy mu Max               3.54377
trainer/Policy mu Min              -2.82989
trainer/Policy log std Mean        -2.19728
trainer/Policy log std Std          0.42314
trainer/Policy log std Max         -0.557519
trainer/Policy log std Min         -2.98566
trainer/Alpha                       0.0770884
trainer/Alpha Loss                 -0.341252
exploration/num steps total    248200
exploration/num paths total      2482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.483333
exploration/Rewards Std             0.583237
exploration/Rewards Max            -0.0202507
exploration/Rewards Min            -4.78744
exploration/Returns Mean          -48.3333
exploration/Returns Std            40.8005
exploration/Returns Max           -16.8252
exploration/Returns Min          -128.799
exploration/Actions Mean           -0.000602387
exploration/Actions Std             0.199999
exploration/Actions Max             0.986407
exploration/Actions Min            -0.997272
exploration/Num Paths               5
exploration/Average Returns       -48.3333
evaluation/num steps total     744000
evaluation/num paths total       7440
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.512631
evaluation/Rewards Std              1.16643
evaluation/Rewards Max             -0.0276652
evaluation/Rewards Min            -11.7086
evaluation/Returns Mean           -51.2631
evaluation/Returns Std             37.6558
evaluation/Returns Max             -3.81638
evaluation/Returns Min           -140.627
evaluation/Actions Mean            -0.00963947
evaluation/Actions Std              0.187217
evaluation/Actions Max              0.997697
evaluation/Actions Min             -0.999689
evaluation/Num Paths               15
evaluation/Average Returns        -51.2631
time/data storing (s)               0.0026537
time/evaluation sampling (s)        0.324652
time/exploration sampling (s)       0.137185
time/logging (s)                    0.00477995
time/saving (s)                     0.00157907
time/training (s)                   1.96719
time/epoch (s)                      2.43804
time/total (s)                   1208.08
Epoch                             495
-----------------------------  ----------------
2019-04-23 00:13:31.482518 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 496 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                    0.160231
trainer/QF2 Loss                    0.190773
trainer/Policy Loss                24.6226
trainer/Q1 Predictions Mean       -22.6855
trainer/Q1 Predictions Std         22.432
trainer/Q1 Predictions Max         -6.696
trainer/Q1 Predictions Min        -86.6179
trainer/Q2 Predictions Mean       -22.6441
trainer/Q2 Predictions Std         22.4044
trainer/Q2 Predictions Max         -6.68312
trainer/Q2 Predictions Min        -85.6347
trainer/Q Targets Mean            -22.9542
trainer/Q Targets Std              22.6158
trainer/Q Targets Max              -6.92684
trainer/Q Targets Min             -86.3858
trainer/Log Pis Mean                2.02874
trainer/Log Pis Std                 1.25706
trainer/Log Pis Max                 7.64142
trainer/Log Pis Min                -4.14581
trainer/Policy mu Mean             -0.0320889
trainer/Policy mu Std               0.440951
trainer/Policy mu Max               2.75147
trainer/Policy mu Min              -3.38947
trainer/Policy log std Mean        -2.29356
trainer/Policy log std Std          0.376501
trainer/Policy log std Max         -0.251667
trainer/Policy log std Min         -3.09618
trainer/Alpha                       0.0793806
trainer/Alpha Loss                  0.0728217
exploration/num steps total    248700
exploration/num paths total      2487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.306396
exploration/Rewards Std             0.800395
exploration/Rewards Max            -0.00444318
exploration/Rewards Min            -8.57901
exploration/Returns Mean          -30.6396
exploration/Returns Std            10.0008
exploration/Returns Max           -19.1772
exploration/Returns Min           -49.2895
exploration/Actions Mean           -0.0111676
exploration/Actions Std             0.225627
exploration/Actions Max             0.997175
exploration/Actions Min            -0.999132
exploration/Num Paths               5
exploration/Average Returns       -30.6396
evaluation/num steps total     745500
evaluation/num paths total       7455
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.478472
evaluation/Rewards Std              0.922625
evaluation/Rewards Max             -0.0104819
evaluation/Rewards Min             -8.82268
evaluation/Returns Mean           -47.8472
evaluation/Returns Std             48.5023
evaluation/Returns Max             -5.93968
evaluation/Returns Min           -153.896
evaluation/Actions Mean             0.00194409
evaluation/Actions Std              0.183344
evaluation/Actions Max              0.995105
evaluation/Actions Min             -0.996813
evaluation/Num Paths               15
evaluation/Average Returns        -47.8472
time/data storing (s)               0.00269835
time/evaluation sampling (s)        0.326837
time/exploration sampling (s)       0.138537
time/logging (s)                    0.00478636
time/saving (s)                     0.00196088
time/training (s)                   1.9648
time/epoch (s)                      2.43962
time/total (s)                   1210.52
Epoch                             496
-----------------------------  ---------------
2019-04-23 00:13:33.923401 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 497 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.88257
trainer/QF2 Loss                    1.85971
trainer/Policy Loss                27.7098
trainer/Q1 Predictions Mean       -25.8107
trainer/Q1 Predictions Std         21.8684
trainer/Q1 Predictions Max         -6.99223
trainer/Q1 Predictions Min        -65.5282
trainer/Q2 Predictions Mean       -25.8027
trainer/Q2 Predictions Std         21.9004
trainer/Q2 Predictions Max         -6.85055
trainer/Q2 Predictions Min        -65.4977
trainer/Q Targets Mean            -25.9006
trainer/Q Targets Std              22.164
trainer/Q Targets Max              -0.259831
trainer/Q Targets Min             -65.9875
trainer/Log Pis Mean                2.01276
trainer/Log Pis Std                 1.24159
trainer/Log Pis Max                 5.3092
trainer/Log Pis Min                -2.85289
trainer/Policy mu Mean             -0.0774421
trainer/Policy mu Std               0.276807
trainer/Policy mu Max               0.618946
trainer/Policy mu Min              -2.74463
trainer/Policy log std Mean        -2.3414
trainer/Policy log std Std          0.307882
trainer/Policy log std Max         -0.841175
trainer/Policy log std Min         -3.03791
trainer/Alpha                       0.0792037
trainer/Alpha Loss                  0.0323529
exploration/num steps total    249200
exploration/num paths total      2492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.334039
exploration/Rewards Std             0.944615
exploration/Rewards Max            -0.0110989
exploration/Rewards Min            -9.51691
exploration/Returns Mean          -33.4039
exploration/Returns Std            19.9498
exploration/Returns Max           -15.8352
exploration/Returns Min           -65.2529
exploration/Actions Mean           -0.00612485
exploration/Actions Std             0.216969
exploration/Actions Max             0.995652
exploration/Actions Min            -0.997798
exploration/Num Paths               5
exploration/Average Returns       -33.4039
evaluation/num steps total     747000
evaluation/num paths total       7470
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.510499
evaluation/Rewards Std              1.01366
evaluation/Rewards Max             -0.0322949
evaluation/Rewards Min            -10.6788
evaluation/Returns Mean           -51.0499
evaluation/Returns Std             48.0222
evaluation/Returns Max            -11.8968
evaluation/Returns Min           -147.908
evaluation/Actions Mean            -0.000178243
evaluation/Actions Std              0.18415
evaluation/Actions Max              0.996339
evaluation/Actions Min             -0.999061
evaluation/Num Paths               15
evaluation/Average Returns        -51.0499
time/data storing (s)               0.00283869
time/evaluation sampling (s)        0.321883
time/exploration sampling (s)       0.137863
time/logging (s)                    0.00476962
time/saving (s)                     0.00197923
time/training (s)                   1.95981
time/epoch (s)                      2.42914
time/total (s)                   1212.96
Epoch                             497
-----------------------------  ----------------
2019-04-23 00:13:36.357614 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 498 finished
-----------------------------  ---------------
replay_buffer/size             100000
trainer/QF1 Loss                  104.978
trainer/QF2 Loss                  104.872
trainer/Policy Loss                23.3261
trainer/Q1 Predictions Mean       -21.5127
trainer/Q1 Predictions Std         21.1653
trainer/Q1 Predictions Max         -6.78835
trainer/Q1 Predictions Min        -65.7387
trainer/Q2 Predictions Mean       -21.4882
trainer/Q2 Predictions Std         21.2097
trainer/Q2 Predictions Max         -6.6202
trainer/Q2 Predictions Min        -65.8992
trainer/Q Targets Mean            -19.7533
trainer/Q Targets Std              20.5739
trainer/Q Targets Max              -0.917043
trainer/Q Targets Min             -66.0863
trainer/Log Pis Mean                1.91251
trainer/Log Pis Std                 1.12948
trainer/Log Pis Max                 6.43977
trainer/Log Pis Min                -1.66037
trainer/Policy mu Mean             -0.0682229
trainer/Policy mu Std               0.435368
trainer/Policy mu Max               2.70514
trainer/Policy mu Min              -3.05206
trainer/Policy log std Mean        -2.22772
trainer/Policy log std Std          0.3784
trainer/Policy log std Max         -0.643775
trainer/Policy log std Min         -3.05041
trainer/Alpha                       0.0756212
trainer/Alpha Loss                 -0.225909
exploration/num steps total    249700
exploration/num paths total      2497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.741528
exploration/Rewards Std             0.994926
exploration/Rewards Max            -0.00858769
exploration/Rewards Min            -8.06165
exploration/Returns Mean          -74.1528
exploration/Returns Std            69.9903
exploration/Returns Max           -16.4306
exploration/Returns Min          -162.513
exploration/Actions Mean            0.0143338
exploration/Actions Std             0.191254
exploration/Actions Max             0.99812
exploration/Actions Min            -0.981024
exploration/Num Paths               5
exploration/Average Returns       -74.1528
evaluation/num steps total     748500
evaluation/num paths total       7485
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.628996
evaluation/Rewards Std              1.00844
evaluation/Rewards Max             -0.00345268
evaluation/Rewards Min             -9.11864
evaluation/Returns Mean           -62.8996
evaluation/Returns Std             48.4346
evaluation/Returns Max             -8.01107
evaluation/Returns Min           -157.657
evaluation/Actions Mean             0.00610661
evaluation/Actions Std              0.18566
evaluation/Actions Max              0.998677
evaluation/Actions Min             -0.997831
evaluation/Num Paths               15
evaluation/Average Returns        -62.8996
time/data storing (s)               0.00268144
time/evaluation sampling (s)        0.323653
time/exploration sampling (s)       0.140855
time/logging (s)                    0.00393194
time/saving (s)                     0.00200189
time/training (s)                   1.94869
time/epoch (s)                      2.42181
time/total (s)                   1215.38
Epoch                             498
-----------------------------  ---------------
2019-04-23 00:13:38.779774 PDT | [sac-pointmass-multitask-10_2019_04_22_23_53_19_0000--s-0] Epoch 499 finished
-----------------------------  ----------------
replay_buffer/size             100000
trainer/QF1 Loss                    1.00809
trainer/QF2 Loss                    1.02437
trainer/Policy Loss                23.6678
trainer/Q1 Predictions Mean       -21.7702
trainer/Q1 Predictions Std         20.6327
trainer/Q1 Predictions Max         -6.83401
trainer/Q1 Predictions Min        -65.0148
trainer/Q2 Predictions Mean       -21.7866
trainer/Q2 Predictions Std         20.6298
trainer/Q2 Predictions Max         -6.82932
trainer/Q2 Predictions Min        -65.17
trainer/Q Targets Mean            -22.0192
trainer/Q Targets Std              21.0117
trainer/Q Targets Max              -0.192216
trainer/Q Targets Min             -66.2033
trainer/Log Pis Mean                2.04337
trainer/Log Pis Std                 1.06719
trainer/Log Pis Max                 3.9482
trainer/Log Pis Min                -2.59052
trainer/Policy mu Mean             -0.0531546
trainer/Policy mu Std               0.364628
trainer/Policy mu Max               2.87726
trainer/Policy mu Min              -2.54669
trainer/Policy log std Mean        -2.32221
trainer/Policy log std Std          0.374011
trainer/Policy log std Max         -0.805036
trainer/Policy log std Min         -3.08886
trainer/Alpha                       0.0736703
trainer/Alpha Loss                  0.113111
exploration/num steps total    250200
exploration/num paths total      2502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.5342
exploration/Rewards Std             0.955775
exploration/Rewards Max            -0.0084753
exploration/Rewards Min            -9.88484
exploration/Returns Mean          -53.42
exploration/Returns Std            30.4941
exploration/Returns Max           -14.1389
exploration/Returns Min           -97.2171
exploration/Actions Mean           -0.0250986
exploration/Actions Std             0.199997
exploration/Actions Max             0.951563
exploration/Actions Min            -0.999639
exploration/Num Paths               5
exploration/Average Returns       -53.42
evaluation/num steps total     750000
evaluation/num paths total       7500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.450192
evaluation/Rewards Std              0.904039
evaluation/Rewards Max             -0.0131215
evaluation/Rewards Min             -8.71194
evaluation/Returns Mean           -45.0192
evaluation/Returns Std             32.0873
evaluation/Returns Max             -6.25232
evaluation/Returns Min           -138.633
evaluation/Actions Mean            -0.000191064
evaluation/Actions Std              0.182482
evaluation/Actions Max              0.998487
evaluation/Actions Min             -0.997825
evaluation/Num Paths               15
evaluation/Average Returns        -45.0192
time/data storing (s)               0.00275025
time/evaluation sampling (s)        0.31987
time/exploration sampling (s)       0.139551
time/logging (s)                    0.00484459
time/saving (s)                     0.00197873
time/training (s)                   1.94246
time/epoch (s)                      2.41146
time/total (s)                   1217.8
Epoch                             499
-----------------------------  ----------------
