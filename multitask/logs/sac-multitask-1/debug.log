2019-04-22 21:08:49.531189 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 0 finished
-----------------------------  ---------------
replay_buffer/size               700
trainer/QF1 Loss                  70.022
trainer/QF2 Loss                  69.984
trainer/Policy Loss               -1.35746
trainer/Q1 Predictions Mean       -0.00218727
trainer/Q1 Predictions Std         0.00232397
trainer/Q1 Predictions Max         0.00278423
trainer/Q1 Predictions Min        -0.00521529
trainer/Q2 Predictions Mean       -0.00454346
trainer/Q2 Predictions Std         0.000727193
trainer/Q2 Predictions Max        -0.00275182
trainer/Q2 Predictions Min        -0.00579494
trainer/Q Targets Mean            -7.76658
trainer/Q Targets Std              3.12005
trainer/Q Targets Max             -0.874379
trainer/Q Targets Min            -12.8133
trainer/Log Pis Mean              -1.36199
trainer/Log Pis Std                0.317914
trainer/Log Pis Max               -0.555221
trainer/Log Pis Min               -1.81802
trainer/Policy mu Mean            -0.000502811
trainer/Policy mu Std              0.00102811
trainer/Policy mu Max              0.00138064
trainer/Policy mu Min             -0.00199294
trainer/Policy log std Mean       -0.00037321
trainer/Policy log std Std         0.00129357
trainer/Policy log std Max         0.00181302
trainer/Policy log std Min        -0.00249422
trainer/Alpha                      0.9997
trainer/Alpha Loss                -0
exploration/num steps total      700
exploration/num paths total        7
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -6.51324
exploration/Rewards Std            2.90475
exploration/Rewards Max           -0.442465
exploration/Rewards Min          -12.6589
exploration/Returns Mean        -651.324
exploration/Returns Std          201.267
exploration/Returns Max         -439.979
exploration/Returns Min         -974.1
exploration/Actions Mean           0.00192077
exploration/Actions Std            0.630284
exploration/Actions Max            0.998429
exploration/Actions Min           -0.998467
exploration/Num Paths              5
exploration/Average Returns     -651.324
evaluation/num steps total      2500
evaluation/num paths total        25
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -6.12263
evaluation/Rewards Std             3.20958
evaluation/Rewards Max            -0.405164
evaluation/Rewards Min           -12.4574
evaluation/Returns Mean         -612.263
evaluation/Returns Std           320.938
evaluation/Returns Max           -48.1342
evaluation/Returns Min         -1243.39
evaluation/Actions Mean           -0.000636515
evaluation/Actions Std             0.00102742
evaluation/Actions Max             0.00135983
evaluation/Actions Min            -0.00219886
evaluation/Num Paths              25
evaluation/Average Returns      -612.263
time/data storing (s)              0.00292137
time/evaluation sampling (s)       0.470714
time/exploration sampling (s)      0.140706
time/logging (s)                   0.00671023
time/saving (s)                    0.00234065
time/training (s)                  1.92337
time/epoch (s)                     2.54676
time/total (s)                     2.81017
Epoch                              0
-----------------------------  ---------------
2019-04-22 21:08:52.143457 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 1 finished
-----------------------------  -------------
replay_buffer/size             1200
trainer/QF1 Loss                  0.906485
trainer/QF2 Loss                  1.56726
trainer/Policy Loss              10.5946
trainer/Q1 Predictions Mean     -12.0999
trainer/Q1 Predictions Std        5.83341
trainer/Q1 Predictions Max       -4.40676
trainer/Q1 Predictions Min      -25.5929
trainer/Q2 Predictions Mean     -11.8273
trainer/Q2 Predictions Std        6.08054
trainer/Q2 Predictions Max       -3.84235
trainer/Q2 Predictions Min      -25.8442
trainer/Q Targets Mean          -12.5056
trainer/Q Targets Std             5.71087
trainer/Q Targets Max            -3.67385
trainer/Q Targets Min           -25.8021
trainer/Log Pis Mean             -0.959006
trainer/Log Pis Std               0.823809
trainer/Log Pis Max               0.68145
trainer/Log Pis Min              -4.5507
trainer/Policy mu Mean            0.39094
trainer/Policy mu Std             0.307265
trainer/Policy mu Max             0.858419
trainer/Policy mu Min            -0.409351
trainer/Policy log std Mean      -0.230612
trainer/Policy log std Std        0.036751
trainer/Policy log std Max       -0.170374
trainer/Policy log std Min       -0.32232
trainer/Alpha                     0.863432
trainer/Alpha Loss               -0.433675
exploration/num steps total    1200
exploration/num paths total      12
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -3.34776
exploration/Rewards Std           1.64431
exploration/Rewards Max          -0.0415461
exploration/Rewards Min         -10.0418
exploration/Returns Mean       -334.776
exploration/Returns Std          68.1772
exploration/Returns Max        -245.595
exploration/Returns Min        -448.166
exploration/Actions Mean          0.213832
exploration/Actions Std           0.540073
exploration/Actions Max           0.990133
exploration/Actions Min          -0.992221
exploration/Num Paths             5
exploration/Average Returns    -334.776
evaluation/num steps total     5000
evaluation/num paths total       50
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -2.64745
evaluation/Rewards Std            1.35084
evaluation/Rewards Max           -0.186147
evaluation/Rewards Min          -10.0284
evaluation/Returns Mean        -264.745
evaluation/Returns Std          107.773
evaluation/Returns Max         -127.821
evaluation/Returns Min         -578.181
evaluation/Actions Mean           0.27668
evaluation/Actions Std            0.179798
evaluation/Actions Max            0.694651
evaluation/Actions Min           -0.346687
evaluation/Num Paths             25
evaluation/Average Returns     -264.745
time/data storing (s)             0.0028638
time/evaluation sampling (s)      0.540433
time/exploration sampling (s)     0.140717
time/logging (s)                  0.006783
time/saving (s)                   0.00194538
time/training (s)                 1.91376
time/epoch (s)                    2.6065
time/total (s)                    5.42162
Epoch                             1
-----------------------------  -------------
2019-04-22 21:08:54.991572 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 2 finished
-----------------------------  -------------
replay_buffer/size             1700
trainer/QF1 Loss                  4.15299
trainer/QF2 Loss                  4.1048
trainer/Policy Loss              16.2156
trainer/Q1 Predictions Mean     -18.0131
trainer/Q1 Predictions Std       11.6003
trainer/Q1 Predictions Max       -6.51667
trainer/Q1 Predictions Min      -50.5305
trainer/Q2 Predictions Mean     -18.0611
trainer/Q2 Predictions Std       11.5772
trainer/Q2 Predictions Max       -6.73911
trainer/Q2 Predictions Min      -50.721
trainer/Q Targets Mean          -17.9332
trainer/Q Targets Std            11.8676
trainer/Q Targets Max            -2.56855
trainer/Q Targets Min           -47.9155
trainer/Log Pis Mean             -0.582523
trainer/Log Pis Std               1.09069
trainer/Log Pis Max               2.22634
trainer/Log Pis Min              -2.90424
trainer/Policy mu Mean            0.313641
trainer/Policy mu Std             0.627539
trainer/Policy mu Max             1.37142
trainer/Policy mu Min            -0.97307
trainer/Policy log std Mean      -0.304433
trainer/Policy log std Std        0.0908185
trainer/Policy log std Max       -0.143591
trainer/Policy log std Min       -0.517771
trainer/Alpha                     0.754427
trainer/Alpha Loss               -0.727082
exploration/num steps total    1700
exploration/num paths total      17
exploration/path length Mean    100
exploration/path length Std       0
exploration/path length Max     100
exploration/path length Min     100
exploration/Rewards Mean         -1.31831
exploration/Rewards Std           0.760641
exploration/Rewards Max          -0.037233
exploration/Rewards Min          -6.17982
exploration/Returns Mean       -131.831
exploration/Returns Std           8.94465
exploration/Returns Max        -121.43
exploration/Returns Min        -146.454
exploration/Actions Mean          0.0622185
exploration/Actions Std           0.564669
exploration/Actions Max           0.992216
exploration/Actions Min          -0.987788
exploration/Num Paths             5
exploration/Average Returns    -131.831
evaluation/num steps total     7500
evaluation/num paths total       75
evaluation/path length Mean     100
evaluation/path length Std        0
evaluation/path length Max      100
evaluation/path length Min      100
evaluation/Rewards Mean          -1.40436
evaluation/Rewards Std            0.802295
evaluation/Rewards Max           -0.0262462
evaluation/Rewards Min           -8.92502
evaluation/Returns Mean        -140.436
evaluation/Returns Std           46.5992
evaluation/Returns Max         -118.985
evaluation/Returns Min         -362.751
evaluation/Actions Mean           0.084597
evaluation/Actions Std            0.165292
evaluation/Actions Max            0.859938
evaluation/Actions Min           -0.75286
evaluation/Num Paths             25
evaluation/Average Returns     -140.436
time/data storing (s)             0.00296386
time/evaluation sampling (s)      0.568393
time/exploration sampling (s)     0.150696
time/logging (s)                  0.00655435
time/saving (s)                   0.00196031
time/training (s)                 2.11212
time/epoch (s)                    2.84269
time/total (s)                    8.26873
Epoch                             2
-----------------------------  -------------
2019-04-22 21:08:57.912786 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 3 finished
-----------------------------  --------------
replay_buffer/size              2200
trainer/QF1 Loss                   5.78797
trainer/QF2 Loss                   5.7759
trainer/Policy Loss               18.6705
trainer/Q1 Predictions Mean      -20.9658
trainer/Q1 Predictions Std        15.9046
trainer/Q1 Predictions Max        -8.64442
trainer/Q1 Predictions Min       -69.4871
trainer/Q2 Predictions Mean      -20.9548
trainer/Q2 Predictions Std        15.9213
trainer/Q2 Predictions Max        -8.77439
trainer/Q2 Predictions Min       -69.5617
trainer/Q Targets Mean           -20.8781
trainer/Q Targets Std             16.0979
trainer/Q Targets Max             -6.70763
trainer/Q Targets Min            -66.4291
trainer/Log Pis Mean              -0.415161
trainer/Log Pis Std                1.29629
trainer/Log Pis Max                3.28898
trainer/Log Pis Min               -4.50995
trainer/Policy mu Mean             0.122325
trainer/Policy mu Std              0.794784
trainer/Policy mu Max              1.57433
trainer/Policy mu Min             -1.41843
trainer/Policy log std Mean       -0.366289
trainer/Policy log std Std         0.115258
trainer/Policy log std Max        -0.172505
trainer/Policy log std Min        -0.594749
trainer/Alpha                      0.662981
trainer/Alpha Loss                -0.992032
exploration/num steps total     2200
exploration/num paths total       22
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.32434
exploration/Rewards Std            0.942954
exploration/Rewards Max           -0.116109
exploration/Rewards Min           -9.68151
exploration/Returns Mean        -132.434
exploration/Returns Std           20.9429
exploration/Returns Max         -109.871
exploration/Returns Min         -170.606
exploration/Actions Mean           0.0761471
exploration/Actions Std            0.538964
exploration/Actions Max            0.99366
exploration/Actions Min           -0.990603
exploration/Num Paths              5
exploration/Average Returns     -132.434
evaluation/num steps total     10000
evaluation/num paths total       100
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.5239
evaluation/Rewards Std             0.834152
evaluation/Rewards Max            -0.166597
evaluation/Rewards Min            -9.74407
evaluation/Returns Mean         -152.39
evaluation/Returns Std            20.4117
evaluation/Returns Max          -130.916
evaluation/Returns Min          -230.225
evaluation/Actions Mean            0.0679599
evaluation/Actions Std             0.191089
evaluation/Actions Max             0.913925
evaluation/Actions Min            -0.892879
evaluation/Num Paths              25
evaluation/Average Returns      -152.39
time/data storing (s)              0.00374035
time/evaluation sampling (s)       0.557791
time/exploration sampling (s)      0.147744
time/logging (s)                   0.00671342
time/saving (s)                    0.00201834
time/training (s)                  2.19852
time/epoch (s)                     2.91652
time/total (s)                    11.1893
Epoch                              3
-----------------------------  --------------
2019-04-22 21:09:00.730809 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 4 finished
-----------------------------  --------------
replay_buffer/size              2700
trainer/QF1 Loss                   0.71822
trainer/QF2 Loss                   0.663287
trainer/Policy Loss               19.1354
trainer/Q1 Predictions Mean      -21.1827
trainer/Q1 Predictions Std        14.5072
trainer/Q1 Predictions Max       -11.3786
trainer/Q1 Predictions Min       -75.4941
trainer/Q2 Predictions Mean      -21.1673
trainer/Q2 Predictions Std        14.5138
trainer/Q2 Predictions Max       -11.4658
trainer/Q2 Predictions Min       -75.5693
trainer/Q Targets Mean           -21.0977
trainer/Q Targets Std             14.5314
trainer/Q Targets Max            -10.3925
trainer/Q Targets Min            -74.7948
trainer/Log Pis Mean              -0.366495
trainer/Log Pis Std                1.29929
trainer/Log Pis Max                3.49455
trainer/Log Pis Min               -4.07063
trainer/Policy mu Mean             0.180988
trainer/Policy mu Std              0.793315
trainer/Policy mu Max              1.72249
trainer/Policy mu Min             -1.49663
trainer/Policy log std Mean       -0.405278
trainer/Policy log std Std         0.131313
trainer/Policy log std Max        -0.194518
trainer/Policy log std Min        -0.656179
trainer/Alpha                      0.580219
trainer/Alpha Loss                -1.28758
exploration/num steps total     2700
exploration/num paths total       27
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.16208
exploration/Rewards Std            1.12301
exploration/Rewards Max           -0.0375566
exploration/Rewards Min          -11.081
exploration/Returns Mean        -116.208
exploration/Returns Std           24.5548
exploration/Returns Max          -95.3987
exploration/Returns Min         -158.664
exploration/Actions Mean           0.045593
exploration/Actions Std            0.55415
exploration/Actions Max            0.991327
exploration/Actions Min           -0.991306
exploration/Num Paths              5
exploration/Average Returns     -116.208
evaluation/num steps total     12500
evaluation/num paths total       125
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.64193
evaluation/Rewards Std             0.916644
evaluation/Rewards Max            -0.080246
evaluation/Rewards Min           -11.0902
evaluation/Returns Mean          -64.193
evaluation/Returns Std            15.6496
evaluation/Returns Max           -45.6203
evaluation/Returns Min          -104.871
evaluation/Actions Mean            0.0196917
evaluation/Actions Std             0.158853
evaluation/Actions Max             0.940607
evaluation/Actions Min            -0.920785
evaluation/Num Paths              25
evaluation/Average Returns       -64.193
time/data storing (s)              0.00327048
time/evaluation sampling (s)       0.529051
time/exploration sampling (s)      0.143169
time/logging (s)                   0.00680716
time/saving (s)                    0.00218944
time/training (s)                  2.12822
time/epoch (s)                     2.81271
time/total (s)                    14.0067
Epoch                              4
-----------------------------  --------------
2019-04-22 21:09:04.610693 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 5 finished
-----------------------------  --------------
replay_buffer/size              3200
trainer/QF1 Loss                   2.92851
trainer/QF2 Loss                   2.88056
trainer/Policy Loss               20.0614
trainer/Q1 Predictions Mean      -21.8394
trainer/Q1 Predictions Std        14.7207
trainer/Q1 Predictions Max       -12.738
trainer/Q1 Predictions Min       -80.2833
trainer/Q2 Predictions Mean      -21.7953
trainer/Q2 Predictions Std        14.7107
trainer/Q2 Predictions Max       -12.8222
trainer/Q2 Predictions Min       -80.1778
trainer/Q Targets Mean           -21.8153
trainer/Q Targets Std             14.9607
trainer/Q Targets Max             -2.56855
trainer/Q Targets Min            -80.0022
trainer/Log Pis Mean              -0.207199
trainer/Log Pis Std                1.40608
trainer/Log Pis Max                3.61426
trainer/Log Pis Min               -2.92106
trainer/Policy mu Mean             0.177227
trainer/Policy mu Std              0.819124
trainer/Policy mu Max              1.89395
trainer/Policy mu Min             -1.57507
trainer/Policy log std Mean       -0.471231
trainer/Policy log std Std         0.141751
trainer/Policy log std Max        -0.235824
trainer/Policy log std Min        -0.70982
trainer/Alpha                      0.505948
trainer/Alpha Loss                -1.50322
exploration/num steps total     3200
exploration/num paths total       32
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.0979
exploration/Rewards Std            1.20456
exploration/Rewards Max           -0.0187795
exploration/Rewards Min          -10.0746
exploration/Returns Mean        -109.79
exploration/Returns Std           15.3758
exploration/Returns Max          -91.7806
exploration/Returns Min         -131.578
exploration/Actions Mean           0.0441178
exploration/Actions Std            0.54497
exploration/Actions Max            0.99429
exploration/Actions Min           -0.98655
exploration/Num Paths              5
exploration/Average Returns     -109.79
evaluation/num steps total     15000
evaluation/num paths total       150
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.381982
evaluation/Rewards Std             1.19298
evaluation/Rewards Max            -0.0850747
evaluation/Rewards Min           -10.9383
evaluation/Returns Mean          -38.1982
evaluation/Returns Std            19.7085
evaluation/Returns Max           -12.0612
evaluation/Returns Min           -74.0492
evaluation/Actions Mean            0.0310086
evaluation/Actions Std             0.182642
evaluation/Actions Max             0.955675
evaluation/Actions Min            -0.944806
evaluation/Num Paths              25
evaluation/Average Returns       -38.1982
time/data storing (s)              0.00320596
time/evaluation sampling (s)       0.629467
time/exploration sampling (s)      0.168686
time/logging (s)                   0.00692276
time/saving (s)                    0.00195447
time/training (s)                  3.06418
time/epoch (s)                     3.87442
time/total (s)                    17.8858
Epoch                              5
-----------------------------  --------------
2019-04-22 21:09:07.472434 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 6 finished
-----------------------------  --------------
replay_buffer/size              3700
trainer/QF1 Loss                   2.90179
trainer/QF2 Loss                   2.92231
trainer/Policy Loss               20.2588
trainer/Q1 Predictions Mean      -21.9057
trainer/Q1 Predictions Std        14.959
trainer/Q1 Predictions Max       -14.0169
trainer/Q1 Predictions Min       -89.0991
trainer/Q2 Predictions Mean      -21.875
trainer/Q2 Predictions Std        14.9635
trainer/Q2 Predictions Max       -14.0767
trainer/Q2 Predictions Min       -89.0718
trainer/Q Targets Mean           -22.0371
trainer/Q Targets Std             15.2468
trainer/Q Targets Max             -0.638513
trainer/Q Targets Min            -88.7907
trainer/Log Pis Mean              -0.133642
trainer/Log Pis Std                1.71473
trainer/Log Pis Max                4.97779
trainer/Log Pis Min               -5.49606
trainer/Policy mu Mean             0.256575
trainer/Policy mu Std              0.816007
trainer/Policy mu Max              2.05289
trainer/Policy mu Min             -1.55561
trainer/Policy log std Mean       -0.462039
trainer/Policy log std Std         0.124421
trainer/Policy log std Max        -0.224425
trainer/Policy log std Min        -0.720728
trainer/Alpha                      0.439238
trainer/Alpha Loss                -1.75477
exploration/num steps total     3700
exploration/num paths total       37
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.992944
exploration/Rewards Std            0.958545
exploration/Rewards Max           -0.0310001
exploration/Rewards Min          -10.2631
exploration/Returns Mean         -99.2944
exploration/Returns Std           18.9645
exploration/Returns Max          -77.1854
exploration/Returns Min         -132.98
exploration/Actions Mean           0.0427591
exploration/Actions Std            0.536517
exploration/Actions Max            0.993062
exploration/Actions Min           -0.994968
exploration/Num Paths              5
exploration/Average Returns      -99.2944
evaluation/num steps total     17500
evaluation/num paths total       175
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.57355
evaluation/Rewards Std             1.22706
evaluation/Rewards Max            -0.0784881
evaluation/Rewards Min           -10.6895
evaluation/Returns Mean          -57.355
evaluation/Returns Std            19.4013
evaluation/Returns Max           -27.1452
evaluation/Returns Min           -89.7706
evaluation/Actions Mean            0.0351921
evaluation/Actions Std             0.186244
evaluation/Actions Max             0.966534
evaluation/Actions Min            -0.933531
evaluation/Num Paths              25
evaluation/Average Returns       -57.355
time/data storing (s)              0.00487127
time/evaluation sampling (s)       0.649952
time/exploration sampling (s)      0.177021
time/logging (s)                   0.00659443
time/saving (s)                    0.00236813
time/training (s)                  2.01492
time/epoch (s)                     2.85573
time/total (s)                    20.7463
Epoch                              6
-----------------------------  --------------
2019-04-22 21:09:10.167475 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 7 finished
-----------------------------  --------------
replay_buffer/size              4200
trainer/QF1 Loss                   5.1774
trainer/QF2 Loss                   5.21185
trainer/Policy Loss               18.8213
trainer/Q1 Predictions Mean      -20.6745
trainer/Q1 Predictions Std        11.6745
trainer/Q1 Predictions Max       -15.3012
trainer/Q1 Predictions Min       -93.7619
trainer/Q2 Predictions Mean      -20.6668
trainer/Q2 Predictions Std        11.7026
trainer/Q2 Predictions Max       -15.3324
trainer/Q2 Predictions Min       -93.7135
trainer/Q Targets Mean           -20.9833
trainer/Q Targets Std             12.0021
trainer/Q Targets Max             -3.27535
trainer/Q Targets Min            -94.237
trainer/Log Pis Mean              -0.490492
trainer/Log Pis Std                1.42726
trainer/Log Pis Max                4.82626
trainer/Log Pis Min               -4.6471
trainer/Policy mu Mean             0.128764
trainer/Policy mu Std              0.758309
trainer/Policy mu Max              2.12855
trainer/Policy mu Min             -1.74061
trainer/Policy log std Mean       -0.509581
trainer/Policy log std Std         0.125134
trainer/Policy log std Max        -0.252546
trainer/Policy log std Min        -0.725118
trainer/Alpha                      0.380702
trainer/Alpha Loss                -2.40447
exploration/num steps total     4200
exploration/num paths total       42
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.04399
exploration/Rewards Std            1.06471
exploration/Rewards Max           -0.0519505
exploration/Rewards Min           -9.73963
exploration/Returns Mean        -104.399
exploration/Returns Std           19.6853
exploration/Returns Max          -78.8683
exploration/Returns Min         -132.615
exploration/Actions Mean           0.0185079
exploration/Actions Std            0.532762
exploration/Actions Max            0.988479
exploration/Actions Min           -0.976589
exploration/Num Paths              5
exploration/Average Returns     -104.399
evaluation/num steps total     20000
evaluation/num paths total       200
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.391838
evaluation/Rewards Std             0.864884
evaluation/Rewards Max            -0.0496237
evaluation/Rewards Min            -9.421
evaluation/Returns Mean          -39.1838
evaluation/Returns Std            13.7955
evaluation/Returns Max           -20.1323
evaluation/Returns Min           -68.7683
evaluation/Actions Mean            0.02184
evaluation/Actions Std             0.162478
evaluation/Actions Max             0.967645
evaluation/Actions Min            -0.95441
evaluation/Num Paths              25
evaluation/Average Returns       -39.1838
time/data storing (s)              0.00290213
time/evaluation sampling (s)       0.57256
time/exploration sampling (s)      0.144764
time/logging (s)                   0.00645139
time/saving (s)                    0.00155779
time/training (s)                  1.96101
time/epoch (s)                     2.68925
time/total (s)                    23.4404
Epoch                              7
-----------------------------  --------------
2019-04-22 21:09:12.840730 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 8 finished
-----------------------------  --------------
replay_buffer/size              4700
trainer/QF1 Loss                  10.1391
trainer/QF2 Loss                  10.1653
trainer/Policy Loss               19.1661
trainer/Q1 Predictions Mean      -20.6866
trainer/Q1 Predictions Std         8.45523
trainer/Q1 Predictions Max       -16.6374
trainer/Q1 Predictions Min       -64.5432
trainer/Q2 Predictions Mean      -20.698
trainer/Q2 Predictions Std         8.48629
trainer/Q2 Predictions Max       -16.6307
trainer/Q2 Predictions Min       -64.4782
trainer/Q Targets Mean           -20.6987
trainer/Q Targets Std              8.76323
trainer/Q Targets Max             -4.45035
trainer/Q Targets Min            -64.7304
trainer/Log Pis Mean              -0.427374
trainer/Log Pis Std                1.13266
trainer/Log Pis Max                3.12596
trainer/Log Pis Min               -4.35377
trainer/Policy mu Mean             0.151617
trainer/Policy mu Std              0.752557
trainer/Policy mu Max              2.01823
trainer/Policy mu Min             -1.86553
trainer/Policy log std Mean       -0.572258
trainer/Policy log std Std         0.151818
trainer/Policy log std Max        -0.307337
trainer/Policy log std Min        -0.807088
trainer/Alpha                      0.329811
trainer/Alpha Loss                -2.69185
exploration/num steps total     4700
exploration/num paths total       47
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.870142
exploration/Rewards Std            0.987875
exploration/Rewards Max           -0.0204574
exploration/Rewards Min           -8.4699
exploration/Returns Mean         -87.0142
exploration/Returns Std           13.2514
exploration/Returns Max          -70.9089
exploration/Returns Min         -108.19
exploration/Actions Mean           0.0382022
exploration/Actions Std            0.515603
exploration/Actions Max            0.994241
exploration/Actions Min           -0.984287
exploration/Num Paths              5
exploration/Average Returns      -87.0142
evaluation/num steps total     22500
evaluation/num paths total       225
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.447724
evaluation/Rewards Std             1.13005
evaluation/Rewards Max            -0.0298961
evaluation/Rewards Min           -10.9841
evaluation/Returns Mean          -44.7724
evaluation/Returns Std            20.7117
evaluation/Returns Max           -21.644
evaluation/Returns Min           -80.3298
evaluation/Actions Mean            0.0286543
evaluation/Actions Std             0.181797
evaluation/Actions Max             0.972969
evaluation/Actions Min            -0.967394
evaluation/Num Paths              25
evaluation/Average Returns       -44.7724
time/data storing (s)              0.00281856
time/evaluation sampling (s)       0.540037
time/exploration sampling (s)      0.14562
time/logging (s)                   0.0069733
time/saving (s)                    0.00159039
time/training (s)                  1.9713
time/epoch (s)                     2.66834
time/total (s)                    26.1134
Epoch                              8
-----------------------------  --------------
2019-04-22 21:09:15.473256 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 9 finished
-----------------------------  --------------
replay_buffer/size              5200
trainer/QF1 Loss                   3.80271
trainer/QF2 Loss                   3.80822
trainer/Policy Loss               21.4075
trainer/Q1 Predictions Mean      -22.5568
trainer/Q1 Predictions Std         9.72539
trainer/Q1 Predictions Max       -17.6119
trainer/Q1 Predictions Min       -69.1553
trainer/Q2 Predictions Mean      -22.5262
trainer/Q2 Predictions Std         9.72284
trainer/Q2 Predictions Max       -17.6089
trainer/Q2 Predictions Min       -69.3382
trainer/Q Targets Mean           -22.562
trainer/Q Targets Std             10.0007
trainer/Q Targets Max             -0.497561
trainer/Q Targets Min            -71.4734
trainer/Log Pis Mean              -0.14868
trainer/Log Pis Std                1.38635
trainer/Log Pis Max                4.30784
trainer/Log Pis Min               -3.47616
trainer/Policy mu Mean             0.160639
trainer/Policy mu Std              0.799152
trainer/Policy mu Max              2.20241
trainer/Policy mu Min             -1.89364
trainer/Policy log std Mean       -0.592229
trainer/Policy log std Std         0.148062
trainer/Policy log std Max        -0.301555
trainer/Policy log std Min        -0.808081
trainer/Alpha                      0.285621
trainer/Alpha Loss                -2.69185
exploration/num steps total     5200
exploration/num paths total       52
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.815725
exploration/Rewards Std            0.676362
exploration/Rewards Max           -0.0398575
exploration/Rewards Min           -7.33463
exploration/Returns Mean         -81.5725
exploration/Returns Std           10.8836
exploration/Returns Max          -68.2603
exploration/Returns Min          -98.2303
exploration/Actions Mean           0.0216735
exploration/Actions Std            0.501383
exploration/Actions Max            0.996832
exploration/Actions Min           -0.971321
exploration/Num Paths              5
exploration/Average Returns      -81.5725
evaluation/num steps total     25000
evaluation/num paths total       250
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.381536
evaluation/Rewards Std             1.10866
evaluation/Rewards Max            -0.122677
evaluation/Rewards Min           -11.1048
evaluation/Returns Mean          -38.1536
evaluation/Returns Std            18.3906
evaluation/Returns Max           -15.3837
evaluation/Returns Min           -75.72
evaluation/Actions Mean            0.0318543
evaluation/Actions Std             0.188359
evaluation/Actions Max             0.976037
evaluation/Actions Min            -0.969758
evaluation/Num Paths              25
evaluation/Average Returns       -38.1536
time/data storing (s)              0.00303669
time/evaluation sampling (s)       0.536967
time/exploration sampling (s)      0.148288
time/logging (s)                   0.0067583
time/saving (s)                    0.00157771
time/training (s)                  1.93013
time/epoch (s)                     2.62676
time/total (s)                    28.7447
Epoch                              9
-----------------------------  --------------
2019-04-22 21:09:18.103655 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 10 finished
-----------------------------  --------------
replay_buffer/size              5700
trainer/QF1 Loss                   7.51885
trainer/QF2 Loss                   7.53364
trainer/Policy Loss               23.8061
trainer/Q1 Predictions Mean      -25.2283
trainer/Q1 Predictions Std        17.1871
trainer/Q1 Predictions Max       -18.481
trainer/Q1 Predictions Min      -102.97
trainer/Q2 Predictions Mean      -25.2436
trainer/Q2 Predictions Std        17.1869
trainer/Q2 Predictions Max       -18.4943
trainer/Q2 Predictions Min      -102.885
trainer/Q Targets Mean           -25.1454
trainer/Q Targets Std             17.6772
trainer/Q Targets Max             -0.609503
trainer/Q Targets Min           -102.768
trainer/Log Pis Mean              -0.101125
trainer/Log Pis Std                1.50638
trainer/Log Pis Max                6.03765
trainer/Log Pis Min               -3.8663
trainer/Policy mu Mean             0.0928422
trainer/Policy mu Std              0.823625
trainer/Policy mu Max              2.34299
trainer/Policy mu Min             -2.11358
trainer/Policy log std Mean       -0.670913
trainer/Policy log std Std         0.141391
trainer/Policy log std Max        -0.398059
trainer/Policy log std Min        -0.874397
trainer/Alpha                      0.247579
trainer/Alpha Loss                -2.93265
exploration/num steps total     5700
exploration/num paths total       57
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.810582
exploration/Rewards Std            1.00262
exploration/Rewards Max           -0.0375007
exploration/Rewards Min           -9.6608
exploration/Returns Mean         -81.0582
exploration/Returns Std           24.1728
exploration/Returns Max          -59.5743
exploration/Returns Min         -124.966
exploration/Actions Mean           0.0321457
exploration/Actions Std            0.487967
exploration/Actions Max            0.994733
exploration/Actions Min           -0.948282
exploration/Num Paths              5
exploration/Average Returns      -81.0582
evaluation/num steps total     27500
evaluation/num paths total       275
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.416196
evaluation/Rewards Std             1.16763
evaluation/Rewards Max            -0.0167221
evaluation/Rewards Min           -10.8072
evaluation/Returns Mean          -41.6196
evaluation/Returns Std            16.9225
evaluation/Returns Max           -16.5358
evaluation/Returns Min           -74.2105
evaluation/Actions Mean            0.0321409
evaluation/Actions Std             0.197435
evaluation/Actions Max             0.982267
evaluation/Actions Min            -0.97649
evaluation/Num Paths              25
evaluation/Average Returns       -41.6196
time/data storing (s)              0.00305964
time/evaluation sampling (s)       0.529882
time/exploration sampling (s)      0.147617
time/logging (s)                   0.00686497
time/saving (s)                    0.00203991
time/training (s)                  1.93555
time/epoch (s)                     2.62501
time/total (s)                    31.3744
Epoch                             10
-----------------------------  --------------
2019-04-22 21:09:20.827516 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 11 finished
-----------------------------  --------------
replay_buffer/size              6200
trainer/QF1 Loss                   4.16844
trainer/QF2 Loss                   4.11576
trainer/Policy Loss               23.4831
trainer/Q1 Predictions Mean      -24.5006
trainer/Q1 Predictions Std        14.2756
trainer/Q1 Predictions Max       -19.3186
trainer/Q1 Predictions Min       -95.0091
trainer/Q2 Predictions Mean      -24.5123
trainer/Q2 Predictions Std        14.2695
trainer/Q2 Predictions Max       -19.2438
trainer/Q2 Predictions Min       -94.888
trainer/Q Targets Mean           -24.5014
trainer/Q Targets Std             14.5027
trainer/Q Targets Max             -0.473509
trainer/Q Targets Min            -95.1176
trainer/Log Pis Mean              -0.138664
trainer/Log Pis Std                1.53109
trainer/Log Pis Max                5.35267
trainer/Log Pis Min               -4.46119
trainer/Policy mu Mean             0.251587
trainer/Policy mu Std              0.829253
trainer/Policy mu Max              2.58035
trainer/Policy mu Min             -2.05302
trainer/Policy log std Mean       -0.763243
trainer/Policy log std Std         0.119231
trainer/Policy log std Max        -0.48024
trainer/Policy log std Min        -0.949846
trainer/Alpha                      0.215372
trainer/Alpha Loss                -3.28307
exploration/num steps total     6200
exploration/num paths total       62
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.783354
exploration/Rewards Std            0.916924
exploration/Rewards Max           -0.0261087
exploration/Rewards Min           -9.07175
exploration/Returns Mean         -78.3354
exploration/Returns Std           16.9358
exploration/Returns Max          -60.7289
exploration/Returns Min         -101.926
exploration/Actions Mean           0.0173053
exploration/Actions Std            0.459325
exploration/Actions Max            0.992752
exploration/Actions Min           -0.981318
exploration/Num Paths              5
exploration/Average Returns      -78.3354
evaluation/num steps total     30000
evaluation/num paths total       300
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.653608
evaluation/Rewards Std             1.00678
evaluation/Rewards Max            -0.00298011
evaluation/Rewards Min           -10.5154
evaluation/Returns Mean          -65.3608
evaluation/Returns Std            16.8963
evaluation/Returns Max           -45.6799
evaluation/Returns Min          -100.415
evaluation/Actions Mean            0.0316684
evaluation/Actions Std             0.18908
evaluation/Actions Max             0.988244
evaluation/Actions Min            -0.972028
evaluation/Num Paths              25
evaluation/Average Returns       -65.3608
time/data storing (s)              0.00295426
time/evaluation sampling (s)       0.527981
time/exploration sampling (s)      0.145246
time/logging (s)                   0.00549449
time/saving (s)                    0.00202083
time/training (s)                  2.03319
time/epoch (s)                     2.71689
time/total (s)                    34.0958
Epoch                             11
-----------------------------  --------------
2019-04-22 21:09:23.770376 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 12 finished
-----------------------------  --------------
replay_buffer/size              6700
trainer/QF1 Loss                   9.50541
trainer/QF2 Loss                   9.39903
trainer/Policy Loss               25.5802
trainer/Q1 Predictions Mean      -26.8052
trainer/Q1 Predictions Std        16.6802
trainer/Q1 Predictions Max       -19.9887
trainer/Q1 Predictions Min      -104.615
trainer/Q2 Predictions Mean      -26.8065
trainer/Q2 Predictions Std        16.6827
trainer/Q2 Predictions Max       -19.8806
trainer/Q2 Predictions Min      -104.53
trainer/Q Targets Mean           -26.7204
trainer/Q Targets Std             17.4933
trainer/Q Targets Max             -1.25315
trainer/Q Targets Min           -100.534
trainer/Log Pis Mean               0.147053
trainer/Log Pis Std                1.76682
trainer/Log Pis Max                5.78169
trainer/Log Pis Min               -4.01476
trainer/Policy mu Mean             0.0988827
trainer/Policy mu Std              0.905088
trainer/Policy mu Max              2.61869
trainer/Policy mu Min             -2.19803
trainer/Policy log std Mean       -0.820848
trainer/Policy log std Std         0.136097
trainer/Policy log std Max        -0.548707
trainer/Policy log std Min        -1.01555
trainer/Alpha                      0.187491
trainer/Alpha Loss                -3.10136
exploration/num steps total     6700
exploration/num paths total       67
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.887408
exploration/Rewards Std            1.22864
exploration/Rewards Max           -0.021161
exploration/Rewards Min          -10.0637
exploration/Returns Mean         -88.7408
exploration/Returns Std           12.4801
exploration/Returns Max          -66.6217
exploration/Returns Min         -105.293
exploration/Actions Mean           0.0425258
exploration/Actions Std            0.451286
exploration/Actions Max            0.997615
exploration/Actions Min           -0.960339
exploration/Num Paths              5
exploration/Average Returns      -88.7408
evaluation/num steps total     32500
evaluation/num paths total       325
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.576068
evaluation/Rewards Std             0.735377
evaluation/Rewards Max            -0.0259819
evaluation/Rewards Min            -9.6009
evaluation/Returns Mean          -57.6068
evaluation/Returns Std            10.7898
evaluation/Returns Max           -44.6819
evaluation/Returns Min           -89.8957
evaluation/Actions Mean            0.0256323
evaluation/Actions Std             0.178325
evaluation/Actions Max             0.988306
evaluation/Actions Min            -0.974411
evaluation/Num Paths              25
evaluation/Average Returns       -57.6068
time/data storing (s)              0.00296573
time/evaluation sampling (s)       0.635636
time/exploration sampling (s)      0.155219
time/logging (s)                   0.00714747
time/saving (s)                    0.00207991
time/training (s)                  2.1358
time/epoch (s)                     2.93885
time/total (s)                    37.0397
Epoch                             12
-----------------------------  --------------
2019-04-22 21:09:26.470255 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 13 finished
-----------------------------  --------------
replay_buffer/size              7200
trainer/QF1 Loss                   4.77114
trainer/QF2 Loss                   4.72077
trainer/Policy Loss               23.5037
trainer/Q1 Predictions Mean      -24.3493
trainer/Q1 Predictions Std        12.4202
trainer/Q1 Predictions Max       -20.2346
trainer/Q1 Predictions Min      -105.186
trainer/Q2 Predictions Mean      -24.3364
trainer/Q2 Predictions Std        12.4297
trainer/Q2 Predictions Max       -20.1829
trainer/Q2 Predictions Min      -105.184
trainer/Q Targets Mean           -24.2737
trainer/Q Targets Std             12.2716
trainer/Q Targets Max             -0.842219
trainer/Q Targets Min            -99.5324
trainer/Log Pis Mean               0.153104
trainer/Log Pis Std                1.69263
trainer/Log Pis Max                7.07169
trainer/Log Pis Min               -5.21117
trainer/Policy mu Mean             0.141305
trainer/Policy mu Std              0.82788
trainer/Policy mu Max              2.47636
trainer/Policy mu Min             -2.23861
trainer/Policy log std Mean       -0.90892
trainer/Policy log std Std         0.145587
trainer/Policy log std Max        -0.536357
trainer/Policy log std Min        -1.10702
trainer/Alpha                      0.1638
trainer/Alpha Loss                -3.34074
exploration/num steps total     7200
exploration/num paths total       72
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.859906
exploration/Rewards Std            1.34062
exploration/Rewards Max           -0.00744975
exploration/Rewards Min          -10.0121
exploration/Returns Mean         -85.9906
exploration/Returns Std           14.4992
exploration/Returns Max          -64.648
exploration/Returns Min         -101.679
exploration/Actions Mean           0.0254163
exploration/Actions Std            0.447554
exploration/Actions Max            0.995913
exploration/Actions Min           -0.992514
exploration/Num Paths              5
exploration/Average Returns      -85.9906
evaluation/num steps total     35000
evaluation/num paths total       350
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.582136
evaluation/Rewards Std             1.08227
evaluation/Rewards Max            -0.0124301
evaluation/Rewards Min           -10.4969
evaluation/Returns Mean          -58.2136
evaluation/Returns Std            17.6796
evaluation/Returns Max           -38.48
evaluation/Returns Min           -89.8716
evaluation/Actions Mean            0.0280047
evaluation/Actions Std             0.196174
evaluation/Actions Max             0.988193
evaluation/Actions Min            -0.976312
evaluation/Num Paths              25
evaluation/Average Returns       -58.2136
time/data storing (s)              0.00307846
time/evaluation sampling (s)       0.550873
time/exploration sampling (s)      0.149805
time/logging (s)                   0.00693667
time/saving (s)                    0.00203614
time/training (s)                  1.98053
time/epoch (s)                     2.69326
time/total (s)                    39.7382
Epoch                             13
-----------------------------  --------------
2019-04-22 21:09:29.478280 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 14 finished
-----------------------------  --------------
replay_buffer/size              7700
trainer/QF1 Loss                   0.520745
trainer/QF2 Loss                   0.552218
trainer/Policy Loss               22.9583
trainer/Q1 Predictions Mean      -23.453
trainer/Q1 Predictions Std         6.58128
trainer/Q1 Predictions Max       -20.5672
trainer/Q1 Predictions Min       -60.4363
trainer/Q2 Predictions Mean      -23.4607
trainer/Q2 Predictions Std         6.61677
trainer/Q2 Predictions Max       -20.5089
trainer/Q2 Predictions Min       -60.9273
trainer/Q Targets Mean           -23.5768
trainer/Q Targets Std              6.27298
trainer/Q Targets Max            -20.5391
trainer/Q Targets Min            -59.1549
trainer/Log Pis Mean               0.258847
trainer/Log Pis Std                1.54763
trainer/Log Pis Max                4.98939
trainer/Log Pis Min               -5.60741
trainer/Policy mu Mean             0.101956
trainer/Policy mu Std              0.7813
trainer/Policy mu Max              2.52944
trainer/Policy mu Min             -1.99087
trainer/Policy log std Mean       -1.01579
trainer/Policy log std Std         0.152758
trainer/Policy log std Max        -0.573906
trainer/Policy log std Min        -1.20622
trainer/Alpha                      0.143823
trainer/Alpha Loss                -3.37595
exploration/num steps total     7700
exploration/num paths total       77
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.664607
exploration/Rewards Std            1.0302
exploration/Rewards Max           -0.00978273
exploration/Rewards Min           -9.60074
exploration/Returns Mean         -66.4607
exploration/Returns Std           17.4337
exploration/Returns Max          -50.1105
exploration/Returns Min          -92.5496
exploration/Actions Mean           0.0306824
exploration/Actions Std            0.409339
exploration/Actions Max            0.997936
exploration/Actions Min           -0.978637
exploration/Num Paths              5
exploration/Average Returns      -66.4607
evaluation/num steps total     37500
evaluation/num paths total       375
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.480478
evaluation/Rewards Std             1.10827
evaluation/Rewards Max            -0.0207022
evaluation/Rewards Min           -11.2112
evaluation/Returns Mean          -48.0478
evaluation/Returns Std            15.7481
evaluation/Returns Max           -24.6336
evaluation/Returns Min           -81.9078
evaluation/Actions Mean            0.0341461
evaluation/Actions Std             0.202044
evaluation/Actions Max             0.987495
evaluation/Actions Min            -0.979548
evaluation/Num Paths              25
evaluation/Average Returns       -48.0478
time/data storing (s)              0.00294561
time/evaluation sampling (s)       0.558083
time/exploration sampling (s)      0.157995
time/logging (s)                   0.00763574
time/saving (s)                    0.00280556
time/training (s)                  2.27317
time/epoch (s)                     3.00264
time/total (s)                    42.746
Epoch                             14
-----------------------------  --------------
2019-04-22 21:09:32.640687 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 15 finished
-----------------------------  --------------
replay_buffer/size              8200
trainer/QF1 Loss                   8.68654
trainer/QF2 Loss                   8.70543
trainer/Policy Loss               23.6403
trainer/Q1 Predictions Mean      -23.859
trainer/Q1 Predictions Std         8.01298
trainer/Q1 Predictions Max       -20.939
trainer/Q1 Predictions Min       -83.041
trainer/Q2 Predictions Mean      -23.8841
trainer/Q2 Predictions Std         8.01894
trainer/Q2 Predictions Max       -20.8775
trainer/Q2 Predictions Min       -83.093
trainer/Q Targets Mean           -23.5867
trainer/Q Targets Std              8.72008
trainer/Q Targets Max             -0.639903
trainer/Q Targets Min            -84.4683
trainer/Log Pis Mean               0.427217
trainer/Log Pis Std                1.55573
trainer/Log Pis Max                7.16874
trainer/Log Pis Min               -3.20071
trainer/Policy mu Mean             0.0515202
trainer/Policy mu Std              0.833582
trainer/Policy mu Max              2.59763
trainer/Policy mu Min             -2.28542
trainer/Policy log std Mean       -1.04303
trainer/Policy log std Std         0.179875
trainer/Policy log std Max        -0.557592
trainer/Policy log std Min        -1.27696
trainer/Alpha                      0.126617
trainer/Alpha Loss                -3.2499
exploration/num steps total     8200
exploration/num paths total       82
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.687832
exploration/Rewards Std            1.20595
exploration/Rewards Max           -0.00843935
exploration/Rewards Min           -9.98696
exploration/Returns Mean         -68.7832
exploration/Returns Std           14.8078
exploration/Returns Max          -51.3759
exploration/Returns Min          -93.2297
exploration/Actions Mean           0.0301273
exploration/Actions Std            0.407525
exploration/Actions Max            0.996269
exploration/Actions Min           -0.993802
exploration/Num Paths              5
exploration/Average Returns      -68.7832
evaluation/num steps total     40000
evaluation/num paths total       400
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.587019
evaluation/Rewards Std             1.31283
evaluation/Rewards Max            -0.0117111
evaluation/Rewards Min           -10.8591
evaluation/Returns Mean          -58.7019
evaluation/Returns Std            86.6394
evaluation/Returns Max           -21.7584
evaluation/Returns Min          -474.228
evaluation/Actions Mean            0.0533679
evaluation/Actions Std             0.229843
evaluation/Actions Max             0.990583
evaluation/Actions Min            -0.979374
evaluation/Num Paths              25
evaluation/Average Returns       -58.7019
time/data storing (s)              0.00294868
time/evaluation sampling (s)       0.561294
time/exploration sampling (s)      0.16671
time/logging (s)                   0.00763858
time/saving (s)                    0.00222838
time/training (s)                  2.41433
time/epoch (s)                     3.15515
time/total (s)                    45.9074
Epoch                             15
-----------------------------  --------------
2019-04-22 21:09:35.612793 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 16 finished
-----------------------------  --------------
replay_buffer/size              8700
trainer/QF1 Loss                   4.85844
trainer/QF2 Loss                   4.84251
trainer/Policy Loss               24.4388
trainer/Q1 Predictions Mean      -24.9411
trainer/Q1 Predictions Std        12.1585
trainer/Q1 Predictions Max       -21.0446
trainer/Q1 Predictions Min       -97.5597
trainer/Q2 Predictions Mean      -24.9065
trainer/Q2 Predictions Std        12.14
trainer/Q2 Predictions Max       -20.9678
trainer/Q2 Predictions Min       -97.5089
trainer/Q Targets Mean           -24.8646
trainer/Q Targets Std             12.4042
trainer/Q Targets Max             -0.319169
trainer/Q Targets Min            -93.5551
trainer/Log Pis Mean               0.404948
trainer/Log Pis Std                1.69071
trainer/Log Pis Max                6.01541
trainer/Log Pis Min               -3.42805
trainer/Policy mu Mean             0.108249
trainer/Policy mu Std              0.837212
trainer/Policy mu Max              2.66569
trainer/Policy mu Min             -2.32589
trainer/Policy log std Mean       -1.1592
trainer/Policy log std Std         0.185415
trainer/Policy log std Max        -0.502688
trainer/Policy log std Min        -1.41961
trainer/Alpha                      0.111691
trainer/Alpha Loss                -3.496
exploration/num steps total     8700
exploration/num paths total       87
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.539986
exploration/Rewards Std            0.763435
exploration/Rewards Max           -0.00939134
exploration/Rewards Min           -7.18625
exploration/Returns Mean         -53.9986
exploration/Returns Std           10.7487
exploration/Returns Max          -36.3491
exploration/Returns Min          -68.837
exploration/Actions Mean           0.0334371
exploration/Actions Std            0.37175
exploration/Actions Max            0.988766
exploration/Actions Min           -0.994937
exploration/Num Paths              5
exploration/Average Returns      -53.9986
evaluation/num steps total     42500
evaluation/num paths total       425
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.476314
evaluation/Rewards Std             1.22051
evaluation/Rewards Max            -0.05812
evaluation/Rewards Min           -10.8398
evaluation/Returns Mean          -47.6314
evaluation/Returns Std            18.5649
evaluation/Returns Max           -21.8011
evaluation/Returns Min           -77.0235
evaluation/Actions Mean            0.0326657
evaluation/Actions Std             0.208673
evaluation/Actions Max             0.991585
evaluation/Actions Min            -0.985586
evaluation/Num Paths              25
evaluation/Average Returns       -47.6314
time/data storing (s)              0.00377291
time/evaluation sampling (s)       0.611222
time/exploration sampling (s)      0.162503
time/logging (s)                   0.00746222
time/saving (s)                    0.00236052
time/training (s)                  2.17852
time/epoch (s)                     2.96584
time/total (s)                    48.8783
Epoch                             16
-----------------------------  --------------
2019-04-22 21:09:38.364743 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 17 finished
-----------------------------  ---------------
replay_buffer/size              9200
trainer/QF1 Loss                   0.277528
trainer/QF2 Loss                   0.279463
trainer/Policy Loss               22.9865
trainer/Q1 Predictions Mean      -22.9143
trainer/Q1 Predictions Std         4.99319
trainer/Q1 Predictions Max       -20.9134
trainer/Q1 Predictions Min       -64.1079
trainer/Q2 Predictions Mean      -22.922
trainer/Q2 Predictions Std         4.99699
trainer/Q2 Predictions Max       -20.9297
trainer/Q2 Predictions Min       -63.9909
trainer/Q Targets Mean           -23.0853
trainer/Q Targets Std              4.84729
trainer/Q Targets Max            -20.9457
trainer/Q Targets Min            -62.1415
trainer/Log Pis Mean               0.551855
trainer/Log Pis Std                1.3875
trainer/Log Pis Max                6.57401
trainer/Log Pis Min               -3.29777
trainer/Policy mu Mean             0.06063
trainer/Policy mu Std              0.783083
trainer/Policy mu Max              2.63315
trainer/Policy mu Min             -2.16027
trainer/Policy log std Mean       -1.16612
trainer/Policy log std Std         0.189324
trainer/Policy log std Max        -0.556483
trainer/Policy log std Min        -1.41748
trainer/Alpha                      0.0989315
trainer/Alpha Loss                -3.34965
exploration/num steps total     9200
exploration/num paths total       92
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.477606
exploration/Rewards Std            0.773721
exploration/Rewards Max           -0.000851368
exploration/Rewards Min           -8.56998
exploration/Returns Mean         -47.7606
exploration/Returns Std           12.2563
exploration/Returns Max          -38.5715
exploration/Returns Min          -70.7003
exploration/Actions Mean           0.0112089
exploration/Actions Std            0.375892
exploration/Actions Max            0.995006
exploration/Actions Min           -0.996882
exploration/Num Paths              5
exploration/Average Returns      -47.7606
evaluation/num steps total     45000
evaluation/num paths total       450
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.345089
evaluation/Rewards Std             0.961394
evaluation/Rewards Max            -0.0271685
evaluation/Rewards Min            -9.19773
evaluation/Returns Mean          -34.5089
evaluation/Returns Std            64.6447
evaluation/Returns Max            -9.81026
evaluation/Returns Min          -344.529
evaluation/Actions Mean            0.0376089
evaluation/Actions Std             0.210474
evaluation/Actions Max             0.987686
evaluation/Actions Min            -0.987597
evaluation/Num Paths              25
evaluation/Average Returns       -34.5089
time/data storing (s)              0.00321238
time/evaluation sampling (s)       0.558533
time/exploration sampling (s)      0.150139
time/logging (s)                   0.010167
time/saving (s)                    0.00251525
time/training (s)                  2.0237
time/epoch (s)                     2.74827
time/total (s)                    51.6317
Epoch                             17
-----------------------------  ---------------
2019-04-22 21:09:41.479899 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 18 finished
-----------------------------  --------------
replay_buffer/size              9700
trainer/QF1 Loss                   4.45797
trainer/QF2 Loss                   4.48484
trainer/Policy Loss               24.5861
trainer/Q1 Predictions Mean      -24.017
trainer/Q1 Predictions Std         8.79786
trainer/Q1 Predictions Max       -20.6597
trainer/Q1 Predictions Min       -67.7369
trainer/Q2 Predictions Mean      -24.0331
trainer/Q2 Predictions Std         8.81716
trainer/Q2 Predictions Max       -20.6366
trainer/Q2 Predictions Min       -67.658
trainer/Q Targets Mean           -24.0999
trainer/Q Targets Std              8.87382
trainer/Q Targets Max             -0.624454
trainer/Q Targets Min            -67.1238
trainer/Log Pis Mean               1.05899
trainer/Log Pis Std                1.37027
trainer/Log Pis Max                6.86892
trainer/Log Pis Min               -2.09179
trainer/Policy mu Mean             0.141117
trainer/Policy mu Std              0.88644
trainer/Policy mu Max              2.80676
trainer/Policy mu Min             -2.40462
trainer/Policy log std Mean       -1.30329
trainer/Policy log std Std         0.223083
trainer/Policy log std Max        -0.478149
trainer/Policy log std Min        -1.56991
trainer/Alpha                      0.0875537
trainer/Alpha Loss                -2.29162
exploration/num steps total     9700
exploration/num paths total       97
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.663614
exploration/Rewards Std            1.11169
exploration/Rewards Max           -0.0263255
exploration/Rewards Min           -7.17043
exploration/Returns Mean         -66.3614
exploration/Returns Std           22.7722
exploration/Returns Max          -50.5923
exploration/Returns Min         -111.231
exploration/Actions Mean           0.0536143
exploration/Actions Std            0.377501
exploration/Actions Max            0.996103
exploration/Actions Min           -0.986224
exploration/Num Paths              5
exploration/Average Returns      -66.3614
evaluation/num steps total     47500
evaluation/num paths total       475
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.603135
evaluation/Rewards Std             1.20323
evaluation/Rewards Max            -0.126706
evaluation/Rewards Min           -10.8978
evaluation/Returns Mean          -60.3135
evaluation/Returns Std            73.8272
evaluation/Returns Max           -27.0294
evaluation/Returns Min          -412.281
evaluation/Actions Mean            0.0521417
evaluation/Actions Std             0.229321
evaluation/Actions Max             0.99155
evaluation/Actions Min            -0.983753
evaluation/Num Paths              25
evaluation/Average Returns       -60.3135
time/data storing (s)              0.00289019
time/evaluation sampling (s)       0.622719
time/exploration sampling (s)      0.154821
time/logging (s)                   0.00694038
time/saving (s)                    0.00202508
time/training (s)                  2.31465
time/epoch (s)                     3.10404
time/total (s)                    54.7413
Epoch                             18
-----------------------------  --------------
2019-04-22 21:09:44.321643 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 19 finished
-----------------------------  --------------
replay_buffer/size             10200
trainer/QF1 Loss                   4.78349
trainer/QF2 Loss                   4.81707
trainer/Policy Loss               25.0283
trainer/Q1 Predictions Mean      -25.0113
trainer/Q1 Predictions Std        11.5012
trainer/Q1 Predictions Max       -20.8307
trainer/Q1 Predictions Min       -87.2403
trainer/Q2 Predictions Mean      -24.9991
trainer/Q2 Predictions Std        11.5081
trainer/Q2 Predictions Max       -20.8312
trainer/Q2 Predictions Min       -87.3328
trainer/Q Targets Mean           -25.0595
trainer/Q Targets Std             11.9024
trainer/Q Targets Max             -1.0234
trainer/Q Targets Min            -87.2459
trainer/Log Pis Mean               0.906233
trainer/Log Pis Std                1.74762
trainer/Log Pis Max                7.63615
trainer/Log Pis Min               -4.28448
trainer/Policy mu Mean            -0.0325348
trainer/Policy mu Std              0.910424
trainer/Policy mu Max              2.88643
trainer/Policy mu Min             -2.73243
trainer/Policy log std Mean       -1.31597
trainer/Policy log std Std         0.272333
trainer/Policy log std Max        -0.38021
trainer/Policy log std Min        -1.60869
trainer/Alpha                      0.077894
trainer/Alpha Loss                -2.79149
exploration/num steps total    10200
exploration/num paths total      102
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.563708
exploration/Rewards Std            1.249
exploration/Rewards Max           -0.0257876
exploration/Rewards Min           -9.3867
exploration/Returns Mean         -56.3708
exploration/Returns Std           15.598
exploration/Returns Max          -32.4488
exploration/Returns Min          -74.9818
exploration/Actions Mean           0.0358497
exploration/Actions Std            0.346772
exploration/Actions Max            0.998985
exploration/Actions Min           -0.993799
exploration/Num Paths              5
exploration/Average Returns      -56.3708
evaluation/num steps total     50000
evaluation/num paths total       500
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.30973
evaluation/Rewards Std             0.946468
evaluation/Rewards Max            -0.0353785
evaluation/Rewards Min            -9.78259
evaluation/Returns Mean          -30.973
evaluation/Returns Std            13.9948
evaluation/Returns Max           -12.5434
evaluation/Returns Min           -64.1269
evaluation/Actions Mean            0.0245098
evaluation/Actions Std             0.196636
evaluation/Actions Max             0.992115
evaluation/Actions Min            -0.987836
evaluation/Num Paths              25
evaluation/Average Returns       -30.973
time/data storing (s)              0.00317975
time/evaluation sampling (s)       0.602003
time/exploration sampling (s)      0.156235
time/logging (s)                   0.00676798
time/saving (s)                    0.00996256
time/training (s)                  2.05736
time/epoch (s)                     2.83551
time/total (s)                    57.5817
Epoch                             19
-----------------------------  --------------
2019-04-22 21:09:47.069211 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 20 finished
-----------------------------  --------------
replay_buffer/size             10700
trainer/QF1 Loss                   4.7235
trainer/QF2 Loss                   4.74719
trainer/Policy Loss               25.5287
trainer/Q1 Predictions Mean      -25.1209
trainer/Q1 Predictions Std        11.4911
trainer/Q1 Predictions Max       -20.7235
trainer/Q1 Predictions Min       -79.2217
trainer/Q2 Predictions Mean      -25.1284
trainer/Q2 Predictions Std        11.5064
trainer/Q2 Predictions Max       -20.7437
trainer/Q2 Predictions Min       -79.0873
trainer/Q Targets Mean           -24.8635
trainer/Q Targets Std             12.0082
trainer/Q Targets Max             -0.0925275
trainer/Q Targets Min            -81.0003
trainer/Log Pis Mean               1.28759
trainer/Log Pis Std                1.67932
trainer/Log Pis Max                7.1235
trainer/Log Pis Min               -2.68289
trainer/Policy mu Mean             0.161465
trainer/Policy mu Std              0.932686
trainer/Policy mu Max              2.86515
trainer/Policy mu Min             -2.65303
trainer/Policy log std Mean       -1.41641
trainer/Policy log std Std         0.289002
trainer/Policy log std Max        -0.425959
trainer/Policy log std Min        -1.71117
trainer/Alpha                      0.070032
trainer/Alpha Loss                -1.89402
exploration/num steps total    10700
exploration/num paths total      107
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.518871
exploration/Rewards Std            1.17612
exploration/Rewards Max           -0.0159203
exploration/Rewards Min          -10.3031
exploration/Returns Mean         -51.8871
exploration/Returns Std           18.3774
exploration/Returns Max          -34.8587
exploration/Returns Min          -80.5219
exploration/Actions Mean           0.0302949
exploration/Actions Std            0.330139
exploration/Actions Max            0.998467
exploration/Actions Min           -0.999667
exploration/Num Paths              5
exploration/Average Returns      -51.8871
evaluation/num steps total     52500
evaluation/num paths total       525
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.795453
evaluation/Rewards Std             1.69667
evaluation/Rewards Max            -0.017501
evaluation/Rewards Min            -8.82557
evaluation/Returns Mean          -79.5453
evaluation/Returns Std           157.324
evaluation/Returns Max            -9.99362
evaluation/Returns Min          -529.847
evaluation/Actions Mean            0.122885
evaluation/Actions Std             0.328383
evaluation/Actions Max             0.994831
evaluation/Actions Min            -0.990542
evaluation/Num Paths              25
evaluation/Average Returns       -79.5453
time/data storing (s)              0.00297603
time/evaluation sampling (s)       0.539007
time/exploration sampling (s)      0.149627
time/logging (s)                   0.00922937
time/saving (s)                    0.0023866
time/training (s)                  2.04065
time/epoch (s)                     2.74388
time/total (s)                    60.3308
Epoch                             20
-----------------------------  --------------
2019-04-22 21:09:49.766868 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 21 finished
-----------------------------  --------------
replay_buffer/size             11200
trainer/QF1 Loss                   4.51952
trainer/QF2 Loss                   4.52439
trainer/Policy Loss               27.0396
trainer/Q1 Predictions Mean      -26.4089
trainer/Q1 Predictions Std        13.9716
trainer/Q1 Predictions Max       -20.4497
trainer/Q1 Predictions Min       -91.455
trainer/Q2 Predictions Mean      -26.3998
trainer/Q2 Predictions Std        13.9536
trainer/Q2 Predictions Max       -20.4607
trainer/Q2 Predictions Min       -91.539
trainer/Q Targets Mean           -26.2947
trainer/Q Targets Std             14.1813
trainer/Q Targets Max             -0.354376
trainer/Q Targets Min            -92.6794
trainer/Log Pis Mean               1.82235
trainer/Log Pis Std                1.96198
trainer/Log Pis Max                8.74178
trainer/Log Pis Min               -1.60278
trainer/Policy mu Mean             0.244025
trainer/Policy mu Std              1.11881
trainer/Policy mu Max              3.20841
trainer/Policy mu Min             -2.78293
trainer/Policy log std Mean       -1.41588
trainer/Policy log std Std         0.351722
trainer/Policy log std Max        -0.450286
trainer/Policy log std Min        -1.83719
trainer/Alpha                      0.062781
trainer/Alpha Loss                -0.491729
exploration/num steps total    11200
exploration/num paths total      112
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.25369
exploration/Rewards Std            1.74486
exploration/Rewards Max           -0.0151884
exploration/Rewards Min           -9.71863
exploration/Returns Mean        -125.369
exploration/Returns Std          131.416
exploration/Returns Max          -40.0924
exploration/Returns Min         -387.134
exploration/Actions Mean           0.198355
exploration/Actions Std            0.453763
exploration/Actions Max            0.998622
exploration/Actions Min           -0.984045
exploration/Num Paths              5
exploration/Average Returns     -125.369
evaluation/num steps total     55000
evaluation/num paths total       550
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.614922
evaluation/Rewards Std             1.35732
evaluation/Rewards Max            -0.0814159
evaluation/Rewards Min           -10.1796
evaluation/Returns Mean          -61.4922
evaluation/Returns Std            91.0262
evaluation/Returns Max           -23.972
evaluation/Returns Min          -498.503
evaluation/Actions Mean            0.0100277
evaluation/Actions Std             0.239036
evaluation/Actions Max             0.997158
evaluation/Actions Min            -0.993835
evaluation/Num Paths              25
evaluation/Average Returns       -61.4922
time/data storing (s)              0.00298971
time/evaluation sampling (s)       0.551182
time/exploration sampling (s)      0.171624
time/logging (s)                   0.00654422
time/saving (s)                    0.00202862
time/training (s)                  1.95349
time/epoch (s)                     2.68786
time/total (s)                    63.024
Epoch                             21
-----------------------------  --------------
2019-04-22 21:09:52.571700 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 22 finished
-----------------------------  --------------
replay_buffer/size             11700
trainer/QF1 Loss                  28.1555
trainer/QF2 Loss                  28.3216
trainer/Policy Loss               24.6519
trainer/Q1 Predictions Mean      -24.1376
trainer/Q1 Predictions Std        10.4436
trainer/Q1 Predictions Max       -20.0276
trainer/Q1 Predictions Min       -97.277
trainer/Q2 Predictions Mean      -24.1488
trainer/Q2 Predictions Std        10.4571
trainer/Q2 Predictions Max       -20.0582
trainer/Q2 Predictions Min       -97.4275
trainer/Q Targets Mean           -23.6228
trainer/Q Targets Std             11.023
trainer/Q Targets Max             -0.572127
trainer/Q Targets Min            -97.731
trainer/Log Pis Mean               1.49354
trainer/Log Pis Std                1.55012
trainer/Log Pis Max                6.40047
trainer/Log Pis Min               -2.42125
trainer/Policy mu Mean             0.11659
trainer/Policy mu Std              0.977701
trainer/Policy mu Max              3.13773
trainer/Policy mu Min             -2.94086
trainer/Policy log std Mean       -1.53702
trainer/Policy log std Std         0.375646
trainer/Policy log std Max        -0.299266
trainer/Policy log std Min        -1.97706
trainer/Alpha                      0.0575413
trainer/Alpha Loss                -1.44598
exploration/num steps total    11700
exploration/num paths total      117
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.400948
exploration/Rewards Std            0.83032
exploration/Rewards Max           -0.00918924
exploration/Rewards Min           -9.45806
exploration/Returns Mean         -40.0948
exploration/Returns Std           14.2678
exploration/Returns Max          -27.9135
exploration/Returns Min          -65.1077
exploration/Actions Mean           0.0118492
exploration/Actions Std            0.289986
exploration/Actions Max            0.9972
exploration/Actions Min           -0.987712
exploration/Num Paths              5
exploration/Average Returns      -40.0948
evaluation/num steps total     57500
evaluation/num paths total       575
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.719101
evaluation/Rewards Std             1.45626
evaluation/Rewards Max            -0.0644248
evaluation/Rewards Min           -10.2112
evaluation/Returns Mean          -71.9101
evaluation/Returns Std           111.551
evaluation/Returns Max           -20.4541
evaluation/Returns Min          -454.623
evaluation/Actions Mean            0.0454375
evaluation/Actions Std             0.294893
evaluation/Actions Max             0.996229
evaluation/Actions Min            -0.993293
evaluation/Num Paths              25
evaluation/Average Returns       -71.9101
time/data storing (s)              0.00292416
time/evaluation sampling (s)       0.546236
time/exploration sampling (s)      0.15757
time/logging (s)                   0.00717829
time/saving (s)                    0.0016038
time/training (s)                  2.08401
time/epoch (s)                     2.79952
time/total (s)                    65.8284
Epoch                             22
-----------------------------  --------------
2019-04-22 21:09:55.314942 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 23 finished
-----------------------------  --------------
replay_buffer/size             12200
trainer/QF1 Loss                   0.650486
trainer/QF2 Loss                   0.694276
trainer/Policy Loss               24.6293
trainer/Q1 Predictions Mean      -23.9595
trainer/Q1 Predictions Std        10.2622
trainer/Q1 Predictions Max       -19.7991
trainer/Q1 Predictions Min       -75.8132
trainer/Q2 Predictions Mean      -23.9349
trainer/Q2 Predictions Std        10.2143
trainer/Q2 Predictions Max       -19.782
trainer/Q2 Predictions Min       -75.663
trainer/Q Targets Mean           -24.2231
trainer/Q Targets Std             10.6041
trainer/Q Targets Max            -19.8235
trainer/Q Targets Min            -76.2014
trainer/Log Pis Mean               1.85902
trainer/Log Pis Std                1.25843
trainer/Log Pis Max                5.61218
trainer/Log Pis Min               -1.61702
trainer/Policy mu Mean             0.152601
trainer/Policy mu Std              0.96559
trainer/Policy mu Max              2.89659
trainer/Policy mu Min             -2.74257
trainer/Policy log std Mean       -1.66746
trainer/Policy log std Std         0.405166
trainer/Policy log std Max        -0.542431
trainer/Policy log std Min        -2.12159
trainer/Alpha                      0.0537156
trainer/Alpha Loss                -0.412216
exploration/num steps total    12200
exploration/num paths total      122
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.535067
exploration/Rewards Std            1.40192
exploration/Rewards Max           -0.00825884
exploration/Rewards Min          -10.3445
exploration/Returns Mean         -53.5067
exploration/Returns Std           17.0906
exploration/Returns Max          -22.7078
exploration/Returns Min          -72.2401
exploration/Actions Mean           0.0263776
exploration/Actions Std            0.315479
exploration/Actions Max            0.99862
exploration/Actions Min           -0.998189
exploration/Num Paths              5
exploration/Average Returns      -53.5067
evaluation/num steps total     60000
evaluation/num paths total       600
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.624884
evaluation/Rewards Std             1.43108
evaluation/Rewards Max            -0.0194474
evaluation/Rewards Min            -9.67248
evaluation/Returns Mean          -62.4884
evaluation/Returns Std           116.604
evaluation/Returns Max           -12.0661
evaluation/Returns Min          -482.526
evaluation/Actions Mean            0.0104139
evaluation/Actions Std             0.308852
evaluation/Actions Max             0.993787
evaluation/Actions Min            -0.996479
evaluation/Num Paths              25
evaluation/Average Returns       -62.4884
time/data storing (s)              0.00287511
time/evaluation sampling (s)       0.550928
time/exploration sampling (s)      0.155458
time/logging (s)                   0.00716308
time/saving (s)                    0.00266585
time/training (s)                  2.01793
time/epoch (s)                     2.73702
time/total (s)                    68.5705
Epoch                             23
-----------------------------  --------------
2019-04-22 21:09:58.073032 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 24 finished
-----------------------------  --------------
replay_buffer/size             12700
trainer/QF1 Loss                  25.9703
trainer/QF2 Loss                  26.0941
trainer/Policy Loss               24.4361
trainer/Q1 Predictions Mean      -23.1729
trainer/Q1 Predictions Std        10.6195
trainer/Q1 Predictions Max       -19.2498
trainer/Q1 Predictions Min       -92.62
trainer/Q2 Predictions Mean      -23.1874
trainer/Q2 Predictions Std        10.6085
trainer/Q2 Predictions Max       -19.2511
trainer/Q2 Predictions Min       -92.4675
trainer/Q Targets Mean           -22.6056
trainer/Q Targets Std             10.4163
trainer/Q Targets Max             -3.10132
trainer/Q Targets Min            -93.5286
trainer/Log Pis Mean               2.05664
trainer/Log Pis Std                1.79673
trainer/Log Pis Max                9.41749
trainer/Log Pis Min               -1.91134
trainer/Policy mu Mean             0.0597212
trainer/Policy mu Std              0.942916
trainer/Policy mu Max              3.03434
trainer/Policy mu Min             -2.9375
trainer/Policy log std Mean       -1.75615
trainer/Policy log std Std         0.413205
trainer/Policy log std Max        -0.528208
trainer/Policy log std Min        -2.22958
trainer/Alpha                      0.051393
trainer/Alpha Loss                 0.168125
exploration/num steps total    12700
exploration/num paths total      127
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.658098
exploration/Rewards Std            1.55633
exploration/Rewards Max           -0.00496745
exploration/Rewards Min          -10.2565
exploration/Returns Mean         -65.8098
exploration/Returns Std           11.2306
exploration/Returns Max          -49.0248
exploration/Returns Min          -79.6556
exploration/Actions Mean           0.0364517
exploration/Actions Std            0.303553
exploration/Actions Max            0.999664
exploration/Actions Min           -0.997749
exploration/Num Paths              5
exploration/Average Returns      -65.8098
evaluation/num steps total     62500
evaluation/num paths total       625
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -1.11796
evaluation/Rewards Std             1.81531
evaluation/Rewards Max            -0.101946
evaluation/Rewards Min           -11.0939
evaluation/Returns Mean         -111.796
evaluation/Returns Std           158.869
evaluation/Returns Max           -20.6177
evaluation/Returns Min          -568.674
evaluation/Actions Mean           -0.0170204
evaluation/Actions Std             0.41268
evaluation/Actions Max             0.995989
evaluation/Actions Min            -0.996486
evaluation/Num Paths              25
evaluation/Average Returns      -111.796
time/data storing (s)              0.00302774
time/evaluation sampling (s)       0.573407
time/exploration sampling (s)      0.160581
time/logging (s)                   0.00702302
time/saving (s)                    0.00199452
time/training (s)                  2.00595
time/epoch (s)                     2.75199
time/total (s)                    71.3273
Epoch                             24
-----------------------------  --------------
2019-04-22 21:10:00.717743 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 25 finished
-----------------------------  --------------
replay_buffer/size             13200
trainer/QF1 Loss                   3.69981
trainer/QF2 Loss                   3.69051
trainer/Policy Loss               22.6017
trainer/Q1 Predictions Mean      -21.6919
trainer/Q1 Predictions Std         7.934
trainer/Q1 Predictions Max       -19.052
trainer/Q1 Predictions Min       -72.8082
trainer/Q2 Predictions Mean      -21.6987
trainer/Q2 Predictions Std         7.97004
trainer/Q2 Predictions Max       -18.9878
trainer/Q2 Predictions Min       -73.1077
trainer/Q Targets Mean           -21.5356
trainer/Q Targets Std              8.35216
trainer/Q Targets Max             -0.721865
trainer/Q Targets Min            -73.329
trainer/Log Pis Mean               1.61142
trainer/Log Pis Std                1.48329
trainer/Log Pis Max                6.55309
trainer/Log Pis Min               -3.59423
trainer/Policy mu Mean             0.108301
trainer/Policy mu Std              0.785991
trainer/Policy mu Max              2.99176
trainer/Policy mu Min             -1.79127
trainer/Policy log std Mean       -1.78393
trainer/Policy log std Std         0.380111
trainer/Policy log std Max        -0.448411
trainer/Policy log std Min        -2.18301
trainer/Alpha                      0.0495273
trainer/Alpha Loss                -1.16772
exploration/num steps total    13200
exploration/num paths total      132
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.450053
exploration/Rewards Std            1.12228
exploration/Rewards Max           -0.0133432
exploration/Rewards Min          -10.6514
exploration/Returns Mean         -45.0053
exploration/Returns Std           18.8345
exploration/Returns Max          -23.4125
exploration/Returns Min          -77.8985
exploration/Actions Mean           0.0126804
exploration/Actions Std            0.282113
exploration/Actions Max            0.999696
exploration/Actions Min           -0.999282
exploration/Num Paths              5
exploration/Average Returns      -45.0053
evaluation/num steps total     65000
evaluation/num paths total       650
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.513409
evaluation/Rewards Std             1.21346
evaluation/Rewards Max            -0.06866
evaluation/Rewards Min           -10.4199
evaluation/Returns Mean          -51.3409
evaluation/Returns Std            64.9458
evaluation/Returns Max           -16.9811
evaluation/Returns Min          -361.232
evaluation/Actions Mean            0.022121
evaluation/Actions Std             0.26356
evaluation/Actions Max             0.995954
evaluation/Actions Min            -0.995679
evaluation/Num Paths              25
evaluation/Average Returns       -51.3409
time/data storing (s)              0.0030103
time/evaluation sampling (s)       0.538131
time/exploration sampling (s)      0.147993
time/logging (s)                   0.00531085
time/saving (s)                    0.00203739
time/training (s)                  1.94104
time/epoch (s)                     2.63752
time/total (s)                    73.9691
Epoch                             25
-----------------------------  --------------
2019-04-22 21:10:03.385547 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 26 finished
-----------------------------  --------------
replay_buffer/size             13700
trainer/QF1 Loss                   3.57587
trainer/QF2 Loss                   3.55558
trainer/Policy Loss               22.4733
trainer/Q1 Predictions Mean      -21.1803
trainer/Q1 Predictions Std         6.7753
trainer/Q1 Predictions Max       -18.3928
trainer/Q1 Predictions Min       -55.1605
trainer/Q2 Predictions Mean      -21.1705
trainer/Q2 Predictions Std         6.70757
trainer/Q2 Predictions Max       -18.3739
trainer/Q2 Predictions Min       -54.5839
trainer/Q Targets Mean           -21.2041
trainer/Q Targets Std              7.08344
trainer/Q Targets Max             -0.534152
trainer/Q Targets Min            -55.7461
trainer/Log Pis Mean               1.8739
trainer/Log Pis Std                1.37341
trainer/Log Pis Max                6.65871
trainer/Log Pis Min               -2.54441
trainer/Policy mu Mean             0.0478219
trainer/Policy mu Std              0.862277
trainer/Policy mu Max              3.16438
trainer/Policy mu Min             -3.10139
trainer/Policy log std Mean       -1.86344
trainer/Policy log std Std         0.42007
trainer/Policy log std Max        -0.359366
trainer/Policy log std Min        -2.25691
trainer/Alpha                      0.0491605
trainer/Alpha Loss                -0.379911
exploration/num steps total    13700
exploration/num paths total      137
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.597383
exploration/Rewards Std            1.50163
exploration/Rewards Max           -0.00901429
exploration/Rewards Min          -10.2343
exploration/Returns Mean         -59.7383
exploration/Returns Std           20.4354
exploration/Returns Max          -24.25
exploration/Returns Min          -79.4733
exploration/Actions Mean           0.0450329
exploration/Actions Std            0.274092
exploration/Actions Max            0.99956
exploration/Actions Min           -0.992568
exploration/Num Paths              5
exploration/Average Returns      -59.7383
evaluation/num steps total     67500
evaluation/num paths total       675
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.81917
evaluation/Rewards Std             1.45944
evaluation/Rewards Max            -0.118127
evaluation/Rewards Min            -9.16821
evaluation/Returns Mean          -81.917
evaluation/Returns Std           107.109
evaluation/Returns Max           -25.1272
evaluation/Returns Min          -401.061
evaluation/Actions Mean            0.0115599
evaluation/Actions Std             0.367415
evaluation/Actions Max             0.99679
evaluation/Actions Min            -0.996841
evaluation/Num Paths              25
evaluation/Average Returns       -81.917
time/data storing (s)              0.00301185
time/evaluation sampling (s)       0.552152
time/exploration sampling (s)      0.146527
time/logging (s)                   0.00684835
time/saving (s)                    0.001974
time/training (s)                  1.95358
time/epoch (s)                     2.66409
time/total (s)                    76.6374
Epoch                             26
-----------------------------  --------------
2019-04-22 21:10:06.007358 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 27 finished
-----------------------------  --------------
replay_buffer/size             14200
trainer/QF1 Loss                   6.76764
trainer/QF2 Loss                   6.79657
trainer/Policy Loss               21.6192
trainer/Q1 Predictions Mean      -20.2559
trainer/Q1 Predictions Std         6.62606
trainer/Q1 Predictions Max       -18.0598
trainer/Q1 Predictions Min       -71.634
trainer/Q2 Predictions Mean      -20.2694
trainer/Q2 Predictions Std         6.66988
trainer/Q2 Predictions Max       -18.0648
trainer/Q2 Predictions Min       -71.97
trainer/Q Targets Mean           -20.0212
trainer/Q Targets Std              7.37512
trainer/Q Targets Max             -0.108317
trainer/Q Targets Min            -73.7688
trainer/Log Pis Mean               2.08255
trainer/Log Pis Std                1.24258
trainer/Log Pis Max                5.78152
trainer/Log Pis Min               -2.36447
trainer/Policy mu Mean            -0.0987322
trainer/Policy mu Std              0.801851
trainer/Policy mu Max              2.92808
trainer/Policy mu Min             -2.89878
trainer/Policy log std Mean       -1.91496
trainer/Policy log std Std         0.416986
trainer/Policy log std Max        -0.361949
trainer/Policy log std Min        -2.33531
trainer/Alpha                      0.0492878
trainer/Alpha Loss                 0.248485
exploration/num steps total    14200
exploration/num paths total      142
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.492339
exploration/Rewards Std            1.169
exploration/Rewards Max           -0.0337511
exploration/Rewards Min          -10.705
exploration/Returns Mean         -49.2339
exploration/Returns Std           21.2968
exploration/Returns Max          -24.6768
exploration/Returns Min          -80.2844
exploration/Actions Mean           0.0293749
exploration/Actions Std            0.261067
exploration/Actions Max            0.999156
exploration/Actions Min           -0.987399
exploration/Num Paths              5
exploration/Average Returns      -49.2339
evaluation/num steps total     70000
evaluation/num paths total       700
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.578489
evaluation/Rewards Std             1.28946
evaluation/Rewards Max            -0.0639933
evaluation/Rewards Min           -10.6831
evaluation/Returns Mean          -57.8489
evaluation/Returns Std            95.0326
evaluation/Returns Max           -22.7312
evaluation/Returns Min          -516.392
evaluation/Actions Mean            0.020415
evaluation/Actions Std             0.254402
evaluation/Actions Max             0.996625
evaluation/Actions Min            -0.995902
evaluation/Num Paths              25
evaluation/Average Returns       -57.8489
time/data storing (s)              0.0028444
time/evaluation sampling (s)       0.534347
time/exploration sampling (s)      0.146523
time/logging (s)                   0.00622576
time/saving (s)                    0.00157474
time/training (s)                  1.92351
time/epoch (s)                     2.61503
time/total (s)                    79.2572
Epoch                             27
-----------------------------  --------------
2019-04-22 21:10:08.607908 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 28 finished
-----------------------------  --------------
replay_buffer/size             14700
trainer/QF1 Loss                   3.63947
trainer/QF2 Loss                   3.59375
trainer/Policy Loss               23.1953
trainer/Q1 Predictions Mean      -21.9558
trainer/Q1 Predictions Std        12.0647
trainer/Q1 Predictions Max       -17.7592
trainer/Q1 Predictions Min       -82.2678
trainer/Q2 Predictions Mean      -21.9638
trainer/Q2 Predictions Std        12.0424
trainer/Q2 Predictions Max       -17.7365
trainer/Q2 Predictions Min       -82.6271
trainer/Q Targets Mean           -21.8756
trainer/Q Targets Std             12.4374
trainer/Q Targets Max             -1.00631
trainer/Q Targets Min            -86.8503
trainer/Log Pis Mean               2.17689
trainer/Log Pis Std                1.73264
trainer/Log Pis Max                9.65374
trainer/Log Pis Min               -2.06642
trainer/Policy mu Mean             0.0591867
trainer/Policy mu Std              0.949383
trainer/Policy mu Max              3.01826
trainer/Policy mu Min             -3.30041
trainer/Policy log std Mean       -1.86435
trainer/Policy log std Std         0.421931
trainer/Policy log std Max        -0.297215
trainer/Policy log std Min        -2.29307
trainer/Alpha                      0.0477761
trainer/Alpha Loss                 0.537957
exploration/num steps total    14700
exploration/num paths total      147
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.452175
exploration/Rewards Std            1.02239
exploration/Rewards Max           -0.0191649
exploration/Rewards Min          -10.196
exploration/Returns Mean         -45.2175
exploration/Returns Std           20.6135
exploration/Returns Max          -26.218
exploration/Returns Min          -83.0309
exploration/Actions Mean           0.0303324
exploration/Actions Std            0.25771
exploration/Actions Max            0.998888
exploration/Actions Min           -0.966352
exploration/Num Paths              5
exploration/Average Returns      -45.2175
evaluation/num steps total     72500
evaluation/num paths total       725
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.682592
evaluation/Rewards Std             1.30249
evaluation/Rewards Max            -0.125046
evaluation/Rewards Min           -11.3652
evaluation/Returns Mean          -68.2592
evaluation/Returns Std            84.0481
evaluation/Returns Max           -23.4259
evaluation/Returns Min          -370.765
evaluation/Actions Mean            0.020217
evaluation/Actions Std             0.317952
evaluation/Actions Max             0.995688
evaluation/Actions Min            -0.997285
evaluation/Num Paths              25
evaluation/Average Returns       -68.2592
time/data storing (s)              0.0029493
time/evaluation sampling (s)       0.533608
time/exploration sampling (s)      0.148501
time/logging (s)                   0.00658421
time/saving (s)                    0.00191196
time/training (s)                  1.90279
time/epoch (s)                     2.59635
time/total (s)                    81.8574
Epoch                             28
-----------------------------  --------------
2019-04-22 21:10:11.231954 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 29 finished
-----------------------------  --------------
replay_buffer/size             15200
trainer/QF1 Loss                   0.49979
trainer/QF2 Loss                   0.536195
trainer/Policy Loss               22.771
trainer/Q1 Predictions Mean      -21.7857
trainer/Q1 Predictions Std        11.2808
trainer/Q1 Predictions Max       -17.6525
trainer/Q1 Predictions Min       -73.8844
trainer/Q2 Predictions Mean      -21.7519
trainer/Q2 Predictions Std        11.2853
trainer/Q2 Predictions Max       -17.644
trainer/Q2 Predictions Min       -74.2018
trainer/Q Targets Mean           -21.7855
trainer/Q Targets Std             11.2439
trainer/Q Targets Max            -17.4701
trainer/Q Targets Min            -75.6716
trainer/Log Pis Mean               1.95699
trainer/Log Pis Std                1.85095
trainer/Log Pis Max                9.86977
trainer/Log Pis Min               -1.83651
trainer/Policy mu Mean             0.0770095
trainer/Policy mu Std              0.969619
trainer/Policy mu Max              3.5045
trainer/Policy mu Min             -3.20049
trainer/Policy log std Mean       -1.79576
trainer/Policy log std Std         0.406857
trainer/Policy log std Max        -0.262198
trainer/Policy log std Min        -2.16837
trainer/Alpha                      0.044157
trainer/Alpha Loss                -0.134178
exploration/num steps total    15200
exploration/num paths total      152
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.30736
exploration/Rewards Std            0.689427
exploration/Rewards Max           -0.014224
exploration/Rewards Min           -7.68458
exploration/Returns Mean         -30.736
exploration/Returns Std           10.6308
exploration/Returns Max          -17.952
exploration/Returns Min          -46.2135
exploration/Actions Mean           0.0185721
exploration/Actions Std            0.25187
exploration/Actions Max            0.996918
exploration/Actions Min           -0.996047
exploration/Num Paths              5
exploration/Average Returns      -30.736
evaluation/num steps total     75000
evaluation/num paths total       750
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.686371
evaluation/Rewards Std             1.4372
evaluation/Rewards Max            -0.0710997
evaluation/Rewards Min           -10.3217
evaluation/Returns Mean          -68.6371
evaluation/Returns Std           110.026
evaluation/Returns Max           -10.3975
evaluation/Returns Min          -423.449
evaluation/Actions Mean            0.00682706
evaluation/Actions Std             0.354059
evaluation/Actions Max             0.998057
evaluation/Actions Min            -0.996139
evaluation/Num Paths              25
evaluation/Average Returns       -68.6371
time/data storing (s)              0.00307248
time/evaluation sampling (s)       0.539161
time/exploration sampling (s)      0.154823
time/logging (s)                   0.00658973
time/saving (s)                    0.0019465
time/training (s)                  1.91253
time/epoch (s)                     2.61812
time/total (s)                    84.4803
Epoch                             29
-----------------------------  --------------
2019-04-22 21:10:13.834550 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 30 finished
-----------------------------  --------------
replay_buffer/size             15700
trainer/QF1 Loss                   3.1087
trainer/QF2 Loss                   3.11053
trainer/Policy Loss               20.9909
trainer/Q1 Predictions Mean      -19.7196
trainer/Q1 Predictions Std         7.5546
trainer/Q1 Predictions Max       -17.1628
trainer/Q1 Predictions Min       -67.942
trainer/Q2 Predictions Mean      -19.7103
trainer/Q2 Predictions Std         7.54041
trainer/Q2 Predictions Max       -17.1065
trainer/Q2 Predictions Min       -67.8609
trainer/Q Targets Mean           -19.7186
trainer/Q Targets Std              7.73623
trainer/Q Targets Max             -1.25315
trainer/Q Targets Min            -68.5835
trainer/Log Pis Mean               1.83583
trainer/Log Pis Std                1.47568
trainer/Log Pis Max                7.41799
trainer/Log Pis Min               -2.32329
trainer/Policy mu Mean             0.0242023
trainer/Policy mu Std              0.868681
trainer/Policy mu Max              3.28927
trainer/Policy mu Min             -3.21332
trainer/Policy log std Mean       -1.82856
trainer/Policy log std Std         0.444129
trainer/Policy log std Max        -0.215544
trainer/Policy log std Min        -2.26184
trainer/Alpha                      0.0415321
trainer/Alpha Loss                -0.522257
exploration/num steps total    15700
exploration/num paths total      157
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.43334
exploration/Rewards Std            1.09876
exploration/Rewards Max           -0.00841336
exploration/Rewards Min          -10.3867
exploration/Returns Mean         -43.334
exploration/Returns Std           14.2701
exploration/Returns Max          -32.0034
exploration/Returns Min          -70.3768
exploration/Actions Mean           0.0334224
exploration/Actions Std            0.280973
exploration/Actions Max            0.99887
exploration/Actions Min           -0.999392
exploration/Num Paths              5
exploration/Average Returns      -43.334
evaluation/num steps total     77500
evaluation/num paths total       775
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.427755
evaluation/Rewards Std             1.10883
evaluation/Rewards Max            -0.0562593
evaluation/Rewards Min           -10.1156
evaluation/Returns Mean          -42.7755
evaluation/Returns Std            75.7966
evaluation/Returns Max           -12.2594
evaluation/Returns Min          -408.821
evaluation/Actions Mean            0.0156614
evaluation/Actions Std             0.259839
evaluation/Actions Max             0.998059
evaluation/Actions Min            -0.997277
evaluation/Num Paths              25
evaluation/Average Returns       -42.7755
time/data storing (s)              0.00290581
time/evaluation sampling (s)       0.521968
time/exploration sampling (s)      0.140351
time/logging (s)                   0.00570101
time/saving (s)                    0.00936388
time/training (s)                  1.91575
time/epoch (s)                     2.59604
time/total (s)                    87.0808
Epoch                             30
-----------------------------  --------------
2019-04-22 21:10:16.426805 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 31 finished
-----------------------------  --------------
replay_buffer/size             16200
trainer/QF1 Loss                   6.30123
trainer/QF2 Loss                   6.22765
trainer/Policy Loss               22.1515
trainer/Q1 Predictions Mean      -21.0949
trainer/Q1 Predictions Std        12.1529
trainer/Q1 Predictions Max       -16.9457
trainer/Q1 Predictions Min       -83.6113
trainer/Q2 Predictions Mean      -21.0928
trainer/Q2 Predictions Std        12.1809
trainer/Q2 Predictions Max       -16.9367
trainer/Q2 Predictions Min       -83.7438
trainer/Q Targets Mean           -20.9445
trainer/Q Targets Std             12.8598
trainer/Q Targets Max             -0.198177
trainer/Q Targets Min            -84.8675
trainer/Log Pis Mean               2.05926
trainer/Log Pis Std                1.81677
trainer/Log Pis Max                7.8207
trainer/Log Pis Min               -3.86739
trainer/Policy mu Mean             0.171764
trainer/Policy mu Std              0.997653
trainer/Policy mu Max              3.18155
trainer/Policy mu Min             -3.35818
trainer/Policy log std Mean       -1.88096
trainer/Policy log std Std         0.502977
trainer/Policy log std Max        -0.276392
trainer/Policy log std Min        -2.32518
trainer/Alpha                      0.0411085
trainer/Alpha Loss                 0.189125
exploration/num steps total    16200
exploration/num paths total      162
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.429208
exploration/Rewards Std            1.22165
exploration/Rewards Max           -0.00865836
exploration/Rewards Min          -10.1031
exploration/Returns Mean         -42.9208
exploration/Returns Std           19.709
exploration/Returns Max          -21.2679
exploration/Returns Min          -70.0106
exploration/Actions Mean           0.0401704
exploration/Actions Std            0.268427
exploration/Actions Max            0.999799
exploration/Actions Min           -0.91124
exploration/Num Paths              5
exploration/Average Returns      -42.9208
evaluation/num steps total     80000
evaluation/num paths total       800
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.374214
evaluation/Rewards Std             1.10731
evaluation/Rewards Max            -0.0411614
evaluation/Rewards Min           -10.7074
evaluation/Returns Mean          -37.4214
evaluation/Returns Std            46.7937
evaluation/Returns Max            -9.02573
evaluation/Returns Min          -247.818
evaluation/Actions Mean            0.0171001
evaluation/Actions Std             0.241466
evaluation/Actions Max             0.998676
evaluation/Actions Min            -0.993926
evaluation/Num Paths              25
evaluation/Average Returns       -37.4214
time/data storing (s)              0.0028305
time/evaluation sampling (s)       0.519208
time/exploration sampling (s)      0.143747
time/logging (s)                   0.00661482
time/saving (s)                    0.00206938
time/training (s)                  1.91283
time/epoch (s)                     2.5873
time/total (s)                    89.6728
Epoch                             31
-----------------------------  --------------
2019-04-22 21:10:19.028716 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 32 finished
-----------------------------  --------------
replay_buffer/size             16700
trainer/QF1 Loss                   3.23208
trainer/QF2 Loss                   3.24725
trainer/Policy Loss               20.5233
trainer/Q1 Predictions Mean      -19.3775
trainer/Q1 Predictions Std        11.2616
trainer/Q1 Predictions Max       -16.4473
trainer/Q1 Predictions Min       -95.4379
trainer/Q2 Predictions Mean      -19.3896
trainer/Q2 Predictions Std        11.2499
trainer/Q2 Predictions Max       -16.4293
trainer/Q2 Predictions Min       -95.51
trainer/Q Targets Mean           -19.4354
trainer/Q Targets Std             11.0359
trainer/Q Targets Max             -0.0531792
trainer/Q Targets Min            -90.2346
trainer/Log Pis Mean               1.8467
trainer/Log Pis Std                1.60055
trainer/Log Pis Max                9.71758
trainer/Log Pis Min               -4.77147
trainer/Policy mu Mean             0.0577105
trainer/Policy mu Std              0.839287
trainer/Policy mu Max              3.03118
trainer/Policy mu Min             -3.13715
trainer/Policy log std Mean       -1.96006
trainer/Policy log std Std         0.435138
trainer/Policy log std Max        -0.444408
trainer/Policy log std Min        -2.36206
trainer/Alpha                      0.0443446
trainer/Alpha Loss                -0.477648
exploration/num steps total    16700
exploration/num paths total      167
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.37193
exploration/Rewards Std            0.981521
exploration/Rewards Max           -0.00451807
exploration/Rewards Min           -7.80773
exploration/Returns Mean         -37.193
exploration/Returns Std            4.38825
exploration/Returns Max          -30.7967
exploration/Returns Min          -43.5161
exploration/Actions Mean           0.0355555
exploration/Actions Std            0.265809
exploration/Actions Max            0.998795
exploration/Actions Min           -0.99892
exploration/Num Paths              5
exploration/Average Returns      -37.193
evaluation/num steps total     82500
evaluation/num paths total       825
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.340082
evaluation/Rewards Std             1.02698
evaluation/Rewards Max            -0.0693895
evaluation/Rewards Min           -11.0968
evaluation/Returns Mean          -34.0082
evaluation/Returns Std            39.6007
evaluation/Returns Max            -7.8968
evaluation/Returns Min          -211.625
evaluation/Actions Mean            0.00791392
evaluation/Actions Std             0.231439
evaluation/Actions Max             0.99804
evaluation/Actions Min            -0.997893
evaluation/Num Paths              25
evaluation/Average Returns       -34.0082
time/data storing (s)              0.00296421
time/evaluation sampling (s)       0.533972
time/exploration sampling (s)      0.14495
time/logging (s)                   0.00665041
time/saving (s)                    0.00193229
time/training (s)                  1.9055
time/epoch (s)                     2.59596
time/total (s)                    92.2736
Epoch                             32
-----------------------------  --------------
2019-04-22 21:10:21.621835 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 33 finished
-----------------------------  --------------
replay_buffer/size             17200
trainer/QF1 Loss                   8.31751
trainer/QF2 Loss                   8.36036
trainer/Policy Loss               21.6064
trainer/Q1 Predictions Mean      -20.2186
trainer/Q1 Predictions Std        12.273
trainer/Q1 Predictions Max       -16.16
trainer/Q1 Predictions Min       -82.3554
trainer/Q2 Predictions Mean      -20.2092
trainer/Q2 Predictions Std        12.2799
trainer/Q2 Predictions Max       -16.1292
trainer/Q2 Predictions Min       -82.4556
trainer/Q Targets Mean           -20.0805
trainer/Q Targets Std             13.1021
trainer/Q Targets Max             -0.163719
trainer/Q Targets Min            -85.7358
trainer/Log Pis Mean               2.13659
trainer/Log Pis Std                1.60673
trainer/Log Pis Max                8.61948
trainer/Log Pis Min               -3.93136
trainer/Policy mu Mean            -0.0408207
trainer/Policy mu Std              0.984294
trainer/Policy mu Max              3.09353
trainer/Policy mu Min             -3.00096
trainer/Policy log std Mean       -1.82311
trainer/Policy log std Std         0.494598
trainer/Policy log std Max        -0.310684
trainer/Policy log std Min        -2.31742
trainer/Alpha                      0.0466847
trainer/Alpha Loss                 0.418585
exploration/num steps total    17200
exploration/num paths total      172
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -1.16475
exploration/Rewards Std            1.76972
exploration/Rewards Max           -0.0175567
exploration/Rewards Min           -9.60368
exploration/Returns Mean        -116.475
exploration/Returns Std          148.453
exploration/Returns Max          -26.976
exploration/Returns Min         -412.229
exploration/Actions Mean           0.0169981
exploration/Actions Std            0.478659
exploration/Actions Max            0.998987
exploration/Actions Min           -0.999558
exploration/Num Paths              5
exploration/Average Returns     -116.475
evaluation/num steps total     85000
evaluation/num paths total       850
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.333693
evaluation/Rewards Std             0.969902
evaluation/Rewards Max            -0.131787
evaluation/Rewards Min           -10.0277
evaluation/Returns Mean          -33.3693
evaluation/Returns Std            12.7181
evaluation/Returns Max           -13.9014
evaluation/Returns Min           -64.4367
evaluation/Actions Mean            0.0316012
evaluation/Actions Std             0.196521
evaluation/Actions Max             0.995898
evaluation/Actions Min            -0.998285
evaluation/Num Paths              25
evaluation/Average Returns       -33.3693
time/data storing (s)              0.00293524
time/evaluation sampling (s)       0.521701
time/exploration sampling (s)      0.145944
time/logging (s)                   0.00495416
time/saving (s)                    0.00205182
time/training (s)                  1.90824
time/epoch (s)                     2.58583
time/total (s)                    94.8637
Epoch                             33
-----------------------------  --------------
2019-04-22 21:10:24.196820 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 34 finished
-----------------------------  --------------
replay_buffer/size             17700
trainer/QF1 Loss                   2.85111
trainer/QF2 Loss                   2.86684
trainer/Policy Loss               18.8325
trainer/Q1 Predictions Mean      -17.2927
trainer/Q1 Predictions Std         4.1771
trainer/Q1 Predictions Max       -15.7469
trainer/Q1 Predictions Min       -44.7165
trainer/Q2 Predictions Mean      -17.2897
trainer/Q2 Predictions Std         4.17449
trainer/Q2 Predictions Max       -15.7527
trainer/Q2 Predictions Min       -44.6431
trainer/Q Targets Mean           -17.4159
trainer/Q Targets Std              4.62636
trainer/Q Targets Max             -0.393161
trainer/Q Targets Min            -45.1183
trainer/Log Pis Mean               1.89525
trainer/Log Pis Std                1.32466
trainer/Log Pis Max                7.24664
trainer/Log Pis Min               -2.31082
trainer/Policy mu Mean            -0.0085342
trainer/Policy mu Std              0.741803
trainer/Policy mu Max              3.2484
trainer/Policy mu Min             -3.10621
trainer/Policy log std Mean       -1.94528
trainer/Policy log std Std         0.431481
trainer/Policy log std Max        -0.290879
trainer/Policy log std Min        -2.34295
trainer/Alpha                      0.0460476
trainer/Alpha Loss                -0.322428
exploration/num steps total    17700
exploration/num paths total      177
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.31655
exploration/Rewards Std            0.724089
exploration/Rewards Max           -0.0128943
exploration/Rewards Min           -6.64601
exploration/Returns Mean         -31.655
exploration/Returns Std            9.06298
exploration/Returns Max          -16.5314
exploration/Returns Min          -42.374
exploration/Actions Mean           0.0220114
exploration/Actions Std            0.263195
exploration/Actions Max            0.998779
exploration/Actions Min           -0.998024
exploration/Num Paths              5
exploration/Average Returns      -31.655
evaluation/num steps total     87500
evaluation/num paths total       875
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.810703
evaluation/Rewards Std             1.81775
evaluation/Rewards Max            -0.0586633
evaluation/Rewards Min           -10.6366
evaluation/Returns Mean          -81.0703
evaluation/Returns Std           153.095
evaluation/Returns Max            -8.83745
evaluation/Returns Min          -607.001
evaluation/Actions Mean            0.00824607
evaluation/Actions Std             0.362036
evaluation/Actions Max             0.997619
evaluation/Actions Min            -0.99852
evaluation/Num Paths              25
evaluation/Average Returns       -81.0703
time/data storing (s)              0.00288293
time/evaluation sampling (s)       0.531243
time/exploration sampling (s)      0.143186
time/logging (s)                   0.00660003
time/saving (s)                    0.00194804
time/training (s)                  1.88488
time/epoch (s)                     2.57074
time/total (s)                    97.4393
Epoch                             34
-----------------------------  --------------
2019-04-22 21:10:26.808780 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 35 finished
-----------------------------  --------------
replay_buffer/size             18200
trainer/QF1 Loss                   2.69113
trainer/QF2 Loss                   2.70785
trainer/Policy Loss               18.7886
trainer/Q1 Predictions Mean      -17.339
trainer/Q1 Predictions Std         5.58039
trainer/Q1 Predictions Max       -15.4303
trainer/Q1 Predictions Min       -49.5712
trainer/Q2 Predictions Mean      -17.3591
trainer/Q2 Predictions Std         5.57386
trainer/Q2 Predictions Max       -15.4594
trainer/Q2 Predictions Min       -49.9162
trainer/Q Targets Mean           -17.3967
trainer/Q Targets Std              5.86085
trainer/Q Targets Max             -0.341892
trainer/Q Targets Min            -48.8682
trainer/Log Pis Mean               1.93885
trainer/Log Pis Std                1.01199
trainer/Log Pis Max                5.3573
trainer/Log Pis Min               -3.46498
trainer/Policy mu Mean             0.0630005
trainer/Policy mu Std              0.750151
trainer/Policy mu Max              3.00561
trainer/Policy mu Min             -3.32032
trainer/Policy log std Mean       -1.90804
trainer/Policy log std Std         0.476971
trainer/Policy log std Max        -0.172188
trainer/Policy log std Min        -2.38545
trainer/Alpha                      0.0458133
trainer/Alpha Loss                -0.188526
exploration/num steps total    18200
exploration/num paths total      182
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.388323
exploration/Rewards Std            1.03457
exploration/Rewards Max           -0.0091856
exploration/Rewards Min           -8.76624
exploration/Returns Mean         -38.8323
exploration/Returns Std            8.87607
exploration/Returns Max          -29.543
exploration/Returns Min          -54.9971
exploration/Actions Mean           0.0419841
exploration/Actions Std            0.265617
exploration/Actions Max            0.9996
exploration/Actions Min           -0.981971
exploration/Num Paths              5
exploration/Average Returns      -38.8323
evaluation/num steps total     90000
evaluation/num paths total       900
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.648069
evaluation/Rewards Std             1.60833
evaluation/Rewards Max            -0.029559
evaluation/Rewards Min           -11.5103
evaluation/Returns Mean          -64.8069
evaluation/Returns Std           118.185
evaluation/Returns Max            -8.02547
evaluation/Returns Min          -495.039
evaluation/Actions Mean            0.0186106
evaluation/Actions Std             0.30281
evaluation/Actions Max             0.997053
evaluation/Actions Min            -0.997827
evaluation/Num Paths              25
evaluation/Average Returns       -64.8069
time/data storing (s)              0.00301634
time/evaluation sampling (s)       0.521698
time/exploration sampling (s)      0.145684
time/logging (s)                   0.00621355
time/saving (s)                    0.0019585
time/training (s)                  1.92769
time/epoch (s)                     2.60626
time/total (s)                   100.049
Epoch                             35
-----------------------------  --------------
2019-04-22 21:10:29.411417 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 36 finished
-----------------------------  --------------
replay_buffer/size             18700
trainer/QF1 Loss                   0.217013
trainer/QF2 Loss                   0.209234
trainer/Policy Loss               19.6432
trainer/Q1 Predictions Mean      -18.084
trainer/Q1 Predictions Std         9.27545
trainer/Q1 Predictions Max       -15.0434
trainer/Q1 Predictions Min       -62.8151
trainer/Q2 Predictions Mean      -18.1047
trainer/Q2 Predictions Std         9.28317
trainer/Q2 Predictions Max       -15.097
trainer/Q2 Predictions Min       -62.6639
trainer/Q Targets Mean           -18.268
trainer/Q Targets Std              9.31744
trainer/Q Targets Max            -15.1983
trainer/Q Targets Min            -64.9041
trainer/Log Pis Mean               1.99377
trainer/Log Pis Std                1.40556
trainer/Log Pis Max                6.31463
trainer/Log Pis Min               -1.75272
trainer/Policy mu Mean             0.057351
trainer/Policy mu Std              0.752516
trainer/Policy mu Max              3.17482
trainer/Policy mu Min             -3.10431
trainer/Policy log std Mean       -2.05691
trainer/Policy log std Std         0.421159
trainer/Policy log std Max        -0.474189
trainer/Policy log std Min        -2.50036
trainer/Alpha                      0.047271
trainer/Alpha Loss                -0.0190266
exploration/num steps total    18700
exploration/num paths total      187
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.438109
exploration/Rewards Std            1.30676
exploration/Rewards Max           -0.00374617
exploration/Rewards Min           -9.81728
exploration/Returns Mean         -43.8109
exploration/Returns Std           15.7312
exploration/Returns Max          -19.7391
exploration/Returns Min          -63.7758
exploration/Actions Mean           0.0379493
exploration/Actions Std            0.258021
exploration/Actions Max            0.999547
exploration/Actions Min           -0.997123
exploration/Num Paths              5
exploration/Average Returns      -43.8109
evaluation/num steps total     92500
evaluation/num paths total       925
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.211269
evaluation/Rewards Std             0.898672
evaluation/Rewards Max            -0.050803
evaluation/Rewards Min           -10.1571
evaluation/Returns Mean          -21.1269
evaluation/Returns Std            16.4382
evaluation/Returns Max            -5.17414
evaluation/Returns Min           -61.9527
evaluation/Actions Mean            0.0257417
evaluation/Actions Std             0.176034
evaluation/Actions Max             0.996931
evaluation/Actions Min            -0.993873
evaluation/Num Paths              25
evaluation/Average Returns       -21.1269
time/data storing (s)              0.0029458
time/evaluation sampling (s)       0.524135
time/exploration sampling (s)      0.142565
time/logging (s)                   0.00652993
time/saving (s)                    0.0019243
time/training (s)                  1.9196
time/epoch (s)                     2.5977
time/total (s)                   102.652
Epoch                             36
-----------------------------  --------------
2019-04-22 21:10:32.036070 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 37 finished
-----------------------------  --------------
replay_buffer/size             19200
trainer/QF1 Loss                   2.39552
trainer/QF2 Loss                   2.39197
trainer/Policy Loss               19.4691
trainer/Q1 Predictions Mean      -18.0787
trainer/Q1 Predictions Std        11.4434
trainer/Q1 Predictions Max       -14.7046
trainer/Q1 Predictions Min       -91.2289
trainer/Q2 Predictions Mean      -18.075
trainer/Q2 Predictions Std        11.4441
trainer/Q2 Predictions Max       -14.7359
trainer/Q2 Predictions Min       -91.1839
trainer/Q Targets Mean           -17.9787
trainer/Q Targets Std             11.4176
trainer/Q Targets Max             -0.0876764
trainer/Q Targets Min            -89.0633
trainer/Log Pis Mean               2.07064
trainer/Log Pis Std                1.64619
trainer/Log Pis Max                9.24447
trainer/Log Pis Min               -2.8663
trainer/Policy mu Mean             0.0724313
trainer/Policy mu Std              0.782767
trainer/Policy mu Max              2.988
trainer/Policy mu Min             -2.92839
trainer/Policy log std Mean       -2.03334
trainer/Policy log std Std         0.435137
trainer/Policy log std Max        -0.550242
trainer/Policy log std Min        -2.51005
trainer/Alpha                      0.049364
trainer/Alpha Loss                 0.212542
exploration/num steps total    19200
exploration/num paths total      192
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.404741
exploration/Rewards Std            1.2671
exploration/Rewards Max           -0.00406473
exploration/Rewards Min          -10.4331
exploration/Returns Mean         -40.4741
exploration/Returns Std           24.6941
exploration/Returns Max          -15.1566
exploration/Returns Min          -70.3278
exploration/Actions Mean           0.0294218
exploration/Actions Std            0.242973
exploration/Actions Max            0.998807
exploration/Actions Min           -0.988317
exploration/Num Paths              5
exploration/Average Returns      -40.4741
evaluation/num steps total     95000
evaluation/num paths total       950
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.173561
evaluation/Rewards Std             0.793436
evaluation/Rewards Max            -0.0296503
evaluation/Rewards Min            -9.60569
evaluation/Returns Mean          -17.3561
evaluation/Returns Std            12.7217
evaluation/Returns Max            -3.11173
evaluation/Returns Min           -47.7238
evaluation/Actions Mean            0.0186899
evaluation/Actions Std             0.170124
evaluation/Actions Max             0.995289
evaluation/Actions Min            -0.998524
evaluation/Num Paths              25
evaluation/Average Returns       -17.3561
time/data storing (s)              0.0028561
time/evaluation sampling (s)       0.534024
time/exploration sampling (s)      0.146211
time/logging (s)                   0.00654462
time/saving (s)                    0.00191371
time/training (s)                  1.92706
time/epoch (s)                     2.61861
time/total (s)                   105.275
Epoch                             37
-----------------------------  --------------
2019-04-22 21:10:34.618336 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 38 finished
-----------------------------  --------------
replay_buffer/size             19700
trainer/QF1 Loss                   2.70853
trainer/QF2 Loss                   2.76271
trainer/Policy Loss               19.0358
trainer/Q1 Predictions Mean      -17.5381
trainer/Q1 Predictions Std        10.9924
trainer/Q1 Predictions Max       -14.3614
trainer/Q1 Predictions Min       -95.7626
trainer/Q2 Predictions Mean      -17.5274
trainer/Q2 Predictions Std        10.9891
trainer/Q2 Predictions Max       -14.3608
trainer/Q2 Predictions Min       -95.6494
trainer/Q Targets Mean           -17.5948
trainer/Q Targets Std             10.7119
trainer/Q Targets Max             -0.0799271
trainer/Q Targets Min            -89.957
trainer/Log Pis Mean               1.99744
trainer/Log Pis Std                1.40972
trainer/Log Pis Max                8.73957
trainer/Log Pis Min               -2.57454
trainer/Policy mu Mean             0.034952
trainer/Policy mu Std              0.814622
trainer/Policy mu Max              3.23696
trainer/Policy mu Min             -3.1502
trainer/Policy log std Mean       -1.95908
trainer/Policy log std Std         0.474651
trainer/Policy log std Max        -0.452132
trainer/Policy log std Min        -2.48145
trainer/Alpha                      0.0487729
trainer/Alpha Loss                -0.00774463
exploration/num steps total    19700
exploration/num paths total      197
exploration/path length Mean     100
exploration/path length Std        0
exploration/path length Max      100
exploration/path length Min      100
exploration/Rewards Mean          -0.350241
exploration/Rewards Std            1.04333
exploration/Rewards Max           -0.00426035
exploration/Rewards Min           -9.93084
exploration/Returns Mean         -35.0241
exploration/Returns Std           19.0387
exploration/Returns Max          -14.435
exploration/Returns Min          -67.9453
exploration/Actions Mean           0.0188862
exploration/Actions Std            0.237623
exploration/Actions Max            0.998283
exploration/Actions Min           -0.9995
exploration/Num Paths              5
exploration/Average Returns      -35.0241
evaluation/num steps total     97500
evaluation/num paths total       975
evaluation/path length Mean      100
evaluation/path length Std         0
evaluation/path length Max       100
evaluation/path length Min       100
evaluation/Rewards Mean           -0.165878
evaluation/Rewards Std             0.811774
evaluation/Rewards Max            -0.00221513
evaluation/Rewards Min            -9.24326
evaluation/Returns Mean          -16.5878
evaluation/Returns Std            11.3079
evaluation/Returns Max            -1.65986
evaluation/Returns Min           -41.2201
evaluation/Actions Mean            0.0251389
evaluation/Actions Std             0.176211
evaluation/Actions Max             0.996626
evaluation/Actions Min            -0.997848
evaluation/Num Paths              25
evaluation/Average Returns       -16.5878
time/data storing (s)              0.00300381
time/evaluation sampling (s)       0.523453
time/exploration sampling (s)      0.14454
time/logging (s)                   0.00661617
time/saving (s)                    0.00164541
time/training (s)                  1.89708
time/epoch (s)                     2.57633
time/total (s)                   107.856
Epoch                             38
-----------------------------  --------------
2019-04-22 21:10:37.206216 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 39 finished
-----------------------------  ---------------
replay_buffer/size              20200
trainer/QF1 Loss                    2.06979
trainer/QF2 Loss                    2.06563
trainer/Policy Loss                17.5913
trainer/Q1 Predictions Mean       -16.0372
trainer/Q1 Predictions Std          5.82125
trainer/Q1 Predictions Max        -13.855
trainer/Q1 Predictions Min        -44.2186
trainer/Q2 Predictions Mean       -16.0526
trainer/Q2 Predictions Std          5.81387
trainer/Q2 Predictions Max        -13.8744
trainer/Q2 Predictions Min        -44.5268
trainer/Q Targets Mean            -16.2388
trainer/Q Targets Std               6.00666
trainer/Q Targets Max              -0.167681
trainer/Q Targets Min             -44.6796
trainer/Log Pis Mean                2.07095
trainer/Log Pis Std                 1.26636
trainer/Log Pis Max                 6.17616
trainer/Log Pis Min                -2.1992
trainer/Policy mu Mean              0.105988
trainer/Policy mu Std               0.733787
trainer/Policy mu Max               3.09742
trainer/Policy mu Min              -2.55518
trainer/Policy log std Mean        -2.06931
trainer/Policy log std Std          0.466717
trainer/Policy log std Max         -0.544033
trainer/Policy log std Min         -2.55438
trainer/Alpha                       0.0485663
trainer/Alpha Loss                  0.214621
exploration/num steps total     20200
exploration/num paths total       202
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.27526
exploration/Rewards Std             0.768571
exploration/Rewards Max            -0.00435517
exploration/Rewards Min            -7.90766
exploration/Returns Mean          -27.526
exploration/Returns Std             8.46458
exploration/Returns Max           -16.3134
exploration/Returns Min           -41.5406
exploration/Actions Mean            0.0363192
exploration/Actions Std             0.230688
exploration/Actions Max             0.997324
exploration/Actions Min            -0.74642
exploration/Num Paths               5
exploration/Average Returns       -27.526
evaluation/num steps total     100000
evaluation/num paths total       1000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.255219
evaluation/Rewards Std              1.0666
evaluation/Rewards Max             -0.0295869
evaluation/Rewards Min            -10.2902
evaluation/Returns Mean           -25.5219
evaluation/Returns Std             15.568
evaluation/Returns Max             -4.23272
evaluation/Returns Min            -61.0027
evaluation/Actions Mean             0.0318876
evaluation/Actions Std              0.198506
evaluation/Actions Max              0.997628
evaluation/Actions Min             -0.998956
evaluation/Num Paths               25
evaluation/Average Returns        -25.5219
time/data storing (s)               0.0028773
time/evaluation sampling (s)        0.523812
time/exploration sampling (s)       0.149971
time/logging (s)                    0.00655478
time/saving (s)                     0.00176832
time/training (s)                   1.897
time/epoch (s)                      2.58198
time/total (s)                    110.443
Epoch                              39
-----------------------------  ---------------
2019-04-22 21:10:39.784703 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 40 finished
-----------------------------  ---------------
replay_buffer/size              20700
trainer/QF1 Loss                    0.550422
trainer/QF2 Loss                    0.600071
trainer/Policy Loss                19.207
trainer/Q1 Predictions Mean       -17.9818
trainer/Q1 Predictions Std         10.3695
trainer/Q1 Predictions Max        -13.8726
trainer/Q1 Predictions Min        -75.6045
trainer/Q2 Predictions Mean       -17.9503
trainer/Q2 Predictions Std         10.358
trainer/Q2 Predictions Max        -13.8191
trainer/Q2 Predictions Min        -75.3414
trainer/Q Targets Mean            -18.1914
trainer/Q Targets Std              10.8147
trainer/Q Targets Max             -13.8012
trainer/Q Targets Min             -77.6497
trainer/Log Pis Mean                2.09567
trainer/Log Pis Std                 1.42481
trainer/Log Pis Max                 7.12905
trainer/Log Pis Min                -2.60296
trainer/Policy mu Mean              0.201869
trainer/Policy mu Std               0.939628
trainer/Policy mu Max               3.07854
trainer/Policy mu Min              -3.51001
trainer/Policy log std Mean        -1.90893
trainer/Policy log std Std          0.499161
trainer/Policy log std Max         -0.259909
trainer/Policy log std Min         -2.46857
trainer/Alpha                       0.0480544
trainer/Alpha Loss                  0.290417
exploration/num steps total     20700
exploration/num paths total       207
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.305175
exploration/Rewards Std             0.876837
exploration/Rewards Max            -0.00701863
exploration/Rewards Min            -9.24068
exploration/Returns Mean          -30.5175
exploration/Returns Std            13.0616
exploration/Returns Max           -16.7716
exploration/Returns Min           -53.8732
exploration/Actions Mean            0.0215358
exploration/Actions Std             0.244556
exploration/Actions Max             0.997304
exploration/Actions Min            -0.998445
exploration/Num Paths               5
exploration/Average Returns       -30.5175
evaluation/num steps total     102500
evaluation/num paths total       1025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.24137
evaluation/Rewards Std              1.0405
evaluation/Rewards Max             -0.01248
evaluation/Rewards Min            -10.7727
evaluation/Returns Mean           -24.137
evaluation/Returns Std             15.967
evaluation/Returns Max             -5.5448
evaluation/Returns Min            -61.3772
evaluation/Actions Mean             0.0291507
evaluation/Actions Std              0.197521
evaluation/Actions Max              0.996391
evaluation/Actions Min             -0.998139
evaluation/Num Paths               25
evaluation/Average Returns        -24.137
time/data storing (s)               0.00308597
time/evaluation sampling (s)        0.516995
time/exploration sampling (s)       0.143549
time/logging (s)                    0.00643997
time/saving (s)                     0.00188618
time/training (s)                   1.90068
time/epoch (s)                      2.57263
time/total (s)                    113.02
Epoch                              40
-----------------------------  ---------------
2019-04-22 21:10:42.384977 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 41 finished
-----------------------------  ---------------
replay_buffer/size              21200
trainer/QF1 Loss                    0.342395
trainer/QF2 Loss                    0.414568
trainer/Policy Loss                18.2877
trainer/Q1 Predictions Mean       -16.7561
trainer/Q1 Predictions Std          8.87558
trainer/Q1 Predictions Max        -13.6409
trainer/Q1 Predictions Min        -74.5216
trainer/Q2 Predictions Mean       -16.7208
trainer/Q2 Predictions Std          8.84634
trainer/Q2 Predictions Max        -13.6106
trainer/Q2 Predictions Min        -74.3549
trainer/Q Targets Mean            -16.8355
trainer/Q Targets Std               9.28515
trainer/Q Targets Max             -13.5476
trainer/Q Targets Min             -78.2994
trainer/Log Pis Mean                1.92522
trainer/Log Pis Std                 1.20549
trainer/Log Pis Max                 6.1431
trainer/Log Pis Min                -1.40215
trainer/Policy mu Mean              0.016949
trainer/Policy mu Std               0.809835
trainer/Policy mu Max               2.99957
trainer/Policy mu Min              -2.86146
trainer/Policy log std Mean        -1.91706
trainer/Policy log std Std          0.488901
trainer/Policy log std Max         -0.302557
trainer/Policy log std Min         -2.42043
trainer/Alpha                       0.0470258
trainer/Alpha Loss                 -0.228591
exploration/num steps total     21200
exploration/num paths total       212
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.569879
exploration/Rewards Std             1.60209
exploration/Rewards Max            -0.00302885
exploration/Rewards Min           -10.7557
exploration/Returns Mean          -56.9879
exploration/Returns Std            19.5774
exploration/Returns Max           -20.2171
exploration/Returns Min           -73.9638
exploration/Actions Mean            0.0463284
exploration/Actions Std             0.279383
exploration/Actions Max             0.998491
exploration/Actions Min            -0.96132
exploration/Num Paths               5
exploration/Average Returns       -56.9879
evaluation/num steps total     105000
evaluation/num paths total       1050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.249733
evaluation/Rewards Std              1.03766
evaluation/Rewards Max             -0.0138752
evaluation/Rewards Min            -10.5876
evaluation/Returns Mean           -24.9733
evaluation/Returns Std             18.9891
evaluation/Returns Max             -5.2068
evaluation/Returns Min            -62.4391
evaluation/Actions Mean             0.0199791
evaluation/Actions Std              0.185642
evaluation/Actions Max              0.996042
evaluation/Actions Min             -0.998768
evaluation/Num Paths               25
evaluation/Average Returns        -24.9733
time/data storing (s)               0.00287724
time/evaluation sampling (s)        0.521853
time/exploration sampling (s)       0.139988
time/logging (s)                    0.00673312
time/saving (s)                     0.0138639
time/training (s)                   1.90948
time/epoch (s)                      2.5948
time/total (s)                    115.619
Epoch                              41
-----------------------------  ---------------
2019-04-22 21:10:45.117392 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 42 finished
-----------------------------  ---------------
replay_buffer/size              21700
trainer/QF1 Loss                    6.133
trainer/QF2 Loss                    6.18214
trainer/Policy Loss                18.3214
trainer/Q1 Predictions Mean       -16.8315
trainer/Q1 Predictions Std         10.2076
trainer/Q1 Predictions Max        -13.3075
trainer/Q1 Predictions Min        -73.0177
trainer/Q2 Predictions Mean       -16.851
trainer/Q2 Predictions Std         10.2034
trainer/Q2 Predictions Max        -13.3399
trainer/Q2 Predictions Min        -72.8491
trainer/Q Targets Mean            -16.5248
trainer/Q Targets Std              10.488
trainer/Q Targets Max              -0.319169
trainer/Q Targets Min             -72.2784
trainer/Log Pis Mean                2.04185
trainer/Log Pis Std                 1.54752
trainer/Log Pis Max                 9.0839
trainer/Log Pis Min                -3.60722
trainer/Policy mu Mean              0.0811695
trainer/Policy mu Std               0.86807
trainer/Policy mu Max               3.09598
trainer/Policy mu Min              -3.56026
trainer/Policy log std Mean        -1.93731
trainer/Policy log std Std          0.457105
trainer/Policy log std Max         -0.471642
trainer/Policy log std Min         -2.41548
trainer/Alpha                       0.04744
trainer/Alpha Loss                  0.127581
exploration/num steps total     21700
exploration/num paths total       217
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.228311
exploration/Rewards Std             0.479782
exploration/Rewards Max            -0.00320363
exploration/Rewards Min            -4.60827
exploration/Returns Mean          -22.8311
exploration/Returns Std             3.9907
exploration/Returns Max           -15.8636
exploration/Returns Min           -26.7234
exploration/Actions Mean            0.00751014
exploration/Actions Std             0.217734
exploration/Actions Max             0.983583
exploration/Actions Min            -0.997996
exploration/Num Paths               5
exploration/Average Returns       -22.8311
evaluation/num steps total     107500
evaluation/num paths total       1075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.254015
evaluation/Rewards Std              0.977801
evaluation/Rewards Max             -0.0303192
evaluation/Rewards Min            -10.6385
evaluation/Returns Mean           -25.4015
evaluation/Returns Std             16.4578
evaluation/Returns Max             -6.77356
evaluation/Returns Min            -58.936
evaluation/Actions Mean             0.0233858
evaluation/Actions Std              0.182165
evaluation/Actions Max              0.997456
evaluation/Actions Min             -0.998883
evaluation/Num Paths               25
evaluation/Average Returns        -25.4015
time/data storing (s)               0.00297904
time/evaluation sampling (s)        0.537588
time/exploration sampling (s)       0.157096
time/logging (s)                    0.00661918
time/saving (s)                     0.00203754
time/training (s)                   2.01979
time/epoch (s)                      2.72611
time/total (s)                    118.35
Epoch                              42
-----------------------------  ---------------
2019-04-22 21:10:47.820022 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 43 finished
-----------------------------  ---------------
replay_buffer/size              22200
trainer/QF1 Loss                    1.74931
trainer/QF2 Loss                    1.76959
trainer/Policy Loss                16.2692
trainer/Q1 Predictions Mean       -14.8576
trainer/Q1 Predictions Std          6.30116
trainer/Q1 Predictions Max        -13.0111
trainer/Q1 Predictions Min        -58.8565
trainer/Q2 Predictions Mean       -14.8209
trainer/Q2 Predictions Std          6.28311
trainer/Q2 Predictions Max        -12.9912
trainer/Q2 Predictions Min        -59.1321
trainer/Q Targets Mean            -14.8267
trainer/Q Targets Std               6.51573
trainer/Q Targets Max              -0.301909
trainer/Q Targets Min             -59.362
trainer/Log Pis Mean                1.78386
trainer/Log Pis Std                 1.49495
trainer/Log Pis Max                 8.3841
trainer/Log Pis Min                -3.29137
trainer/Policy mu Mean              0.153161
trainer/Policy mu Std               0.668822
trainer/Policy mu Max               3.16259
trainer/Policy mu Min              -1.12524
trainer/Policy log std Mean        -1.99534
trainer/Policy log std Std          0.420601
trainer/Policy log std Max         -0.571532
trainer/Policy log std Min         -2.43839
trainer/Alpha                       0.0491139
trainer/Alpha Loss                 -0.651347
exploration/num steps total     22200
exploration/num paths total       222
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.339996
exploration/Rewards Std             0.910055
exploration/Rewards Max            -0.00466364
exploration/Rewards Min            -7.81378
exploration/Returns Mean          -33.9996
exploration/Returns Std             7.23439
exploration/Returns Max           -27.1575
exploration/Returns Min           -43.0227
exploration/Actions Mean            0.0110167
exploration/Actions Std             0.252552
exploration/Actions Max             0.998704
exploration/Actions Min            -0.999692
exploration/Num Paths               5
exploration/Average Returns       -33.9996
evaluation/num steps total     110000
evaluation/num paths total       1100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.132721
evaluation/Rewards Std              0.69477
evaluation/Rewards Max             -0.00578546
evaluation/Rewards Min             -8.27676
evaluation/Returns Mean           -13.2721
evaluation/Returns Std              9.82512
evaluation/Returns Max             -1.24783
evaluation/Returns Min            -33.8408
evaluation/Actions Mean             0.0131296
evaluation/Actions Std              0.169163
evaluation/Actions Max              0.995821
evaluation/Actions Min             -0.998719
evaluation/Num Paths               25
evaluation/Average Returns        -13.2721
time/data storing (s)               0.00288615
time/evaluation sampling (s)        0.51489
time/exploration sampling (s)       0.148631
time/logging (s)                    0.00667776
time/saving (s)                     0.00194104
time/training (s)                   2.02178
time/epoch (s)                      2.69681
time/total (s)                    121.052
Epoch                              43
-----------------------------  ---------------
2019-04-22 21:10:50.412055 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 44 finished
-----------------------------  ---------------
replay_buffer/size              22700
trainer/QF1 Loss                    0.508596
trainer/QF2 Loss                    0.493877
trainer/Policy Loss                16.4068
trainer/Q1 Predictions Mean       -15.3406
trainer/Q1 Predictions Std         10.3271
trainer/Q1 Predictions Max        -12.7068
trainer/Q1 Predictions Min        -96.0538
trainer/Q2 Predictions Mean       -15.3041
trainer/Q2 Predictions Std         10.323
trainer/Q2 Predictions Max        -12.6952
trainer/Q2 Predictions Min        -95.8599
trainer/Q Targets Mean            -15.3572
trainer/Q Targets Std               9.76551
trainer/Q Targets Max             -12.7244
trainer/Q Targets Min             -89.2406
trainer/Log Pis Mean                1.84735
trainer/Log Pis Std                 1.63772
trainer/Log Pis Max                10.0618
trainer/Log Pis Min                -3.84268
trainer/Policy mu Mean              0.0721838
trainer/Policy mu Std               0.696869
trainer/Policy mu Max               3.29852
trainer/Policy mu Min              -3.08067
trainer/Policy log std Mean        -2.06106
trainer/Policy log std Std          0.395418
trainer/Policy log std Max         -0.535489
trainer/Policy log std Min         -2.49426
trainer/Alpha                       0.0475759
trainer/Alpha Loss                 -0.464903
exploration/num steps total     22700
exploration/num paths total       227
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.25648
exploration/Rewards Std             0.652767
exploration/Rewards Max            -0.00618269
exploration/Rewards Min            -6.08083
exploration/Returns Mean          -25.648
exploration/Returns Std             6.5198
exploration/Returns Max           -14.2947
exploration/Returns Min           -31.5853
exploration/Actions Mean            0.0082386
exploration/Actions Std             0.226388
exploration/Actions Max             0.997279
exploration/Actions Min            -0.996431
exploration/Num Paths               5
exploration/Average Returns       -25.648
evaluation/num steps total     112500
evaluation/num paths total       1125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.215472
evaluation/Rewards Std              0.932106
evaluation/Rewards Max             -0.017364
evaluation/Rewards Min            -10.3659
evaluation/Returns Mean           -21.5472
evaluation/Returns Std             15.1811
evaluation/Returns Max             -4.34068
evaluation/Returns Min            -58.9397
evaluation/Actions Mean             0.0208439
evaluation/Actions Std              0.183115
evaluation/Actions Max              0.997098
evaluation/Actions Min             -0.998851
evaluation/Num Paths               25
evaluation/Average Returns        -21.5472
time/data storing (s)               0.00291838
time/evaluation sampling (s)        0.526709
time/exploration sampling (s)       0.142505
time/logging (s)                    0.00655814
time/saving (s)                     0.0019192
time/training (s)                   1.90512
time/epoch (s)                      2.58573
time/total (s)                    123.642
Epoch                              44
-----------------------------  ---------------
2019-04-22 21:10:53.004986 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 45 finished
-----------------------------  ---------------
replay_buffer/size              23200
trainer/QF1 Loss                    0.362589
trainer/QF2 Loss                    0.317787
trainer/Policy Loss                16.0706
trainer/Q1 Predictions Mean       -14.5647
trainer/Q1 Predictions Std          7.67366
trainer/Q1 Predictions Max        -12.1377
trainer/Q1 Predictions Min        -72.3179
trainer/Q2 Predictions Mean       -14.6128
trainer/Q2 Predictions Std          7.73001
trainer/Q2 Predictions Max        -12.1722
trainer/Q2 Predictions Min        -72.8192
trainer/Q Targets Mean            -15.0092
trainer/Q Targets Std               7.90601
trainer/Q Targets Max             -12.4736
trainer/Q Targets Min             -75.9673
trainer/Log Pis Mean                1.90335
trainer/Log Pis Std                 1.55484
trainer/Log Pis Max                 7.66989
trainer/Log Pis Min                -4.23279
trainer/Policy mu Mean              0.0444924
trainer/Policy mu Std               0.783314
trainer/Policy mu Max               3.20744
trainer/Policy mu Min              -3.08588
trainer/Policy log std Mean        -2.05301
trainer/Policy log std Std          0.443883
trainer/Policy log std Max         -0.355715
trainer/Policy log std Min         -2.49416
trainer/Alpha                       0.0477607
trainer/Alpha Loss                 -0.293984
exploration/num steps total     23200
exploration/num paths total       232
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.359499
exploration/Rewards Std             1.07925
exploration/Rewards Max            -0.00367717
exploration/Rewards Min            -9.86347
exploration/Returns Mean          -35.9499
exploration/Returns Std            16.2889
exploration/Returns Max           -16.7836
exploration/Returns Min           -63.2062
exploration/Actions Mean            0.0321588
exploration/Actions Std             0.237925
exploration/Actions Max             0.999186
exploration/Actions Min            -0.996844
exploration/Num Paths               5
exploration/Average Returns       -35.9499
evaluation/num steps total     115000
evaluation/num paths total       1150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.255519
evaluation/Rewards Std              1.03456
evaluation/Rewards Max             -0.0115271
evaluation/Rewards Min             -9.83944
evaluation/Returns Mean           -25.5519
evaluation/Returns Std             14.6672
evaluation/Returns Max             -4.32448
evaluation/Returns Min            -57.5164
evaluation/Actions Mean             0.0256072
evaluation/Actions Std              0.193486
evaluation/Actions Max              0.995924
evaluation/Actions Min             -0.998451
evaluation/Num Paths               25
evaluation/Average Returns        -25.5519
time/data storing (s)               0.0029536
time/evaluation sampling (s)        0.522386
time/exploration sampling (s)       0.142762
time/logging (s)                    0.00651115
time/saving (s)                     0.00155743
time/training (s)                   1.91065
time/epoch (s)                      2.58682
time/total (s)                    126.234
Epoch                              45
-----------------------------  ---------------
2019-04-22 21:10:55.562867 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 46 finished
-----------------------------  ---------------
replay_buffer/size              23700
trainer/QF1 Loss                    6.33482
trainer/QF2 Loss                    6.39275
trainer/Policy Loss                16.6543
trainer/Q1 Predictions Mean       -15.1672
trainer/Q1 Predictions Std         10.047
trainer/Q1 Predictions Max        -12.1573
trainer/Q1 Predictions Min        -81.1925
trainer/Q2 Predictions Mean       -15.1799
trainer/Q2 Predictions Std         10.0282
trainer/Q2 Predictions Max        -12.1843
trainer/Q2 Predictions Min        -81.2414
trainer/Q Targets Mean            -14.8422
trainer/Q Targets Std              10.3478
trainer/Q Targets Max              -0.0643682
trainer/Q Targets Min             -78.1336
trainer/Log Pis Mean                2.0251
trainer/Log Pis Std                 1.60594
trainer/Log Pis Max                 9.99332
trainer/Log Pis Min                -2.76643
trainer/Policy mu Mean              0.0699981
trainer/Policy mu Std               0.82969
trainer/Policy mu Max               3.40019
trainer/Policy mu Min              -2.8595
trainer/Policy log std Mean        -2.02768
trainer/Policy log std Std          0.458918
trainer/Policy log std Max         -0.463004
trainer/Policy log std Min         -2.52914
trainer/Alpha                       0.0489224
trainer/Alpha Loss                  0.0757374
exploration/num steps total     23700
exploration/num paths total       237
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.372686
exploration/Rewards Std             1.03604
exploration/Rewards Max            -0.00949547
exploration/Rewards Min           -10.1078
exploration/Returns Mean          -37.2686
exploration/Returns Std            16.5264
exploration/Returns Max           -24.6192
exploration/Returns Min           -69.2933
exploration/Actions Mean            0.0134464
exploration/Actions Std             0.245308
exploration/Actions Max             0.996902
exploration/Actions Min            -0.996937
exploration/Num Paths               5
exploration/Average Returns       -37.2686
evaluation/num steps total     117500
evaluation/num paths total       1175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.290748
evaluation/Rewards Std              1.04241
evaluation/Rewards Max             -0.0736383
evaluation/Rewards Min            -10.3604
evaluation/Returns Mean           -29.0748
evaluation/Returns Std             16.7392
evaluation/Returns Max             -9.04492
evaluation/Returns Min            -64.9276
evaluation/Actions Mean             0.0266617
evaluation/Actions Std              0.191747
evaluation/Actions Max              0.998399
evaluation/Actions Min             -0.99773
evaluation/Num Paths               25
evaluation/Average Returns        -29.0748
time/data storing (s)               0.00273355
time/evaluation sampling (s)        0.52814
time/exploration sampling (s)       0.138907
time/logging (s)                    0.00659471
time/saving (s)                     0.00192029
time/training (s)                   1.87359
time/epoch (s)                      2.55189
time/total (s)                    128.79
Epoch                              46
-----------------------------  ---------------
2019-04-22 21:10:58.158529 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 47 finished
-----------------------------  ---------------
replay_buffer/size              24200
trainer/QF1 Loss                    0.213749
trainer/QF2 Loss                    0.184828
trainer/Policy Loss                14.7803
trainer/Q1 Predictions Mean       -13.209
trainer/Q1 Predictions Std          5.34917
trainer/Q1 Predictions Max        -11.8135
trainer/Q1 Predictions Min        -48.4642
trainer/Q2 Predictions Mean       -13.2375
trainer/Q2 Predictions Std          5.35601
trainer/Q2 Predictions Max        -11.8155
trainer/Q2 Predictions Min        -48.2219
trainer/Q Targets Mean            -13.5724
trainer/Q Targets Std               5.46852
trainer/Q Targets Max             -11.9939
trainer/Q Targets Min             -48.4898
trainer/Log Pis Mean                1.81436
trainer/Log Pis Std                 1.26262
trainer/Log Pis Max                 7.28789
trainer/Log Pis Min                -2.15084
trainer/Policy mu Mean              0.0845375
trainer/Policy mu Std               0.607294
trainer/Policy mu Max               3.02726
trainer/Policy mu Min              -2.30577
trainer/Policy log std Mean        -2.05701
trainer/Policy log std Std          0.387689
trainer/Policy log std Max         -0.554659
trainer/Policy log std Min         -2.47424
trainer/Alpha                       0.049209
trainer/Alpha Loss                 -0.559079
exploration/num steps total     24200
exploration/num paths total       242
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.404663
exploration/Rewards Std             1.20923
exploration/Rewards Max            -0.00737781
exploration/Rewards Min            -9.87084
exploration/Returns Mean          -40.4663
exploration/Returns Std            18.9082
exploration/Returns Max           -22.0828
exploration/Returns Min           -67.2989
exploration/Actions Mean            0.0382541
exploration/Actions Std             0.250558
exploration/Actions Max             0.998985
exploration/Actions Min            -0.870988
exploration/Num Paths               5
exploration/Average Returns       -40.4663
evaluation/num steps total     120000
evaluation/num paths total       1200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225536
evaluation/Rewards Std              0.982779
evaluation/Rewards Max             -0.0023
evaluation/Rewards Min             -9.44963
evaluation/Returns Mean           -22.5536
evaluation/Returns Std             13.9836
evaluation/Returns Max             -2.68242
evaluation/Returns Min            -49.1229
evaluation/Actions Mean             0.0303922
evaluation/Actions Std              0.184798
evaluation/Actions Max              0.997154
evaluation/Actions Min             -0.993772
evaluation/Num Paths               25
evaluation/Average Returns        -22.5536
time/data storing (s)               0.00293608
time/evaluation sampling (s)        0.520825
time/exploration sampling (s)       0.144341
time/logging (s)                    0.00665342
time/saving (s)                     0.00194837
time/training (s)                   1.91291
time/epoch (s)                      2.58961
time/total (s)                    131.385
Epoch                              47
-----------------------------  ---------------
2019-04-22 21:11:00.766496 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 48 finished
-----------------------------  ---------------
replay_buffer/size              24700
trainer/QF1 Loss                    2.97988
trainer/QF2 Loss                    3.01223
trainer/Policy Loss                15.3693
trainer/Q1 Predictions Mean       -13.8517
trainer/Q1 Predictions Std          7.81373
trainer/Q1 Predictions Max        -11.7891
trainer/Q1 Predictions Min        -71.7048
trainer/Q2 Predictions Mean       -13.8544
trainer/Q2 Predictions Std          7.81755
trainer/Q2 Predictions Max        -11.786
trainer/Q2 Predictions Min        -71.4265
trainer/Q Targets Mean            -13.746
trainer/Q Targets Std               8.28881
trainer/Q Targets Max              -0.107401
trainer/Q Targets Min             -75.3884
trainer/Log Pis Mean                1.91445
trainer/Log Pis Std                 1.15559
trainer/Log Pis Max                 5.5345
trainer/Log Pis Min                -1.73065
trainer/Policy mu Mean              0.091815
trainer/Policy mu Std               0.639444
trainer/Policy mu Max               2.99756
trainer/Policy mu Min              -2.69339
trainer/Policy log std Mean        -2.11902
trainer/Policy log std Std          0.408607
trainer/Policy log std Max         -0.421249
trainer/Policy log std Min         -2.50463
trainer/Alpha                       0.0502293
trainer/Alpha Loss                 -0.25591
exploration/num steps total     24700
exploration/num paths total       247
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.29264
exploration/Rewards Std             0.783961
exploration/Rewards Max            -0.00450407
exploration/Rewards Min            -7.42023
exploration/Returns Mean          -29.264
exploration/Returns Std             9.81587
exploration/Returns Max           -19.7913
exploration/Returns Min           -45.0899
exploration/Actions Mean            0.0275626
exploration/Actions Std             0.222095
exploration/Actions Max             0.999034
exploration/Actions Min            -0.994153
exploration/Num Paths               5
exploration/Average Returns       -29.264
evaluation/num steps total     122500
evaluation/num paths total       1225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.257222
evaluation/Rewards Std              0.995198
evaluation/Rewards Max             -0.0331549
evaluation/Rewards Min            -10.0566
evaluation/Returns Mean           -25.7222
evaluation/Returns Std             15.2124
evaluation/Returns Max             -5.92267
evaluation/Returns Min            -53.3729
evaluation/Actions Mean             0.0224379
evaluation/Actions Std              0.190862
evaluation/Actions Max              0.997019
evaluation/Actions Min             -0.998417
evaluation/Num Paths               25
evaluation/Average Returns        -25.7222
time/data storing (s)               0.00290447
time/evaluation sampling (s)        0.5213
time/exploration sampling (s)       0.146008
time/logging (s)                    0.00655058
time/saving (s)                     0.00193237
time/training (s)                   1.92293
time/epoch (s)                      2.60163
time/total (s)                    133.991
Epoch                              48
-----------------------------  ---------------
2019-04-22 21:11:03.355929 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 49 finished
-----------------------------  ---------------
replay_buffer/size              25200
trainer/QF1 Loss                    0.188175
trainer/QF2 Loss                    0.218897
trainer/Policy Loss                15.9947
trainer/Q1 Predictions Mean       -14.2818
trainer/Q1 Predictions Std          7.48214
trainer/Q1 Predictions Max        -11.6169
trainer/Q1 Predictions Min        -54.022
trainer/Q2 Predictions Mean       -14.2952
trainer/Q2 Predictions Std          7.45382
trainer/Q2 Predictions Max        -11.6248
trainer/Q2 Predictions Min        -53.6528
trainer/Q Targets Mean            -14.3758
trainer/Q Targets Std               7.41123
trainer/Q Targets Max             -11.6166
trainer/Q Targets Min             -54.6896
trainer/Log Pis Mean                2.09874
trainer/Log Pis Std                 1.33784
trainer/Log Pis Max                 7.68887
trainer/Log Pis Min                -1.66285
trainer/Policy mu Mean              0.0928353
trainer/Policy mu Std               0.839923
trainer/Policy mu Max               3.03613
trainer/Policy mu Min              -3.32843
trainer/Policy log std Mean        -2.00446
trainer/Policy log std Std          0.494561
trainer/Policy log std Max         -0.41086
trainer/Policy log std Min         -2.47613
trainer/Alpha                       0.0507586
trainer/Alpha Loss                  0.294318
exploration/num steps total     25200
exploration/num paths total       252
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.364103
exploration/Rewards Std             1.07466
exploration/Rewards Max            -0.00354541
exploration/Rewards Min            -9.22299
exploration/Returns Mean          -36.4103
exploration/Returns Std            15.3494
exploration/Returns Max           -20.6814
exploration/Returns Min           -55.3826
exploration/Actions Mean            0.0327658
exploration/Actions Std             0.248348
exploration/Actions Max             0.998713
exploration/Actions Min            -0.986333
exploration/Num Paths               5
exploration/Average Returns       -36.4103
evaluation/num steps total     125000
evaluation/num paths total       1250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.231552
evaluation/Rewards Std              0.97561
evaluation/Rewards Max             -0.0111263
evaluation/Rewards Min            -11.2758
evaluation/Returns Mean           -23.1552
evaluation/Returns Std             15.8241
evaluation/Returns Max             -4.72592
evaluation/Returns Min            -63.2259
evaluation/Actions Mean             0.0307439
evaluation/Actions Std              0.185721
evaluation/Actions Max              0.996125
evaluation/Actions Min             -0.998258
evaluation/Num Paths               25
evaluation/Average Returns        -23.1552
time/data storing (s)               0.00295951
time/evaluation sampling (s)        0.516844
time/exploration sampling (s)       0.144663
time/logging (s)                    0.00660643
time/saving (s)                     0.00194123
time/training (s)                   1.911
time/epoch (s)                      2.58402
time/total (s)                    136.579
Epoch                              49
-----------------------------  ---------------
2019-04-22 21:11:05.940505 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 50 finished
-----------------------------  ---------------
replay_buffer/size              25700
trainer/QF1 Loss                    1.73365
trainer/QF2 Loss                    1.75731
trainer/Policy Loss                14.903
trainer/Q1 Predictions Mean       -13.3497
trainer/Q1 Predictions Std          8.76009
trainer/Q1 Predictions Max        -11.3506
trainer/Q1 Predictions Min        -86.8561
trainer/Q2 Predictions Mean       -13.3438
trainer/Q2 Predictions Std          8.78263
trainer/Q2 Predictions Max        -11.3648
trainer/Q2 Predictions Min        -87.1064
trainer/Q Targets Mean            -13.2501
trainer/Q Targets Std               8.32652
trainer/Q Targets Max              -0.111551
trainer/Q Targets Min             -81.2568
trainer/Log Pis Mean                1.98165
trainer/Log Pis Std                 1.2828
trainer/Log Pis Max                 8.45722
trainer/Log Pis Min                -3.01514
trainer/Policy mu Mean              0.0528491
trainer/Policy mu Std               0.616681
trainer/Policy mu Max               3.21053
trainer/Policy mu Min              -2.62833
trainer/Policy log std Mean        -2.12132
trainer/Policy log std Std          0.381663
trainer/Policy log std Max         -0.630725
trainer/Policy log std Min         -2.46536
trainer/Alpha                       0.0511655
trainer/Alpha Loss                 -0.0545487
exploration/num steps total     25700
exploration/num paths total       257
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.559885
exploration/Rewards Std             1.61285
exploration/Rewards Max            -0.00606239
exploration/Rewards Min           -10.5489
exploration/Returns Mean          -55.9885
exploration/Returns Std            16.1821
exploration/Returns Max           -24.7579
exploration/Returns Min           -69.5968
exploration/Actions Mean            0.031122
exploration/Actions Std             0.273782
exploration/Actions Max             0.999426
exploration/Actions Min            -0.999098
exploration/Num Paths               5
exploration/Average Returns       -55.9885
evaluation/num steps total     127500
evaluation/num paths total       1275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.228863
evaluation/Rewards Std              0.997037
evaluation/Rewards Max             -0.0186937
evaluation/Rewards Min             -9.58781
evaluation/Returns Mean           -22.8863
evaluation/Returns Std             14.9541
evaluation/Returns Max             -4.31743
evaluation/Returns Min            -49.2649
evaluation/Actions Mean             0.0195087
evaluation/Actions Std              0.192555
evaluation/Actions Max              0.996118
evaluation/Actions Min             -0.997797
evaluation/Num Paths               25
evaluation/Average Returns        -22.8863
time/data storing (s)               0.00286439
time/evaluation sampling (s)        0.517211
time/exploration sampling (s)       0.142827
time/logging (s)                    0.00651467
time/saving (s)                     0.00190159
time/training (s)                   1.90759
time/epoch (s)                      2.57891
time/total (s)                    139.162
Epoch                              50
-----------------------------  ---------------
2019-04-22 21:11:08.517392 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 51 finished
-----------------------------  ---------------
replay_buffer/size              26200
trainer/QF1 Loss                    0.187968
trainer/QF2 Loss                    0.218331
trainer/Policy Loss                14.2742
trainer/Q1 Predictions Mean       -12.7935
trainer/Q1 Predictions Std          6.56128
trainer/Q1 Predictions Max        -11.2486
trainer/Q1 Predictions Min        -73.8786
trainer/Q2 Predictions Mean       -12.7892
trainer/Q2 Predictions Std          6.57279
trainer/Q2 Predictions Max        -11.2163
trainer/Q2 Predictions Min        -73.9885
trainer/Q Targets Mean            -12.8529
trainer/Q Targets Std               6.6516
trainer/Q Targets Max             -11.1726
trainer/Q Targets Min             -74.7415
trainer/Log Pis Mean                1.84636
trainer/Log Pis Std                 1.19492
trainer/Log Pis Max                 8.93091
trainer/Log Pis Min                -1.02743
trainer/Policy mu Mean              0.0206957
trainer/Policy mu Std               0.651077
trainer/Policy mu Max               3.21827
trainer/Policy mu Min              -2.5249
trainer/Policy log std Mean        -2.03946
trainer/Policy log std Std          0.419629
trainer/Policy log std Max         -0.358511
trainer/Policy log std Min         -2.48458
trainer/Alpha                       0.0499001
trainer/Alpha Loss                 -0.460552
exploration/num steps total     26200
exploration/num paths total       262
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.31731
exploration/Rewards Std             0.910272
exploration/Rewards Max            -0.00332704
exploration/Rewards Min            -9.22734
exploration/Returns Mean          -31.731
exploration/Returns Std            14.7176
exploration/Returns Max           -18.335
exploration/Returns Min           -59.1055
exploration/Actions Mean            0.0171716
exploration/Actions Std             0.238097
exploration/Actions Max             0.998883
exploration/Actions Min            -0.998153
exploration/Num Paths               5
exploration/Average Returns       -31.731
evaluation/num steps total     130000
evaluation/num paths total       1300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.190606
evaluation/Rewards Std              0.873148
evaluation/Rewards Max             -0.0207823
evaluation/Rewards Min            -11.3479
evaluation/Returns Mean           -19.0606
evaluation/Returns Std             15.4529
evaluation/Returns Max             -3.4129
evaluation/Returns Min            -63.3048
evaluation/Actions Mean             0.0153191
evaluation/Actions Std              0.179174
evaluation/Actions Max              0.996733
evaluation/Actions Min             -0.998101
evaluation/Num Paths               25
evaluation/Average Returns        -19.0606
time/data storing (s)               0.00279431
time/evaluation sampling (s)        0.509433
time/exploration sampling (s)       0.144079
time/logging (s)                    0.00652413
time/saving (s)                     0.00192209
time/training (s)                   1.90602
time/epoch (s)                      2.57077
time/total (s)                    141.738
Epoch                              51
-----------------------------  ---------------
2019-04-22 21:11:11.111669 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 52 finished
-----------------------------  ---------------
replay_buffer/size              26700
trainer/QF1 Loss                    0.0954061
trainer/QF2 Loss                    0.130078
trainer/Policy Loss                13.5328
trainer/Q1 Predictions Mean       -11.9976
trainer/Q1 Predictions Std          4.72457
trainer/Q1 Predictions Max        -10.8768
trainer/Q1 Predictions Min        -46.4068
trainer/Q2 Predictions Mean       -11.984
trainer/Q2 Predictions Std          4.76628
trainer/Q2 Predictions Max        -10.8397
trainer/Q2 Predictions Min        -46.8148
trainer/Q Targets Mean            -12.196
trainer/Q Targets Std               4.67546
trainer/Q Targets Max             -10.9665
trainer/Q Targets Min             -45.7949
trainer/Log Pis Mean                1.92488
trainer/Log Pis Std                 1.37916
trainer/Log Pis Max                 7.04236
trainer/Log Pis Min                -2.43594
trainer/Policy mu Mean              0.0158431
trainer/Policy mu Std               0.526156
trainer/Policy mu Max               2.50771
trainer/Policy mu Min              -2.80294
trainer/Policy log std Mean        -2.16829
trainer/Policy log std Std          0.342359
trainer/Policy log std Max         -0.494291
trainer/Policy log std Min         -2.48571
trainer/Alpha                       0.0511428
trainer/Alpha Loss                 -0.223345
exploration/num steps total     26700
exploration/num paths total       267
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.370693
exploration/Rewards Std             1.11073
exploration/Rewards Max            -0.0126731
exploration/Rewards Min            -9.22779
exploration/Returns Mean          -37.0693
exploration/Returns Std             8.54642
exploration/Returns Max           -25.842
exploration/Returns Min           -49.3199
exploration/Actions Mean            0.0106766
exploration/Actions Std             0.255601
exploration/Actions Max             0.998883
exploration/Actions Min            -0.996363
exploration/Num Paths               5
exploration/Average Returns       -37.0693
evaluation/num steps total     132500
evaluation/num paths total       1325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.175601
evaluation/Rewards Std              0.843148
evaluation/Rewards Max             -0.00203105
evaluation/Rewards Min             -9.33043
evaluation/Returns Mean           -17.5601
evaluation/Returns Std             11.636
evaluation/Returns Max             -1.56095
evaluation/Returns Min            -47.6708
evaluation/Actions Mean             0.0209249
evaluation/Actions Std              0.183859
evaluation/Actions Max              0.996163
evaluation/Actions Min             -0.99754
evaluation/Num Paths               25
evaluation/Average Returns        -17.5601
time/data storing (s)               0.00291951
time/evaluation sampling (s)        0.529532
time/exploration sampling (s)       0.140998
time/logging (s)                    0.00482637
time/saving (s)                     0.00155144
time/training (s)                   1.90659
time/epoch (s)                      2.58642
time/total (s)                    144.329
Epoch                              52
-----------------------------  ---------------
2019-04-22 21:11:13.715320 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 53 finished
-----------------------------  ---------------
replay_buffer/size              27200
trainer/QF1 Loss                    0.192729
trainer/QF2 Loss                    0.195644
trainer/Policy Loss                13.3563
trainer/Q1 Predictions Mean       -11.7061
trainer/Q1 Predictions Std          3.42381
trainer/Q1 Predictions Max        -10.6367
trainer/Q1 Predictions Min        -35.4604
trainer/Q2 Predictions Mean       -11.7232
trainer/Q2 Predictions Std          3.40422
trainer/Q2 Predictions Max        -10.6524
trainer/Q2 Predictions Min        -35.3372
trainer/Q Targets Mean            -11.9563
trainer/Q Targets Std               3.37663
trainer/Q Targets Max             -10.7953
trainer/Q Targets Min             -35.4592
trainer/Log Pis Mean                1.97393
trainer/Log Pis Std                 1.21528
trainer/Log Pis Max                 6.34215
trainer/Log Pis Min                -1.68295
trainer/Policy mu Mean             -0.0370049
trainer/Policy mu Std               0.562663
trainer/Policy mu Max               2.89144
trainer/Policy mu Min              -2.52085
trainer/Policy log std Mean        -2.15136
trainer/Policy log std Std          0.378333
trainer/Policy log std Max         -0.400227
trainer/Policy log std Min         -2.51792
trainer/Alpha                       0.0524843
trainer/Alpha Loss                 -0.0768503
exploration/num steps total     27200
exploration/num paths total       272
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.33525
exploration/Rewards Std             0.956183
exploration/Rewards Max            -0.00579633
exploration/Rewards Min            -7.70871
exploration/Returns Mean          -33.525
exploration/Returns Std             6.85489
exploration/Returns Max           -22.8771
exploration/Returns Min           -42.4008
exploration/Actions Mean            0.0162494
exploration/Actions Std             0.252231
exploration/Actions Max             0.993627
exploration/Actions Min            -0.99821
exploration/Num Paths               5
exploration/Average Returns       -33.525
evaluation/num steps total     135000
evaluation/num paths total       1350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.25984
evaluation/Rewards Std              1.06003
evaluation/Rewards Max             -0.0235886
evaluation/Rewards Min            -10.9552
evaluation/Returns Mean           -25.984
evaluation/Returns Std             16.0369
evaluation/Returns Max             -4.67375
evaluation/Returns Min            -60.9778
evaluation/Actions Mean             0.0294878
evaluation/Actions Std              0.18937
evaluation/Actions Max              0.996005
evaluation/Actions Min             -0.995509
evaluation/Num Paths               25
evaluation/Average Returns        -25.984
time/data storing (s)               0.00341925
time/evaluation sampling (s)        0.513659
time/exploration sampling (s)       0.166678
time/logging (s)                    0.00645237
time/saving (s)                     0.0115362
time/training (s)                   1.8979
time/epoch (s)                      2.59965
time/total (s)                    146.933
Epoch                              53
-----------------------------  ---------------
2019-04-22 21:11:16.300889 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 54 finished
-----------------------------  ---------------
replay_buffer/size              27700
trainer/QF1 Loss                    2.40002
trainer/QF2 Loss                    2.41779
trainer/Policy Loss                14.0716
trainer/Q1 Predictions Mean       -12.5187
trainer/Q1 Predictions Std          6.24942
trainer/Q1 Predictions Max        -10.5758
trainer/Q1 Predictions Min        -46.8984
trainer/Q2 Predictions Mean       -12.5262
trainer/Q2 Predictions Std          6.25164
trainer/Q2 Predictions Max        -10.5978
trainer/Q2 Predictions Min        -46.7737
trainer/Q Targets Mean            -12.5062
trainer/Q Targets Std               6.80999
trainer/Q Targets Max              -0.1826
trainer/Q Targets Min             -49.372
trainer/Log Pis Mean                1.86877
trainer/Log Pis Std                 1.2673
trainer/Log Pis Max                 6.46781
trainer/Log Pis Min                -2.67024
trainer/Policy mu Mean              0.0949449
trainer/Policy mu Std               0.684681
trainer/Policy mu Max               3.08926
trainer/Policy mu Min              -2.42103
trainer/Policy log std Mean        -2.02256
trainer/Policy log std Std          0.401581
trainer/Policy log std Max         -0.406552
trainer/Policy log std Min         -2.44813
trainer/Alpha                       0.0529869
trainer/Alpha Loss                 -0.385506
exploration/num steps total     27700
exploration/num paths total       277
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.347513
exploration/Rewards Std             0.957284
exploration/Rewards Max            -0.00696916
exploration/Rewards Min            -8.62146
exploration/Returns Mean          -34.7513
exploration/Returns Std            11.0463
exploration/Returns Max           -24.7669
exploration/Returns Min           -54.3354
exploration/Actions Mean            0.0244585
exploration/Actions Std             0.243709
exploration/Actions Max             0.999538
exploration/Actions Min            -0.995731
exploration/Num Paths               5
exploration/Average Returns       -34.7513
evaluation/num steps total     137500
evaluation/num paths total       1375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.239605
evaluation/Rewards Std              1.11413
evaluation/Rewards Max             -0.00208614
evaluation/Rewards Min            -11.1886
evaluation/Returns Mean           -23.9605
evaluation/Returns Std             20.2133
evaluation/Returns Max             -1.90744
evaluation/Returns Min            -61.547
evaluation/Actions Mean             0.0261362
evaluation/Actions Std              0.189881
evaluation/Actions Max              0.997537
evaluation/Actions Min             -0.99787
evaluation/Num Paths               25
evaluation/Average Returns        -23.9605
time/data storing (s)               0.0031542
time/evaluation sampling (s)        0.518332
time/exploration sampling (s)       0.143069
time/logging (s)                    0.00636611
time/saving (s)                     0.00194248
time/training (s)                   1.90643
time/epoch (s)                      2.57929
time/total (s)                    149.517
Epoch                              54
-----------------------------  ---------------
2019-04-22 21:11:18.873821 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 55 finished
-----------------------------  ---------------
replay_buffer/size              28200
trainer/QF1 Loss                    1.31371
trainer/QF2 Loss                    1.34108
trainer/Policy Loss                13.6305
trainer/Q1 Predictions Mean       -11.9704
trainer/Q1 Predictions Std          4.26867
trainer/Q1 Predictions Max        -10.3558
trainer/Q1 Predictions Min        -35.4146
trainer/Q2 Predictions Mean       -11.9758
trainer/Q2 Predictions Std          4.26229
trainer/Q2 Predictions Max        -10.3521
trainer/Q2 Predictions Min        -35.5401
trainer/Q Targets Mean            -12.0372
trainer/Q Targets Std               4.43494
trainer/Q Targets Max              -0.252327
trainer/Q Targets Min             -34.5256
trainer/Log Pis Mean                1.91729
trainer/Log Pis Std                 1.32169
trainer/Log Pis Max                 7.04545
trainer/Log Pis Min                -1.82866
trainer/Policy mu Mean             -0.0542825
trainer/Policy mu Std               0.738607
trainer/Policy mu Max               2.78505
trainer/Policy mu Min              -3.0391
trainer/Policy log std Mean        -1.99938
trainer/Policy log std Std          0.460617
trainer/Policy log std Max         -0.363224
trainer/Policy log std Min         -2.43974
trainer/Alpha                       0.0526618
trainer/Alpha Loss                 -0.243485
exploration/num steps total     28200
exploration/num paths total       282
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.44454
exploration/Rewards Std             1.26208
exploration/Rewards Max            -0.00646295
exploration/Rewards Min            -9.45364
exploration/Returns Mean          -44.454
exploration/Returns Std            13.1579
exploration/Returns Max           -21.3519
exploration/Returns Min           -57.4317
exploration/Actions Mean            0.0379197
exploration/Actions Std             0.264433
exploration/Actions Max             0.998282
exploration/Actions Min            -0.998306
exploration/Num Paths               5
exploration/Average Returns       -44.454
evaluation/num steps total     140000
evaluation/num paths total       1400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.294553
evaluation/Rewards Std              1.07055
evaluation/Rewards Max             -0.0697264
evaluation/Rewards Min            -10.5061
evaluation/Returns Mean           -29.4553
evaluation/Returns Std             15.3086
evaluation/Returns Max             -7.31578
evaluation/Returns Min            -62.9495
evaluation/Actions Mean             0.0324623
evaluation/Actions Std              0.20255
evaluation/Actions Max              0.996712
evaluation/Actions Min             -0.995265
evaluation/Num Paths               25
evaluation/Average Returns        -29.4553
time/data storing (s)               0.00275007
time/evaluation sampling (s)        0.520667
time/exploration sampling (s)       0.143275
time/logging (s)                    0.00664342
time/saving (s)                     0.0019161
time/training (s)                   1.89293
time/epoch (s)                      2.56818
time/total (s)                    152.089
Epoch                              55
-----------------------------  ---------------
2019-04-22 21:11:21.439453 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 56 finished
-----------------------------  ---------------
replay_buffer/size              28700
trainer/QF1 Loss                    0.0150702
trainer/QF2 Loss                    0.0154419
trainer/Policy Loss                13.0233
trainer/Q1 Predictions Mean       -11.2267
trainer/Q1 Predictions Std          4.74375
trainer/Q1 Predictions Max        -10.3393
trainer/Q1 Predictions Min        -57.3037
trainer/Q2 Predictions Mean       -11.2382
trainer/Q2 Predictions Std          4.73267
trainer/Q2 Predictions Max        -10.3344
trainer/Q2 Predictions Min        -57.1859
trainer/Q Targets Mean            -11.2244
trainer/Q Targets Std               4.75035
trainer/Q Targets Max             -10.1941
trainer/Q Targets Min             -57.2777
trainer/Log Pis Mean                1.94962
trainer/Log Pis Std                 1.06524
trainer/Log Pis Max                 4.32184
trainer/Log Pis Min                -4.14053
trainer/Policy mu Mean              0.0951645
trainer/Policy mu Std               0.451425
trainer/Policy mu Max               3.08511
trainer/Policy mu Min              -1.15349
trainer/Policy log std Mean        -2.17451
trainer/Policy log std Std          0.319117
trainer/Policy log std Max         -0.733904
trainer/Policy log std Min         -2.52055
trainer/Alpha                       0.05498
trainer/Alpha Loss                 -0.146137
exploration/num steps total     28700
exploration/num paths total       287
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.349048
exploration/Rewards Std             1.00847
exploration/Rewards Max            -0.00186029
exploration/Rewards Min            -8.10917
exploration/Returns Mean          -34.9048
exploration/Returns Std             8.86609
exploration/Returns Max           -24.1528
exploration/Returns Min           -46.7039
exploration/Actions Mean            0.0361995
exploration/Actions Std             0.235243
exploration/Actions Max             0.996348
exploration/Actions Min            -0.995401
exploration/Num Paths               5
exploration/Average Returns       -34.9048
evaluation/num steps total     142500
evaluation/num paths total       1425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.202285
evaluation/Rewards Std              0.871389
evaluation/Rewards Max             -0.0146693
evaluation/Rewards Min             -9.82118
evaluation/Returns Mean           -20.2285
evaluation/Returns Std             14.8792
evaluation/Returns Max             -4.78255
evaluation/Returns Min            -57.3479
evaluation/Actions Mean             0.0252838
evaluation/Actions Std              0.175745
evaluation/Actions Max              0.996492
evaluation/Actions Min             -0.994406
evaluation/Num Paths               25
evaluation/Average Returns        -20.2285
time/data storing (s)               0.00282011
time/evaluation sampling (s)        0.514932
time/exploration sampling (s)       0.144515
time/logging (s)                    0.006494
time/saving (s)                     0.00194193
time/training (s)                   1.88858
time/epoch (s)                      2.55928
time/total (s)                    154.653
Epoch                              56
-----------------------------  ---------------
2019-04-22 21:11:24.017378 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 57 finished
-----------------------------  ---------------
replay_buffer/size              29200
trainer/QF1 Loss                    2.10209
trainer/QF2 Loss                    2.12626
trainer/Policy Loss                13.7705
trainer/Q1 Predictions Mean       -12.216
trainer/Q1 Predictions Std          7.45636
trainer/Q1 Predictions Max         -9.80967
trainer/Q1 Predictions Min        -55.1499
trainer/Q2 Predictions Mean       -12.2661
trainer/Q2 Predictions Std          7.47759
trainer/Q2 Predictions Max         -9.86718
trainer/Q2 Predictions Min        -55.3236
trainer/Q Targets Mean            -12.2547
trainer/Q Targets Std               7.4167
trainer/Q Targets Max              -0.0322522
trainer/Q Targets Min             -53.1902
trainer/Log Pis Mean                1.87956
trainer/Log Pis Std                 1.27252
trainer/Log Pis Max                 7.41582
trainer/Log Pis Min                -1.29856
trainer/Policy mu Mean              0.0799965
trainer/Policy mu Std               0.710128
trainer/Policy mu Max               2.88602
trainer/Policy mu Min              -3.12504
trainer/Policy log std Mean        -2.02224
trainer/Policy log std Std          0.471829
trainer/Policy log std Max         -0.509378
trainer/Policy log std Min         -2.45746
trainer/Alpha                       0.0547537
trainer/Alpha Loss                 -0.349881
exploration/num steps total     29200
exploration/num paths total       292
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.171618
exploration/Rewards Std             0.269853
exploration/Rewards Max            -0.0126378
exploration/Rewards Min            -3.48441
exploration/Returns Mean          -17.1618
exploration/Returns Std             3.88579
exploration/Returns Max           -13.8426
exploration/Returns Min           -24.429
exploration/Actions Mean            0.0141055
exploration/Actions Std             0.190066
exploration/Actions Max             0.996216
exploration/Actions Min            -0.632715
exploration/Num Paths               5
exploration/Average Returns       -17.1618
evaluation/num steps total     145000
evaluation/num paths total       1450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.266191
evaluation/Rewards Std              1.04491
evaluation/Rewards Max             -0.0508741
evaluation/Rewards Min             -9.8151
evaluation/Returns Mean           -26.6191
evaluation/Returns Std             16.3463
evaluation/Returns Max             -5.76667
evaluation/Returns Min            -57.7903
evaluation/Actions Mean             0.0203729
evaluation/Actions Std              0.192084
evaluation/Actions Max              0.994521
evaluation/Actions Min             -0.997798
evaluation/Num Paths               25
evaluation/Average Returns        -26.6191
time/data storing (s)               0.00277314
time/evaluation sampling (s)        0.512861
time/exploration sampling (s)       0.138766
time/logging (s)                    0.00518046
time/saving (s)                     0.0019175
time/training (s)                   1.90896
time/epoch (s)                      2.57046
time/total (s)                    157.228
Epoch                              57
-----------------------------  ---------------
2019-04-22 21:11:26.597809 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 58 finished
-----------------------------  ---------------
replay_buffer/size              29700
trainer/QF1 Loss                    1.13226
trainer/QF2 Loss                    1.12944
trainer/Policy Loss                13.5414
trainer/Q1 Predictions Mean       -12.136
trainer/Q1 Predictions Std          8.57509
trainer/Q1 Predictions Max         -9.86975
trainer/Q1 Predictions Min        -69.2514
trainer/Q2 Predictions Mean       -12.1059
trainer/Q2 Predictions Std          8.58814
trainer/Q2 Predictions Max         -9.79841
trainer/Q2 Predictions Min        -69.2987
trainer/Q Targets Mean            -12.1188
trainer/Q Targets Std               8.71222
trainer/Q Targets Max              -0.534152
trainer/Q Targets Min             -70.4753
trainer/Log Pis Mean                1.83687
trainer/Log Pis Std                 1.4493
trainer/Log Pis Max                 8.49412
trainer/Log Pis Min                -3.22956
trainer/Policy mu Mean              0.0885506
trainer/Policy mu Std               0.724864
trainer/Policy mu Max               3.09174
trainer/Policy mu Min              -2.7185
trainer/Policy log std Mean        -2.03432
trainer/Policy log std Std          0.464581
trainer/Policy log std Max         -0.521408
trainer/Policy log std Min         -2.48008
trainer/Alpha                       0.0559103
trainer/Alpha Loss                 -0.470475
exploration/num steps total     29700
exploration/num paths total       297
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.519497
exploration/Rewards Std             1.52961
exploration/Rewards Max            -0.0028125
exploration/Rewards Min           -10.9852
exploration/Returns Mean          -51.9497
exploration/Returns Std            19.8765
exploration/Returns Max           -25.535
exploration/Returns Min           -71.6887
exploration/Actions Mean            0.0587822
exploration/Actions Std             0.262172
exploration/Actions Max             0.99892
exploration/Actions Min            -0.702182
exploration/Num Paths               5
exploration/Average Returns       -51.9497
evaluation/num steps total     147500
evaluation/num paths total       1475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.243794
evaluation/Rewards Std              1.0081
evaluation/Rewards Max             -0.0213081
evaluation/Rewards Min            -10.2288
evaluation/Returns Mean           -24.3794
evaluation/Returns Std             15.9745
evaluation/Returns Max             -4.19857
evaluation/Returns Min            -56.2948
evaluation/Actions Mean             0.0227891
evaluation/Actions Std              0.182941
evaluation/Actions Max              0.996065
evaluation/Actions Min             -0.996827
evaluation/Num Paths               25
evaluation/Average Returns        -24.3794
time/data storing (s)               0.00270031
time/evaluation sampling (s)        0.517823
time/exploration sampling (s)       0.140076
time/logging (s)                    0.00650226
time/saving (s)                     0.00193393
time/training (s)                   1.90667
time/epoch (s)                      2.5757
time/total (s)                    159.809
Epoch                              58
-----------------------------  ---------------
2019-04-22 21:11:29.230884 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 59 finished
-----------------------------  ---------------
replay_buffer/size              30200
trainer/QF1 Loss                    2.07999
trainer/QF2 Loss                    2.09189
trainer/Policy Loss                14.3638
trainer/Q1 Predictions Mean       -12.4988
trainer/Q1 Predictions Std          9.56195
trainer/Q1 Predictions Max         -9.75515
trainer/Q1 Predictions Min        -80.1322
trainer/Q2 Predictions Mean       -12.5187
trainer/Q2 Predictions Std          9.55958
trainer/Q2 Predictions Max         -9.76266
trainer/Q2 Predictions Min        -80.2296
trainer/Q Targets Mean            -12.3663
trainer/Q Targets Std               9.85509
trainer/Q Targets Max              -0.0603592
trainer/Q Targets Min             -83.3456
trainer/Log Pis Mean                2.24255
trainer/Log Pis Std                 1.34456
trainer/Log Pis Max                 9.22958
trainer/Log Pis Min                -0.37077
trainer/Policy mu Mean              0.112117
trainer/Policy mu Std               0.775689
trainer/Policy mu Max               3.23575
trainer/Policy mu Min              -2.73296
trainer/Policy log std Mean        -2.02296
trainer/Policy log std Std          0.469804
trainer/Policy log std Max         -0.517434
trainer/Policy log std Min         -2.47593
trainer/Alpha                       0.0536458
trainer/Alpha Loss                  0.709577
exploration/num steps total     30200
exploration/num paths total       302
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.32653
exploration/Rewards Std             0.889868
exploration/Rewards Max            -0.00162577
exploration/Rewards Min            -7.31824
exploration/Returns Mean          -32.653
exploration/Returns Std             6.21085
exploration/Returns Max           -21.9403
exploration/Returns Min           -39.3436
exploration/Actions Mean            0.0425706
exploration/Actions Std             0.238777
exploration/Actions Max             0.998216
exploration/Actions Min            -0.48784
exploration/Num Paths               5
exploration/Average Returns       -32.653
evaluation/num steps total     150000
evaluation/num paths total       1500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.252943
evaluation/Rewards Std              1.04144
evaluation/Rewards Max             -0.0281927
evaluation/Rewards Min            -10.1546
evaluation/Returns Mean           -25.2943
evaluation/Returns Std             16.3969
evaluation/Returns Max             -4.52046
evaluation/Returns Min            -58.5778
evaluation/Actions Mean             0.0271603
evaluation/Actions Std              0.18815
evaluation/Actions Max              0.997163
evaluation/Actions Min             -0.995924
evaluation/Num Paths               25
evaluation/Average Returns        -25.2943
time/data storing (s)               0.0029202
time/evaluation sampling (s)        0.523647
time/exploration sampling (s)       0.142728
time/logging (s)                    0.00542938
time/saving (s)                     0.00195678
time/training (s)                   1.94938
time/epoch (s)                      2.62606
time/total (s)                    162.439
Epoch                              59
-----------------------------  ---------------
2019-04-22 21:11:32.060682 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 60 finished
-----------------------------  ---------------
replay_buffer/size              30700
trainer/QF1 Loss                    1.1745
trainer/QF2 Loss                    1.16249
trainer/Policy Loss                12.9604
trainer/Q1 Predictions Mean       -11.3957
trainer/Q1 Predictions Std          5.85925
trainer/Q1 Predictions Max         -9.57372
trainer/Q1 Predictions Min        -48.4922
trainer/Q2 Predictions Mean       -11.3906
trainer/Q2 Predictions Std          5.88184
trainer/Q2 Predictions Max         -9.5617
trainer/Q2 Predictions Min        -48.7259
trainer/Q Targets Mean            -11.3238
trainer/Q Targets Std               5.74952
trainer/Q Targets Max              -1.33844
trainer/Q Targets Min             -48.251
trainer/Log Pis Mean                1.90645
trainer/Log Pis Std                 1.21833
trainer/Log Pis Max                 5.05561
trainer/Log Pis Min                -4.02772
trainer/Policy mu Mean              0.0594555
trainer/Policy mu Std               0.705811
trainer/Policy mu Max               3.13864
trainer/Policy mu Min              -2.58253
trainer/Policy log std Mean        -2.08539
trainer/Policy log std Std          0.484577
trainer/Policy log std Max         -0.491989
trainer/Policy log std Min         -2.529
trainer/Alpha                       0.0553416
trainer/Alpha Loss                 -0.270767
exploration/num steps total     30700
exploration/num paths total       307
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.358516
exploration/Rewards Std             1.11212
exploration/Rewards Max            -0.008444
exploration/Rewards Min            -9.7207
exploration/Returns Mean          -35.8516
exploration/Returns Std            18.0899
exploration/Returns Max           -12.9295
exploration/Returns Min           -58.3606
exploration/Actions Mean            0.0209663
exploration/Actions Std             0.241298
exploration/Actions Max             0.999438
exploration/Actions Min            -0.991712
exploration/Num Paths               5
exploration/Average Returns       -35.8516
evaluation/num steps total     152500
evaluation/num paths total       1525
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.277473
evaluation/Rewards Std              1.194
evaluation/Rewards Max             -0.0158447
evaluation/Rewards Min            -11.0444
evaluation/Returns Mean           -27.7473
evaluation/Returns Std             19.0475
evaluation/Returns Max             -2.34638
evaluation/Returns Min            -60.3639
evaluation/Actions Mean             0.024528
evaluation/Actions Std              0.198829
evaluation/Actions Max              0.997676
evaluation/Actions Min             -0.996624
evaluation/Num Paths               25
evaluation/Average Returns        -27.7473
time/data storing (s)               0.00345858
time/evaluation sampling (s)        0.539455
time/exploration sampling (s)       0.149005
time/logging (s)                    0.00662579
time/saving (s)                     0.0020951
time/training (s)                   2.12423
time/epoch (s)                      2.82487
time/total (s)                    165.269
Epoch                              60
-----------------------------  ---------------
2019-04-22 21:11:35.083726 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 61 finished
-----------------------------  ---------------
replay_buffer/size              31200
trainer/QF1 Loss                    0.274843
trainer/QF2 Loss                    0.292741
trainer/Policy Loss                14.9423
trainer/Q1 Predictions Mean       -13.3706
trainer/Q1 Predictions Std         11.0964
trainer/Q1 Predictions Max         -9.37896
trainer/Q1 Predictions Min        -75.7171
trainer/Q2 Predictions Mean       -13.3869
trainer/Q2 Predictions Std         11.1119
trainer/Q2 Predictions Max         -9.38773
trainer/Q2 Predictions Min        -75.7856
trainer/Q Targets Mean            -13.5406
trainer/Q Targets Std              11.2764
trainer/Q Targets Max              -9.46438
trainer/Q Targets Min             -77.1563
trainer/Log Pis Mean                2.31481
trainer/Log Pis Std                 1.47354
trainer/Log Pis Max                 8.01644
trainer/Log Pis Min                -1.84512
trainer/Policy mu Mean              0.087565
trainer/Policy mu Std               0.962972
trainer/Policy mu Max               3.09363
trainer/Policy mu Min              -3.27226
trainer/Policy log std Mean        -1.93191
trainer/Policy log std Std          0.560218
trainer/Policy log std Max         -0.389878
trainer/Policy log std Min         -2.48519
trainer/Alpha                       0.0549069
trainer/Alpha Loss                  0.913623
exploration/num steps total     31200
exploration/num paths total       312
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.298216
exploration/Rewards Std             0.81312
exploration/Rewards Max            -0.00501739
exploration/Rewards Min            -7.30358
exploration/Returns Mean          -29.8216
exploration/Returns Std             7.44234
exploration/Returns Max           -16.9183
exploration/Returns Min           -39.9265
exploration/Actions Mean            0.0296487
exploration/Actions Std             0.233907
exploration/Actions Max             0.996255
exploration/Actions Min            -0.996978
exploration/Num Paths               5
exploration/Average Returns       -29.8216
evaluation/num steps total     155000
evaluation/num paths total       1550
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.322124
evaluation/Rewards Std              1.2149
evaluation/Rewards Max             -0.00885348
evaluation/Rewards Min            -10.2989
evaluation/Returns Mean           -32.2124
evaluation/Returns Std             16.5562
evaluation/Returns Max             -8.01327
evaluation/Returns Min            -61.7379
evaluation/Actions Mean             0.0292772
evaluation/Actions Std              0.209966
evaluation/Actions Max              0.996008
evaluation/Actions Min             -0.996012
evaluation/Num Paths               25
evaluation/Average Returns        -32.2124
time/data storing (s)               0.00308369
time/evaluation sampling (s)        0.695828
time/exploration sampling (s)       0.167562
time/logging (s)                    0.0063324
time/saving (s)                     0.00216576
time/training (s)                   2.1416
time/epoch (s)                      3.01657
time/total (s)                    168.29
Epoch                              61
-----------------------------  ---------------
2019-04-22 21:11:38.728846 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 62 finished
-----------------------------  ---------------
replay_buffer/size              31700
trainer/QF1 Loss                    0.375075
trainer/QF2 Loss                    0.438439
trainer/Policy Loss                13.2231
trainer/Q1 Predictions Mean       -11.8456
trainer/Q1 Predictions Std          7.5828
trainer/Q1 Predictions Max         -9.28552
trainer/Q1 Predictions Min        -64.0678
trainer/Q2 Predictions Mean       -11.8557
trainer/Q2 Predictions Std          7.55878
trainer/Q2 Predictions Max         -9.29615
trainer/Q2 Predictions Min        -64.1992
trainer/Q Targets Mean            -12.0224
trainer/Q Targets Std               7.72287
trainer/Q Targets Max              -9.33582
trainer/Q Targets Min             -64.3657
trainer/Log Pis Mean                1.75881
trainer/Log Pis Std                 1.55738
trainer/Log Pis Max                 6.53456
trainer/Log Pis Min                -3.74983
trainer/Policy mu Mean             -0.00279593
trainer/Policy mu Std               0.841685
trainer/Policy mu Max               3.06264
trainer/Policy mu Min              -2.91875
trainer/Policy log std Mean        -1.98131
trainer/Policy log std Std          0.542347
trainer/Policy log std Max         -0.460929
trainer/Policy log std Min         -2.51473
trainer/Alpha                       0.054175
trainer/Alpha Loss                 -0.703193
exploration/num steps total     31700
exploration/num paths total       317
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.272463
exploration/Rewards Std             0.695791
exploration/Rewards Max            -0.00441826
exploration/Rewards Min            -5.85842
exploration/Returns Mean          -27.2463
exploration/Returns Std             3.37547
exploration/Returns Max           -21.8332
exploration/Returns Min           -31.4433
exploration/Actions Mean            0.0250021
exploration/Actions Std             0.235295
exploration/Actions Max             0.994982
exploration/Actions Min            -0.994504
exploration/Num Paths               5
exploration/Average Returns       -27.2463
evaluation/num steps total     157500
evaluation/num paths total       1575
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.232978
evaluation/Rewards Std              0.981818
evaluation/Rewards Max             -0.0225469
evaluation/Rewards Min            -10.6015
evaluation/Returns Mean           -23.2978
evaluation/Returns Std             15.0207
evaluation/Returns Max             -4.59879
evaluation/Returns Min            -57.1103
evaluation/Actions Mean             0.0258563
evaluation/Actions Std              0.191454
evaluation/Actions Max              0.997522
evaluation/Actions Min             -0.994896
evaluation/Num Paths               25
evaluation/Average Returns        -23.2978
time/data storing (s)               0.00307888
time/evaluation sampling (s)        0.570907
time/exploration sampling (s)       0.18355
time/logging (s)                    0.00978403
time/saving (s)                     0.002966
time/training (s)                   2.87223
time/epoch (s)                      3.64251
time/total (s)                    171.937
Epoch                              62
-----------------------------  ---------------
2019-04-22 21:11:42.042812 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 63 finished
-----------------------------  ---------------
replay_buffer/size              32200
trainer/QF1 Loss                    1.01286
trainer/QF2 Loss                    1.03267
trainer/Policy Loss                12.5525
trainer/Q1 Predictions Mean       -10.8408
trainer/Q1 Predictions Std          6.2188
trainer/Q1 Predictions Max         -9.14275
trainer/Q1 Predictions Min        -61.2805
trainer/Q2 Predictions Mean       -10.8516
trainer/Q2 Predictions Std          6.23178
trainer/Q2 Predictions Max         -9.15024
trainer/Q2 Predictions Min        -61.4382
trainer/Q Targets Mean            -10.8411
trainer/Q Targets Std               6.25998
trainer/Q Targets Max              -0.994588
trainer/Q Targets Min             -61.3937
trainer/Log Pis Mean                2.14525
trainer/Log Pis Std                 1.4381
trainer/Log Pis Max                 9.01487
trainer/Log Pis Min                -1.33096
trainer/Policy mu Mean             -0.00162347
trainer/Policy mu Std               0.700843
trainer/Policy mu Max               2.96233
trainer/Policy mu Min              -2.67838
trainer/Policy log std Mean        -2.06569
trainer/Policy log std Std          0.449403
trainer/Policy log std Max         -0.44912
trainer/Policy log std Min         -2.47634
trainer/Alpha                       0.0550321
trainer/Alpha Loss                  0.4212
exploration/num steps total     32200
exploration/num paths total       322
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351257
exploration/Rewards Std             1.00454
exploration/Rewards Max            -0.00519019
exploration/Rewards Min            -8.50782
exploration/Returns Mean          -35.1257
exploration/Returns Std             9.84413
exploration/Returns Max           -24.9178
exploration/Returns Min           -51.3969
exploration/Actions Mean            0.0298452
exploration/Actions Std             0.236975
exploration/Actions Max             0.998253
exploration/Actions Min            -0.986733
exploration/Num Paths               5
exploration/Average Returns       -35.1257
evaluation/num steps total     160000
evaluation/num paths total       1600
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234137
evaluation/Rewards Std              1.10083
evaluation/Rewards Max             -0.00421768
evaluation/Rewards Min            -10.6513
evaluation/Returns Mean           -23.4137
evaluation/Returns Std             17.2344
evaluation/Returns Max             -2.22612
evaluation/Returns Min            -56.9666
evaluation/Actions Mean             0.0255284
evaluation/Actions Std              0.195069
evaluation/Actions Max              0.997139
evaluation/Actions Min             -0.997579
evaluation/Num Paths               25
evaluation/Average Returns        -23.4137
time/data storing (s)               0.00410796
time/evaluation sampling (s)        0.72751
time/exploration sampling (s)       0.295447
time/logging (s)                    0.00861417
time/saving (s)                     0.00218108
time/training (s)                   2.26624
time/epoch (s)                      3.3041
time/total (s)                    175.247
Epoch                              63
-----------------------------  ---------------
2019-04-22 21:11:45.178017 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 64 finished
-----------------------------  ---------------
replay_buffer/size              32700
trainer/QF1 Loss                    0.997452
trainer/QF2 Loss                    1.03308
trainer/Policy Loss                13.3634
trainer/Q1 Predictions Mean       -11.7853
trainer/Q1 Predictions Std          8.20195
trainer/Q1 Predictions Max         -9.0608
trainer/Q1 Predictions Min        -59.1226
trainer/Q2 Predictions Mean       -11.78
trainer/Q2 Predictions Std          8.1825
trainer/Q2 Predictions Max         -9.05358
trainer/Q2 Predictions Min        -58.9332
trainer/Q Targets Mean            -11.7733
trainer/Q Targets Std               8.41598
trainer/Q Targets Max              -0.18969
trainer/Q Targets Min             -59.0122
trainer/Log Pis Mean                2.15267
trainer/Log Pis Std                 1.2043
trainer/Log Pis Max                 9.65815
trainer/Log Pis Min                -0.679344
trainer/Policy mu Mean              0.0407166
trainer/Policy mu Std               0.763824
trainer/Policy mu Max               3.14326
trainer/Policy mu Min              -2.75454
trainer/Policy log std Mean        -2.09918
trainer/Policy log std Std          0.485795
trainer/Policy log std Max         -0.162746
trainer/Policy log std Min         -2.51852
trainer/Alpha                       0.0545142
trainer/Alpha Loss                  0.444161
exploration/num steps total     32700
exploration/num paths total       327
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.304847
exploration/Rewards Std             0.883646
exploration/Rewards Max            -0.00754092
exploration/Rewards Min            -7.8361
exploration/Returns Mean          -30.4847
exploration/Returns Std            11.0502
exploration/Returns Max           -14.4662
exploration/Returns Min           -47.6731
exploration/Actions Mean            0.0246525
exploration/Actions Std             0.227344
exploration/Actions Max             0.999011
exploration/Actions Min            -0.99424
exploration/Num Paths               5
exploration/Average Returns       -30.4847
evaluation/num steps total     162500
evaluation/num paths total       1625
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.267325
evaluation/Rewards Std              1.12502
evaluation/Rewards Max             -0.0166616
evaluation/Rewards Min            -10.2561
evaluation/Returns Mean           -26.7325
evaluation/Returns Std             18.5122
evaluation/Returns Max             -3.3665
evaluation/Returns Min            -61.2703
evaluation/Actions Mean             0.0327381
evaluation/Actions Std              0.187399
evaluation/Actions Max              0.997224
evaluation/Actions Min             -0.985482
evaluation/Num Paths               25
evaluation/Average Returns        -26.7325
time/data storing (s)               0.00317564
time/evaluation sampling (s)        0.646133
time/exploration sampling (s)       0.157555
time/logging (s)                    0.00691435
time/saving (s)                     0.00202246
time/training (s)                   2.31066
time/epoch (s)                      3.12646
time/total (s)                    178.378
Epoch                              64
-----------------------------  ---------------
2019-04-22 21:11:48.247583 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 65 finished
-----------------------------  ---------------
replay_buffer/size              33200
trainer/QF1 Loss                    1.06513
trainer/QF2 Loss                    1.03278
trainer/Policy Loss                12.2546
trainer/Q1 Predictions Mean       -10.5128
trainer/Q1 Predictions Std          6.25078
trainer/Q1 Predictions Max         -8.98263
trainer/Q1 Predictions Min        -65.0988
trainer/Q2 Predictions Mean       -10.5273
trainer/Q2 Predictions Std          6.26109
trainer/Q2 Predictions Max         -8.994
trainer/Q2 Predictions Min        -65.1492
trainer/Q Targets Mean            -10.4036
trainer/Q Targets Std               6.18392
trainer/Q Targets Max              -1.74355
trainer/Q Targets Min             -64.0579
trainer/Log Pis Mean                1.97176
trainer/Log Pis Std                 1.27007
trainer/Log Pis Max                 8.42622
trainer/Log Pis Min                -2.91275
trainer/Policy mu Mean              0.0690385
trainer/Policy mu Std               0.665041
trainer/Policy mu Max               3.10622
trainer/Policy mu Min              -2.73704
trainer/Policy log std Mean        -2.0538
trainer/Policy log std Std          0.428519
trainer/Policy log std Max         -0.544858
trainer/Policy log std Min         -2.47476
trainer/Alpha                       0.0557062
trainer/Alpha Loss                 -0.0815516
exploration/num steps total     33200
exploration/num paths total       332
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.37329
exploration/Rewards Std             1.11715
exploration/Rewards Max            -0.00910807
exploration/Rewards Min            -9.014
exploration/Returns Mean          -37.329
exploration/Returns Std            13.1077
exploration/Returns Max           -21.3547
exploration/Returns Min           -55.6065
exploration/Actions Mean            0.0233731
exploration/Actions Std             0.252332
exploration/Actions Max             0.998459
exploration/Actions Min            -0.988453
exploration/Num Paths               5
exploration/Average Returns       -37.329
evaluation/num steps total     165000
evaluation/num paths total       1650
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.244726
evaluation/Rewards Std              1.09083
evaluation/Rewards Max             -0.00727791
evaluation/Rewards Min            -10.3344
evaluation/Returns Mean           -24.4726
evaluation/Returns Std             16.9667
evaluation/Returns Max             -3.35757
evaluation/Returns Min            -59.0329
evaluation/Actions Mean             0.0273956
evaluation/Actions Std              0.196443
evaluation/Actions Max              0.997068
evaluation/Actions Min             -0.994756
evaluation/Num Paths               25
evaluation/Average Returns        -24.4726
time/data storing (s)               0.00425551
time/evaluation sampling (s)        0.587178
time/exploration sampling (s)       0.17153
time/logging (s)                    0.0068835
time/saving (s)                     0.00200209
time/training (s)                   2.29099
time/epoch (s)                      3.06284
time/total (s)                    181.446
Epoch                              65
-----------------------------  ---------------
2019-04-22 21:11:51.191431 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 66 finished
-----------------------------  ---------------
replay_buffer/size              33700
trainer/QF1 Loss                    1.69681
trainer/QF2 Loss                    1.73386
trainer/Policy Loss                12.4316
trainer/Q1 Predictions Mean       -10.6036
trainer/Q1 Predictions Std          6.28528
trainer/Q1 Predictions Max         -8.80719
trainer/Q1 Predictions Min        -57.9359
trainer/Q2 Predictions Mean       -10.6263
trainer/Q2 Predictions Std          6.29126
trainer/Q2 Predictions Max         -8.84476
trainer/Q2 Predictions Min        -57.7267
trainer/Q Targets Mean            -10.4368
trainer/Q Targets Std               6.66085
trainer/Q Targets Max              -0.115436
trainer/Q Targets Min             -60.6148
trainer/Log Pis Mean                2.17504
trainer/Log Pis Std                 1.33993
trainer/Log Pis Max                 6.39
trainer/Log Pis Min                -2.32472
trainer/Policy mu Mean              0.129411
trainer/Policy mu Std               0.689245
trainer/Policy mu Max               3.07364
trainer/Policy mu Min              -2.24054
trainer/Policy log std Mean        -2.14984
trainer/Policy log std Std          0.468875
trainer/Policy log std Max         -0.567599
trainer/Policy log std Min         -2.56887
trainer/Alpha                       0.0553258
trainer/Alpha Loss                  0.506665
exploration/num steps total     33700
exploration/num paths total       337
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.259342
exploration/Rewards Std             0.824879
exploration/Rewards Max            -0.00487891
exploration/Rewards Min            -9.00874
exploration/Returns Mean          -25.9342
exploration/Returns Std            13.1019
exploration/Returns Max           -13.7328
exploration/Returns Min           -48.1711
exploration/Actions Mean            0.0398025
exploration/Actions Std             0.223493
exploration/Actions Max             0.997765
exploration/Actions Min            -0.42631
exploration/Num Paths               5
exploration/Average Returns       -25.9342
evaluation/num steps total     167500
evaluation/num paths total       1675
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226464
evaluation/Rewards Std              0.992694
evaluation/Rewards Max             -0.0104216
evaluation/Rewards Min            -10.3518
evaluation/Returns Mean           -22.6464
evaluation/Returns Std             16.9113
evaluation/Returns Max             -4.10502
evaluation/Returns Min            -59.4098
evaluation/Actions Mean             0.0248437
evaluation/Actions Std              0.188824
evaluation/Actions Max              0.996395
evaluation/Actions Min             -0.996944
evaluation/Num Paths               25
evaluation/Average Returns        -22.6464
time/data storing (s)               0.00336438
time/evaluation sampling (s)        0.584764
time/exploration sampling (s)       0.179314
time/logging (s)                    0.00730496
time/saving (s)                     0.00210495
time/training (s)                   2.16129
time/epoch (s)                      2.93814
time/total (s)                    184.389
Epoch                              66
-----------------------------  ---------------
2019-04-22 21:11:54.061171 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 67 finished
-----------------------------  ---------------
replay_buffer/size              34200
trainer/QF1 Loss                    1.56359
trainer/QF2 Loss                    1.58067
trainer/Policy Loss                12.4872
trainer/Q1 Predictions Mean       -10.9962
trainer/Q1 Predictions Std          8.13874
trainer/Q1 Predictions Max         -8.53072
trainer/Q1 Predictions Min        -61.0852
trainer/Q2 Predictions Mean       -10.9855
trainer/Q2 Predictions Std          8.13418
trainer/Q2 Predictions Max         -8.52925
trainer/Q2 Predictions Min        -61.1378
trainer/Q Targets Mean            -11.0495
trainer/Q Targets Std               8.21907
trainer/Q Targets Max              -0.245267
trainer/Q Targets Min             -60.7596
trainer/Log Pis Mean                1.78095
trainer/Log Pis Std                 1.32753
trainer/Log Pis Max                 6.71444
trainer/Log Pis Min                -1.46341
trainer/Policy mu Mean              0.117814
trainer/Policy mu Std               0.750461
trainer/Policy mu Max               3.06304
trainer/Policy mu Min              -1.91914
trainer/Policy log std Mean        -2.03909
trainer/Policy log std Std          0.500748
trainer/Policy log std Max         -0.265216
trainer/Policy log std Min         -2.52617
trainer/Alpha                       0.0559365
trainer/Alpha Loss                 -0.631618
exploration/num steps total     34200
exploration/num paths total       342
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.41285
exploration/Rewards Std             1.23252
exploration/Rewards Max            -0.00295725
exploration/Rewards Min            -9.46901
exploration/Returns Mean          -41.285
exploration/Returns Std            15.3432
exploration/Returns Max           -16.3428
exploration/Returns Min           -62.3061
exploration/Actions Mean            0.0326276
exploration/Actions Std             0.256817
exploration/Actions Max             0.998442
exploration/Actions Min            -0.992573
exploration/Num Paths               5
exploration/Average Returns       -41.285
evaluation/num steps total     170000
evaluation/num paths total       1700
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.212431
evaluation/Rewards Std              0.995837
evaluation/Rewards Max             -0.00889391
evaluation/Rewards Min            -10.7137
evaluation/Returns Mean           -21.2431
evaluation/Returns Std             17.9752
evaluation/Returns Max             -2.43942
evaluation/Returns Min            -58.9376
evaluation/Actions Mean             0.0220456
evaluation/Actions Std              0.180779
evaluation/Actions Max              0.997074
evaluation/Actions Min             -0.995797
evaluation/Num Paths               25
evaluation/Average Returns        -21.2431
time/data storing (s)               0.00351896
time/evaluation sampling (s)        0.610187
time/exploration sampling (s)       0.183458
time/logging (s)                    0.00735386
time/saving (s)                     0.00201009
time/training (s)                   2.05623
time/epoch (s)                      2.86275
time/total (s)                    187.257
Epoch                              67
-----------------------------  ---------------
2019-04-22 21:11:57.007582 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 68 finished
-----------------------------  ---------------
replay_buffer/size              34700
trainer/QF1 Loss                    0.221493
trainer/QF2 Loss                    0.231532
trainer/Policy Loss                11.7093
trainer/Q1 Predictions Mean        -9.91404
trainer/Q1 Predictions Std          4.24569
trainer/Q1 Predictions Max         -8.6307
trainer/Q1 Predictions Min        -37.9525
trainer/Q2 Predictions Mean        -9.94488
trainer/Q2 Predictions Std          4.26804
trainer/Q2 Predictions Max         -8.66889
trainer/Q2 Predictions Min        -38.2086
trainer/Q Targets Mean             -9.95966
trainer/Q Targets Std               4.41523
trainer/Q Targets Max              -8.53897
trainer/Q Targets Min             -39.0033
trainer/Log Pis Mean                2.0803
trainer/Log Pis Std                 0.939774
trainer/Log Pis Max                 6.40527
trainer/Log Pis Min                -0.427049
trainer/Policy mu Mean              0.0724821
trainer/Policy mu Std               0.621847
trainer/Policy mu Max               2.95016
trainer/Policy mu Min              -2.33682
trainer/Policy log std Mean        -2.1154
trainer/Policy log std Std          0.420138
trainer/Policy log std Max         -0.440252
trainer/Policy log std Min         -2.4955
trainer/Alpha                       0.0536394
trainer/Alpha Loss                  0.234905
exploration/num steps total     34700
exploration/num paths total       347
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.346749
exploration/Rewards Std             0.957353
exploration/Rewards Max            -0.00380189
exploration/Rewards Min            -8.09098
exploration/Returns Mean          -34.6749
exploration/Returns Std             8.87975
exploration/Returns Max           -23.6062
exploration/Returns Min           -47.7802
exploration/Actions Mean            0.024274
exploration/Actions Std             0.237606
exploration/Actions Max             0.997969
exploration/Actions Min            -0.997183
exploration/Num Paths               5
exploration/Average Returns       -34.6749
evaluation/num steps total     172500
evaluation/num paths total       1725
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.230862
evaluation/Rewards Std              0.946903
evaluation/Rewards Max             -0.0204953
evaluation/Rewards Min             -9.38083
evaluation/Returns Mean           -23.0862
evaluation/Returns Std             14.3915
evaluation/Returns Max             -5.58727
evaluation/Returns Min            -53.6562
evaluation/Actions Mean             0.0243546
evaluation/Actions Std              0.184855
evaluation/Actions Max              0.995211
evaluation/Actions Min             -0.996506
evaluation/Num Paths               25
evaluation/Average Returns        -23.0862
time/data storing (s)               0.00304573
time/evaluation sampling (s)        0.591497
time/exploration sampling (s)       0.1653
time/logging (s)                    0.00704922
time/saving (s)                     0.00202683
time/training (s)                   2.17105
time/epoch (s)                      2.93997
time/total (s)                    190.201
Epoch                              68
-----------------------------  ---------------
2019-04-22 21:11:59.722053 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 69 finished
-----------------------------  ---------------
replay_buffer/size              35200
trainer/QF1 Loss                    0.205732
trainer/QF2 Loss                    0.173311
trainer/Policy Loss                12.2022
trainer/Q1 Predictions Mean       -10.5083
trainer/Q1 Predictions Std          8.10334
trainer/Q1 Predictions Max         -8.30225
trainer/Q1 Predictions Min        -78.072
trainer/Q2 Predictions Mean       -10.5082
trainer/Q2 Predictions Std          8.04626
trainer/Q2 Predictions Max         -8.31191
trainer/Q2 Predictions Min        -77.4761
trainer/Q Targets Mean            -10.64
trainer/Q Targets Std               7.77768
trainer/Q Targets Max              -8.431
trainer/Q Targets Min             -75.1082
trainer/Log Pis Mean                2.00472
trainer/Log Pis Std                 1.49978
trainer/Log Pis Max                 7.53323
trainer/Log Pis Min                -4.20444
trainer/Policy mu Mean              0.158999
trainer/Policy mu Std               0.667841
trainer/Policy mu Max               3.02136
trainer/Policy mu Min              -2.1502
trainer/Policy log std Mean        -2.1132
trainer/Policy log std Std          0.429445
trainer/Policy log std Max         -0.555559
trainer/Policy log std Min         -2.50303
trainer/Alpha                       0.0556412
trainer/Alpha Loss                  0.013635
exploration/num steps total     35200
exploration/num paths total       352
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.256767
exploration/Rewards Std             0.70905
exploration/Rewards Max            -0.00806529
exploration/Rewards Min            -6.71465
exploration/Returns Mean          -25.6767
exploration/Returns Std             8.86657
exploration/Returns Max           -13.6452
exploration/Returns Min           -38.0318
exploration/Actions Mean            0.016415
exploration/Actions Std             0.223213
exploration/Actions Max             0.998026
exploration/Actions Min            -0.996451
exploration/Num Paths               5
exploration/Average Returns       -25.6767
evaluation/num steps total     175000
evaluation/num paths total       1750
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.187835
evaluation/Rewards Std              0.884736
evaluation/Rewards Max             -0.00878892
evaluation/Rewards Min             -9.95683
evaluation/Returns Mean           -18.7835
evaluation/Returns Std             12.3285
evaluation/Returns Max             -3.32786
evaluation/Returns Min            -48.4161
evaluation/Actions Mean             0.0199681
evaluation/Actions Std              0.184088
evaluation/Actions Max              0.996257
evaluation/Actions Min             -0.996979
evaluation/Num Paths               25
evaluation/Average Returns        -18.7835
time/data storing (s)               0.00319257
time/evaluation sampling (s)        0.584364
time/exploration sampling (s)       0.15971
time/logging (s)                    0.00715945
time/saving (s)                     0.0019394
time/training (s)                   1.95152
time/epoch (s)                      2.70789
time/total (s)                    192.914
Epoch                              69
-----------------------------  ---------------
2019-04-22 21:12:02.658917 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 70 finished
-----------------------------  ---------------
replay_buffer/size              35700
trainer/QF1 Loss                    0.779795
trainer/QF2 Loss                    0.77916
trainer/Policy Loss                12.7955
trainer/Q1 Predictions Mean       -10.9638
trainer/Q1 Predictions Std          7.9299
trainer/Q1 Predictions Max         -8.37158
trainer/Q1 Predictions Min        -54.9704
trainer/Q2 Predictions Mean       -10.9292
trainer/Q2 Predictions Std          7.90562
trainer/Q2 Predictions Max         -8.33788
trainer/Q2 Predictions Min        -54.7911
trainer/Q Targets Mean            -10.8904
trainer/Q Targets Std               7.93373
trainer/Q Targets Max              -0.548791
trainer/Q Targets Min             -56.0976
trainer/Log Pis Mean                2.11523
trainer/Log Pis Std                 1.21255
trainer/Log Pis Max                 5.4588
trainer/Log Pis Min                -2.52566
trainer/Policy mu Mean              0.154111
trainer/Policy mu Std               0.726641
trainer/Policy mu Max               3.03386
trainer/Policy mu Min              -2.94846
trainer/Policy log std Mean        -2.08748
trainer/Policy log std Std          0.465051
trainer/Policy log std Max         -0.662426
trainer/Policy log std Min         -2.54916
trainer/Alpha                       0.0571715
trainer/Alpha Loss                  0.329773
exploration/num steps total     35700
exploration/num paths total       357
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.279516
exploration/Rewards Std             0.847928
exploration/Rewards Max            -0.00153187
exploration/Rewards Min            -8.95261
exploration/Returns Mean          -27.9516
exploration/Returns Std            12.7267
exploration/Returns Max           -14.6414
exploration/Returns Min           -48.5545
exploration/Actions Mean            0.0220165
exploration/Actions Std             0.225461
exploration/Actions Max             0.996324
exploration/Actions Min            -0.991914
exploration/Num Paths               5
exploration/Average Returns       -27.9516
evaluation/num steps total     177500
evaluation/num paths total       1775
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.268548
evaluation/Rewards Std              1.09764
evaluation/Rewards Max             -0.00799877
evaluation/Rewards Min            -11.2528
evaluation/Returns Mean           -26.8548
evaluation/Returns Std             18.9864
evaluation/Returns Max             -4.75433
evaluation/Returns Min            -64.629
evaluation/Actions Mean             0.0251956
evaluation/Actions Std              0.193043
evaluation/Actions Max              0.996879
evaluation/Actions Min             -0.997479
evaluation/Num Paths               25
evaluation/Average Returns        -26.8548
time/data storing (s)               0.00318011
time/evaluation sampling (s)        0.540326
time/exploration sampling (s)       0.151666
time/logging (s)                    0.00903545
time/saving (s)                     0.00270806
time/training (s)                   2.22524
time/epoch (s)                      2.93216
time/total (s)                    195.851
Epoch                              70
-----------------------------  ---------------
2019-04-22 21:12:05.638612 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 71 finished
-----------------------------  ---------------
replay_buffer/size              36200
trainer/QF1 Loss                    1.56575
trainer/QF2 Loss                    1.58144
trainer/Policy Loss                13.4233
trainer/Q1 Predictions Mean       -11.7305
trainer/Q1 Predictions Std          9.75008
trainer/Q1 Predictions Max         -8.21872
trainer/Q1 Predictions Min        -73.6302
trainer/Q2 Predictions Mean       -11.7165
trainer/Q2 Predictions Std          9.7631
trainer/Q2 Predictions Max         -8.19852
trainer/Q2 Predictions Min        -73.6052
trainer/Q Targets Mean            -11.6798
trainer/Q Targets Std               9.88106
trainer/Q Targets Max              -0.0918548
trainer/Q Targets Min             -73.8315
trainer/Log Pis Mean                2.1433
trainer/Log Pis Std                 1.69606
trainer/Log Pis Max                 8.87722
trainer/Log Pis Min                -2.55582
trainer/Policy mu Mean              0.105204
trainer/Policy mu Std               0.909183
trainer/Policy mu Max               3.35843
trainer/Policy mu Min              -2.7422
trainer/Policy log std Mean        -2.00661
trainer/Policy log std Std          0.535194
trainer/Policy log std Max         -0.199616
trainer/Policy log std Min         -2.49585
trainer/Alpha                       0.0538171
trainer/Alpha Loss                  0.41873
exploration/num steps total     36200
exploration/num paths total       362
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.332267
exploration/Rewards Std             1.00025
exploration/Rewards Max            -0.00478605
exploration/Rewards Min           -10.4272
exploration/Returns Mean          -33.2267
exploration/Returns Std            16.8472
exploration/Returns Max           -20.6606
exploration/Returns Min           -66.1975
exploration/Actions Mean            0.00215556
exploration/Actions Std             0.242639
exploration/Actions Max             0.997238
exploration/Actions Min            -0.999197
exploration/Num Paths               5
exploration/Average Returns       -33.2267
evaluation/num steps total     180000
evaluation/num paths total       1800
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.226479
evaluation/Rewards Std              0.966022
evaluation/Rewards Max             -0.00904515
evaluation/Rewards Min             -9.71273
evaluation/Returns Mean           -22.6479
evaluation/Returns Std             14.2058
evaluation/Returns Max             -3.47466
evaluation/Returns Min            -51.3514
evaluation/Actions Mean             0.0197193
evaluation/Actions Std              0.187695
evaluation/Actions Max              0.995944
evaluation/Actions Min             -0.996882
evaluation/Num Paths               25
evaluation/Average Returns        -22.6479
time/data storing (s)               0.00316559
time/evaluation sampling (s)        0.616962
time/exploration sampling (s)       0.162103
time/logging (s)                    0.00799688
time/saving (s)                     0.00205776
time/training (s)                   2.17936
time/epoch (s)                      2.97164
time/total (s)                    198.828
Epoch                              71
-----------------------------  ---------------
2019-04-22 21:12:08.702766 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 72 finished
-----------------------------  ---------------
replay_buffer/size              36700
trainer/QF1 Loss                    0.739784
trainer/QF2 Loss                    0.753682
trainer/Policy Loss                11.3463
trainer/Q1 Predictions Mean        -9.66659
trainer/Q1 Predictions Std          6.23753
trainer/Q1 Predictions Max         -8.07825
trainer/Q1 Predictions Min        -60.5533
trainer/Q2 Predictions Mean        -9.71533
trainer/Q2 Predictions Std          6.22483
trainer/Q2 Predictions Max         -8.13369
trainer/Q2 Predictions Min        -60.5021
trainer/Q Targets Mean             -9.67506
trainer/Q Targets Std               6.26084
trainer/Q Targets Max              -0.0805905
trainer/Q Targets Min             -60.7547
trainer/Log Pis Mean                1.96364
trainer/Log Pis Std                 1.17042
trainer/Log Pis Max                 5.99897
trainer/Log Pis Min                -3.66252
trainer/Policy mu Mean              0.0253581
trainer/Policy mu Std               0.634641
trainer/Policy mu Max               2.92639
trainer/Policy mu Min              -3.00344
trainer/Policy log std Mean        -2.12103
trainer/Policy log std Std          0.451936
trainer/Policy log std Max         -0.594852
trainer/Policy log std Min         -2.57633
trainer/Alpha                       0.0537579
trainer/Alpha Loss                 -0.1063
exploration/num steps total     36700
exploration/num paths total       367
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.330733
exploration/Rewards Std             0.940222
exploration/Rewards Max            -0.00176522
exploration/Rewards Min            -8.01904
exploration/Returns Mean          -33.0733
exploration/Returns Std             7.20893
exploration/Returns Max           -23.2174
exploration/Returns Min           -44.0994
exploration/Actions Mean            0.0206484
exploration/Actions Std             0.244679
exploration/Actions Max             0.997329
exploration/Actions Min            -0.997453
exploration/Num Paths               5
exploration/Average Returns       -33.0733
evaluation/num steps total     182500
evaluation/num paths total       1825
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.218077
evaluation/Rewards Std              1.00873
evaluation/Rewards Max             -0.00108401
evaluation/Rewards Min            -10.2544
evaluation/Returns Mean           -21.8077
evaluation/Returns Std             16.6392
evaluation/Returns Max             -2.76956
evaluation/Returns Min            -56.0019
evaluation/Actions Mean             0.0238368
evaluation/Actions Std              0.184475
evaluation/Actions Max              0.997522
evaluation/Actions Min             -0.995672
evaluation/Num Paths               25
evaluation/Average Returns        -21.8077
time/data storing (s)               0.00306393
time/evaluation sampling (s)        0.565072
time/exploration sampling (s)       0.15809
time/logging (s)                    0.00792599
time/saving (s)                     0.00261717
time/training (s)                   2.32008
time/epoch (s)                      3.05685
time/total (s)                    201.89
Epoch                              72
-----------------------------  ---------------
2019-04-22 21:12:11.674375 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 73 finished
-----------------------------  ---------------
replay_buffer/size              37200
trainer/QF1 Loss                    5.5381
trainer/QF2 Loss                    5.59534
trainer/Policy Loss                11.4135
trainer/Q1 Predictions Mean        -9.95145
trainer/Q1 Predictions Std          7.39002
trainer/Q1 Predictions Max         -8.10077
trainer/Q1 Predictions Min        -65.775
trainer/Q2 Predictions Mean        -9.93473
trainer/Q2 Predictions Std          7.34599
trainer/Q2 Predictions Max         -8.08205
trainer/Q2 Predictions Min        -65.441
trainer/Q Targets Mean             -9.75478
trainer/Q Targets Std               7.46926
trainer/Q Targets Max              -0.104716
trainer/Q Targets Min             -68.3734
trainer/Log Pis Mean                1.83716
trainer/Log Pis Std                 1.28758
trainer/Log Pis Max                 6.91079
trainer/Log Pis Min                -2.60741
trainer/Policy mu Mean             -0.021072
trainer/Policy mu Std               0.619578
trainer/Policy mu Max               3.05025
trainer/Policy mu Min              -2.70663
trainer/Policy log std Mean        -2.1637
trainer/Policy log std Std          0.423222
trainer/Policy log std Max         -0.581166
trainer/Policy log std Min         -2.54715
trainer/Alpha                       0.0550676
trainer/Alpha Loss                 -0.472092
exploration/num steps total     37200
exploration/num paths total       372
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.445128
exploration/Rewards Std             1.33354
exploration/Rewards Max            -0.00102321
exploration/Rewards Min            -9.6547
exploration/Returns Mean          -44.5128
exploration/Returns Std            18.0443
exploration/Returns Max           -22.1561
exploration/Returns Min           -63.3304
exploration/Actions Mean            0.0289782
exploration/Actions Std             0.251107
exploration/Actions Max             0.997517
exploration/Actions Min            -0.994363
exploration/Num Paths               5
exploration/Average Returns       -44.5128
evaluation/num steps total     185000
evaluation/num paths total       1850
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.232625
evaluation/Rewards Std              0.960087
evaluation/Rewards Max             -0.0474259
evaluation/Rewards Min            -11.0356
evaluation/Returns Mean           -23.2625
evaluation/Returns Std             15.822
evaluation/Returns Max             -5.49048
evaluation/Returns Min            -64.5835
evaluation/Actions Mean             0.0290998
evaluation/Actions Std              0.18957
evaluation/Actions Max              0.996956
evaluation/Actions Min             -0.994657
evaluation/Num Paths               25
evaluation/Average Returns        -23.2625
time/data storing (s)               0.00324352
time/evaluation sampling (s)        0.618063
time/exploration sampling (s)       0.167327
time/logging (s)                    0.0082212
time/saving (s)                     0.00233983
time/training (s)                   2.16608
time/epoch (s)                      2.96527
time/total (s)                    204.86
Epoch                              73
-----------------------------  ---------------
2019-04-22 21:12:14.540354 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 74 finished
-----------------------------  ---------------
replay_buffer/size              37700
trainer/QF1 Loss                    1.3505
trainer/QF2 Loss                    1.37433
trainer/Policy Loss                11.8255
trainer/Q1 Predictions Mean        -9.98749
trainer/Q1 Predictions Std          7.00808
trainer/Q1 Predictions Max         -8.02494
trainer/Q1 Predictions Min        -58.9517
trainer/Q2 Predictions Mean        -9.99009
trainer/Q2 Predictions Std          7.01094
trainer/Q2 Predictions Max         -8.02124
trainer/Q2 Predictions Min        -58.9995
trainer/Q Targets Mean             -9.83807
trainer/Q Targets Std               7.09692
trainer/Q Targets Max              -0.0835095
trainer/Q Targets Min             -58.8683
trainer/Log Pis Mean                2.0361
trainer/Log Pis Std                 1.43531
trainer/Log Pis Max                 7.62006
trainer/Log Pis Min                -1.69102
trainer/Policy mu Mean              0.0994202
trainer/Policy mu Std               0.678476
trainer/Policy mu Max               3.05992
trainer/Policy mu Min              -2.73434
trainer/Policy log std Mean        -2.10572
trainer/Policy log std Std          0.453823
trainer/Policy log std Max         -0.475237
trainer/Policy log std Min         -2.54665
trainer/Alpha                       0.0557673
trainer/Alpha Loss                  0.104215
exploration/num steps total     37700
exploration/num paths total       377
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.400502
exploration/Rewards Std             1.26654
exploration/Rewards Max            -0.00386744
exploration/Rewards Min            -9.87719
exploration/Returns Mean          -40.0502
exploration/Returns Std            21.1098
exploration/Returns Max           -13.655
exploration/Returns Min           -66.4399
exploration/Actions Mean            0.0337197
exploration/Actions Std             0.235512
exploration/Actions Max             0.998841
exploration/Actions Min            -0.911849
exploration/Num Paths               5
exploration/Average Returns       -40.0502
evaluation/num steps total     187500
evaluation/num paths total       1875
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.187648
evaluation/Rewards Std              0.88669
evaluation/Rewards Max             -0.00678547
evaluation/Rewards Min             -9.36951
evaluation/Returns Mean           -18.7648
evaluation/Returns Std             13.7506
evaluation/Returns Max             -3.27988
evaluation/Returns Min            -50.5706
evaluation/Actions Mean             0.0218257
evaluation/Actions Std              0.179369
evaluation/Actions Max              0.996271
evaluation/Actions Min             -0.99704
evaluation/Num Paths               25
evaluation/Average Returns        -18.7648
time/data storing (s)               0.00320656
time/evaluation sampling (s)        0.583936
time/exploration sampling (s)       0.163672
time/logging (s)                    0.00697265
time/saving (s)                     0.00205295
time/training (s)                   2.09728
time/epoch (s)                      2.85712
time/total (s)                    207.722
Epoch                              74
-----------------------------  ---------------
2019-04-22 21:12:17.474294 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 75 finished
-----------------------------  ---------------
replay_buffer/size              38200
trainer/QF1 Loss                    1.06661
trainer/QF2 Loss                    1.0799
trainer/Policy Loss                11.2808
trainer/Q1 Predictions Mean        -9.79949
trainer/Q1 Predictions Std          7.72984
trainer/Q1 Predictions Max         -7.94598
trainer/Q1 Predictions Min        -74.1882
trainer/Q2 Predictions Mean        -9.77648
trainer/Q2 Predictions Std          7.74116
trainer/Q2 Predictions Max         -7.92639
trainer/Q2 Predictions Min        -74.2338
trainer/Q Targets Mean             -9.90673
trainer/Q Targets Std               8.34104
trainer/Q Targets Max              -0.421728
trainer/Q Targets Min             -78.6013
trainer/Log Pis Mean                1.88944
trainer/Log Pis Std                 1.11031
trainer/Log Pis Max                 7.57443
trainer/Log Pis Min                -1.37484
trainer/Policy mu Mean              0.00824448
trainer/Policy mu Std               0.641129
trainer/Policy mu Max               3.29353
trainer/Policy mu Min              -2.43431
trainer/Policy log std Mean        -2.05618
trainer/Policy log std Std          0.39406
trainer/Policy log std Max         -0.36829
trainer/Policy log std Min         -2.45144
trainer/Alpha                       0.0557173
trainer/Alpha Loss                 -0.319221
exploration/num steps total     38200
exploration/num paths total       382
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.400828
exploration/Rewards Std             1.17435
exploration/Rewards Max            -0.00732891
exploration/Rewards Min           -10.7593
exploration/Returns Mean          -40.0828
exploration/Returns Std            17.6112
exploration/Returns Max           -23.9467
exploration/Returns Min           -67.8948
exploration/Actions Mean            0.0368917
exploration/Actions Std             0.257127
exploration/Actions Max             0.999071
exploration/Actions Min            -0.994664
exploration/Num Paths               5
exploration/Average Returns       -40.0828
evaluation/num steps total     190000
evaluation/num paths total       1900
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.22874
evaluation/Rewards Std              0.955789
evaluation/Rewards Max             -0.0364391
evaluation/Rewards Min            -10.4226
evaluation/Returns Mean           -22.874
evaluation/Returns Std             16.5753
evaluation/Returns Max             -5.04152
evaluation/Returns Min            -62.8424
evaluation/Actions Mean             0.020168
evaluation/Actions Std              0.181469
evaluation/Actions Max              0.996616
evaluation/Actions Min             -0.995753
evaluation/Num Paths               25
evaluation/Average Returns        -22.874
time/data storing (s)               0.00307209
time/evaluation sampling (s)        0.585307
time/exploration sampling (s)       0.157523
time/logging (s)                    0.00692813
time/saving (s)                     0.00204474
time/training (s)                   2.17203
time/epoch (s)                      2.92691
time/total (s)                    210.654
Epoch                              75
-----------------------------  ---------------
2019-04-22 21:12:20.388335 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 76 finished
-----------------------------  ---------------
replay_buffer/size              38700
trainer/QF1 Loss                    1.28459
trainer/QF2 Loss                    1.30169
trainer/Policy Loss                10.9014
trainer/Q1 Predictions Mean        -9.27383
trainer/Q1 Predictions Std          6.13891
trainer/Q1 Predictions Max         -7.80632
trainer/Q1 Predictions Min        -61.0746
trainer/Q2 Predictions Mean        -9.30015
trainer/Q2 Predictions Std          6.13615
trainer/Q2 Predictions Max         -7.83235
trainer/Q2 Predictions Min        -61.0428
trainer/Q Targets Mean             -9.23951
trainer/Q Targets Std               6.39162
trainer/Q Targets Max              -0.145915
trainer/Q Targets Min             -62.8039
trainer/Log Pis Mean                1.82739
trainer/Log Pis Std                 1.14668
trainer/Log Pis Max                 5.32689
trainer/Log Pis Min                -2.34926
trainer/Policy mu Mean              0.0343595
trainer/Policy mu Std               0.569648
trainer/Policy mu Max               3.20154
trainer/Policy mu Min              -2.45811
trainer/Policy log std Mean        -2.10284
trainer/Policy log std Std          0.387057
trainer/Policy log std Max         -0.59118
trainer/Policy log std Min         -2.50356
trainer/Alpha                       0.0549297
trainer/Alpha Loss                 -0.50085
exploration/num steps total     38700
exploration/num paths total       387
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.243899
exploration/Rewards Std             0.642883
exploration/Rewards Max            -0.00421746
exploration/Rewards Min            -6.84877
exploration/Returns Mean          -24.3899
exploration/Returns Std            10.8652
exploration/Returns Max           -12.9344
exploration/Returns Min           -41.0588
exploration/Actions Mean            0.00342759
exploration/Actions Std             0.215958
exploration/Actions Max             0.99928
exploration/Actions Min            -0.994085
exploration/Num Paths               5
exploration/Average Returns       -24.3899
evaluation/num steps total     192500
evaluation/num paths total       1925
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.216871
evaluation/Rewards Std              0.989614
evaluation/Rewards Max             -0.0115646
evaluation/Rewards Min            -11.3484
evaluation/Returns Mean           -21.6871
evaluation/Returns Std             17.8553
evaluation/Returns Max             -3.64201
evaluation/Returns Min            -63.6484
evaluation/Actions Mean             0.0230511
evaluation/Actions Std              0.184484
evaluation/Actions Max              0.997353
evaluation/Actions Min             -0.997014
evaluation/Num Paths               25
evaluation/Average Returns        -21.6871
time/data storing (s)               0.0030198
time/evaluation sampling (s)        0.582128
time/exploration sampling (s)       0.163789
time/logging (s)                    0.00684889
time/saving (s)                     0.00195472
time/training (s)                   2.14964
time/epoch (s)                      2.90738
time/total (s)                    213.567
Epoch                              76
-----------------------------  ---------------
2019-04-22 21:12:23.330160 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 77 finished
-----------------------------  ---------------
replay_buffer/size              39200
trainer/QF1 Loss                    0.632181
trainer/QF2 Loss                    0.638214
trainer/Policy Loss                11.491
trainer/Q1 Predictions Mean        -9.65385
trainer/Q1 Predictions Std          6.45213
trainer/Q1 Predictions Max         -7.64547
trainer/Q1 Predictions Min        -41.0993
trainer/Q2 Predictions Mean        -9.66685
trainer/Q2 Predictions Std          6.4508
trainer/Q2 Predictions Max         -7.67165
trainer/Q2 Predictions Min        -41.0632
trainer/Q Targets Mean             -9.74034
trainer/Q Targets Std               6.42672
trainer/Q Targets Max              -0.136135
trainer/Q Targets Min             -40.6421
trainer/Log Pis Mean                2.10716
trainer/Log Pis Std                 1.22099
trainer/Log Pis Max                 6.77252
trainer/Log Pis Min                -0.85816
trainer/Policy mu Mean              0.0442523
trainer/Policy mu Std               0.659922
trainer/Policy mu Max               2.98513
trainer/Policy mu Min              -2.88372
trainer/Policy log std Mean        -2.16512
trainer/Policy log std Std          0.432747
trainer/Policy log std Max         -0.565762
trainer/Policy log std Min         -2.54341
trainer/Alpha                       0.0515323
trainer/Alpha Loss                  0.317788
exploration/num steps total     39200
exploration/num paths total       392
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.338955
exploration/Rewards Std             1.02781
exploration/Rewards Max            -0.0127022
exploration/Rewards Min           -10.2379
exploration/Returns Mean          -33.8955
exploration/Returns Std            17.277
exploration/Returns Max           -19.7555
exploration/Returns Min           -67.5416
exploration/Actions Mean            0.013976
exploration/Actions Std             0.2327
exploration/Actions Max             0.997521
exploration/Actions Min            -0.997601
exploration/Num Paths               5
exploration/Average Returns       -33.8955
evaluation/num steps total     195000
evaluation/num paths total       1950
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.253472
evaluation/Rewards Std              1.10566
evaluation/Rewards Max             -0.017159
evaluation/Rewards Min            -10.122
evaluation/Returns Mean           -25.3472
evaluation/Returns Std             18.53
evaluation/Returns Max             -2.69826
evaluation/Returns Min            -58.1077
evaluation/Actions Mean             0.0305723
evaluation/Actions Std              0.190505
evaluation/Actions Max              0.995414
evaluation/Actions Min             -0.990613
evaluation/Num Paths               25
evaluation/Average Returns        -25.3472
time/data storing (s)               0.00329162
time/evaluation sampling (s)        0.613206
time/exploration sampling (s)       0.161296
time/logging (s)                    0.00722683
time/saving (s)                     0.0020499
time/training (s)                   2.14774
time/epoch (s)                      2.93482
time/total (s)                    216.506
Epoch                              77
-----------------------------  ---------------
2019-04-22 21:12:26.351476 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 78 finished
-----------------------------  ---------------
replay_buffer/size              39700
trainer/QF1 Loss                    0.051286
trainer/QF2 Loss                    0.0711084
trainer/Policy Loss                10.5893
trainer/Q1 Predictions Mean        -8.78286
trainer/Q1 Predictions Std          4.82762
trainer/Q1 Predictions Max         -7.71448
trainer/Q1 Predictions Min        -53.5167
trainer/Q2 Predictions Mean        -8.7826
trainer/Q2 Predictions Std          4.82637
trainer/Q2 Predictions Max         -7.70609
trainer/Q2 Predictions Min        -53.6043
trainer/Q Targets Mean             -8.8639
trainer/Q Targets Std               4.7711
trainer/Q Targets Max              -7.7331
trainer/Q Targets Min             -52.7388
trainer/Log Pis Mean                1.94147
trainer/Log Pis Std                 1.02295
trainer/Log Pis Max                 5.96974
trainer/Log Pis Min                -1.59759
trainer/Policy mu Mean              0.0329443
trainer/Policy mu Std               0.599031
trainer/Policy mu Max               3.22084
trainer/Policy mu Min              -2.32621
trainer/Policy log std Mean        -2.13514
trainer/Policy log std Std          0.43519
trainer/Policy log std Max         -0.544712
trainer/Policy log std Min         -2.57554
trainer/Alpha                       0.0527535
trainer/Alpha Loss                 -0.172201
exploration/num steps total     39700
exploration/num paths total       397
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.387137
exploration/Rewards Std             1.18231
exploration/Rewards Max            -0.00883291
exploration/Rewards Min           -10.8169
exploration/Returns Mean          -38.7137
exploration/Returns Std            16.5995
exploration/Returns Max           -23.4945
exploration/Returns Min           -67.5863
exploration/Actions Mean            0.0281108
exploration/Actions Std             0.250767
exploration/Actions Max             0.998988
exploration/Actions Min            -0.997059
exploration/Num Paths               5
exploration/Average Returns       -38.7137
evaluation/num steps total     197500
evaluation/num paths total       1975
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.205082
evaluation/Rewards Std              1.00835
evaluation/Rewards Max             -0.0018438
evaluation/Rewards Min            -10.2567
evaluation/Returns Mean           -20.5082
evaluation/Returns Std             16.4361
evaluation/Returns Max             -0.605075
evaluation/Returns Min            -54.5928
evaluation/Actions Mean             0.0213076
evaluation/Actions Std              0.186641
evaluation/Actions Max              0.997331
evaluation/Actions Min             -0.995259
evaluation/Num Paths               25
evaluation/Average Returns        -20.5082
time/data storing (s)               0.00330744
time/evaluation sampling (s)        0.634226
time/exploration sampling (s)       0.17315
time/logging (s)                    0.00651235
time/saving (s)                     0.00211978
time/training (s)                   2.19492
time/epoch (s)                      3.01423
time/total (s)                    219.525
Epoch                              78
-----------------------------  ---------------
2019-04-22 21:12:29.575380 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 79 finished
-----------------------------  ---------------
replay_buffer/size              40200
trainer/QF1 Loss                    0.12787
trainer/QF2 Loss                    0.138862
trainer/Policy Loss                11.0911
trainer/Q1 Predictions Mean        -9.37417
trainer/Q1 Predictions Std          5.56669
trainer/Q1 Predictions Max         -7.73259
trainer/Q1 Predictions Min        -49.9702
trainer/Q2 Predictions Mean        -9.39494
trainer/Q2 Predictions Std          5.58287
trainer/Q2 Predictions Max         -7.73381
trainer/Q2 Predictions Min        -49.9576
trainer/Q Targets Mean             -9.41029
trainer/Q Targets Std               5.63814
trainer/Q Targets Max              -7.70038
trainer/Q Targets Min             -49.9692
trainer/Log Pis Mean                2.04715
trainer/Log Pis Std                 1.4326
trainer/Log Pis Max                 6.65981
trainer/Log Pis Min                -6.58439
trainer/Policy mu Mean              0.0995415
trainer/Policy mu Std               0.683202
trainer/Policy mu Max               3.20265
trainer/Policy mu Min              -2.82414
trainer/Policy log std Mean        -2.11008
trainer/Policy log std Std          0.432327
trainer/Policy log std Max         -0.790489
trainer/Policy log std Min         -2.57353
trainer/Alpha                       0.0526083
trainer/Alpha Loss                  0.138853
exploration/num steps total     40200
exploration/num paths total       402
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.351798
exploration/Rewards Std             1.10232
exploration/Rewards Max            -0.00917006
exploration/Rewards Min           -10.2083
exploration/Returns Mean          -35.1798
exploration/Returns Std            17.8929
exploration/Returns Max           -17.1996
exploration/Returns Min           -66.0059
exploration/Actions Mean            0.0274284
exploration/Actions Std             0.243963
exploration/Actions Max             0.997619
exploration/Actions Min            -0.991764
exploration/Num Paths               5
exploration/Average Returns       -35.1798
evaluation/num steps total     200000
evaluation/num paths total       2000
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234443
evaluation/Rewards Std              0.956672
evaluation/Rewards Max             -0.029834
evaluation/Rewards Min             -9.24992
evaluation/Returns Mean           -23.4443
evaluation/Returns Std             12.7968
evaluation/Returns Max             -5.93286
evaluation/Returns Min            -51.2606
evaluation/Actions Mean             0.0221697
evaluation/Actions Std              0.187908
evaluation/Actions Max              0.996611
evaluation/Actions Min             -0.996422
evaluation/Num Paths               25
evaluation/Average Returns        -23.4443
time/data storing (s)               0.00318719
time/evaluation sampling (s)        0.650123
time/exploration sampling (s)       0.165671
time/logging (s)                    0.00794439
time/saving (s)                     0.00269631
time/training (s)                   2.38932
time/epoch (s)                      3.21894
time/total (s)                    222.749
Epoch                              79
-----------------------------  ---------------
2019-04-22 21:12:32.750999 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 80 finished
-----------------------------  ---------------
replay_buffer/size              40700
trainer/QF1 Loss                    0.644535
trainer/QF2 Loss                    0.64725
trainer/Policy Loss                11.5472
trainer/Q1 Predictions Mean        -9.76485
trainer/Q1 Predictions Std          6.9687
trainer/Q1 Predictions Max         -7.7145
trainer/Q1 Predictions Min        -62.4951
trainer/Q2 Predictions Mean        -9.76505
trainer/Q2 Predictions Std          6.99562
trainer/Q2 Predictions Max         -7.71833
trainer/Q2 Predictions Min        -62.6824
trainer/Q Targets Mean             -9.73582
trainer/Q Targets Std               7.11829
trainer/Q Targets Max              -0.167681
trainer/Q Targets Min             -62.9106
trainer/Log Pis Mean                2.21422
trainer/Log Pis Std                 1.25824
trainer/Log Pis Max                 8.66705
trainer/Log Pis Min                -0.840463
trainer/Policy mu Mean              0.170427
trainer/Policy mu Std               0.668959
trainer/Policy mu Max               3.0328
trainer/Policy mu Min              -2.03014
trainer/Policy log std Mean        -2.11695
trainer/Policy log std Std          0.434911
trainer/Policy log std Max         -0.449046
trainer/Policy log std Min         -2.49021
trainer/Alpha                       0.0530465
trainer/Alpha Loss                  0.629057
exploration/num steps total     40700
exploration/num paths total       407
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.529121
exploration/Rewards Std             1.51197
exploration/Rewards Max            -0.0191821
exploration/Rewards Min           -10.1105
exploration/Returns Mean          -52.9121
exploration/Returns Std            11.8644
exploration/Returns Max           -32.608
exploration/Returns Min           -67.7499
exploration/Actions Mean            0.0602232
exploration/Actions Std             0.263522
exploration/Actions Max             0.998077
exploration/Actions Min            -0.788869
exploration/Num Paths               5
exploration/Average Returns       -52.9121
evaluation/num steps total     202500
evaluation/num paths total       2025
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.281977
evaluation/Rewards Std              1.0368
evaluation/Rewards Max             -0.00801292
evaluation/Rewards Min            -10.4426
evaluation/Returns Mean           -28.1977
evaluation/Returns Std             16.0336
evaluation/Returns Max             -6.78372
evaluation/Returns Min            -64.6908
evaluation/Actions Mean             0.0208163
evaluation/Actions Std              0.186936
evaluation/Actions Max              0.996974
evaluation/Actions Min             -0.99643
evaluation/Num Paths               25
evaluation/Average Returns        -28.1977
time/data storing (s)               0.00443856
time/evaluation sampling (s)        0.68032
time/exploration sampling (s)       0.189751
time/logging (s)                    0.00724481
time/saving (s)                     0.00209164
time/training (s)                   2.28259
time/epoch (s)                      3.16644
time/total (s)                    225.921
Epoch                              80
-----------------------------  ---------------
2019-04-22 21:12:35.521649 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 81 finished
-----------------------------  ---------------
replay_buffer/size              41200
trainer/QF1 Loss                    0.0438608
trainer/QF2 Loss                    0.0447221
trainer/Policy Loss                10.1568
trainer/Q1 Predictions Mean        -8.68306
trainer/Q1 Predictions Std          3.12192
trainer/Q1 Predictions Max         -7.70576
trainer/Q1 Predictions Min        -32.4369
trainer/Q2 Predictions Mean        -8.64684
trainer/Q2 Predictions Std          3.13269
trainer/Q2 Predictions Max         -7.65596
trainer/Q2 Predictions Min        -32.4288
trainer/Q Targets Mean             -8.6396
trainer/Q Targets Std               3.06216
trainer/Q Targets Max              -7.55907
trainer/Q Targets Min             -32.26
trainer/Log Pis Mean                1.67463
trainer/Log Pis Std                 1.28783
trainer/Log Pis Max                 5.72839
trainer/Log Pis Min                -2.59816
trainer/Policy mu Mean              0.0459565
trainer/Policy mu Std               0.562492
trainer/Policy mu Max               2.95044
trainer/Policy mu Min              -2.23758
trainer/Policy log std Mean        -2.1397
trainer/Policy log std Std          0.38372
trainer/Policy log std Max         -0.654556
trainer/Policy log std Min         -2.46575
trainer/Alpha                       0.0515701
trainer/Alpha Loss                 -0.964611
exploration/num steps total     41200
exploration/num paths total       412
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.337565
exploration/Rewards Std             0.941656
exploration/Rewards Max            -0.00153104
exploration/Rewards Min            -8.384
exploration/Returns Mean          -33.7565
exploration/Returns Std            10.3247
exploration/Returns Max           -26.9768
exploration/Returns Min           -54.185
exploration/Actions Mean            0.0214916
exploration/Actions Std             0.236535
exploration/Actions Max             0.999127
exploration/Actions Min            -0.998013
exploration/Num Paths               5
exploration/Average Returns       -33.7565
evaluation/num steps total     205000
evaluation/num paths total       2050
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.248443
evaluation/Rewards Std              1.01994
evaluation/Rewards Max             -0.0227478
evaluation/Rewards Min            -10.4236
evaluation/Returns Mean           -24.8443
evaluation/Returns Std             14.8162
evaluation/Returns Max             -3.73377
evaluation/Returns Min            -54.3576
evaluation/Actions Mean             0.0281373
evaluation/Actions Std              0.189167
evaluation/Actions Max              0.997505
evaluation/Actions Min             -0.997076
evaluation/Num Paths               25
evaluation/Average Returns        -24.8443
time/data storing (s)               0.00322632
time/evaluation sampling (s)        0.594319
time/exploration sampling (s)       0.170058
time/logging (s)                    0.00686442
time/saving (s)                     0.00196858
time/training (s)                   1.98693
time/epoch (s)                      2.76337
time/total (s)                    228.69
Epoch                              81
-----------------------------  ---------------
2019-04-22 21:12:38.450461 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 82 finished
-----------------------------  ---------------
replay_buffer/size              41700
trainer/QF1 Loss                    0.604914
trainer/QF2 Loss                    0.622476
trainer/Policy Loss                10.8294
trainer/Q1 Predictions Mean        -8.97115
trainer/Q1 Predictions Std          5.62058
trainer/Q1 Predictions Max         -7.53259
trainer/Q1 Predictions Min        -51.5221
trainer/Q2 Predictions Mean        -9.02356
trainer/Q2 Predictions Std          5.61855
trainer/Q2 Predictions Max         -7.57401
trainer/Q2 Predictions Min        -51.6166
trainer/Q Targets Mean             -8.96943
trainer/Q Targets Std               5.68284
trainer/Q Targets Max              -0.0899715
trainer/Q Targets Min             -51.7776
trainer/Log Pis Mean                1.97021
trainer/Log Pis Std                 1.02818
trainer/Log Pis Max                 5.27537
trainer/Log Pis Min                -1.69783
trainer/Policy mu Mean              0.0688576
trainer/Policy mu Std               0.579005
trainer/Policy mu Max               3.07815
trainer/Policy mu Min              -1.94999
trainer/Policy log std Mean        -2.15318
trainer/Policy log std Std          0.376092
trainer/Policy log std Max         -0.637583
trainer/Policy log std Min         -2.49093
trainer/Alpha                       0.0514285
trainer/Alpha Loss                 -0.0884102
exploration/num steps total     41700
exploration/num paths total       417
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.311678
exploration/Rewards Std             0.97907
exploration/Rewards Max            -0.00630046
exploration/Rewards Min            -9.59268
exploration/Returns Mean          -31.1678
exploration/Returns Std            17.5691
exploration/Returns Max           -14.805
exploration/Returns Min           -61.2018
exploration/Actions Mean            0.0306777
exploration/Actions Std             0.228601
exploration/Actions Max             0.998739
exploration/Actions Min            -0.981402
exploration/Num Paths               5
exploration/Average Returns       -31.1678
evaluation/num steps total     207500
evaluation/num paths total       2075
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.225011
evaluation/Rewards Std              0.960566
evaluation/Rewards Max             -0.0212807
evaluation/Rewards Min             -9.47679
evaluation/Returns Mean           -22.5011
evaluation/Returns Std             13.5692
evaluation/Returns Max             -3.1372
evaluation/Returns Min            -47.7835
evaluation/Actions Mean             0.0238907
evaluation/Actions Std              0.189614
evaluation/Actions Max              0.996306
evaluation/Actions Min             -0.997164
evaluation/Num Paths               25
evaluation/Average Returns        -22.5011
time/data storing (s)               0.00302174
time/evaluation sampling (s)        0.569951
time/exploration sampling (s)       0.165029
time/logging (s)                    0.00654698
time/saving (s)                     0.00190622
time/training (s)                   2.17531
time/epoch (s)                      2.92177
time/total (s)                    231.616
Epoch                              82
-----------------------------  ---------------
2019-04-22 21:12:41.734858 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 83 finished
-----------------------------  ---------------
replay_buffer/size              42200
trainer/QF1 Loss                    1.76466
trainer/QF2 Loss                    1.76732
trainer/Policy Loss                10.8692
trainer/Q1 Predictions Mean        -9.2577
trainer/Q1 Predictions Std          6.64474
trainer/Q1 Predictions Max         -7.60168
trainer/Q1 Predictions Min        -61.3179
trainer/Q2 Predictions Mean        -9.2294
trainer/Q2 Predictions Std          6.63953
trainer/Q2 Predictions Max         -7.56426
trainer/Q2 Predictions Min        -61.1916
trainer/Q Targets Mean             -9.01027
trainer/Q Targets Std               6.9146
trainer/Q Targets Max              -0.0832481
trainer/Q Targets Min             -62.0618
trainer/Log Pis Mean                1.8906
trainer/Log Pis Std                 1.25466
trainer/Log Pis Max                 5.28274
trainer/Log Pis Min                -2.53494
trainer/Policy mu Mean              0.104164
trainer/Policy mu Std               0.619377
trainer/Policy mu Max               3.15992
trainer/Policy mu Min              -2.59895
trainer/Policy log std Mean        -2.13103
trainer/Policy log std Std          0.434606
trainer/Policy log std Max         -0.306035
trainer/Policy log std Min         -2.52149
trainer/Alpha                       0.0527127
trainer/Alpha Loss                 -0.321946
exploration/num steps total     42200
exploration/num paths total       422
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.297222
exploration/Rewards Std             0.865617
exploration/Rewards Max            -0.010833
exploration/Rewards Min            -8.99512
exploration/Returns Mean          -29.7222
exploration/Returns Std            12.1148
exploration/Returns Max           -13.3635
exploration/Returns Min           -50.6187
exploration/Actions Mean            0.026712
exploration/Actions Std             0.222411
exploration/Actions Max             0.998792
exploration/Actions Min            -0.997169
exploration/Num Paths               5
exploration/Average Returns       -29.7222
evaluation/num steps total     210000
evaluation/num paths total       2100
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.213463
evaluation/Rewards Std              0.886101
evaluation/Rewards Max             -0.00386558
evaluation/Rewards Min            -10.1012
evaluation/Returns Mean           -21.3463
evaluation/Returns Std             14.5756
evaluation/Returns Max             -4.40175
evaluation/Returns Min            -55.9649
evaluation/Actions Mean             0.0111237
evaluation/Actions Std              0.177662
evaluation/Actions Max              0.997588
evaluation/Actions Min             -0.997431
evaluation/Num Paths               25
evaluation/Average Returns        -21.3463
time/data storing (s)               0.00317644
time/evaluation sampling (s)        0.675714
time/exploration sampling (s)       0.205797
time/logging (s)                    0.00904657
time/saving (s)                     0.0024518
time/training (s)                   2.38383
time/epoch (s)                      3.28001
time/total (s)                    234.902
Epoch                              83
-----------------------------  ---------------
2019-04-22 21:12:44.742630 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 84 finished
-----------------------------  ---------------
replay_buffer/size              42700
trainer/QF1 Loss                    1.16659
trainer/QF2 Loss                    1.18145
trainer/Policy Loss                10.6566
trainer/Q1 Predictions Mean        -8.99271
trainer/Q1 Predictions Std          5.61585
trainer/Q1 Predictions Max         -7.43136
trainer/Q1 Predictions Min        -52.2446
trainer/Q2 Predictions Mean        -8.96564
trainer/Q2 Predictions Std          5.60065
trainer/Q2 Predictions Max         -7.40433
trainer/Q2 Predictions Min        -51.9936
trainer/Q Targets Mean             -8.91671
trainer/Q Targets Std               5.78929
trainer/Q Targets Max              -0.133247
trainer/Q Targets Min             -52.0256
trainer/Log Pis Mean                1.92213
trainer/Log Pis Std                 1.30751
trainer/Log Pis Max                 6.39271
trainer/Log Pis Min                -2.6783
trainer/Policy mu Mean              0.0895333
trainer/Policy mu Std               0.661227
trainer/Policy mu Max               3.01754
trainer/Policy mu Min              -2.71129
trainer/Policy log std Mean        -2.1154
trainer/Policy log std Std          0.434698
trainer/Policy log std Max         -0.474913
trainer/Policy log std Min         -2.51245
trainer/Alpha                       0.0538443
trainer/Alpha Loss                 -0.22751
exploration/num steps total     42700
exploration/num paths total       427
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.336929
exploration/Rewards Std             0.92204
exploration/Rewards Max            -0.00315159
exploration/Rewards Min            -7.36967
exploration/Returns Mean          -33.6929
exploration/Returns Std             5.49551
exploration/Returns Max           -27.6382
exploration/Returns Min           -44.0091
exploration/Actions Mean            0.0295409
exploration/Actions Std             0.244712
exploration/Actions Max             0.998811
exploration/Actions Min            -0.995423
exploration/Num Paths               5
exploration/Average Returns       -33.6929
evaluation/num steps total     212500
evaluation/num paths total       2125
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.273698
evaluation/Rewards Std              1.0459
evaluation/Rewards Max             -0.00361321
evaluation/Rewards Min            -10.1742
evaluation/Returns Mean           -27.3698
evaluation/Returns Std             15.5262
evaluation/Returns Max             -5.47179
evaluation/Returns Min            -62.457
evaluation/Actions Mean             0.0291748
evaluation/Actions Std              0.194515
evaluation/Actions Max              0.996629
evaluation/Actions Min             -0.995898
evaluation/Num Paths               25
evaluation/Average Returns        -27.3698
time/data storing (s)               0.00470431
time/evaluation sampling (s)        0.631912
time/exploration sampling (s)       0.176409
time/logging (s)                    0.00884179
time/saving (s)                     0.00277866
time/training (s)                   2.17354
time/epoch (s)                      2.99818
time/total (s)                    237.906
Epoch                              84
-----------------------------  ---------------
2019-04-22 21:12:47.733936 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 85 finished
-----------------------------  ---------------
replay_buffer/size              43200
trainer/QF1 Loss                    0.725157
trainer/QF2 Loss                    0.778763
trainer/Policy Loss                11.2112
trainer/Q1 Predictions Mean        -9.34833
trainer/Q1 Predictions Std          6.91532
trainer/Q1 Predictions Max         -7.31893
trainer/Q1 Predictions Min        -52.7747
trainer/Q2 Predictions Mean        -9.37873
trainer/Q2 Predictions Std          6.91036
trainer/Q2 Predictions Max         -7.3445
trainer/Q2 Predictions Min        -52.7025
trainer/Q Targets Mean             -9.40097
trainer/Q Targets Std               7.00045
trainer/Q Targets Max              -0.321743
trainer/Q Targets Min             -52.2172
trainer/Log Pis Mean                2.13716
trainer/Log Pis Std                 1.08407
trainer/Log Pis Max                 6.05725
trainer/Log Pis Min                -0.472542
trainer/Policy mu Mean              0.0776245
trainer/Policy mu Std               0.699897
trainer/Policy mu Max               2.98492
trainer/Policy mu Min              -2.59178
trainer/Policy log std Mean        -2.13711
trainer/Policy log std Std          0.456322
trainer/Policy log std Max         -0.391184
trainer/Policy log std Min         -2.51282
trainer/Alpha                       0.0532153
trainer/Alpha Loss                  0.402357
exploration/num steps total     43200
exploration/num paths total       432
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.380658
exploration/Rewards Std             1.13925
exploration/Rewards Max            -0.00329657
exploration/Rewards Min            -9.95499
exploration/Returns Mean          -38.0658
exploration/Returns Std            13.7729
exploration/Returns Max           -25.8415
exploration/Returns Min           -63.3379
exploration/Actions Mean            0.0503888
exploration/Actions Std             0.245543
exploration/Actions Max             0.999345
exploration/Actions Min            -0.887307
exploration/Num Paths               5
exploration/Average Returns       -38.0658
evaluation/num steps total     215000
evaluation/num paths total       2150
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.189258
evaluation/Rewards Std              0.850444
evaluation/Rewards Max             -0.00177494
evaluation/Rewards Min             -8.50232
evaluation/Returns Mean           -18.9258
evaluation/Returns Std             10.8439
evaluation/Returns Max             -2.13933
evaluation/Returns Min            -40.2833
evaluation/Actions Mean             0.0226013
evaluation/Actions Std              0.186162
evaluation/Actions Max              0.995526
evaluation/Actions Min             -0.995477
evaluation/Num Paths               25
evaluation/Average Returns        -18.9258
time/data storing (s)               0.00385583
time/evaluation sampling (s)        0.645495
time/exploration sampling (s)       0.162239
time/logging (s)                    0.00678432
time/saving (s)                     0.00199763
time/training (s)                   2.16151
time/epoch (s)                      2.98188
time/total (s)                    240.893
Epoch                              85
-----------------------------  ---------------
2019-04-22 21:12:50.630004 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 86 finished
-----------------------------  ---------------
replay_buffer/size              43700
trainer/QF1 Loss                    0.557534
trainer/QF2 Loss                    0.558401
trainer/Policy Loss                 9.69664
trainer/Q1 Predictions Mean        -8.15875
trainer/Q1 Predictions Std          4.10933
trainer/Q1 Predictions Max         -7.24065
trainer/Q1 Predictions Min        -45.577
trainer/Q2 Predictions Mean        -8.15993
trainer/Q2 Predictions Std          4.11813
trainer/Q2 Predictions Max         -7.22795
trainer/Q2 Predictions Min        -45.7017
trainer/Q Targets Mean             -8.23673
trainer/Q Targets Std               4.21173
trainer/Q Targets Max              -0.107401
trainer/Q Targets Min             -46.0635
trainer/Log Pis Mean                1.71707
trainer/Log Pis Std                 1.31471
trainer/Log Pis Max                 7.09732
trainer/Log Pis Min                -2.20504
trainer/Policy mu Mean              0.0376488
trainer/Policy mu Std               0.570404
trainer/Policy mu Max               2.91918
trainer/Policy mu Min              -1.67492
trainer/Policy log std Mean        -2.07589
trainer/Policy log std Std          0.401181
trainer/Policy log std Max         -0.481732
trainer/Policy log std Min         -2.47975
trainer/Alpha                       0.0540074
trainer/Alpha Loss                 -0.825725
exploration/num steps total     43700
exploration/num paths total       437
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.375368
exploration/Rewards Std             1.11727
exploration/Rewards Max            -0.0057152
exploration/Rewards Min           -10.9698
exploration/Returns Mean          -37.5368
exploration/Returns Std            15.1137
exploration/Returns Max           -26.1787
exploration/Returns Min           -67.4353
exploration/Actions Mean            0.0255814
exploration/Actions Std             0.245041
exploration/Actions Max             0.99909
exploration/Actions Min            -0.998801
exploration/Num Paths               5
exploration/Average Returns       -37.5368
evaluation/num steps total     217500
evaluation/num paths total       2175
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.221337
evaluation/Rewards Std              0.998674
evaluation/Rewards Max             -0.00521904
evaluation/Rewards Min            -11.0376
evaluation/Returns Mean           -22.1337
evaluation/Returns Std             12.5016
evaluation/Returns Max             -1.9551
evaluation/Returns Min            -61.0643
evaluation/Actions Mean             0.0263283
evaluation/Actions Std              0.19664
evaluation/Actions Max              0.99683
evaluation/Actions Min             -0.995928
evaluation/Num Paths               25
evaluation/Average Returns        -22.1337
time/data storing (s)               0.00316831
time/evaluation sampling (s)        0.575041
time/exploration sampling (s)       0.163201
time/logging (s)                    0.00604646
time/saving (s)                     0.00166978
time/training (s)                   2.13874
time/epoch (s)                      2.88787
time/total (s)                    243.787
Epoch                              86
-----------------------------  ---------------
2019-04-22 21:12:53.493315 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 87 finished
-----------------------------  ---------------
replay_buffer/size              44200
trainer/QF1 Loss                    0.900816
trainer/QF2 Loss                    0.95496
trainer/Policy Loss                11.1113
trainer/Q1 Predictions Mean        -9.33481
trainer/Q1 Predictions Std          9.06272
trainer/Q1 Predictions Max         -7.34088
trainer/Q1 Predictions Min        -81.5647
trainer/Q2 Predictions Mean        -9.30711
trainer/Q2 Predictions Std          9.07654
trainer/Q2 Predictions Max         -7.31255
trainer/Q2 Predictions Min        -81.7588
trainer/Q Targets Mean             -9.24429
trainer/Q Targets Std               8.78702
trainer/Q Targets Max              -0.0467435
trainer/Q Targets Min             -77.439
trainer/Log Pis Mean                2.15791
trainer/Log Pis Std                 1.36697
trainer/Log Pis Max                 7.99843
trainer/Log Pis Min                -1.93636
trainer/Policy mu Mean             -0.00687315
trainer/Policy mu Std               0.608981
trainer/Policy mu Max               3.09726
trainer/Policy mu Min              -2.79669
trainer/Policy log std Mean        -2.2206
trainer/Policy log std Std          0.446371
trainer/Policy log std Max         -0.462453
trainer/Policy log std Min         -2.56641
trainer/Alpha                       0.0540865
trainer/Alpha Loss                  0.460661
exploration/num steps total     44200
exploration/num paths total       442
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.315961
exploration/Rewards Std             1.00033
exploration/Rewards Max            -0.00425144
exploration/Rewards Min            -9.62494
exploration/Returns Mean          -31.5961
exploration/Returns Std            14.9032
exploration/Returns Max           -13.8779
exploration/Returns Min           -55.0419
exploration/Actions Mean            0.0368822
exploration/Actions Std             0.232663
exploration/Actions Max             0.998802
exploration/Actions Min            -0.94713
exploration/Num Paths               5
exploration/Average Returns       -31.5961
evaluation/num steps total     220000
evaluation/num paths total       2200
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.250515
evaluation/Rewards Std              1.03141
evaluation/Rewards Max             -0.0283264
evaluation/Rewards Min            -10.2142
evaluation/Returns Mean           -25.0515
evaluation/Returns Std             16.3477
evaluation/Returns Max             -3.95836
evaluation/Returns Min            -59.1941
evaluation/Actions Mean             0.0272403
evaluation/Actions Std              0.18289
evaluation/Actions Max              0.995913
evaluation/Actions Min             -0.993284
evaluation/Num Paths               25
evaluation/Average Returns        -25.0515
time/data storing (s)               0.00313489
time/evaluation sampling (s)        0.574636
time/exploration sampling (s)       0.1656
time/logging (s)                    0.00685328
time/saving (s)                     0.00196467
time/training (s)                   2.10493
time/epoch (s)                      2.85712
time/total (s)                    246.649
Epoch                              87
-----------------------------  ---------------
2019-04-22 21:12:56.372016 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 88 finished
-----------------------------  ---------------
replay_buffer/size              44700
trainer/QF1 Loss                    0.628156
trainer/QF2 Loss                    0.634041
trainer/Policy Loss                10.2306
trainer/Q1 Predictions Mean        -8.4429
trainer/Q1 Predictions Std          3.77385
trainer/Q1 Predictions Max         -7.123
trainer/Q1 Predictions Min        -35.7514
trainer/Q2 Predictions Mean        -8.46668
trainer/Q2 Predictions Std          3.75668
trainer/Q2 Predictions Max         -7.14184
trainer/Q2 Predictions Min        -35.7118
trainer/Q Targets Mean             -8.56846
trainer/Q Targets Std               3.863
trainer/Q Targets Max              -0.392799
trainer/Q Targets Min             -35.9558
trainer/Log Pis Mean                1.99516
trainer/Log Pis Std                 0.916196
trainer/Log Pis Max                 4.74813
trainer/Log Pis Min                -0.657194
trainer/Policy mu Mean              0.0426364
trainer/Policy mu Std               0.647405
trainer/Policy mu Max               2.93287
trainer/Policy mu Min              -2.58899
trainer/Policy log std Mean        -2.11885
trainer/Policy log std Std          0.449925
trainer/Policy log std Max         -0.540244
trainer/Policy log std Min         -2.52184
trainer/Alpha                       0.0547883
trainer/Alpha Loss                 -0.0140706
exploration/num steps total     44700
exploration/num paths total       447
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.259518
exploration/Rewards Std             0.703391
exploration/Rewards Max            -0.00809588
exploration/Rewards Min            -5.99075
exploration/Returns Mean          -25.9518
exploration/Returns Std             4.13964
exploration/Returns Max           -18.4069
exploration/Returns Min           -30.0792
exploration/Actions Mean            0.0319923
exploration/Actions Std             0.223412
exploration/Actions Max             0.999234
exploration/Actions Min            -0.995494
exploration/Num Paths               5
exploration/Average Returns       -25.9518
evaluation/num steps total     222500
evaluation/num paths total       2225
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.207043
evaluation/Rewards Std              0.931724
evaluation/Rewards Max             -0.00650617
evaluation/Rewards Min             -9.86787
evaluation/Returns Mean           -20.7043
evaluation/Returns Std             14.9838
evaluation/Returns Max             -2.41014
evaluation/Returns Min            -56.8549
evaluation/Actions Mean             0.0230709
evaluation/Actions Std              0.17688
evaluation/Actions Max              0.995968
evaluation/Actions Min             -0.997377
evaluation/Num Paths               25
evaluation/Average Returns        -20.7043
time/data storing (s)               0.00297453
time/evaluation sampling (s)        0.594893
time/exploration sampling (s)       0.161458
time/logging (s)                    0.00594401
time/saving (s)                     0.00197149
time/training (s)                   2.10354
time/epoch (s)                      2.87078
time/total (s)                    249.524
Epoch                              88
-----------------------------  ---------------
2019-04-22 21:12:59.184628 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 89 finished
-----------------------------  ----------------
replay_buffer/size              45200
trainer/QF1 Loss                    0.596809
trainer/QF2 Loss                    0.613267
trainer/Policy Loss                 9.83297
trainer/Q1 Predictions Mean        -8.0337
trainer/Q1 Predictions Std          3.66066
trainer/Q1 Predictions Max         -7.21037
trainer/Q1 Predictions Min        -41.5936
trainer/Q2 Predictions Mean        -8.03762
trainer/Q2 Predictions Std          3.64653
trainer/Q2 Predictions Max         -7.20019
trainer/Q2 Predictions Min        -41.5898
trainer/Q Targets Mean             -8.05916
trainer/Q Targets Std               3.77836
trainer/Q Targets Max              -0.579894
trainer/Q Targets Min             -41.5467
trainer/Log Pis Mean                1.93225
trainer/Log Pis Std                 1.05035
trainer/Log Pis Max                 5.8803
trainer/Log Pis Min                -1.47524
trainer/Policy mu Mean              0.000365707
trainer/Policy mu Std               0.514697
trainer/Policy mu Max               2.988
trainer/Policy mu Min              -2.56075
trainer/Policy log std Mean        -2.11414
trainer/Policy log std Std          0.362358
trainer/Policy log std Max         -0.61084
trainer/Policy log std Min         -2.46617
trainer/Alpha                       0.0535909
trainer/Alpha Loss                 -0.198264
exploration/num steps total     45200
exploration/num paths total       452
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.338868
exploration/Rewards Std             1.06652
exploration/Rewards Max            -0.00262062
exploration/Rewards Min           -10.8151
exploration/Returns Mean          -33.8868
exploration/Returns Std            20.437
exploration/Returns Max           -13.8189
exploration/Returns Min           -70.0717
exploration/Actions Mean            0.0285781
exploration/Actions Std             0.243598
exploration/Actions Max             0.99913
exploration/Actions Min            -0.99025
exploration/Num Paths               5
exploration/Average Returns       -33.8868
evaluation/num steps total     225000
evaluation/num paths total       2250
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.234977
evaluation/Rewards Std              0.997929
evaluation/Rewards Max             -0.00372195
evaluation/Rewards Min             -9.88289
evaluation/Returns Mean           -23.4977
evaluation/Returns Std             14.6123
evaluation/Returns Max             -3.01701
evaluation/Returns Min            -56.3594
evaluation/Actions Mean             0.0219252
evaluation/Actions Std              0.195188
evaluation/Actions Max              0.996439
evaluation/Actions Min             -0.9973
evaluation/Num Paths               25
evaluation/Average Returns        -23.4977
time/data storing (s)               0.00305106
time/evaluation sampling (s)        0.561084
time/exploration sampling (s)       0.156082
time/logging (s)                    0.00686642
time/saving (s)                     0.00191357
time/training (s)                   2.07835
time/epoch (s)                      2.80735
time/total (s)                    252.337
Epoch                              89
-----------------------------  ----------------
2019-04-22 21:13:02.058476 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 90 finished
-----------------------------  ---------------
replay_buffer/size              45700
trainer/QF1 Loss                    0.0562493
trainer/QF2 Loss                    0.0561588
trainer/Policy Loss                11.7432
trainer/Q1 Predictions Mean        -9.97588
trainer/Q1 Predictions Std          8.40669
trainer/Q1 Predictions Max         -7.2472
trainer/Q1 Predictions Min        -58.732
trainer/Q2 Predictions Mean        -9.94656
trainer/Q2 Predictions Std          8.41586
trainer/Q2 Predictions Max         -7.21566
trainer/Q2 Predictions Min        -58.8241
trainer/Q Targets Mean            -10.0127
trainer/Q Targets Std               8.48874
trainer/Q Targets Max              -7.17911
trainer/Q Targets Min             -59.1996
trainer/Log Pis Mean                2.16151
trainer/Log Pis Std                 1.45129
trainer/Log Pis Max                 8.69181
trainer/Log Pis Min                -1.09569
trainer/Policy mu Mean              0.120908
trainer/Policy mu Std               0.809071
trainer/Policy mu Max               3.20607
trainer/Policy mu Min              -2.83888
trainer/Policy log std Mean        -2.05696
trainer/Policy log std Std          0.538837
trainer/Policy log std Max         -0.306721
trainer/Policy log std Min         -2.50391
trainer/Alpha                       0.0526948
trainer/Alpha Loss                  0.475372
exploration/num steps total     45700
exploration/num paths total       457
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.296949
exploration/Rewards Std             0.879965
exploration/Rewards Max            -0.00499448
exploration/Rewards Min            -8.54288
exploration/Returns Mean          -29.6949
exploration/Returns Std            11.2852
exploration/Returns Max           -11.5087
exploration/Returns Min           -46.9055
exploration/Actions Mean            0.00897257
exploration/Actions Std             0.230629
exploration/Actions Max             0.996024
exploration/Actions Min            -0.998858
exploration/Num Paths               5
exploration/Average Returns       -29.6949
evaluation/num steps total     227500
evaluation/num paths total       2275
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.247839
evaluation/Rewards Std              1.12875
evaluation/Rewards Max             -0.00143623
evaluation/Rewards Min            -10.7118
evaluation/Returns Mean           -24.7839
evaluation/Returns Std             16.6177
evaluation/Returns Max             -0.562117
evaluation/Returns Min            -54.9611
evaluation/Actions Mean             0.0312291
evaluation/Actions Std              0.195184
evaluation/Actions Max              0.997105
evaluation/Actions Min             -0.994882
evaluation/Num Paths               25
evaluation/Average Returns        -24.7839
time/data storing (s)               0.00335892
time/evaluation sampling (s)        0.563896
time/exploration sampling (s)       0.194157
time/logging (s)                    0.00718059
time/saving (s)                     0.00188253
time/training (s)                   2.09661
time/epoch (s)                      2.86708
time/total (s)                    255.209
Epoch                              90
-----------------------------  ---------------
2019-04-22 21:13:04.892166 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 91 finished
-----------------------------  ---------------
replay_buffer/size              46200
trainer/QF1 Loss                    0.625655
trainer/QF2 Loss                    0.644919
trainer/Policy Loss                10.7281
trainer/Q1 Predictions Mean        -9.32602
trainer/Q1 Predictions Std          7.42177
trainer/Q1 Predictions Max         -7.21874
trainer/Q1 Predictions Min        -54.2592
trainer/Q2 Predictions Mean        -9.31751
trainer/Q2 Predictions Std          7.40939
trainer/Q2 Predictions Max         -7.21069
trainer/Q2 Predictions Min        -53.9816
trainer/Q Targets Mean             -9.28926
trainer/Q Targets Std               7.70819
trainer/Q Targets Max              -0.200718
trainer/Q Targets Min             -56.7867
trainer/Log Pis Mean                1.71141
trainer/Log Pis Std                 1.20455
trainer/Log Pis Max                 5.7058
trainer/Log Pis Min                -1.67256
trainer/Policy mu Mean              0.142623
trainer/Policy mu Std               0.616659
trainer/Policy mu Max               2.90931
trainer/Policy mu Min              -1.20076
trainer/Policy log std Mean        -2.03767
trainer/Policy log std Std          0.407424
trainer/Policy log std Max         -0.545665
trainer/Policy log std Min         -2.4035
trainer/Alpha                       0.0532537
trainer/Alpha Loss                 -0.846251
exploration/num steps total     46200
exploration/num paths total       462
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.257887
exploration/Rewards Std             0.709278
exploration/Rewards Max            -0.00479264
exploration/Rewards Min            -7.86919
exploration/Returns Mean          -25.7887
exploration/Returns Std            11.7726
exploration/Returns Max           -13.5025
exploration/Returns Min           -48.0942
exploration/Actions Mean            0.0240105
exploration/Actions Std             0.214226
exploration/Actions Max             0.997041
exploration/Actions Min            -0.743501
exploration/Num Paths               5
exploration/Average Returns       -25.7887
evaluation/num steps total     230000
evaluation/num paths total       2300
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.258104
evaluation/Rewards Std              1.06578
evaluation/Rewards Max             -0.0321476
evaluation/Rewards Min            -10.0629
evaluation/Returns Mean           -25.8104
evaluation/Returns Std             16.4164
evaluation/Returns Max             -4.03385
evaluation/Returns Min            -59.8066
evaluation/Actions Mean             0.0209711
evaluation/Actions Std              0.190276
evaluation/Actions Max              0.995281
evaluation/Actions Min             -0.996789
evaluation/Num Paths               25
evaluation/Average Returns        -25.8104
time/data storing (s)               0.00310831
time/evaluation sampling (s)        0.570631
time/exploration sampling (s)       0.162365
time/logging (s)                    0.00690236
time/saving (s)                     0.00199013
time/training (s)                   2.08164
time/epoch (s)                      2.82663
time/total (s)                    258.04
Epoch                              91
-----------------------------  ---------------
2019-04-22 21:13:07.756563 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 92 finished
-----------------------------  ---------------
replay_buffer/size              46700
trainer/QF1 Loss                    0.740732
trainer/QF2 Loss                    0.734926
trainer/Policy Loss                11.23
trainer/Q1 Predictions Mean        -9.89705
trainer/Q1 Predictions Std         11.552
trainer/Q1 Predictions Max         -7.06442
trainer/Q1 Predictions Min        -74.0858
trainer/Q2 Predictions Mean        -9.87614
trainer/Q2 Predictions Std         11.5345
trainer/Q2 Predictions Max         -7.03598
trainer/Q2 Predictions Min        -73.9839
trainer/Q Targets Mean             -9.95377
trainer/Q Targets Std              11.6637
trainer/Q Targets Max              -0.133256
trainer/Q Targets Min             -76.1243
trainer/Log Pis Mean                1.80787
trainer/Log Pis Std                 1.57303
trainer/Log Pis Max                 9.05988
trainer/Log Pis Min                -2.77318
trainer/Policy mu Mean              0.0873734
trainer/Policy mu Std               0.666604
trainer/Policy mu Max               3.2881
trainer/Policy mu Min              -3.01465
trainer/Policy log std Mean        -2.14237
trainer/Policy log std Std          0.44143
trainer/Policy log std Max         -0.523333
trainer/Policy log std Min         -2.53211
trainer/Alpha                       0.0522439
trainer/Alpha Loss                 -0.567129
exploration/num steps total     46700
exploration/num paths total       467
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.435248
exploration/Rewards Std             1.30722
exploration/Rewards Max            -0.0137251
exploration/Rewards Min           -10.2222
exploration/Returns Mean          -43.5248
exploration/Returns Std            19.165
exploration/Returns Max           -25.5445
exploration/Returns Min           -70.3303
exploration/Actions Mean            0.0413868
exploration/Actions Std             0.24904
exploration/Actions Max             0.999076
exploration/Actions Min            -0.937747
exploration/Num Paths               5
exploration/Average Returns       -43.5248
evaluation/num steps total     232500
evaluation/num paths total       2325
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.220964
evaluation/Rewards Std              0.992413
evaluation/Rewards Max             -0.0203754
evaluation/Rewards Min             -9.99737
evaluation/Returns Mean           -22.0964
evaluation/Returns Std             16.796
evaluation/Returns Max             -2.46259
evaluation/Returns Min            -53.308
evaluation/Actions Mean             0.0216474
evaluation/Actions Std              0.183435
evaluation/Actions Max              0.995923
evaluation/Actions Min             -0.993606
evaluation/Num Paths               25
evaluation/Average Returns        -22.0964
time/data storing (s)               0.00297918
time/evaluation sampling (s)        0.574971
time/exploration sampling (s)       0.159463
time/logging (s)                    0.006583
time/saving (s)                     0.00193462
time/training (s)                   2.11097
time/epoch (s)                      2.8569
time/total (s)                    260.902
Epoch                              92
-----------------------------  ---------------
2019-04-22 21:13:10.756445 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 93 finished
-----------------------------  ---------------
replay_buffer/size              47200
trainer/QF1 Loss                    0.0657757
trainer/QF2 Loss                    0.0918089
trainer/Policy Loss                10.3507
trainer/Q1 Predictions Mean        -8.60075
trainer/Q1 Predictions Std          5.94848
trainer/Q1 Predictions Max         -7.14219
trainer/Q1 Predictions Min        -60.0249
trainer/Q2 Predictions Mean        -8.59157
trainer/Q2 Predictions Std          5.9285
trainer/Q2 Predictions Max         -7.10529
trainer/Q2 Predictions Min        -59.9224
trainer/Q Targets Mean             -8.67426
trainer/Q Targets Std               6.01444
trainer/Q Targets Max              -7.04921
trainer/Q Targets Min             -60.1858
trainer/Log Pis Mean                1.89417
trainer/Log Pis Std                 1.00654
trainer/Log Pis Max                 5.44421
trainer/Log Pis Min                -1.44921
trainer/Policy mu Mean             -0.0190315
trainer/Policy mu Std               0.568579
trainer/Policy mu Max               2.90377
trainer/Policy mu Min              -2.59175
trainer/Policy log std Mean        -2.11756
trainer/Policy log std Std          0.395506
trainer/Policy log std Max         -0.494304
trainer/Policy log std Min         -2.45876
trainer/Alpha                       0.0519757
trainer/Alpha Loss                 -0.312952
exploration/num steps total     47200
exploration/num paths total       472
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.269036
exploration/Rewards Std             0.753708
exploration/Rewards Max            -0.00708348
exploration/Rewards Min            -8.19691
exploration/Returns Mean          -26.9036
exploration/Returns Std            12.7947
exploration/Returns Max           -16.7537
exploration/Returns Min           -51.7622
exploration/Actions Mean            0.0136998
exploration/Actions Std             0.219917
exploration/Actions Max             0.996065
exploration/Actions Min            -0.998931
exploration/Num Paths               5
exploration/Average Returns       -26.9036
evaluation/num steps total     235000
evaluation/num paths total       2350
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.214225
evaluation/Rewards Std              0.88773
evaluation/Rewards Max             -0.0410009
evaluation/Rewards Min             -9.66253
evaluation/Returns Mean           -21.4225
evaluation/Returns Std             13.1979
evaluation/Returns Max             -5.24072
evaluation/Returns Min            -52.3609
evaluation/Actions Mean             0.0176036
evaluation/Actions Std              0.184669
evaluation/Actions Max              0.996146
evaluation/Actions Min             -0.99732
evaluation/Num Paths               25
evaluation/Average Returns        -21.4225
time/data storing (s)               0.00341997
time/evaluation sampling (s)        0.638022
time/exploration sampling (s)       0.159139
time/logging (s)                    0.00647518
time/saving (s)                     0.00190882
time/training (s)                   2.1835
time/epoch (s)                      2.99247
time/total (s)                    263.9
Epoch                              93
-----------------------------  ---------------
2019-04-22 21:13:13.662807 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 94 finished
-----------------------------  ---------------
replay_buffer/size              47700
trainer/QF1 Loss                    0.0722631
trainer/QF2 Loss                    0.0710261
trainer/Policy Loss                10.5126
trainer/Q1 Predictions Mean        -8.41785
trainer/Q1 Predictions Std          4.78354
trainer/Q1 Predictions Max         -7.14053
trainer/Q1 Predictions Min        -39.1146
trainer/Q2 Predictions Mean        -8.40547
trainer/Q2 Predictions Std          4.84975
trainer/Q2 Predictions Max         -7.06645
trainer/Q2 Predictions Min        -39.3613
trainer/Q Targets Mean             -8.46471
trainer/Q Targets Std               4.96097
trainer/Q Targets Max              -7.0404
trainer/Q Targets Min             -40.2861
trainer/Log Pis Mean                2.17083
trainer/Log Pis Std                 1.0988
trainer/Log Pis Max                 5.81024
trainer/Log Pis Min                -3.10122
trainer/Policy mu Mean              0.0833021
trainer/Policy mu Std               0.602854
trainer/Policy mu Max               2.96139
trainer/Policy mu Min              -2.52165
trainer/Policy log std Mean        -2.22437
trainer/Policy log std Std          0.426393
trainer/Policy log std Max         -0.540084
trainer/Policy log std Min         -2.58186
trainer/Alpha                       0.0528274
trainer/Alpha Loss                  0.50242
exploration/num steps total     47700
exploration/num paths total       477
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.233897
exploration/Rewards Std             0.69634
exploration/Rewards Max            -0.00787956
exploration/Rewards Min            -7.10953
exploration/Returns Mean          -23.3897
exploration/Returns Std            10.34
exploration/Returns Max           -11.264
exploration/Returns Min           -37.4251
exploration/Actions Mean            0.0263783
exploration/Actions Std             0.198725
exploration/Actions Max             0.997581
exploration/Actions Min            -0.923241
exploration/Num Paths               5
exploration/Average Returns       -23.3897
evaluation/num steps total     237500
evaluation/num paths total       2375
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.254698
evaluation/Rewards Std              1.01006
evaluation/Rewards Max             -0.00474033
evaluation/Rewards Min             -9.94931
evaluation/Returns Mean           -25.4698
evaluation/Returns Std             16.4609
evaluation/Returns Max             -5.4365
evaluation/Returns Min            -57.9966
evaluation/Actions Mean             0.0261776
evaluation/Actions Std              0.184673
evaluation/Actions Max              0.997207
evaluation/Actions Min             -0.995465
evaluation/Num Paths               25
evaluation/Average Returns        -25.4698
time/data storing (s)               0.00340004
time/evaluation sampling (s)        0.569527
time/exploration sampling (s)       0.160786
time/logging (s)                    0.00672202
time/saving (s)                     0.00194542
time/training (s)                   2.15733
time/epoch (s)                      2.89971
time/total (s)                    266.804
Epoch                              94
-----------------------------  ---------------
2019-04-22 21:13:16.485631 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 95 finished
-----------------------------  ---------------
replay_buffer/size              48200
trainer/QF1 Loss                    0.0249238
trainer/QF2 Loss                    0.0233331
trainer/Policy Loss                11.0355
trainer/Q1 Predictions Mean        -8.97821
trainer/Q1 Predictions Std          6.79313
trainer/Q1 Predictions Max         -7.1006
trainer/Q1 Predictions Min        -49.5057
trainer/Q2 Predictions Mean        -9.00246
trainer/Q2 Predictions Std          6.78001
trainer/Q2 Predictions Max         -7.11394
trainer/Q2 Predictions Min        -49.851
trainer/Q Targets Mean             -9.02393
trainer/Q Targets Std               6.75657
trainer/Q Targets Max              -7.0577
trainer/Q Targets Min             -49.8337
trainer/Log Pis Mean                2.19518
trainer/Log Pis Std                 1.36402
trainer/Log Pis Max                 9.14071
trainer/Log Pis Min                -1.01475
trainer/Policy mu Mean              0.129334
trainer/Policy mu Std               0.649856
trainer/Policy mu Max               3.01358
trainer/Policy mu Min              -3.01422
trainer/Policy log std Mean        -2.14429
trainer/Policy log std Std          0.418299
trainer/Policy log std Max         -0.443826
trainer/Policy log std Min         -2.45933
trainer/Alpha                       0.0524602
trainer/Alpha Loss                  0.575321
exploration/num steps total     48200
exploration/num paths total       482
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.28944
exploration/Rewards Std             0.840499
exploration/Rewards Max            -0.00328947
exploration/Rewards Min            -8.29287
exploration/Returns Mean          -28.944
exploration/Returns Std            12.5772
exploration/Returns Max           -15.6182
exploration/Returns Min           -50.798
exploration/Actions Mean            0.0141373
exploration/Actions Std             0.229353
exploration/Actions Max             0.999781
exploration/Actions Min            -0.997132
exploration/Num Paths               5
exploration/Average Returns       -28.944
evaluation/num steps total     240000
evaluation/num paths total       2400
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.232085
evaluation/Rewards Std              1.02503
evaluation/Rewards Max             -0.00315369
evaluation/Rewards Min            -10.5809
evaluation/Returns Mean           -23.2085
evaluation/Returns Std             17.4995
evaluation/Returns Max             -2.89675
evaluation/Returns Min            -58.1483
evaluation/Actions Mean             0.0236294
evaluation/Actions Std              0.189542
evaluation/Actions Max              0.996628
evaluation/Actions Min             -0.995753
evaluation/Num Paths               25
evaluation/Average Returns        -23.2085
time/data storing (s)               0.00298551
time/evaluation sampling (s)        0.556694
time/exploration sampling (s)       0.155587
time/logging (s)                    0.00657552
time/saving (s)                     0.00198402
time/training (s)                   2.09171
time/epoch (s)                      2.81554
time/total (s)                    269.625
Epoch                              95
-----------------------------  ---------------
2019-04-22 21:13:19.353993 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 96 finished
-----------------------------  ---------------
replay_buffer/size              48700
trainer/QF1 Loss                    1.06788
trainer/QF2 Loss                    1.09388
trainer/Policy Loss                10.9708
trainer/Q1 Predictions Mean        -9.03142
trainer/Q1 Predictions Std          6.37462
trainer/Q1 Predictions Max         -7.03304
trainer/Q1 Predictions Min        -38.6716
trainer/Q2 Predictions Mean        -9.06086
trainer/Q2 Predictions Std          6.39626
trainer/Q2 Predictions Max         -7.02832
trainer/Q2 Predictions Min        -38.5398
trainer/Q Targets Mean             -8.96367
trainer/Q Targets Std               6.4296
trainer/Q Targets Max              -0.0339119
trainer/Q Targets Min             -38.2296
trainer/Log Pis Mean                2.07106
trainer/Log Pis Std                 1.19429
trainer/Log Pis Max                 6.47452
trainer/Log Pis Min                -1.59208
trainer/Policy mu Mean              0.118798
trainer/Policy mu Std               0.708763
trainer/Policy mu Max               3.02762
trainer/Policy mu Min              -2.56533
trainer/Policy log std Mean        -2.1277
trainer/Policy log std Std          0.431231
trainer/Policy log std Max         -0.431368
trainer/Policy log std Min         -2.44855
trainer/Alpha                       0.0534838
trainer/Alpha Loss                  0.208098
exploration/num steps total     48700
exploration/num paths total       487
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.363806
exploration/Rewards Std             1.04915
exploration/Rewards Max            -0.00653195
exploration/Rewards Min            -8.60218
exploration/Returns Mean          -36.3806
exploration/Returns Std            11.8803
exploration/Returns Max           -17
exploration/Returns Min           -50.7581
exploration/Actions Mean            0.0254167
exploration/Actions Std             0.235117
exploration/Actions Max             0.998229
exploration/Actions Min            -0.984832
exploration/Num Paths               5
exploration/Average Returns       -36.3806
evaluation/num steps total     242500
evaluation/num paths total       2425
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.291898
evaluation/Rewards Std              1.15576
evaluation/Rewards Max             -0.0416083
evaluation/Rewards Min            -10.6826
evaluation/Returns Mean           -29.1898
evaluation/Returns Std             17.2122
evaluation/Returns Max             -4.28353
evaluation/Returns Min            -57.24
evaluation/Actions Mean             0.028377
evaluation/Actions Std              0.197381
evaluation/Actions Max              0.99599
evaluation/Actions Min             -0.995355
evaluation/Num Paths               25
evaluation/Average Returns        -29.1898
time/data storing (s)               0.00310239
time/evaluation sampling (s)        0.568612
time/exploration sampling (s)       0.16311
time/logging (s)                    0.00672333
time/saving (s)                     0.00198442
time/training (s)                   2.11804
time/epoch (s)                      2.86157
time/total (s)                    272.491
Epoch                              96
-----------------------------  ---------------
2019-04-22 21:13:22.168510 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 97 finished
-----------------------------  ---------------
replay_buffer/size              49200
trainer/QF1 Loss                    0.223814
trainer/QF2 Loss                    0.242799
trainer/Policy Loss                 9.75852
trainer/Q1 Predictions Mean        -8.47381
trainer/Q1 Predictions Std          3.79665
trainer/Q1 Predictions Max         -7.16029
trainer/Q1 Predictions Min        -33.1622
trainer/Q2 Predictions Mean        -8.48129
trainer/Q2 Predictions Std          3.78359
trainer/Q2 Predictions Max         -7.14141
trainer/Q2 Predictions Min        -33.1353
trainer/Q Targets Mean             -8.36628
trainer/Q Targets Std               3.70018
trainer/Q Targets Max              -7.08738
trainer/Q Targets Min             -33.1201
trainer/Log Pis Mean                1.49266
trainer/Log Pis Std                 1.13753
trainer/Log Pis Max                 4.85833
trainer/Log Pis Min                -3.05375
trainer/Policy mu Mean             -0.0158806
trainer/Policy mu Std               0.626332
trainer/Policy mu Max               2.6991
trainer/Policy mu Min              -2.50515
trainer/Policy log std Mean        -1.86798
trainer/Policy log std Std          0.400817
trainer/Policy log std Max         -0.533317
trainer/Policy log std Min         -2.23116
trainer/Alpha                       0.0520793
trainer/Alpha Loss                 -1.4987
exploration/num steps total     49200
exploration/num paths total       492
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.389378
exploration/Rewards Std             0.94228
exploration/Rewards Max            -0.00670901
exploration/Rewards Min            -7.59866
exploration/Returns Mean          -38.9378
exploration/Returns Std             5.8819
exploration/Returns Max           -31.6898
exploration/Returns Min           -49.0298
exploration/Actions Mean            0.0270235
exploration/Actions Std             0.261454
exploration/Actions Max             0.997571
exploration/Actions Min            -0.998638
exploration/Num Paths               5
exploration/Average Returns       -38.9378
evaluation/num steps total     245000
evaluation/num paths total       2450
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.33458
evaluation/Rewards Std              1.07711
evaluation/Rewards Max             -0.105643
evaluation/Rewards Min            -10.8428
evaluation/Returns Mean           -33.458
evaluation/Returns Std             16.2512
evaluation/Returns Max            -13.7902
evaluation/Returns Min            -68.4123
evaluation/Actions Mean             0.024837
evaluation/Actions Std              0.197915
evaluation/Actions Max              0.994531
evaluation/Actions Min             -0.997295
evaluation/Num Paths               25
evaluation/Average Returns        -33.458
time/data storing (s)               0.0029959
time/evaluation sampling (s)        0.555338
time/exploration sampling (s)       0.158681
time/logging (s)                    0.00612331
time/saving (s)                     0.00194072
time/training (s)                   2.0809
time/epoch (s)                      2.80598
time/total (s)                    275.302
Epoch                              97
-----------------------------  ---------------
2019-04-22 21:13:25.041030 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 98 finished
-----------------------------  ---------------
replay_buffer/size              49700
trainer/QF1 Loss                    0.0406316
trainer/QF2 Loss                    0.0382443
trainer/Policy Loss                10.235
trainer/Q1 Predictions Mean        -8.57824
trainer/Q1 Predictions Std          7.60405
trainer/Q1 Predictions Max         -6.97321
trainer/Q1 Predictions Min        -79.3319
trainer/Q2 Predictions Mean        -8.63724
trainer/Q2 Predictions Std          7.59589
trainer/Q2 Predictions Max         -7.0326
trainer/Q2 Predictions Min        -79.2427
trainer/Q Targets Mean             -8.67733
trainer/Q Targets Std               7.61517
trainer/Q Targets Max              -6.99057
trainer/Q Targets Min             -79.7838
trainer/Log Pis Mean                1.82312
trainer/Log Pis Std                 1.28185
trainer/Log Pis Max                 7.10615
trainer/Log Pis Min                -1.61645
trainer/Policy mu Mean              0.0735765
trainer/Policy mu Std               0.643479
trainer/Policy mu Max               3.30727
trainer/Policy mu Min              -2.87716
trainer/Policy log std Mean        -2.13953
trainer/Policy log std Std          0.396306
trainer/Policy log std Max         -0.612058
trainer/Policy log std Min         -2.44448
trainer/Alpha                       0.0520187
trainer/Alpha Loss                 -0.522893
exploration/num steps total     49700
exploration/num paths total       497
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.335586
exploration/Rewards Std             1.01962
exploration/Rewards Max            -0.0132086
exploration/Rewards Min            -9.11642
exploration/Returns Mean          -33.5586
exploration/Returns Std            15.7906
exploration/Returns Max           -15.3447
exploration/Returns Min           -58.6686
exploration/Actions Mean            0.025428
exploration/Actions Std             0.236056
exploration/Actions Max             0.997434
exploration/Actions Min            -0.992419
exploration/Num Paths               5
exploration/Average Returns       -33.5586
evaluation/num steps total     247500
evaluation/num paths total       2475
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.306647
evaluation/Rewards Std              1.22296
evaluation/Rewards Max             -0.00822177
evaluation/Rewards Min            -10.3776
evaluation/Returns Mean           -30.6647
evaluation/Returns Std             19.2009
evaluation/Returns Max             -4.45316
evaluation/Returns Min            -59.4974
evaluation/Actions Mean             0.0290611
evaluation/Actions Std              0.201533
evaluation/Actions Max              0.998621
evaluation/Actions Min             -0.995995
evaluation/Num Paths               25
evaluation/Average Returns        -30.6647
time/data storing (s)               0.00340433
time/evaluation sampling (s)        0.551068
time/exploration sampling (s)       0.157302
time/logging (s)                    0.00669656
time/saving (s)                     0.00203116
time/training (s)                   2.14567
time/epoch (s)                      2.86617
time/total (s)                    278.174
Epoch                              98
-----------------------------  ---------------
2019-04-22 21:13:27.865401 PDT | [sac-pointmass-multitask-1_2019_04_22_21_08_46_0000--s-0] Epoch 99 finished
-----------------------------  ---------------
replay_buffer/size              50200
trainer/QF1 Loss                    1.48372
trainer/QF2 Loss                    1.50113
trainer/Policy Loss                 9.99039
trainer/Q1 Predictions Mean        -7.91742
trainer/Q1 Predictions Std          3.09052
trainer/Q1 Predictions Max         -7.03819
trainer/Q1 Predictions Min        -28.7367
trainer/Q2 Predictions Mean        -7.91113
trainer/Q2 Predictions Std          3.08592
trainer/Q2 Predictions Max         -7.03287
trainer/Q2 Predictions Min        -28.6616
trainer/Q Targets Mean             -7.74385
trainer/Q Targets Std               3.38867
trainer/Q Targets Max              -0.210617
trainer/Q Targets Min             -28.4953
trainer/Log Pis Mean                2.24043
trainer/Log Pis Std                 1.12902
trainer/Log Pis Max                 7.68592
trainer/Log Pis Min                -1.7061
trainer/Policy mu Mean              0.0660324
trainer/Policy mu Std               0.516815
trainer/Policy mu Max               2.63018
trainer/Policy mu Min              -2.92745
trainer/Policy log std Mean        -2.24702
trainer/Policy log std Std          0.357174
trainer/Policy log std Max         -0.658898
trainer/Policy log std Min         -2.52767
trainer/Alpha                       0.0526732
trainer/Alpha Loss                  0.7078
exploration/num steps total     50200
exploration/num paths total       502
exploration/path length Mean      100
exploration/path length Std         0
exploration/path length Max       100
exploration/path length Min       100
exploration/Rewards Mean           -0.221185
exploration/Rewards Std             0.628866
exploration/Rewards Max            -0.00768866
exploration/Rewards Min            -7.58632
exploration/Returns Mean          -22.1185
exploration/Returns Std             8.9141
exploration/Returns Max           -11.8704
exploration/Returns Min           -38.1324
exploration/Actions Mean            0.00771356
exploration/Actions Std             0.210236
exploration/Actions Max             0.994696
exploration/Actions Min            -0.997005
exploration/Num Paths               5
exploration/Average Returns       -22.1185
evaluation/num steps total     250000
evaluation/num paths total       2500
evaluation/path length Mean       100
evaluation/path length Std          0
evaluation/path length Max        100
evaluation/path length Min        100
evaluation/Rewards Mean            -0.230299
evaluation/Rewards Std              1.07749
evaluation/Rewards Max             -0.00901021
evaluation/Rewards Min            -10.688
evaluation/Returns Mean           -23.0299
evaluation/Returns Std             17.8131
evaluation/Returns Max             -1.37988
evaluation/Returns Min            -59.8734
evaluation/Actions Mean             0.0204362
evaluation/Actions Std              0.192861
evaluation/Actions Max              0.997703
evaluation/Actions Min             -0.996765
evaluation/Num Paths               25
evaluation/Average Returns        -23.0299
time/data storing (s)               0.00300868
time/evaluation sampling (s)        0.562643
time/exploration sampling (s)       0.159568
time/logging (s)                    0.00541332
time/saving (s)                     0.00159204
time/training (s)                   2.08287
time/epoch (s)                      2.81509
time/total (s)                    280.994
Epoch                              99
-----------------------------  ---------------
